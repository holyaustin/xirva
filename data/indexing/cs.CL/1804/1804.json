[{"id": "1804.00015", "submitter": "Shinji Watanabe", "authors": "Shinji Watanabe, Takaaki Hori, Shigeki Karita, Tomoki Hayashi, Jiro\n  Nishitoba, Yuya Unno, Nelson Enrique Yalta Soplin, Jahn Heymann, Matthew\n  Wiesner, Nanxin Chen, Adithya Renduchintala, Tsubasa Ochiai", "title": "ESPnet: End-to-End Speech Processing Toolkit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new open source platform for end-to-end speech\nprocessing named ESPnet. ESPnet mainly focuses on end-to-end automatic speech\nrecognition (ASR), and adopts widely-used dynamic neural network toolkits,\nChainer and PyTorch, as a main deep learning engine. ESPnet also follows the\nKaldi ASR toolkit style for data processing, feature extraction/format, and\nrecipes to provide a complete setup for speech recognition and other speech\nprocessing experiments. This paper explains a major architecture of this\nsoftware platform, several important functionalities, which differentiate\nESPnet from other open source ASR toolkits, and experimental results with major\nASR benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 18:09:39 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Watanabe", "Shinji", ""], ["Hori", "Takaaki", ""], ["Karita", "Shigeki", ""], ["Hayashi", "Tomoki", ""], ["Nishitoba", "Jiro", ""], ["Unno", "Yuya", ""], ["Soplin", "Nelson Enrique Yalta", ""], ["Heymann", "Jahn", ""], ["Wiesner", "Matthew", ""], ["Chen", "Nanxin", ""], ["Renduchintala", "Adithya", ""], ["Ochiai", "Tsubasa", ""]]}, {"id": "1804.00047", "submitter": "Albert Haque", "authors": "Albert Haque, Michelle Guo, Prateek Verma", "title": "Conditional End-to-End Audio Transforms", "comments": "Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an end-to-end method for transforming audio from one style to\nanother. For the case of speech, by conditioning on speaker identities, we can\ntrain a single model to transform words spoken by multiple people into multiple\ntarget voices. For the case of music, we can specify musical instruments and\nachieve the same result. Architecturally, our method is a fully-differentiable\nsequence-to-sequence model based on convolutional and hierarchical recurrent\nneural networks. It is designed to capture long-term acoustic dependencies,\nrequires minimal post-processing, and produces realistic audio transforms.\nAblation studies confirm that our model can separate speaker and instrument\nproperties from acoustic content at different receptive fields. Empirically,\nour method achieves competitive performance on community-standard datasets.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 20:17:31 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 06:37:44 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Haque", "Albert", ""], ["Guo", "Michelle", ""], ["Verma", "Prateek", ""]]}, {"id": "1804.00065", "submitter": "Yohan Jo", "authors": "Yohan Jo, Shivani Poddar, Byungsoo Jeon, Qinlan Shen, Carolyn P. Rose,\n  Graham Neubig", "title": "Attentive Interaction Model: Modeling Changes in View in Argumentation", "comments": "2018 Conference of the North American Chapter of the Association for\n  Computational Linguistics: Human Language Technologies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural architecture for modeling argumentative dialogue that\nexplicitly models the interplay between an Opinion Holder's (OH's) reasoning\nand a challenger's argument, with the goal of predicting if the argument\nsuccessfully changes the OH's view. The model has two components: (1)\nvulnerable region detection, an attention model that identifies parts of the\nOH's reasoning that are amenable to change, and (2) interaction encoding, which\nidentifies the relationship between the content of the OH's reasoning and that\nof the challenger's argument. Based on evaluation on discussions from the\nChange My View forum on Reddit, the two components work together to predict an\nOH's change in view, outperforming several baselines. A posthoc analysis\nsuggests that sentences picked out by the attention model are addressed more\nfrequently by successful arguments than by unsuccessful ones.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 21:57:40 GMT"}, {"version": "v2", "created": "Wed, 18 Apr 2018 15:35:32 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Jo", "Yohan", ""], ["Poddar", "Shivani", ""], ["Jeon", "Byungsoo", ""], ["Shen", "Qinlan", ""], ["Rose", "Carolyn P.", ""], ["Neubig", "Graham", ""]]}, {"id": "1804.00079", "submitter": "Sandeep Subramanian", "authors": "Sandeep Subramanian, Adam Trischler, Yoshua Bengio, Christopher J Pal", "title": "Learning General Purpose Distributed Sentence Representations via Large\n  Scale Multi-task Learning", "comments": "Accepted at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A lot of the recent success in natural language processing (NLP) has been\ndriven by distributed vector representations of words trained on large amounts\nof text in an unsupervised manner. These representations are typically used as\ngeneral purpose features for words across a range of NLP problems. However,\nextending this success to learning representations of sequences of words, such\nas sentences, remains an open problem. Recent work has explored unsupervised as\nwell as supervised learning techniques with different training objectives to\nlearn general purpose fixed-length sentence representations. In this work, we\npresent a simple, effective multi-task learning framework for sentence\nrepresentations that combines the inductive biases of diverse training\nobjectives in a single model. We train this model on several data sources with\nmultiple training objectives on over 100 million sentences. Extensive\nexperiments demonstrate that sharing a single recurrent sentence encoder across\nweakly related tasks leads to consistent improvements over previous methods. We\npresent substantial improvements in the context of transfer learning and\nlow-resource settings using our learned general-purpose representations.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 23:05:15 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Subramanian", "Sandeep", ""], ["Trischler", "Adam", ""], ["Bengio", "Yoshua", ""], ["Pal", "Christopher J", ""]]}, {"id": "1804.00084", "submitter": "Johnnatan Messias", "authors": "Johnnatan Messias", "title": "Characterizing Interconnections and Linguistic Patterns in Twitter", "comments": "This is a dissertation presented to the Graduate Program in Computer\n  Science of the Universidade Federal de Minas Gerais in partial fulfillment of\n  the requirements for the degree of Master in Computer Science.\n  http://www.bibliotecadigital.ufmg.br/dspace/handle/1843/JCES-ARDPRE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media is considered a democratic space in which people connect and\ninteract with each other regardless of their gender, race, or any other\ndemographic aspect. Despite numerous efforts that explore demographic aspects\nin social media, it is still unclear whether social media perpetuates old\ninequalities from the offline world. In this dissertation, we attempt to\nidentify gender and race of Twitter users located in the United States using\nadvanced image processing algorithms from Face++. We investigate how different\ndemographic groups connect with each other and differentiate them regarding\nlinguistic styles and also their interests. We quantify to what extent one\ngroup follows and interacts with each other and the extent to which these\nconnections and interactions reflect in inequalities in Twitter. We also\nextract linguistic features from six categories (affective attributes,\ncognitive attributes, lexical density and awareness, temporal references,\nsocial and personal concerns, and interpersonal focus) in order to identify the\nsimilarities and the differences in the messages they share in Twitter.\nFurthermore, we extract the absolute ranking difference of top phrases between\ndemographic groups. As a dimension of diversity, we use the topics of interest\nthat we retrieve from each user. Our analysis shows that users identified as\nwhite and male tend to attain higher positions, in terms of the number of\nfollowers and number of times in another user's lists, in Twitter. There are\nclear differences in the way of writing across different demographic groups in\nboth gender and race domains as well as in the topic of interest. We hope our\neffort can stimulate the development of new theories of demographic information\nin the online space. Finally, we developed a Web-based system that leverages\nthe demographic aspects of users to provide transparency to the Twitter\ntrending topics system.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 23:31:43 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Messias", "Johnnatan", ""]]}, {"id": "1804.00146", "submitter": "Simon Keizer", "authors": "Simon Keizer and Verena Rieser", "title": "Towards Learning Transferable Conversational Skills using\n  Multi-dimensional Dialogue Modelling", "comments": "A short version of this paper has been published in Proc. 21st\n  Workshop on the Semantics and Pragmatics of Dialogue (SemDial/SaarDial)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent statistical approaches have improved the robustness and scalability of\nspoken dialogue systems. However, despite recent progress in domain adaptation,\ntheir reliance on in-domain data still limits their cross-domain scalability.\nIn this paper, we argue that this problem can be addressed by extending current\nmodels to reflect and exploit the multi-dimensional nature of human dialogue.\nWe present our multi-dimensional, statistical dialogue management framework, in\nwhich transferable conversational skills can be learnt by separating out\ndomain-independent dimensions of communication and using multi-agent\nreinforcement learning. Our initial experiments with a simulated user show that\nwe can speed up the learning process by transferring learnt policies.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2018 10:15:44 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Keizer", "Simon", ""], ["Rieser", "Verena", ""]]}, {"id": "1804.00247", "submitter": "Martin Popel", "authors": "Martin Popel, Ond\\v{r}ej Bojar", "title": "Training Tips for the Transformer Model", "comments": "This is the version published in PBML\n  (https://ufal.mff.cuni.cz/pbml/110/art-popel-bojar.pdf)", "journal-ref": "The Prague Bulletin of Mathematical Linguistics 110, April 2018,\n  pp. 43-70", "doi": "10.2478/pralin-2018-0002", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article describes our experiments in neural machine translation using\nthe recent Tensor2Tensor framework and the Transformer sequence-to-sequence\nmodel (Vaswani et al., 2017). We examine some of the critical parameters that\naffect the final translation quality, memory usage, training stability and\ntraining time, concluding each experiment with a set of recommendations for\nfellow researchers. In addition to confirming the general mantra \"more data and\nlarger models\", we address scaling to multiple GPUs and provide practical tips\nfor improved training regarding batch size, learning rate, warmup steps,\nmaximum sentence length and checkpoint averaging. We hope that our observations\nwill allow others to get better results given their particular hardware and\ndata constraints.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 01:59:52 GMT"}, {"version": "v2", "created": "Wed, 2 May 2018 15:27:25 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Popel", "Martin", ""], ["Bojar", "Ond\u0159ej", ""]]}, {"id": "1804.00306", "submitter": "Cun Mu", "authors": "Cun Mu, Guang Yang and Zheng Yan", "title": "Revisiting Skip-Gram Negative Sampling Model with Rectification", "comments": "Accepted for publication in the proceedings of 2019 Computing\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit skip-gram negative sampling (SGNS), one of the most popular\nneural-network based approaches to learning distributed word representation. We\nfirst point out the ambiguity issue undermining the SGNS model, in the sense\nthat the word vectors can be entirely distorted without changing the objective\nvalue. To resolve the issue, we investigate the intrinsic structures in\nsolution that a good word embedding model should deliver. Motivated by this, we\nrectify the SGNS model with quadratic regularization, and show that this simple\nmodification suffices to structure the solution in the desired manner. A\ntheoretical justification is presented, which provides novel insights into\nquadratic regularization . Preliminary experiments are also conducted on\nGoogle's analytical reasoning task to support the modified SGNS model.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 15:41:01 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 16:14:55 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Mu", "Cun", ""], ["Yang", "Guang", ""], ["Yan", "Zheng", ""]]}, {"id": "1804.00316", "submitter": "Hung-Yi Lee", "authors": "Da-Rong Liu, Kuan-Yu Chen, Hung-Yi Lee, Lin-shan Lee", "title": "Completely Unsupervised Phoneme Recognition by Adversarially Learning\n  Mapping Relationships from Audio Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised discovery of acoustic tokens from audio corpora without\nannotation and learning vector representations for these tokens have been\nwidely studied. Although these techniques have been shown successful in some\napplications such as query-by-example Spoken Term Detection (STD), the lack of\nmapping relationships between these discovered tokens and real phonemes have\nlimited the down-stream applications. This paper represents probably the first\nattempt towards the goal of completely unsupervised phoneme recognition, or\nmapping audio signals to phoneme sequences without phoneme-labeled audio data.\nThe basic idea is to cluster the embedded acoustic tokens and learn the mapping\nbetween the cluster sequences and the unknown phoneme sequences with a\nGenerative Adversarial Network (GAN). An unsupervised phoneme recognition\naccuracy of 36% was achieved in the preliminary experiments.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 16:35:21 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Liu", "Da-Rong", ""], ["Chen", "Kuan-Yu", ""], ["Lee", "Hung-Yi", ""], ["Lee", "Lin-shan", ""]]}, {"id": "1804.00318", "submitter": "Hung-Yi Lee", "authors": "Pei-Hung Chung, Kuan Tung, Ching-Lun Tai, Hung-Yi Lee", "title": "Joint Learning of Interactive Spoken Content Retrieval and Trainable\n  User Simulator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User-machine interaction is crucial for information retrieval, especially for\nspoken content retrieval, because spoken content is difficult to browse, and\nspeech recognition has a high degree of uncertainty. In interactive retrieval,\nthe machine takes different actions to interact with the user to obtain better\nretrieval results; here it is critical to select the most efficient action. In\nprevious work, deep Q-learning techniques were proposed to train an interactive\nretrieval system but rely on a hand-crafted user simulator; building a reliable\nuser simulator is difficult. In this paper, we further improve the interactive\nspoken content retrieval framework by proposing a learnable user simulator\nwhich is jointly trained with interactive retrieval system, making the\nhand-crafted user simulator unnecessary. The experimental results show that the\nlearned simulated users not only achieve larger rewards than the hand-crafted\nones but act more like real users.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 16:46:53 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Chung", "Pei-Hung", ""], ["Tung", "Kuan", ""], ["Tai", "Ching-Lun", ""], ["Lee", "Hung-Yi", ""]]}, {"id": "1804.00320", "submitter": "Hung-Yi Lee", "authors": "Chia-Hsuan Li, Szu-Lin Wu, Chi-Liang Liu, Hung-yi Lee", "title": "Spoken SQuAD: A Study of Mitigating the Impact of Speech Recognition\n  Errors on Listening Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reading comprehension has been widely studied. One of the most representative\nreading comprehension tasks is Stanford Question Answering Dataset (SQuAD), on\nwhich machine is already comparable with human. On the other hand, accessing\nlarge collections of multimedia or spoken content is much more difficult and\ntime-consuming than plain text content for humans. It's therefore highly\nattractive to develop machines which can automatically understand spoken\ncontent. In this paper, we propose a new listening comprehension task - Spoken\nSQuAD. On the new task, we found that speech recognition errors have\ncatastrophic impact on machine comprehension, and several approaches are\nproposed to mitigate the impact.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 17:12:47 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Li", "Chia-Hsuan", ""], ["Wu", "Szu-Lin", ""], ["Liu", "Chi-Liang", ""], ["Lee", "Hung-yi", ""]]}, {"id": "1804.00344", "submitter": "Marcin Junczys-Dowmunt", "authors": "Marcin Junczys-Dowmunt, Roman Grundkiewicz, Tomasz Dwojak, Hieu Hoang,\n  Kenneth Heafield, Tom Neckermann, Frank Seide, Ulrich Germann, Alham Fikri\n  Aji, Nikolay Bogoychev, Andr\\'e F. T. Martins, Alexandra Birch", "title": "Marian: Fast Neural Machine Translation in C++", "comments": "Demonstration paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Marian, an efficient and self-contained Neural Machine Translation\nframework with an integrated automatic differentiation engine based on dynamic\ncomputation graphs. Marian is written entirely in C++. We describe the design\nof the encoder-decoder framework and demonstrate that a research-friendly\ntoolkit can achieve high training and translation speed.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 20:50:57 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 04:11:44 GMT"}, {"version": "v3", "created": "Wed, 4 Apr 2018 15:34:17 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Junczys-Dowmunt", "Marcin", ""], ["Grundkiewicz", "Roman", ""], ["Dwojak", "Tomasz", ""], ["Hoang", "Hieu", ""], ["Heafield", "Kenneth", ""], ["Neckermann", "Tom", ""], ["Seide", "Frank", ""], ["Germann", "Ulrich", ""], ["Aji", "Alham Fikri", ""], ["Bogoychev", "Nikolay", ""], ["Martins", "Andr\u00e9 F. T.", ""], ["Birch", "Alexandra", ""]]}, {"id": "1804.00401", "submitter": "Carsten Binnig", "authors": "Prasetya Utama, Nathaniel Weir, Fuat Basik, Carsten Binnig, Ugur\n  Cetintemel, Benjamin H\\\"attasch, Amir Ilkhechi, Shekar Ramaswamy, Arif Usta", "title": "An End-to-end Neural Natural Language Interface for Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to extract insights from new data sets is critical for decision\nmaking. Visual interactive tools play an important role in data exploration\nsince they provide non-technical users with an effective way to visually\ncompose queries and comprehend the results. Natural language has recently\ngained traction as an alternative query interface to databases with the\npotential to enable non-expert users to formulate complex questions and\ninformation needs efficiently and effectively. However, understanding natural\nlanguage questions and translating them accurately to SQL is a challenging\ntask, and thus Natural Language Interfaces for Databases (NLIDBs) have not yet\nmade their way into practical tools and commercial products.\n  In this paper, we present DBPal, a novel data exploration tool with a natural\nlanguage interface. DBPal leverages recent advances in deep models to make\nquery understanding more robust in the following ways: First, DBPal uses a deep\nmodel to translate natural language statements to SQL, making the translation\nprocess more robust to paraphrasing and other linguistic variations. Second, to\nsupport the users in phrasing questions without knowing the database schema and\nthe query features, DBPal provides a learned auto-completion model that\nsuggests partial query extensions to users during query formulation and thus\nhelps to write complex queries.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 05:36:38 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Utama", "Prasetya", ""], ["Weir", "Nathaniel", ""], ["Basik", "Fuat", ""], ["Binnig", "Carsten", ""], ["Cetintemel", "Ugur", ""], ["H\u00e4ttasch", "Benjamin", ""], ["Ilkhechi", "Amir", ""], ["Ramaswamy", "Shekar", ""], ["Usta", "Arif", ""]]}, {"id": "1804.00425", "submitter": "Fuming Fang", "authors": "Fuming Fang, Junichi Yamagishi, Isao Echizen, Jaime Lorenzo-Trueba", "title": "High-quality nonparallel voice conversion based on cycle-consistent\n  adversarial network", "comments": "accepted at ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although voice conversion (VC) algorithms have achieved remarkable success\nalong with the development of machine learning, superior performance is still\ndifficult to achieve when using nonparallel data. In this paper, we propose\nusing a cycle-consistent adversarial network (CycleGAN) for nonparallel\ndata-based VC training. A CycleGAN is a generative adversarial network (GAN)\noriginally developed for unpaired image-to-image translation. A subjective\nevaluation of inter-gender conversion demonstrated that the proposed method\nsignificantly outperformed a method based on the Merlin open source neural\nnetwork speech synthesis system (a parallel VC system adapted for our setup)\nand a GAN-based parallel VC system. This is the first research to show that the\nperformance of a nonparallel VC method can exceed that of state-of-the-art\nparallel VC methods.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 07:58:23 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Fang", "Fuming", ""], ["Yamagishi", "Junichi", ""], ["Echizen", "Isao", ""], ["Lorenzo-Trueba", "Jaime", ""]]}, {"id": "1804.00482", "submitter": "Spiros Georgakopoulos", "authors": "Sotiris K. Tasoulis, Aristidis G. Vrahatis, Spiros V. Georgakopoulos,\n  Vassilis P. Plagianakos", "title": "Real Time Sentiment Change Detection of Twitter Data Streams", "comments": null, "journal-ref": null, "doi": "10.1109/INISTA.2018.8466326", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, there has been a huge growth in Twitter sentiment\nanalysis having already provided a fair amount of research on sentiment\ndetection of public opinion among Twitter users. Given the fact that Twitter\nmessages are generated constantly with dizzying rates, a huge volume of\nstreaming data is created, thus there is an imperative need for accurate\nmethods for knowledge discovery and mining of this information. Although there\nexists a plethora of twitter sentiment analysis methods in the recent\nliterature, the researchers have shifted to real-time sentiment identification\non twitter streaming data, as expected. A major challenge is to deal with the\nBig Data challenges arising in Twitter streaming applications concerning both\nVolume and Velocity. Under this perspective, in this paper, a methodological\napproach based on open source tools is provided for real-time detection of\nchanges in sentiment that is ultra efficient with respect to both memory\nconsumption and computational cost. This is achieved by iteratively collecting\ntweets in real time and discarding them immediately after their process. For\nthis purpose, we employ the Lexicon approach for sentiment characterizations,\nwhile change detection is achieved through appropriate control charts that do\nnot require historical information. We believe that the proposed methodology\nprovides the trigger for a potential large-scale monitoring of threads in an\nattempt to discover fake news spread or propaganda efforts in their early\nstages. Our experimental real-time analysis based on a recent hashtag provides\nevidence that the proposed approach can detect meaningful sentiment changes\nacross a hashtags lifetime.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 13:31:11 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Tasoulis", "Sotiris K.", ""], ["Vrahatis", "Aristidis G.", ""], ["Georgakopoulos", "Spiros V.", ""], ["Plagianakos", "Vassilis P.", ""]]}, {"id": "1804.00508", "submitter": "Norma Ang\\'elica \\'Alvarez Torres", "authors": "Rivas P. Pedro E., Velarde-Anaya Omar, Gonzalez-Lopez Samuel, Rivas P.\n  Pablo, Alvarez-Torres Norma Angelica", "title": "Entrenamiento de una red neuronal para el reconocimiento de imagenes de\n  lengua de senas capturadas con sensores de profundidad", "comments": "5 pages, in Spanish, 10 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the growth of the population with hearing problems, devices have been\ndeveloped that facilitate the inclusion of deaf people in society, using\ntechnology as a communication tool, such as vision systems. Then, a solution to\nthis problem is presented using neural networks and autoencoders for the\nclassification of American Sign Language images. As a result, 99.5% accuracy\nand an error of 0.01684 were obtained for image classification\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 05:40:28 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["E.", "Rivas P. Pedro", ""], ["Omar", "Velarde-Anaya", ""], ["Samuel", "Gonzalez-Lopez", ""], ["Pablo", "Rivas P.", ""], ["Angelica", "Alvarez-Torres Norma", ""]]}, {"id": "1804.00520", "submitter": "Thanh Vu", "authors": "Thanh Vu, Dat Quoc Nguyen, Xuan-Son Vu, Dai Quoc Nguyen, Michael Catt\n  and Michael Trenell", "title": "NIHRIO at SemEval-2018 Task 3: A Simple and Accurate Neural Network\n  Model for Irony Detection in Twitter", "comments": "In proceedings of the 12th International Workshop on Semantic\n  Evaluation, SemEval 2018, to appear (6 pages, 2 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our NIHRIO system for SemEval-2018 Task 3 \"Irony\ndetection in English tweets\". We propose to use a simple neural network\narchitecture of Multilayer Perceptron with various types of input features\nincluding: lexical, syntactic, semantic and polarity features. Our system\nachieves very high performance in both subtasks of binary and multi-class irony\ndetection in tweets. In particular, we rank third using the accuracy metric and\nfifth using the F1 metric. Our code is available at\nhttps://github.com/NIHRIO/IronyDetectionInTwitter\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 14:09:01 GMT"}, {"version": "v2", "created": "Sun, 8 Apr 2018 17:34:25 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Vu", "Thanh", ""], ["Nguyen", "Dat Quoc", ""], ["Vu", "Xuan-Son", ""], ["Nguyen", "Dai Quoc", ""], ["Catt", "Michael", ""], ["Trenell", "Michael", ""]]}, {"id": "1804.00522", "submitter": "Ehsan Hosseini-Asl", "authors": "Ehsan Hosseini-Asl, Yingbo Zhou, Caiming Xiong, Richard Socher", "title": "A Multi-Discriminator CycleGAN for Unsupervised Non-Parallel Speech\n  Domain Adaptation", "comments": "Accepted to Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation plays an important role for speech recognition models, in\nparticular, for domains that have low resources. We propose a novel generative\nmodel based on cyclic-consistent generative adversarial network (CycleGAN) for\nunsupervised non-parallel speech domain adaptation. The proposed model employs\nmultiple independent discriminators on the power spectrogram, each in charge of\ndifferent frequency bands. As a result we have 1) better discriminators that\nfocus on fine-grained details of the frequency features, and 2) a generator\nthat is capable of generating more realistic domain-adapted spectrogram. We\ndemonstrate the effectiveness of our method on speech recognition with gender\nadaptation, where the model only has access to supervised data from one gender\nduring training, but is evaluated on the other at test time. Our model is able\nto achieve an average of $7.41\\%$ on phoneme error rate, and $11.10\\%$ word\nerror rate relative performance improvement as compared to the baseline, on\nTIMIT and WSJ dataset, respectively. Qualitatively, our model also generates\nmore natural sounding speech, when conditioned on data from the other domain.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 05:04:39 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 23:53:05 GMT"}, {"version": "v3", "created": "Mon, 14 May 2018 03:30:29 GMT"}, {"version": "v4", "created": "Mon, 9 Jul 2018 19:25:18 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Hosseini-Asl", "Ehsan", ""], ["Zhou", "Yingbo", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1804.00538", "submitter": "Wei Zhao", "authors": "Wei Zhao, Jianbo Ye, Min Yang, Zeyang Lei, Suofei Zhang, Zhou Zhao", "title": "Investigating Capsule Networks with Dynamic Routing for Text\n  Classification", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we explore capsule networks with dynamic routing for text\nclassification. We propose three strategies to stabilize the dynamic routing\nprocess to alleviate the disturbance of some noise capsules which may contain\n\"background\" information or have not been successfully trained. A series of\nexperiments are conducted with capsule networks on six text classification\nbenchmarks. Capsule networks achieve state of the art on 4 out of 6 datasets,\nwhich shows the effectiveness of capsule networks for text classification. We\nadditionally show that capsule networks exhibit significant improvement when\ntransfer single-label to multi-label text classification over strong baseline\nmethods. To the best of our knowledge, this is the first work that capsule\nnetworks have been empirically investigated for text modeling.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 02:27:42 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 09:02:46 GMT"}, {"version": "v3", "created": "Wed, 20 Jun 2018 09:06:09 GMT"}, {"version": "v4", "created": "Mon, 3 Sep 2018 09:58:52 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Zhao", "Wei", ""], ["Ye", "Jianbo", ""], ["Yang", "Min", ""], ["Lei", "Zeyang", ""], ["Zhang", "Suofei", ""], ["Zhao", "Zhou", ""]]}, {"id": "1804.00540", "submitter": "Jitendra Singh Thakur", "authors": "Madhvi Soni and Jitendra Singh Thakur", "title": "A Systematic Review of Automated Grammar Checking in English Language", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Grammar checking is the task of detection and correction of grammatical\nerrors in the text. English is the dominating language in the field of science\nand technology. Therefore, the non-native English speakers must be able to use\ncorrect English grammar while reading, writing or speaking. This generates the\nneed of automatic grammar checking tools. So far many approaches have been\nproposed and implemented. But less efforts have been made in surveying the\nliterature in the past decade. The objective of this systematic review is to\nexamine the existing literature, highlighting the current issues and suggesting\nthe potential directions of future research. This systematic review is a result\nof analysis of 12 primary studies obtained after designing a search strategy\nfor selecting papers found on the web. We also present a possible scheme for\nthe classification of grammar errors. Among the main observations, we found\nthat there is a lack of efficient and robust grammar checking tools for real\ntime applications. We present several useful illustrations- most prominent are\nthe schematic diagrams that we provide for each approach and a table that\nsummarizes these approaches along different dimensions such as target error\ntypes, linguistic dataset used, strengths and limitations of the approach. This\nfacilitates better understandability, comparison and evaluation of previous\nresearch.\n", "versions": [{"version": "v1", "created": "Thu, 29 Mar 2018 10:42:03 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Soni", "Madhvi", ""], ["Thakur", "Jitendra Singh", ""]]}, {"id": "1804.00551", "submitter": "Artem Artemov", "authors": "A.Artemov, A. Sergeev, A. Khasenevich, A. Yuzhakov, M. Chugunov", "title": "The Training of Neuromodels for Machine Comprehension of Text.\n  Brain2Text Algorithm", "comments": "5 pages, 2 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the Internet represents a vast informational space, growing\nexponentially and the problem of search for relevant data becomes essential as\nnever before. The algorithm proposed in the article allows to perform natural\nlanguage queries on content of the document and get comprehensive meaningful\nanswers. The problem is partially solved for English as SQuAD contains enough\ndata to learn on, but there is no such dataset in Russian, so the methods used\nby scientists now are not applicable to Russian. Brain2 framework allows to\ncope with the problem - it stands out for its ability to be applied on small\ndatasets and does not require impressive computing power. The algorithm is\nillustrated on Sberbank of Russia Strategy's text and assumes the use of a\nneuromodel consisting of 65 mln synapses. The trained model is able to\nconstruct word-by-word answers to questions based on a given text. The existing\nlimitations are its current inability to identify synonyms, pronoun relations\nand allegories. Nevertheless, the results of conducted experiments showed high\ncapacity and generalisation ability of the suggested approach.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 08:32:42 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Artemov", "A.", ""], ["Sergeev", "A.", ""], ["Khasenevich", "A.", ""], ["Yuzhakov", "A.", ""], ["Chugunov", "M.", ""]]}, {"id": "1804.00619", "submitter": "Su Wang", "authors": "Su Wang, Greg Durrett, Katrin Erk", "title": "Modeling Semantic Plausibility by Injecting World Knowledge", "comments": "camera-ready draft (with link to data), Published at NAACL 2018 as a\n  conference paper (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributional data tells us that a man can swallow candy, but not that a man\ncan swallow a paintball, since this is never attested. However both are\nphysically plausible events. This paper introduces the task of semantic\nplausibility: recognizing plausible but possibly novel events. We present a new\ncrowdsourced dataset of semantic plausibility judgments of single events such\nas \"man swallow paintball\". Simple models based on distributional\nrepresentations perform poorly on this task, despite doing well on selection\npreference, but injecting manually elicited knowledge about entity properties\nprovides a substantial performance boost. Our error analysis shows that our new\ndataset is a great testbed for semantic plausibility models: more sophisticated\nknowledge representation and propagation could address many of the remaining\nerrors.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 16:32:53 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 15:30:37 GMT"}, {"version": "v3", "created": "Tue, 10 Apr 2018 01:26:27 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Wang", "Su", ""], ["Durrett", "Greg", ""], ["Erk", "Katrin", ""]]}, {"id": "1804.00644", "submitter": "Zhong Meng", "authors": "Zhong Meng, Jinyu Li, Yifan Gong, Biing-Hwang (Fred) Juang", "title": "Adversarial Teacher-Student Learning for Unsupervised Domain Adaptation", "comments": "5 pages, 1 figure, ICASSP 2018", "journal-ref": "2018 IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP), Calgary, Canada", "doi": "10.1109/ICASSP.2018.8461682", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The teacher-student (T/S) learning has been shown effective in unsupervised\ndomain adaptation [1]. It is a form of transfer learning, not in terms of the\ntransfer of recognition decisions, but the knowledge of posteriori\nprobabilities in the source domain as evaluated by the teacher model. It learns\nto handle the speaker and environment variability inherent in and restricted to\nthe speech signal in the target domain without proactively addressing the\nrobustness to other likely conditions. Performance degradation may thus ensue.\nIn this work, we advance T/S learning by proposing adversarial T/S learning to\nexplicitly achieve condition-robust unsupervised domain adaptation. In this\nmethod, a student acoustic model and a condition classifier are jointly\noptimized to minimize the Kullback-Leibler divergence between the output\ndistributions of the teacher and student models, and simultaneously, to\nmin-maximize the condition classification loss. A condition-invariant deep\nfeature is learned in the adapted student model through this procedure. We\nfurther propose multi-factorial adversarial T/S learning which suppresses\ncondition variabilities caused by multiple factors simultaneously. Evaluated\nwith the noisy CHiME-3 test set, the proposed methods achieve relative word\nerror rate improvements of 44.60% and 5.38%, respectively, over a clean source\nmodel and a strong T/S learning baseline model.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 17:45:57 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 15:43:09 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Meng", "Zhong", "", "Fred"], ["Li", "Jinyu", "", "Fred"], ["Gong", "Yifan", "", "Fred"], ["Biing-Hwang", "", "", "Fred"], ["Juang", "", ""]]}, {"id": "1804.00720", "submitter": "Bhuwan Dhingra", "authors": "Bhuwan Dhingra, Danish Pruthi, Dheeraj Rajagopal", "title": "Simple and Effective Semi-Supervised Question Answering", "comments": "Short paper, NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent success of deep learning models for the task of extractive Question\nAnswering (QA) is hinged on the availability of large annotated corpora.\nHowever, large domain specific annotated corpora are limited and expensive to\nconstruct. In this work, we envision a system where the end user specifies a\nset of base documents and only a few labelled examples. Our system exploits the\ndocument structure to create cloze-style questions from these base documents;\npre-trains a powerful neural network on the cloze style questions; and further\nfine-tunes the model on the labeled examples. We evaluate our proposed system\nacross three diverse datasets from different domains, and find it to be highly\neffective with very little labeled data. We attain more than 50% F1 score on\nSQuAD and TriviaQA with less than a thousand labelled examples. We are also\nreleasing a set of 3.2M cloze-style questions for practitioners to use while\nbuilding QA systems.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 20:29:21 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Dhingra", "Bhuwan", ""], ["Pruthi", "Danish", ""], ["Rajagopal", "Dheeraj", ""]]}, {"id": "1804.00732", "submitter": "Zhong Meng", "authors": "Zhong Meng, Jinyu Li, Zhuo Chen, Yong Zhao, Vadim Mazalov, Yifan Gong,\n  Biing-Hwang (Fred) Juang", "title": "Speaker-Invariant Training via Adversarial Learning", "comments": "5 pages, 3 figures, ICASSP 2018", "journal-ref": "2018 IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP), Calgary, Canada", "doi": "10.1109/ICASSP.2018.8461932", "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel adversarial multi-task learning scheme, aiming at actively\ncurtailing the inter-talker feature variability while maximizing its senone\ndiscriminability so as to enhance the performance of a deep neural network\n(DNN) based ASR system. We call the scheme speaker-invariant training (SIT). In\nSIT, a DNN acoustic model and a speaker classifier network are jointly\noptimized to minimize the senone (tied triphone state) classification loss, and\nsimultaneously mini-maximize the speaker classification loss. A\nspeaker-invariant and senone-discriminative deep feature is learned through\nthis adversarial multi-task learning. With SIT, a canonical DNN acoustic model\nwith significantly reduced variance in its output probabilities is learned with\nno explicit speaker-independent (SI) transformations or speaker-specific\nrepresentations used in training or testing. Evaluated on the CHiME-3 dataset,\nthe SIT achieves 4.99% relative word error rate (WER) improvement over the\nconventional SI acoustic model. With additional unsupervised speaker\nadaptation, the speaker-adapted (SA) SIT model achieves 4.86% relative WER gain\nover the SA SI acoustic model.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 21:09:30 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 07:43:31 GMT"}, {"version": "v3", "created": "Tue, 30 Apr 2019 15:35:29 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Meng", "Zhong", "", "Fred"], ["Li", "Jinyu", "", "Fred"], ["Chen", "Zhuo", "", "Fred"], ["Zhao", "Yong", "", "Fred"], ["Mazalov", "Vadim", "", "Fred"], ["Gong", "Yifan", "", "Fred"], ["Biing-Hwang", "", "", "Fred"], ["Juang", "", ""]]}, {"id": "1804.00804", "submitter": "Nurendra Choudhary", "authors": "Rajat Singh, Nurendra Choudhary and Manish Shrivastava", "title": "Automatic Normalization of Word Variations in Code-Mixed Social Media\n  Text", "comments": "Accepted Long Paper at 19th International Conference on Computational\n  Linguistics and Intelligent Text Processing, March 2018, Hanoi, Vietnam", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media platforms such as Twitter and Facebook are becoming popular in\nmultilingual societies. This trend induces portmanteau of South Asian languages\nwith English. The blend of multiple languages as code-mixed data has recently\nbecome popular in research communities for various NLP tasks. Code-mixed data\nconsist of anomalies such as grammatical errors and spelling variations. In\nthis paper, we leverage the contextual property of words where the different\nspelling variation of words share similar context in a large noisy social media\ntext. We capture different variations of words belonging to same context in an\nunsupervised manner using distributed representations of words. Our experiments\nreveal that preprocessing of the code-mixed dataset based on our approach\nimproves the performance in state-of-the-art part-of-speech tagging\n(POS-tagging) and sentiment analysis tasks.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 03:19:31 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Singh", "Rajat", ""], ["Choudhary", "Nurendra", ""], ["Shrivastava", "Manish", ""]]}, {"id": "1804.00805", "submitter": "Nurendra Choudhary", "authors": "Nurendra Choudhary, Rajat Singh, Ishita Bindlish and Manish\n  Shrivastava", "title": "Emotions are Universal: Learning Sentiment Based Representations of\n  Resource-Poor Languages using Siamese Networks", "comments": "Accepted Long Paper at 19th International Conference on Computational\n  Linguistics and Intelligent Text Processing, March 2018, Hanoi, Vietnam.\n  arXiv admin note: text overlap with arXiv:1804.00806", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning approaches in sentiment analysis principally rely on the\nabundance of resources. To limit this dependence, we propose a novel method\ncalled Siamese Network Architecture for Sentiment Analysis (SNASA) to learn\nrepresentations of resource-poor languages by jointly training them with\nresource-rich languages using a siamese network.\n  SNASA model consists of twin Bi-directional Long Short-Term Memory Recurrent\nNeural Networks (Bi-LSTM RNN) with shared parameters joined by a contrastive\nloss function, based on a similarity metric. The model learns the sentence\nrepresentations of resource-poor and resource-rich language in a common\nsentiment space by using a similarity metric based on their individual\nsentiments. The model, hence, projects sentences with similar sentiment closer\nto each other and the sentences with different sentiment farther from each\nother. Experiments on large-scale datasets of resource-rich languages - English\nand Spanish and resource-poor languages - Hindi and Telugu reveal that SNASA\noutperforms the state-of-the-art sentiment analysis approaches based on\ndistributional semantics, semantic rules, lexicon lists and deep neural network\nrepresentations without sh\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 03:19:36 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Choudhary", "Nurendra", ""], ["Singh", "Rajat", ""], ["Bindlish", "Ishita", ""], ["Shrivastava", "Manish", ""]]}, {"id": "1804.00806", "submitter": "Nurendra Choudhary", "authors": "Nurendra Choudhary, Rajat Singh, Ishita Bindlish and Manish\n  Shrivastava", "title": "Sentiment Analysis of Code-Mixed Languages leveraging Resource Rich\n  Languages", "comments": "Accepted Long Paper at 19th International Conference on Computational\n  Linguistics and Intelligent Text Processing, March 2018, Hanoi, Vietnam.\n  arXiv admin note: text overlap with arXiv:1804.00805", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code-mixed data is an important challenge of natural language processing\nbecause its characteristics completely vary from the traditional structures of\nstandard languages.\n  In this paper, we propose a novel approach called Sentiment Analysis of\nCode-Mixed Text (SACMT) to classify sentences into their corresponding\nsentiment - positive, negative or neutral, using contrastive learning. We\nutilize the shared parameters of siamese networks to map the sentences of\ncode-mixed and standard languages to a common sentiment space. Also, we\nintroduce a basic clustering based preprocessing method to capture variations\nof code-mixed transliterated words. Our experiments reveal that SACMT\noutperforms the state-of-the-art approaches in sentiment analysis for\ncode-mixed text by 7.6% in accuracy and 10.1% in F-score.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 03:19:41 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Choudhary", "Nurendra", ""], ["Singh", "Rajat", ""], ["Bindlish", "Ishita", ""], ["Shrivastava", "Manish", ""]]}, {"id": "1804.00823", "submitter": "Lingfei Wu", "authors": "Kun Xu, Lingfei Wu, Zhiguo Wang, Yansong Feng, Michael Witbrock, and\n  Vadim Sheinin", "title": "Graph2Seq: Graph to Sequence Learning with Attention-based Neural\n  Networks", "comments": "16 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The celebrated Sequence to Sequence learning (Seq2Seq) technique and its\nnumerous variants achieve excellent performance on many tasks. However, many\nmachine learning tasks have inputs naturally represented as graphs; existing\nSeq2Seq models face a significant challenge in achieving accurate conversion\nfrom graph form to the appropriate sequence. To address this challenge, we\nintroduce a novel general end-to-end graph-to-sequence neural encoder-decoder\nmodel that maps an input graph to a sequence of vectors and uses an\nattention-based LSTM method to decode the target sequence from these vectors.\nOur method first generates the node and graph embeddings using an improved\ngraph-based neural network with a novel aggregation strategy to incorporate\nedge direction information in the node embeddings. We further introduce an\nattention mechanism that aligns node embeddings and the decoding sequence to\nbetter cope with large graphs. Experimental results on bAbI, Shortest Path, and\nNatural Language Generation tasks demonstrate that our model achieves\nstate-of-the-art performance and significantly outperforms existing graph\nneural networks, Seq2Seq, and Tree2Seq models; using the proposed\nbi-directional node embedding aggregation strategy, the model can converge\nrapidly to the optimal performance.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 04:47:22 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 11:58:25 GMT"}, {"version": "v3", "created": "Fri, 25 May 2018 06:13:54 GMT"}, {"version": "v4", "created": "Mon, 3 Dec 2018 16:43:37 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Xu", "Kun", ""], ["Wu", "Lingfei", ""], ["Wang", "Zhiguo", ""], ["Feng", "Yansong", ""], ["Witbrock", "Michael", ""], ["Sheinin", "Vadim", ""]]}, {"id": "1804.00828", "submitter": "Byung-Ju Choi", "authors": "Kang-Min Kim, Aliyeva Dinara, Byung-Ju Choi, SangKeun Lee", "title": "Incorporating Word Embeddings into Open Directory Project based\n  Large-scale Classification", "comments": "12 pages, 2 figures, In proceedings of the 22nd Pacific-Asia\n  Conference on Knowledge Discovery and Data Mining (PAKDD)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, implicit representation models, such as embedding or deep learning,\nhave been successfully adopted to text classification task due to their\noutstanding performance. However, these approaches are limited to small- or\nmoderate-scale text classification. Explicit representation models are often\nused in a large-scale text classification, like the Open Directory Project\n(ODP)-based text classification. However, the performance of these models is\nlimited to the associated knowledge bases. In this paper, we incorporate word\nembeddings into the ODP-based large-scale classification. To this end, we first\ngenerate category vectors, which represent the semantics of ODP categories by\njointly modeling word embeddings and the ODP-based text classification. We then\npropose a novel semantic similarity measure, which utilizes the category and\nword vectors obtained from the joint model and word embeddings, respectively.\nThe evaluation results clearly show the efficacy of our methodology in\nlarge-scale text classification. The proposed scheme exhibits significant\nimprovements of 10% and 28% in terms of macro-averaging F1-score and precision\nat k, respectively, over state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 05:09:32 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Kim", "Kang-Min", ""], ["Dinara", "Aliyeva", ""], ["Choi", "Byung-Ju", ""], ["Lee", "SangKeun", ""]]}, {"id": "1804.00831", "submitter": "Yanghoon Kim", "authors": "Yanghoon Kim and Hwanhee Lee and Kyomin Jung", "title": "AttnConvnet at SemEval-2018 Task 1: Attention-based Convolutional Neural\n  Networks for Multi-label Emotion Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an attention-based classifier that predicts\nmultiple emotions of a given sentence. Our model imitates human's two-step\nprocedure of sentence understanding and it can effectively represent and\nclassify sentences. With emoji-to-meaning preprocessing and extra lexicon\nutilization, we further improve the model performance. We train and evaluate\nour model with data provided by SemEval-2018 task 1-5, each sentence of which\nhas several labels among 11 given sentiments. Our model achieves 5-th/1-th rank\nin English/Spanish respectively.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 05:31:35 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 00:21:43 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Kim", "Yanghoon", ""], ["Lee", "Hwanhee", ""], ["Jung", "Kyomin", ""]]}, {"id": "1804.00832", "submitter": "Iroro Orife", "authors": "Iroro Orife", "title": "Attentive Sequence-to-Sequence Learning for Diacritic Restoration of\n  Yor\\`ub\\'a Language Text", "comments": "6 pages, 3 figures. Interspeech 2018 preprint with extra figures and\n  reviewer comments addressed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Yor\\`ub\\'a is a widely spoken West African language with a writing system\nrich in tonal and orthographic diacritics. With very few exceptions, diacritics\nare omitted from electronic texts, due to limited device and application\nsupport. Diacritics provide morphological information, are crucial for lexical\ndisambiguation, pronunciation and are vital for any Yor\\`ub\\'a text-to-speech\n(TTS), automatic speech recognition (ASR) and natural language processing (NLP)\ntasks. Reframing Automatic Diacritic Restoration (ADR) as a machine translation\ntask, we experiment with two different attentive Sequence-to-Sequence neural\nmodels to process undiacritized text. On our evaluation dataset, this approach\nproduces diacritization error rates of less than 5%. We have released\npre-trained models, datasets and source-code as an open-source project to\nadvance efforts on Yor\\`ub\\'a language technology.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 05:33:38 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 03:43:54 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Orife", "Iroro", ""]]}, {"id": "1804.00857", "submitter": "Tao Shen", "authors": "Tao Shen, Tianyi Zhou, Guodong Long, Jing Jiang, Chengqi Zhang", "title": "Bi-Directional Block Self-Attention for Fast and Memory-Efficient\n  Sequence Modeling", "comments": "18 pages, 7 figures; Accepted in ICLR-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNN), convolutional neural networks (CNN) and\nself-attention networks (SAN) are commonly used to produce context-aware\nrepresentations. RNN can capture long-range dependency but is hard to\nparallelize and not time-efficient. CNN focuses on local dependency but does\nnot perform well on some tasks. SAN can model both such dependencies via highly\nparallelizable computation, but memory requirement grows rapidly in line with\nsequence length. In this paper, we propose a model, called \"bi-directional\nblock self-attention network (Bi-BloSAN)\", for RNN/CNN-free sequence encoding.\nIt requires as little memory as RNN but with all the merits of SAN. Bi-BloSAN\nsplits the entire sequence into blocks, and applies an intra-block SAN to each\nblock for modeling local context, then applies an inter-block SAN to the\noutputs for all blocks to capture long-range dependency. Thus, each SAN only\nneeds to process a short sequence, and only a small amount of memory is\nrequired. Additionally, we use feature-level attention to handle the variation\nof contexts around the same word, and use forward/backward masks to encode\ntemporal order information. On nine benchmark datasets for different NLP tasks,\nBi-BloSAN achieves or improves upon state-of-the-art accuracy, and shows better\nefficiency-memory trade-off than existing RNN/CNN/SAN.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 07:41:10 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Shen", "Tao", ""], ["Zhou", "Tianyi", ""], ["Long", "Guodong", ""], ["Jiang", "Jing", ""], ["Zhang", "Chengqi", ""]]}, {"id": "1804.00920", "submitter": "Lauri Juvela", "authors": "Lauri Juvela and Bajibabu Bollepalli and Xin Wang and Hirokazu Kameoka\n  and Manu Airaksinen and Junichi Yamagishi and Paavo Alku", "title": "Speech waveform synthesis from MFCC sequences with generative\n  adversarial networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a method for generating speech from filterbank mel\nfrequency cepstral coefficients (MFCC), which are widely used in speech\napplications, such as ASR, but are generally considered unusable for speech\nsynthesis. First, we predict fundamental frequency and voicing information from\nMFCCs with an autoregressive recurrent neural net. Second, the spectral\nenvelope information contained in MFCCs is converted to all-pole filters, and a\npitch-synchronous excitation model matched to these filters is trained.\nFinally, we introduce a generative adversarial network -based noise model to\nadd a realistic high-frequency stochastic component to the modeled excitation\nsignal. The results show that high quality speech reconstruction can be\nobtained, given only MFCC information at test time.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 11:43:36 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Juvela", "Lauri", ""], ["Bollepalli", "Bajibabu", ""], ["Wang", "Xin", ""], ["Kameoka", "Hirokazu", ""], ["Airaksinen", "Manu", ""], ["Yamagishi", "Junichi", ""], ["Alku", "Paavo", ""]]}, {"id": "1804.00968", "submitter": "Prudhvi Raj Dachapally", "authors": "Prudhvi Raj Dachapally and Srikanth Ramanam", "title": "In-depth Question classification using Convolutional Neural Networks", "comments": "4 pages, short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks for computer vision are fairly intuitive. In a\ntypical CNN used in image classification, the first layers learn edges, and the\nfollowing layers learn some filters that can identify an object. But CNNs for\nNatural Language Processing are not used often and are not completely\nintuitive. We have a good idea about what the convolution filters learn for the\ntask of text classification, and to that, we propose a neural network structure\nthat will be able to give good results in less time. We will be using\nconvolutional neural networks to predict the primary or broader topic of a\nquestion, and then use separate networks for each of these predicted topics to\naccurately classify their sub-topics.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2018 19:52:26 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Dachapally", "Prudhvi Raj", ""], ["Ramanam", "Srikanth", ""]]}, {"id": "1804.00982", "submitter": "Sebastian Ruder", "authors": "Sebastian Ruder, John Glover, Afshin Mehrabani, Parsa Ghaffari", "title": "360{\\deg} Stance Detection", "comments": "Proceedings of NAACL-HLT 2018: System Demonstrations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of fake news and filter bubbles makes it increasingly\ndifficult to form an unbiased, balanced opinion towards a topic. To ameliorate\nthis, we propose 360{\\deg} Stance Detection, a tool that aggregates news with\nmultiple perspectives on a topic. It presents them on a spectrum ranging from\nsupport to opposition, enabling the user to base their opinion on multiple\npieces of diverse evidence.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 14:17:09 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Ruder", "Sebastian", ""], ["Glover", "John", ""], ["Mehrabani", "Afshin", ""], ["Ghaffari", "Parsa", ""]]}, {"id": "1804.00987", "submitter": "Kyle Richardson", "authors": "Kyle Richardson", "title": "A Language for Function Signature Representations", "comments": "short note", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent work by (Richardson and Kuhn, 2017a,b; Richardson et al., 2018) looks\nat semantic parser induction and question answering in the domain of source\ncode libraries and APIs. In this brief note, we formalize the representations\nbeing learned in these studies and introduce a simple domain specific language\nand a systematic translation from this language to first-order logic. By\nrecasting the target representations in terms of classical logic, we aim to\nbroaden the applicability of existing code datasets for investigating more\ncomplex natural language understanding and reasoning problems in the software\ndomain.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2018 13:01:29 GMT"}, {"version": "v2", "created": "Wed, 18 Apr 2018 13:23:03 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Richardson", "Kyle", ""]]}, {"id": "1804.01000", "submitter": "Vishal Sunder", "authors": "Karamjit Singh and Vishal Sunder", "title": "CIKM AnalytiCup 2017 Lazada Product Title Quality Challenge An Ensemble\n  of Deep and Shallow Learning to predict the Quality of Product Titles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach where two different models (Deep and Shallow) are\ntrained separately on the data and a weighted average of the outputs is taken\nas the final result. For the Deep approach, we use different combinations of\nmodels like Convolution Neural Network, pretrained word2vec embeddings and\nLSTMs to get representations which are then used to train a Deep Neural\nNetwork. For Clarity prediction, we also use an Attentive Pooling approach for\nthe pooling operation so as to be aware of the Title-Category pair. For the\nshallow approach, we use boosting technique LightGBM on features generated\nusing title and categories. We find that an ensemble of these approaches does a\nbetter job than using them alone suggesting that the results of the deep and\nshallow approach are highly complementary\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 13:02:57 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Singh", "Karamjit", ""], ["Sunder", "Vishal", ""]]}, {"id": "1804.01041", "submitter": "Prashant Mathur", "authors": "Prashant Mathur, Nicola Ueffing and Gregor Leusch", "title": "Multi-lingual neural title generation for e-Commerce browse pages", "comments": "To appear in NAACL 2018 (Industry track), 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To provide better access of the inventory to buyers and better search engine\noptimization, e-Commerce websites are automatically generating millions of\neasily searchable browse pages. A browse page consists of a set of slot\nname/value pairs within a given category, grouping multiple items which share\nsome characteristics. These browse pages require a title describing the content\nof the page. Since the number of browse pages are huge, manual creation of\nthese titles is infeasible. Previous statistical and neural approaches depend\nheavily on the availability of large amounts of data in a language. In this\nresearch, we apply sequence-to-sequence models to generate titles for high- &\nlow-resourced languages by leveraging transfer learning. We train these models\non multi-lingual data, thereby creating one joint model which can generate\ntitles in various different languages. Performance of the title generation\nsystem is evaluated on three different languages; English, German, and French,\nwith a particular focus on low-resourced French language.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 15:41:44 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Mathur", "Prashant", ""], ["Ueffing", "Nicola", ""], ["Leusch", "Gregor", ""]]}, {"id": "1804.01155", "submitter": "M\\'arton Karsai", "authors": "Jacob Levy Abitbol, M\\'arton Karsai, Jean-Philippe Magu\\'e,\n  Jean-Pierre Chevrot and Eric Fleury", "title": "Socioeconomic Dependencies of Linguistic Patterns in Twitter: A\n  Multivariate Analysis", "comments": "In WWW 2018: The Web Conference, 10 pages, 6 figures", "journal-ref": null, "doi": "10.1145/3178876.3186011", "report-no": null, "categories": "cs.CL cs.CY cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our usage of language is not solely reliant on cognition but is arguably\ndetermined by myriad external factors leading to a global variability of\nlinguistic patterns. This issue, which lies at the core of sociolinguistics and\nis backed by many small-scale studies on face-to-face communication, is\naddressed here by constructing a dataset combining the largest French Twitter\ncorpus to date with detailed socioeconomic maps obtained from national census\nin France. We show how key linguistic variables measured in individual Twitter\nstreams depend on factors like socioeconomic status, location, time, and the\nsocial network of individuals. We found that (i) people of higher socioeconomic\nstatus, active to a greater degree during the daytime, use a more standard\nlanguage; (ii) the southern part of the country is more prone to use more\nstandard language than the northern one, while locally the used variety or\ndialect is determined by the spatial distribution of socioeconomic status; and\n(iii) individuals connected in the social network are closer linguistically\nthan disconnected ones, even after the effects of status homophily have been\nremoved. Our results inform sociolinguistic theory and may inspire novel\nlearning methods for the inference of socioeconomic status of people from the\nway they tweet.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 20:18:11 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Abitbol", "Jacob Levy", ""], ["Karsai", "M\u00e1rton", ""], ["Magu\u00e9", "Jean-Philippe", ""], ["Chevrot", "Jean-Pierre", ""], ["Fleury", "Eric", ""]]}, {"id": "1804.01189", "submitter": "Baosen Zhang", "authors": "Aaron Jaech and Baosen Zhang and Mari Ostendorf and Daniel S. Kirschen", "title": "Real-Time Prediction of the Duration of Distribution System Outages", "comments": "Appears in IEEE Transactions on Power Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.CL math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of predicting duration of unplanned power\noutages, using historical outage records to train a series of neural network\npredictors. The initial duration prediction is made based on environmental\nfactors, and it is updated based on incoming field reports using natural\nlanguage processing to automatically analyze the text. Experiments using 15\nyears of outage records show good initial results and improved performance\nleveraging text. Case studies show that the language processing identifies\nphrases that point to outage causes and repair steps.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 23:10:36 GMT"}, {"version": "v2", "created": "Mon, 30 Jul 2018 01:55:15 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Jaech", "Aaron", ""], ["Zhang", "Baosen", ""], ["Ostendorf", "Mari", ""], ["Kirschen", "Daniel S.", ""]]}, {"id": "1804.01452", "submitter": "David Harwath", "authors": "David Harwath, Adri\\`a Recasens, D\\'idac Sur\\'is, Galen Chuang,\n  Antonio Torralba, and James Glass", "title": "Jointly Discovering Visual Objects and Spoken Words from Raw Sensory\n  Input", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore neural network models that learn to associate\nsegments of spoken audio captions with the semantically relevant portions of\nnatural images that they refer to. We demonstrate that these audio-visual\nassociative localizations emerge from network-internal representations learned\nas a by-product of training to perform an image-audio retrieval task. Our\nmodels operate directly on the image pixels and speech waveform, and do not\nrely on any conventional supervision in the form of labels, segmentations, or\nalignments between the modalities during training. We perform analysis using\nthe Places 205 and ADE20k datasets demonstrating that our models implicitly\nlearn semantically-coupled object and word detectors.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 15:03:08 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Harwath", "David", ""], ["Recasens", "Adri\u00e0", ""], ["Sur\u00eds", "D\u00eddac", ""], ["Chuang", "Galen", ""], ["Torralba", "Antonio", ""], ["Glass", "James", ""]]}, {"id": "1804.01486", "submitter": "Andrew Beam", "authors": "Andrew L. Beam, Benjamin Kompa, Allen Schmaltz, Inbar Fried, Griffin\n  Weber, Nathan P. Palmer, Xu Shi, Tianxi Cai, Isaac S. Kohane", "title": "Clinical Concept Embeddings Learned from Massive Sources of Multimodal\n  Medical Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are a popular approach to unsupervised learning of word\nrelationships that are widely used in natural language processing. In this\narticle, we present a new set of embeddings for medical concepts learned using\nan extremely large collection of multimodal medical data. Leaning on recent\ntheoretical insights, we demonstrate how an insurance claims database of 60\nmillion members, a collection of 20 million clinical notes, and 1.7 million\nfull text biomedical journal articles can be combined to embed concepts into a\ncommon space, resulting in the largest ever set of embeddings for 108,477\nmedical concepts. To evaluate our approach, we present a new benchmark\nmethodology based on statistical power specifically designed to test embeddings\nof medical concepts. Our approach, called cui2vec, attains state-of-the-art\nperformance relative to previous methods in most instances. Finally, we provide\na downloadable set of pre-trained embeddings for other researchers to use, as\nwell as an online tool for interactive exploration of the cui2vec embeddings\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 16:02:54 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 19:25:31 GMT"}, {"version": "v3", "created": "Tue, 20 Aug 2019 00:32:33 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Beam", "Andrew L.", ""], ["Kompa", "Benjamin", ""], ["Schmaltz", "Allen", ""], ["Fried", "Inbar", ""], ["Weber", "Griffin", ""], ["Palmer", "Nathan P.", ""], ["Shi", "Xu", ""], ["Cai", "Tianxi", ""], ["Kohane", "Isaac S.", ""]]}, {"id": "1804.01503", "submitter": "Garrett Honke PhD", "authors": "Paul Azunre, Craig Corcoran, David Sullivan, Garrett Honke, Rebecca\n  Ruppel, Sandeep Verma, Jonathon Morgan", "title": "Abstractive Tabular Dataset Summarization via Knowledge Base Semantic\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an abstractive summarization method for tabular data\nwhich employs a knowledge base semantic embedding to generate the summary.\nAssuming the dataset contains descriptive text in headers, columns and/or some\naugmenting metadata, the system employs the embedding to recommend a\nsubject/type for each text segment. Recommendations are aggregated into a small\ncollection of super types considered to be descriptive of the dataset by\nexploiting the hierarchy of types in a pre-specified ontology. Using February\n2015 Wikipedia as the knowledge base, and a corresponding DBpedia ontology as\ntypes, we present experimental results on open data taken from several\nsources--OpenML, CKAN and data.world--to illustrate the effectiveness of the\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 16:45:04 GMT"}, {"version": "v2", "created": "Thu, 5 Apr 2018 14:57:10 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Azunre", "Paul", ""], ["Corcoran", "Craig", ""], ["Sullivan", "David", ""], ["Honke", "Garrett", ""], ["Ruppel", "Rebecca", ""], ["Verma", "Sandeep", ""], ["Morgan", "Jonathon", ""]]}, {"id": "1804.01720", "submitter": "Martin Engilberge", "authors": "Martin Engilberge, Louis Chevallier, Patrick P\\'erez, Matthieu Cord", "title": "Finding beans in burgers: Deep semantic-visual embedding with\n  localization", "comments": "Accepted to CVPR2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several works have proposed to learn a two-path neural network that maps\nimages and texts, respectively, to a same shared Euclidean space where geometry\ncaptures useful semantic relationships. Such a multi-modal embedding can be\ntrained and used for various tasks, notably image captioning. In the present\nwork, we introduce a new architecture of this type, with a visual path that\nleverages recent space-aware pooling mechanisms. Combined with a textual path\nwhich is jointly trained from scratch, our semantic-visual embedding offers a\nversatile model. Once trained under the supervision of captioned images, it\nyields new state-of-the-art performance on cross-modal retrieval. It also\nallows the localization of new concepts from the embedding space into any input\nimage, delivering state-of-the-art result on the visual grounding of phrases.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 08:13:37 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2018 14:04:35 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Engilberge", "Martin", ""], ["Chevallier", "Louis", ""], ["P\u00e9rez", "Patrick", ""], ["Cord", "Matthieu", ""]]}, {"id": "1804.01760", "submitter": "Longyue Wang", "authors": "Longyue Wang", "title": "Domain Adaptation for Statistical Machine Translation", "comments": "M.Sc Degres Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Statistical machine translation (SMT) systems perform poorly when it is\napplied to new target domains. Our goal is to explore domain adaptation\napproaches and techniques for improving the translation quality of\ndomain-specific SMT systems. However, translating texts from a specific domain\n(e.g., medicine) is full of challenges. The first challenge is ambiguity. Words\nor phrases contain different meanings in different contexts. The second one is\nlanguage style due to the fact that texts from different genres are always\npresented in different syntax, length and structural organization. The third\none is the out-of-vocabulary words (OOVs) problem. In-domain training data are\noften scarce with low terminology coverage. In this thesis, we explore the\nstate-of-the-art domain adaptation approaches and propose effective solutions\nto address those problems.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 10:24:15 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Wang", "Longyue", ""]]}, {"id": "1804.01768", "submitter": "Longyue Wang", "authors": "Siyou Liu, Longyue Wang, Chao-Hong Liu", "title": "Chinese-Portuguese Machine Translation: A Study on Building Parallel\n  Corpora from Comparable Texts", "comments": "accepted by LREC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although there are increasing and significant ties between China and\nPortuguese-speaking countries, there is not much parallel corpora in the\nChinese-Portuguese language pair. Both languages are very populous, with 1.2\nbillion native Chinese speakers and 279 million native Portuguese speakers, the\nlanguage pair, however, could be considered as low-resource in terms of\navailable parallel corpora. In this paper, we describe our methods to curate\nChinese-Portuguese parallel corpora and evaluate their quality. We extracted\nbilingual data from Macao government websites and proposed a hierarchical\nstrategy to build a large parallel corpus. Experiments are conducted on\nexisting and our corpora using both Phrased-Based Machine Translation (PBMT)\nand the state-of-the-art Neural Machine Translation (NMT) models. The results\nof this work can be used as a benchmark for future Chinese-Portuguese MT\nsystems. The approach we used in this paper also shows a good example on how to\nboost performance of MT systems for low-resource language pairs.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 10:35:51 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Liu", "Siyou", ""], ["Wang", "Longyue", ""], ["Liu", "Chao-Hong", ""]]}, {"id": "1804.01772", "submitter": "Jose Manuel Gomez Perez", "authors": "Andres Garcia and Jose Manuel Gomez-Perez", "title": "Not just about size - A Study on the Role of Distributed Word\n  Representations in the Analysis of Scientific Publications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of knowledge graphs in the scholarly communication domain and\nrecent advances in artificial intelligence and natural language processing\nbring us closer to a scenario where intelligent systems can assist scientists\nover a range of knowledge-intensive tasks. In this paper we present\nexperimental results about the generation of word embeddings from scholarly\npublications for the intelligent processing of scientific texts extracted from\nSciGraph. We compare the performance of domain-specific embeddings with\nexisting pre-trained vectors generated from very large and general purpose\ncorpora. Our results suggest that there is a trade-off between corpus\nspecificity and volume. Embeddings from domain-specific scientific corpora\neffectively capture the semantics of the domain. On the other hand, obtaining\ncomparable results through general corpora can also be achieved, but only in\nthe presence of very large corpora of well formed text. Furthermore, We also\nshow that the degree of overlapping between knowledge areas is directly related\nto the performance of embeddings in domain evaluation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 10:48:26 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Garcia", "Andres", ""], ["Gomez-Perez", "Jose Manuel", ""]]}, {"id": "1804.01778", "submitter": "Sheng Yu", "authors": "Yuanhao Liu and Sheng Yu", "title": "Word Segmentation as Graph Partition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach to the Chinese word segmentation problem that\nconsiders the sentence as an undirected graph, whose nodes are the characters.\nOne can use various techniques to compute the edge weights that measure the\nconnection strength between characters. Spectral graph partition algorithms are\nused to group the characters and achieve word segmentation. We follow the graph\npartition approach and design several unsupervised algorithms, and we show\ntheir inspiring segmentation results on two corpora: (1) electronic health\nrecords in Chinese, and (2) benchmark data from the Second International\nChinese Word Segmentation Bakeoff.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 11:02:38 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Liu", "Yuanhao", ""], ["Yu", "Sheng", ""]]}, {"id": "1804.01855", "submitter": "Nurendra Choudhary", "authors": "Nurendra Choudhary, Rajat Singh, Ishita Bindlish and Manish\n  Shrivastava", "title": "Contrastive Learning of Emoji-based Representations for Resource-Poor\n  Languages", "comments": "Accepted Long Paper at 19th International Conference on Computational\n  Linguistics and Intelligent Text Processing, March 2018, Hanoi, Vietnam.\n  arXiv admin note: substantial text overlap with arXiv:1804.00805", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The introduction of emojis (or emoticons) in social media platforms has given\nthe users an increased potential for expression. We propose a novel method\ncalled Classification of Emojis using Siamese Network Architecture (CESNA) to\nlearn emoji-based representations of resource-poor languages by jointly\ntraining them with resource-rich languages using a siamese network.\n  CESNA model consists of twin Bi-directional Long Short-Term Memory Recurrent\nNeural Networks (Bi-LSTM RNN) with shared parameters joined by a contrastive\nloss function based on a similarity metric. The model learns the\nrepresentations of resource-poor and resource-rich language in a common emoji\nspace by using a similarity metric based on the emojis present in sentences\nfrom both languages. The model, hence, projects sentences with similar emojis\ncloser to each other and the sentences with different emojis farther from one\nanother. Experiments on large-scale Twitter datasets of resource-rich languages\n- English and Spanish and resource-poor languages - Hindi and Telugu reveal\nthat CESNA outperforms the state-of-the-art emoji prediction approaches based\non distributional semantics, semantic rules, lexicon lists and deep neural\nnetwork representations without shared parameters.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 03:19:45 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Choudhary", "Nurendra", ""], ["Singh", "Rajat", ""], ["Bindlish", "Ishita", ""], ["Shrivastava", "Manish", ""]]}, {"id": "1804.01963", "submitter": "Emmanuel Dufourq Mr", "authors": "Emmanuel Dufourq, Bruce A. Bassett", "title": "Automated Classification of Text Sentiment", "comments": "In \"2017 Annual Conference of the South African Institute of Computer\n  Scientists and Information\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The ability to identify sentiment in text, referred to as sentiment analysis,\nis one which is natural to adult humans. This task is, however, not one which a\ncomputer can perform by default. Identifying sentiments in an automated,\nalgorithmic manner will be a useful capability for business and research in\ntheir search to understand what consumers think about their products or\nservices and to understand human sociology. Here we propose two new Genetic\nAlgorithms (GAs) for the task of automated text sentiment analysis. The GAs\nlearn whether words occurring in a text corpus are either sentiment or\namplifier words, and their corresponding magnitude. Sentiment words, such as\n'horrible', add linearly to the final sentiment. Amplifier words in contrast,\nwhich are typically adjectives/adverbs like 'very', multiply the sentiment of\nthe following word. This increases, decreases or negates the sentiment of the\nfollowing word. The sentiment of the full text is then the sum of these terms.\nThis approach grows both a sentiment and amplifier dictionary which can be\nreused for other purposes and fed into other machine learning algorithms. We\nreport the results of multiple experiments conducted on large Amazon data sets.\nThe results reveal that our proposed approach was able to outperform several\npublic and/or commercial sentiment analysis algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 17:21:48 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Dufourq", "Emmanuel", ""], ["Bassett", "Bruce A.", ""]]}, {"id": "1804.02042", "submitter": "Nora Hollenstein", "authors": "Jonathan Rotsztejn, Nora Hollenstein, Ce Zhang", "title": "ETH-DS3Lab at SemEval-2018 Task 7: Effectively Combining Recurrent and\n  Convolutional Neural Networks for Relation Classification and Extraction", "comments": "Accepted to SemEval 2018 (12th International Workshop on Semantic\n  Evaluation)", "journal-ref": "Proceedings of The 12th International Workshop on Semantic\n  Evaluation, 2018, Association for Computational Linguistics, p. 689-696,\n  http://aclweb.org/anthology/S18-1112", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliably detecting relevant relations between entities in unstructured text\nis a valuable resource for knowledge extraction, which is why it has awaken\nsignificant interest in the field of Natural Language Processing. In this\npaper, we present a system for relation classification and extraction based on\nan ensemble of convolutional and recurrent neural networks that ranked first in\n3 out of the 4 subtasks at SemEval 2018 Task 7. We provide detailed\nexplanations and grounds for the design choices behind the most relevant\nfeatures and analyze their importance.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 20:01:48 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Rotsztejn", "Jonathan", ""], ["Hollenstein", "Nora", ""], ["Zhang", "Ce", ""]]}, {"id": "1804.02063", "submitter": "Sunny Chopra", "authors": "Katherine Bailey and Sunny Chopra", "title": "Few-Shot Text Classification with Pre-Trained Word Embeddings and a\n  Human in the Loop", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the literature around text classification treats it as a supervised\nlearning problem: given a corpus of labeled documents, train a classifier such\nthat it can accurately predict the classes of unseen documents. In industry,\nhowever, it is not uncommon for a business to have entire corpora of documents\nwhere few or none have been classified, or where existing classifications have\nbecome meaningless. With web content, for example, poor taxonomy management can\nresult in labels being applied indiscriminately, making filtering by these\nlabels unhelpful. Our work aims to make it possible to classify an entire\ncorpus of unlabeled documents using a human-in-the-loop approach, where the\ncontent owner manually classifies just one or two documents per category and\nthe rest can be automatically classified. This \"few-shot\" learning approach\nrequires rich representations of the documents such that those that have been\nmanually labeled can be treated as prototypes, and automatic classification of\nthe rest is a simple case of measuring the distance to prototypes. This\napproach uses pre-trained word embeddings, where documents are represented\nusing a simple weighted average of constituent word embeddings. We have tested\nthe accuracy of the approach on existing labeled datasets and provide the\nresults here. We have also made code available for reproducing the results we\ngot on the 20 Newsgroups dataset.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 21:28:54 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Bailey", "Katherine", ""], ["Chopra", "Sunny", ""]]}, {"id": "1804.02135", "submitter": "Kei Akuzawa", "authors": "Kei Akuzawa, Yusuke Iwasawa, Yutaka Matsuo", "title": "Expressive Speech Synthesis via Modeling Expressions with Variational\n  Autoencoder", "comments": "Accepted by Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in neural autoregressive models have improve the performance\nof speech synthesis (SS). However, as they lack the ability to model global\ncharacteristics of speech (such as speaker individualities or speaking styles),\nparticularly when these characteristics have not been labeled, making neural\nautoregressive SS systems more expressive is still an open issue. In this\npaper, we propose to combine VoiceLoop, an autoregressive SS model, with\nVariational Autoencoder (VAE). This approach, unlike traditional autoregressive\nSS systems, uses VAE to model the global characteristics explicitly, enabling\nthe expressiveness of the synthesized speech to be controlled in an\nunsupervised manner. Experiments using the VCTK and Blizzard2012 datasets show\nthe VAE helps VoiceLoop to generate higher quality speech and to control the\nexpressions in its synthesized speech by incorporating global characteristics\ninto the speech generating process.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 05:27:14 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2018 06:42:35 GMT"}, {"version": "v3", "created": "Mon, 11 Feb 2019 09:41:22 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Akuzawa", "Kei", ""], ["Iwasawa", "Yusuke", ""], ["Matsuo", "Yutaka", ""]]}, {"id": "1804.02173", "submitter": "Egor Lakomkin", "authors": "Egor Lakomkin, Mohammad Ali Zamani, Cornelius Weber, Sven Magg and\n  Stefan Wermter", "title": "On the Robustness of Speech Emotion Recognition for Human-Robot\n  Interaction with Deep Neural Networks", "comments": "Submitted to IROS'18, Madrid, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CL cs.HC cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech emotion recognition (SER) is an important aspect of effective\nhuman-robot collaboration and received a lot of attention from the research\ncommunity. For example, many neural network-based architectures were proposed\nrecently and pushed the performance to a new level. However, the applicability\nof such neural SER models trained only on in-domain data to noisy conditions is\ncurrently under-researched. In this work, we evaluate the robustness of\nstate-of-the-art neural acoustic emotion recognition models in human-robot\ninteraction scenarios. We hypothesize that a robot's ego noise, room\nconditions, and various acoustic events that can occur in a home environment\ncan significantly affect the performance of a model. We conduct several\nexperiments on the iCub robot platform and propose several novel ways to reduce\nthe gap between the model's performance during training and testing in\nreal-world conditions. Furthermore, we observe large improvements in the model\nperformance on the robot and demonstrate the necessity of introducing several\ndata augmentation techniques like overlaying background noise and loudness\nvariations to improve the robustness of the neural approaches.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 09:03:29 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Lakomkin", "Egor", ""], ["Zamani", "Mohammad Ali", ""], ["Weber", "Cornelius", ""], ["Magg", "Sven", ""], ["Wermter", "Stefan", ""]]}, {"id": "1804.02186", "submitter": "Sreekavitha Parupalli", "authors": "Sreekavitha Parupalli and Navjyoti Singh", "title": "Enrichment of OntoSenseNet: Adding a Sense-annotated Telugu lexicon", "comments": "Accepted Long Paper at 19th International Conference on Computational\n  Linguistics and Intelligent Text Processing, March 2018, Hanoi, Vietnam", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper describes the enrichment of OntoSenseNet - a verb-centric lexical\nresource for Indian Languages. This resource contains a newly developed\nTelugu-Telugu dictionary. It is important because native speakers can better\nannotate the senses when both the word and its meaning are in Telugu. Hence\nefforts are made to develop a soft copy of Telugu dictionary. Our resource also\nhas manually annotated gold standard corpus consisting 8483 verbs, 253 adverbs\nand 1673 adjectives. Annotations are done by native speakers according to\ndefined annotation guidelines. In this paper, we provide an overview of the\nannotation procedure and present the validation of our resource through\ninter-annotator agreement. Concepts of sense-class and sense-type are\ndiscussed. Additionally, we discuss the potential of lexical sense-annotated\ncorpora in improving word sense disambiguation (WSD) tasks. Telugu WordNet is\ncrowd-sourced for annotation of individual words in synsets and is compared\nwith the developed sense-annotated lexicon (OntoSenseNet) to examine the\nimprovement. Also, we present a special categorization (spatio-temporal\nclassification) of adjectives.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 10:17:16 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2018 04:02:33 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Parupalli", "Sreekavitha", ""], ["Singh", "Navjyoti", ""]]}, {"id": "1804.02204", "submitter": "Mustafa Haider", "authors": "Adnan Haider and Philip C. Woodland", "title": "Sequence Training of DNN Acoustic Models With Natural Gradient", "comments": "In Proceedings of IEEE ASRU 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Network (DNN) acoustic models often use discriminative sequence\ntraining that optimises an objective function that better approximates the word\nerror rate (WER) than frame-based training. Sequence training is normally\nimplemented using Stochastic Gradient Descent (SGD) or Hessian Free (HF)\ntraining. This paper proposes an alternative batch style optimisation framework\nthat employs a Natural Gradient (NG) approach to traverse through the parameter\nspace. By correcting the gradient according to the local curvature of the\nKL-divergence, the NG optimisation process converges more quickly than HF.\nFurthermore, the proposed NG approach can be applied to any sequence\ndiscriminative training criterion. The efficacy of the NG method is shown using\nexperiments on a Multi-Genre Broadcast (MGB) transcription task that\ndemonstrates both the computational efficiency and the accuracy of the\nresulting DNN models.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 11:05:53 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Haider", "Adnan", ""], ["Woodland", "Philip C.", ""]]}, {"id": "1804.02233", "submitter": "Igor Mozeti\\v{c}", "authors": "Igor Mozeti\\v{c}, Peter Gabrov\\v{s}ek, Petra Kralj Novak", "title": "Forex trading and Twitter: Spam, bots, and reputation manipulation", "comments": "MIS2: Misinformation and Misbehavior Mining on the Web, Workshop at\n  WSDM-18, Marina Del Rey, CA, USA, Feb. 9, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY econ.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currency trading (Forex) is the largest world market in terms of volume. We\nanalyze trading and tweeting about the EUR-USD currency pair over a period of\nthree years. First, a large number of tweets were manually labeled, and a\nTwitter stance classification model is constructed. The model then classifies\nall the tweets by the trading stance signal: buy, hold, or sell (EUR vs. USD).\nThe Twitter stance is compared to the actual currency rates by applying the\nevent study methodology, well-known in financial economics. It turns out that\nthere are large differences in Twitter stance distribution and potential\ntrading returns between the four groups of Twitter users: trading robots,\nspammers, trading companies, and individual traders. Additionally, we observe\nattempts of reputation manipulation by post festum removal of tweets with poor\npredictions, and deleting/reposting of identical tweets to increase the\nvisibility without tainting one's Twitter timeline.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 12:36:28 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 11:53:56 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Mozeti\u010d", "Igor", ""], ["Gabrov\u0161ek", "Peter", ""], ["Novak", "Petra Kralj", ""]]}, {"id": "1804.02286", "submitter": "Richard Moot", "authors": "Richard Moot (CNRS, LIRMM/INFO, UM)", "title": "Chart Parsing Multimodal Grammars", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The short note describes the chart parser for multimodal type-logical\ngrammars which has been developed in conjunction with the type-logical treebank\nfor French. The chart parser presents an incomplete but fast implementation of\nproof search for multimodal type-logical grammars using the \"deductive parsing\"\nframework. Proofs found can be transformed to natural deduction proofs.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 14:11:33 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Moot", "Richard", "", "CNRS, LIRMM/INFO, UM"]]}, {"id": "1804.02341", "submitter": "Edward Choi", "authors": "Edward Choi, Angeliki Lazaridou, Nando de Freitas", "title": "Compositional Obverter Communication Learning From Raw Visual Input", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the distinguishing aspects of human language is its compositionality,\nwhich allows us to describe complex environments with limited vocabulary.\nPreviously, it has been shown that neural network agents can learn to\ncommunicate in a highly structured, possibly compositional language based on\ndisentangled input (e.g. hand- engineered features). Humans, however, do not\nlearn to communicate based on well-summarized features. In this work, we train\nneural agents to simultaneously develop visual perception from raw image\npixels, and learn to communicate with a sequence of discrete symbols. The\nagents play an image description game where the image contains factors such as\ncolors and shapes. We train the agents using the obverter technique where an\nagent introspects to generate messages that maximize its own understanding.\nThrough qualitative analysis, visualization and a zero-shot test, we show that\nthe agents can develop, out of raw image pixels, a language with compositional\nproperties, given a proper pressure from the environment.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 16:12:51 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Choi", "Edward", ""], ["Lazaridou", "Angeliki", ""], ["de Freitas", "Nando", ""]]}, {"id": "1804.02472", "submitter": "Rachel Rudinger", "authors": "Rachel Rudinger, Aaron Steven White, Benjamin Van Durme", "title": "Neural models of factuality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two neural models for event factuality prediction, which yield\nsignificant performance gains over previous models on three event factuality\ndatasets: FactBank, UW, and MEANTIME. We also present a substantial expansion\nof the It Happened portion of the Universal Decompositional Semantics dataset,\nyielding the largest event factuality dataset to date. We report model results\non this extended factuality dataset as well.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 22:11:17 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Rudinger", "Rachel", ""], ["White", "Aaron Steven", ""], ["Van Durme", "Benjamin", ""]]}, {"id": "1804.02504", "submitter": "Hung-Yi Lee", "authors": "Chih-Wei Lee, Yau-Shian Wang, Tsung-Yuan Hsu, Kuan-Yu Chen, Hung-Yi\n  Lee, Lin-shan Lee", "title": "Scalable Sentiment for Sequence-to-sequence Chatbot Response with\n  Performance Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional seq2seq chatbot models only try to find the sentences with the\nhighest probabilities conditioned on the input sequences, without considering\nthe sentiment of the output sentences. Some research works trying to modify the\nsentiment of the output sequences were reported. In this paper, we propose five\nmodels to scale or adjust the sentiment of the chatbot response: persona-based\nmodel, reinforcement learning, plug and play model, sentiment transformation\nnetwork and cycleGAN, all based on the conventional seq2seq model. We also\ndevelop two evaluation metrics to estimate if the responses are reasonable\ngiven the input. These metrics together with other two popularly used metrics\nwere used to analyze the performance of the five proposed models on different\naspects, and reinforcement learning and cycleGAN were shown to be very\nattractive. The evaluation metrics were also found to be well correlated with\nhuman evaluation.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2018 03:56:55 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Lee", "Chih-Wei", ""], ["Wang", "Yau-Shian", ""], ["Hsu", "Tsung-Yuan", ""], ["Chen", "Kuan-Yu", ""], ["Lee", "Hung-Yi", ""], ["Lee", "Lin-shan", ""]]}, {"id": "1804.02525", "submitter": "Dario Pavllo", "authors": "Dario Pavllo, Tiziano Piccardi, Robert West", "title": "Quootstrap: Scalable Unsupervised Extraction of Quotation-Speaker Pairs\n  from Large News Corpora via Bootstrapping", "comments": "Accepted at the 12th International Conference on Web and Social Media\n  (ICWSM), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Quootstrap, a method for extracting quotations, as well as the\nnames of the speakers who uttered them, from large news corpora. Whereas prior\nwork has addressed this problem primarily with supervised machine learning, our\napproach follows a fully unsupervised bootstrapping paradigm. It leverages the\nredundancy present in large news corpora, more precisely, the fact that the\nsame quotation often appears across multiple news articles in slightly\ndifferent contexts. Starting from a few seed patterns, such as [\"Q\", said S.],\nour method extracts a set of quotation-speaker pairs (Q, S), which are in turn\nused for discovering new patterns expressing the same quotations; the process\nis then repeated with the larger pattern set. Our algorithm is highly scalable,\nwhich we demonstrate by running it on the large ICWSM 2011 Spinn3r corpus.\nValidating our results against a crowdsourced ground truth, we obtain 90%\nprecision at 40% recall using a single seed pattern, with significantly higher\nrecall values for more frequently reported (and thus likely more interesting)\nquotations. Finally, we showcase the usefulness of our algorithm's output for\ncomputational social science by analyzing the sentiment expressed in our\nextracted quotations.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2018 07:50:50 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Pavllo", "Dario", ""], ["Piccardi", "Tiziano", ""], ["West", "Robert", ""]]}, {"id": "1804.02545", "submitter": "Alexander Robertson", "authors": "Alexander Robertson, Sharon Goldwater", "title": "Evaluating historical text normalization systems: How well do they\n  generalize?", "comments": "Accepted to NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We highlight several issues in the evaluation of historical text\nnormalization systems that make it hard to tell how well these systems would\nactually work in practice---i.e., for new datasets or languages; in comparison\nto more na\\\"ive systems; or as a preprocessing step for downstream NLP tools.\nWe illustrate these issues and exemplify our proposed evaluation practices by\ncomparing two neural models against a na\\\"ive baseline system. We show that the\nneural models generalize well to unseen words in tests on five languages;\nnevertheless, they provide no clear benefit over the na\\\"ive baseline for\ndownstream POS tagging of an English historical collection. We conclude that\nfuture work should include more rigorous evaluation, including both intrinsic\nand extrinsic measures where possible.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2018 11:06:26 GMT"}, {"version": "v2", "created": "Fri, 13 Apr 2018 08:00:06 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Robertson", "Alexander", ""], ["Goldwater", "Sharon", ""]]}, {"id": "1804.02549", "submitter": "Xin Wang", "authors": "Xin Wang, Jaime Lorenzo-Trueba, Shinji Takaki, Lauri Juvela, Junichi\n  Yamagishi", "title": "A comparison of recent waveform generation and acoustic modeling methods\n  for neural-network-based speech synthesis", "comments": "To appear in ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in speech synthesis suggest that limitations such as the\nlossy nature of the amplitude spectrum with minimum phase approximation and the\nover-smoothing effect in acoustic modeling can be overcome by using advanced\nmachine learning approaches. In this paper, we build a framework in which we\ncan fairly compare new vocoding and acoustic modeling techniques with\nconventional approaches by means of a large scale crowdsourced evaluation.\nResults on acoustic models showed that generative adversarial networks and an\nautoregressive (AR) model performed better than a normal recurrent network and\nthe AR model performed best. Evaluation on vocoders by using the same AR\nacoustic model demonstrated that a Wavenet vocoder outperformed classical\nsource-filter-based vocoders. Particularly, generated speech waveforms from the\ncombination of AR acoustic model and Wavenet vocoder achieved a similar score\nof speech quality to vocoded speech.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2018 12:16:50 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Wang", "Xin", ""], ["Lorenzo-Trueba", "Jaime", ""], ["Takaki", "Shinji", ""], ["Juvela", "Lauri", ""], ["Yamagishi", "Junichi", ""]]}, {"id": "1804.02559", "submitter": "Jingyi Zhang", "authors": "Jingyi Zhang, Masao Utiyama, Eiichro Sumita, Graham Neubig, Satoshi\n  Nakamura", "title": "Guiding Neural Machine Translation with Retrieved Translation Pieces", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the difficulties of neural machine translation (NMT) is the recall and\nappropriate translation of low-frequency words or phrases. In this paper, we\npropose a simple, fast, and effective method for recalling previously seen\ntranslation examples and incorporating them into the NMT decoding process.\nSpecifically, for an input sentence, we use a search engine to retrieve\nsentence pairs whose source sides are similar with the input sentence, and then\ncollect $n$-grams that are both in the retrieved target sentences and aligned\nwith words that match in the source sentences, which we call \"translation\npieces\". We compute pseudo-probabilities for each retrieved sentence based on\nsimilarities between the input sentence and the retrieved source sentences, and\nuse these to weight the retrieved translation pieces. Finally, an existing NMT\nmodel is used to translate the input sentence, with an additional bonus given\nto outputs that contain the collected translation pieces. We show our method\nimproves NMT translation results up to 6 BLEU points on three narrow domain\ntranslation tasks where repetitiveness of the target sentences is particularly\nsalient. It also causes little increase in the translation time, and compares\nfavorably to another alternative retrieval-based method with respect to\naccuracy, speed, and simplicity of implementation.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2018 13:20:24 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Zhang", "Jingyi", ""], ["Utiyama", "Masao", ""], ["Sumita", "Eiichro", ""], ["Neubig", "Graham", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "1804.02596", "submitter": "Vivek Kulkarni", "authors": "Vivek Kulkarni and William Yang Wang", "title": "Simple Models for Word Formation in English Slang", "comments": "10 pages, 5 figures, 6 tables. Accepted at NAACL HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose generative models for three types of extra-grammatical word\nformation phenomena abounding in English slang: Blends, Clippings, and\nReduplicatives. Adopting a data-driven approach coupled with linguistic\nknowledge, we propose simple models with state of the art performance on human\nannotated gold standard datasets. Overall, our models reveal insights into the\ngenerative processes of word formation in slang -- insights which are\nincreasingly relevant in the context of the rising prevalence of slang and\nnon-standard varieties on the Internet.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2018 21:59:46 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Kulkarni", "Vivek", ""], ["Wang", "William Yang", ""]]}, {"id": "1804.02617", "submitter": "Utkarsh Contractor", "authors": "Mehrad Moradshahi and Utkarsh Contractor", "title": "Language Modeling with Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have been promising in the field of\nimage generation, however, they have been hard to train for language\ngeneration. GANs were originally designed to output differentiable values, so\ndiscrete language generation is challenging for them which causes high levels\nof instability in training GANs. Consequently, past work has resorted to\npre-training with maximum-likelihood or training GANs without pre-training with\na WGAN objective with a gradient penalty. In this study, we present a\ncomparison of those approaches. Furthermore, we present the results of some\nexperiments that indicate better training and convergence of Wasserstein GANs\n(WGANs) when a weaker regularization term is enforcing the Lipschitz\nconstraint.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 03:18:13 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Moradshahi", "Mehrad", ""], ["Contractor", "Utkarsh", ""]]}, {"id": "1804.02657", "submitter": "Takumi Ichimura", "authors": "Takumi Ichimura, Issei Tachibana", "title": "Emotion Orientated Recommendation System for Hiroshima Tourist by Fuzzy\n  Petri Net", "comments": "6 pages, 10 figures, Proc. of IEEE 6th International Workshop on\n  Computational Intelligence and Applications (IWCIA2013)", "journal-ref": null, "doi": "10.1109/IWCIA.2013.6624776", "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We developed an Android Smartophone application software for tourist\ninformation system. Especially, the agent system recommends the sightseeing\nspot and local hospitality corresponding to the current feelings. The system\nsuch as concierge can estimate user's emotion and mood by Emotion Generating\nCalculations and Mental State Transition Network. In this paper, the system\ndecides the next candidates for spots and foods by the reasoning of fuzzy Petri\nNet in order to make more smooth communication between human and smartphone.\nThe system was developed for Hiroshima Tourist Information and described some\nhospitality about the concierge system.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 09:18:56 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Ichimura", "Takumi", ""], ["Tachibana", "Issei", ""]]}, {"id": "1804.02812", "submitter": "Ju-Chieh Chou", "authors": "Ju-chieh Chou, Cheng-chieh Yeh, Hung-yi Lee, Lin-shan Lee", "title": "Multi-target Voice Conversion without Parallel Data by Adversarially\n  Learning Disentangled Audio Representations", "comments": "Accepted to Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, cycle-consistent adversarial network (Cycle-GAN) has been\nsuccessfully applied to voice conversion to a different speaker without\nparallel data, although in those approaches an individual model is needed for\neach target speaker. In this paper, we propose an adversarial learning\nframework for voice conversion, with which a single model can be trained to\nconvert the voice to many different speakers, all without parallel data, by\nseparating the speaker characteristics from the linguistic content in speech\nsignals. An autoencoder is first trained to extract speaker-independent latent\nrepresentations and speaker embedding separately using another auxiliary\nspeaker classifier to regularize the latent representation. The decoder then\ntakes the speaker-independent latent representation and the target speaker\nembedding as the input to generate the voice of the target speaker with the\nlinguistic content of the source utterance. The quality of decoder output is\nfurther improved by patching with the residual signal produced by another pair\nof generator and discriminator. A target speaker set size of 20 was tested in\nthe preliminary experiments, and very good voice quality was obtained.\nConventional voice conversion metrics are reported. We also show that the\nspeaker information has been properly reduced from the latent representations.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 04:31:43 GMT"}, {"version": "v2", "created": "Sun, 24 Jun 2018 18:11:02 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Chou", "Ju-chieh", ""], ["Yeh", "Cheng-chieh", ""], ["Lee", "Hung-yi", ""], ["Lee", "Lin-shan", ""]]}, {"id": "1804.03052", "submitter": "David Harwath", "authors": "David Harwath, Galen Chuang, and James Glass", "title": "Vision as an Interlingua: Learning Multilingual Semantic Embeddings of\n  Untranscribed Speech", "comments": "to appear at ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore the learning of neural network embeddings for\nnatural images and speech waveforms describing the content of those images.\nThese embeddings are learned directly from the waveforms without the use of\nlinguistic transcriptions or conventional speech recognition technology. While\nprior work has investigated this setting in the monolingual case using English\nspeech data, this work represents the first effort to apply these techniques to\nlanguages beyond English. Using spoken captions collected in English and Hindi,\nwe show that the same model architecture can be successfully applied to both\nlanguages. Further, we demonstrate that training a multilingual model\nsimultaneously on both languages offers improved performance over the\nmonolingual models. Finally, we show that these models are capable of\nperforming semantic cross-lingual speech-to-speech retrieval.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 15:15:37 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Harwath", "David", ""], ["Chuang", "Galen", ""], ["Glass", "James", ""]]}, {"id": "1804.03124", "submitter": "Jing Qian", "authors": "Jing Qian, Mai ElSherief, Elizabeth M. Belding, William Yang Wang", "title": "Leveraging Intra-User and Inter-User Representation Learning for\n  Automated Hate Speech Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hate speech detection is a critical, yet challenging problem in Natural\nLanguage Processing (NLP). Despite the existence of numerous studies dedicated\nto the development of NLP hate speech detection approaches, the accuracy is\nstill poor. The central problem is that social media posts are short and noisy,\nand most existing hate speech detection solutions take each post as an isolated\ninput instance, which is likely to yield high false positive and negative\nrates. In this paper, we radically improve automated hate speech detection by\npresenting a novel model that leverages intra-user and inter-user\nrepresentation learning for robust hate speech detection on Twitter. In\naddition to the target Tweet, we collect and analyze the user's historical\nposts to model intra-user Tweet representations. To suppress the noise in a\nsingle Tweet, we also model the similar Tweets posted by all other users with\nreinforced inter-user representation learning techniques. Experimentally, we\nshow that leveraging these two representations can significantly improve the\nf-score of a strong bidirectional LSTM baseline model by 10.1%.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 17:46:33 GMT"}, {"version": "v2", "created": "Fri, 14 Sep 2018 02:31:25 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Qian", "Jing", ""], ["ElSherief", "Mai", ""], ["Belding", "Elizabeth M.", ""], ["Wang", "William Yang", ""]]}, {"id": "1804.03201", "submitter": "Wei-Ning Hsu", "authors": "Wei-Ning Hsu and James Glass", "title": "Scalable Factorized Hierarchical Variational Autoencoder Training", "comments": "Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models have achieved great success in unsupervised learning\nwith the ability to capture complex nonlinear relationships between latent\ngenerating factors and observations. Among them, a factorized hierarchical\nvariational autoencoder (FHVAE) is a variational inference-based model that\nformulates a hierarchical generative process for sequential data. Specifically,\nan FHVAE model can learn disentangled and interpretable representations, which\nhave been proven useful for numerous speech applications, such as speaker\nverification, robust speech recognition, and voice conversion. However, as we\nwill elaborate in this paper, the training algorithm proposed in the original\npaper is not scalable to datasets of thousands of hours, which makes this model\nless applicable on a larger scale. After identifying limitations in terms of\nruntime, memory, and hyperparameter optimization, we propose a hierarchical\nsampling training algorithm to address all three issues. Our proposed method is\nevaluated comprehensively on a wide variety of datasets, ranging from 3 to\n1,000 hours and involving different types of generating factors, such as\nrecording conditions and noise types. In addition, we also present a new\nvisualization method for qualitatively evaluating the performance with respect\nto the interpretability and disentanglement. Models trained with our proposed\nalgorithm demonstrate the desired characteristics on all the datasets.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 19:44:29 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 04:25:16 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Hsu", "Wei-Ning", ""], ["Glass", "James", ""]]}, {"id": "1804.03209", "submitter": "Pete Warden", "authors": "Pete Warden", "title": "Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Describes an audio dataset of spoken words designed to help train and\nevaluate keyword spotting systems. Discusses why this task is an interesting\nchallenge, and why it requires a specialized dataset that is different from\nconventional datasets used for automatic speech recognition of full sentences.\nSuggests a methodology for reproducible and comparable accuracy metrics for\nthis task. Describes how the data was collected and verified, what it contains,\nprevious versions and properties. Concludes by reporting baseline results of\nmodels trained on this dataset.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 19:58:17 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Warden", "Pete", ""]]}, {"id": "1804.03240", "submitter": "Djordje Gligorijevic", "authors": "Djordje Gligorijevic, Jelena Stojanovic, Wayne Satz, Ivan Stojkovic,\n  Kathrin Schreyer, Daniel Del Portal, Zoran Obradovic", "title": "Deep Attention Model for Triage of Emergency Department Patients", "comments": "Proceedings of the 2018 SIAM International Conference on Data Mining\n  (SDM 2018), San Diego, CA, May 2018. *Authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization of patient throughput and wait time in emergency departments\n(ED) is an important task for hospital systems. For that reason, Emergency\nSeverity Index (ESI) system for patient triage was introduced to help guide\nmanual estimation of acuity levels, which is used by nurses to rank the\npatients and organize hospital resources. However, despite improvements that it\nbrought to managing medical resources, such triage system greatly depends on\nnurse's subjective judgment and is thus prone to human errors. Here, we propose\na novel deep model based on the word attention mechanism designed for\npredicting a number of resources an ED patient would need. Our approach\nincorporates routinely available continuous and nominal (structured) data with\nmedical text (unstructured) data, including patient's chief complaint, past\nmedical history, medication list, and nurse assessment collected for 338,500 ED\nvisits over three years in a large urban hospital. Using both structured and\nunstructured data, the proposed approach achieves the AUC of $\\sim 88\\%$ for\nthe task of identifying resource intensive patients (binary classification),\nand the accuracy of $\\sim 44\\%$ for predicting exact category of number of\nresources (multi-class classification task), giving an estimated lift over\nnurses' performance by 16\\% in accuracy. Furthermore, the attention mechanism\nof the proposed model provides interpretability by assigning attention scores\nfor nurses' notes which is crucial for decision making and implementation of\nsuch approaches in the real systems working on human health.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 16:06:29 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Gligorijevic", "Djordje", ""], ["Stojanovic", "Jelena", ""], ["Satz", "Wayne", ""], ["Stojkovic", "Ivan", ""], ["Schreyer", "Kathrin", ""], ["Del Portal", "Daniel", ""], ["Obradovic", "Zoran", ""]]}, {"id": "1804.03243", "submitter": "Zhehuai Chen", "authors": "Zhehuai Chen, Justin Luitjens, Hainan Xu, Yiming Wang, Daniel Povey,\n  Sanjeev Khudanpur", "title": "A GPU-based WFST Decoder with Exact Lattice Generation", "comments": "accepted by INTERSPEECH 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe initial work on an extension of the Kaldi toolkit that supports\nweighted finite-state transducer (WFST) decoding on Graphics Processing Units\n(GPUs). We implement token recombination as an atomic GPU operation in order to\nfully parallelize the Viterbi beam search, and propose a dynamic load balancing\nstrategy for more efficient token passing scheduling among GPU threads. We also\nredesign the exact lattice generation and lattice pruning algorithms for better\nutilization of the GPUs. Experiments on the Switchboard corpus show that the\nproposed method achieves identical 1-best results and lattice quality in\nrecognition and confidence measure tasks, while running 3 to 15 times faster\nthan the single process Kaldi decoder. The above results are reported on\ndifferent GPU architectures. Additionally we obtain a 46-fold speedup with\nsequence parallelism and multi-process service (MPS) in GPU.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 21:23:26 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 00:10:54 GMT"}, {"version": "v3", "created": "Fri, 27 Jul 2018 08:46:50 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Chen", "Zhehuai", ""], ["Luitjens", "Justin", ""], ["Xu", "Hainan", ""], ["Wang", "Yiming", ""], ["Povey", "Daniel", ""], ["Khudanpur", "Sanjeev", ""]]}, {"id": "1804.03257", "submitter": "Haw-Shiuan Chang", "authors": "Haw-Shiuan Chang, Amol Agrawal, Ananya Ganesh, Anirudha Desai, Vinayak\n  Mathur, Alfred Hough, Andrew McCallum", "title": "Efficient Graph-based Word Sense Induction by Distributional Inclusion\n  Vector Embeddings", "comments": "TextGraphs 2018: the Workshop on Graph-based Methods for Natural\n  Language Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word sense induction (WSI), which addresses polysemy by unsupervised\ndiscovery of multiple word senses, resolves ambiguities for downstream NLP\ntasks and also makes word representations more interpretable. This paper\nproposes an accurate and efficient graph-based method for WSI that builds a\nglobal non-negative vector embedding basis (which are interpretable like\ntopics) and clusters the basis indexes in the ego network of each polysemous\nword. By adopting distributional inclusion vector embeddings as our basis\nformation model, we avoid the expensive step of nearest neighbor search that\nplagues other graph-based methods without sacrificing the quality of sense\nclusters. Experiments on three datasets show that our proposed method produces\nsimilar or better sense clusters and embeddings compared with previous\nstate-of-the-art methods while being significantly more efficient.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 22:10:57 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 19:38:04 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Chang", "Haw-Shiuan", ""], ["Agrawal", "Amol", ""], ["Ganesh", "Ananya", ""], ["Desai", "Anirudha", ""], ["Mathur", "Vinayak", ""], ["Hough", "Alfred", ""], ["McCallum", "Andrew", ""]]}, {"id": "1804.03317", "submitter": "Yingqi Qu", "authors": "Yingqi Qu, Jie Liu, Liangyi Kang, Qinfeng Shi, Dan Ye", "title": "Question Answering over Freebase via Attentive RNN with Similarity\n  Matrix based CNN", "comments": "The experiments need to improve and add strategy for multi-relation\n  questions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of knowledge bases (KBs), question answering over\nknowledge base, a.k.a. KBQA has drawn huge attention in recent years. Most of\nthe existing KBQA methods follow so called encoder-compare framework. They map\nthe question and the KB facts to a common embedding space, in which the\nsimilarity between the question vector and the fact vectors can be conveniently\ncomputed. This, however, inevitably loses original words interaction\ninformation. To preserve more original information, we propose an attentive\nrecurrent neural network with similarity matrix based convolutional neural\nnetwork (AR-SMCNN) model, which is able to capture comprehensive hierarchical\ninformation utilizing the advantages of both RNN and CNN. We use RNN to capture\nsemantic-level correlation by its sequential modeling nature, and use an\nattention mechanism to keep track of the entities and relations simultaneously.\nMeanwhile, we use a similarity matrix based CNN with two-directions pooling to\nextract literal-level words interaction matching utilizing CNNs strength of\nmodeling spatial correlation among data. Moreover, we have developed a new\nheuristic extension method for entity detection, which significantly decreases\nthe effect of noise. Our method has outperformed the state-of-the-arts on\nSimpleQuestion benchmark in both accuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 02:39:41 GMT"}, {"version": "v2", "created": "Sat, 28 Apr 2018 09:26:44 GMT"}, {"version": "v3", "created": "Sun, 27 May 2018 13:36:15 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Qu", "Yingqi", ""], ["Liu", "Jie", ""], ["Kang", "Liangyi", ""], ["Shi", "Qinfeng", ""], ["Ye", "Dan", ""]]}, {"id": "1804.03396", "submitter": "Lin Qiu", "authors": "Lin Qiu, Hao Zhou, Yanru Qu, Weinan Zhang, Suoheng Li, Shu Rong,\n  Dongyu Ru, Lihua Qian, Kewei Tu and Yong Yu", "title": "QA4IE: A Question Answering based Framework for Information Extraction", "comments": "Accepted by 17th International Semantic Web Conference (ISWC'18)", "journal-ref": null, "doi": "10.1007/978-3-030-00671-6_12", "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information Extraction (IE) refers to automatically extracting structured\nrelation tuples from unstructured texts. Common IE solutions, including\nRelation Extraction (RE) and open IE systems, can hardly handle cross-sentence\ntuples, and are severely restricted by limited relation types as well as\ninformal relation specifications (e.g., free-text based relation tuples). In\norder to overcome these weaknesses, we propose a novel IE framework named\nQA4IE, which leverages the flexible question answering (QA) approaches to\nproduce high quality relation triples across sentences. Based on the framework,\nwe develop a large IE benchmark with high quality human evaluation. This\nbenchmark contains 293K documents, 2M golden relation triples, and 636 relation\ntypes. We compare our system with some IE baselines on our benchmark and the\nresults show that our system achieves great improvements.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 08:31:03 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 12:38:21 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Qiu", "Lin", ""], ["Zhou", "Hao", ""], ["Qu", "Yanru", ""], ["Zhang", "Weinan", ""], ["Li", "Suoheng", ""], ["Rong", "Shu", ""], ["Ru", "Dongyu", ""], ["Qian", "Lihua", ""], ["Tu", "Kewei", ""], ["Yu", "Yong", ""]]}, {"id": "1804.03424", "submitter": "Yookoon Park", "authors": "Yookoon Park, Jaemin Cho and Gunhee Kim", "title": "A Hierarchical Latent Structure for Variational Conversation Modeling", "comments": "Published in NAACL 2018 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAE) combined with hierarchical RNNs have emerged\nas a powerful framework for conversation modeling. However, they suffer from\nthe notorious degeneration problem, where the decoders learn to ignore latent\nvariables and reduce to vanilla RNNs. We empirically show that this degeneracy\noccurs mostly due to two reasons. First, the expressive power of hierarchical\nRNN decoders is often high enough to model the data using only its decoding\ndistributions without relying on the latent variables. Second, the conditional\nVAE structure whose generation process is conditioned on a context, makes the\nrange of training targets very sparse; that is, the RNN decoders can easily\noverfit to the training data ignoring the latent variables. To solve the\ndegeneration problem, we propose a novel model named Variational Hierarchical\nConversation RNNs (VHCR), involving two key ideas of (1) using a hierarchical\nstructure of latent variables, and (2) exploiting an utterance drop\nregularization. With evaluations on two datasets of Cornell Movie Dialog and\nUbuntu Dialog Corpus, we show that our VHCR successfully utilizes latent\nvariables and outperforms state-of-the-art models for conversation generation.\nMoreover, it can perform several new utterance control tasks, thanks to its\nhierarchical latent structure.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 10:00:36 GMT"}, {"version": "v2", "created": "Thu, 12 Apr 2018 06:02:24 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Park", "Yookoon", ""], ["Cho", "Jaemin", ""], ["Kim", "Gunhee", ""]]}, {"id": "1804.03433", "submitter": "Fabio Del Vigna", "authors": "Fabio Del Vigna, Marinella Petrocchi, Alessandro Tommasi, Cesare\n  Zavattari, Maurizio Tesconi", "title": "Who framed Roger Reindeer? De-censorship of Facebook posts by snippet\n  classification", "comments": "Accepted for publication: Elsevier Online Social Networks and Media", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers online news censorship and it concentrates on censorship\nof identities. Obfuscating identities may occur for disparate reasons, from\nmilitary to judiciary ones. In the majority of cases, this happens to protect\nindividuals from being identified and persecuted by hostile people. However,\nbeing the collaborative web characterised by a redundancy of information, it is\nnot unusual that the same fact is reported by multiple sources, which may not\napply the same restriction policies in terms of censorship. Also, the proven\naptitude of social network users to disclose personal information leads to the\nphenomenon that comments to news can reveal the data withheld in the news\nitself. This gives us a mean to figure out who the subject of the censored news\nis. We propose an adaptation of a text analysis approach to unveil censored\nidentities. The approach is tested on a synthesised scenario, which however\nresembles a real use case. Leveraging a text analysis based on a context\nclassifier trained over snippets from posts and comments of Facebook pages, we\nachieve promising results. Despite the quite constrained settings in which we\noperate -- such as considering only snippets of very short length -- our system\nsuccessfully detects the censored name, choosing among 10 different candidate\nnames, in more than 50\\% of the investigated cases. This outperforms the\nresults of two reference baselines. The findings reported in this paper, other\nthan being supported by a thorough experimental methodology and interesting on\ntheir own, also pave the way for further investigation on the insidious issues\nof censorship on the web.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 10:22:19 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Del Vigna", "Fabio", ""], ["Petrocchi", "Marinella", ""], ["Tommasi", "Alessandro", ""], ["Zavattari", "Cesare", ""], ["Tesconi", "Maurizio", ""]]}, {"id": "1804.03540", "submitter": "Arkaitz Zubiaga", "authors": "Arkaitz Zubiaga", "title": "Mining Social Media for Newsgathering: A Review", "comments": "Accepted for publication in Online Social Networks and Media", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media is becoming an increasingly important data source for learning\nabout breaking news and for following the latest developments of ongoing news.\nThis is in part possible thanks to the existence of mobile devices, which\nallows anyone with access to the Internet to post updates from anywhere,\nleading in turn to a growing presence of citizen journalism. Consequently,\nsocial media has become a go-to resource for journalists during the process of\nnewsgathering. Use of social media for newsgathering is however challenging,\nand suitable tools are needed in order to facilitate access to useful\ninformation for reporting. In this paper, we provide an overview of research in\ndata mining and natural language processing for mining social media for\nnewsgathering. We discuss five different areas that researchers have worked on\nto mitigate the challenges inherent to social media newsgathering: news\ndiscovery, curation of news, validation and verification of content,\nnewsgathering dashboards, and other tasks. We outline the progress made so far\nin the field, summarise the current challenges as well as discuss future\ndirections in the use of computational journalism to assist with social media\nnewsgathering. This review is relevant to computer scientists researching news\nin social media as well as for interdisciplinary researchers interested in the\nintersection of computer science and journalism.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 13:54:05 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 14:22:53 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Zubiaga", "Arkaitz", ""]]}, {"id": "1804.03608", "submitter": "Tanmay Gupta", "authors": "Tanmay Gupta, Dustin Schwenk, Ali Farhadi, Derek Hoiem, and Aniruddha\n  Kembhavi", "title": "Imagine This! Scripts to Compositions to Videos", "comments": "Supplementary material included", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imagining a scene described in natural language with realistic layout and\nappearance of entities is the ultimate test of spatial, visual, and semantic\nworld knowledge. Towards this goal, we present the Composition, Retrieval, and\nFusion Network (CRAFT), a model capable of learning this knowledge from\nvideo-caption data and applying it while generating videos from novel captions.\nCRAFT explicitly predicts a temporal-layout of mentioned entities (characters\nand objects), retrieves spatio-temporal entity segments from a video database\nand fuses them to generate scene videos. Our contributions include sequential\ntraining of components of CRAFT while jointly modeling layout and appearances,\nand losses that encourage learning compositional representations for retrieval.\nWe evaluate CRAFT on semantic fidelity to caption, composition consistency, and\nvisual quality. CRAFT outperforms direct pixel generation approaches and\ngeneralizes well to unseen captions and to unseen video databases with no text\nannotations. We demonstrate CRAFT on FLINTSTONES, a new richly annotated\nvideo-caption dataset with over 25000 videos. For a glimpse of videos generated\nby CRAFT, see https://youtu.be/688Vv86n0z8.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 15:59:45 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Gupta", "Tanmay", ""], ["Schwenk", "Dustin", ""], ["Farhadi", "Ali", ""], ["Hoiem", "Derek", ""], ["Kembhavi", "Aniruddha", ""]]}, {"id": "1804.03673", "submitter": "Reshma U", "authors": "Reshma U, Barathi Ganesh H B, Mandar Kale, Prachi Mankame and Gouri\n  Kulkarni", "title": "Deep Learning for Digital Text Analytics: Sentiment Analysis", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In today's scenario, imagining a world without negativity is something very\nunrealistic, as bad NEWS spreads more virally than good ones. Though it seems\nimpractical in real life, this could be implemented by building a system using\nMachine Learning and Natural Language Processing techniques in identifying the\nnews datum with negative shade and filter them by taking only the news with\npositive shade (good news) to the end user. In this work, around two lakhs\ndatum have been trained and tested using a combination of rule-based and data\ndriven approaches. VADER along with a filtration method has been used as an\nannotating tool followed by statistical Machine Learning approach that have\nused Document Term Matrix (representation) and Support Vector Machine\n(classification). Deep Learning algorithms then came into picture to make this\nsystem reliable (Doc2Vec) which finally ended up with Convolutional Neural\nNetwork(CNN) that yielded better results than the other experimented modules.\nIt showed up a training accuracy of 96%, while a test accuracy of (internal and\nexternal news datum) above 85% was obtained.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 18:10:33 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["U", "Reshma", ""], ["B", "Barathi Ganesh H", ""], ["Kale", "Mandar", ""], ["Mankame", "Prachi", ""], ["Kulkarni", "Gouri", ""]]}, {"id": "1804.03782", "submitter": "Sidi Lu", "authors": "Sidi Lu and Lantao Yu and Siyuan Feng and Yaoming Zhu and Weinan Zhang\n  and Yong Yu", "title": "CoT: Cooperative Training for Generative Modeling of Discrete Data", "comments": "Appearing as a Conference Paper on ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the generative models of sequential discrete data. To\ntackle the exposure bias problem inherent in maximum likelihood estimation\n(MLE), generative adversarial networks (GANs) are introduced to penalize the\nunrealistic generated samples. To exploit the supervision signal from the\ndiscriminator, most previous models leverage REINFORCE to address the\nnon-differentiable problem of sequential discrete data. However, because of the\nunstable property of the training signal during the dynamic process of\nadversarial training, the effectiveness of REINFORCE, in this case, is hardly\nguaranteed. To deal with such a problem, we propose a novel approach called\nCooperative Training (CoT) to improve the training of sequence generative\nmodels. CoT transforms the min-max game of GANs into a joint maximization\nframework and manages to explicitly estimate and optimize Jensen-Shannon\ndivergence. Moreover, CoT works without the necessity of pre-training via MLE,\nwhich is crucial to the success of previous methods. In the experiments,\ncompared to existing state-of-the-art methods, CoT shows superior or at least\ncompetitive performance on sample quality, diversity, as well as training\nstability.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 02:10:55 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 05:38:27 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 04:44:48 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Lu", "Sidi", ""], ["Yu", "Lantao", ""], ["Feng", "Siyuan", ""], ["Zhu", "Yaoming", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""]]}, {"id": "1804.03799", "submitter": "Rashmi Gangadharaiah", "authors": "Rashmi Gangadharaiah, Balakrishnan Narayanaswamy, Charles Elkan", "title": "Achieving Fluency and Coherency in Task-oriented Dialog", "comments": "Workshop on Conversational AI, NIPS 2017, Long Beach, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider real world task-oriented dialog settings, where agents need to\ngenerate both fluent natural language responses and correct external actions\nlike database queries and updates. We demonstrate that, when applied to\ncustomer support chat transcripts, Sequence to Sequence (Seq2Seq) models often\ngenerate short, incoherent and ungrammatical natural language responses that\nare dominated by words that occur with high frequency in the training data.\nThese phenomena do not arise in synthetic datasets such as bAbI, where we show\nSeq2Seq models are nearly perfect. We develop techniques to learn embeddings\nthat succinctly capture relevant information from the dialog history, and\ndemonstrate that nearest neighbor based approaches in this learned neural\nembedding space generate more fluent responses. However, we see that these\nmethods are not able to accurately predict when to execute an external action.\nWe show how to combine nearest neighbor and Seq2Seq methods in a hybrid model,\nwhere nearest neighbor is used to generate fluent responses and Seq2Seq type\nmodels ensure dialog coherency and generate accurate external actions. We show\nthat this approach is well suited for customer support scenarios, where agents'\nresponses are typically script-driven, and correct external actions are\ncritically important. The hybrid model on the customer support data achieves a\n78% relative improvement in fluency scores, and a 130% improvement in accuracy\nof external calls.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 03:49:22 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Gangadharaiah", "Rashmi", ""], ["Narayanaswamy", "Balakrishnan", ""], ["Elkan", "Charles", ""]]}, {"id": "1804.03824", "submitter": "Leshem Choshen", "authors": "Leshem Choshen and Omri Abend", "title": "Reference-less Measure of Faithfulness for Grammatical Error Correction", "comments": "Final version for NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose USim, a semantic measure for Grammatical Error Correction (GEC)\nthat measures the semantic faithfulness of the output to the source, thereby\ncomplementing existing reference-less measures (RLMs) for measuring the\noutput's grammaticality. USim operates by comparing the semantic symbolic\nstructure of the source and the correction, without relying on manually-curated\nreferences. Our experiments establish the validity of USim, by showing that (1)\nsemantic annotation can be consistently applied to ungrammatical text; (2)\nvalid corrections obtain a high USim similarity score to the source; and (3)\ninvalid corrections obtain a lower score.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 06:10:48 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 14:41:08 GMT"}, {"version": "v3", "created": "Fri, 27 Apr 2018 05:24:00 GMT"}, {"version": "v4", "created": "Wed, 9 May 2018 13:56:12 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Choshen", "Leshem", ""], ["Abend", "Omri", ""]]}, {"id": "1804.03839", "submitter": "Nishtha Madaan", "authors": "Nishtha Madaan, Gautam Singh, Sameep Mehta, Aditya Chetan, Brihi Joshi", "title": "Generating Clues for Gender based Occupation De-biasing in Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vast availability of text data has enabled widespread training and use of AI\nsystems that not only learn and predict attributes from the text but also\ngenerate text automatically. However, these AI models also learn gender, racial\nand ethnic biases present in the training data. In this paper, we present the\nfirst system that discovers the possibility that a given text portrays a gender\nstereotype associated with an occupation. If the possibility exists, the system\noffers counter-evidences of opposite gender also being associated with the same\noccupation in the context of user-provided geography and timespan. The system\nthus enables text de-biasing by assisting a human-in-the-loop. The system can\nnot only act as a text pre-processor before training any AI model but also help\nhuman story writers write stories free of occupation-level gender bias in the\ngeographical and temporal context of their choice.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 07:14:09 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Madaan", "Nishtha", ""], ["Singh", "Gautam", ""], ["Mehta", "Sameep", ""], ["Chetan", "Aditya", ""], ["Joshi", "Brihi", ""]]}, {"id": "1804.03923", "submitter": "Farshad Jafari", "authors": "Farshad Jafari", "title": "Generating Multilingual Parallel Corpus Using Subtitles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation with its significant results, still has a great\nproblem: lack or absence of parallel corpus for many languages. This article\nsuggests a method for generating considerable amount of parallel corpus for any\nlanguage pairs, extracted from open source materials existing on the Internet.\nParallel corpus contents will be derived from video subtitles. It needs a set\nof video titles, with some attributes like release date, rating, duration and\netc. Process of finding and downloading subtitle pairs for desired language\npairs is automated by using a crawler. Finally sentence pairs will be extracted\nfrom synchronous dialogues in subtitles. The main problem of this method is\nunsynchronized subtitle pairs. Therefore subtitles will be verified before\ndownloading. If two subtitle were not synchronized, then another subtitle of\nthat video will be processed till it finds the matching subtitle. Using this\napproach gives ability to make context based parallel corpus through filtering\nvideos by genre. Context based corpus can be used in complex translators which\ndecode sentences by different networks after determining contents subject.\nLanguages have many differences in their formal and informal styles, including\nwords and syntax. Other advantage of this method is to make corpus of informal\nstyle of languages. Because most of movies dialogues are parts of a\nconversation. So they had informal style. This feature of generated corpus can\nbe used in real-time translators to have more accurate conversation\ntranslations.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 11:07:16 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Jafari", "Farshad", ""]]}, {"id": "1804.03980", "submitter": "Kris Cao", "authors": "Kris Cao, Angeliki Lazaridou, Marc Lanctot, Joel Z Leibo, Karl Tuyls,\n  Stephen Clark", "title": "Emergent Communication through Negotiation", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning offers a way to study how communication\ncould emerge in communities of agents needing to solve specific problems. In\nthis paper, we study the emergence of communication in the negotiation\nenvironment, a semi-cooperative model of agent interaction. We introduce two\ncommunication protocols -- one grounded in the semantics of the game, and one\nwhich is \\textit{a priori} ungrounded and is a form of cheap talk. We show that\nself-interested agents can use the pre-grounded communication channel to\nnegotiate fairly, but are unable to effectively use the ungrounded channel.\nHowever, prosocial agents do learn to use cheap talk to find an optimal\nnegotiating strategy, suggesting that cooperation is necessary for language to\nemerge. We also study communication behaviour in a setting where one agent\ninteracts with agents in a community with different levels of prosociality and\nshow how agent identifiability can aid negotiation.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 13:48:08 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Cao", "Kris", ""], ["Lazaridou", "Angeliki", ""], ["Lanctot", "Marc", ""], ["Leibo", "Joel Z", ""], ["Tuyls", "Karl", ""], ["Clark", "Stephen", ""]]}, {"id": "1804.03984", "submitter": "Angeliki  Lazaridou", "authors": "Angeliki Lazaridou, Karl Moritz Hermann, Karl Tuyls, Stephen Clark", "title": "Emergence of Linguistic Communication from Referential Games with\n  Symbolic and Pixel Input", "comments": "To appear at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of algorithms to evolve or learn (compositional) communication\nprotocols has traditionally been studied in the language evolution literature\nthrough the use of emergent communication tasks. Here we scale up this research\nby using contemporary deep learning methods and by training\nreinforcement-learning neural network agents on referential communication\ngames. We extend previous work, in which agents were trained in symbolic\nenvironments, by developing agents which are able to learn from raw pixel data,\na more challenging and realistic input representation. We find that the degree\nof structure found in the input data affects the nature of the emerged\nprotocols, and thereby corroborate the hypothesis that structured compositional\nlanguage is most likely to emerge when agents perceive the world as being\nstructured.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 13:51:19 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Lazaridou", "Angeliki", ""], ["Hermann", "Karl Moritz", ""], ["Tuyls", "Karl", ""], ["Clark", "Stephen", ""]]}, {"id": "1804.04003", "submitter": "Ayush Singh", "authors": "Ayush Singh, Ritu Palod", "title": "Sentiment Transfer using Seq2Seq Adversarial Autoencoders", "comments": "Report built as a part of project for CSYE7245 Northeastern\n  University under Prof. Nik Brown. arXiv admin note: text overlap with\n  arXiv:1711.06861, arXiv:1409.3215, arXiv:1705.07663 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expressing in language is subjective. Everyone has a different style of\nreading and writing, apparently it all boil downs to the way their mind\nunderstands things (in a specific format). Language style transfer is a way to\npreserve the meaning of a text and change the way it is expressed. Progress in\nlanguage style transfer is lagged behind other domains, such as computer\nvision, mainly because of the lack of parallel data, use cases, and reliable\nevaluation metrics. In response to the challenge of lacking parallel data, we\nexplore learning style transfer from non-parallel data. We propose a model\ncombining seq2seq, autoencoders, and adversarial loss to achieve this goal. The\nkey idea behind the proposed models is to learn separate content\nrepresentations and style representations using adversarial networks.\nConsidering the problem of evaluating style transfer tasks, we frame the\nproblem as sentiment transfer and evaluation using a sentiment classifier to\ncalculate how many sentiments was the model able to transfer. We report our\nresults on several kinds of models.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 16:28:33 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Singh", "Ayush", ""], ["Palod", "Ritu", ""]]}, {"id": "1804.04053", "submitter": "Egor Lakomkin", "authors": "Egor Lakomkin, Mohammad Ali Zamani, Cornelius Weber, Sven Magg, Stefan\n  Wermter", "title": "EmoRL: Continuous Acoustic Emotion Classification using Deep\n  Reinforcement Learning", "comments": "Accepted to the IEEE International Conference on Robotics and\n  Automation (ICRA'18), Brisbane, Australia, May 21-25, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CL cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustically expressed emotions can make communication with a robot more\nefficient. Detecting emotions like anger could provide a clue for the robot\nindicating unsafe/undesired situations. Recently, several deep neural\nnetwork-based models have been proposed which establish new state-of-the-art\nresults in affective state evaluation. These models typically start processing\nat the end of each utterance, which not only requires a mechanism to detect the\nend of an utterance but also makes it difficult to use them in a real-time\ncommunication scenario, e.g. human-robot interaction. We propose the EmoRL\nmodel that triggers an emotion classification as soon as it gains enough\nconfidence while listening to a person speaking. As a result, we minimize the\nneed for segmenting the audio signal for classification and achieve lower\nlatency as the audio signal is processed incrementally. The method is\ncompetitive with the accuracy of a strong baseline model, while allowing much\nearlier prediction.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 09:21:11 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Lakomkin", "Egor", ""], ["Zamani", "Mohammad Ali", ""], ["Weber", "Cornelius", ""], ["Magg", "Sven", ""], ["Wermter", "Stefan", ""]]}, {"id": "1804.04058", "submitter": "Rizwan Sadiq", "authors": "Rizwan Sadiq, Mohsin Khan", "title": "Analyzing Self-Driving Cars on Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies users' perception regarding a controversial product,\nnamely self-driving (autonomous) cars. To find people's opinion regarding this\nnew technology, we used an annotated Twitter dataset, and extracted the topics\nin positive and negative tweets using an unsupervised, probabilistic model\nknown as topic modeling. We later used the topics, as well as linguist and\nTwitter specific features to classify the sentiment of the tweets. Regarding\nthe opinions, the result of our analysis shows that people are optimistic and\nexcited about the future technology, but at the same time they find it\ndangerous and not reliable. For the classification task, we found Twitter\nspecific features, such as hashtags as well as linguistic features such as\nemphatic words among top attributes in classifying the sentiment of the tweets.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 23:31:44 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Sadiq", "Rizwan", ""], ["Khan", "Mohsin", ""]]}, {"id": "1804.04059", "submitter": "Stefano M. Iacus", "authors": "A. Ceron, L. Curini, S.M. Iacus", "title": "ISIS at its apogee: the Arabic discourse on Twitter and what we can\n  learn from that about ISIS support and Foreign Fighters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze 26.2 million comments published in Arabic language on Twitter,\nfrom July 2014 to January 2015, when ISIS' strength reached its peak and the\ngroup was prominently expanding the territorial area under its control. By\ndoing that, we are able to measure the share of support and aversion toward the\nIslamic State within the online Arab communities. We then investigate two\nspecific topics. First, by exploiting the time-granularity of the tweets, we\nlink the opinions with daily events to understand the main determinants of the\nchanging trend in support toward ISIS. Second, by taking advantage of the\ngeographical locations of tweets, we explore the relationship between online\nopinions across countries and the number of foreign fighters joining ISIS.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 05:29:30 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 14:39:59 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Ceron", "A.", ""], ["Curini", "L.", ""], ["Iacus", "S. M.", ""]]}, {"id": "1804.04083", "submitter": "Claudia Schulz", "authors": "Claudia Schulz, Steffen Eger, Johannes Daxenberger, Tobias Kahse,\n  Iryna Gurevych", "title": "Multi-Task Learning for Argumentation Mining in Low-Resource Settings", "comments": "Accepted at NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate whether and where multi-task learning (MTL) can improve\nperformance on NLP problems related to argumentation mining (AM), in particular\nargument component identification. Our results show that MTL performs\nparticularly well (and better than single-task learning) when little training\ndata is available for the main task, a common scenario in AM. Our findings\nchallenge previous assumptions that conceptualizations across AM datasets are\ndivergent and that MTL is difficult for semantic or higher-level tasks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 16:43:13 GMT"}, {"version": "v2", "created": "Fri, 13 Apr 2018 10:59:54 GMT"}, {"version": "v3", "created": "Fri, 4 May 2018 12:25:09 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Schulz", "Claudia", ""], ["Eger", "Steffen", ""], ["Daxenberger", "Johannes", ""], ["Kahse", "Tobias", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1804.04087", "submitter": "Marco Lippi", "authors": "Marco Lippi, Marcelo A Montemurro, Mirko Degli Esposti, Giampaolo\n  Cristadoro", "title": "Natural Language Statistical Features of LSTM-generated Texts", "comments": null, "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, 2019", "doi": "10.1109/TNNLS.2019.2890970", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long Short-Term Memory (LSTM) networks have recently shown remarkable\nperformance in several tasks dealing with natural language generation, such as\nimage captioning or poetry composition. Yet, only few works have analyzed text\ngenerated by LSTMs in order to quantitatively evaluate to which extent such\nartificial texts resemble those generated by humans. We compared the\nstatistical structure of LSTM-generated language to that of written natural\nlanguage, and to those produced by Markov models of various orders. In\nparticular, we characterized the statistical structure of language by assessing\nword-frequency statistics, long-range correlations, and entropy measures. Our\nmain finding is that while both LSTM and Markov-generated texts can exhibit\nfeatures similar to real ones in their word-frequency statistics and entropy\nmeasures, LSTM-texts are shown to reproduce long-range correlations at scales\ncomparable to those found in natural language. Moreover, for LSTM networks a\ntemperature-like parameter controlling the generation process shows an optimal\nvalue---for which the produced texts are closest to real language---consistent\nacross all the different statistical features investigated.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 13:17:36 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 09:14:28 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Lippi", "Marco", ""], ["Montemurro", "Marcelo A", ""], ["Esposti", "Mirko Degli", ""], ["Cristadoro", "Giampaolo", ""]]}, {"id": "1804.04093", "submitter": "Ye Zhang", "authors": "Ye Zhang, Nan Ding, Radu Soricut", "title": "SHAPED: Shared-Private Encoder-Decoder for Text Style Adaptation", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised training of abstractive language generation models results in\nlearning conditional probabilities over language sequences based on the\nsupervised training signal. When the training signal contains a variety of\nwriting styles, such models may end up learning an 'average' style that is\ndirectly influenced by the training data make-up and cannot be controlled by\nthe needs of an application. We describe a family of model architectures\ncapable of capturing both generic language characteristics via shared model\nparameters, as well as particular style characteristics via private model\nparameters. Such models are able to generate language according to a specific\nlearned style, while still taking advantage of their power to model generic\nlanguage phenomena. Furthermore, we describe an extension that uses a mixture\nof output distributions from all learned styles to perform on-the fly style\nadaptation based on the textual input alone. Experimentally, we find that the\nproposed models consistently outperform models that encapsulate single-style or\naverage-style language generation capabilities.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 16:56:04 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Zhang", "Ye", ""], ["Ding", "Nan", ""], ["Soricut", "Radu", ""]]}, {"id": "1804.04095", "submitter": "Nikolaos Aletras", "authors": "Nikolaos Aletras and Benjamin Paul Chamberlain", "title": "Predicting Twitter User Socioeconomic Attributes with Network and\n  Language Information", "comments": "Accepted at ACM HT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Inferring socioeconomic attributes of social media users such as occupation\nand income is an important problem in computational social science. Automated\ninference of such characteristics has applications in personalised recommender\nsystems, targeted computational advertising and online political campaigning.\nWhile previous work has shown that language features can reliably predict\nsocioeconomic attributes on Twitter, employing information coming from users'\nsocial networks has not yet been explored for such complex user\ncharacteristics. In this paper, we describe a method for predicting the\noccupational class and the income of Twitter users given information extracted\nfrom their extended networks by learning a low-dimensional vector\nrepresentation of users, i.e. graph embeddings. We use this representation to\ntrain predictive models for occupational class and income. Results on two\npublicly available datasets show that our method consistently outperforms the\nstate-of-the-art methods in both tasks. We also obtain further significant\nimprovements when we combine graph embeddings with textual features,\ndemonstrating that social network and language information are complementary.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 17:00:27 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Aletras", "Nikolaos", ""], ["Chamberlain", "Benjamin Paul", ""]]}, {"id": "1804.04164", "submitter": "Boyang Li", "authors": "Hannah Kim, Denys Katerenchuk, Daniel Billet, Jun Huan, Haesun Park,\n  Boyang Li", "title": "Understanding Actors and Evaluating Personae with Gaussian Embeddings", "comments": "Accepted at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.MM cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding narrative content has become an increasingly popular topic.\nNonetheless, research on identifying common types of narrative characters, or\npersonae, is impeded by the lack of automatic and broad-coverage evaluation\nmethods. We argue that computationally modeling actors provides benefits,\nincluding novel evaluation mechanisms for personae. Specifically, we propose\ntwo actor-modeling tasks, cast prediction and versatility ranking, which can\ncapture complementary aspects of the relation between actors and the characters\nthey portray. For an actor model, we present a technique for embedding actors,\nmovies, character roles, genres, and descriptive keywords as Gaussian\ndistributions and translation vectors, where the Gaussian variance corresponds\nto actors' versatility. Empirical results indicate that (1) the technique\nconsiderably outperforms TransE (Bordes et al. 2013) and ablation baselines and\n(2) automatically identified persona topics (Bamman, O'Connor, and Smith 2013)\nyield statistically significant improvements in both tasks, whereas simplistic\npersona descriptors including age and gender perform inconsistently, validating\nprior research.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 17:44:23 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 08:19:59 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Kim", "Hannah", ""], ["Katerenchuk", "Denys", ""], ["Billet", "Daniel", ""], ["Huan", "Jun", ""], ["Park", "Haesun", ""], ["Li", "Boyang", ""]]}, {"id": "1804.04191", "submitter": "Tao Ding", "authors": "Shimei Pan, Tao Ding", "title": "Automatically Infer Human Traits and Behavior from Social Media Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the complexity of human minds and their behavioral flexibility, it\nrequires sophisticated data analysis to sift through a large amount of human\nbehavioral evidence to model human minds and to predict human behavior. People\ncurrently spend a significant amount of time on social media such as Twitter\nand Facebook. Thus many aspects of their lives and behaviors have been\ndigitally captured and continuously archived on these platforms. This makes\nsocial media a great source of large, rich and diverse human behavioral\nevidence. In this paper, we survey the recent work on applying machine learning\nto infer human traits and behavior from social media data. We will also point\nout several future research directions.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 19:59:44 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Pan", "Shimei", ""], ["Ding", "Tao", ""]]}, {"id": "1804.04205", "submitter": "Ziyi Zhao", "authors": "Ziyi Zhao, Krittaphat Pugdeethosapol, Sheng Lin, Zhe Li, Caiwen Ding,\n  Yanzhi Wang, Qinru Qiu", "title": "Learning Topics using Semantic Locality", "comments": "International Conference of Pattern Recognition (ICPR) in 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The topic modeling discovers the latent topic probability of the given text\ndocuments. To generate the more meaningful topic that better represents the\ngiven document, we proposed a new feature extraction technique which can be\nused in the data preprocessing stage. The method consists of three steps.\nFirst, it generates the word/word-pair from every single document. Second, it\napplies a two-way TF-IDF algorithm to word/word-pair for semantic filtering.\nThird, it uses the K-means algorithm to merge the word pairs that have the\nsimilar semantic meaning.\n  Experiments are carried out on the Open Movie Database (OMDb), Reuters\nDataset and 20NewsGroup Dataset. The mean Average Precision score is used as\nthe evaluation metric. Comparing our results with other state-of-the-art topic\nmodels, such as Latent Dirichlet allocation and traditional Restricted\nBoltzmann Machines. Our proposed data preprocessing can improve the generated\ntopic accuracy by up to 12.99\\%.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 20:23:23 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Zhao", "Ziyi", ""], ["Pugdeethosapol", "Krittaphat", ""], ["Lin", "Sheng", ""], ["Li", "Zhe", ""], ["Ding", "Caiwen", ""], ["Wang", "Yanzhi", ""], ["Qiu", "Qinru", ""]]}, {"id": "1804.04211", "submitter": "Maryam Fanaeepour", "authors": "Maryam Fanaeepour, Adam Makarucha, Jey Han Lau", "title": "Evaluating Word Embedding Hyper-Parameters for Similarity and Analogy\n  Tasks", "comments": "8 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The versatility of word embeddings for various applications is attracting\nresearchers from various fields. However, the impact of hyper-parameters when\ntraining embedding model is often poorly understood. How much do\nhyper-parameters such as vector dimensions and corpus size affect the quality\nof embeddings, and how do these results translate to downstream applications?\nUsing standard embedding evaluation metrics and datasets, we conduct a study to\nempirically measure the impact of these hyper-parameters.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 20:35:36 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Fanaeepour", "Maryam", ""], ["Makarucha", "Adam", ""], ["Lau", "Jey Han", ""]]}, {"id": "1804.04212", "submitter": "Hugo Caselles-Dupr\\'e", "authors": "Hugo Caselles-Dupr\\'e, Florian Lesaint, Jimena Royo-Letelier", "title": "Word2Vec applied to Recommendation: Hyperparameters Matter", "comments": "This paper is published on the 12th ACM Conference on Recommender\n  Systems, Vancouver, Canada, 2nd-7th October 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skip-gram with negative sampling, a popular variant of Word2vec originally\ndesigned and tuned to create word embeddings for Natural Language Processing,\nhas been used to create item embeddings with successful applications in\nrecommendation. While these fields do not share the same type of data, neither\nevaluate on the same tasks, recommendation applications tend to use the same\nalready tuned hyperparameters values, even if optimal hyperparameters values\nare often known to be data and task dependent. We thus investigate the marginal\nimportance of each hyperparameter in a recommendation setting through large\nhyperparameter grid searches on various datasets. Results reveal that\noptimizing neglected hyperparameters, namely negative sampling distribution,\nnumber of epochs, subsampling parameter and window-size, significantly improves\nperformance on a recommendation task, and can increase it by an order of\nmagnitude. Importantly, we find that optimal hyperparameters configurations for\nNatural Language Processing tasks and Recommendation tasks are noticeably\ndifferent.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 20:37:35 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 19:30:18 GMT"}, {"version": "v3", "created": "Wed, 29 Aug 2018 15:16:08 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Caselles-Dupr\u00e9", "Hugo", ""], ["Lesaint", "Florian", ""], ["Royo-Letelier", "Jimena", ""]]}, {"id": "1804.04225", "submitter": "Yue Liu", "authors": "Yue Liu, Tao Ge, Kusum S. Mathews, Heng Ji, Deborah L. McGuinness", "title": "Exploiting Task-Oriented Resources to Learn Word Embeddings for Clinical\n  Abbreviation Expansion", "comments": "Proceedings of BioNLP 15", "journal-ref": null, "doi": "10.18653/v1/W15-3810", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the medical domain, identifying and expanding abbreviations in clinical\ntexts is a vital task for both better human and machine understanding. It is a\nchallenging task because many abbreviations are ambiguous especially for\nintensive care medicine texts, in which phrase abbreviations are frequently\nused. Besides the fact that there is no universal dictionary of clinical\nabbreviations and no universal rules for abbreviation writing, such texts are\ndifficult to acquire, expensive to annotate and even sometimes, confusing to\ndomain experts. This paper proposes a novel and effective approach - exploiting\ntask-oriented resources to learn word embeddings for expanding abbreviations in\nclinical notes. We achieved 82.27% accuracy, close to expert human performance.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 21:16:39 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Liu", "Yue", ""], ["Ge", "Tao", ""], ["Mathews", "Kusum S.", ""], ["Ji", "Heng", ""], ["McGuinness", "Deborah L.", ""]]}, {"id": "1804.04242", "submitter": "Ye Wang", "authors": "Han Wang, Ye Wang, Xinxiang Zhang, Mi Lu, Yoonsuck Choe, Jingjing Cao", "title": "English Out-of-Vocabulary Lexical Evaluation Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike previous unknown nouns tagging task, this is the first attempt to\nfocus on out-of-vocabulary (OOV) lexical evaluation tasks that do not require\nany prior knowledge. The OOV words are words that only appear in test samples.\nThe goal of tasks is to provide solutions for OOV lexical classification and\nprediction. The tasks require annotators to conclude the attributes of the OOV\nwords based on their related contexts. Then, we utilize unsupervised word\nembedding methods such as Word2Vec and Word2GM to perform the baseline\nexperiments on the categorical classification task and OOV words attribute\nprediction tasks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 22:04:07 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2019 01:19:05 GMT"}, {"version": "v3", "created": "Fri, 3 May 2019 19:17:17 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Wang", "Han", ""], ["Wang", "Ye", ""], ["Zhang", "Xinxiang", ""], ["Lu", "Mi", ""], ["Choe", "Yoonsuck", ""], ["Cao", "Jingjing", ""]]}, {"id": "1804.04257", "submitter": "Vivek Kulkarni", "authors": "Mai ElSherief, Vivek Kulkarni, Dana Nguyen, William Yang Wang,\n  Elizabeth Belding", "title": "Hate Lingo: A Target-based Linguistic Analysis of Hate Speech in Social\n  Media", "comments": "10 pages, 7 figures. ICWSM-2018 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While social media empowers freedom of expression and individual voices, it\nalso enables anti-social behavior, online harassment, cyberbullying, and hate\nspeech. In this paper, we deepen our understanding of online hate speech by\nfocusing on a largely neglected but crucial aspect of hate speech -- its\ntarget: either \"directed\" towards a specific person or entity, or \"generalized\"\ntowards a group of people sharing a common protected characteristic. We perform\nthe first linguistic and psycholinguistic analysis of these two forms of hate\nspeech and reveal the presence of interesting markers that distinguish these\ntypes of hate speech. Our analysis reveals that Directed hate speech, in\naddition to being more personal and directed, is more informal, angrier, and\noften explicitly attacks the target (via name calling) with fewer analytic\nwords and more words suggesting authority and influence. Generalized hate\nspeech, on the other hand, is dominated by religious hate, is characterized by\nthe use of lethal words such as murder, exterminate, and kill; and quantity\nwords such as million and many. Altogether, our work provides a data-driven\nanalysis of the nuances of online-hate speech that enables not only a deepened\nunderstanding of hate speech and its social implications but also its\ndetection.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 23:39:49 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["ElSherief", "Mai", ""], ["Kulkarni", "Vivek", ""], ["Nguyen", "Dana", ""], ["Wang", "William Yang", ""], ["Belding", "Elizabeth", ""]]}, {"id": "1804.04262", "submitter": "Junichi Yamagishi Dr.", "authors": "Jaime Lorenzo-Trueba, Junichi Yamagishi, Tomoki Toda, Daisuke Saito,\n  Fernando Villavicencio, Tomi Kinnunen, Zhenhua Ling", "title": "The Voice Conversion Challenge 2018: Promoting Development of Parallel\n  and Nonparallel Methods", "comments": "Accepted for Speaker Odyssey 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Voice Conversion Challenge 2018, designed as a follow up to\nthe 2016 edition with the aim of providing a common framework for evaluating\nand comparing different state-of-the-art voice conversion (VC) systems. The\nobjective of the challenge was to perform speaker conversion (i.e. transform\nthe vocal identity) of a source speaker to a target speaker while maintaining\nlinguistic information. As an update to the previous challenge, we considered\nboth parallel and non-parallel data to form the Hub and Spoke tasks,\nrespectively. A total of 23 teams from around the world submitted their\nsystems, 11 of them additionally participated in the optional Spoke task. A\nlarge-scale crowdsourced perceptual evaluation was then carried out to rate the\nsubmitted converted speech in terms of naturalness and similarity to the target\nspeaker identity. In this paper, we present a brief summary of the\nstate-of-the-art techniques for VC, followed by a detailed explanation of the\nchallenge tasks and the results that were obtained.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 00:14:10 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Lorenzo-Trueba", "Jaime", ""], ["Yamagishi", "Junichi", ""], ["Toda", "Tomoki", ""], ["Saito", "Daisuke", ""], ["Villavicencio", "Fernando", ""], ["Kinnunen", "Tomi", ""], ["Ling", "Zhenhua", ""]]}, {"id": "1804.04264", "submitter": "Phu Mon Htut", "authors": "Phu Mon Htut, Samuel R. Bowman, Kyunghyun Cho", "title": "Training a Ranking Function for Open-Domain Question Answering", "comments": "To appear at NAACL-SRW 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there have been amazing advances in deep learning methods\nfor machine reading. In machine reading, the machine reader has to extract the\nanswer from the given ground truth paragraph. Recently, the state-of-the-art\nmachine reading models achieve human level performance in SQuAD which is a\nreading comprehension-style question answering (QA) task. The success of\nmachine reading has inspired researchers to combine information retrieval with\nmachine reading to tackle open-domain QA. However, these systems perform poorly\ncompared to reading comprehension-style QA because it is difficult to retrieve\nthe pieces of paragraphs that contain the answer to the question. In this\nstudy, we propose two neural network rankers that assign scores to different\npassages based on their likelihood of containing the answer to a given\nquestion. Additionally, we analyze the relative importance of semantic\nsimilarity and word level relevance matching in open-domain QA.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 00:25:45 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Htut", "Phu Mon", ""], ["Bowman", "Samuel R.", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1804.04266", "submitter": "Dai Quoc Nguyen", "authors": "Dai Quoc Nguyen, Thanh Vu, Tu Dinh Nguyen and Dinh Phung", "title": "A Capsule Network-based Embedding Model for Search Personalization", "comments": "A updated version is available at: arXiv:1808.04122", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search personalization aims to tailor search results to each specific user\nbased on the user's personal interests and preferences (i.e., the user\nprofile). Recent research approaches to search personalization by modelling the\npotential 3-way relationship between the submitted query, the user and the\nsearch results (i.e., documents). That relationship is then used to personalize\nthe search results to that user. In this paper, we introduce a novel embedding\nmodel based on capsule network, which recently is a breakthrough in deep\nlearning, to model the 3-way relationships for search personalization. In the\nmodel, each user (submitted query or returned document) is embedded by a vector\nin the same vector space. The 3-way relationship is described as a triple of\n(query, user, document) which is then modeled as a 3-column matrix containing\nthe three embedding vectors. After that, the 3-column matrix is fed into a deep\nlearning architecture to re-rank the search results returned by a basis ranker.\nExperimental results on query logs from a commercial web search engine show\nthat our model achieves better performances than the basis ranker as well as\nstrong search personalization baselines.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 00:36:53 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 12:05:45 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Nguyen", "Dai Quoc", ""], ["Vu", "Thanh", ""], ["Nguyen", "Tu Dinh", ""], ["Phung", "Dinh", ""]]}, {"id": "1804.04380", "submitter": "Daniel Fleischer", "authors": "Alon Rozental, Daniel Fleischer", "title": "Amobee at SemEval-2018 Task 1: GRU Neural Network with a CNN Attention\n  Mechanism for Sentiment Classification", "comments": "8 pages, accepted to the 12th International Workshop on Semantic\n  Evaluation 2018", "journal-ref": null, "doi": "10.18653/v1/S18-1033", "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the participation of Amobee in the shared sentiment\nanalysis task at SemEval 2018. We participated in all the English sub-tasks and\nthe Spanish valence tasks. Our system consists of three parts: training\ntask-specific word embeddings, training a model consisting of\ngated-recurrent-units (GRU) with a convolution neural network (CNN) attention\nmechanism and training stacking-based ensembles for each of the sub-tasks. Our\nalgorithm reached 3rd and 1st places in the valence ordinal classification\nsub-tasks in English and Spanish, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 09:04:50 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Rozental", "Alon", ""], ["Fleischer", "Daniel", ""]]}, {"id": "1804.04475", "submitter": "Arnab Bhattacharya", "authors": "Mitodru Niyogi, Kripabandhu Ghosh, Arnab Bhattacharya", "title": "Learning Multilingual Embeddings for Cross-Lingual Information Retrieval\n  in the Presence of Topically Aligned Corpora", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual information retrieval is a challenging task in the absence of\naligned parallel corpora. In this paper, we address this problem by considering\ntopically aligned corpora designed for evaluating an IR setup. To emphasize, we\nneither use any sentence-aligned corpora or document-aligned corpora, nor do we\nuse any language specific resources such as dictionary, thesaurus, or grammar\nrules. Instead, we use an embedding into a common space and learn word\ncorrespondences directly from there. We test our proposed approach for\nbilingual IR on standard FIRE datasets for Bangla, Hindi and English. The\nproposed method is superior to the state-of-the-art method not only for IR\nevaluation measures but also in terms of time requirements. We extend our\nmethod successfully to the trilingual setting.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 12:46:08 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Niyogi", "Mitodru", ""], ["Ghosh", "Kripabandhu", ""], ["Bhattacharya", "Arnab", ""]]}, {"id": "1804.04526", "submitter": "Simon Gottschalk", "authors": "Simon Gottschalk, Elena Demidova", "title": "EventKG: A Multilingual Event-Centric Temporal Knowledge Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key requirements to facilitate semantic analytics of information\nregarding contemporary and historical events on the Web, in the news and in\nsocial media is the availability of reference knowledge repositories containing\ncomprehensive representations of events and temporal relations. Existing\nknowledge graphs, with popular examples including DBpedia, YAGO and Wikidata,\nfocus mostly on entity-centric information and are insufficient in terms of\ntheir coverage and completeness with respect to events and temporal relations.\nEventKG presented in this paper is a multilingual event-centric temporal\nknowledge graph that addresses this gap. EventKG incorporates over 690 thousand\ncontemporary and historical events and over 2.3 million temporal relations\nextracted from several large-scale knowledge graphs and semi-structured sources\nand makes them available through a canonical representation.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 14:12:48 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Gottschalk", "Simon", ""], ["Demidova", "Elena", ""]]}, {"id": "1804.04589", "submitter": "Yue Dong", "authors": "Yue Dong", "title": "A Survey on Neural Network-Based Summarization Methods", "comments": "16 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic text summarization, the automated process of shortening a text\nwhile reserving the main ideas of the document(s), is a critical research area\nin natural language processing. The aim of this literature review is to survey\nthe recent work on neural-based models in automatic text summarization. We\nexamine in detail ten state-of-the-art neural-based summarizers: five\nabstractive models and five extractive models. In addition, we discuss the\nrelated techniques that can be applied to the summarization tasks and present\npromising paths for future research in neural-based summarization.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 18:49:16 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Dong", "Yue", ""]]}, {"id": "1804.04749", "submitter": "Christoph Treude", "authors": "Christoph Treude and Markus Wagner", "title": "Predicting Good Configurations for GitHub and Stack Overflow Topic\n  Models", "comments": "to appear as full paper at MSR 2019, the 16th International\n  Conference on Mining Software Repositories", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software repositories contain large amounts of textual data, ranging from\nsource code comments and issue descriptions to questions, answers, and comments\non Stack Overflow. To make sense of this textual data, topic modelling is\nfrequently used as a text-mining tool for the discovery of hidden semantic\nstructures in text bodies. Latent Dirichlet allocation (LDA) is a commonly used\ntopic model that aims to explain the structure of a corpus by grouping texts.\nLDA requires multiple parameters to work well, and there are only rough and\nsometimes conflicting guidelines available on how these parameters should be\nset. In this paper, we contribute (i) a broad study of parameters to arrive at\ngood local optima for GitHub and Stack Overflow text corpora, (ii) an\na-posteriori characterisation of text corpora related to eight programming\nlanguages, and (iii) an analysis of corpus feature importance via per-corpus\nLDA configuration. We find that (1) popular rules of thumb for topic modelling\nparameter configuration are not applicable to the corpora used in our\nexperiments, (2) corpora sampled from GitHub and Stack Overflow have different\ncharacteristics and require different configurations to achieve good model fit,\nand (3) we can predict good configurations for unseen corpora reliably. These\nfindings support researchers and practitioners in efficiently determining\nsuitable configurations for topic modelling when analysing textual data\ncontained in software repositories.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 00:09:48 GMT"}, {"version": "v2", "created": "Sat, 23 Jun 2018 11:30:52 GMT"}, {"version": "v3", "created": "Sun, 10 Mar 2019 07:38:41 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Treude", "Christoph", ""], ["Wagner", "Markus", ""]]}, {"id": "1804.04838", "submitter": "Duygu Altinok", "authors": "Duygu Altinok", "title": "An Ontology-Based Dialogue Management System for Banking and Finance\n  Dialogue Systems", "comments": "9 pages, 27 figures, goes to 1st Financial Narrative Processing\n  Workshop @ LREC 7-12 May 2018, Miyazaki, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Keeping the dialogue state in dialogue systems is a notoriously difficult\ntask. We introduce an ontology-based dialogue manage(OntoDM), a dialogue\nmanager that keeps the state of the conversation, provides a basis for anaphora\nresolution and drives the conversation via domain ontologies. The banking and\nfinance area promises great potential for disambiguating the context via a rich\nset of products and specificity of proper nouns, named entities and verbs. We\nused ontologies both as a knowledge base and a basis for the dialogue manager;\nthe knowledge base component and dialogue manager components coalesce in a\nsense. Domain knowledge is used to track Entities of Interest, i.e. nodes\n(classes) of the ontology which happen to be products and services. In this way\nwe also introduced conversation memory and attention in a sense. We finely\nblended linguistic methods, domain-driven keyword ranking and domain ontologies\nto create ways of domain-driven conversation. Proposed framework is used in our\nin-house German language banking and finance chatbots. General challenges of\nGerman language processing and finance-banking domain chatbot language models\nand lexicons are also introduced. This work is still in progress, hence no\nsuccess metrics have been introduced yet.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 08:40:57 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Altinok", "Duygu", ""]]}, {"id": "1804.05017", "submitter": "Yangming Zhou", "authors": "Qi Wang, Yuhang Xia, Yangming Zhou, Tong Ruan, Daqi Gao, Ping He", "title": "Incorporating Dictionaries into Deep Neural Networks for the Chinese\n  Clinical Named Entity Recognition", "comments": "21 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical Named Entity Recognition (CNER) aims to identify and classify\nclinical terms such as diseases, symptoms, treatments, exams, and body parts in\nelectronic health records, which is a fundamental and crucial task for clinical\nand translational research. In recent years, deep neural networks have achieved\nsignificant success in named entity recognition and many other Natural Language\nProcessing (NLP) tasks. Most of these algorithms are trained end to end, and\ncan automatically learn features from large scale labeled datasets. However,\nthese data-driven methods typically lack the capability of processing rare or\nunseen entities. Previous statistical methods and feature engineering practice\nhave demonstrated that human knowledge can provide valuable information for\nhandling rare and unseen cases. In this paper, we address the problem by\nincorporating dictionaries into deep neural networks for the Chinese CNER task.\nTwo different architectures that extend the Bi-directional Long Short-Term\nMemory (Bi-LSTM) neural network and five different feature representation\nschemes are proposed to handle the task. Computational results on the CCKS-2017\nTask 2 benchmark dataset show that the proposed method achieves the highly\ncompetitive performance compared with the state-of-the-art deep learning\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 16:36:44 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Wang", "Qi", ""], ["Xia", "Yuhang", ""], ["Zhou", "Yangming", ""], ["Ruan", "Tong", ""], ["Gao", "Daqi", ""], ["He", "Ping", ""]]}, {"id": "1804.05038", "submitter": "Miguel Ballesteros", "authors": "Jerry Quinn and Miguel Ballesteros", "title": "Pieces of Eight: 8-bit Neural Machine Translation", "comments": "To appear at NAACL 2018 Industry Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation has achieved levels of fluency and adequacy that\nwould have been surprising a short time ago. Output quality is extremely\nrelevant for industry purposes, however it is equally important to produce\nresults in the shortest time possible, mainly for latency-sensitive\napplications and to control cloud hosting costs. In this paper we show the\neffectiveness of translating with 8-bit quantization for models that have been\ntrained using 32-bit floating point values. Results show that 8-bit translation\nmakes a non-negligible impact in terms of speed with no degradation in accuracy\nand adequacy.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 17:10:12 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Quinn", "Jerry", ""], ["Ballesteros", "Miguel", ""]]}, {"id": "1804.05088", "submitter": "Yuval Pinter", "authors": "Ian Stewart, Yuval Pinter, Jacob Eisenstein", "title": "S\\'i o no, qu\\`e penses? Catalonian Independence and Linguistic Identity\n  on Social Media", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Political identity is often manifested in language variation, but the\nrelationship between the two is still relatively unexplored from a quantitative\nperspective. This study examines the use of Catalan, a language local to the\nsemi-autonomous region of Catalonia in Spain, on Twitter in discourse related\nto the 2017 independence referendum. We corroborate prior findings that\npro-independence tweets are more likely to include the local language than\nanti-independence tweets. We also find that Catalan is used more often in\nreferendum-related discourse than in other contexts, contrary to prior findings\non language variation. This suggests a strong role for the Catalan language in\nthe expression of Catalonian political identity.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 18:52:14 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Stewart", "Ian", ""], ["Pinter", "Yuval", ""], ["Eisenstein", "Jacob", ""]]}, {"id": "1804.05095", "submitter": "Atul Kr. Ojha Mr.", "authors": "Priya Rani, Atul Kr. Ojha, Girish Nath Jha", "title": "Automatic Language Identification System for Hindi and Magahi", "comments": "WILDRE-4 2018 Workshop Proceedings under the LREC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language identification has become a prerequisite for all kinds of automated\ntext processing systems. In this paper, we present a rule-based language\nidentifier tool for two closely related Indo-Aryan languages: Hindi and Magahi.\nThis system has currently achieved an accuracy of approx 86.34%. We hope to\nimprove this in the future. Automatic identification of languages will be\nsignificant in the accuracy of output of Web Crawlers.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 19:38:52 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Rani", "Priya", ""], ["Ojha", "Atul Kr.", ""], ["Jha", "Girish Nath", ""]]}, {"id": "1804.05166", "submitter": "Jinyu Li", "authors": "Jinyu Li, Rui Zhao, Zhuo Chen, Changliang Liu, Xiong Xiao, Guoli Ye,\n  and Yifan Gong", "title": "Developing Far-Field Speaker System Via Teacher-Student Learning", "comments": "Accepted at ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we develop the keyword spotting (KWS) and acoustic model (AM)\ncomponents in a far-field speaker system. Specifically, we use teacher-student\n(T/S) learning to adapt a close-talk well-trained production AM to far-field by\nusing parallel close-talk and simulated far-field data. We also use T/S\nlearning to compress a large-size KWS model into a small-size one to fit the\ndevice computational cost. Without the need of transcription, T/S learning well\nutilizes untranscribed data to boost the model performance in both the AM\nadaptation and KWS model compression. We further optimize the models with\nsequence discriminative training and live data to reach the best performance of\nsystems. The adapted AM improved from the baseline by 72.60% and 57.16%\nrelative word error rate reduction on play-back and live test data,\nrespectively. The final KWS model size was reduced by 27 times from a\nlarge-size KWS model without losing accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 04:52:23 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Li", "Jinyu", ""], ["Zhao", "Rui", ""], ["Chen", "Zhuo", ""], ["Liu", "Changliang", ""], ["Xiao", "Xiong", ""], ["Ye", "Guoli", ""], ["Gong", "Yifan", ""]]}, {"id": "1804.05253", "submitter": "Debanjan Ghosh", "authors": "Debanjan Ghosh and Smaranda Muresan", "title": "\"With 1 follower I must be AWESOME :P\". Exploring the role of irony\n  markers in irony recognition", "comments": "ICWSM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversations in social media often contain the use of irony or sarcasm, when\nthe users say the opposite of what they really mean. Irony markers are the\nmeta-communicative clues that inform the reader that an utterance is ironic. We\npropose a thorough analysis of theoretically grounded irony markers in two\nsocial media platforms: $Twitter$ and $Reddit$. Classification and frequency\nanalysis show that for $Twitter$, typographic markers such as emoticons and\nemojis are the most discriminative markers to recognize ironic utterances,\nwhile for $Reddit$ the morphological markers (e.g., interjections, tag\nquestions) are the most discriminative.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 17:39:45 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Ghosh", "Debanjan", ""], ["Muresan", "Smaranda", ""]]}, {"id": "1804.05260", "submitter": "Danushka Bollegala", "authors": "Danushka Bollegala, Vincent Atanasov, Takanori Maehara, Ken-ichi\n  Kawarabayashi", "title": "ClassiNet -- Predicting Missing Features for Short-Text Classification", "comments": "Accepted to ACM TKDD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fundamental problem in short-text classification is \\emph{feature\nsparseness} -- the lack of feature overlap between a trained model and a test\ninstance to be classified. We propose \\emph{ClassiNet} -- a network of\nclassifiers trained for predicting missing features in a given instance, to\novercome the feature sparseness problem. Using a set of unlabeled training\ninstances, we first learn binary classifiers as feature predictors for\npredicting whether a particular feature occurs in a given instance. Next, each\nfeature predictor is represented as a vertex $v_i$ in the ClassiNet where a\none-to-one correspondence exists between feature predictors and vertices. The\nweight of the directed edge $e_{ij}$ connecting a vertex $v_i$ to a vertex\n$v_j$ represents the conditional probability that given $v_i$ exists in an\ninstance, $v_j$ also exists in the same instance. We show that ClassiNets\ngeneralize word co-occurrence graphs by considering implicit co-occurrences\nbetween features. We extract numerous features from the trained ClassiNet to\novercome feature sparseness. In particular, for a given instance $\\vec{x}$, we\nfind similar features from ClassiNet that did not appear in $\\vec{x}$, and\nappend those features in the representation of $\\vec{x}$. Moreover, we propose\na method based on graph propagation to find features that are indirectly\nrelated to a given short-text. We evaluate ClassiNets on several benchmark\ndatasets for short-text classification. Our experimental results show that by\nusing ClassiNet, we can statistically significantly improve the accuracy in\nshort-text classification tasks, without having to use any external resources\nsuch as thesauri for finding related features.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 18:24:06 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Bollegala", "Danushka", ""], ["Atanasov", "Vincent", ""], ["Maehara", "Takanori", ""], ["Kawarabayashi", "Ken-ichi", ""]]}, {"id": "1804.05262", "submitter": "Danushka Bollegala", "authors": "Joshua Coates, Danushka Bollegala", "title": "Frustratingly Easy Meta-Embedding -- Computing Meta-Embeddings by\n  Averaging Source Word Embeddings", "comments": "Accepted to NAACL-HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating accurate meta-embeddings from pre-trained source embeddings has\nreceived attention lately. Methods based on global and locally-linear\ntransformation and concatenation have shown to produce accurate\nmeta-embeddings. In this paper, we show that the arithmetic mean of two\ndistinct word embedding sets yields a performant meta-embedding that is\ncomparable or better than more complex meta-embedding learning methods. The\nresult seems counter-intuitive given that vector spaces in different source\nembeddings are not comparable and cannot be simply averaged. We give insight\ninto why averaging can still produce accurate meta-embedding despite the\nincomparability of the source vector spaces.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 18:30:01 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Coates", "Joshua", ""], ["Bollegala", "Danushka", ""]]}, {"id": "1804.05276", "submitter": "Ashok Deb", "authors": "Ashok Deb, Kristina Lerman, Emilio Ferrara", "title": "Predicting Cyber Events by Leveraging Hacker Sentiment", "comments": null, "journal-ref": "Information 2018, 9(11), 280", "doi": "10.3390/info9110280", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent high-profile cyber attacks exemplify why organizations need better\ncyber defenses. Cyber threats are hard to accurately predict because attackers\nusually try to mask their traces. However, they often discuss exploits and\ntechniques on hacking forums. The community behavior of the hackers may provide\ninsights into groups' collective malicious activity. We propose a novel\napproach to predict cyber events using sentiment analysis. We test our approach\nusing cyber attack data from 2 major business organizations. We consider 3\ntypes of events: malicious software installation, malicious destination visits,\nand malicious emails that surpassed the target organizations' defenses. We\nconstruct predictive signals by applying sentiment analysis on hacker forum\nposts to better understand hacker behavior. We analyze over 400K posts\ngenerated between January 2016 and January 2018 on over 100 hacking forums both\non surface and Dark Web. We find that some forums have significantly more\npredictive power than others. Sentiment-based models that leverage specific\nforums can outperform state-of-the-art deep learning and time-series models on\nforecasting cyber attacks weeks ahead of the events.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 20:56:58 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Deb", "Ashok", ""], ["Lerman", "Kristina", ""], ["Ferrara", "Emilio", ""]]}, {"id": "1804.05294", "submitter": "Antonio San Mart\\'in", "authors": "P. Le\\'on-Ara\\'uz, A. San Mart\\'in", "title": "The EcoLexicon Semantic Sketch Grammar: from Knowledge Patterns to Word\n  Sketches", "comments": "Proceedings of the LREC 2018 Workshop Globalex 2018 Lexicography &\n  WordNets, edited by Kerneman, I. & Krek, S., pages 94-99. Miyazaki: Globalex", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many projects have applied knowledge patterns (KPs) to the retrieval of\nspecialized information. Yet terminologists still rely on manual analysis of\nconcordance lines to extract semantic information, since there are no\nuser-friendly publicly available applications enabling them to find knowledge\nrich contexts (KRCs). To fill this void, we have created the KP-based\nEcoLexicon Semantic SketchGrammar (ESSG) in the well-known corpus query system\nSketch Engine. For the first time, the ESSG is now publicly available inSketch\nEngine to query the EcoLexicon English Corpus. Additionally, reusing the ESSG\nin any English corpus uploaded by the user enables Sketch Engine to extract\nKRCs codifying generic-specific, part-whole, location, cause and function\nrelations, because most of the KPs are domain-independent. The information is\ndisplayed in the form of summary lists (word sketches) containing the pairs of\nterms linked by a given semantic relation. This paper describes the process of\nbuilding a KP-based sketch grammar with special focus on the last stage,\nnamely, the evaluation with refinement purposes. We conducted an initial\nshallow precision and recall evaluation of the 64 English sketch grammar rules\ncreated so far for hyponymy, meronymy and causality. Precision was measured\nbased on a random sample of concordances extracted from each word sketch type.\nRecall was assessed based on a random sample of concordances where known term\npairs are found. The results are necessary for the improvement and refinement\nof the ESSG. The noise of false positives helped to further specify the rules,\nwhereas the silence of false negatives allows us to find useful new patterns.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 02:21:28 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Le\u00f3n-Ara\u00faz", "P.", ""], ["Mart\u00edn", "A. San", ""]]}, {"id": "1804.05306", "submitter": "Che-Ping Tsai", "authors": "Che-Ping Tsai, Yi-Lin Tuan and Lin-shan Lee", "title": "Transcribing Lyrics From Commercial Song Audio: The First Step Towards\n  Singing Content Processing", "comments": "Accepted as a conference paper at ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken content processing (such as retrieval and browsing) is maturing, but\nthe singing content is still almost completely left out. Songs are human voice\ncarrying plenty of semantic information just as speech, and may be considered\nas a special type of speech with highly flexible prosody. The various problems\nin song audio, for example the significantly changing phone duration over\nhighly flexible pitch contours, make the recognition of lyrics from song audio\nmuch more difficult. This paper reports an initial attempt towards this goal.\nWe collected music-removed version of English songs directly from commercial\nsinging content. The best results were obtained by TDNN-LSTM with data\naugmentation with 3-fold speed perturbation plus some special approaches. The\nWER achieved (73.90%) was significantly lower than the baseline (96.21%), but\nstill relatively high.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 05:50:27 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Tsai", "Che-Ping", ""], ["Tuan", "Yi-Lin", ""], ["Lee", "Lin-shan", ""]]}, {"id": "1804.05374", "submitter": "Mirco Ravanelli", "authors": "Mirco Ravanelli, Dmitriy Serdyuk, Yoshua Bengio", "title": "Twin Regularization for online speech recognition", "comments": "Accepted at INTESPEECH 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online speech recognition is crucial for developing natural human-machine\ninterfaces. This modality, however, is significantly more challenging than\noff-line ASR, since real-time/low-latency constraints inevitably hinder the use\nof future information, that is known to be very helpful to perform robust\npredictions. A popular solution to mitigate this issue consists of feeding\nneural acoustic models with context windows that gather some future frames.\nThis introduces a latency which depends on the number of employed look-ahead\nfeatures. This paper explores a different approach, based on estimating the\nfuture rather than waiting for it. Our technique encourages the hidden\nrepresentations of a unidirectional recurrent network to embed some useful\ninformation about the future. Inspired by a recently proposed technique called\nTwin Networks, we add a regularization term that forces forward hidden states\nto be as close as possible to cotemporal backward ones, computed by a \"twin\"\nneural network running backwards in time. The experiments, conducted on a\nnumber of datasets, recurrent architectures, input features, and acoustic\nconditions, have shown the effectiveness of this approach. One important\nadvantage is that our method does not introduce any additional computation at\ntest time if compared to standard unidirectional recurrent networks.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 15:52:16 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 01:00:03 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Ravanelli", "Mirco", ""], ["Serdyuk", "Dmitriy", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1804.05388", "submitter": "Kim Anh Nguyen", "authors": "Kim Anh Nguyen, Sabine Schulte im Walde, Ngoc Thang Vu", "title": "Introducing two Vietnamese Datasets for Evaluating Semantic Models of\n  (Dis-)Similarity and Relatedness", "comments": "The 16th Annual Conference of the North American Chapter of the\n  Association for Computational Linguistics: Human Language Technologies (NAACL\n  HLT 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two novel datasets for the low-resource language Vietnamese to\nassess models of semantic similarity: ViCon comprises pairs of synonyms and\nantonyms across word classes, thus offering data to distinguish between\nsimilarity and dissimilarity. ViSim-400 provides degrees of similarity across\nfive semantic relations, as rated by human judges. The two datasets are\nverified through standard co-occurrence and neural network models, showing\nresults comparable to the respective English datasets.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 17:38:16 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 11:33:48 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Nguyen", "Kim Anh", ""], ["Walde", "Sabine Schulte im", ""], ["Vu", "Ngoc Thang", ""]]}, {"id": "1804.05392", "submitter": "Kenton Lee", "authors": "Kenton Lee, Luheng He, Luke Zettlemoyer", "title": "Higher-order Coreference Resolution with Coarse-to-fine Inference", "comments": "Accepted to NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a fully differentiable approximation to higher-order inference\nfor coreference resolution. Our approach uses the antecedent distribution from\na span-ranking architecture as an attention mechanism to iteratively refine\nspan representations. This enables the model to softly consider multiple hops\nin the predicted clusters. To alleviate the computational cost of this\niterative process, we introduce a coarse-to-fine approach that incorporates a\nless accurate but more efficient bilinear factor, enabling more aggressive\npruning without hurting accuracy. Compared to the existing state-of-the-art\nspan-ranking approach, our model significantly improves accuracy on the English\nOntoNotes benchmark, while being far more computationally efficient.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 17:47:26 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Lee", "Kenton", ""], ["He", "Luheng", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1804.05398", "submitter": "Radhika Mamidi Dr", "authors": "Radhika Mamidi", "title": "Context and Humor: Understanding Amul advertisements of India", "comments": "Presented at Workshop in Designing Humour in Human-Computer\n  Interaction (HUMIC 2017). September 26th 2017, Mumbai, India. In conjunction\n  with INTERACT 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Contextual knowledge is the most important element in understanding language.\nBy contextual knowledge we mean both general knowledge and discourse knowledge\ni.e. knowledge of the situational context, background knowledge and the\nco-textual context [10]. In this paper, we will discuss the importance of\ncontextual knowledge in understanding the humor present in the cartoon based\nAmul advertisements in India.In the process, we will analyze these\nadvertisements and also see if humor is an effective tool for advertising and\nthereby, for marketing.These bilingual advertisements also expect the audience\nto have the appropriate linguistic knowledge which includes knowledge of\nEnglish and Hindi vocabulary, morphology and syntax. Different techniques like\npunning, portmanteaus and parodies of popular proverbs, expressions, acronyms,\nfamous dialogues, songs etc are employed to convey the message in a humorous\nway. The present study will concentrate on these linguistic cues and the\nrequired context for understanding wit and humor.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 18:00:53 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Mamidi", "Radhika", ""]]}, {"id": "1804.05408", "submitter": "Sean MacAvaney", "authors": "Sean MacAvaney, Luca Soldaini, Arman Cohan, Nazli Goharian", "title": "GU IRLAB at SemEval-2018 Task 7: Tree-LSTMs for Scientific Relation\n  Classification", "comments": "5 pages, Accepted to SemEval 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SemEval 2018 Task 7 focuses on relation ex- traction and classification in\nscientific literature. In this work, we present our tree-based LSTM network for\nthis shared task. Our approach placed 9th (of 28) for subtask 1.1 (relation\nclassification), and 5th (of 20) for subtask 1.2 (relation classification with\nnoisy entities). We also provide an ablation study of features included as\ninput to the network.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 19:02:13 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["MacAvaney", "Sean", ""], ["Soldaini", "Luca", ""], ["Cohan", "Arman", ""], ["Goharian", "Nazli", ""]]}, {"id": "1804.05416", "submitter": "Johannes Wahle", "authors": "Taraka Rama, Johann-Mattis List, Johannes Wahle, Gerhard J\\\"ager", "title": "Are Automatic Methods for Cognate Detection Good Enough for Phylogenetic\n  Reconstruction in Historical Linguistics?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We evaluate the performance of state-of-the-art algorithms for automatic\ncognate detection by comparing how useful automatically inferred cognates are\nfor the task of phylogenetic inference compared to classical manually annotated\ncognate sets. Our findings suggest that phylogenies inferred from automated\ncognate sets come close to phylogenies inferred from expert-annotated ones,\nalthough on average, the latter are still superior. We conclude that future\nwork on phylogenetic reconstruction can profit much from automatic cognate\ndetection. Especially where scholars are merely interested in exploring the\nbigger picture of a language family's phylogeny, algorithms for automatic\ncognate detection are a useful complement for current research on language\nphylogenies.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 19:45:07 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Rama", "Taraka", ""], ["List", "Johann-Mattis", ""], ["Wahle", "Johannes", ""], ["J\u00e4ger", "Gerhard", ""]]}, {"id": "1804.05417", "submitter": "Reuben Cohn-Gordon", "authors": "Reuben Cohn-Gordon, Noah Goodman, Christopher Potts", "title": "Pragmatically Informative Image Captioning with Character-Level\n  Inference", "comments": "NAACL Paper, 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We combine a neural image captioner with a Rational Speech Acts (RSA) model\nto make a system that is pragmatically informative: its objective is to produce\ncaptions that are not merely true but also distinguish their inputs from\nsimilar images. Previous attempts to combine RSA with neural image captioning\nrequire an inference which normalizes over the entire set of possible\nutterances. This poses a serious problem of efficiency, previously solved by\nsampling a small subset of possible utterances. We instead solve this problem\nby implementing a version of RSA which operates at the level of characters\n(\"a\",\"b\",\"c\"...) during the unrolling of the caption. We find that the\nutterance-level effect of referential captions can be obtained with only\ncharacter-level decisions. Finally, we introduce an automatic method for\ntesting the performance of pragmatic speaker models, and show that our model\noutperforms a non-pragmatic baseline as well as a word-level RSA captioner.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 19:55:13 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 17:10:15 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Cohn-Gordon", "Reuben", ""], ["Goodman", "Noah", ""], ["Potts", "Christopher", ""]]}, {"id": "1804.05435", "submitter": "Peter Clark", "authors": "Peter Clark, Bhavana Dalvi, Niket Tandon", "title": "What Happened? Leveraging VerbNet to Predict the Effects of Actions in\n  Procedural Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is to answer questions about paragraphs describing processes (e.g.,\nphotosynthesis). Texts of this genre are challenging because the effects of\nactions are often implicit (unstated), requiring background knowledge and\ninference to reason about the changing world states. To supply this knowledge,\nwe leverage VerbNet to build a rulebase (called the Semantic Lexicon) of the\npreconditions and effects of actions, and use it along with commonsense\nknowledge of persistence to answer questions about change. Our evaluation shows\nthat our system, ProComp, significantly outperforms two strong reading\ncomprehension (RC) baselines. Our contributions are two-fold: the Semantic\nLexicon rulebase itself, and a demonstration of how a simulation-based approach\nto machine reading can outperform RC methods that rely on surface cues alone.\n  Since this work was performed, we have developed neural systems that\noutperform ProComp, described elsewhere (Dalvi et al., NAACL'18). However, the\nSemantic Lexicon remains a novel and potentially useful resource, and its\nintegration with neural systems remains a currently unexplored opportunity for\nfurther improvements in machine reading about processes.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 21:48:28 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Clark", "Peter", ""], ["Dalvi", "Bhavana", ""], ["Tandon", "Niket", ""]]}, {"id": "1804.05448", "submitter": "Xin Wang", "authors": "Xin Wang, Yuan-Fang Wang, William Yang Wang", "title": "Watch, Listen, and Describe: Globally and Locally Aligned Cross-Modal\n  Attentions for Video Captioning", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge for video captioning is to combine audio and visual cues.\nExisting multi-modal fusion methods have shown encouraging results in video\nunderstanding. However, the temporal structures of multiple modalities at\ndifferent granularities are rarely explored, and how to selectively fuse the\nmulti-modal representations at different levels of details remains uncharted.\nIn this paper, we propose a novel hierarchically aligned cross-modal attention\n(HACA) framework to learn and selectively fuse both global and local temporal\ndynamics of different modalities. Furthermore, for the first time, we validate\nthe superior performance of the deep audio features on the video captioning\ntask. Finally, our HACA model significantly outperforms the previous best\nsystems and achieves new state-of-the-art results on the widely used MSR-VTT\ndataset.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 23:04:57 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Wang", "Xin", ""], ["Wang", "Yuan-Fang", ""], ["Wang", "William Yang", ""]]}, {"id": "1804.05499", "submitter": "Aaron Jaech", "authors": "Aaron Jaech and Shobhit Hathi and Mari Ostendorf", "title": "Community Member Retrieval on Social Media using Textual Information", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of community membership detection using only\ntext features in a scenario where a small number of positive labeled examples\ndefines the community. The solution introduces an unsupervised proxy task for\nlearning user embeddings: user re-identification. Experiments with 16 different\ncommunities show that the resulting embeddings are more effective for community\nmembership identification than common unsupervised representations.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 04:03:52 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Jaech", "Aaron", ""], ["Hathi", "Shobhit", ""], ["Ostendorf", "Mari", ""]]}, {"id": "1804.05630", "submitter": "Ismail El Bazi", "authors": "Ismail El Bazi and Nabil Laachfoubi", "title": "Arabic Named Entity Recognition using Word Representations", "comments": null, "journal-ref": "International Journal of Computer Science and Information Security\n  (IJCSIS), Vol. 14, No. 8, August 2016", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown the effectiveness of the word representations features\nin significantly improving supervised NER for the English language. In this\nstudy we investigate whether word representations can also boost supervised NER\nin Arabic. We use word representations as additional features in a Conditional\nRandom Field (CRF) model and we systematically compare three popular neural\nword embedding algorithms (SKIP-gram, CBOW and GloVe) and six different\napproaches for integrating word representations into NER system. Experimental\nresults show that Brown Clustering achieves the best performance among the six\napproaches. Concerning the word embedding features, the clustering embedding\nfeatures outperform other embedding features and the distributional prototypes\nproduce the second best result. Moreover, the combination of Brown clusters and\nword embedding features provides additional improvement of nearly 10% in\nF1-score over the baseline.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 12:08:13 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Bazi", "Ismail El", ""], ["Laachfoubi", "Nabil", ""]]}, {"id": "1804.05685", "submitter": "Arman Cohan", "authors": "Arman Cohan, Franck Dernoncourt, Doo Soon Kim, Trung Bui, Seokhwan\n  Kim, Walter Chang and Nazli Goharian", "title": "A Discourse-Aware Attention Model for Abstractive Summarization of Long\n  Documents", "comments": "NAACL HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural abstractive summarization models have led to promising results in\nsummarizing relatively short documents. We propose the first model for\nabstractive summarization of single, longer-form documents (e.g., research\npapers). Our approach consists of a new hierarchical encoder that models the\ndiscourse structure of a document, and an attentive discourse-aware decoder to\ngenerate the summary. Empirical results on two large-scale datasets of\nscientific papers show that our model significantly outperforms\nstate-of-the-art models.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 13:55:20 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 13:06:37 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Cohan", "Arman", ""], ["Dernoncourt", "Franck", ""], ["Kim", "Doo Soon", ""], ["Bui", "Trung", ""], ["Kim", "Seokhwan", ""], ["Chang", "Walter", ""], ["Goharian", "Nazli", ""]]}, {"id": "1804.05686", "submitter": "Sabine Ploux Dr.", "authors": "Sabine Ploux and Viviane D\\'eprez", "title": "Organization and Independence or Interdependence? Study of the\n  Neurophysiological Dynamics of Syntactic and Semantic Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we present a multivariate model for determining the different\nsyntactic, semantic, and form (surface-structure) processes underlying the\ncomprehension of simple phrases. This model is applied to EEG signals recorded\nduring a reading task. The results show a hierarchical precedence of the\nneurolinguistic processes : form, then syntactic and lastly semantic processes.\nWe also found (a) that verbs are at the heart of phrase syntax processing, (b)\nan interaction between syntactic movement within the phrase, and semantic\nprocesses derived from a person-centered reference frame. Eigenvectors of the\nmultivariate model provide electrode-times profiles that separate the\ndistinctive linguistic processes and/or highlight their interaction. The\naccordance of these findings with different linguistic theories are discussed.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 13:59:08 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Ploux", "Sabine", ""], ["D\u00e9prez", "Viviane", ""]]}, {"id": "1804.05689", "submitter": "Sowmya Vajjala", "authors": "Sowmya Vajjala and Ziwei Zhou", "title": "The Relevance of Text and Speech Features in Automatic Non-native\n  English Accent Identification", "comments": "Paper was originally submitted for NAACL 2018 and rejected. However,\n  we don't plan to work further on this project due to logistic constraints.\n  So, we are uploading the submitted version, with some changes to address\n  reviewer comments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our experiments with automatically identifying native\naccents from speech samples of non-native English speakers using low level\naudio features, and n-gram features from manual transcriptions. Using a\npublicly available non-native speech corpus and simple audio feature\nrepresentations that do not perform word/phoneme recognition, we show that it\nis possible to achieve close to 90% classification accuracy for this task.\nWhile character n-grams perform similar to speech features, we show that speech\nfeatures are not affected by prompt variation, whereas ngrams are. Since the\napproach followed can be easily adapted to any language provided we have enough\ntraining data, we believe these results will provide useful insights for the\ndevelopment of accent recognition systems and for the study of accents in the\ncontext of language learning.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 14:03:45 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Vajjala", "Sowmya", ""], ["Zhou", "Ziwei", ""]]}, {"id": "1804.05734", "submitter": "Chenhua Chen", "authors": "Chenhua Chen, Yue Zhang", "title": "Learning How to Self-Learn: Enhancing Self-Training Using Neural\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-training is a useful strategy for semi-supervised learning, leveraging\nraw texts for enhancing model performances. Traditional self-training methods\ndepend on heuristics such as model confidence for instance selection, the\nmanual adjustment of which can be expensive. To address these challenges, we\npropose a deep reinforcement learning method to learn the self-training\nstrategy automatically. Based on neural network representation of sentences,\nour model automatically learns an optimal policy for instance selection.\nExperimental results show that our approach outperforms the baseline solutions\nin terms of better tagging performances and stability.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 15:25:53 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Chen", "Chenhua", ""], ["Zhang", "Yue", ""]]}, {"id": "1804.05825", "submitter": "Lena Hettinger", "authors": "Lena Hettinger, Alexander Dallmann, Albin Zehe, Thomas Niebler,\n  Andreas Hotho", "title": "ClaiRE at SemEval-2018 Task 7 - Extended Version", "comments": "This is the extended version for our work: ClaiRE at SemEval-2018\n  Task 7", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe our post-evaluation results for SemEval-2018 Task 7\non clas- sification of semantic relations in scientific literature for clean\n(subtask 1.1) and noisy data (subtask 1.2). This is an extended ver- sion of\nour workshop paper (Hettinger et al., 2018) including further technical details\n(Sec- tions 3.2 and 4.3) and changes made to the preprocessing step in the\npost-evaluation phase (Section 2.1). Due to these changes Classification of\nRelations using Embeddings (ClaiRE) achieved an improved F1 score of 75.11% for\nthe first subtask and 81.44% for the second.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 17:52:36 GMT"}, {"version": "v2", "created": "Tue, 1 May 2018 07:33:00 GMT"}, {"version": "v3", "created": "Tue, 15 May 2018 18:30:34 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Hettinger", "Lena", ""], ["Dallmann", "Alexander", ""], ["Zehe", "Albin", ""], ["Niebler", "Thomas", ""], ["Hotho", "Andreas", ""]]}, {"id": "1804.05831", "submitter": "Alexander Panchenko", "authors": "Nikita Muravyev, Alexander Panchenko, Sergei Obiedkov", "title": "Neologisms on Facebook", "comments": "in Russian", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a study of neologisms and loan words frequently\noccurring in Facebook user posts. We have analyzed a dataset of several million\npublically available posts written during 2006-2013 by Russian-speaking\nFacebook users. From these, we have built a vocabulary of most frequent\nlemmatized words missing from the OpenCorpora dictionary the assumption being\nthat many such words have entered common use only recently. This assumption is\ncertainly not true for all the words extracted in this way; for that reason, we\nmanually filtered the automatically obtained list in order to exclude\nnon-Russian or incorrectly lemmatized words, as well as words recorded by other\ndictionaries or those occurring in texts from the Russian National Corpus. The\nresult is a list of 168 words that can potentially be considered neologisms. We\npresent an attempt at an etymological classification of these neologisms\n(unsurprisingly, most of them have recently been borrowed from English, but\nthere are also quite a few new words composed of previously borrowed stems) and\nidentify various derivational patterns. We also classify words into several\nlarge thematic areas, \"internet\", \"marketing\", and \"multimedia\" being among\nthose with the largest number of words. We believe that, together with the word\nbase collected in the process, they can serve as a starting point in further\nstudies of neologisms and lexical processes that lead to their acceptance into\nthe mainstream language.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 16:57:59 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Muravyev", "Nikita", ""], ["Panchenko", "Alexander", ""], ["Obiedkov", "Sergei", ""]]}, {"id": "1804.05868", "submitter": "Irshad Bhat", "authors": "Irshad Ahmad Bhat, Riyaz Ahmad Bhat, Manish Shrivastava and Dipti\n  Misra Sharma", "title": "Universal Dependency Parsing for Hindi-English Code-switching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code-switching is a phenomenon of mixing grammatical structures of two or\nmore languages under varied social constraints. The code-switching data differ\nso radically from the benchmark corpora used in NLP community that the\napplication of standard technologies to these data degrades their performance\nsharply. Unlike standard corpora, these data often need to go through\nadditional processes such as language identification, normalization and/or\nback-transliteration for their efficient processing. In this paper, we\ninvestigate these indispensable processes and other problems associated with\nsyntactic parsing of code-switching data and propose methods to mitigate their\neffects. In particular, we study dependency parsing of code-switching data of\nHindi and English multilingual speakers from Twitter. We present a treebank of\nHindi-English code-switching tweets under Universal Dependencies scheme and\npropose a neural stacking model for parsing that efficiently leverages\npart-of-speech tag and syntactic tree annotations in the code-switching\ntreebank and the preexisting Hindi and English treebanks. We also present\nnormalization and back-transliteration models with a decoding process tailored\nfor code-switching data. Results show that our neural stacking parser is 1.5%\nLAS points better than the augmented parsing model and our decoding process\nimproves results by 3.8% LAS points over the first-best normalization and/or\nback-transliteration.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 18:05:52 GMT"}, {"version": "v2", "created": "Wed, 18 Apr 2018 10:09:30 GMT"}, {"version": "v3", "created": "Tue, 24 Apr 2018 17:05:21 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Bhat", "Irshad Ahmad", ""], ["Bhat", "Riyaz Ahmad", ""], ["Shrivastava", "Manish", ""], ["Sharma", "Dipti Misra", ""]]}, {"id": "1804.05918", "submitter": "Zeyu Dai", "authors": "Zeyu Dai, Ruihong Huang", "title": "Improving Implicit Discourse Relation Classification by Modeling\n  Inter-dependencies of Discourse Units in a Paragraph", "comments": "Accepted by NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue that semantic meanings of a sentence or clause can not be\ninterpreted independently from the rest of a paragraph, or independently from\nall discourse relations and the overall paragraph-level discourse structure.\nWith the goal of improving implicit discourse relation classification, we\nintroduce a paragraph-level neural networks that model inter-dependencies\nbetween discourse units as well as discourse relation continuity and patterns,\nand predict a sequence of discourse relations in a paragraph. Experimental\nresults show that our model outperforms the previous state-of-the-art systems\non the benchmark corpus of PDTB.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 20:01:06 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Dai", "Zeyu", ""], ["Huang", "Ruihong", ""]]}, {"id": "1804.05922", "submitter": "Bhuwan Dhingra", "authors": "Bhuwan Dhingra, Qiao Jin, Zhilin Yang, William W. Cohen, Ruslan\n  Salakhutdinov", "title": "Neural Models for Reasoning over Multiple Mentions using Coreference", "comments": "NAACL 2018 (Short Paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems in NLP require aggregating information from multiple mentions\nof the same entity which may be far apart in the text. Existing Recurrent\nNeural Network (RNN) layers are biased towards short-term dependencies and\nhence not suited to such tasks. We present a recurrent layer which is instead\nbiased towards coreferent dependencies. The layer uses coreference annotations\nextracted from an external system to connect entity mentions belonging to the\nsame cluster. Incorporating this layer into a state-of-the-art reading\ncomprehension model improves performance on three datasets -- Wikihop, LAMBADA\nand the bAbi AI tasks -- with large gains when training data is scarce.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 20:07:44 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Dhingra", "Bhuwan", ""], ["Jin", "Qiao", ""], ["Yang", "Zhilin", ""], ["Cohen", "William W.", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1804.05940", "submitter": "Marcin Junczys-Dowmunt", "authors": "Marcin Junczys-Dowmunt, Roman Grundkiewicz, Shubha Guha, Kenneth\n  Heafield", "title": "Approaching Neural Grammatical Error Correction as a Low-Resource\n  Machine Translation Task", "comments": "Accepted for oral presentation in long paper research track at NAACL\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previously, neural methods in grammatical error correction (GEC) did not\nreach state-of-the-art results compared to phrase-based statistical machine\ntranslation (SMT) baselines. We demonstrate parallels between neural GEC and\nlow-resource neural MT and successfully adapt several methods from low-resource\nMT to neural GEC. We further establish guidelines for trustable results in\nneural GEC and propose a set of model-independent methods for neural GEC that\ncan be easily applied in most GEC settings. Proposed methods include adding\nsource-side noise, domain-adaptation techniques, a GEC-specific\ntraining-objective, transfer learning with monolingual data, and ensembling of\nindependently trained GEC models and language models. The combined effects of\nthese methods result in better than state-of-the-art neural GEC models that\noutperform previously best neural GEC systems by more than 10% M$^2$ on the\nCoNLL-2014 benchmark and 5.9% on the JFLEG test set. Non-neural\nstate-of-the-art systems are outperformed by more than 2% on the CoNLL-2014\nbenchmark and by 4% on JFLEG.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 21:06:14 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Junczys-Dowmunt", "Marcin", ""], ["Grundkiewicz", "Roman", ""], ["Guha", "Shubha", ""], ["Heafield", "Kenneth", ""]]}, {"id": "1804.05945", "submitter": "Marcin Junczys-Dowmunt", "authors": "Roman Grundkiewicz, Marcin Junczys-Dowmunt", "title": "Near Human-Level Performance in Grammatical Error Correction with Hybrid\n  Machine Translation", "comments": "Accepted for oral presentation, research track, short papers, at\n  NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We combine two of the most popular approaches to automated Grammatical Error\nCorrection (GEC): GEC based on Statistical Machine Translation (SMT) and GEC\nbased on Neural Machine Translation (NMT). The hybrid system achieves new\nstate-of-the-art results on the CoNLL-2014 and JFLEG benchmarks. This GEC\nsystem preserves the accuracy of SMT output and, at the same time, generates\nmore fluent sentences as it typical for NMT. Our analysis shows that the\ncreated systems are closer to reaching human-level performance than any other\nGEC system reported so far.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 21:13:31 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Grundkiewicz", "Roman", ""], ["Junczys-Dowmunt", "Marcin", ""]]}, {"id": "1804.05958", "submitter": "Julia Kreutzer", "authors": "Julia Kreutzer, Shahram Khadivi, Evgeny Matusov, Stefan Riezler", "title": "Can Neural Machine Translation be Improved with User Feedback?", "comments": "Accepted at NAACL-HLT 2018 (Industry Track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first real-world application of methods for improving neural\nmachine translation (NMT) with human reinforcement, based on explicit and\nimplicit user feedback collected on the eBay e-commerce platform. Previous work\nhas been confined to simulation experiments, whereas in this paper we work with\nreal logged feedback for offline bandit learning of NMT parameters. We conduct\na thorough analysis of the available explicit user judgments---five-star\nratings of translation quality---and show that they are not reliable enough to\nyield significant improvements in bandit learning. In contrast, we successfully\nutilize implicit task-based feedback collected in a cross-lingual search task\nto improve task-specific and machine translation quality metrics.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 21:55:45 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Kreutzer", "Julia", ""], ["Khadivi", "Shahram", ""], ["Matusov", "Evgeny", ""], ["Riezler", "Stefan", ""]]}, {"id": "1804.05972", "submitter": "Sean MacAvaney", "authors": "Sean MacAvaney, Amir Zeldes", "title": "A Deeper Look into Dependency-Based Word Embeddings", "comments": "6 pages; to appear at NAACL-SRW 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the effect of various dependency-based word embeddings on\ndistinguishing between functional and domain similarity, word similarity\nrankings, and two downstream tasks in English. Variations include word\nembeddings trained using context windows from Stanford and Universal\ndependencies at several levels of enhancement (ranging from unlabeled, to\nEnhanced++ dependencies). Results are compared to basic linear contexts and\nevaluated on several datasets. We found that embeddings trained with Universal\nand Stanford dependency contexts excel at different tasks, and that enhanced\ndependencies often improve performance.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 23:12:07 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["MacAvaney", "Sean", ""], ["Zeldes", "Amir", ""]]}, {"id": "1804.05990", "submitter": "Hao Peng", "authors": "Hao Peng, Sam Thomson, Swabha Swayamdipta, and Noah A. Smith", "title": "Learning Joint Semantic Parsers from Disjoint Data", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to learning semantic parsers from multiple\ndatasets, even when the target semantic formalisms are drastically different,\nand the underlying corpora do not overlap. We handle such \"disjoint\" data by\ntreating annotations for unobserved formalisms as latent structured variables.\nBuilding on state-of-the-art baselines, we show improvements both in\nframe-semantic parsing and semantic dependency parsing by modeling them\njointly.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 00:14:32 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Peng", "Hao", ""], ["Thomson", "Sam", ""], ["Swayamdipta", "Swabha", ""], ["Smith", "Noah A.", ""]]}, {"id": "1804.06004", "submitter": "Katherine Keith", "authors": "Katherine A. Keith, Su Lin Blodgett, and Brendan O'Connor", "title": "Monte Carlo Syntax Marginals for Exploring and Using Dependency Parses", "comments": "To appear in Proceedings of NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dependency parsing research, which has made significant gains in recent\nyears, typically focuses on improving the accuracy of single-tree predictions.\nHowever, ambiguity is inherent to natural language syntax, and communicating\nsuch ambiguity is important for error analysis and better-informed downstream\napplications. In this work, we propose a transition sampling algorithm to\nsample from the full joint distribution of parse trees defined by a\ntransition-based parsing model, and demonstrate the use of the samples in\nprobabilistic dependency analysis. First, we define the new task of dependency\npath prediction, inferring syntactic substructures over part of a sentence, and\nprovide the first analysis of performance on this task. Second, we demonstrate\nthe usefulness of our Monte Carlo syntax marginal method for parser error\nanalysis and calibration. Finally, we use this method to propagate parse\nuncertainty to two downstream information extraction applications: identifying\npersons killed by police and semantic role assignment.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 01:22:41 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Keith", "Katherine A.", ""], ["Blodgett", "Su Lin", ""], ["O'Connor", "Brendan", ""]]}, {"id": "1804.06024", "submitter": "Manuel Mager", "authors": "Katharina Kann, Manuel Mager, Ivan Meza-Ruiz, Hinrich Sch\\\"utze", "title": "Fortification of Neural Morphological Segmentation Models for\n  Polysynthetic Minimal-Resource Languages", "comments": "Long Paper, 16th Annual Conference of the North American Chapter of\n  the Association for Computational Linguistics: Human Language Technologies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Morphological segmentation for polysynthetic languages is challenging,\nbecause a word may consist of many individual morphemes and training data can\nbe extremely scarce. Since neural sequence-to-sequence (seq2seq) models define\nthe state of the art for morphological segmentation in high-resource settings\nand for (mostly) European languages, we first show that they also obtain\ncompetitive performance for Mexican polysynthetic languages in minimal-resource\nsettings. We then propose two novel multi-task training approaches -one with,\none without need for external unlabeled resources-, and two corresponding data\naugmentation methods, improving over the neural baseline for all languages.\nFinally, we explore cross-lingual transfer as a third way to fortify our neural\nmodel and show that we can train one single multi-lingual model for related\nlanguages while maintaining comparable or even improved performance, thus\nreducing the amount of parameters by close to 75%. We provide our morphological\nsegmentation datasets for Mexicanero, Nahuatl, Wixarika and Yorem Nokki for\nfuture research.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 03:10:51 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Kann", "Katharina", ""], ["Mager", "Manuel", ""], ["Meza-Ruiz", "Ivan", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1804.06026", "submitter": "Varun Manjunatha", "authors": "Varun Manjunatha and Mohit Iyyer and Jordan Boyd-Graber and Larry\n  Davis", "title": "Learning to Color from Language", "comments": "6 pages", "journal-ref": "North American Chapter of the Association for Computational\n  Linguistics (NAACL), 2018", "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic colorization is the process of adding color to greyscale images. We\ncondition this process on language, allowing end users to manipulate a\ncolorized image by feeding in different captions. We present two different\narchitectures for language-conditioned colorization, both of which produce more\naccurate and plausible colorizations than a language-agnostic version. Through\nthis language-based framework, we can dramatically alter colorizations by\nmanipulating descriptive color words in captions.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 03:22:00 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Manjunatha", "Varun", ""], ["Iyyer", "Mohit", ""], ["Boyd-Graber", "Jordan", ""], ["Davis", "Larry", ""]]}, {"id": "1804.06028", "submitter": "Nikita Nangia", "authors": "Nikita Nangia and Samuel R. Bowman", "title": "ListOps: A Diagnostic Dataset for Latent Tree Learning", "comments": "8 pages, 4 figures, 3 tables, NAACL-SRW (2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent tree learning models learn to parse a sentence without syntactic\nsupervision, and use that parse to build the sentence representation. Existing\nwork on such models has shown that, while they perform well on tasks like\nsentence classification, they do not learn grammars that conform to any\nplausible semantic or syntactic formalism (Williams et al., 2018a). Studying\nthe parsing ability of such models in natural language can be challenging due\nto the inherent complexities of natural language, like having several valid\nparses for a single sentence. In this paper we introduce ListOps, a toy dataset\ncreated to study the parsing ability of latent tree models. ListOps sequences\nare in the style of prefix arithmetic. The dataset is designed to have a single\ncorrect parsing strategy that a system needs to learn to succeed at the task.\nWe show that the current leading latent tree models are unable to learn to\nparse and succeed at ListOps. These models achieve accuracies worse than purely\nsequential RNNs.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 03:26:28 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Nangia", "Nikita", ""], ["Bowman", "Samuel R.", ""]]}, {"id": "1804.06035", "submitter": "Jiawei Wu", "authors": "Jiawei Wu, Lei Li, William Yang Wang", "title": "Reinforced Co-Training", "comments": "11 pages, 3 figures. Accepted to NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Co-training is a popular semi-supervised learning framework to utilize a\nlarge amount of unlabeled data in addition to a small labeled set. Co-training\nmethods exploit predicted labels on the unlabeled data and select samples based\non prediction confidence to augment the training. However, the selection of\nsamples in existing co-training methods is based on a predetermined policy,\nwhich ignores the sampling bias between the unlabeled and the labeled subsets,\nand fails to explore the data space. In this paper, we propose a novel method,\nReinforced Co-Training, to select high-quality unlabeled samples to better\nco-train on. More specifically, our approach uses Q-learning to learn a data\nselection policy with a small labeled dataset, and then exploits this policy to\ntrain the co-training classifiers automatically. Experimental results on\nclickbait detection and generic text classification tasks demonstrate that our\nproposed method can obtain more accurate text classification results.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 03:41:55 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Wu", "Jiawei", ""], ["Li", "Lei", ""], ["Wang", "William Yang", ""]]}, {"id": "1804.06059", "submitter": "Mohit Iyyer", "authors": "Mohit Iyyer, John Wieting, Kevin Gimpel, Luke Zettlemoyer", "title": "Adversarial Example Generation with Syntactically Controlled Paraphrase\n  Networks", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose syntactically controlled paraphrase networks (SCPNs) and use them\nto generate adversarial examples. Given a sentence and a target syntactic form\n(e.g., a constituency parse), SCPNs are trained to produce a paraphrase of the\nsentence with the desired syntax. We show it is possible to create training\ndata for this task by first doing backtranslation at a very large scale, and\nthen using a parser to label the syntactic transformations that naturally occur\nduring this process. Such data allows us to train a neural encoder-decoder\nmodel with extra inputs to specify the target syntax. A combination of\nautomated and human evaluations show that SCPNs generate paraphrases that\nfollow their target specifications without decreasing paraphrase quality when\ncompared to baseline (uncontrolled) paraphrase systems. Furthermore, they are\nmore capable of generating syntactically adversarial examples that both (1)\n\"fool\" pretrained models and (2) improve the robustness of these models to\nsyntactic variation when used to augment their training data.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 06:12:36 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Iyyer", "Mohit", ""], ["Wieting", "John", ""], ["Gimpel", "Kevin", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1804.06137", "submitter": "Venkatesh Duppada", "authors": "Venkatesh Duppada, Royal Jain, Sushant Hiray", "title": "SeerNet at SemEval-2018 Task 1: Domain Adaptation for Affect in Tweets", "comments": "SemEval-2018 Task 1: Affect in Tweets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper describes the best performing system for the SemEval-2018 Affect in\nTweets (English) sub-tasks. The system focuses on the ordinal classification\nand regression sub-tasks for valence and emotion. For ordinal classification\nvalence is classified into 7 different classes ranging from -3 to 3 whereas\nemotion is classified into 4 different classes 0 to 3 separately for each\nemotion namely anger, fear, joy and sadness. The regression sub-tasks estimate\nthe intensity of valence and each emotion. The system performs domain\nadaptation of 4 different models and creates an ensemble to give the final\nprediction. The proposed system achieved 1st position out of 75 teams which\nparticipated in the fore-mentioned sub-tasks. We outperform the baseline model\nby margins ranging from 49.2% to 76.4%, thus, pushing the state-of-the-art\nsignificantly.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 09:50:01 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Duppada", "Venkatesh", ""], ["Jain", "Royal", ""], ["Hiray", "Sushant", ""]]}, {"id": "1804.06189", "submitter": "Alberto Poncelas", "authors": "Alberto Poncelas, Dimitar Shterionov, Andy Way, Gideon Maillette de\n  Buy Wenniger and Peyman Passban", "title": "Investigating Backtranslation in Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A prerequisite for training corpus-based machine translation (MT) systems --\neither Statistical MT (SMT) or Neural MT (NMT) -- is the availability of\nhigh-quality parallel data. This is arguably more important today than ever\nbefore, as NMT has been shown in many studies to outperform SMT, but mostly\nwhen large parallel corpora are available; in cases where data is limited, SMT\ncan still outperform NMT.\n  Recently researchers have shown that back-translating monolingual data can be\nused to create synthetic parallel corpora, which in turn can be used in\ncombination with authentic parallel data to train a high-quality NMT system.\nGiven that large collections of new parallel text become available only quite\nrarely, backtranslation has become the norm when building state-of-the-art NMT\nsystems, especially in resource-poor scenarios.\n  However, we assert that there are many unknown factors regarding the actual\neffects of back-translated data on the translation capabilities of an NMT\nmodel. Accordingly, in this work we investigate how using back-translated data\nas a training corpus -- both as a separate standalone dataset as well as\ncombined with human-generated parallel data -- affects the performance of an\nNMT model. We use incrementally larger amounts of back-translated data to train\na range of NMT systems for German-to-English, and analyse the resulting\ntranslation performance.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 12:16:25 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Poncelas", "Alberto", ""], ["Shterionov", "Dimitar", ""], ["Way", "Andy", ""], ["Wenniger", "Gideon Maillette de Buy", ""], ["Passban", "Peyman", ""]]}, {"id": "1804.06201", "submitter": "Herbert Hu", "authors": "Guangneng Hu, Yu Zhang, Qiang Yang", "title": "LCMR: Local and Centralized Memories for Collaborative Filtering with\n  Unstructured Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering (CF) is the key technique for recommender systems.\nPure CF approaches exploit the user-item interaction data (e.g., clicks, likes,\nand views) only and suffer from the sparsity issue. Items are usually\nassociated with content information such as unstructured text (e.g., abstracts\nof articles and reviews of products). CF can be extended to leverage text. In\nthis paper, we develop a unified neural framework to exploit interaction data\nand content information seamlessly. The proposed framework, called LCMR, is\nbased on memory networks and consists of local and centralized memories for\nexploiting content information and interaction data, respectively. By modeling\ncontent information as local memories, LCMR attentively learns what to exploit\nwith the guidance of user-item interaction. On real-world datasets, LCMR shows\nbetter performance by comparing with various baselines in terms of the hit\nratio and NDCG metrics. We further conduct analyses to understand how local and\ncentralized memories work for the proposed framework.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 12:32:23 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 16:23:00 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Hu", "Guangneng", ""], ["Zhang", "Yu", ""], ["Yang", "Qiang", ""]]}, {"id": "1804.06323", "submitter": "Ye Qi", "authors": "Ye Qi, Devendra Singh Sachan, Matthieu Felix, Sarguna Janani\n  Padmanabhan, Graham Neubig", "title": "When and Why are Pre-trained Word Embeddings Useful for Neural Machine\n  Translation?", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of Neural Machine Translation (NMT) systems often suffers in\nlow-resource scenarios where sufficiently large-scale parallel corpora cannot\nbe obtained. Pre-trained word embeddings have proven to be invaluable for\nimproving performance in natural language analysis tasks, which often suffer\nfrom paucity of data. However, their utility for NMT has not been extensively\nexplored. In this work, we perform five sets of experiments that analyze when\nwe can expect pre-trained word embeddings to help in NMT tasks. We show that\nsuch embeddings can be surprisingly effective in some cases -- providing gains\nof up to 20 BLEU points in the most favorable setting.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 15:34:07 GMT"}, {"version": "v2", "created": "Wed, 18 Apr 2018 07:03:57 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Qi", "Ye", ""], ["Sachan", "Devendra Singh", ""], ["Felix", "Matthieu", ""], ["Padmanabhan", "Sarguna Janani", ""], ["Neubig", "Graham", ""]]}, {"id": "1804.06333", "submitter": "Atish Pawar", "authors": "Atish Pawar, Vijay Mago", "title": "Similarity between Learning Outcomes from Course Objectives using\n  Semantic Analysis, Blooms taxonomy and Corpus statistics", "comments": "13 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The course description provided by instructors is an essential piece of\ninformation as it defines what is expected from the instructor and what he/she\nis going to deliver during a particular course. One of the key components of a\ncourse description is the Learning Objectives section. The contents of this\nsection are used by program managers who are tasked to compare and match two\ndifferent courses during the development of Transfer Agreements between various\ninstitutions. This research introduces the development of semantic similarity\nalgorithms to calculate the similarity between two learning objectives of the\nsame domain. We present a novel methodology which deals with the semantic\nsimilarity by using a previously established algorithm and integrating it with\nthe domain corpus utilizing domain statistics. The disambiguated domain serves\nas a supervised learning data for the algorithm. We also introduce Bloom Index\nto calculate the similarity between action verbs in the Learning Objectives\nreferring to the Blooms taxonomy.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 15:54:25 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Pawar", "Atish", ""], ["Mago", "Vijay", ""]]}, {"id": "1804.06385", "submitter": "Laura Perez-Beltrachini", "authors": "Laura Perez-Beltrachini and Mirella Lapata", "title": "Bootstrapping Generators from Noisy Data", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A core step in statistical data-to-text generation concerns learning\ncorrespondences between structured data representations (e.g., facts in a\ndatabase) and associated texts. In this paper we aim to bootstrap generators\nfrom large scale datasets where the data (e.g., DBPedia facts) and related\ntexts (e.g., Wikipedia abstracts) are loosely aligned. We tackle this\nchallenging task by introducing a special-purpose content selection mechanism.\nWe use multi-instance learning to automatically discover correspondences\nbetween data and text pairs and show how these can be used to enhance the\ncontent signal while training an encoder-decoder architecture. Experimental\nresults demonstrate that models trained with content-specific objectives\nimprove upon a vanilla encoder-decoder which solely relies on soft attention.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 17:30:02 GMT"}, {"version": "v2", "created": "Wed, 18 Apr 2018 16:55:37 GMT"}, {"version": "v3", "created": "Mon, 18 Mar 2019 10:10:26 GMT"}, {"version": "v4", "created": "Thu, 19 Dec 2019 17:43:59 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Perez-Beltrachini", "Laura", ""], ["Lapata", "Mirella", ""]]}, {"id": "1804.06437", "submitter": "He He", "authors": "Juncen Li and Robin Jia and He He and Percy Liang", "title": "Delete, Retrieve, Generate: A Simple Approach to Sentiment and Style\n  Transfer", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of text attribute transfer: transforming a sentence to\nalter a specific attribute (e.g., sentiment) while preserving its\nattribute-independent content (e.g., changing \"screen is just the right size\"\nto \"screen is too small\"). Our training data includes only sentences labeled\nwith their attribute (e.g., positive or negative), but not pairs of sentences\nthat differ only in their attributes, so we must learn to disentangle\nattributes from attribute-independent content in an unsupervised way. Previous\nwork using adversarial methods has struggled to produce high-quality outputs.\nIn this paper, we propose simpler methods motivated by the observation that\ntext attributes are often marked by distinctive phrases (e.g., \"too small\").\nOur strongest method extracts content words by deleting phrases associated with\nthe sentence's original attribute value, retrieves new phrases associated with\nthe target attribute, and uses a neural model to fluently combine these into a\nfinal output. On human evaluation, our best method generates grammatical and\nappropriate responses on 22% more inputs than the best previous system,\naveraged over three attribute transfer datasets: altering sentiment of reviews\non Yelp, altering sentiment of reviews on Amazon, and altering image captions\nto be more romantic or humorous.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 18:59:51 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Li", "Juncen", ""], ["Jia", "Robin", ""], ["He", "He", ""], ["Liang", "Percy", ""]]}, {"id": "1804.06439", "submitter": "Nicolas Fiorini", "authors": "Nicolas Fiorini, Zhiyong Lu", "title": "Personalized neural language models for real-world query auto completion", "comments": "To appear in NAACL-HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Query auto completion (QAC) systems are a standard part of search engines in\nindustry, helping users formulate their query. Such systems update their\nsuggestions after the user types each character, predicting the user's intent\nusing various signals - one of the most common being popularity. Recently, deep\nlearning approaches have been proposed for the QAC task, to specifically\naddress the main limitation of previous popularity-based methods: the inability\nto predict unseen queries. In this work we improve previous methods based on\nneural language modeling, with the goal of building an end-to-end system. We\nparticularly focus on using real-world data by integrating user information for\npersonalized suggestions when possible. We also make use of time information\nand study how to increase diversity in the suggestions while studying the\nimpact on scalability. Our empirical results demonstrate a marked improvement\non two separate datasets over previous best methods in both accuracy and\nscalability, making a step towards neural query auto-completion in production\nsearch engines.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 19:11:14 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2018 13:58:40 GMT"}, {"version": "v3", "created": "Wed, 9 May 2018 16:16:25 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Fiorini", "Nicolas", ""], ["Lu", "Zhiyong", ""]]}, {"id": "1804.06440", "submitter": "Sweta Karlekar", "authors": "Sweta Karlekar, Tong Niu, Mohit Bansal", "title": "Detecting Linguistic Characteristics of Alzheimer's Dementia by\n  Interpreting Neural Models", "comments": "NAACL 2018 (7 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alzheimer's disease (AD) is an irreversible and progressive brain disease\nthat can be stopped or slowed down with medical treatment. Language changes\nserve as a sign that a patient's cognitive functions have been impacted,\npotentially leading to early diagnosis. In this work, we use NLP techniques to\nclassify and analyze the linguistic characteristics of AD patients using the\nDementiaBank dataset. We apply three neural models based on CNNs, LSTM-RNNs,\nand their combination, to distinguish between language samples from AD and\ncontrol patients. We achieve a new independent benchmark accuracy for the AD\nclassification task. More importantly, we next interpret what these neural\nmodels have learned about the linguistic characteristics of AD patients, via\nanalysis based on activation clustering and first-derivative saliency\ntechniques. We then perform novel automatic pattern discovery inside activation\nclusters, and consolidate AD patients' distinctive grammar patterns.\nAdditionally, we show that first derivative saliency can not only rediscover\nprevious language patterns of AD patients, but also shed light on the\nlimitations of neural models. Lastly, we also include analysis of\ngender-separated AD data.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 19:17:05 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Karlekar", "Sweta", ""], ["Niu", "Tong", ""], ["Bansal", "Mohit", ""]]}, {"id": "1804.06451", "submitter": "Ramakanth Pasunuru", "authors": "Ramakanth Pasunuru, Mohit Bansal", "title": "Multi-Reward Reinforced Summarization with Saliency and Entailment", "comments": "NAACL 2018 (9 pages; added human evaluation and more analysis)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstractive text summarization is the task of compressing and rewriting a\nlong document into a short summary while maintaining saliency, directed logical\nentailment, and non-redundancy. In this work, we address these three important\naspects of a good summary via a reinforcement learning approach with two novel\nreward functions: ROUGESal and Entail, on top of a coverage-based baseline. The\nROUGESal reward modifies the ROUGE metric by up-weighting the salient\nphrases/words detected via a keyphrase classifier. The Entail reward gives high\n(length-normalized) scores to logically-entailed summaries using an entailment\nclassifier. Further, we show superior performance improvement when these\nrewards are combined with traditional metric (ROUGE) based rewards, via our\nnovel and effective multi-reward approach of optimizing multiple rewards\nsimultaneously in alternate mini-batches. Our method achieves the new\nstate-of-the-art results (including human evaluation) on the CNN/Daily Mail\ndataset as well as strong improvements in a test-only transfer setup on\nDUC-2002.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 19:39:26 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 14:45:28 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Pasunuru", "Ramakanth", ""], ["Bansal", "Mohit", ""]]}, {"id": "1804.06473", "submitter": "Yicheng Wang", "authors": "Yicheng Wang, Mohit Bansal", "title": "Robust Machine Comprehension Models via Adversarial Training", "comments": "NAACL 2018 (7 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is shown that many published models for the Stanford Question Answering\nDataset (Rajpurkar et al., 2016) lack robustness, suffering an over 50%\ndecrease in F1 score during adversarial evaluation based on the AddSent (Jia\nand Liang, 2017) algorithm. It has also been shown that retraining models on\ndata generated by AddSent has limited effect on their robustness. We propose a\nnovel alternative adversary-generation algorithm, AddSentDiverse, that\nsignificantly increases the variance within the adversarial training data by\nproviding effective examples that punish the model for making certain\nsuperficial assumptions. Further, in order to improve robustness to AddSent's\nsemantic perturbations (e.g., antonyms), we jointly improve the model's\nsemantic-relationship learning capabilities in addition to our\nAddSentDiverse-based adversarial training data augmentation. With these\nadditions, we show that we can make a state-of-the-art model significantly more\nrobust, achieving a 36.5% increase in F1 score under many different types of\nadversarial evaluation while maintaining performance on the regular SQuAD task.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 21:24:20 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Wang", "Yicheng", ""], ["Bansal", "Mohit", ""]]}, {"id": "1804.06506", "submitter": "Peyman Passban", "authors": "Peyman Passban, Qun Liu, Andy Way", "title": "Improving Character-based Decoding Using Target-Side Morphological\n  Information for Neural Machine Translation", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, neural machine translation (NMT) has emerged as a powerful\nalternative to conventional statistical approaches. However, its performance\ndrops considerably in the presence of morphologically rich languages (MRLs).\nNeural engines usually fail to tackle the large vocabulary and high\nout-of-vocabulary (OOV) word rate of MRLs. Therefore, it is not suitable to\nexploit existing word-based models to translate this set of languages. In this\npaper, we propose an extension to the state-of-the-art model of Chung et al.\n(2016), which works at the character level and boosts the decoder with\ntarget-side morphological information. In our architecture, an additional\nmorphology table is plugged into the model. Each time the decoder samples from\na target vocabulary, the table sends auxiliary signals from the most relevant\naffixes in order to enrich the decoder's current state and constrain it to\nprovide better predictions. We evaluated our model to translate English into\nGerman, Russian, and Turkish as three MRLs and observed significant\nimprovements.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 23:54:26 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Passban", "Peyman", ""], ["Liu", "Qun", ""], ["Way", "Andy", ""]]}, {"id": "1804.06512", "submitter": "Bing Liu", "authors": "Bing Liu, Gokhan Tur, Dilek Hakkani-Tur, Pararth Shah, Larry Heck", "title": "Dialogue Learning with Human Teaching and Feedback in End-to-End\n  Trainable Task-Oriented Dialogue Systems", "comments": "To appear in NAACL 2018 as a long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a hybrid learning method for training task-oriented\ndialogue systems through online user interactions. Popular methods for learning\ntask-oriented dialogues include applying reinforcement learning with user\nfeedback on supervised pre-training models. Efficiency of such learning method\nmay suffer from the mismatch of dialogue state distribution between offline\ntraining and online interactive learning stages. To address this challenge, we\npropose a hybrid imitation and reinforcement learning method, with which a\ndialogue agent can effectively learn from its interaction with users by\nlearning from human teaching and feedback. We design a neural network based\ntask-oriented dialogue agent that can be optimized end-to-end with the proposed\nlearning method. Experimental results show that our end-to-end dialogue agent\ncan learn effectively from the mistake it makes via imitation learning from\nuser teaching. Applying reinforcement learning with user feedback after the\nimitation learning stage further improves the agent's capability in\nsuccessfully completing a task.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 00:26:38 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Liu", "Bing", ""], ["Tur", "Gokhan", ""], ["Hakkani-Tur", "Dilek", ""], ["Shah", "Pararth", ""], ["Heck", "Larry", ""]]}, {"id": "1804.06517", "submitter": "Dominik Schlechtweg", "authors": "Dominik Schlechtweg, Sabine Schulte im Walde, Stefanie Eckmann", "title": "Diachronic Usage Relatedness (DURel): A Framework for the Annotation of\n  Lexical Semantic Change", "comments": "5 pages, NAACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a framework that extends synchronic polysemy annotation to\ndiachronic changes in lexical meaning, to counteract the lack of resources for\nevaluating computational models of lexical semantic change. Our framework\nexploits an intuitive notion of semantic relatedness, and distinguishes between\ninnovative and reductive meaning changes with high inter-annotator agreement.\nThe resulting test set for German comprises ratings from five annotators for\nthe relatedness of 1,320 use pairs across 22 target words.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 00:50:56 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Schlechtweg", "Dominik", ""], ["Walde", "Sabine Schulte im", ""], ["Eckmann", "Stefanie", ""]]}, {"id": "1804.06536", "submitter": "Binxuan Huang", "authors": "Binxuan Huang, Yanglan Ou, Kathleen M. Carley", "title": "Aspect Level Sentiment Classification with Attention-over-Attention\n  Neural Networks", "comments": "Accepted at SBP-BRiMS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-level sentiment classification aims to identify the sentiment\nexpressed towards some aspects given context sentences. In this paper, we\nintroduce an attention-over-attention (AOA) neural network for aspect level\nsentiment classification. Our approach models aspects and sentences in a joint\nway and explicitly captures the interaction between aspects and context\nsentences. With the AOA module, our model jointly learns the representations\nfor aspects and sentences, and automatically focuses on the important parts in\nsentences. Our experiments on laptop and restaurant datasets demonstrate our\napproach outperforms previous LSTM-based architectures.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 03:15:01 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Huang", "Binxuan", ""], ["Ou", "Yanglan", ""], ["Carley", "Kathleen M.", ""]]}, {"id": "1804.06609", "submitter": "Matt Post", "authors": "Matt Post and David Vilar", "title": "Fast Lexically Constrained Decoding with Dynamic Beam Allocation for\n  Neural Machine Translation", "comments": "11 pages, 9 figures, Proceedings of the 2018 Conference of the North\n  American Chapter of the Association for Computational Linguistics: Human\n  Language Technologies, Volume 1 (Long Papers)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The end-to-end nature of neural machine translation (NMT) removes many ways\nof manually guiding the translation process that were available in older\nparadigms. Recent work, however, has introduced a new capability: lexically\nconstrained or guided decoding, a modification to beam search that forces the\ninclusion of pre-specified words and phrases in the output. However, while\ntheoretically sound, existing approaches have computational complexities that\nare either linear (Hokamp and Liu, 2017) or exponential (Anderson et al., 2017)\nin the number of constraints. We present a algorithm for lexically constrained\ndecoding with a complexity of O(1) in the number of constraints. We demonstrate\nthe algorithms remarkable ability to properly place these constraints, and use\nit to explore the shaky relationship between model and BLEU scores. Our\nimplementation is available as part of Sockeye.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 09:06:11 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 21:40:15 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Post", "Matt", ""], ["Vilar", "David", ""]]}, {"id": "1804.06610", "submitter": "Jungo Kasai", "authors": "Jungo Kasai and Robert Frank and Pauli Xu and William Merrill and Owen\n  Rambow", "title": "End-to-end Graph-based TAG Parsing with Neural Networks", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a graph-based Tree Adjoining Grammar (TAG) parser that uses\nBiLSTMs, highway connections, and character-level CNNs. Our best end-to-end\nparser, which jointly performs supertagging, POS tagging, and parsing,\noutperforms the previously reported best results by more than 2.2 LAS and UAS\npoints. The graph-based parsing architecture allows for global inference and\nrich feature representations for TAG parsing, alleviating the fundamental\ntrade-off between transition-based and graph-based parsing systems. We also\ndemonstrate that the proposed parser achieves state-of-the-art performance in\nthe downstream tasks of Parsing Evaluation using Textual Entailments (PETE) and\nUnbounded Dependency Recovery. This provides further support for the claim that\nTAG is a viable formalism for problems that require rich structural analysis of\nsentences.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 09:07:16 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 01:14:19 GMT"}, {"version": "v3", "created": "Sat, 28 Apr 2018 03:42:45 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Kasai", "Jungo", ""], ["Frank", "Robert", ""], ["Xu", "Pauli", ""], ["Merrill", "William", ""], ["Rambow", "Owen", ""]]}, {"id": "1804.06636", "submitter": "Sowmya Vajjala", "authors": "Sowmya Vajjala and Taraka Rama", "title": "Experiments with Universal CEFR Classification", "comments": "to appear in the proceedings of The 13th Workshop on Innovative Use\n  of NLP for Building Educational Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Common European Framework of Reference (CEFR) guidelines describe\nlanguage proficiency of learners on a scale of 6 levels. While the description\nof CEFR guidelines is generic across languages, the development of automated\nproficiency classification systems for different languages follow different\napproaches. In this paper, we explore universal CEFR classification using\ndomain-specific and domain-agnostic, theory-guided as well as data-driven\nfeatures. We report the results of our preliminary experiments in monolingual,\ncross-lingual, and multilingual classification with three languages: German,\nCzech, and Italian. Our results show that both monolingual and multilingual\nmodels achieve similar performance, and cross-lingual classification yields\nlower, but comparable results to monolingual classification.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 10:33:47 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Vajjala", "Sowmya", ""], ["Rama", "Taraka", ""]]}, {"id": "1804.06657", "submitter": "Christos Baziotis", "authors": "Christos Baziotis, Nikos Athanasiou, Georgios Paraskevopoulos,\n  Nikolaos Ellinas, Athanasia Kolovou, Alexandros Potamianos", "title": "NTUA-SLP at SemEval-2018 Task 2: Predicting Emojis using RNNs with\n  Context-aware Attention", "comments": "SemEval-2018, Task 2 \"Multilingual Emoji Prediction\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a deep-learning model that competed at SemEval-2018\nTask 2 \"Multilingual Emoji Prediction\". We participated in subtask A, in which\nwe are called to predict the most likely associated emoji in English tweets.\nThe proposed architecture relies on a Long Short-Term Memory network, augmented\nwith an attention mechanism, that conditions the weight of each word, on a\n\"context vector\" which is taken as the aggregation of a tweet's meaning.\nMoreover, we initialize the embedding layer of our model, with word2vec word\nembeddings, pretrained on a dataset of 550 million English tweets. Finally, our\nmodel does not rely on hand-crafted features or lexicons and is trained\nend-to-end with back-propagation. We ranked 2nd out of 48 teams.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 11:30:57 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Baziotis", "Christos", ""], ["Athanasiou", "Nikos", ""], ["Paraskevopoulos", "Georgios", ""], ["Ellinas", "Nikolaos", ""], ["Kolovou", "Athanasia", ""], ["Potamianos", "Alexandros", ""]]}, {"id": "1804.06658", "submitter": "Christos Baziotis", "authors": "Christos Baziotis, Nikos Athanasiou, Alexandra Chronopoulou, Athanasia\n  Kolovou, Georgios Paraskevopoulos, Nikolaos Ellinas, Shrikanth Narayanan,\n  Alexandros Potamianos", "title": "NTUA-SLP at SemEval-2018 Task 1: Predicting Affective Content in Tweets\n  with Deep Attentive RNNs and Transfer Learning", "comments": "Semeval 2018, Task 1 \"Affect in Tweets\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present deep-learning models that submitted to the\nSemEval-2018 Task~1 competition: \"Affect in Tweets\". We participated in all\nsubtasks for English tweets. We propose a Bi-LSTM architecture equipped with a\nmulti-layer self attention mechanism. The attention mechanism improves the\nmodel performance and allows us to identify salient words in tweets, as well as\ngain insight into the models making them more interpretable. Our model utilizes\na set of word2vec word embeddings trained on a large collection of 550 million\nTwitter messages, augmented by a set of word affective features. Due to the\nlimited amount of task-specific training data, we opted for a transfer learning\napproach by pretraining the Bi-LSTMs on the dataset of Semeval 2017, Task 4A.\nThe proposed approach ranked 1st in Subtask E \"Multi-Label Emotion\nClassification\", 2nd in Subtask A \"Emotion Intensity Regression\" and achieved\ncompetitive results in other subtasks.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 11:31:06 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Baziotis", "Christos", ""], ["Athanasiou", "Nikos", ""], ["Chronopoulou", "Alexandra", ""], ["Kolovou", "Athanasia", ""], ["Paraskevopoulos", "Georgios", ""], ["Ellinas", "Nikolaos", ""], ["Narayanan", "Shrikanth", ""], ["Potamianos", "Alexandros", ""]]}, {"id": "1804.06659", "submitter": "Christos Baziotis", "authors": "Christos Baziotis, Nikos Athanasiou, Pinelopi Papalampidi, Athanasia\n  Kolovou, Georgios Paraskevopoulos, Nikolaos Ellinas, Alexandros Potamianos", "title": "NTUA-SLP at SemEval-2018 Task 3: Tracking Ironic Tweets using Ensembles\n  of Word and Character Level Attentive RNNs", "comments": "SemEval-2018, Task 3 \"Irony detection in English tweets\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present two deep-learning systems that competed at\nSemEval-2018 Task 3 \"Irony detection in English tweets\". We design and ensemble\ntwo independent models, based on recurrent neural networks (Bi-LSTM), which\noperate at the word and character level, in order to capture both the semantic\nand syntactic information in tweets. Our models are augmented with a\nself-attention mechanism, in order to identify the most informative words. The\nembedding layer of our word-level model is initialized with word2vec word\nembeddings, pretrained on a collection of 550 million English tweets. We did\nnot utilize any handcrafted features, lexicons or external datasets as prior\ninformation and our models are trained end-to-end using back propagation on\nconstrained data. Furthermore, we provide visualizations of tweets with\nannotations for the salient tokens of the attention layer that can help to\ninterpret the inner workings of the proposed models. We ranked 2nd out of 42\nteams in Subtask A and 2nd out of 31 teams in Subtask B. However,\npost-task-completion enhancements of our models achieve state-of-the-art\nresults ranking 1st for both subtasks.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 11:35:56 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Baziotis", "Christos", ""], ["Athanasiou", "Nikos", ""], ["Papalampidi", "Pinelopi", ""], ["Kolovou", "Athanasia", ""], ["Paraskevopoulos", "Georgios", ""], ["Ellinas", "Nikolaos", ""], ["Potamianos", "Alexandros", ""]]}, {"id": "1804.06705", "submitter": "Jan Pichl", "authors": "Jan Pichl, Petr Marek, Jakub Konr\\'ad, Martin Matul\\'ik, Hoang Long\n  Nguyen and Jan \\v{S}ediv\\'y", "title": "Alquist: The Alexa Prize Socialbot", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new open domain dialogue system Alquist developed as\npart of the Alexa Prize competition for the Amazon Echo line of products. The\nAlquist dialogue system is designed to conduct a coherent and engaging\nconversation on popular topics. We are presenting a hybrid system combining\nseveral machine learning and rule based approaches. We discuss and describe the\nAlquist pipeline, data acquisition, and processing, dialogue manager, NLG,\nknowledge aggregation and hierarchy of sub-dialogs. We present some of the\nexperimental results.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 13:22:06 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Pichl", "Jan", ""], ["Marek", "Petr", ""], ["Konr\u00e1d", "Jakub", ""], ["Matul\u00edk", "Martin", ""], ["Nguyen", "Hoang Long", ""], ["\u0160ediv\u00fd", "Jan", ""]]}, {"id": "1804.06716", "submitter": "Atul Kr. Ojha Mr.", "authors": "Rajneesh Pandey, Atul Kr. Ojha, Girish Nath Jha", "title": "Demo of Sanskrit-Hindi SMT System", "comments": "Proceedings of the 4th Workshop on Indian Language Data: Resources\n  and Evaluation (under the 11th LREC2018, May 07-12, 2018)", "journal-ref": "http://lrec-conf.org/workshops/lrec2018/W11/summaries/20_W11.html", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The demo proposal presents a Phrase-based Sanskrit-Hindi (SaHiT) Statistical\nMachine Translation system. The system has been developed on Moses. 43k\nsentences of Sanskrit-Hindi parallel corpus and 56k sentences of a monolingual\ncorpus in the target language (Hindi) have been used. This system gives 57 BLEU\nscore.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 19:44:56 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Pandey", "Rajneesh", ""], ["Ojha", "Atul Kr.", ""], ["Jha", "Girish Nath", ""]]}, {"id": "1804.06719", "submitter": "Dominik Schlechtweg", "authors": "Dominik Schlechtweg, Sabine Schulte im Walde", "title": "Distribution-based Prediction of the Degree of Grammaticalization for\n  German Prepositions", "comments": "2 pages, EvoLang", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We test the hypothesis that the degree of grammaticalization of German\nprepositions correlates with their corpus-based contextual dispersion measured\nby word entropy. We find that there is indeed a moderate correlation for\nentropy, but a stronger correlation for frequency and number of context types.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 18:19:38 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Schlechtweg", "Dominik", ""], ["Walde", "Sabine Schulte im", ""]]}, {"id": "1804.06759", "submitter": "Libby Hemphill", "authors": "Ping Liu, Joshua Guberman, Libby Hemphill, Aron Culotta", "title": "Forecasting the presence and intensity of hostility on Instagram using\n  linguistic and social features", "comments": "ICWSM'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Online antisocial behavior, such as cyberbullying, harassment, and trolling,\nis a widespread problem that threatens free discussion and has negative\nphysical and mental health consequences for victims and communities. While\nprior work has proposed automated methods to identify hostile comments in\nonline discussions, these methods work retrospectively on comments that have\nalready been posted, making it difficult to intervene before an interaction\nescalates. In this paper we instead consider the problem of forecasting future\nhostilities in online discussions, which we decompose into two tasks: (1) given\nan initial sequence of non-hostile comments in a discussion, predict whether\nsome future comment will contain hostility; and (2) given the first hostile\ncomment in a discussion, predict whether this will lead to an escalation of\nhostility in subsequent comments. Thus, we aim to forecast both the presence\nand intensity of hostile comments based on linguistic and social features from\nearlier comments. To evaluate our approach, we introduce a corpus of over 30K\nannotated Instagram comments from over 1,100 posts. Our approach is able to\npredict the appearance of a hostile comment on an Instagram post ten or more\nhours in the future with an AUC of .82 (task 1), and can furthermore\ndistinguish between high and low levels of future hostility with an AUC of .91\n(task 2).\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 14:32:34 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Liu", "Ping", ""], ["Guberman", "Joshua", ""], ["Hemphill", "Libby", ""], ["Culotta", "Aron", ""]]}, {"id": "1804.06775", "submitter": "Benjamin Milde", "authors": "Benjamin Milde, Chris Biemann", "title": "Unspeech: Unsupervised Speech Context Embeddings", "comments": "Accepted at Interspeech 2018, Hyderabad, India. This version matches\n  the final version submitted to the conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce \"Unspeech\" embeddings, which are based on unsupervised learning\nof context feature representations for spoken language. The embeddings were\ntrained on up to 9500 hours of crawled English speech data without\ntranscriptions or speaker information, by using a straightforward learning\nobjective based on context and non-context discrimination with negative\nsampling. We use a Siamese convolutional neural network architecture to train\nUnspeech embeddings and evaluate them on speaker comparison, utterance\nclustering and as a context feature in TDNN-HMM acoustic models trained on\nTED-LIUM, comparing it to i-vector baselines. Particularly decoding\nout-of-domain speech data from the recently released Common Voice corpus shows\nconsistent WER reductions. We release our source code and pre-trained Unspeech\nmodels under a permissive open source license.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 15:02:10 GMT"}, {"version": "v2", "created": "Thu, 23 Aug 2018 10:33:44 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Milde", "Benjamin", ""], ["Biemann", "Chris", ""]]}, {"id": "1804.06786", "submitter": "Jack Hessel", "authors": "Jack Hessel, David Mimno, Lillian Lee", "title": "Quantifying the visual concreteness of words and topics in multimodal\n  datasets", "comments": "NAACL HLT 2018, 14 pages, 6 figures, data available at\n  http://www.cs.cornell.edu/~jhessel/concreteness/concreteness.html", "journal-ref": "2018 North American Chapter of the Association for Computational\n  Linguistics: Human Language Technologies (NAACL HLT)", "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal machine learning algorithms aim to learn visual-textual\ncorrespondences. Previous work suggests that concepts with concrete visual\nmanifestations may be easier to learn than concepts with abstract ones. We give\nan algorithm for automatically computing the visual concreteness of words and\ntopics within multimodal datasets. We apply the approach in four settings,\nranging from image captions to images/text scraped from historical books. In\naddition to enabling explorations of concepts in multimodal datasets, our\nconcreteness scores predict the capacity of machine learning algorithms to\nlearn textual/visual relationships. We find that 1) concrete concepts are\nindeed easier to learn; 2) the large number of algorithms we consider have\nsimilar failure cases; 3) the precise positive relationship between\nconcreteness and performance varies between datasets. We conclude with\nrecommendations for using concreteness scores to facilitate future multimodal\nresearch.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 15:23:04 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 19:15:45 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Hessel", "Jack", ""], ["Mimno", "David", ""], ["Lee", "Lillian", ""]]}, {"id": "1804.06868", "submitter": "Alane Suhr", "authors": "Alane Suhr, Srinivasan Iyer, Yoav Artzi", "title": "Learning to Map Context-Dependent Sentences to Executable Formal Queries", "comments": "NAACL-HLT 2018 Long Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a context-dependent model to map utterances within an interaction\nto executable formal queries. To incorporate interaction history, the model\nmaintains an interaction-level encoder that updates after each turn, and can\ncopy sub-sequences of previously predicted queries during generation. Our\napproach combines implicit and explicit modeling of references between\nutterances. We evaluate our model on the ATIS flight planning interactions, and\ndemonstrate the benefits of modeling context and explicit references.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 18:34:46 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2018 20:44:42 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Suhr", "Alane", ""], ["Iyer", "Srinivasan", ""], ["Artzi", "Yoav", ""]]}, {"id": "1804.06870", "submitter": "Hao Tan", "authors": "Hao Tan, Mohit Bansal", "title": "Object Ordering with Bidirectional Matchings for Visual Reasoning", "comments": "NAACL 2018 (8 pages; added pointer-ordering examples)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual reasoning with compositional natural language instructions, e.g.,\nbased on the newly-released Cornell Natural Language Visual Reasoning (NLVR)\ndataset, is a challenging task, where the model needs to have the ability to\ncreate an accurate mapping between the diverse phrases and the several objects\nplaced in complex arrangements in the image. Further, this mapping needs to be\nprocessed to answer the question in the statement given the ordering and\nrelationship of the objects across three similar images. In this paper, we\npropose a novel end-to-end neural model for the NLVR task, where we first use\njoint bidirectional attention to build a two-way conditioning between the\nvisual information and the language phrases. Next, we use an RL-based pointer\nnetwork to sort and process the varying number of unordered objects (so as to\nmatch the order of the statement phrases) in each of the three images and then\npool over the three decisions. Our model achieves strong improvements (of 4-6%\nabsolute) over the state-of-the-art on both the structured representation and\nraw image versions of the dataset.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 18:39:17 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 16:56:32 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Tan", "Hao", ""], ["Bansal", "Mohit", ""]]}, {"id": "1804.06876", "submitter": "Mark Yatskar", "authors": "Jieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, Kai-Wei Chang", "title": "Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods", "comments": "NAACL '18 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new benchmark, WinoBias, for coreference resolution focused on\ngender bias. Our corpus contains Winograd-schema style sentences with entities\ncorresponding to people referred by their occupation (e.g. the nurse, the\ndoctor, the carpenter). We demonstrate that a rule-based, a feature-rich, and a\nneural coreference system all link gendered pronouns to pro-stereotypical\nentities with higher accuracy than anti-stereotypical entities, by an average\ndifference of 21.1 in F1 score. Finally, we demonstrate a data-augmentation\napproach that, in combination with existing word-embedding debiasing\ntechniques, removes the bias demonstrated by these systems in WinoBias without\nsignificantly affecting their performance on existing coreference benchmark\ndatasets. Our dataset and code are available at http://winobias.org.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 18:51:00 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Zhao", "Jieyu", ""], ["Wang", "Tianlu", ""], ["Yatskar", "Mark", ""], ["Ordonez", "Vicente", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "1804.06898", "submitter": "Youmna Farag", "authors": "Youmna Farag, Helen Yannakoudakis, Ted Briscoe", "title": "Neural Automated Essay Scoring and Coherence Modeling for Adversarially\n  Crafted Input", "comments": "9, NAACL 2018", "journal-ref": "The 16th Annual Conference of the North American Chapter of the\n  Association for Computational Linguistics (NAACL 2018)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that current state-of-the-art approaches to Automated Essay\nScoring (AES) are not well-suited to capturing adversarially crafted input of\ngrammatical but incoherent sequences of sentences. We develop a neural model of\nlocal coherence that can effectively learn connectedness features between\nsentences, and propose a framework for integrating and jointly training the\nlocal coherence model with a state-of-the-art AES model. We evaluate our\napproach against a number of baselines and experimentally demonstrate its\neffectiveness on both the AES task and the task of flagging adversarial input,\nfurther contributing to the development of an approach that strengthens the\nvalidity of neural essay scoring models.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 19:55:18 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 00:27:43 GMT"}, {"version": "v3", "created": "Thu, 30 Apr 2020 17:28:02 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Farag", "Youmna", ""], ["Yannakoudakis", "Helen", ""], ["Briscoe", "Ted", ""]]}, {"id": "1804.06922", "submitter": "Sebastian Schuster", "authors": "Sebastian Schuster, Joakim Nivre, Christopher D. Manning", "title": "Sentences with Gapping: Parsing and Reconstructing Elided Predicates", "comments": "To be presented at NAACL 2018", "journal-ref": "Proceedings of the 16th Annual Conference of the North American\n  Chapter of the Association for Computational Linguistics: Human Language\n  Technologies (NAACL 2018)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentences with gapping, such as Paul likes coffee and Mary tea, lack an overt\npredicate to indicate the relation between two or more arguments. Surface\nsyntax representations of such sentences are often produced poorly by parsers,\nand even if correct, not well suited to downstream natural language\nunderstanding tasks such as relation extraction that are typically designed to\nextract information from sentences with canonical clause structure. In this\npaper, we present two methods for parsing to a Universal Dependencies graph\nrepresentation that explicitly encodes the elided material with additional\nnodes and edges. We find that both methods can reconstruct elided material from\ndependency trees with high accuracy when the parser correctly predicts the\nexistence of a gap. We further demonstrate that one of our methods can be\napplied to other languages based on a case study on Swedish.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 21:32:17 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Schuster", "Sebastian", ""], ["Nivre", "Joakim", ""], ["Manning", "Christopher D.", ""]]}, {"id": "1804.06987", "submitter": "Jat Sharmistha", "authors": "Sharmistha Jat, Siddhesh Khandelwal, Partha Talukdar", "title": "Improving Distantly Supervised Relation Extraction using Word and Entity\n  Based Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Relation extraction is the problem of classifying the relationship between\ntwo entities in a given sentence. Distant Supervision (DS) is a popular\ntechnique for developing relation extractors starting with limited supervision.\nWe note that most of the sentences in the distant supervision relation\nextraction setting are very long and may benefit from word attention for better\nsentence representation. Our contributions in this paper are threefold.\nFirstly, we propose two novel word attention models for distantly- supervised\nrelation extraction: (1) a Bi-directional Gated Recurrent Unit (Bi-GRU) based\nword attention model (BGWA), (2) an entity-centric attention model (EA), and\n(3) a combination model which combines multiple complementary models using\nweighted voting method for improved relation extraction. Secondly, we introduce\nGDS, a new distant supervision dataset for relation extraction. GDS removes\ntest data noise present in all previous distant- supervision benchmark\ndatasets, making credible automatic evaluation possible. Thirdly, through\nextensive experiments on multiple real-world datasets, we demonstrate the\neffectiveness of the proposed methods.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 03:38:43 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Jat", "Sharmistha", ""], ["Khandelwal", "Siddhesh", ""], ["Talukdar", "Partha", ""]]}, {"id": "1804.07000", "submitter": "Marcel Trotzek", "authors": "Marcel Trotzek, Sven Koitka, Christoph M. Friedrich", "title": "Utilizing Neural Networks and Linguistic Metadata for Early Detection of\n  Depression Indications in Text Sequences", "comments": "This work has been submitted to the IEEE and has been accepted for\n  future publication in IEEE Transactions on Knowledge and Data Engineering.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible. 14 pages, 3 figures, 7 tables", "journal-ref": null, "doi": "10.1109/TKDE.2018.2885515", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depression is ranked as the largest contributor to global disability and is\nalso a major reason for suicide. Still, many individuals suffering from forms\nof depression are not treated for various reasons. Previous studies have shown\nthat depression also has an effect on language usage and that many depressed\nindividuals use social media platforms or the internet in general to get\ninformation or discuss their problems. This paper addresses the early detection\nof depression using machine learning models based on messages on a social\nplatform. In particular, a convolutional neural network based on different word\nembeddings is evaluated and compared to a classification based on user-level\nlinguistic metadata. An ensemble of both approaches is shown to achieve\nstate-of-the-art results in a current early detection task. Furthermore, the\ncurrently popular ERDE score as metric for early detection systems is examined\nin detail and its drawbacks in the context of shared tasks are illustrated. A\nslightly modified metric is proposed and compared to the original score.\nFinally, a new word embedding was trained on a large corpus of the same domain\nas the described task and is evaluated as well.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 05:25:51 GMT"}, {"version": "v2", "created": "Sun, 25 Nov 2018 12:44:50 GMT"}, {"version": "v3", "created": "Fri, 21 Dec 2018 08:15:23 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Trotzek", "Marcel", ""], ["Koitka", "Sven", ""], ["Friedrich", "Christoph M.", ""]]}, {"id": "1804.07007", "submitter": "Yi Liao", "authors": "Yi Liao, Lidong Bing, Piji Li, Shuming Shi, Wai Lam, Tong Zhang", "title": "QuaSE: Accurate Text Style Transfer under Quantifiable Guidance", "comments": "accepted by emnlp2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the task of Quantifiable Sequence Editing (QuaSE): editing an\ninput sequence to generate an output sequence that satisfies a given numerical\noutcome value measuring a certain property of the sequence, with the\nrequirement of keeping the main content of the input sequence. For example, an\ninput sequence could be a word sequence, such as review sentence and\nadvertisement text. For a review sentence, the outcome could be the review\nrating; for an advertisement, the outcome could be the click-through rate. The\nmajor challenge in performing QuaSE is how to perceive the outcome-related\nwordings, and only edit them to change the outcome. In this paper, the proposed\nframework contains two latent factors, namely, outcome factor and content\nfactor, disentangled from the input sentence to allow convenient editing to\nchange the outcome and keep the content. Our framework explores the\npseudo-parallel sentences by modeling their content similarity and outcome\ndifferences to enable a better disentanglement of the latent factors, which\nallows generating an output to better satisfy the desired outcome and keep the\ncontent. The dual reconstruction structure further enhances the capability of\ngenerating expected output by exploiting the couplings of latent factors of\npseudo-parallel sentences. For evaluation, we prepared a dataset of Yelp review\nsentences with the ratings as outcome. Extensive experimental results are\nreported and discussed to elaborate the peculiarities of our framework.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 06:13:48 GMT"}, {"version": "v2", "created": "Fri, 31 Aug 2018 08:34:42 GMT"}, {"version": "v3", "created": "Wed, 30 Jan 2019 05:14:32 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Liao", "Yi", ""], ["Bing", "Lidong", ""], ["Li", "Piji", ""], ["Shi", "Shuming", ""], ["Lam", "Wai", ""], ["Zhang", "Tong", ""]]}, {"id": "1804.07036", "submitter": "Yuxiang Wu", "authors": "Yuxiang Wu, Baotian Hu", "title": "Learning to Extract Coherent Summary via Deep Reinforcement Learning", "comments": "8 pages, 1 figure, presented at AAAI-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coherence plays a critical role in producing a high-quality summary from a\ndocument. In recent years, neural extractive summarization is becoming\nincreasingly attractive. However, most of them ignore the coherence of\nsummaries when extracting sentences. As an effort towards extracting coherent\nsummaries, we propose a neural coherence model to capture the cross-sentence\nsemantic and syntactic coherence patterns. The proposed neural coherence model\nobviates the need for feature engineering and can be trained in an end-to-end\nfashion using unlabeled data. Empirical results show that the proposed neural\ncoherence model can efficiently capture the cross-sentence coherence patterns.\nUsing the combined output of the neural coherence model and ROUGE package as\nthe reward, we design a reinforcement learning method to train a proposed\nneural extractive summarizer which is named Reinforced Neural Extractive\nSummarization (RNES) model. The RNES model learns to optimize coherence and\ninformative importance of the summary simultaneously. Experimental results show\nthat the proposed RNES outperforms existing baselines and achieves\nstate-of-the-art performance in term of ROUGE on CNN/Daily Mail dataset. The\nqualitative evaluation indicates that summaries produced by RNES are more\ncoherent and readable.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 08:42:32 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Wu", "Yuxiang", ""], ["Hu", "Baotian", ""]]}, {"id": "1804.07068", "submitter": "Masashi Yoshikawa", "authors": "Masashi Yoshikawa, Koji Mineshima, Hiroshi Noji and Daisuke Bekki", "title": "Consistent CCG Parsing over Multiple Sentences for Improved Logical\n  Reasoning", "comments": "6 pages. short paper accepted to NAACL2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In formal logic-based approaches to Recognizing Textual Entailment (RTE), a\nCombinatory Categorial Grammar (CCG) parser is used to parse input premises and\nhypotheses to obtain their logical formulas. Here, it is important that the\nparser processes the sentences consistently; failing to recognize a similar\nsyntactic structure results in inconsistent predicate argument structures among\nthem, in which case the succeeding theorem proving is doomed to failure. In\nthis work, we present a simple method to extend an existing CCG parser to parse\na set of sentences consistently, which is achieved with an inter-sentence\nmodeling with Markov Random Fields (MRF). When combined with existing\nlogic-based systems, our method always shows improvement in the RTE experiments\non English and Japanese languages.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 10:17:47 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Yoshikawa", "Masashi", ""], ["Mineshima", "Koji", ""], ["Noji", "Hiroshi", ""], ["Bekki", "Daisuke", ""]]}, {"id": "1804.07097", "submitter": "Bernhard Kratzwald", "authors": "Bernhard Kratzwald and Stefan Feuerriegel", "title": "Putting Question-Answering Systems into Practice: Transfer Learning for\n  Efficient Domain Customization", "comments": "Accepted by ACM TMIS", "journal-ref": null, "doi": "10.1145/3309706", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional information retrieval (such as that offered by web search\nengines) impedes users with information overload from extensive result pages\nand the need to manually locate the desired information therein. Conversely,\nquestion-answering systems change how humans interact with information systems:\nusers can now ask specific questions and obtain a tailored answer - both\nconveniently in natural language. Despite obvious benefits, their use is often\nlimited to an academic context, largely because of expensive domain\ncustomizations, which means that the performance in domain-specific\napplications often fails to meet expectations. This paper proposes\ncost-efficient remedies: (i) we leverage metadata through a filtering\nmechanism, which increases the precision of document retrieval, and (ii) we\ndevelop a novel fuse-and-oversample approach for transfer learning in order to\nimprove the performance of answer extraction. Here knowledge is inductively\ntransferred from a related, yet different, tasks to the domain-specific\napplication, while accounting for potential differences in the sample sizes\nacross both tasks. The resulting performance is demonstrated with actual use\ncases from a finance company and the film industry, where fewer than 400\nquestion-answer pairs had to be annotated in order to yield significant\nperformance gains. As a direct implication to management, this presents a\npromising path to better leveraging of knowledge stored in information systems.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 11:40:08 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2019 00:57:05 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Kratzwald", "Bernhard", ""], ["Feuerriegel", "Stefan", ""]]}, {"id": "1804.07212", "submitter": "Sarthak Jain", "authors": "Sarthak Jain, Edward Banner, Jan-Willem van de Meent, Iain J.\n  Marshall, Byron C. Wallace", "title": "Learning Disentangled Representations of Texts with Application to\n  Biomedical Abstracts", "comments": "Accepted to EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for learning disentangled representations of texts that\ncode for distinct and complementary aspects, with the aim of affording\nefficient model transfer and interpretability. To induce disentangled\nembeddings, we propose an adversarial objective based on the (dis)similarity\nbetween triplets of documents with respect to specific aspects. Our motivating\napplication is embedding biomedical abstracts describing clinical trials in a\nmanner that disentangles the populations, interventions, and outcomes in a\ngiven trial. We show that our method learns representations that encode these\nclinically salient aspects, and that these can be effectively used to perform\naspect-specific retrieval. We demonstrate that the approach generalizes beyond\nour motivating application in experiments on two multi-aspect review corpora.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 15:09:14 GMT"}, {"version": "v2", "created": "Mon, 3 Sep 2018 19:19:39 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Jain", "Sarthak", ""], ["Banner", "Edward", ""], ["van de Meent", "Jan-Willem", ""], ["Marshall", "Iain J.", ""], ["Wallace", "Byron C.", ""]]}, {"id": "1804.07247", "submitter": "Dominic Seyler", "authors": "Dominic Seyler, Lunan Li, ChengXiang Zhai", "title": "Semantic Text Analysis for Detection of Compromised Accounts on Social\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compromised accounts on social networks are regular user accounts that have\nbeen taken over by an entity with malicious intent. Since the adversary\nexploits the already established trust of a compromised account, it is crucial\nto detect these accounts to limit the damage they can cause. We propose a novel\ngeneral framework for semantic analysis of text messages coming out from an\naccount to detect compromised accounts. Our framework is built on the\nobservation that normal users will use language that is measurably different\nfrom the language that an adversary would use when the account is compromised.\nWe propose to use the difference of language models of users and adversaries to\ndefine novel interpretable semantic features for measuring semantic incoherence\nin a message stream. We study the effectiveness of the proposed semantic\nfeatures using a Twitter data set. Evaluation results show that the proposed\nframework is effective for discovering compromised accounts on social networks\nand a KL-divergence-based language model feature works best.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 16:06:29 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 18:06:25 GMT"}, {"version": "v3", "created": "Wed, 6 May 2020 21:26:02 GMT"}, {"version": "v4", "created": "Fri, 23 Oct 2020 15:56:27 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Seyler", "Dominic", ""], ["Li", "Lunan", ""], ["Zhai", "ChengXiang", ""]]}, {"id": "1804.07253", "submitter": "Luca Soldaini", "authors": "Luca Soldaini, Timothy Walsh, Arman Cohan, Julien Han, Nazli Goharian", "title": "Helping or Hurting? Predicting Changes in Users' Risk of Self-Harm\n  Through Online Community Interactions", "comments": "10 pages, 4 figures, 5 tables, accepted for publication at the\n  CLPsych workshop at NAACL-HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, online communities have formed around suicide and self-harm\nprevention. While these communities offer support in moment of crisis, they can\nalso normalize harmful behavior, discourage professional treatment, and\ninstigate suicidal ideation. In this work, we focus on how interaction with\nothers in such a community affects the mental state of users who are seeking\nsupport. We first build a dataset of conversation threads between users in a\ndistressed state and community members offering support. We then show how to\nconstruct a classifier to predict whether distressed users are helped or harmed\nby the interactions in the thread, and we achieve a macro-F1 score of up to\n0.69.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 16:18:51 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Soldaini", "Luca", ""], ["Walsh", "Timothy", ""], ["Cohan", "Arman", ""], ["Han", "Julien", ""], ["Goharian", "Nazli", ""]]}, {"id": "1804.07329", "submitter": "Yevgeni Berzak", "authors": "Yevgeni Berzak, Boris Katz, Roger Levy", "title": "Assessing Language Proficiency from Eye Movements in Reading", "comments": "NAACL 2018 (license change to CC BY)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel approach for determining learners' second language\nproficiency which utilizes behavioral traces of eye movements during reading.\nOur approach provides stand-alone eyetracking based English proficiency scores\nwhich reflect the extent to which the learner's gaze patterns in reading are\nsimilar to those of native English speakers. We show that our scores correlate\nstrongly with standardized English proficiency tests. We also demonstrate that\ngaze information can be used to accurately predict the outcomes of such tests.\nOur approach yields the strongest performance when the test taker is presented\nwith a suite of sentences for which we have eyetracking data from other\nreaders. However, it remains effective even using eyetracking with sentences\nfor which eye movement data have not been previously collected. By deriving\nproficiency as an automatic byproduct of eye movements during ordinary reading,\nour approach offers a potentially valuable new tool for second language\nproficiency assessment. More broadly, our results open the door to future\nmethods for inferring reader characteristics from the behavioral traces of\nreading.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 18:32:11 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 00:26:44 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Berzak", "Yevgeni", ""], ["Katz", "Boris", ""], ["Levy", "Roger", ""]]}, {"id": "1804.07331", "submitter": "Murali Raghu Babu Balusu", "authors": "Murali Raghu Babu Balusu and Taha Merghani and Jacob Eisenstein", "title": "Stylistic Variation in Social Media Part-of-Speech Tagging", "comments": "9 pages, Published in Proceedings of NAACL workshop on stylistic\n  variation (2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media features substantial stylistic variation, raising new challenges\nfor syntactic analysis of online writing. However, this variation is often\naligned with author attributes such as age, gender, and geography, as well as\nmore readily-available social network metadata. In this paper, we report new\nevidence on the link between language and social networks in the task of\npart-of-speech tagging. We find that tagger error rates are correlated with\nnetwork structure, with high accuracy in some parts of the network, and lower\naccuracy elsewhere. As a result, tagger accuracy depends on training from a\nbalanced sample of the network, rather than training on texts from a narrow\nsubcommunity. We also describe our attempts to add robustness to stylistic\nvariation, by building a mixture-of-experts model in which each expert is\nassociated with a region of the social network. While prior work found that\nsimilar approaches yield performance improvements in sentiment analysis and\nentity linking, we were unable to obtain performance improvements in\npart-of-speech tagging, despite strong evidence for the link between\npart-of-speech error rates and social network structure.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 18:37:40 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Balusu", "Murali Raghu Babu", ""], ["Merghani", "Taha", ""], ["Eisenstein", "Jacob", ""]]}, {"id": "1804.07375", "submitter": "Amir Zeldes", "authors": "Amir Zeldes", "title": "A Predictive Model for Notional Anaphora in English", "comments": "NAACL 2018 Workshop on Computational Models of Reference, Anaphora,\n  and Coreference (CRAC). New Orleans, LA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Notional anaphors are pronouns which disagree with their antecedents'\ngrammatical categories for notional reasons, such as plural to singular\nagreement in: 'the government ... they'. Since such cases are rare and conflict\nwith evidence from strictly agreeing cases ('the government ... it'), they\npresent a substantial challenge to both coreference resolution and referring\nexpression generation. Using the OntoNotes corpus, this paper takes an ensemble\napproach to predicting English notional anaphora in context on the basis of the\nlargest empirical data to date. In addition to state of the art prediction\naccuracy, the results suggest that theoretical approaches positing a plural\nconstrual at the antecedent's utterance are insufficient, and that\ncircumstances at the anaphor's utterance location, as well as global factors\nsuch as genre, have a strong effect on the choice of referring expression.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 20:48:53 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Zeldes", "Amir", ""]]}, {"id": "1804.07399", "submitter": "Shubham Dash", "authors": "Akash Ganesan, Divyansh Pal, Karthik Muthuraman, Shubham Dash", "title": "Video based Contextual Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The primary aim of this project is to build a contextual Question-Answering\nmodel for videos. The current methodologies provide a robust model for image\nbased Question-Answering, but we are aim to generalize this approach to be\nvideos. We propose a graphical representation of video which is able to handle\nseveral types of queries across the whole video. For example, if a frame has an\nimage of a man and a cat sitting, it should be able to handle queries like,\nwhere is the cat sitting with respect to the man? or ,what is the man holding\nin his hand?. It should be able to answer queries relating to temporal\nrelationships also.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 23:06:00 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Ganesan", "Akash", ""], ["Pal", "Divyansh", ""], ["Muthuraman", "Karthik", ""], ["Dash", "Shubham", ""]]}, {"id": "1804.07445", "submitter": "Tu Vu", "authors": "Tu Vu, Baotian Hu, Tsendsuren Munkhdalai and Hong Yu", "title": "Sentence Simplification with Memory-Augmented Neural Networks", "comments": "Accepted as a conference paper at NAACL HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence simplification aims to simplify the content and structure of complex\nsentences, and thus make them easier to interpret for human readers, and easier\nto process for downstream NLP applications. Recent advances in neural machine\ntranslation have paved the way for novel approaches to the task. In this paper,\nwe adapt an architecture with augmented memory capacities called Neural\nSemantic Encoders (Munkhdalai and Yu, 2017) for sentence simplification. Our\nexperiments demonstrate the effectiveness of our approach on different\nsimplification datasets, both in terms of automatic evaluation measures and\nhuman judgments.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 03:52:20 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Vu", "Tu", ""], ["Hu", "Baotian", ""], ["Munkhdalai", "Tsendsuren", ""], ["Yu", "Hong", ""]]}, {"id": "1804.07461", "submitter": "Alex Wang", "authors": "Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy,\n  Samuel R. Bowman", "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language\n  Understanding", "comments": "ICLR 2019; https://gluebenchmark.com/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For natural language understanding (NLU) technology to be maximally useful,\nboth practically and as a scientific object of study, it must be general: it\nmust be able to process language in a way that is not exclusively tailored to\nany one specific task or dataset. In pursuit of this objective, we introduce\nthe General Language Understanding Evaluation benchmark (GLUE), a tool for\nevaluating and analyzing the performance of models across a diverse range of\nexisting NLU tasks. GLUE is model-agnostic, but it incentivizes sharing\nknowledge across tasks because certain tasks have very limited training data.\nWe further provide a hand-crafted diagnostic test suite that enables detailed\nlinguistic analysis of NLU models. We evaluate baselines based on current\nmethods for multi-task and transfer learning and find that they do not\nimmediately give substantial improvements over the aggregate performance of\ntraining a separate model per task, indicating room for improvement in\ndeveloping general and robust NLU systems.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 06:35:04 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 21:17:15 GMT"}, {"version": "v3", "created": "Fri, 22 Feb 2019 23:53:34 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Wang", "Alex", ""], ["Singh", "Amanpreet", ""], ["Michael", "Julian", ""], ["Hill", "Felix", ""], ["Levy", "Omer", ""], ["Bowman", "Samuel R.", ""]]}, {"id": "1804.07581", "submitter": "Preslav Nakov", "authors": "Mitra Mohtarami, Ramy Baly, James Glass, Preslav Nakov, Lluis Marquez,\n  Alessandro Moschitti", "title": "Automatic Stance Detection Using End-to-End Memory Networks", "comments": "NAACL-2018; Stance detection; Fact-Checking; Veracity; Memory\n  networks; Neural Networks; Distributed Representations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel end-to-end memory network for stance detection, which\njointly (i) predicts whether a document agrees, disagrees, discusses or is\nunrelated with respect to a given target claim, and also (ii) extracts snippets\nof evidence for that prediction. The network operates at the paragraph level\nand integrates convolutional and recurrent neural networks, as well as a\nsimilarity matrix as part of the overall architecture. The experimental\nevaluation on the Fake News Challenge dataset shows state-of-the-art\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 12:48:10 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Mohtarami", "Mitra", ""], ["Baly", "Ramy", ""], ["Glass", "James", ""], ["Nakov", "Preslav", ""], ["Marquez", "Lluis", ""], ["Moschitti", "Alessandro", ""]]}, {"id": "1804.07583", "submitter": "Besnik Fetahu", "authors": "Besnik Fetahu", "title": "Approaches for Enriching and Improving Textual Knowledge Bases", "comments": "PhD thesis, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verifiability is one of the core editing principles in Wikipedia, where\neditors are encouraged to provide citations for the added statements.\nStatements can be any arbitrary piece of text, ranging from a sentence up to a\nparagraph. However, in many cases, citations are either outdated, missing, or\nlink to non-existing references (e.g. dead URL, moved content etc.). In total,\n20\\% of the cases such citations refer to news articles and represent the\nsecond most cited source. Even in cases where citations are provided, there are\nno explicit indicators for the span of a citation for a given piece of text. In\naddition to issues related with the verifiability principle, many Wikipedia\nentity pages are incomplete, with relevant information that is already\navailable in online news sources missing. Even for the already existing\ncitations, there is often a delay between the news publication time and the\nreference time.\n  In this thesis, we address the aforementioned issues and propose automated\napproaches that enforce the verifiability principle in Wikipedia, and suggest\nrelevant and missing news references for further enriching Wikipedia entity\npages.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 12:49:54 GMT"}, {"version": "v2", "created": "Sat, 28 Apr 2018 07:49:13 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Fetahu", "Besnik", ""]]}, {"id": "1804.07587", "submitter": "Preslav Nakov", "authors": "Israa Jaradat, Pepa Gencheva, Alberto Barron-Cedeno, Lluis Marquez,\n  Preslav Nakov", "title": "ClaimRank: Detecting Check-Worthy Claims in Arabic and English", "comments": "Check-worthiness; Fact-Checking; Veracity; Community-Question\n  Answering; Neural Networks; Arabic; English", "journal-ref": "NAACL-2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ClaimRank, an online system for detecting check-worthy claims.\nWhile originally trained on political debates, the system can work for any kind\nof text, e.g., interviews or regular news articles. Its aim is to facilitate\nmanual fact-checking efforts by prioritizing the claims that fact-checkers\nshould consider first. ClaimRank supports both Arabic and English, it is\ntrained on actual annotations from nine reputable fact-checking organizations\n(PolitiFact, FactCheck, ABC, CNN, NPR, NYT, Chicago Tribune, The Guardian, and\nWashington Post), and thus it can mimic the claim selection strategies for each\nand any of them, as well as for the union of them all.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 13:00:58 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Jaradat", "Israa", ""], ["Gencheva", "Pepa", ""], ["Barron-Cedeno", "Alberto", ""], ["Marquez", "Lluis", ""], ["Nakov", "Preslav", ""]]}, {"id": "1804.07656", "submitter": "Hitomi Yanaka", "authors": "Hitomi Yanaka, Koji Mineshima, Pascual Martinez-Gomez and Daisuke\n  Bekki", "title": "Acquisition of Phrase Correspondences using Natural Deduction Proofs", "comments": "11 pages, 4 figures, accepted as long paper of NAACL HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to identify, extract, and use phrasal knowledge is a crucial problem for\nthe task of Recognizing Textual Entailment (RTE). To solve this problem, we\npropose a method for detecting paraphrases via natural deduction proofs of\nsemantic relations between sentence pairs. Our solution relies on a graph\nreformulation of partial variable unifications and an algorithm that induces\nsubgraph alignments between meaning representations. Experiments show that our\nmethod can automatically detect various paraphrases that are absent from\nexisting paraphrase databases. In addition, the detection of paraphrases using\nproof information improves the accuracy of RTE tasks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 15:02:25 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Yanaka", "Hitomi", ""], ["Mineshima", "Koji", ""], ["Martinez-Gomez", "Pascual", ""], ["Bekki", "Daisuke", ""]]}, {"id": "1804.07691", "submitter": "Kaixiang Mo", "authors": "Kaixiang Mo, Yu Zhang, Qiang Yang, Pascale Fung", "title": "Cross-domain Dialogue Policy Transfer via Simultaneous Speech-act and\n  Slot Alignment", "comments": "v7", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue policy transfer enables us to build dialogue policies in a target\ndomain with little data by leveraging knowledge from a source domain with\nplenty of data. Dialogue sentences are usually represented by speech-acts and\ndomain slots, and the dialogue policy transfer is usually achieved by assigning\na slot mapping matrix based on human heuristics. However, existing dialogue\npolicy transfer methods cannot transfer across dialogue domains with different\nspeech-acts, for example, between systems built by different companies. Also,\nthey depend on either common slots or slot entropy, which are not available\nwhen the source and target slots are totally disjoint and no database is\navailable to calculate the slot entropy. To solve this problem, we propose a\nPolicy tRansfer across dOMaIns and SpEech-acts (PROMISE) model, which is able\nto transfer dialogue policies across domains with different speech-acts and\ndisjoint slots. The PROMISE model can learn to align different speech-acts and\nslots simultaneously, and it does not require common slots or the calculation\nof the slot entropy. Experiments on both real-world dialogue data and\nsimulations demonstrate that PROMISE model can effectively transfer dialogue\npolicies across domains with different speech-acts and disjoint slots.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 15:51:14 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Mo", "Kaixiang", ""], ["Zhang", "Yu", ""], ["Yang", "Qiang", ""], ["Fung", "Pascale", ""]]}, {"id": "1804.07705", "submitter": "Anton Bakhtin", "authors": "Anton Bakhtin, Arthur Szlam, Marc'Aurelio Ranzato, Edouard Grave", "title": "Lightweight Adaptive Mixture of Neural and N-gram Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is often the case that the best performing language model is an ensemble\nof a neural language model with n-grams. In this work, we propose a method to\nimprove how these two models are combined. By using a small network which\npredicts the mixture weight between the two models, we adapt their relative\nimportance at each time step. Because the gating network is small, it trains\nquickly on small amounts of held out data, and does not add overhead at scoring\ntime. Our experiments carried out on the One Billion Word benchmark show a\nsignificant improvement over the state of the art ensemble without retraining\nof the basic modules.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 16:18:35 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 11:37:29 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Bakhtin", "Anton", ""], ["Szlam", "Arthur", ""], ["Ranzato", "Marc'Aurelio", ""], ["Grave", "Edouard", ""]]}, {"id": "1804.07707", "submitter": "Kris Cao", "authors": "Kris Cao and Stephen Clark", "title": "Factorising AMR generation through syntax", "comments": "Camera ready; accepted at NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating from Abstract Meaning Representation (AMR) is an underspecified\nproblem, as many syntactic decisions are not constrained by the semantic graph.\nTo explicitly account for this underspecification, we break down generating\nfrom AMR into two steps: first generate a syntactic structure, and then\ngenerate the surface form. We show that decomposing the generation process this\nway leads to state-of-the-art single model performance generating from AMR\nwithout additional unlabelled data. We also demonstrate that we can generate\nmeaning-preserving syntactic paraphrases of the same AMR graph, as judged by\nhumans.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 16:24:12 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 16:45:01 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Cao", "Kris", ""], ["Clark", "Stephen", ""]]}, {"id": "1804.07726", "submitter": "Minjoon Seo", "authors": "Minjoon Seo, Tom Kwiatkowski, Ankur P. Parikh, Ali Farhadi, Hannaneh\n  Hajishirzi", "title": "Phrase-Indexed Question Answering: A New Challenge for Scalable Document\n  Comprehension", "comments": "EMNLP 2018 short; 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalize a new modular variant of current question answering tasks by\nenforcing complete independence of the document encoder from the question\nencoder. This formulation addresses a key challenge in machine comprehension by\nrequiring a standalone representation of the document discourse. It\nadditionally leads to a significant scalability advantage since the encoding of\nthe answer candidate phrases in the document can be pre-computed and indexed\noffline for efficient retrieval. We experiment with baseline models for the new\ntask, which achieve a reasonable accuracy but significantly underperform\nunconstrained QA models. We invite the QA research community to engage in\nPhrase-Indexed Question Answering (PIQA, pika) for closing the gap. The\nleaderboard is at: nlp.cs.washington.edu/piqa\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 17:05:03 GMT"}, {"version": "v2", "created": "Wed, 26 Sep 2018 08:31:58 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Seo", "Minjoon", ""], ["Kwiatkowski", "Tom", ""], ["Parikh", "Ankur P.", ""], ["Farhadi", "Ali", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "1804.07745", "submitter": "Armand Joulin", "authors": "Armand Joulin, Piotr Bojanowski, Tomas Mikolov, Herve Jegou, Edouard\n  Grave", "title": "Loss in Translation: Learning Bilingual Word Mapping with a Retrieval\n  Criterion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous word representations learned separately on distinct languages can\nbe aligned so that their words become comparable in a common space. Existing\nworks typically solve a least-square regression problem to learn a rotation\naligning a small bilingual lexicon, and use a retrieval criterion for\ninference. In this paper, we propose an unified formulation that directly\noptimizes a retrieval criterion in an end-to-end fashion. Our experiments on\nstandard benchmarks show that our approach outperforms the state of the art on\nword translation, with the biggest improvements observed for distant language\npairs such as English-Chinese.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 17:41:15 GMT"}, {"version": "v2", "created": "Mon, 3 Sep 2018 09:02:40 GMT"}, {"version": "v3", "created": "Wed, 5 Sep 2018 11:52:08 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Joulin", "Armand", ""], ["Bojanowski", "Piotr", ""], ["Mikolov", "Tomas", ""], ["Jegou", "Herve", ""], ["Grave", "Edouard", ""]]}, {"id": "1804.07754", "submitter": "Daniel Cer", "authors": "Yinfei Yang, Steve Yuan, Daniel Cer, Sheng-yi Kong, Noah Constant,\n  Petr Pilar, Heming Ge, Yun-Hsuan Sung, Brian Strope, Ray Kurzweil", "title": "Learning Semantic Textual Similarity from Conversations", "comments": "10 pages, 8 Figures, 6 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to learn representations for sentence-level\nsemantic similarity using conversational data. Our method trains an\nunsupervised model to predict conversational input-response pairs. The\nresulting sentence embeddings perform well on the semantic textual similarity\n(STS) benchmark and SemEval 2017's Community Question Answering (CQA) question\nsimilarity subtask. Performance is further improved by introducing multitask\ntraining combining the conversational input-response prediction task and a\nnatural language inference task. Extensive experiments show the proposed model\nachieves the best performance among all neural models on the STS benchmark and\nis competitive with the state-of-the-art feature engineered and mixed systems\nin both tasks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 17:58:45 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Yang", "Yinfei", ""], ["Yuan", "Steve", ""], ["Cer", "Daniel", ""], ["Kong", "Sheng-yi", ""], ["Constant", "Noah", ""], ["Pilar", "Petr", ""], ["Ge", "Heming", ""], ["Sung", "Yun-Hsuan", ""], ["Strope", "Brian", ""], ["Kurzweil", "Ray", ""]]}, {"id": "1804.07755", "submitter": "Guillaume Lample", "authors": "Guillaume Lample, Myle Ott, Alexis Conneau, Ludovic Denoyer,\n  Marc'Aurelio Ranzato", "title": "Phrase-Based & Neural Unsupervised Machine Translation", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine translation systems achieve near human-level performance on some\nlanguages, yet their effectiveness strongly relies on the availability of large\namounts of parallel sentences, which hinders their applicability to the\nmajority of language pairs. This work investigates how to learn to translate\nwhen having access to only large monolingual corpora in each language. We\npropose two model variants, a neural and a phrase-based model. Both versions\nleverage a careful initialization of the parameters, the denoising effect of\nlanguage models and automatic generation of parallel data by iterative\nback-translation. These models are significantly better than methods from the\nliterature, while being simpler and having fewer hyper-parameters. On the\nwidely used WMT'14 English-French and WMT'16 German-English benchmarks, our\nmodels respectively obtain 28.1 and 25.2 BLEU points without using a single\nparallel sentence, outperforming the state of the art by more than 11 BLEU\npoints. On low-resource languages like English-Urdu and English-Romanian, our\nmethods achieve even better results than semi-supervised and supervised\napproaches leveraging the paucity of available bitexts. Our code for NMT and\nPBSMT is publicly available.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 17:59:13 GMT"}, {"version": "v2", "created": "Mon, 13 Aug 2018 22:50:37 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Lample", "Guillaume", ""], ["Ott", "Myle", ""], ["Conneau", "Alexis", ""], ["Denoyer", "Ludovic", ""], ["Ranzato", "Marc'Aurelio", ""]]}, {"id": "1804.07781", "submitter": "Shi Feng", "authors": "Shi Feng, Eric Wallace, Alvin Grissom II, Mohit Iyyer, Pedro\n  Rodriguez, Jordan Boyd-Graber", "title": "Pathologies of Neural Models Make Interpretations Difficult", "comments": "EMNLP 2018 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One way to interpret neural model predictions is to highlight the most\nimportant input features---for example, a heatmap visualization over the words\nin an input sentence. In existing interpretation methods for NLP, a word's\nimportance is determined by either input perturbation---measuring the decrease\nin model confidence when that word is removed---or by the gradient with respect\nto that word. To understand the limitations of these methods, we use input\nreduction, which iteratively removes the least important word from the input.\nThis exposes pathological behaviors of neural models: the remaining words\nappear nonsensical to humans and are not the ones determined as important by\ninterpretation methods. As we confirm with human experiments, the reduced\nexamples lack information to support the prediction of any label, but models\nstill make the same predictions with high confidence. To explain these\ncounterintuitive results, we draw connections to adversarial examples and\nconfidence calibration: pathological behaviors reveal difficulties in\ninterpreting neural models trained with maximum likelihood. To mitigate their\ndeficiencies, we fine-tune the models by encouraging high entropy outputs on\nreduced examples. Fine-tuned models become more interpretable under input\nreduction without accuracy loss on regular examples.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 18:18:06 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 17:01:55 GMT"}, {"version": "v3", "created": "Tue, 28 Aug 2018 15:53:19 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Feng", "Shi", ""], ["Wallace", "Eric", ""], ["Grissom", "Alvin", "II"], ["Iyyer", "Mohit", ""], ["Rodriguez", "Pedro", ""], ["Boyd-Graber", "Jordan", ""]]}, {"id": "1804.07789", "submitter": "Anirban Laha", "authors": "Preksha Nema, Shreyas Shetty, Parag Jain, Anirban Laha, Karthik\n  Sankaranarayanan, Mitesh M. Khapra", "title": "Generating Descriptions from Structured Data Using a Bifocal Attention\n  Mechanism and Gated Orthogonalization", "comments": "Accepted in NAACL-HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we focus on the task of generating natural language\ndescriptions from a structured table of facts containing fields (such as\nnationality, occupation, etc) and values (such as Indian, actor, director,\netc). One simple choice is to treat the table as a sequence of fields and\nvalues and then use a standard seq2seq model for this task. However, such a\nmodel is too generic and does not exploit task-specific characteristics. For\nexample, while generating descriptions from a table, a human would attend to\ninformation at two levels: (i) the fields (macro level) and (ii) the values\nwithin the field (micro level). Further, a human would continue attending to a\nfield for a few timesteps till all the information from that field has been\nrendered and then never return back to this field (because there is nothing\nleft to say about it). To capture this behavior we use (i) a fused bifocal\nattention mechanism which exploits and combines this micro and macro level\ninformation and (ii) a gated orthogonalization mechanism which tries to ensure\nthat a field is remembered for a few time steps and then forgotten. We\nexperiment with a recently released dataset which contains fact tables about\npeople and their corresponding one line biographical descriptions in English.\nIn addition, we also introduce two similar datasets for French and German. Our\nexperiments show that the proposed model gives 21% relative improvement over a\nrecently proposed state of the art method and 10% relative improvement over\nbasic seq2seq models. The code and the datasets developed as a part of this\nwork are publicly available.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 18:30:18 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Nema", "Preksha", ""], ["Shetty", "Shreyas", ""], ["Jain", "Parag", ""], ["Laha", "Anirban", ""], ["Sankaranarayanan", "Karthik", ""], ["Khapra", "Mitesh M.", ""]]}, {"id": "1804.07790", "submitter": "Anirban Laha", "authors": "Parag Jain, Anirban Laha, Karthik Sankaranarayanan, Preksha Nema,\n  Mitesh M. Khapra, Shreyas Shetty", "title": "A Mixed Hierarchical Attention based Encoder-Decoder Approach for\n  Standard Table Summarization", "comments": "Accepted in NAACL-HLT 2018 (Short paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured data summarization involves generation of natural language\nsummaries from structured input data. In this work, we consider summarizing\nstructured data occurring in the form of tables as they are prevalent across a\nwide variety of domains. We formulate the standard table summarization problem,\nwhich deals with tables conforming to a single predefined schema. To this end,\nwe propose a mixed hierarchical attention based encoder-decoder model which is\nable to leverage the structure in addition to the content of the tables. Our\nexperiments on the publicly available WEATHERGOV dataset show around 18 BLEU (~\n30%) improvement over the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 18:31:29 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Jain", "Parag", ""], ["Laha", "Anirban", ""], ["Sankaranarayanan", "Karthik", ""], ["Nema", "Preksha", ""], ["Khapra", "Mitesh M.", ""], ["Shetty", "Shreyas", ""]]}, {"id": "1804.07827", "submitter": "Liyuan Liu", "authors": "Liyuan Liu, Xiang Ren, Jingbo Shang, Jian Peng and Jiawei Han", "title": "Efficient Contextualized Representation: Language Model Pruning for\n  Sequence Labeling", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many efforts have been made to facilitate natural language processing tasks\nwith pre-trained language models (LMs), and brought significant improvements to\nvarious applications. To fully leverage the nearly unlimited corpora and\ncapture linguistic information of multifarious levels, large-size LMs are\nrequired; but for a specific task, only parts of these information are useful.\nSuch large-sized LMs, even in the inference stage, may cause heavy computation\nworkloads, making them too time-consuming for large-scale applications. Here we\npropose to compress bulky LMs while preserving useful information with regard\nto a specific task. As different layers of the model keep different\ninformation, we develop a layer selection method for model pruning using\nsparsity-inducing regularization. By introducing the dense connectivity, we can\ndetach any layer without affecting others, and stretch shallow and wide LMs to\nbe deep and narrow. In model training, LMs are learned with layer-wise dropouts\nfor better robustness. Experiments on two benchmark datasets demonstrate the\neffectiveness of our method.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 21:10:17 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 17:24:49 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Liu", "Liyuan", ""], ["Ren", "Xiang", ""], ["Shang", "Jingbo", ""], ["Peng", "Jian", ""], ["Han", "Jiawei", ""]]}, {"id": "1804.07828", "submitter": "Qiang Ning", "authors": "Qiang Ning and Hao Wu and Dan Roth", "title": "A Multi-Axis Annotation Scheme for Event Temporal Relations", "comments": "[Final Version] 14 pages, accepted by ACL'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing temporal relation (TempRel) annotation schemes often have low\ninter-annotator agreements (IAA) even between experts, suggesting that the\ncurrent annotation task needs a better definition. This paper proposes a new\nmulti-axis modeling to better capture the temporal structure of events. In\naddition, we identify that event end-points are a major source of confusion in\nannotation, so we also propose to annotate TempRels based on start-points only.\nA pilot expert annotation using the proposed scheme shows significant\nimprovement in IAA from the conventional 60's to 80's (Cohen's Kappa). This\nbetter-defined annotation scheme further enables the use of crowdsourcing to\nalleviate the labor intensity for each annotator. We hope that this work can\nfoster more interesting studies towards event understanding.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 21:10:21 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 03:30:53 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Ning", "Qiang", ""], ["Wu", "Hao", ""], ["Roth", "Dan", ""]]}, {"id": "1804.07835", "submitter": "Li Zhang", "authors": "Li Zhang, Steven R. Wilson, Rada Mihalcea", "title": "Direct Network Transfer: Transfer Learning of Sentence Embeddings for\n  Semantic Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence encoders, which produce sentence embeddings using neural networks,\nare typically evaluated by how well they transfer to downstream tasks. This\nincludes semantic similarity, an important task in natural language\nunderstanding. Although there has been much work dedicated to building sentence\nencoders, the accompanying transfer learning techniques have received\nrelatively little attention. In this paper, we propose a transfer learning\nsetting specialized for semantic similarity, which we refer to as direct\nnetwork transfer. Through experiments on several standard text similarity\ndatasets, we show that applying direct network transfer to existing encoders\ncan lead to state-of-the-art performance. Additionally, we compare several\napproaches to transfer sentence encoders to semantic similarity tasks, showing\nthat the choice of transfer learning setting greatly affects the performance in\nmany cases, and differs by encoder and dataset.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 21:40:28 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 18:53:28 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Zhang", "Li", ""], ["Wilson", "Steven R.", ""], ["Mihalcea", "Rada", ""]]}, {"id": "1804.07847", "submitter": "Giannis Bekoulis", "authors": "Giannis Bekoulis, Johannes Deleu, Thomas Demeester, Chris Develder", "title": "Joint entity recognition and relation extraction as a multi-head\n  selection problem", "comments": "Expert Systems with Applications, code is available at\n  https://github.com/bekou/multihead_joint_entity_relation_extraction", "journal-ref": "Expert Systems with Applications, Volume 114, 30 December 2018,\n  Pages 34-45, ISSN 0957-4174", "doi": "10.1016/j.eswa.2018.07.032", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art models for joint entity recognition and relation extraction\nstrongly rely on external natural language processing (NLP) tools such as POS\n(part-of-speech) taggers and dependency parsers. Thus, the performance of such\njoint models depends on the quality of the features obtained from these NLP\ntools. However, these features are not always accurate for various languages\nand contexts. In this paper, we propose a joint neural model which performs\nentity recognition and relation extraction simultaneously, without the need of\nany manually extracted features or the use of any external tool. Specifically,\nwe model the entity recognition task using a CRF (Conditional Random Fields)\nlayer and the relation extraction task as a multi-head selection problem (i.e.,\npotentially identify multiple relations for each entity). We present an\nextensive experimental setup, to demonstrate the effectiveness of our method\nusing datasets from various contexts (i.e., news, biomedical, real estate) and\nlanguages (i.e., English, Dutch). Our model outperforms the previous neural\nmodels that use automatically extracted features, while it performs within a\nreasonable margin of feature-based neural models, or even beats them.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 22:16:40 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2018 14:51:57 GMT"}, {"version": "v3", "created": "Mon, 17 Dec 2018 09:41:19 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Bekoulis", "Giannis", ""], ["Deleu", "Johannes", ""], ["Demeester", "Thomas", ""], ["Develder", "Chris", ""]]}, {"id": "1804.07849", "submitter": "Karl Stratos", "authors": "Karl Stratos", "title": "Mutual Information Maximization for Simple and Accurate Part-Of-Speech\n  Induction", "comments": "NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address part-of-speech (POS) induction by maximizing the mutual\ninformation between the induced label and its context. We focus on two training\nobjectives that are amenable to stochastic gradient descent (SGD): a novel\ngeneralization of the classical Brown clustering objective and a recently\nproposed variational lower bound. While both objectives are subject to noise in\ngradient updates, we show through analysis and experiments that the variational\nlower bound is robust whereas the generalized Brown objective is vulnerable. We\nobtain competitive performance on a multitude of datasets and languages with a\nsimple architecture that encodes morphology and context.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 22:34:29 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 01:14:25 GMT"}, {"version": "v3", "created": "Tue, 30 Oct 2018 18:51:25 GMT"}, {"version": "v4", "created": "Tue, 2 Apr 2019 20:27:15 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Stratos", "Karl", ""]]}, {"id": "1804.07853", "submitter": "David Gaddy", "authors": "David Gaddy, Mitchell Stern, and Dan Klein", "title": "What's Going On in Neural Constituency Parsers? An Analysis", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of differences have emerged between modern and classic approaches to\nconstituency parsing in recent years, with structural components like grammars\nand feature-rich lexicons becoming less central while recurrent neural network\nrepresentations rise in popularity. The goal of this work is to analyze the\nextent to which information provided directly by the model structure in\nclassical systems is still being captured by neural methods. To this end, we\npropose a high-performance neural model (92.08 F1 on PTB) that is\nrepresentative of recent work and perform a series of investigative\nexperiments. We find that our model implicitly learns to encode much of the\nsame information that was explicitly provided by grammars and lexicons in the\npast, indicating that this scaffolding can largely be subsumed by powerful\ngeneral-purpose neural machinery.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 23:00:11 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Gaddy", "David", ""], ["Stern", "Mitchell", ""], ["Klein", "Dan", ""]]}, {"id": "1804.07855", "submitter": "Xiujun Li", "authors": "Da Tang and Xiujun Li and Jianfeng Gao and Chong Wang and Lihong Li\n  and Tony Jebara", "title": "Subgoal Discovery for Hierarchical Dialogue Policy Learning", "comments": "11 pages, 6 figures, EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing agents to engage in complex goal-oriented dialogues is challenging\npartly because the main learning signals are very sparse in long conversations.\nIn this paper, we propose a divide-and-conquer approach that discovers and\nexploits the hidden structure of the task to enable efficient policy learning.\nFirst, given successful example dialogues, we propose the Subgoal Discovery\nNetwork (SDN) to divide a complex goal-oriented task into a set of simpler\nsubgoals in an unsupervised fashion. We then use these subgoals to learn a\nmulti-level policy by hierarchical reinforcement learning. We demonstrate our\nmethod by building a dialogue agent for the composite task of travel planning.\nExperiments with simulated and real users show that our approach performs\ncompetitively against a state-of-the-art method that requires human-defined\nsubgoals. Moreover, we show that the learned subgoals are often human\ncomprehensible.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 23:06:44 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 22:20:26 GMT"}, {"version": "v3", "created": "Sat, 22 Sep 2018 22:46:52 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Tang", "Da", ""], ["Li", "Xiujun", ""], ["Gao", "Jianfeng", ""], ["Wang", "Chong", ""], ["Li", "Lihong", ""], ["Jebara", "Tony", ""]]}, {"id": "1804.07875", "submitter": "Lifu Huang", "authors": "Lifu Huang, Kyunghyun Cho, Boliang Zhang, Heng Ji, Kevin Knight", "title": "Multi-lingual Common Semantic Space Construction via Cluster-consistent\n  Word Embedding", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We construct a multilingual common semantic space based on distributional\nsemantics, where words from multiple languages are projected into a shared\nspace to enable knowledge and resource transfer across languages. Beyond word\nalignment, we introduce multiple cluster-level alignments and enforce the word\nclusters to be consistently distributed across multiple languages. We exploit\nthree signals for clustering: (1) neighbor words in the monolingual word\nembedding space; (2) character-level information; and (3) linguistic properties\n(e.g., apposition, locative suffix) derived from linguistic structure knowledge\nbases available for thousands of languages. We introduce a new\ncluster-consistent correlational neural network to construct the common\nsemantic space by aligning words as well as clusters. Intrinsic evaluation on\nmonolingual and multilingual QVEC tasks shows our approach achieves\nsignificantly higher correlation with linguistic features than state-of-the-art\nmulti-lingual embedding learning methods do. Using low-resource language name\ntagging as a case study for extrinsic evaluation, our approach achieves up to\n24.5\\% absolute F-score gain over the state of the art.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 01:48:38 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Huang", "Lifu", ""], ["Cho", "Kyunghyun", ""], ["Zhang", "Boliang", ""], ["Ji", "Heng", ""], ["Knight", "Kevin", ""]]}, {"id": "1804.07878", "submitter": "Zhong Zhou", "authors": "Zhong Zhou, Matthias Sperber, Alex Waibel", "title": "Massively Parallel Cross-Lingual Learning in Low-Resource Target\n  Language Translation", "comments": "Accepted at 2018 Third Conference on Machine Translation (WMT18)", "journal-ref": "Proceedings of the 3rd conference on Machine Translation Worshop\n  of the 23rd Conference on Empirical Methods in Natural Language Processing.\n  2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We work on translation from rich-resource languages to low-resource\nlanguages. The main challenges we identify are the lack of low-resource\nlanguage data, effective methods for cross-lingual transfer, and the\nvariable-binding problem that is common in neural systems. We build a\ntranslation system that addresses these challenges using eight European\nlanguage families as our test ground. Firstly, we add the source and the target\nfamily labels and study intra-family and inter-family influences for effective\ncross-lingual transfer. We achieve an improvement of +9.9 in BLEU score for\nEnglish-Swedish translation using eight families compared to the single-family\nmulti-source multi-target baseline. Moreover, we find that training on two\nneighboring families closest to the low-resource language is often enough.\nSecondly, we construct an ablation study and find that reasonably good results\ncan be achieved even with considerably less target data. Thirdly, we address\nthe variable-binding problem by building an order-preserving named entity\ntranslation model. We obtain 60.6% accuracy in qualitative evaluation where our\ntranslations are akin to human translations in a preliminary study.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 02:18:36 GMT"}, {"version": "v2", "created": "Sat, 25 Aug 2018 15:03:59 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Zhou", "Zhong", ""], ["Sperber", "Matthias", ""], ["Waibel", "Alex", ""]]}, {"id": "1804.07881", "submitter": "Tongtao Zhang", "authors": "Tongtao Zhang and Heng Ji", "title": "Event Extraction with Generative Adversarial Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for event extraction (EE) task based on an imitation\nlearning framework, specifically, inverse reinforcement learning (IRL) via\ngenerative adversarial network (GAN). The GAN estimates proper rewards\naccording to the difference between the actions committed by the expert (or\nground truth) and the agent among complicated states in the environment. EE\ntask benefits from these dynamic rewards because instances and labels yield to\nvarious extents of difficulty and the gains are expected to be diverse -- e.g.,\nan ambiguous but correctly detected trigger or argument should receive high\ngains -- while the traditional RL models usually neglect such differences and\npay equal attention on all instances. Moreover, our experiments also\ndemonstrate that the proposed framework outperforms state-of-the-art methods,\nwithout explicit feature engineering.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 02:43:00 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Zhang", "Tongtao", ""], ["Ji", "Heng", ""]]}, {"id": "1804.07888", "submitter": "Xiaodong Liu", "authors": "Xiaodong Liu, Kevin Duh and Jianfeng Gao", "title": "Stochastic Answer Networks for Natural Language Inference", "comments": "6 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a stochastic answer network (SAN) to explore multi-step inference\nstrategies in Natural Language Inference. Rather than directly predicting the\nresults given the inputs, the model maintains a state and iteratively refines\nits predictions. Our experiments show that SAN achieves the state-of-the-art\nresults on three benchmarks: Stanford Natural Language Inference (SNLI)\ndataset, MultiGenre Natural Language Inference (MultiNLI) dataset and Quora\nQuestion Pairs dataset.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 04:31:59 GMT"}, {"version": "v2", "created": "Sat, 30 Mar 2019 20:49:11 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Liu", "Xiaodong", ""], ["Duh", "Kevin", ""], ["Gao", "Jianfeng", ""]]}, {"id": "1804.07889", "submitter": "Di Lu", "authors": "Di Lu, Spencer Whitehead, Lifu Huang, Heng Ji, Shih-Fu Chang", "title": "Entity-aware Image Caption Generation", "comments": "In proceedings of EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current image captioning approaches generate descriptions which lack specific\ninformation, such as named entities that are involved in the images. In this\npaper we propose a new task which aims to generate informative image captions,\ngiven images and hashtags as input. We propose a simple but effective approach\nto tackle this problem. We first train a convolutional neural networks - long\nshort term memory networks (CNN-LSTM) model to generate a template caption\nbased on the input image. Then we use a knowledge graph based collective\ninference algorithm to fill in the template with specific named entities\nretrieved via the hashtags. Experiments on a new benchmark dataset collected\nfrom Flickr show that our model generates news-style image descriptions with\nmuch richer information. Our model outperforms unimodal baselines significantly\nwith various evaluation metrics.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 04:40:10 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 04:12:38 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Lu", "Di", ""], ["Whitehead", "Spencer", ""], ["Huang", "Lifu", ""], ["Ji", "Heng", ""], ["Chang", "Shih-Fu", ""]]}, {"id": "1804.07893", "submitter": "Kumiko Tanaka-Ishii", "authors": "Tatsuru Kobayashi, Kumiko Tanaka-Ishii", "title": "Taylor's law for Human Linguistic Sequences", "comments": "11 pages, 16 figures, Accepted as ACL 2018 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taylor's law describes the fluctuation characteristics underlying a system in\nwhich the variance of an event within a time span grows by a power law with\nrespect to the mean. Although Taylor's law has been applied in many natural and\nsocial systems, its application for language has been scarce. This article\ndescribes a new quantification of Taylor's law in natural language and reports\nan analysis of over 1100 texts across 14 languages. The Taylor exponents of\nwritten natural language texts were found to exhibit almost the same value. The\nexponent was also compared for other language-related data, such as the\nchild-directed speech, music, and programming language code. The results show\nhow the Taylor exponent serves to quantify the fundamental structural\ncomplexity underlying linguistic time series. The article also shows the\napplicability of these findings in evaluating language models.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 05:24:10 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 15:18:20 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Kobayashi", "Tatsuru", ""], ["Tanaka-Ishii", "Kumiko", ""]]}, {"id": "1804.07899", "submitter": "Markus Freitag", "authors": "Markus Freitag, Scott Roy", "title": "Unsupervised Natural Language Generation with Denoising Autoencoders", "comments": "Accepted at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating text from structured data is important for various tasks such as\nquestion answering and dialog systems. We show that in at least one domain,\nwithout any supervision and only based on unlabeled text, we are able to build\na Natural Language Generation (NLG) system with higher performance than\nsupervised approaches. In our approach, we interpret the structured data as a\ncorrupt representation of the desired output and use a denoising auto-encoder\nto reconstruct the sentence. We show how to introduce noise into training\nexamples that do not contain structured data, and that the resulting denoising\nauto-encoder generalizes to generate correct sentences when given structured\ndata.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 06:16:57 GMT"}, {"version": "v2", "created": "Fri, 24 Aug 2018 19:53:33 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Freitag", "Markus", ""], ["Roy", "Scott", ""]]}, {"id": "1804.07911", "submitter": "Kai-Wei Chang", "authors": "Wasi Uddin Ahmad, Xueying Bai, Zhechao Huang, Chao Jiang, Nanyun Peng,\n  Kai-Wei Chang", "title": "Multi-task Learning for Universal Sentence Embeddings: A Thorough\n  Evaluation using Transfer and Auxiliary Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning distributed sentence representations is one of the key challenges in\nnatural language processing. Previous work demonstrated that a recurrent neural\nnetwork (RNNs) based sentence encoder trained on a large collection of\nannotated natural language inference data, is efficient in the transfer\nlearning to facilitate other related tasks. In this paper, we show that joint\nlearning of multiple tasks results in better generalizable sentence\nrepresentations by conducting extensive experiments and analysis comparing the\nmulti-task and single-task learned sentence encoders. The quantitative analysis\nusing auxiliary tasks show that multi-task learning helps to embed better\nsemantic information in the sentence representations compared to single-task\nlearning. In addition, we compare multi-task sentence encoders with\ncontextualized word representations and show that combining both of them can\nfurther boost the performance of transfer learning.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 07:53:07 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2018 18:14:01 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Ahmad", "Wasi Uddin", ""], ["Bai", "Xueying", ""], ["Huang", "Zhechao", ""], ["Jiang", "Chao", ""], ["Peng", "Nanyun", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "1804.07915", "submitter": "Yun Chen", "authors": "Yun Chen, Victor O.K. Li, Kyunghyun Cho, Samuel R. Bowman", "title": "A Stable and Effective Learning Strategy for Trainable Greedy Decoding", "comments": "Accepted by EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beam search is a widely used approximate search strategy for neural network\ndecoders, and it generally outperforms simple greedy decoding on tasks like\nmachine translation. However, this improvement comes at substantial\ncomputational cost. In this paper, we propose a flexible new method that allows\nus to reap nearly the full benefits of beam search with nearly no additional\ncomputational cost. The method revolves around a small neural network actor\nthat is trained to observe and manipulate the hidden state of a\npreviously-trained decoder. To train this actor network, we introduce the use\nof a pseudo-parallel corpus built using the output of beam search on a base\nmodel, ranked by a target quality metric like BLEU. Our method is inspired by\nearlier work on this problem, but requires no reinforcement learning, and can\nbe trained reliably on a range of models. Experiments on three parallel corpora\nand three architectures show that the method yields substantial improvements in\ntranslation quality and speed over each base system.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 08:14:58 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 03:35:54 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Chen", "Yun", ""], ["Li", "Victor O. K.", ""], ["Cho", "Kyunghyun", ""], ["Bowman", "Samuel R.", ""]]}, {"id": "1804.07918", "submitter": "Jonathan Herzig", "authors": "Jonathan Herzig and Jonathan Berant", "title": "Decoupling Structure and Lexicon for Zero-Shot Semantic Parsing", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building a semantic parser quickly in a new domain is a fundamental challenge\nfor conversational interfaces, as current semantic parsers require expensive\nsupervision and lack the ability to generalize to new domains. In this paper,\nwe introduce a zero-shot approach to semantic parsing that can parse utterances\nin unseen domains while only being trained on examples in other source domains.\nFirst, we map an utterance to an abstract, domain-independent, logical form\nthat represents the structure of the logical form, but contains slots instead\nof KB constants. Then, we replace slots with KB constants via lexical alignment\nscores and global inference. Our model reaches an average accuracy of 53.4% on\n7 domains in the Overnight dataset, substantially better than other zero-shot\nbaselines, and performs as good as a parser trained on over 30% of the target\ndomain examples.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 08:27:14 GMT"}, {"version": "v2", "created": "Sat, 22 Sep 2018 09:07:52 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Herzig", "Jonathan", ""], ["Berant", "Jonathan", ""]]}, {"id": "1804.07927", "submitter": "Rahul Aralikatte", "authors": "Amrita Saha, Rahul Aralikatte, Mitesh M. Khapra, Karthik\n  Sankaranarayanan", "title": "DuoRC: Towards Complex Language Understanding with Paraphrased Reading\n  Comprehension", "comments": "Accepted in ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose DuoRC, a novel dataset for Reading Comprehension (RC) that\nmotivates several new challenges for neural approaches in language\nunderstanding beyond those offered by existing RC datasets. DuoRC contains\n186,089 unique question-answer pairs created from a collection of 7680 pairs of\nmovie plots where each pair in the collection reflects two versions of the same\nmovie - one from Wikipedia and the other from IMDb - written by two different\nauthors. We asked crowdsourced workers to create questions from one version of\nthe plot and a different set of workers to extract or synthesize answers from\nthe other version. This unique characteristic of DuoRC where questions and\nanswers are created from different versions of a document narrating the same\nunderlying story, ensures by design, that there is very little lexical overlap\nbetween the questions created from one version and the segments containing the\nanswer in the other version. Further, since the two versions have different\nlevels of plot detail, narration style, vocabulary, etc., answering questions\nfrom the second version requires deeper language understanding and\nincorporating external background knowledge. Additionally, the narrative style\nof passages arising from movie plots (as opposed to typical descriptive\npassages in existing datasets) exhibits the need to perform complex reasoning\nover events across multiple sentences. Indeed, we observe that state-of-the-art\nneural RC models which have achieved near human performance on the SQuAD\ndataset, even when coupled with traditional NLP techniques to address the\nchallenges presented in DuoRC exhibit very poor performance (F1 score of 37.42%\non DuoRC v/s 86% on SQuAD dataset). This opens up several interesting research\navenues wherein DuoRC could complement other RC datasets to explore novel\nneural approaches for studying language understanding.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 09:43:06 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 05:59:37 GMT"}, {"version": "v3", "created": "Thu, 31 May 2018 10:31:08 GMT"}, {"version": "v4", "created": "Wed, 10 Oct 2018 09:28:33 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Saha", "Amrita", ""], ["Aralikatte", "Rahul", ""], ["Khapra", "Mitesh M.", ""], ["Sankaranarayanan", "Karthik", ""]]}, {"id": "1804.07942", "submitter": "Zhaopeng Tu", "authors": "Zhaopeng Tu and Yong Jiang and Xiaojiang Liu and Lei Shu and Shuming\n  Shi", "title": "Generative Stock Question Answering", "comments": "data: http://ai.tencent.com/ailab/nlp/data/stockQA.tar.gz", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of stock related question answering (StockQA):\nautomatically generating answers to stock related questions, just like\nprofessional stock analysts providing action recommendations to stocks upon\nuser's requests. StockQA is quite different from previous QA tasks since (1)\nthe answers in StockQA are natural language sentences (rather than entities or\nvalues) and due to the dynamic nature of StockQA, it is scarcely possible to\nget reasonable answers in an extractive way from the training data; and (2)\nStockQA requires properly analyzing the relationship between keywords in QA\npair and the numerical features of a stock. We propose to address the problem\nwith a memory-augmented encoder-decoder architecture, and integrate different\nmechanisms of number understanding and generation, which is a critical\ncomponent of StockQA.\n  We build a large-scale dataset containing over 180K StockQA instances, based\non which various technique combinations are extensively studied and compared.\nExperimental results show that a hybrid word-character model with separate\ncharacter components for number processing, achieves the best performance. By\nanalyzing the results, we found that 44.8% of answers generated by our best\nmodel still suffer from the generic answer problem, which can be alleviated by\na straightforward hybrid retrieval-generation model.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 10:59:06 GMT"}, {"version": "v2", "created": "Thu, 20 Sep 2018 08:39:05 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Tu", "Zhaopeng", ""], ["Jiang", "Yong", ""], ["Liu", "Xiaojiang", ""], ["Shu", "Lei", ""], ["Shi", "Shuming", ""]]}, {"id": "1804.07944", "submitter": "Akash Srivastava", "authors": "Akash Srivastava, Charles Sutton", "title": "Variational Inference In Pachinko Allocation Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Pachinko Allocation Machine (PAM) is a deep topic model that allows\nrepresenting rich correlation structures among topics by a directed acyclic\ngraph over topics. Because of the flexibility of the model, however,\napproximate inference is very difficult. Perhaps for this reason, only a small\nnumber of potential PAM architectures have been explored in the literature. In\nthis paper we present an efficient and flexible amortized variational inference\nmethod for PAM, using a deep inference network to parameterize the approximate\nposterior distribution in a manner similar to the variational autoencoder. Our\ninference method produces more coherent topics than state-of-art inference\nmethods for PAM while being an order of magnitude faster, which allows\nexploration of a wider range of PAM architectures than have previously been\nstudied.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 11:12:25 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Srivastava", "Akash", ""], ["Sutton", "Charles", ""]]}, {"id": "1804.07946", "submitter": "Hwiyeol Jo", "authors": "Hwiyeol Jo and Stanley Jungkyu Choi", "title": "Extrofitting: Enriching Word Representation and its Vector Space with\n  Semantic Lexicons", "comments": "In Proceedings of the 3rd ACL Workshop on Representation Learning for\n  NLP (RepL4NLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose post-processing method for enriching not only word representation\nbut also its vector space using semantic lexicons, which we call extrofitting.\nThe method consists of 3 steps as follows: (i) Expanding 1 or more dimension(s)\non all the word vectors, filling with their representative value. (ii)\nTransferring semantic knowledge by averaging each representative values of\nsynonyms and filling them in the expanded dimension(s). These two steps make\nrepresentations of the synonyms close together. (iii) Projecting the vector\nspace using Linear Discriminant Analysis, which eliminates the expanded\ndimension(s) with semantic knowledge. When experimenting with GloVe, we find\nthat our method outperforms Faruqui's retrofitting on some of word similarity\ntask. We also report further analysis on our method in respect to word vector\ndimensions, vocabulary size as well as other well-known pretrained word vectors\n(e.g., Word2Vec, Fasttext).\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 11:17:26 GMT"}, {"version": "v2", "created": "Sun, 3 Jun 2018 08:35:28 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Jo", "Hwiyeol", ""], ["Choi", "Stanley Jungkyu", ""]]}, {"id": "1804.07954", "submitter": "Radu Tudor Ionescu", "authors": "M\\u{a}d\\u{a}lina Cozma and Andrei M. Butnaru and Radu Tudor Ionescu", "title": "Automated essay scoring with string kernels and word embeddings", "comments": "Accepted at ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present an approach based on combining string kernels and\nword embeddings for automatic essay scoring. String kernels capture the\nsimilarity among strings based on counting common character n-grams, which are\na low-level yet powerful type of feature, demonstrating state-of-the-art\nresults in various text classification tasks such as Arabic dialect\nidentification or native language identification. To our best knowledge, we are\nthe first to apply string kernels to automatically score essays. We are also\nthe first to combine them with a high-level semantic feature representation,\nnamely the bag-of-super-word-embeddings. We report the best performance on the\nAutomated Student Assessment Prize data set, in both in-domain and cross-domain\nsettings, surpassing recent state-of-the-art deep learning approaches.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 12:26:29 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2018 12:49:40 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Cozma", "M\u0103d\u0103lina", ""], ["Butnaru", "Andrei M.", ""], ["Ionescu", "Radu Tudor", ""]]}, {"id": "1804.07958", "submitter": "Sha Yuan", "authors": "Sha Yuan, Yu Zhang, Jie Tang, Juan Bautista Cabot\\`a", "title": "Expert Finding in Community Question Answering: A Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid development recently of Community Question Answering (CQA)\nsatisfies users quest for professional and personal knowledge about anything.\nIn CQA, one central issue is to find users with expertise and willingness to\nanswer the given questions. Expert finding in CQA often exhibits very different\nchallenges compared to traditional methods. Sparse data and new features\nviolate fundamental assumptions of traditional recommendation systems. This\npaper focuses on reviewing and categorizing the current progress on expert\nfinding in CQA. We classify all the existing solutions into four different\ncategories: matrix factorization based models (MF-based models), gradient\nboosting tree based models (GBT-based models), deep learning based models\n(DL-based models) and ranking based models (R-based models). We find that\nMF-based models outperform other categories of models in the field of expert\nfinding in CQA. Moreover, we use innovative diagrams to clarify several\nimportant concepts of ensemble learning, and find that ensemble models with\nseveral specific single models can further boosting the performance. Further,\nwe compare the performance of different models on different types of matching\ntasks, including text vs. text, graph vs. text, audio vs. text and video vs.\ntext. The results can help the model selection of expert finding in practice.\nFinally, we explore some potential future issues in expert finding research in\nCQA.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 12:37:45 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Yuan", "Sha", ""], ["Zhang", "Yu", ""], ["Tang", "Jie", ""], ["Cabot\u00e0", "Juan Bautista", ""]]}, {"id": "1804.07961", "submitter": "Daniel Fern\\'andez-Gonz\\'alez", "authors": "Daniel Fern\\'andez-Gonz\\'alez and Carlos G\\'omez-Rodr\\'iguez", "title": "Faster Shift-Reduce Constituent Parsing with a Non-Binary, Bottom-Up\n  Strategy", "comments": "Final peer-reviewed manuscript accepted for publication", "journal-ref": "Artificial Intelligence, Volume 275, 2019, Pages 559-574, ISSN\n  0004-3702", "doi": "10.1016/j.artint.2019.07.006", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasingly wide range of artificial intelligence applications rely on\nsyntactic information to process and extract meaning from natural language text\nor speech, with constituent trees being one of the most widely used syntactic\nformalisms. To produce these phrase-structure representations from sentences in\nnatural language, shift-reduce constituent parsers have become one of the most\nefficient approaches. Increasing their accuracy and speed is still one of the\nmain objectives pursued by the research community so that artificial\nintelligence applications that make use of parsing outputs, such as machine\ntranslation or voice assistant services, can improve their performance. With\nthis goal in mind, we propose in this article a novel non-binary shift-reduce\nalgorithm for constituent parsing. Our parser follows a classical bottom-up\nstrategy but, unlike others, it straightforwardly creates non-binary branchings\nwith just one Reduce transition, instead of requiring prior binarization or a\nsequence of binary transitions, allowing its direct application to any language\nwithout the need of further resources such as percolation tables. As a result,\nit uses fewer transitions per sentence than existing transition-based\nconstituent parsers, becoming the fastest such system and, as a consequence,\nspeeding up downstream applications. Using static oracle training and greedy\nsearch, the accuracy of this novel approach is on par with state-of-the-art\ntransition-based constituent parsers and outperforms all top-down and bottom-up\ngreedy shift-reduce systems on the Wall Street Journal section from the English\nPenn Treebank and the Penn Chinese Treebank. Additionally, we develop a dynamic\noracle for training the proposed transition-based algorithm, achieving further\nimprovements in both benchmarks and obtaining the best accuracy to date on the\nPenn Chinese Treebank among greedy shift-reduce parsers.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 13:01:55 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 13:11:10 GMT"}, {"version": "v3", "created": "Fri, 2 Aug 2019 12:07:58 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Fern\u00e1ndez-Gonz\u00e1lez", "Daniel", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "1804.07972", "submitter": "Ond\\v{r}ej C\\'ifka", "authors": "Ond\\v{r}ej C\\'ifka, Aliaksei Severyn, Enrique Alfonseca, Katja\n  Filippova", "title": "Eval all, trust a few, do wrong to none: Comparing sentence generation\n  models", "comments": "12 pages (3 page appendix); v2: added hyperparameter settings,\n  clarifications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study recent neural generative models for text generation\nrelated to variational autoencoders. Previous works have employed various\ntechniques to control the prior distribution of the latent codes in these\nmodels, which is important for sampling performance, but little attention has\nbeen paid to reconstruction error. In our study, we follow a rigorous\nevaluation protocol using a large set of previously used and novel automatic\nand human evaluation metrics, applied to both generated samples and\nreconstructions. We hope that it will become the new evaluation standard when\ncomparing neural generative models for text.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 14:29:39 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 20:29:16 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["C\u00edfka", "Ond\u0159ej", ""], ["Severyn", "Aliaksei", ""], ["Alfonseca", "Enrique", ""], ["Filippova", "Katja", ""]]}, {"id": "1804.07976", "submitter": "Rachel Rudinger", "authors": "Rachel Rudinger, Adam Teichert, Ryan Culkin, Sheng Zhang, Benjamin Van\n  Durme", "title": "Neural-Davidsonian Semantic Proto-role Labeling", "comments": "Accepted to EMNLP 2018; errata corrected in Appendix Tables 7 and 8", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a model for semantic proto-role labeling (SPRL) using an adapted\nbidirectional LSTM encoding strategy that we call \"Neural-Davidsonian\":\npredicate-argument structure is represented as pairs of hidden states\ncorresponding to predicate and argument head tokens of the input sequence. We\ndemonstrate: (1) state-of-the-art results in SPRL, and (2) that our network\nnaturally shares parameters between attributes, allowing for learning new\nattribute types with limited added supervision.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 14:48:56 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 02:25:11 GMT"}, {"version": "v3", "created": "Tue, 27 Aug 2019 04:12:12 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Rudinger", "Rachel", ""], ["Teichert", "Adam", ""], ["Culkin", "Ryan", ""], ["Zhang", "Sheng", ""], ["Van Durme", "Benjamin", ""]]}, {"id": "1804.07983", "submitter": "Douwe Kiela", "authors": "Douwe Kiela, Changhan Wang, Kyunghyun Cho", "title": "Dynamic Meta-Embeddings for Improved Sentence Representations", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While one of the first steps in many NLP systems is selecting what\npre-trained word embeddings to use, we argue that such a step is better left\nfor neural networks to figure out by themselves. To that end, we introduce\ndynamic meta-embeddings, a simple yet effective method for the supervised\nlearning of embedding ensembles, which leads to state-of-the-art performance\nwithin the same model class on a variety of tasks. We subsequently show how the\ntechnique can be used to shed new light on the usage of word embeddings in NLP\nsystems.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 15:32:32 GMT"}, {"version": "v2", "created": "Wed, 5 Sep 2018 16:12:13 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Kiela", "Douwe", ""], ["Wang", "Changhan", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1804.07998", "submitter": "Moustafa Alzantot", "authors": "Moustafa Alzantot, Yash Sharma, Ahmed Elgohary, Bo-Jhang Ho, Mani\n  Srivastava, Kai-Wei Chang", "title": "Generating Natural Language Adversarial Examples", "comments": "Accepted in EMNLP 2018 (Conference on Empirical Methods in Natural\n  Language Processing)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are vulnerable to adversarial examples,\nperturbations to correctly classified examples which can cause the model to\nmisclassify. In the image domain, these perturbations are often virtually\nindistinguishable to human perception, causing humans and state-of-the-art\nmodels to disagree. However, in the natural language domain, small\nperturbations are clearly perceptible, and the replacement of a single word can\ndrastically alter the semantics of the document. Given these challenges, we use\na black-box population-based optimization algorithm to generate semantically\nand syntactically similar adversarial examples that fool well-trained sentiment\nanalysis and textual entailment models with success rates of 97% and 70%,\nrespectively. We additionally demonstrate that 92.3% of the successful\nsentiment analysis adversarial examples are classified to their original label\nby 20 human annotators, and that the examples are perceptibly quite similar.\nFinally, we discuss an attempt to use adversarial training as a defense, but\nfail to yield improvement, demonstrating the strength and diversity of our\nadversarial examples. We hope our findings encourage researchers to pursue\nimproving the robustness of DNNs in the natural language domain.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 17:02:20 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2018 20:29:35 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Alzantot", "Moustafa", ""], ["Sharma", "Yash", ""], ["Elgohary", "Ahmed", ""], ["Ho", "Bo-Jhang", ""], ["Srivastava", "Mani", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "1804.08000", "submitter": "Sheng Zhang", "authors": "Sheng Zhang, Kevin Duh and Benjamin Van Durme", "title": "Fine-grained Entity Typing through Increased Discourse Context and\n  Adaptive Classification Thresholds", "comments": "Accepted to StarSem 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-grained entity typing is the task of assigning fine-grained semantic\ntypes to entity mentions. We propose a neural architecture which learns a\ndistributional semantic representation that leverages a greater amount of\nsemantic context -- both document and sentence level information -- than prior\nwork. We find that additional context improves performance, with further\nimprovements gained by utilizing adaptive classification thresholds.\nExperiments show that our approach without reliance on hand-crafted features\nachieves the state-of-the-art results on three benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 17:21:28 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Zhang", "Sheng", ""], ["Duh", "Kevin", ""], ["Van Durme", "Benjamin", ""]]}, {"id": "1804.08012", "submitter": "Preslav Nakov", "authors": "Ramy Baly, Mitra Mohtarami, James Glass, Lluis Marquez, Alessandro\n  Moschitti, Preslav Nakov", "title": "Integrating Stance Detection and Fact Checking in a Unified Corpus", "comments": "Stance Detection, Fact-Checking, Veracity, Arabic, NAACL-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A reasonable approach for fact checking a claim involves retrieving\npotentially relevant documents from different sources (e.g., news websites,\nsocial media, etc.), determining the stance of each document with respect to\nthe claim, and finally making a prediction about the claim's factuality by\naggregating the strength of the stances, while taking the reliability of the\nsource into account. Moreover, a fact checking system should be able to explain\nits decision by providing relevant extracts (rationales) from the documents.\nYet, this setup is not directly supported by existing datasets, which treat\nfact checking, document retrieval, source credibility, stance detection and\nrationale extraction as independent tasks. In this paper, we support the\ninterdependencies between these tasks as annotations in the same corpus. We\nimplement this setup on an Arabic fact checking corpus, the first of its kind.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 19:18:22 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Baly", "Ramy", ""], ["Mohtarami", "Mitra", ""], ["Glass", "James", ""], ["Marquez", "Lluis", ""], ["Moschitti", "Alessandro", ""], ["Nakov", "Preslav", ""]]}, {"id": "1804.08037", "submitter": "Sheng Zhang", "authors": "Sheng Zhang, Kevin Duh and Benjamin Van Durme", "title": "Cross-lingual Semantic Parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the task of cross-lingual semantic parsing: mapping content\nprovided in a source language into a meaning representation based on a target\nlanguage. We present: (1) a meaning representation designed to allow systems to\ntarget varying levels of structural complexity (shallow to deep analysis), (2)\nan evaluation metric to measure the similarity between system output and\nreference meaning representations, (3) an end-to-end model with a novel copy\nmechanism that supports intrasentential coreference, and (4) an evaluation\ndataset where experiments show our model outperforms strong baselines by at\nleast 1.18 F1 score.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 22:15:36 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Zhang", "Sheng", ""], ["Duh", "Kevin", ""], ["Van Durme", "Benjamin", ""]]}, {"id": "1804.08049", "submitter": "Afshin Rahimi", "authors": "Afshin Rahimi, Trevor Cohn, Timothy Baldwin", "title": "Semi-supervised User Geolocation via Graph Convolutional Networks", "comments": "ACL2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Social media user geolocation is vital to many applications such as event\ndetection. In this paper, we propose GCN, a multiview geolocation model based\non Graph Convolutional Networks, that uses both text and network context. We\ncompare GCN to the state-of-the-art, and to two baselines we propose, and show\nthat our model achieves or is competitive with the state- of-the-art over three\nbenchmark geolocation datasets when sufficient supervision is available. We\nalso evaluate GCN under a minimal supervision scenario, and show it outperforms\nbaselines. We find that highway network gates are essential for controlling the\namount of useful neighbourhood expansion in GCN.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 00:23:58 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 02:44:55 GMT"}, {"version": "v3", "created": "Sun, 13 May 2018 22:56:42 GMT"}, {"version": "v4", "created": "Tue, 15 May 2018 00:27:27 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Rahimi", "Afshin", ""], ["Cohn", "Trevor", ""], ["Baldwin", "Timothy", ""]]}, {"id": "1804.08050", "submitter": "Tomoki Hayashi", "authors": "Tomoki Hayashi, Shinji Watanabe, Tomoki Toda, Kazuya Takeda", "title": "Multi-Head Decoder for End-to-End Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new network architecture called multi-head decoder for\nend-to-end speech recognition as an extension of a multi-head attention model.\nIn the multi-head attention model, multiple attentions are calculated, and\nthen, they are integrated into a single attention. On the other hand, instead\nof the integration in the attention level, our proposed method uses multiple\ndecoders for each attention and integrates their outputs to generate a final\noutput. Furthermore, in order to make each head to capture the different\nmodalities, different attention functions are used for each head, leading to\nthe improvement of the recognition performance with an ensemble effect. To\nevaluate the effectiveness of our proposed method, we conduct an experimental\nevaluation using Corpus of Spontaneous Japanese. Experimental results\ndemonstrate that our proposed method outperforms the conventional methods such\nas location-based and multi-head attention models, and that it can capture\ndifferent speech/linguistic contexts within the attention-based encoder-decoder\nframework.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 00:28:23 GMT"}, {"version": "v2", "created": "Sat, 28 Jul 2018 05:31:32 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Hayashi", "Tomoki", ""], ["Watanabe", "Shinji", ""], ["Toda", "Tomoki", ""], ["Takeda", "Kazuya", ""]]}, {"id": "1804.08053", "submitter": "Tanner Bohn", "authors": "Tanner Bohn, Yining Hu, Jinhang Zhang, Charles X. Ling", "title": "Learning Sentence Embeddings for Coherence Modelling and Beyond", "comments": "Accepted for publication at RANLP 2019. 8 pages (10 with references),\n  4 Figures in the main text. This version contains significant improvements in\n  the algorithm and reports on a wider set of applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel and effective technique for performing text coherence\ntasks while facilitating deeper insights into the data. Despite obtaining\never-increasing task performance, modern deep-learning approaches to NLP tasks\noften only provide users with the final network decision and no additional\nunderstanding of the data. In this work, we show that a new type of sentence\nembedding learned through self-supervision can be applied effectively to text\ncoherence tasks while serving as a window through which deeper understanding of\nthe data can be obtained. To produce these sentence embeddings, we train a\nrecurrent neural network to take individual sentences and predict their\nlocation in a document in the form of a distribution over locations. We\ndemonstrate that these embeddings, combined with simple visual heuristics, can\nbe used to achieve performance competitive with state-of-the-art on multiple\ntext coherence tasks, outperforming more complex and specialized approaches.\nAdditionally, we demonstrate that these embeddings can provide insights useful\nto writers for improving writing quality and informing document structuring,\nand assisting readers in summarizing and locating information.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 01:02:23 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 20:23:30 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Bohn", "Tanner", ""], ["Hu", "Yining", ""], ["Zhang", "Jinhang", ""], ["Ling", "Charles X.", ""]]}, {"id": "1804.08057", "submitter": "Md Faisal Mahbub Chowdhury", "authors": "Md Faisal Mahbub Chowdhury and Vijil Chenthamarakshan and Rishav\n  Chakravarti and Alfio M. Gliozzo", "title": "A Study on Passage Re-ranking in Embedding based Unsupervised Semantic\n  Search", "comments": "Fixed latex compiling issues", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State of the art approaches for (embedding based) unsupervised semantic\nsearch exploits either compositional similarity (of a query and a passage) or\npair-wise word (or term) similarity (from the query and the passage). By\ndesign, word based approaches do not incorporate similarity in the larger\ncontext (query/passage), while compositional similarity based approaches are\nusually unable to take advantage of the most important cues in the context. In\nthis paper we propose a new compositional similarity based approach, called\nvariable centroid vector (VCVB), that tries to address both of these\nlimitations. We also presents results using a different type of compositional\nsimilarity based approach by exploiting universal sentence embedding. We\nprovide empirical evaluation on two different benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 02:20:32 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 17:14:06 GMT"}, {"version": "v3", "created": "Tue, 12 Mar 2019 15:49:13 GMT"}, {"version": "v4", "created": "Wed, 13 Mar 2019 17:06:22 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Chowdhury", "Md Faisal Mahbub", ""], ["Chenthamarakshan", "Vijil", ""], ["Chakravarti", "Rishav", ""], ["Gliozzo", "Alfio M.", ""]]}, {"id": "1804.08058", "submitter": "Xiao Yang", "authors": "Xiao Yang, Madian Khabsa, Miaosen Wang, Wei Wang, Madian Khabsa, Ahmed\n  Awadallah, Daniel Kifer, C. Lee Giles", "title": "Adversarial Training for Community Question Answer Selection Based on\n  Multi-scale Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community-based question answering (CQA) websites represent an important\nsource of information. As a result, the problem of matching the most valuable\nanswers to their corresponding questions has become an increasingly popular\nresearch topic. We frame this task as a binary (relevant/irrelevant)\nclassification problem, and present an adversarial training framework to\nalleviate label imbalance issue. We employ a generative model to iteratively\nsample a subset of challenging negative samples to fool our classification\nmodel. Both models are alternatively optimized using REINFORCE algorithm. The\nproposed method is completely different from previous ones, where negative\nsamples in training set are directly used or uniformly down-sampled. Further,\nwe propose using Multi-scale Matching which explicitly inspects the correlation\nbetween words and ngrams of different levels of granularity. We evaluate the\nproposed method on SemEval 2016 and SemEval 2017 datasets and achieves\nstate-of-the-art or similar performance.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 02:24:54 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 21:03:35 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Yang", "Xiao", ""], ["Khabsa", "Madian", ""], ["Wang", "Miaosen", ""], ["Wang", "Wei", ""], ["Khabsa", "Madian", ""], ["Awadallah", "Ahmed", ""], ["Kifer", "Daniel", ""], ["Giles", "C. Lee", ""]]}, {"id": "1804.08064", "submitter": "Young-Bum Kim", "authors": "Young-Bum Kim, Dongchan Kim, Joo-Kyung Kim, Ruhi Sarikaya", "title": "A Scalable Neural Shortlisting-Reranking Approach for Large-Scale Domain\n  Classification in Natural Language Understanding", "comments": "Accepted to NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent personal digital assistants (IPDAs), a popular real-life\napplication with spoken language understanding capabilities, can cover\npotentially thousands of overlapping domains for natural language\nunderstanding, and the task of finding the best domain to handle an utterance\nbecomes a challenging problem on a large scale. In this paper, we propose a set\nof efficient and scalable neural shortlisting-reranking models for large-scale\ndomain classification in IPDAs. The shortlisting stage focuses on efficiently\ntrimming all domains down to a list of k-best candidate domains, and the\nreranking stage performs a list-wise reranking of the initial k-best domains\nwith additional contextual information. We show the effectiveness of our\napproach with extensive experiments on 1,500 IPDA domains.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 03:56:39 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Kim", "Young-Bum", ""], ["Kim", "Dongchan", ""], ["Kim", "Joo-Kyung", ""], ["Sarikaya", "Ruhi", ""]]}, {"id": "1804.08065", "submitter": "Young-Bum Kim", "authors": "Young-Bum Kim, Dongchan Kim, Anjishnu Kumar, Ruhi Sarikaya", "title": "Efficient Large-Scale Domain Classification with Personalized Attention", "comments": "Accepted to ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore the task of mapping spoken language utterances to\none of thousands of natural language understanding domains in intelligent\npersonal digital assistants (IPDAs). This scenario is observed for many\nmainstream IPDAs in industry that allow third parties to develop thousands of\nnew domains to augment built-in ones to rapidly increase domain coverage and\noverall IPDA capabilities. We propose a scalable neural model architecture with\na shared encoder, a novel attention mechanism that incorporates personalization\ninformation and domain-specific classifiers that solves the problem\nefficiently. Our architecture is designed to efficiently accommodate new\ndomains that appear in-between full model retraining cycles with a rapid\nbootstrapping mechanism two orders of magnitude faster than retraining. We\naccount for practical constraints in real-time production systems, and design\nto minimize memory footprint and runtime latency. We demonstrate that\nincorporating personalization results in significantly more accurate domain\nclassification in the setting with thousands of overlapping domains.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 04:00:36 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Kim", "Young-Bum", ""], ["Kim", "Dongchan", ""], ["Kumar", "Anjishnu", ""], ["Sarikaya", "Ruhi", ""]]}, {"id": "1804.08069", "submitter": "Tiancheng Zhao", "authors": "Tiancheng Zhao, Kyusong Lee and Maxine Eskenazi", "title": "Unsupervised Discrete Sentence Representation Learning for Interpretable\n  Neural Dialog Generation", "comments": "Accepted as a long paper in ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The encoder-decoder dialog model is one of the most prominent methods used to\nbuild dialog systems in complex domains. Yet it is limited because it cannot\noutput interpretable actions as in traditional systems, which hinders humans\nfrom understanding its generation process. We present an unsupervised discrete\nsentence representation learning method that can integrate with any existing\nencoder-decoder dialog models for interpretable response generation. Building\nupon variational autoencoders (VAEs), we present two novel models, DI-VAE and\nDI-VST that improve VAEs and can discover interpretable semantics via either\nauto encoding or context predicting. Our methods have been validated on\nreal-world dialog datasets to discover semantic representations and enhance\nencoder-decoder models with interpretable generation.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 05:08:52 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Zhao", "Tiancheng", ""], ["Lee", "Kyusong", ""], ["Eskenazi", "Maxine", ""]]}, {"id": "1804.08077", "submitter": "Jordan Boyd-Graber", "authors": "Fenfei Guo, Mohit Iyyer, Jordan Boyd-Graber", "title": "Inducing and Embedding Senses with Scaled Gumbel Softmax", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for learning word sense embeddings represent a single word with\nmultiple sense-specific vectors. These methods should not only produce\ninterpretable sense embeddings, but should also learn how to select which sense\nto use in a given context. We propose an unsupervised model that learns sense\nembeddings using a modified Gumbel softmax function, which allows for\ndifferentiable discrete sense selection. Our model produces sense embeddings\nthat are competitive (and sometimes state of the art) on multiple similarity\nbased downstream evaluations. However, performance on these downstream\nevaluations tasks does not correlate with interpretability of sense embeddings,\nas we discover through an interpretability comparison with competing\nmulti-sense embeddings. While many previous approaches perform well on\ndownstream evaluations, they do not produce interpretable embeddings and learn\nduplicated sense groups; our method achieves the best of both worlds.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 07:12:05 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 16:29:22 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Guo", "Fenfei", ""], ["Iyyer", "Mohit", ""], ["Boyd-Graber", "Jordan", ""]]}, {"id": "1804.08094", "submitter": "Edison Marrese-Taylor", "authors": "Edison Marrese-Taylor, Suzana Ilic, Jorge A. Balazs, Yutaka Matsuo,\n  Helmut Prendinger", "title": "IIIDYT at SemEval-2018 Task 3: Irony detection in English tweets", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce our system for the task of Irony detection in\nEnglish tweets, a part of SemEval 2018. We propose representation learning\napproach that relies on a multi-layered bidirectional LSTM, without using\nexternal features that provide additional semantic information. Although our\nmodel is able to outperform the baseline in the validation set, our results\nshow limited generalization power over the test set. Given the limited size of\nthe dataset, we think the usage of more pre-training schemes would greatly\nimprove the obtained results.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 11:01:08 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Marrese-Taylor", "Edison", ""], ["Ilic", "Suzana", ""], ["Balazs", "Jorge A.", ""], ["Matsuo", "Yutaka", ""], ["Prendinger", "Helmut", ""]]}, {"id": "1804.08117", "submitter": "Masatoshi Tsuchiya", "authors": "Masatoshi Tsuchiya", "title": "Performance Impact Caused by Hidden Bias of Training Data for\n  Recognizing Textual Entailment", "comments": "Proceedings of the 11th International Conference on Language\n  Resources and Evaluation (LREC2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of training data is one of the crucial problems when a\nlearning-centered approach is employed. This paper proposes a new method to\ninvestigate the quality of a large corpus designed for the recognizing textual\nentailment (RTE) task. The proposed method, which is inspired by a statistical\nhypothesis test, consists of two phases: the first phase is to introduce the\npredictability of textual entailment labels as a null hypothesis which is\nextremely unacceptable if a target corpus has no hidden bias, and the second\nphase is to test the null hypothesis using a Naive Bayes model. The\nexperimental result of the Stanford Natural Language Inference (SNLI) corpus\ndoes not reject the null hypothesis. Therefore, it indicates that the SNLI\ncorpus has a hidden bias which allows prediction of textual entailment labels\nfrom hypothesis sentences even if no context information is given by a premise\nsentence. This paper also presents the performance impact of NN models for RTE\ncaused by this hidden bias.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 14:26:28 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Tsuchiya", "Masatoshi", ""]]}, {"id": "1804.08125", "submitter": "Jeff Mitchell", "authors": "Jeff Mitchell, Sebastian Riedel", "title": "Reduce, Reuse, Recycle: New uses for old QA resources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate applying repurposed generic QA data and models to a recently\nproposed relation extraction task. We find that training on SQuAD produces\nbetter zero-shot performance and more robust generalisation compared to the\ntask specific training set. We also show that standard QA architectures (e.g.\nFastQA or BiDAF) can be applied to the slot filling queries without the need\nfor model modification.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 15:44:17 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 14:59:33 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Mitchell", "Jeff", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1804.08139", "submitter": "Xipeng Qiu", "authors": "Renjie Zheng, Junkun Chen, Xipeng Qiu", "title": "Same Representation, Different Attentions: Shareable Sentence\n  Representation Learning from Multiple Tasks", "comments": "7 pages", "journal-ref": "IJCAI 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed representation plays an important role in deep learning based\nnatural language processing. However, the representation of a sentence often\nvaries in different tasks, which is usually learned from scratch and suffers\nfrom the limited amounts of training data. In this paper, we claim that a good\nsentence representation should be invariant and can benefit the various\nsubsequent tasks. To achieve this purpose, we propose a new scheme of\ninformation sharing for multi-task learning. More specifically, all tasks share\nthe same sentence representation and each task can select the task-specific\ninformation from the shared sentence representation with attention mechanism.\nThe query vector of each task's attention could be either static parameters or\ngenerated dynamically. We conduct extensive experiments on 16 different text\nclassification tasks, which demonstrate the benefits of our architecture.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 17:13:06 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Zheng", "Renjie", ""], ["Chen", "Junkun", ""], ["Qiu", "Xipeng", ""]]}, {"id": "1804.08166", "submitter": "Dongxu Zhang", "authors": "Dongxu Zhang and Zhichao Yang", "title": "Word Embedding Perturbation for Sentence Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this technique report, we aim to mitigate the overfitting problem of\nnatural language by applying data augmentation methods. Specifically, we\nattempt several types of noise to perturb the input word embedding, such as\nGaussian noise, Bernoulli noise, and adversarial noise, etc. We also apply\nseveral constraints on different types of noise. By implementing these proposed\ndata augmentation methods, the baseline models can gain improvements on several\nsentence classification tasks.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 20:42:13 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Zhang", "Dongxu", ""], ["Yang", "Zhichao", ""]]}, {"id": "1804.08186", "submitter": "Marcos Zampieri", "authors": "Tommi Jauhiainen, Marco Lui, Marcos Zampieri, Timothy Baldwin, Krister\n  Lind\\'en", "title": "Automatic Language Identification in Texts: A Survey", "comments": "Under review at JAIR - Journal of Artificial Intelligence Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language identification (LI) is the problem of determining the natural\nlanguage that a document or part thereof is written in. Automatic LI has been\nextensively researched for over fifty years. Today, LI is a key part of many\ntext processing pipelines, as text processing techniques generally assume that\nthe language of the input text is known. Research in this area has recently\nbeen especially active. This article provides a brief history of LI research,\nand an extensive survey of the features and methods used so far in the LI\nliterature. For describing the features and methods we introduce a unified\nnotation. We discuss evaluation methods, applications of LI, as well as\noff-the-shelf LI systems that do not require training by the end user. Finally,\nwe identify open issues, survey the work to date on each issue, and propose\nfuture directions for research in LI.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 22:30:30 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 11:43:29 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Jauhiainen", "Tommi", ""], ["Lui", "Marco", ""], ["Zampieri", "Marcos", ""], ["Baldwin", "Timothy", ""], ["Lind\u00e9n", "Krister", ""]]}, {"id": "1804.08198", "submitter": "Phillip Keung", "authors": "Yichao Lu, Phillip Keung, Faisal Ladhak, Vikas Bhardwaj, Shaonan\n  Zhang, Jason Sun", "title": "A neural interlingua for multilingual machine translation", "comments": "Accepted in WMT 18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We incorporate an explicit neural interlingua into a multilingual\nencoder-decoder neural machine translation (NMT) architecture. We demonstrate\nthat our model learns a language-independent representation by performing\ndirect zero-shot translation (without using pivot translation), and by using\nthe source sentence embeddings to create an English Yelp review classifier\nthat, through the mediation of the neural interlingua, can also classify French\nand German reviews. Furthermore, we show that, despite using a smaller number\nof parameters than a pairwise collection of bilingual NMT models, our approach\nproduces comparable BLEU scores for each language pair in WMT15.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 00:21:37 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 20:44:27 GMT"}, {"version": "v3", "created": "Tue, 16 Oct 2018 09:33:54 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Lu", "Yichao", ""], ["Keung", "Phillip", ""], ["Ladhak", "Faisal", ""], ["Bhardwaj", "Vikas", ""], ["Zhang", "Shaonan", ""], ["Sun", "Jason", ""]]}, {"id": "1804.08199", "submitter": "Emma Strubell", "authors": "Emma Strubell, Patrick Verga, Daniel Andor, David Weiss, Andrew\n  McCallum", "title": "Linguistically-Informed Self-Attention for Semantic Role Labeling", "comments": "In Conference on Empirical Methods in Natural Language Processing\n  (EMNLP). Brussels, Belgium. October 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current state-of-the-art semantic role labeling (SRL) uses a deep neural\nnetwork with no explicit linguistic features. However, prior work has shown\nthat gold syntax trees can dramatically improve SRL decoding, suggesting the\npossibility of increased accuracy from explicit modeling of syntax. In this\nwork, we present linguistically-informed self-attention (LISA): a neural\nnetwork model that combines multi-head self-attention with multi-task learning\nacross dependency parsing, part-of-speech tagging, predicate detection and SRL.\nUnlike previous models which require significant pre-processing to prepare\nlinguistic features, LISA can incorporate syntax using merely raw tokens as\ninput, encoding the sequence only once to simultaneously perform parsing,\npredicate detection and role labeling for all predicates. Syntax is\nincorporated by training one attention head to attend to syntactic parents for\neach token. Moreover, if a high-quality syntactic parse is already available,\nit can be beneficially injected at test time without re-training our SRL model.\nIn experiments on CoNLL-2005 SRL, LISA achieves new state-of-the-art\nperformance for a model using predicted predicates and standard word\nembeddings, attaining 2.5 F1 absolute higher than the previous state-of-the-art\non newswire and more than 3.5 F1 on out-of-domain data, nearly 10% reduction in\nerror. On ConLL-2012 English SRL we also show an improvement of more than 2.5\nF1. LISA also out-performs the state-of-the-art with contextually-encoded\n(ELMo) word representations, by nearly 1.0 F1 on news and more than 2.0 F1 on\nout-of-domain text.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 00:21:49 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 00:03:58 GMT"}, {"version": "v3", "created": "Mon, 12 Nov 2018 15:07:24 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Strubell", "Emma", ""], ["Verga", "Patrick", ""], ["Andor", "Daniel", ""], ["Weiss", "David", ""], ["McCallum", "Andrew", ""]]}, {"id": "1804.08204", "submitter": "Jatin Ganhotra", "authors": "Jatin Ganhotra, Lazaros Polymenakos", "title": "Knowledge-based end-to-end memory networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  End-to-end dialog systems have become very popular because they hold the\npromise of learning directly from human to human dialog interaction. Retrieval\nand Generative methods have been explored in this area with mixed results. A\nkey element that is missing so far, is the incorporation of a-priori knowledge\nabout the task at hand. This knowledge may exist in the form of structured or\nunstructured information. As a first step towards this direction, we present a\nnovel approach, Knowledge based end-to-end memory networks (KB-memN2N), which\nallows special handling of named entities for goal-oriented dialog tasks. We\npresent results on two datasets, DSTC6 challenge dataset and dialog bAbI tasks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 00:47:48 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Ganhotra", "Jatin", ""], ["Polymenakos", "Lazaros", ""]]}, {"id": "1804.08205", "submitter": "Sabrina Mielke", "authors": "Sabrina J. Mielke and Jason Eisner", "title": "Spell Once, Summon Anywhere: A Two-Level Open-Vocabulary Language Model", "comments": "Accepted for publication at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how the spellings of known words can help us deal with unknown words\nin open-vocabulary NLP tasks. The method we propose can be used to extend any\nclosed-vocabulary generative model, but in this paper we specifically consider\nthe case of neural language modeling. Our Bayesian generative story combines a\nstandard RNN language model (generating the word tokens in each sentence) with\nan RNN-based spelling model (generating the letters in each word type). These\ntwo RNNs respectively capture sentence structure and word structure, and are\nkept separate as in linguistics. By invoking the second RNN to generate\nspellings for novel words in context, we obtain an open-vocabulary language\nmodel. For known words, embeddings are naturally inferred by combining evidence\nfrom type spelling and token context. Comparing to baselines (including a novel\nstrong baseline), we beat previous work and establish state-of-the-art results\non multiple datasets.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 00:56:23 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 18:26:20 GMT"}, {"version": "v3", "created": "Fri, 23 Nov 2018 21:52:46 GMT"}, {"version": "v4", "created": "Tue, 25 Feb 2020 18:27:08 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Mielke", "Sabrina J.", ""], ["Eisner", "Jason", ""]]}, {"id": "1804.08207", "submitter": "Adam Poliak", "authors": "Adam Poliak, Aparajita Haldar, Rachel Rudinger, J. Edward Hu, Ellie\n  Pavlick, Aaron Steven White, Benjamin Van Durme", "title": "Collecting Diverse Natural Language Inference Problems for Sentence\n  Representation Evaluation", "comments": "To be presented at EMNLP 2018. 15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a large-scale collection of diverse natural language inference\n(NLI) datasets that help provide insight into how well a sentence\nrepresentation captures distinct types of reasoning. The collection results\nfrom recasting 13 existing datasets from 7 semantic phenomena into a common NLI\nstructure, resulting in over half a million labeled context-hypothesis pairs in\ntotal. We refer to our collection as the DNC: Diverse Natural Language\nInference Collection. The DNC is available online at https://www.decomp.net,\nand will grow over time as additional resources are recast and added from novel\nsources.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 01:03:46 GMT"}, {"version": "v2", "created": "Wed, 29 Aug 2018 15:40:37 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Poliak", "Adam", ""], ["Haldar", "Aparajita", ""], ["Rudinger", "Rachel", ""], ["Hu", "J. Edward", ""], ["Pavlick", "Ellie", ""], ["White", "Aaron Steven", ""], ["Van Durme", "Benjamin", ""]]}, {"id": "1804.08217", "submitter": "Chien-Sheng Wu", "authors": "Andrea Madotto and Chien-Sheng Wu and Pascale Fung", "title": "Mem2Seq: Effectively Incorporating Knowledge Bases into End-to-End\n  Task-Oriented Dialog Systems", "comments": "Accepted by the Association for Computational Linguistics (ACL) 2018.\n  Andrea Madotto* and Chien-Sheng Wu* contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end task-oriented dialog systems usually suffer from the challenge of\nincorporating knowledge bases. In this paper, we propose a novel yet simple\nend-to-end differentiable model called memory-to-sequence (Mem2Seq) to address\nthis issue. Mem2Seq is the first neural generative model that combines the\nmulti-hop attention over memories with the idea of pointer network. We\nempirically show how Mem2Seq controls each generation step, and how its\nmulti-hop attention mechanism helps in learning correlations between memories.\nIn addition, our model is quite general without complicated task-specific\ndesigns. As a result, we show that Mem2Seq can be trained faster and attain the\nstate-of-the-art performance on three different task-oriented dialog datasets.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 01:46:13 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 09:15:07 GMT"}, {"version": "v3", "created": "Mon, 21 May 2018 01:54:41 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Madotto", "Andrea", ""], ["Wu", "Chien-Sheng", ""], ["Fung", "Pascale", ""]]}, {"id": "1804.08228", "submitter": "Yijia Liu", "authors": "Yijia Liu, Yi Zhu, Wanxiang Che, Bing Qin, Nathan Schneider, Noah A.\n  Smith", "title": "Parsing Tweets into Universal Dependencies", "comments": "To be presented at NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of analyzing tweets with Universal Dependencies. We\nextend the UD guidelines to cover special constructions in tweets that affect\ntokenization, part-of-speech tagging, and labeled dependencies. Using the\nextended guidelines, we create a new tweet treebank for English (Tweebank v2)\nthat is four times larger than the (unlabeled) Tweebank v1 introduced by Kong\net al. (2014). We characterize the disagreements between our annotators and\nshow that it is challenging to deliver consistent annotation due to ambiguity\nin understanding and explaining tweets. Nonetheless, using the new treebank, we\nbuild a pipeline system to parse raw tweets into UD. To overcome annotation\nnoise without sacrificing computational efficiency, we propose a new method to\ndistill an ensemble of 20 transition-based parsers into a single one. Our\nparser achieves an improvement of 2.2 in LAS over the un-ensembled baseline and\noutperforms parsers that are state-of-the-art on other treebanks in both\naccuracy and speed.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 02:38:20 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Liu", "Yijia", ""], ["Zhu", "Yi", ""], ["Che", "Wanxiang", ""], ["Qin", "Bing", ""], ["Schneider", "Nathan", ""], ["Smith", "Noah A.", ""]]}, {"id": "1804.08234", "submitter": "Muhmmad Al-Khiza'ay", "authors": "Muhmmad Al-Khiza'ay, Noora Alallaq, Qusay Alanoz, Adil Al-Azzawi,\n  N.Maheswari", "title": "PeRView: A Framework for Personalized Review Selection Using\n  Micro-Reviews", "comments": "27 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the contemporary era, social media has its influence on people in making\ndecisions. The proliferation of online reviews with diversified and verbose\ncontent often causes problems inaccurate decision making. Since online reviews\nhave an impact on people of all walks of life while taking decisions, choosing\nappropriate reviews based on the podsolization consisting is very important\nsince it relies on using such micro-reviews consistency to evaluate the review\nset section. Micro-reviews are very concise and directly talk about product or\nservice instead of having unnecessary verbose content. Thus, micro-reviews can\nhelp in choosing reviews based on their personalized consistency that is\nrelated to directly or indirectly to the main profile of the reviews.\nPersonalized reviews selection that is highly relevant with high personalized\ncoverage in terms of matching with micro-reviews is the main problem that is\nconsidered in this paper. Furthermore, personalization with user preferences\nwhile making review selection is also considered based on the personalized\nusers' profile. Towards this end, we proposed a framework known as PeRView for\npersonalized review selection using micro-reviews based on the proposed\nevaluation metric approach which considering two main factors (personalized\nmatching score and subset size). Personalized Review Selection Algorithm (PRSA)\nis proposed which makes use of multiple similarity measures merged to have\nhighly efficient personalized reviews matching function for selection. The\nexperimental results based on using reviews dataset which is collected from\nYELP.COM while micro-reviews dataset is obtained from Foursqure.COM. show that\nthe personalized reviews selection is a very empirical case of study.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 03:07:45 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Al-Khiza'ay", "Muhmmad", ""], ["Alallaq", "Noora", ""], ["Alanoz", "Qusay", ""], ["Al-Azzawi", "Adil", ""], ["Maheswari", "N.", ""]]}, {"id": "1804.08261", "submitter": "Zhongliang Yang", "authors": "Zhongliang Yang, Yongfeng Huang, Yiran Jiang, Yuxi Sun, Yu-Jin Zhan,\n  Pengcheng Luo", "title": "Clinical Assistant Diagnosis for Electronic Medical Record Based on\n  Convolutional Neural Network", "comments": "9 pages, 4 figures, Accepted by Scientific Reports", "journal-ref": null, "doi": "10.1038/s41598-018-24389-w", "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically extracting useful information from electronic medical records\nalong with conducting disease diagnoses is a promising task for both clinical\ndecision support(CDS) and neural language processing(NLP). Most of the existing\nsystems are based on artificially constructed knowledge bases, and then\nauxiliary diagnosis is done by rule matching. In this study, we present a\nclinical intelligent decision approach based on Convolutional Neural\nNetworks(CNN), which can automatically extract high-level semantic information\nof electronic medical records and then perform automatic diagnosis without\nartificial construction of rules or knowledge bases. We use collected 18,590\ncopies of the real-world clinical electronic medical records to train and test\nthe proposed model. Experimental results show that the proposed model can\nachieve 98.67\\% accuracy and 96.02\\% recall, which strongly supports that using\nconvolutional neural network to automatically learn high-level semantic\nfeatures of electronic medical records and then conduct assist diagnosis is\nfeasible and effective.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 06:52:13 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Yang", "Zhongliang", ""], ["Huang", "Yongfeng", ""], ["Jiang", "Yiran", ""], ["Sun", "Yuxi", ""], ["Zhan", "Yu-Jin", ""], ["Luo", "Pengcheng", ""]]}, {"id": "1804.08262", "submitter": "Jason Eisner", "authors": "Ryan Cotterell, Christo Kirov, Mans Hulden, Jason Eisner", "title": "On the Diachronic Stability of Irregularity in Inflectional Morphology", "comments": "accepted to NAACL 2018; withdrawn in order to add more thorough\n  experiments (coming in next version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many languages' inflectional morphological systems are replete with\nirregulars, i.e., words that do not seem to follow standard inflectional rules.\nIn this work, we quantitatively investigate the conditions under which\nirregulars can survive in a language over the course of time. Using recurrent\nneural networks to simulate language learners, we test the diachronic relation\nbetween frequency of words and their irregularity.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 07:01:52 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Cotterell", "Ryan", ""], ["Kirov", "Christo", ""], ["Hulden", "Mans", ""], ["Eisner", "Jason", ""]]}, {"id": "1804.08266", "submitter": "Timothy Niven", "authors": "Tim Niven, Hung-Yu Kao", "title": "NLITrans at SemEval-2018 Task 12: Transfer of Semantic Knowledge for\n  Argument Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Argument Reasoning Comprehension Task requires significant language\nunderstanding and complex reasoning over world knowledge. We focus on transfer\nof a sentence encoder to bootstrap more complicated models given the small size\nof the dataset. Our best model uses a pre-trained BiLSTM to encode input\nsentences, learns task-specific features for the argument and warrants, then\nperforms independent argument-warrant matching. This model achieves mean test\nset accuracy of 64.43%. Encoder transfer yields a significant gain to our best\nmodel over random initialization. Independent warrant matching effectively\ndoubles the size of the dataset and provides additional regularization. We\ndemonstrate that regularization comes from ignoring statistical correlations\nbetween warrant features and position. We also report an experiment with our\nbest model that only matches warrants to reasons, ignoring claims. Relatively\nlow performance degradation suggests that our model is not necessarily learning\nthe intended task.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 07:21:21 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Niven", "Tim", ""], ["Kao", "Hung-Yu", ""]]}, {"id": "1804.08280", "submitter": "Ji Ho Park", "authors": "Ji Ho Park, Peng Xu, Pascale Fung", "title": "PlusEmo2Vec at SemEval-2018 Task 1: Exploiting emotion knowledge from\n  emoji and #hashtags", "comments": "9 pages, Accepted to SemEval 2018 Task 1: Affects in Tweets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our system that has been submitted to SemEval-2018 Task\n1: Affect in Tweets (AIT) to solve five subtasks. We focus on modeling both\nsentence and word level representations of emotion inside texts through large\ndistantly labeled corpora with emojis and hashtags. We transfer the emotional\nknowledge by exploiting neural network models as feature extractors and use\nthese representations for traditional machine learning models such as support\nvector regression (SVR) and logistic regression to solve the competition tasks.\nOur system is placed among the Top3 for all subtasks we participated.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 08:30:46 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Park", "Ji Ho", ""], ["Xu", "Peng", ""], ["Fung", "Pascale", ""]]}, {"id": "1804.08313", "submitter": "Jasmijn Bastings", "authors": "Diego Marcheggiani, Jasmijn Bastings, Ivan Titov", "title": "Exploiting Semantics in Neural Machine Translation with Graph\n  Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic representations have long been argued as potentially useful for\nenforcing meaning preservation and improving generalization performance of\nmachine translation methods. In this work, we are the first to incorporate\ninformation about predicate-argument structure of source sentences (namely,\nsemantic-role representations) into neural machine translation. We use Graph\nConvolutional Networks (GCNs) to inject a semantic bias into sentence encoders\nand achieve improvements in BLEU scores over the linguistic-agnostic and\nsyntax-aware versions on the English--German language pair.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 09:54:29 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 11:19:50 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Marcheggiani", "Diego", ""], ["Bastings", "Jasmijn", ""], ["Titov", "Ivan", ""]]}, {"id": "1804.08316", "submitter": "Josu Goikoetxea", "authors": "J.Goikoetxea, A.Soroa, E.Agirre", "title": "Bilingual Embeddings with Random Walks over Multilingual Wordnets", "comments": "Preprint version, Knowledge-Based Systems (ISSN: 0950-7051). (2018)", "journal-ref": null, "doi": "10.1016/j.knosys.2018.03.017", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilingual word embeddings represent words of two languages in the same space,\nand allow to transfer knowledge from one language to the other without machine\ntranslation. The main approach is to train monolingual embeddings first and\nthen map them using bilingual dictionaries. In this work, we present a novel\nmethod to learn bilingual embeddings based on multilingual knowledge bases (KB)\nsuch as WordNet. Our method extracts bilingual information from multilingual\nwordnets via random walks and learns a joint embedding space in one go. We\nfurther reinforce cross-lingual equivalence adding bilingual con- straints in\nthe loss function of the popular skipgram model. Our experiments involve twelve\ncross-lingual word similarity and relatedness datasets in six lan- guage pairs\ncovering four languages, and show that: 1) random walks over mul- tilingual\nwordnets improve results over just using dictionaries; 2) multilingual wordnets\non their own improve over text-based systems in similarity datasets; 3) the\ngood results are consistent for large wordnets (e.g. English, Spanish), smaller\nwordnets (e.g. Basque) or loosely aligned wordnets (e.g. Italian); 4) the\ncombination of wordnets and text yields the best results, above mapping-based\napproaches. Our method can be applied to richer KBs like DBpedia or Babel- Net,\nand can be easily extended to multilingual embeddings. All software and\nresources are open source.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 10:02:29 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Goikoetxea", "J.", ""], ["Soroa", "A.", ""], ["Agirre", "E.", ""]]}, {"id": "1804.08338", "submitter": "Duyu Tang", "authors": "Yibo Sun, Duyu Tang, Nan Duan, Jianshu Ji, Guihong Cao, Xiaocheng\n  Feng, Bing Qin, Ting Liu, Ming Zhou", "title": "Semantic Parsing with Syntax- and Table-Aware SQL Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a generative model to map natural language questions into SQL\nqueries. Existing neural network based approaches typically generate a SQL\nquery word-by-word, however, a large portion of the generated results are\nincorrect or not executable due to the mismatch between question words and\ntable contents. Our approach addresses this problem by considering the\nstructure of table and the syntax of SQL language. The quality of the generated\nSQL query is significantly improved through (1) learning to replicate content\nfrom column names, cells or SQL keywords; and (2) improving the generation of\nWHERE clause by leveraging the column-cell relation. Experiments are conducted\non WikiSQL, a recently released dataset with the largest question-SQL pairs.\nOur approach significantly improves the state-of-the-art execution accuracy\nfrom 69.0% to 74.4%.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 11:18:47 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Sun", "Yibo", ""], ["Tang", "Duyu", ""], ["Duan", "Nan", ""], ["Ji", "Jianshu", ""], ["Cao", "Guihong", ""], ["Feng", "Xiaocheng", ""], ["Qin", "Bing", ""], ["Liu", "Ting", ""], ["Zhou", "Ming", ""]]}, {"id": "1804.08420", "submitter": "Qiang Ning", "authors": "Qiang Ning, Zhongzhi Yu, Chuchu Fan, Dan Roth", "title": "Exploiting Partially Annotated Data for Temporal Relation Extraction", "comments": "[Final Version] short paper accepted by *SEM'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Annotating temporal relations (TempRel) between events described in natural\nlanguage is known to be labor intensive, partly because the total number of\nTempRels is quadratic in the number of events. As a result, only a small number\nof documents are typically annotated, limiting the coverage of various\nlexical/semantic phenomena. In order to improve existing approaches, one\npossibility is to make use of the readily available, partially annotated data\n(P as in partial) that cover more documents. However, missing annotations in P\nare known to hurt, rather than help, existing systems. This work is a case\nstudy in exploring various usages of P for TempRel extraction. Results show\nthat despite missing annotations, P is still a useful supervision signal for\nthis task within a constrained bootstrapping learning framework. The system\ndescribed in this system is publicly available.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 21:33:00 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2018 02:31:40 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Ning", "Qiang", ""], ["Yu", "Zhongzhi", ""], ["Fan", "Chuchu", ""], ["Roth", "Dan", ""]]}, {"id": "1804.08426", "submitter": "G\\\"unter Neumann GN", "authors": "Tyler Renslow and G\\\"unter Neumann", "title": "LightRel SemEval-2018 Task 7: Lightweight and Fast Relation\n  Classification", "comments": "SemEval-2018 task 7 Semantic Relation Extraction and Classification\n  in Scientific Papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present LightRel, a lightweight and fast relation classifier. Our goal is\nto develop a high baseline for different relation extraction tasks. By defining\nonly very few data-internal, word-level features and external knowledge sources\nin the form of word clusters and word embeddings, we train a fast and simple\nlinear classifier.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 09:42:01 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Renslow", "Tyler", ""], ["Neumann", "G\u00fcnter", ""]]}, {"id": "1804.08438", "submitter": "Tomi Kinnunen", "authors": "Tomi Kinnunen, Jaime Lorenzo-Trueba, Junichi Yamagishi, Tomoki Toda,\n  Daisuke Saito, Fernando Villavicencio, Zhenhua Ling", "title": "A Spoofing Benchmark for the 2018 Voice Conversion Challenge: Leveraging\n  from Spoofing Countermeasures for Speech Artifact Assessment", "comments": "Correction (bug fix) of a published ODYSSEY 2018 publication with the\n  same title and author list; more details in footnote in page 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice conversion (VC) aims at conversion of speaker characteristic without\naltering content. Due to training data limitations and modeling imperfections,\nit is difficult to achieve believable speaker mimicry without introducing\nprocessing artifacts; performance assessment of VC, therefore, usually involves\nboth speaker similarity and quality evaluation by a human panel. As a\ntime-consuming, expensive, and non-reproducible process, it hinders rapid\nprototyping of new VC technology. We address artifact assessment using an\nalternative, objective approach leveraging from prior work on spoofing\ncountermeasures (CMs) for automatic speaker verification. Therein, CMs are used\nfor rejecting `fake' inputs such as replayed, synthetic or converted speech but\ntheir potential for automatic speech artifact assessment remains unknown. This\nstudy serves to fill that gap. As a supplement to subjective results for the\n2018 Voice Conversion Challenge (VCC'18) data, we configure a standard\nconstant-Q cepstral coefficient CM to quantify the extent of processing\nartifacts. Equal error rate (EER) of the CM, a confusability index of VC\nsamples with real human speech, serves as our artifact measure. Two clusters of\nVCC'18 entries are identified: low-quality ones with detectable artifacts (low\nEERs), and higher quality ones with less artifacts. None of the VCC'18 systems,\nhowever, is perfect: all EERs are < 30 % (the `ideal' value would be 50 %). Our\npreliminary findings suggest potential of CMs outside of their original\napplication, as a supplemental optimization and benchmarking tool to enhance VC\ntechnology.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 13:54:47 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 17:14:57 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Kinnunen", "Tomi", ""], ["Lorenzo-Trueba", "Jaime", ""], ["Yamagishi", "Junichi", ""], ["Toda", "Tomoki", ""], ["Saito", "Daisuke", ""], ["Villavicencio", "Fernando", ""], ["Ling", "Zhenhua", ""]]}, {"id": "1804.08454", "submitter": "Akilesh Badrinaaraayanan", "authors": "Akilesh B, Abhishek Sinha, Mausoom Sarkar, Balaji Krishnamurthy", "title": "Attention Based Natural Language Grounding by Navigating Virtual\n  Environment", "comments": "Accepted at WACV 2019. Also at NeurIPS 2017 workshop on\n  Visually-Grounded Interaction and Language (ViGIL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we focus on the problem of grounding language by training an\nagent to follow a set of natural language instructions and navigate to a target\nobject in an environment. The agent receives visual information through raw\npixels and a natural language instruction telling what task needs to be\nachieved and is trained in an end-to-end way. We develop an attention mechanism\nfor multi-modal fusion of visual and textual modalities that allows the agent\nto learn to complete the task and achieve language grounding. Our experimental\nresults show that our attention mechanism outperforms the existing multi-modal\nfusion mechanisms proposed for both 2D and 3D environments in order to solve\nthe above-mentioned task in terms of both speed and success rate. We show that\nthe learnt textual representations are semantically meaningful as they follow\nvector arithmetic in the embedding space. The effectiveness of our attention\napproach over the contemporary fusion mechanisms is also highlighted from the\ntextual embeddings learnt by the different approaches. We also show that our\nmodel generalizes effectively to unseen scenarios and exhibit zero-shot\ngeneralization capabilities both in 2D and 3D environments. The code for our 2D\nenvironment as well as the models that we developed for both 2D and 3D are\navailable at https://github.com/rl-lang-grounding/rl-lang-ground.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 14:11:17 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 19:00:54 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["B", "Akilesh", ""], ["Sinha", "Abhishek", ""], ["Sarkar", "Mausoom", ""], ["Krishnamurthy", "Balaji", ""]]}, {"id": "1804.08460", "submitter": "Daniil Sorokin", "authors": "Daniil Sorokin, Iryna Gurevych", "title": "Mixing Context Granularities for Improved Entity Linking on Question\n  Answering Data across Entity Categories", "comments": "Accepted as *SEM 2018 Long Paper (co-located with NAACL 2018), 9\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first stage of every knowledge base question answering approach is to\nlink entities in the input question. We investigate entity linking in the\ncontext of a question answering task and present a jointly optimized neural\narchitecture for entity mention detection and entity disambiguation that models\nthe surrounding context on different levels of granularity. We use the Wikidata\nknowledge base and available question answering datasets to create benchmarks\nfor entity linking on question answering data. Our approach outperforms the\nprevious state-of-the-art system on this data, resulting in an average 8%\nimprovement of the final score. We further demonstrate that our model delivers\na strong performance across different entity categories.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 14:22:21 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Sorokin", "Daniil", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1804.08477", "submitter": "Laurent Besacier", "authors": "Zied Elloumi and Laurent Besacier and Olivier Galibert and Juliette\n  Kahn and Benjamin Lecouteux", "title": "ASR Performance Prediction on Unseen Broadcast Programs using\n  Convolutional Neural Networks", "comments": "IEEE ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we address a relatively new task: prediction of ASR\nperformance on unseen broadcast programs. We first propose an heterogenous\nFrench corpus dedicated to this task. Two prediction approaches are compared: a\nstate-of-the-art performance prediction based on regression (engineered\nfeatures) and a new strategy based on convolutional neural networks (learnt\nfeatures). We particularly focus on the combination of both textual (ASR\ntranscription) and signal inputs. While the joint use of textual and signal\nfeatures did not work for the regression baseline, the combination of inputs\nfor CNNs leads to the best WER prediction performance. We also show that our\nCNN prediction remarkably predicts the WER distribution on a collection of\nspeech recordings.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 14:42:12 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Elloumi", "Zied", ""], ["Besacier", "Laurent", ""], ["Galibert", "Olivier", ""], ["Kahn", "Juliette", ""], ["Lecouteux", "Benjamin", ""]]}, {"id": "1804.08559", "submitter": "Srijan Kumar", "authors": "Srijan Kumar, Neil Shah", "title": "False Information on Web and Social Media: A Survey", "comments": "To appear in the book titled Social Media Analytics: Advances and\n  Applications, by CRC press, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  False information can be created and spread easily through the web and social\nmedia platforms, resulting in widespread real-world impact. Characterizing how\nfalse information proliferates on social platforms and why it succeeds in\ndeceiving readers are critical to develop efficient detection algorithms and\ntools for early detection. A recent surge of research in this area has aimed to\naddress the key issues using methods based on feature engineering, graph\nmining, and information modeling. Majority of the research has primarily\nfocused on two broad categories of false information: opinion-based (e.g., fake\nreviews), and fact-based (e.g., false news and hoaxes). Therefore, in this\nwork, we present a comprehensive survey spanning diverse aspects of false\ninformation, namely (i) the actors involved in spreading false information,\n(ii) rationale behind successfully deceiving readers, (iii) quantifying the\nimpact of false information, (iv) measuring its characteristics across\ndifferent dimensions, and finally, (iv) algorithms developed to detect false\ninformation. In doing so, we create a unified framework to describe these\nrecent methods and highlight a number of important directions for future\nresearch.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 16:52:49 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Kumar", "Srijan", ""], ["Shah", "Neil", ""]]}, {"id": "1804.08666", "submitter": "Skyler Wharton", "authors": "Christopher Mitcheltree, Skyler Wharton, and Avneesh Saluja", "title": "Using Aspect Extraction Approaches to Generate Review Summaries and User\n  Profiles", "comments": "Equal contribution from first two authors. Accepted for publication\n  in the NAACL 2018 Industry Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reviews of products or services on Internet marketplace websites contain a\nrich amount of information. Users often wish to survey reviews or review\nsnippets from the perspective of a certain aspect, which has resulted in a\nlarge body of work on aspect identification and extraction from such corpora.\nIn this work, we evaluate a newly-proposed neural model for aspect extraction\non two practical tasks. The first is to extract canonical sentences of various\naspects from reviews, and is judged by human evaluators against alternatives. A\n$k$-means baseline does remarkably well in this setting. The second experiment\nfocuses on the suitability of the recovered aspect distributions to represent\nusers by the reviews they have written. Through a set of review reranking\nexperiments, we find that aspect-based profiles can largely capture notions of\nuser preferences, by showing that divergent users generate markedly different\nreview rankings.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 18:52:50 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 01:45:20 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Mitcheltree", "Christopher", ""], ["Wharton", "Skyler", ""], ["Saluja", "Avneesh", ""]]}, {"id": "1804.08675", "submitter": "Aniket Jain", "authors": "Aniket Jain, Bhavya Sharma, Paridhi Choudhary, Rohan Sangave, William\n  Yang", "title": "Data-Driven Investigative Journalism For Connectas Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The following paper explores the possibility of using Machine Learning\nalgorithms to detect the cases of corruption and malpractice by governments.\nThe dataset used by the authors contains information about several government\ncontracts in Colombia from year 2007 to 2012. The authors begin with exploring\nand cleaning the data, followed by which they perform feature engineering\nbefore finally implementing Machine Learning models to detect anomalies in the\ngiven dataset.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 19:15:45 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Jain", "Aniket", ""], ["Sharma", "Bhavya", ""], ["Choudhary", "Paridhi", ""], ["Sangave", "Rohan", ""], ["Yang", "William", ""]]}, {"id": "1804.08749", "submitter": "Amir Bakarov", "authors": "Amir Bakarov", "title": "Can Eye Movement Data Be Used As Ground Truth For Word Embeddings\n  Evaluation?", "comments": "1st Workshop on Linguistic and Neuro-Cognitive Resources (LiNCR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years a certain success in the task of modeling lexical semantics\nwas obtained with distributional semantic models. Nevertheless, the scientific\ncommunity is still unaware what is the most reliable evaluation method for\nthese models. Some researchers argue that the only possible gold standard could\nbe obtained from neuro-cognitive resources that store information about human\ncognition. One of such resources is eye movement data on silent reading. The\ngoal of this work is to test the hypothesis of whether such data could be used\nto evaluate distributional semantic models on different languages. We propose\nexperiments with English and Russian eye movement datasets (Provo Corpus, GECO\nand Russian Sentence Corpus), word vectors (Skip-Gram models trained on\nnational corpora and Web corpora) and word similarity datasets of Russian and\nEnglish assessed by humans in order to find the existence of correlation\nbetween embeddings and eye movement data and test the hypothesis that this\ncorrelation is language independent. As a result, we found that the validity of\nthe hypothesis being tested could be questioned.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 21:29:30 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Bakarov", "Amir", ""]]}, {"id": "1804.08756", "submitter": "Hai Hu", "authors": "Hai Hu, Wen Li, Sandra K\\\"ubler", "title": "Detecting Syntactic Features of Translated Chinese", "comments": "Accepted to 2nd Workshop on Stylistic Variation, NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a machine learning approach to distinguish texts translated to\nChinese (by humans) from texts originally written in Chinese, with a focus on a\nwide range of syntactic features. Using Support Vector Machines (SVMs) as\nclassifier on a genre-balanced corpus in translation studies of Chinese, we\nfind that constituent parse trees and dependency triples as features without\nlexical information perform very well on the task, with an F-measure above 90%,\nclose to the results of lexical n-gram features, without the risk of learning\ntopic information rather than translation features. Thus, we claim syntactic\nfeatures alone can accurately distinguish translated from original Chinese.\nTranslated Chinese exhibits an increased use of determiners, subject position\npronouns, NP + 'de' as NP modifiers, multiple NPs or VPs conjoined by a Chinese\nspecific punctuation, among other structures. We also interpret the syntactic\nfeatures with reference to previous translation studies in Chinese,\nparticularly the usage of pronouns.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 21:56:11 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Hu", "Hai", ""], ["Li", "Wen", ""], ["K\u00fcbler", "Sandra", ""]]}, {"id": "1804.08759", "submitter": "Chen Qu", "authors": "Chen Qu, Liu Yang, W. Bruce Croft, Johanne R. Trippas, Yongfeng Zhang\n  and Minghui Qiu", "title": "Analyzing and Characterizing User Intent in Information-seeking\n  Conversations", "comments": "Accepted by SIGIR 2018 as a short paper", "journal-ref": null, "doi": "10.1145/3209978.3210124", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and characterizing how people interact in information-seeking\nconversations is crucial in developing conversational search systems. In this\npaper, we introduce a new dataset designed for this purpose and use it to\nanalyze information-seeking conversations by user intent distribution,\nco-occurrence, and flow patterns. The MSDialog dataset is a labeled dialog\ndataset of question answering (QA) interactions between information seekers and\nproviders from an online forum on Microsoft products. The dataset contains more\nthan 2,000 multi-turn QA dialogs with 10,000 utterances that are annotated with\nuser intent on the utterance level. Annotations were done using crowdsourcing.\nWith MSDialog, we find some highly recurring patterns in user intent during an\ninformation-seeking process. They could be useful for designing conversational\nsearch systems. We will make our dataset freely available to encourage\nexploration of information-seeking conversation models.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 22:07:28 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Qu", "Chen", ""], ["Yang", "Liu", ""], ["Croft", "W. Bruce", ""], ["Trippas", "Johanne R.", ""], ["Zhang", "Yongfeng", ""], ["Qiu", "Minghui", ""]]}, {"id": "1804.08771", "submitter": "Matt Post", "authors": "Matt Post", "title": "A Call for Clarity in Reporting BLEU Scores", "comments": "6 pages, 1 figure", "journal-ref": "Proceedings of the Third Conference on Machine Translation\n  (WMT18). 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of machine translation faces an under-recognized problem because of\ninconsistency in the reporting of scores from its dominant metric. Although\npeople refer to \"the\" BLEU score, BLEU is in fact a parameterized metric whose\nvalues can vary wildly with changes to these parameters. These parameters are\noften not reported or are hard to find, and consequently, BLEU scores between\npapers cannot be directly compared. I quantify this variation, finding\ndifferences as high as 1.8 between commonly used configurations. The main\nculprit is different tokenization and normalization schemes applied to the\nreference. Pointing to the success of the parsing community, I suggest machine\ntranslation researchers settle upon the BLEU scheme used by the annual\nConference on Machine Translation (WMT), which does not allow for user-supplied\nreference processing, and provide a new tool, SacreBLEU, to facilitate this.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 22:54:55 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 14:13:33 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Post", "Matt", ""]]}, {"id": "1804.08782", "submitter": "Md Nasir", "authors": "Md Nasir, Brian Baucom, Shrikanth Narayanan, Panayiotis Georgiou", "title": "Towards an Unsupervised Entrainment Distance in Conversational Speech\n  using Deep Neural Networks", "comments": "submitted to Interspeech 2018", "journal-ref": null, "doi": "10.21437/Interspeech.2018-1395", "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Entrainment is a known adaptation mechanism that causes interaction\nparticipants to adapt or synchronize their acoustic characteristics.\nUnderstanding how interlocutors tend to adapt to each other's speaking style\nthrough entrainment involves measuring a range of acoustic features and\ncomparing those via multiple signal comparison methods. In this work, we\npresent a turn-level distance measure obtained in an unsupervised manner using\na Deep Neural Network (DNN) model, which we call Neural Entrainment Distance\n(NED). This metric establishes a framework that learns an embedding from the\npopulation-wide entrainment in an unlabeled training corpus. We use the\nframework for a set of acoustic features and validate the measure\nexperimentally by showing its efficacy in distinguishing real conversations\nfrom fake ones created by randomly shuffling speaker turns. Moreover, we show\nreal world evidence of the validity of the proposed measure. We find that high\nvalue of NED is associated with high ratings of emotional bond in suicide\nassessment interviews, which is consistent with prior studies.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 23:45:30 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Nasir", "Md", ""], ["Baucom", "Brian", ""], ["Narayanan", "Shrikanth", ""], ["Georgiou", "Panayiotis", ""]]}, {"id": "1804.08798", "submitter": "Michael Petrochuk", "authors": "Michael Petrochuk and Luke Zettlemoyer", "title": "SimpleQuestions Nearly Solved: A New Upperbound and Baseline Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The SimpleQuestions dataset is one of the most commonly used benchmarks for\nstudying single-relation factoid questions. In this paper, we present new\nevidence that this benchmark can be nearly solved by standard methods. First we\nshow that ambiguity in the data bounds performance on this benchmark at 83.4%;\nthere are often multiple answers that cannot be disambiguated from the\nlinguistic signal alone. Second we introduce a baseline that sets a new\nstate-of-the-art performance level at 78.1% accuracy, despite using standard\nmethods. Finally, we report an empirical analysis showing that the upperbound\nis loose; roughly a third of the remaining errors are also not resolvable from\nthe linguistic signal. Together, these results suggest that the SimpleQuestions\ndataset is nearly solved.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 01:24:35 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Petrochuk", "Michael", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1804.08813", "submitter": "Wenpeng Yin", "authors": "Wenpeng Yin, Hinrich Sch\\\"utze and Dan Roth", "title": "End-Task Oriented Textual Entailment via Deep Explorations of\n  Inter-Sentence Interactions", "comments": "ACL'2018 camera-ready; 6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work deals with SciTail, a natural entailment challenge derived from a\nmulti-choice question answering problem. The premises and hypotheses in SciTail\nwere generated with no awareness of each other, and did not specifically aim at\nthe entailment task. This makes it more challenging than other entailment data\nsets and more directly useful to the end-task -- question answering. We propose\nDEISTE (deep explorations of inter-sentence interactions for textual\nentailment) for this entailment task. Given word-to-word interactions between\nthe premise-hypothesis pair ($P$, $H$), DEISTE consists of: (i) a\nparameter-dynamic convolution to make important words in $P$ and $H$ play a\ndominant role in learnt representations; and (ii) a position-aware attentive\nconvolution to encode the representation and position information of the\naligned word pairs. Experiments show that DEISTE gets $\\approx$5\\% improvement\nover prior state of the art and that the pretrained DEISTE on SciTail\ngeneralizes well on RTE-5.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 02:29:14 GMT"}, {"version": "v2", "created": "Sat, 12 May 2018 03:29:42 GMT"}, {"version": "v3", "created": "Tue, 15 May 2018 03:53:53 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Yin", "Wenpeng", ""], ["Sch\u00fctze", "Hinrich", ""], ["Roth", "Dan", ""]]}, {"id": "1804.08845", "submitter": "Tu Vu", "authors": "Tu Vu, Vered Shwartz", "title": "Integrating Multiplicative Features into Supervised Distributional\n  Methods for Lexical Entailment", "comments": "Accepted as a conference paper at *SEM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised distributional methods are applied successfully in lexical\nentailment, but recent work questioned whether these methods actually learn a\nrelation between two words. Specifically, Levy et al. (2015) claimed that\nlinear classifiers learn only separate properties of each word. We suggest a\ncheap and easy way to boost the performance of these methods by integrating\nmultiplicative features into commonly used representations. We provide an\nextensive evaluation with different classifiers and evaluation setups, and\nsuggest a suitable evaluation setup for the task, eliminating biases existing\nin previous ones.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 05:34:59 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Vu", "Tu", ""], ["Shwartz", "Vered", ""]]}, {"id": "1804.08847", "submitter": "Elvis Saravia", "authors": "Elvis Saravia, Hsien-Chi Toby Liu, Yi-Shin Chen", "title": "DeepEmo: Learning and Enriching Pattern-Based Emotion Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a graph-based mechanism to extract rich-emotion bearing patterns,\nwhich fosters a deeper analysis of online emotional expressions, from a corpus.\nThe patterns are then enriched with word embeddings and evaluated through\nseveral emotion recognition tasks. Moreover, we conduct analysis on the\nemotion-oriented patterns to demonstrate its applicability and to explore its\nproperties. Our experimental results demonstrate that the proposed techniques\noutperform most state-of-the-art emotion recognition techniques.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 06:00:28 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Saravia", "Elvis", ""], ["Liu", "Hsien-Chi Toby", ""], ["Chen", "Yi-Shin", ""]]}, {"id": "1804.08875", "submitter": "Nikola Nikolov", "authors": "Nikola I. Nikolov, Michael Pfeiffer, Richard H.R. Hahnloser", "title": "Data-driven Summarization of Scientific Articles", "comments": "8 pages, 3 figures. 7th International Workshop on Mining Scientific\n  Publications, LREC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven approaches to sequence-to-sequence modelling have been\nsuccessfully applied to short text summarization of news articles. Such models\nare typically trained on input-summary pairs consisting of only a single or a\nfew sentences, partially due to limited availability of multi-sentence training\ndata. Here, we propose to use scientific articles as a new milestone for text\nsummarization: large-scale training data come almost for free with two types of\nhigh-quality summaries at different levels - the title and the abstract. We\ngenerate two novel multi-sentence summarization datasets from scientific\narticles and test the suitability of a wide range of existing extractive and\nabstractive neural network-based summarization approaches. Our analysis\ndemonstrates that scientific papers are suitable for data-driven text\nsummarization. Our results could serve as valuable benchmarks for scaling\nsequence-to-sequence models to very long sequences.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 07:40:31 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Nikolov", "Nikola I.", ""], ["Pfeiffer", "Michael", ""], ["Hahnloser", "Richard H. R.", ""]]}, {"id": "1804.08881", "submitter": "Kumiko Tanaka-Ishii", "authors": "Shuntaro Takahashi and Kumiko Tanaka-Ishii", "title": "Assessing Language Models with Scaling Properties", "comments": "14 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language models have primarily been evaluated with perplexity. While\nperplexity quantifies the most comprehensible prediction performance, it does\nnot provide qualitative information on the success or failure of models.\nAnother approach for evaluating language models is thus proposed, using the\nscaling properties of natural language. Five such tests are considered, with\nthe first two accounting for the vocabulary population and the other three for\nthe long memory of natural language. The following models were evaluated with\nthese tests: n-grams, probabilistic context-free grammar (PCFG), Simon and\nPitman-Yor (PY) processes, hierarchical PY, and neural language models. Only\nthe neural language models exhibit the long memory properties of natural\nlanguage, but to a limited degree. The effectiveness of every test of these\nmodels is also discussed.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 07:58:20 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Takahashi", "Shuntaro", ""], ["Tanaka-Ishii", "Kumiko", ""]]}, {"id": "1804.08887", "submitter": "Farhad Nooralahzadeh", "authors": "Farhad Nooralahzadeh, Lilja {\\O}vrelid, Jan Tore L{\\o}nning", "title": "SIRIUS-LTG-UiO at SemEval-2018 Task 7: Convolutional Neural Networks\n  with Shortest Dependency Paths for Semantic Relation Extraction and\n  Classification in Scientific Papers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents the SIRIUS-LTG-UiO system for the SemEval 2018 Task 7\non Semantic Relation Extraction and Classification in Scientific Papers. First\nwe extract the shortest dependency path (sdp) between two entities, then we\nintroduce a convolutional neural network (CNN) which takes the shortest\ndependency path embeddings as input and performs relation classification with\ndiffering objectives for each subtask of the shared task. This approach\nachieved overall F1 scores of 76.7 and 83.2 for relation classification on\nclean and noisy data, respectively. Furthermore, for combined relation\nextraction and classification on clean data, it obtained F1 scores of 37.4 and\n33.6 for each phase. Our system ranks 3rd in all three sub-tasks of the shared\ntask.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 08:10:07 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Nooralahzadeh", "Farhad", ""], ["\u00d8vrelid", "Lilja", ""], ["L\u00f8nning", "Jan Tore", ""]]}, {"id": "1804.08915", "submitter": "Eliyahu Kiperwasser", "authors": "Eliyahu Kiperwasser and Miguel Ballesteros", "title": "Scheduled Multi-Task Learning: From Syntax to Translation", "comments": null, "journal-ref": "Transactions of the Association for Computational Linguistics,\n  6:225-240 (2018)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural encoder-decoder models of machine translation have achieved impressive\nresults, while learning linguistic knowledge of both the source and target\nlanguages in an implicit end-to-end manner. We propose a framework in which our\nmodel begins learning syntax and translation interleaved, gradually putting\nmore focus on translation. Using this approach, we achieve considerable\nimprovements in terms of BLEU score on relatively large parallel corpus (WMT14\nEnglish to German) and a low-resource (WIT German to English) setup.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 09:18:13 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Kiperwasser", "Eliyahu", ""], ["Ballesteros", "Miguel", ""]]}, {"id": "1804.09000", "submitter": "Shrimai Prabhumoye", "authors": "Shrimai Prabhumoye, Yulia Tsvetkov, Ruslan Salakhutdinov, Alan W Black", "title": "Style Transfer Through Back-Translation", "comments": "Accepted at ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Style transfer is the task of rephrasing the text to contain specific\nstylistic properties without changing the intent or affect within the context.\nThis paper introduces a new method for automatic style transfer. We first learn\na latent representation of the input sentence which is grounded in a language\ntranslation model in order to better preserve the meaning of the sentence while\nreducing stylistic properties. Then adversarial generation techniques are used\nto make the output match the desired style. We evaluate this technique on three\ndifferent style transformations: sentiment, gender and political slant.\nCompared to two state-of-the-art style transfer modeling techniques we show\nimprovements both in automatic evaluation of style transfer and in manual\nevaluation of meaning preservation and fluency.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 12:58:45 GMT"}, {"version": "v2", "created": "Fri, 27 Apr 2018 03:44:32 GMT"}, {"version": "v3", "created": "Thu, 24 May 2018 17:12:43 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Prabhumoye", "Shrimai", ""], ["Tsvetkov", "Yulia", ""], ["Salakhutdinov", "Ruslan", ""], ["Black", "Alan W", ""]]}, {"id": "1804.09010", "submitter": "Jiwei Tan", "authors": "Jianmin Zhang, Jiwei Tan, Xiaojun Wan", "title": "Towards a Neural Network Approach to Abstractive Multi-Document\n  Summarization", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Till now, neural abstractive summarization methods have achieved great\nsuccess for single document summarization (SDS). However, due to the lack of\nlarge scale multi-document summaries, such methods can be hardly applied to\nmulti-document summarization (MDS). In this paper, we investigate neural\nabstractive methods for MDS by adapting a state-of-the-art neural abstractive\nsummarization model for SDS. We propose an approach to extend the neural\nabstractive model trained on large scale SDS data to the MDS task. Our approach\nonly makes use of a small number of multi-document summaries for fine tuning.\nExperimental results on two benchmark DUC datasets demonstrate that our\napproach can outperform a variety of baseline neural models.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 13:24:08 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Zhang", "Jianmin", ""], ["Tan", "Jiwei", ""], ["Wan", "Xiaojun", ""]]}, {"id": "1804.09021", "submitter": "Zhenghui Wang", "authors": "Zhenghui Wang, Yanru Qu, Liheng Chen, Jian Shen, Weinan Zhang,\n  Shaodian Zhang, Yimei Gao, Gen Gu, Ken Chen, Yong Yu", "title": "Label-aware Double Transfer Learning for Cross-Specialty Medical Named\n  Entity Recognition", "comments": "NAACL HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of named entity recognition (NER) from electronic\nmedical records, which is one of the most fundamental and critical problems for\nmedical text mining. Medical records which are written by clinicians from\ndifferent specialties usually contain quite different terminologies and writing\nstyles. The difference of specialties and the cost of human annotation makes it\nparticularly difficult to train a universal medical NER system. In this paper,\nwe propose a label-aware double transfer learning framework (La-DTL) for\ncross-specialty NER, so that a medical NER system designed for one specialty\ncould be conveniently applied to another one with minimal annotation efforts.\nThe transferability is guaranteed by two components: (i) we propose label-aware\nMMD for feature representation transfer, and (ii) we perform parameter transfer\nwith a theoretical upper bound which is also label aware. We conduct extensive\nexperiments on 12 cross-specialty NER tasks. The experimental results\ndemonstrate that La-DTL provides consistent accuracy improvement over strong\nbaselines. Besides, the promising experimental results on non-medical NER\nscenarios indicate that La-DTL is potential to be seamlessly adapted to a wide\nrange of NER tasks.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 13:35:11 GMT"}, {"version": "v2", "created": "Sat, 28 Apr 2018 09:46:39 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Wang", "Zhenghui", ""], ["Qu", "Yanru", ""], ["Chen", "Liheng", ""], ["Shen", "Jian", ""], ["Zhang", "Weinan", ""], ["Zhang", "Shaodian", ""], ["Gao", "Yimei", ""], ["Gu", "Gen", ""], ["Chen", "Ken", ""], ["Yu", "Yong", ""]]}, {"id": "1804.09028", "submitter": "Einat Kermany", "authors": "Guy Hadash, Einat Kermany, Boaz Carmeli, Ofer Lavi, George Kour and\n  Alon Jacovi", "title": "Estimate and Replace: A Novel Approach to Integrating Deep Neural\n  Networks with Existing Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing applications include a huge amount of knowledge that is out of reach\nfor deep neural networks. This paper presents a novel approach for integrating\ncalls to existing applications into deep learning architectures. Using this\napproach, we estimate each application's functionality with an estimator, which\nis implemented as a deep neural network (DNN). The estimator is then embedded\ninto a base network that we direct into complying with the application's\ninterface during an end-to-end optimization process. At inference time, we\nreplace each estimator with its existing application counterpart and let the\nbase network solve the task by interacting with the existing application. Using\nthis 'Estimate and Replace' method, we were able to train a DNN end-to-end with\nless data and outperformed a matching DNN that did not interact with the\nexternal application.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 13:40:09 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Hadash", "Guy", ""], ["Kermany", "Einat", ""], ["Carmeli", "Boaz", ""], ["Lavi", "Ofer", ""], ["Kour", "George", ""], ["Jacovi", "Alon", ""]]}, {"id": "1804.09057", "submitter": "Zhen Yang", "authors": "Zhen Yang, Wei Chen, Feng Wang, Bo Xu", "title": "Unsupervised Neural Machine Translation with Weight Sharing", "comments": "Unsupervised NMT, Accepted by ACL2018, code released", "journal-ref": "ACL2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised neural machine translation (NMT) is a recently proposed approach\nfor machine translation which aims to train the model without using any labeled\ndata. The models proposed for unsupervised NMT often use only one shared\nencoder to map the pairs of sentences from different languages to a\nshared-latent space, which is weak in keeping the unique and internal\ncharacteristics of each language, such as the style, terminology, and sentence\nstructure. To address this issue, we introduce an extension by utilizing two\nindependent encoders but sharing some partial weights which are responsible for\nextracting high-level representations of the input sentences. Besides, two\ndifferent generative adversarial networks (GANs), namely the local GAN and\nglobal GAN, are proposed to enhance the cross-language translation. With this\nnew approach, we achieve significant improvements on English-German,\nEnglish-French and Chinese-to-English translation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 14:11:28 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Yang", "Zhen", ""], ["Chen", "Wei", ""], ["Wang", "Feng", ""], ["Xu", "Bo", ""]]}, {"id": "1804.09132", "submitter": "Seid Muhie Yimam", "authors": "Seid Muhie Yimam and Chris Biemann and Shervin Malmasi and Gustavo H.\n  Paetzold and Lucia Specia and Sanja \\v{S}tajner and Ana\\\"is Tack and Marcos\n  Zampieri", "title": "A Report on the Complex Word Identification Shared Task 2018", "comments": "Second CWI Shared Task co-located with the BEA Workshop 2018 at\n  NAACL-HLT in New Orleans, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We report the findings of the second Complex Word Identification (CWI) shared\ntask organized as part of the BEA workshop co-located with NAACL-HLT'2018. The\nsecond CWI shared task featured multilingual and multi-genre datasets divided\ninto four tracks: English monolingual, German monolingual, Spanish monolingual,\nand a multilingual track with a French test set, and two tasks: binary\nclassification and probabilistic classification. A total of 12 teams submitted\ntheir results in different task/track combinations and 11 of them wrote system\ndescription papers that are referred to in this report and appear in the BEA\nworkshop proceedings.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 16:49:30 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Yimam", "Seid Muhie", ""], ["Biemann", "Chris", ""], ["Malmasi", "Shervin", ""], ["Paetzold", "Gustavo H.", ""], ["Specia", "Lucia", ""], ["\u0160tajner", "Sanja", ""], ["Tack", "Ana\u00efs", ""], ["Zampieri", "Marcos", ""]]}, {"id": "1804.09148", "submitter": "Diego Saldana", "authors": "Diego Saldana Miranda", "title": "Automated Detection of Adverse Drug Reactions in the Biomedical\n  Literature Using Convolutional Neural Networks and Biomedical Word Embeddings", "comments": "Accepted as conference paper at SwissText 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring the biomedical literature for cases of Adverse Drug Reactions\n(ADRs) is a critically important and time consuming task in pharmacovigilance.\nThe development of computer assisted approaches to aid this process in\ndifferent forms has been the subject of many recent works. One particular area\nthat has shown promise is the use of Deep Neural Networks, in particular,\nConvolutional Neural Networks (CNNs), for the detection of ADR relevant\nsentences. Using token-level convolutions and general purpose word embeddings,\nthis architecture has shown good performance relative to more traditional\nmodels as well as Long Short Term Memory (LSTM) models. In this work, we\nevaluate and compare two different CNN architectures using the ADE corpus. In\naddition, we show that by de-duplicating the ADR relevant sentences, we can\ngreatly reduce overoptimism in the classification results. Finally, we evaluate\nthe use of word embeddings specifically developed for biomedical text and show\nthat they lead to a better performance in this task.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 17:18:01 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Miranda", "Diego Saldana", ""]]}, {"id": "1804.09160", "submitter": "Xin Wang", "authors": "Xin Wang, Wenhu Chen, Yuan-Fang Wang, William Yang Wang", "title": "No Metrics Are Perfect: Adversarial Reward Learning for Visual\n  Storytelling", "comments": "ACL 2018. 15 pages, 10 figures, 4 tables, with supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though impressive results have been achieved in visual captioning, the task\nof generating abstract stories from photo streams is still a little-tapped\nproblem. Different from captions, stories have more expressive language styles\nand contain many imaginary concepts that do not appear in the images. Thus it\nposes challenges to behavioral cloning algorithms. Furthermore, due to the\nlimitations of automatic metrics on evaluating story quality, reinforcement\nlearning methods with hand-crafted rewards also face difficulties in gaining an\noverall performance boost. Therefore, we propose an Adversarial REward Learning\n(AREL) framework to learn an implicit reward function from human\ndemonstrations, and then optimize policy search with the learned reward\nfunction. Though automatic eval- uation indicates slight performance boost over\nstate-of-the-art (SOTA) methods in cloning expert behaviors, human evaluation\nshows that our approach achieves significant improvement in generating more\nhuman-like stories than SOTA systems.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 17:41:24 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2018 00:15:14 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Wang", "Xin", ""], ["Chen", "Wenhu", ""], ["Wang", "Yuan-Fang", ""], ["Wang", "William Yang", ""]]}, {"id": "1804.09259", "submitter": "Stanis{\\l}aw Jastrz\\k{e}bski", "authors": "Stanis{\\l}aw Jastrz\\k{e}bski, Dzmitry Bahdanau, Seyedarian Hosseini,\n  Michael Noukhovitch, Yoshua Bengio, Jackie Chi Kit Cheung", "title": "Commonsense mining as knowledge base completion? A study on the impact\n  of novelty", "comments": "Published in Workshop on New Forms of Generalization in Deep Learning\n  and Natural Language Processing (NAACL 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense knowledge bases such as ConceptNet represent knowledge in the\nform of relational triples. Inspired by the recent work by Li et al., we\nanalyse if knowledge base completion models can be used to mine commonsense\nknowledge from raw text. We propose novelty of predicted triples with respect\nto the training set as an important factor in interpreting results. We\ncritically analyse the difficulty of mining novel commonsense knowledge, and\nshow that a simple baseline method outperforms the previous state of the art on\npredicting more novel.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 21:07:04 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Jastrz\u0119bski", "Stanis\u0142aw", ""], ["Bahdanau", "Dzmitry", ""], ["Hosseini", "Seyedarian", ""], ["Noukhovitch", "Michael", ""], ["Bengio", "Yoshua", ""], ["Cheung", "Jackie Chi Kit", ""]]}, {"id": "1804.09298", "submitter": "Jinyu Li", "authors": "Dong Yu and Jinyu Li", "title": "Recent Progresses in Deep Learning based Acoustic Models (Updated)", "comments": "This is an updated version with latest literature until ICASSP2018 of\n  the paper: Dong Yu and Jinyu Li, \"Recent Progresses in Deep Learning based\n  Acoustic Models,\" vol.4, no.3, IEEE/CAA Journal of Automatica Sinica, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we summarize recent progresses made in deep learning based\nacoustic models and the motivation and insights behind the surveyed techniques.\nWe first discuss acoustic models that can effectively exploit variable-length\ncontextual information, such as recurrent neural networks (RNNs), convolutional\nneural networks (CNNs), and their various combination with other models. We\nthen describe acoustic models that are optimized end-to-end with emphasis on\nfeature representations learned jointly with rest of the system, the\nconnectionist temporal classification (CTC) criterion, and the attention-based\nsequence-to-sequence model. We further illustrate robustness issues in speech\nrecognition systems, and discuss acoustic model adaptation, speech enhancement\nand separation, and robust training strategies. We also cover modeling\ntechniques that lead to more efficient decoding and discuss possible future\ndirections in acoustic model research.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 00:24:39 GMT"}, {"version": "v2", "created": "Fri, 27 Apr 2018 01:13:39 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Yu", "Dong", ""], ["Li", "Jinyu", ""]]}, {"id": "1804.09299", "submitter": "Alexander M. Rush", "authors": "Hendrik Strobelt, Sebastian Gehrmann, Michael Behrisch, Adam Perer,\n  Hanspeter Pfister, Alexander M. Rush", "title": "Seq2Seq-Vis: A Visual Debugging Tool for Sequence-to-Sequence Models", "comments": "VAST - IEEE VIS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Sequence-to-Sequence models have proven to be accurate and robust for\nmany sequence prediction tasks, and have become the standard approach for\nautomatic translation of text. The models work in a five stage blackbox process\nthat involves encoding a source sequence to a vector space and then decoding\nout to a new target sequence. This process is now standard, but like many deep\nlearning methods remains quite difficult to understand or debug. In this work,\nwe present a visual analysis tool that allows interaction with a trained\nsequence-to-sequence model through each stage of the translation process. The\naim is to identify which patterns have been learned and to detect model errors.\nWe demonstrate the utility of our tool through several real-world large-scale\nsequence-to-sequence use cases.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 00:32:45 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 15:59:38 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Strobelt", "Hendrik", ""], ["Gehrmann", "Sebastian", ""], ["Behrisch", "Michael", ""], ["Perer", "Adam", ""], ["Pfister", "Hanspeter", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1804.09301", "submitter": "Rachel Rudinger", "authors": "Rachel Rudinger, Jason Naradowsky, Brian Leonard, Benjamin Van Durme", "title": "Gender Bias in Coreference Resolution", "comments": "Accepted to NAACL-HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an empirical study of gender bias in coreference resolution\nsystems. We first introduce a novel, Winograd schema-style set of minimal pair\nsentences that differ only by pronoun gender. With these \"Winogender schemas,\"\nwe evaluate and confirm systematic gender bias in three publicly-available\ncoreference resolution systems, and correlate this bias with real-world and\ntextual gender statistics.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 00:46:14 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Rudinger", "Rachel", ""], ["Naradowsky", "Jason", ""], ["Leonard", "Brian", ""], ["Van Durme", "Benjamin", ""]]}, {"id": "1804.09321", "submitter": "Xi Rao", "authors": "Xi Rao and Zhenxing Ke", "title": "Hierarchical RNN for Information Extraction from Lawsuit Documents", "comments": "IMECS2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every lawsuit document contains the information about the party's claim,\ncourt's analysis, decision and others, and all of this information are helpful\nto understand the case better and predict the judge's decision on similar case\nin the future. However, the extraction of these information from the document\nis difficult because the language is too complicated and sentences varied at\nlength. We treat this problem as a task of sequence labeling, and this paper\npresents the first research to extract relevant information from the civil\nlawsuit document in China with the hierarchical RNN framework.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 02:18:51 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Rao", "Xi", ""], ["Ke", "Zhenxing", ""]]}, {"id": "1804.09530", "submitter": "Sebastian Ruder", "authors": "Sebastian Ruder, Barbara Plank", "title": "Strong Baselines for Neural Semi-supervised Learning under Domain Shift", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novel neural models have been proposed in recent years for learning under\ndomain shift. Most models, however, only evaluate on a single task, on\nproprietary datasets, or compare to weak baselines, which makes comparison of\nmodels difficult. In this paper, we re-evaluate classic general-purpose\nbootstrapping approaches in the context of neural networks under domain shifts\nvs. recent neural approaches and propose a novel multi-task tri-training method\nthat reduces the time and space complexity of classic tri-training. Extensive\nexperiments on two benchmarks are negative: while our novel method establishes\na new state-of-the-art for sentiment analysis, it does not fare consistently\nthe best. More importantly, we arrive at the somewhat surprising conclusion\nthat classic tri-training, with some additions, outperforms the state of the\nart. We conclude that classic approaches constitute an important and strong\nbaseline.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 13:06:29 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Ruder", "Sebastian", ""], ["Plank", "Barbara", ""]]}, {"id": "1804.09540", "submitter": "Jatin Ganhotra", "authors": "Janarthanan Rajendran, Jatin Ganhotra, Xiaoxiao Guo, Mo Yu, Satinder\n  Singh, Lazaros Polymenakos", "title": "NE-Table: A Neural key-value table for Named Entities", "comments": "RANLP 2019 - http://lml.bas.bg/ranlp2019/accepted.php . Datasets are\n  available at - https://github.com/IBM/ne-table-datasets/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Many Natural Language Processing (NLP) tasks depend on using Named Entities\n(NEs) that are contained in texts and in external knowledge sources. While this\nis easy for humans, the present neural methods that rely on learned word\nembeddings may not perform well for these NLP tasks, especially in the presence\nof Out-Of-Vocabulary (OOV) or rare NEs. In this paper, we propose a solution\nfor this problem, and present empirical evaluations on: a) a structured\nQuestion-Answering task, b) three related Goal-Oriented dialog tasks, and c) a\nReading-Comprehension task, which show that the proposed method can be\neffective in dealing with both in-vocabulary and OOV NEs. We create extended\nversions of dialog bAbI tasks 1,2 and 4 and OOV versions of the CBT test set\navailable at - https://github.com/IBM/ne-table-datasets.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 20:09:13 GMT"}, {"version": "v2", "created": "Sun, 21 Jul 2019 22:27:48 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Rajendran", "Janarthanan", ""], ["Ganhotra", "Jatin", ""], ["Guo", "Xiaoxiao", ""], ["Yu", "Mo", ""], ["Singh", "Satinder", ""], ["Polymenakos", "Lazaros", ""]]}, {"id": "1804.09541", "submitter": "Adams Wei Yu", "authors": "Adams Wei Yu, David Dohan, Minh-Thang Luong, Rui Zhao, Kai Chen,\n  Mohammad Norouzi, Quoc V. Le", "title": "QANet: Combining Local Convolution with Global Self-Attention for\n  Reading Comprehension", "comments": "Published as full paper in ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current end-to-end machine reading and question answering (Q\\&A) models are\nprimarily based on recurrent neural networks (RNNs) with attention. Despite\ntheir success, these models are often slow for both training and inference due\nto the sequential nature of RNNs. We propose a new Q\\&A architecture called\nQANet, which does not require recurrent networks: Its encoder consists\nexclusively of convolution and self-attention, where convolution models local\ninteractions and self-attention models global interactions. On the SQuAD\ndataset, our model is 3x to 13x faster in training and 4x to 9x faster in\ninference, while achieving equivalent accuracy to recurrent models. The\nspeed-up gain allows us to train the model with much more data. We hence\ncombine our model with data generated by backtranslation from a neural machine\ntranslation model. On the SQuAD dataset, our single model, trained with\naugmented data, achieves 84.6 F1 score on the test set, which is significantly\nbetter than the best published F1 score of 81.8.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 11:33:43 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Yu", "Adams Wei", ""], ["Dohan", "David", ""], ["Luong", "Minh-Thang", ""], ["Zhao", "Rui", ""], ["Chen", "Kai", ""], ["Norouzi", "Mohammad", ""], ["Le", "Quoc V.", ""]]}, {"id": "1804.09543", "submitter": "Dafydd Gibbon", "authors": "Dafydd Gibbon", "title": "The Future of Prosody: It's about Time", "comments": "9 pages, 15 figures, keynote address draft for Speech Prosody 9,\n  Poznan, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prosody is usually defined in terms of the three distinct but interacting\ndomains of pitch, intensity and duration patterning, or, more generally, as\nphonological and phonetic properties of 'suprasegmentals', speech segments\nwhich are larger than consonants and vowels. Rather than taking this approach,\nthe concept of multiple time domains for prosody processing is taken up, and\nmethods of time domain analysis are discussed: annotation mining with timing\ndispersion measures, time tree induction, oscillator models in phonology and\nphonetics, and finally the use of the Amplitude Envelope Modulation Spectrum\n(AEMS). While frequency demodulation (in the form of pitch tracking) is a\ncentral issue in prosodic analysis, in the present context it is amplitude\nenvelope demodulation and frequency zones in the long time-domain spectra of\nthe demodulated envelope which are focused. A generalised view is taken of\noscillation as iteration in abstract prosodic models and as modulation and\ndemodulation of a variety of rhythms in the speech signal.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 20:54:43 GMT"}, {"version": "v2", "created": "Tue, 1 May 2018 14:19:31 GMT"}, {"version": "v3", "created": "Mon, 7 May 2018 09:31:38 GMT"}, {"version": "v4", "created": "Tue, 15 May 2018 05:55:55 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Gibbon", "Dafydd", ""]]}, {"id": "1804.09552", "submitter": "Kyongsik Yun", "authors": "Kyongsik Yun, Joseph Osborne, Madison Lee, Thomas Lu, Edward Chow", "title": "Automatic speech recognition for launch control center communication\n  using recurrent neural networks with data augmentation and custom language\n  model", "comments": "SPIE 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transcribing voice communications in NASA's launch control center is\nimportant for information utilization. However, automatic speech recognition in\nthis environment is particularly challenging due to the lack of training data,\nunfamiliar words in acronyms, multiple different speakers and accents, and\nconversational characteristics of speaking. We used bidirectional deep\nrecurrent neural networks to train and test speech recognition performance. We\nshowed that data augmentation and custom language models can improve speech\nrecognition accuracy. Transcribing communications from the launch control\ncenter will help the machine analyze information and accelerate knowledge\ngeneration.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 10:28:57 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Yun", "Kyongsik", ""], ["Osborne", "Joseph", ""], ["Lee", "Madison", ""], ["Lu", "Thomas", ""], ["Chow", "Edward", ""]]}, {"id": "1804.09558", "submitter": "Raquel P\\'erez-Arnal", "authors": "Raquel P\\'erez-Arnal, Armand Vilalta, Dario Garcia-Gasulla, Ulises\n  Cort\\'es, Eduard Ayguad\\'e, Jesus Labarta", "title": "A Visual Distance for WordNet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring the distance between concepts is an important field of study of\nNatural Language Processing, as it can be used to improve tasks related to the\ninterpretation of those same concepts. WordNet, which includes a wide variety\nof concepts associated with words (i.e., synsets), is often used as a source\nfor computing those distances. In this paper, we explore a distance for WordNet\nsynsets based on visual features, instead of lexical ones. For this purpose, we\nextract the graphic features generated within a deep convolutional neural\nnetworks trained with ImageNet and use those features to generate a\nrepresentative of each synset. Based on those representatives, we define a\ndistance measure of synsets, which complements the traditional lexical\ndistances. Finally, we propose some experiments to evaluate its performance and\ncompare it with the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 15:34:33 GMT"}, {"version": "v2", "created": "Fri, 27 Apr 2018 09:17:36 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["P\u00e9rez-Arnal", "Raquel", ""], ["Vilalta", "Armand", ""], ["Garcia-Gasulla", "Dario", ""], ["Cort\u00e9s", "Ulises", ""], ["Ayguad\u00e9", "Eduard", ""], ["Labarta", "Jesus", ""]]}, {"id": "1804.09635", "submitter": "Dongyeop Kang", "authors": "Dongyeop Kang and Waleed Ammar and Bhavana Dalvi and Madeleine van\n  Zuylen and Sebastian Kohlmeier and Eduard Hovy and Roy Schwartz", "title": "A Dataset of Peer Reviews (PeerRead): Collection, Insights and NLP\n  Applications", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer reviewing is a central component in the scientific publishing process.\nWe present the first public dataset of scientific peer reviews available for\nresearch purposes (PeerRead v1) providing an opportunity to study this\nimportant artifact. The dataset consists of 14.7K paper drafts and the\ncorresponding accept/reject decisions in top-tier venues including ACL, NIPS\nand ICLR. The dataset also includes 10.7K textual peer reviews written by\nexperts for a subset of the papers. We describe the data collection process and\nreport interesting observed phenomena in the peer reviews. We also propose two\nnovel NLP tasks based on this dataset and provide simple baseline models. In\nthe first task, we show that simple models can predict whether a paper is\naccepted with up to 21% error reduction compared to the majority baseline. In\nthe second task, we predict the numerical scores of review aspects and show\nthat simple models can outperform the mean baseline for aspects with high\nvariance such as 'originality' and 'impact'.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 15:41:15 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Kang", "Dongyeop", ""], ["Ammar", "Waleed", ""], ["Dalvi", "Bhavana", ""], ["van Zuylen", "Madeleine", ""], ["Kohlmeier", "Sebastian", ""], ["Hovy", "Eduard", ""], ["Schwartz", "Roy", ""]]}, {"id": "1804.09661", "submitter": "Aaron Jaech", "authors": "Aaron Jaech and Mari Ostendorf", "title": "Personalized Language Model for Query Auto-Completion", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Query auto-completion is a search engine feature whereby the system suggests\ncompleted queries as the user types. Recently, the use of a recurrent neural\nnetwork language model was suggested as a method of generating query\ncompletions. We show how an adaptable language model can be used to generate\npersonalized completions and how the model can use online updating to make\npredictions for users not seen during training. The personalized predictions\nare significantly better than a baseline that uses no user information.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 16:26:39 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Jaech", "Aaron", ""], ["Ostendorf", "Mari", ""]]}, {"id": "1804.09692", "submitter": "Laura Wendlandt", "authors": "Laura Wendlandt, Jonathan K. Kummerfeld, Rada Mihalcea", "title": "Factors Influencing the Surprising Instability of Word Embeddings", "comments": "NAACL HLT 2018", "journal-ref": "NAACL-HLT (2018) 2092-2102", "doi": "10.18653/v1/N18-1190", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent popularity of word embedding methods, there is only a\nsmall body of work exploring the limitations of these representations. In this\npaper, we consider one aspect of embedding spaces, namely their stability. We\nshow that even relatively high frequency words (100-200 occurrences) are often\nunstable. We provide empirical evidence for how various factors contribute to\nthe stability of word embeddings, and we analyze the effects of stability on\ndownstream tasks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 17:40:20 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Wendlandt", "Laura", ""], ["Kummerfeld", "Jonathan K.", ""], ["Mihalcea", "Rada", ""]]}, {"id": "1804.09713", "submitter": "Shruti Palaskar", "authors": "Shruti Palaskar, Ramon Sanabria and Florian Metze", "title": "End-to-End Multimodal Speech Recognition", "comments": "5 pages, 5 figures, Accepted at IEEE International Conference on\n  Acoustics, Speech and Signal Processing 2018 (ICASSP 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transcription or sub-titling of open-domain videos is still a challenging\ndomain for Automatic Speech Recognition (ASR) due to the data's challenging\nacoustics, variable signal processing and the essentially unrestricted domain\nof the data. In previous work, we have shown that the visual channel --\nspecifically object and scene features -- can help to adapt the acoustic model\n(AM) and language model (LM) of a recognizer, and we are now expanding this\nwork to end-to-end approaches. In the case of a Connectionist Temporal\nClassification (CTC)-based approach, we retain the separation of AM and LM,\nwhile for a sequence-to-sequence (S2S) approach, both information sources are\nadapted together, in a single model. This paper also analyzes the behavior of\nCTC and S2S models on noisy video data (How-To corpus), and compares it to\nresults on the clean Wall Street Journal (WSJ) corpus, providing insight into\nthe robustness of both approaches.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 22:54:06 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Palaskar", "Shruti", ""], ["Sanabria", "Ramon", ""], ["Metze", "Florian", ""]]}, {"id": "1804.09746", "submitter": "Olivier Bournez", "authors": "Olivier Bournez and Sabrina Ouazzani", "title": "Cheap Non-standard Analysis and Computability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non standard analysis is an area of Mathematics dealing with notions of\ninfinitesimal and infinitely large numbers, in which many statements from\nclassical analysis can be expressed very naturally. Cheap non-standard analysis\nintroduced by Terence Tao in 2012 is based on the idea that considering that a\nproperty holds eventually is sufficient to give the essence of many of its\nstatements. This provides constructivity but at some (acceptable) price. We\nconsider computability in cheap non-standard analysis. We prove that many\nconcepts from computable analysis as well as several concepts from\ncomputability can be very elegantly and alternatively presented in this\nframework. It provides a dual view and dual proofs to several statements\nalready known in these fields.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 18:36:17 GMT"}, {"version": "v2", "created": "Sun, 30 Dec 2018 22:07:06 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Bournez", "Olivier", ""], ["Ouazzani", "Sabrina", ""]]}, {"id": "1804.09769", "submitter": "Tao Yu", "authors": "Tao Yu, Zifan Li, Zilin Zhang, Rui Zhang, Dragomir Radev", "title": "TypeSQL: Knowledge-based Type-Aware Neural Text-to-SQL Generation", "comments": "NAACL 2018", "journal-ref": "The 16th Annual Conference of the North American Chapter of the\n  Association for Computational Linguistics, New Orleans, 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interacting with relational databases through natural language helps users of\nany background easily query and analyze a vast amount of data. This requires a\nsystem that understands users' questions and converts them to SQL queries\nautomatically. In this paper we present a novel approach, TypeSQL, which views\nthis problem as a slot filling task. Additionally, TypeSQL utilizes type\ninformation to better understand rare entities and numbers in natural language\nquestions. We test this idea on the WikiSQL dataset and outperform the prior\nstate-of-the-art by 5.5% in much less time. We also show that accessing the\ncontent of databases can significantly improve the performance when users'\nqueries are not well-formed. TypeSQL gets 82.6% accuracy, a 17.5% absolute\nimprovement compared to the previous content-sensitive model.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 19:35:56 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Yu", "Tao", ""], ["Li", "Zifan", ""], ["Zhang", "Zilin", ""], ["Zhang", "Rui", ""], ["Radev", "Dragomir", ""]]}, {"id": "1804.09779", "submitter": "Adam Poliak", "authors": "Adam Poliak, Yonatan Belinkov, James Glass, Benjamin Van Durme", "title": "On the Evaluation of Semantic Phenomena in Neural Machine Translation\n  Using Natural Language Inference", "comments": "To be presented at NAACL 2018 - 11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a process for investigating the extent to which sentence\nrepresentations arising from neural machine translation (NMT) systems encode\ndistinct semantic phenomena. We use these representations as features to train\na natural language inference (NLI) classifier based on datasets recast from\nexisting semantic annotations. In applying this process to a representative NMT\nsystem, we find its encoder appears most suited to supporting inferences at the\nsyntax-semantics interface, as compared to anaphora resolution requiring\nworld-knowledge. We conclude with a discussion on the merits and potential\ndeficiencies of the existing process, and how it may be improved and extended\nas a broader framework for evaluating semantic coverage.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 20:03:09 GMT"}, {"version": "v2", "created": "Sun, 6 May 2018 17:58:48 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Poliak", "Adam", ""], ["Belinkov", "Yonatan", ""], ["Glass", "James", ""], ["Van Durme", "Benjamin", ""]]}, {"id": "1804.09843", "submitter": "Ben Athiwaratkun", "authors": "Ben Athiwaratkun and Andrew Gordon Wilson", "title": "Hierarchical Density Order Embeddings", "comments": "Published at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By representing words with probability densities rather than point vectors,\nprobabilistic word embeddings can capture rich and interpretable semantic\ninformation and uncertainty. The uncertainty information can be particularly\nmeaningful in capturing entailment relationships -- whereby general words such\nas \"entity\" correspond to broad distributions that encompass more specific\nwords such as \"animal\" or \"instrument\". We introduce density order embeddings,\nwhich learn hierarchical representations through encapsulation of probability\ndensities. In particular, we propose simple yet effective loss functions and\ndistance metrics, as well as graph-based schemes to select negative samples to\nbetter learn hierarchical density representations. Our approach provides\nstate-of-the-art performance on the WordNet hypernym relationship prediction\ntask and the challenging HyperLex lexical entailment dataset -- while retaining\na rich and interpretable density representation.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 00:43:49 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Athiwaratkun", "Ben", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1804.09849", "submitter": "Orhan Firat", "authors": "Mia Xu Chen, Orhan Firat, Ankur Bapna, Melvin Johnson, Wolfgang\n  Macherey, George Foster, Llion Jones, Niki Parmar, Mike Schuster, Zhifeng\n  Chen, Yonghui Wu, Macduff Hughes", "title": "The Best of Both Worlds: Combining Recent Advances in Neural Machine\n  Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past year has witnessed rapid advances in sequence-to-sequence (seq2seq)\nmodeling for Machine Translation (MT). The classic RNN-based approaches to MT\nwere first out-performed by the convolutional seq2seq model, which was then\nout-performed by the more recent Transformer model. Each of these new\napproaches consists of a fundamental architecture accompanied by a set of\nmodeling and training techniques that are in principle applicable to other\nseq2seq architectures. In this paper, we tease apart the new architectures and\ntheir accompanying techniques in two ways. First, we identify several key\nmodeling and training techniques, and apply them to the RNN architecture,\nyielding a new RNMT+ model that outperforms all of the three fundamental\narchitectures on the benchmark WMT'14 English to French and English to German\ntasks. Second, we analyze the properties of each fundamental seq2seq\narchitecture and devise new hybrid architectures intended to combine their\nstrengths. Our hybrid models obtain further improvements, outperforming the\nRNMT+ model on both benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 01:24:39 GMT"}, {"version": "v2", "created": "Fri, 27 Apr 2018 02:31:16 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Chen", "Mia Xu", ""], ["Firat", "Orhan", ""], ["Bapna", "Ankur", ""], ["Johnson", "Melvin", ""], ["Macherey", "Wolfgang", ""], ["Foster", "George", ""], ["Jones", "Llion", ""], ["Parmar", "Niki", ""], ["Schuster", "Mike", ""], ["Chen", "Zhifeng", ""], ["Wu", "Yonghui", ""], ["Hughes", "Macduff", ""]]}, {"id": "1804.09931", "submitter": "Qi Zhu", "authors": "Qi Zhu, Xiang Ren, Jingbo Shang, Yu Zhang, Ahmed El-Kishky, Jiawei Han", "title": "Integrating Local Context and Global Cohesiveness for Open Information\n  Extraction", "comments": "8 pages + 1 page reference. Accepted to WSDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting entities and their relations from text is an important task for\nunderstanding massive text corpora. Open information extraction (IE) systems\nmine relation tuples (i.e., entity arguments and a predicate string to describe\ntheir relation) from sentences. These relation tuples are not confined to a\npredefined schema for the relations of interests. However, current Open IE\nsystems focus on modeling local context information in a sentence to extract\nrelation tuples, while ignoring the fact that global statistics in a large\ncorpus can be collectively leveraged to identify high-quality sentence-level\nextractions. In this paper, we propose a novel Open IE system, called ReMine,\nwhich integrates local context signals and global structural signals in a\nunified, distant-supervision framework. Leveraging facts from external\nknowledge bases as supervision, the new system can be applied to many different\ndomains to facilitate sentence-level tuple extractions using corpus-level\nstatistics. Our system operates by solving a joint optimization problem to\nunify (1) segmenting entity/relation phrases in individual sentences based on\nlocal context; and (2) measuring the quality of tuples extracted from\nindividual sentences with a translating-based objective. Learning the two\nsubtasks jointly helps correct errors produced in each subtask so that they can\nmutually enhance each other. Experiments on two real-world corpora from\ndifferent domains demonstrate the effectiveness, generality, and robustness of\nReMine when compared to state-of-the-art open IE systems.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 08:10:58 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 16:01:40 GMT"}, {"version": "v3", "created": "Sun, 4 Nov 2018 19:14:05 GMT"}, {"version": "v4", "created": "Sat, 1 Dec 2018 22:19:01 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Zhu", "Qi", ""], ["Ren", "Xiang", ""], ["Shang", "Jingbo", ""], ["Zhang", "Yu", ""], ["El-Kishky", "Ahmed", ""], ["Han", "Jiawei", ""]]}, {"id": "1804.09949", "submitter": "Adam Bielski", "authors": "Adam Bielski, Tomasz Trzcinski", "title": "Pay Attention to Virality: understanding popularity of social media\n  videos with the attention mechanism", "comments": "Conference on Computer Vision and Pattern Recognition Workshops\n  (CVPRW), CVPR 2018 workshop on Visual Understanding of Subjective Attributes\n  of Data (V-USAD)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting popularity of social media videos before they are published is a\nchallenging task, mainly due to the complexity of content distribution network\nas well as the number of factors that play part in this process. As solving\nthis task provides tremendous help for media content creators, many successful\nmethods were proposed to solve this problem with machine learning. In this\nwork, we change the viewpoint and postulate that it is not only the predicted\npopularity that matters, but also, maybe even more importantly, understanding\nof how individual parts influence the final popularity score. To that end, we\npropose to combine the Grad-CAM visualization method with a soft attention\nmechanism. Our preliminary results show that this approach allows for more\nintuitive interpretation of the content impact on video popularity, while\nachieving competitive results in terms of prediction accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 09:06:06 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Bielski", "Adam", ""], ["Trzcinski", "Tomasz", ""]]}, {"id": "1804.10080", "submitter": "Sergey Novoselov", "authors": "Sergey Novoselov, Andrey Shulipa, Ivan Kremnev, Alexandr Kozlov, Vadim\n  Shchemelinin", "title": "On deep speaker embeddings for text-independent speaker recognition", "comments": "Submitted to Odyssey 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate deep neural network performance in the textindependent speaker\nrecognition task. We demonstrate that using angular softmax activation at the\nlast classification layer of a classification neural network instead of a\nsimple softmax activation allows to train a more generalized discriminative\nspeaker embedding extractor. Cosine similarity is an effective metric for\nspeaker verification in this embedding space. We also address the problem of\nchoosing an architecture for the extractor. We found that deep networks with\nresidual frame level connections outperform wide but relatively shallow\narchitectures. This paper also proposes several improvements for previous\nDNN-based extractor systems to increase the speaker recognition accuracy. We\nshow that the discriminatively trained similarity metric learning approach\noutperforms the standard LDA-PLDA method as an embedding backend. The results\nobtained on Speakers in the Wild and NIST SRE 2016 evaluation sets demonstrate\nrobustness of the proposed systems when dealing with close to real-life\nconditions.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 14:22:01 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Novoselov", "Sergey", ""], ["Shulipa", "Andrey", ""], ["Kremnev", "Ivan", ""], ["Kozlov", "Alexandr", ""], ["Shchemelinin", "Vadim", ""]]}, {"id": "1804.10184", "submitter": "Shduong Hao", "authors": "Shudong Hao, Jordan Boyd-Graber, Michael J. Paul", "title": "Lessons from the Bible on Modern Topics: Low-Resource Multilingual Topic\n  Model Evaluation", "comments": "North American Chapter of the Association for Computational\n  Linguistics: Human Language Technologies (NAACL-HLT), New Orleans, Louisiana.\n  June 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multilingual topic models enable document analysis across languages through\ncoherent multilingual summaries of the data. However, there is no standard and\neffective metric to evaluate the quality of multilingual topics. We introduce a\nnew intrinsic evaluation of multilingual topic models that correlates well with\nhuman judgments of multilingual topic coherence as well as performance in\ndownstream applications. Importantly, we also study evaluation for low-resource\nlanguages. Because standard metrics fail to accurately measure topic quality\nwhen robust external resources are unavailable, we propose an adaptation model\nthat improves the accuracy and reliability of these metrics in low-resource\nsettings.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 17:35:15 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Hao", "Shudong", ""], ["Boyd-Graber", "Jordan", ""], ["Paul", "Michael J.", ""]]}, {"id": "1804.10188", "submitter": "Sahil Garg", "authors": "Sahil Garg, Irina Rish, Guillermo Cecchi, Palash Goyal, Sarik\n  Ghazarian, Shuyang Gao, Greg Ver Steeg, Aram Galstyan", "title": "Modeling Psychotherapy Dialogues with Kernelized Hashcode\n  Representations: A Nonparametric Information-Theoretic Approach", "comments": "Response generative based model added, along with human evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel dialogue modeling framework, the first-ever nonparametric\nkernel functions based approach for dialogue modeling, which learns kernelized\nhashcodes as compressed text representations; unlike traditional deep learning\nmodels, it handles well relatively small datasets, while also scaling to large\nones. We also derive a novel lower bound on mutual information, used as a\nmodel-selection criterion favoring representations with better alignment\nbetween the utterances of participants in a collaborative dialogue setting, as\nwell as higher predictability of the generated responses. As demonstrated on\nthree real-life datasets, including prominently psychotherapy sessions, the\nproposed approach significantly outperforms several state-of-art neural network\nbased dialogue systems, both in terms of computational efficiency, reducing\ntraining time from days or weeks to hours, and the response quality, achieving\nan order of magnitude improvement over competitors in frequency of being chosen\nas the best model by human evaluators.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 17:39:28 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 00:32:09 GMT"}, {"version": "v3", "created": "Wed, 30 May 2018 03:58:19 GMT"}, {"version": "v4", "created": "Fri, 6 Jul 2018 14:54:22 GMT"}, {"version": "v5", "created": "Thu, 18 Oct 2018 15:23:28 GMT"}, {"version": "v6", "created": "Fri, 8 Mar 2019 02:16:21 GMT"}, {"version": "v7", "created": "Mon, 9 Sep 2019 19:43:38 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Garg", "Sahil", ""], ["Rish", "Irina", ""], ["Cecchi", "Guillermo", ""], ["Goyal", "Palash", ""], ["Ghazarian", "Sarik", ""], ["Gao", "Shuyang", ""], ["Steeg", "Greg Ver", ""], ["Galstyan", "Aram", ""]]}, {"id": "1804.10202", "submitter": "Hao Fang", "authors": "Hao Fang, Hao Cheng, Maarten Sap, Elizabeth Clark, Ari Holtzman, Yejin\n  Choi, Noah A. Smith, Mari Ostendorf", "title": "Sounding Board: A User-Centric and Content-Driven Social Chatbot", "comments": "5 pages, 3 figures, NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Sounding Board, a social chatbot that won the 2017 Amazon Alexa\nPrize. The system architecture consists of several components including spoken\nlanguage processing, dialogue management, language generation, and content\nmanagement, with emphasis on user-centric and content-driven design. We also\nshare insights gained from large-scale online logs based on 160,000\nconversations with real-world users.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 08:11:16 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Fang", "Hao", ""], ["Cheng", "Hao", ""], ["Sap", "Maarten", ""], ["Clark", "Elizabeth", ""], ["Holtzman", "Ari", ""], ["Choi", "Yejin", ""], ["Smith", "Noah A.", ""], ["Ostendorf", "Mari", ""]]}, {"id": "1804.10204", "submitter": "Jonathan Le Roux", "authors": "Zhong-Qiu Wang, Jonathan Le Roux, DeLiang Wang, John R. Hershey", "title": "End-to-End Speech Separation with Unfolded Iterative Phase\n  Reconstruction", "comments": "Submitted to Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an end-to-end approach for single-channel\nspeaker-independent multi-speaker speech separation, where time-frequency (T-F)\nmasking, the short-time Fourier transform (STFT), and its inverse are\nrepresented as layers within a deep network. Previous approaches, rather than\ncomputing a loss on the reconstructed signal, used a surrogate loss based on\nthe target STFT magnitudes. This ignores reconstruction error introduced by\nphase inconsistency. In our approach, the loss function is directly defined on\nthe reconstructed signals, which are optimized for best separation. In\naddition, we train through unfolded iterations of a phase reconstruction\nalgorithm, represented as a series of STFT and inverse STFT layers. While mask\nvalues are typically limited to lie between zero and one for approaches using\nthe mixture phase for reconstruction, this limitation is less relevant if the\nestimated magnitudes are to be used together with phase reconstruction. We thus\npropose several novel activation functions for the output layer of the T-F\nmasking, to allow mask values beyond one. On the publicly-available wsj0-2mix\ndataset, our approach achieves state-of-the-art 12.6 dB scale-invariant\nsignal-to-distortion ratio (SI-SDR) and 13.1 dB SDR, revealing new\npossibilities for deep learning based phase reconstruction and representing a\nfundamental progress towards solving the notoriously-hard cocktail party\nproblem.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 13:14:22 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Wang", "Zhong-Qiu", ""], ["Roux", "Jonathan Le", ""], ["Wang", "DeLiang", ""], ["Hershey", "John R.", ""]]}, {"id": "1804.10413", "submitter": "Jakub K\\'udela", "authors": "Jakub K\\'udela, Irena Holubov\\'a, Ond\\v{r}ej Bojar", "title": "Extracting Parallel Paragraphs from Common Crawl", "comments": "Accepted to the Prague Bulletin of Mathematical Linguistics 107,\n  April 2017", "journal-ref": "The Prague Bulletin of Mathematical Linguistics, Volume 107, Issue\n  1, Pages 39-56, ISSN (Online) 1804-0462 (2017)", "doi": "10.1515/pralin-2017-0003", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the current methods for mining parallel texts from the web assume\nthat web pages of web sites share same structure across languages. We believe\nthat there still exists a non-negligible amount of parallel data spread across\nsources not satisfying this assumption. We propose an approach based on a\ncombination of bivec (a bilingual extension of word2vec) and locality-sensitive\nhashing which allows us to efficiently identify pairs of parallel segments\nlocated anywhere on pages of a given web domain, regardless their structure. We\nvalidate our method on realigning segments from a large parallel corpus.\nAnother experiment with real-world data provided by Common Crawl Foundation\nconfirms that our solution scales to hundreds of terabytes large set of\nweb-crawled data.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 09:33:49 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["K\u00fadela", "Jakub", ""], ["Holubov\u00e1", "Irena", ""], ["Bojar", "Ond\u0159ej", ""]]}, {"id": "1804.10490", "submitter": "Martin Raison", "authors": "Martin Raison, Pierre-Emmanuel Mazar\\'e, Rajarshi Das, Antoine Bordes", "title": "Weaver: Deep Co-Encoding of Questions and Documents for Machine Reading", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims at improving how machines can answer questions directly from\ntext, with the focus of having models that can answer correctly multiple types\nof questions and from various types of texts, documents or even from large\ncollections of them. To that end, we introduce the Weaver model that uses a new\nway to relate a question to a textual context by weaving layers of recurrent\nnetworks, with the goal of making as few assumptions as possible as to how the\ninformation from both question and context should be combined to form the\nanswer. We show empirically on six datasets that Weaver performs well in\nmultiple conditions. For instance, it produces solid results on the very\npopular SQuAD dataset (Rajpurkar et al., 2016), solves almost all bAbI tasks\n(Weston et al., 2015) and greatly outperforms state-of-the-art methods for open\ndomain question answering from text (Chen et al., 2017).\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 13:24:11 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Raison", "Martin", ""], ["Mazar\u00e9", "Pierre-Emmanuel", ""], ["Das", "Rajarshi", ""], ["Bordes", "Antoine", ""]]}, {"id": "1804.10615", "submitter": "Carlos G\\'omez-Rodr\\'iguez", "authors": "Tianze Shi, Carlos G\\'omez-Rodr\\'iguez, Lillian Lee", "title": "Improving Coverage and Runtime Complexity for Exact Inference in\n  Non-Projective Transition-Based Dependency Parsers", "comments": "Proceedings of NAACL-HLT 2018. 6 pages. This version fixes display\n  issue in an author name", "journal-ref": "Proceedings of NAACL-HLT 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize Cohen, G\\'omez-Rodr\\'iguez, and Satta's (2011) parser to a\nfamily of non-projective transition-based dependency parsers allowing\npolynomial-time exact inference. This includes novel parsers with better\ncoverage than Cohen et al. (2011), and even a variant that reduces time\ncomplexity to $O(n^6)$, improving over the known bounds in exact inference for\nnon-projective transition-based parsing. We hope that this piece of theoretical\nwork inspires design of novel transition systems with better coverage and\nbetter run-time guarantees.\n  Code available at https://github.com/tzshi/nonproj-dp-variants-naacl2018\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 17:59:15 GMT"}, {"version": "v2", "created": "Wed, 2 May 2018 16:36:15 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Shi", "Tianze", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""], ["Lee", "Lillian", ""]]}, {"id": "1804.10637", "submitter": "Phong Le", "authors": "Phong Le and Ivan Titov", "title": "Improving Entity Linking by Modeling Latent Relations between Mentions", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity linking involves aligning textual mentions of named entities to their\ncorresponding entries in a knowledge base. Entity linking systems often exploit\nrelations between textual mentions in a document (e.g., coreference) to decide\nif the linking decisions are compatible. Unlike previous approaches, which\nrelied on supervised systems or heuristics to predict these relations, we treat\nrelations as latent variables in our neural entity-linking model. We induce the\nrelations without any supervision while optimizing the entity-linking system in\nan end-to-end fashion. Our multi-relational model achieves the best reported\nscores on the standard benchmark (AIDA-CoNLL) and substantially outperforms its\nrelation-agnostic version. Its training also converges much faster, suggesting\nthat the injected structural bias helps to explain regularities in the training\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 18:28:24 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Le", "Phong", ""], ["Titov", "Ivan", ""]]}, {"id": "1804.10686", "submitter": "Dmitry Ustalov", "authors": "Dmitry Ustalov, Denis Teslenko, Alexander Panchenko, Mikhail\n  Chernoskutov, Chris Biemann, Simone Paolo Ponzetto", "title": "An Unsupervised Word Sense Disambiguation System for Under-Resourced\n  Languages", "comments": "In Proceedings of the 11th Conference on Language Resources and\n  Evaluation (LREC 2018). Miyazaki, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present Watasense, an unsupervised system for word sense\ndisambiguation. Given a sentence, the system chooses the most relevant sense of\neach input word with respect to the semantic similarity between the given\nsentence and the synset constituting the sense of the target word. Watasense\nhas two modes of operation. The sparse mode uses the traditional vector space\nmodel to estimate the most similar word sense corresponding to its context. The\ndense mode, instead, uses synset embeddings to cope with the sparsity problem.\nWe describe the architecture of the present system and also conduct its\nevaluation on three different lexical semantic resources for Russian. We found\nthat the dense mode substantially outperforms the sparse one on all datasets\naccording to the adjusted Rand index.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 20:44:49 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Ustalov", "Dmitry", ""], ["Teslenko", "Denis", ""], ["Panchenko", "Alexander", ""], ["Chernoskutov", "Mikhail", ""], ["Biemann", "Chris", ""], ["Ponzetto", "Simone Paolo", ""]]}, {"id": "1804.10718", "submitter": "Benjamin Robaidek", "authors": "Benjamin Robaidek, Rik Koncel-Kedziorski, Hannaneh Hajishirzi", "title": "Data-Driven Methods for Solving Algebra Word Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore contemporary, data-driven techniques for solving math word\nproblems over recent large-scale datasets. We show that well-tuned neural\nequation classifiers can outperform more sophisticated models such as sequence\nto sequence and self-attention across these datasets. Our error analysis\nindicates that, while fully data driven models show some promise, semantic and\nworld knowledge is necessary for further advances.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 01:19:51 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Robaidek", "Benjamin", ""], ["Koncel-Kedziorski", "Rik", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "1804.10731", "submitter": "Weiyan Shi", "authors": "Weiyan Shi, Zhou Yu", "title": "Sentiment Adaptive End-to-End Dialog Systems", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end learning framework is useful for building dialog systems for its\nsimplicity in training and efficiency in model updating. However, current\nend-to-end approaches only consider user semantic inputs in learning and\nunder-utilize other user information. Therefore, we propose to include user\nsentiment obtained through multimodal information (acoustic, dialogic and\ntextual), in the end-to-end learning framework to make systems more\nuser-adaptive and effective. We incorporated user sentiment information in both\nsupervised and reinforcement learning settings. In both settings, adding\nsentiment information reduced the dialog length and improved the task success\nrate on a bus information search task. This work is the first attempt to\nincorporate multimodal user information in the adaptive end-to-end dialog\nsystem training framework and attained state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 03:29:22 GMT"}, {"version": "v2", "created": "Sun, 13 May 2018 23:09:55 GMT"}, {"version": "v3", "created": "Tue, 2 Jul 2019 21:34:15 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Shi", "Weiyan", ""], ["Yu", "Zhou", ""]]}, {"id": "1804.10747", "submitter": "Chu-Cheng Lin", "authors": "Chu-Cheng Lin and Jason Eisner", "title": "Neural Particle Smoothing for Sampling from Conditional Sequence Models", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce neural particle smoothing, a sequential Monte Carlo method for\nsampling annotations of an input string from a given probability model. In\ncontrast to conventional particle filtering algorithms, we train a proposal\ndistribution that looks ahead to the end of the input string by means of a\nright-to-left LSTM. We demonstrate that this innovation can improve the quality\nof the sample. To motivate our formal choices, we explain how our neural model\nand neural sampler can be viewed as low-dimensional but nonlinear\napproximations to working with HMMs over very large state spaces.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 06:10:45 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Lin", "Chu-Cheng", ""], ["Eisner", "Jason", ""]]}, {"id": "1804.10752", "submitter": "Shiyu Zhou", "authors": "Shiyu Zhou, Linhao Dong, Shuang Xu, Bo Xu", "title": "Syllable-Based Sequence-to-Sequence Speech Recognition with the\n  Transformer in Mandarin Chinese", "comments": "accepted by INTERSPEECH2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence attention-based models have recently shown very\npromising results on automatic speech recognition (ASR) tasks, which integrate\nan acoustic, pronunciation and language model into a single neural network. In\nthese models, the Transformer, a new sequence-to-sequence attention-based model\nrelying entirely on self-attention without using RNNs or convolutions, achieves\na new single-model state-of-the-art BLEU on neural machine translation (NMT)\ntasks. Since the outstanding performance of the Transformer, we extend it to\nspeech and concentrate on it as the basic architecture of sequence-to-sequence\nattention-based model on Mandarin Chinese ASR tasks. Furthermore, we\ninvestigate a comparison between syllable based model and context-independent\nphoneme (CI-phoneme) based model with the Transformer in Mandarin Chinese.\nAdditionally, a greedy cascading decoder with the Transformer is proposed for\nmapping CI-phoneme sequences and syllable sequences into word sequences.\nExperiments on HKUST datasets demonstrate that syllable based model with the\nTransformer performs better than CI-phoneme based counterpart, and achieves a\ncharacter error rate (CER) of \\emph{$28.77\\%$}, which is competitive to the\nstate-of-the-art CER of $28.0\\%$ by the joint CTC-attention based\nencoder-decoder network.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 06:54:11 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2018 07:46:02 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Zhou", "Shiyu", ""], ["Dong", "Linhao", ""], ["Xu", "Shuang", ""], ["Xu", "Bo", ""]]}, {"id": "1804.10911", "submitter": "Yadi Lao", "authors": "Yadi Lao, Jun Xu, Yanyan Lan, Jiafeng Guo, Sheng Gao, Xueqi Cheng", "title": "A Tree Search Algorithm for Sequence Labeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel reinforcement learning based model for\nsequence tagging, referred to as MM-Tag. Inspired by the success and\nmethodology of the AlphaGo Zero, MM-Tag formalizes the problem of sequence\ntagging with a Monte Carlo tree search (MCTS) enhanced Markov decision process\n(MDP) model, in which the time steps correspond to the positions of words in a\nsentence from left to right, and each action corresponds to assign a tag to a\nword. Two long short-term memory networks (LSTM) are used to summarize the past\ntag assignments and words in the sentence. Based on the outputs of LSTMs, the\npolicy for guiding the tag assignment and the value for predicting the whole\ntagging accuracy of the whole sentence are produced. The policy and value are\nthen strengthened with MCTS, which takes the produced raw policy and value as\ninputs, simulates and evaluates the possible tag assignments at the subsequent\npositions, and outputs a better search policy for assigning tags. A\nreinforcement learning algorithm is proposed to train the model parameters. Our\nwork is the first to apply the MCTS enhanced MDP model to the sequence tagging\ntask. We show that MM-Tag can accurately predict the tags thanks to the\nexploratory decision making mechanism introduced by MCTS. Experimental results\nshow based on a chunking benchmark showed that MM-Tag outperformed the\nstate-of-the-art sequence tagging baselines including CRF and CRF with LSTM.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 11:57:15 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 01:13:09 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Lao", "Yadi", ""], ["Xu", "Jun", ""], ["Lan", "Yanyan", ""], ["Guo", "Jiafeng", ""], ["Gao", "Sheng", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1804.10922", "submitter": "Fatima Zohra Smaili", "authors": "Fatima Zohra Smaili, Xin Gao and Robert Hoehndorf", "title": "OPA2Vec: combining formal and informal content of biomedical ontologies\n  to improve similarity-based prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivation: Ontologies are widely used in biology for data annotation,\nintegration, and analysis. In addition to formally structured axioms,\nontologies contain meta-data in the form of annotation axioms which provide\nvaluable pieces of information that characterize ontology classes. Annotations\ncommonly used in ontologies include class labels, descriptions, or synonyms.\nDespite being a rich source of semantic information, the ontology meta-data are\ngenerally unexploited by ontology-based analysis methods such as semantic\nsimilarity measures. Results: We propose a novel method, OPA2Vec, to generate\nvector representations of biological entities in ontologies by combining formal\nontology axioms and annotation axioms from the ontology meta-data. We apply a\nWord2Vec model that has been pre-trained on PubMed abstracts to produce feature\nvectors from our collected data. We validate our method in two different ways:\nfirst, we use the obtained vector representations of proteins as a similarity\nmeasure to predict protein-protein interaction (PPI) on two different datasets.\nSecond, we evaluate our method on predicting gene-disease associations based on\nphenotype similarity by generating vector representations of genes and diseases\nusing a phenotype ontology, and applying the obtained vectors to predict\ngene-disease associations. These two experiments are just an illustration of\nthe possible applications of our method. OPA2Vec can be used to produce vector\nrepresentations of any biomedical entity given any type of biomedical ontology.\nAvailability: https://github.com/bio-ontology-research-group/opa2vec Contact:\nrobert.hoehndorf@kaust.edu.sa and xin.gao@kaust.edu.sa.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 12:49:29 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Smaili", "Fatima Zohra", ""], ["Gao", "Xin", ""], ["Hoehndorf", "Robert", ""]]}, {"id": "1804.10959", "submitter": "Taku Kudo", "authors": "Taku Kudo", "title": "Subword Regularization: Improving Neural Network Translation Models with\n  Multiple Subword Candidates", "comments": "Accepted as a long paper at ACL2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subword units are an effective way to alleviate the open vocabulary problems\nin neural machine translation (NMT). While sentences are usually converted into\nunique subword sequences, subword segmentation is potentially ambiguous and\nmultiple segmentations are possible even with the same vocabulary. The question\naddressed in this paper is whether it is possible to harness the segmentation\nambiguity as a noise to improve the robustness of NMT. We present a simple\nregularization method, subword regularization, which trains the model with\nmultiple subword segmentations probabilistically sampled during training. In\naddition, for better subword sampling, we propose a new subword segmentation\nalgorithm based on a unigram language model. We experiment with multiple\ncorpora and report consistent improvements especially on low resource and\nout-of-domain settings.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 16:13:44 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Kudo", "Taku", ""]]}, {"id": "1804.10974", "submitter": "Zihang Dai", "authors": "Zihang Dai, Qizhe Xie, Eduard Hovy", "title": "From Credit Assignment to Entropy Regularization: Two New Algorithms for\n  Neural Sequence Prediction", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this work, we study the credit assignment problem in reward augmented\nmaximum likelihood (RAML) learning, and establish a theoretical equivalence\nbetween the token-level counterpart of RAML and the entropy regularized\nreinforcement learning. Inspired by the connection, we propose two sequence\nprediction algorithms, one extending RAML with fine-grained credit assignment\nand the other improving Actor-Critic with a systematic entropy regularization.\nOn two benchmark datasets, we show the proposed algorithms outperform RAML and\nActor-Critic respectively, providing new alternatives to sequence prediction.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 18:27:43 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Dai", "Zihang", ""], ["Xie", "Qizhe", ""], ["Hovy", "Eduard", ""]]}, {"id": "1804.11019", "submitter": "Fei Liu", "authors": "Fei Liu and Trevor Cohn and Timothy Baldwin", "title": "Recurrent Entity Networks with Delayed Memory Update for Targeted\n  Aspect-based Sentiment Analysis", "comments": "Accepted to NAACL 2018 (camera-ready)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural networks have been shown to achieve impressive results for\nsentence-level sentiment analysis, targeted aspect-based sentiment analysis\n(TABSA) --- extraction of fine-grained opinion polarity w.r.t. a pre-defined\nset of aspects --- remains a difficult task. Motivated by recent advances in\nmemory-augmented models for machine reading, we propose a novel architecture,\nutilising external \"memory chains\" with a delayed memory update mechanism to\ntrack entities. On a TABSA task, the proposed model demonstrates substantial\nimprovements over state-of-the-art approaches, including those using external\nknowledge bases.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 01:57:31 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Liu", "Fei", ""], ["Cohn", "Trevor", ""], ["Baldwin", "Timothy", ""]]}, {"id": "1804.11046", "submitter": "Albert Haque", "authors": "Albert Haque, Corinna Fukushima", "title": "Automatic Documentation of ICD Codes with Far-Field Speech Recognition", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/3", "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Documentation errors increase healthcare costs and cause unnecessary patient\ndeaths. As the standard language for diagnoses and billing, ICD codes serve as\nthe foundation for medical documentation worldwide. Despite the prevalence of\nelectronic medical records, hospitals still witness high levels of ICD\nmiscoding. In this paper, we propose to automatically document ICD codes with\nfar-field speech recognition. Far-field speech occurs when the microphone is\nlocated several meters from the source, as is common with smart homes and\nsecurity systems. Our method combines acoustic signal processing with recurrent\nneural networks to recognize and document ICD codes in real time. To evaluate\nour model, we collected a far-field speech dataset of ICD-10 codes and found\nour model to achieve 87% accuracy with a BLEU score of 85%. By sampling from an\nunsupervised medical language model, our method is able to outperform existing\nmethods. Overall, this work shows the potential of automatic speech recognition\nto provide efficient, accurate, and cost-effective healthcare documentation.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 04:41:33 GMT"}, {"version": "v2", "created": "Sun, 4 Nov 2018 08:37:12 GMT"}, {"version": "v3", "created": "Wed, 21 Nov 2018 03:59:04 GMT"}, {"version": "v4", "created": "Tue, 27 Nov 2018 01:51:13 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Haque", "Albert", ""], ["Fukushima", "Corinna", ""]]}, {"id": "1804.11067", "submitter": "Trung Ngo Trong", "authors": "Trung Ngo Trong and Ville Hautam\\\"aki and Kristiina Jokinen", "title": "Staircase Network: structural language identification via hierarchical\n  attentive units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language recognition system is typically trained directly to optimize\nclassification error on the target language labels, without using the external,\nor meta-information in the estimation of the model parameters. However labels\nare not independent of each other, there is a dependency enforced by, for\nexample, the language family, which affects negatively on classification. The\nother external information sources (e.g. audio encoding, telephony or video\nspeech) can also decrease classification accuracy. In this paper, we attempt to\nsolve these issues by constructing a deep hierarchical neural network, where\ndifferent levels of meta-information are encapsulated by attentive prediction\nunits and also embedded into the training progress. The proposed method learns\nauxiliary tasks to obtain robust internal representation and to construct a\nvariant of attentive units within the hierarchical model. The final result is\nthe structural prediction of the target language and a closely related language\nfamily. The algorithm reflects a \"staircase\" way of learning in both its\narchitecture and training, advancing from the fundamental audio encoding to the\nlanguage family level and finally to the target language level. This process\nnot only improves generalization but also tackles the issues of imbalanced\nclass priors and channel variability in the deep neural network model. Our\nexperimental findings show that the proposed architecture outperforms the\nstate-of-the-art i-vector approaches on both small and big language corpora by\na significant margin.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 07:55:55 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Trong", "Trung Ngo", ""], ["Hautam\u00e4ki", "Ville", ""], ["Jokinen", "Kristiina", ""]]}, {"id": "1804.11105", "submitter": "Asan Agibetov", "authors": "Asan Agibetov, Matthias Samwald", "title": "Fast and scalable learning of neuro-symbolic representations of\n  biomedical knowledge", "comments": "Accepted to workshop on Deep Learning for Knowledge Graphs and\n  Semantic Technologies (DL4KGS) at ESWC 2018, June 2018, Greece", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we address the problem of fast and scalable learning of\nneuro-symbolic representations for general biological knowledge. Based on a\nrecently published comprehensive biological knowledge graph (Alshahrani, 2017)\nthat was used for demonstrating neuro-symbolic representation learning, we show\nhow to train fast (under 1 minute) log-linear neural embeddings of the\nentities. We utilize these representations as inputs for machine learning\nclassifiers to enable important tasks such as biological link prediction.\nClassifiers are trained by concatenating learned entity embeddings to represent\nentity relations, and training classifiers on the concatenated embeddings to\ndiscern true relations from automatically generated negative examples. Our\nsimple embedding methodology greatly improves on classification error compared\nto previously published state-of-the-art results, yielding a maximum increase\nof $+0.28$ F-measure and $+0.22$ ROC AUC scores for the most difficult\nbiological link prediction problem. Finally, our embedding approach is orders\nof magnitude faster to train ($\\leq$ 1 minute vs. hours), much more economical\nin terms of embedding dimensions ($d=50$ vs. $d=512$), and naturally encodes\nthe directionality of the asymmetric biological relations, that can be\ncontrolled by the order with which we concatenate the embeddings.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 09:54:12 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Agibetov", "Asan", ""], ["Samwald", "Matthias", ""]]}, {"id": "1804.11109", "submitter": "Arpit Mittal", "authors": "Andrew Hopkinson and Amit Gurdasani and Dave Palfrey and Arpit Mittal", "title": "Demand-Weighted Completeness Prediction for a Knowledge Base", "comments": "To appear in NAACL-HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce the notion of Demand-Weighted Completeness,\nallowing estimation of the completeness of a knowledge base with respect to how\nit is used. Defining an entity by its classes, we employ usage data to predict\nthe distribution over relations for that entity. For example, instances of\nperson in a knowledge base may require a birth date, name and nationality to be\nconsidered complete. These predicted relation distributions enable detection of\nimportant gaps in the knowledge base, and define the required facts for unseen\nentities. Such characterisation of the knowledge base can also quantify how\nusage and completeness change over time. We demonstrate a method to measure\nDemand-Weighted Completeness, and show that a simple neural network model\nperforms well at this prediction task.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 10:06:46 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Hopkinson", "Andrew", ""], ["Gurdasani", "Amit", ""], ["Palfrey", "Dave", ""], ["Mittal", "Arpit", ""]]}, {"id": "1804.11146", "submitter": "Micael Carvalho", "authors": "Micael Carvalho, R\\'emi Cad\\`ene, David Picard, Laure Soulier, Nicolas\n  Thome, Matthieu Cord", "title": "Cross-Modal Retrieval in the Cooking Context: Learning Semantic\n  Text-Image Embeddings", "comments": "accepted at the 41st International ACM SIGIR Conference on Research\n  and Development in Information Retrieval, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing powerful tools that support cooking activities has rapidly gained\npopularity due to the massive amounts of available data, as well as recent\nadvances in machine learning that are capable of analyzing them. In this paper,\nwe propose a cross-modal retrieval model aligning visual and textual data (like\npictures of dishes and their recipes) in a shared representation space. We\ndescribe an effective learning scheme, capable of tackling large-scale\nproblems, and validate it on the Recipe1M dataset containing nearly 1 million\npicture-recipe pairs. We show the effectiveness of our approach regarding\nprevious state-of-the-art models and present qualitative results over\ncomputational cooking use cases.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 12:14:32 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Carvalho", "Micael", ""], ["Cad\u00e8ne", "R\u00e9mi", ""], ["Picard", "David", ""], ["Soulier", "Laure", ""], ["Thome", "Nicolas", ""], ["Cord", "Matthieu", ""]]}, {"id": "1804.11149", "submitter": "Sheikh Shams Azam", "authors": "Sheikh Shams Azam, Manoj Raju, Venkatesh Pagidimarri, Vamsi\n  Kasivajjala", "title": "Q-Map: Clinical Concept Mining from Clinical Documents", "comments": "6 pages, 1 figure", "journal-ref": "International Journal of Computer and Information Engineering,\n  12(9), 2018, 691 - 696", "doi": "10.5281/zenodo.1474513", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade, there has been a steep rise in the data-driven analysis\nin major areas of medicine, such as clinical decision support system, survival\nanalysis, patient similarity analysis, image analytics etc. Most of the data in\nthe field are well-structured and available in numerical or categorical formats\nwhich can be used for experiments directly. But on the opposite end of the\nspectrum, there exists a wide expanse of data that is intractable for direct\nanalysis owing to its unstructured nature which can be found in the form of\ndischarge summaries, clinical notes, procedural notes which are in human\nwritten narrative format and neither have any relational model nor any standard\ngrammatical structure. An important step in the utilization of these texts for\nsuch studies is to transform and process the data to retrieve structured\ninformation from the haystack of irrelevant data using information retrieval\nand data mining techniques. To address this problem, the authors present Q-Map\nin this paper, which is a simple yet robust system that can sift through\nmassive datasets with unregulated formats to retrieve structured information\naggressively and efficiently. It is backed by an effective mining technique\nwhich is based on a string matching algorithm that is indexed on curated\nknowledge sources, that is both fast and configurable. The authors also briefly\nexamine its comparative performance with MetaMap, one of the most reputed tools\nfor medical concepts retrieval and present the advantages the former displays\nover the latter.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 12:19:03 GMT"}, {"version": "v2", "created": "Mon, 16 Jul 2018 12:24:39 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Azam", "Sheikh Shams", ""], ["Raju", "Manoj", ""], ["Pagidimarri", "Venkatesh", ""], ["Kasivajjala", "Vamsi", ""]]}, {"id": "1804.11225", "submitter": "Leshem Choshen", "authors": "Leshem Choshen and Omri Abend", "title": "Automatic Metric Validation for Grammatical Error Correction", "comments": "Accepted to ACL2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric validation in Grammatical Error Correction (GEC) is currently done by\nobserving the correlation between human and metric-induced rankings. However,\nsuch correlation studies are costly, methodologically troublesome, and suffer\nfrom low inter-rater agreement. We propose MAEGE, an automatic methodology for\nGEC metric validation, that overcomes many of the difficulties with existing\npractices. Experiments with \\maege\\ shed a new light on metric quality, showing\nfor example that the standard $M^2$ metric fares poorly on corpus-level\nranking. Moreover, we use MAEGE to perform a detailed analysis of metric\nbehavior, showing that correcting some types of errors is consistently\npenalized by existing metrics.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 14:17:36 GMT"}, {"version": "v2", "created": "Mon, 7 May 2018 14:44:37 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Choshen", "Leshem", ""], ["Abend", "Omri", ""]]}, {"id": "1804.11243", "submitter": "Shih-Feng Yang", "authors": "Shih-Feng Yang and Julia Taylor Rayz", "title": "An Event Detection Approach Based On Twitter Hashtags", "comments": "The 18th International Conference on Computational Linguistics and\n  Intelligent Text Processing, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twitter is one of the most popular microblogging services in the world. The\ngreat amount of information within Twitter makes it an important information\nchannel for people to learn and share news. Twitter hashtag is an popular\nfeature that can be viewed as human-labeled information which people use to\nidentify the topic of a tweet. Many researchers have proposed event-detection\napproaches that can monitor Twitter data and determine whether special events,\nsuch as accidents, extreme weather, earthquakes, or crimes take place. Although\nmany approaches use hashtags as one of their features, few of them explicitly\nfocus on the effectiveness of using hashtags on event detection. In this study,\nwe proposed an event detection approach that utilizes hashtags in tweets. We\nadopted the feature extraction used in STREAMCUBE and applied a clustering\nK-means approach to it. The experiments demonstrated that the K-means approach\nperformed better than STREAMCUBE in the clustering results. A discussion on\noptimal K values for the K-means approach is also provided.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 19:57:29 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Yang", "Shih-Feng", ""], ["Rayz", "Julia Taylor", ""]]}, {"id": "1804.11251", "submitter": "Enrico Santus", "authors": "Enrico Santus, Chris Biemann, Emmanuele Chersoni", "title": "BomJi at SemEval-2018 Task 10: Combining Vector-, Pattern- and\n  Graph-based Information to Identify Discriminative Attributes", "comments": "3 tables, 4 pages, SemEval, NAACL, NLP, Task", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes BomJi, a supervised system for capturing discriminative\nattributes in word pairs (e.g. yellow as discriminative for banana over\nwatermelon). The system relies on an XGB classifier trained on carefully\nengineered graph-, pattern- and word embedding based features. It participated\nin the SemEval- 2018 Task 10 on Capturing Discriminative Attributes, achieving\nan F1 score of 0:73 and ranking 2nd out of 26 participant systems.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 14:58:22 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Santus", "Enrico", ""], ["Biemann", "Chris", ""], ["Chersoni", "Emmanuele", ""]]}, {"id": "1804.11254", "submitter": "Leshem Choshen", "authors": "Leshem Choshen and Omri Abend", "title": "Inherent Biases in Reference based Evaluation for Grammatical Error\n  Correction and Text Simplification", "comments": "Accepted to ACL 2018 (figures currently omitted due to technical\n  arxiv issues", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prevalent use of too few references for evaluating text-to-text\ngeneration is known to bias estimates of their quality ({\\it low coverage bias}\nor LCB). This paper shows that overcoming LCB in Grammatical Error Correction\n(GEC) evaluation cannot be attained by re-scaling or by increasing the number\nof references in any feasible range, contrary to previous suggestions. This is\ndue to the long-tailed distribution of valid corrections for a sentence.\nConcretely, we show that LCB incentivizes GEC systems to avoid correcting even\nwhen they can generate a valid correction. Consequently, existing systems\nobtain comparable or superior performance compared to humans, by making few but\ntargeted changes to the input. Similar effects on Text Simplification further\nsupport our claims.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 14:59:56 GMT"}, {"version": "v2", "created": "Tue, 1 May 2018 17:45:17 GMT"}, {"version": "v3", "created": "Wed, 18 Sep 2019 08:30:56 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Choshen", "Leshem", ""], ["Abend", "Omri", ""]]}, {"id": "1804.11258", "submitter": "Xipeng Qiu", "authors": "Zhan Shi, Xinchi Chen, Xipeng Qiu, Xuanjing Huang", "title": "Toward Diverse Text Generation with Inverse Reinforcement Learning", "comments": "7 pages, IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text generation is a crucial task in NLP. Recently, several adversarial\ngenerative models have been proposed to improve the exposure bias problem in\ntext generation. Though these models gain great success, they still suffer from\nthe problems of reward sparsity and mode collapse. In order to address these\ntwo problems, in this paper, we employ inverse reinforcement learning (IRL) for\ntext generation. Specifically, the IRL framework learns a reward function on\ntraining data, and then an optimal policy to maximum the expected total reward.\nSimilar to the adversarial models, the reward and policy function in IRL are\noptimized alternately. Our method has two advantages: (1) the reward function\ncan produce more dense reward signals. (2) the generation policy, trained by\n\"entropy regularized\" policy gradient, encourages to generate more diversified\ntexts. Experiment results demonstrate that our proposed method can generate\nhigher quality texts than the previous methods.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 15:04:21 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 10:19:42 GMT"}, {"version": "v3", "created": "Thu, 7 Jun 2018 06:04:33 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Shi", "Zhan", ""], ["Chen", "Xinchi", ""], ["Qiu", "Xipeng", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1804.11283", "submitter": "Yoav Artzi", "authors": "Max Grusky, Mor Naaman, Yoav Artzi", "title": "Newsroom: A Dataset of 1.3 Million Summaries with Diverse Extractive\n  Strategies", "comments": "Proceedings of NAACL-HLT 2018 (Long Paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present NEWSROOM, a summarization dataset of 1.3 million articles and\nsummaries written by authors and editors in newsrooms of 38 major news\npublications. Extracted from search and social media metadata between 1998 and\n2017, these high-quality summaries demonstrate high diversity of summarization\nstyles. In particular, the summaries combine abstractive and extractive\nstrategies, borrowing words and phrases from articles at varying rates. We\nanalyze the extraction strategies used in NEWSROOM summaries against other\ndatasets to quantify the diversity and difficulty of our new data, and train\nexisting methods on the data to evaluate its utility and challenges.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 15:53:05 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 19:10:09 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Grusky", "Max", ""], ["Naaman", "Mor", ""], ["Artzi", "Yoav", ""]]}, {"id": "1804.11297", "submitter": "Rachid Riad", "authors": "Rachid Riad, Corentin Dancette, Julien Karadayi, Neil Zeghidour,\n  Thomas Schatz, Emmanuel Dupoux", "title": "Sampling strategies in Siamese Networks for unsupervised speech\n  representation learning", "comments": "Conference paper at Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have investigated siamese network architectures for learning\ninvariant speech representations using same-different side information at the\nword level. Here we investigate systematically an often ignored component of\nsiamese networks: the sampling procedure (how pairs of same vs. different\ntokens are selected). We show that sampling strategies taking into account\nZipf's Law, the distribution of speakers and the proportions of same and\ndifferent pairs of words significantly impact the performance of the network.\nIn particular, we show that word frequency compression improves learning across\na large range of variations in number of training pairs. This effect does not\napply to the same extent to the fully unsupervised setting, where the pairs of\nsame-different words are obtained by spoken term discovery. We apply these\nresults to pairs of words discovered using an unsupervised algorithm and show\nan improvement on state-of-the-art in unsupervised representation learning\nusing siamese networks.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 16:19:51 GMT"}, {"version": "v2", "created": "Thu, 23 Aug 2018 14:17:38 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Riad", "Rachid", ""], ["Dancette", "Corentin", ""], ["Karadayi", "Julien", ""], ["Zeghidour", "Neil", ""], ["Schatz", "Thomas", ""], ["Dupoux", "Emmanuel", ""]]}, {"id": "1804.11324", "submitter": "Gonzalo Iglesias", "authors": "Gonzalo Iglesias, William Tambellini, Adri\\`a De Gispert, Eva Hasler\n  and Bill Byrne", "title": "Accelerating NMT Batched Beam Decoding with LMBR Posteriors for\n  Deployment", "comments": "Proceedings of NAACL-HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a batched beam decoding algorithm for NMT with LMBR n-gram\nposteriors, showing that LMBR techniques still yield gains on top of the best\nrecently reported results with Transformers. We also discuss acceleration\nstrategies for deployment, and the effect of the beam size and batching on\nmemory and speed.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 17:03:07 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Iglesias", "Gonzalo", ""], ["Tambellini", "William", ""], ["De Gispert", "Adri\u00e0", ""], ["Hasler", "Eva", ""], ["Byrne", "Bill", ""]]}, {"id": "1804.11346", "submitter": "Marcos Zampieri", "authors": "Iria del R\\'io, Marcos Zampieri, Shervin Malmasi", "title": "A Portuguese Native Language Identification Dataset", "comments": "Proceedings of The 13th Workshop on Innovative Use of NLP for\n  Building Educational Applications (BEA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present NLI-PT, the first Portuguese dataset compiled for\nNative Language Identification (NLI), the task of identifying an author's first\nlanguage based on their second language writing. The dataset includes 1,868\nstudent essays written by learners of European Portuguese, native speakers of\nthe following L1s: Chinese, English, Spanish, German, Russian, French,\nJapanese, Italian, Dutch, Tetum, Arabic, Polish, Korean, Romanian, and Swedish.\nNLI-PT includes the original student text and four different types of\nannotation: POS, fine-grained POS, constituency parses, and dependency parses.\nNLI-PT can be used not only in NLI but also in research on several topics in\nthe field of Second Language Acquisition and educational NLP. We discuss\npossible applications of this dataset and present the results obtained for the\nfirst lexical baseline system for Portuguese NLI.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 17:52:28 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["del R\u00edo", "Iria", ""], ["Zampieri", "Marcos", ""], ["Malmasi", "Shervin", ""]]}]