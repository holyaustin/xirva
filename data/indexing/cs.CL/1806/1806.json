[{"id": "1806.00044", "submitter": "Subhojeet Pramanik", "authors": "Subhojeet Pramanik, Aman Hussain", "title": "Text normalization using memory augmented neural networks", "comments": "9 pages, 10 tables, 3 figures", "journal-ref": "Speech Communication, Volume 109, 2019, Pages 15-23, ISSN\n  0167-6393", "doi": "10.1016/j.specom.2019.02.003", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We perform text normalization, i.e. the transformation of words from the\nwritten to the spoken form, using a memory augmented neural network. With the\naddition of dynamic memory access and storage mechanism, we present a neural\narchitecture that will serve as a language-agnostic text normalization system\nwhile avoiding the kind of unacceptable errors made by the LSTM-based recurrent\nneural networks. By successfully reducing the frequency of such mistakes, we\nshow that this novel architecture is indeed a better alternative. Our proposed\nsystem requires significantly lesser amounts of data, training time and compute\nresources. Additionally, we perform data up-sampling, circumventing the data\nsparsity problem in some semiotic classes, to show that sufficient examples in\nany particular class can improve the performance of our text normalization\nsystem. Although a few occurrences of these errors still remain in certain\nsemiotic classes, we demonstrate that memory augmented networks with\nmeta-learning capabilities can open many doors to a superior text normalization\nsystem.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 18:37:37 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2018 14:38:54 GMT"}, {"version": "v3", "created": "Wed, 3 Apr 2019 18:44:30 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Pramanik", "Subhojeet", ""], ["Hussain", "Aman", ""]]}, {"id": "1806.00047", "submitter": "Valts Blukis", "authors": "Valts Blukis and Nataly Brukhim and Andrew Bennett and Ross A. Knepper\n  and Yoav Artzi", "title": "Following High-level Navigation Instructions on a Simulated Quadcopter\n  with Imitation Learning", "comments": "To appear in Robotics: Science and Systems (RSS), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method for following high-level navigation instructions by\nmapping directly from images, instructions and pose estimates to continuous\nlow-level velocity commands for real-time control. The Grounded Semantic\nMapping Network (GSMN) is a fully-differentiable neural network architecture\nthat builds an explicit semantic map in the world reference frame by\nincorporating a pinhole camera projection model within the network. The\ninformation stored in the map is learned from experience, while the\nlocal-to-world transformation is computed explicitly. We train the model using\nDAggerFM, a modified variant of DAgger that trades tabular convergence\nguarantees for improved training speed and memory use. We test GSMN in virtual\nenvironments on a realistic quadcopter simulator and show that incorporating an\nexplicit mapping and grounding modules allows GSMN to outperform strong neural\nbaselines and almost reach an expert policy performance. Finally, we analyze\nthe learned map representations and show that using an explicit map leads to an\ninterpretable instruction-following model.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 18:42:26 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Blukis", "Valts", ""], ["Brukhim", "Nataly", ""], ["Bennett", "Andrew", ""], ["Knepper", "Ross A.", ""], ["Artzi", "Yoav", ""]]}, {"id": "1806.00187", "submitter": "Myle Ott", "authors": "Myle Ott and Sergey Edunov and David Grangier and Michael Auli", "title": "Scaling Neural Machine Translation", "comments": "WMT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence to sequence learning models still require several days to reach\nstate of the art performance on large benchmark datasets using a single\nmachine. This paper shows that reduced precision and large batch training can\nspeedup training by nearly 5x on a single 8-GPU machine with careful tuning and\nimplementation. On WMT'14 English-German translation, we match the accuracy of\nVaswani et al. (2017) in under 5 hours when training on 8 GPUs and we obtain a\nnew state of the art of 29.3 BLEU after training for 85 minutes on 128 GPUs. We\nfurther improve these results to 29.8 BLEU by training on the much larger\nParacrawl dataset. On the WMT'14 English-French task, we obtain a\nstate-of-the-art BLEU of 43.2 in 8.5 hours on 128 GPUs.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2018 04:33:16 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 16:12:21 GMT"}, {"version": "v3", "created": "Tue, 4 Sep 2018 23:19:27 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Ott", "Myle", ""], ["Edunov", "Sergey", ""], ["Grangier", "David", ""], ["Auli", "Michael", ""]]}, {"id": "1806.00258", "submitter": "Chenhui Chu", "authors": "Chenhui Chu and Rui Wang", "title": "A Survey of Domain Adaptation for Neural Machine Translation", "comments": "COLING 2018, 16 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural machine translation (NMT) is a deep learning based approach for\nmachine translation, which yields the state-of-the-art translation performance\nin scenarios where large-scale parallel corpora are available. Although the\nhigh-quality and domain-specific translation is crucial in the real world,\ndomain-specific corpora are usually scarce or nonexistent, and thus vanilla NMT\nperforms poorly in such scenarios. Domain adaptation that leverages both\nout-of-domain parallel corpora as well as monolingual corpora for in-domain\ntranslation, is very important for domain-specific translation. In this paper,\nwe give a comprehensive survey of the state-of-the-art domain adaptation\ntechniques for NMT.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2018 09:54:32 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Chu", "Chenhui", ""], ["Wang", "Rui", ""]]}, {"id": "1806.00354", "submitter": "Shane Steinert-Threlkeld", "authors": "Sandro Pezzelle, Shane Steinert-Threlkeld, Raffaela Bernardi, Jakub\n  Szymanik", "title": "Some of Them Can be Guessed! Exploring the Effect of Linguistic Context\n  in Predicting Quantifiers", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the role of linguistic context in predicting quantifiers (`few',\n`all'). We collect crowdsourced data from human participants and test various\nmodels in a local (single-sentence) and a global context (multi-sentence)\ncondition. Models significantly out-perform humans in the former setting and\nare only slightly better in the latter. While human performance improves with\nmore linguistic context (especially on proportional quantifiers), model\nperformance suffers. Models are very effective in exploiting lexical and\nmorpho-syntactic patterns; humans are better at genuinely understanding the\nmeaning of the (global) context.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2018 14:02:39 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Pezzelle", "Sandro", ""], ["Steinert-Threlkeld", "Shane", ""], ["Bernardi", "Raffaela", ""], ["Szymanik", "Jakub", ""]]}, {"id": "1806.00358", "submitter": "Rajarshi Das", "authors": "Michael Boratko, Harshit Padigela, Divyendra Mikkilineni, Pritish\n  Yuvraj, Rajarshi Das, Andrew McCallum, Maria Chang, Achille Fokoue-Nkoutche,\n  Pavan Kapanipathi, Nicholas Mattei, Ryan Musa, Kartik Talamadupula, Michael\n  Witbrock", "title": "A Systematic Classification of Knowledge, Reasoning, and Context within\n  the ARC Dataset", "comments": "Presented at the Machine Reading for Question Answering (MRQA 2018)\n  Workshop at the 55th Annual Meeting of the Association for Computational\n  Linguistics (ACL 2018). 11 pages, 5 tables, 4 figures. Added missing\n  citations in the latest draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent work of Clark et al. introduces the AI2 Reasoning Challenge (ARC)\nand the associated ARC dataset that partitions open domain, complex science\nquestions into an Easy Set and a Challenge Set. That paper includes an analysis\nof 100 questions with respect to the types of knowledge and reasoning required\nto answer them; however, it does not include clear definitions of these types,\nnor does it offer information about the quality of the labels. We propose a\ncomprehensive set of definitions of knowledge and reasoning types necessary for\nanswering the questions in the ARC dataset. Using ten annotators and a\nsophisticated annotation interface, we analyze the distribution of labels\nacross the Challenge Set and statistics related to them. Additionally, we\ndemonstrate that although naive information retrieval methods return sentences\nthat are irrelevant to answering the query, sufficient supporting text is often\npresent in the (ARC) corpus. Evaluating with human-selected relevant sentences\nimproves the performance of a neural machine comprehension model by 42 points.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2018 14:06:45 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 20:59:32 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Boratko", "Michael", ""], ["Padigela", "Harshit", ""], ["Mikkilineni", "Divyendra", ""], ["Yuvraj", "Pritish", ""], ["Das", "Rajarshi", ""], ["McCallum", "Andrew", ""], ["Chang", "Maria", ""], ["Fokoue-Nkoutche", "Achille", ""], ["Kapanipathi", "Pavan", ""], ["Mattei", "Nicholas", ""], ["Musa", "Ryan", ""], ["Talamadupula", "Kartik", ""], ["Witbrock", "Michael", ""]]}, {"id": "1806.00512", "submitter": "Maohua Zhu", "authors": "Maohua Zhu, Jason Clemons, Jeff Pool, Minsoo Rhu, Stephen W. Keckler,\n  Yuan Xie", "title": "Structurally Sparsified Backward Propagation for Faster Long Short-Term\n  Memory Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploiting sparsity enables hardware systems to run neural networks faster\nand more energy-efficiently. However, most prior sparsity-centric optimization\ntechniques only accelerate the forward pass of neural networks and usually\nrequire an even longer training process with iterative pruning and retraining.\nWe observe that artificially inducing sparsity in the gradients of the gates in\nan LSTM cell has little impact on the training quality. Further, we can enforce\nstructured sparsity in the gate gradients to make the LSTM backward pass up to\n45% faster than the state-of-the-art dense approach and 168% faster than the\nstate-of-the-art sparsifying method on modern GPUs. Though the structured\nsparsifying method can impact the accuracy of a model, this performance gap can\nbe eliminated by mixing our sparse training method and the standard dense\ntraining method. Experimental results show that the mixed method can achieve\ncomparable results in a shorter time span than using purely dense training.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2018 19:08:30 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Zhu", "Maohua", ""], ["Clemons", "Jason", ""], ["Pool", "Jeff", ""], ["Rhu", "Minsoo", ""], ["Keckler", "Stephen W.", ""], ["Xie", "Yuan", ""]]}, {"id": "1806.00522", "submitter": "AbdelRahim Elmadany", "authors": "AbdelRahim Elmadany, Sherif Abdou, Mervat Gheith", "title": "Improving Dialogue Act Classification for Spontaneous Arabic Speech and\n  Instant Messages at Utterance Level", "comments": null, "journal-ref": "11th edition of the Language Resources and Evaluation Conference,\n  7-12 May 2018, Miyazaki (Japan)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to model and automatically detect dialogue act is an important\nstep toward understanding spontaneous speech and Instant Messages. However, it\nhas been difficult to infer a dialogue act from a surface utterance because it\nhighly depends on the context of the utterance and speaker linguistic\nknowledge; especially in Arabic dialects. This paper proposes a statistical\ndialogue analysis model to recognize utterance's dialogue acts using a\nmulti-classes hierarchical structure. The model can automatically acquire\nprobabilistic discourse knowledge from a dialogue corpus were collected and\nannotated manually from multi-genre Egyptian call-centers. Extensive\nexperiments were conducted using Support Vector Machines classifier to evaluate\nthe system performance. The results attained in the term of average F-measure\nscores of 0.912; showed that the proposed approach has moderately improved\nF-measure by approximately 20%.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 22:27:15 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Elmadany", "AbdelRahim", ""], ["Abdou", "Sherif", ""], ["Gheith", "Mervat", ""]]}, {"id": "1806.00525", "submitter": "Huda Alamri", "authors": "Huda Alamri, Vincent Cartillier, Raphael Gontijo Lopes, Abhishek Das,\n  Jue Wang, Irfan Essa, Dhruv Batra, Devi Parikh, Anoop Cherian, Tim K. Marks,\n  Chiori Hori", "title": "Audio Visual Scene-Aware Dialog (AVSD) Challenge at DSTC7", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scene-aware dialog systems will be able to have conversations with users\nabout the objects and events around them. Progress on such systems can be made\nby integrating state-of-the-art technologies from multiple research areas\nincluding end-to-end dialog systems visual dialog, and video description. We\nintroduce the Audio Visual Scene Aware Dialog (AVSD) challenge and dataset. In\nthis challenge, which is one track of the 7th Dialog System Technology\nChallenges (DSTC7) workshop1, the task is to build a system that generates\nresponses in a dialog about an input video\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2018 19:51:58 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Alamri", "Huda", ""], ["Cartillier", "Vincent", ""], ["Lopes", "Raphael Gontijo", ""], ["Das", "Abhishek", ""], ["Wang", "Jue", ""], ["Essa", "Irfan", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""], ["Cherian", "Anoop", ""], ["Marks", "Tim K.", ""], ["Hori", "Chiori", ""]]}, {"id": "1806.00588", "submitter": "Xing Shi", "authors": "Xing Shi, Shizhen Xu, Kevin Knight", "title": "Fast Locality Sensitive Hashing for Beam Search on GPU", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a GPU-based Locality Sensitive Hashing (LSH) algorithm to speed up\nbeam search for sequence models. We utilize the winner-take-all (WTA) hash,\nwhich is based on relative ranking order of hidden dimensions and thus\nresilient to perturbations in numerical values. Our algorithm is designed by\nfully considering the underling architecture of CUDA-enabled GPUs\n(Algorithm/Architecture Co-design): 1) A parallel Cuckoo hash table is applied\nfor LSH code lookup (guaranteed O(1) lookup time); 2) Candidate lists are\nshared across beams to maximize the parallelism; 3) Top frequent words are\nmerged into candidate lists to improve performance. Experiments on 4\nlarge-scale neural machine translation models demonstrate that our algorithm\ncan achieve up to 4x speedup on softmax module, and 2x overall speedup without\nhurting BLEU on GPU.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jun 2018 06:18:15 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Shi", "Xing", ""], ["Xu", "Shizhen", ""], ["Knight", "Kevin", ""]]}, {"id": "1806.00591", "submitter": "Jon Gauthier", "authors": "Jon Gauthier, Anna Ivanova", "title": "Does the brain represent words? An evaluation of brain decoding studies\n  of language understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language decoding studies have identified word representations which can be\nused to predict brain activity in response to novel words and sentences\n(Anderson et al., 2016; Pereira et al., 2018). The unspoken assumption of these\nstudies is that, during processing, linguistic information is transformed into\nsome shared semantic space, and those semantic representations are then used\nfor a variety of linguistic and non-linguistic tasks. We claim that current\nstudies vastly underdetermine the content of these representations, the\nalgorithms which the brain deploys to produce and consume them, and the\ncomputational tasks which they are designed to solve. We illustrate this\nindeterminacy with an extension of the sentence-decoding experiment of Pereira\net al. (2018), showing how standard evaluations fail to distinguish between\nlanguage processing models which deploy different mechanisms and which are\noptimized to solve very different tasks. We conclude by suggesting changes to\nthe brain decoding paradigm which can support stronger claims of neural\nrepresentation.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jun 2018 06:33:47 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Gauthier", "Jon", ""], ["Ivanova", "Anna", ""]]}, {"id": "1806.00615", "submitter": "Slava Jankin Mikhaylov", "authors": "Caleb Pomeroy and Niheer Dasandi and Slava Jankin Mikhaylov", "title": "Multiplex Communities and the Emergence of International Conflict", "comments": "arXiv admin note: text overlap with arXiv:1802.00396", "journal-ref": "PLoS ONE 14(10): e0223040 (2019)", "doi": "10.1371/journal.pone.0223040", "report-no": null, "categories": "cs.CL cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in community detection reveal new insights into multiplex and\nmultilayer networks. Less work, however, investigates the relationship between\nthese communities and outcomes in social systems. We leverage these advances to\nshed light on the relationship between the cooperative mesostructure of the\ninternational system and the onset of interstate conflict. We detect\ncommunities based upon weaker signals of affinity expressed in United Nations\nvotes and speeches, as well as stronger signals observed across multiple layers\nof bilateral cooperation. Communities of diplomatic affinity display an\nexpected negative relationship with conflict onset. Ties in communities based\nupon observed cooperation, however, display no effect under a standard model\nspecification and a positive relationship with conflict under an alternative\nspecification. These results align with some extant hypotheses but also point\nto a paucity in our understanding of the relationship between community\nstructure and behavioral outcomes in networks.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jun 2018 09:58:50 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 08:41:22 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Pomeroy", "Caleb", ""], ["Dasandi", "Niheer", ""], ["Mikhaylov", "Slava Jankin", ""]]}, {"id": "1806.00616", "submitter": "Zhiyuan Tang", "authors": "Zhiyuan Tang, Dong Wang and Qing Chen", "title": "AP18-OLR Challenge: Three Tasks and Their Baselines", "comments": "arXiv admin note: substantial text overlap with arXiv:1706.09742", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The third oriental language recognition (OLR) challenge AP18-OLR is\nintroduced in this paper, including the data profile, the tasks and the\nevaluation principles. Following the events in the last two years, namely\nAP16-OLR and AP17-OLR, the challenge this year focuses on more challenging\ntasks, including (1) short-duration utterances, (2) confusing languages, and\n(3) open-set recognition. The same as the previous events, the data of AP18-OLR\nis also provided by SpeechOcean and the NSFC M2ASR project. Baselines based on\nboth the i-vector model and neural networks are constructed for the\nparticipants' reference. We report the baseline results on the three tasks and\ndemonstrate that the three tasks are truly challenging. All the data is free\nfor participants, and the Kaldi recipes for the baselines have been published\nonline.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jun 2018 10:07:10 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Tang", "Zhiyuan", ""], ["Wang", "Dong", ""], ["Chen", "Qing", ""]]}, {"id": "1806.00628", "submitter": "Xi Chen", "authors": "Xi Chen, Zhihong Deng, Gehui Shen, Ting Huang", "title": "A Novel Framework for Recurrent Neural Networks with Enhancing\n  Information Processing and Transmission between Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel framework for recurrent neural networks (RNNs)\ninspired by the human memory models in the field of cognitive neuroscience to\nenhance information processing and transmission between adjacent RNNs' units.\nThe proposed framework for RNNs consists of three stages that is working\nmemory, forget, and long-term store. The first stage includes taking input data\ninto sensory memory and transferring it to working memory for preliminary\ntreatment. And the second stage mainly focuses on proactively forgetting the\nsecondary information rather than the primary in the working memory. And\nfinally, we get the long-term store normally using some kind of RNN's unit. Our\nframework, which is generalized and simple, is evaluated on 6 datasets which\nfall into 3 different tasks, corresponding to text classification, image\nclassification and language modelling. Experiments reveal that our framework\ncan obviously improve the performance of traditional recurrent neural networks.\nAnd exploratory task shows the ability of our framework of correctly forgetting\nthe secondary information.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jun 2018 12:59:18 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Chen", "Xi", ""], ["Deng", "Zhihong", ""], ["Shen", "Gehui", ""], ["Huang", "Ting", ""]]}, {"id": "1806.00674", "submitter": "Armin Seyeditabari", "authors": "Armin Seyeditabari, Narges Tabari, Wlodek Zadrozny", "title": "Emotion Detection in Text: a Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, emotion detection in text has become more popular due to its\nvast potential applications in marketing, political science, psychology,\nhuman-computer interaction, artificial intelligence, etc. Access to a huge\namount of textual data, especially opinionated and self-expression text also\nplayed a special role to bring attention to this field. In this paper, we\nreview the work that has been done in identifying emotion expressions in text\nand argue that although many techniques, methodologies, and models have been\ncreated to detect emotion in text, there are various reasons that make these\nmethods insufficient. Although, there is an essential need to improve the\ndesign and architecture of current systems, factors such as the complexity of\nhuman emotions, and the use of implicit and metaphorical language in expressing\nit, lead us to think that just re-purposing standard methodologies will not be\nenough to capture these complexities, and it is important to pay attention to\nthe linguistic intricacies of emotion expression.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jun 2018 17:18:06 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Seyeditabari", "Armin", ""], ["Tabari", "Narges", ""], ["Zadrozny", "Wlodek", ""]]}, {"id": "1806.00692", "submitter": "Abhilasha Ravichander", "authors": "Aakanksha Naik, Abhilasha Ravichander, Norman Sadeh, Carolyn Rose,\n  Graham Neubig", "title": "Stress Test Evaluation for Natural Language Inference", "comments": "COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language inference (NLI) is the task of determining if a natural\nlanguage hypothesis can be inferred from a given premise in a justifiable\nmanner. NLI was proposed as a benchmark task for natural language\nunderstanding. Existing models perform well at standard datasets for NLI,\nachieving impressive results across different genres of text. However, the\nextent to which these models understand the semantic content of sentences is\nunclear. In this work, we propose an evaluation methodology consisting of\nautomatically constructed \"stress tests\" that allow us to examine whether\nsystems have the ability to make real inferential decisions. Our evaluation of\nsix sentence-encoder models on these stress tests reveals strengths and\nweaknesses of these models with respect to challenging linguistic phenomena,\nand suggests important directions for future work in this area.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jun 2018 19:14:39 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 04:23:55 GMT"}, {"version": "v3", "created": "Wed, 13 Jun 2018 23:54:17 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Naik", "Aakanksha", ""], ["Ravichander", "Abhilasha", ""], ["Sadeh", "Norman", ""], ["Rose", "Carolyn", ""], ["Neubig", "Graham", ""]]}, {"id": "1806.00696", "submitter": "Michael Felderer", "authors": "Vahid Garousi, Sara Bauer, Michael Felderer", "title": "NLP-assisted software testing: A systematic mapping of the literature", "comments": "Software testing; Natural Language Processing (NLP); systematic\n  literature mapping; systematic literature review. arXiv admin note: text\n  overlap with arXiv:1801.02201", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context: To reduce manual effort of extracting test cases from\nnatural-language requirements, many approaches based on Natural Language\nProcessing (NLP) have been proposed in the literature. Given the large amount\nof approaches in this area, and since many practitioners are eager to utilize\nsuch techniques, it is important to synthesize and provide an overview of the\nstate-of-the-art in this area. Objective: Our objective is to summarize the\nstate-of-the-art in NLP-assisted software testing which could benefit\npractitioners to potentially utilize those NLP-based techniques. Moreover, this\ncan benefit researchers in providing an overview of the research landscape.\nMethod: To address the above need, we conducted a survey in the form of a\nsystematic literature mapping (classification). After compiling an initial pool\nof 95 papers, we conducted a systematic voting, and our final pool included 67\ntechnical papers. Results: This review paper provides an overview of the\ncontribution types presented in the papers, types of NLP approaches used to\nassist software testing, types of required input requirements, and a review of\ntool support in this area. Some key results we have detected are: (1) only four\nof the 38 tools (11%) presented in the papers are available for download; (2) a\nlarger ratio of the papers (30 of 67) provided a shallow exposure to the NLP\naspects (almost no details). Conclusion: This paper would benefit both\npractitioners and researchers by serving as an \"index\" to the body of knowledge\nin this area. The results could help practitioners utilizing the existing\nNLP-based techniques; this in turn reduces the cost of test-case design and\ndecreases the amount of human resources spent on test activities. After sharing\nthis review with some of our industrial collaborators, initial insights show\nthat this review can indeed be useful and beneficial to practitioners.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jun 2018 20:00:44 GMT"}, {"version": "v2", "created": "Sun, 19 May 2019 17:53:07 GMT"}, {"version": "v3", "created": "Sat, 21 Mar 2020 11:21:57 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Garousi", "Vahid", ""], ["Bauer", "Sara", ""], ["Felderer", "Michael", ""]]}, {"id": "1806.00699", "submitter": "Andres Karjus", "authors": "Andres Karjus, Richard A. Blythe, Simon Kirby, Kenny Smith", "title": "Quantifying the dynamics of topical fluctuations in language", "comments": "Code to run the analyses described in this paper is now available at\n  https://github.com/andreskarjus/topical_cultural_advection_model . A previous\n  shorter version of this paper outlining the basic model appeared as an\n  extended abstract in the proceedings of the Society for Computation in\n  Linguistics (Karjus et al. 2018, Topical advection as a baseline model for\n  corpus-based lexical dynamics)", "journal-ref": "Language Dynamics and Change, 10(1) 2020, 86-125", "doi": "10.1163/22105832-01001200", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The availability of large diachronic corpora has provided the impetus for a\ngrowing body of quantitative research on language evolution and meaning change.\nThe central quantities in this research are token frequencies of linguistic\nelements in texts, with changes in frequency taken to reflect the popularity or\nselective fitness of an element. However, corpus frequencies may change for a\nwide variety of reasons, including purely random sampling effects, or because\ncorpora are composed of contemporary media and fiction texts within which the\nunderlying topics ebb and flow with cultural and socio-political trends. In\nthis work, we introduce a simple model for controlling for topical fluctuations\nin corpora - the topical-cultural advection model - and demonstrate how it\nprovides a robust baseline of variability in word frequency changes over time.\nWe validate the model on a diachronic corpus spanning two centuries, and a\ncarefully-controlled artificial language change scenario, and then use it to\ncorrect for topical fluctuations in historical time series. Finally, we use the\nmodel to show that the emergence of new words typically corresponds with the\nrise of a trending topic. This suggests that some lexical innovations occur due\nto growing communicative need in a subspace of the lexicon, and that the\ntopical-cultural advection model can be used to quantify this.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jun 2018 20:14:17 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2018 16:26:54 GMT"}, {"version": "v3", "created": "Fri, 21 Jun 2019 17:18:57 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Karjus", "Andres", ""], ["Blythe", "Richard A.", ""], ["Kirby", "Simon", ""], ["Smith", "Kenny", ""]]}, {"id": "1806.00722", "submitter": "Yanyao Shen", "authors": "Yanyao Shen, Xu Tan, Di He, Tao Qin, Tie-Yan Liu", "title": "Dense Information Flow for Neural Machine Translation", "comments": null, "journal-ref": "in Proceedings of NAACL-HLT 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recently, neural machine translation has achieved remarkable progress by\nintroducing well-designed deep neural networks into its encoder-decoder\nframework. From the optimization perspective, residual connections are adopted\nto improve learning performance for both encoder and decoder in most of these\ndeep architectures, and advanced attention connections are applied as well.\nInspired by the success of the DenseNet model in computer vision problems, in\nthis paper, we propose a densely connected NMT architecture (DenseNMT) that is\nable to train more efficiently for NMT. The proposed DenseNMT not only allows\ndense connection in creating new features for both encoder and decoder, but\nalso uses the dense attention structure to improve attention quality. Our\nexperiments on multiple datasets show that DenseNMT structure is more\ncompetitive and efficient.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jun 2018 01:29:27 GMT"}, {"version": "v2", "created": "Mon, 2 Jul 2018 03:10:41 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Shen", "Yanyao", ""], ["Tan", "Xu", ""], ["He", "Di", ""], ["Qin", "Tao", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1806.00738", "submitter": "Diana Gonz\\'alez-Rico", "authors": "Diana Gonzalez-Rico, Gibran Fuentes-Pineda", "title": "Contextualize, Show and Tell: A Neural Visual Storyteller", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural model for generating short stories from image sequences,\nwhich extends the image description model by Vinyals et al. (Vinyals et al.,\n2015). This extension relies on an encoder LSTM to compute a context vector of\neach story from the image sequence. This context vector is used as the first\nstate of multiple independent decoder LSTMs, each of which generates the\nportion of the story corresponding to each image in the sequence by taking the\nimage embedding as the first input. Our model showed competitive results with\nthe METEOR metric and human ratings in the internal track of the Visual\nStorytelling Challenge 2018.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jun 2018 05:09:54 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Gonzalez-Rico", "Diana", ""], ["Fuentes-Pineda", "Gibran", ""]]}, {"id": "1806.00749", "submitter": "Yang Yang", "authors": "Yang Yang, Lei Zheng, Jiawei Zhang, Qingcai Cui, Zhoujun Li, Philip S.\n  Yu", "title": "TI-CNN: Convolutional Neural Networks for Fake News Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of social networks, fake news for various commercial and\npolitical purposes has been appearing in large numbers and gotten widespread in\nthe online world. With deceptive words, people can get infected by the fake\nnews very easily and will share them without any fact-checking. For instance,\nduring the 2016 US president election, various kinds of fake news about the\ncandidates widely spread through both official news media and the online social\nnetworks. These fake news is usually released to either smear the opponents or\nsupport the candidate on their side. The erroneous information in the fake news\nis usually written to motivate the voters' irrational emotion and enthusiasm.\nSuch kinds of fake news sometimes can bring about devastating effects, and an\nimportant goal in improving the credibility of online social networks is to\nidentify the fake news timely. In this paper, we propose to study the fake news\ndetection problem. Automatic fake news identification is extremely hard, since\npure model based fact-checking for news is still an open problem, and few\nexisting models can be applied to solve the problem. With a thorough\ninvestigation of a fake news data, lots of useful explicit features are\nidentified from both the text words and images used in the fake news. Besides\nthe explicit features, there also exist some hidden patterns in the words and\nimages used in fake news, which can be captured with a set of latent features\nextracted via the multiple convolutional layers in our model. A model named as\nTI-CNN (Text and Image information based Convolutinal Neural Network) is\nproposed in this paper. By projecting the explicit and latent features into a\nunified feature space, TI-CNN is trained with both the text and image\ninformation simultaneously. Extensive experiments carried on the real-world\nfake news datasets have demonstrate the effectiveness of TI-CNN.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jun 2018 08:09:58 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Yang", "Yang", ""], ["Zheng", "Lei", ""], ["Zhang", "Jiawei", ""], ["Cui", "Qingcai", ""], ["Li", "Zhoujun", ""], ["Yu", "Philip S.", ""]]}, {"id": "1806.00754", "submitter": "Hwiyeol Jo", "authors": "Hwiyeol Jo and Jeong Ryu", "title": "Psychological State in Text: A Limitation of Sentiment Analysis", "comments": "In Proceedings of IJCAI-ECAI Workshop on AI and Computational\n  Psychology: Theories, Algorithms and Applications (CompPsy)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Starting with the idea that sentiment analysis models should be able to\npredict not only positive or negative but also other psychological states of a\nperson, we implement a sentiment analysis model to investigate the relationship\nbetween the model and emotional state. We first examine psychological\nmeasurements of 64 participants and ask them to write a book report about a\nstory. After that, we train our sentiment analysis model using crawled movie\nreview data. We finally evaluate participants' writings, using the pretrained\nmodel as a concept of transfer learning. The result shows that sentiment\nanalysis model performs good at predicting a score, but the score does not have\nany correlation with human's self-checked sentiment.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jun 2018 08:52:23 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Jo", "Hwiyeol", ""], ["Ryu", "Jeong", ""]]}, {"id": "1806.00778", "submitter": "Yi Tay", "authors": "Yi Tay, Luu Anh Tuan, Siu Cheung Hui", "title": "Multi-Cast Attention Networks for Retrieval-based Question Answering and\n  Response Prediction", "comments": "Accepted to KDD 2018 (Paper titled only \"Multi-Cast Attention\n  Networks\" in KDD version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention is typically used to select informative sub-phrases that are used\nfor prediction. This paper investigates the novel use of attention as a form of\nfeature augmentation, i.e, casted attention. We propose Multi-Cast Attention\nNetworks (MCAN), a new attention mechanism and general model architecture for a\npotpourri of ranking tasks in the conversational modeling and question\nanswering domains. Our approach performs a series of soft attention operations,\neach time casting a scalar feature upon the inner word embeddings. The key idea\nis to provide a real-valued hint (feature) to a subsequent encoder layer and is\ntargeted at improving the representation learning process. There are several\nadvantages to this design, e.g., it allows an arbitrary number of attention\nmechanisms to be casted, allowing for multiple attention types (e.g.,\nco-attention, intra-attention) and attention variants (e.g., alignment-pooling,\nmax-pooling, mean-pooling) to be executed simultaneously. This not only\neliminates the costly need to tune the nature of the co-attention layer, but\nalso provides greater extents of explainability to practitioners. Via extensive\nexperiments on four well-known benchmark datasets, we show that MCAN achieves\nstate-of-the-art performance. On the Ubuntu Dialogue Corpus, MCAN outperforms\nexisting state-of-the-art models by $9\\%$. MCAN also achieves the best\nperforming score to date on the well-studied TrecQA dataset.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jun 2018 12:22:28 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Tay", "Yi", ""], ["Tuan", "Luu Anh", ""], ["Hui", "Siu Cheung", ""]]}, {"id": "1806.00780", "submitter": "Vladimir Ilievski Mr.", "authors": "Vladimir Ilievski", "title": "Building Advanced Dialogue Managers for Goal-Oriented Dialogue Systems", "comments": "master thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goal-Oriented (GO) Dialogue Systems, colloquially known as goal oriented\nchatbots, help users achieve a predefined goal (e.g. book a movie ticket)\nwithin a closed domain. A first step is to understand the user's goal by using\nnatural language understanding techniques. Once the goal is known, the bot must\nmanage a dialogue to achieve that goal, which is conducted with respect to a\nlearnt policy. The success of the dialogue system depends on the quality of the\npolicy, which is in turn reliant on the availability of high-quality training\ndata for the policy learning method, for instance Deep Reinforcement Learning.\n  Due to the domain specificity, the amount of available data is typically too\nlow to allow the training of good dialogue policies. In this master thesis we\nintroduce a transfer learning method to mitigate the effects of the low\nin-domain data availability. Our transfer learning based approach improves the\nbot's success rate by $20\\%$ in relative terms for distant domains and we more\nthan double it for close domains, compared to the model without transfer\nlearning. Moreover, the transfer learning chatbots learn the policy up to 5 to\n10 times faster. Finally, as the transfer learning approach is complementary to\nadditional processing such as warm-starting, we show that their joint\napplication gives the best outcomes.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jun 2018 12:36:06 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Ilievski", "Vladimir", ""]]}, {"id": "1806.00793", "submitter": "Slava Jankin Mikhaylov", "authors": "Alexander Herzog and Peter John and Slava Jankin Mikhaylov", "title": "Transfer Topic Labeling with Domain-Specific Knowledge Base: An Analysis\n  of UK House of Commons Speeches 1935-2014", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models are widely used in natural language processing, allowing\nresearchers to estimate the underlying themes in a collection of documents.\nMost topic models use unsupervised methods and hence require the additional\nstep of attaching meaningful labels to estimated topics. This process of manual\nlabeling is not scalable and suffers from human bias. We present a\nsemi-automatic transfer topic labeling method that seeks to remedy these\nproblems. Domain-specific codebooks form the knowledge-base for automated topic\nlabeling. We demonstrate our approach with a dynamic topic model analysis of\nthe complete corpus of UK House of Commons speeches 1935-2014, using the coding\ninstructions of the Comparative Agendas Project to label topics. We show that\nour method works well for a majority of the topics we estimate; but we also\nfind that institution-specific topics, in particular on subnational governance,\nrequire manual input. We validate our results using human expert coding.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jun 2018 13:22:10 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 16:56:27 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Herzog", "Alexander", ""], ["John", "Peter", ""], ["Mikhaylov", "Slava Jankin", ""]]}, {"id": "1806.00807", "submitter": "Badri Narayana Patro", "authors": "Badri N. Patro, Vinod K. Kurmi, Sandeep Kumar, Vinay P. Namboodiri", "title": "Learning Semantic Sentence Embeddings using Sequential Pair-wise\n  Discriminator", "comments": "COLING 2018 (accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose a method for obtaining sentence-level embeddings.\nWhile the problem of securing word-level embeddings is very well studied, we\npropose a novel method for obtaining sentence-level embeddings. This is\nobtained by a simple method in the context of solving the paraphrase generation\ntask. If we use a sequential encoder-decoder model for generating paraphrase,\nwe would like the generated paraphrase to be semantically close to the original\nsentence. One way to ensure this is by adding constraints for true paraphrase\nembeddings to be close and unrelated paraphrase candidate sentence embeddings\nto be far. This is ensured by using a sequential pair-wise discriminator that\nshares weights with the encoder that is trained with a suitable loss function.\nOur loss function penalizes paraphrase sentence embedding distances from being\ntoo large. This loss is used in combination with a sequential encoder-decoder\nnetwork. We also validated our method by evaluating the obtained embeddings for\na sentiment analysis task. The proposed method results in semantic embeddings\nand outperforms the state-of-the-art on the paraphrase generation and sentiment\nanalysis task on standard datasets. These results are also shown to be\nstatistically significant.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jun 2018 15:00:05 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 14:07:37 GMT"}, {"version": "v3", "created": "Fri, 15 Jun 2018 12:26:48 GMT"}, {"version": "v4", "created": "Mon, 2 Jul 2018 05:26:02 GMT"}, {"version": "v5", "created": "Thu, 14 Mar 2019 19:14:10 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Patro", "Badri N.", ""], ["Kurmi", "Vinod K.", ""], ["Kumar", "Sandeep", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "1806.00840", "submitter": "Jean Maillard", "authors": "Jean Maillard and Stephen Clark", "title": "Latent Tree Learning with Differentiable Parsers: Shift-Reduce Parsing\n  and Chart Parsing", "comments": "ACL 2018 workshop on Relevance of Linguistic Structure in Neural\n  Architectures for NLP", "journal-ref": "Proceedings of the Workshop on the Relevance of Linguistic\n  Structure in Neural Architectures for NLP, ACL 2018", "doi": "10.18653/v1/W18-2903", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent tree learning models represent sentences by composing their words\naccording to an induced parse tree, all based on a downstream task. These\nmodels often outperform baselines which use (externally provided) syntax trees\nto drive the composition order. This work contributes (a) a new latent tree\nlearning model based on shift-reduce parsing, with competitive downstream\nperformance and non-trivial induced trees, and (b) an analysis of the trees\nlearned by our shift-reduce model and by a chart-based model.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jun 2018 17:34:41 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Maillard", "Jean", ""], ["Clark", "Stephen", ""]]}, {"id": "1806.00910", "submitter": "Abeed Sarker", "authors": "Abeed Sarker and Graciela Gonzalez-Hernandez", "title": "An unsupervised and customizable misspelling generator for mining noisy\n  health-related text sources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a customizable datacentric system that\nautomatically generates common misspellings for complex health-related terms.\nThe spelling variant generator relies on a dense vector model learned from\nlarge unlabeled text, which is used to find semantically close terms to the\noriginal/seed keyword, followed by the filtering of terms that are lexically\ndissimilar beyond a given threshold. The process is executed recursively,\nconverging when no new terms similar (lexically and semantically) to the seed\nkeyword are found. Weighting of intra-word character sequence similarities\nallows further problem-specific customization of the system. On a dataset\nprepared for this study, our system outperforms the current state-of-the-art\nfor medication name variant generation with best F1-score of 0.69 and\nF1/4-score of 0.78. Extrinsic evaluation of the system on a set of\ncancer-related terms showed an increase of over 67% in retrieval rate from\nTwitter posts when the generated variants are included. Our proposed spelling\nvariant generator has several advantages over the current state-of-the-art and\nother types of variant generators-(i) it is capable of filtering out lexically\nsimilar but semantically dissimilar terms, (ii) the number of variants\ngenerated is low as many low-frequency and ambiguous misspellings are filtered\nout, and (iii) the system is fully automatic, customizable and easily\nexecutable. While the base system is fully unsupervised, we show how\nsupervision maybe employed to adjust weights for task-specific customization.\nThe performance and significant relative simplicity of our proposed approach\nmakes it a much needed misspelling generation resource for health-related text\nmining from noisy sources. The source code for the system has been made\npublicly available for research purposes.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2018 01:07:37 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Sarker", "Abeed", ""], ["Gonzalez-Hernandez", "Graciela", ""]]}, {"id": "1806.00913", "submitter": "Oren Melamud", "authors": "Jacob Goldberger and Oren Melamud", "title": "Self-Normalization Properties of Language Modeling", "comments": "Accepted to Coling 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-normalizing discriminative models approximate the normalized probability\nof a class without having to compute the partition function. In the context of\nlanguage modeling, this property is particularly appealing as it may\nsignificantly reduce run-times due to large word vocabularies. In this study,\nwe provide a comprehensive investigation of language modeling\nself-normalization. First, we theoretically analyze the inherent\nself-normalization properties of Noise Contrastive Estimation (NCE) language\nmodels. Then, we compare them empirically to softmax-based approaches, which\nare self-normalized using explicit regularization, and suggest a hybrid model\nwith compelling properties. Finally, we uncover a surprising negative\ncorrelation between self-normalization and perplexity across the board, as well\nas some regularity in the observed errors, which may potentially be used for\nimproving self-normalization algorithms in the future.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2018 01:20:59 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Goldberger", "Jacob", ""], ["Melamud", "Oren", ""]]}, {"id": "1806.00920", "submitter": "Chih-Chieh Shao", "authors": "Chih Chieh Shao, Trois Liu, Yuting Lai, Yiying Tseng and Sam Tsai", "title": "DRCD: a Chinese Machine Reading Comprehension Dataset", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we introduce DRCD (Delta Reading Comprehension Dataset), an\nopen domain traditional Chinese machine reading comprehension (MRC) dataset.\nThis dataset aimed to be a standard Chinese machine reading comprehension\ndataset, which can be a source dataset in transfer learning. The dataset\ncontains 10,014 paragraphs from 2,108 Wikipedia articles and 30,000+ questions\ngenerated by annotators. We build a baseline model that achieves an F1 score of\n89.59%. F1 score of Human performance is 93.30%.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2018 01:50:21 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 02:55:38 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 02:55:39 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Shao", "Chih Chieh", ""], ["Liu", "Trois", ""], ["Lai", "Yuting", ""], ["Tseng", "Yiying", ""], ["Tsai", "Sam", ""]]}, {"id": "1806.00971", "submitter": "Shuhei Kurita", "authors": "Shuhei Kurita, Daisuke Kawahara and Sadao Kurohashi", "title": "Neural Adversarial Training for Semi-supervised Japanese\n  Predicate-argument Structure Analysis", "comments": "Accepted by ACL-2018. 9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Japanese predicate-argument structure (PAS) analysis involves zero anaphora\nresolution, which is notoriously difficult. To improve the performance of\nJapanese PAS analysis, it is straightforward to increase the size of corpora\nannotated with PAS. However, since it is prohibitively expensive, it is\npromising to take advantage of a large amount of raw corpora. In this paper, we\npropose a novel Japanese PAS analysis model based on semi-supervised\nadversarial training with a raw corpus. In our experiments, our model\noutperforms existing state-of-the-art models for Japanese PAS analysis.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2018 06:26:19 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 03:18:01 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Kurita", "Shuhei", ""], ["Kawahara", "Daisuke", ""], ["Kurohashi", "Sadao", ""]]}, {"id": "1806.01045", "submitter": "Tobias Hecking", "authors": "Tobias Hecking and Loet Leydesdorff", "title": "Topic Modelling of Empirical Text Corpora: Validity, Reliability, and\n  Reproducibility in Comparison to Semantic Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using the 6,638 case descriptions of societal impact submitted for evaluation\nin the Research Excellence Framework (REF 2014), we replicate the topic model\n(Latent Dirichlet Allocation or LDA) made in this context and compare the\nresults with factor-analytic results using a traditional word-document matrix\n(Principal Component Analysis or PCA). Removing a small fraction of documents\nfrom the sample, for example, has on average a much larger impact on LDA than\non PCA-based models to the extent that the largest distortion in the case of\nPCA has less effect than the smallest distortion of LDA-based models. In terms\nof semantic coherence, however, LDA models outperform PCA-based models. The\ntopic models inform us about the statistical properties of the document sets\nunder study, but the results are statistical and should not be used for a\nsemantic interpretation - for example, in grant selections and micro-decision\nmaking, or scholarly work-without follow-up using domain-specific semantic\nmaps.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2018 11:03:11 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Hecking", "Tobias", ""], ["Leydesdorff", "Loet", ""]]}, {"id": "1806.01170", "submitter": "Keisuke Sakaguchi", "authors": "Keisuke Sakaguchi, Benjamin Van Durme", "title": "Efficient Online Scalar Annotation with Bounded Support", "comments": "Accepted at ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a novel method for efficiently eliciting scalar annotations for\ndataset construction and system quality estimation by human judgments. We\ncontrast direct assessment (annotators assign scores to items directly), online\npairwise ranking aggregation (scores derive from annotator comparison of\nitems), and a hybrid approach (EASL: Efficient Annotation of Scalar Labels)\nproposed here. Our proposal leads to increased correlation with ground truth,\nat far greater annotator efficiency, suggesting this strategy as an improved\nmechanism for dataset creation and manual system evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2018 16:10:19 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Sakaguchi", "Keisuke", ""], ["Van Durme", "Benjamin", ""]]}, {"id": "1806.01185", "submitter": "Thomas Lansdall-Welfare", "authors": "Thomas Lansdall-Welfare and Nello Cristianini", "title": "History Playground: A Tool for Discovering Temporal Trends in Massive\n  Textual Corpora", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that macroscopic patterns of continuity and change\nover the course of centuries can be detected through the analysis of time\nseries extracted from massive textual corpora. Similar data-driven approaches\nhave already revolutionised the natural sciences, and are widely believed to\nhold similar potential for the humanities and social sciences, driven by the\nmass-digitisation projects that are currently under way, and coupled with the\never-increasing number of documents which are \"born digital\". As such, new\ninteractive tools are required to discover and extract macroscopic patterns\nfrom these vast quantities of textual data. Here we present History Playground,\nan interactive web-based tool for discovering trends in massive textual\ncorpora. The tool makes use of scalable algorithms to first extract trends from\ntextual corpora, before making them available for real-time search and\ndiscovery, presenting users with an interface to explore the data. Included in\nthe tool are algorithms for standardization, regression, change-point detection\nin the relative frequencies of ngrams, multi-term indices and comparison of\ntrends across different corpora.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2018 16:30:03 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Lansdall-Welfare", "Thomas", ""], ["Cristianini", "Nello", ""]]}, {"id": "1806.01264", "submitter": "Subhabrata Mukherjee", "authors": "Guineng Zheng, Subhabrata Mukherjee, Xin Luna Dong, Feifei Li", "title": "OpenTag: Open Attribute Value Extraction from Product Profiles [Deep\n  Learning, Active Learning, Named Entity Recognition]", "comments": "Proceedings of the 24th ACM SIGKDD International Conference on\n  Knowledge Discovery and Data Mining, London, UK, August 19-23, 2018", "journal-ref": null, "doi": "10.1145/3219819.3219839", "report-no": null, "categories": "cs.CL cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extraction of missing attribute values is to find values describing an\nattribute of interest from a free text input. Most past related work on\nextraction of missing attribute values work with a closed world assumption with\nthe possible set of values known beforehand, or use dictionaries of values and\nhand-crafted features. How can we discover new attribute values that we have\nnever seen before? Can we do this with limited human annotation or supervision?\nWe study this problem in the context of product catalogs that often have\nmissing values for many attributes of interest.\n  In this work, we leverage product profile information such as titles and\ndescriptions to discover missing values of product attributes. We develop a\nnovel deep tagging model OpenTag for this extraction problem with the following\ncontributions: (1) we formalize the problem as a sequence tagging task, and\npropose a joint model exploiting recurrent neural networks (specifically,\nbidirectional LSTM) to capture context and semantics, and Conditional Random\nFields (CRF) to enforce tagging consistency, (2) we develop a novel attention\nmechanism to provide interpretable explanation for our model's decisions, (3)\nwe propose a novel sampling strategy exploring active learning to reduce the\nburden of human annotation. OpenTag does not use any dictionary or hand-crafted\nfeatures as in prior works. Extensive experiments in real-life datasets in\ndifferent domains show that OpenTag with our active learning strategy discovers\nnew attribute values from as few as 150 annotated samples (reduction in 3.3x\namount of annotation effort) with a high F-score of 83%, outperforming\nstate-of-the-art models.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2018 19:41:07 GMT"}, {"version": "v2", "created": "Sat, 6 Oct 2018 17:29:28 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Zheng", "Guineng", ""], ["Mukherjee", "Subhabrata", ""], ["Dong", "Xin Luna", ""], ["Li", "Feifei", ""]]}, {"id": "1806.01330", "submitter": "Sunipa Dev", "authors": "Sunipa Dev, Safia Hassan, Jeff M. Phillips", "title": "Closed Form Word Embedding Alignment", "comments": "Accepted ICDM 2019 and KAIS Special Issue", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We develop a family of techniques to align word embeddings which are derived\nfrom different source datasets or created using different mechanisms (e.g.,\nGloVe or word2vec). Our methods are simple and have a closed form to optimally\nrotate, translate, and scale to minimize root mean squared errors or maximize\nthe average cosine similarity between two embeddings of the same vocabulary\ninto the same dimensional space. Our methods extend approaches known as\nAbsolute Orientation, which are popular for aligning objects in\nthree-dimensions, and generalize an approach by Smith etal (ICLR 2017). We\nprove new results for optimal scaling and for maximizing cosine similarity.\nThen we demonstrate how to evaluate the similarity of embeddings from different\nsources or mechanisms, and that certain properties like synonyms and analogies\nare preserved across the embeddings and can be enhanced by simply aligning and\naveraging ensembles of embeddings.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2018 19:03:52 GMT"}, {"version": "v2", "created": "Sat, 22 Sep 2018 00:07:17 GMT"}, {"version": "v3", "created": "Thu, 29 Aug 2019 18:57:29 GMT"}, {"version": "v4", "created": "Tue, 17 Nov 2020 19:46:43 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Dev", "Sunipa", ""], ["Hassan", "Safia", ""], ["Phillips", "Jeff M.", ""]]}, {"id": "1806.01351", "submitter": "Khoi-Nguyen Tran", "authors": "Khoi-Nguyen Tran and Jey Han Lau and Danish Contractor and Utkarsh\n  Gupta and Bikram Sengupta and Christopher J. Butler and Mukesh Mohania", "title": "Document Chunking and Learning Objective Generation for Instruction\n  Design", "comments": "Proceedings of the 11th International Conference on Education Data\n  Mining (EDM 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instructional Systems Design is the practice of creating of instructional\nexperiences that make the acquisition of knowledge and skill more efficient,\neffective, and appealing. Specifically in designing courses, an hour of\ntraining material can require between 30 to 500 hours of effort in sourcing and\norganizing reference data for use in just the preparation of course material.\nIn this paper, we present the first system of its kind that helps reduce the\neffort associated with sourcing reference material and course creation. We\npresent algorithms for document chunking and automatic generation of learning\nobjectives from content, creating descriptive content metadata to improve\ncontent-discoverability. Unlike existing methods, the learning objectives\ngenerated by our system incorporate pedagogically motivated Bloom's verbs. We\ndemonstrate the usefulness of our methods using real world data from the\nbanking industry and through a live deployment at a large pharmaceutical\ncompany.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2018 06:47:28 GMT"}, {"version": "v2", "created": "Mon, 6 Aug 2018 02:18:26 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Tran", "Khoi-Nguyen", ""], ["Lau", "Jey Han", ""], ["Contractor", "Danish", ""], ["Gupta", "Utkarsh", ""], ["Sengupta", "Bikram", ""], ["Butler", "Christopher J.", ""], ["Mohania", "Mukesh", ""]]}, {"id": "1806.01353", "submitter": "Scott Lee", "authors": "Scott Lee", "title": "Natural Language Generation for Electronic Health Records", "comments": null, "journal-ref": null, "doi": "10.1038/s41746-018-0070-0", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of methods existing for generating synthetic electronic health\nrecords (EHRs), but they are not capable of generating unstructured text, like\nemergency department (ED) chief complaints, history of present illness or\nprogress notes. Here, we use the encoder-decoder model, a deep learning\nalgorithm that features in many contemporary machine translation systems, to\ngenerate synthetic chief complaints from discrete variables in EHRs, like age\ngroup, gender, and discharge diagnosis. After being trained end-to-end on\nauthentic records, the model can generate realistic chief complaint text that\npreserves much of the epidemiological information in the original data. As a\nside effect of the model's optimization goal, these synthetic chief complaints\nare also free of relatively uncommon abbreviation and misspellings, and they\ninclude none of the personally-identifiable information (PII) that was in the\ntraining data, suggesting it may be used to support the de-identification of\ntext in EHRs. When combined with algorithms like generative adversarial\nnetworks (GANs), our model could be used to generate fully-synthetic EHRs,\nfacilitating data sharing between healthcare providers and researchers and\nimproving our ability to develop machine learning methods tailored to the\ninformation in healthcare data.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2018 12:01:48 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Lee", "Scott", ""]]}, {"id": "1806.01483", "submitter": "Hongru Liang", "authors": "Hongru Liang, Haozheng Wang, Jun Wang, Shaodi You, Zhe Sun, Jin-Mao\n  Wei, Zhenglu Yang", "title": "JTAV: Jointly Learning Social Media Content Representation by Fusing\n  Textual, Acoustic, and Visual Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning social media content is the basis of many real-world applications,\nincluding information retrieval and recommendation systems, among others. In\ncontrast with previous works that focus mainly on single modal or bi-modal\nlearning, we propose to learn social media content by fusing jointly textual,\nacoustic, and visual information (JTAV). Effective strategies are proposed to\nextract fine-grained features of each modality, that is, attBiGRU and DCRNN. We\nalso introduce cross-modal fusion and attentive pooling techniques to integrate\nmulti-modal information comprehensively. Extensive experimental evaluation\nconducted on real-world datasets demonstrates our proposed model outperforms\nthe state-of-the-art approaches by a large margin.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2018 03:50:50 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 14:49:22 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Liang", "Hongru", ""], ["Wang", "Haozheng", ""], ["Wang", "Jun", ""], ["You", "Shaodi", ""], ["Sun", "Zhe", ""], ["Wei", "Jin-Mao", ""], ["Yang", "Zhenglu", ""]]}, {"id": "1806.01501", "submitter": "Jingjing Gong", "authors": "Jingjing Gong, Xipeng Qiu, Shaojing Wang and Xuanjing Huang", "title": "Information Aggregation via Dynamic Routing for Sequence Encoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While much progress has been made in how to encode a text sequence into a\nsequence of vectors, less attention has been paid to how to aggregate these\npreceding vectors (outputs of RNN/CNN) into fixed-size encoding vector.\nUsually, a simple max or average pooling is used, which is a bottom-up and\npassive way of aggregation and lack of guidance by task information. In this\npaper, we propose an aggregation mechanism to obtain a fixed-size encoding with\na dynamic routing policy. The dynamic routing policy is dynamically deciding\nthat what and how much information need be transferred from each word to the\nfinal encoding of the text sequence. Following the work of Capsule Network, we\ndesign two dynamic routing policies to aggregate the outputs of RNN/CNN\nencoding layer into a final encoding vector. Compared to the other aggregation\nmethods, dynamic routing can refine the messages according to the state of\nfinal encoding vector. Experimental results on five text classification tasks\nshow that our method outperforms other aggregating models by a significant\nmargin. Related source code is released on our github page.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2018 05:34:15 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Gong", "Jingjing", ""], ["Qiu", "Xipeng", ""], ["Wang", "Shaojing", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1806.01515", "submitter": "Shuoyang Ding", "authors": "Shuoyang Ding and Kevin Duh", "title": "How Do Source-side Monolingual Word Embeddings Impact Neural Machine\n  Translation?", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using pre-trained word embeddings as input layer is a common practice in many\nnatural language processing (NLP) tasks, but it is largely neglected for neural\nmachine translation (NMT). In this paper, we conducted a systematic analysis on\nthe effect of using pre-trained source-side monolingual word embedding in NMT.\nWe compared several strategies, such as fixing or updating the embeddings\nduring NMT training on varying amounts of data, and we also proposed a novel\nstrategy called dual-embedding that blends the fixing and updating strategies.\nOur results suggest that pre-trained embeddings can be helpful if properly\nincorporated into NMT, especially when parallel data is limited or additional\nin-domain monolingual data is readily available.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2018 06:45:23 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2018 06:58:20 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Ding", "Shuoyang", ""], ["Duh", "Kevin", ""]]}, {"id": "1806.01523", "submitter": "Fariz Ikhwantri", "authors": "Fariz Ikhwantri, Samuel Louvan, Kemal Kurniawan, Bagas Abisena, Valdi\n  Rachman, Alfan Farizki Wicaksono, Rahmad Mahendra", "title": "Multi-Task Active Learning for Neural Semantic Role Labeling on Low\n  Resource Conversational Corpus", "comments": "ACL 2018 workshop on Deep Learning Approaches for Low-Resource NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Most Semantic Role Labeling (SRL) approaches are supervised methods which\nrequire a significant amount of annotated corpus, and the annotation requires\nlinguistic expertise. In this paper, we propose a Multi-Task Active Learning\nframework for Semantic Role Labeling with Entity Recognition (ER) as the\nauxiliary task to alleviate the need for extensive data and use additional\ninformation from ER to help SRL. We evaluate our approach on Indonesian\nconversational dataset. Our experiments show that multi-task active learning\ncan outperform single-task active learning method and standard multi-task\nlearning. According to our results, active learning is more efficient by using\n12% less of training data compared to passive learning in both single-task and\nmulti-task setting. We also introduce a new dataset for SRL in Indonesian\nconversational domain to encourage further research in this area.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2018 07:34:02 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Ikhwantri", "Fariz", ""], ["Louvan", "Samuel", ""], ["Kurniawan", "Kemal", ""], ["Abisena", "Bagas", ""], ["Rachman", "Valdi", ""], ["Wicaksono", "Alfan Farizki", ""], ["Mahendra", "Rahmad", ""]]}, {"id": "1806.01526", "submitter": "Piek Vossen", "authors": "Piek Vossen, Selene Baez, Lenka Baj\\v{c}eti\\'c, and Bram Kraaijeveld", "title": "Leolani: a reference machine with a theory of mind for social\n  communication", "comments": "Invited keynote at 21st International Conference on Text, Speech and\n  Dialogue, https://www.tsdconference.org/tsd2018/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our state of mind is based on experiences and what other people tell us. This\nmay result in conflicting information, uncertainty, and alternative facts. We\npresent a robot that models relativity of knowledge and perception within\nsocial interaction following principles of the theory of mind. We utilized\nvision and speech capabilities on a Pepper robot to build an interaction model\nthat stores the interpretations of perceptions and conversations in combination\nwith provenance on its sources. The robot learns directly from what people tell\nit, possibly in relation to its perception. We demonstrate how the robot's\ncommunication is driven by hunger to acquire more knowledge from and on people\nand objects, to resolve uncertainties and conflicts, and to share awareness of\nthe per- ceived environment. Likewise, the robot can make reference to the\nworld and its knowledge about the world and the encounters with people that\nyielded this knowledge.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2018 07:36:36 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Vossen", "Piek", ""], ["Baez", "Selene", ""], ["Baj\u010deti\u0107", "Lenka", ""], ["Kraaijeveld", "Bram", ""]]}, {"id": "1806.01620", "submitter": "Andreas Marfurt", "authors": "Erik Holmer, Andreas Marfurt", "title": "Explaining Away Syntactic Structure in Semantic Document Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most generative document models act on bag-of-words input in an attempt to\nfocus on the semantic content and thereby partially forego syntactic\ninformation. We argue that it is preferable to keep the original word order\nintact and explicitly account for the syntactic structure instead. We propose\nan extension to the Neural Variational Document Model (Miao et al., 2016) that\ndoes exactly that to separate local (syntactic) context from the global\n(semantic) representation of the document. Our model builds on the variational\nautoencoder framework to define a generative document model based on next-word\nprediction. We name our approach Sequence-Aware Variational Autoencoder since\nin contrast to its predecessor, it operates on the true input sequence. In a\nseries of experiments we observe stronger topicality of the learned\nrepresentations as well as increased robustness to syntactic noise in our\ntraining data.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2018 12:02:11 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Holmer", "Erik", ""], ["Marfurt", "Andreas", ""]]}, {"id": "1806.01694", "submitter": "Alberto Poncelas", "authors": "Chao-Hong Liu, Declan Groves, Akira Hayakawa, Alberto Poncelas and Qun\n  Liu", "title": "Understanding Meanings in Multilingual Customer Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and being able to react to customer feedback is the most\nfundamental task in providing good customer service. However, there are two\nmajor obstacles for international companies to automatically detect the meaning\nof customer feedback in a global multilingual environment. Firstly, there is no\nwidely acknowledged categorisation (classes) of meaning for customer feedback.\nSecondly, the applicability of one meaning categorisation, if it exists, to\ncustomer feedback in multiple languages is questionable. In this paper, we\nextracted representative real world samples of customer feedback from Microsoft\nOffice customers in multiple languages, English, Spanish and Japanese,and\nconcluded a five-class categorisation(comment, request, bug, complaint and\nmeaningless) for meaning classification that could be used across languages in\nthe realm of customer feedback analysis.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2018 13:59:32 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Liu", "Chao-Hong", ""], ["Groves", "Declan", ""], ["Hayakawa", "Akira", ""], ["Poncelas", "Alberto", ""], ["Liu", "Qun", ""]]}, {"id": "1806.01733", "submitter": "Robyn Speer", "authors": "Robyn Speer and Joanna Lowry-Duda", "title": "Luminoso at SemEval-2018 Task 10: Distinguishing Attributes Using Text\n  Corpora and Relational Knowledge", "comments": "SemEval 2018, 5 pages", "journal-ref": "Proceedings of The 12th International Workshop on Semantic\n  Evaluation (2018), p. 985-989", "doi": "10.18653/v1/S18-1162", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Luminoso participated in the SemEval 2018 task on \"Capturing Discriminative\nAttributes\" with a system based on ConceptNet, an open knowledge graph focused\non general knowledge. In this paper, we describe how we trained a linear\nclassifier on a small number of semantically-informed features to achieve an\n$F_1$ score of 0.7368 on the task, close to the task's high score of 0.75.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2018 15:02:13 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 18:51:42 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Speer", "Robyn", ""], ["Lowry-Duda", "Joanna", ""]]}, {"id": "1806.01742", "submitter": "Alexander LeClair", "authors": "Alexander LeClair, Zachary Eberhart, Collin McMillan", "title": "Adapting Neural Text Classification for Improved Software Categorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software Categorization is the task of organizing software into groups that\nbroadly describe the behavior of the software, such as \"editors\" or \"science.\"\nCategorization plays an important role in several maintenance tasks, such as\nrepository navigation and feature elicitation. Current approaches attempt to\ncast the problem as text classification, to make use of the rich body of\nliterature from the NLP domain. However, as we will show in this paper, text\nclassification algorithms are generally not applicable off-the-shelf to source\ncode; we found that they work well when high-level project descriptions are\navailable, but suffer very large performance penalties when classifying source\ncode and comments only. We propose a set of adaptations to a state-of-the-art\nneural classification algorithm and perform two evaluations: one with reference\ndata from Debian end-user programs, and one with a set of C/C++ libraries that\nwe hired professional programmers to annotate. We show that our proposed\napproach achieves performance exceeding that of previous software\nclassification techniques as well as a state-of-the-art neural text\nclassification technique.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2018 15:18:47 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 14:37:29 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["LeClair", "Alexander", ""], ["Eberhart", "Zachary", ""], ["McMillan", "Collin", ""]]}, {"id": "1806.01773", "submitter": "Lambert Mathias", "authors": "Chetan Naik, Arpit Gupta, Hancheng Ge, Lambert Mathias, Ruhi Sarikaya", "title": "Contextual Slot Carryover for Disparate Schemas", "comments": "Accepted at Interspeech 2018", "journal-ref": null, "doi": "10.21437/Interspeech.2018-1035", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the slot-filling paradigm, where a user can refer back to slots in the\ncontext during a conversation, the goal of the contextual understanding system\nis to resolve the referring expressions to the appropriate slots in the\ncontext. In large-scale multi-domain systems, this presents two challenges -\nscaling to a very large and potentially unbounded set of slot values, and\ndealing with diverse schemas. We present a neural network architecture that\naddresses the slot value scalability challenge by reformulating the contextual\ninterpretation as a decision to carryover a slot from a set of possible\ncandidates. To deal with heterogenous schemas, we introduce a simple\ndata-driven method for trans- forming the candidate slots. Our experiments show\nthat our approach can scale to multiple domains and provides competitive\nresults over a strong baseline.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2018 16:15:23 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Naik", "Chetan", ""], ["Gupta", "Arpit", ""], ["Ge", "Hancheng", ""], ["Mathias", "Lambert", ""], ["Sarikaya", "Ruhi", ""]]}, {"id": "1806.02179", "submitter": "Sapna Negi", "authors": "Sapna Negi, Maarten de Rijke, Paul Buitelaar", "title": "Open Domain Suggestion Mining: Problem Definition and Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a formal definition for the task of suggestion mining in the\ncontext of a wide range of open domain applications. Human perception of the\nterm \\emph{suggestion} is subjective and this effects the preparation of hand\nlabeled datasets for the task of suggestion mining. Existing work either lacks\na formal problem definition and annotation procedure, or provides domain and\napplication specific definitions. Moreover, many previously used manually\nlabeled datasets remain proprietary. We first present an annotation study, and\nbased on our observations propose a formal task definition and annotation\nprocedure for creating benchmark datasets for suggestion mining. With this\nstudy, we also provide publicly available labeled datasets for suggestion\nmining in multiple domains.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2018 13:38:57 GMT"}, {"version": "v2", "created": "Sat, 30 Jun 2018 17:36:23 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Negi", "Sapna", ""], ["de Rijke", "Maarten", ""], ["Buitelaar", "Paul", ""]]}, {"id": "1806.02253", "submitter": "Amir Bakarov", "authors": "Amir Bakarov, Roman Suvorov, Ilya Sochenkov", "title": "The Limitations of Cross-language Word Embeddings Evaluation", "comments": "In Proceedings of the 7th Joint Conference on Lexical and\n  Computational Semantics (*SEM 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this work is to explore the possible limitations of existing\nmethods of cross-language word embeddings evaluation, addressing the lack of\ncorrelation between intrinsic and extrinsic cross-language evaluation methods.\nTo prove this hypothesis, we construct English-Russian datasets for extrinsic\nand intrinsic evaluation tasks and compare performances of 5 different\ncross-language models on them. The results say that the scores even on\ndifferent intrinsic benchmarks do not correlate to each other. We can conclude\nthat the use of human references as ground truth for cross-language word\nembeddings is not proper unless one does not understand how do native speakers\nprocess semantics in their cognition.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2018 15:42:22 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Bakarov", "Amir", ""], ["Suvorov", "Roman", ""], ["Sochenkov", "Ilya", ""]]}, {"id": "1806.02418", "submitter": "Edwin D. Simpson", "authors": "Edwin Simpson and Iryna Gurevych", "title": "Finding Convincing Arguments Using Scalable Bayesian Preference Learning", "comments": "Accepted for publication in TACL. To be presented at ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We introduce a scalable Bayesian preference learning method for identifying\nconvincing arguments in the absence of gold-standard rat- ings or rankings. In\ncontrast to previous work, we avoid the need for separate methods to perform\nquality control on training data, predict rankings and perform pairwise\nclassification. Bayesian approaches are an effective solution when faced with\nsparse or noisy training data, but have not previously been used to identify\nconvincing arguments. One issue is scalability, which we address by developing\na stochastic variational inference method for Gaussian process (GP) preference\nlearning. We show how our method can be applied to predict argument\nconvincingness from crowdsourced data, outperforming the previous\nstate-of-the-art, particularly when trained with small amounts of unreliable\ndata. We demonstrate how the Bayesian approach enables more effective active\nlearning, thereby reducing the amount of data required to identify convincing\narguments for new users and domains. While word embeddings are principally used\nwith neural networks, our results show that word embeddings in combination with\nlinguistic features also benefit GPs when predicting argument convincingness.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2018 20:47:47 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Simpson", "Edwin", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1806.02437", "submitter": "Casey Casalnuovo", "authors": "Casey Casalnuovo, Kenji Sagae, Prem Devanbu", "title": "Studying the Difference Between Natural and Programming Language Corpora", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code corpora, as observed in large software systems, are now known to be far\nmore repetitive and predictable than natural language corpora. But why? Does\nthe difference simply arise from the syntactic limitations of programming\nlanguages? Or does it arise from the differences in authoring decisions made by\nthe writers of these natural and programming language texts? We conjecture that\nthe differences are not entirely due to syntax, but also from the fact that\nreading and writing code is un-natural for humans, and requires substantial\nmental effort; so, people prefer to write code in ways that are familiar to\nboth reader and writer. To support this argument, we present results from two\nsets of studies: 1) a first set aimed at attenuating the effects of syntax, and\n2) a second, aimed at measuring repetitiveness of text written in other\nsettings (e.g. second language, technical/specialized jargon), which are also\neffortful to write. We find find that this repetition in source code is not\nentirely the result of grammar constraints, and thus some repetition must\nresult from human choice. While the evidence we find of similar repetitive\nbehavior in technical and learner corpora does not conclusively show that such\nlanguage is used by humans to mitigate difficulty, it is consistent with that\ntheory.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2018 22:00:32 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Casalnuovo", "Casey", ""], ["Sagae", "Kenji", ""], ["Devanbu", "Prem", ""]]}, {"id": "1806.02525", "submitter": "Yuta Nishimura", "authors": "Yuta Nishimura, Katsuhito Sudoh, Graham Neubig, Satoshi Nakamura", "title": "Multi-Source Neural Machine Translation with Missing Data", "comments": "ACL 2018 Workshop on Neural Machine Translation and Generation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-source translation is an approach to exploit multiple inputs (e.g. in\ntwo different languages) to increase translation accuracy. In this paper, we\nexamine approaches for multi-source neural machine translation (NMT) using an\nincomplete multilingual corpus in which some translations are missing. In\npractice, many multilingual corpora are not complete due to the difficulty to\nprovide translations in all of the relevant languages (for example, in TED\ntalks, most English talks only have subtitles for a small portion of the\nlanguages that TED supports). Existing studies on multi-source translation did\nnot explicitly handle such situations. This study focuses on the use of\nincomplete multilingual corpora in multi-encoder NMT and mixture of NMT experts\nand examines a very simple implementation where missing source translations are\nreplaced by a special symbol <NULL>. These methods allow us to use incomplete\ncorpora both at training time and test time. In experiments with real\nincomplete multilingual corpora of TED Talks, the multi-source NMT with the\n<NULL> tokens achieved higher translation accuracies measured by BLEU than\nthose by any one-to-one NMT systems.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2018 06:11:34 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 01:29:32 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Nishimura", "Yuta", ""], ["Sudoh", "Katsuhito", ""], ["Neubig", "Graham", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "1806.02724", "submitter": "Ronghang Hu", "authors": "Daniel Fried, Ronghang Hu, Volkan Cirik, Anna Rohrbach, Jacob Andreas,\n  Louis-Philippe Morency, Taylor Berg-Kirkpatrick, Kate Saenko, Dan Klein,\n  Trevor Darrell", "title": "Speaker-Follower Models for Vision-and-Language Navigation", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Navigation guided by natural language instructions presents a challenging\nreasoning problem for instruction followers. Natural language instructions\ntypically identify only a few high-level decisions and landmarks rather than\ncomplete low-level motor behaviors; much of the missing information must be\ninferred based on perceptual context. In machine learning settings, this is\ndoubly challenging: it is difficult to collect enough annotated data to enable\nlearning of this reasoning process from scratch, and also difficult to\nimplement the reasoning process using generic sequence models. Here we describe\nan approach to vision-and-language navigation that addresses both these issues\nwith an embedded speaker model. We use this speaker model to (1) synthesize new\ninstructions for data augmentation and to (2) implement pragmatic reasoning,\nwhich evaluates how well candidate action sequences explain an instruction.\nBoth steps are supported by a panoramic action space that reflects the\ngranularity of human-generated instructions. Experiments show that all three\ncomponents of this approach---speaker-driven data augmentation, pragmatic\nreasoning and panoramic action space---dramatically improve the performance of\na baseline instruction follower, more than doubling the success rate over the\nbest existing approach on a standard benchmark.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2018 15:15:35 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 01:38:56 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Fried", "Daniel", ""], ["Hu", "Ronghang", ""], ["Cirik", "Volkan", ""], ["Rohrbach", "Anna", ""], ["Andreas", "Jacob", ""], ["Morency", "Louis-Philippe", ""], ["Berg-Kirkpatrick", "Taylor", ""], ["Saenko", "Kate", ""], ["Klein", "Dan", ""], ["Darrell", "Trevor", ""]]}, {"id": "1806.02725", "submitter": "Pierre Isabelle", "authors": "Pierre Isabelle and Roland Kuhn", "title": "A Challenge Set for French --> English Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a challenge set for French --> English machine translation based\non the approach introduced in Isabelle, Cherry and Foster (EMNLP 2017). Such\nchallenge sets are made up of sentences that are expected to be relatively\ndifficult for machines to translate correctly because their most\nstraightforward translations tend to be linguistically divergent. We present\nhere a set of 506 manually constructed French sentences, 307 of which are\ntargeted to the same kinds of structural divergences as in the paper mentioned\nabove. The remaining 199 sentences are designed to test the ability of the\nsystems to correctly translate difficult grammatical words such as\nprepositions. We report on the results of using this challenge set for testing\ntwo different systems, namely Google Translate and DEEPL, each on two different\ndates (October 2017 and January 2018). All the resulting data are made publicly\navailable.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2018 15:16:02 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 13:30:42 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Isabelle", "Pierre", ""], ["Kuhn", "Roland", ""]]}, {"id": "1806.02782", "submitter": "Lei Xie", "authors": "Sining Sun, Ching-Feng Yeh, Mari Ostendorf, Mei-Yuh Hwang, Lei Xie", "title": "Training Augmentation with Adversarial Examples for Robust Speech\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the use of adversarial examples in training speech\nrecognition systems to increase robustness of deep neural network acoustic\nmodels. During training, the fast gradient sign method is used to generate\nadversarial examples augmenting the original training data. Different from\nconventional data augmentation based on data transformations, the examples are\ndynamically generated based on current acoustic model parameters. We assess the\nimpact of adversarial data augmentation in experiments on the Aurora-4 and\nCHiME-4 single-channel tasks, showing improved robustness against noise and\nchannel variation. Further improvement is obtained when combining adversarial\nexamples with teacher/student training, leading to a 23% relative word error\nrate reduction on Aurora-4.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2018 16:53:12 GMT"}, {"version": "v2", "created": "Sun, 17 Jun 2018 04:09:26 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Sun", "Sining", ""], ["Yeh", "Ching-Feng", ""], ["Ostendorf", "Mari", ""], ["Hwang", "Mei-Yuh", ""], ["Xie", "Lei", ""]]}, {"id": "1806.02786", "submitter": "Lei Xie", "authors": "Sining Sun, Ching-Feng Yeh, Mei-Yuh Hwang, Mari Ostendorf, Lei Xie", "title": "Domain Adversarial Training for Accented Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a domain adversarial training (DAT) algorithm to\nalleviate the accented speech recognition problem. In order to reduce the\nmismatch between labeled source domain data (\"standard\" accent) and unlabeled\ntarget domain data (with heavy accents), we augment the learning objective for\na Kaldi TDNN network with a domain adversarial training (DAT) objective to\nencourage the model to learn accent-invariant features. In experiments with\nthree Mandarin accents, we show that DAT yields up to 7.45% relative character\nerror rate reduction when we do not have transcriptions of the accented speech,\ncompared with the baseline trained on standard accent data only. We also find a\nbenefit from DAT when used in combination with training from automatic\ntranscriptions on the accented data. Furthermore, we find that DAT is superior\nto multi-task learning for accented speech recognition.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2018 17:02:54 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Sun", "Sining", ""], ["Yeh", "Ching-Feng", ""], ["Hwang", "Mei-Yuh", ""], ["Ostendorf", "Mari", ""], ["Xie", "Lei", ""]]}, {"id": "1806.02814", "submitter": "Denis Newman-Griffis", "authors": "Denis Newman-Griffis and Ayah Zirikly", "title": "Embedding Transfer for Low-Resource Medical Named Entity Recognition: A\n  Case Study on Patient Mobility", "comments": "Accepted to BioNLP 2018. 11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functioning is gaining recognition as an important indicator of global\nhealth, but remains under-studied in medical natural language processing\nresearch. We present the first analysis of automatically extracting\ndescriptions of patient mobility, using a recently-developed dataset of free\ntext electronic health records. We frame the task as a named entity recognition\n(NER) problem, and investigate the applicability of NER techniques to mobility\nextraction. As text corpora focused on patient functioning are scarce, we\nexplore domain adaptation of word embeddings for use in a recurrent neural\nnetwork NER system. We find that embeddings trained on a small in-domain corpus\nperform nearly as well as those learned from large out-of-domain corpora, and\nthat domain adaptation techniques yield additional improvements in both\nprecision and recall. Our analysis identifies several significant challenges in\nextracting descriptions of patient mobility, including the length and\ncomplexity of annotated entities and high linguistic variability in mobility\ndescriptions.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2018 17:49:54 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Newman-Griffis", "Denis", ""], ["Zirikly", "Ayah", ""]]}, {"id": "1806.02847", "submitter": "Trieu Trinh", "authors": "Trieu H. Trinh and Quoc V. Le", "title": "A Simple Method for Commonsense Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense reasoning is a long-standing challenge for deep learning. For\nexample, it is difficult to use neural networks to tackle the Winograd Schema\ndataset (Levesque et al., 2011). In this paper, we present a simple method for\ncommonsense reasoning with neural networks, using unsupervised learning. Key to\nour method is the use of language models, trained on a massive amount of\nunlabled data, to score multiple choice questions posed by commonsense\nreasoning tests. On both Pronoun Disambiguation and Winograd Schema challenges,\nour models outperform previous state-of-the-art methods by a large margin,\nwithout using expensive annotated knowledge bases or hand-engineered features.\nWe train an array of large RNN language models that operate at word or\ncharacter level on LM-1-Billion, CommonCrawl, SQuAD, Gutenberg Books, and a\ncustomized corpus for this task and show that diversity of training data plays\nan important role in test performance. Further analysis also shows that our\nsystem successfully discovers important features of the context that decide the\ncorrect answer, indicating a good grasp of commonsense knowledge.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2018 18:13:08 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 22:33:06 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Trinh", "Trieu H.", ""], ["Le", "Quoc V.", ""]]}, {"id": "1806.02863", "submitter": "Rahul Gupta", "authors": "Rahul Gupta, Saurabh Sahu, Carol Espy-Wilson, Shrikanth Narayanan", "title": "Semi-supervised and Transfer learning approaches for low resource\n  sentiment classification", "comments": "5 pages, Accepted to International Conference on Acoustics, Speech,\n  and Signal Processing (ICASSP), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment classification involves quantifying the affective reaction of a\nhuman to a document, media item or an event. Although researchers have\ninvestigated several methods to reliably infer sentiment from lexical, speech\nand body language cues, training a model with a small set of labeled datasets\nis still a challenge. For instance, in expanding sentiment analysis to new\nlanguages and cultures, it may not always be possible to obtain comprehensive\nlabeled datasets. In this paper, we investigate the application of\nsemi-supervised and transfer learning methods to improve performances on low\nresource sentiment classification tasks. We experiment with extracting dense\nfeature representations, pre-training and manifold regularization in enhancing\nthe performance of sentiment classification systems. Our goal is a coherent\nimplementation of these methods and we evaluate the gains achieved by these\nmethods in matched setting involving training and testing on a single corpus\nsetting as well as two cross corpora settings. In both the cases, our\nexperiments demonstrate that the proposed methods can significantly enhance the\nmodel performance against a purely supervised approach, particularly in cases\ninvolving a handful of training data.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2018 18:59:26 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Gupta", "Rahul", ""], ["Sahu", "Saurabh", ""], ["Espy-Wilson", "Carol", ""], ["Narayanan", "Shrikanth", ""]]}, {"id": "1806.02873", "submitter": "Jinyang Gao", "authors": "Xiangrui Cai, Jinyang Gao, Kee Yuan Ngiam, Beng Chin Ooi, Ying Zhang,\n  Xiaojie Yuan", "title": "Medical Concept Embedding with Time-Aware Attention", "comments": "7 pages. IJCAI-ECAI-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embeddings of medical concepts such as medication, procedure and diagnosis\ncodes in Electronic Medical Records (EMRs) are central to healthcare analytics.\nPrevious work on medical concept embedding takes medical concepts and EMRs as\nwords and documents respectively. Nevertheless, such models miss out the\ntemporal nature of EMR data. On the one hand, two consecutive medical concepts\ndo not indicate they are temporally close, but the correlations between them\ncan be revealed by the time gap. On the other hand, the temporal scopes of\nmedical concepts often vary greatly (e.g., \\textit{common cold} and\n\\textit{diabetes}). In this paper, we propose to incorporate the temporal\ninformation to embed medical codes. Based on the Continuous Bag-of-Words model,\nwe employ the attention mechanism to learn a \"soft\" time-aware context window\nfor each medical concept. Experiments on public and proprietary datasets\nthrough clustering and nearest neighbour search tasks demonstrate the\neffectiveness of our model, showing that it outperforms five state-of-the-art\nbaselines.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2018 07:45:06 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Cai", "Xiangrui", ""], ["Gao", "Jinyang", ""], ["Ngiam", "Kee Yuan", ""], ["Ooi", "Beng Chin", ""], ["Zhang", "Ying", ""], ["Yuan", "Xiaojie", ""]]}, {"id": "1806.02875", "submitter": "Benjamin Horne", "authors": "Mauricio Gruppi, Benjamin D. Horne, Sibel Adali", "title": "An Exploration of Unreliable News Classification in Brazil and The U.S", "comments": "Presented and Peer-Reviewed at NECO 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The propagation of unreliable information is on the rise in many places\naround the world. This expansion is facilitated by the rapid spread of\ninformation and anonymity granted by the Internet. The spread of unreliable\ninformation is a wellstudied issue and it is associated with negative social\nimpacts. In a previous work, we have identified significant differences in the\nstructure of news articles from reliable and unreliable sources in the US\nmedia. Our goal in this work was to explore such differences in the Brazilian\nmedia. We found significant features in two data sets: one with Brazilian news\nin Portuguese and another one with US news in English. Our results show that\nfeatures related to the writing style were prominent in both data sets and,\ndespite the language difference, some features have a universal behavior, being\nsignificant to both US and Brazilian news articles. Finally, we combined both\ndata sets and used the universal features to build a machine learning\nclassifier to predict the source type of a news article as reliable or\nunreliable.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2018 19:28:35 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Gruppi", "Mauricio", ""], ["Horne", "Benjamin D.", ""], ["Adali", "Sibel", ""]]}, {"id": "1806.02901", "submitter": "Ben Athiwaratkun", "authors": "Ben Athiwaratkun, Andrew Gordon Wilson, Anima Anandkumar", "title": "Probabilistic FastText for Multi-Sense Word Embeddings", "comments": "Published at ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Probabilistic FastText, a new model for word embeddings that can\ncapture multiple word senses, sub-word structure, and uncertainty information.\nIn particular, we represent each word with a Gaussian mixture density, where\nthe mean of a mixture component is given by the sum of n-grams. This\nrepresentation allows the model to share statistical strength across sub-word\nstructures (e.g. Latin roots), producing accurate representations of rare,\nmisspelt, or even unseen words. Moreover, each component of the mixture can\ncapture a different word sense. Probabilistic FastText outperforms both\nFastText, which has no probabilistic model, and dictionary-level probabilistic\nembeddings, which do not incorporate subword structures, on several\nword-similarity benchmarks, including English RareWord and foreign language\ndatasets. We also achieve state-of-art performance on benchmarks that measure\nability to discern different meanings. Thus, the proposed model is the first to\nachieve multi-sense representations while having enriched semantics on rare\nwords.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2018 20:57:22 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Athiwaratkun", "Ben", ""], ["Wilson", "Andrew Gordon", ""], ["Anandkumar", "Anima", ""]]}, {"id": "1806.02908", "submitter": "Fahim Mohammad PhD", "authors": "Fahim Mohammad", "title": "Is preprocessing of text really worth your time for online comment\n  classification?", "comments": "11 pages,including Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large proportion of online comments present on public domains are\nconstructive, however a significant proportion are toxic in nature. The\ncomments contain lot of typos which increases the number of features manifold,\nmaking the ML model difficult to train. Considering the fact that the data\nscientists spend approximately 80% of their time in collecting, cleaning and\norganizing their data [1], we explored how much effort should we invest in the\npreprocessing (transformation) of raw comments before feeding it to the\nstate-of-the-art classification models. With the help of four models on Jigsaw\ntoxic comment classification data, we demonstrated that the training of model\nwithout any transformation produce relatively decent model. Applying even basic\ntransformations, in some cases, lead to worse performance and should be applied\nwith caution.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2018 21:29:39 GMT"}, {"version": "v2", "created": "Wed, 29 Aug 2018 22:45:27 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Mohammad", "Fahim", ""]]}, {"id": "1806.02923", "submitter": "Saurav Sahay", "authors": "Saurav Sahay, Shachi H Kumar, Rui Xia, Jonathan Huang, Lama Nachman", "title": "Multimodal Relational Tensor Network for Sentiment and Emotion\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding Affect from video segments has brought researchers from the\nlanguage, audio and video domains together. Most of the current multimodal\nresearch in this area deals with various techniques to fuse the modalities, and\nmostly treat the segments of a video independently. Motivated by the work of\n(Zadeh et al., 2017) and (Poria et al., 2017), we present our architecture,\nRelational Tensor Network, where we use the inter-modal interactions within a\nsegment (intra-segment) and also consider the sequence of segments in a video\nto model the inter-segment inter-modal interactions. We also generate rich\nrepresentations of text and audio modalities by leveraging richer audio and\nlinguistic context alongwith fusing fine-grained knowledge based polarity\nscores from text. We present the results of our model on CMU-MOSEI dataset and\nshow that our model outperforms many baselines and state of the art methods for\nsentiment classification and emotion recognition.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2018 23:21:51 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Sahay", "Saurav", ""], ["Kumar", "Shachi H", ""], ["Xia", "Rui", ""], ["Huang", "Jonathan", ""], ["Nachman", "Lama", ""]]}, {"id": "1806.02934", "submitter": "Ashwin Vijayakumar", "authors": "Ashwin Kalyan, Stefan Lee, Anitha Kannan, Dhruv Batra", "title": "Learn from Your Neighbor: Learning Multi-modal Mappings from Sparse\n  Annotations", "comments": "To be presented at ICML 2018; 10 pages 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many structured prediction problems (particularly in vision and language\ndomains) are ambiguous, with multiple outputs being correct for an input - e.g.\nthere are many ways of describing an image, multiple ways of translating a\nsentence; however, exhaustively annotating the applicability of all possible\noutputs is intractable due to exponentially large output spaces (e.g. all\nEnglish sentences). In practice, these problems are cast as multi-class\nprediction, with the likelihood of only a sparse set of annotations being\nmaximized - unfortunately penalizing for placing beliefs on plausible but\nunannotated outputs. We make and test the following hypothesis - for a given\ninput, the annotations of its neighbors may serve as an additional supervisory\nsignal. Specifically, we propose an objective that transfers supervision from\nneighboring examples. We first study the properties of our developed method in\na controlled toy setup before reporting results on multi-label classification\nand two image-grounded sequence modeling tasks - captioning and question\ngeneration. We evaluate using standard task-specific metrics and measures of\noutput diversity, finding consistent improvements over standard maximum\nlikelihood training and other baselines.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2018 01:18:10 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Kalyan", "Ashwin", ""], ["Lee", "Stefan", ""], ["Kannan", "Anitha", ""], ["Batra", "Dhruv", ""]]}, {"id": "1806.02940", "submitter": "Graham Neubig", "authors": "Alexandra Birch, Andrew Finch, Minh-Thang Luong, Graham Neubig, Yusuke\n  Oda", "title": "Findings of the Second Workshop on Neural Machine Translation and\n  Generation", "comments": "WNMT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document describes the findings of the Second Workshop on Neural Machine\nTranslation and Generation, held in concert with the annual conference of the\nAssociation for Computational Linguistics (ACL 2018). First, we summarize the\nresearch trends of papers presented in the proceedings, and note that there is\nparticular interest in linguistic structure, domain adaptation, data\naugmentation, handling inadequate resources, and analysis of models. Second, we\ndescribe the results of the workshop's shared task on efficient neural machine\ntranslation, where participants were tasked with creating MT systems that are\nboth accurate and efficient.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2018 01:41:20 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 01:31:11 GMT"}, {"version": "v3", "created": "Mon, 18 Jun 2018 18:01:25 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Birch", "Alexandra", ""], ["Finch", "Andrew", ""], ["Luong", "Minh-Thang", ""], ["Neubig", "Graham", ""], ["Oda", "Yusuke", ""]]}, {"id": "1806.02960", "submitter": "Ikuya Yamada", "authors": "Ikuya Yamada, Hiroyuki Shindo, Yoshiyasu Takefuji", "title": "Representation Learning of Entities and Documents from Knowledge Base\n  Descriptions", "comments": "Accepted at COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe TextEnt, a neural network model that learns\ndistributed representations of entities and documents directly from a knowledge\nbase (KB). Given a document in a KB consisting of words and entity annotations,\nwe train our model to predict the entity that the document describes and map\nthe document and its target entity close to each other in a continuous vector\nspace. Our model is trained using a large number of documents extracted from\nWikipedia. The performance of the proposed model is evaluated using two tasks,\nnamely fine-grained entity typing and multiclass text classification. The\nresults demonstrate that our model achieves state-of-the-art performance on\nboth tasks. The code and the trained representations are made available online\nfor further academic research.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2018 03:49:34 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Yamada", "Ikuya", ""], ["Shindo", "Hiroyuki", ""], ["Takefuji", "Yoshiyasu", ""]]}, {"id": "1806.02988", "submitter": "Zhuohan Li", "authors": "Zhuohan Li, Di He, Fei Tian, Wei Chen, Tao Qin, Liwei Wang, Tie-Yan\n  Liu", "title": "Towards Binary-Valued Gates for Robust LSTM Training", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long Short-Term Memory (LSTM) is one of the most widely used recurrent\nstructures in sequence modeling. It aims to use gates to control information\nflow (e.g., whether to skip some information or not) in the recurrent\ncomputations, although its practical implementation based on soft gates only\npartially achieves this goal. In this paper, we propose a new way for LSTM\ntraining, which pushes the output values of the gates towards 0 or 1. By doing\nso, we can better control the information flow: the gates are mostly open or\nclosed, instead of in a middle state, which makes the results more\ninterpretable. Empirical studies show that (1) Although it seems that we\nrestrict the model capacity, there is no performance drop: we achieve better or\ncomparable performances due to its better generalization ability; (2) The\noutputs of gates are not sensitive to their inputs: we can easily compress the\nLSTM unit in multiple ways, e.g., low-rank approximation and low-precision\napproximation. The compressed models are even better than the baseline models\nwithout compression.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2018 06:57:16 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Li", "Zhuohan", ""], ["He", "Di", ""], ["Tian", "Fei", ""], ["Chen", "Wei", ""], ["Qin", "Tao", ""], ["Wang", "Liwei", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1806.03125", "submitter": "Erica Kido Shimomoto", "authors": "Erica K. Shimomoto, Lincon S. Souza, Bernardo B. Gatto, Kazuhiro Fukui", "title": "Text Classification based on Word Subspace with Term-Frequency", "comments": "Accepted at the International Joint Conference on Neural Networks,\n  IJCNN, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text classification has become indispensable due to the rapid increase of\ntext in digital form. Over the past three decades, efforts have been made to\napproach this task using various learning algorithms and statistical models\nbased on bag-of-words (BOW) features. Despite its simple implementation, BOW\nfeatures lack semantic meaning representation. To solve this problem, neural\nnetworks started to be employed to learn word vectors, such as the word2vec.\nWord2vec embeds word semantic structure into vectors, where the angle between\nvectors indicates the meaningful similarity between words. To measure the\nsimilarity between texts, we propose the novel concept of word subspace, which\ncan represent the intrinsic variability of features in a set of word vectors.\nThrough this concept, it is possible to model text from word vectors while\nholding semantic information. To incorporate the word frequency directly in the\nsubspace model, we further extend the word subspace to the term-frequency (TF)\nweighted word subspace. Based on these new concepts, text classification can be\nperformed under the mutual subspace method (MSM) framework. The validity of our\nmodeling is shown through experiments on the Reuters text database, comparing\nthe results to various state-of-art algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2018 12:55:37 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Shimomoto", "Erica K.", ""], ["Souza", "Lincon S.", ""], ["Gatto", "Bernardo B.", ""], ["Fukui", "Kazuhiro", ""]]}, {"id": "1806.03191", "submitter": "Stephen Roller", "authors": "Stephen Roller, Douwe Kiela, and Maximilian Nickel", "title": "Hearst Patterns Revisited: Automatic Hypernym Detection from Large Text\n  Corpora", "comments": "Accepted as a short paper to ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for unsupervised hypernym detection may broadly be categorized\naccording to two paradigms: pattern-based and distributional methods. In this\npaper, we study the performance of both approaches on several hypernymy tasks\nand find that simple pattern-based methods consistently outperform\ndistributional methods on common benchmark datasets. Our results show that\npattern-based models provide important contextual constraints which are not yet\ncaptured in distributional methods.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2018 14:34:29 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Roller", "Stephen", ""], ["Kiela", "Douwe", ""], ["Nickel", "Maximilian", ""]]}, {"id": "1806.03223", "submitter": "Debanjan Ghosh", "authors": "Elena Musi, Debanjan Ghosh, Smaranda Muresan", "title": "ChangeMyView Through Concessions: Do Concessions Increase Persuasion?", "comments": "Dialogue and Discourse journal 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In discourse studies concessions are considered among those argumentative\nstrategies that increase persuasion. We aim to empirically test this hypothesis\nby calculating the distribution of argumentative concessions in persuasive vs.\nnon-persuasive comments from the ChangeMyView subreddit. This constitutes a\nchallenging task since concessions are not always part of an argument. Drawing\nfrom a theoretically-informed typology of concessions, we conduct an annotation\ntask to label a set of polysemous lexical markers as introducing an\nargumentative concession or not and we observe their distribution in threads\nthat achieved and did not achieve persuasion. For the annotation, we used both\nexpert and novice annotators. With the ultimate goal of conducting the study on\nlarge datasets, we present a self-training method to automatically identify\nargumentative concessions using linguistically motivated features. We achieve a\nmoderate F1 of 57.4% on the development set and 46.0% on the test set via the\nself-training method. These results are comparable to state of the art results\non similar tasks of identifying explicit discourse connective types from the\nPenn Discourse Treebank. Our findings from the manual labeling and the\nclassification experiments indicate that the type of argumentative concessions\nwe investigated is almost equally likely to be used in winning and losing\narguments from the ChangeMyView dataset. While this result seems to contradict\ntheoretical assumptions, we provide some reasons for this discrepancy related\nto the ChangeMyView subreddit.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2018 15:38:04 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Musi", "Elena", ""], ["Ghosh", "Debanjan", ""], ["Muresan", "Smaranda", ""]]}, {"id": "1806.03280", "submitter": "Miguel Ballesteros", "authors": "Graeme Blackwood and Miguel Ballesteros and Todd Ward", "title": "Multilingual Neural Machine Translation with Task-Specific Attention", "comments": "COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual machine translation addresses the task of translating between\nmultiple source and target languages. We propose task-specific attention\nmodels, a simple but effective technique for improving the quality of\nsequence-to-sequence neural multilingual translation. Our approach seeks to\nretain as much of the parameter sharing generalization of NMT models as\npossible, while still allowing for language-specific specialization of the\nattention model to a particular language-pair or task. Our experiments on four\nlanguages of the Europarl corpus show that using a target-specific model of\nattention provides consistent gains in translation quality for all possible\ntranslation directions, compared to a model in which all parameters are shared.\nWe observe improved translation quality even in the (extreme) low-resource\nzero-shot translation directions for which the model never saw explicitly\npaired parallel data.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2018 17:18:26 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Blackwood", "Graeme", ""], ["Ballesteros", "Miguel", ""], ["Ward", "Todd", ""]]}, {"id": "1806.03290", "submitter": "Daniel Fried", "authors": "Daniel Fried and Dan Klein", "title": "Policy Gradient as a Proxy for Dynamic Oracles in Constituency Parsing", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic oracles provide strong supervision for training constituency parsers\nwith exploration, but must be custom defined for a given parser's transition\nsystem. We explore using a policy gradient method as a parser-agnostic\nalternative. In addition to directly optimizing for a tree-level metric such as\nF1, policy gradient has the potential to reduce exposure bias by allowing\nexploration during training; moreover, it does not require a dynamic oracle for\nsupervision. On four constituency parsers in three languages, the method\nsubstantially outperforms static oracle likelihood training in almost all\nsettings. For parsers where a dynamic oracle is available (including a novel\noracle which we define for the transition system of Dyer et al. 2016), policy\ngradient typically recaptures a substantial fraction of the performance gain\nafforded by the dynamic oracle.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2018 17:45:13 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Fried", "Daniel", ""], ["Klein", "Dan", ""]]}, {"id": "1806.03357", "submitter": "Victor Ardulov", "authors": "Victor Ardulov, Manoj Kumar, Shanna Williams, Thomas Lyon, Shrikanth\n  Narayanan", "title": "Measuring Conversational Productivity in Child Forensic Interviews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Child Forensic Interviewing (FI) presents a challenge for effective\ninformation retrieval and decision making. The high stakes associated with the\nprocess demand that expert legal interviewers are able to effectively establish\na channel of communication and elicit substantive knowledge from the\nchild-client while minimizing potential for experiencing trauma. As a first\nstep toward computationally modeling and producing quality spoken interviewing\nstrategies and a generalized understanding of interview dynamics, we propose a\nnovel methodology to computationally model effectiveness criteria, by applying\nsummarization and topic modeling techniques to objectively measure and rank the\nresponsiveness and conversational productivity of a child during FI. We score\ninformation retrieval by constructing an agenda to represent general topics of\ninterest and measuring alignment with a given response and leveraging lexical\nentrainment for responsiveness. For comparison, we present our methods along\nwith traditional metrics of evaluation and discuss the use of prior information\nfor generating situational awareness.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2018 21:21:19 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Ardulov", "Victor", ""], ["Kumar", "Manoj", ""], ["Williams", "Shanna", ""], ["Lyon", "Thomas", ""], ["Narayanan", "Shrikanth", ""]]}, {"id": "1806.03369", "submitter": "Natalie Parde", "authors": "Natalie Parde and Rodney D. Nielsen", "title": "#SarcasmDetection is soooo general! Towards a Domain-Independent\n  Approach for Detecting Sarcasm", "comments": "Proceedings of the 30th International Florida Artificial Intelligence\n  Research Society Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic sarcasm detection methods have traditionally been designed for\nmaximum performance on a specific domain. This poses challenges for those\nwishing to transfer those approaches to other existing or novel domains, which\nmay be typified by very different language characteristics. We develop a\ngeneral set of features and evaluate it under different training scenarios\nutilizing in-domain and/or out-of-domain training data. The best-performing\nscenario, training on both while employing a domain adaptation step, achieves\nan F1 of 0.780, which is well above baseline F1-measures of 0.515 and 0.345. We\nalso show that the approach outperforms the best results from prior work on the\nsame target domain.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2018 22:47:10 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Parde", "Natalie", ""], ["Nielsen", "Rodney D.", ""]]}, {"id": "1806.03431", "submitter": "Kumiko Tanaka-Ishii", "authors": "Kumiko Tanaka-Ishii and Hiroshi Terada", "title": "Word Familiarity and Frequency", "comments": "17 pages, 8 figures, Published in Studia Linguistica in 2011.\n  Available also from Wiley Online Library", "journal-ref": null, "doi": "10.1111/j.1467-9582.2010.01176.x", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word frequency is assumed to correlate with word familiarity, but the\nstrength of this correlation has not been thoroughly investigated. In this\npaper, we report on our analysis of the correlation between a word familiarity\nrating list obtained through a psycholinguistic experiment and the\nlog-frequency obtained from various corpora of different kinds and sizes (up to\nthe terabyte scale) for English and Japanese. Major findings are threefold:\nFirst, for a given corpus, familiarity is necessary for a word to achieve high\nfrequency, but familiar words are not necessarily frequent. Second, correlation\nincreases with the corpus data size. Third, a corpus of spoken language\ncorrelates better than one of written language. These findings suggest that\ncognitive familiarity ratings are correlated to frequency, but more highly to\nthat of spoken rather than written language.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jun 2018 07:40:38 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Tanaka-Ishii", "Kumiko", ""], ["Terada", "Hiroshi", ""]]}, {"id": "1806.03489", "submitter": "Abbas Ghaddar", "authors": "Abbas Ghaddar and Philippe Langlais", "title": "Robust Lexical Features for Improved Neural Network Named-Entity\n  Recognition", "comments": "12 pages, to appear in COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural network approaches to Named-Entity Recognition reduce the need for\ncarefully hand-crafted features. While some features do remain in\nstate-of-the-art systems, lexical features have been mostly discarded, with the\nexception of gazetteers. In this work, we show that this is unfair: lexical\nfeatures are actually quite useful. We propose to embed words and entity types\ninto a low-dimensional vector space we train from annotated data produced by\ndistant supervision thanks to Wikipedia. From this, we compute - offline - a\nfeature vector representing each word. When used with a vanilla recurrent\nneural network model, this representation yields substantial improvements. We\nestablish a new state-of-the-art F1 score of 87.95 on ONTONOTES 5.0, while\nmatching state-of-the-art performance with a F1 score of 91.73 on the\nover-studied CONLL-2003 dataset.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jun 2018 15:40:09 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Ghaddar", "Abbas", ""], ["Langlais", "Philippe", ""]]}, {"id": "1806.03497", "submitter": "Siyuan Qi", "authors": "Siyuan Qi, Baoxiong Jia, Song-Chun Zhu", "title": "Generalized Earley Parser: Bridging Symbolic Grammars and Sequence Data\n  for Future Prediction", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future predictions on sequence data (e.g., videos or audios) require the\nalgorithms to capture non-Markovian and compositional properties of high-level\nsemantics. Context-free grammars are natural choices to capture such\nproperties, but traditional grammar parsers (e.g., Earley parser) only take\nsymbolic sentences as inputs. In this paper, we generalize the Earley parser to\nparse sequence data which is neither segmented nor labeled. This generalized\nEarley parser integrates a grammar parser with a classifier to find the optimal\nsegmentation and labels, and makes top-down future predictions. Experiments\nshow that our method significantly outperforms other approaches for future\nhuman activity prediction.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jun 2018 16:07:02 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Qi", "Siyuan", ""], ["Jia", "Baoxiong", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "1806.03529", "submitter": "Mor Geva", "authors": "Mor Geva and Jonathan Berant", "title": "Learning to Search in Long Documents Using Document Structure", "comments": "COLING 2018 (camera ready version); v2: added acknowledgments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reading comprehension models are based on recurrent neural networks that\nsequentially process the document tokens. As interest turns to answering more\ncomplex questions over longer documents, sequential reading of large portions\nof text becomes a substantial bottleneck. Inspired by how humans use document\nstructure, we propose a novel framework for reading comprehension. We represent\ndocuments as trees, and model an agent that learns to interleave quick\nnavigation through the document tree with more expensive answer extraction. To\nencourage exploration of the document tree, we propose a new algorithm, based\non Deep Q-Network (DQN), which strategically samples tree nodes at training\ntime. Empirically we find our algorithm improves question answering performance\ncompared to DQN and a strong information-retrieval (IR) baseline, and that\nensembling our model with the IR baseline results in further gains in\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jun 2018 18:55:00 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 13:14:28 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Geva", "Mor", ""], ["Berant", "Jonathan", ""]]}, {"id": "1806.03537", "submitter": "Andrey Kutuzov", "authors": "Andrey Kutuzov, Lilja {\\O}vrelid, Terrence Szymanski, Erik Velldal", "title": "Diachronic word embeddings and semantic shifts: a survey", "comments": "Proceedings of COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent years have witnessed a surge of publications aimed at tracing temporal\nchanges in lexical semantics using distributional methods, particularly\nprediction-based word embedding models. However, this vein of research lacks\nthe cohesion, common terminology and shared practices of more established areas\nof natural language processing. In this paper, we survey the current state of\nacademic research related to diachronic word embeddings and semantic shifts\ndetection. We start with discussing the notion of semantic shifts, and then\ncontinue with an overview of the existing methods for tracing such time-related\nshifts with word embedding models. We propose several axes along which these\nmethods can be compared, and outline the main challenges before this emerging\nsubfield of NLP, as well as prospects and possible applications.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jun 2018 20:23:27 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2018 11:01:18 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Kutuzov", "Andrey", ""], ["\u00d8vrelid", "Lilja", ""], ["Szymanski", "Terrence", ""], ["Velldal", "Erik", ""]]}, {"id": "1806.03561", "submitter": "Peter Clark", "authors": "Peter Clark", "title": "What Knowledge is Needed to Solve the RTE5 Textual Entailment Challenge?", "comments": "Reprint of an unpublished 2010 Working Note", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document gives a knowledge-oriented analysis of about 20 interesting\nRecognizing Textual Entailment (RTE) examples, drawn from the 2005 RTE5\ncompetition test set. The analysis ignores shallow statistical matching\ntechniques between T and H, and rather asks: What would it take to reasonably\ninfer that T implies H? What world knowledge would be needed for this task?\nAlthough such knowledge-intensive techniques have not had much success in RTE\nevaluations, ultimately an intelligent system should be expected to know and\ndeploy this kind of world knowledge required to perform this kind of reasoning.\n  The selected examples are typically ones which our RTE system (called BLUE)\ngot wrong and ones which require world knowledge to answer. In particular, the\nanalysis covers cases where there was near-perfect lexical overlap between T\nand H, yet the entailment was NO, i.e., examples that most likely all current\nRTE systems will have got wrong. A nice example is #341 (page 26), that\nrequires inferring from \"a river floods\" that \"a river overflows its banks\".\nSeems it should be easy, right? Enjoy!\n", "versions": [{"version": "v1", "created": "Sun, 10 Jun 2018 00:33:47 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Clark", "Peter", ""]]}, {"id": "1806.03578", "submitter": "An Yang", "authors": "An Yang, Kai Liu, Jing Liu, Yajuan Lyu, Sujian Li", "title": "Adaptations of ROUGE and BLEU to Better Evaluate Machine Reading\n  Comprehension Task", "comments": "7 pages, 2 figures, ACL 2018 MRQA Workshop camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current evaluation metrics to question answering based machine reading\ncomprehension (MRC) systems generally focus on the lexical overlap between the\ncandidate and reference answers, such as ROUGE and BLEU. However, bias may\nappear when these metrics are used for specific question types, especially\nquestions inquiring yes-no opinions and entity lists. In this paper, we make\nadaptations on the metrics to better correlate n-gram overlap with the human\njudgment for answers to these two question types. Statistical analysis proves\nthe effectiveness of our approach. Our adaptations may provide positive\nguidance for the development of real-scene MRC systems.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jun 2018 03:50:10 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Yang", "An", ""], ["Liu", "Kai", ""], ["Liu", "Jing", ""], ["Lyu", "Yajuan", ""], ["Li", "Sujian", ""]]}, {"id": "1806.03590", "submitter": "Nurendra Choudhary", "authors": "Nurendra Choudhary, Rajat Singh, Manish Shrivastava", "title": "Cross-Lingual Task-Specific Representation Learning for Text\n  Classification in Resource Poor Languages", "comments": "This work was presented at 1st Workshop on Humanizing AI (HAI) at\n  IJCAI'18 in Stockholm, Sweden. arXiv admin note: text overlap with\n  arXiv:1804.00805, arXiv:1804.01855", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network models have shown promising results for text classification.\nHowever, these solutions are limited by their dependence on the availability of\nannotated data.\n  The prospect of leveraging resource-rich languages to enhance the text\nclassification of resource-poor languages is fascinating. The performance on\nresource-poor languages can significantly improve if the resource availability\nconstraints can be offset. To this end, we present a twin Bidirectional Long\nShort Term Memory (Bi-LSTM) network with shared parameters consolidated by a\ncontrastive loss function (based on a similarity metric). The model learns the\nrepresentation of resource-poor and resource-rich sentences in a common space\nby using the similarity between their assigned annotation tags. Hence, the\nmodel projects sentences with similar tags closer and those with different tags\nfarther from each other. We evaluated our model on the classification tasks of\nsentiment analysis and emoji prediction for resource-poor languages - Hindi and\nTelugu and resource-rich languages - English and Spanish. Our model\nsignificantly outperforms the state-of-the-art approaches in both the tasks\nacross all metrics.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jun 2018 06:09:57 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Choudhary", "Nurendra", ""], ["Singh", "Rajat", ""], ["Shrivastava", "Manish", ""]]}, {"id": "1806.03621", "submitter": "Lei Xie", "authors": "Yougen Yuan, Cheung-Chi Leung, Lei Xie, Hongjie Chen, Bin Ma, Haizhou\n  Li", "title": "Learning Acoustic Word Embeddings with Temporal Context for\n  Query-by-Example Speech Search", "comments": "5 pages, 4 figures, INTERSPEECH 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to learn acoustic word embeddings with temporal context for\nquery-by-example (QbE) speech search. The temporal context includes the leading\nand trailing word sequences of a word. We assume that there exist spoken word\npairs in the training database. We pad the word pairs with their original\ntemporal context to form fixed-length speech segment pairs. We obtain the\nacoustic word embeddings through a deep convolutional neural network (CNN)\nwhich is trained on the speech segment pairs with a triplet loss. Shifting a\nfixed-length analysis window through the search content, we obtain a running\nsequence of embeddings. In this way, searching for the spoken query is\nequivalent to the matching of acoustic word embeddings. The experiments show\nthat our proposed acoustic word embeddings learned with temporal context are\neffective in QbE speech search. They outperform the state-of-the-art\nframe-level feature representations and reduce run-time computation since no\ndynamic time warping is required in QbE speech search. We also find that it is\nimportant to have sufficient speech segment pairs to train the deep CNN for\neffective acoustic word embeddings.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jun 2018 09:40:08 GMT"}, {"version": "v2", "created": "Sun, 17 Jun 2018 07:38:18 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Yuan", "Yougen", ""], ["Leung", "Cheung-Chi", ""], ["Xie", "Lei", ""], ["Chen", "Hongjie", ""], ["Ma", "Bin", ""], ["Li", "Haizhou", ""]]}, {"id": "1806.03648", "submitter": "Ken Yano", "authors": "Ken Yano", "title": "Neural Disease Named Entity Extraction with Character-based BiLSTM+CRF\n  in Japanese Medical Text", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an 'end-to-end' character-based recurrent neural network that\nextracts disease named entities from a Japanese medical text and simultaneously\njudges its modality as either positive or negative; i.e., the mentioned disease\nor symptom is affirmed or negated. The motivation to adopt neural networks is\nto learn effective lexical and structural representation features for Entity\nRecognition and also for Positive/Negative classification from an annotated\ncorpora without explicitly providing any rule-based or manual feature sets. We\nconfirmed the superiority of our method over previous char-based CRF or SVM\nmethods in the results.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jun 2018 12:34:00 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Yano", "Ken", ""]]}, {"id": "1806.03653", "submitter": "An Yang", "authors": "An Yang and Sujian Li", "title": "SciDTB: Discourse Dependency TreeBank for Scientific Abstracts", "comments": "Accepted to ACL 2018 (short paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Annotation corpus for discourse relations benefits NLP tasks such as machine\ntranslation and question answering. In this paper, we present SciDTB, a\ndomain-specific discourse treebank annotated on scientific articles. Different\nfrom widely-used RST-DT and PDTB, SciDTB uses dependency trees to represent\ndiscourse structure, which is flexible and simplified to some extent but do not\nsacrifice structural integrity. We discuss the labeling framework, annotation\nworkflow and some statistics about SciDTB. Furthermore, our treebank is made as\na benchmark for evaluating discourse dependency parsers, on which we provide\nseveral baselines as fundamental work.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jun 2018 13:00:15 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Yang", "An", ""], ["Li", "Sujian", ""]]}, {"id": "1806.03661", "submitter": "Nadir Durrani Dr", "authors": "Fahim Dalvi and Nadir Durrani and Hassan Sajjad and Stephan Vogel", "title": "Incremental Decoding and Training Methods for Simultaneous Translation\n  in Neural Machine Translation", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of simultaneous translation by modifying the Neural MT\ndecoder to operate with dynamically built encoder and attention. We propose a\ntunable agent which decides the best segmentation strategy for a user-defined\nBLEU loss and Average Proportion (AP) constraint. Our agent outperforms\npreviously proposed Wait-if-diff and Wait-if-worse agents (Cho and Esipova,\n2016) on BLEU with a lower latency. Secondly we proposed data-driven changes to\nNeural MT training to better match the incremental decoding framework.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jun 2018 13:50:17 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Dalvi", "Fahim", ""], ["Durrani", "Nadir", ""], ["Sajjad", "Hassan", ""], ["Vogel", "Stephan", ""]]}, {"id": "1806.03688", "submitter": "Michael Bommarito II", "authors": "Michael J Bommarito II and Daniel Martin Katz and Eric M Detterman", "title": "LexNLP: Natural language processing and information extraction for legal\n  and regulatory texts", "comments": "9 pages, 0 figures; see also\n  https://github.com/LexPredict/lexpredict-lexnlp", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LexNLP is an open source Python package focused on natural language\nprocessing and machine learning for legal and regulatory text. The package\nincludes functionality to (i) segment documents, (ii) identify key text such as\ntitles and section headings, (iii) extract over eighteen types of structured\ninformation like distances and dates, (iv) extract named entities such as\ncompanies and geopolitical entities, (v) transform text into features for model\ntraining, and (vi) build unsupervised and supervised models such as word\nembedding or tagging models. LexNLP includes pre-trained models based on\nthousands of unit tests drawn from real documents available from the SEC EDGAR\ndatabase as well as various judicial and regulatory proceedings. LexNLP is\ndesigned for use in both academic research and industrial applications, and is\ndistributed at https://github.com/LexPredict/lexpredict-lexnlp.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jun 2018 16:55:40 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Bommarito", "Michael J", "II"], ["Katz", "Daniel Martin", ""], ["Detterman", "Eric M", ""]]}, {"id": "1806.03692", "submitter": "Junyang Lin", "authors": "Junyang Lin, Xu Sun, Xuancheng Ren, Shuming Ma, Jinsong Su, Qi Su", "title": "Deconvolution-Based Global Decoding for Neural Machine Translation", "comments": "Accepted by COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A great proportion of sequence-to-sequence (Seq2Seq) models for Neural\nMachine Translation (NMT) adopt Recurrent Neural Network (RNN) to generate\ntranslation word by word following a sequential order. As the studies of\nlinguistics have proved that language is not linear word sequence but sequence\nof complex structure, translation at each step should be conditioned on the\nwhole target-side context. To tackle the problem, we propose a new NMT model\nthat decodes the sequence with the guidance of its structural prediction of the\ncontext of the target sequence. Our model generates translation based on the\nstructural prediction of the target-side context so that the translation can be\nfreed from the bind of sequential order. Experimental results demonstrate that\nour model is more competitive compared with the state-of-the-art methods, and\nthe analysis reflects that our model is also robust to translating sentences of\ndifferent lengths and it also reduces repetition with the instruction from the\ntarget-side context for decoding.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jun 2018 17:05:31 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Lin", "Junyang", ""], ["Sun", "Xu", ""], ["Ren", "Xuancheng", ""], ["Ma", "Shuming", ""], ["Su", "Jinsong", ""], ["Su", "Qi", ""]]}, {"id": "1806.03711", "submitter": "Qingyu Yin", "authors": "Qingyu Yin, Yu Zhang, Weinan Zhang, Ting Liu, William Yang Wang", "title": "Deep Reinforcement Learning for Chinese Zero pronoun Resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network models for Chinese zero pronoun resolution learn semantic\ninformation for zero pronoun and candidate antecedents, but tend to be\nshort-sighted---they often make local decisions. They typically predict\ncoreference chains between the zero pronoun and one single candidate antecedent\none link at a time, while overlooking their long-term influence on future\ndecisions. Ideally, modeling useful information of preceding potential\nantecedents is critical when later predicting zero pronoun-candidate antecedent\npairs. In this study, we show how to integrate local and global decision-making\nby exploiting deep reinforcement learning models. With the help of the\nreinforcement learning agent, our model learns the policy of selecting\nantecedents in a sequential manner, where useful information provided by\nearlier predicted antecedents could be utilized for making later coreference\ndecisions. Experimental results on OntoNotes 5.0 dataset show that our\ntechnique surpasses the state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jun 2018 19:29:03 GMT"}, {"version": "v2", "created": "Thu, 19 Jul 2018 10:07:54 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Yin", "Qingyu", ""], ["Zhang", "Yu", ""], ["Zhang", "Weinan", ""], ["Liu", "Ting", ""], ["Wang", "William Yang", ""]]}, {"id": "1806.03713", "submitter": "Elena Kochkina", "authors": "Elena Kochkina, Maria Liakata, Arkaitz Zubiaga", "title": "All-in-one: Multi-task Learning for Rumour Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic resolution of rumours is a challenging task that can be broken down\ninto smaller components that make up a pipeline, including rumour detection,\nrumour tracking and stance classification, leading to the final outcome of\ndetermining the veracity of a rumour. In previous work, these steps in the\nprocess of rumour verification have been developed as separate components where\nthe output of one feeds into the next. We propose a multi-task learning\napproach that allows joint training of the main and auxiliary tasks, improving\nthe performance of rumour verification. We examine the connection between the\ndataset properties and the outcomes of the multi-task learning models used.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jun 2018 19:46:17 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Kochkina", "Elena", ""], ["Liakata", "Maria", ""], ["Zubiaga", "Arkaitz", ""]]}, {"id": "1806.03740", "submitter": "Sabrina Mielke", "authors": "Ryan Cotterell, Christo Kirov, Sabrina J. Mielke, Jason Eisner", "title": "Unsupervised Disambiguation of Syncretism in Inflected Lexicons", "comments": "Published at NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexical ambiguity makes it difficult to compute various useful statistics of\na corpus. A given word form might represent any of several morphological\nfeature bundles. One can, however, use unsupervised learning (as in EM) to fit\na model that probabilistically disambiguates word forms. We present such an\napproach, which employs a neural network to smoothly model a prior distribution\nover feature bundles (even rare ones). Although this basic model does not\nconsider a token's context, that very property allows it to operate on a simple\nlist of unigram type counts, partitioning each count among different analyses\nof that unigram. We discuss evaluation metrics for this novel task and report\nresults on 5 languages.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jun 2018 23:19:07 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 18:28:48 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Cotterell", "Ryan", ""], ["Kirov", "Christo", ""], ["Mielke", "Sabrina J.", ""], ["Eisner", "Jason", ""]]}, {"id": "1806.03743", "submitter": "Sabrina Mielke", "authors": "Ryan Cotterell, Sabrina J. Mielke, Jason Eisner, Brian Roark", "title": "Are All Languages Equally Hard to Language-Model?", "comments": "Published at NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For general modeling methods applied to diverse languages, a natural question\nis: how well should we expect our models to work on languages with differing\ntypological profiles? In this work, we develop an evaluation framework for fair\ncross-linguistic comparison of language models, using translated text so that\nall models are asked to predict approximately the same information. We then\nconduct a study on 21 languages, demonstrating that in some languages, the\ntextual expression of the information is harder to predict with both $n$-gram\nand LSTM language models. We show complex inflectional morphology to be a cause\nof performance differences among languages.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jun 2018 23:24:33 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 18:30:29 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Cotterell", "Ryan", ""], ["Mielke", "Sabrina J.", ""], ["Eisner", "Jason", ""], ["Roark", "Brian", ""]]}, {"id": "1806.03746", "submitter": "Sabrina Mielke", "authors": "Lawrence Wolf-Sonkin, Jason Naradowsky, Sabrina J. Mielke, Ryan\n  Cotterell", "title": "A Structured Variational Autoencoder for Contextual Morphological\n  Inflection", "comments": "Published at ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical morphological inflectors are typically trained on fully\nsupervised, type-level data. One remaining open research question is the\nfollowing: How can we effectively exploit raw, token-level data to improve\ntheir performance? To this end, we introduce a novel generative latent-variable\nmodel for the semi-supervised learning of inflection generation. To enable\nposterior inference over the latent variables, we derive an efficient\nvariational inference procedure based on the wake-sleep algorithm. We\nexperiment on 23 languages, using the Universal Dependencies corpora in a\nsimulated low-resource setting, and find improvements of over 10% absolute\naccuracy in some cases.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jun 2018 23:47:53 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 18:32:11 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Wolf-Sonkin", "Lawrence", ""], ["Naradowsky", "Jason", ""], ["Mielke", "Sabrina J.", ""], ["Cotterell", "Ryan", ""]]}, {"id": "1806.03757", "submitter": "Antonios Anastasopoulos", "authors": "Antonis Anastasopoulos, Marika Lekakou, Josep Quer, Eleni Zimianiti,\n  Justin DeBenedetto, and David Chiang", "title": "Part-of-Speech Tagging on an Endangered Language: a Parallel\n  Griko-Italian Resource", "comments": "to be presented at COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Most work on part-of-speech (POS) tagging is focused on high resource\nlanguages, or examines low-resource and active learning settings through\nsimulated studies. We evaluate POS tagging techniques on an actual endangered\nlanguage, Griko. We present a resource that contains 114 narratives in Griko,\nalong with sentence-level translations in Italian, and provides gold\nannotations for the test set. Based on a previously collected small corpus, we\ninvestigate several traditional methods, as well as methods that take advantage\nof monolingual data or project cross-lingual POS tags. We show that the\ncombination of a semi-supervised method with cross-lingual transfer is more\nappropriate for this extremely challenging setting, with the best tagger\nachieving an accuracy of 72.9%. With an applied active learning scheme, which\nwe use to collect sentence-level annotations over the test set, we achieve\nimprovements of more than 21 percentage points.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 01:08:52 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Anastasopoulos", "Antonis", ""], ["Lekakou", "Marika", ""], ["Quer", "Josep", ""], ["Zimianiti", "Eleni", ""], ["DeBenedetto", "Justin", ""], ["Chiang", "David", ""]]}, {"id": "1806.03821", "submitter": "Rama Rohit Reddy Gangula", "authors": "Gangula Rama Rohit Reddy, Radhika Mamidi", "title": "Addition of Code Mixed Features to Enhance the Sentiment Prediction of\n  Song Lyrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis, also called opinion mining, is the field of study that\nanalyzes people's opinions,sentiments, attitudes and emotions. Songs are\nimportant to sentiment analysis since the songs and mood are mutually dependent\non each other. Based on the selected song it becomes easy to find the mood of\nthe listener, in future it can be used for recommendation. The song lyric is a\nrich source of datasets containing words that are helpful in analysis and\nclassification of sentiments generated from it. Now a days we observe a lot of\ninter-sentential and intra-sentential code-mixing in songs which has a varying\nimpact on audience. To study this impact we created a Telugu songs dataset\nwhich contained both Telugu-English code-mixed and pure Telugu songs. In this\npaper, we classify the songs based on its arousal as exciting or non-exciting.\nWe develop a language identification tool and introduce code-mixing features\nobtained from it as additional features. Our system with these additional\nfeatures attains 4-5% accuracy greater than traditional approaches on our\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 06:08:40 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Reddy", "Gangula Rama Rohit", ""], ["Mamidi", "Radhika", ""]]}, {"id": "1806.03822", "submitter": "Robin Jia", "authors": "Pranav Rajpurkar, Robin Jia, and Percy Liang", "title": "Know What You Don't Know: Unanswerable Questions for SQuAD", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extractive reading comprehension systems can often locate the correct answer\nto a question in a context document, but they also tend to make unreliable\nguesses on questions for which the correct answer is not stated in the context.\nExisting datasets either focus exclusively on answerable questions, or use\nautomatically generated unanswerable questions that are easy to identify. To\naddress these weaknesses, we present SQuAD 2.0, the latest version of the\nStanford Question Answering Dataset (SQuAD). SQuAD 2.0 combines existing SQuAD\ndata with over 50,000 unanswerable questions written adversarially by\ncrowdworkers to look similar to answerable ones. To do well on SQuAD 2.0,\nsystems must not only answer questions when possible, but also determine when\nno answer is supported by the paragraph and abstain from answering. SQuAD 2.0\nis a challenging natural language understanding task for existing models: a\nstrong neural system that gets 86% F1 on SQuAD 1.1 achieves only 66% F1 on\nSQuAD 2.0.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 06:10:11 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Rajpurkar", "Pranav", ""], ["Jia", "Robin", ""], ["Liang", "Percy", ""]]}, {"id": "1806.03831", "submitter": "Mohit Shridhar", "authors": "Mohit Shridhar, David Hsu", "title": "Interactive Visual Grounding of Referring Expressions for Human-Robot\n  Interaction", "comments": "In Robotics: Science & Systems (RSS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents INGRESS, a robot system that follows human natural\nlanguage instructions to pick and place everyday objects. The core issue here\nis the grounding of referring expressions: infer objects and their\nrelationships from input images and language expressions. INGRESS allows for\nunconstrained object categories and unconstrained language expressions.\nFurther, it asks questions to disambiguate referring expressions interactively.\nTo achieve these, we take the approach of grounding by generation and propose a\ntwo-stage neural network model for grounding. The first stage uses a neural\nnetwork to generate visual descriptions of objects, compares them with the\ninput language expression, and identifies a set of candidate objects. The\nsecond stage uses another neural network to examine all pairwise relations\nbetween the candidates and infers the most likely referred object. The same\nneural networks are used for both grounding and question generation for\ndisambiguation. Experiments show that INGRESS outperformed a state-of-the-art\nmethod on the RefCOCO dataset and in robot experiments with humans.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 06:58:19 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Shridhar", "Mohit", ""], ["Hsu", "David", ""]]}, {"id": "1806.03847", "submitter": "Aly Magassouba", "authors": "Aly Magassouba, Komei Sugiura and Hisashi Kawai", "title": "A Multimodal Classifier Generative Adversarial Network for Carry and\n  Place Tasks from Ambiguous Language Instructions", "comments": "9 pages, 7 figures, accepted for IEEE Robotics and Automation Letters\n  (RA-L)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on a multimodal language understanding method for\ncarry-and-place tasks with domestic service robots. We address the case of\nambiguous instructions, that is, when the target area is not specified. For\ninstance \"put away the milk and cereal\" is a natural instruction where there is\nambiguity regarding the target area, considering environments in daily life.\nConventionally, this instruction can be disambiguated from a dialogue system,\nbut at the cost of time and cumbersome interaction. Instead, we propose a\nmultimodal approach, in which the instructions are disambiguated using the\nrobot's state and environment context. We develop the Multi-Modal Classifier\nGenerative Adversarial Network (MMC-GAN) to predict the likelihood of different\ntarget areas considering the robot's physical limitation and the target\nclutter. Our approach, MMC-GAN, significantly improves accuracy compared with\nbaseline methods that use instructions only or simple deep neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 07:52:28 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Magassouba", "Aly", ""], ["Sugiura", "Komei", ""], ["Kawai", "Hisashi", ""]]}, {"id": "1806.03869", "submitter": "Yuichiroh Matsubayashi", "authors": "Yuichiroh Matsubayashi and Kentaro Inui", "title": "Distance-Free Modeling of Multi-Predicate Interactions in End-to-End\n  Japanese Predicate-Argument Structure Analysis", "comments": "13 pages, Coling 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Capturing interactions among multiple predicate-argument structures (PASs) is\na crucial issue in the task of analyzing PAS in Japanese. In this paper, we\npropose new Japanese PAS analysis models that integrate the label prediction\ninformation of arguments in multiple PASs by extending the input and last\nlayers of a standard deep bidirectional recurrent neural network (bi-RNN)\nmodel. In these models, using the mechanisms of pooling and attention, we aim\nto directly capture the potential interactions among multiple PASs, without\nbeing disturbed by the word order and distance. Our experiments show that the\nproposed models improve the prediction accuracy specifically for cases where\nthe predicate and argument are in an indirect dependency relation and achieve a\nnew state of the art in the overall $F_1$ on a standard benchmark corpus.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 09:18:52 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 00:47:34 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Matsubayashi", "Yuichiroh", ""], ["Inui", "Kentaro", ""]]}, {"id": "1806.03957", "submitter": "Aleksandr Chuklin", "authors": "Aleksandr Chuklin, Aliaksei Severyn, Johanne Trippas, Enrique\n  Alfonseca, Hanna Silen and Damiano Spina", "title": "Prosody Modifications for Question-Answering in Voice-Only Settings", "comments": "Shorter version of this paper was accepted to CLEF'2019, Lugano,\n  Switzerland. The final authenticated version is available online at\n  https://doi.org/10.1007/978-3-030-28577-7_12", "journal-ref": "Lecture Notes in Computer Science, vol 11696 CLEF 2019", "doi": "10.1007/978-3-030-28577-7_12", "report-no": null, "categories": "cs.CL cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Many popular form factors of digital assistants---such as Amazon Echo, Apple\nHomepod, or Google Home---enable the user to hold a conversation with these\nsystems based only on the speech modality. The lack of a screen presents unique\nchallenges. To satisfy the information need of a user, the presentation of the\nanswer needs to be optimized for such voice-only interactions. In this paper,\nwe propose a task of evaluating the usefulness of audio transformations (i.e.,\nprosodic modifications) for voice-only question answering. We introduce a\ncrowdsourcing setup where we evaluate the quality of our proposed modifications\nalong multiple dimensions corresponding to the informativeness, naturalness,\nand ability of the user to identify key parts of the answer. We offer a set of\nprosodic modifications that highlight potentially important parts of the answer\nusing various acoustic cues. Our experiments show that some of these prosodic\nmodifications lead to better comprehension at the expense of only slightly\ndegraded naturalness of the audio.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 13:25:23 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 09:41:51 GMT"}, {"version": "v3", "created": "Thu, 4 Jul 2019 10:21:55 GMT"}, {"version": "v4", "created": "Wed, 2 Oct 2019 14:18:34 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Chuklin", "Aleksandr", ""], ["Severyn", "Aliaksei", ""], ["Trippas", "Johanne", ""], ["Alfonseca", "Enrique", ""], ["Silen", "Hanna", ""], ["Spina", "Damiano", ""]]}, {"id": "1806.04068", "submitter": "Mo Yu", "authors": "Shuohang Wang, Mo Yu, Shiyu Chang, Jing Jiang", "title": "A Co-Matching Model for Multi-choice Reading Comprehension", "comments": "6, accepted ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-choice reading comprehension is a challenging task, which involves the\nmatching between a passage and a question-answer pair. This paper proposes a\nnew co-matching approach to this problem, which jointly models whether a\npassage can match both a question and a candidate answer. Experimental results\non the RACE dataset demonstrate that our approach achieves state-of-the-art\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 15:50:13 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Wang", "Shuohang", ""], ["Yu", "Mo", ""], ["Chang", "Shiyu", ""], ["Jiang", "Jing", ""]]}, {"id": "1806.04092", "submitter": "Abhik Jana", "authors": "Abhik Jana, Pranjal Kanojiya, Pawan Goyal and Animesh Mukherjee", "title": "WikiRef: Wikilinks as a route to recommending appropriate references for\n  scientific Wikipedia pages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exponential increase in the usage of Wikipedia as a key source of\nscientific knowledge among the researchers is making it absolutely necessary to\nmetamorphose this knowledge repository into an integral and self-contained\nsource of information for direct utilization. Unfortunately, the references\nwhich support the content of each Wikipedia entity page, are far from complete.\nWhy are the reference section ill-formed for most Wikipedia pages? Is this\nsection edited as frequently as the other sections of a page? Can there be\nappropriate surrogates that can automatically enhance the reference section? In\nthis paper, we propose a novel two step approach -- WikiRef -- that (i)\nleverages the wikilinks present in a scientific Wikipedia target page and,\nthereby, (ii) recommends highly relevant references to be included in that\ntarget page appropriately and automatically borrowed from the reference section\nof the wikilinks. In the first step, we build a classifier to ascertain whether\na wikilink is a potential source of reference or not. In the following step, we\nrecommend references to the target page from the reference section of the\nwikilinks that are classified as potential sources of references in the first\nstep. We perform an extensive evaluation of our approach on datasets from two\ndifferent domains -- Computer Science and Physics. For Computer Science we\nachieve a notably good performance with a precision@1 of 0.44 for reference\nrecommendation as opposed to 0.38 obtained from the most competitive baseline.\nFor the Physics dataset, we obtain a similar performance boost of 10% with\nrespect to the most competitive baseline.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 16:26:56 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 05:19:46 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Jana", "Abhik", ""], ["Kanojiya", "Pranjal", ""], ["Goyal", "Pawan", ""], ["Mukherjee", "Animesh", ""]]}, {"id": "1806.04127", "submitter": "John Hale", "authors": "John Hale, Chris Dyer, Adhiguna Kuncoro, Jonathan R. Brennan", "title": "Finding Syntax in Human Encephalography with Beam Search", "comments": "ACL2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural network grammars (RNNGs) are generative models of\n(tree,string) pairs that rely on neural networks to evaluate derivational\nchoices. Parsing with them using beam search yields a variety of incremental\ncomplexity metrics such as word surprisal and parser action count. When used as\nregressors against human electrophysiological responses to naturalistic text,\nthey derive two amplitude effects: an early peak and a P600-like later peak. By\ncontrast, a non-syntactic neural language model yields no reliable effects.\nModel comparisons attribute the early peak to syntactic composition within the\nRNNG. This pattern of results recommends the RNNG+beam search combination as a\nmechanistic model of the syntactic processing that occurs during normal human\nlanguage comprehension.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 17:51:23 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Hale", "John", ""], ["Dyer", "Chris", ""], ["Kuncoro", "Adhiguna", ""], ["Brennan", "Jonathan R.", ""]]}, {"id": "1806.04168", "submitter": "Yikang Shen", "authors": "Yikang Shen, Zhouhan Lin, Athul Paul Jacob, Alessandro Sordoni, Aaron\n  Courville, Yoshua Bengio", "title": "Straight to the Tree: Constituency Parsing with Neural Syntactic\n  Distance", "comments": "Published at ACL2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a novel constituency parsing scheme. The model\npredicts a vector of real-valued scalars, named syntactic distances, for each\nsplit position in the input sentence. The syntactic distances specify the order\nin which the split points will be selected, recursively partitioning the input,\nin a top-down fashion. Compared to traditional shift-reduce parsing schemes,\nour approach is free from the potential problem of compounding errors, while\nbeing faster and easier to parallelize. Our model achieves competitive\nperformance amongst single model, discriminative parsers in the PTB dataset and\noutperforms previous models in the CTB dataset.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 18:18:00 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Shen", "Yikang", ""], ["Lin", "Zhouhan", ""], ["Jacob", "Athul Paul", ""], ["Sordoni", "Alessandro", ""], ["Courville", "Aaron", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1806.04185", "submitter": "Benjamin Nye", "authors": "Benjamin Nye, Junyi Jessy Li, Roma Patel, Yinfei Yang, Iain J.\n  Marshall, Ani Nenkova, Byron C. Wallace", "title": "A Corpus with Multi-Level Annotations of Patients, Interventions and\n  Outcomes to Support Language Processing for Medical Literature", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a corpus of 5,000 richly annotated abstracts of medical articles\ndescribing clinical randomized controlled trials. Annotations include\ndemarcations of text spans that describe the Patient population enrolled, the\nInterventions studied and to what they were Compared, and the Outcomes measured\n(the `PICO' elements). These spans are further annotated at a more granular\nlevel, e.g., individual interventions within them are marked and mapped onto a\nstructured medical vocabulary. We acquired annotations from a diverse set of\nworkers with varying levels of expertise and cost. We describe our data\ncollection process and the corpus itself in detail. We then outline a set of\nchallenging NLP tasks that would aid searching of the medical literature and\nthe practice of evidence-based medicine.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 18:52:01 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Nye", "Benjamin", ""], ["Li", "Junyi Jessy", ""], ["Patel", "Roma", ""], ["Yang", "Yinfei", ""], ["Marshall", "Iain J.", ""], ["Nenkova", "Ani", ""], ["Wallace", "Byron C.", ""]]}, {"id": "1806.04189", "submitter": "Minjia Zhang", "authors": "Minjia Zhang, Xiaodong Liu, Wenhan Wang, Jianfeng Gao, Yuxiong He", "title": "Navigating with Graph Representations for Fast and Scalable Decoding of\n  Neural Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural language models (NLMs) have recently gained a renewed interest by\nachieving state-of-the-art performance across many natural language processing\n(NLP) tasks. However, NLMs are very computationally demanding largely due to\nthe computational cost of the softmax layer over a large vocabulary. We observe\nthat, in decoding of many NLP tasks, only the probabilities of the top-K\nhypotheses need to be calculated preciously and K is often much smaller than\nthe vocabulary size. This paper proposes a novel softmax layer approximation\nalgorithm, called Fast Graph Decoder (FGD), which quickly identifies, for a\ngiven context, a set of K words that are most likely to occur according to a\nNLM. We demonstrate that FGD reduces the decoding time by an order of magnitude\nwhile attaining close to the full softmax baseline accuracy on neural machine\ntranslation and language modeling tasks. We also prove the theoretical\nguarantee on the softmax approximation quality.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 18:57:49 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Zhang", "Minjia", ""], ["Liu", "Xiaodong", ""], ["Wang", "Wenhan", ""], ["Gao", "Jianfeng", ""], ["He", "Yuxiong", ""]]}, {"id": "1806.04197", "submitter": "Sanjana Sharma", "authors": "Sanjana Sharma, Saksham Agrawal, Manish Shrivastava", "title": "Degree based Classification of Harmful Speech using Twitter Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Harmful speech has various forms and it has been plaguing the social media in\ndifferent ways. If we need to crackdown different degrees of hate speech and\nabusive behavior amongst it, the classification needs to be based on complex\nramifications which needs to be defined and hold accountable for, other than\nracist, sexist or against some particular group and community. This paper\nprimarily describes how we created an ontological classification of harmful\nspeech based on degree of hateful intent, and used it to annotate twitter data\naccordingly. The key contribution of this paper is the new dataset of tweets we\ncreated based on ontological classes and degrees of harmful speech found in the\ntext. We also propose supervised classification system for recognizing these\nrespective harmful speech classes in the texts hence.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 19:07:40 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Sharma", "Sanjana", ""], ["Agrawal", "Saksham", ""], ["Shrivastava", "Manish", ""]]}, {"id": "1806.04262", "submitter": "Jad Kabbara", "authors": "Andre Cianflone, Yulan Feng, Jad Kabbara, Jackie Chi Kit Cheung", "title": "Let's do it \"again\": A First Computational Approach to Detecting\n  Adverbial Presupposition Triggers", "comments": "ACL 2018 camera-ready version. Best paper award. First three listed\n  authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the task of predicting adverbial presupposition triggers such as\nalso and again. Solving such a task requires detecting recurring or similar\nevents in the discourse context, and has applications in natural language\ngeneration tasks such as summarization and dialogue systems. We create two new\ndatasets for the task, derived from the Penn Treebank and the Annotated English\nGigaword corpora, as well as a novel attention mechanism tailored to this task.\nOur attention mechanism augments a baseline recurrent neural network without\nthe need for additional trainable parameters, minimizing the added\ncomputational cost of our mechanism. We demonstrate that our model\nstatistically outperforms a number of baselines, including an LSTM-based\nlanguage model.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 22:44:38 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Cianflone", "Andre", ""], ["Feng", "Yulan", ""], ["Kabbara", "Jad", ""], ["Cheung", "Jackie Chi Kit", ""]]}, {"id": "1806.04270", "submitter": "Shduong Hao", "authors": "Shudong Hao, Michael J. Paul", "title": "Learning Multilingual Topics from Incomparable Corpus", "comments": "To appear in International Conference on Computational Linguistics\n  (COLING), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual topic models enable crosslingual tasks by extracting consistent\ntopics from multilingual corpora. Most models require parallel or comparable\ntraining corpora, which limits their ability to generalize. In this paper, we\nfirst demystify the knowledge transfer mechanism behind multilingual topic\nmodels by defining an alternative but equivalent formulation. Based on this\nanalysis, we then relax the assumption of training data required by most\nexisting models, creating a model that only requires a dictionary for training.\nExperiments show that our new method effectively learns coherent multilingual\ntopics from partially and fully incomparable corpora with limited amounts of\ndictionary resources.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 23:51:18 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Hao", "Shudong", ""], ["Paul", "Michael J.", ""]]}, {"id": "1806.04284", "submitter": "Chenhui Chu", "authors": "Chenhui Chu, Mayu Otani and Yuta Nakashima", "title": "iParaphrasing: Extracting Visually Grounded Paraphrases via an Image", "comments": "COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A paraphrase is a restatement of the meaning of a text in other words.\nParaphrases have been studied to enhance the performance of many natural\nlanguage processing tasks. In this paper, we propose a novel task iParaphrasing\nto extract visually grounded paraphrases (VGPs), which are different phrasal\nexpressions describing the same visual concept in an image. These extracted\nVGPs have the potential to improve language and image multimodal tasks such as\nvisual question answering and image captioning. How to model the similarity\nbetween VGPs is the key of iParaphrasing. We apply various existing methods as\nwell as propose a novel neural network-based method with image attention, and\nreport the results of the first attempt toward iParaphrasing.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 00:58:59 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Chu", "Chenhui", ""], ["Otani", "Mayu", ""], ["Nakashima", "Yuta", ""]]}, {"id": "1806.04291", "submitter": "Manuel Mager", "authors": "Manuel Mager, Ximena Gutierrez-Vasques, Gerardo Sierra, Ivan Meza", "title": "Challenges of language technologies for the indigenous languages of the\n  Americas", "comments": "In Proceedings of the 27th International Conference on Computational\n  Linguistics (COLING 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Indigenous languages of the American continent are highly diverse. However,\nthey have received little attention from the technological perspective. In this\npaper, we review the research, the digital resources and the available NLP\nsystems that focus on these languages. We present the main challenges and\nresearch questions that arise when distant languages and low-resource scenarios\nare faced. We would like to encourage NLP research in linguistically rich and\ndiverse areas like the Americas.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 01:26:55 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Mager", "Manuel", ""], ["Gutierrez-Vasques", "Ximena", ""], ["Sierra", "Gerardo", ""], ["Meza", "Ivan", ""]]}, {"id": "1806.04313", "submitter": "Bhuwan Dhingra", "authors": "Bhuwan Dhingra, Christopher J. Shallue, Mohammad Norouzi, Andrew M.\n  Dai, George E. Dahl", "title": "Embedding Text in Hyperbolic Spaces", "comments": "TextGraphs 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language text exhibits hierarchical structure in a variety of\nrespects. Ideally, we could incorporate our prior knowledge of this\nhierarchical structure into unsupervised learning algorithms that work on text\ndata. Recent work by Nickel & Kiela (2017) proposed using hyperbolic instead of\nEuclidean embedding spaces to represent hierarchical data and demonstrated\nencouraging results when embedding graphs. In this work, we extend their method\nwith a re-parameterization technique that allows us to learn hyperbolic\nembeddings of arbitrarily parameterized objects. We apply this framework to\nlearn word and sentence embeddings in hyperbolic space in an unsupervised\nmanner from text corpora. The resulting embeddings seem to encode certain\nintuitive notions of hierarchy, such as word-context frequency and phrase\nconstituency. However, the implicit continuous hierarchy in the learned\nhyperbolic space makes interrogating the model's learned hierarchies more\ndifficult than for models that learn explicit edges between items. The learned\nhyperbolic embeddings show improvements over Euclidean embeddings in some --\nbut not all -- downstream tasks, suggesting that hierarchical organization is\nmore useful for some tasks than others.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 03:25:15 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Dhingra", "Bhuwan", ""], ["Shallue", "Christopher J.", ""], ["Norouzi", "Mohammad", ""], ["Dai", "Andrew M.", ""], ["Dahl", "George E.", ""]]}, {"id": "1806.04327", "submitter": "Alessandra Cervone", "authors": "Stefano Mezza, Alessandra Cervone, Giuliano Tortoreto, Evgeny A.\n  Stepanov, Giuseppe Riccardi", "title": "ISO-Standard Domain-Independent Dialogue Act Tagging for Conversational\n  Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue Act (DA) tagging is crucial for spoken language understanding\nsystems, as it provides a general representation of speakers' intents, not\nbound to a particular dialogue system. Unfortunately, publicly available data\nsets with DA annotation are all based on different annotation schemes and thus\nincompatible with each other. Moreover, their schemes often do not cover all\naspects necessary for open-domain human-machine interaction. In this paper, we\npropose a methodology to map several publicly available corpora to a subset of\nthe ISO standard, in order to create a large task-independent training corpus\nfor DA classification. We show the feasibility of using this corpus to train a\ndomain-independent DA tagger testing it on out-of-domain conversational data,\nand argue the importance of training on multiple corpora to achieve robustness\nacross different DA categories.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 04:22:11 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Mezza", "Stefano", ""], ["Cervone", "Alessandra", ""], ["Tortoreto", "Giuliano", ""], ["Stepanov", "Evgeny A.", ""], ["Riccardi", "Giuseppe", ""]]}, {"id": "1806.04330", "submitter": "Wuwei Lan", "authors": "Wuwei Lan and Wei Xu", "title": "Neural Network Models for Paraphrase Identification, Semantic Textual\n  Similarity, Natural Language Inference, and Question Answering", "comments": "13 pages; accepted to COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we analyze several neural network designs (and their\nvariations) for sentence pair modeling and compare their performance\nextensively across eight datasets, including paraphrase identification,\nsemantic textual similarity, natural language inference, and question answering\ntasks. Although most of these models have claimed state-of-the-art performance,\nthe original papers often reported on only one or two selected datasets. We\nprovide a systematic study and show that (i) encoding contextual information by\nLSTM and inter-sentence interactions are critical, (ii) Tree-LSTM does not help\nas much as previously claimed but surprisingly improves performance on Twitter\ndatasets, (iii) the Enhanced Sequential Inference Model is the best so far for\nlarger datasets, while the Pairwise Word Interaction Model achieves the best\nperformance when less data is available. We release our implementations as an\nopen-source toolkit.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 04:48:06 GMT"}, {"version": "v2", "created": "Thu, 23 Aug 2018 03:52:02 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Lan", "Wuwei", ""], ["Xu", "Wei", ""]]}, {"id": "1806.04346", "submitter": "Ruidan He", "authors": "Ruidan He and Wee Sun Lee and Hwee Tou Ng and Daniel Dahlmeier", "title": "Exploiting Document Knowledge for Aspect-level Sentiment Classification", "comments": "Accepted to ACL 2018 (short paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based long short-term memory (LSTM) networks have proven to be\nuseful in aspect-level sentiment classification. However, due to the\ndifficulties in annotating aspect-level data, existing public datasets for this\ntask are all relatively small, which largely limits the effectiveness of those\nneural models. In this paper, we explore two approaches that transfer knowledge\nfrom document- level data, which is much less expensive to obtain, to improve\nthe performance of aspect-level sentiment classification. We demonstrate the\neffectiveness of our approaches on 4 public datasets from SemEval 2014, 2015,\nand 2016, and we show that attention-based LSTM benefits from document-level\nknowledge in multiple ways.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 06:04:11 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["He", "Ruidan", ""], ["Lee", "Wee Sun", ""], ["Ng", "Hwee Tou", ""], ["Dahlmeier", "Daniel", ""]]}, {"id": "1806.04357", "submitter": "Xing Niu", "authors": "Xing Niu, Sudha Rao, Marine Carpuat", "title": "Multi-Task Neural Models for Translating Between Styles Within and\n  Across Languages", "comments": "Accepted at the 27th International Conference on Computational\n  Linguistics (COLING 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generating natural language requires conveying content in an appropriate\nstyle. We explore two related tasks on generating text of varying formality:\nmonolingual formality transfer and formality-sensitive machine translation. We\npropose to solve these tasks jointly using multi-task learning, and show that\nour models achieve state-of-the-art performance for formality transfer and are\nable to perform formality-sensitive translation without being explicitly\ntrained on style-annotated translation examples.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 06:59:43 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Niu", "Xing", ""], ["Rao", "Sudha", ""], ["Carpuat", "Marine", ""]]}, {"id": "1806.04381", "submitter": "Jeremy Barnes", "authors": "Jeremy Barnes, Roman Klinger, Sabine Schulte im Walde", "title": "Projecting Embeddings for Domain Adaptation: Joint Modeling of Sentiment\n  Analysis in Diverse Domains", "comments": "Accepted to COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Domain adaptation for sentiment analysis is challenging due to the fact that\nsupervised classifiers are very sensitive to changes in domain. The two most\nprominent approaches to this problem are structural correspondence learning and\nautoencoders. However, they either require long training times or suffer\ngreatly on highly divergent domains. Inspired by recent advances in\ncross-lingual sentiment analysis, we provide a novel perspective and cast the\ndomain adaptation problem as an embedding projection task. Our model takes as\ninput two mono-domain embedding spaces and learns to project them to a\nbi-domain space, which is jointly optimized to (1) project across domains and\nto (2) predict sentiment. We perform domain adaptation experiments on 20\nsource-target domain pairs for sentiment classification and report novel\nstate-of-the-art results on 11 domain pairs, including the Amazon domain\nadaptation datasets and SemEval 2013 and 2016 datasets. Our analysis shows that\nour model performs comparably to state-of-the-art approaches on domains that\nare similar, while performing significantly better on highly divergent domains.\nOur code is available at https://github.com/jbarnesspain/domain_blse\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 08:16:28 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2018 22:51:12 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Barnes", "Jeremy", ""], ["Klinger", "Roman", ""], ["Walde", "Sabine Schulte im", ""]]}, {"id": "1806.04387", "submitter": "Bhargav Chippada", "authors": "Bhargav Chippada and Shubajit Saha", "title": "Knowledge Amalgam: Generating Jokes and Quotes Together", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating humor and quotes are very challenging problems in the field of\ncomputational linguistics and are often tackled separately. In this paper, we\npresent a controlled Long Short-Term Memory (LSTM) architecture which is\ntrained with categorical data like jokes and quotes together by passing\ncategory as an input along with the sequence of words. The idea is that a\nsingle neural net will learn the structure of both jokes and quotes to generate\nthem on demand according to input category. Importantly, we believe the neural\nnet has more knowledge as it's trained on different datasets and hence will\nenable it to generate more creative jokes or quotes from the mixture of\ninformation. May the network generate a funny inspirational joke!\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 08:22:21 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2018 15:24:29 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Chippada", "Bhargav", ""], ["Saha", "Shubajit", ""]]}, {"id": "1806.04402", "submitter": "Julia Kreutzer", "authors": "Ryan Cotterell, Julia Kreutzer", "title": "Explaining and Generalizing Back-Translation through Wake-Sleep", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Back-translation has become a commonly employed heuristic for semi-supervised\nneural machine translation. The technique is both straightforward to apply and\nhas led to state-of-the-art results. In this work, we offer a principled\ninterpretation of back-translation as approximate inference in a generative\nmodel of bitext and show how the standard implementation of back-translation\ncorresponds to a single iteration of the wake-sleep algorithm in our proposed\nmodel. Moreover, this interpretation suggests a natural iterative\ngeneralization, which we demonstrate leads to further improvement of up to 1.6\nBLEU.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 09:17:40 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Cotterell", "Ryan", ""], ["Kreutzer", "Julia", ""]]}, {"id": "1806.04441", "submitter": "Haoyang Wen", "authors": "Haoyang Wen, Yijia Liu, Wanxiang Che, Libo Qin, Ting Liu", "title": "Sequence-to-Sequence Learning for Task-oriented Dialogue with Dialogue\n  State Representation", "comments": "To appear at COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Classic pipeline models for task-oriented dialogue system require explicit\nmodeling the dialogue states and hand-crafted action spaces to query a\ndomain-specific knowledge base. Conversely, sequence-to-sequence models learn\nto map dialogue history to the response in current turn without explicit\nknowledge base querying. In this work, we propose a novel framework that\nleverages the advantages of classic pipeline and sequence-to-sequence models.\nOur framework models a dialogue state as a fixed-size distributed\nrepresentation and use this representation to query a knowledge base via an\nattention mechanism. Experiment on Stanford Multi-turn Multi-domain\nTask-oriented Dialogue Dataset shows that our framework significantly\noutperforms other sequence-to-sequence based baseline models on both automatic\nand human evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 11:21:16 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Wen", "Haoyang", ""], ["Liu", "Yijia", ""], ["Che", "Wanxiang", ""], ["Qin", "Libo", ""], ["Liu", "Ting", ""]]}, {"id": "1806.04450", "submitter": "Arpita Das", "authors": "Madan Gopal Jhanwar, Arpita Das", "title": "An Ensemble Model for Sentiment Analysis of Hindi-English Code-Mixed\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In multilingual societies like India, code-mixed social media texts comprise\nthe majority of the Internet. Detecting the sentiment of the code-mixed user\nopinions plays a crucial role in understanding social, economic and political\ntrends. In this paper, we propose an ensemble of character-trigrams based LSTM\nmodel and word-ngrams based Multinomial Naive Bayes (MNB) model to identify the\nsentiments of Hindi-English (Hi-En) code-mixed data. The ensemble model\ncombines the strengths of rich sequential patterns from the LSTM model and\npolarity of keywords from the probabilistic ngram model to identify sentiments\nin sparse and inconsistent code-mixed data. Experiments on reallife user\ncode-mixed data reveals that our approach yields state-of-the-art results as\ncompared to several baselines and other deep learning based proposed methods.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 11:46:51 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Jhanwar", "Madan Gopal", ""], ["Das", "Arpita", ""]]}, {"id": "1806.04456", "submitter": "Rajeev Gupta", "authors": "Rajeev Gupta, Ranganath Kondapally, Chakrapani Ravi Kiran", "title": "Impersonation: Modeling Persona in Smart Responses to Email", "comments": "IJCAI 2018 conference. Workshop on Humanizing AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present design, implementation, and effectiveness of\ngenerating personalized suggestions for email replies. To personalize email\nresponses based on users style and personality, we model the users persona\nbased on her past responses to emails. This model is added to the\nlanguage-based model created across users using past responses of the all user\nemails.\n  A users model captures the typical responses of the user given a particular\ncontext. The context includes the email received, recipient of the email, and\nother external signals such as calendar activities, preferences, etc. The\ncontext along with users personality (e.g., extrovert, formal, reserved, etc.)\nis used to suggest responses. These responses can be a mixture of multiple\nmodes: email replies (textual), audio clips, etc. This helps in making\nresponses mimic the user as much as possible and helps the user to be more\nproductive while retaining her mark in the responses.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 12:08:30 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Gupta", "Rajeev", ""], ["Kondapally", "Ranganath", ""], ["Kiran", "Chakrapani Ravi", ""]]}, {"id": "1806.04458", "submitter": "Mayumi Ohta", "authors": "Artem Sokolov, Julian Hitschler, Mayumi Ohta, Stefan Riezler", "title": "Sparse Stochastic Zeroth-Order Optimization with an Application to\n  Bandit Structured Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic zeroth-order (SZO), or gradient-free, optimization allows to\noptimize arbitrary functions by relying only on function evaluations under\nparameter perturbations, however, the iteration complexity of SZO methods\nsuffers a factor proportional to the dimensionality of the perturbed function.\nWe show that in scenarios with natural sparsity patterns as in structured\nprediction applications, this factor can be reduced to the expected number of\nactive features over input-output pairs. We give a general proof that applies\nsparse SZO optimization to Lipschitz-continuous, nonconvex, stochastic\nobjectives, and present an experimental evaluation on linear bandit structured\nprediction tasks with sparse word-based feature representations that confirm\nour theoretical results.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 12:16:54 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 10:31:14 GMT"}, {"version": "v3", "created": "Tue, 10 Nov 2020 11:11:28 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Sokolov", "Artem", ""], ["Hitschler", "Julian", ""], ["Ohta", "Mayumi", ""], ["Riezler", "Stefan", ""]]}, {"id": "1806.04466", "submitter": "Shaohui Kuang", "authors": "Shaohui Kuang, Deyi Xiong", "title": "Fusing Recency into Neural Machine Translation with an Inter-Sentence\n  Gate Model", "comments": "Accepted by COLING2018.11 pages,4 figures. arXiv admin note: text\n  overlap with arXiv:1711.11221", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) systems are usually trained on a large\namount of bilingual sentence pairs and translate one sentence at a time,\nignoring inter-sentence information. This may make the translation of a\nsentence ambiguous or even inconsistent with the translations of neighboring\nsentences. In order to handle this issue, we propose an inter-sentence gate\nmodel that uses the same encoder to encode two adjacent sentences and controls\nthe amount of information flowing from the preceding sentence to the\ntranslation of the current sentence with an inter-sentence gate. In this way,\nour proposed model can capture the connection between sentences and fuse\nrecency from neighboring sentences into neural machine translation. On several\nNIST Chinese-English translation tasks, our experiments demonstrate that the\nproposed inter-sentence gate model achieves substantial improvements over the\nbaseline.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 12:37:20 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Kuang", "Shaohui", ""], ["Xiong", "Deyi", ""]]}, {"id": "1806.04470", "submitter": "Jie Yang", "authors": "Jie Yang, Shuailong Liang, Yue Zhang", "title": "Design Challenges and Misconceptions in Neural Sequence Labeling", "comments": "Accepted by COLING 2018 (Best Paper Award)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the design challenges of constructing effective and efficient\nneural sequence labeling systems, by reproducing twelve neural sequence\nlabeling models, which include most of the state-of-the-art structures, and\nconduct a systematic model comparison on three benchmarks (i.e. NER, Chunking,\nand POS tagging). Misconceptions and inconsistent conclusions in existing\nliterature are examined and clarified under statistical experiments. In the\ncomparison and analysis process, we reach several practical conclusions which\ncan be useful to practitioners.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 12:43:42 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 09:31:10 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Yang", "Jie", ""], ["Liang", "Shuailong", ""], ["Zhang", "Yue", ""]]}, {"id": "1806.04508", "submitter": "Ndapandula Nakashole", "authors": "Ndapa Nakashole and Raphael Flauger", "title": "Characterizing Departures from Linearity in Word Translation", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the behavior of maps learned by machine translation methods.\nThe maps translate words by projecting between word embedding spaces of\ndifferent languages. We locally approximate these maps using linear maps, and\nfind that they vary across the word embedding space. This demonstrates that the\nunderlying maps are non-linear. Importantly, we show that the locally linear\nmaps vary by an amount that is tightly correlated with the distance between the\nneighborhoods on which they are trained. Our results can be used to test\nnon-linear methods, and to drive the design of more accurate maps for word\ntranslation.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2018 23:04:19 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 23:15:14 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Nakashole", "Ndapa", ""], ["Flauger", "Raphael", ""]]}, {"id": "1806.04510", "submitter": "Abel Peirson V", "authors": "Abel L Peirson V and E Meltem Tolunay", "title": "Dank Learning: Generating Memes Using Deep Neural Networks", "comments": "Stanford CS 224n Project", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel meme generation system, which given any image can\nproduce a humorous and relevant caption. Furthermore, the system can be\nconditioned on not only an image but also a user-defined label relating to the\nmeme template, giving a handle to the user on meme content. The system uses a\npretrained Inception-v3 network to return an image embedding which is passed to\nan attention-based deep-layer LSTM model producing the caption - inspired by\nthe widely recognised Show and Tell Model. We implement a modified beam search\nto encourage diversity in the captions. We evaluate the quality of our model\nusing perplexity and human assessment on both the quality of memes generated\nand whether they can be differentiated from real ones. Our model produces\noriginal memes that cannot on the whole be differentiated from real ones.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2018 03:29:30 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Peirson", "Abel L", "V"], ["Tolunay", "E Meltem", ""]]}, {"id": "1806.04511", "submitter": "Aysu Can", "authors": "Ethem F. Can, Aysu Ezen-Can, Fazli Can", "title": "Multilingual Sentiment Analysis: An RNN-Based Framework for Limited Data", "comments": "ACM SIGIR 2018 Workshop on Learning from Limited or Noisy Data\n  (LND4IR'18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis is a widely studied NLP task where the goal is to\ndetermine opinions, emotions, and evaluations of users towards a product, an\nentity or a service that they are reviewing. One of the biggest challenges for\nsentiment analysis is that it is highly language dependent. Word embeddings,\nsentiment lexicons, and even annotated data are language specific. Further,\noptimizing models for each language is very time consuming and labor intensive\nespecially for recurrent neural network models. From a resource perspective, it\nis very challenging to collect data for different languages.\n  In this paper, we look for an answer to the following research question: can\na sentiment analysis model trained on a language be reused for sentiment\nanalysis in other languages, Russian, Spanish, Turkish, and Dutch, where the\ndata is more limited? Our goal is to build a single model in the language with\nthe largest dataset available for the task, and reuse it for languages that\nhave limited resources. For this purpose, we train a sentiment analysis model\nusing recurrent neural networks with reviews in English. We then translate\nreviews in other languages and reuse this model to evaluate the sentiments.\nExperimental results show that our robust approach of single model trained on\nEnglish reviews statistically significantly outperforms the baselines in\nseveral different languages.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2018 14:01:31 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Can", "Ethem F.", ""], ["Ezen-Can", "Aysu", ""], ["Can", "Fazli", ""]]}, {"id": "1806.04523", "submitter": "Wenpeng Yin", "authors": "Wenpeng Yin, Yadollah Yaghoobzadeh, Hinrich Sch\\\"utze", "title": "Recurrent One-Hop Predictions for Reasoning over Knowledge Graphs", "comments": "COLING'2018 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large scale knowledge graphs (KGs) such as Freebase are generally incomplete.\nReasoning over multi-hop (mh) KG paths is thus an important capability that is\nneeded for question answering or other NLP tasks that require knowledge about\nthe world. mh-KG reasoning includes diverse scenarios, e.g., given a head\nentity and a relation path, predict the tail entity; or given two entities\nconnected by some relation paths, predict the unknown relation between them. We\npresent ROPs, recurrent one-hop predictors, that predict entities at each step\nof mh-KB paths by using recurrent neural networks and vector representations of\nentities and relations, with two benefits: (i) modeling mh-paths of arbitrary\nlengths while updating the entity and relation representations by the training\nsignal at each step; (ii) handling different types of mh-KG reasoning in a\nunified framework. Our models show state-of-the-art for two important multi-hop\nKG reasoning tasks: Knowledge Base Completion and Path Query Answering.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 13:52:15 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Yin", "Wenpeng", ""], ["Yaghoobzadeh", "Yadollah", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1806.04524", "submitter": "Edison Marrese-Taylor", "authors": "Edison Marrese-Taylor, Ai Nakajima, Yutaka Matsuo, Ono Yuichi", "title": "Learning to Automatically Generate Fill-In-The-Blank Quizzes", "comments": "5 pages", "journal-ref": "5th Workshop on Natural Language Processing Techniques for\n  Educational Applications (NLPTEA), collocated with ACL 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we formalize the problem automatic fill-in-the-blank question\ngeneration using two standard NLP machine learning schemes, proposing concrete\ndeep learning models for each. We present an empirical study based on data\nobtained from a language learning platform showing that both of our proposed\nsettings offer promising results.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 13:53:22 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Marrese-Taylor", "Edison", ""], ["Nakajima", "Ai", ""], ["Matsuo", "Yutaka", ""], ["Yuichi", "Ono", ""]]}, {"id": "1806.04525", "submitter": "Anton Osika", "authors": "Anton Osika, Susanna Nilsson, Andrii Sydorchuk, Faruk Sahin, Anders\n  Huss", "title": "Second Language Acquisition Modeling: An Ensemble Approach", "comments": null, "journal-ref": "Proceedings of the Thirteenth Workshop, Building Educational\n  Applications, NAACL 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate prediction of students knowledge is a fundamental building block of\npersonalized learning systems. Here, we propose a novel ensemble model to\npredict student knowledge gaps. Applying our approach to student trace data\nfrom the online educational platform Duolingo we achieved highest score on both\nevaluation metrics for all three datasets in the 2018 Shared Task on Second\nLanguage Acquisition Modeling. We describe our model and discuss relevance of\nthe task compared to how it would be setup in a production environment for\npersonalized education.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jun 2018 18:09:37 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Osika", "Anton", ""], ["Nilsson", "Susanna", ""], ["Sydorchuk", "Andrii", ""], ["Sahin", "Faruk", ""], ["Huss", "Anders", ""]]}, {"id": "1806.04532", "submitter": "Wenpeng Yin", "authors": "Wenpeng Yin, Dan Roth", "title": "Term Definitions Help Hypernymy Detection", "comments": "*SEM'2018 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing methods of hypernymy detection mainly rely on statistics over a big\ncorpus, either mining some co-occurring patterns like \"animals such as cats\" or\nembedding words of interest into context-aware vectors. These approaches are\ntherefore limited by the availability of a large enough corpus that can cover\nall terms of interest and provide sufficient contextual information to\nrepresent their meaning. In this work, we propose a new paradigm, HyperDef, for\nhypernymy detection -- expressing word meaning by encoding word definitions,\nalong with context driven representation. This has two main benefits: (i)\nDefinitional sentences express (sense-specific) corpus-independent meanings of\nwords, hence definition-driven approaches enable strong generalization -- once\ntrained, the model is expected to work well in open-domain testbeds; (ii)\nGlobal context from a large corpus and definitions provide complementary\ninformation for words. Consequently, our model, HyperDef, once trained on\ntask-agnostic data, gets state-of-the-art results in multiple benchmarks\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 14:00:18 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Yin", "Wenpeng", ""], ["Roth", "Dan", ""]]}, {"id": "1806.04535", "submitter": "Srishti Aggarwal", "authors": "Srishti Aggarwal, Kritik Mathur, Radhika Mamidi", "title": "Automatic Target Recovery for Hindi-English Code Mixed Puns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order for our computer systems to be more human-like, with a higher\nemotional quotient, they need to be able to process and understand intrinsic\nhuman language phenomena like humour. In this paper, we consider a subtype of\nhumour - puns, which are a common type of wordplay-based jokes. In particular,\nwe consider code-mixed puns which have become increasingly mainstream on social\nmedia, in informal conversations and advertisements and aim to build a system\nwhich can automatically identify the pun location and recover the target of\nsuch puns. We first study and classify code-mixed puns into two categories\nnamely intra-sentential and intra-word, and then propose a four-step algorithm\nto recover the pun targets for puns belonging to the intra-sentential category.\nOur algorithm uses language models, and phonetic similarity-based features to\nget the desired results. We test our approach on a small set of code-mixed\npunning advertisements, and observe that our system is successfully able to\nrecover the targets for 67% of the puns.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 09:45:34 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Aggarwal", "Srishti", ""], ["Mathur", "Kritik", ""], ["Mamidi", "Radhika", ""]]}, {"id": "1806.04550", "submitter": "Florian Schmidt", "authors": "Florian Schmidt and Thomas Hofmann", "title": "Deep State Space Models for Unconditional Word Generation", "comments": "NIPS camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoregressive feedback is considered a necessity for successful\nunconditional text generation using stochastic sequence models. However, such\nfeedback is known to introduce systematic biases into the training process and\nit obscures a principle of generation: committing to global information and\nforgetting local nuances. We show that a non-autoregressive deep state space\nmodel with a clear separation of global and local uncertainty can be built from\nonly two ingredients: An independent noise source and a deterministic\ntransition function. Recent advances on flow-based variational inference can be\nused to train an evidence lower-bound without resorting to annealing, auxiliary\nlosses or similar measures. The result is a highly interpretable generative\nmodel on par with comparable auto-regressive models on the task of word\ngeneration.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 14:19:48 GMT"}, {"version": "v2", "created": "Sun, 28 Oct 2018 19:07:26 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Schmidt", "Florian", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1806.04558", "submitter": "Ye Jia", "authors": "Ye Jia, Yu Zhang, Ron J. Weiss, Quan Wang, Jonathan Shen, Fei Ren,\n  Zhifeng Chen, Patrick Nguyen, Ruoming Pang, Ignacio Lopez Moreno, Yonghui Wu", "title": "Transfer Learning from Speaker Verification to Multispeaker\n  Text-To-Speech Synthesis", "comments": "NeurIPS 2018", "journal-ref": "Advances in Neural Information Processing Systems 31 (2018),\n  4485-4495", "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a neural network-based system for text-to-speech (TTS) synthesis\nthat is able to generate speech audio in the voice of many different speakers,\nincluding those unseen during training. Our system consists of three\nindependently trained components: (1) a speaker encoder network, trained on a\nspeaker verification task using an independent dataset of noisy speech from\nthousands of speakers without transcripts, to generate a fixed-dimensional\nembedding vector from seconds of reference speech from a target speaker; (2) a\nsequence-to-sequence synthesis network based on Tacotron 2, which generates a\nmel spectrogram from text, conditioned on the speaker embedding; (3) an\nauto-regressive WaveNet-based vocoder that converts the mel spectrogram into a\nsequence of time domain waveform samples. We demonstrate that the proposed\nmodel is able to transfer the knowledge of speaker variability learned by the\ndiscriminatively-trained speaker encoder to the new task, and is able to\nsynthesize natural speech from speakers that were not seen during training. We\nquantify the importance of training the speaker encoder on a large and diverse\nspeaker set in order to obtain the best generalization performance. Finally, we\nshow that randomly sampled speaker embeddings can be used to synthesize speech\nin the voice of novel speakers dissimilar from those used in training,\nindicating that the model has learned a high quality speaker representation.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 14:29:22 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 23:59:44 GMT"}, {"version": "v3", "created": "Mon, 5 Nov 2018 19:48:56 GMT"}, {"version": "v4", "created": "Wed, 2 Jan 2019 19:00:05 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Jia", "Ye", ""], ["Zhang", "Yu", ""], ["Weiss", "Ron J.", ""], ["Wang", "Quan", ""], ["Shen", "Jonathan", ""], ["Ren", "Fei", ""], ["Chen", "Zhifeng", ""], ["Nguyen", "Patrick", ""], ["Pang", "Ruoming", ""], ["Moreno", "Ignacio Lopez", ""], ["Wu", "Yonghui", ""]]}, {"id": "1806.04616", "submitter": "Annie Louis", "authors": "Annie Louis, Santanu Kumar Dash, Earl T. Barr and Charles Sutton", "title": "Deep Learning to Detect Redundant Method Comments", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comments in software are critical for maintenance and reuse. But apart from\nprescriptive advice, there is little practical support or quantitative\nunderstanding of what makes a comment useful. In this paper, we introduce the\ntask of identifying comments which are uninformative about the code they are\nmeant to document. To address this problem, we introduce the notion of comment\nentailment from code, high entailment indicating that a comment's natural\nlanguage semantics can be inferred directly from the code. Although not all\nentailed comments are low quality, comments that are too easily inferred, for\nexample, comments that restate the code, are widely discouraged by authorities\non software style. Based on this, we develop a tool called CRAIC which scores\nmethod-level comments for redundancy. Highly redundant comments can then be\nexpanded or alternately removed by the developer. CRAIC uses deep language\nmodels to exploit large software corpora without requiring expensive manual\nannotations of entailment. We show that CRAIC can perform the comment\nentailment task with good agreement with human judgements. Our findings also\nhave implications for documentation tools. For example, we find that common\ntags in Javadoc are at least two times more predictable from code than\nnon-Javadoc sentences, suggesting that Javadoc tags are less informative than\nmore free-form comments\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 15:49:14 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Louis", "Annie", ""], ["Dash", "Santanu Kumar", ""], ["Barr", "Earl T.", ""], ["Sutton", "Charles", ""]]}, {"id": "1806.04713", "submitter": "Hanan Aldarmaki", "authors": "Hanan Aldarmaki and Mona Diab", "title": "Evaluation of Unsupervised Compositional Representations", "comments": "12 pages, 5 figures. COLING 2018", "journal-ref": "Proceedings of the 27th International Conference on Computational\n  Linguistics (2018)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluated various compositional models, from bag-of-words representations\nto compositional RNN-based models, on several extrinsic supervised and\nunsupervised evaluation benchmarks. Our results confirm that weighted vector\naveraging can outperform context-sensitive models in most benchmarks, but\nstructural features encoded in RNN models can also be useful in certain\nclassification tasks. We analyzed some of the evaluation datasets to identify\nthe aspects of meaning they measure and the characteristics of the various\nmodels that explain their performance variance.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 18:53:14 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2018 16:43:27 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Aldarmaki", "Hanan", ""], ["Diab", "Mona", ""]]}, {"id": "1806.04818", "submitter": "Zexian Zeng", "authors": "Zexian Zeng, Ankita Roy, Xiaoyu Li, Sasa Espino, Susan Clare, Seema\n  Khan, Yuan Luo", "title": "Using Clinical Narratives and Structured Data to Identify Distant\n  Recurrences in Breast Cancer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately identifying distant recurrences in breast cancer from the\nElectronic Health Records (EHR) is important for both clinical care and\nsecondary analysis. Although multiple applications have been developed for\ncomputational phenotyping in breast cancer, distant recurrence identification\nstill relies heavily on manual chart review. In this study, we aim to develop a\nmodel that identifies distant recurrences in breast cancer using clinical\nnarratives and structured data from EHR. We apply MetaMap to extract features\nfrom clinical narratives and also retrieve structured clinical data from EHR.\nUsing these features, we train a support vector machine model to identify\ndistant recurrences in breast cancer patients. We train the model using 1,396\ndouble-annotated subjects and validate the model using 599 double-annotated\nsubjects. In addition, we validate the model on a set of 4,904 single-annotated\nsubjects as a generalization test. We obtained a high area under curve (AUC)\nscore of 0.92 (SD=0.01) in the cross-validation using the training dataset,\nthen obtained AUC scores of 0.95 and 0.93 in the held-out test and\ngeneralization test using 599 and 4,904 samples respectively. Our model can\naccurately and efficiently identify distant recurrences in breast cancer by\ncombining features extracted from unstructured clinical narratives and\nstructured clinical data.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 01:58:22 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2018 21:36:22 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Zeng", "Zexian", ""], ["Roy", "Ankita", ""], ["Li", "Xiaoyu", ""], ["Espino", "Sasa", ""], ["Clare", "Susan", ""], ["Khan", "Seema", ""], ["Luo", "Yuan", ""]]}, {"id": "1806.04820", "submitter": "Zexian Zeng", "authors": "Zexian Zeng, Yu Deng, Xiaoyu Li, Tristan Naumann, Yuan Luo", "title": "Natural Language Processing for EHR-Based Computational Phenotyping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article reviews recent advances in applying natural language processing\n(NLP) to Electronic Health Records (EHRs) for computational phenotyping.\nNLP-based computational phenotyping has numerous applications including\ndiagnosis categorization, novel phenotype discovery, clinical trial screening,\npharmacogenomics, drug-drug interaction (DDI) and adverse drug event (ADE)\ndetection, as well as genome-wide and phenome-wide association studies.\nSignificant progress has been made in algorithm development and resource\nconstruction for computational phenotyping. Among the surveyed methods,\nwell-designed keyword search and rule-based systems often achieve good\nperformance. However, the construction of keyword and rule lists requires\nsignificant manual effort, which is difficult to scale. Supervised machine\nlearning models have been favored because they are capable of acquiring both\nclassification patterns and structures from data. Recently, deep learning and\nunsupervised learning have received growing attention, with the former favored\nfor its performance and the latter for its ability to find novel phenotypes.\nIntegrating heterogeneous data sources have become increasingly important and\nhave shown promise in improving model performance. Often better performance is\nachieved by combining multiple modalities of information. Despite these many\nadvances, challenges and opportunities remain for NLP-based computational\nphenotyping, including better model interpretability and generalizability, and\nproper characterization of feature relations in clinical narratives\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 02:14:19 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2018 21:33:30 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Zeng", "Zexian", ""], ["Deng", "Yu", ""], ["Li", "Xiaoyu", ""], ["Naumann", "Tristan", ""], ["Luo", "Yuan", ""]]}, {"id": "1806.04822", "submitter": "Pengcheng Yang", "authors": "Pengcheng Yang and Xu Sun and Wei Li and Shuming Ma and Wei Wu and\n  Houfeng Wang", "title": "SGM: Sequence Generation Model for Multi-label Classification", "comments": "Accepted by COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label classification is an important yet challenging task in natural\nlanguage processing. It is more complex than single-label classification in\nthat the labels tend to be correlated. Existing methods tend to ignore the\ncorrelations between labels. Besides, different parts of the text can\ncontribute differently for predicting different labels, which is not considered\nby existing models. In this paper, we propose to view the multi-label\nclassification task as a sequence generation problem, and apply a sequence\ngeneration model with a novel decoder structure to solve it. Extensive\nexperimental results show that our proposed methods outperform previous work by\na substantial margin. Further analysis of experimental results demonstrates\nthat the proposed methods not only capture the correlations between labels, but\nalso select the most informative words automatically when predicting different\nlabels.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 02:16:01 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2018 15:16:53 GMT"}, {"version": "v3", "created": "Fri, 15 Jun 2018 05:52:24 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Yang", "Pengcheng", ""], ["Sun", "Xu", ""], ["Li", "Wei", ""], ["Ma", "Shuming", ""], ["Wu", "Wei", ""], ["Wang", "Houfeng", ""]]}, {"id": "1806.04841", "submitter": "Hao Tang", "authors": "Hao Tang and Wei-Ning Hsu and Francois Grondin and James Glass", "title": "A Study of Enhancement, Augmentation, and Autoencoder Methods for Domain\n  Adaptation in Distant Speech Recognition", "comments": "Interspeech, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech recognizers trained on close-talking speech do not generalize to\ndistant speech and the word error rate degradation can be as large as 40%\nabsolute. Most studies focus on tackling distant speech recognition as a\nseparate problem, leaving little effort to adapting close-talking speech\nrecognizers to distant speech. In this work, we review several approaches from\na domain adaptation perspective. These approaches, including speech\nenhancement, multi-condition training, data augmentation, and autoencoders, all\ninvolve a transformation of the data between domains. We conduct experiments on\nthe AMI data set, where these approaches can be realized under the same\ncontrolled setting. These approaches lead to different amounts of improvement\nunder their respective assumptions. The purpose of this paper is to quantify\nand characterize the performance gap between the two domains, setting up the\nbasis for studying adaptation of speech recognizers from close-talking speech\nto distant speech. Our results also have implications for improving distant\nspeech recognition.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 04:07:22 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Tang", "Hao", ""], ["Hsu", "Wei-Ning", ""], ["Grondin", "Francois", ""], ["Glass", "James", ""]]}, {"id": "1806.04856", "submitter": "Kaitao Song", "authors": "Kaitao Song, Xu Tan, Di He, Jianfeng Lu, Tao Qin and Tie-Yan Liu", "title": "Double Path Networks for Sequence to Sequence Learning", "comments": "11 pages, to appear in COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Encoder-decoder based Sequence to Sequence learning (S2S) has made remarkable\nprogress in recent years. Different network architectures have been used in the\nencoder/decoder. Among them, Convolutional Neural Networks (CNN) and Self\nAttention Networks (SAN) are the prominent ones. The two architectures achieve\nsimilar performances but use very different ways to encode and decode context:\nCNN use convolutional layers to focus on the local connectivity of the\nsequence, while SAN uses self-attention layers to focus on global semantics. In\nthis work we propose Double Path Networks for Sequence to Sequence learning\n(DPN-S2S), which leverage the advantages of both models by using double path\ninformation fusion. During the encoding step, we develop a double path\narchitecture to maintain the information coming from different paths with\nconvolutional layers and self-attention layers separately. To effectively use\nthe encoded context, we develop a cross attention module with gating and use it\nto automatically pick up the information needed during the decoding step. By\ndeeply integrating the two paths with cross attention, both types of\ninformation are combined and well exploited. Experiments show that our proposed\nmethod can significantly improve the performance of sequence to sequence\nlearning over state-of-the-art systems.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 05:51:10 GMT"}, {"version": "v2", "created": "Wed, 4 Jul 2018 08:46:21 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Song", "Kaitao", ""], ["Tan", "Xu", ""], ["He", "Di", ""], ["Lu", "Jianfeng", ""], ["Qin", "Tao", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1806.04860", "submitter": "Chen Zhu", "authors": "Zhou Su, Chen Zhu, Yinpeng Dong, Dongqi Cai, Yurong Chen, Jianguo Li", "title": "Learning Visual Knowledge Memory Networks for Visual Question Answering", "comments": "Supplementary to CVPR 2018 version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual question answering (VQA) requires joint comprehension of images and\nnatural language questions, where many questions can't be directly or clearly\nanswered from visual content but require reasoning from structured human\nknowledge with confirmation from visual content. This paper proposes visual\nknowledge memory network (VKMN) to address this issue, which seamlessly\nincorporates structured human knowledge and deep visual features into memory\nnetworks in an end-to-end learning framework. Comparing to existing methods for\nleveraging external knowledge for supporting VQA, this paper stresses more on\ntwo missing mechanisms. First is the mechanism for integrating visual contents\nwith knowledge facts. VKMN handles this issue by embedding knowledge triples\n(subject, relation, target) and deep visual features jointly into the visual\nknowledge features. Second is the mechanism for handling multiple knowledge\nfacts expanding from question and answer pairs. VKMN stores joint embedding\nusing key-value pair structure in the memory networks so that it is easy to\nhandle multiple facts. Experiments show that the proposed method achieves\npromising results on both VQA v1.0 and v2.0 benchmarks, while outperforms\nstate-of-the-art methods on the knowledge-reasoning related questions.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 06:37:42 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Su", "Zhou", ""], ["Zhu", "Chen", ""], ["Dong", "Yinpeng", ""], ["Cai", "Dongqi", ""], ["Chen", "Yurong", ""], ["Li", "Jianguo", ""]]}, {"id": "1806.04872", "submitter": "Wei-Ning Hsu", "authors": "Wei-Ning Hsu, Hao Tang, James Glass", "title": "Unsupervised Adaptation with Interpretable Disentangled Representations\n  for Distant Conversational Speech Recognition", "comments": "to appear in Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current trend in automatic speech recognition is to leverage large\namounts of labeled data to train supervised neural network models.\nUnfortunately, obtaining data for a wide range of domains to train robust\nmodels can be costly. However, it is relatively inexpensive to collect large\namounts of unlabeled data from domains that we want the models to generalize\nto. In this paper, we propose a novel unsupervised adaptation method that\nlearns to synthesize labeled data for the target domain from unlabeled\nin-domain data and labeled out-of-domain data. We first learn without\nsupervision an interpretable latent representation of speech that encodes\nlinguistic and nuisance factors (e.g., speaker and channel) using different\nlatent variables. To transform a labeled out-of-domain utterance without\naltering its transcript, we transform the latent nuisance variables while\nmaintaining the linguistic variables. To demonstrate our approach, we focus on\na channel mismatch setting, where the domain of interest is distant\nconversational speech, and labels are only available for close-talking speech.\nOur proposed method is evaluated on the AMI dataset, outperforming all\nbaselines and bridging the gap between unadapted and in-domain models by over\n77% without using any parallel data.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 07:14:15 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Hsu", "Wei-Ning", ""], ["Tang", "Hao", ""], ["Glass", "James", ""]]}, {"id": "1806.04936", "submitter": "Stanislau Semeniuta", "authors": "Stanislau Semeniuta, Aliaksei Severyn, Sylvain Gelly", "title": "On Accurate Evaluation of GANs for Language Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are a promising approach to language\ngeneration. The latest works introducing novel GAN models for language\ngeneration use n-gram based metrics for evaluation and only report single\nscores of the best run. In this paper, we argue that this often misrepresents\nthe true picture and does not tell the full story, as GAN models can be\nextremely sensitive to the random initialization and small deviations from the\nbest hyperparameter choice. In particular, we demonstrate that the previously\nused BLEU score is not sensitive to semantic deterioration of generated texts\nand propose alternative metrics that better capture the quality and diversity\nof the generated samples. We also conduct a set of experiments comparing a\nnumber of GAN models for text with a conventional Language Model (LM) and find\nthat neither of the considered models performs convincingly better than the LM.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 10:35:45 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2018 12:25:16 GMT"}, {"version": "v3", "created": "Thu, 18 Jul 2019 16:36:18 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Semeniuta", "Stanislau", ""], ["Severyn", "Aliaksei", ""], ["Gelly", "Sylvain", ""]]}, {"id": "1806.04973", "submitter": "Michael Bommarito II", "authors": "Michael J Bommarito II and Daniel Martin Katz and Eric M Detterman", "title": "OpenEDGAR: Open Source Software for SEC EDGAR Analysis", "comments": "12 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OpenEDGAR is an open source Python framework designed to rapidly construct\nresearch databases based on the Electronic Data Gathering, Analysis, and\nRetrieval (EDGAR) system operated by the US Securities and Exchange Commission\n(SEC). OpenEDGAR is built on the Django application framework, supports\ndistributed compute across one or more servers, and includes functionality to\n(i) retrieve and parse index and filing data from EDGAR, (ii) build tables for\nkey metadata like form type and filer, (iii) retrieve, parse, and update CIK to\nticker and industry mappings, (iv) extract content and metadata from filing\ndocuments, and (v) search filing document contents. OpenEDGAR is designed for\nuse in both academic research and industrial applications, and is distributed\nunder MIT License at https://github.com/LexPredict/openedgar.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 12:16:37 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Bommarito", "Michael J", "II"], ["Katz", "Daniel Martin", ""], ["Detterman", "Eric M", ""]]}, {"id": "1806.05030", "submitter": "Herman Kamper", "authors": "Herman Kamper and Michael Roth", "title": "Visually grounded cross-lingual keyword spotting in speech", "comments": "5 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work considered how images paired with speech can be used as\nsupervision for building speech systems when transcriptions are not available.\nWe ask whether visual grounding can be used for cross-lingual keyword spotting:\ngiven a text keyword in one language, the task is to retrieve spoken utterances\ncontaining that keyword in another language. This could enable searching\nthrough speech in a low-resource language using text queries in a high-resource\nlanguage. As a proof-of-concept, we use English speech with German queries: we\nuse a German visual tagger to add keyword labels to each training image, and\nthen train a neural network to map English speech to German keywords. Without\nseeing parallel speech-transcriptions or translations, the model achieves a\nprecision at ten of 58%. We show that most erroneous retrievals contain\nequivalent or semantically relevant keywords; excluding these would improve\nP@10 to 91%.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 13:37:34 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Kamper", "Herman", ""], ["Roth", "Michael", ""]]}, {"id": "1806.05059", "submitter": "Shiyu Zhou", "authors": "Shiyu Zhou, Shuang Xu, Bo Xu", "title": "Multilingual End-to-End Speech Recognition with A Single Transformer on\n  Low-Resource Languages", "comments": "arXiv admin note: text overlap with arXiv:1805.06239", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence attention-based models integrate an acoustic,\npronunciation and language model into a single neural network, which make them\nvery suitable for multilingual automatic speech recognition (ASR). In this\npaper, we are concerned with multilingual speech recognition on low-resource\nlanguages by a single Transformer, one of sequence-to-sequence attention-based\nmodels. Sub-words are employed as the multilingual modeling unit without using\nany pronunciation lexicon. First, we show that a single multilingual ASR\nTransformer performs well on low-resource languages despite of some language\nconfusion. We then look at incorporating language information into the model by\ninserting the language symbol at the beginning or at the end of the original\nsub-words sequence under the condition of language information being known\nduring training. Experiments on CALLHOME datasets demonstrate that the\nmultilingual ASR Transformer with the language symbol at the end performs\nbetter and can obtain relatively 10.5\\% average word error rate (WER) reduction\ncompared to SHL-MLSTM with residual learning. We go on to show that, assuming\nthe language information being known during training and testing, about\nrelatively 12.4\\% average WER reduction can be observed compared to SHL-MLSTM\nwith residual learning through giving the language symbol as the sentence start\ntoken.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 05:13:04 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2018 00:48:39 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Zhou", "Shiyu", ""], ["Xu", "Shuang", ""], ["Xu", "Bo", ""]]}, {"id": "1806.05099", "submitter": "Zhengzhong Liu", "authors": "Zhengzhong Liu, Teruko Mitamura, Eduard Hovy", "title": "Graph-Based Decoding for Event Sequencing and Coreference Resolution", "comments": "13 pages. COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Events in text documents are interrelated in complex ways. In this paper, we\nstudy two types of relation: Event Coreference and Event Sequencing. We show\nthat the popular tree-like decoding structure for automated Event Coreference\nis not suitable for Event Sequencing. To this end, we propose a graph-based\ndecoding algorithm that is applicable to both tasks. The new decoding algorithm\nsupports flexible feature sets for both tasks. Empirically, our event\ncoreference system has achieved state-of-the-art performance on the TAC-KBP\n2015 event coreference task and our event sequencing system beats a strong\ntemporal-based, oracle-informed baseline. We discuss the challenges of studying\nthese event relations.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 15:05:39 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Liu", "Zhengzhong", ""], ["Mitamura", "Teruko", ""], ["Hovy", "Eduard", ""]]}, {"id": "1806.05130", "submitter": "Andrew Wood", "authors": "Andrew Wood, Paige Rodeghero, Ameer Armaly, Collin McMillan", "title": "Detecting Speech Act Types in Developer Question/Answer Conversations\n  During Bug Repair", "comments": "12 pages (10 for content, two for references), accepted into FSE\n  (Foundations of Software Engineering) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper targets the problem of speech act detection in conversations about\nbug repair. We conduct a \"Wizard of Oz\" experiment with 30 professional\nprogrammers, in which the programmers fix bugs for two hours, and use a\nsimulated virtual assistant for help. Then, we use an open coding manual\nannotation procedure to identify the speech act types in the conversations.\nFinally, we train and evaluate a supervised learning algorithm to automatically\ndetect the speech act types in the conversations. In 30 two-hour conversations,\nwe made 2459 annotations and uncovered 26 speech act types. Our automated\ndetection achieved 69% precision and 50% recall. The key application of this\nwork is to advance the state of the art for virtual assistants in software\nengineering. Virtual assistant technology is growing rapidly, though\napplications in software engineering are behind those in other areas, largely\ndue to a lack of relevant data and experiments. This paper targets this problem\nin the area of developer Q/A conversations about bug repair.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 16:26:28 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2018 21:49:34 GMT"}, {"version": "v3", "created": "Tue, 3 Jul 2018 21:19:23 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Wood", "Andrew", ""], ["Rodeghero", "Paige", ""], ["Armaly", "Ameer", ""], ["McMillan", "Collin", ""]]}, {"id": "1806.05138", "submitter": "Harshil Shah", "authors": "Harshil Shah, David Barber", "title": "Generative Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Generative Neural Machine Translation (GNMT), a latent variable\narchitecture which is designed to model the semantics of the source and target\nsentences. We modify an encoder-decoder translation model by adding a latent\nvariable as a language agnostic representation which is encouraged to learn the\nmeaning of the sentence. GNMT achieves competitive BLEU scores on pure\ntranslation tasks, and is superior when there are missing words in the source\nsentence. We augment the model to facilitate multilingual translation and\nsemi-supervised learning without adding parameters. This framework\nsignificantly reduces overfitting when there is limited paired data available,\nand is effective for translating between pairs of languages not seen during\ntraining.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 16:35:32 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Shah", "Harshil", ""], ["Barber", "David", ""]]}, {"id": "1806.05177", "submitter": "Subba Reddy Oota", "authors": "Subba Reddy Oota, Naresh Manwani, and Bapi Raju S", "title": "fMRI Semantic Category Decoding using Linguistic Encoding of Word\n  Embeddings", "comments": "12 pages, 7 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The dispute of how the human brain represents conceptual knowledge has been\nargued in many scientific fields. Brain imaging studies have shown that the\nspatial patterns of neural activation in the brain are correlated with thinking\nabout different semantic categories of words (for example, tools, animals, and\nbuildings) or when viewing the related pictures. In this paper, we present a\ncomputational model that learns to predict the neural activation captured in\nfunctional magnetic resonance imaging (fMRI) data of test words. Unlike the\nmodels with hand-crafted features that have been used in the literature, in\nthis paper we propose a novel approach wherein decoding models are built with\nfeatures extracted from popular linguistic encodings of Word2Vec, GloVe,\nMeta-Embeddings in conjunction with the empirical fMRI data associated with\nviewing several dozen concrete nouns. We compared these models with several\nother models that use word features extracted from FastText, Randomly-generated\nfeatures, Mitchell's 25 features [1]. The experimental results show that the\npredicted fMRI images using Meta-Embeddings meet the state-of-the-art\nperformance. Although models with features from GloVe and Word2Vec predict fMRI\nimages similar to the state-of-the-art model, model with features from\nMeta-Embeddings predicts significantly better. The proposed scheme that uses\npopular linguistic encoding offers a simple and easy approach for semantic\ndecoding from fMRI experiments.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 10:59:33 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Oota", "Subba Reddy", ""], ["Manwani", "Naresh", ""], ["S", "Bapi Raju", ""]]}, {"id": "1806.05178", "submitter": "Harshil Shah", "authors": "Harshil Shah, Bowen Zheng, David Barber", "title": "Generating Sentences Using a Dynamic Canvas", "comments": "AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Attentive Unsupervised Text (W)riter (AUTR), which is a word\nlevel generative model for natural language. It uses a recurrent neural network\nwith a dynamic attention and canvas memory mechanism to iteratively construct\nsentences. By viewing the state of the memory at intermediate stages and where\nthe model is placing its attention, we gain insight into how it constructs\nsentences. We demonstrate that AUTR learns a meaningful latent representation\nfor each sentence, and achieves competitive log-likelihood lower bounds whilst\nbeing computationally efficient. It is effective at generating and\nreconstructing sentences, as well as imputing missing words.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 12:57:19 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Shah", "Harshil", ""], ["Zheng", "Bowen", ""], ["Barber", "David", ""]]}, {"id": "1806.05180", "submitter": "Andreas Hanselowski Dr.", "authors": "Andreas Hanselowski, Avinesh PVS, Benjamin Schiller, Felix Caspelherr,\n  Debanjan Chaudhuri, Christian M. Meyer and Iryna Gurevych", "title": "A Retrospective Analysis of the Fake News Challenge Stance Detection\n  Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 2017 Fake News Challenge Stage 1 (FNC-1) shared task addressed a stance\nclassification task as a crucial first step towards detecting fake news. To\ndate, there is no in-depth analysis paper to critically discuss FNC-1's\nexperimental setup, reproduce the results, and draw conclusions for\nnext-generation stance classification methods. In this paper, we provide such\nan in-depth analysis for the three top-performing systems. We first find that\nFNC-1's proposed evaluation metric favors the majority class, which can be\neasily classified, and thus overestimates the true discriminative power of the\nmethods. Therefore, we propose a new F1-based metric yielding a changed system\nranking. Next, we compare the features and architectures used, which leads to a\nnovel feature-rich stacked LSTM model that performs on par with the best\nsystems, but is superior in predicting minority classes. To understand the\nmethods' ability to generalize, we derive a new dataset and perform both\nin-domain and cross-domain experiments. Our qualitative and quantitative study\nhelps interpreting the original FNC-1 scores and understand which features help\nimproving performance and why. Our new dataset and all source code used during\nthe reproduction study are publicly available for future research.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 15:38:09 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Hanselowski", "Andreas", ""], ["PVS", "Avinesh", ""], ["Schiller", "Benjamin", ""], ["Caspelherr", "Felix", ""], ["Chaudhuri", "Debanjan", ""], ["Meyer", "Christian M.", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1806.05210", "submitter": "Gongbo Tang", "authors": "Gongbo Tang and Fabienne Cap and Eva Pettersson and Joakim Nivre", "title": "An Evaluation of Neural Machine Translation Models on Historical\n  Spelling Normalization", "comments": "12 pages, accepted by COLING 2018, added subword-level Transformer\n  models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we apply different NMT models to the problem of historical\nspelling normalization for five languages: English, German, Hungarian,\nIcelandic, and Swedish. The NMT models are at different levels, have different\nattention mechanisms, and different neural network architectures. Our results\nshow that NMT models are much better than SMT models in terms of character\nerror rate. The vanilla RNNs are competitive to GRUs/LSTMs in historical\nspelling normalization. Transformer models perform better only when provided\nwith more training data. We also find that subword-level models with a small\nsubword vocabulary are better than character-level models for low-resource\nlanguages. In addition, we propose a hybrid method which further improves the\nperformance of historical spelling normalization.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 18:29:09 GMT"}, {"version": "v2", "created": "Sat, 4 Aug 2018 21:33:54 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Tang", "Gongbo", ""], ["Cap", "Fabienne", ""], ["Pettersson", "Eva", ""], ["Nivre", "Joakim", ""]]}, {"id": "1806.05219", "submitter": "Andrew Moore", "authors": "Andrew Moore and Paul Rayson", "title": "Bringing replication and reproduction together with generalisability in\n  NLP: Three reproduction studies for Target Dependent Sentiment Analysis", "comments": "COLING 2018. Code available at: https://github.com/apmoore1/Bella", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Lack of repeatability and generalisability are two significant threats to\ncontinuing scientific development in Natural Language Processing. Language\nmodels and learning methods are so complex that scientific conference papers no\nlonger contain enough space for the technical depth required for replication or\nreproduction. Taking Target Dependent Sentiment Analysis as a case study, we\nshow how recent work in the field has not consistently released code, or\ndescribed settings for learning methods in enough detail, and lacks\ncomparability and generalisability in train, test or validation data. To\ninvestigate generalisability and to enable state of the art comparative\nevaluations, we carry out the first reproduction studies of three groups of\ncomplementary methods and perform the first large-scale mass evaluation on six\ndifferent English datasets. Reflecting on our experiences, we recommend that\nfuture replication or reproduction experiments should always consider a variety\nof datasets alongside documenting and releasing their methods and published\ncode in order to minimise the barriers to both repeatability and\ngeneralisability. We have released our code with a model zoo on GitHub with\nJupyter Notebooks to aid understanding and full documentation, and we recommend\nthat others do the same with their papers at submission time through an\nanonymised GitHub account.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 18:51:05 GMT"}, {"version": "v2", "created": "Mon, 6 Aug 2018 09:45:51 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Moore", "Andrew", ""], ["Rayson", "Paul", ""]]}, {"id": "1806.05231", "submitter": "David Skillicorn", "authors": "D.B. Skillicorn and N. Alsadhan", "title": "Beyond Bags of Words: Inferring Systemic Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Textual analytics based on representations of documents as bags of words have\nbeen reasonably successful. However, analysis that requires deeper insight into\nlanguage, into author properties, or into the contexts in which documents were\ncreated requires a richer representation. Systemic nets are one such\nrepresentation. They have not been extensively used because they required human\neffort to construct. We show that systemic nets can be algorithmically inferred\nfrom corpora, that the resulting nets are plausible, and that they can provide\npractical benefits for knowledge discovery problems. This opens up a new class\nof practical analysis techniques for textual analytics.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 19:14:14 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Skillicorn", "D. B.", ""], ["Alsadhan", "N.", ""]]}, {"id": "1806.05258", "submitter": "Arman Cohan", "authors": "Arman Cohan, Bart Desmet, Andrew Yates, Luca Soldaini, Sean MacAvaney\n  and Nazli Goharian", "title": "SMHD: A Large-Scale Resource for Exploring Online Language Usage for\n  Multiple Mental Health Conditions", "comments": "COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mental health is a significant and growing public health concern. As language\nusage can be leveraged to obtain crucial insights into mental health\nconditions, there is a need for large-scale, labeled, mental health-related\ndatasets of users who have been diagnosed with one or more of such conditions.\nIn this paper, we investigate the creation of high-precision patterns to\nidentify self-reported diagnoses of nine different mental health conditions,\nand obtain high-quality labeled data without the need for manual labelling. We\nintroduce the SMHD (Self-reported Mental Health Diagnoses) dataset and make it\navailable. SMHD is a novel large dataset of social media posts from users with\none or multiple mental health conditions along with matched control users. We\nexamine distinctions in users' language, as measured by linguistic and\npsychological variables. We further explore text classification methods to\nidentify individuals with mental conditions through their language.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 20:29:25 GMT"}, {"version": "v2", "created": "Tue, 10 Jul 2018 19:52:19 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Cohan", "Arman", ""], ["Desmet", "Bart", ""], ["Yates", "Andrew", ""], ["Soldaini", "Luca", ""], ["MacAvaney", "Sean", ""], ["Goharian", "Nazli", ""]]}, {"id": "1806.05284", "submitter": "Vladimir Eidelman", "authors": "Vlad Eidelman, Anastassia Kornilova, Daniel Argyle", "title": "How Predictable is Your State? Leveraging Lexical and Contextual\n  Information for Predicting Legislative Floor Action at the State Level", "comments": "In Proceedings of COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling U.S. Congressional legislation and roll-call votes has received\nsignificant attention in previous literature. However, while legislators across\n50 state governments and D.C. propose over 100,000 bills each year, and on\naverage enact over 30% of them, state level analysis has received relatively\nless attention due in part to the difficulty in obtaining the necessary data.\nSince each state legislature is guided by their own procedures, politics and\nissues, however, it is difficult to qualitatively asses the factors that affect\nthe likelihood of a legislative initiative succeeding. Herein, we present\nseveral methods for modeling the likelihood of a bill receiving floor action\nacross all 50 states and D.C. We utilize the lexical content of over 1 million\nbills, along with contextual legislature and legislator derived features to\nbuild our predictive models, allowing a comparison of the factors that are\nimportant to the lawmaking process. Furthermore, we show that these signals\nhold complementary predictive power, together achieving an average improvement\nin accuracy of 18% over state specific baselines.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 22:05:10 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Eidelman", "Vlad", ""], ["Kornilova", "Anastassia", ""], ["Argyle", "Daniel", ""]]}, {"id": "1806.05337", "submitter": "Chandan Singh", "authors": "Chandan Singh, W. James Murdoch, Bin Yu", "title": "Hierarchical interpretations for neural network predictions", "comments": "Published in ICLR 2019", "journal-ref": "ICLR 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have achieved impressive predictive performance\ndue to their ability to learn complex, non-linear relationships between\nvariables. However, the inability to effectively visualize these relationships\nhas led to DNNs being characterized as black boxes and consequently limited\ntheir applications. To ameliorate this problem, we introduce the use of\nhierarchical interpretations to explain DNN predictions through our proposed\nmethod, agglomerative contextual decomposition (ACD). Given a prediction from a\ntrained DNN, ACD produces a hierarchical clustering of the input features,\nalong with the contribution of each cluster to the final prediction. This\nhierarchy is optimized to identify clusters of features that the DNN learned\nare predictive. Using examples from Stanford Sentiment Treebank and ImageNet,\nwe show that ACD is effective at diagnosing incorrect predictions and\nidentifying dataset bias. Through human experiments, we demonstrate that ACD\nenables users both to identify the more accurate of two DNNs and to better\ntrust a DNN's outputs. We also find that ACD's hierarchy is largely robust to\nadversarial perturbations, implying that it captures fundamental aspects of the\ninput and ignores spurious noise.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 02:41:03 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2019 07:15:40 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Singh", "Chandan", ""], ["Murdoch", "W. James", ""], ["Yu", "Bin", ""]]}, {"id": "1806.05432", "submitter": "Haris Bin Zia", "authors": "Haris Bin Zia, Agha Ali Raza, Awais Athar", "title": "Urdu Word Segmentation using Conditional Random Fields (CRFs)", "comments": "8 pages, COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  State-of-the-art Natural Language Processing algorithms rely heavily on\nefficient word segmentation. Urdu is amongst languages for which word\nsegmentation is a complex task as it exhibits space omission as well as space\ninsertion issues. This is partly due to the Arabic script which although\ncursive in nature, consists of characters that have inherent joining and\nnon-joining attributes regardless of word boundary. This paper presents a word\nsegmentation system for Urdu which uses a Conditional Random Field sequence\nmodeler with orthographic, linguistic and morphological features. Our proposed\nmodel automatically learns to predict white space as word boundary as well as\nZero Width Non-Joiner (ZWNJ) as sub-word boundary. Using a manually annotated\ncorpus, our model achieves F1 score of 0.97 for word boundary identification\nand 0.85 for sub-word boundary identification tasks. We have made our code and\ncorpus publicly available to make our results reproducible.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 09:39:32 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Zia", "Haris Bin", ""], ["Raza", "Agha Ali", ""], ["Athar", "Awais", ""]]}, {"id": "1806.05434", "submitter": "Minghui Qiu", "authors": "Minghui Qiu, Liu Yang, Feng Ji, Weipeng Zhao, Wei Zhou, Jun Huang,\n  Haiqing Chen, W. Bruce Croft, Wei Lin", "title": "Transfer Learning for Context-Aware Question Matching in\n  Information-seeking Conversations in E-commerce", "comments": "6", "journal-ref": "ACL 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Building multi-turn information-seeking conversation systems is an important\nand challenging research topic. Although several advanced neural text matching\nmodels have been proposed for this task, they are generally not efficient for\nindustrial applications. Furthermore, they rely on a large amount of labeled\ndata, which may not be available in real-world applications. To alleviate these\nproblems, we study transfer learning for multi-turn information seeking\nconversations in this paper. We first propose an efficient and effective\nmulti-turn conversation model based on convolutional neural networks. After\nthat, we extend our model to adapt the knowledge learned from a resource-rich\ndomain to enhance the performance. Finally, we deployed our model in an\nindustrial chatbot called AliMe Assist\n(https://consumerservice.taobao.com/online-help) and observed a significant\nimprovement over the existing online model.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 09:44:59 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Qiu", "Minghui", ""], ["Yang", "Liu", ""], ["Ji", "Feng", ""], ["Zhao", "Weipeng", ""], ["Zhou", "Wei", ""], ["Huang", "Jun", ""], ["Chen", "Haiqing", ""], ["Croft", "W. Bruce", ""], ["Lin", "Wei", ""]]}, {"id": "1806.05461", "submitter": "Yanyan Zou", "authors": "Yanyan Zou and Wei Lu", "title": "Learning Cross-lingual Distributed Logical Representations for Semantic\n  Parsing", "comments": "Accepted by ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  With the development of several multilingual datasets used for semantic\nparsing, recent research efforts have looked into the problem of learning\nsemantic parsers in a multilingual setup. However, how to improve the\nperformance of a monolingual semantic parser for a specific language by\nleveraging data annotated in different languages remains a research question\nthat is under-explored. In this work, we present a study to show how learning\ndistributed representations of the logical forms from data annotated in\ndifferent languages can be used for improving the performance of a monolingual\nsemantic parser. We extend two existing monolingual semantic parsers to\nincorporate such cross-lingual distributed logical representations as features.\nExperiments show that our proposed approach is able to yield improved semantic\nparsing results on the standard multilingual GeoQuery dataset.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 10:59:22 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Zou", "Yanyan", ""], ["Lu", "Wei", ""]]}, {"id": "1806.05480", "submitter": "Ciprian-Octavian Truica", "authors": "Ciprian-Octavian Truic\\u{a} and Julien Velcin and Alexandru Boicea", "title": "Automatic Language Identification for Romance Languages using Stop Words\n  and Diacritics", "comments": null, "journal-ref": null, "doi": "10.1109/SYNASC.2015.45", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic language identification is a natural language processing problem\nthat tries to determine the natural language of a given content. In this paper\nwe present a statistical method for automatic language identification of\nwritten text using dictionaries containing stop words and diacritics. We\npropose different approaches that combine the two dictionaries to accurately\ndetermine the language of textual corpora. This method was chosen because stop\nwords and diacritics are very specific to a language, although some languages\nhave some similar words and special characters they are not all common. The\nlanguages taken into account were romance languages because they are very\nsimilar and usually it is hard to distinguish between them from a computational\npoint of view. We have tested our method using a Twitter corpus and a news\narticle corpus. Both corpora consists of UTF-8 encoded text, so the diacritics\ncould be taken into account, in the case that the text has no diacritics only\nthe stop words are used to determine the language of the text. The experimental\nresults show that the proposed method has an accuracy of over 90% for small\ntexts and over 99.8% for\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 11:38:24 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Truic\u0103", "Ciprian-Octavian", ""], ["Velcin", "Julien", ""], ["Boicea", "Alexandru", ""]]}, {"id": "1806.05482", "submitter": "Dominik Mach\\'a\\v{c}ek", "authors": "Dominik Mach\\'a\\v{c}ek, Jon\\'a\\v{s} Vidra, Ond\\v{r}ej Bojar", "title": "Morphological and Language-Agnostic Word Segmentation for NMT", "comments": "In print. To appear in TSD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state of the art of handling rich morphology in neural machine\ntranslation (NMT) is to break word forms into subword units, so that the\noverall vocabulary size of these units fits the practical limits given by the\nNMT model and GPU memory capacity. In this paper, we compare two common but\nlinguistically uninformed methods of subword construction (BPE and STE, the\nmethod implemented in Tensor2Tensor toolkit) and two linguistically-motivated\nmethods: Morfessor and one novel method, based on a derivational dictionary.\nOur experiments with German-to-Czech translation, both morphologically rich,\ndocument that so far, the non-motivated methods perform better. Furthermore, we\niden- tify a critical difference between BPE and STE and show a simple pre-\nprocessing step for BPE that considerably increases translation quality as\nevaluated by automatic measures.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 11:44:48 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Mach\u00e1\u010dek", "Dominik", ""], ["Vidra", "Jon\u00e1\u0161", ""], ["Bojar", "Ond\u0159ej", ""]]}, {"id": "1806.05484", "submitter": "Lina Rojas-Barahona", "authors": "Lina M.Rojas-Barahona, Stefan Ultes, Pawel Budzianowski, I\\~nigo\n  Casanueva, Milica Gasic, Bo-Hsiang Tseng and Steve Young", "title": "Nearly Zero-Shot Learning for Semantic Decoding in Spoken Dialogue\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents two ways of dealing with scarce data in semantic decoding\nusing N-Best speech recognition hypotheses. First, we learn features by using a\ndeep learning architecture in which the weights for the unknown and known\ncategories are jointly optimised. Second, an unsupervised method is used for\nfurther tuning the weights. Sharing weights injects prior knowledge to unknown\ncategories. The unsupervised tuning (i.e. the risk minimisation) improves the\nF-Measure when recognising nearly zero-shot data on the DSTC3 corpus. This\nunsupervised method can be applied subject to two assumptions: the rank of the\nclass marginal is assumed to be known and the class-conditional scores of the\nclassifier are assumed to follow a Gaussian distribution.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 11:47:14 GMT"}, {"version": "v2", "created": "Thu, 21 Jun 2018 11:55:21 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Rojas-Barahona", "Lina M.", ""], ["Ultes", "Stefan", ""], ["Budzianowski", "Pawel", ""], ["Casanueva", "I\u00f1igo", ""], ["Gasic", "Milica", ""], ["Tseng", "Bo-Hsiang", ""], ["Young", "Steve", ""]]}, {"id": "1806.05499", "submitter": "Reinald Kim Amplayo", "authors": "Reinald Kim Amplayo and Seung-won Hwang", "title": "Aspect Sentiment Model for Micro Reviews", "comments": "ICDM 2017", "journal-ref": "Data Mining (ICDM), 2017 IEEE International Conference on", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims at an aspect sentiment model for aspect-based sentiment\nanalysis (ABSA) focused on micro reviews. This task is important in order to\nunderstand short reviews majority of the users write, while existing topic\nmodels are targeted for expert-level long reviews with sufficient co-occurrence\npatterns to observe. Current methods on aggregating micro reviews using\nmetadata information may not be effective as well due to metadata absence,\ntopical heterogeneity, and cold start problems. To this end, we propose a model\ncalled Micro Aspect Sentiment Model (MicroASM). MicroASM is based on the\nobservation that short reviews 1) are viewed with sentiment-aspect word pairs\nas building blocks of information, and 2) can be clustered into larger reviews.\nWhen compared to the current state-of-the-art aspect sentiment models,\nexperiments show that our model provides better performance on aspect-level\ntasks such as aspect term extraction and document-level tasks such as sentiment\nclassification.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 12:28:43 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Amplayo", "Reinald Kim", ""], ["Hwang", "Seung-won", ""]]}, {"id": "1806.05504", "submitter": "Reinald Kim Amplayo", "authors": "Reinald Kim Amplayo and Seonjae Lim and Seung-won Hwang", "title": "Entity Commonsense Representation for Neural Abstractive Summarization", "comments": "NAACL 2018", "journal-ref": "Proceedings of the 2018 Conference of the North American Chapter\n  of the Association for Computational Linguistics: Human Language\n  Technologies, Volume 1 (Long Papers)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major proportion of a text summary includes important entities found in the\noriginal text. These entities build up the topic of the summary. Moreover, they\nhold commonsense information once they are linked to a knowledge base. Based on\nthese observations, this paper investigates the usage of linked entities to\nguide the decoder of a neural text summarizer to generate concise and better\nsummaries. To this end, we leverage on an off-the-shelf entity linking system\n(ELS) to extract linked entities and propose Entity2Topic (E2T), a module\neasily attachable to a sequence-to-sequence model that transforms a list of\nentities into a vector representation of the topic of the summary. Current\navailable ELS's are still not sufficiently effective, possibly introducing\nunresolved ambiguities and irrelevant entities. We resolve the imperfections of\nthe ELS by (a) encoding entities with selective disambiguation, and (b) pooling\nentity vectors using firm attention. By applying E2T to a simple\nsequence-to-sequence model with attention mechanism as base model, we see\nsignificant improvements of the performance in the Gigaword (sentence to title)\nand CNN (long document to multi-sentence highlights) summarization datasets by\nat least 2 ROUGE points.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 12:41:50 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Amplayo", "Reinald Kim", ""], ["Lim", "Seonjae", ""], ["Hwang", "Seung-won", ""]]}, {"id": "1806.05507", "submitter": "Reinald Kim Amplayo", "authors": "Reinald Kim Amplayo and Jihyeok Kim and Sua Sung and Seung-won Hwang", "title": "Cold-Start Aware User and Product Attention for Sentiment Classification", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of user/product information in sentiment analysis is important,\nespecially for cold-start users/products, whose number of reviews are very\nlimited. However, current models do not deal with the cold-start problem which\nis typical in review websites. In this paper, we present Hybrid Contextualized\nSentiment Classifier (HCSC), which contains two modules: (1) a fast word\nencoder that returns word vectors embedded with short and long range dependency\nfeatures; and (2) Cold-Start Aware Attention (CSAA), an attention mechanism\nthat considers the existence of cold-start problem when attentively pooling the\nencoded word vectors. HCSC introduces shared vectors that are constructed from\nsimilar users/products, and are used when the original distinct vectors do not\nhave sufficient information (i.e. cold-start). This is decided by a\nfrequency-guided selective gate vector. Our experiments show that in terms of\nRMSE, HCSC performs significantly better when compared with on famous datasets,\ndespite having less complexity, and thus can be trained much faster. More\nimportantly, our model performs significantly better than previous models when\nthe training data is sparse and has cold-start problems.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 12:48:31 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Amplayo", "Reinald Kim", ""], ["Kim", "Jihyeok", ""], ["Sung", "Sua", ""], ["Hwang", "Seung-won", ""]]}, {"id": "1806.05513", "submitter": "Ankush Khandelwal", "authors": "Ankush Khandelwal, Sahil Swami, Syed S. Akhtar and Manish Shrivastava", "title": "Humor Detection in English-Hindi Code-Mixed Social Media Content :\n  Corpus and Baseline System", "comments": "5 pages, 1 figure, LREC 2018", "journal-ref": "Khandelwa, Ankush, et. al , \"Humor Detection in English-Hindi\n  Code-Mixed Social Media Content : Corpus and Baseline System\". Proceedings of\n  the Eleventh International Conference on Language Resources and Evaluation\n  (LREC 2018)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tremendous amount of user generated data through social networking sites\nled to the gaining popularity of automatic text classification in the field of\ncomputational linguistics over the past decade. Within this domain, one problem\nthat has drawn the attention of many researchers is automatic humor detection\nin texts. In depth semantic understanding of the text is required to detect\nhumor which makes the problem difficult to automate. With increase in the\nnumber of social media users, many multilingual speakers often interchange\nbetween languages while posting on social media which is called code-mixing. It\nintroduces some challenges in the field of linguistic analysis of social media\ncontent (Barman et al., 2014), like spelling variations and non-grammatical\nstructures in a sentence. Past researches include detecting puns in texts (Kao\net al., 2016) and humor in one-lines (Mihalcea et al., 2010) in a single\nlanguage, but with the tremendous amount of code-mixed data available online,\nthere is a need to develop techniques which detects humor in code-mixed tweets.\nIn this paper, we analyze the task of humor detection in texts and describe a\nfreely available corpus containing English-Hindi code-mixed tweets annotated\nwith humorous(H) or non-humorous(N) tags. We also tagged the words in the\ntweets with Language tags (English/Hindi/Others). Moreover, we describe the\nexperiments carried out on the corpus and provide a baseline classification\nsystem which distinguishes between humorous and non-humorous texts.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 12:57:13 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Khandelwal", "Ankush", ""], ["Swami", "Sahil", ""], ["Akhtar", "Syed S.", ""], ["Shrivastava", "Manish", ""]]}, {"id": "1806.05516", "submitter": "Reinald Kim Amplayo", "authors": "Reinald Kim Amplayo and Kyungjae Lee and Jinyeong Yeo and Seung-won\n  Hwang", "title": "Translations as Additional Contexts for Sentence Classification", "comments": "IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In sentence classification tasks, additional contexts, such as the\nneighboring sentences, may improve the accuracy of the classifier. However,\nsuch contexts are domain-dependent and thus cannot be used for another\nclassification task with an inappropriate domain. In contrast, we propose the\nuse of translated sentences as context that is always available regardless of\nthe domain. We find that naive feature expansion of translations gains only\nmarginal improvements and may decrease the performance of the classifier, due\nto possible inaccurate translations thus producing noisy sentence vectors. To\nthis end, we present multiple context fixing attachment (MCFA), a series of\nmodules attached to multiple sentence vectors to fix the noise in the vectors\nusing the other sentence vectors as context. We show that our method performs\ncompetitively compared to previous models, achieving best classification\nperformance on multiple data sets. We are the first to use translations as\ndomain-free contexts for sentence classification.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 13:01:04 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Amplayo", "Reinald Kim", ""], ["Lee", "Kyungjae", ""], ["Yeo", "Jinyeong", ""], ["Hwang", "Seung-won", ""]]}, {"id": "1806.05521", "submitter": "Jisun An", "authors": "Jisun An, Haewoon Kwak, Yong-Yeol Ahn", "title": "SemAxis: A Lightweight Framework to Characterize Domain-Specific Word\n  Semantics Beyond Sentiment", "comments": "Accepted in ACL 2018 as a full paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because word semantics can substantially change across communities and\ncontexts, capturing domain-specific word semantics is an important challenge.\nHere, we propose SEMAXIS, a simple yet powerful framework to characterize word\nsemantics using many semantic axes in word- vector spaces beyond sentiment. We\ndemonstrate that SEMAXIS can capture nuanced semantic representations in\nmultiple online communities. We also show that, when the sentiment axis is\nexamined, SEMAXIS outperforms the state-of-the-art approaches in building\ndomain-specific sentiment lexicons.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 13:11:36 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["An", "Jisun", ""], ["Kwak", "Haewoon", ""], ["Ahn", "Yong-Yeol", ""]]}, {"id": "1806.05559", "submitter": "Francis Gr\\'egoire", "authors": "Francis Gr\\'egoire, Philippe Langlais", "title": "Extracting Parallel Sentences with Bidirectional Recurrent Neural\n  Networks to Improve Machine Translation", "comments": "12 pages, 7 figures, COLING 2018. arXiv admin note: text overlap with\n  arXiv:1709.09783", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel sentence extraction is a task addressing the data sparsity problem\nfound in multilingual natural language processing applications. We propose a\nbidirectional recurrent neural network based approach to extract parallel\nsentences from collections of multilingual texts. Our experiments with noisy\nparallel corpora show that we can achieve promising results against a\ncompetitive baseline by removing the need of specific feature engineering or\nadditional external resources. To justify the utility of our approach, we\nextract sentence pairs from Wikipedia articles to train machine translation\nsystems and show significant improvements in translation performance.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 13:57:13 GMT"}, {"version": "v2", "created": "Fri, 24 Aug 2018 18:16:03 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Gr\u00e9goire", "Francis", ""], ["Langlais", "Philippe", ""]]}, {"id": "1806.05599", "submitter": "Christina Niklaus", "authors": "Christina Niklaus, Matthias Cetto, Andr\\'e Freitas and Siegfried\n  Handschuh", "title": "A Survey on Open Information Extraction", "comments": "27th International Conference on Computational Linguistics (COLING\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We provide a detailed overview of the various approaches that were proposed\nto date to solve the task of Open Information Extraction. We present the major\nchallenges that such systems face, show the evolution of the suggested\napproaches over time and depict the specific issues they address. In addition,\nwe provide a critique of the commonly applied evaluation procedures for\nassessing the performance of Open IE systems and highlight some directions for\nfuture work.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 15:07:46 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Niklaus", "Christina", ""], ["Cetto", "Matthias", ""], ["Freitas", "Andr\u00e9", ""], ["Handschuh", "Siegfried", ""]]}, {"id": "1806.05600", "submitter": "Ankush Khandelwal", "authors": "Ankush Khandelwal, Sahil Swami, Syed Sarfaraz Akhtar and Manish\n  Shrivastava", "title": "Gender Prediction in English-Hindi Code-Mixed Social Media Content :\n  Corpus and Baseline System", "comments": "10 pages, CiCLing 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid expansion in the usage of social media networking sites leads to a\nhuge amount of unprocessed user generated data which can be used for text\nmining. Author profiling is the problem of automatically determining profiling\naspects like the author's gender and age group through a text is gaining much\npopularity in computational linguistics. Most of the past research in author\nprofiling is concentrated on English texts \\cite{1,2}. However many users often\nchange the language while posting on social media which is called code-mixing,\nand it develops some challenges in the field of text classification and author\nprofiling like variations in spelling, non-grammatical structure and\ntransliteration \\cite{3}. There are very few English-Hindi code-mixed annotated\ndatasets of social media content present online \\cite{4}. In this paper, we\nanalyze the task of author's gender prediction in code-mixed content and\npresent a corpus of English-Hindi texts collected from Twitter which is\nannotated with author's gender. We also explore language identification of\nevery word in this corpus. We present a supervised classification baseline\nsystem which uses various machine learning algorithms to identify the gender of\nan author using a text, based on character and word level features.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 15:08:22 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Khandelwal", "Ankush", ""], ["Swami", "Sahil", ""], ["Akhtar", "Syed Sarfaraz", ""], ["Shrivastava", "Manish", ""]]}, {"id": "1806.05626", "submitter": "Jie Yang", "authors": "Jie Yang, Yue Zhang", "title": "NCRF++: An Open-source Neural Sequence Labeling Toolkit", "comments": "ACL 2018, demonstration paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes NCRF++, a toolkit for neural sequence labeling. NCRF++\nis designed for quick implementation of different neural sequence labeling\nmodels with a CRF inference layer. It provides users with an inference for\nbuilding the custom model structure through configuration file with flexible\nneural feature design and utilization. Built on PyTorch, the core operations\nare calculated in batch, making the toolkit efficient with the acceleration of\nGPU. It also includes the implementations of most state-of-the-art neural\nsequence labeling models such as LSTM-CRF, facilitating reproducing and\nrefinement on those methods.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 16:10:57 GMT"}, {"version": "v2", "created": "Sun, 17 Jun 2018 20:36:27 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Yang", "Jie", ""], ["Zhang", "Yue", ""]]}, {"id": "1806.05645", "submitter": "Marc Tanti", "authors": "Hoa Trong Vu, Claudio Greco, Aliia Erofeeva, Somayeh Jafaritazehjan,\n  Guido Linders, Marc Tanti, Alberto Testoni, Raffaella Bernardi, Albert Gatt", "title": "Grounded Textual Entailment", "comments": "15 pages, 2 figures, 14 tables, 2 appendices. Accepted in COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capturing semantic relations between sentences, such as entailment, is a\nlong-standing challenge for computational semantics. Logic-based models analyse\nentailment in terms of possible worlds (interpretations, or situations) where a\npremise P entails a hypothesis H iff in all worlds where P is true, H is also\ntrue. Statistical models view this relationship probabilistically, addressing\nit in terms of whether a human would likely infer H from P. In this paper, we\nwish to bridge these two perspectives, by arguing for a visually-grounded\nversion of the Textual Entailment task. Specifically, we ask whether models can\nperform better if, in addition to P and H, there is also an image\n(corresponding to the relevant \"world\" or \"situation\"). We use a multimodal\nversion of the SNLI dataset (Bowman et al., 2015) and we compare \"blind\" and\nvisually-augmented models of textual entailment. We show that visual\ninformation is beneficial, but we also conduct an in-depth error analysis that\nreveals that current multimodal models are not performing \"grounding\" in an\noptimal fashion.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 16:56:44 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Vu", "Hoa Trong", ""], ["Greco", "Claudio", ""], ["Erofeeva", "Aliia", ""], ["Jafaritazehjan", "Somayeh", ""], ["Linders", "Guido", ""], ["Tanti", "Marc", ""], ["Testoni", "Alberto", ""], ["Bernardi", "Raffaella", ""], ["Gatt", "Albert", ""]]}, {"id": "1806.05655", "submitter": "Fei Liu", "authors": "Kexin Liao, Logan Lebanoff, Fei Liu", "title": "Abstract Meaning Representation for Multi-Document Summarization", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating an abstract from a collection of documents is a desirable\ncapability for many real-world applications. However, abstractive approaches to\nmulti-document summarization have not been thoroughly investigated. This paper\nstudies the feasibility of using Abstract Meaning Representation (AMR), a\nsemantic representation of natural language grounded in linguistic theory, as a\nform of content representation. Our approach condenses source documents to a\nset of summary graphs following the AMR formalism. The summary graphs are then\ntransformed to a set of summary sentences in a surface realization step. The\nframework is fully data-driven and flexible. Each component can be optimized\nindependently using small-scale, in-domain training data. We perform\nexperiments on benchmark summarization datasets and report promising results.\nWe also describe opportunities and challenges for advancing this line of\nresearch.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 17:25:43 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Liao", "Kexin", ""], ["Lebanoff", "Logan", ""], ["Liu", "Fei", ""]]}, {"id": "1806.05658", "submitter": "Fei Liu", "authors": "Kaiqiang Song, Lin Zhao, Fei Liu", "title": "Structure-Infused Copy Mechanisms for Abstractive Summarization", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seq2seq learning has produced promising results on summarization. However, in\nmany cases, system summaries still struggle to keep the meaning of the original\nintact. They may miss out important words or relations that play critical roles\nin the syntactic structure of source sentences. In this paper, we present\nstructure-infused copy mechanisms to facilitate copying important words and\nrelations from the source sentence to summary sentence. The approach naturally\ncombines source dependency structure with the copy mechanism of an abstractive\nsentence summarizer. Experimental results demonstrate the effectiveness of\nincorporating source-side syntactic information in the system, and our proposed\napproach compares favorably to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 17:31:18 GMT"}, {"version": "v2", "created": "Sun, 24 Jun 2018 01:36:22 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Song", "Kaiqiang", ""], ["Zhao", "Lin", ""], ["Liu", "Fei", ""]]}, {"id": "1806.05662", "submitter": "Zhilin Yang", "authors": "Zhilin Yang, Jake Zhao, Bhuwan Dhingra, Kaiming He, William W. Cohen,\n  Ruslan Salakhutdinov, Yann LeCun", "title": "GLoMo: Unsupervisedly Learned Relational Graphs as Transferable\n  Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep transfer learning approaches have mainly focused on learning\ngeneric feature vectors from one task that are transferable to other tasks,\nsuch as word embeddings in language and pretrained convolutional features in\nvision. However, these approaches usually transfer unary features and largely\nignore more structured graphical representations. This work explores the\npossibility of learning generic latent relational graphs that capture\ndependencies between pairs of data units (e.g., words or pixels) from\nlarge-scale unlabeled data and transferring the graphs to downstream tasks. Our\nproposed transfer learning framework improves performance on various tasks\nincluding question answering, natural language inference, sentiment analysis,\nand image classification. We also show that the learned graphs are generic\nenough to be transferred to different embeddings on which the graphs have not\nbeen trained (including GloVe embeddings, ELMo embeddings, and task-specific\nRNN hidden unit), or embedding-free units such as image pixels.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 17:41:19 GMT"}, {"version": "v2", "created": "Sun, 17 Jun 2018 04:36:08 GMT"}, {"version": "v3", "created": "Mon, 2 Jul 2018 20:24:33 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Yang", "Zhilin", ""], ["Zhao", "Jake", ""], ["Dhingra", "Bhuwan", ""], ["He", "Kaiming", ""], ["Cohen", "William W.", ""], ["Salakhutdinov", "Ruslan", ""], ["LeCun", "Yann", ""]]}, {"id": "1806.05740", "submitter": "Rediet Abebe", "authors": "Rediet Abebe, Shawndra Hill, Jennifer Wortman Vaughan, Peter M. Small,\n  H. Andrew Schwartz", "title": "Using Search Queries to Understand Health Information Needs in Africa", "comments": "Extended version of an ICWSM 2019 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of comprehensive, high-quality health data in developing nations\ncreates a roadblock for combating the impacts of disease. One key challenge is\nunderstanding the health information needs of people in these nations. Without\nunderstanding people's everyday needs, concerns, and misconceptions, health\norganizations and policymakers lack the ability to effectively target education\nand programming efforts. In this paper, we propose a bottom-up approach that\nuses search data from individuals to uncover and gain insight into health\ninformation needs in Africa. We analyze Bing searches related to HIV/AIDS,\nmalaria, and tuberculosis from all 54 African nations. For each disease, we\nautomatically derive a set of common search themes or topics, revealing a\nwide-spread interest in various types of information, including disease\nsymptoms, drugs, concerns about breastfeeding, as well as stigma, beliefs in\nnatural cures, and other topics that may be hard to uncover through traditional\nsurveys. We expose the different patterns that emerge in health information\nneeds by demographic groups (age and sex) and country. We also uncover\ndiscrepancies in the quality of content returned by search engines to users by\ntopic. Combined, our results suggest that search data can help illuminate\nhealth information needs in Africa and inform discussions on health policy and\ntargeted education efforts both on- and offline.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 20:48:41 GMT"}, {"version": "v2", "created": "Wed, 17 Apr 2019 17:49:06 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Abebe", "Rediet", ""], ["Hill", "Shawndra", ""], ["Vaughan", "Jennifer Wortman", ""], ["Small", "Peter M.", ""], ["Schwartz", "H. Andrew", ""]]}, {"id": "1806.05838", "submitter": "Marco Del Tredici", "authors": "Marco Del Tredici, Raquel Fern\\'andez", "title": "The Road to Success: Assessing the Fate of Linguistic Innovations in\n  Online Communities", "comments": "13 pages, Proceedings of the 27th International Conference on\n  Computational Linguistics (COLING 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the birth and diffusion of lexical innovations in a large\ndataset of online social communities. We build on sociolinguistic theories and\nfocus on the relation between the spread of a novel term and the social role of\nthe individuals who use it, uncovering characteristics of innovators and\nadopters. Finally, we perform a prediction task that allows us to anticipate\nwhether an innovation will successfully spread within a community.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2018 07:38:01 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Del Tredici", "Marco", ""], ["Fern\u00e1ndez", "Raquel", ""]]}, {"id": "1806.05847", "submitter": "Marco Del Tredici", "authors": "Marco Del Tredici and Raquel Fern\\'andez", "title": "Semantic Variation in Online Communities of Practice", "comments": "13 pages, Proceedings of the 12th International Conference on\n  Computational Semantics (IWCS 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a framework for quantifying semantic variation of common words\nin Communities of Practice and in sets of topic-related communities. We show\nthat while some meaning shifts are shared across related communities, others\nare community-specific, and therefore independent from the discussed topic. We\npropose such findings as evidence in favour of sociolinguistic theories of\nsocially-driven semantic variation. Results are evaluated using an independent\nlanguage modelling task. Furthermore, we investigate extralinguistic features\nand show that factors such as prominence and dissemination of words are related\nto semantic variation.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2018 08:10:12 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Del Tredici", "Marco", ""], ["Fern\u00e1ndez", "Raquel", ""]]}, {"id": "1806.05900", "submitter": "Arne K\\\"ohn", "authors": "Arne K\\\"ohn, Timo Baumann, Oskar D\\\"orfler", "title": "An Empirical Analysis of the Correlation of Syntax and Prosody", "comments": "Accepted for Interspeech 2018 (camera-ready version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The relation of syntax and prosody (the syntax--prosody interface) has been\nan active area of research, mostly in linguistics and typically studied under\ncontrolled conditions. More recently, prosody has also been successfully used\nin the data-based training of syntax parsers. However, there is a gap between\nthe controlled and detailed study of the individual effects between syntax and\nprosody and the large-scale application of prosody in syntactic parsing with\nonly a shallow analysis of the respective influences. In this paper, we close\nthe gap by investigating the significance of correlations of prosodic\nrealization with specific syntactic functions using linear mixed effects models\nin a very large corpus of read-out German encyclopedic texts. Using this\ncorpus, we are able to analyze prosodic structuring performed by a diverse set\nof speakers while they try to optimize factual content delivery. After\nnormalization by speaker, we obtain significant effects, e.g. confirming that\nthe subject function, as compared to the object function, has a positive effect\non pitch and duration of a word, but a negative effect on loudness.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2018 10:55:39 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["K\u00f6hn", "Arne", ""], ["Baumann", "Timo", ""], ["D\u00f6rfler", "Oskar", ""]]}, {"id": "1806.05947", "submitter": "Christoph Teichmann", "authors": "Nikos Engonopoulos and Christoph Teichmann and Alexander Koller", "title": "Discovering User Groups for Natural Language Generation", "comments": "9 pages, 7 Figures, Accepted for SIGDIAL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a model which predicts how individual users of a dialog system\nunderstand and produce utterances based on user groups. In contrast to previous\nwork, these user groups are not specified beforehand, but learned in training.\nWe evaluate on two referring expression (RE) generation tasks; our experiments\nshow that our model can identify user groups and learn how to most effectively\ntalk to them, and can dynamically assign unseen users to the correct groups as\nthey interact with the system.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2018 13:27:32 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Engonopoulos", "Nikos", ""], ["Teichmann", "Christoph", ""], ["Koller", "Alexander", ""]]}, {"id": "1806.05997", "submitter": "Suman Banerjee", "authors": "Suman Banerjee, Nikita Moghe, Siddhartha Arora and Mitesh M. Khapra", "title": "A Dataset for Building Code-Mixed Goal Oriented Conversation Systems", "comments": "15 pages, 2 figures, 10 tables, Accepted in COLING - 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is an increasing demand for goal-oriented conversation systems which\ncan assist users in various day-to-day activities such as booking tickets,\nrestaurant reservations, shopping, etc. Most of the existing datasets for\nbuilding such conversation systems focus on monolingual conversations and there\nis hardly any work on multilingual and/or code-mixed conversations. Such\ndatasets and systems thus do not cater to the multilingual regions of the\nworld, such as India, where it is very common for people to speak more than one\nlanguage and seamlessly switch between them resulting in code-mixed\nconversations. For example, a Hindi speaking user looking to book a restaurant\nwould typically ask, \"Kya tum is restaurant mein ek table book karne mein meri\nhelp karoge?\" (\"Can you help me in booking a table at this restaurant?\"). To\nfacilitate the development of such code-mixed conversation models, we build a\ngoal-oriented dialog dataset containing code-mixed conversations. Specifically,\nwe take the text from the DSTC2 restaurant reservation dataset and create\ncode-mixed versions of it in Hindi-English, Bengali-English, Gujarati-English\nand Tamil-English. We also establish initial baselines on this dataset using\nexisting state of the art models. This dataset along with our baseline\nimplementations is made publicly available for research purposes.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2018 14:28:50 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Banerjee", "Suman", ""], ["Moghe", "Nikita", ""], ["Arora", "Siddhartha", ""], ["Khapra", "Mitesh M.", ""]]}, {"id": "1806.06176", "submitter": "Paul Pu Liang", "authors": "Yao-Hung Hubert Tsai and Paul Pu Liang and Amir Zadeh and\n  Louis-Philippe Morency and Ruslan Salakhutdinov", "title": "Learning Factorized Multimodal Representations", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning multimodal representations is a fundamentally complex research\nproblem due to the presence of multiple heterogeneous sources of information.\nAlthough the presence of multiple modalities provides additional valuable\ninformation, there are two key challenges to address when learning from\nmultimodal data: 1) models must learn the complex intra-modal and cross-modal\ninteractions for prediction and 2) models must be robust to unexpected missing\nor noisy modalities during testing. In this paper, we propose to optimize for a\njoint generative-discriminative objective across multimodal data and labels. We\nintroduce a model that factorizes representations into two sets of independent\nfactors: multimodal discriminative and modality-specific generative factors.\nMultimodal discriminative factors are shared across all modalities and contain\njoint multimodal features required for discriminative tasks such as sentiment\nprediction. Modality-specific generative factors are unique for each modality\nand contain the information required for generating data. Experimental results\nshow that our model is able to learn meaningful multimodal representations that\nachieve state-of-the-art or competitive performance on six multimodal datasets.\nOur model demonstrates flexible generative capabilities by conditioning on\nindependent factors and can reconstruct missing modalities without\nsignificantly impacting performance. Lastly, we interpret our factorized\nrepresentations to understand the interactions that influence multimodal\nlearning.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jun 2018 03:48:50 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 00:17:03 GMT"}, {"version": "v3", "created": "Tue, 14 May 2019 14:16:40 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Tsai", "Yao-Hung Hubert", ""], ["Liang", "Paul Pu", ""], ["Zadeh", "Amir", ""], ["Morency", "Louis-Philippe", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1806.06187", "submitter": "Wenhan Xiong", "authors": "Wenhan Xiong, Xiaoxiao Guo, Mo Yu, Shiyu Chang, Bowen Zhou, William\n  Yang Wang", "title": "Scheduled Policy Optimization for Natural Language Communication with\n  Intelligent Agents", "comments": "IJCAI-ECAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the task of learning to follow natural language instructions\nby jointly reasoning with visual observations and language inputs. In contrast\nto existing methods which start with learning from demonstrations (LfD) and\nthen use reinforcement learning (RL) to fine-tune the model parameters, we\npropose a novel policy optimization algorithm which dynamically schedules\ndemonstration learning and RL. The proposed training paradigm provides\nefficient exploration and better generalization beyond existing methods.\nComparing to existing ensemble models, the best single model based on our\nproposed method tremendously decreases the execution error by over 50% on a\nblock-world environment. To further illustrate the exploration strategy of our\nRL algorithm, We also include systematic studies on the evolution of policy\nentropy during training.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jun 2018 05:17:32 GMT"}, {"version": "v2", "created": "Sat, 7 Jul 2018 06:45:42 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Xiong", "Wenhan", ""], ["Guo", "Xiaoxiao", ""], ["Yu", "Mo", ""], ["Chang", "Shiyu", ""], ["Zhou", "Bowen", ""], ["Wang", "William Yang", ""]]}, {"id": "1806.06200", "submitter": "Lei Xie", "authors": "Pengcheng Guo, Haihua Xu, Lei Xie, Eng Siong Chng", "title": "Study of Semi-supervised Approaches to Improving English-Mandarin\n  Code-Switching Speech Recognition", "comments": "5pages, 3 figures, INTERSPEECH 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present our overall efforts to improve the performance of a\ncode-switching speech recognition system using semi-supervised training methods\nfrom lexicon learning to acoustic modeling, on the South East Asian\nMandarin-English (SEAME) data. We first investigate semi-supervised lexicon\nlearning approach to adapt the canonical lexicon, which is meant to alleviate\nthe heavily accented pronunciation issue within the code-switching conversation\nof the local area. As a result, the learned lexicon yields improved\nperformance. Furthermore, we attempt to use semi-supervised training to deal\nwith those transcriptions that are highly mismatched between human transcribers\nand ASR system. Specifically, we conduct semi-supervised training assuming\nthose poorly transcribed data as unsupervised data. We found the\nsemi-supervised acoustic modeling can lead to improved results. Finally, to\nmake up for the limitation of the conventional n-gram language models due to\ndata sparsity issue, we perform lattice rescoring using neural network language\nmodels, and significant WER reduction is obtained.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jun 2018 07:18:22 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Guo", "Pengcheng", ""], ["Xu", "Haihua", ""], ["Xie", "Lei", ""], ["Chng", "Eng Siong", ""]]}, {"id": "1806.06208", "submitter": "Sauradip Nag", "authors": "Sauradip Nag, Pallab Kumar Ganguly, Sumit Roy, Sourab Jha, Krishna\n  Bose, Abhishek Jha, Kousik Dasgupta", "title": "Offline Extraction of Indic Regional Language from Natural Scene Image\n  using Text Segmentation and Deep Convolutional Sequence", "comments": "Accepted in Second International Conference on Computational\n  Intelligence, Communications, and Business Analytics (CICBA-2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regional language extraction from a natural scene image is always a\nchallenging proposition due to its dependence on the text information extracted\nfrom Image. Text Extraction on the other hand varies on different lighting\ncondition, arbitrary orientation, inadequate text information, heavy background\ninfluence over text and change of text appearance. This paper presents a novel\nunified method for tackling the above challenges. The proposed work uses an\nimage correction and segmentation technique on the existing Text Detection\nPipeline an Efficient and Accurate Scene Text Detector (EAST). EAST uses\nstandard PVAnet architecture to select features and non maximal suppression to\ndetect text from image. Text recognition is done using combined architecture of\nMaxOut convolution neural network (CNN) and Bidirectional long short term\nmemory (LSTM) network. After recognizing text using the Deep Learning based\napproach, the native Languages are translated to English and tokenized using\nstandard Text Tokenizers. The tokens that very likely represent a location is\nused to find the Global Positioning System (GPS) coordinates of the location\nand subsequently the regional languages spoken in that location is extracted.\nThe proposed method is tested on a self generated dataset collected from\nGovernment of India dataset and experimented on Standard Dataset to evaluate\nthe performance of the proposed technique. Comparative study with a few\nstate-of-the-art methods on text detection, recognition and extraction of\nregional language from images shows that the proposed method outperforms the\nexisting methods.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jun 2018 08:31:06 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2018 20:10:03 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Nag", "Sauradip", ""], ["Ganguly", "Pallab Kumar", ""], ["Roy", "Sumit", ""], ["Jha", "Sourab", ""], ["Bose", "Krishna", ""], ["Jha", "Abhishek", ""], ["Dasgupta", "Kousik", ""]]}, {"id": "1806.06219", "submitter": "Nikolaos Pappas", "authors": "Nikolaos Pappas and James Henderson", "title": "GILE: A Generalized Input-Label Embedding for Text Classification", "comments": "To appear in TACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural text classification models typically treat output labels as\ncategorical variables which lack description and semantics. This forces their\nparametrization to be dependent on the label set size, and, hence, they are\nunable to scale to large label sets and generalize to unseen ones. Existing\njoint input-label text models overcome these issues by exploiting label\ndescriptions, but they are unable to capture complex label relationships, have\nrigid parametrization, and their gains on unseen labels happen often at the\nexpense of weak performance on the labels seen during training. In this paper,\nwe propose a new input-label model which generalizes over previous such models,\naddresses their limitations and does not compromise performance on seen labels.\nThe model consists of a joint non-linear input-label embedding with\ncontrollable capacity and a joint-space-dependent classification unit which is\ntrained with cross-entropy loss to optimize classification performance. We\nevaluate models on full-resource and low- or zero-resource text classification\nof multilingual news and biomedical text with a large label set. Our model\noutperforms monolingual and multilingual models which do not leverage label\nsemantics and previous joint input-label space models in both scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jun 2018 10:47:41 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 14:24:02 GMT"}, {"version": "v3", "created": "Wed, 30 Jan 2019 18:33:05 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Pappas", "Nikolaos", ""], ["Henderson", "James", ""]]}, {"id": "1806.06228", "submitter": "Soujanya Poria", "authors": "N. Majumder, D. Hazarika, A. Gelbukh, E. Cambria, S. Poria", "title": "Multimodal Sentiment Analysis using Hierarchical Fusion with Context\n  Modeling", "comments": "Accepted for publication at Knowledge Based Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Multimodal sentiment analysis is a very actively growing field of research. A\npromising area of opportunity in this field is to improve the multimodal fusion\nmechanism. We present a novel feature fusion strategy that proceeds in a\nhierarchical fashion, first fusing the modalities two in two and only then\nfusing all three modalities. On multimodal sentiment analysis of individual\nutterances, our strategy outperforms conventional concatenation of features by\n1%, which amounts to 5% reduction in error rate. On utterance-level multimodal\nsentiment analysis of multi-utterance video clips, for which current\nstate-of-the-art techniques incorporate contextual information from other\nutterances of the same clip, our hierarchical fusion gives up to 2.4% (almost\n10% error rate reduction) over currently used concatenation. The implementation\nof our method is publicly available in the form of open-source code.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jun 2018 12:05:24 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Majumder", "N.", ""], ["Hazarika", "D.", ""], ["Gelbukh", "A.", ""], ["Cambria", "E.", ""], ["Poria", "S.", ""]]}, {"id": "1806.06259", "submitter": "Christian Samuel Perone", "authors": "Christian S. Perone, Roberto Silveira, Thomas S. Paula", "title": "Evaluation of sentence embeddings in downstream and linguistic probing\n  tasks", "comments": "15 pages, 3 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the fast developmental pace of new sentence embedding methods, it is\nstill challenging to find comprehensive evaluations of these different\ntechniques. In the past years, we saw significant improvements in the field of\nsentence embeddings and especially towards the development of universal\nsentence encoders that could provide inductive transfer to a wide variety of\ndownstream tasks. In this work, we perform a comprehensive evaluation of recent\nmethods using a wide variety of downstream and linguistic feature probing\ntasks. We show that a simple approach using bag-of-words with a recently\nintroduced language model for deep context-dependent word embeddings proved to\nyield better results in many tasks when compared to sentence encoders trained\non entailment datasets. We also show, however, that we are still far away from\na universal encoder that can perform consistently across several downstream\ntasks.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jun 2018 16:07:49 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Perone", "Christian S.", ""], ["Silveira", "Roberto", ""], ["Paula", "Thomas S.", ""]]}, {"id": "1806.06301", "submitter": "Thomas Lansdall-Welfare", "authors": "Adam Sutton, Thomas Lansdall-Welfare, Nello Cristianini", "title": "Biased Embeddings from Wild Data: Measuring, Understanding and Removing", "comments": "Author's original version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern Artificial Intelligence (AI) systems make use of data embeddings,\nparticularly in the domain of Natural Language Processing (NLP). These\nembeddings are learnt from data that has been gathered \"from the wild\" and have\nbeen found to contain unwanted biases. In this paper we make three\ncontributions towards measuring, understanding and removing this problem. We\npresent a rigorous way to measure some of these biases, based on the use of\nword lists created for social psychology applications; we observe how gender\nbias in occupations reflects actual gender bias in the same occupations in the\nreal world; and finally we demonstrate how a simple projection can\nsignificantly reduce the effects of embedding bias. All this is part of an\nongoing effort to understand how trust can be built into AI systems.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jun 2018 21:46:59 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Sutton", "Adam", ""], ["Lansdall-Welfare", "Thomas", ""], ["Cristianini", "Nello", ""]]}, {"id": "1806.06342", "submitter": "Linhao Dong", "authors": "Linhao Dong, Shiyu Zhou, Wei Chen, Bo Xu", "title": "Extending Recurrent Neural Aligner for Streaming End-to-End Speech\n  Recognition in Mandarin", "comments": "To appear in Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end models have been showing superiority in Automatic Speech\nRecognition (ASR). At the same time, the capacity of streaming recognition has\nbecome a growing requirement for end-to-end models. Following these trends, an\nencoder-decoder recurrent neural network called Recurrent Neural Aligner (RNA)\nhas been freshly proposed and shown its competitiveness on two English ASR\ntasks. However, it is not clear if RNA can be further improved and applied to\nother spoken language. In this work, we explore the applicability of RNA in\nMandarin Chinese and present four effective extensions: In the encoder, we\nredesign the temporal down-sampling and introduce a powerful convolutional\nstructure. In the decoder, we utilize a regularizer to smooth the output\ndistribution and conduct joint training with a language model. On two Mandarin\nChinese conversational telephone speech recognition (MTS) datasets, our\nExtended-RNA obtains promising performance. Particularly, it achieves 27.7%\ncharacter error rate (CER), which is superior to current state-of-the-art\nresult on the popular HKUST task.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jun 2018 06:57:30 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 02:51:49 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Dong", "Linhao", ""], ["Zhou", "Shiyu", ""], ["Chen", "Wei", ""], ["Xu", "Bo", ""]]}, {"id": "1806.06349", "submitter": "Hao Zhu", "authors": "Huiming Jin, Hao Zhu, Zhiyuan Liu, Ruobing Xie, Maosong Sun, Fen Lin,\n  Leyu Lin", "title": "Incorporating Chinese Characters of Words for Lexical Sememe Prediction", "comments": "Accepted as an ACL 2018 long paper. The first two authors contribute\n  equally. Code is available at\n  https://github.com/thunlp/Character-enhanced-Sememe-Prediction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sememes are minimum semantic units of concepts in human languages, such that\neach word sense is composed of one or multiple sememes. Words are usually\nmanually annotated with their sememes by linguists, and form linguistic\ncommon-sense knowledge bases widely used in various NLP tasks. Recently, the\nlexical sememe prediction task has been introduced. It consists of\nautomatically recommending sememes for words, which is expected to improve\nannotation efficiency and consistency. However, existing methods of lexical\nsememe prediction typically rely on the external context of words to represent\nthe meaning, which usually fails to deal with low-frequency and\nout-of-vocabulary words. To address this issue for Chinese, we propose a novel\nframework to take advantage of both internal character information and external\ncontext information of words. We experiment on HowNet, a Chinese sememe\nknowledge base, and demonstrate that our framework outperforms state-of-the-art\nbaselines by a large margin, and maintains a robust performance even for\nlow-frequency words.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jun 2018 08:44:55 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Jin", "Huiming", ""], ["Zhu", "Hao", ""], ["Liu", "Zhiyuan", ""], ["Xie", "Ruobing", ""], ["Sun", "Maosong", ""], ["Lin", "Fen", ""], ["Lin", "Leyu", ""]]}, {"id": "1806.06371", "submitter": "Lisa Beinborn", "authors": "Lisa Beinborn, Teresa Botschen and Iryna Gurevych", "title": "Multimodal Grounding for Language Processing", "comments": "The paper has been published in the Proceedings of the 27 Conference\n  of Computational Linguistics. Please refer to this version for citations:\n  https://www.aclweb.org/anthology/papers/C/C18/C18-1197/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This survey discusses how recent developments in multimodal processing\nfacilitate conceptual grounding of language. We categorize the information flow\nin multimodal processing with respect to cognitive models of human information\nprocessing and analyze different methods for combining multimodal\nrepresentations. Based on this methodological inventory, we discuss the benefit\nof multimodal grounding for a variety of language processing tasks and the\nchallenges that arise. We particularly focus on multimodal grounding of verbs\nwhich play a crucial role for the compositional power of language.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jun 2018 12:13:37 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 09:28:26 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Beinborn", "Lisa", ""], ["Botschen", "Teresa", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1806.06407", "submitter": "Sarit Chakraborty", "authors": "Bijoyan Das, Sarit Chakraborty", "title": "An Improved Text Sentiment Classification Model Using TF-IDF and Next\n  Word Negation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of Text sentiment analysis, the demand for automatic\nclassification of electronic documents has increased by leaps and bound. The\nparadigm of text classification or text mining has been the subject of many\nresearch works in recent time. In this paper we propose a technique for text\nsentiment classification using term frequency- inverse document frequency\n(TF-IDF) along with Next Word Negation (NWN). We have also compared the\nperformances of binary bag of words model, TF-IDF model and TF-IDF with next\nword negation (TF-IDF-NWN) model for text classification. Our proposed model is\nthen applied on three different text mining algorithms and we found the Linear\nSupport vector machine (LSVM) is the most appropriate to work with our proposed\nmodel. The achieved results show significant increase in accuracy compared to\nearlier methods.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jun 2018 16:25:57 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Das", "Bijoyan", ""], ["Chakraborty", "Sarit", ""]]}, {"id": "1806.06411", "submitter": "Svitlana Vakulenko", "authors": "Svitlana Vakulenko, Maarten de Rijke, Michael Cochez, Vadim Savenkov,\n  Axel Polleres", "title": "Measuring Semantic Coherence of a Conversation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational systems have become increasingly popular as a way for humans\nto interact with computers. To be able to provide intelligent responses,\nconversational systems must correctly model the structure and semantics of a\nconversation. We introduce the task of measuring semantic (in)coherence in a\nconversation with respect to background knowledge, which relies on the\nidentification of semantic relations between concepts introduced during a\nconversation. We propose and evaluate graph-based and machine learning-based\napproaches for measuring semantic coherence using knowledge graphs, their\nvector space embeddings and word embedding models, as sources of background\nknowledge. We demonstrate how these approaches are able to uncover different\ncoherence patterns in conversations on the Ubuntu Dialogue Corpus.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jun 2018 16:38:48 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Vakulenko", "Svitlana", ""], ["de Rijke", "Maarten", ""], ["Cochez", "Michael", ""], ["Savenkov", "Vadim", ""], ["Polleres", "Axel", ""]]}, {"id": "1806.06478", "submitter": "Muhao Chen", "authors": "Muhao Chen, Yingtao Tian, Kai-Wei Chang, Steven Skiena, Carlo Zaniolo", "title": "Co-training Embeddings of Knowledge Graphs and Entity Descriptions for\n  Cross-lingual Entity Alignment", "comments": "To appear in IJCAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual knowledge graph (KG) embeddings provide latent semantic\nrepresentations of entities and structured knowledge with cross-lingual\ninferences, which benefit various knowledge-driven cross-lingual NLP tasks.\nHowever, precisely learning such cross-lingual inferences is usually hindered\nby the low coverage of entity alignment in many KGs. Since many multilingual\nKGs also provide literal descriptions of entities, in this paper, we introduce\nan embedding-based approach which leverages a weakly aligned multilingual KG\nfor semi-supervised cross-lingual learning using entity descriptions. Our\napproach performs co-training of two embedding models, i.e. a multilingual KG\nembedding model and a multilingual literal description embedding model. The\nmodels are trained on a large Wikipedia-based trilingual dataset where most\nentity alignment is unknown to training. Experimental results show that the\nperformance of the proposed approach on the entity alignment task improves at\neach iteration of co-training, and eventually reaches a stage at which it\nsignificantly surpasses previous approaches. We also show that our approach has\npromising abilities for zero-shot entity alignment, and cross-lingual KG\ncompletion.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 02:06:46 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Chen", "Muhao", ""], ["Tian", "Yingtao", ""], ["Chang", "Kai-Wei", ""], ["Skiena", "Steven", ""], ["Zaniolo", "Carlo", ""]]}, {"id": "1806.06513", "submitter": "Chao Zhang", "authors": "Chao Zhang, Philip Woodland", "title": "Semi-tied Units for Efficient Gating in LSTM and Highway Networks", "comments": "To appear in Proc. INTERSPEECH 2018, September 2-6, 2018, Hyderabad,\n  India", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gating is a key technique used for integrating information from multiple\nsources by long short-term memory (LSTM) models and has recently also been\napplied to other models such as the highway network. Although gating is\npowerful, it is rather expensive in terms of both computation and storage as\neach gating unit uses a separate full weight matrix. This issue can be severe\nsince several gates can be used together in e.g. an LSTM cell. This paper\nproposes a semi-tied unit (STU) approach to solve this efficiency issue, which\nuses one shared weight matrix to replace those in all the units in the same\nlayer. The approach is termed \"semi-tied\" since extra parameters are used to\nseparately scale each of the shared output values. These extra scaling factors\nare associated with the network activation functions and result in the use of\nparameterised sigmoid, hyperbolic tangent, and rectified linear unit functions.\nSpeech recognition experiments using British English multi-genre broadcast data\nshowed that using STUs can reduce the calculation and storage cost by a factor\nof three for highway networks and four for LSTMs, while giving similar word\nerror rates to the original models.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 06:49:00 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Zhang", "Chao", ""], ["Woodland", "Philip", ""]]}, {"id": "1806.06571", "submitter": "Tom Kocmi", "authors": "Tom Kocmi and Ond\\v{r}ej Bojar", "title": "SubGram: Extending Skip-gram Word Representation with Substrings", "comments": "Published at TSD 2016", "journal-ref": "Text, Speech, and Dialogue: 19th International Conference, TSD\n  2016", "doi": "10.1007/978-3-319-45510-5_21", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skip-gram (word2vec) is a recent method for creating vector representations\nof words (\"distributed word representations\") using a neural network. The\nrepresentation gained popularity in various areas of natural language\nprocessing, because it seems to capture syntactic and semantic information\nabout words without any explicit supervision in this respect. We propose\nSubGram, a refinement of the Skip-gram model to consider also the word\nstructure during the training process, achieving large gains on the Skip-gram\noriginal test set.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 09:31:38 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Kocmi", "Tom", ""], ["Bojar", "Ond\u0159ej", ""]]}, {"id": "1806.06583", "submitter": "Yin Zheng", "authors": "Xuefei Ning, Yin Zheng, Zhuxi Jiang, Yu Wang, Huazhong Yang, Junzhou\n  Huang", "title": "Nonparametric Topic Modeling with Neural Inference", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work focuses on combining nonparametric topic models with Auto-Encoding\nVariational Bayes (AEVB). Specifically, we first propose iTM-VAE, where the\ntopics are treated as trainable parameters and the document-specific topic\nproportions are obtained by a stick-breaking construction. The inference of\niTM-VAE is modeled by neural networks such that it can be computed in a simple\nfeed-forward manner. We also describe how to introduce a hyper-prior into\niTM-VAE so as to model the uncertainty of the prior parameter. Actually, the\nhyper-prior technique is quite general and we show that it can be applied to\nother AEVB based models to alleviate the {\\it collapse-to-prior} problem\nelegantly. Moreover, we also propose HiTM-VAE, where the document-specific\ntopic distributions are generated in a hierarchical manner. HiTM-VAE is even\nmore flexible and can generate topic distributions with better variability.\nExperimental results on 20News and Reuters RCV1-V2 datasets show that the\nproposed models outperform the state-of-the-art baselines significantly. The\nadvantages of the hyper-prior technique and the hierarchical model construction\nare also confirmed by experiments.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 10:22:18 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Ning", "Xuefei", ""], ["Zheng", "Yin", ""], ["Jiang", "Zhuxi", ""], ["Wang", "Yu", ""], ["Yang", "Huazhong", ""], ["Huang", "Junzhou", ""]]}, {"id": "1806.06626", "submitter": "Rahul Gupta", "authors": "Saurabh Sahu, Rahul Gupta, Carol Espy-Wilson", "title": "On Enhancing Speech Emotion Recognition using Generative Adversarial\n  Networks", "comments": "5 pages, Accepted to Interspeech, Hyderabad-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have gained a lot of attention from\nmachine learning community due to their ability to learn and mimic an input\ndata distribution. GANs consist of a discriminator and a generator working in\ntandem playing a min-max game to learn a target underlying data distribution;\nwhen fed with data-points sampled from a simpler distribution (like uniform or\nGaussian distribution). Once trained, they allow synthetic generation of\nexamples sampled from the target distribution. We investigate the application\nof GANs to generate synthetic feature vectors used for speech emotion\nrecognition. Specifically, we investigate two set ups: (i) a vanilla GAN that\nlearns the distribution of a lower dimensional representation of the actual\nhigher dimensional feature vector and, (ii) a conditional GAN that learns the\ndistribution of the higher dimensional feature vectors conditioned on the\nlabels or the emotional class to which it belongs. As a potential practical\napplication of these synthetically generated samples, we measure any\nimprovement in a classifier's performance when the synthetic data is used along\nwith real data for training. We perform cross-validation analyses followed by a\ncross-corpus study.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 12:21:18 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Sahu", "Saurabh", ""], ["Gupta", "Rahul", ""], ["Espy-Wilson", "Carol", ""]]}, {"id": "1806.06734", "submitter": "Laurent Besacier", "authors": "Pierre Godard, Marcely Zanon-Boito, Lucas Ondel, Alexandre Berard,\n  Fran\\c{c}ois Yvon, Aline Villavicencio, and Laurent Besacier", "title": "Unsupervised Word Segmentation from Speech with Attention", "comments": "Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a first attempt to perform attentional word segmentation directly\nfrom the speech signal, with the final goal to automatically identify lexical\nunits in a low-resource, unwritten language (UL). Our methodology assumes a\npairing between recordings in the UL with translations in a well-resourced\nlanguage. It uses Acoustic Unit Discovery (AUD) to convert speech into a\nsequence of pseudo-phones that is segmented using neural soft-alignments\nproduced by a neural machine translation model. Evaluation uses an actual Bantu\nUL, Mboshi; comparisons to monolingual and bilingual baselines illustrate the\npotential of attentional word segmentation for language documentation.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 14:35:14 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Godard", "Pierre", ""], ["Zanon-Boito", "Marcely", ""], ["Ondel", "Lucas", ""], ["Berard", "Alexandre", ""], ["Yvon", "Fran\u00e7ois", ""], ["Villavicencio", "Aline", ""], ["Besacier", "Laurent", ""]]}, {"id": "1806.06874", "submitter": "Ruixi Lin", "authors": "Ruixi Lin", "title": "Combining Word Feature Vector Method with the Convolutional Neural\n  Network for Slot Filling in Spoken Language Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Slot filling is an important problem in Spoken Language Understanding (SLU)\nand Natural Language Processing (NLP), which involves identifying a user's\nintent and assigning a semantic concept to each word in a sentence. This paper\npresents a word feature vector method and combines it into the convolutional\nneural network (CNN). We consider 18 word features and each word feature is\nconstructed by merging similar word labels. By introducing the concept of\nexternal library, we propose a feature set approach that is beneficial for\nbuilding the relationship between a word from the training dataset and the\nfeature. Computational results are reported using the ATIS dataset and\ncomparisons with traditional CNN as well as bi-directional sequential CNN are\nalso presented.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 18:13:21 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Lin", "Ruixi", ""]]}, {"id": "1806.06950", "submitter": "Patrick Chen", "authors": "Patrick H. Chen, Si Si, Yang Li, Ciprian Chelba, Cho-jui Hsieh", "title": "GroupReduce: Block-Wise Low-Rank Approximation for Neural Language Model\n  Shrinking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model compression is essential for serving large deep neural nets on devices\nwith limited resources or applications that require real-time responses. As a\ncase study, a state-of-the-art neural language model usually consists of one or\nmore recurrent layers sandwiched between an embedding layer used for\nrepresenting input tokens and a softmax layer for generating output tokens. For\nproblems with a very large vocabulary size, the embedding and the softmax\nmatrices can account for more than half of the model size. For instance, the\nbigLSTM model achieves state-of- the-art performance on the One-Billion-Word\n(OBW) dataset with around 800k vocabulary, and its word embedding and softmax\nmatrices use more than 6GBytes space, and are responsible for over 90% of the\nmodel parameters. In this paper, we propose GroupReduce, a novel compression\nmethod for neural language models, based on vocabulary-partition (block) based\nlow-rank matrix approximation and the inherent frequency distribution of tokens\n(the power-law distribution of words). The experimental results show our method\ncan significantly outperform traditional compression methods such as low-rank\napproximation and pruning. On the OBW dataset, our method achieved 6.6 times\ncompression rate for the embedding and softmax matrices, and when combined with\nquantization, our method can achieve 26 times compression rate, which\ntranslates to a factor of 12.8 times compression for the entire model with very\nlittle degradation in perplexity.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 23:08:15 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Chen", "Patrick H.", ""], ["Si", "Si", ""], ["Li", "Yang", ""], ["Chelba", "Ciprian", ""], ["Hsieh", "Cho-jui", ""]]}, {"id": "1806.06957", "submitter": "Surafel Melaku Lakew Mr.", "authors": "Surafel M. Lakew, Mauro Cettolo, Marcello Federico", "title": "A Comparison of Transformer and Recurrent Neural Networks on\n  Multilingual Neural Machine Translation", "comments": "12 pages, to appear on the 27th International Conference on\n  Computational Linguistics (COLING 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, neural machine translation (NMT) has been extended to\nmultilinguality, that is to handle more than one translation direction with a\nsingle system. Multilingual NMT showed competitive performance against pure\nbilingual systems. Notably, in low-resource settings, it proved to work\neffectively and efficiently, thanks to shared representation space that is\nforced across languages and induces a sort of transfer-learning. Furthermore,\nmultilingual NMT enables so-called zero-shot inference across language pairs\nnever seen at training time. Despite the increasing interest in this framework,\nan in-depth analysis of what a multilingual NMT model is capable of and what it\nis not is still missing. Motivated by this, our work (i) provides a\nquantitative and comparative analysis of the translations produced by\nbilingual, multilingual and zero-shot systems; (ii) investigates the\ntranslation quality of two of the currently dominant neural architectures in\nMT, which are the Recurrent and the Transformer ones; and (iii) quantitatively\nexplores how the closeness between languages influences the zero-shot\ntranslation. Our analysis leverages multiple professional post-edits of\nautomatic translations by several different systems and focuses both on\nautomatic standard metrics (BLEU and TER) and on widely used error categories,\nwhich are lexical, morphology, and word order errors.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 21:18:18 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 19:16:46 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Lakew", "Surafel M.", ""], ["Cettolo", "Mauro", ""], ["Federico", "Marcello", ""]]}, {"id": "1806.06972", "submitter": "Soumya Wadhwa", "authors": "Soumya Wadhwa and Khyathi Raghavi Chandu and Eric Nyberg", "title": "Comparative Analysis of Neural QA models on SQuAD", "comments": "Accepted at Workshop on Machine Reading for Question Answering\n  (MRQA), ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of Question Answering has gained prominence in the past few decades\nfor testing the ability of machines to understand natural language. Large\ndatasets for Machine Reading have led to the development of neural models that\ncater to deeper language understanding compared to information retrieval tasks.\nDifferent components in these neural architectures are intended to tackle\ndifferent challenges. As a first step towards achieving generalization across\nmultiple domains, we attempt to understand and compare the peculiarities of\nexisting end-to-end neural models on the Stanford Question Answering Dataset\n(SQuAD) by performing quantitative as well as qualitative analysis of the\nresults attained by each of them. We observed that prediction errors reflect\ncertain model-specific biases, which we further discuss in this paper.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 22:29:51 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Wadhwa", "Soumya", ""], ["Chandu", "Khyathi Raghavi", ""], ["Nyberg", "Eric", ""]]}, {"id": "1806.06998", "submitter": "Leif Hanlen", "authors": "Leif W. Hanlen and Richard Nock and Hanna Suominen and Neil Bacon", "title": "Private Text Classification", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Confidential text corpora exist in many forms, but do not allow arbitrary\nsharing. We explore how to use such private corpora using privacy preserving\ntext analytics. We construct typical text processing applications using\nappropriate privacy preservation techniques (including homomorphic encryption,\nRademacher operators and secure computation). We set out the preliminary\nmaterials from Rademacher operators for binary classifiers, and then construct\nbasic text processing approaches to match those binary classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 01:24:32 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Hanlen", "Leif W.", ""], ["Nock", "Richard", ""], ["Suominen", "Hanna", ""], ["Bacon", "Neil", ""]]}, {"id": "1806.07000", "submitter": "Jingyuan Li", "authors": "Jingyuan Li, Xiao Sun", "title": "A Syntactically Constrained Bidirectional-Asynchronous Approach for\n  Emotional Conversation Generation", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional neural language models tend to generate generic replies with poor\nlogic and no emotion. In this paper, a syntactically constrained\nbidirectional-asynchronous approach for emotional conversation generation\n(E-SCBA) is proposed to address this issue. In our model, pre-generated emotion\nkeywords and topic keywords are asynchronously introduced into the process of\ndecoding. It is much different from most existing methods which generate\nreplies from the first word to the last. Through experiments, the results\nindicate that our approach not only improves the diversity of replies, but\ngains a boost on both logic and emotion compared with baselines.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 01:28:58 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 14:05:09 GMT"}, {"version": "v3", "created": "Thu, 21 Jun 2018 13:44:17 GMT"}, {"version": "v4", "created": "Mon, 27 Aug 2018 07:17:25 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Li", "Jingyuan", ""], ["Sun", "Xiao", ""]]}, {"id": "1806.07039", "submitter": "Linkai Luo", "authors": "Linkai Luo, Haiqing Yang and Francis Y. L. Chin", "title": "EmotionX-DLC: Self-Attentive BiLSTM for Detecting Sequential Emotions in\n  Dialogue", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a self-attentive bidirectional long short-term\nmemory (SA-BiLSTM) network to predict multiple emotions for the EmotionX\nchallenge. The BiLSTM exhibits the power of modeling the word dependencies, and\nextracting the most relevant features for emotion classification. Building on\ntop of BiLSTM, the self-attentive network can model the contextual dependencies\nbetween utterances which are helpful for classifying the ambiguous emotions. We\nachieve 59.6 and 55.0 unweighted accuracy scores in the \\textit{Friends} and\nthe \\textit{EmotionPush} test sets, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 05:03:23 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 07:07:53 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Luo", "Linkai", ""], ["Yang", "Haiqing", ""], ["Chin", "Francis Y. L.", ""]]}, {"id": "1806.07042", "submitter": "Yu Wu", "authors": "Yu Wu, Furu Wei, Shaohan Huang, Yunli Wang, Zhoujun Li, Ming Zhou", "title": "Response Generation by Context-aware Prototype Editing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open domain response generation has achieved remarkable progress in recent\nyears, but sometimes yields short and uninformative responses. We propose a new\nparadigm for response generation, that is response generation by editing, which\nsignificantly increases the diversity and informativeness of the generation\nresults. Our assumption is that a plausible response can be generated by\nslightly revising an existing response prototype. The prototype is retrieved\nfrom a pre-defined index and provides a good start-point for generation because\nit is grammatical and informative. We design a response editing model, where an\nedit vector is formed by considering differences between a prototype context\nand a current context, and then the edit vector is fed to a decoder to revise\nthe prototype response for the current context. Experiment results on a large\nscale dataset demonstrate that the response editing model outperforms\ngenerative and retrieval-based models on various aspects.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 05:13:34 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 07:02:03 GMT"}, {"version": "v3", "created": "Fri, 27 Jul 2018 08:01:12 GMT"}, {"version": "v4", "created": "Fri, 16 Nov 2018 08:48:50 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Wu", "Yu", ""], ["Wei", "Furu", ""], ["Huang", "Shaohan", ""], ["Wang", "Yunli", ""], ["Li", "Zhoujun", ""], ["Zhou", "Ming", ""]]}, {"id": "1806.07072", "submitter": "Sauradip Nag", "authors": "Sauradip Nag, Palaiahnakote Shivakumara, Wu Yirui, Umapada Pal, and\n  Tong Lu", "title": "A New COLD Feature based Handwriting Analysis for Ethnicity/Nationality\n  Identification", "comments": "Accepted in ICFHR18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying crime for forensic investigating teams when crimes involve people\nof different nationals is challenging. This paper proposes a new method for\nethnicity (nationality) identification based on Cloud of Line Distribution\n(COLD) features of handwriting components. The proposed method, at first,\nexplores tangent angle for the contour pixels in each row and the mean of\nintensity values of each row in an image for segmenting text lines. For\nsegmented text lines, we use tangent angle and direction of base lines to\nremove rule lines in the image. We use polygonal approximation for finding\ndominant points for contours of edge components. Then the proposed method\nconnects the nearest dominant points of every dominant point, which results in\nline segments of dominant point pairs. For each line segment, the proposed\nmethod estimates angle and length, which gives a point in polar domain. For all\nthe line segments, the proposed method generates dense points in polar domain,\nwhich results in COLD distribution. As character component shapes change,\naccording to nationals, the shape of the distribution changes. This observation\nis extracted based on distance from pixels of distribution to Principal Axis of\nthe distribution. Then the features are subjected to an SVM classifier for\nidentifying nationals. Experiments are conducted on a complex dataset, which\nshow the proposed method is effective and outperforms the existing method\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 07:14:54 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Nag", "Sauradip", ""], ["Shivakumara", "Palaiahnakote", ""], ["Yirui", "Wu", ""], ["Pal", "Umapada", ""], ["Lu", "Tong", ""]]}, {"id": "1806.07098", "submitter": "Neil Zeghidour", "authors": "Neil Zeghidour, Nicolas Usunier, Gabriel Synnaeve, Ronan Collobert,\n  Emmanuel Dupoux", "title": "End-to-End Speech Recognition From the Raw Waveform", "comments": "Accepted for presentation at Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art speech recognition systems rely on fixed, hand-crafted\nfeatures such as mel-filterbanks to preprocess the waveform before the training\npipeline. In this paper, we study end-to-end systems trained directly from the\nraw waveform, building on two alternatives for trainable replacements of\nmel-filterbanks that use a convolutional architecture. The first one is\ninspired by gammatone filterbanks (Hoshen et al., 2015; Sainath et al, 2015),\nand the second one by the scattering transform (Zeghidour et al., 2017). We\npropose two modifications to these architectures and systematically compare\nthem to mel-filterbanks, on the Wall Street Journal dataset. The first\nmodification is the addition of an instance normalization layer, which greatly\nimproves on the gammatone-based trainable filterbanks and speeds up the\ntraining of the scattering-based filterbanks. The second one relates to the\nlow-pass filter used in these approaches. These modifications consistently\nimprove performances for both approaches, and remove the need for a careful\ninitialization in scattering-based trainable filterbanks. In particular, we\nshow a consistent improvement in word error rate of the trainable filterbanks\nrelatively to comparable mel-filterbanks. It is the first time end-to-end\nmodels trained from the raw signal significantly outperform mel-filterbanks on\na large vocabulary task under clean recording conditions.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 08:32:49 GMT"}, {"version": "v2", "created": "Thu, 21 Jun 2018 11:56:15 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Zeghidour", "Neil", ""], ["Usunier", "Nicolas", ""], ["Synnaeve", "Gabriel", ""], ["Collobert", "Ronan", ""], ["Dupoux", "Emmanuel", ""]]}, {"id": "1806.07139", "submitter": "Henry Moss", "authors": "Henry B.Moss, David S.Leslie and Paul Rayson", "title": "Using J-K fold Cross Validation to Reduce Variance When Tuning NLP\n  Models", "comments": "COLING 2018. Code available at:\n  https://github.com/henrymoss/COLING2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  K-fold cross validation (CV) is a popular method for estimating the true\nperformance of machine learning models, allowing model selection and parameter\ntuning. However, the very process of CV requires random partitioning of the\ndata and so our performance estimates are in fact stochastic, with variability\nthat can be substantial for natural language processing tasks. We demonstrate\nthat these unstable estimates cannot be relied upon for effective parameter\ntuning. The resulting tuned parameters are highly sensitive to how our data is\npartitioned, meaning that we often select sub-optimal parameter choices and\nhave serious reproducibility issues.\n  Instead, we propose to use the less variable J-K-fold CV, in which J\nindependent K-fold cross validations are used to assess performance. Our main\ncontributions are extending J-K-fold CV from performance estimation to\nparameter tuning and investigating how to choose J and K. We argue that\nvariability is more important than bias for effective tuning and so advocate\nlower choices of K than are typically seen in the NLP literature, instead use\nthe saved computation to increase J. To demonstrate the generality of our\nrecommendations we investigate a wide range of case-studies: sentiment\nclassification (both general and target-specific), part-of-speech tagging and\ndocument classification.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 10:12:25 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Moss", "Henry B.", ""], ["Leslie", "David S.", ""], ["Rayson", "Paul", ""]]}, {"id": "1806.07169", "submitter": "Shahram Khadivi", "authors": "Pavel Petrushkov and Shahram Khadivi and Evgeny Matusov", "title": "Learning from Chunk-based Feedback in Neural Machine Translation", "comments": "the paper accepted in ACL 2018 Conference, Melbourne, Australia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We empirically investigate learning from partial feedback in neural machine\ntranslation (NMT), when partial feedback is collected by asking users to\nhighlight a correct chunk of a translation. We propose a simple and effective\nway of utilizing such feedback in NMT training. We demonstrate how the common\nmachine translation problem of domain mismatch between training and deployment\ncan be reduced solely based on chunk-level user feedback. We conduct a series\nof simulation experiments to test the effectiveness of the proposed method. Our\nresults show that chunk-level feedback outperforms sentence based feedback by\nup to 2.61% BLEU absolute.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 11:56:22 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Petrushkov", "Pavel", ""], ["Khadivi", "Shahram", ""], ["Matusov", "Evgeny", ""]]}, {"id": "1806.07186", "submitter": "Josef Mich\\'alek", "authors": "Jan Vanek, Josef Michalek, Josef Psutka", "title": "Recurrent DNNs and its Ensembles on the TIMIT Phone Recognition Task", "comments": "Submitted to SPECOM 2018, 20th International Conference on Speech and\n  Computer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we have investigated recurrent deep neural networks (DNNs) in\ncombination with regularization techniques as dropout, zoneout, and\nregularization post-layer. As a benchmark, we chose the TIMIT phone recognition\ntask due to its popularity and broad availability in the community. It also\nsimulates a low-resource scenario that is helpful in minor languages. Also, we\nprefer the phone recognition task because it is much more sensitive to an\nacoustic model quality than a large vocabulary continuous speech recognition\ntask. In recent years, recurrent DNNs pushed the error rates in automatic\nspeech recognition down. But, there was no clear winner in proposed\narchitectures. The dropout was used as the regularization technique in most\ncases, but combination with other regularization techniques together with model\nensembles was omitted. However, just an ensemble of recurrent DNNs performed\nbest and achieved an average phone error rate from 10 experiments 14.84 %\n(minimum 14.69 %) on core test set that is slightly lower then the\nbest-published PER to date, according to our knowledge. Finally, in contrast of\nthe most papers, we published the open-source scripts to easily replicate the\nresults and to help continue the development.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 12:39:22 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Vanek", "Jan", ""], ["Michalek", "Josef", ""], ["Psutka", "Josef", ""]]}, {"id": "1806.07221", "submitter": "Xuan-Son Vu", "authors": "Xuan-Son Vu, Lili Jiang", "title": "Self-adaptive Privacy Concern Detection for User-generated Content", "comments": null, "journal-ref": "Proceedings of the 19th International Conference on Computational\n  Linguistics and Intelligent Text Processing, 2018", "doi": null, "report-no": null, "categories": "cs.CR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To protect user privacy in data analysis, a state-of-the-art strategy is\ndifferential privacy in which scientific noise is injected into the real\nanalysis output. The noise masks individual's sensitive information contained\nin the dataset. However, determining the amount of noise is a key challenge,\nsince too much noise will destroy data utility while too little noise will\nincrease privacy risk. Though previous research works have designed some\nmechanisms to protect data privacy in different scenarios, most of the existing\nstudies assume uniform privacy concerns for all individuals. Consequently,\nputting an equal amount of noise to all individuals leads to insufficient\nprivacy protection for some users, while over-protecting others. To address\nthis issue, we propose a self-adaptive approach for privacy concern detection\nbased on user personality. Our experimental studies demonstrate the\neffectiveness to address a suitable personalized privacy protection for\ncold-start users (i.e., without their privacy-concern information in training\ndata).\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 13:40:27 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Vu", "Xuan-Son", ""], ["Jiang", "Lili", ""]]}, {"id": "1806.07304", "submitter": "Han Guo", "authors": "Han Guo, Ramakanth Pasunuru, Mohit Bansal", "title": "Dynamic Multi-Level Multi-Task Learning for Sentence Simplification", "comments": "COLING 2018 (15 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentence simplification aims to improve readability and understandability,\nbased on several operations such as splitting, deletion, and paraphrasing.\nHowever, a valid simplified sentence should also be logically entailed by its\ninput sentence. In this work, we first present a strong pointer-copy mechanism\nbased sequence-to-sequence sentence simplification model, and then improve its\nentailment and paraphrasing capabilities via multi-task learning with related\nauxiliary tasks of entailment and paraphrase generation. Moreover, we propose a\nnovel 'multi-level' layered soft sharing approach where each auxiliary task\nshares different (higher versus lower) level layers of the sentence\nsimplification model, depending on the task's semantic versus lexico-syntactic\nnature. We also introduce a novel multi-armed bandit based training approach\nthat dynamically learns how to effectively switch across tasks during\nmulti-task learning. Experiments on multiple popular datasets demonstrate that\nour model outperforms competitive simplification systems in SARI and FKGL\nautomatic metrics, and human evaluation. Further, we present several ablation\nanalyses on alternative layer sharing methods, soft versus hard sharing,\ndynamic multi-armed bandit sampling approaches, and our model's learned\nentailment and paraphrasing skills.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 15:21:37 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Guo", "Han", ""], ["Pasunuru", "Ramakanth", ""], ["Bansal", "Mohit", ""]]}, {"id": "1806.07346", "submitter": "Imon Banerjee", "authors": "Imon Banerjee, Hailey H. Choi, Terry Desser, Daniel L. Rubin", "title": "A Scalable Machine Learning Approach for Inferring Probabilistic\n  US-LI-RADS Categorization", "comments": "AMIA Annual Symposium 2018 (accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a scalable computerized approach for large-scale inference of\nLiver Imaging Reporting and Data System (LI-RADS) final assessment categories\nin narrative ultrasound (US) reports. Although our model was trained on reports\ncreated using a LI-RADS template, it was also able to infer LI-RADS scoring for\nunstructured reports that were created before the LI-RADS guidelines were\nestablished. No human-labelled data was required in any step of this study; for\ntraining, LI-RADS scores were automatically extracted from those reports that\ncontained structured LI-RADS scores, and it translated the derived knowledge to\nreasoning on unstructured radiology reports. By providing automated LI-RADS\ncategorization, our approach may enable standardizing screening recommendations\nand treatment planning of patients at risk for hepatocellular carcinoma, and it\nmay facilitate AI-based healthcare research with US images by offering large\nscale text mining and data gathering opportunities from standard hospital\nclinical data repositories.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2018 20:11:22 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Banerjee", "Imon", ""], ["Choi", "Hailey H.", ""], ["Desser", "Terry", ""], ["Rubin", "Daniel L.", ""]]}, {"id": "1806.07407", "submitter": "Tobias Menne", "authors": "Tobias Menne, Ralf Schl\\\"uter, Hermann Ney", "title": "Speaker Adapted Beamforming for Multi-Channel Automatic Speech\n  Recognition", "comments": "submitted to IEEE SLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents, in the context of multi-channel ASR, a method to adapt a\nmask based, statistically optimal beamforming approach to a speaker of\ninterest. The beamforming vector of the statistically optimal beamformer is\ncomputed by utilizing speech and noise masks, which are estimated by a neural\nnetwork. The proposed adaptation approach is based on the integration of the\nbeamformer, which includes the mask estimation network, and the acoustic model\nof the ASR system. This allows for the propagation of the training error, from\nthe acoustic modeling cost function, all the way through the beamforming\noperation and through the mask estimation network. By using the results of a\nfirst pass recognition and by keeping all other parameters fixed, the mask\nestimation network can therefore be fine tuned by retraining. Utterances of a\nspeaker of interest can thus be used in a two pass approach, to optimize the\nbeamforming for the speech characteristics of that specific speaker. It is\nshown that this approach improves the ASR performance of a state-of-the-art\nmulti-channel ASR system on the CHiME-4 data. Furthermore the effect of the\nadaptation on the estimated speech masks is discussed.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 18:03:33 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Menne", "Tobias", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "1806.07495", "submitter": "Hamed Shahbazi", "authors": "Hamed Shahbazi, Xiaoli Z. Fern, Reza Ghaeini, Chao Ma, Rasha Obeidat,\n  Prasad Tadepalli", "title": "Joint Neural Entity Disambiguation with Output Space Search", "comments": "Accepted as a long paper at COLING 2018, 11 pages", "journal-ref": "Proceedings of COLING 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel model for entity disambiguation that\ncombines both local contextual information and global evidences through Limited\nDiscrepancy Search (LDS). Given an input document, we start from a complete\nsolution constructed by a local model and conduct a search in the space of\npossible corrections to improve the local solution from a global view point.\nOur search utilizes a heuristic function to focus more on the least confident\nlocal decisions and a pruning function to score the global solutions based on\ntheir local fitness and the global coherences among the predicted entities.\nExperimental results on CoNLL 2003 and TAC 2010 benchmarks verify the\neffectiveness of our model.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 23:05:18 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Shahbazi", "Hamed", ""], ["Fern", "Xiaoli Z.", ""], ["Ghaeini", "Reza", ""], ["Ma", "Chao", ""], ["Obeidat", "Rasha", ""], ["Tadepalli", "Prasad", ""]]}, {"id": "1806.07573", "submitter": "Heri Ramampiaro", "authors": "{\\O}ystein Repp and Heri Ramampiaro", "title": "Extracting News Events from Microblogs", "comments": null, "journal-ref": "In Journal of Statistics and Management Systems, 21(4), pp.\n  695-723. Taylor & Francis", "doi": "10.1080/09720510.2018.1486273", "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twitter stream has become a large source of information for many people, but\nthe magnitude of tweets and the noisy nature of its content have made\nharvesting the knowledge from Twitter a challenging task for researchers for a\nlong time. Aiming at overcoming some of the main challenges of extracting the\nhidden information from tweet streams, this work proposes a new approach for\nreal-time detection of news events from the Twitter stream. We divide our\napproach into three steps. The first step is to use a neural network or deep\nlearning to detect news-relevant tweets from the stream. The second step is to\napply a novel streaming data clustering algorithm to the detected news tweets\nto form news events. The third and final step is to rank the detected events\nbased on the size of the event clusters and growth speed of the tweet\nfrequencies. We evaluate the proposed system on a large, publicly available\ncorpus of annotated news events from Twitter. As part of the evaluation, we\ncompare our approach with a related state-of-the-art solution. Overall, our\nexperiments and user-based evaluation show that our approach on detecting\ncurrent (real) news events delivers a state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 06:54:17 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Repp", "\u00d8ystein", ""], ["Ramampiaro", "Heri", ""]]}, {"id": "1806.07687", "submitter": "Andreas Vlachos", "authors": "James Thorne, Andreas Vlachos", "title": "Automated Fact Checking: Task formulations, methods and future\n  directions", "comments": "Published at the 27th International Conference on Computational\n  Linguistics (COLING 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recently increased focus on misinformation has stimulated research in\nfact checking, the task of assessing the truthfulness of a claim. Research in\nautomating this task has been conducted in a variety of disciplines including\nnatural language processing, machine learning, knowledge representation,\ndatabases, and journalism. While there has been substantial progress, relevant\npapers and articles have been published in research communities that are often\nunaware of each other and use inconsistent terminology, thus impeding\nunderstanding and further progress. In this paper we survey automated fact\nchecking research stemming from natural language processing and related\ndisciplines, unifying the task formulations and methodologies across papers and\nauthors. Furthermore, we highlight the use of evidence as an important\ndistinguishing factor among them cutting across task formulations and methods.\nWe conclude with proposing avenues for future NLP research on automated fact\nchecking.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 12:13:53 GMT"}, {"version": "v2", "created": "Wed, 5 Sep 2018 12:47:39 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Thorne", "James", ""], ["Vlachos", "Andreas", ""]]}, {"id": "1806.07699", "submitter": "Vivian Silva", "authors": "Vivian S. Silva, Andr\\'e Freitas, Siegfried Handschuh", "title": "Word Tagging with Foundational Ontology Classes: Extending the\n  WordNet-DOLCE Mapping to Verbs", "comments": "13 pages, 1 figure, presented at EKAW 2016", "journal-ref": "Proceedings of the 20th International Conference on Knowledge\n  Engineering and Knowledge Management, Bologna, Italy, 2016, pp 593-605", "doi": "10.1007/978-3-319-49004-5_38", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic annotation is fundamental to deal with large-scale lexical\ninformation, mapping the information to an enumerable set of categories over\nwhich rules and algorithms can be applied, and foundational ontology classes\ncan be used as a formal set of categories for such tasks. A previous alignment\nbetween WordNet noun synsets and DOLCE provided a starting point for\nontology-based annotation, but in NLP tasks verbs are also of substantial\nimportance. This work presents an extension to the WordNet-DOLCE noun mapping,\naligning verbs according to their links to nouns denoting perdurants,\ntransferring to the verb the DOLCE class assigned to the noun that best\nrepresents that verb's occurrence. To evaluate the usefulness of this resource,\nwe implemented a foundational ontology-based semantic annotation framework,\nthat assigns a high-level foundational category to each word or phrase in a\ntext, and compared it to a similar annotation tool, obtaining an increase of\n9.05% in accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 12:56:54 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Silva", "Vivian S.", ""], ["Freitas", "Andr\u00e9", ""], ["Handschuh", "Siegfried", ""]]}, {"id": "1806.07711", "submitter": "Vivian Silva", "authors": "Vivian S. Silva, Siegfried Handschuh, Andr\\'e Freitas", "title": "Categorization of Semantic Roles for Dictionary Definitions", "comments": "9 pages, 2 figures, presented at CogALex-V 2016", "journal-ref": "Proceedings of the 5th Workshop on Cognitive Aspects of the\n  Lexicon (CogALex-V), Osaka, Japan, 2016, pp 176-184", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the semantic relationships between terms is a fundamental task\nin natural language processing applications. While structured resources that\ncan express those relationships in a formal way, such as ontologies, are still\nscarce, a large number of linguistic resources gathering dictionary definitions\nis becoming available, but understanding the semantic structure of natural\nlanguage definitions is fundamental to make them useful in semantic\ninterpretation tasks. Based on an analysis of a subset of WordNet's glosses, we\npropose a set of semantic roles that compose the semantic structure of a\ndictionary definition, and show how they are related to the definition's\nsyntactic configuration, identifying patterns that can be used in the\ndevelopment of information extraction frameworks and semantic models.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 13:14:12 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Silva", "Vivian S.", ""], ["Handschuh", "Siegfried", ""], ["Freitas", "Andr\u00e9", ""]]}, {"id": "1806.07713", "submitter": "Amin Omidvar", "authors": "Amin Omidvar, Hui Jiang, Aijun An", "title": "Using Neural Network for Identifying Clickbaits in Online News Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online news media sometimes use misleading headlines to lure users to open\nthe news article. These catchy headlines that attract users but disappointed\nthem at the end, are called Clickbaits. Because of the importance of automatic\nclickbait detection in online medias, lots of machine learning methods were\nproposed and employed to find the clickbait headlines. In this research, a\nmodel using deep learning methods is proposed to find the clickbaits in\nClickbait Challenge 2017's dataset. The proposed model gained the first rank in\nthe Clickbait Challenge 2017 in terms of Mean Squared Error. Also, data\nanalytics and visualization techniques are employed to explore and discover the\nprovided dataset to get more insight from the data.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 13:21:53 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Omidvar", "Amin", ""], ["Jiang", "Hui", ""], ["An", "Aijun", ""]]}, {"id": "1806.07721", "submitter": "Vivian Silva", "authors": "Vivian S. Silva, Manuela H\\\"urliman, Brian Davis, Siegfried Handschuh,\n  Andr\\'e Freitas", "title": "Semantic Relation Classification: Task Formalisation and Refinement", "comments": "10 pages, presented at CogALex-V 2016", "journal-ref": "Proceedings of the 5th Workshop on Cognitive Aspects of the\n  Lexicon, Osaka, Japan, 2016, pp 30-39", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The identification of semantic relations between terms within texts is a\nfundamental task in Natural Language Processing which can support applications\nrequiring a lightweight semantic interpretation model. Currently, semantic\nrelation classification concentrates on relations which are evaluated over\nopen-domain data. This work provides a critique on the set of abstract\nrelations used for semantic relation classification with regard to their\nability to express relationships between terms which are found in a\ndomain-specific corpora. Based on this analysis, this work proposes an\nalternative semantic relation model based on reusing and extending the set of\nabstract relations present in the DOLCE ontology. The resulting set of\nrelations is well grounded, allows to capture a wide range of relations and\ncould thus be used as a foundation for automatic classification of semantic\nrelations.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 13:30:51 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Silva", "Vivian S.", ""], ["H\u00fcrliman", "Manuela", ""], ["Davis", "Brian", ""], ["Handschuh", "Siegfried", ""], ["Freitas", "Andr\u00e9", ""]]}, {"id": "1806.07722", "submitter": "Paul Kinsler", "authors": "Paul Kinsler", "title": "Stylized innovation: interrogating incrementally available randomised\n  dictionaries", "comments": "12 pages. Note: some pdf viewers have trouble rendering some of the\n  figures perfectly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by recent work of Fink, Reeves, Palma and Farr (2017) on innovation\nin language, gastronomy, and technology, I study how new symbol discovery\nmanifests itself in terms of additional \"word\" vocabulary being available from\ndictionaries generated from a finite number of symbols. Several distinct\ndictionary generation models are investigated using numerical simulation, with\nemphasis on the scaling of knowledge as dictionary generators and parameters\nare varied, and the role of which order the symbols are discovered in.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2018 09:29:05 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Kinsler", "Paul", ""]]}, {"id": "1806.07731", "submitter": "Vivian Silva", "authors": "Vivian S. Silva, Andr\\'e Freitas, Siegfried Handschuh", "title": "Building a Knowledge Graph from Natural Language Definitions for\n  Interpretable Text Entailment Recognition", "comments": "5 pages, 5 figures, presented at LREC 2018", "journal-ref": "Proceedings of the Eleventh International Conference on Language\n  Resources and Evaluation, Miyazaki, Japan, 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language definitions of terms can serve as a rich source of\nknowledge, but structuring them into a comprehensible semantic model is\nessential to enable them to be used in semantic interpretation tasks. We\npropose a method and provide a set of tools for automatically building a graph\nworld knowledge base from natural language definitions. Adopting a conceptual\nmodel composed of a set of semantic roles for dictionary definitions, we\ntrained a classifier for automatically labeling definitions, preparing the data\nto be later converted to a graph representation. WordNetGraph, a knowledge\ngraph built out of noun and verb WordNet definitions according to this\nmethodology, was successfully used in an interpretable text entailment\nrecognition approach which uses paths in this graph to provide clear\njustifications for entailment decisions.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 13:50:46 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Silva", "Vivian S.", ""], ["Freitas", "Andr\u00e9", ""], ["Handschuh", "Siegfried", ""]]}, {"id": "1806.07787", "submitter": "Valentin Barriere", "authors": "Valentin Barriere and Chlo\\'e Clavel and Slim Essid", "title": "Opinion Dynamics Modeling for Movie Review Transcripts Classification\n  with Hidden Conditional Random Fields", "comments": "Oral Interspeech 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the main goal is to detect a movie reviewer's opinion using\nhidden conditional random fields. This model allows us to capture the dynamics\nof the reviewer's opinion in the transcripts of long unsegmented audio reviews\nthat are analyzed by our system. High level linguistic features are computed at\nthe level of inter-pausal segments. The features include syntactic features, a\nstatistical word embedding model and subjectivity lexicons. The proposed system\nis evaluated on the ICT-MMMO corpus. We obtain a F1-score of 82\\%, which is\nbetter than logistic regression and recurrent neural network approaches. We\nalso offer a discussion that sheds some light on the capacity of our system to\nadapt the word embedding model learned from general written texts data to\nspoken movie reviews and thus model the dynamics of the opinion.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 15:14:10 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Barriere", "Valentin", ""], ["Clavel", "Chlo\u00e9", ""], ["Essid", "Slim", ""]]}, {"id": "1806.07832", "submitter": "Pengcheng Yin", "authors": "Pengcheng Yin, Chunting Zhou, Junxian He, Graham Neubig", "title": "StructVAE: Tree-structured Latent Variable Models for Semi-supervised\n  Semantic Parsing", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic parsing is the task of transducing natural language (NL) utterances\ninto formal meaning representations (MRs), commonly represented as tree\nstructures. Annotating NL utterances with their corresponding MRs is expensive\nand time-consuming, and thus the limited availability of labeled data often\nbecomes the bottleneck of data-driven, supervised models. We introduce\nStructVAE, a variational auto-encoding model for semisupervised semantic\nparsing, which learns both from limited amounts of parallel data, and\nreadily-available unlabeled NL utterances. StructVAE models latent MRs not\nobserved in the unlabeled data as tree-structured latent variables. Experiments\non semantic parsing on the ATIS domain and Python code generation show that\nwith extra unlabeled data, StructVAE outperforms strong supervised models.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 16:29:01 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Yin", "Pengcheng", ""], ["Zhou", "Chunting", ""], ["He", "Junxian", ""], ["Neubig", "Graham", ""]]}, {"id": "1806.07914", "submitter": "Charles Costello", "authors": "Charles Costello, Ruixi Lin, Vishwas Mruthyunjaya, Bettina Bolla,\n  Charles Jankowski", "title": "Multi-Layer Ensembling Techniques for Multilingual Intent Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we determine how multi-layer ensembling improves performance on\nmultilingual intent classification. We develop a novel multi-layer ensembling\napproach that ensembles both different model initializations and different\nmodel architectures. We also introduce a new banking domain dataset and compare\nresults against the standard ATIS dataset and the Chinese SMP2017 dataset to\ndetermine ensembling performance in multilingual and multi-domain contexts. We\nrun ensemble experiments across all three datasets, and conclude that\nensembling provides significant performance increases, and that multi-layer\nensembling is a no-risk way to improve performance on intent classification. We\nalso find that a diverse ensemble of simple models can reach perform comparable\nto much more sophisticated state-of-the-art models. Our best F 1 scores on\nATIS, Banking, and SMP are 97.54%, 91.79%, and 93.55% respectively, which\ncompare well with the state-of-the-art on ATIS and best submission to the\nSMP2017 competition. The total ensembling performance increases we achieve are\n0.23%, 1.96%, and 4.04% F 1 respectively.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 18:17:40 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Costello", "Charles", ""], ["Lin", "Ruixi", ""], ["Mruthyunjaya", "Vishwas", ""], ["Bolla", "Bettina", ""], ["Jankowski", "Charles", ""]]}, {"id": "1806.07916", "submitter": "Sean MacAvaney", "authors": "Sean MacAvaney, Bart Desmet, Arman Cohan, Luca Soldaini, Andrew Yates,\n  Ayah Zirikly, Nazli Goharian", "title": "RSDD-Time: Temporal Annotation of Self-Reported Mental Health Diagnoses", "comments": "6 pages, accepted for publication at the CLPsych workshop at\n  NAACL-HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-reported diagnosis statements have been widely employed in studying\nlanguage related to mental health in social media. However, existing research\nhas largely ignored the temporality of mental health diagnoses. In this work,\nwe introduce RSDD-Time: a new dataset of 598 manually annotated self-reported\ndepression diagnosis posts from Reddit that include temporal information about\nthe diagnosis. Annotations include whether a mental health condition is present\nand how recently the diagnosis happened. Furthermore, we include exact temporal\nspans that relate to the date of diagnosis. This information is valuable for\nvarious computational methods to examine mental health through social media\nbecause one's mental health state is not static. We also test several baseline\nclassification and extraction approaches, which suggest that extracting\ntemporal information from self-reported diagnosis statements is challenging.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 18:18:52 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["MacAvaney", "Sean", ""], ["Desmet", "Bart", ""], ["Cohan", "Arman", ""], ["Soldaini", "Luca", ""], ["Yates", "Andrew", ""], ["Zirikly", "Ayah", ""], ["Goharian", "Nazli", ""]]}, {"id": "1806.07974", "submitter": "Josef Mich\\'alek", "authors": "Josef Michalek, Jan Vanek", "title": "A Survey of Recent DNN Architectures on the TIMIT Phone Recognition Task", "comments": "Submitted to TSD 2018, 21st International Conference on Text, Speech\n  and Dialogue. arXiv admin note: substantial text overlap with\n  arXiv:1806.07186", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this survey paper, we have evaluated several recent deep neural network\n(DNN) architectures on a TIMIT phone recognition task. We chose the TIMIT\ncorpus due to its popularity and broad availability in the community. It also\nsimulates a low-resource scenario that is helpful in minor languages. Also, we\nprefer the phone recognition task because it is much more sensitive to an\nacoustic model quality than a large vocabulary continuous speech recognition\n(LVCSR) task. In recent years, many DNN published papers reported results on\nTIMIT. However, the reported phone error rates (PERs) were often much higher\nthan a PER of a simple feed-forward (FF) DNN. That was the main motivation of\nthis paper: To provide a baseline DNNs with open-source scripts to easily\nreplicate the baseline results for future papers with lowest possible PERs.\nAccording to our knowledge, the best-achieved PER of this survey is better than\nthe best-published PER to date.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 12:43:41 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Michalek", "Josef", ""], ["Vanek", "Jan", ""]]}, {"id": "1806.07976", "submitter": "Lucy Wang", "authors": "Lucy Lu Wang, Chandra Bhagavatula, Mark Neumann, Kyle Lo, Chris\n  Wilhelm, Waleed Ammar", "title": "Ontology Alignment in the Biomedical Domain Using Entity Definitions and\n  Context", "comments": "ACL 2018 BioNLP workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontology alignment is the task of identifying semantically equivalent\nentities from two given ontologies. Different ontologies have different\nrepresentations of the same entity, resulting in a need to de-duplicate\nentities when merging ontologies. We propose a method for enriching entities in\nan ontology with external definition and context information, and use this\nadditional information for ontology alignment. We develop a neural architecture\ncapable of encoding the additional information when available, and show that\nthe addition of external data results in an F1-score of 0.69 on the Ontology\nAlignment Evaluation Initiative (OAEI) largebio SNOMED-NCI subtask, comparable\nwith the entity-level matchers in a SOTA system.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 20:29:24 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Wang", "Lucy Lu", ""], ["Bhagavatula", "Chandra", ""], ["Neumann", "Mark", ""], ["Lo", "Kyle", ""], ["Wilhelm", "Chris", ""], ["Ammar", "Waleed", ""]]}, {"id": "1806.07977", "submitter": "Gabriela Ramirez-De-La-Rosa", "authors": "Gabriela Ram\\'irez-de-la-Rosa, Esa\\'u Villatoro-Tello, H\\'ector\n  Jim\\'enez-Salazar", "title": "TxPI-u: A Resource for Personality Identification of Undergraduates", "comments": null, "journal-ref": "Journal of Intelligent & Fuzzy Systems, vol. 34, no. 5, pp.\n  2991-3001, 2018", "doi": "10.3233/JIFS-169484", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resources such as labeled corpora are necessary to train automatic models\nwithin the natural language processing (NLP) field. Historically, a large\nnumber of resources regarding a broad number of problems are available mostly\nin English. One of such problems is known as Personality Identification where\nbased on a psychological model (e.g. The Big Five Model), the goal is to find\nthe traits of a subject's personality given, for instance, a text written by\nthe same subject. In this paper we introduce a new corpus in Spanish called\nTexts for Personality Identification (TxPI). This corpus will help to develop\nmodels to automatically assign a personality trait to an author of a text\ndocument. Our corpus, TxPI-u, contains information of 416 Mexican undergraduate\nstudents with some demographics information such as, age, gender, and the\nacademic program they are enrolled. Finally, as an additional contribution, we\npresent a set of baselines to provide a comparison scheme for further research.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 20:31:47 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Ram\u00edrez-de-la-Rosa", "Gabriela", ""], ["Villatoro-Tello", "Esa\u00fa", ""], ["Jim\u00e9nez-Salazar", "H\u00e9ctor", ""]]}, {"id": "1806.07978", "submitter": "Tobias Eichinger", "authors": "Tobias Eichinger", "title": "The Corpus Replication Task", "comments": "the references might not render appropriately. contact the author for\n  details", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In the field of Natural Language Processing (NLP), we revisit the well-known\nword embedding algorithm word2vec. Word embeddings identify words by vectors\nsuch that the words' distributional similarity is captured. Unexpectedly,\nbesides semantic similarity even relational similarity has been shown to be\ncaptured in word embeddings generated by word2vec, whence two questions arise.\nFirstly, which kind of relations are representable in continuous space and\nsecondly, how are relations built. In order to tackle these questions we\npropose a bottom-up point of view. We call generating input text for which\nword2vec outputs target relations solving the Corpus Replication Task. Deeming\ngeneralizations of this approach to any set of relations possible, we expect\nsolving of the Corpus Replication Task to provide partial answers to the\nquestions.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 20:37:28 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Eichinger", "Tobias", ""]]}, {"id": "1806.07999", "submitter": "Paul Landes", "authors": "Paul Landes, Barbara Di Eugenio", "title": "A Supervised Approach To The Interpretation Of Imperative To-Do Lists", "comments": "9 pages; https://github.com/plandes/todo-task/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To-do lists are a popular medium for personal information management. As\nto-do tasks are increasingly tracked in electronic form with mobile and desktop\norganizers, so does the potential for software support for the corresponding\ntasks by means of intelligent agents. While there has been work in the area of\npersonal assistants for to-do tasks, no work has focused on classifying user\nintention and information extraction as we do. We show that our methods perform\nwell across two corpora that span sub-domains, one of which we released.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 21:46:49 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Landes", "Paul", ""], ["Di Eugenio", "Barbara", ""]]}, {"id": "1806.08009", "submitter": "Antonio Uva", "authors": "Antonio Uva, Daniele Bonadiman, Alessandro Moschitti", "title": "Injecting Relational Structural Representation in Neural Networks for\n  Question Similarity", "comments": "ACL2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effectively using full syntactic parsing information in Neural Networks (NNs)\nto solve relational tasks, e.g., question similarity, is still an open problem.\nIn this paper, we propose to inject structural representations in NNs by (i)\nlearning an SVM model using Tree Kernels (TKs) on relatively few pairs of\nquestions (few thousands) as gold standard (GS) training data is typically\nscarce, (ii) predicting labels on a very large corpus of question pairs, and\n(iii) pre-training NNs on such large corpus. The results on Quora and SemEval\nquestion similarity datasets show that NNs trained with our approach can learn\nmore accurate models, especially after fine tuning on GS.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 22:09:50 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Uva", "Antonio", ""], ["Bonadiman", "Daniele", ""], ["Moschitti", "Alessandro", ""]]}, {"id": "1806.08040", "submitter": "Yingjie Hu", "authors": "Yingjie Hu and Krzysztof Janowicz", "title": "An empirical study on the names of points of interest and their changes\n  with geographic distance", "comments": "15 pages, 7 figures, GIScience 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While Points Of Interest (POIs), such as restaurants, hotels, and barber\nshops, are part of urban areas irrespective of their specific locations, the\nnames of these POIs often reveal valuable information related to local culture,\nlandmarks, influential families, figures, events, and so on. Place names have\nlong been studied by geographers, e.g., to understand their origins and\nrelations to family names. However, there is a lack of large-scale empirical\nstudies that examine the localness of place names and their changes with\ngeographic distance. In addition to enhancing our understanding of the\ncoherence of geographic regions, such empirical studies are also significant\nfor geographic information retrieval where they can inform computational models\nand improve the accuracy of place name disambiguation. In this work, we conduct\nan empirical study based on 112,071 POIs in seven US metropolitan areas\nextracted from an open Yelp dataset. We propose to adopt term frequency and\ninverse document frequency in geographic contexts to identify local terms used\nin POI names and to analyze their usages across different POI types. Our\nresults show an uneven usage of local terms across POI types, which is highly\nconsistent among different geographic regions. We also examine the decaying\neffect of POI name similarity with the increase of distance among POIs. While\nour analysis focuses on urban POI names, the presented methods can be\ngeneralized to other place types as well, such as mountain peaks and streets.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2018 01:33:30 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Hu", "Yingjie", ""], ["Janowicz", "Krzysztof", ""]]}, {"id": "1806.08044", "submitter": "Alessandra Cervone", "authors": "Alessandra Cervone and Evgeny Stepanov and Giuseppe Riccardi", "title": "Coherence Models for Dialogue", "comments": "Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coherence across multiple turns is a major challenge for state-of-the-art\ndialogue models. Arguably the most successful approach to automatically\nlearning text coherence is the entity grid, which relies on modelling patterns\nof distribution of entities across multiple sentences of a text. Originally\napplied to the evaluation of automatic summaries and the news genre, among its\nmany extensions, this model has also been successfully used to assess dialogue\ncoherence. Nevertheless, both the original grid and its extensions do not model\nintents, a crucial aspect that has been studied widely in the literature in\nconnection to dialogue structure. We propose to augment the original grid\ndocument representation for dialogue with the intentional structure of the\nconversation. Our models outperform the original grid representation on both\ntext discrimination and insertion, the two main standard tasks for coherence\nassessment across three different dialogue datasets, confirming that intents\nplay a key role in modelling dialogue coherence.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2018 02:14:24 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Cervone", "Alessandra", ""], ["Stepanov", "Evgeny", ""], ["Riccardi", "Giuseppe", ""]]}, {"id": "1806.08077", "submitter": "Shaohan Huang", "authors": "Shaohan Huang, Yu Wu, Furu Wei, Ming Zhou", "title": "Dictionary-Guided Editing Networks for Paraphrase Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An intuitive way for a human to write paraphrase sentences is to replace\nwords or phrases in the original sentence with their corresponding synonyms and\nmake necessary changes to ensure the new sentences are fluent and grammatically\ncorrect. We propose a novel approach to modeling the process with\ndictionary-guided editing networks which effectively conduct rewriting on the\nsource sentence to generate paraphrase sentences. It jointly learns the\nselection of the appropriate word level and phrase level paraphrase pairs in\nthe context of the original sentence from an off-the-shelf dictionary as well\nas the generation of fluent natural language sentences. Specifically, the\nsystem retrieves a set of word level and phrase level araphrased pairs derived\nfrom the Paraphrase Database (PPDB) for the original sentence, which is used to\nguide the decision of which the words might be deleted or inserted with the\nsoft attention mechanism under the sequence-to-sequence framework. We conduct\nexperiments on two benchmark datasets for paraphrase generation, namely the\nMSCOCO and Quora dataset. The evaluation results demonstrate that our\ndictionary-guided editing networks outperforms the baseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2018 06:21:14 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Huang", "Shaohan", ""], ["Wu", "Yu", ""], ["Wei", "Furu", ""], ["Zhou", "Ming", ""]]}, {"id": "1806.08097", "submitter": "Dayiheng Liu", "authors": "Dayiheng Liu, Jie Fu, Qian Qu, Jiancheng Lv", "title": "BFGAN: Backward and Forward Generative Adversarial Networks for\n  Lexically Constrained Sentence Generation", "comments": null, "journal-ref": null, "doi": "10.1109/TASLP.2019.2943018", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating prior knowledge like lexical constraints into the model's\noutput to generate meaningful and coherent sentences has many applications in\ndialogue system, machine translation, image captioning, etc. However, existing\nRNN-based models incrementally generate sentences from left to right via beam\nsearch, which makes it difficult to directly introduce lexical constraints into\nthe generated sentences. In this paper, we propose a new algorithmic framework,\ndubbed BFGAN, to address this challenge. Specifically, we employ a backward\ngenerator and a forward generator to generate lexically constrained sentences\ntogether, and use a discriminator to guide the joint training of two generators\nby assigning them reward signals. Due to the difficulty of BFGAN training, we\npropose several training techniques to make the training process more stable\nand efficient. Our extensive experiments on two large-scale datasets with human\nevaluation demonstrate that BFGAN has significant improvements over previous\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2018 07:44:32 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 04:49:41 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Liu", "Dayiheng", ""], ["Fu", "Jie", ""], ["Qu", "Qian", ""], ["Lv", "Jiancheng", ""]]}, {"id": "1806.08115", "submitter": "Johannes Hellrich", "authors": "Johannes Hellrich, Sven Buechel, Udo Hahn", "title": "Modeling Word Emotion in Historical Language: Quantity Beats Supposed\n  Stability in Seed Word Selection", "comments": "Updated for LaTeCH-CLfL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand historical texts, we must be aware that language -- including\nthe emotional connotation attached to words -- changes over time. In this\npaper, we aim at estimating the emotion which is associated with a given word\nin former language stages of English and German. Emotion is represented\nfollowing the popular Valence-Arousal-Dominance (VAD) annotation scheme. While\nbeing more expressive than polarity alone, existing word emotion induction\nmethods are typically not suited for addressing it. To overcome this\nlimitation, we present adaptations of two popular algorithms to VAD. To measure\ntheir effectiveness in diachronic settings, we present the first gold standard\nfor historical word emotions, which was created by scholars with proficiency in\nthe respective language stages and covers both English and German. In contrast\nto claims in previous work, our findings indicate that hand-selecting small\nsets of seed words with supposedly stable emotional meaning is actually harmful\nrather than helpful.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2018 08:53:06 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2019 11:32:41 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Hellrich", "Johannes", ""], ["Buechel", "Sven", ""], ["Hahn", "Udo", ""]]}, {"id": "1806.08202", "submitter": "Hussein AL-Natsheh", "authors": "Hussein T. Al-Natsheh, Lucie Martinet, Fabrice Muhlenbach, Fabien\n  Rico, Djamel A. Zighed", "title": "Metadata Enrichment of Multi-Disciplinary Digital Library: A\n  Semantic-based Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the scientific digital libraries, some papers from different research\ncommunities can be described by community-dependent keywords even if they share\na semantically similar topic. Articles that are not tagged with enough keyword\nvariations are poorly indexed in any information retrieval system which limits\npotentially fruitful exchanges between scientific disciplines. In this paper,\nwe introduce a novel experimentally designed pipeline for multi-label\nsemantic-based tagging developed for open-access metadata digital libraries.\nThe approach starts by learning from a standard scientific categorization and a\nsample of topic tagged articles to find semantically relevant articles and\nenrich its metadata accordingly. Our proposed pipeline aims to enable\nresearchers reaching articles from various disciplines that tend to use\ndifferent terminologies. It allows retrieving semantically relevant articles\ngiven a limited known variation of search terms. In addition to achieving an\naccuracy that is higher than an expanded query based method using a topic\nsynonym set extracted from a semantic network, our experiments also show a\nhigher computational scalability versus other comparable techniques. We created\na new benchmark extracted from the open-access metadata of a scientific digital\nlibrary and published it along with the experiment code to allow further\nresearch in the topic.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2018 12:35:23 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Al-Natsheh", "Hussein T.", ""], ["Martinet", "Lucie", ""], ["Muhlenbach", "Fabrice", ""], ["Rico", "Fabien", ""], ["Zighed", "Djamel A.", ""]]}, {"id": "1806.08309", "submitter": "Seid Muhie Yimam", "authors": "Seid Muhie Yimam and Chris Biemann", "title": "Par4Sim -- Adaptive Paraphrasing for Text Simplification", "comments": "COLING 2018 main conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning from a real-world data stream and continuously updating the model\nwithout explicit supervision is a new challenge for NLP applications with\nmachine learning components. In this work, we have developed an adaptive\nlearning system for text simplification, which improves the underlying\nlearning-to-rank model from usage data, i.e. how users have employed the system\nfor the task of simplification. Our experimental result shows that, over a\nperiod of time, the performance of the embedded paraphrase ranking model\nincreases steadily improving from a score of 62.88% up to 75.70% based on the\nNDCG@10 evaluation metrics. To our knowledge, this is the first study where an\nNLP component is adaptively improved through usage.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2018 16:24:31 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Yimam", "Seid Muhie", ""], ["Biemann", "Chris", ""]]}, {"id": "1806.08409", "submitter": "Chiori Hori Dr.", "authors": "Chiori Hori, Huda Alamri, Jue Wang, Gordon Wichern, Takaaki Hori,\n  Anoop Cherian, Tim K. Marks, Vincent Cartillier, Raphael Gontijo Lopes,\n  Abhishek Das, Irfan Essa, Dhruv Batra, Devi Parikh", "title": "End-to-End Audio Visual Scene-Aware Dialog using Multimodal\n  Attention-Based Video Features", "comments": "A prototype system for the Audio Visual Scene-aware Dialog (AVSD) at\n  DSTC7", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialog systems need to understand dynamic visual scenes in order to have\nconversations with users about the objects and events around them. Scene-aware\ndialog systems for real-world applications could be developed by integrating\nstate-of-the-art technologies from multiple research areas, including:\nend-to-end dialog technologies, which generate system responses using models\ntrained from dialog data; visual question answering (VQA) technologies, which\nanswer questions about images using learned image features; and video\ndescription technologies, in which descriptions/captions are generated from\nvideos using multimodal information. We introduce a new dataset of dialogs\nabout videos of human behaviors. Each dialog is a typed conversation that\nconsists of a sequence of 10 question-and-answer(QA) pairs between two Amazon\nMechanical Turk (AMT) workers. In total, we collected dialogs on roughly 9,000\nvideos. Using this new dataset for Audio Visual Scene-aware dialog (AVSD), we\ntrained an end-to-end conversation model that generates responses in a dialog\nabout a video. Our experiments demonstrate that using multimodal features that\nwere developed for multimodal attention-based video description enhances the\nquality of generated dialog about dynamic scenes (videos). Our dataset, model\ncode and pretrained models will be publicly available for a new Video\nScene-Aware Dialog challenge.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2018 19:43:13 GMT"}, {"version": "v2", "created": "Sat, 30 Jun 2018 00:35:25 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Hori", "Chiori", ""], ["Alamri", "Huda", ""], ["Wang", "Jue", ""], ["Wichern", "Gordon", ""], ["Hori", "Takaaki", ""], ["Cherian", "Anoop", ""], ["Marks", "Tim K.", ""], ["Cartillier", "Vincent", ""], ["Lopes", "Raphael Gontijo", ""], ["Das", "Abhishek", ""], ["Essa", "Irfan", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""]]}, {"id": "1806.08462", "submitter": "Lili Mou", "authors": "Hareesh Bahuleyan, Lili Mou, Hao Zhou, Olga Vechtomova", "title": "Stochastic Wasserstein Autoencoder for Probabilistic Sentence Generation", "comments": "Accepted by NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The variational autoencoder (VAE) imposes a probabilistic distribution\n(typically Gaussian) on the latent space and penalizes the Kullback--Leibler\n(KL) divergence between the posterior and prior. In NLP, VAEs are extremely\ndifficult to train due to the problem of KL collapsing to zero. One has to\nimplement various heuristics such as KL weight annealing and word dropout in a\ncarefully engineered manner to successfully train a VAE for text. In this\npaper, we propose to use the Wasserstein autoencoder (WAE) for probabilistic\nsentence generation, where the encoder could be either stochastic or\ndeterministic. We show theoretically and empirically that, in the original WAE,\nthe stochastically encoded Gaussian distribution tends to become a Dirac-delta\nfunction, and we propose a variant of WAE that encourages the stochasticity of\nthe encoder. Experimental results show that the latent space learned by WAE\nexhibits properties of continuity and smoothness as in VAEs, while\nsimultaneously achieving much higher BLEU scores for sentence reconstruction.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2018 01:11:40 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 17:43:25 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Bahuleyan", "Hareesh", ""], ["Mou", "Lili", ""], ["Zhou", "Hao", ""], ["Vechtomova", "Olga", ""]]}, {"id": "1806.08467", "submitter": "Henrique Ferraz de Arruda", "authors": "Henrique F. de Arruda, Vanessa Q. Marinho, Luciano da F. Costa, Diego\n  R. Amancio", "title": "Paragraph-based complex networks: application to document classification\n  and authenticity verification", "comments": null, "journal-ref": "Information Processing & Management 56 (3) 479-494, 2019", "doi": "10.1016/j.ipm.2018.12.008", "report-no": null, "categories": "cs.CL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing number of texts made available on the Internet, many\napplications have relied on text mining tools to tackle a diversity of\nproblems. A relevant model to represent texts is the so-called word adjacency\n(co-occurrence) representation, which is known to capture mainly syntactical\nfeatures of texts.In this study, we introduce a novel network representation\nthat considers the semantic similarity between paragraphs. Two main properties\nof paragraph networks are considered: (i) their ability to incorporate\ncharacteristics that can discriminate real from artificial, shuffled\nmanuscripts and (ii) their ability to capture syntactical and semantic textual\nfeatures. Our results revealed that real texts are organized into communities,\nwhich turned out to be an important feature for discriminating them from\nartificial texts. Interestingly, we have also found that, differently from\ntraditional co-occurrence networks, the adopted representation is able to\ncapture semantic features. Additionally, the proposed framework was employed to\nanalyze the Voynich manuscript, which was found to be compatible with texts\nwritten in natural languages. Taken together, our findings suggest that the\nproposed methodology can be combined with traditional network models to improve\ntext classification tasks.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2018 01:58:44 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["de Arruda", "Henrique F.", ""], ["Marinho", "Vanessa Q.", ""], ["Costa", "Luciano da F.", ""], ["Amancio", "Diego R.", ""]]}, {"id": "1806.08621", "submitter": "Tanel Alum\\\"ae", "authors": "Martin Karu, Tanel Alum\\\"ae", "title": "Weakly Supervised Training of Speaker Identification Models", "comments": "Odyssey 2018 The Speaker and Language Recognition Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.HC eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approach for training speaker identification models in a weakly\nsupervised manner. We concentrate on the setting where the training data\nconsists of a set of audio recordings and the speaker annotation is provided\nonly at the recording level. The method uses speaker diarization to find unique\nspeakers in each recording, and i-vectors to project the speech of each speaker\nto a fixed-dimensional vector. A neural network is then trained to map\ni-vectors to speakers, using a special objective function that allows to\noptimize the model using recording-level speaker labels. We report experiments\non two different real-world datasets. On the VoxCeleb dataset, the method\nprovides 94.6% accuracy on a closed set speaker identification task, surpassing\nthe baseline performance by a large margin. On an Estonian broadcast news\ndataset, the method provides 66% time-weighted speaker identification recall at\n93% precision.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2018 12:15:35 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Karu", "Martin", ""], ["Alum\u00e4e", "Tanel", ""]]}, {"id": "1806.08727", "submitter": "Pasquale Minervini", "authors": "Dirk Weissenborn, Pasquale Minervini, Tim Dettmers, Isabelle\n  Augenstein, Johannes Welbl, Tim Rockt\\\"aschel, Matko Bo\\v{s}njak, Jeff\n  Mitchell, Thomas Demeester, Pontus Stenetorp, Sebastian Riedel", "title": "Jack the Reader - A Machine Reading Framework", "comments": "Proceedings of the Annual Meeting of the Association for\n  Computational Linguistics (ACL 2018), System Demonstrations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many Machine Reading and Natural Language Understanding tasks require reading\nsupporting text in order to answer questions. For example, in Question\nAnswering, the supporting text can be newswire or Wikipedia articles; in\nNatural Language Inference, premises can be seen as the supporting text and\nhypotheses as questions. Providing a set of useful primitives operating in a\nsingle framework of related tasks would allow for expressive modelling, and\neasier model comparison and replication. To that end, we present Jack the\nReader (Jack), a framework for Machine Reading that allows for quick model\nprototyping by component reuse, evaluation of new models on existing datasets\nas well as integrating new datasets and applying them on a growing set of\nimplemented baseline models. Jack is currently supporting (but not limited to)\nthree tasks: Question Answering, Natural Language Inference, and Link\nPrediction. It is developed with the aim of increasing research efficiency and\ncode reuse.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 00:30:29 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Weissenborn", "Dirk", ""], ["Minervini", "Pasquale", ""], ["Dettmers", "Tim", ""], ["Augenstein", "Isabelle", ""], ["Welbl", "Johannes", ""], ["Rockt\u00e4schel", "Tim", ""], ["Bo\u0161njak", "Matko", ""], ["Mitchell", "Jeff", ""], ["Demeester", "Thomas", ""], ["Stenetorp", "Pontus", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1806.08730", "submitter": "Nitish Shirish Keskar", "authors": "Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard\n  Socher", "title": "The Natural Language Decathlon: Multitask Learning as Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has improved performance on many natural language processing\n(NLP) tasks individually. However, general NLP models cannot emerge within a\nparadigm that focuses on the particularities of a single metric, dataset, and\ntask. We introduce the Natural Language Decathlon (decaNLP), a challenge that\nspans ten tasks: question answering, machine translation, summarization,\nnatural language inference, sentiment analysis, semantic role labeling,\nzero-shot relation extraction, goal-oriented dialogue, semantic parsing, and\ncommonsense pronoun resolution. We cast all tasks as question answering over a\ncontext. Furthermore, we present a new Multitask Question Answering Network\n(MQAN) jointly learns all tasks in decaNLP without any task-specific modules or\nparameters in the multitask setting. MQAN shows improvements in transfer\nlearning for machine translation and named entity recognition, domain\nadaptation for sentiment analysis and natural language inference, and zero-shot\ncapabilities for text classification. We demonstrate that the MQAN's\nmulti-pointer-generator decoder is key to this success and performance further\nimproves with an anti-curriculum training strategy. Though designed for\ndecaNLP, MQAN also achieves state of the art results on the WikiSQL semantic\nparsing task in the single-task setting. We also release code for procuring and\nprocessing data, training and evaluating models, and reproducing all\nexperiments for decaNLP.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 16:39:26 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["McCann", "Bryan", ""], ["Keskar", "Nitish Shirish", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1806.08748", "submitter": "Heeyoul Choi", "authors": "Heeyoul Choi", "title": "Persistent Hidden States and Nonlinear Transformation for Long\n  Short-Term Memory", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) have been drawing much attention with great\nsuccess in many applications like speech recognition and neural machine\ntranslation. Long short-term memory (LSTM) is one of the most popular RNN units\nin deep learning applications. LSTM transforms the input and the previous\nhidden states to the next states with the affine transformation, multiplication\noperations and a nonlinear activation function, which makes a good data\nrepresentation for a given task. The affine transformation includes rotation\nand reflection, which change the semantic or syntactic information of\ndimensions in the hidden states. However, considering that a model interprets\nthe output sequence of LSTM over the whole input sequence, the dimensions of\nthe states need to keep the same type of semantic or syntactic information\nregardless of the location in the sequence. In this paper, we propose a simple\nvariant of the LSTM unit, persistent recurrent unit (PRU), where each dimension\nof hidden states keeps persistent information across time, so that the space\nkeeps the same meaning over the whole sequence. In addition, to improve the\nnonlinear transformation power, we add a feedforward layer in the PRU\nstructure. In the experiment, we evaluate our proposed methods with three\ndifferent tasks, and the results confirm that our methods have better\nperformance than the conventional LSTM.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2018 16:19:46 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2018 07:09:14 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Choi", "Heeyoul", ""]]}, {"id": "1806.08760", "submitter": "Khuong Vo", "authors": "Khuong Vo, Dang Pham, Mao Nguyen, Trung Mai and Tho Quan", "title": "Combination of Domain Knowledge and Deep Learning for Sentiment Analysis", "comments": "Accepted to MIWAI 2017", "journal-ref": null, "doi": "10.1007/978-3-319-69456-6_14", "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The emerging technique of deep learning has been widely applied in many\ndifferent areas. However, when adopted in a certain specific domain, this\ntechnique should be combined with domain knowledge to improve efficiency and\naccuracy. In particular, when analyzing the applications of deep learning in\nsentiment analysis, we found that the current approaches are suffering from the\nfollowing drawbacks: (i) the existing works have not paid much attention to the\nimportance of different types of sentiment terms, which is an important concept\nin this area; and (ii) the loss function currently employed does not well\nreflect the degree of error of sentiment misclassification. To overcome such\nproblem, we propose to combine domain knowledge with deep learning. Our\nproposal includes using sentiment scores, learnt by quadratic programming, to\naugment training data; and introducing the penalty matrix for enhancing the\nloss function of cross entropy. When experimented, we achieved a significant\nimprovement in classification results.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2018 16:39:37 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 05:47:31 GMT"}, {"version": "v3", "created": "Sat, 16 Feb 2019 00:58:24 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Vo", "Khuong", ""], ["Pham", "Dang", ""], ["Nguyen", "Mao", ""], ["Mai", "Trung", ""], ["Quan", "Tho", ""]]}, {"id": "1806.08890", "submitter": "Sven Buechel", "authors": "Sven Buechel and Udo Hahn", "title": "Emotion Representation Mapping for Automatic Lexicon Construction\n  (Mostly) Performs on Human Level", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Emotion Representation Mapping (ERM) has the goal to convert existing emotion\nratings from one representation format into another one, e.g., mapping\nValence-Arousal-Dominance annotations for words or sentences into Ekman's Basic\nEmotions and vice versa. ERM can thus not only be considered as an alternative\nto Word Emotion Induction (WEI) techniques for automatic emotion lexicon\nconstruction but may also help mitigate problems that come from the\nproliferation of emotion representation formats in recent years. We propose a\nnew neural network approach to ERM that not only outperforms the previous\nstate-of-the-art. Equally important, we present a refined evaluation\nmethodology and gather strong evidence that our model yields results which are\n(almost) as reliable as human annotations, even in cross-lingual settings.\nBased on these results we generate new emotion ratings for 13 typologically\ndiverse languages and claim that they have near-gold quality, at least.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jun 2018 02:00:13 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Buechel", "Sven", ""], ["Hahn", "Udo", ""]]}, {"id": "1806.09010", "submitter": "Gabrielle Liu", "authors": "Gabrielle K. Liu", "title": "Evaluating Gammatone Frequency Cepstral Coefficients with Neural\n  Networks for Emotion Recognition from Speech", "comments": "5 pages, 1 figure, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current approaches to speech emotion recognition focus on speech features\nthat can capture the emotional content of a speech signal. Mel Frequency\nCepstral Coefficients (MFCCs) are one of the most commonly used representations\nfor audio speech recognition and classification. This paper proposes Gammatone\nFrequency Cepstral Coefficients (GFCCs) as a potentially better representation\nof speech signals for emotion recognition. The effectiveness of MFCC and GFCC\nrepresentations are compared and evaluated over emotion and intensity\nclassification tasks with fully connected and recurrent neural network\narchitectures. The results provide evidence that GFCCs outperform MFCCs in\nspeech emotion recognition.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jun 2018 17:42:32 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Liu", "Gabrielle K.", ""]]}, {"id": "1806.09029", "submitter": "Jonathan K Kummerfeld", "authors": "Catherine Finegan-Dollak, Jonathan K. Kummerfeld, Li Zhang, Karthik\n  Ramanathan, Sesh Sadasivam, Rui Zhang, Dragomir Radev", "title": "Improving Text-to-SQL Evaluation Methodology", "comments": "To appear at ACL 2018", "journal-ref": "ACL (2018) 351-360", "doi": "10.18653/v1/P18-1033", "report-no": null, "categories": "cs.CL cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To be informative, an evaluation must measure how well systems generalize to\nrealistic unseen data. We identify limitations of and propose improvements to\ncurrent evaluations of text-to-SQL systems. First, we compare human-generated\nand automatically generated questions, characterizing properties of queries\nnecessary for real-world applications. To facilitate evaluation on multiple\ndatasets, we release standardized and improved versions of seven existing\ndatasets and one new text-to-SQL dataset. Second, we show that the current\ndivision of data into training and test sets measures robustness to variations\nin the way questions are asked, but only partially tests how well systems\ngeneralize to new queries; therefore, we propose a complementary dataset split\nfor evaluation of future work. Finally, we demonstrate how the common practice\nof anonymizing variables during evaluation removes an important challenge of\nthe task. Our observations highlight key difficulties, and our methodology\nenables effective measurement of future development.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jun 2018 20:02:55 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Finegan-Dollak", "Catherine", ""], ["Kummerfeld", "Jonathan K.", ""], ["Zhang", "Li", ""], ["Ramanathan", "Karthik", ""], ["Sadasivam", "Sesh", ""], ["Zhang", "Rui", ""], ["Radev", "Dragomir", ""]]}, {"id": "1806.09030", "submitter": "Javid Ebrahimi", "authors": "Javid Ebrahimi, Daniel Lowd, Dejing Dou", "title": "On Adversarial Examples for Character-Level Neural Machine Translation", "comments": null, "journal-ref": "COLING 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Evaluating on adversarial examples has become a standard procedure to measure\nrobustness of deep learning models. Due to the difficulty of creating white-box\nadversarial examples for discrete text input, most analyses of the robustness\nof NLP models have been done through black-box adversarial examples. We\ninvestigate adversarial examples for character-level neural machine translation\n(NMT), and contrast black-box adversaries with a novel white-box adversary,\nwhich employs differentiable string-edit operations to rank adversarial\nchanges. We propose two novel types of attacks which aim to remove or change a\nword in a translation, rather than simply break the NMT. We demonstrate that\nwhite-box adversarial examples are significantly stronger than their black-box\ncounterparts in different attack scenarios, which show more serious\nvulnerabilities than previously known. In addition, after performing\nadversarial training, which takes only 3 times longer than regular training, we\ncan improve the model's robustness significantly.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jun 2018 20:08:56 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Ebrahimi", "Javid", ""], ["Lowd", "Daniel", ""], ["Dou", "Dejing", ""]]}, {"id": "1806.09055", "submitter": "Hanxiao Liu", "authors": "Hanxiao Liu, Karen Simonyan, Yiming Yang", "title": "DARTS: Differentiable Architecture Search", "comments": "Published at ICLR 2019; Code and pretrained models available at\n  https://github.com/quark0/darts", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the scalability challenge of architecture search by\nformulating the task in a differentiable manner. Unlike conventional approaches\nof applying evolution or reinforcement learning over a discrete and\nnon-differentiable search space, our method is based on the continuous\nrelaxation of the architecture representation, allowing efficient search of the\narchitecture using gradient descent. Extensive experiments on CIFAR-10,\nImageNet, Penn Treebank and WikiText-2 show that our algorithm excels in\ndiscovering high-performance convolutional architectures for image\nclassification and recurrent architectures for language modeling, while being\norders of magnitude faster than state-of-the-art non-differentiable techniques.\nOur implementation has been made publicly available to facilitate further\nresearch on efficient architecture search algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jun 2018 00:06:13 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2019 06:29:32 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Liu", "Hanxiao", ""], ["Simonyan", "Karen", ""], ["Yang", "Yiming", ""]]}, {"id": "1806.09089", "submitter": "Chanhee Lee", "authors": "Chanhee Lee, Young-Bum Kim, Dongyub Lee, HeuiSeok Lim", "title": "Character-Level Feature Extraction with Densely Connected Networks", "comments": "12 pages, 4 figures, accepted as a conference paper at COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating character-level features is an important step for achieving good\nresults in various natural language processing tasks. To alleviate the need for\nhuman labor in generating hand-crafted features, methods that utilize neural\narchitectures such as Convolutional Neural Network (CNN) or Recurrent Neural\nNetwork (RNN) to automatically extract such features have been proposed and\nhave shown great results. However, CNN generates position-independent features,\nand RNN is slow since it needs to process the characters sequentially. In this\npaper, we propose a novel method of using a densely connected network to\nautomatically extract character-level features. The proposed method does not\nrequire any language or task specific assumptions, and shows robustness and\neffectiveness while being faster than CNN- or RNN-based methods. Evaluating\nthis method on three sequence labeling tasks - slot tagging, Part-of-Speech\n(POS) tagging, and Named-Entity Recognition (NER) - we obtain state-of-the-art\nperformance with a 96.62 F1-score and 97.73% accuracy on slot tagging and POS\ntagging, respectively, and comparable performance to the state-of-the-art 91.13\nF1-score on NER.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jun 2018 05:54:45 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 14:40:36 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Lee", "Chanhee", ""], ["Kim", "Young-Bum", ""], ["Lee", "Dongyub", ""], ["Lim", "HeuiSeok", ""]]}, {"id": "1806.09102", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang, Jiangtong Li, Pengfei Zhu, Hai Zhao and Gongshen Liu", "title": "Modeling Multi-turn Conversation with Deep Utterance Aggregation", "comments": "Proceedings of the 27th International Conference on Computational\n  Linguistics (COLING 2018)", "journal-ref": "COLING 2018, pages 3740-3752", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-turn conversation understanding is a major challenge for building\nintelligent dialogue systems. This work focuses on retrieval-based response\nmatching for multi-turn conversation whose related work simply concatenates the\nconversation utterances, ignoring the interactions among previous utterances\nfor context modeling. In this paper, we formulate previous utterances into\ncontext using a proposed deep utterance aggregation model to form a\nfine-grained context representation. In detail, a self-matching attention is\nfirst introduced to route the vital information in each utterance. Then the\nmodel matches a response with each refined utterance and the final matching\nscore is obtained after attentive turns aggregation. Experimental results show\nour model outperforms the state-of-the-art methods on three multi-turn\nconversation benchmarks, including a newly introduced e-commerce dialogue\ncorpus.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jun 2018 08:15:54 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 16:27:27 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["Li", "Jiangtong", ""], ["Zhu", "Pengfei", ""], ["Zhao", "Hai", ""], ["Liu", "Gongshen", ""]]}, {"id": "1806.09103", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang, Yafang Huang and Hai Zhao", "title": "Subword-augmented Embedding for Cloze Reading Comprehension", "comments": "Proceedings of the 27th International Conference on Computational\n  Linguistics (COLING 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning is the foundation of machine reading comprehension.\nIn state-of-the-art models, deep learning methods broadly use word and\ncharacter level representations. However, character is not naturally the\nminimal linguistic unit. In addition, with a simple concatenation of character\nand word embedding, previous models actually give suboptimal solution. In this\npaper, we propose to use subword rather than character for word embedding\nenhancement. We also empirically explore different augmentation strategies on\nsubword-augmented embedding to enhance the cloze-style reading comprehension\nmodel reader. In detail, we present a reader that uses subword-level\nrepresentation to augment word embedding with a short list to handle rare words\neffectively. A thorough examination is conducted to evaluate the comprehensive\nperformance and generalization ability of the proposed reader. Experimental\nresults show that the proposed approach helps the reader significantly\noutperform the state-of-the-art baselines on various public datasets.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jun 2018 08:18:12 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["Huang", "Yafang", ""], ["Zhao", "Hai", ""]]}, {"id": "1806.09105", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang and Hai Zhao", "title": "One-shot Learning for Question-Answering in Gaokao History Challenge", "comments": "Proceedings of the 27th International Conference on Computational\n  Linguistics (COLING 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering questions from university admission exams (Gaokao in Chinese) is a\nchallenging AI task since it requires effective representation to capture\ncomplicated semantic relations between questions and answers. In this work, we\npropose a hybrid neural model for deep question-answering task from history\nexaminations. Our model employs a cooperative gated neural network to retrieve\nanswers with the assistance of extra labels given by a neural turing machine\nlabeler. Empirical study shows that the labeler works well with only a small\ntraining dataset and the gated mechanism is good at fetching the semantic\nrepresentation of lengthy answers. Experiments on question answering\ndemonstrate the proposed model obtains substantial performance gains over\nvarious neural model baselines in terms of multiple evaluation metrics.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jun 2018 08:36:23 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["Zhao", "Hai", ""]]}, {"id": "1806.09202", "submitter": "Sayash Kapoor", "authors": "Sayash Kapoor, Vijay Keswani, Nisheeth K. Vishnoi, L. Elisa Celis", "title": "Balanced News Using Constrained Bandit-based Personalization", "comments": "To appear as a demo-paper in IJCAI-ECAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a prototype for a news search engine that presents balanced\nviewpoints across liberal and conservative articles with the goal of\nde-polarizing content and allowing users to escape their filter bubble. The\nbalancing is done according to flexible user-defined constraints, and leverages\nrecent advances in constrained bandit optimization. We showcase our balanced\nnews feed by displaying it side-by-side with the news feed produced by a\ntraditional (polarized) feed.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jun 2018 20:02:25 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Kapoor", "Sayash", ""], ["Keswani", "Vijay", ""], ["Vishnoi", "Nisheeth K.", ""], ["Celis", "L. Elisa", ""]]}, {"id": "1806.09279", "submitter": "Amritpal Kaur", "authors": "Amritpal Kaur and Harkiran Kaur", "title": "Framework for Opinion Mining Approach to Augment Education System\n  Performance", "comments": "5 pages, 2 figures", "journal-ref": "http://ijitce.co.uk/vol8n6.aspx June 2018 Issue Vol.8 No.6", "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The extensive expansion growth of social networking sites allows the people\nto share their views and experiences freely with their peers on internet. Due\nto this, huge amount of data is generated on everyday basis which can be used\nfor the opinion mining to extract the views of people in a particular field.\nOpinion mining finds its applications in many areas such as Tourism, Politics,\neducation and entertainment, etc. It has not been extensively implemented in\narea of education system. This paper discusses the malpractices in the present\nexamination system. In the present scenario, Opinion mining is vastly used for\ndecision making. The authors of this paper have designed a framework by\napplying Na\\\"ive Bayes approach to the education dataset. The various phases of\nNa\\\"ive Bayes approach include three steps: conversion of data into frequency\ntable, making classes of dataset and apply the Na\\\"ive Bayes algorithm equation\nto calculate the probabilities of classes. Finally the highest probability\nclass is the outcome of this prediction. These predictions are used to make\nimprovements in the education system and help to provide better education.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 04:17:44 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Kaur", "Amritpal", ""], ["Kaur", "Harkiran", ""]]}, {"id": "1806.09325", "submitter": "Chenxing Li", "authors": "Chenxing Li, Tieqiang Wang, Shuang Xu, Bo Xu", "title": "Single-channel Speech Dereverberation via Generative Adversarial\n  Training", "comments": "5 pages. Accepted by Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a single-channel speech dereverberation system\n(DeReGAT) based on convolutional, bidirectional long short-term memory and deep\nfeed-forward neural network (CBLDNN) with generative adversarial training\n(GAT). In order to obtain better speech quality instead of only minimizing a\nmean square error (MSE), GAT is employed to make the dereverberated speech\nindistinguishable form the clean samples. Besides, our system can deal with\nwide range reverberation and be well adapted to variant environments. The\nexperimental results show that the proposed model outperforms weighted\nprediction error (WPE) and deep neural network-based systems. In addition,\nDeReGAT is extended to an online speech dereverberation scenario, which reports\ncomparable performance with the offline case.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 08:35:56 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Li", "Chenxing", ""], ["Wang", "Tieqiang", ""], ["Xu", "Shuang", ""], ["Xu", "Bo", ""]]}, {"id": "1806.09374", "submitter": "Herman Kamper", "authors": "Raghav Menon, Herman Kamper, John Quinn, Thomas Niesler", "title": "Fast ASR-free and almost zero-resource keyword spotting using DTW and\n  CNNs for humanitarian monitoring", "comments": "5 pages, 4 figures, 3 tables, accepted at Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use dynamic time warping (DTW) as supervision for training a convolutional\nneural network (CNN) based keyword spotting system using a small set of spoken\nisolated keywords. The aim is to allow rapid deployment of a keyword spotting\nsystem in a new language to support urgent United Nations (UN) relief\nprogrammes in parts of Africa where languages are extremely under-resourced and\nthe development of annotated speech resources is infeasible. First, we use 1920\nrecorded keywords (40 keyword types, 34 minutes of speech) as exemplars in a\nDTW-based template matching system and apply it to untranscribed broadcast\nspeech. Then, we use the resulting DTW scores as targets to train a CNN on the\nsame unlabelled speech. In this way we use just 34 minutes of labelled speech,\nbut leverage a large amount of unlabelled data for training. While the\nresulting CNN keyword spotter cannot match the performance of the DTW-based\nsystem, it substantially outperforms a CNN classifier trained only on the\nkeywords, improving the area under the ROC curve from 0.54 to 0.64. Because our\nCNN system is several orders of magnitude faster at runtime than the DTW\nsystem, it represents the most viable keyword spotter on this extremely limited\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 10:41:29 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Menon", "Raghav", ""], ["Kamper", "Herman", ""], ["Quinn", "John", ""], ["Niesler", "Thomas", ""]]}, {"id": "1806.09439", "submitter": "Lucas Sterckx", "authors": "Lucas Sterckx, Johannes Deleu, Chris Develder, Thomas Demeester", "title": "Prior Attention for Style-aware Sequence-to-Sequence Models", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend sequence-to-sequence models with the possibility to control the\ncharacteristics or style of the generated output, via attention that is\ngenerated a priori (before decoding) from a latent code vector. After training\nan initial attention-based sequence-to-sequence model, we use a variational\nauto-encoder conditioned on representations of input sequences and a latent\ncode vector space to generate attention matrices. By sampling the code vector\nfrom specific regions of this latent space during decoding and imposing prior\nattention generated from it in the seq2seq model, output can be steered towards\nhaving certain attributes. This is demonstrated for the task of sentence\nsimplification, where the latent code vector allows control over output length\nand lexical simplification, and enables fine-tuning to optimize for different\nevaluation metrics.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 13:17:24 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Sterckx", "Lucas", ""], ["Deleu", "Johannes", ""], ["Develder", "Chris", ""], ["Demeester", "Thomas", ""]]}, {"id": "1806.09511", "submitter": "Jose Marcelino", "authors": "Jos\\'e Marcelino, Jo\\~ao Faria, Lu\\'is Ba\\'ia, Ricardo Gamelas Sousa", "title": "A Hierarchical Deep Learning Natural Language Parser for Fashion", "comments": "In Proceedings of KDD 2018 (KDD Workshop on AI for Fashion)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a hierarchical deep learning natural language parser for\nfashion. Our proposal intends not only to recognize fashion-domain entities but\nalso to expose syntactic and morphologic insights. We leverage the usage of an\narchitecture of specialist models, each one for a different task (from parsing\nto entity recognition). Such architecture renders a hierarchical model able to\ncapture the nuances of the fashion language. The natural language parser is\nable to deal with textual ambiguities which are left unresolved by our\ncurrently existing solution. Our empirical results establish a robust baseline,\nwhich justifies the use of hierarchical architectures of deep learning models\nwhile opening new research avenues to explore.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 14:57:52 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Marcelino", "Jos\u00e9", ""], ["Faria", "Jo\u00e3o", ""], ["Ba\u00eda", "Lu\u00eds", ""], ["Sousa", "Ricardo Gamelas", ""]]}, {"id": "1806.09514", "submitter": "No\\'e Tits", "authors": "Adaeze Adigwe, No\\'e Tits, Kevin El Haddad, Sarah Ostadabbas and\n  Thierry Dutoit", "title": "The Emotional Voices Database: Towards Controlling the Emotion Dimension\n  in Voice Generation Systems", "comments": "Submitted to SLSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a database of emotional speech intended to be\nopen-sourced and used for synthesis and generation purpose. It contains data\nfor male and female actors in English and a male actor in French. The database\ncovers 5 emotion classes so it could be suitable to build synthesis and voice\ntransformation systems with the potential to control the emotional dimension in\na continuous way. We show the data's efficiency by building a simple MLP system\nconverting neutral to angry speech style and evaluate it via a CMOS perception\ntest. Even though the system is a very simple one, the test show the efficiency\nof the data which is promising for future work.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 15:01:54 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Adigwe", "Adaeze", ""], ["Tits", "No\u00e9", ""], ["Haddad", "Kevin El", ""], ["Ostadabbas", "Sarah", ""], ["Dutoit", "Thierry", ""]]}, {"id": "1806.09533", "submitter": "Fabrice Daniel", "authors": "Marc Velay and Fabrice Daniel", "title": "Using NLP on news headlines to predict index trends", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper attempts to provide a state of the art in trend prediction using\nnews headlines. We present the research done on predicting DJIA trends using\nNatural Language Processing. We will explain the different algorithms we have\nused as well as the various embedding techniques attempted. We rely on\nstatistical and deep learning models in order to extract information from the\ncorpuses.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2018 15:37:35 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Velay", "Marc", ""], ["Daniel", "Fabrice", ""]]}, {"id": "1806.09542", "submitter": "Wei-Hung Weng", "authors": "Wei-Hung Weng and Peter Szolovits", "title": "Mapping Unparalleled Clinical Professional and Consumer Languages with\n  Embedding Alignment", "comments": "Accepted by 2018 KDD Workshop on Machine Learning for Medicine and\n  Healthcare", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mapping and translating professional but arcane clinical jargons to consumer\nlanguage is essential to improve the patient-clinician communication.\nResearchers have used the existing biomedical ontologies and consumer health\nvocabulary dictionary to translate between the languages. However, such\napproaches are limited by expert efforts to manually build the dictionary,\nwhich is hard to be generalized and scalable. In this work, we utilized the\nembeddings alignment method for the word mapping between unparalleled clinical\nprofessional and consumer language embeddings. To map semantically similar\nwords in two different word embeddings, we first independently trained word\nembeddings on both the corpus with abundant clinical professional terms and the\nother with mainly healthcare consumer terms. Then, we aligned the embeddings by\nthe Procrustes algorithm. We also investigated the approach with the\nadversarial training with refinement. We evaluated the quality of the alignment\nthrough the similar words retrieval both by computing the model precision and\nas well as judging qualitatively by human. We show that the Procrustes\nalgorithm can be performant for the professional consumer language embeddings\nalignment, whereas adversarial training with refinement may find some relations\nbetween two languages.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 15:54:45 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Weng", "Wei-Hung", ""], ["Szolovits", "Peter", ""]]}, {"id": "1806.09652", "submitter": "Sree Harsha Ramesh", "authors": "Sree Harsha Ramesh and Krishna Prasad Sankaranarayanan", "title": "Neural Machine Translation for Low Resource Languages using Bilingual\n  Lexicon Induced from Comparable Corpora", "comments": "8 pages, 3 figures, 4 tables, NAACL-SRW (2018)", "journal-ref": null, "doi": "10.18653/v1/N18-4016", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resources for the non-English languages are scarce and this paper addresses\nthis problem in the context of machine translation, by automatically extracting\nparallel sentence pairs from the multilingual articles available on the\nInternet. In this paper, we have used an end-to-end Siamese bidirectional\nrecurrent neural network to generate parallel sentences from comparable\nmultilingual articles in Wikipedia. Subsequently, we have showed that using the\nharvested dataset improved BLEU scores on both NMT and phrase-based SMT systems\nfor the low-resource language pairs: English--Hindi and English--Tamil, when\ncompared to training exclusively on the limited bilingual corpora collected for\nthese language pairs.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 18:22:27 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Ramesh", "Sree Harsha", ""], ["Sankaranarayanan", "Krishna Prasad", ""]]}, {"id": "1806.09736", "submitter": "Amir Karami", "authors": "Amir Karami and Noelle M. Pendergraft", "title": "Computational Analysis of Insurance Complaints: GEICO Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The online environment has provided a great opportunity for insurance\npolicyholders to share their complaints with respect to different services.\nThese complaints can reveal valuable information for insurance companies who\nseek to improve their services; however, analyzing a huge number of online\ncomplaints is a complicated task for human and must involve computational\nmethods to create an efficient process. This research proposes a computational\napproach to characterize the major topics of a large number of online\ncomplaints. Our approach is based on using the topic modeling approach to\ndisclose the latent semantic of complaints. The proposed approach deployed on\nthousands of GEICO negative reviews. Analyzing 1,371 GEICO complaints indicates\nthat there are 30 major complains in four categories: (1) customer service, (2)\ninsurance coverage, paperwork, policy, and reports, (3) legal issues, and (4)\ncosts, estimates, and payments. This research approach can be used in other\napplications to explore a large number of reviews.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 00:12:14 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Karami", "Amir", ""], ["Pendergraft", "Noelle M.", ""]]}, {"id": "1806.09751", "submitter": "Hussein S. Al-Olimat", "authors": "Hussein S. Al-Olimat and Steven Gustafson and Jason Mackay and\n  Krishnaprasad Thirunarayan and Amit Sheth", "title": "A Practical Incremental Learning Framework For Sparse Entity Extraction", "comments": "https://www.aclweb.org/anthology/C18-1059/", "journal-ref": "In Proceedings of COLING 2018, the 27th International Conference\n  on Computational Linguistics: Technical Papers", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work addresses challenges arising from extracting entities from textual\ndata, including the high cost of data annotation, model accuracy, selecting\nappropriate evaluation criteria, and the overall quality of annotation. We\npresent a framework that integrates Entity Set Expansion (ESE) and Active\nLearning (AL) to reduce the annotation cost of sparse data and provide an\nonline evaluation method as feedback. This incremental and interactive learning\nframework allows for rapid annotation and subsequent extraction of sparse data\nwhile maintaining high accuracy. We evaluate our framework on three publicly\navailable datasets and show that it drastically reduces the cost of sparse\nentity annotation by an average of 85% and 45% to reach 0.9 and 1.0 F-Scores\nrespectively. Moreover, the method exhibited robust performance across all\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 01:36:44 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 18:38:51 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Al-Olimat", "Hussein S.", ""], ["Gustafson", "Steven", ""], ["Mackay", "Jason", ""], ["Thirunarayan", "Krishnaprasad", ""], ["Sheth", "Amit", ""]]}, {"id": "1806.09764", "submitter": "Zhiting Hu", "authors": "Zhiting Hu, Zichao Yang, Ruslan Salakhutdinov, Xiaodan Liang, Lianhui\n  Qin, Haoye Dong, Eric Xing", "title": "Deep Generative Models with Learnable Knowledge Constraints", "comments": "Neural Information Processing Systems (NeurIPS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The broad set of deep generative models (DGMs) has achieved remarkable\nadvances. However, it is often difficult to incorporate rich structured domain\nknowledge with the end-to-end DGMs. Posterior regularization (PR) offers a\nprincipled framework to impose structured constraints on probabilistic models,\nbut has limited applicability to the diverse DGMs that can lack a Bayesian\nformulation or even explicit density evaluation. PR also requires constraints\nto be fully specified a priori, which is impractical or suboptimal for complex\nknowledge with learnable uncertain parts. In this paper, we establish\nmathematical correspondence between PR and reinforcement learning (RL), and,\nbased on the connection, expand PR to learn constraints as the extrinsic reward\nin RL. The resulting algorithm is model-agnostic to apply to any DGMs, and is\nflexible to adapt arbitrary constraints with the model jointly. Experiments on\nhuman image generation and templated sentence generation show models with\nlearned knowledge constraints by our algorithm greatly improve over base\ngenerative models.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 02:31:35 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 02:10:48 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Hu", "Zhiting", ""], ["Yang", "Zichao", ""], ["Salakhutdinov", "Ruslan", ""], ["Liang", "Xiaodan", ""], ["Qin", "Lianhui", ""], ["Dong", "Haoye", ""], ["Xing", "Eric", ""]]}, {"id": "1806.09792", "submitter": "Dayiheng Liu", "authors": "Dayiheng Liu, Quan Guo, Wubo Li, Jiancheng Lv", "title": "A Multi-Modal Chinese Poetry Generation Model", "comments": "Accepted at the International Joint Conference on Neural Networks,\n  IJCNN, 2018", "journal-ref": null, "doi": "10.1109/IJCNN.2018.8489579", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies in sequence-to-sequence learning demonstrate that RNN\nencoder-decoder structure can successfully generate Chinese poetry. However,\nexisting methods can only generate poetry with a given first line or user's\nintent theme. In this paper, we proposed a three-stage multi-modal Chinese\npoetry generation approach. Given a picture, the first line, the title and the\nother lines of the poem are successively generated in three stages. According\nto the characteristics of Chinese poems, we propose a hierarchy-attention\nseq2seq model which can effectively capture character, phrase, and sentence\ninformation between contexts and improve the symmetry delivered in poems. In\naddition, the Latent Dirichlet allocation (LDA) model is utilized for title\ngeneration and improve the relevance of the whole poem and the title. Compared\nwith strong baseline, the experimental results demonstrate the effectiveness of\nour approach, using machine evaluations as well as human judgments.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 05:01:51 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Liu", "Dayiheng", ""], ["Guo", "Quan", ""], ["Li", "Wubo", ""], ["Lv", "Jiancheng", ""]]}, {"id": "1806.09827", "submitter": "Sim\\'on Roca-Sotelo", "authors": "Sim\\'on Roca-Sotelo and Jer\\'onimo Arenas-Garc\\'ia", "title": "Unveiling the semantic structure of text documents using paragraph-aware\n  Topic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classic Topic Models are built under the Bag Of Words assumption, in which\nword position is ignored for simplicity. Besides, symmetric priors are\ntypically used in most applications. In order to easily learn topics with\ndifferent properties among the same corpus, we propose a new line of work in\nwhich the paragraph structure is exploited. Our proposal is based on the\nfollowing assumption: in many text document corpora there are formal\nconstraints shared across all the collection, e.g. sections. When this\nassumption is satisfied, some paragraphs may be related to general concepts\nshared by all documents in the corpus, while others would contain the genuine\ndescription of documents. Assuming each paragraph can be semantically more\ngeneral, specific, or hybrid, we look for ways to measure this, transferring\nthis distinction to topics and being able to learn what we call specific and\ngeneral topics. Experiments show that this is a proper methodology to highlight\ncertain paragraphs in structured documents at the same time we learn\ninteresting and more diverse topics.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 07:50:37 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Roca-Sotelo", "Sim\u00f3n", ""], ["Arenas-Garc\u00eda", "Jer\u00f3nimo", ""]]}, {"id": "1806.09828", "submitter": "Qian Chen", "authors": "Qian Chen, Zhen-Hua Ling, Xiaodan Zhu", "title": "Enhancing Sentence Embedding with Generalized Pooling", "comments": "Accepted by COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pooling is an essential component of a wide variety of sentence\nrepresentation and embedding models. This paper explores generalized pooling\nmethods to enhance sentence embedding. We propose vector-based multi-head\nattention that includes the widely used max pooling, mean pooling, and scalar\nself-attention as special cases. The model benefits from properly designed\npenalization terms to reduce redundancy in multi-head attention. We evaluate\nthe proposed model on three different tasks: natural language inference (NLI),\nauthor profiling, and sentiment classification. The experiments show that the\nproposed model achieves significant improvement over strong\nsentence-encoding-based methods, resulting in state-of-the-art performances on\nfour datasets. The proposed approach can be easily implemented for more\nproblems than we discuss in this paper.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 07:50:46 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Chen", "Qian", ""], ["Ling", "Zhen-Hua", ""], ["Zhu", "Xiaodan", ""]]}, {"id": "1806.09835", "submitter": "Daniel Beck", "authors": "Daniel Beck, Gholamreza Haffari, Trevor Cohn", "title": "Graph-to-Sequence Learning using Gated Graph Neural Networks", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many NLP applications can be framed as a graph-to-sequence learning problem.\nPrevious work proposing neural architectures on this setting obtained promising\nresults compared to grammar-based approaches but still rely on linearisation\nheuristics and/or standard recurrent networks to achieve the best performance.\nIn this work, we propose a new model that encodes the full structural\ninformation contained in the graph. Our architecture couples the recently\nproposed Gated Graph Neural Networks with an input transformation that allows\nnodes and edges to have their own hidden representations, while tackling the\nparameter explosion problem present in previous work. Experimental results show\nthat our model outperforms strong baselines in generation from AMR graphs and\nsyntax-based neural machine translation.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 08:08:30 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Beck", "Daniel", ""], ["Haffari", "Gholamreza", ""], ["Cohn", "Trevor", ""]]}, {"id": "1806.09932", "submitter": "Mohamed Afify", "authors": "Mohamed Adel, Mohamed Afify and Akram Gaballah", "title": "Text-Independent Speaker Verification Based on Deep Neural Networks and\n  Segmental Dynamic Time Warping", "comments": "Submitted to SLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a new method for text-independent speaker\nverification that combines segmental dynamic time warping (SDTW) and the\nd-vector approach. The d-vectors, generated from a feed forward deep neural\nnetwork trained to distinguish between speakers, are used as features to\nperform alignment and hence calculate the overall distance between the\nenrolment and test utterances.We present results on the NIST 2008 data set for\nspeaker verification where the proposed method outperforms the conventional\ni-vector baseline with PLDA scores and outperforms d-vector approach with local\ndistances based on cosine and PLDA scores. Also score combination with the\ni-vector/PLDA baseline leads to significant gains over both methods.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 12:05:33 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Adel", "Mohamed", ""], ["Afify", "Mohamed", ""], ["Gaballah", "Akram", ""]]}, {"id": "1806.10090", "submitter": "Artyom Gadetsky", "authors": "Artyom Gadetsky, Ilya Yakubovskiy, Dmitry Vetrov", "title": "Conditional Generators of Words Definitions", "comments": "Accepted as a conference paper at ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore recently introduced definition modeling technique that provided\nthe tool for evaluation of different distributed vector representations of\nwords through modeling dictionary definitions of words. In this work, we study\nthe problem of word ambiguities in definition modeling and propose a possible\nsolution by employing latent variable modeling and soft attention mechanisms.\nOur quantitative and qualitative evaluation and analysis of the model shows\nthat taking into account words ambiguity and polysemy leads to performance\nimprovement.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 16:07:50 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Gadetsky", "Artyom", ""], ["Yakubovskiy", "Ilya", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1806.10201", "submitter": "Avirup Sil", "authors": "Gourab Kundu and Avirup Sil and Radu Florian and Wael Hamza", "title": "Neural Cross-Lingual Coreference Resolution and its Application to\n  Entity Linking", "comments": null, "journal-ref": "ACL 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an entity-centric neural cross-lingual coreference model that\nbuilds on multi-lingual embeddings and language-independent features. We\nperform both intrinsic and extrinsic evaluations of our model. In the intrinsic\nevaluation, we show that our model, when trained on English and tested on\nChinese and Spanish, achieves competitive results to the models trained\ndirectly on Chinese and Spanish respectively. In the extrinsic evaluation, we\nshow that our English model helps achieve superior entity linking accuracy on\nChinese and Spanish test sets than the top 2015 TAC system without using any\nannotated data from Chinese or Spanish.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 20:24:52 GMT"}], "update_date": "2018-06-28", "authors_parsed": [["Kundu", "Gourab", ""], ["Sil", "Avirup", ""], ["Florian", "Radu", ""], ["Hamza", "Wael", ""]]}, {"id": "1806.10215", "submitter": "Anirudh Raju", "authors": "Anirudh Raju, Behnam Hedayatnia, Linda Liu, Ankur Gandhe, Chandra\n  Khatri, Angeliki Metallinou, Anu Venkatesh, Ariya Rastrow", "title": "Contextual Language Model Adaptation for Conversational Agents", "comments": "Interspeech 2018 (accepted)", "journal-ref": "Proc. Interspeech 2018, 3333-3337", "doi": "10.21437/Interspeech.2018-1122", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical language models (LM) play a key role in Automatic Speech\nRecognition (ASR) systems used by conversational agents. These ASR systems\nshould provide a high accuracy under a variety of speaking styles, domains,\nvocabulary and argots. In this paper, we present a DNN-based method to adapt\nthe LM to each user-agent interaction based on generalized contextual\ninformation, by predicting an optimal, context-dependent set of LM\ninterpolation weights. We show that this framework for contextual adaptation\nprovides accuracy improvements under different possible mixture LM partitions\nthat are relevant for both (1) Goal-oriented conversational agents where it's\nnatural to partition the data by the requested application and for (2) Non-goal\noriented conversational agents where the data can be partitioned using topic\nlabels that come from predictions of a topic classifier. We obtain a relative\nWER improvement of 3% with a 1-pass decoding strategy and 6% in a 2-pass\ndecoding framework, over an unadapted model. We also show up to a 15% relative\nimprovement in recognizing named entities which is of significant value for\nconversational ASR systems.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 21:17:09 GMT"}, {"version": "v2", "created": "Thu, 28 Jun 2018 05:04:40 GMT"}, {"version": "v3", "created": "Fri, 6 Jul 2018 00:44:47 GMT"}, {"version": "v4", "created": "Tue, 31 Jul 2018 04:05:01 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Raju", "Anirudh", ""], ["Hedayatnia", "Behnam", ""], ["Liu", "Linda", ""], ["Gandhe", "Ankur", ""], ["Khatri", "Chandra", ""], ["Metallinou", "Angeliki", ""], ["Venkatesh", "Anu", ""], ["Rastrow", "Ariya", ""]]}, {"id": "1806.10306", "submitter": "Yerbolat Khassanov", "authors": "Yerbolat Khassanov and Eng Siong Chng", "title": "Unsupervised and Efficient Vocabulary Expansion for Recurrent Neural\n  Network Language Models in ASR", "comments": "5 pages, 1 figure, accepted at INTERSPEECH 2018", "journal-ref": null, "doi": "10.21437/Interspeech.2018-1021", "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In automatic speech recognition (ASR) systems, recurrent neural network\nlanguage models (RNNLM) are used to rescore a word lattice or N-best hypotheses\nlist. Due to the expensive training, the RNNLM's vocabulary set accommodates\nonly small shortlist of most frequent words. This leads to suboptimal\nperformance if an input speech contains many out-of-shortlist (OOS) words. An\neffective solution is to increase the shortlist size and retrain the entire\nnetwork which is highly inefficient. Therefore, we propose an efficient method\nto expand the shortlist set of a pretrained RNNLM without incurring expensive\nretraining and using additional training data. Our method exploits the\nstructure of RNNLM which can be decoupled into three parts: input projection\nlayer, middle layers, and output projection layer. Specifically, our method\nexpands the word embedding matrices in projection layers and keeps the middle\nlayers unchanged. In this approach, the functionality of the pretrained RNNLM\nwill be correctly maintained as long as OOS words are properly modeled in two\nembedding spaces. We propose to model the OOS words by borrowing linguistic\nknowledge from appropriate in-shortlist words. Additionally, we propose to\ngenerate the list of OOS words to expand vocabulary in unsupervised manner by\nautomatically extracting them from ASR output.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2018 05:50:05 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Khassanov", "Yerbolat", ""], ["Chng", "Eng Siong", ""]]}, {"id": "1806.10348", "submitter": "Haoyue Shi", "authors": "Haoyue Shi, Jiayuan Mao, Tete Xiao, Yuning Jiang, Jian Sun", "title": "Learning Visually-Grounded Semantics from Contrastive Adversarial\n  Samples", "comments": "To Appear at COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of grounding distributional representations of texts on\nthe visual domain, namely visual-semantic embeddings (VSE for short). Begin\nwith an insightful adversarial attack on VSE embeddings, we show the limitation\nof current frameworks and image-text datasets (e.g., MS-COCO) both\nquantitatively and qualitatively. The large gap between the number of possible\nconstitutions of real-world semantics and the size of parallel data, to a large\nextent, restricts the model to establish the link between textual semantics and\nvisual concepts. We alleviate this problem by augmenting the MS-COCO image\ncaptioning datasets with textual contrastive adversarial samples. These samples\nare synthesized using linguistic rules and the WordNet knowledge base. The\nconstruction procedure is both syntax- and semantics-aware. The samples enforce\nthe model to ground learned embeddings to concrete concepts within the image.\nThis simple but powerful technique brings a noticeable improvement over the\nbaselines on a diverse set of downstream tasks, in addition to defending\nknown-type adversarial attacks. We release the codes at\nhttps://github.com/ExplorerFreda/VSE-C.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2018 08:58:57 GMT"}], "update_date": "2018-06-28", "authors_parsed": [["Shi", "Haoyue", ""], ["Mao", "Jiayuan", ""], ["Xiao", "Tete", ""], ["Jiang", "Yuning", ""], ["Sun", "Jian", ""]]}, {"id": "1806.10478", "submitter": "Tommaso Soru", "authors": "Tommaso Soru, Edgard Marx, Andr\\'e Valdestilhas, Diego Esteves, Diego\n  Moussallem, Gustavo Publio", "title": "Neural Machine Translation for Query Construction and Composition", "comments": "ICML workshop on Neural Abstract Machines & Program Induction v2\n  (NAMPI), extended abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on question answering with knowledge base has recently seen an\nincreasing use of deep architectures. In this extended abstract, we study the\napplication of the neural machine translation paradigm for question parsing. We\nemploy a sequence-to-sequence model to learn graph patterns in the SPARQL graph\nquery language and their compositions. Instead of inducing the programs through\nquestion-answer pairs, we expect a semi-supervised approach, where alignments\nbetween questions and queries are built through templates. We argue that the\ncoverage of language utterances can be expanded using late notable works in\nnatural language generation.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2018 13:40:49 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2018 14:25:46 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Soru", "Tommaso", ""], ["Marx", "Edgard", ""], ["Valdestilhas", "Andr\u00e9", ""], ["Esteves", "Diego", ""], ["Moussallem", "Diego", ""], ["Publio", "Gustavo", ""]]}, {"id": "1806.10654", "submitter": "Alexander Koller", "authors": "Stefan Gr\\\"unewald and Sophie Henning and Alexander Koller", "title": "Generalized chart constraints for efficient PCFG and TAG parsing", "comments": null, "journal-ref": "Proceedings of ACL 2018 (Short Papers)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chart constraints, which specify at which string positions a constituent may\nbegin or end, have been shown to speed up chart parsers for PCFGs. We\ngeneralize chart constraints to more expressive grammar formalisms and describe\na neural tagger which predicts chart constraints at very high precision. Our\nconstraints accelerate both PCFG and TAG parsing, and combine effectively with\nother pruning techniques (coarse-to-fine and supertagging) for an overall\nspeedup of two orders of magnitude, while improving accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2018 19:36:05 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Gr\u00fcnewald", "Stefan", ""], ["Henning", "Sophie", ""], ["Koller", "Alexander", ""]]}, {"id": "1806.10722", "submitter": "Allen Nie", "authors": "Allen Nie, Ashley Zehnder, Rodney L. Page, Arturo L. Pineda, Manuel A.\n  Rivas, Carlos D. Bustamante, James Zou", "title": "DeepTag: inferring all-cause diagnoses from clinical notes in\n  under-resourced medical domain", "comments": "17 pages, 6 figures. Updated the text for clarity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large scale veterinary clinical records can become a powerful resource for\npatient care and research. However, clinicians lack the time and resource to\nannotate patient records with standard medical diagnostic codes and most\nveterinary visits are captured in free text notes. The lack of standard coding\nmakes it challenging to use the clinical data to improve patient care. It is\nalso a major impediment to cross-species translational research, which relies\non the ability to accurately identify patient cohorts with specific diagnostic\ncriteria in humans and animals. In order to reduce the coding burden for\nveterinary clinical practice and aid translational research, we have developed\na deep learning algorithm, DeepTag, which automatically infers diagnostic codes\nfrom veterinary free text notes. DeepTag is trained on a newly curated dataset\nof 112,558 veterinary notes manually annotated by experts. DeepTag extends\nmulti-task LSTM with an improved hierarchical objective that captures the\nsemantic structures between diseases. To foster human-machine collaboration,\nDeepTag also learns to abstain in examples when it is uncertain and defers them\nto human experts, resulting in improved performance. DeepTag accurately infers\ndisease codes from free text even in challenging cross-hospital settings where\nthe text comes from different clinical settings than the ones used for\ntraining. It enables automated disease annotation across a broad range of\nclinical diagnoses with minimal pre-processing. The technical framework in this\nwork can be applied in other medical domains that currently lack medical coding\nresources.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2018 00:45:04 GMT"}, {"version": "v2", "created": "Mon, 3 Sep 2018 18:33:06 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Nie", "Allen", ""], ["Zehnder", "Ashley", ""], ["Page", "Rodney L.", ""], ["Pineda", "Arturo L.", ""], ["Rivas", "Manuel A.", ""], ["Bustamante", "Carlos D.", ""], ["Zou", "James", ""]]}, {"id": "1806.10771", "submitter": "Andrew Stuart Matteson", "authors": "Andrew Matteson, Chanhee Lee, Young-Bum Kim, Heuiseok Lim", "title": "Rich Character-Level Information for Korean Morphological Analysis and\n  Part-of-Speech Tagging", "comments": "10 pages, 6 figures, accepted as a conference paper at COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to the fact that Korean is a highly agglutinative, character-rich\nlanguage, previous work on Korean morphological analysis typically employs the\nuse of sub-character features known as graphemes or otherwise utilizes\ncomprehensive prior linguistic knowledge (i.e., a dictionary of known\nmorphological transformation forms, or actions). These models have been created\nwith the assumption that character-level, dictionary-less morphological\nanalysis was intractable due to the number of actions required. We present, in\nthis study, a multi-stage action-based model that can perform morphological\ntransformation and part-of-speech tagging using arbitrary units of input and\napply it to the case of character-level Korean morphological analysis. Among\nmodels that do not employ prior linguistic knowledge, we achieve\nstate-of-the-art word and sentence-level tagging accuracy with the Sejong\nKorean corpus using our proposed data-driven Bi-LSTM model.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2018 05:09:38 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Matteson", "Andrew", ""], ["Lee", "Chanhee", ""], ["Kim", "Young-Bum", ""], ["Lim", "Heuiseok", ""]]}, {"id": "1806.11099", "submitter": "Taylor Arnold", "authors": "Taylor Arnold, Nicolas Ballier, Thomas Gaillat, Paula Liss\\`on", "title": "Predicting CEFRL levels in learner English on the basis of metrics and\n  full texts", "comments": "Conference paper presented at Conf\\'erence sur l'Apprentissage\n  Automatique (CAp) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyses the contribution of language metrics and, potentially, of\nlinguistic structures, to classify French learners of English according to\nlevels of the Common European Framework of Reference for Languages (CEFRL). The\npurpose is to build a model for the prediction of learner levels as a function\nof language complexity features. We used the EFCAMDAT corpus, a database of one\nmillion written assignments by learners. After applying language complexity\nmetrics on the texts, we built a representation matching the language metrics\nof the texts to their assigned CEFRL levels. Lexical and syntactic metrics were\ncomputed with LCA, LSA, and koRpus. Several supervised learning models were\nbuilt by using Gradient Boosted Trees and Keras Neural Network methods and by\ncontrasting pairs of CEFRL levels. Results show that it is possible to\nimplement pairwise distinctions, especially for levels ranging from A1 to B1\n(A1=>A2: 0.916 AUC and A2=>B1: 0.904 AUC). Model explanation reveals\nsignificant linguistic features for the predictiveness in the corpus. Word\ntokens and word types appear to play a significant role in determining levels.\nThis shows that levels are highly dependent on specific semantic profiles.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2018 17:42:54 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Arnold", "Taylor", ""], ["Ballier", "Nicolas", ""], ["Gaillat", "Thomas", ""], ["Liss\u00f2n", "Paula", ""]]}, {"id": "1806.11183", "submitter": "Taylor Arnold", "authors": "Taylor Arnold and Lauren Tilton", "title": "Cross-Discourse and Multilingual Exploration of Textual Corpora with the\n  DualNeighbors Algorithm", "comments": "Chosen for oral presentation at 2nd Joint SIGHUM Workshop on\n  Computational Linguistics for Cultural Heritage, Social Sciences, Humanities\n  and Literature (LaTeCH-CLfL 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Word choice is dependent on the cultural context of writers and their\nsubjects. Different words are used to describe similar actions, objects, and\nfeatures based on factors such as class, race, gender, geography and political\naffinity. Exploratory techniques based on locating and counting words may,\ntherefore, lead to conclusions that reinforce culturally inflected boundaries.\nWe offer a new method, the DualNeighbors algorithm, for linking thematically\nsimilar documents both within and across discursive and linguistic barriers to\nreveal cross-cultural connections. Qualitative and quantitative evaluations of\nthis technique are shown as applied to two cultural datasets of interest to\nresearchers across the humanities and social sciences. An open-source\nimplementation of the DualNeighbors algorithm is provided to assist in its\napplication.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2018 20:55:18 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Arnold", "Taylor", ""], ["Tilton", "Lauren", ""]]}, {"id": "1806.11249", "submitter": "Fandong Meng", "authors": "Fandong Meng, Zhaopeng Tu, Yong Cheng, Haiyang Wu, Junjie Zhai, Yuekui\n  Yang, Di Wang", "title": "Neural Machine Translation with Key-Value Memory-Augmented Attention", "comments": "Accepted at IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although attention-based Neural Machine Translation (NMT) has achieved\nremarkable progress in recent years, it still suffers from issues of repeating\nand dropping translations. To alleviate these issues, we propose a novel\nkey-value memory-augmented attention model for NMT, called KVMEMATT.\nSpecifically, we maintain a timely updated keymemory to keep track of attention\nhistory and a fixed value-memory to store the representation of source sentence\nthroughout the whole translation process. Via nontrivial transformations and\niterative interactions between the two memories, the decoder focuses on more\nappropriate source word(s) for predicting the next target word at each decoding\nstep, therefore can improve the adequacy of translations. Experimental results\non Chinese=>English and WMT17 German<=>English translation tasks demonstrate\nthe superiority of the proposed model.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 02:06:00 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Meng", "Fandong", ""], ["Tu", "Zhaopeng", ""], ["Cheng", "Yong", ""], ["Wu", "Haiyang", ""], ["Zhai", "Junjie", ""], ["Yang", "Yuekui", ""], ["Wang", "Di", ""]]}, {"id": "1806.11316", "submitter": "Oluwaseun Ajao", "authors": "Oluwaseun Ajao, Deepayan Bhowmik and Shahrzad Zargari", "title": "Fake News Identification on Twitter with Hybrid CNN and RNN Models", "comments": "5 Pages", "journal-ref": "Oluwaseun Ajao, Deepayan Bhowmik, and Shahrzad Zargari. 2018. Fake\n  News Identification on Twitter with Hybrid CNN and RNN Models. In Proceedings\n  of the International Conference on Social Media & Society, Copenhagen,\n  Denmark (SMSociety)", "doi": "10.1145/3217804.3217917", "report-no": "Jul 2018", "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem associated with the propagation of fake news continues to grow at\nan alarming scale. This trend has generated much interest from politics to\nacademia and industry alike. We propose a framework that detects and classifies\nfake news messages from Twitter posts using hybrid of convolutional neural\nnetworks and long-short term recurrent neural network models. The proposed work\nusing this deep learning approach achieves 82% accuracy. Our approach\nintuitively identifies relevant features associated with fake news stories\nwithout previous knowledge of the domain.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 09:36:46 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Ajao", "Oluwaseun", ""], ["Bhowmik", "Deepayan", ""], ["Zargari", "Shahrzad", ""]]}, {"id": "1806.11322", "submitter": "Nicholas Asher", "authors": "Nicholas Asher and Soumya Paul", "title": "Bias in Semantic and Discourse Interpretation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show how game-theoretic work on conversation combined with\na theory of discourse structure provides a framework for studying interpretive\nbias. Interpretive bias is an essential feature of learning and understanding\nbut also something that can be used to pervert or subvert the truth. The\nframework we develop here provides tools for understanding and analyzing the\nrange of interpretive biases and the factors that contribute to them.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 09:51:26 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Asher", "Nicholas", ""], ["Paul", "Soumya", ""]]}, {"id": "1806.11420", "submitter": "Chandrakant Bothe", "authors": "Chandrakant Bothe, Sven Magg, Cornelius Weber, Stefan Wermter", "title": "Discourse-Wizard: Discovering Deep Discourse Structure in your\n  Conversation with RNNs", "comments": "Submitted to EMNLP 2018: System Demonstrations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken language understanding is one of the key factors in a dialogue system,\nand a context in a conversation plays an important role to understand the\ncurrent utterance. In this work, we demonstrate the importance of context\nwithin the dialogue for neural network models through an online web interface\nlive demo. We developed two different neural models: a model that does not use\ncontext and a context-based model. The no-context model classifies dialogue\nacts at an utterance-level whereas the context-based model takes some preceding\nutterances into account. We make these trained neural models available as a\nlive demo called Discourse-Wizard using a modular server architecture. The live\ndemo provides an easy to use interface for conversational analysis and for\ndiscovering deep discourse structures in a conversation.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 14:02:04 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Bothe", "Chandrakant", ""], ["Magg", "Sven", ""], ["Weber", "Cornelius", ""], ["Wermter", "Stefan", ""]]}, {"id": "1806.11432", "submitter": "Richard Diehl Martinez", "authors": "Richard Diehl Martinez, John Kaleialoha Kamalu", "title": "Using General Adversarial Networks for Marketing: A Case Study of Airbnb", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we examine the use case of general adversarial networks (GANs)\nin the field of marketing. In particular, we analyze how GAN models can\nreplicate text patterns from successful product listings on Airbnb, a\npeer-to-peer online market for short-term apartment rentals. To do so, we\ndefine the Diehl-Martinez-Kamalu (DMK) loss function as a new class of\nfunctions that forces the model's generated output to include a set of\nuser-defined keywords. This allows the general adversarial network to recommend\na way of rewording the phrasing of a listing description to increase the\nlikelihood that it is booked. Although we tailor our analysis to Airbnb data,\nwe believe this framework establishes a more general model for how generative\nalgorithms can be used to produce text samples for the purposes of marketing.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 14:19:20 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Martinez", "Richard Diehl", ""], ["Kamalu", "John Kaleialoha", ""]]}, {"id": "1806.11461", "submitter": "Matthew Roddy", "authors": "Matthew Roddy, Gabriel Skantze, Naomi Harte", "title": "Investigating Speech Features for Continuous Turn-Taking Prediction\n  Using LSTMs", "comments": "Accepted for Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For spoken dialog systems to conduct fluid conversational interactions with\nusers, the systems must be sensitive to turn-taking cues produced by a user.\nModels should be designed so that effective decisions can be made as to when it\nis appropriate, or not, for the system to speak. Traditional end-of-turn\nmodels, where decisions are made at utterance end-points, are limited in their\nability to model fast turn-switches and overlap. A more flexible approach is to\nmodel turn-taking in a continuous manner using RNNs, where the system predicts\nspeech probability scores for discrete frames within a future window. The\ncontinuous predictions represent generalized turn-taking behaviors observed in\nthe training data and can be applied to make decisions that are not just\nlimited to end-of-turn detection. In this paper, we investigate optimal\nspeech-related feature sets for making predictions at pauses and overlaps in\nconversation. We find that while traditional acoustic features perform well,\npart-of-speech features generally perform worse than word features. We show\nthat our current models outperform previously reported baselines.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 15:07:17 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Roddy", "Matthew", ""], ["Skantze", "Gabriel", ""], ["Harte", "Naomi", ""]]}, {"id": "1806.11525", "submitter": "Eric Yuan", "authors": "Xingdi Yuan, Marc-Alexandre C\\^ot\\'e, Alessandro Sordoni, Romain\n  Laroche, Remi Tachet des Combes, Matthew Hausknecht, Adam Trischler", "title": "Counting to Explore and Generalize in Text-based Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a recurrent RL agent with an episodic exploration mechanism that\nhelps discovering good policies in text-based game environments. We show\npromising results on a set of generated text-based games of varying difficulty\nwhere the goal is to collect a coin located at the end of a chain of rooms. In\ncontrast to previous text-based RL approaches, we observe that our agent learns\npolicies that generalize to unseen games of greater difficulty.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 16:40:29 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 03:17:42 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Yuan", "Xingdi", ""], ["C\u00f4t\u00e9", "Marc-Alexandre", ""], ["Sordoni", "Alessandro", ""], ["Laroche", "Romain", ""], ["Combes", "Remi Tachet des", ""], ["Hausknecht", "Matthew", ""], ["Trischler", "Adam", ""]]}, {"id": "1806.11532", "submitter": "Marc-Alexandre C\\^ot\\'e", "authors": "Marc-Alexandre C\\^ot\\'e, \\'Akos K\\'ad\\'ar, Xingdi Yuan, Ben Kybartas,\n  Tavian Barnes, Emery Fine, James Moore, Ruo Yu Tao, Matthew Hausknecht, Layla\n  El Asri, Mahmoud Adada, Wendy Tay, Adam Trischler", "title": "TextWorld: A Learning Environment for Text-based Games", "comments": "Presented at the Computer Games Workshop at IJCAI 2018, Stockholm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce TextWorld, a sandbox learning environment for the training and\nevaluation of RL agents on text-based games. TextWorld is a Python library that\nhandles interactive play-through of text games, as well as backend functions\nlike state tracking and reward assignment. It comes with a curated list of\ngames whose features and challenges we have analyzed. More significantly, it\nenables users to handcraft or automatically generate new games. Its generative\nmechanisms give precise control over the difficulty, scope, and language of\nconstructed games, and can be used to relax challenges inherent to commercial\ntext games like partial observability and sparse rewards. By generating sets of\nvaried but similar games, TextWorld can also be used to study generalization\nand transfer learning. We cast text-based games in the Reinforcement Learning\nformalism, use our framework to develop a set of benchmark games, and evaluate\nseveral baseline agents on this set and the curated list.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 16:56:07 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 14:57:21 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["C\u00f4t\u00e9", "Marc-Alexandre", ""], ["K\u00e1d\u00e1r", "\u00c1kos", ""], ["Yuan", "Xingdi", ""], ["Kybartas", "Ben", ""], ["Barnes", "Tavian", ""], ["Fine", "Emery", ""], ["Moore", "James", ""], ["Tao", "Ruo Yu", ""], ["Hausknecht", "Matthew", ""], ["Asri", "Layla El", ""], ["Adada", "Mahmoud", ""], ["Tay", "Wendy", ""], ["Trischler", "Adam", ""]]}]