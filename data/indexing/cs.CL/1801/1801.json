[{"id": "1801.00049", "submitter": "Ama\\c{c} Herda\\u{g}delen", "authors": "Ama\\c{c} Herda\\u{g}delen", "title": "Personal Names in Modern Turkey", "comments": "in Turkish", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyzed the most common 5000 male and 5000 female Turkish names based on\ntheir etymological, morphological, and semantic attributes. The name statistics\nare based on all Turkish citizens who were alive in 2014 and they cover 90% of\nall population. To the best of our knowledge, this study is the most\ncomprehensive data-driven analysis of Turkish personal names. Female names have\na greater diversity than male names (e.g., top 15 male names cover 25% of the\nmale population, whereas top 28 female names cover 25% of the female\npopulation). Despite their diversity, female names exhibit predictable\npatterns. For example, certain roots such as g\\\"ul and nar (rose and\npomegranate/red, respectively) are used to generate hundreds of unique female\nnames. Turkish personal names have their origins mainly in Arabic, followed by\nTurkish and Persian. We computed overall frequencies of names according to\nbroad semantic themes that were identified in previous studies. We found that\nforeign-origin names such as olga and khaled, pastoral names such as ya\\u{g}mur\nand deniz (rain and sea, respectively), and names based on fruits and plants\nsuch as filiz and menek\\c{s}e (sprout and violet, respectively) are more\nfrequently observed among females. Among males, names based on animals such as\narslan and yunus (lion and dolphin, respectively) and names based on famous\nand/or historical figures such as mustafa kemal and o\\u{g}uz ka\\u{g}an (founder\nof the Turkish Republic and the founder of the Turks in Turkish mythology,\nrespectively) are observed more frequently.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 22:21:39 GMT"}, {"version": "v2", "created": "Sun, 14 Jan 2018 23:34:01 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Herda\u011fdelen", "Ama\u00e7", ""]]}, {"id": "1801.00059", "submitter": "Kyu Han", "authors": "Kyu J. Han, Akshay Chandrashekaran, Jungsuk Kim, Ian Lane", "title": "The CAPIO 2017 Conversational Speech Recognition System", "comments": "8 page, 3 figures, 8 tables; extra experimental results added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show how we have achieved the state-of-the-art performance\non the industry-standard NIST 2000 Hub5 English evaluation set. We explore\ndensely connected LSTMs, inspired by the densely connected convolutional\nnetworks recently introduced for image classification tasks. We also propose an\nacoustic model adaptation scheme that simply averages the parameters of a seed\nneural network acoustic model and its adapted version. This method was applied\nwith the CallHome training corpus and improved individual system performances\nby on average 6.1% (relative) against the CallHome portion of the evaluation\nset with no performance loss on the Switchboard portion. With RNN-LM rescoring\nand lattice combination on the 5 systems trained across three different phone\nsets, our 2017 speech recognition system has obtained 5.0% and 9.1% on\nSwitchboard and CallHome, respectively, both of which are the best word error\nrates reported thus far. According to IBM in their latest work to compare human\nand machine transcriptions, our reported Switchboard word error rate can be\nconsidered to surpass the human parity (5.1%) of transcribing conversational\ntelephone speech.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 23:31:05 GMT"}, {"version": "v2", "created": "Tue, 10 Apr 2018 00:17:37 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Han", "Kyu J.", ""], ["Chandrashekaran", "Akshay", ""], ["Kim", "Jungsuk", ""], ["Lane", "Ian", ""]]}, {"id": "1801.00076", "submitter": "Huilin Gao", "authors": "Tong Guo, Huilin Gao", "title": "Bidirectional Attention for SQL Generation", "comments": "7 pages 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating structural query language (SQL) queries from natural language is a\nlong-standing open problem. Answering a natural language question about a\ndatabase table requires modeling complex interactions between the columns of\nthe table and the question. In this paper, we apply the synthesizing approach\nto solve this problem. Based on the structure of SQL queries, we break down the\nmodel to three sub-modules and design specific deep neural networks for each of\nthem. Taking inspiration from the similar machine reading task, we employ the\nbidirectional attention mechanisms and character-level embedding with\nconvolutional neural networks (CNNs) to improve the result. Experimental\nevaluations show that our model achieves the state-of-the-art results in\nWikiSQL dataset.\n", "versions": [{"version": "v1", "created": "Sat, 30 Dec 2017 02:38:07 GMT"}, {"version": "v2", "created": "Tue, 30 Jan 2018 09:17:33 GMT"}, {"version": "v3", "created": "Wed, 31 Jan 2018 03:34:45 GMT"}, {"version": "v4", "created": "Sat, 28 Apr 2018 01:41:13 GMT"}, {"version": "v5", "created": "Fri, 18 May 2018 02:57:37 GMT"}, {"version": "v6", "created": "Thu, 21 Jun 2018 01:30:09 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Guo", "Tong", ""], ["Gao", "Huilin", ""]]}, {"id": "1801.00102", "submitter": "Yi Tay", "authors": "Yi Tay, Luu Anh Tuan, Siu Cheung Hui", "title": "Compare, Compress and Propagate: Enhancing Neural Architectures with\n  Alignment Factorization for Natural Language Inference", "comments": "EMNLP 2018 CRC and Update CAFE + ELMo result on SNLI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new deep learning architecture for Natural Language\nInference (NLI). Firstly, we introduce a new architecture where alignment pairs\nare compared, compressed and then propagated to upper layers for enhanced\nrepresentation learning. Secondly, we adopt factorization layers for efficient\nand expressive compression of alignment vectors into scalar features, which are\nthen used to augment the base word representations. The design of our approach\nis aimed to be conceptually simple, compact and yet powerful. We conduct\nexperiments on three popular benchmarks, SNLI, MultiNLI and SciTail, achieving\ncompetitive performance on all. A lightweight parameterization of our model\nalso enjoys a $\\approx 3$ times reduction in parameter size compared to the\nexisting state-of-the-art models, e.g., ESIM and DIIN, while maintaining\ncompetitive performance. Additionally, visual analysis shows that our\npropagated features are highly interpretable.\n", "versions": [{"version": "v1", "created": "Sat, 30 Dec 2017 08:54:16 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 14:38:47 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Tay", "Yi", ""], ["Tuan", "Luu Anh", ""], ["Hui", "Siu Cheung", ""]]}, {"id": "1801.00168", "submitter": "Ramon Ferrer i Cancho", "authors": "Ramon Ferrer-i-Cancho and Michael S. Vitevitch", "title": "The origins of Zipf's meaning-frequency law", "comments": null, "journal-ref": "Journal of the American Society for Information Science and\n  Technology 69 (11), 1369-1379 (2018)", "doi": "10.1002/asi.24057", "report-no": null, "categories": "cs.CL cs.IT math.IT physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In his pioneering research, G. K. Zipf observed that more frequent words tend\nto have more meanings, and showed that the number of meanings of a word grows\nas the square root of its frequency. He derived this relationship from two\nassumptions: that words follow Zipf's law for word frequencies (a power law\ndependency between frequency and rank) and Zipf's law of meaning distribution\n(a power law dependency between number of meanings and rank). Here we show that\na single assumption on the joint probability of a word and a meaning suffices\nto infer Zipf's meaning-frequency law or relaxed versions. Interestingly, this\nassumption can be justified as the outcome of a biased random walk in the\nprocess of mental exploration.\n", "versions": [{"version": "v1", "created": "Sat, 30 Dec 2017 17:59:41 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Ferrer-i-Cancho", "Ramon", ""], ["Vitevitch", "Michael S.", ""]]}, {"id": "1801.00215", "submitter": "Simon Stiebellehner", "authors": "Simon Stiebellehner, Jun Wang, Shuai Yuan", "title": "Learning Continuous User Representations through Hybrid Filtering with\n  doc2vec", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Players in the online ad ecosystem are struggling to acquire the user data\nrequired for precise targeting. Audience look-alike modeling has the potential\nto alleviate this issue, but models' performance strongly depends on quantity\nand quality of available data. In order to maximize the predictive performance\nof our look-alike modeling algorithms, we propose two novel hybrid filtering\ntechniques that utilize the recent neural probabilistic language model\nalgorithm doc2vec. We apply these methods to data from a large mobile ad\nexchange and additional app metadata acquired from the Apple App store and\nGoogle Play store. First, we model mobile app users through their app usage\nhistories and app descriptions (user2vec). Second, we introduce context\nawareness to that model by incorporating additional user and app-related\nmetadata in model training (context2vec). Our findings are threefold: (1) the\nquality of recommendations provided by user2vec is notably higher than current\nstate-of-the-art techniques. (2) User representations generated through hybrid\nfiltering using doc2vec prove to be highly valuable features in supervised\nmachine learning models for look-alike modeling. This represents the first\napplication of hybrid filtering user models using neural probabilistic language\nmodels, specifically doc2vec, in look-alike modeling. (3) Incorporating context\nmetadata in the doc2vec model training process to introduce context awareness\nhas positive effects on performance and is superior to directly including the\ndata as features in the downstream supervised models.\n", "versions": [{"version": "v1", "created": "Sun, 31 Dec 2017 00:51:56 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Stiebellehner", "Simon", ""], ["Wang", "Jun", ""], ["Yuan", "Shuai", ""]]}, {"id": "1801.00254", "submitter": "Youngsam Kim", "authors": "Youngsam Kim, Hyopil Shin", "title": "A New Approach for Measuring Sentiment Orientation based on\n  Multi-Dimensional Vector Space", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study implements a vector space model approach to measure the sentiment\norientations of words. Two representative vectors for positive/negative\npolarity are constructed using high-dimensional vec-tor space in both an\nunsupervised and a semi-supervised manner. A sentiment ori-entation value per\nword is determined by taking the difference between the cosine distances\nagainst the two reference vec-tors. These two conditions (unsupervised and\nsemi-supervised) are compared against an existing unsupervised method (Turney,\n2002). As a result of our experi-ment, we demonstrate that this novel ap-proach\nsignificantly outperforms the pre-vious unsupervised approach and is more\npractical and data efficient as well.\n", "versions": [{"version": "v1", "created": "Sun, 31 Dec 2017 08:44:51 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Kim", "Youngsam", ""], ["Shin", "Hyopil", ""]]}, {"id": "1801.00388", "submitter": "Walid Shalaby", "authors": "Walid Shalaby, Wlodek Zadrozny, and Hongxia Jin", "title": "Beyond Word Embeddings: Learning Entity and Concept Representations from\n  Large Scale Knowledge Bases", "comments": "arXiv admin note: text overlap with arXiv:1702.03342", "journal-ref": "Inf Retrieval J (2018)", "doi": "10.1007/s10791-018-9340-3", "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text representations using neural word embeddings have proven effective in\nmany NLP applications. Recent researches adapt the traditional word embedding\nmodels to learn vectors of multiword expressions (concepts/entities). However,\nthese methods are limited to textual knowledge bases (e.g., Wikipedia). In this\npaper, we propose a novel and simple technique for integrating the knowledge\nabout concepts from two large scale knowledge bases of different structure\n(Wikipedia and Probase) in order to learn concept representations. We adapt the\nefficient skip-gram model to seamlessly learn from the knowledge in Wikipedia\ntext and Probase concept graph. We evaluate our concept embedding models on two\ntasks: (1) analogical reasoning, where we achieve a state-of-the-art\nperformance of 91% on semantic analogies, (2) concept categorization, where we\nachieve a state-of-the-art performance on two benchmark datasets achieving\ncategorization accuracy of 100% on one and 98% on the other. Additionally, we\npresent a case study to evaluate our model on unsupervised argument type\nidentification for neural semantic parsing. We demonstrate the competitive\naccuracy of our unsupervised method and its ability to better generalize to out\nof vocabulary entity mentions compared to the tedious and error prone methods\nwhich depend on gazetteers and regular expressions.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jan 2018 03:43:30 GMT"}, {"version": "v2", "created": "Thu, 30 Aug 2018 21:54:56 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Shalaby", "Walid", ""], ["Zadrozny", "Wlodek", ""], ["Jin", "Hongxia", ""]]}, {"id": "1801.00409", "submitter": "Haris Bin Zia", "authors": "Haris Bin Zia, Agha Ali Raza, Awais Athar", "title": "PronouncUR: An Urdu Pronunciation Lexicon Generator", "comments": "5 pages, LREC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art speech recognition systems rely heavily on three basic\ncomponents: an acoustic model, a pronunciation lexicon and a language model. To\nbuild these components, a researcher needs linguistic as well as technical\nexpertise, which is a barrier in low-resource domains. Techniques to construct\nthese three components without having expert domain knowledge are in great\ndemand. Urdu, despite having millions of speakers all over the world, is a\nlow-resource language in terms of standard publically available linguistic\nresources. In this paper, we present a grapheme-to-phoneme conversion tool for\nUrdu that generates a pronunciation lexicon in a form suitable for use with\nspeech recognition systems from a list of Urdu words. The tool predicts the\npronunciation of words using a LSTM-based model trained on a handcrafted expert\nlexicon of around 39,000 words and shows an accuracy of 64% upon internal\nevaluation. For external evaluation on a speech recognition task, we obtain a\nword error rate comparable to one achieved using a fully handcrafted expert\nlexicon.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jan 2018 07:54:09 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2018 17:57:03 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Zia", "Haris Bin", ""], ["Raza", "Agha Ali", ""], ["Athar", "Awais", ""]]}, {"id": "1801.00428", "submitter": "Rahul Aralikatte", "authors": "Rahul Aralikatte, Neelamadhav Gantayat, Naveen Panwar, Anush Sankaran,\n  Senthil Mani", "title": "Sanskrit Sandhi Splitting using seq2(seq)^2", "comments": "Accepted in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Sanskrit, small words (morphemes) are combined to form compound words\nthrough a process known as Sandhi. Sandhi splitting is the process of splitting\na given compound word into its constituent morphemes. Although rules governing\nword splitting exists in the language, it is highly challenging to identify the\nlocation of the splits in a compound word. Though existing Sandhi splitting\nsystems incorporate these pre-defined splitting rules, they have a low accuracy\nas the same compound word might be broken down in multiple ways to provide\nsyntactically correct splits.\n  In this research, we propose a novel deep learning architecture called Double\nDecoder RNN (DD-RNN), which (i) predicts the location of the split(s) with 95%\naccuracy, and (ii) predicts the constituent words (learning the Sandhi\nsplitting rules) with 79.5% accuracy, outperforming the state-of-art by 20%.\nAdditionally, we show the generalization capability of our deep learning model,\nby showing competitive results in the problem of Chinese word segmentation, as\nwell.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jan 2018 11:27:05 GMT"}, {"version": "v2", "created": "Mon, 8 Jan 2018 07:46:12 GMT"}, {"version": "v3", "created": "Mon, 27 Aug 2018 07:19:25 GMT"}, {"version": "v4", "created": "Mon, 15 Jul 2019 13:25:29 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Aralikatte", "Rahul", ""], ["Gantayat", "Neelamadhav", ""], ["Panwar", "Naveen", ""], ["Sankaran", "Anush", ""], ["Mani", "Senthil", ""]]}, {"id": "1801.00453", "submitter": "Alex James Dr", "authors": "Akzharkyn Izbassarova, Aidana Irmanova, A. P. James", "title": "Automated rating of recorded classroom presentations using speech\n  analysis in kazakh", "comments": null, "journal-ref": "2017 International Conference on Advances in Computing,\n  Communications and Informatics (ICACCI), Udupi, 2017, pp. 393-397", "doi": "10.1109/ICACCI.2017.8125872", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective presentation skills can help to succeed in business, career and\nacademy. This paper presents the design of speech assessment during the oral\npresentation and the algorithm for speech evaluation based on criteria of\noptimal intonation. As the pace of the speech and its optimal intonation varies\nfrom language to language, developing an automatic identification of language\nduring the presentation is required. Proposed algorithm was tested with\npresentations delivered in Kazakh language. For testing purposes the features\nof Kazakh phonemes were extracted using MFCC and PLP methods and created a\nHidden Markov Model (HMM) [5], [5] of Kazakh phonemes. Kazakh vowel formants\nwere defined and the correlation between the deviation rate in fundamental\nfrequency and the liveliness of the speech to evaluate intonation of the\npresentation was analyzed. It was established that the threshold value between\nmonotone and dynamic speech is 0.16 and the error for intonation evaluation is\n19%.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jan 2018 14:56:56 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Izbassarova", "Akzharkyn", ""], ["Irmanova", "Aidana", ""], ["James", "A. P.", ""]]}, {"id": "1801.00532", "submitter": "Shaonan Wang", "authors": "Shaonan Wang, Jiajun Zhang, Chengqing Zong", "title": "Learning Multimodal Word Representation via Dynamic Fusion Methods", "comments": "To be appear in AAAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal models have been proven to outperform text-based models on\nlearning semantic word representations. Almost all previous multimodal models\ntypically treat the representations from different modalities equally. However,\nit is obvious that information from different modalities contributes\ndifferently to the meaning of words. This motivates us to build a multimodal\nmodel that can dynamically fuse the semantic representations from different\nmodalities according to different types of words. To that end, we propose three\nnovel dynamic fusion methods to assign importance weights to each modality, in\nwhich weights are learned under the weak supervision of word association pairs.\nThe extensive experiments have demonstrated that the proposed methods\noutperform strong unimodal baselines and state-of-the-art multimodal models.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 00:32:29 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Wang", "Shaonan", ""], ["Zhang", "Jiajun", ""], ["Zong", "Chengqing", ""]]}, {"id": "1801.00554", "submitter": "Moustafa Alzantot", "authors": "Moustafa Alzantot, Bharathan Balaji, Mani Srivastava", "title": "Did you hear that? Adversarial Examples Against Automatic Speech\n  Recognition", "comments": "Published in NIPS 2017 Machine Deception workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech is a common and effective way of communication between humans, and\nmodern consumer devices such as smartphones and home hubs are equipped with\ndeep learning based accurate automatic speech recognition to enable natural\ninteraction between humans and machines. Recently, researchers have\ndemonstrated powerful attacks against machine learning models that can fool\nthem to produceincorrect results. However, nearly all previous research in\nadversarial attacks has focused on image recognition and object detection\nmodels. In this short paper, we present a first of its kind demonstration of\nadversarial attacks against speech classification model. Our algorithm performs\ntargeted attacks with 87% success by adding small background noise without\nhaving to know the underlying model parameter and architecture. Our attack only\nchanges the least significant bits of a subset of audio clip samples, and the\nnoise does not change 89% the human listener's perception of the audio clip as\nevaluated in our human study.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 05:24:30 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Alzantot", "Moustafa", ""], ["Balaji", "Bharathan", ""], ["Srivastava", "Mani", ""]]}, {"id": "1801.00625", "submitter": "Selvakumar M", "authors": "Suriyadeepan Ramamoorthy and Selvakumar Murugan", "title": "An Attentive Sequence Model for Adverse Drug Event Extraction from\n  Biomedical Text", "comments": "7 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adverse reaction caused by drugs is a potentially dangerous problem which may\nlead to mortality and morbidity in patients. Adverse Drug Event (ADE)\nextraction is a significant problem in biomedical research. We model ADE\nextraction as a Question-Answering problem and take inspiration from Machine\nReading Comprehension (MRC) literature, to design our model. Our objective in\ndesigning such a model, is to exploit the local linguistic context in clinical\ntext and enable intra-sequence interaction, in order to jointly learn to\nclassify drug and disease entities, and to extract adverse reactions caused by\na given drug. Our model makes use of a self-attention mechanism to facilitate\nintra-sequence interaction in a text sequence. This enables us to visualize and\nunderstand how the network makes use of the local and wider context for\nclassification.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 12:19:08 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Ramamoorthy", "Suriyadeepan", ""], ["Murugan", "Selvakumar", ""]]}, {"id": "1801.00632", "submitter": "Cedric De Boom", "authors": "Cedric De Boom, Thomas Demeester, Bart Dhoedt", "title": "Character-level Recurrent Neural Networks in Practice: Comparing\n  Training and Sampling Schemes", "comments": "23 pages, 11 figures, 4 tables", "journal-ref": null, "doi": "10.1007/s00521-017-3322-z", "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recurrent neural networks are nowadays successfully used in an abundance of\napplications, going from text, speech and image processing to recommender\nsystems. Backpropagation through time is the algorithm that is commonly used to\ntrain these networks on specific tasks. Many deep learning frameworks have\ntheir own implementation of training and sampling procedures for recurrent\nneural networks, while there are in fact multiple other possibilities to choose\nfrom and other parameters to tune. In existing literature this is very often\noverlooked or ignored. In this paper we therefore give an overview of possible\ntraining and sampling schemes for character-level recurrent neural networks to\nsolve the task of predicting the next token in a given sequence. We test these\ndifferent schemes on a variety of datasets, neural network architectures and\nparameter settings, and formulate a number of take-home recommendations. The\nchoice of training and sampling scheme turns out to be subject to a number of\ntrade-offs, such as training stability, sampling time, model performance and\nimplementation effort, but is largely independent of the data. Perhaps the most\nsurprising result is that transferring hidden states for correctly initializing\nthe model on subsequences often leads to unstable training behavior depending\non the dataset.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 12:50:12 GMT"}, {"version": "v2", "created": "Tue, 9 Jan 2018 09:15:07 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["De Boom", "Cedric", ""], ["Demeester", "Thomas", ""], ["Dhoedt", "Bart", ""]]}, {"id": "1801.00644", "submitter": "Reagan Mozer", "authors": "Reagan Mozer, Luke Miratrix, Aaron Russell Kaufman, L. Jason\n  Anastasopoulos", "title": "Matching with Text Data: An Experimental Evaluation of Methods for\n  Matching Documents and of Measuring Match Quality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matching for causal inference is a well-studied problem, but standard methods\nfail when the units to match are text documents: the high-dimensional and rich\nnature of the data renders exact matching infeasible, causes propensity scores\nto produce incomparable matches, and makes assessing match quality difficult.\nIn this paper, we characterize a framework for matching text documents that\ndecomposes existing methods into: (1) the choice of text representation, and\n(2) the choice of distance metric. We investigate how different choices within\nthis framework affect both the quantity and quality of matches identified\nthrough a systematic multifactor evaluation experiment using human subjects.\nAltogether we evaluate over 100 unique text matching methods along with 5\ncomparison methods taken from the literature. Our experimental results identify\nmethods that generate matches with higher subjective match quality than current\nstate-of-the-art techniques. We enhance the precision of these results by\ndeveloping a predictive model to estimate the match quality of pairs of text\ndocuments as a function of our various distance scores. This model, which we\nfind successfully mimics human judgment, also allows for approximate and\nunsupervised evaluation of new procedures. We then employ the identified best\nmethod to illustrate the utility of text matching in two applications. First,\nwe engage with a substantive debate in the study of media bias by using text\nmatching to control for topic selection when comparing news articles from\nthirteen news sources. We then show how conditioning on text data leads to more\nprecise causal inferences in an observational study examining the effects of a\nmedical intervention.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 13:47:43 GMT"}, {"version": "v2", "created": "Fri, 12 Jan 2018 17:14:00 GMT"}, {"version": "v3", "created": "Sun, 15 Apr 2018 20:13:44 GMT"}, {"version": "v4", "created": "Mon, 11 Jun 2018 19:40:04 GMT"}, {"version": "v5", "created": "Fri, 29 Jun 2018 09:17:43 GMT"}, {"version": "v6", "created": "Wed, 3 Oct 2018 20:57:57 GMT"}, {"version": "v7", "created": "Wed, 13 Mar 2019 19:50:07 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Mozer", "Reagan", ""], ["Miratrix", "Luke", ""], ["Kaufman", "Aaron Russell", ""], ["Anastasopoulos", "L. Jason", ""]]}, {"id": "1801.00801", "submitter": "Nicolai Pogrebnyakov", "authors": "Nicolai Pogrebnyakov and Edgar Maldonado", "title": "Identifying emergency stages in Facebook posts of police departments\n  with convolutional and recurrent neural networks and support vector machines", "comments": null, "journal-ref": "Proceedings of the 5th IEEE International Conference on Big Data,\n  Boston, MA, USA, December 11-14, 2017", "doi": "10.1109/BigData.2017.8258464", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification of social media posts in emergency response is an important\npractical problem: accurate classification can help automate processing of such\nmessages and help other responders and the public react to emergencies in a\ntimely fashion. This research focused on classifying Facebook messages of US\npolice departments. Randomly selected 5,000 messages were used to train\nclassifiers that distinguished between four categories of messages: emergency\npreparedness, response and recovery, as well as general engagement messages.\nFeatures were represented with bag-of-words and word2vec, and models were\nconstructed using support vector machines (SVMs) and convolutional (CNNs) and\nrecurrent neural networks (RNNs). The best performing classifier was an RNN\nwith a custom-trained word2vec model to represent features, which achieved the\nF1 measure of 0.839.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 19:09:47 GMT"}, {"version": "v2", "created": "Wed, 24 Jan 2018 13:27:53 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Pogrebnyakov", "Nicolai", ""], ["Maldonado", "Edgar", ""]]}, {"id": "1801.00841", "submitter": "Kanishka Rao", "authors": "Kanishka Rao, Ha\\c{s}im Sak, Rohit Prabhavalkar", "title": "Exploring Architectures, Data and Units For Streaming End-to-End Speech\n  Recognition with RNN-Transducer", "comments": "In Proceedings of IEEE ASRU 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate training end-to-end speech recognition models with the\nrecurrent neural network transducer (RNN-T): a streaming, all-neural,\nsequence-to-sequence architecture which jointly learns acoustic and language\nmodel components from transcribed acoustic data. We explore various model\narchitectures and demonstrate how the model can be improved further if\nadditional text or pronunciation data are available. The model consists of an\n`encoder', which is initialized from a connectionist temporal\nclassification-based (CTC) acoustic model, and a `decoder' which is partially\ninitialized from a recurrent neural network language model trained on text data\nalone. The entire neural network is trained with the RNN-T loss and directly\noutputs the recognized transcript as a sequence of graphemes, thus performing\nend-to-end speech recognition. We find that performance can be improved further\nthrough the use of sub-word units (`wordpieces') which capture longer context\nand significantly reduce substitution errors. The best RNN-T system, a\ntwelve-layer LSTM encoder with a two-layer LSTM decoder trained with 30,000\nwordpieces as output targets achieves a word error rate of 8.5\\% on\nvoice-search and 5.2\\% on voice-dictation tasks and is comparable to a\nstate-of-the-art baseline at 8.3\\% on voice-search and 5.4\\% voice-dictation.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 21:29:41 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Rao", "Kanishka", ""], ["Sak", "Ha\u015fim", ""], ["Prabhavalkar", "Rohit", ""]]}, {"id": "1801.00984", "submitter": "Abdelkrime Aries", "authors": "Abdelkrime Aries, Djamel Eddine Zegour, Walid Khaled Hidouci", "title": "Sentence Object Notation: Multilingual sentence notation based on\n  Wordnet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The representation of sentences is a very important task. It can be used as a\nway to exchange data inter-applications. One main characteristic, that a\nnotation must have, is a minimal size and a representative form. This can\nreduce the transfer time, and hopefully the processing time as well.\n  Usually, sentence representation is associated to the processed language. The\ngrammar of this language affects how we represent the sentence. To avoid\nlanguage-dependent notations, we have to come up with a new representation\nwhich don't use words, but their meanings. This can be done using a lexicon\nlike wordnet, instead of words we use their synsets. As for syntactic\nrelations, they have to be universal as much as possible.\n  Our new notation is called STON \"SenTences Object Notation\", which somehow\nhas similarities to JSON. It is meant to be minimal, representative and\nlanguage-independent syntactic representation. Also, we want it to be readable\nand easy to be created. This simplifies developing simple automatic generators\nand creating test banks manually. Its benefit is to be used as a medium between\ndifferent parts of applications like: text summarization, language translation,\netc. The notation is based on 4 languages: Arabic, English, Franch and\nJapanese; and there are some cases where these languages don't agree on one\nrepresentation. Also, given the diversity of grammatical structure of different\nworld languages, this annotation may fail for some languages which allows more\nfuture improvements.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 13:02:25 GMT"}, {"version": "v2", "created": "Wed, 10 Jan 2018 19:09:39 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Aries", "Abdelkrime", ""], ["Zegour", "Djamel Eddine", ""], ["Hidouci", "Walid Khaled", ""]]}, {"id": "1801.01102", "submitter": "Barathi Ganesh H B", "authors": "Barathi Ganesh HB", "title": "Social Media Analysis based on Semanticity of Streaming and Batch Data", "comments": "54 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Languages shared by people differ in different regions based on their\naccents, pronunciation and word usages. In this era sharing of language takes\nplace mainly through social media and blogs. Every second swing of such a micro\nposts exist which induces the need of processing those micro posts, in-order to\nextract knowledge out of it. Knowledge extraction differs with respect to the\napplication in which the research on cognitive science fed the necessities for\nthe same. This work further moves forward such a research by extracting\nsemantic information of streaming and batch data in applications like Named\nEntity Recognition and Author Profiling. In the case of Named Entity\nRecognition context of a single micro post has been utilized and context that\nlies in the pool of micro posts were utilized to identify the sociolect aspects\nof the author of those micro posts. In this work Conditional Random Field has\nbeen utilized to do the entity recognition and a novel approach has been\nproposed to find the sociolect aspects of the author (Gender, Age group).\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 18:23:41 GMT"}, {"version": "v2", "created": "Fri, 5 Jan 2018 05:40:59 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["HB", "Barathi Ganesh", ""]]}, {"id": "1801.01331", "submitter": "Dat Quoc Nguyen", "authors": "Thanh Vu, Dat Quoc Nguyen, Dai Quoc Nguyen, Mark Dras, Mark Johnson", "title": "VnCoreNLP: A Vietnamese Natural Language Processing Toolkit", "comments": "Proceedings of the 2018 Conference of the North American Chapter of\n  the Association for Computational Linguistics: Demonstrations, NAACL 2018, to\n  appear", "journal-ref": null, "doi": "10.18653/v1/N18-5012", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an easy-to-use and fast toolkit, namely VnCoreNLP---a Java NLP\nannotation pipeline for Vietnamese. Our VnCoreNLP supports key natural language\nprocessing (NLP) tasks including word segmentation, part-of-speech (POS)\ntagging, named entity recognition (NER) and dependency parsing, and obtains\nstate-of-the-art (SOTA) results for these tasks. We release VnCoreNLP to\nprovide rich linguistic annotations to facilitate research work on Vietnamese\nNLP. Our VnCoreNLP is open-source and available at:\nhttps://github.com/vncorenlp/VnCoreNLP\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 12:52:43 GMT"}, {"version": "v2", "created": "Sun, 1 Apr 2018 13:13:39 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Vu", "Thanh", ""], ["Nguyen", "Dat Quoc", ""], ["Nguyen", "Dai Quoc", ""], ["Dras", "Mark", ""], ["Johnson", "Mark", ""]]}, {"id": "1801.01531", "submitter": "Kevin Bowden", "authors": "Kevin K. Bowden, Jiaqi Wu, Shereen Oraby, Amita Misra and Marilyn\n  Walker", "title": "Slugbot: An Application of a Novel and Scalable Open Domain Socialbot\n  Framework", "comments": null, "journal-ref": "Alexa Prize Proceedings 2017", "doi": null, "report-no": null, "categories": "cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a novel, open domain socialbot for the Amazon\nAlexa Prize competition, aimed at carrying on friendly conversations with users\non a variety of topics. We present our modular system, highlighting our\ndifferent data sources and how we use the human mind as a model for data\nmanagement. Additionally we build and employ natural language understanding and\ninformation retrieval tools and APIs to expand our knowledge bases. We describe\nour semistructured, scalable framework for crafting topic-specific dialogue\nflows, and give details on our dialogue management schemes and scoring\nmechanisms. Finally we briefly evaluate the performance of our system and\nobserve the challenges that an open domain socialbot faces.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 19:58:46 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Bowden", "Kevin K.", ""], ["Wu", "Jiaqi", ""], ["Oraby", "Shereen", ""], ["Misra", "Amita", ""], ["Walker", "Marilyn", ""]]}, {"id": "1801.01641", "submitter": "Liu Yang", "authors": "Liu Yang and Qingyao Ai and Jiafeng Guo and W. Bruce Croft", "title": "aNMM: Ranking Short Answer Texts with Attention-Based Neural Matching\n  Model", "comments": "Accepted as a full paper by CIKM'16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an alternative to question answering methods based on feature engineering,\ndeep learning approaches such as convolutional neural networks (CNNs) and Long\nShort-Term Memory Models (LSTMs) have recently been proposed for semantic\nmatching of questions and answers. To achieve good results, however, these\nmodels have been combined with additional features such as word overlap or BM25\nscores. Without this combination, these models perform significantly worse than\nmethods based on linguistic feature engineering. In this paper, we propose an\nattention based neural matching model for ranking short answer text. We adopt\nvalue-shared weighting scheme instead of position-shared weighting scheme for\ncombining different matching signals and incorporate question term importance\nlearning using question attention network. Using the popular benchmark TREC QA\ndata, we show that the relatively simple aNMM model can significantly\noutperform other neural network models that have been used for the question\nanswering task, and is competitive with models that are combined with\nadditional features. When aNMM is combined with additional features, it\noutperforms all baselines.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 06:06:17 GMT"}, {"version": "v2", "created": "Sat, 1 Jun 2019 02:38:18 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Yang", "Liu", ""], ["Ai", "Qingyao", ""], ["Guo", "Jiafeng", ""], ["Croft", "W. Bruce", ""]]}, {"id": "1801.01725", "submitter": "Jingang Wang", "authors": "Jingang Wang, Junfeng Tian, Long Qiu, Sheng Li, Jun Lang, Luo Si and\n  Man Lan", "title": "A Multi-task Learning Approach for Improving Product Title Compression\n  with User Search Log Data", "comments": "8 Pages, accepted at AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a challenging and practical research problem to obtain effective\ncompression of lengthy product titles for E-commerce. This is particularly\nimportant as more and more users browse mobile E-commerce apps and more\nmerchants make the original product titles redundant and lengthy for Search\nEngine Optimization. Traditional text summarization approaches often require a\nlarge amount of preprocessing costs and do not capture the important issue of\nconversion rate in E-commerce. This paper proposes a novel multi-task learning\napproach for improving product title compression with user search log data. In\nparticular, a pointer network-based sequence-to-sequence approach is utilized\nfor title compression with an attentive mechanism as an extractive method and\nan attentive encoder-decoder approach is utilized for generating user search\nqueries. The encoding parameters (i.e., semantic embedding of original titles)\nare shared among the two tasks and the attention distributions are jointly\noptimized. An extensive set of experiments with both human annotated data and\nonline deployment demonstrate the advantage of the proposed research for both\ncompression qualities and online business values.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 11:52:44 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Wang", "Jingang", ""], ["Tian", "Junfeng", ""], ["Qiu", "Long", ""], ["Li", "Sheng", ""], ["Lang", "Jun", ""], ["Si", "Luo", ""], ["Lan", "Man", ""]]}, {"id": "1801.01768", "submitter": "Corina Florescu", "authors": "Corina Florescu and Wei Jin", "title": "Learning Feature Representations for Keyphrase Extraction", "comments": "To appear in AAAI 2018 Student Abstract and Poster Program", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In supervised approaches for keyphrase extraction, a candidate phrase is\nencoded with a set of hand-crafted features and machine learning algorithms are\ntrained to discriminate keyphrases from non-keyphrases. Although the\nmanually-designed features have shown to work well in practice, feature\nengineering is a difficult process that requires expert knowledge and normally\ndoes not generalize well. In this paper, we present SurfKE, a feature learning\nframework that exploits the text itself to automatically discover patterns that\nkeyphrases exhibit. Our model represents the document as a graph and\nautomatically learns feature representation of phrases. The proposed model\nobtains remarkable improvements in performance over strong baselines.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 14:36:31 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Florescu", "Corina", ""], ["Jin", "Wei", ""]]}, {"id": "1801.01825", "submitter": "Danish Contractor", "authors": "Danish Contractor, Barun Patra, Mausam Singla, Parag Singla", "title": "Towards Understanding and Answering Multi-Sentence Recommendation\n  Questions on Tourism", "comments": null, "journal-ref": null, "doi": "10.1017/S1351324920000017", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the first system towards the novel task of answering complex\nmultisentence recommendation questions in the tourism domain. Our solution uses\na pipeline of two modules: question understanding and answering. For question\nunderstanding, we define an SQL-like query language that captures the semantic\nintent of a question; it supports operators like subset, negation, preference\nand similarity, which are often found in recommendation questions. We train and\ncompare traditional CRFs as well as bidirectional LSTM-based models for\nconverting a question to its semantic representation. We extend these models to\na semisupervised setting with partially labeled sequences gathered through\ncrowdsourcing. We find that our best model performs semi-supervised training of\nBiDiLSTM+CRF with hand-designed features and CCM(Chang et al., 2007)\nconstraints. Finally, in an end to end QA system, our answering component\nconverts our question representation into queries fired on underlying knowledge\nsources. Our experiments on two different answer corpora demonstrate that our\nsystem can significantly outperform baselines with up to 20 pt higher accuracy\nand 17 pt higher recall.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 16:38:05 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Contractor", "Danish", ""], ["Patra", "Barun", ""], ["Singla", "Mausam", ""], ["Singla", "Parag", ""]]}, {"id": "1801.01828", "submitter": "Sergio Rojas-Galeano", "authors": "Nestor Rodriguez and Sergio Rojas-Galeano", "title": "Shielding Google's language toxicity model against adversarial attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lack of moderation in online communities enables participants to incur in\npersonal aggression, harassment or cyberbullying, issues that have been\naccentuated by extremist radicalisation in the contemporary post-truth politics\nscenario. This kind of hostility is usually expressed by means of toxic\nlanguage, profanity or abusive statements. Recently Google has developed a\nmachine-learning-based toxicity model in an attempt to assess the hostility of\na comment; unfortunately, it has been suggested that said model can be deceived\nby adversarial attacks that manipulate the text sequence of the comment. In\nthis paper we firstly characterise such adversarial attacks as using\nobfuscation and polarity transformations. The former deceives by corrupting\ntoxic trigger content with typographic edits, whereas the latter deceives by\ngrammatical negation of the toxic content. Then, we propose a two--stage\napproach to counter--attack these anomalies, bulding upon a recently proposed\ntext deobfuscation method and the toxicity scoring model. Lastly, we conducted\nan experiment with approximately 24000 distorted comments, showing how in this\nway it is feasible to restore toxicity of the adversarial variants, while\nincurring roughly on a twofold increase in processing time. Even though novel\nadversary challenges would keep coming up derived from the versatile nature of\nwritten language, we anticipate that techniques combining machine learning and\ntext pattern recognition methods, each one targeting different layers of\nlinguistic features, would be needed to achieve robust detection of toxic\nlanguage, thus fostering aggression--free digital interaction.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 16:45:59 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Rodriguez", "Nestor", ""], ["Rojas-Galeano", "Sergio", ""]]}, {"id": "1801.01884", "submitter": "Neil Smalheiser", "authors": "Neil R. Smalheiser, Gary Bonifield", "title": "Unsupervised Low-Dimensional Vector Representations for Words, Phrases\n  and Text that are Transparent, Scalable, and produce Similarity Metrics that\n  are Complementary to Neural Embeddings", "comments": "27 pages, 9 tables, and 6 supplemental files which can be accessed at\n  http://arrowsmith.psych.uic.edu/arrowsmith_uic/word_similarity_metrics.html.\n  Rewrote Introduction. This ms. has been submitted to J. Biomed. Informatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neural embeddings are a popular set of methods for representing words,\nphrases or text as a low dimensional vector (typically 50-500 dimensions).\nHowever, it is difficult to interpret these dimensions in a meaningful manner,\nand creating neural embeddings requires extensive training and tuning of\nmultiple parameters and hyperparameters. We present here a simple unsupervised\nmethod for representing words, phrases or text as a low dimensional vector, in\nwhich the meaning and relative importance of dimensions is transparent to\ninspection. We have created a near-comprehensive vector representation of\nwords, and selected bigrams, trigrams and abbreviations, using the set of\ntitles and abstracts in PubMed as a corpus. This vector is used to create\nseveral novel implicit word-word and text-text similarity metrics. The implicit\nword-word similarity metrics correlate well with human judgement of word pair\nsimilarity and relatedness, and outperform or equal all other reported methods\non a variety of biomedical benchmarks, including several implementations of\nneural embeddings trained on PubMed corpora. Our implicit word-word metrics\ncapture different aspects of word-word relatedness than word2vec-based metrics\nand are only partially correlated (rho = ~0.5-0.8 depending on task and\ncorpus). The vector representations of words, bigrams, trigrams, abbreviations,\nand PubMed title+abstracts are all publicly available from\nhttp://arrowsmith.psych.uic.edu for release under CC-BY-NC license. Several\npublic web query interfaces are also available at the same site, including one\nwhich allows the user to specify a given word and view its most closely related\nterms according to direct co-occurrence as well as different implicit\nsimilarity metrics.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 19:00:04 GMT"}, {"version": "v2", "created": "Tue, 9 Jan 2018 18:22:15 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Smalheiser", "Neil R.", ""], ["Bonifield", "Gary", ""]]}, {"id": "1801.01900", "submitter": "Devendra Singh Chaplot", "authors": "Devendra Singh Chaplot, Ruslan Salakhutdinov", "title": "Knowledge-based Word Sense Disambiguation using Topic Models", "comments": "To appear in AAAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word Sense Disambiguation is an open problem in Natural Language Processing\nwhich is particularly challenging and useful in the unsupervised setting where\nall the words in any given text need to be disambiguated without using any\nlabeled data. Typically WSD systems use the sentence or a small window of words\naround the target word as the context for disambiguation because their\ncomputational complexity scales exponentially with the size of the context. In\nthis paper, we leverage the formalism of topic model to design a WSD system\nthat scales linearly with the number of words in the context. As a result, our\nsystem is able to utilize the whole document as the context for a word to be\ndisambiguated. The proposed method is a variant of Latent Dirichlet Allocation\nin which the topic proportions for a document are replaced by synset\nproportions. We further utilize the information in the WordNet by assigning a\nnon-uniform prior to synset distribution over words and a logistic-normal prior\nfor document distribution over synsets. We evaluate the proposed method on\nSenseval-2, Senseval-3, SemEval-2007, SemEval-2013 and SemEval-2015 English\nAll-Word WSD datasets and show that it outperforms the state-of-the-art\nunsupervised knowledge-based WSD system by a significant margin.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 19:20:24 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Chaplot", "Devendra Singh", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1801.01967", "submitter": "Amir Mazaheri", "authors": "Amir Mazaheri, Mubarak Shah", "title": "Visual Text Correction", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-01261-8_10", "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Videos, images, and sentences are mediums that can express the same\nsemantics. One can imagine a picture by reading a sentence or can describe a\nscene with some words. However, even small changes in a sentence can cause a\nsignificant semantic inconsistency with the corresponding video/image. For\nexample, by changing the verb of a sentence, the meaning may drastically\nchange. There have been many efforts to encode a video/sentence and decode it\nas a sentence/video. In this research, we study a new scenario in which both\nthe sentence and the video are given, but the sentence is inaccurate. A\nsemantic inconsistency between the sentence and the video or between the words\nof a sentence can result in an inaccurate description. This paper introduces a\nnew problem, called Visual Text Correction (VTC), i.e., finding and replacing\nan inaccurate word in the textual description of a video. We propose a deep\nnetwork that can simultaneously detect an inaccuracy in a sentence, and fix it\nby replacing the inaccurate word(s). Our method leverages the semantic\ninterdependence of videos and words, as well as the short-term and long-term\nrelations of the words in a sentence. In our formulation, part of a visual\nfeature vector for every single word is dynamically selected through a gating\nprocess. Furthermore, to train and evaluate our model, we propose an approach\nto automatically construct a large dataset for VTC problem. Our experiments and\nperformance analysis demonstrates that the proposed method provides very good\nresults and also highlights the general challenges in solving the VTC problem.\nTo the best of our knowledge, this work is the first of its kind for the Visual\nText Correction task.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jan 2018 04:58:38 GMT"}, {"version": "v2", "created": "Sun, 18 Mar 2018 08:21:48 GMT"}, {"version": "v3", "created": "Thu, 13 Sep 2018 20:09:12 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Mazaheri", "Amir", ""], ["Shah", "Mubarak", ""]]}, {"id": "1801.01999", "submitter": "Mikul\\'a\\v{s} Zelinka", "authors": "Mikul\\'a\\v{s} Zelinka", "title": "Using reinforcement learning to learn how to play text-based games", "comments": "Master thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to learn optimal control policies in systems where action space\nis defined by sentences in natural language would allow many interesting\nreal-world applications such as automatic optimisation of dialogue systems.\nText-based games with multiple endings and rewards are a promising platform for\nthis task, since their feedback allows us to employ reinforcement learning\ntechniques to jointly learn text representations and control policies. We\npresent a general text game playing agent, testing its generalisation and\ntransfer learning performance and showing its ability to play multiple games at\nonce. We also present pyfiction, an open-source library for universal access to\ndifferent text games that could, together with our agent that implements its\ninterface, serve as a baseline for future research.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jan 2018 10:38:51 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Zelinka", "Mikul\u00e1\u0161", ""]]}, {"id": "1801.02054", "submitter": "Arthur Jacobs M", "authors": "Arthur M. Jacobs", "title": "Explorations in an English Poetry Corpus: A Neurocognitive Poetics\n  Perspective", "comments": "27 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a corpus of about 3000 English literary texts with about\n250 million words extracted from the Gutenberg project that span a range of\ngenres from both fiction and non-fiction written by more than 130 authors\n(e.g., Darwin, Dickens, Shakespeare). Quantitative Narrative Analysis (QNA) is\nused to explore a cleaned subcorpus, the Gutenberg English Poetry Corpus (GEPC)\nwhich comprises over 100 poetic texts with around 2 million words from about 50\nauthors (e.g., Keats, Joyce, Wordsworth). Some exemplary QNA studies show\nauthor similarities based on latent semantic analysis, significant topics for\neach author or various text-analytic metrics for George Eliot's poem 'How Lisa\nLoved the King' and James Joyce's 'Chamber Music', concerning e.g. lexical\ndiversity or sentiment analysis. The GEPC is particularly suited for research\nin Digital Humanities, Natural Language Processing or Neurocognitive Poetics,\ne.g. as training and test corpus, or for stimulus development and control.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jan 2018 17:28:21 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Jacobs", "Arthur M.", ""]]}, {"id": "1801.02073", "submitter": "Tomasz Jurczyk", "authors": "Tomasz Jurczyk, Amit Deshmane, Jinho D. Choi", "title": "Analysis of Wikipedia-based Corpora for Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper gives comprehensive analyses of corpora based on Wikipedia for\nseveral tasks in question answering. Four recent corpora are collected,WikiQA,\nSelQA, SQuAD, and InfoQA, and first analyzed intrinsically by contextual\nsimilarities, question types, and answer categories. These corpora are then\nanalyzed extrinsically by three question answering tasks, answer retrieval,\nselection, and triggering. An indexing-based method for the creation of a\nsilver-standard dataset for answer retrieval using the entire Wikipedia is also\npresented. Our analysis shows the uniqueness of these corpora and suggests a\nbetter use of them for statistical question answering learning.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jan 2018 19:28:15 GMT"}, {"version": "v2", "created": "Mon, 5 Feb 2018 07:41:32 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Jurczyk", "Tomasz", ""], ["Deshmane", "Amit", ""], ["Choi", "Jinho D.", ""]]}, {"id": "1801.02107", "submitter": "Omid Kashefi", "authors": "Omid Kashefi", "title": "MIZAN: A Large Persian-English Parallel Corpus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most major and essential tasks in natural language processing is\nmachine translation that is now highly dependent upon multilingual parallel\ncorpora. Through this paper, we introduce the biggest Persian-English parallel\ncorpus with more than one million sentence pairs collected from masterpieces of\nliterature. We also present acquisition process and statistics of the corpus,\nand experiment a base-line statistical machine translation system using the\ncorpus.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jan 2018 00:48:43 GMT"}, {"version": "v2", "created": "Wed, 10 Jan 2018 18:30:45 GMT"}, {"version": "v3", "created": "Fri, 31 Jan 2020 00:55:29 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Kashefi", "Omid", ""]]}, {"id": "1801.02243", "submitter": "Wanfeng Chen", "authors": "Catherine Xiao, Wanfeng Chen", "title": "Trading the Twitter Sentiment with Reinforcement Learning", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is to explore the possibility to use alternative data and\nartificial intelligence techniques to trade stocks. The efficacy of the daily\nTwitter sentiment on predicting the stock return is examined using machine\nlearning methods. Reinforcement learning(Q-learning) is applied to generate the\noptimal trading policy based on the sentiment signal. The predicting power of\nthe sentiment signal is more significant if the stock price is driven by the\nexpectation of the company growth and when the company has a major event that\ndraws the public attention. The optimal trading strategy based on reinforcement\nlearning outperforms the trading strategy based on the machine learning\nprediction.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jan 2018 20:26:00 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Xiao", "Catherine", ""], ["Chen", "Wanfeng", ""]]}, {"id": "1801.02581", "submitter": "Soumil Mandal", "authors": "Soumil Mandal, Dipankar Das", "title": "Analyzing Roles of Classifiers and Code-Mixed factors for Sentiment\n  Identification", "comments": "18th International Conference on Computational Linguistics and\n  Intelligent Text Processing, CICLing 2017 (RCS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multilingual speakers often switch between languages to express themselves on\nsocial communication platforms. Sometimes, the original script of the language\nis preserved, while using a common script for all the languages is quite\npopular as well due to convenience. On such occasions, multiple languages are\nbeing mixed with different rules of grammar, using the same script which makes\nit a challenging task for natural language processing even in case of accurate\nsentiment identification. In this paper, we report results of various\nexperiments carried out on movie reviews dataset having this code-mixing\nproperty of two languages, English and Bengali, both typed in Roman script. We\nhave tested various machine learning algorithms trained only on English\nfeatures on our code-mixed data and have achieved the maximum accuracy of\n59.00% using Naive Bayes (NB) model. We have also tested various models trained\non code-mixed data, as well as English features and the highest accuracy of\n72.50% was obtained by a Support Vector Machine (SVM) model. Finally, we have\nanalyzed the misclassified snippets and have discussed the challenges needed to\nbe resolved for better accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 17:43:12 GMT"}, {"version": "v2", "created": "Thu, 15 Mar 2018 19:31:44 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Mandal", "Soumil", ""], ["Das", "Dipankar", ""]]}, {"id": "1801.02668", "submitter": "Ting-Hao Huang", "authors": "Ting-Hao 'Kenneth' Huang and Joseph Chee Chang and Jeffrey P. Bigham", "title": "Evorus: A Crowd-powered Conversational Assistant Built to Automate\n  Itself Over Time", "comments": "10 pages. To appear in the Proceedings of the Conference on Human\n  Factors in Computing Systems 2018 (CHI'18)", "journal-ref": null, "doi": "10.1145/3173574.3173869", "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowd-powered conversational assistants have been shown to be more robust\nthan automated systems, but do so at the cost of higher response latency and\nmonetary costs. A promising direction is to combine the two approaches for high\nquality, low latency, and low cost solutions. In this paper, we introduce\nEvorus, a crowd-powered conversational assistant built to automate itself over\ntime by (i) allowing new chatbots to be easily integrated to automate more\nscenarios, (ii) reusing prior crowd answers, and (iii) learning to\nautomatically approve response candidates. Our 5-month-long deployment with 80\nparticipants and 281 conversations shows that Evorus can automate itself\nwithout compromising conversation quality. Crowd-AI architectures have long\nbeen proposed as a way to reduce cost and latency for crowd-powered systems;\nEvorus demonstrates how automation can be introduced successfully in a deployed\nsystem. Its architecture allows future researchers to make further innovation\non the underlying automated components in the context of a deployed open domain\ndialog system.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 20:07:35 GMT"}, {"version": "v2", "created": "Wed, 10 Jan 2018 03:49:24 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Huang", "Ting-Hao 'Kenneth'", ""], ["Chang", "Joseph Chee", ""], ["Bigham", "Jeffrey P.", ""]]}, {"id": "1801.02808", "submitter": "Bing Liu", "authors": "Zhiyuan Chen, Nianzu Ma, Bing Liu", "title": "Lifelong Learning for Sentiment Classification", "comments": null, "journal-ref": "ACL 2015", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel lifelong learning (LL) approach to sentiment\nclassification. LL mimics the human continuous learning process, i.e.,\nretaining the knowledge learned from past tasks and use it to help future\nlearning. In this paper, we first discuss LL in general and then LL for\nsentiment classification in particular. The proposed LL approach adopts a\nBayesian optimization framework based on stochastic gradient descent. Our\nexperimental results show that the proposed method outperforms baseline methods\nsignificantly, which demonstrates that lifelong learning is a promising\nresearch direction.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 06:11:50 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Chen", "Zhiyuan", ""], ["Ma", "Nianzu", ""], ["Liu", "Bing", ""]]}, {"id": "1801.02832", "submitter": "Carsten Eickhoff", "authors": "Ferenc Galk\\'o and Carsten Eickhoff", "title": "Biomedical Question Answering via Weighted Neural Network Passage\n  Retrieval", "comments": "To appear in ECIR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The amount of publicly available biomedical literature has been growing\nrapidly in recent years, yet question answering systems still struggle to\nexploit the full potential of this source of data. In a preliminary processing\nstep, many question answering systems rely on retrieval models for identifying\nrelevant documents and passages. This paper proposes a weighted cosine distance\nretrieval scheme based on neural network word embeddings. Our experiments are\nbased on publicly available data and tasks from the BioASQ biomedical question\nanswering challenge and demonstrate significant performance gains over a wide\nrange of state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 08:23:46 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Galk\u00f3", "Ferenc", ""], ["Eickhoff", "Carsten", ""]]}, {"id": "1801.02916", "submitter": "Miroslav Vodol\\'an", "authors": "Miroslav Vodol\\'an, Filip Jur\\v{c}\\'i\\v{c}ek", "title": "Denotation Extraction for Interactive Learning in Dialogue Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel task using real user data obtained in\nhuman-machine conversation. The task concerns with denotation extraction from\nanswer hints collected interactively in a dialogue. The task is motivated by\nthe need for large amounts of training data for question answering dialogue\nsystem development, where the data is often expensive and hard to collect.\nBeing able to collect denotation interactively and directly from users, one\ncould improve, for example, natural understanding components on-line and ease\nthe collection of the training data. This paper also presents introductory\nresults of evaluation of several denotation extraction models including\nattention-based neural network approaches.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 12:30:45 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Vodol\u00e1n", "Miroslav", ""], ["Jur\u010d\u00ed\u010dek", "Filip", ""]]}, {"id": "1801.03032", "submitter": "Ritvik Shrivastava", "authors": "Kuntal Dey, Ritvik Shrivastava, Saroj Kaushik", "title": "Topical Stance Detection for Twitter: A Two-Phase LSTM Model Using\n  Attention", "comments": "Accepted at the 40th European Conference on Information Retrieval\n  (ECIR), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The topical stance detection problem addresses detecting the stance of the\ntext content with respect to a given topic: whether the sentiment of the given\ntext content is in FAVOR of (positive), is AGAINST (negative), or is NONE\n(neutral) towards the given topic. Using the concept of attention, we develop a\ntwo-phase solution. In the first phase, we classify subjectivity - whether a\ngiven tweet is neutral or subjective with respect to the given topic. In the\nsecond phase, we classify sentiment of the subjective tweets (ignoring the\nneutral tweets) - whether a given subjective tweet has a FAVOR or AGAINST\nstance towards the topic. We propose a Long Short-Term memory (LSTM) based deep\nneural network for each phase, and embed attention at each of the phases. On\nthe SemEval 2016 stance detection Twitter task dataset, we obtain a best-case\nmacro F-score of 68.84% and a best-case accuracy of 60.2%, outperforming the\nexisting deep learning based solutions. Our framework, T-PAN, is the first in\nthe topical stance detection literature, that uses deep learning within a\ntwo-phase architecture.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 17:00:24 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Dey", "Kuntal", ""], ["Shrivastava", "Ritvik", ""], ["Kaushik", "Saroj", ""]]}, {"id": "1801.03257", "submitter": "Longyue Wang", "authors": "Longyue Wang, Zhaopeng Tu, Shuming Shi, Tong Zhang, Yvette Graham, Qun\n  Liu", "title": "Translating Pro-Drop Languages with Reconstruction Models", "comments": "Accepted by AAAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pronouns are frequently omitted in pro-drop languages, such as Chinese,\ngenerally leading to significant challenges with respect to the production of\ncomplete translations. To date, very little attention has been paid to the\ndropped pronoun (DP) problem within neural machine translation (NMT). In this\nwork, we propose a novel reconstruction-based approach to alleviating DP\ntranslation problems for NMT models. Firstly, DPs within all source sentences\nare automatically annotated with parallel information extracted from the\nbilingual training corpus. Next, the annotated source sentence is reconstructed\nfrom hidden representations in the NMT model. With auxiliary training\nobjectives, in terms of reconstruction scores, the parameters associated with\nthe NMT model are guided to produce enhanced hidden representations that are\nencouraged as much as possible to embed annotated DP information. Experimental\nresults on both Chinese-English and Japanese-English dialogue translation tasks\nshow that the proposed approach significantly and consistently improves\ntranslation performance over a strong NMT baseline, which is directly built on\nthe training data annotated with DPs.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 07:53:22 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Wang", "Longyue", ""], ["Tu", "Zhaopeng", ""], ["Shi", "Shuming", ""], ["Zhang", "Tong", ""], ["Graham", "Yvette", ""], ["Liu", "Qun", ""]]}, {"id": "1801.03339", "submitter": "Felix Kreuk", "authors": "Felix Kreuk, Yossi Adi, Moustapha Cisse, Joseph Keshet", "title": "Fooling End-to-end Speaker Verification by Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speaker verification systems are increasingly used as the primary\nmeans to authenticate costumers. Recently, it has been proposed to train\nspeaker verification systems using end-to-end deep neural models. In this\npaper, we show that such systems are vulnerable to adversarial example attack.\nAdversarial examples are generated by adding a peculiar noise to original\nspeaker examples, in such a way that they are almost indistinguishable from the\noriginal examples by a human listener. Yet, the generated waveforms, which\nsound as speaker A can be used to fool such a system by claiming as if the\nwaveforms were uttered by speaker B. We present white-box attacks on an\nend-to-end deep network that was either trained on YOHO or NTIMIT. We also\npresent two black-box attacks: where the adversarial examples were generated\nwith a system that was trained on YOHO, but the attack is on a system that was\ntrained on NTIMIT; and when the adversarial examples were generated with a\nsystem that was trained on Mel-spectrum feature set, but the attack is on a\nsystem that was trained on MFCC. Results suggest that the accuracy of the\nattacked system was decreased and the false-positive rate was dramatically\nincreased.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 12:24:34 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2018 13:40:02 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Kreuk", "Felix", ""], ["Adi", "Yossi", ""], ["Cisse", "Moustapha", ""], ["Keshet", "Joseph", ""]]}, {"id": "1801.03460", "submitter": "Marcelo Criscuolo", "authors": "Marcelo Criscuolo, Erick Rocha Fonseca, Sandra Maria Alu\\'isio, Ana\n  Carolina Speran\\c{c}a-Criscuolo", "title": "MilkQA: a Dataset of Consumer Questions for the Task of Answer Selection", "comments": "6 pages", "journal-ref": "Intelligent Systems (BRACIS), 2017 Brazilian Conference on", "doi": "10.1109/BRACIS.2017.12", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce MilkQA, a question answering dataset from the dairy domain\ndedicated to the study of consumer questions. The dataset contains 2,657 pairs\nof questions and answers, written in the Portuguese language and originally\ncollected by the Brazilian Agricultural Research Corporation (Embrapa). All\nquestions were motivated by real situations and written by thousands of authors\nwith very different backgrounds and levels of literacy, while answers were\nelaborated by specialists from Embrapa's customer service. Our dataset was\nfiltered and anonymized by three human annotators. Consumer questions are a\nchallenging kind of question that is usually employed as a form of seeking\ninformation. Although several question answering datasets are available, most\nof such resources are not suitable for research on answer selection models for\nconsumer questions. We aim to fill this gap by making MilkQA publicly\navailable. We study the behavior of four answer selection models on MilkQA: two\nbaseline models and two convolutional neural network archictetures. Our results\nshow that MilkQA poses real challenges to computational models, particularly\ndue to linguistic characteristics of its questions and to their unusually\nlonger lengths. Only one of the experimented models gives reasonable results,\nat the cost of high computational requirements.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 17:16:36 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Criscuolo", "Marcelo", ""], ["Fonseca", "Erick Rocha", ""], ["Alu\u00edsio", "Sandra Maria", ""], ["Speran\u00e7a-Criscuolo", "Ana Carolina", ""]]}, {"id": "1801.03562", "submitter": "Paul Tupper", "authors": "Paul Tupper, Paul Smolensky, Pyeong Whan Cho", "title": "Discrete symbolic optimization and Boltzmann sampling by continuous\n  neural dynamics: Gradient Symbolic Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient Symbolic Computation is proposed as a means of solving discrete\nglobal optimization problems using a neurally plausible continuous stochastic\ndynamical system. Gradient symbolic dynamics involves two free parameters that\nmust be adjusted as a function of time to obtain the global maximizer at the\nend of the computation. We provide a summary of what is known about the GSC\ndynamics for special cases of settings of the parameters, and also establish\nthat there is a schedule for the two parameters for which convergence to the\ncorrect answer occurs with high probability. These results put the empirical\nresults already obtained for GSC on a sound theoretical footing.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 21:30:05 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Tupper", "Paul", ""], ["Smolensky", "Paul", ""], ["Cho", "Pyeong Whan", ""]]}, {"id": "1801.03563", "submitter": "Nia Dowell", "authors": "Nia Dowell, Tristian Nixon, and Arthur Graesser", "title": "Group Communication Analysis: A Computational Linguistics Approach for\n  Detecting Sociocognitive Roles in Multi-Party Interactions", "comments": null, "journal-ref": "Behavior Research Methods 2018", "doi": "10.3758/s13428-018-1102-z", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Roles are one of the most important concepts in understanding human\nsociocognitive behavior. During group interactions, members take on different\nroles within the discussion. Roles have distinct patterns of behavioral\nengagement (i.e., active or passive, leading or following), contribution\ncharacteristics (i.e., providing new information or echoing given material),\nand social orientation (i.e., individual or group). Different combinations of\nthese roles can produce characteristically different group outcomes, being\neither less or more productive towards collective goals. In online\ncollaborative learning environments, this can lead to better or worse learning\noutcomes for the individual participants. In this study, we propose and\nvalidate a novel approach for detecting emergent roles from the participants'\ncontributions and patterns of interaction. Specifically, we developed a group\ncommunication analysis (GCA) by combining automated computational linguistic\ntechniques with analyses of the sequential interactions of online group\ncommunication. The GCA was applied to three large collaborative interaction\ndatasets (participant N = 2,429; group N = 3,598). Cluster analyses and linear\nmixed-effects modeling were used to assess the validity of the GCA approach and\nthe influence of learner roles on student and group performance. The results\nindicate that participants' patterns in linguistic coordination and cohesion\nare representative of the roles that individuals play in collaborative\ndiscussions. More broadly, GCA provides a framework for researchers to explore\nthe micro intra- and interpersonal patterns associated with the participants'\nroles and the sociocognitive processes related to successful collaboration.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jan 2018 15:18:21 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Dowell", "Nia", ""], ["Nixon", "Tristian", ""], ["Graesser", "Arthur", ""]]}, {"id": "1801.03564", "submitter": "Omid Kashefi", "authors": "Omid Kashefi", "title": "Unsupervised Part-of-Speech Induction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Part-of-Speech (POS) tagging is an old and fundamental task in natural\nlanguage processing. While supervised POS taggers have shown promising\naccuracy, it is not always feasible to use supervised methods due to lack of\nlabeled data. In this project, we attempt to unsurprisingly induce POS tags by\niteratively looking for a recurring pattern of words through a hierarchical\nagglomerative clustering process. Our approach shows promising results when\ncompared to the tagging results of the state-of-the-art unsupervised POS\ntaggers.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 21:47:26 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Kashefi", "Omid", ""]]}, {"id": "1801.03603", "submitter": "Wenliang Chen", "authors": "Zhengqiu He and Wenliang Chen and Zhenghua Li and Meishan Zhang and\n  Wei Zhang and Min Zhang", "title": "SEE: Syntax-aware Entity Embedding for Neural Relation Extraction", "comments": "8 pages, AAAI-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distant supervised relation extraction is an efficient approach to scale\nrelation extraction to very large corpora, and has been widely used to find\nnovel relational facts from plain text. Recent studies on neural relation\nextraction have shown great progress on this task via modeling the sentences in\nlow-dimensional spaces, but seldom considered syntax information to model the\nentities. In this paper, we propose to learn syntax-aware entity embedding for\nneural relation extraction. First, we encode the context of entities on a\ndependency tree as sentence-level entity embedding based on tree-GRU. Then, we\nutilize both intra-sentence and inter-sentence attentions to obtain sentence\nset-level entity embedding over all sentences containing the focus entity pair.\nFinally, we combine both sentence embedding and entity embedding for relation\nclassification. We conduct experiments on a widely used real-world dataset and\nthe experimental results show that our model can make full use of all\ninformative instances and achieve state-of-the-art performance of relation\nextraction.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 01:16:13 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["He", "Zhengqiu", ""], ["Chen", "Wenliang", ""], ["Li", "Zhenghua", ""], ["Zhang", "Meishan", ""], ["Zhang", "Wei", ""], ["Zhang", "Min", ""]]}, {"id": "1801.03604", "submitter": "Chandra Khatri", "authors": "Ashwin Ram, Rohit Prasad, Chandra Khatri, Anu Venkatesh, Raefer\n  Gabriel, Qing Liu, Jeff Nunn, Behnam Hedayatnia, Ming Cheng, Ashish Nagar,\n  Eric King, Kate Bland, Amanda Wartick, Yi Pan, Han Song, Sk Jayadevan, Gene\n  Hwang, Art Pettigrue", "title": "Conversational AI: The Science Behind the Alexa Prize", "comments": "18 pages, 5 figures, Alexa Prize Proceedings Paper\n  (https://developer.amazon.com/alexaprize/proceedings), Alexa Prize University\n  Competition to advance Conversational AI", "journal-ref": "Alexa.Prize.Proceedings\n  https://developer.amazon.com/alexaprize/proceedings accessed (2018)-01-01", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CY cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational agents are exploding in popularity. However, much work remains\nin the area of social conversation as well as free-form conversation over a\nbroad range of domains and topics. To advance the state of the art in\nconversational AI, Amazon launched the Alexa Prize, a 2.5-million-dollar\nuniversity competition where sixteen selected university teams were challenged\nto build conversational agents, known as socialbots, to converse coherently and\nengagingly with humans on popular topics such as Sports, Politics,\nEntertainment, Fashion and Technology for 20 minutes. The Alexa Prize offers\nthe academic community a unique opportunity to perform research with a live\nsystem used by millions of users. The competition provided university teams\nwith real user conversational data at scale, along with the user-provided\nratings and feedback augmented with annotations by the Alexa team. This enabled\nteams to effectively iterate and make improvements throughout the competition\nwhile being evaluated in real-time through live user interactions. To build\ntheir socialbots, university teams combined state-of-the-art techniques with\nnovel strategies in the areas of Natural Language Understanding, Context\nModeling, Dialog Management, Response Generation, and Knowledge Acquisition. To\nsupport the efforts of participating teams, the Alexa Prize team made\nsignificant scientific and engineering investments to build and improve\nConversational Speech Recognition, Topic Tracking, Dialog Evaluation, Voice\nUser Experience, and tools for traffic management and scalability. This paper\noutlines the advances created by the university teams as well as the Alexa\nPrize team to achieve the common goal of solving the problem of Conversational\nAI.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 01:23:50 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Ram", "Ashwin", ""], ["Prasad", "Rohit", ""], ["Khatri", "Chandra", ""], ["Venkatesh", "Anu", ""], ["Gabriel", "Raefer", ""], ["Liu", "Qing", ""], ["Nunn", "Jeff", ""], ["Hedayatnia", "Behnam", ""], ["Cheng", "Ming", ""], ["Nagar", "Ashish", ""], ["King", "Eric", ""], ["Bland", "Kate", ""], ["Wartick", "Amanda", ""], ["Pan", "Yi", ""], ["Song", "Han", ""], ["Jayadevan", "Sk", ""], ["Hwang", "Gene", ""], ["Pettigrue", "Art", ""]]}, {"id": "1801.03615", "submitter": "Kai Song", "authors": "Kai Song, Yue Zhang, Min Zhang, Weihua Luo", "title": "Improved English to Russian Translation by Neural Suffix Prediction", "comments": "8 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) suffers a performance deficiency when a\nlimited vocabulary fails to cover the source or target side adequately, which\nhappens frequently when dealing with morphologically rich languages. To address\nthis problem, previous work focused on adjusting translation granularity or\nexpanding the vocabulary size. However, morphological information is relatively\nunder-considered in NMT architectures, which may further improve translation\nquality. We propose a novel method, which can not only reduce data sparsity but\nalso model morphology through a simple but effective mechanism. By predicting\nthe stem and suffix separately during decoding, our system achieves an\nimprovement of up to 1.98 BLEU compared with previous work on English to\nRussian translation. Our method is orthogonal to different NMT architectures\nand stably gains improvements on various domains.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 02:18:06 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Song", "Kai", ""], ["Zhang", "Yue", ""], ["Zhang", "Min", ""], ["Luo", "Weihua", ""]]}, {"id": "1801.03622", "submitter": "Chandra Khatri", "authors": "Fenfei Guo, Angeliki Metallinou, Chandra Khatri, Anirudh Raju, Anu\n  Venkatesh, Ashwin Ram", "title": "Topic-based Evaluation for Conversational Bots", "comments": "10 Pages, 2 figures, 9 tables. NIPS 2017 Conversational AI workshop\n  paper.\n  http://alborz-geramifard.com/workshops/nips17-Conversational-AI/Main.html", "journal-ref": "Nips.Workshop.ConversationalAI 2017-12-08", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialog evaluation is a challenging problem, especially for non task-oriented\ndialogs where conversational success is not well-defined. We propose to\nevaluate dialog quality using topic-based metrics that describe the ability of\na conversational bot to sustain coherent and engaging conversations on a topic,\nand the diversity of topics that a bot can handle. To detect conversation\ntopics per utterance, we adopt Deep Average Networks (DAN) and train a topic\nclassifier on a variety of question and query data categorized into multiple\ntopics. We propose a novel extension to DAN by adding a topic-word attention\ntable that allows the system to jointly capture topic keywords in an utterance\nand perform topic classification. We compare our proposed topic based metrics\nwith the ratings provided by users and show that our metrics both correlate\nwith and complement human judgment. Our analysis is performed on tens of\nthousands of real human-bot dialogs from the Alexa Prize competition and\nhighlights user expectations for conversational bots.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 03:20:02 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Guo", "Fenfei", ""], ["Metallinou", "Angeliki", ""], ["Khatri", "Chandra", ""], ["Raju", "Anirudh", ""], ["Venkatesh", "Anu", ""], ["Ram", "Ashwin", ""]]}, {"id": "1801.03625", "submitter": "Chandra Khatri", "authors": "Anu Venkatesh, Chandra Khatri, Ashwin Ram, Fenfei Guo, Raefer Gabriel,\n  Ashish Nagar, Rohit Prasad, Ming Cheng, Behnam Hedayatnia, Angeliki\n  Metallinou, Rahul Goel, Shaohua Yang, Anirudh Raju", "title": "On Evaluating and Comparing Open Domain Dialog Systems", "comments": "10 pages, 5 tables. NIPS 2017 Conversational AI workshop.\n  http://alborz-geramifard.com/workshops/nips17-Conversational-AI/Main.html", "journal-ref": "NIPS.Workshop.ConversationalAI 2017-12-08\n  http://alborz-geramifard.com/workshops/nips17-Conversational-AI/Main.html\n  accessed 2018-01-01", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational agents are exploding in popularity. However, much work remains\nin the area of non goal-oriented conversations, despite significant growth in\nresearch interest over recent years. To advance the state of the art in\nconversational AI, Amazon launched the Alexa Prize, a 2.5-million dollar\nuniversity competition where sixteen selected university teams built\nconversational agents to deliver the best social conversational experience.\nAlexa Prize provided the academic community with the unique opportunity to\nperform research with a live system used by millions of users. The subjectivity\nassociated with evaluating conversations is key element underlying the\nchallenge of building non-goal oriented dialogue systems. In this paper, we\npropose a comprehensive evaluation strategy with multiple metrics designed to\nreduce subjectivity by selecting metrics which correlate well with human\njudgement. The proposed metrics provide granular analysis of the conversational\nagents, which is not captured in human ratings. We show that these metrics can\nbe used as a reasonable proxy for human judgment. We provide a mechanism to\nunify the metrics for selecting the top performing agents, which has also been\napplied throughout the Alexa Prize competition. To our knowledge, to date it is\nthe largest setting for evaluating agents with millions of conversations and\nhundreds of thousands of ratings from users. We believe that this work is a\nstep towards an automatic evaluation process for conversational AIs.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 03:30:00 GMT"}, {"version": "v2", "created": "Wed, 26 Dec 2018 20:15:08 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Venkatesh", "Anu", ""], ["Khatri", "Chandra", ""], ["Ram", "Ashwin", ""], ["Guo", "Fenfei", ""], ["Gabriel", "Raefer", ""], ["Nagar", "Ashish", ""], ["Prasad", "Rohit", ""], ["Cheng", "Ming", ""], ["Hedayatnia", "Behnam", ""], ["Metallinou", "Angeliki", ""], ["Goel", "Rahul", ""], ["Yang", "Shaohua", ""], ["Raju", "Anirudh", ""]]}, {"id": "1801.03825", "submitter": "Mohnish Dubey", "authors": "Mohnish Dubey, Debayan Banerjee, Debanjan Chaudhuri, Jens Lehmann", "title": "EARL: Joint Entity and Relation Linking for Question Answering over\n  Knowledge Graphs", "comments": "International Semantic Web Conference 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many question answering systems over knowledge graphs rely on entity and\nrelation linking components in order to connect the natural language input to\nthe underlying knowledge graph. Traditionally, entity linking and relation\nlinking have been performed either as dependent sequential tasks or as\nindependent parallel tasks. In this paper, we propose a framework called EARL,\nwhich performs entity linking and relation linking as a joint task. EARL\nimplements two different solution strategies for which we provide a comparative\nanalysis in this paper: The first strategy is a formalisation of the joint\nentity and relation linking tasks as an instance of the Generalised Travelling\nSalesman Problem (GTSP). In order to be computationally feasible, we employ\napproximate GTSP solvers. The second strategy uses machine learning in order to\nexploit the connection density between nodes in the knowledge graph. It relies\non three base features and re-ranking steps in order to predict entities and\nrelations. We compare the strategies and evaluate them on a dataset with 5000\nquestions. Both strategies significantly outperform the current\nstate-of-the-art approaches for entity and relation linking.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 15:40:31 GMT"}, {"version": "v2", "created": "Tue, 16 Jan 2018 12:28:56 GMT"}, {"version": "v3", "created": "Sat, 16 Jun 2018 08:21:59 GMT"}, {"version": "v4", "created": "Mon, 25 Jun 2018 14:00:37 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Dubey", "Mohnish", ""], ["Banerjee", "Debayan", ""], ["Chaudhuri", "Debanjan", ""], ["Lehmann", "Jens", ""]]}, {"id": "1801.03911", "submitter": "Sahil Garg", "authors": "Sahil Garg and Greg Ver Steeg and Aram Galstyan", "title": "Stochastic Learning of Nonstationary Kernels for Natural Language\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language processing often involves computations with semantic or\nsyntactic graphs to facilitate sophisticated reasoning based on structural\nrelationships. While convolution kernels provide a powerful tool for comparing\ngraph structure based on node (word) level relationships, they are difficult to\ncustomize and can be computationally expensive. We propose a generalization of\nconvolution kernels, with a nonstationary model, for better expressibility of\nnatural languages in supervised settings. For a scalable learning of the\nparameters introduced with our model, we propose a novel algorithm that\nleverages stochastic sampling on k-nearest neighbor graphs, along with\napproximations based on locality-sensitive hashing. We demonstrate the\nadvantages of our approach on a challenging real-world (structured inference)\nproblem of automatically extracting biological models from the text of\nscientific papers.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 18:24:02 GMT"}, {"version": "v2", "created": "Thu, 1 Feb 2018 21:41:27 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Garg", "Sahil", ""], ["Steeg", "Greg Ver", ""], ["Galstyan", "Aram", ""]]}, {"id": "1801.04017", "submitter": "David Kernot", "authors": "David Kernot, Terry Bossomaier, Roger Bradbury", "title": "Did William Shakespeare and Thomas Kyd Write Edward III?", "comments": "13 pages, 5 Figures, 3 Tables", "journal-ref": "International Journal on Natural Language Computing (IJNLC) Vol.6,\n  No.6, December 2017", "doi": "10.5121/ijnlc.2017.6601", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  William Shakespeare is believed to be a significant author in the anonymous\nplay, The Reign of King Edward III, published in 1596. However, recently,\nThomas Kyd, has been suggested as the primary author. Using a neurolinguistics\napproach to authorship identification we use a four-feature technique, RPAS, to\nconvert the 19 scenes in Edward III into a multi-dimensional vector. Three\ncomplementary analytical techniques are applied to cluster the data and reduce\nsingle technique bias before an alternate method, seriation, is used to measure\nthe distances between clusters and test the strength of the connections. We\nfind the multivariate techniques robust and are able to allocate up to 14\nscenes to Thomas Kyd, and further question if scenes long believed to be\nShakespeare's are not his.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 23:40:39 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Kernot", "David", ""], ["Bossomaier", "Terry", ""], ["Bradbury", "Roger", ""]]}, {"id": "1801.04354", "submitter": "Yanjun  Qi Dr.", "authors": "Ji Gao, Jack Lanchantin, Mary Lou Soffa, Yanjun Qi", "title": "Black-box Generation of Adversarial Text Sequences to Evade Deep\n  Learning Classifiers", "comments": "This is an extended version of the 6page Workshop version appearing\n  in 1st Deep Learning and Security Workshop colocated with IEEE S&P", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although various techniques have been proposed to generate adversarial\nsamples for white-box attacks on text, little attention has been paid to\nblack-box attacks, which are more realistic scenarios. In this paper, we\npresent a novel algorithm, DeepWordBug, to effectively generate small text\nperturbations in a black-box setting that forces a deep-learning classifier to\nmisclassify a text input. We employ novel scoring strategies to identify the\ncritical tokens that, if modified, cause the classifier to make an incorrect\nprediction. Simple character-level transformations are applied to the\nhighest-ranked tokens in order to minimize the edit distance of the\nperturbation, yet change the original classification. We evaluated DeepWordBug\non eight real-world text datasets, including text classification, sentiment\nanalysis, and spam detection. We compare the result of DeepWordBug with two\nbaselines: Random (Black-box) and Gradient (White-box). Our experimental\nresults indicate that DeepWordBug reduces the prediction accuracy of current\nstate-of-the-art deep-learning models, including a decrease of 68\\% on average\nfor a Word-LSTM model and 48\\% on average for a Char-CNN model.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jan 2018 00:42:30 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 02:59:45 GMT"}, {"version": "v3", "created": "Sat, 7 Apr 2018 03:32:12 GMT"}, {"version": "v4", "created": "Mon, 16 Apr 2018 12:59:01 GMT"}, {"version": "v5", "created": "Wed, 23 May 2018 15:55:55 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Gao", "Ji", ""], ["Lanchantin", "Jack", ""], ["Soffa", "Mary Lou", ""], ["Qi", "Yanjun", ""]]}, {"id": "1801.04433", "submitter": "Heri Ramampiaro", "authors": "Georgios K. Pitsilis and Heri Ramampiaro and Helge Langseth", "title": "Detecting Offensive Language in Tweets Using Deep Learning", "comments": null, "journal-ref": "Applied Intelligence, 48(12), 4730-4742 (2018)", "doi": "10.1007/s10489-018-1242-y", "report-no": null, "categories": "cs.CL cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the important problem of discerning hateful content in\nsocial media. We propose a detection scheme that is an ensemble of Recurrent\nNeural Network (RNN) classifiers, and it incorporates various features\nassociated with user-related information, such as the users' tendency towards\nracism or sexism. These data are fed as input to the above classifiers along\nwith the word frequency vectors derived from the textual content. Our approach\nhas been evaluated on a publicly available corpus of 16k tweets, and the\nresults demonstrate its effectiveness in comparison to existing state of the\nart solutions. More specifically, our scheme can successfully distinguish\nracism and sexism messages from normal text, and achieve higher classification\nquality than current state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jan 2018 12:58:43 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Pitsilis", "Georgios K.", ""], ["Ramampiaro", "Heri", ""], ["Langseth", "Helge", ""]]}, {"id": "1801.04470", "submitter": "Kamil Bennani-Smires", "authors": "Kamil Bennani-Smires, Claudiu Musat, Andreea Hossmann, Michael\n  Baeriswyl, Martin Jaggi", "title": "Simple Unsupervised Keyphrase Extraction using Sentence Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyphrase extraction is the task of automatically selecting a small set of\nphrases that best describe a given free text document. Supervised keyphrase\nextraction requires large amounts of labeled training data and generalizes very\npoorly outside the domain of the training data. At the same time, unsupervised\nsystems have poor accuracy, and often do not generalize well, as they require\nthe input document to belong to a larger corpus also given as input. Addressing\nthese drawbacks, in this paper, we tackle keyphrase extraction from single\ndocuments with EmbedRank: a novel unsupervised method, that leverages sentence\nembeddings. EmbedRank achieves higher F-scores than graph-based state of the\nart systems on standard datasets and is suitable for real-time processing of\nlarge amounts of Web data. With EmbedRank, we also explicitly increase coverage\nand diversity among the selected keyphrases by introducing an embedding-based\nmaximal marginal relevance (MMR) for new phrases. A user study including over\n200 votes showed that, although reducing the phrases' semantic overlap leads to\nno gains in F-score, our high diversity selection is preferred by humans.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jan 2018 17:57:33 GMT"}, {"version": "v2", "created": "Mon, 19 Feb 2018 10:32:16 GMT"}, {"version": "v3", "created": "Wed, 5 Sep 2018 21:46:35 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Bennani-Smires", "Kamil", ""], ["Musat", "Claudiu", ""], ["Hossmann", "Andreea", ""], ["Baeriswyl", "Michael", ""], ["Jaggi", "Martin", ""]]}, {"id": "1801.04554", "submitter": "Charles Ferreira", "authors": "Charles Henrique Porto Ferreira, Debora Maria Rossi de Medeiros,\n  Fabricio Olivetti de Fran\\c{c}a", "title": "DCDistance: A Supervised Text Document Feature extraction based on class\n  labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text Mining is a field that aims at extracting information from textual data.\nOne of the challenges of such field of study comes from the pre-processing\nstage in which a vector (and structured) representation should be extracted\nfrom unstructured data. The common extraction creates large and sparse vectors\nrepresenting the importance of each term to a document. As such, this usually\nleads to the curse-of-dimensionality that plagues most machine learning\nalgorithms. To cope with this issue, in this paper we propose a new supervised\nfeature extraction and reduction algorithm, named DCDistance, that creates\nfeatures based on the distance between a document to a representative of each\nclass label. As such, the proposed technique can reduce the features set in\nmore than 99% of the original set. Additionally, this algorithm was also\ncapable of improving the classification accuracy over a set of benchmark\ndatasets when compared to traditional and state-of-the-art features selection\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jan 2018 13:28:19 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Ferreira", "Charles Henrique Porto", ""], ["de Medeiros", "Debora Maria Rossi", ""], ["de Fran\u00e7a", "Fabricio Olivetti", ""]]}, {"id": "1801.04726", "submitter": "Mantong Zhou", "authors": "Mantong Zhou, Minlie Huang, Xiaoyan Zhu", "title": "An Interpretable Reasoning Network for Multi-Relation Question Answering", "comments": "COLING 2018, 13pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-relation Question Answering is a challenging task, due to the\nrequirement of elaborated analysis on questions and reasoning over multiple\nfact triples in knowledge base. In this paper, we present a novel model called\nInterpretable Reasoning Network that employs an interpretable, hop-by-hop\nreasoning process for question answering. The model dynamically decides which\npart of an input question should be analyzed at each hop; predicts a relation\nthat corresponds to the current parsed results; utilizes the predicted relation\nto update the question representation and the state of the reasoning process;\nand then drives the next-hop reasoning. Experiments show that our model yields\nstate-of-the-art results on two datasets. More interestingly, the model can\noffer traceable and observable intermediate predictions for reasoning analysis\nand failure diagnosis, thereby allowing manual manipulation in predicting the\nfinal answer.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 10:31:01 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 15:28:22 GMT"}, {"version": "v3", "created": "Fri, 1 Jun 2018 04:34:29 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Zhou", "Mantong", ""], ["Huang", "Minlie", ""], ["Zhu", "Xiaoyan", ""]]}, {"id": "1801.04813", "submitter": "Quan Hoang", "authors": "Quan Hoang", "title": "Predicting Movie Genres Based on Plot Summaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This project explores several Machine Learning methods to predict movie\ngenres based on plot summaries. Naive Bayes, Word2Vec+XGBoost and Recurrent\nNeural Networks are used for text classification, while K-binary\ntransformation, rank method and probabilistic classification with learned\nprobability threshold are employed for the multi-label problem involved in the\ngenre tagging task.Experiments with more than 250,000 movies show that\nemploying the Gated Recurrent Units (GRU) neural networks for the probabilistic\nclassification with learned probability threshold approach achieves the best\nresult on the test set. The model attains a Jaccard Index of 50.0%, a F-score\nof 0.56, and a hit rate of 80.5%.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 14:11:57 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Hoang", "Quan", ""]]}, {"id": "1801.04871", "submitter": "Pararth Shah", "authors": "Pararth Shah, Dilek Hakkani-T\\\"ur, Gokhan T\\\"ur, Abhinav Rastogi,\n  Ankur Bapna, Neha Nayak, Larry Heck", "title": "Building a Conversational Agent Overnight with Dialogue Self-Play", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Machines Talking To Machines (M2M), a framework combining\nautomation and crowdsourcing to rapidly bootstrap end-to-end dialogue agents\nfor goal-oriented dialogues in arbitrary domains. M2M scales to new tasks with\njust a task schema and an API client from the dialogue system developer, but it\nis also customizable to cater to task-specific interactions. Compared to the\nWizard-of-Oz approach for data collection, M2M achieves greater diversity and\ncoverage of salient dialogue flows while maintaining the naturalness of\nindividual utterances. In the first phase, a simulated user bot and a\ndomain-agnostic system bot converse to exhaustively generate dialogue\n\"outlines\", i.e. sequences of template utterances and their semantic parses. In\nthe second phase, crowd workers provide contextual rewrites of the dialogues to\nmake the utterances more natural while preserving their meaning. The entire\nprocess can finish within a few hours. We propose a new corpus of 3,000\ndialogues spanning 2 domains collected with M2M, and present comparisons with\npopular dialogue datasets on the quality and diversity of the surface forms and\ndialogue flows.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 16:45:56 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Shah", "Pararth", ""], ["Hakkani-T\u00fcr", "Dilek", ""], ["T\u00fcr", "Gokhan", ""], ["Rastogi", "Abhinav", ""], ["Bapna", "Ankur", ""], ["Nayak", "Neha", ""], ["Heck", "Larry", ""]]}, {"id": "1801.04958", "submitter": "Robert Giaquinto", "authors": "Robert Giaquinto and Arindam Banerjee", "title": "Topic Modeling on Health Journals with Regularized Variational Inference", "comments": "Published in Thirty-Second AAAI Conference on Artificial\n  Intelligence, February 2018, New Orleans, Louisiana, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic modeling enables exploration and compact representation of a corpus.\nThe CaringBridge (CB) dataset is a massive collection of journals written by\npatients and caregivers during a health crisis. Topic modeling on the CB\ndataset, however, is challenging due to the asynchronous nature of multiple\nauthors writing about their health journeys. To overcome this challenge we\nintroduce the Dynamic Author-Persona topic model (DAP), a probabilistic\ngraphical model designed for temporal corpora with multiple authors. The\nnovelty of the DAP model lies in its representation of authors by a persona ---\nwhere personas capture the propensity to write about certain topics over time.\nFurther, we present a regularized variational inference algorithm, which we use\nto encourage the DAP model's personas to be distinct. Our results show\nsignificant improvements over competing topic models --- particularly after\nregularization, and highlight the DAP model's unique ability to capture common\njourneys shared by different authors.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 19:23:21 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Giaquinto", "Robert", ""], ["Banerjee", "Arindam", ""]]}, {"id": "1801.04962", "submitter": "Antonio Toral", "authors": "Antonio Toral and Andy Way", "title": "What Level of Quality can Neural Machine Translation Attain on Literary\n  Text?", "comments": "Chapter for the forthcoming book \"Translation Quality Assessment:\n  From Principles to Practice\" (Springer)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the rise of a new approach to MT, Neural MT (NMT), and its promising\nperformance on different text types, we assess the translation quality it can\nattain on what is perceived to be the greatest challenge for MT: literary text.\nSpecifically, we target novels, arguably the most popular type of literary\ntext. We build a literary-adapted NMT system for the English-to-Catalan\ntranslation direction and evaluate it against a system pertaining to the\nprevious dominant paradigm in MT: statistical phrase-based MT (PBSMT). To this\nend, for the first time we train MT systems, both NMT and PBSMT, on large\namounts of literary text (over 100 million words) and evaluate them on a set of\ntwelve widely known novels spanning from the the 1920s to the present day.\nAccording to the BLEU automatic evaluation metric, NMT is significantly better\nthan PBSMT (p < 0.01) on all the novels considered. Overall, NMT results in a\n11% relative improvement (3 points absolute) over PBSMT. A complementary human\nevaluation on three of the books shows that between 17% and 34% of the\ntranslations, depending on the book, produced by NMT (versus 8% and 20% with\nPBSMT) are perceived by native speakers of the target language to be of\nequivalent quality to translations produced by a professional human translator.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 19:39:19 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Toral", "Antonio", ""], ["Way", "Andy", ""]]}, {"id": "1801.05032", "submitter": "Feng-Lin Li", "authors": "Feng-Lin Li, Minghui Qiu, Haiqing Chen, Xiongwei Wang, Xing Gao, Jun\n  Huang, Juwei Ren, Zhongzhou Zhao, Weipeng Zhao, Lei Wang, Guwei Jin, Wei Chu", "title": "AliMe Assist: An Intelligent Assistant for Creating an Innovative\n  E-commerce Experience", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present AliMe Assist, an intelligent assistant designed for creating an\ninnovative online shopping experience in E-commerce. Based on question\nanswering (QA), AliMe Assist offers assistance service, customer service, and\nchatting service. It is able to take voice and text input, incorporate context\nto QA, and support multi-round interaction. Currently, it serves millions of\ncustomer questions per day and is able to address 85% of them. In this paper,\nwe demonstrate the system, present the underlying techniques, and share our\nexperience in dealing with real-world QA in the E-commerce field.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 12:11:30 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Li", "Feng-Lin", ""], ["Qiu", "Minghui", ""], ["Chen", "Haiqing", ""], ["Wang", "Xiongwei", ""], ["Gao", "Xing", ""], ["Huang", "Jun", ""], ["Ren", "Juwei", ""], ["Zhao", "Zhongzhou", ""], ["Zhao", "Weipeng", ""], ["Wang", "Lei", ""], ["Jin", "Guwei", ""], ["Chu", "Wei", ""]]}, {"id": "1801.05088", "submitter": "Chandra Khatri", "authors": "Chandra Khatri", "title": "Real-time Road Traffic Information Detection Through Social Media", "comments": "138 Pages, 21 Figures, 15 Tables. Masters Thesis in Computational\n  Science & Engineering Group @ Georgia Tech.\n  https://smartech.gatech.edu/bitstream/handle/1853/53889/KHATRI-THESIS-2015.pdf.\n  arXiv admin note: text overlap with arXiv:1703.03921 by other author", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In current study, a mechanism to extract traffic related information such as\ncongestion and incidents from textual data from the internet is proposed. The\ncurrent source of data is Twitter. As the data being considered is extremely\nlarge in size automated models are developed to stream, download, and mine the\ndata in real-time. Furthermore, if any tweet has traffic related information\nthen the models should be able to infer and extract this data.\n  Currently, the data is collected only for United States and a total of\n120,000 geo-tagged traffic related tweets are extracted, while six million\ngeo-tagged non-traffic related tweets are retrieved and classification models\nare trained. Furthermore, this data is used for various kinds of spatial and\ntemporal analysis. A mechanism to calculate level of traffic congestion,\nsafety, and traffic perception for cities in U.S. is proposed. Traffic\ncongestion and safety rankings for the various urban areas are obtained and\nthen they are statistically validated with existing widely adopted rankings.\nTraffic perception depicts the attitude and perception of people towards the\ntraffic.\n  It is also seen that traffic related data when visualized spatially and\ntemporally provides the same pattern as the actual traffic flows for various\nurban areas. When visualized at the city level, it is clearly visible that the\nflow of tweets is similar to flow of vehicles and that the traffic related\ntweets are representative of traffic within the cities. With all the findings\nin current study, it is shown that significant amount of traffic related\ninformation can be extracted from Twitter and other sources on internet.\nFurthermore, Twitter and these data sources are freely available and are not\nbound by spatial and temporal limitations. That is, wherever there is a user\nthere is a potential for data.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 01:26:33 GMT"}], "update_date": "2018-01-20", "authors_parsed": [["Khatri", "Chandra", ""]]}, {"id": "1801.05096", "submitter": "Komei Sugiura", "authors": "Komei Sugiura, Hisashi Kawai", "title": "Grounded Language Understanding for Manipulation Instructions Using\n  GAN-Based Classification", "comments": "6 pages, 3 figures, published at IEEE ASRU 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The target task of this study is grounded language understanding for domestic\nservice robots (DSRs). In particular, we focus on instruction understanding for\nshort sentences where verbs are missing. This task is of critical importance to\nbuild communicative DSRs because manipulation is essential for DSRs. Existing\ninstruction understanding methods usually estimate missing information only\nfrom non-grounded knowledge; therefore, whether the predicted action is\nphysically executable or not was unclear.\n  In this paper, we present a grounded instruction understanding method to\nestimate appropriate objects given an instruction and situation. We extend the\nGenerative Adversarial Nets (GAN) and build a GAN-based classifier using latent\nrepresentations. To quantitatively evaluate the proposed method, we have\ndeveloped a data set based on the standard data set used for Visual QA.\nExperimental results have shown that the proposed method gives the better\nresult than baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 02:05:50 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Sugiura", "Komei", ""], ["Kawai", "Hisashi", ""]]}, {"id": "1801.05119", "submitter": "Jinsong Su", "authors": "Jinsong Su, Shan Wu, Deyi Xiong, Yaojie Lu, Xianpei Han, Biao Zhang", "title": "Variational Recurrent Neural Machine Translation", "comments": "accepted by AAAI 18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partially inspired by successful applications of variational recurrent neural\nnetworks, we propose a novel variational recurrent neural machine translation\n(VRNMT) model in this paper. Different from the variational NMT, VRNMT\nintroduces a series of latent random variables to model the translation\nprocedure of a sentence in a generative way, instead of a single latent\nvariable. Specifically, the latent random variables are included into the\nhidden states of the NMT decoder with elements from the variational\nautoencoder. In this way, these variables are recurrently generated, which\nenables them to further capture strong and complex dependencies among the\noutput translations at different timesteps. In order to deal with the\nchallenges in performing efficient posterior inference and large-scale training\nduring the incorporation of latent variables, we build a neural posterior\napproximator, and equip it with a reparameterization technique to estimate the\nvariational lower bound. Experiments on Chinese-English and English-German\ntranslation tasks demonstrate that the proposed model achieves significant\nimprovements over both the conventional and variational NMT models.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 05:18:06 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Su", "Jinsong", ""], ["Wu", "Shan", ""], ["Xiong", "Deyi", ""], ["Lu", "Yaojie", ""], ["Han", "Xianpei", ""], ["Zhang", "Biao", ""]]}, {"id": "1801.05122", "submitter": "Jinsong Su", "authors": "Xiangwen Zhang, Jinsong Su, Yue Qin, Yang Liu, Rongrong Ji, Hongji\n  Wang", "title": "Asynchronous Bidirectional Decoding for Neural Machine Translation", "comments": "accepted by AAAI 18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dominant neural machine translation (NMT) models apply unified\nattentional encoder-decoder neural networks for translation. Traditionally, the\nNMT decoders adopt recurrent neural networks (RNNs) to perform translation in a\nleft-toright manner, leaving the target-side contexts generated from right to\nleft unexploited during translation. In this paper, we equip the conventional\nattentional encoder-decoder NMT framework with a backward decoder, in order to\nexplore bidirectional decoding for NMT. Attending to the hidden state sequence\nproduced by the encoder, our backward decoder first learns to generate the\ntarget-side hidden state sequence from right to left. Then, the forward decoder\nperforms translation in the forward direction, while in each translation\nprediction timestep, it simultaneously applies two attention models to consider\nthe source-side and reverse target-side hidden states, respectively. With this\nnew architecture, our model is able to fully exploit source- and target-side\ncontexts to improve translation quality altogether. Experimental results on\nNIST Chinese-English and WMT English-German translation tasks demonstrate that\nour model achieves substantial improvements over the conventional NMT by 3.14\nand 1.38 BLEU points, respectively. The source code of this work can be\nobtained from https://github.com/DeepLearnXMU/ABDNMT.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 05:21:43 GMT"}, {"version": "v2", "created": "Sat, 3 Feb 2018 08:43:03 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Zhang", "Xiangwen", ""], ["Su", "Jinsong", ""], ["Qin", "Yue", ""], ["Liu", "Yang", ""], ["Ji", "Rongrong", ""], ["Wang", "Hongji", ""]]}, {"id": "1801.05147", "submitter": "Wenliang Chen", "authors": "YaoSheng Yang and Meishan Zhang and Wenliang Chen and Wei Zhang and\n  Haofen Wang and Min Zhang", "title": "Adversarial Learning for Chinese NER from Crowd Annotations", "comments": "8 pages, AAAI-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To quickly obtain new labeled data, we can choose crowdsourcing as an\nalternative way at lower cost in a short time. But as an exchange, crowd\nannotations from non-experts may be of lower quality than those from experts.\nIn this paper, we propose an approach to performing crowd annotation learning\nfor Chinese Named Entity Recognition (NER) to make full use of the noisy\nsequence labels from multiple annotators. Inspired by adversarial learning, our\napproach uses a common Bi-LSTM and a private Bi-LSTM for representing\nannotator-generic and -specific information. The annotator-generic information\nis the common knowledge for entities easily mastered by the crowd. Finally, we\nbuild our Chinese NE tagger based on the LSTM-CRF model. In our experiments, we\ncreate two data sets for Chinese NER tasks from two domains. The experimental\nresults show that our system achieves better scores than strong baseline\nsystems.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 08:11:01 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Yang", "YaoSheng", ""], ["Zhang", "Meishan", ""], ["Chen", "Wenliang", ""], ["Zhang", "Wei", ""], ["Wang", "Haofen", ""], ["Zhang", "Min", ""]]}, {"id": "1801.05149", "submitter": "Young-Bum Kim", "authors": "Young-Bum Kim, Sungjin Lee, Karl Stratos", "title": "OneNet: Joint Domain, Intent, Slot Prediction for Spoken Language\n  Understanding", "comments": "5 pages conference paper accepted to IEEE ASRU 2017. Will be\n  published in December 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practice, most spoken language understanding systems process user input in\na pipelined manner; first domain is predicted, then intent and semantic slots\nare inferred according to the semantic frames of the predicted domain. The\npipeline approach, however, has some disadvantages: error propagation and lack\nof information sharing. To address these issues, we present a unified neural\nnetwork that jointly performs domain, intent, and slot predictions. Our\napproach adopts a principled architecture for multitask learning to fold in the\nstate-of-the-art models for each task. With a few more ingredients, e.g.\northography-sensitive input encoding and curriculum training, our model\ndelivered significant improvements in all three tasks across all domains over\nstrong baselines, including one using oracle prediction for domain detection,\non real user data of a commercial personal assistant.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 08:28:53 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Kim", "Young-Bum", ""], ["Lee", "Sungjin", ""], ["Stratos", "Karl", ""]]}, {"id": "1801.05164", "submitter": "Jean Neraud", "authors": "Jean N\\'eraud (LITIS, UNIROUEN), Carla Selmi (LITIS, UNIROUEN)", "title": "Embedding a $\\theta$-invariant code into a complete one", "comments": "arXiv admin note: text overlap with arXiv:1705.05564", "journal-ref": "Theoretical Computer Science, Elsevier", "doi": "10.1016/j.tcs.2018.08.022", "report-no": null, "categories": "cs.DM cs.CL math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let A be a finite or countable alphabet and let $\\theta$ be a literal\n(anti-)automorphism onto A * (by definition, such a correspondence is\ndeterminated by a permutation of the alphabet). This paper deals with sets\nwhich are invariant under $\\theta$ ($\\theta$-invariant for short) that is,\nlanguages L such that $\\theta$ (L) is a subset of L.We establish an extension\nof the famous defect theorem. With regards to the so-called notion of\ncompleteness, we provide a series of examples of finite complete\n$\\theta$-invariant codes. Moreover, we establish a formula which allows to\nembed any non-complete $\\theta$-invariant code into a complete one. As a\nconsequence, in the family of the so-called thin $\\theta$--invariant codes,\nmaximality and completeness are two equivalent notions.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 09:09:58 GMT"}, {"version": "v2", "created": "Mon, 13 Aug 2018 16:59:05 GMT"}, {"version": "v3", "created": "Mon, 3 Sep 2018 09:10:32 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["N\u00e9raud", "Jean", "", "LITIS, UNIROUEN"], ["Selmi", "Carla", "", "LITIS, UNIROUEN"]]}, {"id": "1801.05420", "submitter": "Qinglong Wang", "authors": "Qinglong Wang, Kaixuan Zhang, Alexander G. Ororbia II, Xinyu Xing, Xue\n  Liu, C. Lee Giles", "title": "A Comparative Study of Rule Extraction for Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding recurrent networks through rule extraction has a long history.\nThis has taken on new interests due to the need for interpreting or verifying\nneural networks. One basic form for representing stateful rules is\ndeterministic finite automata (DFA). Previous research shows that extracting\nDFAs from trained second-order recurrent networks is not only possible but also\nrelatively stable. Recently, several new types of recurrent networks with more\ncomplicated architectures have been introduced. These handle challenging\nlearning tasks usually involving sequential data. However, it remains an open\nproblem whether DFAs can be adequately extracted from these models.\nSpecifically, it is not clear how DFA extraction will be affected when applied\nto different recurrent networks trained on data sets with different levels of\ncomplexity. Here, we investigate DFA extraction on several widely adopted\nrecurrent networks that are trained to learn a set of seven regular Tomita\ngrammars. We first formally analyze the complexity of Tomita grammars and\ncategorize these grammars according to that complexity. Then we empirically\nevaluate different recurrent networks for their performance of DFA extraction\non all Tomita grammars. Our experiments show that for most recurrent networks,\ntheir extraction performance decreases as the complexity of the underlying\ngrammar increases. On grammars of lower complexity, most recurrent networks\nobtain desirable extraction performance. As for grammars with the highest level\nof complexity, while several complicated models fail with only certain\nrecurrent networks having satisfactory extraction performance.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 03:19:37 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 19:34:54 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Wang", "Qinglong", ""], ["Zhang", "Kaixuan", ""], ["Ororbia", "Alexander G.", "II"], ["Xing", "Xinyu", ""], ["Liu", "Xue", ""], ["Giles", "C. Lee", ""]]}, {"id": "1801.05453", "submitter": "William Murdoch", "authors": "W. James Murdoch, Peter J. Liu, Bin Yu", "title": "Beyond Word Importance: Contextual Decomposition to Extract Interactions\n  from LSTMs", "comments": "Oral presentation at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The driving force behind the recent success of LSTMs has been their ability\nto learn complex and non-linear relationships. Consequently, our inability to\ndescribe these relationships has led to LSTMs being characterized as black\nboxes. To this end, we introduce contextual decomposition (CD), an\ninterpretation algorithm for analysing individual predictions made by standard\nLSTMs, without any changes to the underlying model. By decomposing the output\nof a LSTM, CD captures the contributions of combinations of words or variables\nto the final prediction of an LSTM. On the task of sentiment analysis with the\nYelp and SST data sets, we show that CD is able to reliably identify words and\nphrases of contrasting sentiment, and how they are combined to yield the LSTM's\nfinal prediction. Using the phrase-level labels in SST, we also demonstrate\nthat CD is able to successfully extract positive and negative negations from an\nLSTM, something which has not previously been done.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 19:21:48 GMT"}, {"version": "v2", "created": "Fri, 27 Apr 2018 22:25:53 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Murdoch", "W. James", ""], ["Liu", "Peter J.", ""], ["Yu", "Bin", ""]]}, {"id": "1801.05613", "submitter": "Shrainik Jain", "authors": "Shrainik Jain, Bill Howe, Jiaqi Yan, Thierry Cruanes", "title": "Query2Vec: An Evaluation of NLP Techniques for Generalized Workload\n  Analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider methods for learning vector representations of SQL queries to\nsupport generalized workload analytics tasks, including workload summarization\nfor index selection and predicting queries that will trigger memory errors. We\nconsider vector representations of both raw SQL text and optimized query plans,\nand evaluate these methods on synthetic and real SQL workloads. We find that\ngeneral algorithms based on vector representations can outperform existing\napproaches that rely on specialized features. For index recommendation, we\ncluster the vector representations to compress large workloads with no loss in\nperformance from the recommended index. For error prediction, we train a\nclassifier over learned vectors that can automatically relate subtle syntactic\npatterns with specific errors raised during query execution. Surprisingly, we\nalso find that these methods enable transfer learning, where a model trained on\none SQL corpus can be applied to an unrelated corpus and still enable good\nperformance. We find that these general approaches, when trained on a large\ncorpus of SQL queries, provides a robust foundation for a variety of workload\nanalysis tasks and database features, without requiring application-specific\nfeature engineering.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 10:21:49 GMT"}, {"version": "v2", "created": "Fri, 2 Feb 2018 22:07:06 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Jain", "Shrainik", ""], ["Howe", "Bill", ""], ["Yan", "Jiaqi", ""], ["Cruanes", "Thierry", ""]]}, {"id": "1801.05617", "submitter": "Gilles Jacobs", "authors": "Cynthia Van Hee, Gilles Jacobs, Chris Emmery, Bart Desmet, Els\n  Lefever, Ben Verhoeven, Guy De Pauw, Walter Daelemans and V\\'eronique Hoste", "title": "Automatic Detection of Cyberbullying in Social Media Text", "comments": "21 pages, 9 tables, under review", "journal-ref": null, "doi": "10.1371/journal.pone.0203794", "report-no": null, "categories": "cs.CL cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While social media offer great communication opportunities, they also\nincrease the vulnerability of young people to threatening situations online.\nRecent studies report that cyberbullying constitutes a growing problem among\nyoungsters. Successful prevention depends on the adequate detection of\npotentially harmful messages and the information overload on the Web requires\nintelligent systems to identify potential risks automatically. The focus of\nthis paper is on automatic cyberbullying detection in social media text by\nmodelling posts written by bullies, victims, and bystanders of online bullying.\nWe describe the collection and fine-grained annotation of a training corpus for\nEnglish and Dutch and perform a series of binary classification experiments to\ndetermine the feasibility of automatic cyberbullying detection. We make use of\nlinear support vector machines exploiting a rich feature set and investigate\nwhich information sources contribute the most for this particular task.\nExperiments on a holdout test set reveal promising results for the detection of\ncyberbullying-related posts. After optimisation of the hyperparameters, the\nclassifier yields an F1-score of 64% and 61% for English and Dutch\nrespectively, and considerably outperforms baseline systems based on keywords\nand word unigrams.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 10:38:20 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Van Hee", "Cynthia", ""], ["Jacobs", "Gilles", ""], ["Emmery", "Chris", ""], ["Desmet", "Bart", ""], ["Lefever", "Els", ""], ["Verhoeven", "Ben", ""], ["De Pauw", "Guy", ""], ["Daelemans", "Walter", ""], ["Hoste", "V\u00e9ronique", ""]]}, {"id": "1801.06024", "submitter": "Gino Brunner", "authors": "Gino Brunner, Yuyi Wang, Roger Wattenhofer, Michael Weigelt", "title": "Natural Language Multitasking: Analyzing and Improving Syntactic\n  Saliency of Hidden Representations", "comments": "The 31st Annual Conference on Neural Information Processing (NIPS) -\n  Workshop on Learning Disentangled Features: from Perception to Control, Long\n  Beach, CA, December 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We train multi-task autoencoders on linguistic tasks and analyze the learned\nhidden sentence representations. The representations change significantly when\ntranslation and part-of-speech decoders are added. The more decoders a model\nemploys, the better it clusters sentences according to their syntactic\nsimilarity, as the representation space becomes less entangled. We explore the\nstructure of the representation space by interpolating between sentences, which\nyields interesting pseudo-English sentences, many of which have recognizable\nsyntactic structure. Lastly, we point out an interesting property of our\nmodels: The difference-vector between two sentences can be added to change a\nthird sentence with similar features in a meaningful way.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 14:10:37 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Brunner", "Gino", ""], ["Wang", "Yuyi", ""], ["Wattenhofer", "Roger", ""], ["Weigelt", "Michael", ""]]}, {"id": "1801.06126", "submitter": "Yedid Hoshen", "authors": "Yedid Hoshen and Lior Wolf", "title": "Non-Adversarial Unsupervised Word Translation", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised word translation from non-parallel inter-lingual corpora has\nattracted much research interest. Very recently, neural network methods trained\nwith adversarial loss functions achieved high accuracy on this task. Despite\nthe impressive success of the recent techniques, they suffer from the typical\ndrawbacks of generative adversarial models: sensitivity to hyper-parameters,\nlong training time and lack of interpretability. In this paper, we make the\nobservation that two sufficiently similar distributions can be aligned\ncorrectly with iterative matching methods. We present a novel method that first\naligns the second moment of the word distributions of the two languages and\nthen iteratively refines the alignment. Extensive experiments on word\ntranslation of European and Non-European languages show that our method\nachieves better performance than recent state-of-the-art deep adversarial\napproaches and is competitive with the supervised baseline. It is also\nefficient, easy to parallelize on CPU and interpretable.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 16:59:19 GMT"}, {"version": "v2", "created": "Sun, 22 Apr 2018 20:56:10 GMT"}, {"version": "v3", "created": "Mon, 13 Aug 2018 15:13:05 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Hoshen", "Yedid", ""], ["Wolf", "Lior", ""]]}, {"id": "1801.06146", "submitter": "Sebastian Ruder", "authors": "Jeremy Howard, Sebastian Ruder", "title": "Universal Language Model Fine-tuning for Text Classification", "comments": "ACL 2018, fixed denominator in Equation 3, line 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inductive transfer learning has greatly impacted computer vision, but\nexisting approaches in NLP still require task-specific modifications and\ntraining from scratch. We propose Universal Language Model Fine-tuning\n(ULMFiT), an effective transfer learning method that can be applied to any task\nin NLP, and introduce techniques that are key for fine-tuning a language model.\nOur method significantly outperforms the state-of-the-art on six text\nclassification tasks, reducing the error by 18-24% on the majority of datasets.\nFurthermore, with only 100 labeled examples, it matches the performance of\ntraining from scratch on 100x more data. We open-source our pretrained models\nand code.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 17:54:52 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 13:57:04 GMT"}, {"version": "v3", "created": "Tue, 15 May 2018 22:02:11 GMT"}, {"version": "v4", "created": "Thu, 17 May 2018 17:46:49 GMT"}, {"version": "v5", "created": "Wed, 23 May 2018 09:23:47 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Howard", "Jeremy", ""], ["Ruder", "Sebastian", ""]]}, {"id": "1801.06172", "submitter": "Shuai Wang", "authors": "Shuai Wang, Mianwei Zhou, Geli Fei, Yi Chang, Bing Liu", "title": "Contextual and Position-Aware Factorization Machines for Sentiment\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While existing machine learning models have achieved great success for\nsentiment classification, they typically do not explicitly capture\nsentiment-oriented word interaction, which can lead to poor results for\nfine-grained analysis at the snippet level (a phrase or sentence).\nFactorization Machine provides a possible approach to learning element-wise\ninteraction for recommender systems, but they are not directly applicable to\nour task due to the inability to model contexts and word sequences. In this\nwork, we develop two Position-aware Factorization Machines which consider word\ninteraction, context and position information. Such information is jointly\nencoded in a set of sentiment-oriented word interaction vectors. Compared to\ntraditional word embeddings, SWI vectors explicitly capture sentiment-oriented\nword interaction and simplify the parameter learning. Experimental results show\nthat while they have comparable performance with state-of-the-art methods for\ndocument-level classification, they benefit the snippet/sentence-level\nsentiment analysis.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 18:51:58 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Wang", "Shuai", ""], ["Zhou", "Mianwei", ""], ["Fei", "Geli", ""], ["Chang", "Yi", ""], ["Liu", "Bing", ""]]}, {"id": "1801.06176", "submitter": "Xiujun Li", "authors": "Baolin Peng and Xiujun Li and Jianfeng Gao and Jingjing Liu and\n  Kam-Fai Wong and Shang-Yu Su", "title": "Deep Dyna-Q: Integrating Planning for Task-Completion Dialogue Policy\n  Learning", "comments": "11 pages, 8 figures, Accepted in ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a task-completion dialogue agent via reinforcement learning (RL) is\ncostly because it requires many interactions with real users. One common\nalternative is to use a user simulator. However, a user simulator usually lacks\nthe language complexity of human interlocutors and the biases in its design may\ntend to degrade the agent. To address these issues, we present Deep Dyna-Q,\nwhich to our knowledge is the first deep RL framework that integrates planning\nfor task-completion dialogue policy learning. We incorporate into the dialogue\nagent a model of the environment, referred to as the world model, to mimic real\nuser response and generate simulated experience. During dialogue policy\nlearning, the world model is constantly updated with real user experience to\napproach real user behavior, and in turn, the dialogue agent is optimized using\nboth real experience and simulated experience. The effectiveness of our\napproach is demonstrated on a movie-ticket booking task in both simulated and\nhuman-in-the-loop settings.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 18:57:33 GMT"}, {"version": "v2", "created": "Sun, 13 May 2018 22:31:38 GMT"}, {"version": "v3", "created": "Wed, 23 May 2018 17:52:27 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Peng", "Baolin", ""], ["Li", "Xiujun", ""], ["Gao", "Jianfeng", ""], ["Liu", "Jingjing", ""], ["Wong", "Kam-Fai", ""], ["Su", "Shang-Yu", ""]]}, {"id": "1801.06261", "submitter": "Devendra Singh Sachan", "authors": "Devendra Singh Sachan and Manzil Zaheer and Ruslan Salakhutdinov", "title": "Investigating the Working of Text Classifiers", "comments": "Proceedings of COLING 2018, the 27th International Conference on\n  Computational Linguistics: Technical Papers (COLING 2018), NIPS 2017 Workshop\n  on Deep Learning: Bridging Theory and Practice", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text classification is one of the most widely studied tasks in natural\nlanguage processing. Motivated by the principle of compositionality, large\nmultilayer neural network models have been employed for this task in an attempt\nto effectively utilize the constituent expressions. Almost all of the reported\nwork train large networks using discriminative approaches, which come with a\ncaveat of no proper capacity control, as they tend to latch on to any signal\nthat may not generalize. Using various recent state-of-the-art approaches for\ntext classification, we explore whether these models actually learn to compose\nthe meaning of the sentences or still just focus on some keywords or lexicons\nfor classifying the document. To test our hypothesis, we carefully construct\ndatasets where the training and test splits have no direct overlap of such\nlexicons, but overall language structure would be similar. We study various\ntext classifiers and observe that there is a big performance drop on these\ndatasets. Finally, we show that even simple models with our proposed\nregularization techniques, which disincentivize focusing on key lexicons, can\nsubstantially improve classification accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 00:29:55 GMT"}, {"version": "v2", "created": "Sun, 5 Aug 2018 16:08:59 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Sachan", "Devendra Singh", ""], ["Zaheer", "Manzil", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1801.06287", "submitter": "Linyuan Gong", "authors": "Linyuan Gong, Ruyi Ji", "title": "What Does a TextCNN Learn?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TextCNN, the convolutional neural network for text, is a useful deep learning\nalgorithm for sentence classification tasks such as sentiment analysis and\nquestion classification. However, neural networks have long been known as black\nboxes because interpreting them is a challenging task. Researchers have\ndeveloped several tools to understand a CNN for image classification by deep\nvisualization, but research about deep TextCNNs is still insufficient. In this\npaper, we are trying to understand what a TextCNN learns on two classical NLP\ndatasets. Our work focuses on functions of different convolutional kernels and\ncorrelations between convolutional kernels.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 04:02:04 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Gong", "Linyuan", ""], ["Ji", "Ruyi", ""]]}, {"id": "1801.06294", "submitter": "Shaika Chowdhury", "authors": "Shaika Chowdhury, Chenwei Zhang and Philip S. Yu", "title": "Multi-Task Pharmacovigilance Mining from Social Media Posts", "comments": "Accepted in the research track of The Web Conference(WWW) 2018", "journal-ref": null, "doi": "10.1145/3178876.3186053", "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media has grown to be a crucial information source for\npharmacovigilance studies where an increasing number of people post adverse\nreactions to medical drugs that are previously unreported. Aiming to\neffectively monitor various aspects of Adverse Drug Reactions (ADRs) from\ndiversely expressed social medical posts, we propose a multi-task neural\nnetwork framework that learns several tasks associated with ADR monitoring with\ndifferent levels of supervisions collectively. Besides being able to correctly\nclassify ADR posts and accurately extract ADR mentions from online posts, the\nproposed framework is also able to further understand reasons for which the\ndrug is being taken, known as 'indication', from the given social media post. A\ncoverage-based attention mechanism is adopted in our framework to help the\nmodel properly identify 'phrasal' ADRs and Indications that are attentive to\nmultiple words in a post. Our framework is applicable in situations where\nlimited parallel data for different pharmacovigilance tasks are available.We\nevaluate the proposed framework on real-world Twitter datasets, where the\nproposed model outperforms the state-of-the-art alternatives of each individual\ntask consistently.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 05:04:21 GMT"}, {"version": "v2", "created": "Sun, 4 Feb 2018 02:07:45 GMT"}, {"version": "v3", "created": "Tue, 13 Feb 2018 06:07:22 GMT"}, {"version": "v4", "created": "Thu, 15 Feb 2018 03:03:56 GMT"}, {"version": "v5", "created": "Fri, 16 Feb 2018 18:43:05 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Chowdhury", "Shaika", ""], ["Zhang", "Chenwei", ""], ["Yu", "Philip S.", ""]]}, {"id": "1801.06353", "submitter": "Siddique Latif", "authors": "Siddique Latif, Rajib Rana, Shahzad Younis, Junaid Qadir, and Julien\n  Epps", "title": "Transfer Learning for Improving Speech Emotion Classification Accuracy", "comments": "Proc. Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of existing speech emotion recognition research focuses on\nautomatic emotion detection using training and testing data from same corpus\ncollected under the same conditions. The performance of such systems has been\nshown to drop significantly in cross-corpus and cross-language scenarios. To\naddress the problem, this paper exploits a transfer learning technique to\nimprove the performance of speech emotion recognition systems that is novel in\ncross-language and cross-corpus scenarios. Evaluations on five different\ncorpora in three different languages show that Deep Belief Networks (DBNs)\noffer better accuracy than previous approaches on cross-corpus emotion\nrecognition, relative to a Sparse Autoencoder and SVM baseline system. Results\nalso suggest that using a large number of languages for training and using a\nsmall fraction of the target data in training can significantly boost accuracy\ncompared with baseline also for the corpus with limited training examples.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 10:16:11 GMT"}, {"version": "v2", "created": "Mon, 22 Jan 2018 07:51:51 GMT"}, {"version": "v3", "created": "Mon, 26 Mar 2018 13:39:49 GMT"}, {"version": "v4", "created": "Tue, 28 Jul 2020 01:36:53 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Latif", "Siddique", ""], ["Rana", "Rajib", ""], ["Younis", "Shahzad", ""], ["Qadir", "Junaid", ""], ["Epps", "Julien", ""]]}, {"id": "1801.06407", "submitter": "Andrey Kutuzov", "authors": "Andrey Kutuzov, Maria Kunilovskaya", "title": "Size vs. Structure in Training Corpora for Word Embedding Models:\n  Araneum Russicum Maximum and Russian National Corpus", "comments": null, "journal-ref": "In: van der Aalst W. et al. (eds) Analysis of Images, Social\n  Networks and Texts. AIST 2017. Lecture Notes in Computer Science, vol 10716.\n  Springer, Cham", "doi": "10.1007/978-3-319-73013-4_5", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we present a distributional word embedding model trained on\none of the largest available Russian corpora: Araneum Russicum Maximum (over 10\nbillion words crawled from the web). We compare this model to the model trained\non the Russian National Corpus (RNC). The two corpora are much different in\ntheir size and compilation procedures. We test these differences by evaluating\nthe trained models against the Russian part of the Multilingual SimLex999\nsemantic similarity dataset. We detect and describe numerous issues in this\ndataset and publish a new corrected version. Aside from the already known fact\nthat the RNC is generally a better training corpus than web corpora, we\nenumerate and explain fine differences in how the models process semantic\nsimilarity task, what parts of the evaluation set are difficult for particular\nmodels and why. Additionally, the learning curves for both models are\ndescribed, showing that the RNC is generally more robust as training material\nfor this task.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 14:11:16 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Kutuzov", "Andrey", ""], ["Kunilovskaya", "Maria", ""]]}, {"id": "1801.06422", "submitter": "Nina Poerner", "authors": "Nina Poerner, Benjamin Roth and Hinrich Sch\\\"utze", "title": "Evaluating neural network explanation methods using hybrid documents and\n  morphological agreement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The behavior of deep neural networks (DNNs) is hard to understand. This makes\nit necessary to explore post hoc explanation methods. We conduct the first\ncomprehensive evaluation of explanation methods for NLP. To this end, we design\ntwo novel evaluation paradigms that cover two important classes of NLP\nproblems: small context and large context problems. Both paradigms require no\nmanual annotation and are therefore broadly applicable. We also introduce\nLIMSSE, an explanation method inspired by LIME that is designed for NLP. We\nshow empirically that LIMSSE, LRP and DeepLIFT are the most effective\nexplanation methods and recommend them for explaining DNNs in NLP.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 14:41:45 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 10:20:13 GMT"}, {"version": "v3", "created": "Mon, 6 May 2019 12:28:05 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Poerner", "Nina", ""], ["Roth", "Benjamin", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1801.06436", "submitter": "Goran Glava\\v{s}", "authors": "Goran Glava\\v{s}, Marc Franco-Salvador, Simone Paolo Ponzetto, Paolo\n  Rosso", "title": "A Resource-Light Method for Cross-Lingual Semantic Textual Similarity", "comments": "Accepted for publication in Knowledge-Based Systems journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recognizing semantically similar sentences or paragraphs across languages is\nbeneficial for many tasks, ranging from cross-lingual information retrieval and\nplagiarism detection to machine translation. Recently proposed methods for\npredicting cross-lingual semantic similarity of short texts, however, make use\nof tools and resources (e.g., machine translation systems, syntactic parsers or\nnamed entity recognition) that for many languages (or language pairs) do not\nexist. In contrast, we propose an unsupervised and a very resource-light\napproach for measuring semantic similarity between texts in different\nlanguages. To operate in the bilingual (or multilingual) space, we project\ncontinuous word vectors (i.e., word embeddings) from one language to the vector\nspace of the other language via the linear translation model. We then align\nwords according to the similarity of their vectors in the bilingual embedding\nspace and investigate different unsupervised measures of semantic similarity\nexploiting bilingual embeddings and word alignments. Requiring only a\nlimited-size set of word translation pairs between the languages, the proposed\napproach is applicable to virtually any pair of languages for which there\nexists a sufficiently large corpus, required to learn monolingual word\nembeddings. Experimental results on three different datasets for measuring\nsemantic textual similarity show that our simple resource-light approach\nreaches performance close to that of supervised and resource intensive methods,\ndisplaying stability across different language pairs. Furthermore, we evaluate\nthe proposed method on two extrinsic tasks, namely extraction of parallel\nsentences from comparable corpora and cross lingual plagiarism detection, and\nshow that it yields performance comparable to those of complex\nresource-intensive state-of-the-art models for the respective tasks.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 15:00:33 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Glava\u0161", "Goran", ""], ["Franco-Salvador", "Marc", ""], ["Ponzetto", "Simone Paolo", ""], ["Rosso", "Paolo", ""]]}, {"id": "1801.06480", "submitter": "Tushar Semwal", "authors": "Tushar Semwal, Gaurav Mathur, Promod Yenigalla and Shivashankar B.\n  Nair", "title": "A Practitioners' Guide to Transfer Learning for Text Classification\n  using Convolutional Neural Networks", "comments": "9 pages, 2 figures, accepted in SDM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer Learning (TL) plays a crucial role when a given dataset has\ninsufficient labeled examples to train an accurate model. In such scenarios,\nthe knowledge accumulated within a model pre-trained on a source dataset can be\ntransferred to a target dataset, resulting in the improvement of the target\nmodel. Though TL is found to be successful in the realm of image-based\napplications, its impact and practical use in Natural Language Processing (NLP)\napplications is still a subject of research. Due to their hierarchical\narchitecture, Deep Neural Networks (DNN) provide flexibility and customization\nin adjusting their parameters and depth of layers, thereby forming an apt area\nfor exploiting the use of TL. In this paper, we report the results and\nconclusions obtained from extensive empirical experiments using a Convolutional\nNeural Network (CNN) and try to uncover thumb rules to ensure a successful\npositive transfer. In addition, we also highlight the flawed means that could\nlead to a negative transfer. We explore the transferability of various layers\nand describe the effect of varying hyper-parameters on the transfer\nperformance. Also, we present a comparison of accuracy value and model size\nagainst state-of-the-art methods. Finally, we derive inferences from the\nempirical results and provide best practices to achieve a successful positive\ntransfer.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 16:24:47 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Semwal", "Tushar", ""], ["Mathur", "Gaurav", ""], ["Yenigalla", "Promod", ""], ["Nair", "Shivashankar B.", ""]]}, {"id": "1801.06482", "submitter": "Amit Awekar", "authors": "Sweta Agrawal, Amit Awekar", "title": "Deep Learning for Detecting Cyberbullying Across Multiple Social Media\n  Platforms", "comments": "Accepted for ECIR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Harassment by cyberbullies is a significant phenomenon on the social media.\nExisting works for cyberbullying detection have at least one of the following\nthree bottlenecks. First, they target only one particular social media platform\n(SMP). Second, they address just one topic of cyberbullying. Third, they rely\non carefully handcrafted features of the data. We show that deep learning based\nmodels can overcome all three bottlenecks. Knowledge learned by these models on\none dataset can be transferred to other datasets. We performed extensive\nexperiments using three real-world datasets: Formspring (12k posts), Twitter\n(16k posts), and Wikipedia(100k posts). Our experiments provide several useful\ninsights about cyberbullying detection. To the best of our knowledge, this is\nthe first work that systematically analyzes cyberbullying detection on various\ntopics across multiple SMPs using deep learning based models and transfer\nlearning.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 16:27:36 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Agrawal", "Sweta", ""], ["Awekar", "Amit", ""]]}, {"id": "1801.06607", "submitter": "Yuanhang Su", "authors": "Yuanhang Su, Yuzhong Huang and C.-C. Jay Kuo", "title": "Efficient Text Classification Using Tree-structured Multi-linear\n  Principal Component Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel text data dimension reduction technique, called the tree-structured\nmulti-linear principal component anal- ysis (TMPCA), is proposed in this work.\nBeing different from traditional text dimension reduction methods that deal\nwith the word-level representation, the TMPCA technique reduces the dimension\nof input sequences and sentences to simplify the following text classification\ntasks. It is shown mathematically and experimentally that the TMPCA tool\ndemands much lower complexity (and, hence, less computing power) than the\nordinary principal component analysis (PCA). Furthermore, it is demon- strated\nby experimental results that the support vector machine (SVM) method applied to\nthe TMPCA-processed data achieves commensurable or better performance than the\nstate-of-the-art recurrent neural network (RNN) approach.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jan 2018 00:15:09 GMT"}, {"version": "v2", "created": "Sat, 24 Feb 2018 03:54:26 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Su", "Yuanhang", ""], ["Huang", "Yuzhong", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "1801.06613", "submitter": "Xuancheng Ren", "authors": "Xuancheng Ren, Xu Sun, Ji Wen, Bingzhen Wei, Weidong Zhan, Zhiyuan\n  Zhang", "title": "Building an Ellipsis-aware Chinese Dependency Treebank for Web Text", "comments": "The treebank is available at\n  https://github.com/lancopku/Chinese-Dependency-Treebank-with-Ellipsis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web 2.0 has brought with it numerous user-produced data revealing one's\nthoughts, experiences, and knowledge, which are a great source for many tasks,\nsuch as information extraction, and knowledge base construction. However, the\ncolloquial nature of the texts poses new challenges for current natural\nlanguage processing techniques, which are more adapt to the formal form of the\nlanguage. Ellipsis is a common linguistic phenomenon that some words are left\nout as they are understood from the context, especially in oral utterance,\nhindering the improvement of dependency parsing, which is of great importance\nfor tasks relied on the meaning of the sentence. In order to promote research\nin this area, we are releasing a Chinese dependency treebank of 319 weibos,\ncontaining 572 sentences with omissions restored and contexts reserved.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jan 2018 01:59:21 GMT"}, {"version": "v2", "created": "Tue, 23 Jan 2018 04:35:30 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Ren", "Xuancheng", ""], ["Sun", "Xu", ""], ["Wen", "Ji", ""], ["Wei", "Bingzhen", ""], ["Zhan", "Weidong", ""], ["Zhang", "Zhiyuan", ""]]}, {"id": "1801.06700", "submitter": "Iulian Vlad Serban", "authors": "Iulian V. Serban, Chinnadhurai Sankar, Mathieu Germain, Saizheng\n  Zhang, Zhouhan Lin, Sandeep Subramanian, Taesup Kim, Michael Pieper, Sarath\n  Chandar, Nan Rosemary Ke, Sai Rajeswar, Alexandre de Brebisson, Jose M. R.\n  Sotelo, Dendi Suhubdy, Vincent Michalski, Alexandre Nguyen, Joelle Pineau,\n  Yoshua Bengio", "title": "A Deep Reinforcement Learning Chatbot (Short Version)", "comments": "9 pages, 1 figure, 2 tables; presented at NIPS 2017, Conversational\n  AI: \"Today's Practice and Tomorrow's Potential\" Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present MILABOT: a deep reinforcement learning chatbot developed by the\nMontreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize\ncompetition. MILABOT is capable of conversing with humans on popular small talk\ntopics through both speech and text. The system consists of an ensemble of\nnatural language generation and retrieval models, including neural network and\ntemplate-based models. By applying reinforcement learning to crowdsourced data\nand real-world user interactions, the system has been trained to select an\nappropriate response from the models in its ensemble. The system has been\nevaluated through A/B testing with real-world users, where it performed\nsignificantly better than other systems. The results highlight the potential of\ncoupling ensemble systems with deep reinforcement learning as a fruitful path\nfor developing real-world, open-domain conversational agents.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jan 2018 17:22:06 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Serban", "Iulian V.", ""], ["Sankar", "Chinnadhurai", ""], ["Germain", "Mathieu", ""], ["Zhang", "Saizheng", ""], ["Lin", "Zhouhan", ""], ["Subramanian", "Sandeep", ""], ["Kim", "Taesup", ""], ["Pieper", "Michael", ""], ["Chandar", "Sarath", ""], ["Ke", "Nan Rosemary", ""], ["Rajeswar", "Sai", ""], ["de Brebisson", "Alexandre", ""], ["Sotelo", "Jose M. R.", ""], ["Suhubdy", "Dendi", ""], ["Michalski", "Vincent", ""], ["Nguyen", "Alexandre", ""], ["Pineau", "Joelle", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1801.06792", "submitter": "Gaurav Bhatt", "authors": "Gaurav Bhatt, Shivam Sharma and Balasubramanian Raman", "title": "Attentive Recurrent Tensor Model for Community Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge to the problem of community question answering is the\nlexical and semantic gap between the sentence representations. Some solutions\nto minimize this gap includes the introduction of extra parameters to deep\nmodels or augmenting the external handcrafted features. In this paper, we\npropose a novel attentive recurrent tensor network for solving the lexical and\nsemantic gap in community question answering. We introduce token-level and\nphrase-level attention strategy that maps input sequences to the output using\ntrainable parameters. Further, we use the tensor parameters to introduce a\n3-way interaction between question, answer and external features in vector\nspace. We introduce simplified tensor matrices with L2 regularization that\nresults in smooth optimization during training. The proposed model achieves\nstate-of-the-art performance on the task of answer sentence selection (TrecQA\nand WikiQA datasets) while outperforming the current state-of-the-art on the\ntasks of best answer selection (Yahoo! L4) and answer triggering task (WikiQA).\n", "versions": [{"version": "v1", "created": "Sun, 21 Jan 2018 09:01:46 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Bhatt", "Gaurav", ""], ["Sharma", "Shivam", ""], ["Raman", "Balasubramanian", ""]]}, {"id": "1801.06807", "submitter": "Philipp Dufter", "authors": "Philipp Dufter, Mengjie Zhao, Martin Schmitt, Alexander Fraser,\n  Hinrich Sch\\\"utze", "title": "Embedding Learning Through Multilingual Concept Induction", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for estimating vector space representations of words:\nembedding learning by concept induction. We test this method on a highly\nparallel corpus and learn semantic representations of words in 1259 different\nlanguages in a single common space. An extensive experimental evaluation on\ncrosslingual word similarity and sentiment analysis indicates that\nconcept-based multilingual embedding learning performs better than previous\napproaches.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jan 2018 11:19:10 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 08:34:01 GMT"}, {"version": "v3", "created": "Wed, 27 Jun 2018 13:30:06 GMT"}], "update_date": "2018-06-28", "authors_parsed": [["Dufter", "Philipp", ""], ["Zhao", "Mengjie", ""], ["Schmitt", "Martin", ""], ["Fraser", "Alexander", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1801.06830", "submitter": "Ronan Cummins", "authors": "Ronan Cummins and Marek Rei", "title": "Neural Multi-task Learning in Automated Assessment", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grammatical error detection and automated essay scoring are two tasks in the\narea of automated assessment. Traditionally these tasks have been treated\nindependently with different machine learning models and features used for each\ntask. In this paper, we develop a multi-task neural network model that jointly\noptimises for both tasks, and in particular we show that neural automated essay\nscoring can be significantly improved. We show that while the essay score\nprovides little evidence to inform grammatical error detection, the essay score\nis highly influenced by error detection.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jan 2018 14:38:23 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Cummins", "Ronan", ""], ["Rei", "Marek", ""]]}, {"id": "1801.07073", "submitter": "Fokkens Antske", "authors": "Antske Fokkens, Serge ter Braake, Niels Ockeloen, Piek Vossen, Susan\n  Leg\\^ene, Guus Schreiber and Victor de Boer", "title": "BiographyNet: Extracting Relations Between People and Events", "comments": "35 pages, 5 figures, \\'A. Z. Bern\\'ad, C. Gruber, M. Kaiser\n  (editors). Europa baut auf Biographien: Aspekte, Bausteine, Normen und\n  Standards f\\\"ur eine europ\\\"aische Biographik (2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes BiographyNet, a digital humanities project (2012-2016)\nthat brings together researchers from history, computational linguistics and\ncomputer science. The project uses data from the Biography Portal of the\nNetherlands (BPN), which contains approximately 125,000 biographies from a\nvariety of Dutch biographical dictionaries from the eighteenth century until\nnow, describing around 76,000 individuals. BiographyNet's aim is to strengthen\nthe value of the portal and comparable biographical datasets for historical\nresearch, by improving the search options and the presentation of its outcome,\nwith a historically justified NLP pipeline that works through a user evaluated\ndemonstrator. The project's main target group are professional historians. The\nproject therefore worked with two key concepts: \"provenance\" -understood as a\nterm allowing for both historical source criticism and for references to\ndata-management and programming interventions in digitized sources; and\n\"perspective\" interpreted as inherent uncertainty concerning the interpretation\nof historical results.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 13:00:02 GMT"}, {"version": "v2", "created": "Wed, 26 Dec 2018 20:42:36 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Fokkens", "Antske", ""], ["ter Braake", "Serge", ""], ["Ockeloen", "Niels", ""], ["Vossen", "Piek", ""], ["Leg\u00eane", "Susan", ""], ["Schreiber", "Guus", ""], ["de Boer", "Victor", ""]]}, {"id": "1801.07174", "submitter": "Simon Gottschalk", "authors": "Hady Elsahar, Elena Demidova, Simon Gottschalk, Christophe Gravier,\n  Frederique Laforest", "title": "Unsupervised Open Relation Extraction", "comments": "4 pages, published in ESWC 2017", "journal-ref": null, "doi": "10.1007/978-3-319-70407-4_3", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore methods to extract relations between named entities from free text\nin an unsupervised setting. In addition to standard feature extraction, we\ndevelop a novel method to re-weight word embeddings. We alleviate the problem\nof features sparsity using an individual feature reduction. Our approach\nexhibits a significant improvement by 5.8% over the state-of-the-art relation\nclustering scoring a F1-score of 0.416 on the NYT-FB dataset.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 16:19:12 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Elsahar", "Hady", ""], ["Demidova", "Elena", ""], ["Gottschalk", "Simon", ""], ["Gravier", "Christophe", ""], ["Laforest", "Frederique", ""]]}, {"id": "1801.07175", "submitter": "Zhitao Gong", "authors": "Zhitao Gong and Wenlu Wang and Bo Li and Dawn Song and Wei-Shinn Ku", "title": "Adversarial Texts with Gradient Methods", "comments": "This work lacks some crucial details. After careful discussion, we\n  decided to withdraw it temporarily and resubmit a full version afterward", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Adversarial samples for images have been extensively studied in the\nliterature. Among many of the attacking methods, gradient-based methods are\nboth effective and easy to compute. In this work, we propose a framework to\nadapt the gradient attacking methods on images to text domain. The main\ndifficulties for generating adversarial texts with gradient methods are i) the\ninput space is discrete, which makes it difficult to accumulate small noise\ndirectly in the inputs, and ii) the measurement of the quality of the\nadversarial texts is difficult. We tackle the first problem by searching for\nadversarials in the embedding space and then reconstruct the adversarial texts\nvia nearest neighbor search. For the latter problem, we employ the Word Mover's\nDistance (WMD) to quantify the quality of adversarial texts. Through extensive\nexperiments on three datasets, IMDB movie reviews, Reuters-2 and Reuters-5\nnewswires, we show that our framework can leverage gradient attacking methods\nto generate very high-quality adversarial texts that are only a few words\ndifferent from the original texts. There are many cases where we can change one\nword to alter the label of the whole piece of text. We successfully incorporate\nFGM and DeepFool into our framework. In addition, we empirically show that WMD\nis closely related to the quality of adversarial texts.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 16:19:52 GMT"}, {"version": "v2", "created": "Wed, 24 Jan 2018 19:54:27 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["Gong", "Zhitao", ""], ["Wang", "Wenlu", ""], ["Li", "Bo", ""], ["Song", "Dawn", ""], ["Ku", "Wei-Shinn", ""]]}, {"id": "1801.07243", "submitter": "Jason  Weston", "authors": "Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela,\n  Jason Weston", "title": "Personalizing Dialogue Agents: I have a dog, do you have pets too?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chit-chat models are known to have several problems: they lack specificity,\ndo not display a consistent personality and are often not very captivating. In\nthis work we present the task of making chit-chat more engaging by conditioning\non profile information. We collect data and train models to (i) condition on\ntheir given profile information; and (ii) information about the person they are\ntalking to, resulting in improved dialogues, as measured by next utterance\nprediction. Since (ii) is initially unknown our model is trained to engage its\npartner with personal topics, and we show the resulting dialogue can be used to\npredict profile information about the interlocutors.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 18:58:18 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 23:08:17 GMT"}, {"version": "v3", "created": "Sun, 13 May 2018 15:53:46 GMT"}, {"version": "v4", "created": "Tue, 4 Sep 2018 04:48:01 GMT"}, {"version": "v5", "created": "Tue, 25 Sep 2018 18:55:07 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Zhang", "Saizheng", ""], ["Dinan", "Emily", ""], ["Urbanek", "Jack", ""], ["Szlam", "Arthur", ""], ["Kiela", "Douwe", ""], ["Weston", "Jason", ""]]}, {"id": "1801.07288", "submitter": "Aman Dalmia", "authors": "Ameya Godbole, Aman Dalmia and Sunil Kumar Sahu", "title": "Siamese Neural Networks with Random Forest for detecting duplicate\n  question pairs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining whether two given questions are semantically similar is a fairly\nchallenging task given the different structures and forms that the questions\ncan take. In this paper, we use Gated Recurrent Units(GRU) in combination with\nother highly used machine learning algorithms like Random Forest, Adaboost and\nSVM for the similarity prediction task on a dataset released by Quora,\nconsisting of about 400k labeled question pairs. We got the best result by\nusing the Siamese adaptation of a Bidirectional GRU with a Random Forest\nclassifier, which landed us among the top 24% in the competition Quora Question\nPairs hosted on Kaggle.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 19:27:31 GMT"}, {"version": "v2", "created": "Wed, 24 Jan 2018 07:58:29 GMT"}, {"version": "v3", "created": "Sun, 28 Jan 2018 08:21:06 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Godbole", "Ameya", ""], ["Dalmia", "Aman", ""], ["Sahu", "Sunil Kumar", ""]]}, {"id": "1801.07311", "submitter": "Arkaitz Zubiaga", "authors": "Arkaitz Zubiaga, Aiqi Jiang", "title": "Early Detection of Social Media Hoaxes at Scale", "comments": "ACM Transactions on the Web (TWEB)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The unmoderated nature of social media enables the diffusion of hoaxes, which\nin turn jeopardises the credibility of information gathered from social media\nplatforms. Existing research on automated detection of hoaxes has the\nlimitation of using relatively small datasets, owing to the difficulty of\ngetting labelled data. This in turn has limited research exploring early\ndetection of hoaxes as well as exploring other factors such as the effect of\nthe size of the training data or the use of sliding windows. To mitigate this\nproblem, we introduce a semi-automated method that leverages the Wikidata\nknowledge base to build large-scale datasets for veracity classification,\nfocusing on celebrity death reports. This enables us to create a dataset with\n4,007 reports including over 13 million tweets, 15% of which are fake.\nExperiments using class-specific representations of word embeddings show that\nwe can achieve F1 scores nearing 72% within 10 minutes of the first tweet being\nposted when we expand the size of the training data following our\nsemi-automated means. Our dataset represents a realistic scenario with a real\ndistribution of true, commemorative and false stories, which we release for\nfurther use as a benchmark in future research.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 20:41:50 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 10:59:14 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 08:53:51 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Zubiaga", "Arkaitz", ""], ["Jiang", "Aiqi", ""]]}, {"id": "1801.07414", "submitter": "Duyu Tang", "authors": "Zhao Yan, Duyu Tang, Nan Duan, Shujie Liu, Wendi Wang, Daxin Jiang,\n  Ming Zhou, Zhoujun Li", "title": "Assertion-based QA with Question-Aware Open Information Extraction", "comments": "To be published at AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present assertion based question answering (ABQA), an open domain question\nanswering task that takes a question and a passage as inputs, and outputs a\nsemi-structured assertion consisting of a subject, a predicate and a list of\narguments. An assertion conveys more evidences than a short answer span in\nreading comprehension, and it is more concise than a tedious passage in\npassage-based QA. These advantages make ABQA more suitable for human-computer\ninteraction scenarios such as voice-controlled speakers. Further progress\ntowards improving ABQA requires richer supervised dataset and powerful models\nof text understanding. To remedy this, we introduce a new dataset called\nWebAssertions, which includes hand-annotated QA labels for 358,427 assertions\nin 55,960 web passages. To address ABQA, we develop both generative and\nextractive approaches. The backbone of our generative approach is sequence to\nsequence learning. In order to capture the structure of the output assertion,\nwe introduce a hierarchical decoder that first generates the structure of the\nassertion and then generates the words of each field. The extractive approach\nis based on learning to rank. Features at different levels of granularity are\ndesigned to measure the semantic relevance between a question and an assertion.\nExperimental results show that our approaches have the ability to infer\nquestion-aware assertions from a passage. We further evaluate our approaches by\nincorporating the ABQA results as additional features in passage-based QA.\nResults on two datasets show that ABQA features significantly improve the\naccuracy on passage-based~QA.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 07:22:34 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Yan", "Zhao", ""], ["Tang", "Duyu", ""], ["Duan", "Nan", ""], ["Liu", "Shujie", ""], ["Wang", "Wendi", ""], ["Jiang", "Daxin", ""], ["Zhou", "Ming", ""], ["Li", "Zhoujun", ""]]}, {"id": "1801.07495", "submitter": "Wafa Alorainy", "authors": "Wafa Alorainy, Pete Burnap, Han Liu, Matthew Williams", "title": "The Enemy Among Us: Detecting Hate Speech with Threats Based 'Othering'\n  Language Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offensive or antagonistic language targeted at individuals and social groups\nbased on their personal characteristics (also known as cyber hate speech or\ncyberhate) has been frequently posted and widely circulated viathe World Wide\nWeb. This can be considered as a key risk factor for individual and societal\ntension linked toregional instability. Automated Web-based cyberhate detection\nis important for observing and understandingcommunity and regional societal\ntension - especially in online social networks where posts can be rapidlyand\nwidely viewed and disseminated. While previous work has involved using\nlexicons, bags-of-words orprobabilistic language parsing approaches, they often\nsuffer from a similar issue which is that cyberhate can besubtle and indirect -\nthus depending on the occurrence of individual words or phrases can lead to a\nsignificantnumber of false negatives, providing inaccurate representation of\nthe trends in cyberhate. This problemmotivated us to challenge thinking around\nthe representation of subtle language use, such as references toperceived\nthreats from \"the other\" including immigration or job prosperity in a hateful\ncontext. We propose anovel framework that utilises language use around the\nconcept of \"othering\" and intergroup threat theory toidentify these subtleties\nand we implement a novel classification method using embedding learning to\ncomputesemantic distances between parts of speech considered to be part of an\n\"othering\" narrative. To validate ourapproach we conduct several experiments on\ndifferent types of cyberhate, namely religion, disability, race andsexual\norientation, with F-measure scores for classifying hateful instances obtained\nthrough applying ourmodel of 0.93, 0.86, 0.97 and 0.98 respectively, providing\na significant improvement in classifier accuracy overthe state-of-the-art\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 11:43:54 GMT"}, {"version": "v2", "created": "Sun, 28 Jan 2018 11:37:38 GMT"}, {"version": "v3", "created": "Thu, 8 Mar 2018 12:25:38 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Alorainy", "Wafa", ""], ["Burnap", "Pete", ""], ["Liu", "Han", ""], ["Williams", "Matthew", ""]]}, {"id": "1801.07507", "submitter": "Yosi Mass", "authors": "Yosi Mass, Lili Kotlerman, Shachar Mirkin, Elad Venezian, Gera\n  Witzling, Noam Slonim", "title": "What did you Mention? A Large Scale Mention Detection Benchmark for\n  Spoken and Written Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a large, high-quality benchmark for the evaluation of Mention\nDetection tools. The benchmark contains annotations of both named entities as\nwell as other types of entities, annotated on different types of text, ranging\nfrom clean text taken from Wikipedia, to noisy spoken data. The benchmark was\nbuilt through a highly controlled crowd sourcing process to ensure its quality.\nWe describe the benchmark, the process and the guidelines that were used to\nbuild it. We then demonstrate the results of a state-of-the-art system running\non that benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 12:22:52 GMT"}, {"version": "v2", "created": "Wed, 24 Jan 2018 11:35:27 GMT"}, {"version": "v3", "created": "Thu, 25 Jan 2018 10:14:28 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["Mass", "Yosi", ""], ["Kotlerman", "Lili", ""], ["Mirkin", "Shachar", ""], ["Venezian", "Elad", ""], ["Witzling", "Gera", ""], ["Slonim", "Noam", ""]]}, {"id": "1801.07537", "submitter": "Jannis Bulian", "authors": "Christian Buck, Jannis Bulian, Massimiliano Ciaramita, Wojciech\n  Gajewski, Andrea Gesmundo, Neil Houlsby, Wei Wang", "title": "Analyzing Language Learned by an Active Question Answering Agent", "comments": "Emergent Communication Workshop, NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the language learned by an agent trained with reinforcement\nlearning as a component of the ActiveQA system [Buck et al., 2017]. In\nActiveQA, question answering is framed as a reinforcement learning task in\nwhich an agent sits between the user and a black box question-answering system.\nThe agent learns to reformulate the user's questions to elicit the optimal\nanswers. It probes the system with many versions of a question that are\ngenerated via a sequence-to-sequence question reformulation model, then\naggregates the returned evidence to find the best answer. This process is an\ninstance of \\emph{machine-machine} communication. The question reformulation\nmodel must adapt its language to increase the quality of the answers returned,\nmatching the language of the question answering system. We find that the agent\ndoes not learn transformations that align with semantic intuitions but\ndiscovers through learning classical information retrieval techniques such as\ntf-idf re-weighting and stemming.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 13:50:11 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Buck", "Christian", ""], ["Bulian", "Jannis", ""], ["Ciaramita", "Massimiliano", ""], ["Gajewski", "Wojciech", ""], ["Gesmundo", "Andrea", ""], ["Houlsby", "Neil", ""], ["Wang", "Wei", ""]]}, {"id": "1801.07704", "submitter": "Tal Baumel", "authors": "Tal Baumel, Matan Eyal, Michael Elhadad", "title": "Query Focused Abstractive Summarization: Incorporating Query Relevance,\n  Multi-Document Coverage, and Summary Length Constraints into seq2seq Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Query Focused Summarization (QFS) has been addressed mostly using extractive\nmethods. Such methods, however, produce text which suffers from low coherence.\nWe investigate how abstractive methods can be applied to QFS, to overcome such\nlimitations. Recent developments in neural-attention based sequence-to-sequence\nmodels have led to state-of-the-art results on the task of abstractive generic\nsingle document summarization. Such models are trained in an end to end method\non large amounts of training data. We address three aspects to make abstractive\nsummarization applicable to QFS: (a)since there is no training data, we\nincorporate query relevance into a pre-trained abstractive model; (b) since\nexisting abstractive models are trained in a single-document setting, we design\nan iterated method to embed abstractive models within the multi-document\nrequirement of QFS; (c) the abstractive models we adapt are trained to generate\ntext of specific length (about 100 words), while we aim at generating output of\na different size (about 250 words); we design a way to adapt the target size of\nthe generated summaries to a given size ratio. We compare our method (Relevance\nSensitive Attention for QFS) to extractive baselines and with various ways to\ncombine abstractive models on the DUC QFS datasets and demonstrate solid\nimprovements on ROUGE performance.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 18:47:03 GMT"}, {"version": "v2", "created": "Thu, 25 Jan 2018 10:45:08 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["Baumel", "Tal", ""], ["Eyal", "Matan", ""], ["Elhadad", "Michael", ""]]}, {"id": "1801.07737", "submitter": "Pedram Hosseini", "authors": "Pedram Hosseini, Ali Ahmadian Ramaki, Hassan Maleki, Mansoureh Anvari,\n  Seyed Abolghasem Mirroshandel", "title": "SentiPers: A Sentiment Analysis Corpus for Persian", "comments": "This work is accepted to the 3rd Conference on Computational\n  Linguistics, Sharif University of Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Sentiment Analysis (SA) is a major field of study in natural language\nprocessing, computational linguistics and information retrieval. Interest in SA\nhas been constantly growing in both academia and industry over the recent\nyears. Moreover, there is an increasing need for generating appropriate\nresources and datasets in particular for low resource languages including\nPersian. These datasets play an important role in designing and developing\nappropriate opinion mining platforms using supervised, semi-supervised or\nunsupervised methods. In this paper, we outline the entire process of\ndeveloping a manually annotated sentiment corpus, SentiPers, which covers\nformal and informal written contemporary Persian. To the best of our knowledge,\nSentiPers is a unique sentiment corpus with such a rich annotation in three\ndifferent levels including document-level, sentence-level, and\nentity/aspect-level for Persian. The corpus contains more than 26000 sentences\nof users opinions from digital product domain and benefits from special\ncharacteristics such as quantifying the positiveness or negativity of an\nopinion through assigning a number within a specific range to any given\nsentence. Furthermore, we present statistics on various components of our\ncorpus as well as studying the inter-annotator agreement among the annotators.\nFinally, some of the challenges that we faced during the annotation process\nwill be discussed as well.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 19:24:38 GMT"}, {"version": "v2", "created": "Fri, 1 Jan 2021 07:17:54 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Hosseini", "Pedram", ""], ["Ramaki", "Ali Ahmadian", ""], ["Maleki", "Hassan", ""], ["Anvari", "Mansoureh", ""], ["Mirroshandel", "Seyed Abolghasem", ""]]}, {"id": "1801.07746", "submitter": "Behzad Golshan", "authors": "Akari Asai, Sara Evensen, Behzad Golshan, Alon Halevy, Vivian Li,\n  Andrei Lopatenko, Daniela Stepanov, Yoshihiko Suhara, Wang-Chiew Tan, Yinzhan\n  Xu", "title": "HappyDB: A Corpus of 100,000 Crowdsourced Happy Moments", "comments": "Typos fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The science of happiness is an area of positive psychology concerned with\nunderstanding what behaviors make people happy in a sustainable fashion.\nRecently, there has been interest in developing technologies that help\nincorporate the findings of the science of happiness into users' daily lives by\nsteering them towards behaviors that increase happiness. With the goal of\nbuilding technology that can understand how people express their happy moments\nin text, we crowd-sourced HappyDB, a corpus of 100,000 happy moments that we\nmake publicly available. This paper describes HappyDB and its properties, and\noutlines several important NLP problems that can be studied with the help of\nthe corpus. We also apply several state-of-the-art analysis techniques to\nanalyze HappyDB. Our results demonstrate the need for deeper NLP techniques to\nbe developed which makes HappyDB an exciting resource for follow-on research.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 19:49:58 GMT"}, {"version": "v2", "created": "Thu, 25 Jan 2018 18:56:35 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["Asai", "Akari", ""], ["Evensen", "Sara", ""], ["Golshan", "Behzad", ""], ["Halevy", "Alon", ""], ["Li", "Vivian", ""], ["Lopatenko", "Andrei", ""], ["Stepanov", "Daniela", ""], ["Suhara", "Yoshihiko", ""], ["Tan", "Wang-Chiew", ""], ["Xu", "Yinzhan", ""]]}, {"id": "1801.07772", "submitter": "Yonatan Belinkov", "authors": "Yonatan Belinkov, Llu\\'is M\\`arquez, Hassan Sajjad, Nadir Durrani,\n  Fahim Dalvi, James Glass", "title": "Evaluating Layers of Representation in Neural Machine Translation on\n  Part-of-Speech and Semantic Tagging Tasks", "comments": "IJCNLP 2017", "journal-ref": "IJCNLP 8 (2017), volume 1, 1-10", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural machine translation (NMT) models provide improved translation\nquality in an elegant, end-to-end framework, it is less clear what they learn\nabout language. Recent work has started evaluating the quality of vector\nrepresentations learned by NMT models on morphological and syntactic tasks. In\nthis paper, we investigate the representations learned at different layers of\nNMT encoders. We train NMT systems on parallel data and use the trained models\nto extract features for training a classifier on two tasks: part-of-speech and\nsemantic tagging. We then measure the performance of the classifier as a proxy\nto the quality of the original NMT model for the given task. Our quantitative\nanalysis yields interesting insights regarding representation learning in NMT\nmodels. For instance, we find that higher layers are better at learning\nsemantics while lower layers tend to be better for part-of-speech tagging. We\nalso observe little effect of the target language on source-side\nrepresentations, especially with higher quality NMT models.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 20:59:55 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Belinkov", "Yonatan", ""], ["M\u00e0rquez", "Llu\u00eds", ""], ["Sajjad", "Hassan", ""], ["Durrani", "Nadir", ""], ["Dalvi", "Fahim", ""], ["Glass", "James", ""]]}, {"id": "1801.07779", "submitter": "Martin Thoma", "authors": "Martin Thoma", "title": "The WiLI benchmark dataset for written language identification", "comments": "{\"pages\": 12, \"figures\": 4, \"language\": \"English\", \"author-ORCiD\":\n  [\"https://orcid.org/0000-0002-6517-1690\"]}", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper describes the WiLI-2018 benchmark dataset for monolingual written\nnatural language identification. WiLI-2018 is a publicly available, free of\ncharge dataset of short text extracts from Wikipedia. It contains 1000\nparagraphs of 235 languages, totaling in 23500 paragraphs. WiLI is a\nclassification dataset: Given an unknown paragraph written in one dominant\nlanguage, it has to be decided which language it is.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 21:40:53 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Thoma", "Martin", ""]]}, {"id": "1801.07804", "submitter": "Duc-Thuan Vo", "authors": "Diem Truong, Duc-Thuan Vo, and U.T Nguyen", "title": "Vietnamese Open Information Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open information extraction (OIE) is the process to extract relations and\ntheir arguments automatically from textual documents without the need to\nrestrict the search to predefined relations. In recent years, several OIE\nsystems for the English language have been created but there is not any system\nfor the Vietnamese language. In this paper, we propose a method of OIE for\nVietnamese using a clause-based approach. Accordingly, we exploit Vietnamese\ndependency parsing using grammar clauses that strives to consider all possible\nrelations in a sentence. The corresponding clause types are identified by their\npropositions as extractable relations based on their grammatical functions of\nconstituents. As a result, our system is the first OIE system named vnOIE for\nthe Vietnamese language that can generate open relations and their arguments\nfrom Vietnamese text with highly scalable extraction while being domain\nindependent. Experimental results show that our OIE system achieves promising\nresults with a precision of 83.71%.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 23:03:23 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Truong", "Diem", ""], ["Vo", "Duc-Thuan", ""], ["Nguyen", "U. T", ""]]}, {"id": "1801.07861", "submitter": "Zhen Wu", "authors": "Zhen Wu, Xin-Yu Dai, Cunyan Yin, Shujian Huang, Jiajun Chen", "title": "Improving Review Representations with User Attention and Product\n  Attention for Sentiment Classification", "comments": "Accepted by AAAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network methods have achieved great success in reviews sentiment\nclassification. Recently, some works achieved improvement by incorporating user\nand product information to generate a review representation. However, in\nreviews, we observe that some words or sentences show strong user's preference,\nand some others tend to indicate product's characteristic. The two kinds of\ninformation play different roles in determining the sentiment label of a\nreview. Therefore, it is not reasonable to encode user and product information\ntogether into one representation. In this paper, we propose a novel framework\nto encode user and product information. Firstly, we apply two individual\nhierarchical neural networks to generate two representations, with user\nattention or with product attention. Then, we design a combined strategy to\nmake full use of the two representations for training and final prediction. The\nexperimental results show that our model obviously outperforms other\nstate-of-the-art methods on IMDB and Yelp datasets. Through the visualization\nof attention over words related to user or product, we validate our observation\nmentioned above.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 05:11:57 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Wu", "Zhen", ""], ["Dai", "Xin-Yu", ""], ["Yin", "Cunyan", ""], ["Huang", "Shujian", ""], ["Chen", "Jiajun", ""]]}, {"id": "1801.07875", "submitter": "Michael Bloodgood", "authors": "Michael Bloodgood", "title": "Support Vector Machine Active Learning Algorithms with\n  Query-by-Committee versus Closest-to-Hyperplane Selection", "comments": "8 pages, 7 figures, 3 tables; published in Proceedings of the IEEE\n  12th International Conference on Semantic Computing (ICSC 2018), Laguna\n  Hills, CA, USA, pages 148-155, January 2018", "journal-ref": "In Proceedings of the 2018 IEEE 12th International Conference on\n  Semantic Computing (ICSC), pages 148-155, Laguna Hills, CA, USA, January\n  2018. IEEE", "doi": "10.1109/ICSC.2018.00029", "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates and evaluates support vector machine active learning\nalgorithms for use with imbalanced datasets, which commonly arise in many\napplications such as information extraction applications. Algorithms based on\nclosest-to-hyperplane selection and query-by-committee selection are combined\nwith methods for addressing imbalance such as positive amplification based on\nprevalence statistics from initial random samples. Three algorithms (ClosestPA,\nQBagPA, and QBoostPA) are presented and carefully evaluated on datasets for\ntext classification and relation extraction. The ClosestPA algorithm is shown\nto consistently outperform the other two in a variety of ways and insights are\nprovided as to why this is the case.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 06:38:06 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 19:16:47 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Bloodgood", "Michael", ""]]}, {"id": "1801.07883", "submitter": "Lei Zhang", "authors": "Lei Zhang, Shuai Wang, Bing Liu", "title": "Deep Learning for Sentiment Analysis : A Survey", "comments": "34 pages, 9 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has emerged as a powerful machine learning technique that\nlearns multiple layers of representations or features of the data and produces\nstate-of-the-art prediction results. Along with the success of deep learning in\nmany other application domains, deep learning is also popularly used in\nsentiment analysis in recent years. This paper first gives an overview of deep\nlearning and then provides a comprehensive survey of its current applications\nin sentiment analysis.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 07:32:29 GMT"}, {"version": "v2", "created": "Tue, 30 Jan 2018 07:20:41 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Zhang", "Lei", ""], ["Wang", "Shuai", ""], ["Liu", "Bing", ""]]}, {"id": "1801.07887", "submitter": "Michael Bloodgood", "authors": "Garrett Beatty, Ethan Kochis and Michael Bloodgood", "title": "Impact of Batch Size on Stopping Active Learning for Text Classification", "comments": "2 pages, 1 table; published in Proceedings of the IEEE 12th\n  International Conference on Semantic Computing (ICSC 2018), Laguna Hills, CA,\n  USA, pages 306-307, January 2018", "journal-ref": "In Proceedings of the 2018 IEEE 12th International Conference on\n  Semantic Computing (ICSC), pages 306-307, Laguna Hills, CA, USA, January\n  2018. IEEE", "doi": "10.1109/ICSC.2018.00059", "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When using active learning, smaller batch sizes are typically more efficient\nfrom a learning efficiency perspective. However, in practice due to speed and\nhuman annotator considerations, the use of larger batch sizes is necessary.\nWhile past work has shown that larger batch sizes decrease learning efficiency\nfrom a learning curve perspective, it remains an open question how batch size\nimpacts methods for stopping active learning. We find that large batch sizes\ndegrade the performance of a leading stopping method over and above the\ndegradation that results from reduced learning efficiency. We analyze this\ndegradation and find that it can be mitigated by changing the window size\nparameter of how many past iterations of learning are taken into account when\nmaking the stopping decision. We find that when using larger batch sizes,\nstopping methods are more effective when smaller window sizes are used.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 07:47:05 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 18:31:45 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Beatty", "Garrett", ""], ["Kochis", "Ethan", ""], ["Bloodgood", "Michael", ""]]}, {"id": "1801.07948", "submitter": "Hayafumi Watanabe", "authors": "Hayafumi Watanabe", "title": "Empirical observations of ultraslow diffusion driven by the fractional\n  dynamics in languages: Dynamical statistical properties of word counts of\n  already popular words", "comments": null, "journal-ref": "Phys. Rev. E 98, 012308 (2018)", "doi": "10.1103/PhysRevE.98.012308", "report-no": null, "categories": "physics.soc-ph cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultraslow diffusion (i.e. logarithmic diffusion) has been extensively studied\ntheoretically, but has hardly been observed empirically. In this paper,\nfirstly, we find the ultraslow-like diffusion of the time-series of word counts\nof already popular words by analysing three different nationwide language\ndatabases: (i) newspaper articles (Japanese), (ii) blog articles (Japanese),\nand (iii) page views of Wikipedia (English, French, Chinese, and Japanese).\nSecondly, we use theoretical analysis to show that this diffusion is basically\nexplained by the random walk model with the power-law forgetting with the\nexponent $\\beta \\approx 0.5$, which is related to the fractional Langevin\nequation. The exponent $\\beta$ characterises the speed of forgetting and $\\beta\n\\approx 0.5$ corresponds to (i) the border (or thresholds) between the\nstationary and the nonstationary and (ii) the right-in-the-middle dynamics\nbetween the IID noise for $\\beta=1$ and the normal random walk for $\\beta=0$.\nThirdly, the generative model of the time-series of word counts of already\npopular words, which is a kind of Poisson process with the Poisson parameter\nsampled by the above-mentioned random walk model, can almost reproduce not only\nthe empirical mean-squared displacement but also the power spectrum density and\nthe probability density function.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 12:11:09 GMT"}, {"version": "v2", "created": "Sat, 27 Jan 2018 04:55:30 GMT"}, {"version": "v3", "created": "Sat, 24 Feb 2018 00:34:19 GMT"}, {"version": "v4", "created": "Wed, 27 Jun 2018 09:56:16 GMT"}, {"version": "v5", "created": "Fri, 29 Jun 2018 18:16:13 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Watanabe", "Hayafumi", ""]]}, {"id": "1801.08186", "submitter": "Licheng Yu", "authors": "Licheng Yu, Zhe Lin, Xiaohui Shen, Jimei Yang, Xin Lu, Mohit Bansal,\n  Tamara L.Berg", "title": "MAttNet: Modular Attention Network for Referring Expression\n  Comprehension", "comments": "Equation of word attention fixed; MAttNet+Grabcut results added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address referring expression comprehension: localizing an\nimage region described by a natural language expression. While most recent work\ntreats expressions as a single unit, we propose to decompose them into three\nmodular components related to subject appearance, location, and relationship to\nother objects. This allows us to flexibly adapt to expressions containing\ndifferent types of information in an end-to-end framework. In our model, which\nwe call the Modular Attention Network (MAttNet), two types of attention are\nutilized: language-based attention that learns the module weights as well as\nthe word/phrase attention that each module should focus on; and visual\nattention that allows the subject and relationship modules to focus on relevant\nimage components. Module weights combine scores from all three modules\ndynamically to output an overall score. Experiments show that MAttNet\noutperforms previous state-of-art methods by a large margin on both\nbounding-box-level and pixel-level comprehension tasks. Demo and code are\nprovided.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 20:54:26 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 15:40:51 GMT"}, {"version": "v3", "created": "Tue, 27 Mar 2018 02:45:55 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Yu", "Licheng", ""], ["Lin", "Zhe", ""], ["Shen", "Xiaohui", ""], ["Yang", "Jimei", ""], ["Lu", "Xin", ""], ["Bansal", "Mohit", ""], ["Berg", "Tamara L.", ""]]}, {"id": "1801.08290", "submitter": "Souvik Kundu", "authors": "Souvik Kundu and Hwee Tou Ng", "title": "A Question-Focused Multi-Factor Attention Network for Question Answering", "comments": "8 pages, AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network models recently proposed for question answering (QA) primarily\nfocus on capturing the passage-question relation. However, they have minimal\ncapability to link relevant facts distributed across multiple sentences which\nis crucial in achieving deeper understanding, such as performing multi-sentence\nreasoning, co-reference resolution, etc. They also do not explicitly focus on\nthe question and answer type which often plays a critical role in QA. In this\npaper, we propose a novel end-to-end question-focused multi-factor attention\nnetwork for answer extraction. Multi-factor attentive encoding using\ntensor-based transformation aggregates meaningful facts even when they are\nlocated in multiple sentences. To implicitly infer the answer type, we also\npropose a max-attentional question aggregation mechanism to encode a question\nvector based on the important words in a question. During prediction, we\nincorporate sequence-level encoding of the first wh-word and its immediately\nfollowing word as an additional source of question type information. Our\nproposed model achieves significant improvements over the best prior\nstate-of-the-art results on three large-scale challenging QA datasets, namely\nNewsQA, TriviaQA, and SearchQA.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 07:08:04 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["Kundu", "Souvik", ""], ["Ng", "Hwee Tou", ""]]}, {"id": "1801.08337", "submitter": "Nadir Durrani Dr", "authors": "Nadir Durrani and Fahim Dalvi", "title": "Continuous Space Reordering Models for Phrase-based MT", "comments": "IWSLT 2017, The 14th International Workshop on Spoken Language\n  Translation (IWSLT 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilingual sequence models improve phrase-based translation and reordering by\novercoming phrasal independence assumption and handling long range reordering.\nHowever, due to data sparsity, these models often fall back to very small\ncontext sizes. This problem has been previously addressed by learning sequences\nover generalized representations such as POS tags or word clusters. In this\npaper, we explore an alternative based on neural network models. More\nconcretely we train neuralized versions of lexicalized reordering and the\noperation sequence models using feed-forward neural network. Our results show\nimprovements of up to 0.6 and 0.5 BLEU points on top of the baseline\nGerman->English and English->German systems. We also observed improvements\ncompared to the systems that used POS tags and word clusters to train these\nmodels. Because we modify the bilingual corpus to integrate reordering\noperations, this allows us to also train a sequence-to-sequence neural MT model\nhaving explicit reordering triggers. Our motivation was to directly enable\nreordering information in the encoder-decoder framework, which otherwise relies\nsolely on the attention model to handle long range reordering. We tried both\ncoarser and fine-grained reordering operations. However, these experiments did\nnot yield any improvements over the baseline Neural MT systems.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 10:17:32 GMT"}, {"version": "v2", "created": "Mon, 29 Jan 2018 08:29:28 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Durrani", "Nadir", ""], ["Dalvi", "Fahim", ""]]}, {"id": "1801.08660", "submitter": "Angli Liu", "authors": "Angli Liu, Katrin Kirchhoff", "title": "Context Models for OOV Word Translation in Low-Resource Languages", "comments": "to be published at AMTA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Out-of-vocabulary word translation is a major problem for the translation of\nlow-resource languages that suffer from a lack of parallel training data. This\npaper evaluates the contributions of target-language context models towards the\ntranslation of OOV words, specifically in those cases where OOV translations\nare derived from external knowledge sources, such as dictionaries. We develop\nboth neural and non-neural context models and evaluate them within both\nphrase-based and self-attention based neural machine translation systems. Our\nresults show that neural language models that integrate additional context\nbeyond the current sentence are the most effective in disambiguating possible\nOOV word translations. We present an efficient second-pass lattice-rescoring\nmethod for wide-context neural language models and demonstrate performance\nimprovements over state-of-the-art self-attention based neural MT systems in\nfive out of six low-resource language pairs.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 02:50:03 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Liu", "Angli", ""], ["Kirchhoff", "Katrin", ""]]}, {"id": "1801.08831", "submitter": "Shamil Chollampatt", "authors": "Shamil Chollampatt and Hwee Tou Ng", "title": "A Multilayer Convolutional Encoder-Decoder Neural Network for\n  Grammatical Error Correction", "comments": "8 pages, 3 figures, In Proceedings of AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We improve automatic correction of grammatical, orthographic, and collocation\nerrors in text using a multilayer convolutional encoder-decoder neural network.\nThe network is initialized with embeddings that make use of character N-gram\ninformation to better suit this task. When evaluated on common benchmark test\ndata sets (CoNLL-2014 and JFLEG), our model substantially outperforms all prior\nneural approaches on this task as well as strong statistical machine\ntranslation-based systems with neural and task-specific features trained on the\nsame data. Our analysis shows the superiority of convolutional neural networks\nover recurrent neural networks such as long short-term memory (LSTM) networks\nin capturing the local context via attention, and thereby improving the\ncoverage in correcting grammatical errors. By ensembling multiple models, and\nincorporating an N-gram language model and edit features via rescoring, our\nnovel method becomes the first neural approach to outperform the current\nstate-of-the-art statistical machine translation-based approach, both in terms\nof grammaticality and fluency.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 14:45:24 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Chollampatt", "Shamil", ""], ["Ng", "Hwee Tou", ""]]}, {"id": "1801.08991", "submitter": "Maxime Peyrard", "authors": "Maxime Peyrard", "title": "A Simple Theoretical Model of Importance for Summarization", "comments": "Accepted at ACL19 (outstanding paper award)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Research on summarization has mainly been driven by empirical approaches,\ncrafting systems to perform well on standard datasets with the notion of\ninformation Importance remaining latent. We argue that establishing theoretical\nmodels of Importance will advance our understanding of the task and help to\nfurther improve summarization systems. To this end, we propose simple but\nrigorous definitions of several concepts that were previously used only\nintuitively in summarization: Redundancy, Relevance, and Informativeness.\nImportance arises as a single quantity naturally unifying these concepts.\nAdditionally, we provide intuitions to interpret the proposed quantities and\nexperiments to demonstrate the potential of the framework to inform and guide\nsubsequent works.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 22:11:10 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 09:18:59 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Peyrard", "Maxime", ""]]}, {"id": "1801.09030", "submitter": "Wei Li", "authors": "Wei Li, Zheng Yang, Xu Sun", "title": "Exploration on Generating Traditional Chinese Medicine Prescription from\n  Symptoms with an End-to-End method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional Chinese Medicine (TCM) is an influential form of medical\ntreatment in China and surrounding areas. In this paper, we propose a TCM\nprescription generation task that aims to automatically generate a herbal\nmedicine prescription based on textual symptom descriptions.\nSequence-to-sequence (seq2seq) model has been successful in dealing with\nsequence generation tasks. We explore a potential end-to-end solution to the\nTCM prescription generation task using seq2seq models. However, experiments\nshow that directly applying seq2seq model leads to unfruitful results due to\nthe repetition problem. To solve the problem, we propose a novel decoder with\ncoverage mechanism and a novel soft loss function. The experimental results\ndemonstrate the effectiveness of the proposed approach. Judged by professors\nwho excel in TCM, the generated prescriptions are rated 7.3 out of 10. It shows\nthat the model can indeed help with the prescribing procedure in real life.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jan 2018 04:01:44 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 11:46:25 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Li", "Wei", ""], ["Yang", "Zheng", ""], ["Sun", "Xu", ""]]}, {"id": "1801.09031", "submitter": "Wei Li", "authors": "Wei Li, Yunfang Wu, Xueqiang Lv", "title": "Improving Word Vector with Prior Knowledge in Semantic Dictionary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using low dimensional vector space to represent words has been very effective\nin many NLP tasks. However, it doesn't work well when faced with the problem of\nrare and unseen words. In this paper, we propose to leverage the knowledge in\nsemantic dictionary in combination with some morphological information to build\nan enhanced vector space. We get an improvement of 2.3% over the\nstate-of-the-art Heidel Time system in temporal expression recognition, and\nobtain a large gain in other name entity recognition (NER) tasks. The semantic\ndictionary Hownet alone also shows promising results in computing lexical\nsimilarity.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jan 2018 04:13:52 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Li", "Wei", ""], ["Wu", "Yunfang", ""], ["Lv", "Xueqiang", ""]]}, {"id": "1801.09036", "submitter": "Wlodek Zadrozny", "authors": "Wlodek Zadrozny and Luciana Garbayo", "title": "A Sheaf Model of Contradictions and Disagreements. Preliminary Report\n  and Discussion", "comments": "This paper was presented at ISAIM 2018, International Symposium on\n  Artificial Intelligence and Mathematics. Fort Lauderdale, FL. January 3 5,\n  2018. Minor typographical errors have been corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new formal model -- based on the mathematical construct of\nsheaves -- for representing contradictory information in textual sources. This\nmodel has the advantage of letting us (a) identify the causes of the\ninconsistency; (b) measure how strong it is; (c) and do something about it,\ne.g. suggest ways to reconcile inconsistent advice. This model naturally\nrepresents the distinction between contradictions and disagreements. It is\nbased on the idea of representing natural language sentences as formulas with\nparameters sitting on lattices, creating partial orders based on predicates\nshared by theories, and building sheaves on these partial orders with products\nof lattices as stalks. Degrees of disagreement are measured by the existence of\nglobal and local sections.\n  Limitations of the sheaf approach and connections to recent work in natural\nlanguage processing, as well as the topics of contextuality in physics, data\nfusion, topological data analysis and epistemology are also discussed.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jan 2018 05:13:55 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Zadrozny", "Wlodek", ""], ["Garbayo", "Luciana", ""]]}, {"id": "1801.09053", "submitter": "Thien Thai Mr", "authors": "Vinh D. Van, Thien Thai, Minh-Quoc Nghiem", "title": "Combining Convolution and Recursive Neural Networks for Sentiment\n  Analysis", "comments": "8 pages, 3 figures, Proceedings of the Eighth International Symposium\n  on Information and Communication Technology. ACM, 2017", "journal-ref": null, "doi": "10.1145/3155133.3155158", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of sentence-level sentiment analysis. In\nrecent years, Convolution and Recursive Neural Networks have been proven to be\neffective network architecture for sentence-level sentiment analysis.\nNevertheless, each of them has their own potential drawbacks. For alleviating\ntheir weaknesses, we combined Convolution and Recursive Neural Networks into a\nnew network architecture. In addition, we employed transfer learning from a\nlarge document-level labeled sentiment dataset to improve the word embedding in\nour models. The resulting models outperform all recent Convolution and\nRecursive Neural Networks. Beyond that, our models achieve comparable\nperformance with state-of-the-art systems on Stanford Sentiment Treebank.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jan 2018 08:33:22 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Van", "Vinh D.", ""], ["Thai", "Thien", ""], ["Nghiem", "Minh-Quoc", ""]]}, {"id": "1801.09079", "submitter": "Alexander Veretennikov Borisovich", "authors": "A. B. Veretennikov", "title": "Using Additional Indexes for Fast Full-Text Search of Phrases That\n  Contain Frequently Used Words", "comments": "These results were published in: Veretennikov A.B. Using Additional\n  Indexes for Fast Full-Text Search of Phrases That Contain Frequently Used\n  Words. Control Systems and Information Technologies. 2013. vol. 52, no. 2.\n  pp. 61-66 (in Russian). This is an English translation of the text", "journal-ref": "Control Systems and Information Technologies. 2013. vol. 52, no.\n  2. pp. 61-66 (in Russian)", "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Searches for phrases and word sets in large text arrays by means of\nadditional indexes are considered. Their use may reduce the query-processing\ntime by an order of magnitude in comparison with standard inverted files.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jan 2018 12:02:03 GMT"}, {"version": "v2", "created": "Sun, 25 Nov 2018 14:36:11 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Veretennikov", "A. B.", ""]]}, {"id": "1801.09251", "submitter": "Yi Tay", "authors": "Yi Tay, Luu Anh Tuan, Siu Cheung Hui", "title": "Multi-Pointer Co-Attention Networks for Recommendation", "comments": "Accepted to KDD 2018 (Research Track)", "journal-ref": null, "doi": "10.1145/3219819.3220086", "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent state-of-the-art recommender systems such as D-ATT, TransNet and\nDeepCoNN exploit reviews for representation learning. This paper proposes a new\nneural architecture for recommendation with reviews. Our model operates on a\nmulti-hierarchical paradigm and is based on the intuition that not all reviews\nare created equal, i.e., only a select few are important. The importance,\nhowever, should be dynamically inferred depending on the current target. To\nthis end, we propose a review-by-review pointer-based learning scheme that\nextracts important reviews, subsequently matching them in a word-by-word\nfashion. This enables not only the most informative reviews to be utilized for\nprediction but also a deeper word-level interaction. Our pointer-based method\noperates with a novel gumbel-softmax based pointer mechanism that enables the\nincorporation of discrete vectors within differentiable neural architectures.\nOur pointer mechanism is co-attentive in nature, learning pointers which are\nco-dependent on user-item relationships. Finally, we propose a multi-pointer\nlearning scheme that learns to combine multiple views of interactions between\nuser and item. Overall, we demonstrate the effectiveness of our proposed model\nvia extensive experiments on \\textbf{24} benchmark datasets from Amazon and\nYelp. Empirical results show that our approach significantly outperforms\nexisting state-of-the-art, with up to 19% and 71% relative improvement when\ncompared to TransNet and DeepCoNN respectively. We study the behavior of our\nmulti-pointer learning mechanism, shedding light on evidence aggregation\npatterns in review-based recommender systems.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jan 2018 17:14:13 GMT"}, {"version": "v2", "created": "Thu, 21 Jun 2018 11:27:30 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Tay", "Yi", ""], ["Tuan", "Luu Anh", ""], ["Hui", "Siu Cheung", ""]]}, {"id": "1801.09536", "submitter": "Amir Bakarov", "authors": "Amir Bakarov", "title": "A Survey of Word Embeddings Evaluation Methods", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Word embeddings are real-valued word representations able to capture lexical\nsemantics and trained on natural language corpora. Models proposing these\nrepresentations have gained popularity in the recent years, but the issue of\nthe most adequate evaluation method still remains open. This paper presents an\nextensive overview of the field of word embeddings evaluation, highlighting\nmain problems and proposing a typology of approaches to evaluation, summarizing\n16 intrinsic methods and 12 extrinsic methods. I describe both widely-used and\nexperimental methods, systematize information about evaluation datasets and\ndiscuss some key challenges.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jan 2018 13:23:10 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Bakarov", "Amir", ""]]}, {"id": "1801.09633", "submitter": "Leon Derczynski", "authors": "Leon Derczynski, Kenny Meesters, Kalina Bontcheva, Diana Maynard", "title": "Helping Crisis Responders Find the Informative Needle in the Tweet\n  Haystack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Crisis responders are increasingly using social media, data and other digital\nsources of information to build a situational understanding of a crisis\nsituation in order to design an effective response. However with the increased\navailability of such data, the challenge of identifying relevant information\nfrom it also increases. This paper presents a successful automatic approach to\nhandling this problem. Messages are filtered for informativeness based on a\ndefinition of the concept drawn from prior research and crisis response\nexperts. Informative messages are tagged for actionable data -- for example,\npeople in need, threats to rescue efforts, changes in environment, and so on.\nIn all, eight categories of actionability are identified. The two components --\ninformativeness and actionability classification -- are packaged together as an\nopenly-available tool called Emina (Emergent Informativeness and\nActionability).\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 17:18:40 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Derczynski", "Leon", ""], ["Meesters", "Kenny", ""], ["Bontcheva", "Kalina", ""], ["Maynard", "Diana", ""]]}, {"id": "1801.09637", "submitter": "Henri Kauhanen", "authors": "Henri Kauhanen, Deepthi Gopal, Tobias Galla, Ricardo Berm\\'udez-Otero", "title": "Geospatial distributions reflect rates of evolution of features of\n  language", "comments": "33 pages, of which 17 pages Supplementary Information, 6 figures, 3\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cond-mat.stat-mech cs.CL nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different structural features of human language change at different rates and\nthus exhibit different temporal stabilities. Existing methods of linguistic\nstability estimation depend upon the prior genealogical classification of the\nworld's languages into language families; these methods result in unreliable\nstability estimates for features which are sensitive to horizontal transfer\nbetween families and whenever data are aggregated from families of divergent\ntime depths. To overcome these problems, we describe a method of stability\nestimation without family classifications, based on mathematical modelling and\nthe analysis of contemporary geospatial distributions of linguistic features.\nRegressing the estimates produced by our model against those of a genealogical\nmethod, we report broad agreement but also important differences. In\nparticular, we show that our approach is not liable to some of the false\npositives and false negatives incurred by the genealogical method. Our results\nsuggest that the historical evolution of a linguistic feature leaves a\nfootprint in its global geospatial distribution, and that rates of evolution\ncan be recovered from these distributions by treating language dynamics as a\nspatially extended stochastic process.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 17:24:27 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Kauhanen", "Henri", ""], ["Gopal", "Deepthi", ""], ["Galla", "Tobias", ""], ["Berm\u00fadez-Otero", "Ricardo", ""]]}, {"id": "1801.09746", "submitter": "Sushant Kafle", "authors": "Sushant Kafle and Matt Huenerfauth", "title": "A Corpus for Modeling Word Importance in Spoken Dialogue Transcripts", "comments": "Language Resources and Evaluation Conference (LREC)", "journal-ref": "Proceedings of the Eleventh International Conference on Language\n  Resources and Evaluation (LREC 2018)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by a project to create a system for people who are deaf or\nhard-of-hearing that would use automatic speech recognition (ASR) to produce\nreal-time text captions of spoken English during in-person meetings with\nhearing individuals, we have augmented a transcript of the Switchboard\nconversational dialogue corpus with an overlay of word-importance annotations,\nwith a numeric score for each word, to indicate its importance to the meaning\nof each dialogue turn. Further, we demonstrate the utility of this corpus by\ntraining an automatic word importance labeling model; our best performing model\nhas an F-score of 0.60 in an ordinal 6-class word-importance classification\ntask with an agreement (concordance correlation coefficient) of 0.839 with the\nhuman annotators (agreement score between annotators is 0.89). Finally, we\ndiscuss our intended future applications of this resource, particularly for the\ntask of evaluating ASR performance, i.e. creating metrics that predict\nASR-output caption text usability for DHH users better thanWord Error Rate\n(WER).\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 20:37:10 GMT"}, {"version": "v2", "created": "Fri, 9 Feb 2018 16:09:30 GMT"}, {"version": "v3", "created": "Tue, 16 Jul 2019 22:45:02 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Kafle", "Sushant", ""], ["Huenerfauth", "Matt", ""]]}, {"id": "1801.09788", "submitter": "Nataliia Ruemmele", "authors": "Natalia Ruemmele, Yuriy Tyshetskiy, Alex Collins", "title": "Evaluating approaches for supervised semantic labeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational data sources are still one of the most popular ways to store\nenterprise or Web data, however, the issue with relational schema is the lack\nof a well-defined semantic description. A common ontology provides a way to\nrepresent the meaning of a relational schema and can facilitate the integration\nof heterogeneous data sources within a domain. Semantic labeling is achieved by\nmapping attributes from the data sources to the classes and properties in the\nontology. We formulate this problem as a multi-class classification problem\nwhere previously labeled data sources are used to learn rules for labeling new\ndata sources. The majority of existing approaches for semantic labeling have\nfocused on data integration challenges such as naming conflicts and semantic\nheterogeneity. In addition, machine learning approaches typically have issues\naround class imbalance, lack of labeled instances and relative importance of\nattributes. To address these issues, we develop a new machine learning model\nwith engineered features as well as two deep learning models which do not\nrequire extensive feature engineering. We evaluate our new approaches with the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 22:43:32 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Ruemmele", "Natalia", ""], ["Tyshetskiy", "Yuriy", ""], ["Collins", "Alex", ""]]}, {"id": "1801.09851", "submitter": "Xuan Wang", "authors": "Xuan Wang, Yu Zhang, Xiang Ren, Yuhao Zhang, Marinka Zitnik, Jingbo\n  Shang, Curtis Langlotz and Jiawei Han", "title": "Cross-type Biomedical Named Entity Recognition with Deep Multi-Task\n  Learning", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: State-of-the-art biomedical named entity recognition (BioNER)\nsystems often require handcrafted features specific to each entity type, such\nas genes, chemicals and diseases. Although recent studies explored using neural\nnetwork models for BioNER to free experts from manual feature engineering, the\nperformance remains limited by the available training data for each entity\ntype. Results: We propose a multi-task learning framework for BioNER to\ncollectively use the training data of different types of entities and improve\nthe performance on each of them. In experiments on 15 benchmark BioNER\ndatasets, our multi-task model achieves substantially better performance\ncompared with state-of-the-art BioNER systems and baseline neural sequence\nlabeling models. Further analysis shows that the large performance gains come\nfrom sharing character- and word-level information among relevant biomedical\nentities across differently labeled corpora.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 04:44:14 GMT"}, {"version": "v2", "created": "Thu, 5 Apr 2018 04:37:50 GMT"}, {"version": "v3", "created": "Tue, 18 Sep 2018 19:32:10 GMT"}, {"version": "v4", "created": "Mon, 8 Oct 2018 01:51:11 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Wang", "Xuan", ""], ["Zhang", "Yu", ""], ["Ren", "Xiang", ""], ["Zhang", "Yuhao", ""], ["Zitnik", "Marinka", ""], ["Shang", "Jingbo", ""], ["Langlotz", "Curtis", ""], ["Han", "Jiawei", ""]]}, {"id": "1801.09866", "submitter": "Kyungmin Lee", "authors": "Kyungmin Lee, Chiyoun Park, Namhoon Kim, and Jaewon Lee", "title": "Accelerating recurrent neural network language model based online speech\n  recognition system", "comments": "4 pages, 4 figures, 3 tables, ICASSP2018(Accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents methods to accelerate recurrent neural network based\nlanguage models (RNNLMs) for online speech recognition systems. Firstly, a\nlossy compression of the past hidden layer outputs (history vector) with\ncaching is introduced in order to reduce the number of LM queries. Next, RNNLM\ncomputations are deployed in a CPU-GPU hybrid manner, which computes each layer\nof the model on a more advantageous platform. The added overhead by data\nexchanges between CPU and GPU is compensated through a frame-wise batching\nstrategy. The performance of the proposed methods evaluated on LibriSpeech test\nsets indicates that the reduction in history vector precision improves the\naverage recognition speed by 1.23 times with minimum degradation in accuracy.\nOn the other hand, the CPU-GPU hybrid parallelization enables RNNLM based\nreal-time recognition with a four times improvement in speed.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 06:58:50 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Lee", "Kyungmin", ""], ["Park", "Chiyoun", ""], ["Kim", "Namhoon", ""], ["Lee", "Jaewon", ""]]}, {"id": "1801.09872", "submitter": "Xuri Tang", "authors": "Xuri Tang", "title": "A State-of-the-Art of Semantic Change Computation", "comments": "This is review of the state of the art of semantic change\n  computation, submitted to Natural Language Engineering", "journal-ref": "2018, Natural Language Engineering", "doi": "10.1017/S1351324918000220", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper reviews the state-of-the-art of semantic change computation, one\nemerging research field in computational linguistics, proposing a framework\nthat summarizes the literature by identifying and expounding five essential\ncomponents in the field: diachronic corpus, diachronic word sense\ncharacterization, change modelling, evaluation data and data visualization.\nDespite the potential of the field, the review shows that current studies are\nmainly focused on testifying hypotheses proposed in theoretical linguistics and\nthat several core issues remain to be solved: the need for diachronic corpora\nof languages other than English, the need for comprehensive evaluation data for\nevaluation, the comparison and construction of approaches to diachronic word\nsense characterization and change modelling, and further exploration of data\nvisualization techniques for hypothesis justification.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 07:17:40 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Tang", "Xuri", ""]]}, {"id": "1801.09893", "submitter": "Hongzhi Zhang", "authors": "Hongzhi Zhang, Guandong Xu, Xiao Liang, Tinglei Huang and Kun fu", "title": "An Attention-Based Word-Level Interaction Model: Relation Detection for\n  Knowledge Base Question Answering", "comments": "Paper submitted to Neurocomputing at 11.12.2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation detection plays a crucial role in Knowledge Base Question Answering\n(KBQA) because of the high variance of relation expression in the question.\nTraditional deep learning methods follow an encoding-comparing paradigm, where\nthe question and the candidate relation are represented as vectors to compare\ntheir semantic similarity. Max- or average- pooling operation, which compresses\nthe sequence of words into fixed-dimensional vectors, becomes the bottleneck of\ninformation. In this paper, we propose to learn attention-based word-level\ninteractions between questions and relations to alleviate the bottleneck issue.\nSimilar to the traditional models, the question and relation are firstly\nrepresented as sequences of vectors. Then, instead of merging the sequence into\na single vector with pooling operation, soft alignments between words from the\nquestion and the relation are learned. The aligned words are subsequently\ncompared with the convolutional neural network (CNN) and the comparison results\nare merged finally. Through performing the comparison on low-level\nrepresentations, the attention-based word-level interaction model (ABWIM)\nrelieves the information loss issue caused by merging the sequence into a\nfixed-dimensional vector before the comparison. The experimental results of\nrelation detection on both SimpleQuestions and WebQuestions datasets show that\nABWIM achieves state-of-the-art accuracy, demonstrating its effectiveness.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 08:44:19 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Zhang", "Hongzhi", ""], ["Xu", "Guandong", ""], ["Liang", "Xiao", ""], ["Huang", "Tinglei", ""], ["fu", "Kun", ""]]}, {"id": "1801.09896", "submitter": "Barbara McGillivray", "authors": "Barbara McGillivray, Federico Sangati", "title": "Pilot study for the COST Action \"Reassembling the Republic of Letters\":\n  language-driven network analysis of letters from the Hartlib's Papers", "comments": "18 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The present report summarizes an exploratory study which we carried out in\nthe context of the COST Action IS1310 \"Reassembling the Republic of Letters,\n1500-1800\", and which is relevant to the activities of Working Group 3 \"Texts\nand Topics\" and Working Group 2 \"People and Networks\". In this study we\ninvestigated the use of Natural Language Processing (NLP) and Network Text\nAnalysis on a small sample of seventeenth-century letters selected from Hartlib\nPapers, whose records are in one of the catalogues of Early Modern Letters\nOnline (EMLO) and whose online edition is available on the website of the\nHumanities Research Institute at the University of Sheffield\n(http://www.hrionline.ac.uk/hartlib/). We outline the NLP pipeline used to\nautomatically process the texts into a network representation, in order to\nidentify the texts' \"narrative centrality\", i.e. the most central entities in\nthe texts, and the relations between them.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 08:50:26 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["McGillivray", "Barbara", ""], ["Sangati", "Federico", ""]]}, {"id": "1801.09936", "submitter": "Mahsa S. Shahshahani", "authors": "Mahsa Sadat Shahshahani, Mahdi Mohseni, Azadeh Shakery, Heshaam Faili", "title": "PEYMA: A Tagged Corpus for Persian Named Entities", "comments": "2017, Signal and Data Processing Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal in the NER task is to classify proper nouns of a text into classes\nsuch as person, location, and organization. This is an important preprocessing\nstep in many NLP tasks such as question-answering and summarization. Although\nmany research studies have been conducted in this area in English and the\nstate-of-the-art NER systems have reached performances of higher than 90\npercent in terms of F1 measure, there are very few research studies for this\ntask in Persian. One of the main important causes of this may be the lack of a\nstandard Persian NER dataset to train and test NER systems. In this research we\ncreate a standard, big-enough tagged Persian NER dataset which will be\ndistributed for free for research purposes. In order to construct such a\nstandard dataset, we studied standard NER datasets which are constructed for\nEnglish researches and found out that almost all of these datasets are\nconstructed using news texts. So we collected documents from ten news websites.\nLater, in order to provide annotators with some guidelines to tag these\ndocuments, after studying guidelines used for constructing CoNLL and MUC\nstandard English datasets, we set our own guidelines considering the Persian\nlinguistic rules.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 11:30:38 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Shahshahani", "Mahsa Sadat", ""], ["Mohseni", "Mahdi", ""], ["Shakery", "Azadeh", ""], ["Faili", "Heshaam", ""]]}, {"id": "1801.09975", "submitter": "Ibrahim Riza Hallac", "authors": "Semiha Makinist, Ibrahim Riza Hallac, Betul Ay Karakus and Galip Aydin", "title": "Preparation of Improved Turkish DataSet for Sentiment Analysis in Social\n  Media", "comments": "Presented at CMES2017", "journal-ref": null, "doi": "10.1051/itmconf/20171301030", "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A public dataset, with a variety of properties suitable for sentiment\nanalysis [1], event prediction, trend detection and other text mining\napplications, is needed in order to be able to successfully perform analysis\nstudies. The vast majority of data on social media is text-based and it is not\npossible to directly apply machine learning processes into these raw data,\nsince several different processes are required to prepare the data before the\nimplementation of the algorithms. For example, different misspellings of same\nword enlarge the word vector space unnecessarily, thereby it leads to reduce\nthe success of the algorithm and increase the computational power requirement.\nThis paper presents an improved Turkish dataset with an effective spelling\ncorrection algorithm based on Hadoop [2]. The collected data is recorded on the\nHadoop Distributed File System and the text based data is processed by\nMapReduce programming model. This method is suitable for the storage and\nprocessing of large sized text based social media data. In this study, movie\nreviews have been automatically recorded with Apache ManifoldCF (MCF) [3] and\ndata clusters have been created. Various methods compared such as Levenshtein\nand Fuzzy String Matching have been proposed to create a public dataset from\ncollected data. Experimental results show that the proposed algorithm, which\ncan be used as an open source dataset in sentiment analysis studies, have been\nperformed successfully to the detection and correction of spelling errors.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 13:18:51 GMT"}, {"version": "v2", "created": "Wed, 31 Jan 2018 14:08:16 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Makinist", "Semiha", ""], ["Hallac", "Ibrahim Riza", ""], ["Karakus", "Betul Ay", ""], ["Aydin", "Galip", ""]]}, {"id": "1801.10063", "submitter": "Stefan Gerdjikov", "authors": "Stefan Gerdjikov", "title": "Characterisation of (Sub)sequential Rational Functions over a General\n  Class Monoids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this technical report we describe a general class of monoids for which\n(sub)sequential rational can be characterised in terms of a congruence relation\nin the flavour of Myhill-Nerode relation. The class of monoids that we consider\ncan be described in terms of natural algebraic axioms, contains the free\nmonoids, groups, the tropical monoid, and is closed under Cartesian.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jan 2018 09:46:22 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Gerdjikov", "Stefan", ""]]}, {"id": "1801.10080", "submitter": "Haimonti Dutta", "authors": "Aayushee Gupta, Haimonti Dutta, Srikanta Bedathur, Lipika Dey", "title": "A Machine Learning Approach to Quantitative Prosopography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Prosopography is an investigation of the common characteristics of a group of\npeople in history, by a collective study of their lives. It involves a study of\nbiographies to solve historical problems. If such biographies are unavailable,\nsurviving documents and secondary biographical data are used. Quantitative\nprosopography involves analysis of information from a wide variety of sources\nabout \"ordinary people\". In this paper, we present a machine learning framework\nfor automatically designing a people gazetteer which forms the basis of\nquantitative prosopographical research. The gazetteer is learnt from the noisy\ntext of newspapers using a Named Entity Recognizer (NER). It is capable of\nidentifying influential people from it by making use of a custom designed\nInfluential Person Index (IPI). Our corpus comprises of 14020 articles from a\nlocal newspaper, \"The Sun\", published from New York in 1896. Some influential\npeople identified by our algorithm include Captain Donald Hankey (an English\nsoldier), Dame Nellie Melba (an Australian operatic soprano), Hugh Allan (a\nCanadian shipping magnate) and Sir Hugh John McDonald (the first Prime Minister\nof Canada).\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 16:13:55 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Gupta", "Aayushee", ""], ["Dutta", "Haimonti", ""], ["Bedathur", "Srikanta", ""], ["Dey", "Lipika", ""]]}, {"id": "1801.10095", "submitter": "Alberto Garcia-Duran", "authors": "Alberto Garcia-Duran, Roberto Gonzalez, Daniel Onoro-Rubio, Mathias\n  Niepert, Hui Li", "title": "TransRev: Modeling Reviews as Translations from Users to Items", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The text of a review expresses the sentiment a customer has towards a\nparticular product. This is exploited in sentiment analysis where machine\nlearning models are used to predict the review score from the text of the\nreview. Furthermore, the products costumers have purchased in the past are\nindicative of the products they will purchase in the future. This is what\nrecommender systems exploit by learning models from purchase information to\npredict the items a customer might be interested in. We propose TransRev, an\napproach to the product recommendation problem that integrates ideas from\nrecommender systems, sentiment analysis, and multi-relational learning into a\njoint learning objective. TransRev learns vector representations for users,\nitems, and reviews. The embedding of a review is learned such that (a) it\nperforms well as input feature of a regression model for sentiment prediction;\nand (b) it always translates the reviewer embedding to the embedding of the\nreviewed items. This allows TransRev to approximate a review embedding at test\ntime as the difference of the embedding of each item and the user embedding.\nThe approximated review embedding is then used with the regression model to\npredict the review score for each item. TransRev outperforms state of the art\nrecommender systems on a large number of benchmark data sets. Moreover, it is\nable to retrieve, for each user and item, the review text from the training set\nwhose embedding is most similar to the approximated review embedding.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 17:01:01 GMT"}, {"version": "v2", "created": "Wed, 18 Apr 2018 09:39:23 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Garcia-Duran", "Alberto", ""], ["Gonzalez", "Roberto", ""], ["Onoro-Rubio", "Daniel", ""], ["Niepert", "Mathias", ""], ["Li", "Hui", ""]]}, {"id": "1801.10198", "submitter": "Peter J Liu", "authors": "Peter J. Liu, Mohammad Saleh, Etienne Pot, Ben Goodrich, Ryan Sepassi,\n  Lukasz Kaiser, Noam Shazeer", "title": "Generating Wikipedia by Summarizing Long Sequences", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that generating English Wikipedia articles can be approached as a\nmulti- document summarization of source documents. We use extractive\nsummarization to coarsely identify salient information and a neural abstractive\nmodel to generate the article. For the abstractive model, we introduce a\ndecoder-only architecture that can scalably attend to very long sequences, much\nlonger than typical encoder- decoder architectures used in sequence\ntransduction. We show that this model can generate fluent, coherent\nmulti-sentence paragraphs and even whole Wikipedia articles. When given\nreference documents, we show it can extract relevant factual information as\nreflected in perplexity, ROUGE scores and human evaluations.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 20:07:01 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Liu", "Peter J.", ""], ["Saleh", "Mohammad", ""], ["Pot", "Etienne", ""], ["Goodrich", "Ben", ""], ["Sepassi", "Ryan", ""], ["Kaiser", "Lukasz", ""], ["Shazeer", "Noam", ""]]}, {"id": "1801.10253", "submitter": "Spencer Cappallo", "authors": "Spencer Cappallo, Stacey Svetlichnaya, Pierre Garrigues, Thomas\n  Mensink, Cees G. M. Snoek", "title": "The New Modality: Emoji Challenges in Prediction, Anticipation, and\n  Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade, emoji have emerged as a new and widespread form of\ndigital communication, spanning diverse social networks and spoken languages.\nWe propose to treat these ideograms as a new modality in their own right,\ndistinct in their semantic structure from both the text in which they are often\nembedded as well as the images which they resemble. As a new modality, emoji\npresent rich novel possibilities for representation and interaction. In this\npaper, we explore the challenges that arise naturally from considering the\nemoji modality through the lens of multimedia research. Specifically, the ways\nin which emoji can be related to other common modalities such as text and\nimages. To do so, we first present a large scale dataset of real-world emoji\nusage collected from Twitter. This dataset contains examples of both text-emoji\nand image-emoji relationships. We present baseline results on the challenge of\npredicting emoji from both text and images, using state-of-the-art neural\nnetworks. Further, we offer a first consideration into the problem of how to\naccount for new, unseen emoji - a relevant issue as the emoji vocabulary\ncontinues to expand on a yearly basis. Finally, we present results for\nmultimedia retrieval using emoji as queries.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 23:19:49 GMT"}, {"version": "v2", "created": "Fri, 2 Feb 2018 14:59:47 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Cappallo", "Spencer", ""], ["Svetlichnaya", "Stacey", ""], ["Garrigues", "Pierre", ""], ["Mensink", "Thomas", ""], ["Snoek", "Cees G. M.", ""]]}, {"id": "1801.10293", "submitter": "Avneesh Saluja", "authors": "Avneesh Saluja, Chris Dyer, Jean-David Ruvini", "title": "Paraphrase-Supervised Models of Compositionality", "comments": "This paper was originally submitted for review at NAACL 2015 and ACL\n  2015. This version maintains the original author affiliation \"as-is\" (as of\n  when the work was done)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compositional vector space models of meaning promise new solutions to\nstubborn language understanding problems. This paper makes two contributions\ntoward this end: (i) it uses automatically-extracted paraphrase examples as a\nsource of supervision for training compositional models, replacing previous\nwork which relied on manual annotations used for the same purpose, and (ii)\ndevelops a context-aware model for scoring phrasal compositionality.\nExperimental results indicate that these multiple sources of information can be\nused to learn partial semantic supervision that matches previous techniques in\nintrinsic evaluation tasks. Our approaches are also evaluated for their impact\non a machine translation system where we show improvements in translation\nquality, demonstrating that compositionality in interpretation correlates with\ncompositionality in translation.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 04:14:11 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Saluja", "Avneesh", ""], ["Dyer", "Chris", ""], ["Ruvini", "Jean-David", ""]]}, {"id": "1801.10296", "submitter": "Tao Shen", "authors": "Tao Shen, Tianyi Zhou, Guodong Long, Jing Jiang, Sen Wang, Chengqi\n  Zhang", "title": "Reinforced Self-Attention Network: a Hybrid of Hard and Soft Attention\n  for Sequence Modeling", "comments": "9 pages, 2 figures; accepted at IJCAI-ECAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many natural language processing tasks solely rely on sparse dependencies\nbetween a few tokens in a sentence. Soft attention mechanisms show promising\nperformance in modeling local/global dependencies by soft probabilities between\nevery two tokens, but they are not effective and efficient when applied to long\nsentences. By contrast, hard attention mechanisms directly select a subset of\ntokens but are difficult and inefficient to train due to their combinatorial\nnature. In this paper, we integrate both soft and hard attention into one\ncontext fusion model, \"reinforced self-attention (ReSA)\", for the mutual\nbenefit of each other. In ReSA, a hard attention trims a sequence for a soft\nself-attention to process, while the soft attention feeds reward signals back\nto facilitate the training of the hard one. For this purpose, we develop a\nnovel hard attention called \"reinforced sequence sampling (RSS)\", selecting\ntokens in parallel and trained via policy gradient. Using two RSS modules, ReSA\nefficiently extracts the sparse dependencies between each pair of selected\ntokens. We finally propose an RNN/CNN-free sentence-encoding model, \"reinforced\nself-attention network (ReSAN)\", solely based on ReSA. It achieves\nstate-of-the-art performance on both Stanford Natural Language Inference (SNLI)\nand Sentences Involving Compositional Knowledge (SICK) datasets.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 04:30:32 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 08:45:49 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Shen", "Tao", ""], ["Zhou", "Tianyi", ""], ["Long", "Guodong", ""], ["Jiang", "Jing", ""], ["Wang", "Sen", ""], ["Zhang", "Chengqi", ""]]}, {"id": "1801.10308", "submitter": "Joel Ruben Antony Moniz", "authors": "Joel Ruben Antony Moniz and David Krueger", "title": "Nested LSTMs", "comments": "Accepted at ACML 2017", "journal-ref": "Proceedings of the Ninth Asian Conference on Machine Learning,\n  PMLR 77:530-544, 2017", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Nested LSTMs (NLSTM), a novel RNN architecture with multiple\nlevels of memory. Nested LSTMs add depth to LSTMs via nesting as opposed to\nstacking. The value of a memory cell in an NLSTM is computed by an LSTM cell,\nwhich has its own inner memory cell. Specifically, instead of computing the\nvalue of the (outer) memory cell as $c^{outer}_t = f_t \\odot c_{t-1} + i_t\n\\odot g_t$, NLSTM memory cells use the concatenation $(f_t \\odot c_{t-1}, i_t\n\\odot g_t)$ as input to an inner LSTM (or NLSTM) memory cell, and set\n$c^{outer}_t$ = $h^{inner}_t$. Nested LSTMs outperform both stacked and\nsingle-layer LSTMs with similar numbers of parameters in our experiments on\nvarious character-level language modeling tasks, and the inner memories of an\nLSTM learn longer term dependencies compared with the higher-level units of a\nstacked LSTM.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 05:52:08 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Moniz", "Joel Ruben Antony", ""], ["Krueger", "David", ""]]}, {"id": "1801.10314", "submitter": "Amrita Saha", "authors": "Amrita Saha, Vardaan Pahuja, Mitesh M. Khapra, Karthik\n  Sankaranarayanan and Sarath Chandar", "title": "Complex Sequential Question Answering: Towards Learning to Converse Over\n  Linked Question Answer Pairs with a Knowledge Graph", "comments": "Accepted in AAAI'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While conversing with chatbots, humans typically tend to ask many questions,\na significant portion of which can be answered by referring to large-scale\nknowledge graphs (KG). While Question Answering (QA) and dialog systems have\nbeen studied independently, there is a need to study them closely to evaluate\nsuch real-world scenarios faced by bots involving both these tasks. Towards\nthis end, we introduce the task of Complex Sequential QA which combines the two\ntasks of (i) answering factual questions through complex inferencing over a\nrealistic-sized KG of millions of entities, and (ii) learning to converse\nthrough a series of coherently linked QA pairs. Through a labor intensive\nsemi-automatic process, involving in-house and crowdsourced workers, we created\na dataset containing around 200K dialogs with a total of 1.6M turns. Further,\nunlike existing large scale QA datasets which contain simple questions that can\nbe answered from a single tuple, the questions in our dialogs require a larger\nsubgraph of the KG. Specifically, our dataset has questions which require\nlogical, quantitative, and comparative reasoning as well as their combinations.\nThis calls for models which can: (i) parse complex natural language questions,\n(ii) use conversation context to resolve coreferences and ellipsis in\nutterances, (iii) ask for clarifications for ambiguous queries, and finally\n(iv) retrieve relevant subgraphs of the KG to answer such questions. However,\nour experiments with a combination of state of the art dialog and QA models\nshow that they clearly do not achieve the above objectives and are inadequate\nfor dealing with such complex real world settings. We believe that this new\ndataset coupled with the limitations of existing models as reported in this\npaper should encourage further research in Complex Sequential QA.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 06:40:40 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 04:51:08 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Saha", "Amrita", ""], ["Pahuja", "Vardaan", ""], ["Khapra", "Mitesh M.", ""], ["Sankaranarayanan", "Karthik", ""], ["Chandar", "Sarath", ""]]}]