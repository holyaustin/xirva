[{"id": "1209.0249", "submitter": "Mohammed El-Dosuky", "authors": "M. A. El-Dosuky, M. Z. Rashad, T. T. Hamza, A. H. EL-Bassiouny", "title": "Robopinion: Opinion Mining Framework Inspired by Autonomous Robot\n  Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data association methods are used by autonomous robots to find matches\nbetween the current landmarks and the new set of observed features. We seek a\nframework for opinion mining to benefit from advancements in autonomous robot\nnavigation in both research and development\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2012 06:00:04 GMT"}], "update_date": "2012-09-04", "authors_parsed": [["El-Dosuky", "M. A.", ""], ["Rashad", "M. Z.", ""], ["Hamza", "T. T.", ""], ["EL-Bassiouny", "A. H.", ""]]}, {"id": "1209.1300", "submitter": "Nisheeth Joshi", "authors": "Nisheeth Joshi, Iti Mathur", "title": "Input Scheme for Hindi Using Phonetic Mapping", "comments": "Proceedings of National Conference on ICT: Theory, Practice and\n  Applications. SPSU Press. Organized by Sir Padampat Singhania University,\n  Udaipur. Sponsored by CSIR, New Delhi. March, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Written Communication on Computers requires knowledge of writing text for the\ndesired language using Computer. Mostly people do not use any other language\nbesides English. This creates a barrier. To resolve this issue we have\ndeveloped a scheme to input text in Hindi using phonetic mapping scheme. Using\nthis scheme we generate intermediate code strings and match them with\npronunciations of input text. Our system show significant success over other\ninput systems available.\n", "versions": [{"version": "v1", "created": "Sun, 19 Aug 2012 02:38:12 GMT"}], "update_date": "2012-09-07", "authors_parsed": [["Joshi", "Nisheeth", ""], ["Mathur", "Iti", ""]]}, {"id": "1209.1301", "submitter": "Nisheeth Joshi", "authors": "Nisheeth Joshi, Iti Mathur", "title": "Evaluation of Computational Grammar Formalisms for Indian Languages", "comments": "Proc. of International Conference in Computer Engineering and\n  Technology, 2012, Organized by Jodhpur Institute of Engineering and\n  Technology, Jodhpur. Sponsored by IEEE, USA and Institution of Engineers\n  (India), Kolkatta", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Natural Language Parsing has been the most prominent research area since the\ngenesis of Natural Language Processing. Probabilistic Parsers are being\ndeveloped to make the process of parser development much easier, accurate and\nfast. In Indian context, identification of which Computational Grammar\nFormalism is to be used is still a question which needs to be answered. In this\npaper we focus on this problem and try to analyze different formalisms for\nIndian languages.\n", "versions": [{"version": "v1", "created": "Sun, 19 Aug 2012 02:31:29 GMT"}], "update_date": "2012-09-07", "authors_parsed": [["Joshi", "Nisheeth", ""], ["Mathur", "Iti", ""]]}, {"id": "1209.1751", "submitter": "Ramon Ferrer i Cancho", "authors": "Ramon Ferrer-i-Cancho and Ferm\\'in Moscoso del Prado Mart\\'in", "title": "Information content versus word length in random typing", "comments": null, "journal-ref": "Journal of Statistical Mechanics, L12002 (2011)", "doi": "10.1088/1742-5468/2011/12/L12002", "report-no": null, "categories": "physics.data-an cond-mat.stat-mech cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, it has been claimed that a linear relationship between a measure of\ninformation content and word length is expected from word length optimization\nand it has been shown that this linearity is supported by a strong correlation\nbetween information content and word length in many languages (Piantadosi et\nal. 2011, PNAS 108, 3825-3826). Here, we study in detail some connections\nbetween this measure and standard information theory. The relationship between\nthe measure and word length is studied for the popular random typing process\nwhere a text is constructed by pressing keys at random from a keyboard\ncontaining letters and a space behaving as a word delimiter. Although this\nrandom process does not optimize word lengths according to information content,\nit exhibits a linear relationship between information content and word length.\nThe exact slope and intercept are presented for three major variants of the\nrandom typing process. A strong correlation between information content and\nword length can simply arise from the units making a word (e.g., letters) and\nnot necessarily from the interplay between a word and its context as proposed\nby Piantadosi et al. In itself, the linear relation does not entail the results\nof any optimization process.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2012 20:19:56 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Ferrer-i-Cancho", "Ramon", ""], ["Mart\u00edn", "Ferm\u00edn Moscoso del Prado", ""]]}, {"id": "1209.2163", "submitter": "Serge Galam", "authors": "Alexandre Delano\\\"e and Serge Galam", "title": "Modeling controversies in the press: the case of the abnormal bees'\n  death", "comments": "22 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The controversy about the cause(s) of abnormal death of bee colonies in\nFrance is investigated through an extensive analysis of the french speaking\npress. A statistical analysis of textual data is first performed on the lexicon\nused by journalists to describe the facts and to present associated\ninformations during the period 1998-2010. Three states are identified to\nexplain the phenomenon. The first state asserts a unique cause, the second one\nfocuses on multifactor causes and the third one states the absence of current\nproof. Assigning each article to one of the three states, we are able to follow\nthe associated opinion dynamics among the journalists over 13 years. Then, we\napply the Galam sequential probabilistic model of opinion dynamic to those\ndata. Assuming journalists are either open mind or inflexible about their\nrespective opinions, the results are reproduced precisely provided we account\nfor a series of annual changes in the proportions of respective inflexibles.\nThe results shed a new counter intuitive light on the various pressure supposed\nto apply on the journalists by either chemical industries or beekeepers and\nexperts or politicians. The obtained dynamics of respective inflexibles shows\nthe possible effect of lobbying, the inertia of the debate and the net\nadvantage gained by the first whistleblowers.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2012 22:03:11 GMT"}], "update_date": "2012-09-12", "authors_parsed": [["Delano\u00eb", "Alexandre", ""], ["Galam", "Serge", ""]]}, {"id": "1209.2341", "submitter": "Subhabrata Mukherjee", "authors": "A.R. Balamurali, Subhabrata Mukherjee, Akshat Malu, Pushpak\n  Bhattacharyya", "title": "Leveraging Sentiment to Compute Word Similarity", "comments": "The paper is available at\n  http://subhabrata-mukherjee.webs.com/publications.htm", "journal-ref": "In Proceedings of The 6th International Global Wordnet Conference\n  (GWC 2012), Matsue, Japan, January, 9-13, 2012", "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this paper, we introduce a new WordNet based similarity metric, SenSim,\nwhich incorporates sentiment content (i.e., degree of positive or negative\nsentiment) of the words being compared to measure the similarity between them.\nThe proposed metric is based on the hypothesis that knowing the sentiment is\nbeneficial in measuring the similarity. To verify this hypothesis, we measure\nand compare the annotator agreement for 2 annotation strategies: 1) sentiment\ninformation of a pair of words is considered while annotating and 2) sentiment\ninformation of a pair of words is not considered while annotating.\nInter-annotator correlation scores show that the agreement is better when the\ntwo annotators consider sentiment information while assigning a similarity\nscore to a pair of words. We use this hypothesis to measure the similarity\nbetween a pair of words. Specifically, we represent each word as a vector\ncontaining sentiment scores of all the content words in the WordNet gloss of\nthe sense of that word. These sentiment scores are derived from a sentiment\nlexicon. We then measure the cosine similarity between the two vectors. We\nperform both intrinsic and extrinsic evaluation of SenSim and compare the\nperformance with other widely usedWordNet similarity metrics.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2012 15:02:20 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2012 14:42:30 GMT"}], "update_date": "2012-09-19", "authors_parsed": [["Balamurali", "A. R.", ""], ["Mukherjee", "Subhabrata", ""], ["Malu", "Akshat", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1209.2352", "submitter": "Subhabrata Mukherjee", "authors": "Subhabrata Mukherjee, Pushpak Bhattacharyya", "title": "Feature Specific Sentiment Analysis for Product Reviews", "comments": "The paper is available at\n  http://subhabrata-mukherjee.webs.com/publications.htm", "journal-ref": "COMPUTATIONAL LINGUISTICS AND INTELLIGENT TEXT PROCESSING, Lecture\n  Notes in Computer Science, 2012, Volume 7181/2012, 475-487", "doi": "10.1007/978-3-642-28604-9_39", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this paper, we present a novel approach to identify feature specific\nexpressions of opinion in product reviews with different features and mixed\nemotions. The objective is realized by identifying a set of potential features\nin the review and extracting opinion expressions about those features by\nexploiting their associations. Capitalizing on the view that more closely\nassociated words come together to express an opinion about a certain feature,\ndependency parsing is used to identify relations between the opinion\nexpressions. The system learns the set of significant relations to be used by\ndependency parsing and a threshold parameter which allows us to merge closely\nassociated opinion expressions. The data requirement is minimal as this is a\none time learning of the domain independent parameters. The associations are\nrepresented in the form of a graph which is partitioned to finally retrieve the\nopinion expression describing the user specified feature. We show that the\nsystem achieves a high accuracy across all domains and performs at par with\nstate-of-the-art systems despite its data limitations.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2012 15:39:18 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2012 14:44:36 GMT"}], "update_date": "2012-09-19", "authors_parsed": [["Mukherjee", "Subhabrata", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1209.2400", "submitter": "Estelle Delpech", "authors": "Estelle Delpech (LINA), B\\'eatrice Daille (LINA), Emmanuel Morin\n  (LINA), Claire Lemaire", "title": "Identification of Fertile Translations in Medical Comparable Corpora: a\n  Morpho-Compositional Approach", "comments": null, "journal-ref": "AMTA, San Diego, CA : United States (2012)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper defines a method for lexicon in the biomedical domain from\ncomparable corpora. The method is based on compositional translation and\nexploits morpheme-level translation equivalences. It can generate translations\nfor a large variety of morphologically constructed words and can also generate\n'fertile' translations. We show that fertile translations increase the overall\nquality of the extracted lexicon for English to French translation.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2012 19:18:26 GMT"}], "update_date": "2012-09-12", "authors_parsed": [["Delpech", "Estelle", "", "LINA"], ["Daille", "B\u00e9atrice", "", "LINA"], ["Morin", "Emmanuel", "", "LINA"], ["Lemaire", "Claire", ""]]}, {"id": "1209.2493", "submitter": "Subhabrata Mukherjee", "authors": "Subhabrata Mukherjee, Pushpak Bhattacharyya", "title": "WikiSent : Weakly Supervised Sentiment Analysis Through Extractive\n  Summarization With Wikipedia", "comments": "The paper is available at\n  http://subhabrata-mukherjee.webs.com/publications.htm", "journal-ref": "Lecture Notes in Computer Science Volume 7523, 2012, pp 774-793", "doi": "10.1007/978-3-642-33460-3_55", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This paper describes a weakly supervised system for sentiment analysis in the\nmovie review domain. The objective is to classify a movie review into a\npolarity class, positive or negative, based on those sentences bearing opinion\non the movie alone. The irrelevant text, not directly related to the reviewer\nopinion on the movie, is left out of analysis. Wikipedia incorporates the world\nknowledge of movie-specific features in the system which is used to obtain an\nextractive summary of the review, consisting of the reviewer's opinions about\nthe specific aspects of the movie. This filters out the concepts which are\nirrelevant or objective with respect to the given movie. The proposed system,\nWikiSent, does not require any labeled data for training. The only weak\nsupervision arises out of the usage of resources like WordNet, Part-of-Speech\nTagger and Sentiment Lexicons by virtue of their construction. WikiSent\nachieves a considerable accuracy improvement over the baseline and has a better\nor comparable accuracy to the existing semi-supervised and unsupervised systems\nin the domain, on the same dataset. We also perform a general movie review\ntrend analysis using WikiSent to find the trend in movie-making and the public\nacceptance in terms of movie genre, year of release and polarity.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2012 04:33:08 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2012 14:44:11 GMT"}], "update_date": "2012-09-19", "authors_parsed": [["Mukherjee", "Subhabrata", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1209.2495", "submitter": "Subhabrata Mukherjee", "authors": "Subhabrata Mukherjee, Akshat Malu, A.R. Balamurali, Pushpak\n  Bhattacharyya", "title": "TwiSent: A Multistage System for Analyzing Sentiment in Twitter", "comments": "The paper is available at\n  http://subhabrata-mukherjee.webs.com/publications.htm", "journal-ref": "In Proceedings of The 21st ACM Conference on Information and\n  Knowledge Management (CIKM), 2012 as a poster", "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this paper, we present TwiSent, a sentiment analysis system for Twitter.\nBased on the topic searched, TwiSent collects tweets pertaining to it and\ncategorizes them into the different polarity classes positive, negative and\nobjective. However, analyzing micro-blog posts have many inherent challenges\ncompared to the other text genres. Through TwiSent, we address the problems of\n1) Spams pertaining to sentiment analysis in Twitter, 2) Structural anomalies\nin the text in the form of incorrect spellings, nonstandard abbreviations,\nslangs etc., 3) Entity specificity in the context of the topic searched and 4)\nPragmatics embedded in text. The system performance is evaluated on manually\nannotated gold standard data and on an automatically annotated tweet set based\non hashtags. It is a common practise to show the efficacy of a supervised\nsystem on an automatically annotated dataset. However, we show that such a\nsystem achieves lesser classification accurcy when tested on generic twitter\ndataset. We also show that our system performs much better than an existing\nsystem.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2012 04:39:37 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2012 14:43:49 GMT"}], "update_date": "2012-09-19", "authors_parsed": [["Mukherjee", "Subhabrata", ""], ["Malu", "Akshat", ""], ["Balamurali", "A. R.", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1209.3126", "submitter": "Juan Manuel Torres Moreno", "authors": "Juan-Manuel Torres-Moreno", "title": "Beyond Stemming and Lemmatization: Ultra-stemming to Improve Automatic\n  Text Summarization", "comments": "22 pages, 12 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In Automatic Text Summarization, preprocessing is an important phase to\nreduce the space of textual representation. Classically, stemming and\nlemmatization have been widely used for normalizing words. However, even using\nnormalization on large texts, the curse of dimensionality can disturb the\nperformance of summarizers. This paper describes a new method for normalization\nof words to further reduce the space of representation. We propose to reduce\neach word to its initial letters, as a form of Ultra-stemming. The results show\nthat Ultra-stemming not only preserve the content of summaries produced by this\nrepresentation, but often the performances of the systems can be dramatically\nimproved. Summaries on trilingual corpora were evaluated automatically with\nFresa. Results confirm an increase in the performance, regardless of summarizer\nsystem used.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2012 08:45:26 GMT"}], "update_date": "2012-09-17", "authors_parsed": [["Torres-Moreno", "Juan-Manuel", ""]]}, {"id": "1209.4277", "submitter": "Elisa Omodei", "authors": "Elisa Omodei, Thierry Poibeau, Jean-Philippe Cointet", "title": "Multi-Level Modeling of Quotation Families Morphogenesis", "comments": "Published in the Proceedings of the ASE/IEEE 4th Intl. Conf. on\n  Social Computing \"SocialCom 2012\", Sep. 3-5, 2012, Amsterdam, NL", "journal-ref": null, "doi": "10.1109/SocialCom-PASSAT.2012.114", "report-no": null, "categories": "cs.CY cs.CL cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates cultural dynamics in social media by examining the\nproliferation and diversification of clearly-cut pieces of content: quoted\ntexts. In line with the pioneering work of Leskovec et al. and Simmons et al.\non memes dynamics we investigate in deep the transformations that quotations\npublished online undergo during their diffusion. We deliberately put aside the\nstructure of the social network as well as the dynamical patterns pertaining to\nthe diffusion process to focus on the way quotations are changed, how often\nthey are modified and how these changes shape more or less diverse families and\nsub-families of quotations. Following a biological metaphor, we try to\nunderstand in which way mutations can transform quotations at different scales\nand how mutation rates depend on various properties of the quotations.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2012 15:16:20 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2013 13:27:21 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Omodei", "Elisa", ""], ["Poibeau", "Thierry", ""], ["Cointet", "Jean-Philippe", ""]]}, {"id": "1209.4471", "submitter": "Nikola Milo\\v{s}evi\\'c MSc", "authors": "Nikola Milo\\v{s}evi\\'c", "title": "Stemmer for Serbian language", "comments": "16 pages, 8 figures, code included", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In linguistic morphology and information retrieval, stemming is the process\nfor reducing inflected (or sometimes derived) words to their stem, base or root\nform; generally a written word form. In this work is presented suffix stripping\nstemmer for Serbian language, one of the highly inflectional languages.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2012 09:21:29 GMT"}], "update_date": "2012-09-21", "authors_parsed": [["Milo\u0161evi\u0107", "Nikola", ""]]}, {"id": "1209.6238", "submitter": "Kevin Mote", "authors": "Kevin Mote", "title": "Natural Language Processing - A Survey", "comments": "Bachelor's Thesis (Washington State University; 2003); 70 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The utility and power of Natural Language Processing (NLP) seems destined to\nchange our technological society in profound and fundamental ways. However\nthere are, to date, few accessible descriptions of the science of NLP that have\nbeen written for a popular audience, or even for an audience of intelligent,\nbut uninitiated scientists. This paper aims to provide just such an overview.\nIn short, the objective of this article is to describe the purpose, procedures\nand practical applications of NLP in a clear, balanced, and readable way. We\nwill examine the most recent literature describing the methods and processes of\nNLP, analyze some of the challenges that researchers are faced with, and\nbriefly survey some of the current and future applications of this science to\nIT research in general.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2012 21:05:08 GMT"}], "update_date": "2012-09-28", "authors_parsed": [["Mote", "Kevin", ""]]}]