[{"id": "1506.00037", "submitter": "Gilchan Park", "authors": "Gilchan Park, Julia M. Taylor", "title": "Using Syntactic Features for Phishing Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports on the comparison of the subject and object of verbs in\ntheir usage between phishing emails and legitimate emails. The purpose of this\nresearch is to explore whether the syntactic structures and subjects and\nobjects of verbs can be distinguishable features for phishing detection. To\nachieve the objective, we have conducted two series of experiments: the\nsyntactic similarity for sentences, and the subject and object of verb\ncomparison. The results of the experiments indicated that both features can be\nused for some verbs, but more work has to be done for others.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2015 21:51:04 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Park", "Gilchan", ""], ["Taylor", "Julia M.", ""]]}, {"id": "1506.00195", "submitter": "Kaisheng Yao", "authors": "Baolin Peng and Kaisheng Yao", "title": "Recurrent Neural Networks with External Memory for Language\n  Understanding", "comments": "submitted to Interspeech 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) have become increasingly popular for the\ntask of language understanding. In this task, a semantic tagger is deployed to\nassociate a semantic label to each word in an input sequence. The success of\nRNN may be attributed to its ability to memorize long-term dependence that\nrelates the current-time semantic label prediction to the observations many\ntime instances away. However, the memory capacity of simple RNNs is limited\nbecause of the gradient vanishing and exploding problem. We propose to use an\nexternal memory to improve memorization capability of RNNs. We conducted\nexperiments on the ATIS dataset, and observed that the proposed model was able\nto achieve the state-of-the-art results. We compare our proposed model with\nalternative models and report analysis results that may provide insights for\nfuture research.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2015 05:10:03 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Peng", "Baolin", ""], ["Yao", "Kaisheng", ""]]}, {"id": "1506.00196", "submitter": "Kaisheng Yao", "authors": "Kaisheng Yao and Geoffrey Zweig", "title": "Sequence-to-Sequence Neural Net Models for Grapheme-to-Phoneme\n  Conversion", "comments": "Published in INTERSPEECH 2015, Dresden, Germany", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence translation methods based on generation with a\nside-conditioned language model have recently shown promising results in\nseveral tasks. In machine translation, models conditioned on source side words\nhave been used to produce target-language text, and in image captioning, models\nconditioned images have been used to generate caption text. Past work with this\napproach has focused on large vocabulary tasks, and measured quality in terms\nof BLEU. In this paper, we explore the applicability of such models to the\nqualitatively different grapheme-to-phoneme task. Here, the input and output\nside vocabularies are small, plain n-gram models do well, and credit is only\ngiven when the output is exactly correct. We find that the simple\nside-conditioned generation approach is able to rival the state-of-the-art, and\nwe are able to significantly advance the stat-of-the-art with bi-directional\nlong short-term memory (LSTM) neural networks that use the same alignment\ninformation that is used in conventional approaches.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2015 05:14:06 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2015 12:47:57 GMT"}, {"version": "v3", "created": "Thu, 20 Aug 2015 06:27:07 GMT"}], "update_date": "2015-08-21", "authors_parsed": [["Yao", "Kaisheng", ""], ["Zweig", "Geoffrey", ""]]}, {"id": "1506.00275", "submitter": "Shay Cohen", "authors": "Shashi Narayan and Shay B. Cohen", "title": "Diversity in Spectral Learning for Natural Language Parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an approach to create a diverse set of predictions with spectral\nlearning of latent-variable PCFGs (L-PCFGs). Our approach works by creating\nmultiple spectral models where noise is added to the underlying features in the\ntraining set before the estimation of each model. We describe three ways to\ndecode with multiple models. In addition, we describe a simple variant of the\nspectral algorithm for L-PCFGs that is fast and leads to compact models. Our\nexperiments for natural language parsing, for English and German, show that we\nget a significant improvement over baselines comparable to state of the art.\nFor English, we achieve the $F_1$ score of 90.18, and for German we achieve the\n$F_1$ score of 83.38.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2015 19:21:26 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2015 12:02:57 GMT"}], "update_date": "2015-08-18", "authors_parsed": [["Narayan", "Shashi", ""], ["Cohen", "Shay B.", ""]]}, {"id": "1506.00278", "submitter": "Licheng Yu", "authors": "Licheng Yu, Eunbyung Park, Alexander C. Berg, and Tamara L. Berg", "title": "Visual Madlibs: Fill in the blank Image Generation and Question\n  Answering", "comments": "10 pages; 8 figures; 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new dataset consisting of 360,001 focused\nnatural language descriptions for 10,738 images. This dataset, the Visual\nMadlibs dataset, is collected using automatically produced fill-in-the-blank\ntemplates designed to gather targeted descriptions about: people and objects,\ntheir appearances, activities, and interactions, as well as inferences about\nthe general scene or its broader context. We provide several analyses of the\nVisual Madlibs dataset and demonstrate its applicability to two new description\ngeneration tasks: focused description generation, and multiple-choice\nquestion-answering for images. Experiments using joint-embedding and deep\nlearning methods show promising results on these tasks.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2015 19:39:44 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Yu", "Licheng", ""], ["Park", "Eunbyung", ""], ["Berg", "Alexander C.", ""], ["Berg", "Tamara L.", ""]]}, {"id": "1506.00301", "submitter": "Travis Wolfe", "authors": "Travis Wolfe, Mark Dredze, James Mayfield, Paul McNamee, Craig Harman,\n  Tim Finin, Benjamin Van Durme", "title": "Interactive Knowledge Base Population", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most work on building knowledge bases has focused on collecting entities and\nfacts from as large a collection of documents as possible. We argue for and\ndescribe a new paradigm where the focus is on a high-recall extraction over a\nsmall collection of documents under the supervision of a human expert, that we\ncall Interactive Knowledge Base Population (IKBP).\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2015 22:56:43 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Wolfe", "Travis", ""], ["Dredze", "Mark", ""], ["Mayfield", "James", ""], ["McNamee", "Paul", ""], ["Harman", "Craig", ""], ["Finin", "Tim", ""], ["Van Durme", "Benjamin", ""]]}, {"id": "1506.00333", "submitter": "Lin Ma", "authors": "Lin Ma, Zhengdong Lu, Hang Li", "title": "Learning to Answer Questions From Image Using Convolutional Neural\n  Network", "comments": "7 pages, 4 figures. Accepted by AAAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose to employ the convolutional neural network (CNN)\nfor the image question answering (QA). Our proposed CNN provides an end-to-end\nframework with convolutional architectures for learning not only the image and\nquestion representations, but also their inter-modal interactions to produce\nthe answer. More specifically, our model consists of three CNNs: one image CNN\nto encode the image content, one sentence CNN to compose the words of the\nquestion, and one multimodal convolution layer to learn their joint\nrepresentation for the classification in the space of candidate answer words.\nWe demonstrate the efficacy of our proposed model on the DAQUAR and COCO-QA\ndatasets, which are two benchmark datasets for the image QA, with the\nperformances significantly outperforming the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 03:09:49 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2015 09:54:59 GMT"}], "update_date": "2015-11-16", "authors_parsed": [["Ma", "Lin", ""], ["Lu", "Zhengdong", ""], ["Li", "Hang", ""]]}, {"id": "1506.00379", "submitter": "Yankai Lin", "authors": "Yankai Lin, Zhiyuan Liu, Huanbo Luan, Maosong Sun, Siwei Rao, Song Liu", "title": "Modeling Relation Paths for Representation Learning of Knowledge Bases", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning of knowledge bases (KBs) aims to embed both entities\nand relations into a low-dimensional space. Most existing methods only consider\ndirect relations in representation learning. We argue that multiple-step\nrelation paths also contain rich inference patterns between entities, and\npropose a path-based representation learning model. This model considers\nrelation paths as translations between entities for representation learning,\nand addresses two key challenges: (1) Since not all relation paths are\nreliable, we design a path-constraint resource allocation algorithm to measure\nthe reliability of relation paths. (2) We represent relation paths via semantic\ncomposition of relation embeddings. Experimental results on real-world datasets\nshow that, as compared with baselines, our model achieves significant and\nconsistent improvements on knowledge base completion and relation extraction\nfrom text.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 08:22:49 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2015 09:28:49 GMT"}], "update_date": "2015-08-18", "authors_parsed": [["Lin", "Yankai", ""], ["Liu", "Zhiyuan", ""], ["Luan", "Huanbo", ""], ["Sun", "Maosong", ""], ["Rao", "Siwei", ""], ["Liu", "Song", ""]]}, {"id": "1506.00406", "submitter": "Amir Pouya Aghasadeghi", "authors": "Amir Pouya Aghasadeghi and Mohadeseh Bastan", "title": "Monolingually Derived Phrase Scores for Phrase Based SMT Using Neural\n  Networks Vector Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose two new features for estimating phrase-based\nmachine translation parameters from mainly monolingual data. Our method is\nbased on two recently introduced neural network vector representation models\nfor words and sentences. It is the first time that these models have been used\nin an end to end phrase-based machine translation system. Scores obtained from\nour method can recover more than 80% of BLEU loss caused by removing phrase\ntable probabilities. We also show that our features combined with the phrase\ntable probabilities improve the BLEU score by absolute 0.74 points.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 09:36:23 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2015 16:44:32 GMT"}, {"version": "v3", "created": "Tue, 24 May 2016 15:42:50 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Aghasadeghi", "Amir Pouya", ""], ["Bastan", "Mohadeseh", ""]]}, {"id": "1506.00468", "submitter": "Michal Lukasik", "authors": "Michal Lukasik and Trevor Cohn and Kalina Bontcheva", "title": "Classifying Tweet Level Judgements of Rumours in Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media is a rich source of rumours and corresponding community\nreactions. Rumours reflect different characteristics, some shared and some\nindividual. We formulate the problem of classifying tweet level judgements of\nrumours as a supervised learning task. Both supervised and unsupervised domain\nadaptation are considered, in which tweets from a rumour are classified on the\nbasis of other annotated rumours. We demonstrate how multi-task learning helps\nachieve good results on rumours from the 2011 England riots.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 12:20:21 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2015 18:25:55 GMT"}], "update_date": "2015-09-11", "authors_parsed": [["Lukasik", "Michal", ""], ["Cohn", "Trevor", ""], ["Bontcheva", "Kalina", ""]]}, {"id": "1506.00528", "submitter": "Liangliang Cao", "authors": "Chang Wang, Liangliang Cao, Bowen Zhou", "title": "Medical Synonym Extraction with Concept Space Models", "comments": "7 pages, to appear in IJCAI 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel approach for medical synonym extraction. We\naim to integrate the term embedding with the medical domain knowledge for\nhealthcare applications. One advantage of our method is that it is very\nscalable. Experiments on a dataset with more than 1M term pairs show that the\nproposed approach outperforms the baseline approaches by a large margin.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 15:21:00 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Wang", "Chang", ""], ["Cao", "Liangliang", ""], ["Zhou", "Bowen", ""]]}, {"id": "1506.00572", "submitter": "Scott A. Hale", "authors": "Han-Teng Liao, King-wa Fu, Scott A. Hale", "title": "How much is said in a microblog? A multilingual inquiry based on Weibo\n  and Twitter", "comments": "9 pages, 4 figures WebSci 2015", "journal-ref": null, "doi": "10.1145/2786451.2786486", "report-no": null, "categories": "cs.SI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a multilingual study on, per single post of microblog\ntext, (a) how much can be said, (b) how much is written in terms of characters\nand bytes, and (c) how much is said in terms of information content in posts by\ndifferent organizations in different languages. Focusing on three different\nlanguages (English, Chinese, and Japanese), this research analyses Weibo and\nTwitter accounts of major embassies and news agencies. We first establish our\ncriterion for quantifying \"how much can be said\" in a digital text based on the\nopenly available Universal Declaration of Human Rights and the translated\nsubtitles from TED talks. These parallel corpora allow us to determine the\nnumber of characters and bits needed to represent the same content in different\nlanguages and character encodings. We then derive the amount of information\nthat is actually contained in microblog posts authored by selected accounts on\nWeibo and Twitter. Our results confirm that languages with larger character\nsets such as Chinese and Japanese contain more information per character than\nEnglish, but the actual information content contained within a microblog text\nvaries depending on both the type of organization and the language of the post.\nWe conclude with a discussion on the design implications of microblog text\nlimits for different languages.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 17:06:00 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2015 14:37:25 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Liao", "Han-Teng", ""], ["Fu", "King-wa", ""], ["Hale", "Scott A.", ""]]}, {"id": "1506.00578", "submitter": "William Blacoe", "authors": "William Blacoe", "title": "On Quantum Generalizations of Information-Theoretic Measures and their\n  Contribution to Distributional Semantics", "comments": "Presented at Quantum Interaction Conference 2015, Filzbach,\n  Switzerland", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CL math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information-theoretic measures such as relative entropy and correlation are\nextremely useful when modeling or analyzing the interaction of probabilistic\nsystems. We survey the quantum generalization of 5 such measures and point out\nsome of their commonalities and interpretations. In particular we find the\napplication of information theory to distributional semantics useful. By\nmodeling the distributional meaning of words as density operators rather than\nvectors, more of their semantic structure may be exploited. Furthermore,\nproperties of and interactions between words such as ambiguity, similarity and\nentailment can be simulated more richly and intuitively when using methods from\nquantum information theory.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 17:23:38 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Blacoe", "William", ""]]}, {"id": "1506.00698", "submitter": "Hendra Setiawan", "authors": "Hendra Setiawan, Zhongqiang Huang, Jacob Devlin, Thomas Lamar, Rabih\n  Zbib, Richard Schwartz and John Makhoul", "title": "Statistical Machine Translation Features with Multitask Tensor Networks", "comments": "11 pages (9 content + 2 references), 2 figures, accepted to ACL 2015\n  as a long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a three-pronged approach to improving Statistical Machine\nTranslation (SMT), building on recent success in the application of neural\nnetworks to SMT. First, we propose new features based on neural networks to\nmodel various non-local translation phenomena. Second, we augment the\narchitecture of the neural network with tensor layers that capture important\nhigher-order interaction among the network units. Third, we apply multitask\nlearning to estimate the neural network parameters jointly. Each of our\nproposed methods results in significant improvements that are complementary.\nThe overall improvement is +2.7 and +1.8 BLEU points for Arabic-English and\nChinese-English translation over a state-of-the-art system that already\nincludes neural network features.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 22:52:36 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Setiawan", "Hendra", ""], ["Huang", "Zhongqiang", ""], ["Devlin", "Jacob", ""], ["Lamar", "Thomas", ""], ["Zbib", "Rabih", ""], ["Schwartz", "Richard", ""], ["Makhoul", "John", ""]]}, {"id": "1506.00765", "submitter": "Rongrong Ji Rongrong Ji", "authors": "Zheng Cai, Donglin Cao, Rongrong Ji", "title": "Video (GIF) Sentiment Analysis using Large-Scale Mid-Level Ontology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  With faster connection speed, Internet users are now making social network a\nhuge reservoir of texts, images and video clips (GIF). Sentiment analysis for\nsuch online platform can be used to predict political elections, evaluates\neconomic indicators and so on. However, GIF sentiment analysis is quite\nchallenging, not only because it hinges on spatio-temporal visual\ncontentabstraction, but also for the relationship between such abstraction and\nfinal sentiment remains unknown.In this paper, we dedicated to find out such\nrelationship.We proposed a SentiPairSequence basedspatiotemporal visual\nsentiment ontology, which forms the midlevel representations for GIFsentiment.\nThe establishment process of SentiPair contains two steps. First, we construct\nthe Synset Forest to define the semantic tree structure of visual sentiment\nlabel elements. Then, through theSynset Forest, we organically select and\ncombine sentiment label elements to form a mid-level visual sentiment\nrepresentation. Our experiments indicate that SentiPair outperforms other\ncompeting mid-level attributes. Using SentiPair, our analysis frameworkcan\nachieve satisfying prediction accuracy (72.6%). We also opened ourdataset\n(GSO-2015) to the research community. GSO-2015 contains more than 6,000\nmanually annotated GIFs out of more than 40,000 candidates. Each is labeled\nwith both sentiment and SentiPair Sequence.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 06:31:57 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Cai", "Zheng", ""], ["Cao", "Donglin", ""], ["Ji", "Rongrong", ""]]}, {"id": "1506.00799", "submitter": "Xiangyu Zeng", "authors": "Xiangyu Zeng and Shi Yin and Dong Wang", "title": "Learning Speech Rate in Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant performance reduction is often observed in speech recognition\nwhen the rate of speech (ROS) is too low or too high. Most of present\napproaches to addressing the ROS variation focus on the change of speech\nsignals in dynamic properties caused by ROS, and accordingly modify the dynamic\nmodel, e.g., the transition probabilities of the hidden Markov model (HMM).\nHowever, an abnormal ROS changes not only the dynamic but also the static\nproperty of speech signals, and thus can not be compensated for purely by\nmodifying the dynamic model. This paper proposes an ROS learning approach based\non deep neural networks (DNN), which involves an ROS feature as the input of\nthe DNN model and so the spectrum distortion caused by ROS can be learned and\ncompensated for. The experimental results show that this approach can deliver\nbetter performance for too slow and too fast utterances, demonstrating our\nconjecture that ROS impacts both the dynamic and the static property of speech.\nIn addition, the proposed approach can be combined with the conventional HMM\ntransition adaptation method, offering additional performance gains.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 08:59:47 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Zeng", "Xiangyu", ""], ["Yin", "Shi", ""], ["Wang", "Dong", ""]]}, {"id": "1506.00839", "submitter": "Eug\\'enio Ribeiro", "authors": "Eug\\'enio Ribeiro, Ricardo Ribeiro, David Martins de Matos", "title": "The Influence of Context on Dialogue Act Recognition", "comments": "30 pages, 8 figures, 19 tables, submitted to Computational\n  Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents an analysis of the influence of context information on\ndialog act recognition. We performed experiments on the widely explored\nSwitchboard corpus, as well as on data annotated according to the recent ISO\n24617-2 standard. The latter was obtained from the Tilburg DialogBank and\nthrough the mapping of the annotations of a subset of the Let's Go corpus. We\nused a classification approach based on SVMs, which had proved successful in\nprevious work and allowed us to limit the amount of context information\nprovided. This way, we were able to observe the influence patterns as the\namount of context information increased. Our base features consisted of\nn-grams, punctuation, and wh-words. Context information was obtained from one\nto five preceding segments and provided either as n-grams or dialog act\nclassifications, with the latter typically leading to better results and more\nstable influence patterns. In addition to the conclusions about the importance\nand influence of context information, our experiments on the Switchboard corpus\nalso led to results that advanced the state-of-the-art on the dialog act\nrecognition task on that corpus. Furthermore, the results obtained on data\nannotated according to the ISO 24617-2 standard define a baseline for future\nwork and contribute for the standardization of experiments in the area.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 11:12:19 GMT"}, {"version": "v2", "created": "Mon, 9 Jan 2017 17:16:52 GMT"}], "update_date": "2017-01-10", "authors_parsed": [["Ribeiro", "Eug\u00e9nio", ""], ["Ribeiro", "Ricardo", ""], ["de Matos", "David Martins", ""]]}, {"id": "1506.00999", "submitter": "Antoine Bordes", "authors": "Alberto Garcia-Duran, Antoine Bordes, Nicolas Usunier, Yves Grandvalet", "title": "Combining Two And Three-Way Embeddings Models for Link Prediction in\n  Knowledge Bases", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tackles the problem of endogenous link prediction for Knowledge\nBase completion. Knowledge Bases can be represented as directed graphs whose\nnodes correspond to entities and edges to relationships. Previous attempts\neither consist of powerful systems with high capacity to model complex\nconnectivity patterns, which unfortunately usually end up overfitting on rare\nrelationships, or in approaches that trade capacity for simplicity in order to\nfairly model all relationships, frequent or not. In this paper, we propose\nTatec a happy medium obtained by complementing a high-capacity model with a\nsimpler one, both pre-trained separately and then combined. We present several\nvariants of this model with different kinds of regularization and combination\nstrategies and show that this approach outperforms existing methods on\ndifferent types of relationships by achieving state-of-the-art results on four\nbenchmarks of the literature.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 19:34:19 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Garcia-Duran", "Alberto", ""], ["Bordes", "Antoine", ""], ["Usunier", "Nicolas", ""], ["Grandvalet", "Yves", ""]]}, {"id": "1506.01057", "submitter": "Jiwei Li", "authors": "Jiwei Li, Minh-Thang Luong and Dan Jurafsky", "title": "A Hierarchical Neural Autoencoder for Paragraphs and Documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language generation of coherent long texts like paragraphs or longer\ndocuments is a challenging problem for recurrent networks models. In this\npaper, we explore an important step toward this generation task: training an\nLSTM (Long-short term memory) auto-encoder to preserve and reconstruct\nmulti-sentence paragraphs. We introduce an LSTM model that hierarchically\nbuilds an embedding for a paragraph from embeddings for sentences and words,\nthen decodes this embedding to reconstruct the original paragraph. We evaluate\nthe reconstructed paragraph using standard metrics like ROUGE and Entity Grid,\nshowing that neural models are able to encode texts in a way that preserve\nsyntactic, semantic, and discourse coherence. While only a first step toward\ngenerating coherent text units from neural models, our work has the potential\nto significantly impact natural language generation and\nsummarization\\footnote{Code for the three models described in this paper can be\nfound at www.stanford.edu/~jiweil/ .\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 20:53:53 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2015 01:47:34 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Li", "Jiwei", ""], ["Luong", "Minh-Thang", ""], ["Jurafsky", "Dan", ""]]}, {"id": "1506.01066", "submitter": "Jiwei Li", "authors": "Jiwei Li, Xinlei Chen, Eduard Hovy and Dan Jurafsky", "title": "Visualizing and Understanding Neural Models in NLP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural networks have been successfully applied to many NLP tasks the\nresulting vector-based models are very difficult to interpret. For example it's\nnot clear how they achieve {\\em compositionality}, building sentence meaning\nfrom the meanings of words and phrases. In this paper we describe four\nstrategies for visualizing compositionality in neural models for NLP, inspired\nby similar work in computer vision. We first plot unit values to visualize\ncompositionality of negation, intensification, and concessive clauses, allow us\nto see well-known markedness asymmetries in negation. We then introduce three\nsimple and straightforward methods for visualizing a unit's {\\em salience}, the\namount it contributes to the final composed meaning: (1) gradient\nback-propagation, (2) the variance of a token from the average word node, (3)\nLSTM-style gates that measure information flow. We test our methods on\nsentiment using simple recurrent nets and LSTMs. Our general-purpose methods\nmay have wide applications for understanding compositionality and other\nsemantic properties of deep networks , and also shed light on why LSTMs\noutperform simple recurrent nets,\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 21:17:31 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2016 18:10:22 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Li", "Jiwei", ""], ["Chen", "Xinlei", ""], ["Hovy", "Eduard", ""], ["Jurafsky", "Dan", ""]]}, {"id": "1506.01070", "submitter": "Jiwei Li", "authors": "Jiwei Li and Dan Jurafsky", "title": "Do Multi-Sense Embeddings Improve Natural Language Understanding?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a distinct representation for each sense of an ambiguous word could\nlead to more powerful and fine-grained models of vector-space representations.\nYet while `multi-sense' methods have been proposed and tested on artificial\nword-similarity tasks, we don't know if they improve real natural language\nunderstanding tasks. In this paper we introduce a multi-sense embedding model\nbased on Chinese Restaurant Processes that achieves state of the art\nperformance on matching human word similarity judgments, and propose a\npipelined architecture for incorporating multi-sense embeddings into language\nunderstanding.\n  We then test the performance of our model on part-of-speech tagging, named\nentity recognition, sentiment analysis, semantic relation identification and\nsemantic relatedness, controlling for embedding dimensionality. We find that\nmulti-sense embeddings do improve performance on some tasks (part-of-speech\ntagging, semantic relation identification, semantic relatedness) but not on\nothers (named entity recognition, various forms of sentiment analysis). We\ndiscuss how these differences may be caused by the different role of word sense\ninformation in each of the tasks. The results highlight the importance of\ntesting embedding models in real applications.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 21:30:21 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2015 04:17:48 GMT"}, {"version": "v3", "created": "Tue, 24 Nov 2015 18:29:40 GMT"}], "update_date": "2015-11-25", "authors_parsed": [["Li", "Jiwei", ""], ["Jurafsky", "Dan", ""]]}, {"id": "1506.01094", "submitter": "Kelvin Guu", "authors": "Kelvin Guu, John Miller, Percy Liang", "title": "Traversing Knowledge Graphs in Vector Space", "comments": "2015 Conference on Empirical Methods on Natural Language Processing\n  (EMNLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Path queries on a knowledge graph can be used to answer compositional\nquestions such as \"What languages are spoken by people living in Lisbon?\".\nHowever, knowledge graphs often have missing facts (edges) which disrupts path\nqueries. Recent models for knowledge base completion impute missing facts by\nembedding knowledge graphs in vector spaces. We show that these models can be\nrecursively applied to answer path queries, but that they suffer from cascading\nerrors. This motivates a new \"compositional\" training objective, which\ndramatically improves all models' ability to answer path queries, in some cases\nmore than doubling accuracy. On a standard knowledge base completion task, we\nalso demonstrate that compositional training acts as a novel form of structural\nregularization, reliably improving performance across all base models (reducing\nerrors by up to 43%) and achieving new state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2015 00:38:25 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2015 05:16:24 GMT"}], "update_date": "2015-08-20", "authors_parsed": [["Guu", "Kelvin", ""], ["Miller", "John", ""], ["Liang", "Percy", ""]]}, {"id": "1506.01171", "submitter": "Ahmed Salama Sayed", "authors": "Ahmed G. M. ElSayed, Ahmed S. Salama and Alaa El-Din M. El-Ghazali", "title": "A Hybrid Model for Enhancing Lexical Statistical Machine Translation\n  (SMT)", "comments": "9 pages, 10 figures", "journal-ref": "International Journal of Computer Science Issues Volume 12, Issue\n  2, March 2015", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interest in statistical machine translation systems increases currently\ndue to political and social events in the world. A proposed Statistical Machine\nTranslation (SMT) based model that can be used to translate a sentence from the\nsource Language (English) to the target language (Arabic) automatically through\nefficiently incorporating different statistical and Natural Language Processing\n(NLP) models such as language model, alignment model, phrase based model,\nreordering model, and translation model. These models are combined to enhance\nthe performance of statistical machine translation (SMT). Many implementation\ntools have been used in this work such as Moses, Gizaa++, IRSTLM, KenLM, and\nBLEU. Based on the implementation, evaluation of this model, and comparing the\ngenerated translation with other implemented machine translation systems like\nGoogle Translate, it was proved that this proposed model has enhanced the\nresults of the statistical machine translation, and forms a reliable and\nefficient model in this field of research.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2015 09:18:05 GMT"}], "update_date": "2015-06-04", "authors_parsed": [["ElSayed", "Ahmed G. M.", ""], ["Salama", "Ahmed S.", ""], ["El-Ghazali", "Alaa El-Din M.", ""]]}, {"id": "1506.01192", "submitter": "Bo-Hsiang Tseng", "authors": "Bo-Hsiang Tseng, Hung-Yi Lee, and Lin-Shan Lee", "title": "Personalizing Universal Recurrent Neural Network Language Model with\n  User Characteristic Features by Social Network Crowdsouring", "comments": "IEEE Automatic Speech Recognition and Understanding Workshop (ASRU\n  2015), 13-17 Dec 2015, Scottsdale, Arizona, USA", "journal-ref": null, "doi": "10.1109/ASRU.2015.7404778", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the popularity of mobile devices, personalized speech recognizer becomes\nmore realizable today and highly attractive. Each mobile device is primarily\nused by a single user, so it's possible to have a personalized recognizer well\nmatching to the characteristics of individual user. Although acoustic model\npersonalization has been investigated for decades, much less work have been\nreported on personalizing language model, probably because of the difficulties\nin collecting enough personalized corpora. Previous work used the corpora\ncollected from social networks to solve the problem, but constructing a\npersonalized model for each user is troublesome. In this paper, we propose a\nuniversal recurrent neural network language model with user characteristic\nfeatures, so all users share the same model, except each with different user\ncharacteristic features. These user characteristic features can be obtained by\ncrowdsouring over social networks, which include huge quantity of texts posted\nby users with known friend relationships, who may share some subject topics and\nwording patterns. The preliminary experiments on Facebook corpus showed that\nthis proposed approach not only drastically reduced the model perplexity, but\noffered very good improvement in recognition accuracy in n-best rescoring\ntests. This approach also mitigated the data sparseness problem for\npersonalized language models.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2015 10:14:21 GMT"}, {"version": "v2", "created": "Tue, 23 Aug 2016 03:40:47 GMT"}, {"version": "v3", "created": "Tue, 22 Nov 2016 10:12:12 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Tseng", "Bo-Hsiang", ""], ["Lee", "Hung-Yi", ""], ["Lee", "Lin-Shan", ""]]}, {"id": "1506.01273", "submitter": "David Martins de Matos", "authors": "Marta Apar\\'icio, Paulo Figueiredo, Francisco Raposo, David Martins de\n  Matos, Ricardo Ribeiro, Lu\\'is Marujo", "title": "Summarization of Films and Documentaries Based on Subtitles and Scripts", "comments": "7 pages, 9 tables, 4 figures, submitted to Pattern Recognition\n  Letters (Elsevier)", "journal-ref": "Pattern Recognition Letters, Volume 73, 1 April 2016, Pages 7-12", "doi": "10.1016/j.patrec.2015.12.016", "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We assess the performance of generic text summarization algorithms applied to\nfilms and documentaries, using the well-known behavior of summarization of news\narticles as reference. We use three datasets: (i) news articles, (ii) film\nscripts and subtitles, and (iii) documentary subtitles. Standard ROUGE metrics\nare used for comparing generated summaries against news abstracts, plot\nsummaries, and synopses. We show that the best performing algorithms are LSA,\nfor news articles and documentaries, and LexRank and Support Sets, for films.\nDespite the different nature of films and documentaries, their relative\nbehavior is in accordance with that obtained for news articles.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2015 15:07:14 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2015 12:41:55 GMT"}, {"version": "v3", "created": "Wed, 9 Mar 2016 16:50:43 GMT"}], "update_date": "2016-03-10", "authors_parsed": [["Apar\u00edcio", "Marta", ""], ["Figueiredo", "Paulo", ""], ["Raposo", "Francisco", ""], ["de Matos", "David Martins", ""], ["Ribeiro", "Ricardo", ""], ["Marujo", "Lu\u00eds", ""]]}, {"id": "1506.01597", "submitter": "Piji Li", "authors": "Lidong Bing, Piji Li, Yi Liao, Wai Lam, Weiwei Guo, Rebecca J.\n  Passonneau", "title": "Abstractive Multi-Document Summarization via Phrase Selection and\n  Merging", "comments": "11 pages, 1 figure, accepted as a full paper at ACL 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an abstraction-based multi-document summarization framework that\ncan construct new sentences by exploring more fine-grained syntactic units than\nsentences, namely, noun/verb phrases. Different from existing abstraction-based\napproaches, our method first constructs a pool of concepts and facts\nrepresented by phrases from the input documents. Then new sentences are\ngenerated by selecting and merging informative phrases to maximize the salience\nof phrases and meanwhile satisfy the sentence construction constraints. We\nemploy integer linear optimization for conducting phrase selection and merging\nsimultaneously in order to achieve the global optimal solution for a summary.\nExperimental results on the benchmark data set TAC 2011 show that our framework\noutperforms the state-of-the-art models under automated pyramid evaluation\nmetric, and achieves reasonably well results on manual linguistic quality\nevaluation.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2015 14:04:10 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2015 15:02:46 GMT"}], "update_date": "2015-06-08", "authors_parsed": [["Bing", "Lidong", ""], ["Li", "Piji", ""], ["Liao", "Yi", ""], ["Lam", "Wai", ""], ["Guo", "Weiwei", ""], ["Passonneau", "Rebecca J.", ""]]}, {"id": "1506.01698", "submitter": "Anna Rohrbach", "authors": "Anna Rohrbach and Marcus Rohrbach and Bernt Schiele", "title": "The Long-Short Story of Movie Description", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating descriptions for videos has many applications including assisting\nblind people and human-robot interaction. The recent advances in image\ncaptioning as well as the release of large-scale movie description datasets\nsuch as MPII Movie Description allow to study this task in more depth. Many of\nthe proposed methods for image captioning rely on pre-trained object classifier\nCNNs and Long-Short Term Memory recurrent networks (LSTMs) for generating\ndescriptions. While image description focuses on objects, we argue that it is\nimportant to distinguish verbs, objects, and places in the challenging setting\nof movie description. In this work we show how to learn robust visual\nclassifiers from the weak annotations of the sentence descriptions. Based on\nthese visual classifiers we learn how to generate a description using an LSTM.\nWe explore different design choices to build and train the LSTM and achieve the\nbest performance to date on the challenging MPII-MD dataset. We compare and\nanalyze our approach and prior work along various dimensions to better\nunderstand the key challenges of the movie description task.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2015 19:45:36 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Rohrbach", "Anna", ""], ["Rohrbach", "Marcus", ""], ["Schiele", "Bernt", ""]]}, {"id": "1506.01906", "submitter": "Hossam Ibrahim", "authors": "Hossam S. Ibrahim, Sherif M. Abdou and Mervat Gheith", "title": "Idioms-Proverbs Lexicon for Modern Standard Arabic and Colloquial\n  Sentiment Analysis", "comments": "arXiv admin note: text overlap with arXiv:1505.03105", "journal-ref": "International Journal of Computer Applications 118(11):26-31, May\n  2015", "doi": "10.5120/20790-3435", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although, the fair amount of works in sentiment analysis (SA) and opinion\nmining (OM) systems in the last decade and with respect to the performance of\nthese systems, but it still not desired performance, especially for\nmorphologically-Rich Language (MRL) such as Arabic, due to the complexities and\nchallenges exist in the nature of the languages itself. One of these challenges\nis the detection of idioms or proverbs phrases within the writer text or\ncomment. An idiom or proverb is a form of speech or an expression that is\npeculiar to itself. Grammatically, it cannot be understood from the individual\nmeanings of its elements and can yield different sentiment when treats as\nseparate words. Consequently, In order to facilitate the task of detection and\nclassification of lexical phrases for automated SA systems, this paper presents\nAIPSeLEX a novel idioms/ proverbs sentiment lexicon for modern standard Arabic\n(MSA) and colloquial. AIPSeLEX is manually collected and annotated at sentence\nlevel with semantic orientation (positive or negative). The efforts of manually\nbuilding and annotating the lexicon are reported. Moreover, we build a\nclassifier that extracts idioms and proverbs, phrases from text using n-gram\nand similarity measure methods. Finally, several experiments were carried out\non various data, including Arabic tweets and Arabic microblogs (hotel\nreservation, product reviews, and TV program comments) from publicly available\nArabic online reviews websites (social media, blogs, forums, e-commerce web\nsites) to evaluate the coverage and accuracy of AIPSeLEX.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2015 13:29:33 GMT"}], "update_date": "2015-06-08", "authors_parsed": [["Ibrahim", "Hossam S.", ""], ["Abdou", "Sherif M.", ""], ["Gheith", "Mervat", ""]]}, {"id": "1506.01914", "submitter": "Niklas Laxstr\\\"om", "authors": "Niklas Laxstr\\\"om, Pau Giner, Santhosh Thottingal", "title": "Content Translation: Computer-assisted translation tool for Wikipedia\n  articles", "comments": "EAMT 2015 user study", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The quality and quantity of articles in each Wikipedia language varies\ngreatly. Translating from another Wikipedia is a natural way to add more\ncontent, but the translation process is not properly supported in the software\nused by Wikipedia. Past computer-assisted translation tools built for Wikipedia\nare not commonly used. We created a tool that adapts to the specific needs of\nan open community and to the kind of content in Wikipedia. Qualitative and\nquantitative data indicates that the new tool helps users translate articles\neasier and faster.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2015 13:48:56 GMT"}], "update_date": "2015-06-08", "authors_parsed": [["Laxstr\u00f6m", "Niklas", ""], ["Giner", "Pau", ""], ["Thottingal", "Santhosh", ""]]}, {"id": "1506.02004", "submitter": "Manaal Faruqui", "authors": "Manaal Faruqui, Yulia Tsvetkov, Dani Yogatama, Chris Dyer, Noah Smith", "title": "Sparse Overcomplete Word Vector Representations", "comments": "Proceedings of ACL 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current distributed representations of words show little resemblance to\ntheories of lexical semantics. The former are dense and uninterpretable, the\nlatter largely based on familiar, discrete classes (e.g., supersenses) and\nrelations (e.g., synonymy and hypernymy). We propose methods that transform\nword vectors into sparse (and optionally binary) vectors. The resulting\nrepresentations are more similar to the interpretable features typically used\nin NLP, though they are discovered automatically from raw corpora. Because the\nvectors are highly sparse, they are computationally easy to work with. Most\nimportantly, we find that they outperform the original vectors on benchmark\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2015 18:20:43 GMT"}], "update_date": "2015-06-08", "authors_parsed": [["Faruqui", "Manaal", ""], ["Tsvetkov", "Yulia", ""], ["Yogatama", "Dani", ""], ["Dyer", "Chris", ""], ["Smith", "Noah", ""]]}, {"id": "1506.02075", "submitter": "Antoine Bordes", "authors": "Antoine Bordes, Nicolas Usunier, Sumit Chopra, Jason Weston", "title": "Large-scale Simple Question Answering with Memory Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training large-scale question answering systems is complicated because\ntraining sources usually cover a small portion of the range of possible\nquestions. This paper studies the impact of multitask and transfer learning for\nsimple question answering; a setting for which the reasoning required to answer\nis quite easy, as long as one can retrieve the correct evidence given a\nquestion, which can be difficult in large-scale conditions. To this end, we\nintroduce a new dataset of 100k questions that we use in conjunction with\nexisting benchmarks. We conduct our study within the framework of Memory\nNetworks (Weston et al., 2015) because this perspective allows us to eventually\nscale up to more complex reasoning, and show that Memory Networks can be\nsuccessfully trained to achieve excellent performance.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2015 21:48:39 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Bordes", "Antoine", ""], ["Usunier", "Nicolas", ""], ["Chopra", "Sumit", ""], ["Weston", "Jason", ""]]}, {"id": "1506.02078", "submitter": "Andrej Karpathy", "authors": "Andrej Karpathy, Justin Johnson, Li Fei-Fei", "title": "Visualizing and Understanding Recurrent Networks", "comments": "changing style, adding references, minor changes to text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs), and specifically a variant with Long\nShort-Term Memory (LSTM), are enjoying renewed interest as a result of\nsuccessful applications in a wide range of machine learning problems that\ninvolve sequential data. However, while LSTMs provide exceptional results in\npractice, the source of their performance and their limitations remain rather\npoorly understood. Using character-level language models as an interpretable\ntestbed, we aim to bridge this gap by providing an analysis of their\nrepresentations, predictions and error types. In particular, our experiments\nreveal the existence of interpretable cells that keep track of long-range\ndependencies such as line lengths, quotes and brackets. Moreover, our\ncomparative analysis with finite horizon n-gram models traces the source of the\nLSTM improvements to long-range structural dependencies. Finally, we provide\nanalysis of the remaining errors and suggests areas for further study.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2015 22:33:04 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2015 02:42:24 GMT"}], "update_date": "2015-11-18", "authors_parsed": [["Karpathy", "Andrej", ""], ["Johnson", "Justin", ""], ["Fei-Fei", "Li", ""]]}, {"id": "1506.02170", "submitter": "Megha Rughani G", "authors": "Megha Rughani, D.Shivakrishna", "title": "Hybridized Feature Extraction and Acoustic Modelling Approach for\n  Dysarthric Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dysarthria is malfunctioning of motor speech caused by faintness in the human\nnervous system. It is characterized by the slurred speech along with physical\nimpairment which restricts their communication and creates the lack of\nconfidence and affects the lifestyle. This paper attempt to increase the\nefficiency of Automatic Speech Recognition (ASR) system for unimpaired speech\nsignal. It describes state of art of research into improving ASR for speakers\nwith dysarthria by means of incorporated knowledge of their speech production.\nHybridized approach for feature extraction and acoustic modelling technique\nalong with evolutionary algorithm is proposed for increasing the efficiency of\nthe overall system. Here number of feature vectors are varied and tested the\nsystem performance. It is observed that system performance is boosted by\ngenetic algorithm. System with 16 acoustic features optimized with genetic\nalgorithm has obtained highest recognition rate of 98.28% with training time of\n5:30:17.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2015 17:05:00 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Rughani", "Megha", ""], ["Shivakrishna", "D.", ""]]}, {"id": "1506.02275", "submitter": "Jacob Eisenstein", "authors": "Umashanthi Pavalanathan and Jacob Eisenstein", "title": "Confounds and Consequences in Geotagged Twitter Data", "comments": "final version for EMNLP 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twitter is often used in quantitative studies that identify\ngeographically-preferred topics, writing styles, and entities. These studies\nrely on either GPS coordinates attached to individual messages, or on the\nuser-supplied location field in each profile. In this paper, we compare these\ndata acquisition techniques and quantify the biases that they introduce; we\nalso measure their effects on linguistic analysis and text-based geolocation.\nGPS-tagging and self-reported locations yield measurably different corpora, and\nthese linguistic differences are partially attributable to differences in\ndataset composition by age and gender. Using a latent variable model to induce\nage and gender, we show how these demographic variables interact with geography\nto affect language use. We also show that the accuracy of text-based\ngeolocation varies with population demographics, giving the best results for\nmen above the age of 40.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2015 15:29:26 GMT"}, {"version": "v2", "created": "Sat, 22 Aug 2015 15:25:59 GMT"}], "update_date": "2015-08-25", "authors_parsed": [["Pavalanathan", "Umashanthi", ""], ["Eisenstein", "Jacob", ""]]}, {"id": "1506.02306", "submitter": "Shibamouli Lahiri", "authors": "Shibamouli Lahiri", "title": "SQUINKY! A Corpus of Sentence-level Formality, Informativeness, and\n  Implicature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a corpus of 7,032 sentences rated by human annotators for\nformality, informativeness, and implicature on a 1-7 scale. The corpus was\nannotated using Amazon Mechanical Turk. Reliability in the obtained judgments\nwas examined by comparing mean ratings across two MTurk experiments, and\ncorrelation with pilot annotations (on sentence formality) conducted in a more\ncontrolled setting. Despite the subjectivity and inherent difficulty of the\nannotation task, correlations between mean ratings were quite encouraging,\nespecially on formality and informativeness. We further explored correlation\nbetween the three linguistic variables, genre-wise variation of ratings and\ncorrelations within genres, compatibility with automatic stylistic scoring, and\nsentential make-up of a document in terms of style. To date, our corpus is the\nlargest sentence-level annotated corpus released for formality,\ninformativeness, and implicature.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2015 19:54:00 GMT"}, {"version": "v2", "created": "Tue, 27 Sep 2016 23:54:06 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Lahiri", "Shibamouli", ""]]}, {"id": "1506.02327", "submitter": "Cheng-Tao Chung", "authors": "Cheng-Tao Chung, Cheng-Yu Tsai, Hsiang-Hung Lu, Yuan-ming Liou,\n  Yen-Chen Wu, Yen-Ju Lu, Hung-yi Lee and Lin-shan Lee", "title": "A Multi-layered Acoustic Tokenizing Deep Neural Network (MAT-DNN) for\n  Unsupervised Discovery of Linguistic Units and Generation of High Quality\n  Features", "comments": "submitted to Interspeech 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper summarizes the work done by the authors for the Zero Resource\nSpeech Challenge organized in the technical program of Interspeech 2015. The\ngoal of the challenge is to discover linguistic units directly from unlabeled\nspeech data. The Multi-layered Acoustic Tokenizer (MAT) proposed in this work\nautomatically discovers multiple sets of acoustic tokens from the given corpus.\nEach acoustic token set is specified by a set of hyperparameters that describe\nthe model configuration. These sets of acoustic tokens carry different\ncharacteristics of the given corpus and the language behind thus can be\nmutually reinforced. The multiple sets of token labels are then used as the\ntargets of a Multi-target DNN (MDNN) trained on low-level acoustic features.\nBottleneck features extracted from the MDNN are used as feedback for the MAT\nand the MDNN itself. We call this iterative system the Multi-layered Acoustic\nTokenizing Deep Neural Network (MAT-DNN) which generates high quality features\nfor track 1 of the challenge and acoustic tokens for track 2 of the challenge.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2015 23:52:54 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Chung", "Cheng-Tao", ""], ["Tsai", "Cheng-Yu", ""], ["Lu", "Hsiang-Hung", ""], ["Liou", "Yuan-ming", ""], ["Wu", "Yen-Chen", ""], ["Lu", "Yen-Ju", ""], ["Lee", "Hung-yi", ""], ["Lee", "Lin-shan", ""]]}, {"id": "1506.02338", "submitter": "Andrew Trask", "authors": "Andrew Trask, David Gilmore, Matthew Russell", "title": "Modeling Order in Neural Word Embeddings at Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Language Processing (NLP) systems commonly leverage bag-of-words\nco-occurrence techniques to capture semantic and syntactic word relationships.\nThe resulting word-level distributed representations often ignore morphological\ninformation, though character-level embeddings have proven valuable to NLP\ntasks. We propose a new neural language model incorporating both word order and\ncharacter order in its embedding. The model produces several vector spaces with\nmeaningful substructure, as evidenced by its performance of 85.8% on a recent\nword-analogy task, exceeding best published syntactic word-analogy scores by a\n58% error margin. Furthermore, the model includes several parallel training\nmethods, most notably allowing a skip-gram network with 160 billion parameters\nto be trained overnight on 3 multi-core CPUs, 14x larger than the previous\nlargest neural network.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2015 02:21:46 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2015 15:42:42 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2015 03:00:29 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Trask", "Andrew", ""], ["Gilmore", "David", ""], ["Russell", "Matthew", ""]]}, {"id": "1506.02516", "submitter": "Edward Grefenstette", "authors": "Edward Grefenstette, Karl Moritz Hermann, Mustafa Suleyman, Phil\n  Blunsom", "title": "Learning to Transduce with Unbounded Memory", "comments": "14 pages, 4 figures, NIPS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, strong results have been demonstrated by Deep Recurrent Neural\nNetworks on natural language transduction problems. In this paper we explore\nthe representational power of these models using synthetic grammars designed to\nexhibit phenomena similar to those found in real transduction problems such as\nmachine translation. These experiments lead us to propose new memory-based\nrecurrent networks that implement continuously differentiable analogues of\ntraditional data structures such as Stacks, Queues, and DeQues. We show that\nthese architectures exhibit superior generalisation performance to Deep RNNs\nand are often able to learn the underlying generating algorithms in our\ntransduction experiments.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2015 14:23:30 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2015 16:24:40 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2015 14:07:29 GMT"}], "update_date": "2015-11-04", "authors_parsed": [["Grefenstette", "Edward", ""], ["Hermann", "Karl Moritz", ""], ["Suleyman", "Mustafa", ""], ["Blunsom", "Phil", ""]]}, {"id": "1506.02739", "submitter": "Hannah Rashkin", "authors": "Hannah Rashkin, Sameer Singh, and Yejin Choi", "title": "Connotation Frames: A Data-Driven Investigation", "comments": "11 pages, published in Proceedings of ACL 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through a particular choice of a predicate (e.g., \"x violated y\"), a writer\ncan subtly connote a range of implied sentiments and presupposed facts about\nthe entities x and y: (1) writer's perspective: projecting x as an\n\"antagonist\"and y as a \"victim\", (2) entities' perspective: y probably dislikes\nx, (3) effect: something bad happened to y, (4) value: y is something valuable,\nand (5) mental state: y is distressed by the event. We introduce connotation\nframes as a representation formalism to organize these rich dimensions of\nconnotation using typed relations. First, we investigate the feasibility of\nobtaining connotative labels through crowdsourcing experiments. We then present\nmodels for predicting the connotation frames of verb predicates based on their\ndistributional word representations and the interplay between different types\nof connotative relations. Empirical results confirm that connotation frames can\nbe induced from various data sources that reflect how people use language and\ngive rise to the connotative meanings. We conclude with analytical results that\nshow the potential use of connotation frames for analyzing subtle biases in\nonline news media.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 00:58:51 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2015 23:03:20 GMT"}, {"version": "v3", "created": "Mon, 22 Aug 2016 03:49:42 GMT"}], "update_date": "2016-08-23", "authors_parsed": [["Rashkin", "Hannah", ""], ["Singh", "Sameer", ""], ["Choi", "Yejin", ""]]}, {"id": "1506.02761", "submitter": "Shihao Ji", "authors": "Shihao Ji, Hyokun Yun, Pinar Yanardag, Shin Matsushima, and S. V. N.\n  Vishwanathan", "title": "WordRank: Learning Word Embeddings via Robust Ranking", "comments": "Conference on Empirical Methods in Natural Language Processing\n  (EMNLP), November 1-5, 2016, Austin, Texas, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding words in a vector space has gained a lot of attention in recent\nyears. While state-of-the-art methods provide efficient computation of word\nsimilarities via a low-dimensional matrix embedding, their motivation is often\nleft unclear. In this paper, we argue that word embedding can be naturally\nviewed as a ranking problem due to the ranking nature of the evaluation\nmetrics. Then, based on this insight, we propose a novel framework WordRank\nthat efficiently estimates word representations via robust ranking, in which\nthe attention mechanism and robustness to noise are readily achieved via the\nDCG-like ranking losses. The performance of WordRank is measured in word\nsimilarity and word analogy benchmarks, and the results are compared to the\nstate-of-the-art word embedding techniques. Our algorithm is very competitive\nto the state-of-the- arts on large corpora, while outperforms them by a\nsignificant margin when the training set is limited (i.e., sparse and noisy).\nWith 17 million tokens, WordRank performs almost as well as existing methods\nusing 7.2 billion tokens on a popular word similarity benchmark. Our multi-node\ndistributed implementation of WordRank is publicly available for general usage.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 03:08:06 GMT"}, {"version": "v2", "created": "Sat, 6 Feb 2016 06:02:56 GMT"}, {"version": "v3", "created": "Tue, 23 Feb 2016 06:40:14 GMT"}, {"version": "v4", "created": "Tue, 27 Sep 2016 21:11:56 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Ji", "Shihao", ""], ["Yun", "Hyokun", ""], ["Yanardag", "Pinar", ""], ["Matsushima", "Shin", ""], ["Vishwanathan", "S. V. N.", ""]]}, {"id": "1506.02816", "submitter": "George Gkotsis", "authors": "George Gkotsis, Maria Liakata, Carlos Pedrinaci, John Domingue", "title": "Leveraging Textual Features for Best Answer Prediction in\n  Community-based Question Answering", "comments": "1 figure, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of determining the best answer in\nCommunity-based Question Answering (CQA) websites by focussing on the content.\nIn particular, we present a system, ACQUA [http://acqua.kmi.open.ac.uk], that\ncan be installed onto the majority of browsers as a plugin. The service offers\na seamless and accurate prediction of the answer to be accepted. Previous\nresearch on this topic relies on the exploitation of community feedback on the\nanswers, which involves rating of either users (e.g., reputation) or answers\n(e.g. scores manually assigned to answers). We propose a new technique that\nleverages the content/textual features of answers in a novel way. Our approach\ndelivers better results than related linguistics-based solutions and manages to\nmatch rating-based approaches. More specifically, the gain in performance is\nachieved by rendering the values of these features into a discretised form. We\nalso show how our technique manages to deliver equally good results in\nreal-time settings, as opposed to having to rely on information not always\nreadily available, such as user ratings and answer scores. We ran an evaluation\non 21 StackExchange websites covering around 4 million questions and more than\n8 million answers. We obtain 84% average precision and 70% recall, which shows\nthat our technique is robust, effective, and widely applicable.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 08:09:34 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2015 10:07:48 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Gkotsis", "George", ""], ["Liakata", "Maria", ""], ["Pedrinaci", "Carlos", ""], ["Domingue", "John", ""]]}, {"id": "1506.02922", "submitter": "Dimitra Gkatzia", "authors": "Dimitra Gkatzia and Helen Hastie", "title": "An Ensemble method for Content Selection for Data-to-text Systems", "comments": "3 pages, 2 figures, 1st International Workshop on Data-to-text\n  Generation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach for automatic report generation from time-series\ndata, in the context of student feedback generation. Our proposed methodology\ntreats content selection as a multi-label classification (MLC) problem, which\ntakes as input time-series data (students' learning data) and outputs a summary\nof these data (feedback). Unlike previous work, this method considers all data\nsimultaneously using ensembles of classifiers, and therefore, it achieves\nhigher accuracy and F- score compared to meaningful baselines.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 14:17:06 GMT"}], "update_date": "2015-06-10", "authors_parsed": [["Gkatzia", "Dimitra", ""], ["Hastie", "Helen", ""]]}, {"id": "1506.03099", "submitter": "Samy Bengio", "authors": "Samy Bengio, Oriol Vinyals, Navdeep Jaitly, Noam Shazeer", "title": "Scheduled Sampling for Sequence Prediction with Recurrent Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks can be trained to produce sequences of tokens given\nsome input, as exemplified by recent results in machine translation and image\ncaptioning. The current approach to training them consists of maximizing the\nlikelihood of each token in the sequence given the current (recurrent) state\nand the previous token. At inference, the unknown previous token is then\nreplaced by a token generated by the model itself. This discrepancy between\ntraining and inference can yield errors that can accumulate quickly along the\ngenerated sequence. We propose a curriculum learning strategy to gently change\nthe training process from a fully guided scheme using the true previous token,\ntowards a less guided scheme which mostly uses the generated token instead.\nExperiments on several sequence prediction tasks show that this approach yields\nsignificant improvements. Moreover, it was used successfully in our winning\nentry to the MSCOCO image captioning challenge, 2015.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 20:33:47 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2015 15:29:22 GMT"}, {"version": "v3", "created": "Wed, 23 Sep 2015 16:35:42 GMT"}], "update_date": "2015-09-24", "authors_parsed": [["Bengio", "Samy", ""], ["Vinyals", "Oriol", ""], ["Jaitly", "Navdeep", ""], ["Shazeer", "Noam", ""]]}, {"id": "1506.03139", "submitter": "Keenon Werling", "authors": "Keenon Werling, Gabor Angeli, Christopher Manning", "title": "Robust Subgraph Generation Improves Abstract Meaning Representation\n  Parsing", "comments": "To appear in ACL 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Abstract Meaning Representation (AMR) is a representation for open-domain\nrich semantics, with potential use in fields like event extraction and machine\ntranslation. Node generation, typically done using a simple dictionary lookup,\nis currently an important limiting factor in AMR parsing. We propose a small\nset of actions that derive AMR subgraphs by transformations on spans of text,\nwhich allows for more robust learning of this stage. Our set of construction\nactions generalize better than the previous approach, and can be learned with a\nsimple classifier. We improve on the previous state-of-the-art result for AMR\nparsing, boosting end-to-end performance by 3 F$_1$ on both the LDC2013E117 and\nLDC2014T12 datasets.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 00:40:12 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Werling", "Keenon", ""], ["Angeli", "Gabor", ""], ["Manning", "Christopher", ""]]}, {"id": "1506.03229", "submitter": "Bruno Golosio", "authors": "Bruno Golosio, Angelo Cangelosi, Olesya Gamotina, Giovanni Luca Masala", "title": "A cognitive neural architecture able to learn and communicate through\n  natural language", "comments": "The source code of the software, the User Guide and the datasets used\n  for its validation are available in the ANNABELL web site at\n  https://github.com/golosio/annabell/wiki", "journal-ref": "PLoS ONE 10 (2015) e0140866", "doi": "10.1371/journal.pone.0140866", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communicative interactions involve a kind of procedural knowledge that is\nused by the human brain for processing verbal and nonverbal inputs and for\nlanguage production. Although considerable work has been done on modeling human\nlanguage abilities, it has been difficult to bring them together to a\ncomprehensive tabula rasa system compatible with current knowledge of how\nverbal information is processed in the brain. This work presents a cognitive\nsystem, entirely based on a large-scale neural architecture, which was\ndeveloped to shed light on the procedural knowledge involved in language\nelaboration. The main component of this system is the central executive, which\nis a supervising system that coordinates the other components of the working\nmemory. In our model, the central executive is a neural network that takes as\ninput the neural activation states of the short-term memory and yields as\noutput mental actions, which control the flow of information among the working\nmemory components through neural gating mechanisms. The proposed system is\ncapable of learning to communicate through natural language starting from\ntabula rasa, without any a priori knowledge of the structure of phrases,\nmeaning of words, role of the different classes of words, only by interacting\nwith a human through a text-based interface, using an open-ended incremental\nlearning process. It is able to learn nouns, verbs, adjectives, pronouns and\nother word classes, and to use them in expressive language. The model was\nvalidated on a corpus of 1587 input sentences, based on literature on early\nlanguage assessment, at the level of about 4-years old child, and produced 521\noutput sentences, expressing a broad range of language processing\nfunctionalities.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 09:25:59 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2015 16:58:57 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2015 16:43:59 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Golosio", "Bruno", ""], ["Cangelosi", "Angelo", ""], ["Gamotina", "Olesya", ""], ["Masala", "Giovanni Luca", ""]]}, {"id": "1506.03257", "submitter": "Borja Navarro-Colorado", "authors": "Borja Navarro-Colorado and Estela Saquete", "title": "Combining Temporal Information and Topic Modeling for Cross-Document\n  Event Ordering", "comments": "5 pages", "journal-ref": "Proceedings of the 9th International Workshop on Semantic\n  Evaluation (SemEval 2015) http://www.aclweb.org/anthology/S/S15/", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building unified timelines from a collection of written news articles\nrequires cross-document event coreference resolution and temporal relation\nextraction. In this paper we present an approach event coreference resolution\naccording to: a) similar temporal information, and b) similar semantic\narguments. Temporal information is detected using an automatic temporal\ninformation system (TIPSem), while semantic information is represented by means\nof LDA Topic Modeling. The evaluation of our approach shows that it obtains the\nhighest Micro-average F-score results in the SemEval2015 Task 4: TimeLine:\nCross-Document Event Ordering (25.36\\% for TrackB, 23.15\\% for SubtrackB), with\nan improvement of up to 6\\% in comparison to the other systems. However, our\nexperiment also showed some draw-backs in the Topic Modeling approach that\ndegrades performance of the system.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 11:28:31 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Navarro-Colorado", "Borja", ""], ["Saquete", "Estela", ""]]}, {"id": "1506.03340", "submitter": "Karl Moritz Hermann", "authors": "Karl Moritz Hermann, Tom\\'a\\v{s} Ko\\v{c}isk\\'y, Edward Grefenstette,\n  Lasse Espeholt, Will Kay, Mustafa Suleyman and Phil Blunsom", "title": "Teaching Machines to Read and Comprehend", "comments": "Appears in: Advances in Neural Information Processing Systems 28\n  (NIPS 2015). 14 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Teaching machines to read natural language documents remains an elusive\nchallenge. Machine reading systems can be tested on their ability to answer\nquestions posed on the contents of documents that they have seen, but until now\nlarge scale training and test datasets have been missing for this type of\nevaluation. In this work we define a new methodology that resolves this\nbottleneck and provides large scale supervised reading comprehension data. This\nallows us to develop a class of attention based deep neural networks that learn\nto read real documents and answer complex questions with minimal prior\nknowledge of language structure.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 14:54:39 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2015 15:04:49 GMT"}, {"version": "v3", "created": "Thu, 19 Nov 2015 15:43:23 GMT"}], "update_date": "2015-11-20", "authors_parsed": [["Hermann", "Karl Moritz", ""], ["Ko\u010disk\u00fd", "Tom\u00e1\u0161", ""], ["Grefenstette", "Edward", ""], ["Espeholt", "Lasse", ""], ["Kay", "Will", ""], ["Suleyman", "Mustafa", ""], ["Blunsom", "Phil", ""]]}, {"id": "1506.03487", "submitter": "John Wieting", "authors": "John Wieting, Mohit Bansal, Kevin Gimpel, Karen Livescu, and Dan Roth", "title": "From Paraphrase Database to Compositional Paraphrase Model and Back", "comments": "2015 TACL paper updated with an appendix describing new 300\n  dimensional embeddings. Submitted 1/2015. Accepted 2/2015. Published 6/2015", "journal-ref": "TACL Vol 3 (2015) pg 345-358", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Paraphrase Database (PPDB; Ganitkevitch et al., 2013) is an extensive\nsemantic resource, consisting of a list of phrase pairs with (heuristic)\nconfidence estimates. However, it is still unclear how it can best be used, due\nto the heuristic nature of the confidences and its necessarily incomplete\ncoverage. We propose models to leverage the phrase pairs from the PPDB to build\nparametric paraphrase models that score paraphrase pairs more accurately than\nthe PPDB's internal scores while simultaneously improving its coverage. They\nallow for learning phrase embeddings as well as improved word embeddings.\nMoreover, we introduce two new, manually annotated datasets to evaluate\nshort-phrase paraphrasing models. Using our paraphrase model trained using\nPPDB, we achieve state-of-the-art results on standard word and bigram\nsimilarity tasks and beat strong baselines on our new short phrase paraphrase\ntasks.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 21:29:28 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2015 21:18:00 GMT"}], "update_date": "2015-08-28", "authors_parsed": [["Wieting", "John", ""], ["Bansal", "Mohit", ""], ["Gimpel", "Kevin", ""], ["Livescu", "Karen", ""], ["Roth", "Dan", ""]]}, {"id": "1506.03500", "submitter": "Angeliki  Lazaridou", "authors": "Angeliki Lazaridou, Dat Tien Nguyen, Raffaella Bernardi, Marco Baroni", "title": "Unveiling the Dreams of Word Embeddings: Towards Language-Driven Image\n  Generation", "comments": "A 6-page version to appear at the Multimodal Machine Learning NIPS\n  2015 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce language-driven image generation, the task of generating an\nimage visualizing the semantic contents of a word embedding, e.g., given the\nword embedding of grasshopper, we generate a natural image of a grasshopper. We\nimplement a simple method based on two mapping functions. The first takes as\ninput a word embedding (as produced, e.g., by the word2vec toolkit) and maps it\nonto a high-level visual space (e.g., the space defined by one of the top\nlayers of a Convolutional Neural Network). The second function maps this\nabstract visual representation to pixel space, in order to generate the target\nimage. Several user studies suggest that the current system produces images\nthat capture general visual properties of the concepts encoded in the word\nembedding, such as color or typical environment, and are sufficient to\ndiscriminate between general categories of objects.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 22:57:20 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2015 16:36:48 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Lazaridou", "Angeliki", ""], ["Nguyen", "Dat Tien", ""], ["Bernardi", "Raffaella", ""], ["Baroni", "Marco", ""]]}, {"id": "1506.03694", "submitter": "Grzegorz Chrupa{\\l}a", "authors": "Grzegorz Chrupa{\\l}a and \\'Akos K\\'ad\\'ar and Afra Alishahi", "title": "Learning language through pictures", "comments": "To appear at ACL 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Imaginet, a model of learning visually grounded representations of\nlanguage from coupled textual and visual input. The model consists of two Gated\nRecurrent Unit networks with shared word embeddings, and uses a multi-task\nobjective by receiving a textual description of a scene and trying to\nconcurrently predict its visual representation and the next word in the\nsentence. Mimicking an important aspect of human language learning, it acquires\nmeaning representations for individual words from descriptions of visual\nscenes. Moreover, it learns to effectively use sequential structure in semantic\ninterpretation of multi-word phrases.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2015 14:45:49 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2015 18:56:57 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Chrupa\u0142a", "Grzegorz", ""], ["K\u00e1d\u00e1r", "\u00c1kos", ""], ["Alishahi", "Afra", ""]]}, {"id": "1506.03775", "submitter": "Prakhar Biyani", "authors": "Prakhar Biyani, Cornelia Caragea, Narayan Bhamidipati", "title": "Entity-Specific Sentiment Classification of Yahoo News Comments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment classification is widely used for product reviews and in online\nsocial media such as forums, Twitter, and blogs. However, the problem of\nclassifying the sentiment of user comments on news sites has not been addressed\nyet. News sites cover a wide range of domains including politics, sports,\ntechnology, and entertainment, in contrast to other online social sites such as\nforums and review sites, which are specific to a particular domain. A user\nassociated with a news site is likely to post comments on diverse topics (e.g.,\npolitics, smartphones, and sports) or diverse entities (e.g., Obama, iPhone, or\nGoogle). Classifying the sentiment of users tied to various entities may help\nobtain a holistic view of their personality, which could be useful in\napplications such as online advertising, content personalization, and political\ncampaign planning. In this paper, we formulate the problem of entity-specific\nsentiment classification of comments posted on news articles in Yahoo News and\npropose novel features that are specific to news comments. Experimental results\nshow that our models outperform state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2015 18:53:56 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Biyani", "Prakhar", ""], ["Caragea", "Cornelia", ""], ["Bhamidipati", "Narayan", ""]]}, {"id": "1506.04089", "submitter": "Hongyuan Mei", "authors": "Hongyuan Mei, Mohit Bansal, Matthew R. Walter", "title": "Listen, Attend, and Walk: Neural Mapping of Navigational Instructions to\n  Action Sequences", "comments": "To appear at AAAI 2016 (and an extended version of a NIPS 2015\n  Multimodal Machine Learning workshop paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a neural sequence-to-sequence model for direction following, a\ntask that is essential to realizing effective autonomous agents. Our\nalignment-based encoder-decoder model with long short-term memory recurrent\nneural networks (LSTM-RNN) translates natural language instructions to action\nsequences based upon a representation of the observable world state. We\nintroduce a multi-level aligner that empowers our model to focus on sentence\n\"regions\" salient to the current world state by using multiple abstractions of\nthe input sentence. In contrast to existing methods, our model uses no\nspecialized linguistic resources (e.g., parsers) or task-specific annotations\n(e.g., seed lexicons). It is therefore generalizable, yet still achieves the\nbest results reported to-date on a benchmark single-sentence dataset and\ncompetitive results for the limited-training multi-sentence setting. We analyze\nour model through a series of ablations that elucidate the contributions of the\nprimary components of our model.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2015 18:05:00 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2015 19:22:33 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2015 20:46:09 GMT"}, {"version": "v4", "created": "Thu, 17 Dec 2015 17:57:42 GMT"}], "update_date": "2015-12-18", "authors_parsed": [["Mei", "Hongyuan", ""], ["Bansal", "Mohit", ""], ["Walter", "Matthew R.", ""]]}, {"id": "1506.04147", "submitter": "Jacob Andreas", "authors": "Jacob Andreas, Maxim Rabinovich, Dan Klein, Michael I. Jordan", "title": "On the accuracy of self-normalized log-linear models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calculation of the log-normalizer is a major computational obstacle in\napplications of log-linear models with large output spaces. The problem of fast\nnormalizer computation has therefore attracted significant attention in the\ntheoretical and applied machine learning literature. In this paper, we analyze\na recently proposed technique known as \"self-normalization\", which introduces a\nregularization term in training to penalize log normalizers for deviating from\nzero. This makes it possible to use unnormalized model scores as approximate\nprobabilities. Empirical evidence suggests that self-normalization is extremely\neffective, but a theoretical understanding of why it should work, and how\ngenerally it can be applied, is largely lacking. We prove generalization bounds\non the estimated variance of normalizers and upper bounds on the loss in\naccuracy due to self-normalization, describe classes of input distributions\nthat self-normalize easily, and construct explicit examples of high-variance\ninput distributions. Our theoretical results make predictions about the\ndifficulty of fitting self-normalized models to several classes of\ndistributions, and we conclude with empirical validation of these predictions.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2015 20:00:29 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2015 15:22:50 GMT"}], "update_date": "2015-06-19", "authors_parsed": [["Andreas", "Jacob", ""], ["Rabinovich", "Maxim", ""], ["Klein", "Dan", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1506.04228", "submitter": "Grigor Iliev", "authors": "Grigor Iliev, Nadezhda Borisova, Elena Karashtranova, Dafina\n  Kostadinova", "title": "A Publicly Available Cross-Platform Lemmatizer for Bulgarian", "comments": "5 pages, Sixth International Scientific Conference - FMNS2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our dictionary-based lemmatizer for the Bulgarian language presented here is\ndistributed as free software, publicly available to download and use under the\nGPL v3 license. The presented software is written entirely in Java and is\ndistributed as a GATE plugin. To our best knowledge, at the time of writing\nthis article, there are not any other free lemmatization tools specifically\ntargeting the Bulgarian language. The presented lemmatizer is a work in\nprogress and currently yields an accuracy of about 95% in comparison to the\nmanually annotated corpus BulTreeBank-Morph, which contains 273933 tokens.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2015 05:47:50 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Iliev", "Grigor", ""], ["Borisova", "Nadezhda", ""], ["Karashtranova", "Elena", ""], ["Kostadinova", "Dafina", ""]]}, {"id": "1506.04229", "submitter": "Grigor Iliev", "authors": "Elena Karashtranova, Grigor Iliev, Nadezhda Borisova, Yana Chankova,\n  Irena Atanasova", "title": "Evaluation of the Accuracy of the BGLemmatizer", "comments": "5 pages, Sixth International Scientific Conference - FMNS2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reveals the results of an analysis of the accuracy of developed\nsoftware for automatic lemmatization for the Bulgarian language. This\nlemmatization software is written entirely in Java and is distributed as a GATE\nplugin. Certain statistical methods are used to define the accuracy of this\nsoftware. The results of the analysis show 95% lemmatization accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2015 05:53:57 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Karashtranova", "Elena", ""], ["Iliev", "Grigor", ""], ["Borisova", "Nadezhda", ""], ["Chankova", "Yana", ""], ["Atanasova", "Irena", ""]]}, {"id": "1506.04334", "submitter": "Jan Buys", "authors": "Jan Buys and Phil Blunsom", "title": "A Bayesian Model for Generative Transition-based Dependency Parsing", "comments": "Depling 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple, scalable, fully generative model for transition-based\ndependency parsing with high accuracy. The model, parameterized by Hierarchical\nPitman-Yor Processes, overcomes the limitations of previous generative models\nby allowing fast and accurate inference. We propose an efficient decoding\nalgorithm based on particle filtering that can adapt the beam size to the\nuncertainty in the model while jointly predicting POS tags and parse trees. The\nUAS of the parser is on par with that of a greedy discriminative baseline. As a\nlanguage model, it obtains better perplexity than a n-gram model by performing\nsemi-supervised learning over a large unlabelled corpus. We show that the model\nis able to generate locally and syntactically coherent sentences, opening the\ndoor to further applications in language generation.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2015 23:39:09 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2015 21:18:50 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Buys", "Jan", ""], ["Blunsom", "Phil", ""]]}, {"id": "1506.04365", "submitter": "Kuan-Yu Chen", "authors": "Kuan-Yu Chen, Shih-Hung Liu, Hsin-Min Wang, Berlin Chen, Hsin-Hsi Chen", "title": "Leveraging Word Embeddings for Spoken Document Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owing to the rapidly growing multimedia content available on the Internet,\nextractive spoken document summarization, with the purpose of automatically\nselecting a set of representative sentences from a spoken document to concisely\nexpress the most important theme of the document, has been an active area of\nresearch and experimentation. On the other hand, word embedding has emerged as\na newly favorite research subject because of its excellent performance in many\nnatural language processing (NLP)-related tasks. However, as far as we are\naware, there are relatively few studies investigating its use in extractive\ntext or speech summarization. A common thread of leveraging word embeddings in\nthe summarization process is to represent the document (or sentence) by\naveraging the word embeddings of the words occurring in the document (or\nsentence). Then, intuitively, the cosine similarity measure can be employed to\ndetermine the relevance degree between a pair of representations. Beyond the\ncontinued efforts made to improve the representation of words, this paper\nfocuses on building novel and efficient ranking models based on the general\nword embedding methods for extractive speech summarization. Experimental\nresults demonstrate the effectiveness of our proposed methods, compared to\nexisting state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2015 09:18:36 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Chen", "Kuan-Yu", ""], ["Liu", "Shih-Hung", ""], ["Wang", "Hsin-Min", ""], ["Chen", "Berlin", ""], ["Chen", "Hsin-Hsi", ""]]}, {"id": "1506.04488", "submitter": "Lili Mou", "authors": "Lili Mou, Ran Jia, Yan Xu, Ge Li, Lu Zhang, Zhi Jin", "title": "Distilling Word Embeddings: An Encoding Approach", "comments": "Accepted by CIKM-16 as a short paper, and by the Representation\n  Learning for Natural Language Processing (RL4NLP) Workshop @ACL-16 for\n  presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distilling knowledge from a well-trained cumbersome network to a small one\nhas recently become a new research topic, as lightweight neural networks with\nhigh performance are particularly in need in various resource-restricted\nsystems. This paper addresses the problem of distilling word embeddings for NLP\ntasks. We propose an encoding approach to distill task-specific knowledge from\na set of high-dimensional embeddings, which can reduce model complexity by a\nlarge margin as well as retain high accuracy, showing a good compromise between\nefficiency and performance. Experiments in two tasks reveal the phenomenon that\ndistilling knowledge from cumbersome embeddings is better than directly\ntraining neural networks with small embeddings.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2015 06:30:36 GMT"}, {"version": "v2", "created": "Sun, 24 Jul 2016 16:22:09 GMT"}], "update_date": "2016-07-26", "authors_parsed": [["Mou", "Lili", ""], ["Jia", "Ran", ""], ["Xu", "Yan", ""], ["Li", "Ge", ""], ["Zhang", "Lu", ""], ["Jin", "Zhi", ""]]}, {"id": "1506.04744", "submitter": "Cristian Danescu-Niculescu-Mizil", "authors": "Vlad Niculae, Srijan Kumar, Jordan Boyd-Graber, Cristian\n  Danescu-Niculescu-Mizil", "title": "Linguistic Harbingers of Betrayal: A Case Study on an Online Strategy\n  Game", "comments": "To appear at ACL 2015. 10pp, 4 fig. Data and other info available at\n  http://vene.ro/betrayal/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpersonal relations are fickle, with close friendships often dissolving\ninto enmity. In this work, we explore linguistic cues that presage such\ntransitions by studying dyadic interactions in an online strategy game where\nplayers form alliances and break those alliances through betrayal. We\ncharacterize friendships that are unlikely to last and examine temporal\npatterns that foretell betrayal.\n  We reveal that subtle signs of imminent betrayal are encoded in the\nconversational patterns of the dyad, even if the victim is not aware of the\nrelationship's fate. In particular, we find that lasting friendships exhibit a\nform of balance that manifests itself through language. In contrast, sudden\nchanges in the balance of certain conversational attributes---such as positive\nsentiment, politeness, or focus on future planning---signal impending betrayal.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2015 20:00:29 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Niculae", "Vlad", ""], ["Kumar", "Srijan", ""], ["Boyd-Graber", "Jordan", ""], ["Danescu-Niculescu-Mizil", "Cristian", ""]]}, {"id": "1506.04803", "submitter": "Afshin Rahimi", "authors": "Afshin Rahimi, Duy Vu, Trevor Cohn, and Timothy Baldwin", "title": "Exploiting Text and Network Context for Geolocation of Social Media\n  Users", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on automatically geolocating social media users has conventionally\nbeen based on the text content of posts from a given user or the social network\nof the user, with very little crossover between the two, and no bench-marking\nof the two approaches over compara- ble datasets. We bring the two threads of\nresearch together in first proposing a text-based method based on adaptive\ngrids, followed by a hybrid network- and text-based method. Evaluating over\nthree Twitter datasets, we show that the empirical difference between text- and\nnetwork-based methods is not great, and that hybridisation of the two is\nsuperior to the component methods, especially in contexts where the user graph\nis not well connected. We achieve state-of-the-art results on all three\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 00:32:33 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Rahimi", "Afshin", ""], ["Vu", "Duy", ""], ["Cohn", "Trevor", ""], ["Baldwin", "Timothy", ""]]}, {"id": "1506.04828", "submitter": "Shubham Sharma", "authors": "T. V. Ananthapadmanabha, A. G. Ramakrishnan, and Shubham Sharma", "title": "Significance of the levels of spectral valleys with application to\n  front/back distinction of vowel sounds", "comments": "39 pages, 6 figures, submitted to JASA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An objective critical distance (OCD) has been defined as that spacing between\nadjacent formants, when the level of the valley between them reaches the mean\nspectral level. The measured OCD lies in the same range (viz., 3-3.5 bark) as\nthe critical distance determined by subjective experiments for similar\nexperimental conditions. The level of spectral valley serves a purpose similar\nto that of the spacing between the formants with an added advantage that it can\nbe measured from the spectral envelope without an explicit knowledge of formant\nfrequencies. Based on the relative spacing of formant frequencies, the level of\nthe spectral valley, VI (between F1 and F2) is much higher than the level of\nVII (spectral valley between F2 and F3) for back vowels and vice-versa for\nfront vowels. Classification of vowels into front/back distinction with the\ndifference (VI-VII) as an acoustic feature, tested using TIMIT, NTIMIT, Tamil\nand Kannada language databases gives, on the average, an accuracy of about 95%,\nwhich is comparable to the accuracy (90.6%) obtained using a neural network\nclassifier trained and tested using MFCC as the feature vector for TIMIT\ndatabase. The acoustic feature (VI-VII) has also been tested for its robustness\non the TIMIT database for additive white and babble noise and an accuracy of\nabout 95% has been obtained for SNRs down to 25 dB for both types of noise.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 04:03:06 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2015 12:44:54 GMT"}], "update_date": "2015-10-06", "authors_parsed": [["Ananthapadmanabha", "T. V.", ""], ["Ramakrishnan", "A. G.", ""], ["Sharma", "Shubham", ""]]}, {"id": "1506.04834", "submitter": "Samuel Bowman", "authors": "Samuel R. Bowman, Christopher D. Manning, and Christopher Potts", "title": "Tree-structured composition in neural networks without tree-structured\n  architectures", "comments": "To appear in the proceedings of the 2015 NIPS Workshop on Cognitive\n  Computation: Integrating Neural and Symbolic Approaches", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree-structured neural networks encode a particular tree geometry for a\nsentence in the network design. However, these models have at best only\nslightly outperformed simpler sequence-based models. We hypothesize that neural\nsequence models like LSTMs are in fact able to discover and implicitly use\nrecursive compositional structure, at least for tasks with clear cues to that\nstructure in the data. We demonstrate this possibility using an artificial data\ntask for which recursive compositional structure is crucial, and find an\nLSTM-based sequence model can indeed learn to exploit the underlying tree\nstructure. However, its performance consistently lags behind that of tree\nmodels, even on large training sets, suggesting that tree-structured models are\nmore effective at exploiting recursive structure.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 05:12:52 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2015 16:08:26 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2015 19:45:09 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Bowman", "Samuel R.", ""], ["Manning", "Christopher D.", ""], ["Potts", "Christopher", ""]]}, {"id": "1506.04891", "submitter": "Douglas Bagnall", "authors": "Douglas Bagnall", "title": "Author Identification using Multi-headed Recurrent Neural Networks", "comments": "8 pages, 3 figures Version 1 was a notebook for the PAN@CLEF Author\n  Identification challenge. Version 2 is expanded to be a full paper for\n  CLEF2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are very good at modelling the flow of text,\nbut typically need to be trained on a far larger corpus than is available for\nthe PAN 2015 Author Identification task. This paper describes a novel approach\nwhere the output layer of a character-level RNN language model is split into\nseveral independent predictive sub-models, each representing an author, while\nthe recurrent layer is shared by all. This allows the recurrent layer to model\nthe language as a whole without over-fitting, while the outputs select aspects\nof the underlying model that reflect their author's style. The method proves\ncompetitive, ranking first in two of the four languages.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 09:41:55 GMT"}, {"version": "v2", "created": "Tue, 16 Aug 2016 05:04:57 GMT"}], "update_date": "2016-08-17", "authors_parsed": [["Bagnall", "Douglas", ""]]}, {"id": "1506.04897", "submitter": "Rudolf Rosa", "authors": "Rudolf Rosa", "title": "Parsing Natural Language Sentences by Semi-supervised Methods", "comments": "Dissertation interim report. Overlap with papers accepted to ACL 2015\n  and Depling 2015, and a paper under review at IWPT 2015", "journal-ref": null, "doi": null, "report-no": "3039210042125978224", "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our work on semi-supervised parsing of natural language sentences,\nfocusing on multi-source crosslingual transfer of delexicalized dependency\nparsers. We first evaluate the influence of treebank annotation styles on\nparsing performance, focusing on adposition attachment style. Then, we present\nKLcpos3, an empirical language similarity measure, designed and tuned for\nsource parser weighting in multi-source delexicalized parser transfer. And\nfinally, we introduce a novel resource combination method, based on\ninterpolation of trained parser models.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 09:54:27 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Rosa", "Rudolf", ""]]}, {"id": "1506.04940", "submitter": "Xi Ma", "authors": "Xi Ma, Xiaoxi Wang, Dong Wang, Zhiyong Zhang", "title": "Recognize Foreign Low-Frequency Words with Similar Pairs", "comments": null, "journal-ref": null, "doi": null, "report-no": "1064", "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-frequency words place a major challenge for automatic speech recognition\n(ASR). The probabilities of these words, which are often important name\nentities, are generally under-estimated by the language model (LM) due to their\nlimited occurrences in the training data. Recently, we proposed a word-pair\napproach to deal with the problem, which borrows information of frequent words\nto enhance the probabilities of low-frequency words. This paper presents an\nextension to the word-pair method by involving multiple `predicting words' to\nproduce better estimation for low-frequency words. We also employ this approach\nto deal with out-of-language words in the task of multi-lingual speech\nrecognition.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 12:31:43 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Ma", "Xi", ""], ["Wang", "Xiaoxi", ""], ["Wang", "Dong", ""], ["Zhang", "Zhiyong", ""]]}, {"id": "1506.05012", "submitter": "Adit Jamdar", "authors": "Adit Jamdar, Jessica Abraham, Karishma Khanna and Rahul Dubey", "title": "Emotion Analysis of Songs Based on Lyrical and Audio Features", "comments": "16 pages, 2 figures, 6 tables, 5 equations in International journal\n  of Artificial Intelligence & Applications (IJAIA)", "journal-ref": null, "doi": "10.5121/ijaia.2015.6304", "report-no": null, "categories": "cs.CL cs.AI cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a method is proposed to detect the emotion of a song based on\nits lyrical and audio features. Lyrical features are generated by segmentation\nof lyrics during the process of data extraction. ANEW and WordNet knowledge is\nthen incorporated to compute Valence and Arousal values. In addition to this,\nlinguistic association rules are applied to ensure that the issue of ambiguity\nis properly addressed. Audio features are used to supplement the lyrical ones\nand include attributes like energy, tempo, and danceability. These features are\nextracted from The Echo Nest, a widely used music intelligence platform.\nConstruction of training and test sets is done on the basis of social tags\nextracted from the last.fm website. The classification is done by applying\nfeature weighting and stepwise threshold reduction on the k-Nearest Neighbors\nalgorithm to provide fuzziness in the classification.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 16:04:08 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Jamdar", "Adit", ""], ["Abraham", "Jessica", ""], ["Khanna", "Karishma", ""], ["Dubey", "Rahul", ""]]}, {"id": "1506.05230", "submitter": "Manaal Faruqui", "authors": "Manaal Faruqui, Chris Dyer", "title": "Non-distributional Word Vector Representations", "comments": "Proceedings of ACL 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven representation learning for words is a technique of central\nimportance in NLP. While indisputably useful as a source of features in\ndownstream tasks, such vectors tend to consist of uninterpretable components\nwhose relationship to the categories of traditional lexical semantic theories\nis tenuous at best. We present a method for constructing interpretable word\nvectors from hand-crafted linguistic resources like WordNet, FrameNet etc.\nThese vectors are binary (i.e, contain only 0 and 1) and are 99.9% sparse. We\nanalyze their performance on state-of-the-art evaluation methods for\ndistributional models of word vectors and find they are competitive to standard\ndistributional approaches.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2015 07:40:14 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Faruqui", "Manaal", ""], ["Dyer", "Chris", ""]]}, {"id": "1506.05402", "submitter": "Philipp Mayr", "authors": "Iana Atanassova, Marc Bertin, Philipp Mayr", "title": "Editorial for the First Workshop on Mining Scientific Papers:\n  Computational Linguistics and Bibliometrics", "comments": "4 pages, Workshop on Mining Scientific Papers: Computational\n  Linguistics and Bibliometrics at ISSI 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The workshop \"Mining Scientific Papers: Computational Linguistics and\nBibliometrics\" (CLBib 2015), co-located with the 15th International Society of\nScientometrics and Informetrics Conference (ISSI 2015), brought together\nresearchers in Bibliometrics and Computational Linguistics in order to study\nthe ways Bibliometrics can benefit from large-scale text analytics and sense\nmining of scientific papers, thus exploring the interdisciplinarity of\nBibliometrics and Natural Language Processing (NLP). The goals of the workshop\nwere to answer questions like: How can we enhance author network analysis and\nBibliometrics using data obtained by text analytics? What insights can NLP\nprovide on the structure of scientific writing, on citation networks, and on\nin-text citation analysis? This workshop is the first step to foster the\nreflection on the interdisciplinarity and the benefits that the two disciplines\nBibliometrics and Natural Language Processing can drive from it.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2015 18:03:25 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Atanassova", "Iana", ""], ["Bertin", "Marc", ""], ["Mayr", "Philipp", ""]]}, {"id": "1506.05514", "submitter": "Ubai Sandouk", "authors": "Ubai Sandouk, Ke Chen", "title": "Learning Contextualized Semantics from Co-occurring Terms via a Siamese\n  Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": "2015-06-18", "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the biggest challenges in Multimedia information retrieval and\nunderstanding is to bridge the semantic gap by properly modeling concept\nsemantics in context. The presence of out of vocabulary (OOV) concepts\nexacerbates this difficulty. To address the semantic gap issues, we formulate a\nproblem on learning contextualized semantics from descriptive terms and propose\na novel Siamese architecture to model the contextualized semantics from\ndescriptive terms. By means of pattern aggregation and probabilistic topic\nmodels, our Siamese architecture captures contextualized semantics from the\nco-occurring descriptive terms via unsupervised learning, which leads to a\nconcept embedding space of the terms in context. Furthermore, the co-occurring\nOOV concepts can be easily represented in the learnt concept embedding space.\nThe main properties of the concept embedding space are demonstrated via\nvisualization. Using various settings in semantic priming, we have carried out\na thorough evaluation by comparing our approach to a number of state-of-the-art\nmethods on six annotation corpora in different domains, i.e., MagTag5K, CAL500\nand Million Song Dataset in the music domain as well as Corel5K, LabelMe and\nSUNDatabase in the image domain. Experimental results on semantic priming\nsuggest that our approach outperforms those state-of-the-art methods\nconsiderably in various aspects.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2015 23:03:43 GMT"}], "update_date": "2015-06-19", "authors_parsed": [["Sandouk", "Ubai", ""], ["Chen", "Ke", ""]]}, {"id": "1506.05561", "submitter": "Richard Moot", "authors": "Richard Moot (LaBRI)", "title": "Comparing and evaluating extended Lambek calculi", "comments": "Empirical advances in categorial grammars, Aug 2015, Barcelona,\n  Spain. 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lambeks Syntactic Calculus, commonly referred to as the Lambek calculus, was\ninnovative in many ways, notably as a precursor of linear logic. But it also\nshowed that we could treat our grammatical framework as a logic (as opposed to\na logical theory). However, though it was successful in giving at least a basic\ntreatment of many linguistic phenomena, it was also clear that a slightly more\nexpressive logical calculus was needed for many other cases. Therefore, many\nextensions and variants of the Lambek calculus have been proposed, since the\neighties and up until the present day. As a result, there is now a large class\nof calculi, each with its own empirical successes and theoretical results, but\nalso each with its own logical primitives. This raises the question: how do we\ncompare and evaluate these different logical formalisms? To answer this\nquestion, I present two unifying frameworks for these extended Lambek calculi.\nBoth are proof net calculi with graph contraction criteria. The first calculus\nis a very general system: you specify the structure of your sequents and it\ngives you the connectives and contractions which correspond to it. The calculus\ncan be extended with structural rules, which translate directly into graph\nrewrite rules. The second calculus is first-order (multiplicative\nintuitionistic) linear logic, which turns out to have several other,\nindependently proposed extensions of the Lambek calculus as fragments. I will\nillustrate the use of each calculus in building bridges between analyses\nproposed in different frameworks, in highlighting differences and in helping to\nidentify problems.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2015 07:10:26 GMT"}], "update_date": "2015-06-19", "authors_parsed": [["Moot", "Richard", "", "LaBRI"]]}, {"id": "1506.05676", "submitter": "Maxime Amblard", "authors": "Jiri Marsik (SEMAGRAMME), Maxime Amblard (SEMAGRAMME)", "title": "Pragmatic Side Effects", "comments": "Redrawing Pragmasemantic Borders, Mar 2015, Groningen, Netherlands.\n  https://sites.google.com/site/redraw2015/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the quest to give a formal compositional semantics to natural languages,\nsemanticists have started turning their attention to phenomena that have been\nalso considered as parts of pragmatics (e.g., discourse anaphora and\npresupposition projection). To account for these phenomena, the very kinds of\nmeanings assigned to words and phrases are often revisited. To be more\nspecific, in the prevalent paradigm of modeling natural language denotations\nusing the simply-typed lambda calculus (higher-order logic) this means\nrevisiting the types of denotations assigned to individual parts of speech.\nHowever, the lambda calculus also serves as a fundamental theory of\ncomputation, and in the study of computation, similar type shifts have been\nemployed to give a meaning to side effects. Side effects in programming\nlanguages correspond to actions that go beyond the lexical scope of an\nexpression (a thrown exception might propagate throughout a program, a variable\nmodified at one point might later be read at an another) or even beyond the\nscope of the program itself (a program might interact with the outside world by\ne.g., printing documents, making sounds, operating robotic limbs...).\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2015 19:55:13 GMT"}], "update_date": "2015-06-19", "authors_parsed": [["Marsik", "Jiri", "", "SEMAGRAMME"], ["Amblard", "Maxime", "", "SEMAGRAMME"]]}, {"id": "1506.05702", "submitter": "Diego Amancio", "authors": "Diego R. Amancio", "title": "Comparing the writing style of real and artificial papers", "comments": "To appear in Scientometrics (2015)", "journal-ref": "Scientometrics 105 (3), (2015) pp. 1763-1779", "doi": "10.1007/s11192-015-1637-z", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the increase of competition in science. While\npromoting the quality of research in many cases, an intense competition among\nscientists can also trigger unethical scientific behaviors. To increase the\ntotal number of published papers, some authors even resort to software tools\nthat are able to produce grammatical, but meaningless scientific manuscripts.\nBecause automatically generated papers can be misunderstood as real papers, it\nbecomes of paramount importance to develop means to identify these scientific\nfrauds. In this paper, I devise a methodology to distinguish real manuscripts\nfrom those generated with SCIGen, an automatic paper generator. Upon modeling\ntexts as complex networks (CN), it was possible to discriminate real from fake\npapers with at least 89\\% of accuracy. A systematic analysis of features\nrelevance revealed that the accessibility and betweenness were useful in\nparticular cases, even though the relevance depended upon the dataset. The\nsuccessful application of the methods described here show, as a proof of\nprinciple, that network features can be used to identify scientific gibberish\npapers. In addition, the CN-based approach can be combined in a straightforward\nfashion with traditional statistical language processing methods to improve the\nperformance in identifying artificially generated papers.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2015 14:46:15 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2015 15:50:56 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Amancio", "Diego R.", ""]]}, {"id": "1506.05703", "submitter": "R\\'emi Lebret", "authors": "R\\'emi Lebret and Ronan Collobert", "title": "\"The Sum of Its Parts\": Joint Learning of Word and Phrase\n  Representations with Autoencoders", "comments": "Deep Learning Workshop, ICML 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been a lot of effort to represent words in continuous\nvector spaces. Those representations have been shown to capture both semantic\nand syntactic information about words. However, distributed representations of\nphrases remain a challenge. We introduce a novel model that jointly learns word\nvector representations and their summation. Word representations are learnt\nusing the word co-occurrence statistical information. To embed sequences of\nwords (i.e. phrases) with different sizes into a common semantic space, we\npropose to average word vector representations. In contrast with previous\nmethods which reported a posteriori some compositionality aspects by simple\nsummation, we simultaneously train words to sum, while keeping the maximum\ninformation from the original vectors. We evaluate the quality of the word\nrepresentations on several classical word evaluation tasks, and we introduce a\nnovel task to evaluate the quality of the phrase representations. While our\ndistributed representations compete with other methods of learning word\nrepresentations on word evaluations, we show that they give better performance\non the phrase evaluation. Such representations of phrases could be interesting\nfor many tasks in natural language processing.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2015 14:46:44 GMT"}], "update_date": "2015-06-19", "authors_parsed": [["Lebret", "R\u00e9mi", ""], ["Collobert", "Ronan", ""]]}, {"id": "1506.05865", "submitter": "Baotian Hu", "authors": "Baotian Hu, Qingcai Chen, Fangze Zhu", "title": "LCSTS: A Large Scale Chinese Short Text Summarization Dataset", "comments": "Recently, we received feedbacks from Yuya Taguchi from NAIST in Japan\n  and Qian Chen from USTC of China, that the results in the EMNLP2015 version\n  seem to be underrated. So we carefully checked our results and find out that\n  we made a mistake while using the standard ROUGE. Then we re-evaluate all\n  methods in the paper and get corrected results listed in Table 2 of this\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic text summarization is widely regarded as the highly difficult\nproblem, partially because of the lack of large text summarization data set.\nDue to the great challenge of constructing the large scale summaries for full\ntext, in this paper, we introduce a large corpus of Chinese short text\nsummarization dataset constructed from the Chinese microblogging website Sina\nWeibo, which is released to the public\n{http://icrc.hitsz.edu.cn/Article/show/139.html}. This corpus consists of over\n2 million real Chinese short texts with short summaries given by the author of\neach text. We also manually tagged the relevance of 10,666 short summaries with\ntheir corresponding short texts. Based on the corpus, we introduce recurrent\nneural network for the summary generation and achieve promising results, which\nnot only shows the usefulness of the proposed corpus for short text\nsummarization research, but also provides a baseline for further research on\nthis topic.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2015 02:40:42 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2015 14:33:39 GMT"}, {"version": "v3", "created": "Mon, 17 Aug 2015 02:43:38 GMT"}, {"version": "v4", "created": "Fri, 19 Feb 2016 16:35:35 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Hu", "Baotian", ""], ["Chen", "Qingcai", ""], ["Zhu", "Fangze", ""]]}, {"id": "1506.05869", "submitter": "Oriol Vinyals", "authors": "Oriol Vinyals, Quoc Le", "title": "A Neural Conversational Model", "comments": "ICML Deep Learning Workshop 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational modeling is an important task in natural language\nunderstanding and machine intelligence. Although previous approaches exist,\nthey are often restricted to specific domains (e.g., booking an airline ticket)\nand require hand-crafted rules. In this paper, we present a simple approach for\nthis task which uses the recently proposed sequence to sequence framework. Our\nmodel converses by predicting the next sentence given the previous sentence or\nsentences in a conversation. The strength of our model is that it can be\ntrained end-to-end and thus requires much fewer hand-crafted rules. We find\nthat this straightforward model can generate simple conversations given a large\nconversational training dataset. Our preliminary results suggest that, despite\noptimizing the wrong objective function, the model is able to converse well. It\nis able extract knowledge from both a domain specific dataset, and from a\nlarge, noisy, and general domain dataset of movie subtitles. On a\ndomain-specific IT helpdesk dataset, the model can find a solution to a\ntechnical problem via conversations. On a noisy open-domain movie transcript\ndataset, the model can perform simple forms of common sense reasoning. As\nexpected, we also find that the lack of consistency is a common failure mode of\nour model.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2015 02:52:23 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2015 22:12:47 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2015 03:29:47 GMT"}], "update_date": "2015-07-23", "authors_parsed": [["Vinyals", "Oriol", ""], ["Le", "Quoc", ""]]}, {"id": "1506.06158", "submitter": "Chris Alberti", "authors": "David Weiss, Chris Alberti, Michael Collins, Slav Petrov", "title": "Structured Training for Neural Network Transition-Based Parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present structured perceptron training for neural network transition-based\ndependency parsing. We learn the neural network representation using a gold\ncorpus augmented by a large number of automatically parsed sentences. Given\nthis fixed network representation, we learn a final layer using the structured\nperceptron with beam-search decoding. On the Penn Treebank, our parser reaches\n94.26% unlabeled and 92.41% labeled attachment accuracy, which to our knowledge\nis the best accuracy on Stanford Dependencies to date. We also provide in-depth\nablative analysis to determine which aspects of our model provide the largest\ngains in accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2015 21:05:01 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Weiss", "David", ""], ["Alberti", "Chris", ""], ["Collins", "Michael", ""], ["Petrov", "Slav", ""]]}, {"id": "1506.06418", "submitter": "Raphael Hoffmann", "authors": "Raphael Hoffmann, Luke Zettlemoyer, Daniel S. Weld", "title": "Extreme Extraction: Only One Hour per Relation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information Extraction (IE) aims to automatically generate a large knowledge\nbase from natural language text, but progress remains slow. Supervised learning\nrequires copious human annotation, while unsupervised and weakly supervised\napproaches do not deliver competitive accuracy. As a result, most fielded\napplications of IE, as well as the leading TAC-KBP systems, rely on significant\namounts of manual engineering. Even \"Extreme\" methods, such as those reported\nin Freedman et al. 2011, require about 10 hours of expert labor per relation.\n  This paper shows how to reduce that effort by an order of magnitude. We\npresent a novel system, InstaRead, that streamlines authoring with an ensemble\nof methods: 1) encoding extraction rules in an expressive and compositional\nrepresentation, 2) guiding the user to promising rules based on corpus\nstatistics and mined resources, and 3) introducing a new interactive\ndevelopment cycle that provides immediate feedback --- even on large datasets.\nExperiments show that experts can create quality extractors in under an hour\nand even NLP novices can author good extractors. These extractors equal or\noutperform ones obtained by comparably supervised and state-of-the-art\ndistantly supervised approaches.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2015 22:04:39 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Hoffmann", "Raphael", ""], ["Zettlemoyer", "Luke", ""], ["Weld", "Daniel S.", ""]]}, {"id": "1506.06442", "submitter": "Fandong Meng", "authors": "Fandong Meng, Zhengdong Lu, Zhaopeng Tu, Hang Li, and Qun Liu", "title": "A Deep Memory-based Architecture for Sequence-to-Sequence Learning", "comments": "13 pages, Under review as a conference paper at ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose DEEPMEMORY, a novel deep architecture for sequence-to-sequence\nlearning, which performs the task through a series of nonlinear transformations\nfrom the representation of the input sequence (e.g., a Chinese sentence) to the\nfinal output sequence (e.g., translation to English). Inspired by the recently\nproposed Neural Turing Machine (Graves et al., 2014), we store the intermediate\nrepresentations in stacked layers of memories, and use read-write operations on\nthe memories to realize the nonlinear transformations between the\nrepresentations. The types of transformations are designed in advance but the\nparameters are learned from data. Through layer-by-layer transformations,\nDEEPMEMORY can model complicated relations between sequences necessary for\napplications such as machine translation between distant languages. The\narchitecture can be trained with normal back-propagation on sequenceto-sequence\ndata, and the learning can be easily scaled up to a large corpus. DEEPMEMORY is\nbroad enough to subsume the state-of-the-art neural translation model in\n(Bahdanau et al., 2015) as its special case, while significantly improving upon\nthe model with its deeper architecture. Remarkably, DEEPMEMORY, being purely\nneural network-based, can achieve performance comparable to the traditional\nphrase-based machine translation system Moses with a small vocabulary and a\nmodest parameter size.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 02:12:54 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2015 13:55:44 GMT"}, {"version": "v3", "created": "Thu, 19 Nov 2015 14:23:34 GMT"}, {"version": "v4", "created": "Thu, 7 Jan 2016 08:14:08 GMT"}], "update_date": "2016-01-08", "authors_parsed": [["Meng", "Fandong", ""], ["Lu", "Zhengdong", ""], ["Tu", "Zhaopeng", ""], ["Li", "Hang", ""], ["Liu", "Qun", ""]]}, {"id": "1506.06490", "submitter": "Baotian Hu", "authors": "Xiaoqiang Zhou, Baotian Hu, Qingcai Chen, Buzhou Tang, Xiaolong Wang", "title": "Answer Sequence Learning with Neural Networks for Answer Selection in\n  Community Question Answering", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the answer selection problem in community question answering\n(CQA) is regarded as an answer sequence labeling task, and a novel approach is\nproposed based on the recurrent architecture for this problem. Our approach\napplies convolution neural networks (CNNs) to learning the joint representation\nof question-answer pair firstly, and then uses the joint representation as\ninput of the long short-term memory (LSTM) to learn the answer sequence of a\nquestion for labeling the matching quality of each answer. Experiments\nconducted on the SemEval 2015 CQA dataset shows the effectiveness of our\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 07:26:51 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Zhou", "Xiaoqiang", ""], ["Hu", "Baotian", ""], ["Chen", "Qingcai", ""], ["Tang", "Buzhou", ""], ["Wang", "Xiaolong", ""]]}, {"id": "1506.06534", "submitter": "Esma Balkir", "authors": "Esma Balkir, Mehrnoosh Sadrzadeh and Bob Coecke", "title": "Distributional Sentence Entailment Using Density Matrices", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IT cs.LO math.CT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Categorical compositional distributional model of Coecke et al. (2010)\nsuggests a way to combine grammatical composition of the formal, type logical\nmodels with the corpus based, empirical word representations of distributional\nsemantics. This paper contributes to the project by expanding the model to also\ncapture entailment relations. This is achieved by extending the representations\nof words from points in meaning space to density operators, which are\nprobability distributions on the subspaces of the space. A symmetric measure of\nsimilarity and an asymmetric measure of entailment is defined, where lexical\nentailment is measured using von Neumann entropy, the quantum variant of\nKullback-Leibler divergence. Lexical entailment, combined with the composition\nmap on word representations, provides a method to obtain entailment relations\non the level of sentences. Truth theoretic and corpus-based examples are\nprovided.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 10:14:47 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2015 14:08:28 GMT"}], "update_date": "2015-10-15", "authors_parsed": [["Balkir", "Esma", ""], ["Sadrzadeh", "Mehrnoosh", ""], ["Coecke", "Bob", ""]]}, {"id": "1506.06646", "submitter": "Tadahiro Taniguchi", "authors": "Tadahiro Taniguchi, Ryo Nakashima, and Shogo Nagasaka", "title": "Nonparametric Bayesian Double Articulation Analyzer for Direct Language\n  Acquisition from Continuous Speech Signals", "comments": "15 pages, 7 figures, Draft submitted to IEEE Transactions on\n  Autonomous Mental Development (TAMD)", "journal-ref": null, "doi": "10.1109/TCDS.2016.2550591", "report-no": null, "categories": "cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human infants can discover words directly from unsegmented speech signals\nwithout any explicitly labeled data. In this paper, we develop a novel machine\nlearning method called nonparametric Bayesian double articulation analyzer\n(NPB-DAA) that can directly acquire language and acoustic models from observed\ncontinuous speech signals. For this purpose, we propose an integrative\ngenerative model that combines a language model and an acoustic model into a\nsingle generative model called the \"hierarchical Dirichlet process hidden\nlanguage model\" (HDP-HLM). The HDP-HLM is obtained by extending the\nhierarchical Dirichlet process hidden semi-Markov model (HDP-HSMM) proposed by\nJohnson et al. An inference procedure for the HDP-HLM is derived using the\nblocked Gibbs sampler originally proposed for the HDP-HSMM. This procedure\nenables the simultaneous and direct inference of language and acoustic models\nfrom continuous speech signals. Based on the HDP-HLM and its inference\nprocedure, we developed a novel double articulation analyzer. By assuming\nHDP-HLM as a generative model of observed time series data, and by inferring\nlatent variables of the model, the method can analyze latent double\narticulation structure, i.e., hierarchically organized latent words and\nphonemes, of the data in an unsupervised manner. The novel unsupervised double\narticulation analyzer is called NPB-DAA.\n  The NPB-DAA can automatically estimate double articulation structure embedded\nin speech signals. We also carried out two evaluation experiments using\nsynthetic data and actual human continuous speech signals representing Japanese\nvowel sequences. In the word acquisition and phoneme categorization tasks, the\nNPB-DAA outperformed a conventional double articulation analyzer (DAA) and\nbaseline automatic speech recognition system whose acoustic model was trained\nin a supervised manner.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 15:21:57 GMT"}, {"version": "v2", "created": "Wed, 9 Mar 2016 15:59:07 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Taniguchi", "Tadahiro", ""], ["Nakashima", "Ryo", ""], ["Nagasaka", "Shogo", ""]]}, {"id": "1506.06714", "submitter": "Michel Galley", "authors": "Alessandro Sordoni, Michel Galley, Michael Auli, Chris Brockett,\n  Yangfeng Ji, Margaret Mitchell, Jian-Yun Nie, Jianfeng Gao, Bill Dolan", "title": "A Neural Network Approach to Context-Sensitive Generation of\n  Conversational Responses", "comments": "A. Sordoni, M. Galley, M. Auli, C. Brockett, Y. Ji, M. Mitchell,\n  J.-Y. Nie, J. Gao, B. Dolan. 2015. A Neural Network Approach to\n  Context-Sensitive Generation of Conversational Responses. In Proc. of\n  NAACL-HLT. Pages 196-205", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel response generation system that can be trained end to end\non large quantities of unstructured Twitter conversations. A neural network\narchitecture is used to address sparsity issues that arise when integrating\ncontextual information into classic statistical models, allowing the system to\ntake into account previous dialog utterances. Our dynamic-context generative\nmodels show consistent gains over both context-sensitive and\nnon-context-sensitive Machine Translation and Information Retrieval baselines.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 18:29:03 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Sordoni", "Alessandro", ""], ["Galley", "Michel", ""], ["Auli", "Michael", ""], ["Brockett", "Chris", ""], ["Ji", "Yangfeng", ""], ["Mitchell", "Margaret", ""], ["Nie", "Jian-Yun", ""], ["Gao", "Jianfeng", ""], ["Dolan", "Bill", ""]]}, {"id": "1506.06724", "submitter": "Yukun Zhu", "authors": "Yukun Zhu, Ryan Kiros, Richard Zemel, Ruslan Salakhutdinov, Raquel\n  Urtasun, Antonio Torralba, Sanja Fidler", "title": "Aligning Books and Movies: Towards Story-like Visual Explanations by\n  Watching Movies and Reading Books", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Books are a rich source of both fine-grained information, how a character, an\nobject or a scene looks like, as well as high-level semantics, what someone is\nthinking, feeling and how these states evolve through a story. This paper aims\nto align books to their movie releases in order to provide rich descriptive\nexplanations for visual content that go semantically far beyond the captions\navailable in current datasets. To align movies and books we exploit a neural\nsentence embedding that is trained in an unsupervised way from a large corpus\nof books, as well as a video-text neural embedding for computing similarities\nbetween movie clips and sentences in the book. We propose a context-aware CNN\nto combine information from multiple sources. We demonstrate good quantitative\nperformance for movie/book alignment and show several qualitative examples that\nshowcase the diversity of tasks our model can be used for.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 19:26:56 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Zhu", "Yukun", ""], ["Kiros", "Ryan", ""], ["Zemel", "Richard", ""], ["Salakhutdinov", "Ruslan", ""], ["Urtasun", "Raquel", ""], ["Torralba", "Antonio", ""], ["Fidler", "Sanja", ""]]}, {"id": "1506.06726", "submitter": "Ryan Kiros", "authors": "Ryan Kiros, Yukun Zhu, Ruslan Salakhutdinov, Richard S. Zemel, Antonio\n  Torralba, Raquel Urtasun, Sanja Fidler", "title": "Skip-Thought Vectors", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an approach for unsupervised learning of a generic, distributed\nsentence encoder. Using the continuity of text from books, we train an\nencoder-decoder model that tries to reconstruct the surrounding sentences of an\nencoded passage. Sentences that share semantic and syntactic properties are\nthus mapped to similar vector representations. We next introduce a simple\nvocabulary expansion method to encode words that were not seen as part of\ntraining, allowing us to expand our vocabulary to a million words. After\ntraining our model, we extract and evaluate our vectors with linear models on 8\ntasks: semantic relatedness, paraphrase detection, image-sentence ranking,\nquestion-type classification and 4 benchmark sentiment and subjectivity\ndatasets. The end result is an off-the-shelf encoder that can produce highly\ngeneric sentence representations that are robust and perform well in practice.\nWe will make our encoder publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 19:33:40 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Kiros", "Ryan", ""], ["Zhu", "Yukun", ""], ["Salakhutdinov", "Ruslan", ""], ["Zemel", "Richard S.", ""], ["Torralba", "Antonio", ""], ["Urtasun", "Raquel", ""], ["Fidler", "Sanja", ""]]}, {"id": "1506.06832", "submitter": "Alex James Dr", "authors": "Assel Davletcharova, Sherin Sugathan, Bibia Abraham, Alex Pappachen\n  James", "title": "Detection and Analysis of Emotion From Speech Signals", "comments": "2nd International Symposium on Computer Vision and the Internet,\n  2015; to appear in Procedia Computer Science Journal, Elsevier, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Recognizing emotion from speech has become one the active research themes in\nspeech processing and in applications based on human-computer interaction. This\npaper conducts an experimental study on recognizing emotions from human speech.\nThe emotions considered for the experiments include neutral, anger, joy and\nsadness. The distinuishability of emotional features in speech were studied\nfirst followed by emotion classification performed on a custom dataset. The\nclassification was performed for different classifiers. One of the main feature\nattribute considered in the prepared dataset was the peak-to-peak distance\nobtained from the graphical representation of the speech signals. After\nperforming the classification tests on a dataset formed from 30 different\nsubjects, it was found that for getting better accuracy, one should consider\nthe data collected from one person rather than considering the data from a\ngroup of people.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2015 00:28:08 GMT"}], "update_date": "2015-06-24", "authors_parsed": [["Davletcharova", "Assel", ""], ["Sugathan", "Sherin", ""], ["Abraham", "Bibia", ""], ["James", "Alex Pappachen", ""]]}, {"id": "1506.06833", "submitter": "Francis Ferraro", "authors": "Francis Ferraro, Nasrin Mostafazadeh, Ting-Hao (Kenneth) Huang, Lucy\n  Vanderwende, Jacob Devlin, Michel Galley, Margaret Mitchell", "title": "A Survey of Current Datasets for Vision and Language Research", "comments": "To appear in EMNLP 2015, short proceedings. Dataset analysis and\n  discussion expanded, including an initial examination into reporting bias for\n  one of them. F.F. and N.M. contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.GL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrating vision and language has long been a dream in work on artificial\nintelligence (AI). In the past two years, we have witnessed an explosion of\nwork that brings together vision and language from images to videos and beyond.\nThe available corpora have played a crucial role in advancing this area of\nresearch. In this paper, we propose a set of quality metrics for evaluating and\nanalyzing the vision & language datasets and categorize them accordingly. Our\nanalyses show that the most recent datasets have been using more complex\nlanguage and more abstract concepts, however, there are different strengths and\nweaknesses in each.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2015 00:59:27 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2015 04:33:37 GMT"}], "update_date": "2015-08-20", "authors_parsed": [["Ferraro", "Francis", "", "Kenneth"], ["Mostafazadeh", "Nasrin", "", "Kenneth"], ["Ting-Hao", "", "", "Kenneth"], ["Huang", "", ""], ["Vanderwende", "Lucy", ""], ["Devlin", "Jacob", ""], ["Galley", "Michel", ""], ["Mitchell", "Margaret", ""]]}, {"id": "1506.06863", "submitter": "Michel Galley", "authors": "Michel Galley, Chris Brockett, Alessandro Sordoni, Yangfeng Ji,\n  Michael Auli, Chris Quirk, Margaret Mitchell, Jianfeng Gao, Bill Dolan", "title": "deltaBLEU: A Discriminative Metric for Generation Tasks with\n  Intrinsically Diverse Targets", "comments": "6 pages, to appear at ACL 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Discriminative BLEU (deltaBLEU), a novel metric for intrinsic\nevaluation of generated text in tasks that admit a diverse range of possible\noutputs. Reference strings are scored for quality by human raters on a scale of\n[-1, +1] to weight multi-reference BLEU. In tasks involving generation of\nconversational responses, deltaBLEU correlates reasonably with human judgments\nand outperforms sentence-level and IBM BLEU in terms of both Spearman's rho and\nKendall's tau.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2015 05:24:53 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2015 01:09:50 GMT"}], "update_date": "2015-06-25", "authors_parsed": [["Galley", "Michel", ""], ["Brockett", "Chris", ""], ["Sordoni", "Alessandro", ""], ["Ji", "Yangfeng", ""], ["Auli", "Michael", ""], ["Quirk", "Chris", ""], ["Mitchell", "Margaret", ""], ["Gao", "Jianfeng", ""], ["Dolan", "Bill", ""]]}, {"id": "1506.06904", "submitter": "HaeGum An", "authors": "Kim Song Jon, An Hae Gum", "title": "New Approach to translation of Isolated Units in English-Korean Machine\n  Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  It is the most effective way for quick translation of tremendous amount of\nexplosively increasing science and technique information material to develop a\npracticable machine translation system and introduce it into translation\npractice. This essay treats problems arising from translation of isolated units\non the basis of the practical materials and experiments obtained in the\ndevelopment and introduction of English-Korean machine translation system. In\nother words, this essay considers establishment of information for isolated\nunits and their Korean equivalents and word order.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2015 08:26:50 GMT"}], "update_date": "2015-06-24", "authors_parsed": [["Jon", "Kim Song", ""], ["Gum", "An Hae", ""]]}, {"id": "1506.07190", "submitter": "Nikola Mrksic", "authors": "Nikola Mrk\\v{s}i\\'c, Diarmuid \\'O S\\'eaghdha, Blaise Thomson, Milica\n  Ga\\v{s}i\\'c, Pei-Hao Su, David Vandyke, Tsung-Hsien Wen and Steve Young", "title": "Multi-domain Dialog State Tracking using Recurrent Neural Networks", "comments": "Accepted as a short paper in the 53rd Annual Meeting of the\n  Association for Computational Linguistics (ACL 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialog state tracking is a key component of many modern dialog systems, most\nof which are designed with a single, well-defined domain in mind. This paper\nshows that dialog data drawn from different dialog domains can be used to train\na general belief tracking model which can operate across all of these domains,\nexhibiting superior performance to each of the domain-specific models. We\npropose a training procedure which uses out-of-domain data to initialise belief\ntracking models for entirely new domains. This procedure leads to improvements\nin belief tracking performance regardless of the amount of in-domain data\navailable for training the model.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2015 20:16:06 GMT"}], "update_date": "2015-06-25", "authors_parsed": [["Mrk\u0161i\u0107", "Nikola", ""], ["S\u00e9aghdha", "Diarmuid \u00d3", ""], ["Thomson", "Blaise", ""], ["Ga\u0161i\u0107", "Milica", ""], ["Su", "Pei-Hao", ""], ["Vandyke", "David", ""], ["Wen", "Tsung-Hsien", ""], ["Young", "Steve", ""]]}, {"id": "1506.07220", "submitter": "Hui Jiang", "authors": "Yangtuo Peng and Hui Jiang", "title": "Leverage Financial News to Predict Stock Price Movements Using Word\n  Embeddings and Deep Neural Networks", "comments": "5 pages, 2 figures, technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial news contains useful information on public companies and the\nmarket. In this paper we apply the popular word embedding methods and deep\nneural networks to leverage financial news to predict stock price movements in\nthe market. Experimental results have shown that our proposed methods are\nsimple but very effective, which can significantly improve the stock prediction\naccuracy on a standard financial database over the baseline system using only\nthe historical price information.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2015 01:43:11 GMT"}], "update_date": "2015-06-25", "authors_parsed": [["Peng", "Yangtuo", ""], ["Jiang", "Hui", ""]]}, {"id": "1506.07285", "submitter": "Richard Socher", "authors": "Ankit Kumar and Ozan Irsoy and Peter Ondruska and Mohit Iyyer and\n  James Bradbury and Ishaan Gulrajani and Victor Zhong and Romain Paulus and\n  Richard Socher", "title": "Ask Me Anything: Dynamic Memory Networks for Natural Language Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most tasks in natural language processing can be cast into question answering\n(QA) problems over language input. We introduce the dynamic memory network\n(DMN), a neural network architecture which processes input sequences and\nquestions, forms episodic memories, and generates relevant answers. Questions\ntrigger an iterative attention process which allows the model to condition its\nattention on the inputs and the result of previous iterations. These results\nare then reasoned over in a hierarchical recurrent sequence model to generate\nanswers. The DMN can be trained end-to-end and obtains state-of-the-art results\non several types of tasks and datasets: question answering (Facebook's bAbI\ndataset), text classification for sentiment analysis (Stanford Sentiment\nTreebank) and sequence modeling for part-of-speech tagging (WSJ-PTB). The\ntraining for these different tasks relies exclusively on trained word vector\nrepresentations and input-question-answer triplets.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2015 08:27:02 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2015 22:21:29 GMT"}, {"version": "v3", "created": "Tue, 29 Sep 2015 05:02:29 GMT"}, {"version": "v4", "created": "Tue, 9 Feb 2016 08:19:30 GMT"}, {"version": "v5", "created": "Sat, 5 Mar 2016 20:18:55 GMT"}], "update_date": "2016-03-08", "authors_parsed": [["Kumar", "Ankit", ""], ["Irsoy", "Ozan", ""], ["Ondruska", "Peter", ""], ["Iyyer", "Mohit", ""], ["Bradbury", "James", ""], ["Gulrajani", "Ishaan", ""], ["Zhong", "Victor", ""], ["Paulus", "Romain", ""], ["Socher", "Richard", ""]]}, {"id": "1506.07477", "submitter": "Jiatao Gu", "authors": "Jiatao Gu and Victor O.K. Li", "title": "Efficient Learning for Undirected Topic Models", "comments": "Accepted by ACL-IJCNLP 2015 short paper. 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Replicated Softmax model, a well-known undirected topic model, is powerful in\nextracting semantic representations of documents. Traditional learning\nstrategies such as Contrastive Divergence are very inefficient. This paper\nprovides a novel estimator to speed up the learning based on Noise Contrastive\nEstimate, extended for documents of variant lengths and weighted inputs.\nExperiments on two benchmarks show that the new estimator achieves great\nlearning efficiency and high accuracy on document retrieval and classification.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2015 17:27:28 GMT"}], "update_date": "2015-06-25", "authors_parsed": [["Gu", "Jiatao", ""], ["Li", "Victor O. K.", ""]]}, {"id": "1506.07503", "submitter": "Jan Chorowski", "authors": "Jan Chorowski, Dzmitry Bahdanau, Dmitriy Serdyuk, Kyunghyun Cho,\n  Yoshua Bengio", "title": "Attention-Based Models for Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent sequence generators conditioned on input data through an attention\nmechanism have recently shown very good performance on a range of tasks in-\ncluding machine translation, handwriting synthesis and image caption gen-\neration. We extend the attention-mechanism with features needed for speech\nrecognition. We show that while an adaptation of the model used for machine\ntranslation in reaches a competitive 18.7% phoneme error rate (PER) on the\nTIMIT phoneme recognition task, it can only be applied to utterances which are\nroughly as long as the ones it was trained on. We offer a qualitative\nexplanation of this failure and propose a novel and generic method of adding\nlocation-awareness to the attention mechanism to alleviate this issue. The new\nmethod yields a model that is robust to long inputs and achieves 18% PER in\nsingle utterances and 20% in 10-times longer (repeated) utterances. Finally, we\npropose a change to the at- tention mechanism that prevents it from\nconcentrating too much on single frames, which further reduces PER to 17.6%\nlevel.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2015 19:10:33 GMT"}], "update_date": "2015-06-25", "authors_parsed": [["Chorowski", "Jan", ""], ["Bahdanau", "Dzmitry", ""], ["Serdyuk", "Dmitriy", ""], ["Cho", "Kyunghyun", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1506.07650", "submitter": "Kun Xu", "authors": "Kun Xu, Yansong Feng, Songfang Huang, Dongyan Zhao", "title": "Semantic Relation Classification via Convolutional Neural Networks with\n  Simple Negative Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syntactic features play an essential role in identifying relationship in a\nsentence. Previous neural network models often suffer from irrelevant\ninformation introduced when subjects and objects are in a long distance. In\nthis paper, we propose to learn more robust relation representations from the\nshortest dependency path through a convolution neural network. We further\npropose a straightforward negative sampling strategy to improve the assignment\nof subjects and objects. Experimental results show that our method outperforms\nthe state-of-the-art methods on the SemEval-2010 Task 8 dataset.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2015 07:51:55 GMT"}], "update_date": "2015-06-26", "authors_parsed": [["Xu", "Kun", ""], ["Feng", "Yansong", ""], ["Huang", "Songfang", ""], ["Zhao", "Dongyan", ""]]}, {"id": "1506.07732", "submitter": "Marie Cottrell", "authors": "Nicolas Bourgeois (SAMM), Marie Cottrell (SAMM), Benjamin D\\'eruelle\n  (LAMOP), St\\'ephane Lamass\\'e (LAMOP), Patrick Letr\\'emy (SAMM)", "title": "How to improve robustness in Kohonen maps and display additional\n  information in Factorial Analysis: application to text mining", "comments": null, "journal-ref": "Neurocomputing, Elsevier, 2014, 147, pp.120-135", "doi": "10.1016/j.neucom.2013.12.057", "report-no": null, "categories": "math.ST cs.CL stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is an extended version of a paper presented in the WSOM'2012\nconference [1]. We display a combination of factorial projections, SOM\nalgorithm and graph techniques applied to a text mining problem. The corpus\ncontains 8 medieval manuscripts which were used to teach arithmetic techniques\nto merchants. Among the techniques for Data Analysis, those used for\nLexicometry (such as Factorial Analysis) highlight the discrepancies between\nmanuscripts. The reason for this is that they focus on the deviation from the\nindependence between words and manuscripts. Still, we also want to discover and\ncharacterize the common vocabulary among the whole corpus. Using the properties\nof stochastic Kohonen maps, which define neighborhood between inputs in a\nnon-deterministic way, we highlight the words which seem to play a special role\nin the vocabulary. We call them fickle and use them to improve both Kohonen map\nrobustness and significance of FCA visualization. Finally we use graph\nalgorithmic to exploit this fickleness for classification of words.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2015 12:56:23 GMT"}], "update_date": "2015-06-26", "authors_parsed": [["Bourgeois", "Nicolas", "", "SAMM"], ["Cottrell", "Marie", "", "SAMM"], ["D\u00e9ruelle", "Benjamin", "", "LAMOP"], ["Lamass\u00e9", "St\u00e9phane", "", "LAMOP"], ["Letr\u00e9my", "Patrick", "", "SAMM"]]}, {"id": "1506.08052", "submitter": "Margherita Zorzi", "authors": "Carlo Combi, Riccardo Lora, Ugo Moretti, Marco Pagliarini, Margherita\n  Zorzi", "title": "Automagically encoding Adverse Drug Reactions in MedDRA", "comments": "Submitted, 22 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pharmacovigilance is the field of science devoted to the collection, analysis\nand prevention of Adverse Drug Reactions (ADRs). Efficient strategies for the\nextraction of information about ADRs from free text resources are essential to\nsupport the work of experts, employed in the crucial task of detecting and\nclassifying unexpected pathologies possibly related to drug assumptions.\nNarrative ADR descriptions may be collected in several way, e.g. by monitoring\nsocial networks or through the so called spontaneous reporting, the main method\npharmacovigilance adopts in order to identify ADRs. The encoding of free-text\nADR descriptions according to MedDRA standard terminology is central for report\nanalysis. It is a complex work, which has to be manually implemented by the\npharmacovigilance experts. The manual encoding is expensive (in terms of time).\nMoreover, a problem about the accuracy of the encoding may occur, since the\nnumber of reports is growing up day by day. In this paper, we propose\nMagiCoder, an efficient Natural Language Processing algorithm able to\nautomatically derive MedDRA terminologies from free-text ADR descriptions.\nMagiCoder is part of VigiWork, a web application for online ADR reporting and\nanalysis. From a practical view-point, MagiCoder radically reduces the revision\ntime of ADR reports: the pharmacologist has simply to revise and validate the\nautomatic solution versus the hard task of choosing solutions in the 70k terms\nof MedDRA. This improvement of the expert work efficiency has a meaningful\nimpact on the quality of data analysis. Moreover, our procedure is general\npurpose. We developed MagiCoder for the Italian pharmacovigilance language, but\npreliminarily analyses show that it is robust to language and dictionary\nchanges.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 13:17:31 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2015 12:29:55 GMT"}, {"version": "v3", "created": "Tue, 17 Jan 2017 11:40:55 GMT"}], "update_date": "2017-01-18", "authors_parsed": [["Combi", "Carlo", ""], ["Lora", "Riccardo", ""], ["Moretti", "Ugo", ""], ["Pagliarini", "Marco", ""], ["Zorzi", "Margherita", ""]]}, {"id": "1506.08126", "submitter": "Dragomir", "authors": "Dragomir Radev and Amanda Stent and Joel Tetreault and Aasish Pappu\n  and Aikaterini Iliakopoulou and Agustin Chanfreau and Paloma de Juan and\n  Jordi Vallmitjana and Alejandro Jaimes and Rahul Jha and Bob Mankoff", "title": "Humor in Collective Discourse: Unsupervised Funniness Detection in the\n  New Yorker Cartoon Caption Contest", "comments": "10 pages, in submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The New Yorker publishes a weekly captionless cartoon. More than 5,000\nreaders submit captions for it. The editors select three of them and ask the\nreaders to pick the funniest one. We describe an experiment that compares a\ndozen automatic methods for selecting the funniest caption. We show that\nnegative sentiment, human-centeredness, and lexical centrality most strongly\nmatch the funniest captions, followed by positive sentiment. These results are\nuseful for understanding humor and also in the design of more engaging\nconversational agents in text and multimodal (vision+text) systems. As part of\nthis work, a large set of cartoons and captions is being made available to the\ncommunity.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 15:48:10 GMT"}], "update_date": "2015-06-29", "authors_parsed": [["Radev", "Dragomir", ""], ["Stent", "Amanda", ""], ["Tetreault", "Joel", ""], ["Pappu", "Aasish", ""], ["Iliakopoulou", "Aikaterini", ""], ["Chanfreau", "Agustin", ""], ["de Juan", "Paloma", ""], ["Vallmitjana", "Jordi", ""], ["Jaimes", "Alejandro", ""], ["Jha", "Rahul", ""], ["Mankoff", "Bob", ""]]}, {"id": "1506.08259", "submitter": "Afshin Rahimi", "authors": "Afshin Rahimi, Trevor Cohn, and Timothy Baldwin", "title": "Twitter User Geolocation Using a Unified Text and Network Prediction\n  Model", "comments": "To appear in ACL 2015, Proceedings of the 53rd Annual Meeting of the\n  Association for Computational Linguistics (ACL 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a label propagation approach to geolocation prediction based on\nModified Adsorption, with two enhancements:(1) the removal of \"celebrity\" nodes\nto increase location homophily and boost tractability, and (2) he incorporation\nof text-based geolocation priors for test users. Experiments over three Twitter\nbenchmark datasets achieve state-of-the-art results, and demonstrate the\neffectiveness of the enhancements.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2015 04:51:18 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2015 00:43:39 GMT"}, {"version": "v3", "created": "Tue, 22 Sep 2015 01:14:20 GMT"}], "update_date": "2015-09-23", "authors_parsed": [["Rahimi", "Afshin", ""], ["Cohn", "Trevor", ""], ["Baldwin", "Timothy", ""]]}, {"id": "1506.08349", "submitter": "Lantian Li Mr.", "authors": "Lantian Li and Yiye Lin and Zhiyong Zhang and Dong Wang", "title": "Improved Deep Speaker Feature Learning for Text-Dependent Speaker\n  Recognition", "comments": "arXiv admin note: substantial text overlap with arXiv:1505.06427", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deep learning approach has been proposed recently to derive speaker\nidentifies (d-vector) by a deep neural network (DNN). This approach has been\napplied to text-dependent speaker recognition tasks and shows reasonable\nperformance gains when combined with the conventional i-vector approach.\nAlthough promising, the existing d-vector implementation still can not compete\nwith the i-vector baseline. This paper presents two improvements for the deep\nlearning approach: a phonedependent DNN structure to normalize phone variation,\nand a new scoring approach based on dynamic time warping (DTW). Experiments on\na text-dependent speaker recognition task demonstrated that the proposed\nmethods can provide considerable performance improvement over the existing\nd-vector implementation.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2015 03:32:02 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Li", "Lantian", ""], ["Lin", "Yiye", ""], ["Zhang", "Zhiyong", ""], ["Wang", "Dong", ""]]}, {"id": "1506.08422", "submitter": "Li-Qiang Niu", "authors": "Li-Qiang Niu and Xin-Yu Dai", "title": "Topic2Vec: Learning Distributed Representations of Topics", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent Dirichlet Allocation (LDA) mining thematic structure of documents\nplays an important role in nature language processing and machine learning\nareas. However, the probability distribution from LDA only describes the\nstatistical relationship of occurrences in the corpus and usually in practice,\nprobability is not the best choice for feature representations. Recently,\nembedding methods have been proposed to represent words and documents by\nlearning essential concepts and representations, such as Word2Vec and Doc2Vec.\nThe embedded representations have shown more effectiveness than LDA-style\nrepresentations in many tasks. In this paper, we propose the Topic2Vec approach\nwhich can learn topic representations in the same semantic vector space with\nwords, as an alternative to probability. The experimental results show that\nTopic2Vec achieves interesting and meaningful results.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2015 16:17:40 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Niu", "Li-Qiang", ""], ["Dai", "Xin-Yu", ""]]}, {"id": "1506.08454", "submitter": "Vijil Chenthamarakshan", "authors": "Vijil Chenthamarakshan, Prasad M Desphande, Raghu Krishnapuram,\n  Ramakrishna Varadarajan, Knut Stolze", "title": "WYSIWYE: An Algebra for Expressing Spatial and Textual Rules for Visual\n  Information Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The visual layout of a webpage can provide valuable clues for certain types\nof Information Extraction (IE) tasks. In traditional rule based IE frameworks,\nthese layout cues are mapped to rules that operate on the HTML source of the\nwebpages. In contrast, we have developed a framework in which the rules can be\nspecified directly at the layout level. This has many advantages, since the\nhigher level of abstraction leads to simpler extraction rules that are largely\nindependent of the source code of the page, and, therefore, more robust. It can\nalso enable specification of new types of rules that are not otherwise\npossible. To the best of our knowledge, there is no general framework that\nallows declarative specification of information extraction rules based on\nspatial layout. Our framework is complementary to traditional text based rules\nframework and allows a seamless combination of spatial layout based rules with\ntraditional text based rules. We describe the algebra that enables such a\nsystem and its efficient implementation using standard relational and text\nindexing features of a relational database. We demonstrate the simplicity and\nefficiency of this system for a task involving the extraction of software\nsystem requirements from software product pages.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2015 21:17:26 GMT"}, {"version": "v2", "created": "Tue, 27 Sep 2016 19:49:41 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Chenthamarakshan", "Vijil", ""], ["Desphande", "Prasad M", ""], ["Krishnapuram", "Raghu", ""], ["Varadarajan", "Ramakrishna", ""], ["Stolze", "Knut", ""]]}, {"id": "1506.08663", "submitter": "Giuseppe Vitiello", "authors": "Massimo Piattelli-Palmarini and Giuseppe Vitiello", "title": "Linguistics and some aspects of its underlying dynamics", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, central components of a new approach to linguistics, the\nMinimalist Program (MP) have come closer to physics. Features of the Minimalist\nProgram, such as the unconstrained nature of recursive Merge, the operation of\nthe Labeling Algorithm that only operates at the interface of Narrow Syntax\nwith the Conceptual-Intentional and the Sensory-Motor interfaces, the\ndifference between pronounced and un-pronounced copies of elements in a\nsentence and the build-up of the Fibonacci sequence in the syntactic derivation\nof sentence structures, are directly accessible to representation in terms of\nalgebraic formalism. Although in our scheme linguistic structures are classical\nones, we find that an interesting and productive isomorphism can be established\nbetween the MP structure, algebraic structures and many-body field theory\nopening new avenues of inquiry on the dynamics underlying some central aspects\nof linguistics.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2015 12:09:01 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Piattelli-Palmarini", "Massimo", ""], ["Vitiello", "Giuseppe", ""]]}, {"id": "1506.08789", "submitter": "Najla Al-Saati", "authors": "Najla Al-Saati and Raghda Abdul-Jaleel", "title": "Requirement Tracing using Term Extraction", "comments": null, "journal-ref": "IJCSIS Vol. 13, No. 5, 2015", "doi": null, "report-no": null, "categories": "cs.SE cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Requirements traceability is an essential step in ensuring the quality of\nsoftware during the early stages of its development life cycle. Requirements\ntracing usually consists of document parsing, candidate link generation and\nevaluation and traceability analysis. This paper demonstrates the applicability\nof Statistical Term Extraction metrics to generate candidate links. It is\napplied and validated using two data sets and four types of filters two for\neach data set, 0.2 and 0.25 for MODIS, 0 and 0.05 for CM1. This method\ngenerates requirements traceability matrices between textual requirements\nartifacts (such as high-level requirements traced to low-level requirements).\nThe proposed method includes ten word frequency metrics divided into three main\ngroups for calculating the frequency of terms. The results show that the\nproposed method gives better result when compared with the traditional TF-IDF\nmethod.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2015 19:21:04 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Al-Saati", "Najla", ""], ["Abdul-Jaleel", "Raghda", ""]]}, {"id": "1506.08909", "submitter": "Ryan Lowe T.", "authors": "Ryan Lowe, Nissan Pow, Iulian Serban, Joelle Pineau", "title": "The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured\n  Multi-Turn Dialogue Systems", "comments": "SIGDIAL 2015. 10 pages, 5 figures. Update includes link to new\n  version of the dataset, with some added features and bug fixes. See:\n  https://github.com/rkadlec/ubuntu-ranking-dataset-creator", "journal-ref": null, "doi": null, "report-no": "Proc. SIGDIAL 16 (2015) pp. 285-294", "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the Ubuntu Dialogue Corpus, a dataset containing almost\n1 million multi-turn dialogues, with a total of over 7 million utterances and\n100 million words. This provides a unique resource for research into building\ndialogue managers based on neural language models that can make use of large\namounts of unlabeled data. The dataset has both the multi-turn property of\nconversations in the Dialog State Tracking Challenge datasets, and the\nunstructured nature of interactions from microblog services such as Twitter. We\nalso describe two neural learning architectures suitable for analyzing this\ndataset, and provide benchmark performance on the task of selecting the best\nnext response.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2015 00:37:09 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2015 16:11:29 GMT"}, {"version": "v3", "created": "Thu, 4 Feb 2016 01:21:35 GMT"}], "update_date": "2016-07-26", "authors_parsed": [["Lowe", "Ryan", ""], ["Pow", "Nissan", ""], ["Serban", "Iulian", ""], ["Pineau", "Joelle", ""]]}, {"id": "1506.08941", "submitter": "Karthik Narasimhan", "authors": "Karthik Narasimhan, Tejas Kulkarni and Regina Barzilay", "title": "Language Understanding for Text-based Games Using Deep Reinforcement\n  Learning", "comments": "11 pages, Appearing at EMNLP, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the task of learning control policies for\ntext-based games. In these games, all interactions in the virtual world are\nthrough text and the underlying state is not observed. The resulting language\nbarrier makes such environments challenging for automatic game players. We\nemploy a deep reinforcement learning framework to jointly learn state\nrepresentations and action policies using game rewards as feedback. This\nframework enables us to map text descriptions into vector representations that\ncapture the semantics of the game states. We evaluate our approach on two game\nworlds, comparing against baselines using bag-of-words and bag-of-bigrams for\nstate representations. Our algorithm outperforms the baselines on both worlds\ndemonstrating the importance of learning expressive representations.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2015 05:51:11 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2015 23:16:13 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Narasimhan", "Karthik", ""], ["Kulkarni", "Tejas", ""], ["Barzilay", "Regina", ""]]}, {"id": "1506.09107", "submitter": "Diego Amancio", "authors": "Diego R. Amancio", "title": "A complex network approach to stylometry", "comments": "PLoS ONE, 2015 (to appear)", "journal-ref": "PLoS ONE 10(8): e0136076, 2015", "doi": "10.1371/journal.pone.0136076", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical methods have been widely employed to study the fundamental\nproperties of language. In recent years, methods from complex and dynamical\nsystems proved useful to create several language models. Despite the large\namount of studies devoted to represent texts with physical models, only a\nlimited number of studies have shown how the properties of the underlying\nphysical systems can be employed to improve the performance of natural language\nprocessing tasks. In this paper, I address this problem by devising complex\nnetworks methods that are able to improve the performance of current\nstatistical methods. Using a fuzzy classification strategy, I show that the\ntopological properties extracted from texts complement the traditional textual\ndescription. In several cases, the performance obtained with hybrid approaches\noutperformed the results obtained when only traditional or networked methods\nwere used. Because the proposed model is generic, the framework devised here\ncould be straightforwardly used to study similar textual applications where the\ntopology plays a pivotal role in the description of the interacting agents.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2015 14:32:30 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2015 13:59:39 GMT"}], "update_date": "2015-09-18", "authors_parsed": [["Amancio", "Diego R.", ""]]}]