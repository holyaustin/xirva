[{"id": "1110.1391", "submitter": "K. Choi", "authors": "K. Choi, H. Isahara, J. Oh", "title": "A Comparison of Different Machine Transliteration Models", "comments": null, "journal-ref": "Journal Of Artificial Intelligence Research, Volume 27, pages\n  119-151, 2006", "doi": "10.1613/jair.1999", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine transliteration is a method for automatically converting words in one\nlanguage into phonetically equivalent ones in another language. Machine\ntransliteration plays an important role in natural language applications such\nas information retrieval and machine translation, especially for handling\nproper nouns and technical terms. Four machine transliteration models --\ngrapheme-based transliteration model, phoneme-based transliteration model,\nhybrid transliteration model, and correspondence-based transliteration model --\nhave been proposed by several researchers. To date, however, there has been\nlittle research on a framework in which multiple transliteration models can\noperate simultaneously. Furthermore, there has been no comparison of the four\nmodels within the same framework and using the same data. We addressed these\nproblems by 1) modeling the four models within the same framework, 2) comparing\nthem under the same conditions, and 3) developing a way to improve machine\ntransliteration through this comparison. Our comparison showed that the hybrid\nand correspondence-based models were the most effective and that the four\nmodels can be used in a complementary manner to improve machine transliteration\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2011 20:48:58 GMT"}], "update_date": "2011-10-10", "authors_parsed": [["Choi", "K.", ""], ["Isahara", "H.", ""], ["Oh", "J.", ""]]}, {"id": "1110.1394", "submitter": "M. Lapata", "authors": "M. Lapata, A. Lascarides", "title": "Learning Sentence-internal Temporal Relations", "comments": null, "journal-ref": "Journal Of Artificial Intelligence Research, Volume 27, pages\n  85-117, 2006", "doi": "10.1613/jair.2015", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a data intensive approach for inferring\nsentence-internal temporal relations. Temporal inference is relevant for\npractical NLP applications which either extract or synthesize temporal\ninformation (e.g., summarisation, question answering). Our method bypasses the\nneed for manual coding by exploiting the presence of markers like after\", which\novertly signal a temporal relation. We first show that models trained on main\nand subordinate clauses connected with a temporal marker achieve good\nperformance on a pseudo-disambiguation task simulating temporal inference\n(during testing the temporal marker is treated as unseen and the models must\nselect the right marker from a set of possible candidates). Secondly, we assess\nwhether the proposed approach holds promise for the semi-automatic creation of\ntemporal annotations. Specifically, we use a model trained on noisy and\napproximate data (i.e., main and subordinate clauses) to predict\nintra-sentential relations present in TimeBank, a corpus annotated rich\ntemporal information. Our experiments compare and contrast several\nprobabilistic models differing in their feature space, linguistic assumptions\nand data requirements. We evaluate performance against gold standard corpora\nand also against human subjects.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2011 20:55:54 GMT"}], "update_date": "2011-10-10", "authors_parsed": [["Lapata", "M.", ""], ["Lascarides", "A.", ""]]}, {"id": "1110.1428", "submitter": "Ziheng Lin", "authors": "Duy Khang Ly and Kazunari Sugiyama and Ziheng Lin and Min-Yen Kan", "title": "Product Review Summarization based on Facet Identification and Sentence\n  Clustering", "comments": "10 pages, 3 figures, 3 tables, short paper version published in JCDL\n  2011", "journal-ref": null, "doi": null, "report-no": "TR30/11", "categories": "cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Product review nowadays has become an important source of information, not\nonly for customers to find opinions about products easily and share their\nreviews with peers, but also for product manufacturers to get feedback on their\nproducts. As the number of product reviews grows, it becomes difficult for\nusers to search and utilize these resources in an efficient way. In this work,\nwe build a product review summarization system that can automatically process a\nlarge collection of reviews and aggregate them to generate a concise summary.\nMore importantly, the drawback of existing product summarization systems is\nthat they cannot provide the underlying reasons to justify users' opinions. In\nour method, we solve this problem by applying clustering, prior to selecting\nrepresentative candidates for summarization.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2011 04:56:43 GMT"}], "update_date": "2011-10-10", "authors_parsed": [["Ly", "Duy Khang", ""], ["Sugiyama", "Kazunari", ""], ["Lin", "Ziheng", ""], ["Kan", "Min-Yen", ""]]}, {"id": "1110.1470", "submitter": "Luis Quesada", "authors": "Luis Quesada and Fernando Berzal and Francisco J. Cortijo", "title": "A Constraint-Satisfaction Parser for Context-Free Grammars", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional language processing tools constrain language designers to\nspecific kinds of grammars. In contrast, model-based language specification\ndecouples language design from language processing. As a consequence,\nmodel-based language specification tools need general parsers able to parse\nunrestricted context-free grammars. As languages specified following this\napproach may be ambiguous, parsers must deal with ambiguities. Model-based\nlanguage specification also allows the definition of associativity, precedence,\nand custom constraints. Therefore parsers generated by model-driven language\nspecification tools need to enforce constraints. In this paper, we propose\nFence, an efficient bottom-up chart parser with lexical and syntactic ambiguity\nsupport that allows the specification of constraints and, therefore, enables\nthe use of model-based language specification in practice.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2011 09:53:41 GMT"}, {"version": "v2", "created": "Mon, 10 Oct 2011 21:14:08 GMT"}, {"version": "v3", "created": "Thu, 2 Feb 2012 16:11:45 GMT"}], "update_date": "2012-02-03", "authors_parsed": [["Quesada", "Luis", ""], ["Berzal", "Fernando", ""], ["Cortijo", "Francisco J.", ""]]}, {"id": "1110.1758", "submitter": "Laurent Romary", "authors": "Laurent Romary (IDSL, INRIA Saclay - Ile de France), Andreas Witt\n  (IDS)", "title": "Data formats for phonological corpora", "comments": "Handbook of Corpus Phonology Oxford University Press (Ed.) (2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of the present chapter is to explore the possibility of providing\nthe research (but also the industrial) community that commonly uses spoken\ncorpora with a stable portfolio of well-documented standardised formats that\nallow a high re-use rate of annotated spoken resources and, as a consequence,\nbetter interoperability across tools used to produce or exploit such resources.\n", "versions": [{"version": "v1", "created": "Sat, 8 Oct 2011 19:15:12 GMT"}, {"version": "v2", "created": "Sun, 4 Mar 2012 19:00:21 GMT"}], "update_date": "2012-03-06", "authors_parsed": [["Romary", "Laurent", "", "IDSL, INRIA Saclay - Ile de France"], ["Witt", "Andreas", "", "IDS"]]}, {"id": "1110.2162", "submitter": "Ruben Sipos", "authors": "Ruben Sipos, Pannaga Shivaswamy, Thorsten Joachims", "title": "Large-Margin Learning of Submodular Summarization Methods", "comments": "update: improved formatting (figure placement) and algorithm\n  pseudocode clarity (Fig. 3)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a supervised learning approach to training\nsubmodular scoring functions for extractive multi-document summarization. By\ntaking a structured predicition approach, we provide a large-margin method that\ndirectly optimizes a convex relaxation of the desired performance measure. The\nlearning method applies to all submodular summarization methods, and we\ndemonstrate its effectiveness for both pairwise as well as coverage-based\nscoring functions on multiple datasets. Compared to state-of-the-art functions\nthat were tuned manually, our method significantly improves performance and\nenables high-fidelity models with numbers of parameters well beyond what could\nreasonbly be tuned by hand.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2011 19:54:57 GMT"}, {"version": "v2", "created": "Thu, 13 Oct 2011 17:51:20 GMT"}], "update_date": "2011-10-14", "authors_parsed": [["Sipos", "Ruben", ""], ["Shivaswamy", "Pannaga", ""], ["Joachims", "Thorsten", ""]]}, {"id": "1110.2215", "submitter": "R. J. Evans", "authors": "R. J. Evans, C. Orasan", "title": "NP Animacy Identification for Anaphora Resolution", "comments": null, "journal-ref": "Journal Of Artificial Intelligence Research, Volume 29, pages\n  79-103, 2007", "doi": "10.1613/jair.2179", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In anaphora resolution for English, animacy identification can play an\nintegral role in the application of agreement restrictions between pronouns and\ncandidates, and as a result, can improve the accuracy of anaphora resolution\nsystems. In this paper, two methods for animacy identification are proposed and\nevaluated using intrinsic and extrinsic measures. The first method is a\nrule-based one which uses information about the unique beginners in WordNet to\nclassify NPs on the basis of their animacy. The second method relies on a\nmachine learning algorithm which exploits a WordNet enriched with animacy\ninformation for each sense. The effect of word sense disambiguation on the two\nmethods is also assessed. The intrinsic evaluation reveals that the machine\nlearning method reaches human levels of performance. The extrinsic evaluation\ndemonstrates that animacy identification can be beneficial in anaphora\nresolution, especially in the cases where animate entities are identified with\nhigh precision.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2011 22:13:24 GMT"}], "update_date": "2011-10-12", "authors_parsed": [["Evans", "R. J.", ""], ["Orasan", "C.", ""]]}, {"id": "1110.3088", "submitter": "Nigel Collier", "authors": "Nigel Collier", "title": "Towards cross-lingual alerting for bursty epidemic events", "comments": null, "journal-ref": "Journal of Biomedical Semantics 2011, 2(Suppl 5):S10", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Background: Online news reports are increasingly becoming a source for event\nbased early warning systems that detect natural disasters. Harnessing the\nmassive volume of information available from multilingual newswire presents as\nmany challenges as opportunities due to the patterns of reporting complex\nspatiotemporal events. Results: In this article we study the problem of\nutilising correlated event reports across languages. We track the evolution of\n16 disease outbreaks using 5 temporal aberration detection algorithms on\ntext-mined events classified according to disease and outbreak country. Using\nProMED reports as a silver standard, comparative analysis of news data for 13\nlanguages over a 129 day trial period showed improved sensitivity, F1 and\ntimeliness across most models using cross-lingual events. We report a detailed\ncase study analysis for Cholera in Angola 2010 which highlights the challenges\nfaced in correlating news events with the silver standard. Conclusions: The\nresults show that automated health surveillance using multilingual text mining\nhas the potential to turn low value news into high value alerts if informed\nchoices are used to govern the selection of models and data sources. An\nimplementation of the C2 alerting algorithm using multilingual news is\navailable at the BioCaster portal http://born.nii.ac.jp/?page=globalroundup.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2011 23:05:48 GMT"}], "update_date": "2011-10-17", "authors_parsed": [["Collier", "Nigel", ""]]}, {"id": "1110.3089", "submitter": "Nigel Collier", "authors": "Nigel Collier, Nguyen Truong Son, Ngoc Mai Nguyen", "title": "OMG U got flu? Analysis of shared health messages for bio-surveillance", "comments": null, "journal-ref": "Journal of Biomedical Semantics 2011, 2(Suppl 5):S9", "doi": "10.1186/2041-1480-2-S5-S9", "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Background: Micro-blogging services such as Twitter offer the potential to\ncrowdsource epidemics in real-time. However, Twitter posts ('tweets') are often\nambiguous and reactive to media trends. In order to ground user messages in\nepidemic response we focused on tracking reports of self-protective behaviour\nsuch as avoiding public gatherings or increased sanitation as the basis for\nfurther risk analysis. Results: We created guidelines for tagging self\nprotective behaviour based on Jones and Salath\\'e (2009)'s behaviour response\nsurvey. Applying the guidelines to a corpus of 5283 Twitter messages related to\ninfluenza like illness showed a high level of inter-annotator agreement (kappa\n0.86). We employed supervised learning using unigrams, bigrams and regular\nexpressions as features with two supervised classifiers (SVM and Naive Bayes)\nto classify tweets into 4 self-reported protective behaviour categories plus a\nself-reported diagnosis. In addition to classification performance we report\nmoderately strong Spearman's Rho correlation by comparing classifier output\nagainst WHO/NREVSS laboratory data for A(H1N1) in the USA during the 2009-2010\ninfluenza season. Conclusions: The study adds to evidence supporting a high\ndegree of correlation between pre-diagnostic social media signals and\ndiagnostic influenza case data, pointing the way towards low cost sensor\nnetworks. We believe that the signals we have modelled may be applicable to a\nwide range of diseases.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2011 23:15:44 GMT"}], "update_date": "2011-10-17", "authors_parsed": [["Collier", "Nigel", ""], ["Son", "Nguyen Truong", ""], ["Nguyen", "Ngoc Mai", ""]]}, {"id": "1110.3091", "submitter": "Nigel Collier", "authors": "Nigel Collier", "title": "What's unusual in online disease outbreak news?", "comments": null, "journal-ref": "Journal of Biomedical Semantics 2010, 1:2", "doi": "10.1186/2041-1480-1-2", "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Background: Accurate and timely detection of public health events of\ninternational concern is necessary to help support risk assessment and response\nand save lives. Novel event-based methods that use the World Wide Web as a\nsignal source offer potential to extend health surveillance into areas where\ntraditional indicator networks are lacking. In this paper we address the issue\nof systematically evaluating online health news to support automatic alerting\nusing daily disease-country counts text mined from real world data using\nBioCaster. For 18 data sets produced by BioCaster, we compare 5 aberration\ndetection algorithms (EARS C2, C3, W2, F-statistic and EWMA) for performance\nagainst expert moderated ProMED-mail postings. Results: We report sensitivity,\nspecificity, positive predictive value (PPV), negative predictive value (NPV),\nmean alerts/100 days and F1, at 95% confidence interval (CI) for 287\nProMED-mail postings on 18 outbreaks across 14 countries over a 366 day period.\nResults indicate that W2 had the best F1 with a slight benefit for day of week\neffect over C2. In drill down analysis we indicate issues arising from the\ngranular choice of country-level modeling, sudden drops in reporting due to day\nof week effects and reporting bias. Automatic alerting has been implemented in\nBioCaster available from http://born.nii.ac.jp. Conclusions: Online health news\nalerts have the potential to enhance manual analytical methods by increasing\nthroughput, timeliness and detection rates. Systematic evaluation of health\nnews aberrations is necessary to push forward our understanding of the complex\nrelationship between news report volumes and case numbers and to select the\nbest performing features and algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2011 23:22:43 GMT"}], "update_date": "2011-10-17", "authors_parsed": [["Collier", "Nigel", ""]]}, {"id": "1110.3094", "submitter": "Nigel Collier", "authors": "Nigel Collier, Son Doan", "title": "Syndromic classification of Twitter messages", "comments": "10 pages, 2 figures, eHealth 2011 conference, Malaga (Spain)\n  (accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Recent studies have shown strong correlation between social networking data\nand national influenza rates. We expanded upon this success to develop an\nautomated text mining system that classifies Twitter messages in real time into\nsix syndromic categories based on key terms from a public health ontology.\n10-fold cross validation tests were used to compare Naive Bayes (NB) and\nSupport Vector Machine (SVM) models on a corpus of 7431 Twitter messages. SVM\nperformed better than NB on 4 out of 6 syndromes. The best performing\nclassifiers showed moderately strong F1 scores: respiratory = 86.2 (NB);\ngastrointestinal = 85.4 (SVM polynomial kernel degree 2); neurological = 88.6\n(SVM polynomial kernel degree 1); rash = 86.0 (SVM polynomial kernel degree 1);\nconstitutional = 89.3 (SVM polynomial kernel degree 1); hemorrhagic = 89.9\n(NB). The resulting classifiers were deployed together with an EARS C2\naberration detection algorithm in an experimental online system.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2011 23:42:32 GMT"}], "update_date": "2011-10-17", "authors_parsed": [["Collier", "Nigel", ""], ["Doan", "Son", ""]]}, {"id": "1110.4123", "submitter": "Antonios Garas", "authors": "David Garcia, Antonios Garas, and Frank Schweitzer", "title": "Positive words carry less information than negative words", "comments": "16 pages, 3 figures, 3 tables", "journal-ref": "EPJ Data Science 2012, 1:3", "doi": "10.1140/epjds3", "report-no": null, "categories": "cs.CL cs.IR physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the frequency of word use is not only determined by the word\nlength \\cite{Zipf1935} and the average information content\n\\cite{Piantadosi2011}, but also by its emotional content. We have analyzed\nthree established lexica of affective word usage in English, German, and\nSpanish, to verify that these lexica have a neutral, unbiased, emotional\ncontent. Taking into account the frequency of word usage, we find that words\nwith a positive emotional content are more frequently used. This lends support\nto Pollyanna hypothesis \\cite{Boucher1969} that there should be a positive bias\nin human expression. We also find that negative words contain more information\nthan positive words, as the informativeness of a word increases uniformly with\nits valence decrease. Our findings support earlier conjectures about (i) the\nrelation between word frequency and information content, and (ii) the impact of\npositive emotions on communication and social links.\n", "versions": [{"version": "v1", "created": "Tue, 18 Oct 2011 20:54:21 GMT"}, {"version": "v2", "created": "Tue, 22 Nov 2011 10:19:34 GMT"}, {"version": "v3", "created": "Wed, 18 Apr 2012 12:29:23 GMT"}, {"version": "v4", "created": "Sun, 27 May 2012 14:55:40 GMT"}], "update_date": "2012-05-29", "authors_parsed": [["Garcia", "David", ""], ["Garas", "Antonios", ""], ["Schweitzer", "Frank", ""]]}, {"id": "1110.4248", "submitter": "Luojie Xiang", "authors": "Luojie Xiang", "title": "Ideogram Based Chinese Sentiment Word Orientation Computation", "comments": "4 pages, 3 figures, accepted by CET 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper presents a novel algorithm to compute sentiment orientation of\nChinese sentiment word. The algorithm uses ideograms which are a distinguishing\nfeature of Chinese language. The proposed algorithm can be applied to any\nsentiment classification scheme. To compute a word's sentiment orientation\nusing the proposed algorithm, only the word itself and a precomputed character\nontology is required, rather than a corpus. The influence of three parameters\nover the algorithm performance is analyzed and verified by experiment.\nExperiment also shows that proposed algorithm achieves an F Measure of 85.02%\noutperforming existing ideogram based algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 19 Oct 2011 11:45:16 GMT"}], "update_date": "2011-10-20", "authors_parsed": [["Xiang", "Luojie", ""]]}, {"id": "1110.6200", "submitter": "Jacob Eisenstein", "authors": "Jacob Eisenstein, Duen Horng \"Polo\" Chau, Aniket Kittur, Eric P. Xing", "title": "TopicViz: Semantic Navigation of Document Collections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When people explore and manage information, they think in terms of topics and\nthemes. However, the software that supports information exploration sees text\nat only the surface level. In this paper we show how topic modeling -- a\ntechnique for identifying latent themes across large collections of documents\n-- can support semantic exploration. We present TopicViz, an interactive\nenvironment for information exploration. TopicViz combines traditional search\nand citation-graph functionality with a range of novel interactive\nvisualizations, centered around a force-directed layout that links documents to\nthe latent themes discovered by the topic model. We describe several use\nscenarios in which TopicViz supports rapid sensemaking on large document\ncollections.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2011 21:37:24 GMT"}, {"version": "v2", "created": "Fri, 4 Nov 2011 03:47:30 GMT"}], "update_date": "2011-11-07", "authors_parsed": [["Eisenstein", "Jacob", ""], ["Chau", "Duen Horng \"Polo\"", ""], ["Kittur", "Aniket", ""], ["Xing", "Eric P.", ""]]}]