[{"id": "1908.00059", "submitter": "Yu Chen", "authors": "Yu Chen, Lingfei Wu and Mohammed J. Zaki", "title": "GraphFlow: Exploiting Conversation Flow with Graph Neural Networks for\n  Conversational Machine Comprehension", "comments": "7 pages. Accepted by IJCAI 2020. Final Version. The SOLE copyright\n  holder is IJCAI (https://www.ijcai.org), all rights reserved", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational machine comprehension (MC) has proven significantly more\nchallenging compared to traditional MC since it requires better utilization of\nconversation history. However, most existing approaches do not effectively\ncapture conversation history and thus have trouble handling questions involving\ncoreference or ellipsis. Moreover, when reasoning over passage text, most of\nthem simply treat it as a word sequence without exploring rich semantic\nrelationships among words. In this paper, we first propose a simple yet\neffective graph structure learning technique to dynamically construct a\nquestion and conversation history aware context graph at each conversation\nturn. Then we propose a novel Recurrent Graph Neural Network, and based on\nthat, we introduce a flow mechanism to model the temporal dependencies in a\nsequence of context graphs. The proposed GraphFlow model can effectively\ncapture conversational flow in a dialog, and shows competitive performance\ncompared to existing state-of-the-art methods on CoQA, QuAC and DoQA\nbenchmarks. In addition, visualization experiments show that our proposed model\ncan offer good interpretability for the reasoning process.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 19:23:38 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 17:43:03 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Chen", "Yu", ""], ["Wu", "Lingfei", ""], ["Zaki", "Mohammed J.", ""]]}, {"id": "1908.00153", "submitter": "Nuha Albadi", "authors": "Nuha Albadi, Maram Kurdi, Shivakant Mishra", "title": "Hateful People or Hateful Bots? Detection and Characterization of Bots\n  Spreading Religious Hatred in Arabic Social Media", "comments": null, "journal-ref": "Proc. ACM Hum.-Comput. Interact. 3, CSCW: Article 61 (2019)", "doi": "10.1145/3359163", "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arabic Twitter space is crawling with bots that fuel political feuds, spread\nmisinformation, and proliferate sectarian rhetoric. While efforts have long\nexisted to analyze and detect English bots, Arabic bot detection and\ncharacterization remains largely understudied. In this work, we contribute new\ninsights into the role of bots in spreading religious hatred on Arabic Twitter\nand introduce a novel regression model that can accurately identify Arabic\nlanguage bots. Our assessment shows that existing tools that are highly\naccurate in detecting English bots don't perform as well on Arabic bots. We\nidentify the possible reasons for this poor performance, perform a thorough\nanalysis of linguistic, content, behavioral and network features, and report on\nthe most informative features that distinguish Arabic bots from humans as well\nas the differences between Arabic and English bots. Our results mark an\nimportant step toward understanding the behavior of malicious bots on Arabic\nTwitter and pave the way for a more effective Arabic bot detection tools.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 00:28:57 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 00:46:25 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Albadi", "Nuha", ""], ["Kurdi", "Maram", ""], ["Mishra", "Shivakant", ""]]}, {"id": "1908.00249", "submitter": "Ting Yao", "authors": "Jing Wang and Yingwei Pan and Ting Yao and Jinhui Tang and Tao Mei", "title": "Convolutional Auto-encoding of Sentence Topics for Image Paragraph\n  Generation", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image paragraph generation is the task of producing a coherent story (usually\na paragraph) that describes the visual content of an image. The problem\nnevertheless is not trivial especially when there are multiple descriptive and\ndiverse gists to be considered for paragraph generation, which often happens in\nreal images. A valid question is how to encapsulate such gists/topics that are\nworthy of mention from an image, and then describe the image from one topic to\nanother but holistically with a coherent structure. In this paper, we present a\nnew design --- Convolutional Auto-Encoding (CAE) that purely employs\nconvolutional and deconvolutional auto-encoding framework for topic modeling on\nthe region-level features of an image. Furthermore, we propose an architecture,\nnamely CAE plus Long Short-Term Memory (dubbed as CAE-LSTM), that novelly\nintegrates the learnt topics in support of paragraph generation. Technically,\nCAE-LSTM capitalizes on a two-level LSTM-based paragraph generation framework\nwith attention mechanism. The paragraph-level LSTM captures the inter-sentence\ndependency in a paragraph, while sentence-level LSTM is to generate one\nsentence which is conditioned on each learnt topic. Extensive experiments are\nconducted on Stanford image paragraph dataset, and superior results are\nreported when comparing to state-of-the-art approaches. More remarkably,\nCAE-LSTM increases CIDEr performance from 20.93% to 25.15%.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 07:58:50 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Wang", "Jing", ""], ["Pan", "Yingwei", ""], ["Yao", "Ting", ""], ["Tang", "Jinhui", ""], ["Mei", "Tao", ""]]}, {"id": "1908.00286", "submitter": "Floris Den Hengst", "authors": "Floris den Hengst, Mark Hoogendoorn, Frank van Harmelen, Joost Bosman", "title": "Reinforcement Learning for Personalized Dialogue Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.HC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Language systems have been of great interest to the research community and\nhave recently reached the mass market through various assistant platforms on\nthe web. Reinforcement Learning methods that optimize dialogue policies have\nseen successes in past years and have recently been extended into methods that\npersonalize the dialogue, e.g. take the personal context of users into account.\nThese works, however, are limited to personalization to a single user with whom\nthey require multiple interactions and do not generalize the usage of context\nacross users. This work introduces a problem where a generalized usage of\ncontext is relevant and proposes two Reinforcement Learning (RL)-based\napproaches to this problem. The first approach uses a single learner and\nextends the traditional POMDP formulation of dialogue state with features that\ndescribe the user context. The second approach segments users by context and\nthen employs a learner per context. We compare these approaches in a benchmark\nof existing non-RL and RL-based methods in three established and one novel\napplication domain of financial product recommendation. We compare the\ninfluence of context and training experiences on performance and find that\nlearning approaches generally outperform a handcrafted gold standard.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 09:19:27 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Hengst", "Floris den", ""], ["Hoogendoorn", "Mark", ""], ["van Harmelen", "Frank", ""], ["Bosman", "Joost", ""]]}, {"id": "1908.00300", "submitter": "Feng Ji", "authors": "Runqi Yang, Jianhai Zhang, Xing Gao, Feng Ji, Haiqing Chen", "title": "Simple and Effective Text Matching with Richer Alignment Features", "comments": "11 pages, 7 tables, 3 figures, accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a fast and strong neural approach for general\npurpose text matching applications. We explore what is sufficient to build a\nfast and well-performed text matching model and propose to keep three key\nfeatures available for inter-sequence alignment: original point-wise features,\nprevious aligned features, and contextual features while simplifying all the\nremaining components. We conduct experiments on four well-studied benchmark\ndatasets across tasks of natural language inference, paraphrase identification\nand answer selection. The performance of our model is on par with the\nstate-of-the-art on all datasets with much fewer parameters and the inference\nspeed is at least 6 times faster compared with similarly performed ones.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 10:07:07 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Yang", "Runqi", ""], ["Zhang", "Jianhai", ""], ["Gao", "Xing", ""], ["Ji", "Feng", ""], ["Chen", "Haiqing", ""]]}, {"id": "1908.00308", "submitter": "Zili Wang", "authors": "Zili Wang", "title": "MSnet: A BERT-based Network for Gendered Pronoun Resolution", "comments": "7 pages; 1 figures; accepted by 1st ACL Workshop on Gender Bias for\n  NLP at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pre-trained BERT model achieves a remarkable state of the art across a\nwide range of tasks in natural language processing. For solving the gender bias\nin gendered pronoun resolution task, I propose a novel neural network model\nbased on the pre-trained BERT. This model is a type of mention score classifier\nand uses an attention mechanism with no parameters to compute the contextual\nrepresentation of entity span, and a vector to represent the triple-wise\nsemantic similarity among the pronoun and the entities. In stage 1 of the\ngendered pronoun resolution task, a variant of this model, trained in the\nfine-tuning approach, reduced the multi-class logarithmic loss to 0.3033 in the\n5-fold cross-validation of training set and 0.2795 in testing set. Besides,\nthis variant won the 2nd place with a score at 0.17289 in stage 2 of the task.\nThe code in this paper is available at:\nhttps://github.com/ziliwang/MSnet-for-Gendered-PronounResolution\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 10:27:29 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Wang", "Zili", ""]]}, {"id": "1908.00321", "submitter": "Sainik Mahata", "authors": "Avishek Garain, Sainik Kumar Mahata", "title": "Sentiment Analysis at SEPLN (TASS)-2019: Sentiment Analysis at Tweet\n  level using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the system submitted to \"Sentiment Analysis at SEPLN\n(TASS)-2019\" shared task. The task includes sentiment analysis of Spanish\ntweets, where the tweets are in different dialects spoken in Spain, Peru, Costa\nRica, Uruguay and Mexico. The tweets are short (up to 240 characters) and the\nlanguage is informal, i.e., it contains misspellings, emojis, onomatopeias etc.\nSentiment analysis includes classification of the tweets into 4 classes, viz.,\nPositive, Negative, Neutral and None. For preparing the proposed system, we use\nDeep Learning networks like LSTMs.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 10:52:26 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Garain", "Avishek", ""], ["Mahata", "Sainik Kumar", ""]]}, {"id": "1908.00323", "submitter": "Sainik Mahata", "authors": "Sainik Kumar Mahata, Dipankar Das, Sivaji Bandyopadhyay", "title": "JUCBNMT at WMT2018 News Translation Task: Character Based Neural Machine\n  Translation of Finnish to English", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the current work, we present a description of the system submitted to WMT\n2018 News Translation Shared task. The system was created to translate news\ntext from Finnish to English. The system used a Character Based Neural Machine\nTranslation model to accomplish the given task. The current paper documents the\npreprocessing steps, the description of the submitted system and the results\nproduced using the same. Our system garnered a BLEU score of 12.9.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 10:57:31 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Mahata", "Sainik Kumar", ""], ["Das", "Dipankar", ""], ["Bandyopadhyay", "Sivaji", ""]]}, {"id": "1908.00358", "submitter": "Zitao Liu", "authors": "Wenbiao Ding, Guowei Xu, Tianqiao Liu, Weiping Fu, Yujia Song, Chaoyou\n  Guo, Cong Kong, Songfan Yang, Gale Yan Huang, Zitao Liu", "title": "Dolphin: A Spoken Language Proficiency Assessment System for Elementary\n  Education", "comments": "Proceedings of The Web Conference 2020 (WWW '20)", "journal-ref": null, "doi": "10.1145/3366423.3380018", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken language proficiency is critically important for children's growth and\npersonal development. Due to the limited and imbalanced educational resources\nin China, elementary students barely have chances to improve their oral\nlanguage skills in classes. Verbal fluency tasks (VFTs) were invented to let\nthe students practice their spoken language proficiency after school. VFTs are\nsimple but concrete math related questions that ask students to not only report\nanswers but speak out the entire thinking process. In spite of the great\nsuccess of VFTs, they bring a heavy grading burden to elementary teachers. To\nalleviate this problem, we develop Dolphin, a spoken language proficiency\nassessment system for Chinese elementary education. Dolphin is able to\nautomatically evaluate both phonological fluency and semantic relevance of\nstudents' VFT answers. We conduct a wide range of offline and online\nexperiments to demonstrate the effectiveness of Dolphin. In our offline\nexperiments, we show that Dolphin improves both phonological fluency and\nsemantic relevance evaluation performance when compared to state-of-the-art\nbaselines on real-world educational data sets. In our online A/B experiments,\nwe test Dolphin with 183 teachers from 2 major cities (Hangzhou and Xi'an) in\nChina for 10 weeks and the results show that VFT assignments grading coverage\nis improved by 22\\%.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 12:31:49 GMT"}, {"version": "v2", "created": "Sun, 4 Aug 2019 08:00:40 GMT"}, {"version": "v3", "created": "Wed, 29 Jan 2020 08:52:58 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Ding", "Wenbiao", ""], ["Xu", "Guowei", ""], ["Liu", "Tianqiao", ""], ["Fu", "Weiping", ""], ["Song", "Yujia", ""], ["Guo", "Chaoyou", ""], ["Kong", "Cong", ""], ["Yang", "Songfan", ""], ["Huang", "Gale Yan", ""], ["Liu", "Zitao", ""]]}, {"id": "1908.00449", "submitter": "Jacob Harer", "authors": "Jacob Harer, Chris Reale and Peter Chin", "title": "Tree-Transformer: A Transformer-Based Method for Correction of\n  Tree-Structured Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many common sequential data sources, such as source code and natural\nlanguage, have a natural tree-structured representation. These trees can be\ngenerated by fitting a sequence to a grammar, yielding a hierarchical ordering\nof the tokens in the sequence. This structure encodes a high degree of\nsyntactic information, making it ideal for problems such as grammar correction.\nHowever, little work has been done to develop neural networks that can operate\non and exploit tree-structured data. In this paper we present the\nTree-Transformer \\textemdash{} a novel neural network architecture designed to\ntranslate between arbitrary input and output trees. We applied this\narchitecture to correction tasks in both the source code and natural language\ndomains. On source code, our model achieved an improvement of $25\\%$\n$\\text{F}0.5$ over the best sequential method. On natural language, we achieved\ncomparable results to the most complex state of the art systems, obtaining a\n$10\\%$ improvement in recall on the CoNLL 2014 benchmark and the highest to\ndate $\\text{F}0.5$ score on the AESW benchmark of $50.43$.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 15:05:41 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Harer", "Jacob", ""], ["Reale", "Chris", ""], ["Chin", "Peter", ""]]}, {"id": "1908.00475", "submitter": "Mennatallah El-Assady", "authors": "Mennatallah El-Assady, Rebecca Kehlbeck, Christopher Collins, Daniel\n  Keim, Oliver Deussen", "title": "Semantic Concept Spaces: Guided Topic Model Refinement using\n  Word-Embedding Projections", "comments": null, "journal-ref": "IEEE Transactions on Visualization and Computer Graphics, 2019", "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework that allows users to incorporate the semantics of\ntheir domain knowledge for topic model refinement while remaining\nmodel-agnostic. Our approach enables users to (1) understand the semantic space\nof the model, (2) identify regions of potential conflicts and problems, and (3)\nreadjust the semantic relation of concepts based on their understanding,\ndirectly influencing the topic modeling. These tasks are supported by an\ninteractive visual analytics workspace that uses word-embedding projections to\ndefine concept regions which can then be refined. The user-refined concepts are\nindependent of a particular document collection and can be transferred to\nrelated corpora. All user interactions within the concept space directly affect\nthe semantic relations of the underlying vector space model, which, in turn,\nchange the topic modeling. In addition to direct manipulation, our system\nguides the users' decision-making process through recommended interactions that\npoint out potential improvements. This targeted refinement aims at minimizing\nthe feedback required for an efficient human-in-the-loop process. We confirm\nthe improvements achieved through our approach in two user studies that show\ntopic model quality improvements through our visual knowledge externalization\nand learning process.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 16:02:04 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["El-Assady", "Mennatallah", ""], ["Kehlbeck", "Rebecca", ""], ["Collins", "Christopher", ""], ["Keim", "Daniel", ""], ["Deussen", "Oliver", ""]]}, {"id": "1908.00493", "submitter": "Mohamed Mahmoud", "authors": "Mohamed El-Geish", "title": "Learning Joint Acoustic-Phonetic Word Embeddings", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most speech recognition tasks pertain to mapping words across two modalities:\nacoustic and orthographic. In this work, we suggest learning encoders that map\nvariable-length, acoustic or phonetic, sequences that represent words into\nfixed-dimensional vectors in a shared latent space; such that the distance\nbetween two word vectors represents how closely the two words sound. Instead of\ndirectly learning the distances between word vectors, we employ weak\nsupervision and model a binary classification task to predict whether two\ninputs, one of each modality, represent the same word given a distance\nthreshold. We explore various deep-learning models, bimodal contrastive losses,\nand techniques for mining hard negative examples such as the semi-supervised\ntechnique of self-labeling. Our best model achieves an $F_1$ score of 0.95 for\nthe binary classification task.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 16:42:47 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["El-Geish", "Mohamed", ""]]}, {"id": "1908.00588", "submitter": "Lindsey Sawatzky", "authors": "Lindsey Sawatzky, Steven Bergner, Fred Popowich", "title": "Visualizing RNN States with Predictive Semantic Encodings", "comments": null, "journal-ref": null, "doi": "10.1109/VISUAL.2019.8933744", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks are an effective and prevalent tool used to model\nsequential data such as natural language text. However, their deep nature and\nmassive number of parameters pose a challenge for those intending to study\nprecisely how they work. We present a visual technique that gives a high level\nintuition behind the semantics of the hidden states within Recurrent Neural\nNetworks. This semantic encoding allows for hidden states to be compared\nthroughout the model independent of their internal details. The proposed\ntechnique is displayed in a proof of concept visualization tool which is\ndemonstrated to visualize the natural language processing task of language\nmodelling.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 19:24:59 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Sawatzky", "Lindsey", ""], ["Bergner", "Steven", ""], ["Popowich", "Fred", ""]]}, {"id": "1908.00648", "submitter": "Amine Trabelsi", "authors": "Amine Trabelsi and Osmar R. Zaiane", "title": "Contrastive Reasons Detection and Clustering from Online Polarized\n  Debate", "comments": "Best paper award in CICLing 2019: International Conference on\n  Computational Linguistics and Intelligent Text Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work tackles the problem of unsupervised modeling and extraction of the\nmain contrastive sentential reasons conveyed by divergent viewpoints on\npolarized issues. It proposes a pipeline approach centered around the detection\nand clustering of phrases, assimilated to argument facets using a novel Phrase\nAuthor Interaction Topic-Viewpoint model. The evaluation is based on the\ninformativeness, the relevance and the clustering accuracy of extracted\nreasons. The pipeline approach shows a significant improvement over\nstate-of-the-art methods in contrastive summarization on online debate\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 22:42:36 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Trabelsi", "Amine", ""], ["Zaiane", "Osmar R.", ""]]}, {"id": "1908.00785", "submitter": "Francois Coste", "authors": "Fran\\c{c}ois Coste (Dyliss)", "title": "Deep learning languages: a key fundamental shift from probabilities to\n  weights?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.OT cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent successes in language modeling, notably with deep learning methods,\ncoincide with a shift from probabilistic to weighted representations. We raise\nhere the question of the importance of this evolution, in the light of the\npractical limitations of a classical and simple probabilistic modeling approach\nfor the classification of protein sequences and in relation to the need for\nprincipled methods to learn non-probabilistic models.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 10:09:51 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Coste", "Fran\u00e7ois", "", "Dyliss"]]}, {"id": "1908.00908", "submitter": "Panayiotis Georgiou", "authors": "Sandeep Nallan Chakravarthula, Haoqi Li, Shao-Yen Tseng, Maija Reblin,\n  Panayiotis Georgiou", "title": "Predicting Behavior in Cancer-Afflicted Patient and Spouse Interactions\n  using Speech and Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Cancer impacts the quality of life of those diagnosed as well as their spouse\ncaregivers, in addition to potentially influencing their day-to-day behaviors.\nThere is evidence that effective communication between spouses can improve\nwell-being related to cancer but it is difficult to efficiently evaluate the\nquality of daily life interactions using manual annotation frameworks.\nAutomated recognition of behaviors based on the interaction cues of speakers\ncan help analyze interactions in such couples and identify behaviors which are\nbeneficial for effective communication. In this paper, we present and detail a\ndataset of dyadic interactions in 85 real-life cancer-afflicted couples and a\nset of observational behavior codes pertaining to interpersonal communication\nattributes. We describe and employ neural network-based systems for classifying\nthese behaviors based on turn-level acoustic and lexical speech patterns.\nFurthermore, we investigate the effect of controlling for factors such as\ngender, patient/caregiver role and conversation content on behavior\nclassification. Analysis of our preliminary results indicates the challenges in\nthis task due to the nature of the targeted behaviors and suggests that\ntechniques incorporating contextual processing might be better suited to tackle\nthis problem.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 15:30:06 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Chakravarthula", "Sandeep Nallan", ""], ["Li", "Haoqi", ""], ["Tseng", "Shao-Yen", ""], ["Reblin", "Maija", ""], ["Georgiou", "Panayiotis", ""]]}, {"id": "1908.00916", "submitter": "Dominik Mach\\'a\\v{c}ek", "authors": "Dominik Mach\\'a\\v{c}ek, Jon\\'a\\v{s} Kratochv\\'il, Tereza\n  Vojt\\v{e}chov\\'a, Ond\\v{r}ej Bojar", "title": "A Speech Test Set of Practice Business Presentations with Additional\n  Relevant Texts", "comments": "SLSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a test corpus of audio recordings and transcriptions of\npresentations of students' enterprises together with their slides and\nweb-pages. The corpus is intended for evaluation of automatic speech\nrecognition (ASR) systems, especially in conditions where the prior\navailability of in-domain vocabulary and named entities is benefitable. The\ncorpus consists of 39 presentations in English, each up to 90 seconds long. The\nspeakers are high school students from European countries with English as their\nsecond language. We benchmark three baseline ASR systems on the corpus and show\ntheir imperfection.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 15:39:31 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Mach\u00e1\u010dek", "Dominik", ""], ["Kratochv\u00edl", "Jon\u00e1\u0161", ""], ["Vojt\u011bchov\u00e1", "Tereza", ""], ["Bojar", "Ond\u0159ej", ""]]}, {"id": "1908.01060", "submitter": "Xinjian Li", "authors": "Xinjian Li, Siddharth Dalmia, Alan W. Black, Florian Metze", "title": "Multilingual Speech Recognition with Corpus Relatedness Sampling", "comments": "Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual acoustic models have been successfully applied to low-resource\nspeech recognition. Most existing works have combined many small corpora\ntogether and pretrained a multilingual model by sampling from each corpus\nuniformly. The model is eventually fine-tuned on each target corpus. This\napproach, however, fails to exploit the relatedness and similarity among\ncorpora in the training set. For example, the target corpus might benefit more\nfrom a corpus in the same domain or a corpus from a close language. In this\nwork, we propose a simple but useful sampling strategy to take advantage of\nthis relatedness. We first compute the corpus-level embeddings and estimate the\nsimilarity between each corpus. Next, we start training the multilingual model\nwith uniform-sampling from each corpus at first, then we gradually increase the\nprobability to sample from related corpora based on its similarity with the\ntarget corpus. Finally, the model would be fine-tuned automatically on the\ntarget corpus. Our sampling strategy outperforms the baseline multilingual\nmodel on 16 low-resource tasks. Additionally, we demonstrate that our corpus\nembeddings capture the language and domain information of each corpus.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 21:08:13 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Li", "Xinjian", ""], ["Dalmia", "Siddharth", ""], ["Black", "Alan W.", ""], ["Metze", "Florian", ""]]}, {"id": "1908.01067", "submitter": "Xinjian Li", "authors": "Xinjian Li, Zhong Zhou, Siddharth Dalmia, Alan W. Black, Florian Metze", "title": "SANTLR: Speech Annotation Toolkit for Low Resource Languages", "comments": "Interspeech 2019 (Show and Tell)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While low resource speech recognition has attracted a lot of attention from\nthe speech community, there are a few tools available to facilitate low\nresource speech collection. In this work, we present SANTLR: Speech Annotation\nToolkit for Low Resource Languages. It is a web-based toolkit which allows\nresearchers to easily collect and annotate a corpus of speech in a low resource\nlanguage. Annotators may use this toolkit for two purposes: transcription or\nrecording. In transcription, annotators would transcribe audio files provided\nby the researchers; in recording, annotators would record their voice by\nreading provided texts. We highlight two properties of this toolkit. First,\nSANTLR has a very user-friendly User Interface (UI). Both researchers and\nannotators may use this simple web interface to interact. There is no\nrequirement for the annotators to have any expertise in audio or text\nprocessing. The toolkit would handle all preprocessing and postprocessing\nsteps. Second, we employ a multi-step ranking mechanism facilitate the\nannotation process. In particular, the toolkit would give higher priority to\nutterances which are easier to annotate and are more beneficial to achieving\nthe goal of the annotation, e.g. quickly training an acoustic model.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 21:13:27 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Li", "Xinjian", ""], ["Zhou", "Zhong", ""], ["Dalmia", "Siddharth", ""], ["Black", "Alan W.", ""], ["Metze", "Florian", ""]]}, {"id": "1908.01165", "submitter": "Utpal Garain", "authors": "Akshay Chaturvedi, Abijith KP, and Utpal Garain", "title": "Exploring the Robustness of NMT Systems to Nonsensical Inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) systems have been shown to give undesirable\ntranslation when a small change is made in the source sentence. In this paper,\nwe study the behaviour of NMT systems when multiple changes are made to the\nsource sentence. In particular, we ask the following question \"Is it possible\nfor an NMT system to predict same translation even when multiple words in the\nsource sentence have been replaced?\". To this end, we propose a soft-attention\nbased technique to make the aforementioned word replacements. The experiments\nare conducted on two language pairs: English-German (en-de) and English-French\n(en-fr) and two state-of-the-art NMT systems: BLSTM-based encoder-decoder with\nattention and Transformer. The proposed soft-attention based technique achieves\nhigh success rate and outperforms existing methods like HotFlip by a\nsignificant margin for all the conducted experiments. The results demonstrate\nthat state-of-the-art NMT systems are unable to capture the semantics of the\nsource language. The proposed soft-attention based technique is an\ninvariance-based adversarial attack on NMT systems. To better evaluate such\nattacks, we propose an alternate metric and argue its benefits in comparison\nwith success rate.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 12:59:40 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 13:05:38 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 14:23:26 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Chaturvedi", "Akshay", ""], ["KP", "Abijith", ""], ["Garain", "Utpal", ""]]}, {"id": "1908.01192", "submitter": "Magdalena Biesialska", "authors": "Magdalena Biesialska, Lluis Guardia and Marta R. Costa-juss\\`a", "title": "The TALP-UPC System for the WMT Similar Language Task: Statistical vs\n  Neural Machine Translation", "comments": "WMT 2019 Shared Task paper", "journal-ref": null, "doi": "10.18653/v1/W19-5424", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the problem of similar language translation has been an area of\nresearch interest for many years, yet it is still far from being solved. In\nthis paper, we study the performance of two popular approaches: statistical and\nneural. We conclude that both methods yield similar results; however, the\nperformance varies depending on the language pair. While the statistical\napproach outperforms the neural one by a difference of 6 BLEU points for the\nSpanish-Portuguese language pair, the proposed neural model surpasses the\nstatistical one by a difference of 2 BLEU points for Czech-Polish. In the\nformer case, the language similarity (based on perplexity) is much higher than\nin the latter case. Additionally, we report negative results for the system\ncombination with back-translation. Our TALP-UPC system submission won 1st place\nfor Czech-to-Polish and 2nd place for Spanish-to-Portuguese in the official\nevaluation of the 1st WMT Similar Language Translation task.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 15:38:19 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Biesialska", "Magdalena", ""], ["Guardia", "Lluis", ""], ["Costa-juss\u00e0", "Marta R.", ""]]}, {"id": "1908.01211", "submitter": "David Matthews", "authors": "David Matthews, Sam Kriegman, Collin Cappelle, Josh Bongard", "title": "Word2vec to behavior: morphology facilitates the grounding of language\n  in machines", "comments": "D. Matthews, S. Kriegman, C. Cappelle and J. Bongard, \"Word2vec to\n  behavior: morphology facilitates the grounding of language in machines,\" 2019\n  IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),\n  Macau, China, 2019. \\c{opyright} 2019 IEEE. Personal use of this material is\n  permitted. Permission from IEEE must be obtained for all other uses", "journal-ref": null, "doi": "10.1109/IROS40897.2019.8967639", "report-no": null, "categories": "cs.CL cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enabling machines to respond appropriately to natural language commands could\ngreatly expand the number of people to whom they could be of service. Recently,\nadvances in neural network-trained word embeddings have empowered non-embodied\ntext-processing algorithms, and suggest they could be of similar utility for\nembodied machines. Here we introduce a method that does so by training robots\nto act similarly to semantically-similar word2vec encoded commands. We show\nthat this enables them to act appropriately, after training, to\npreviously-unheard commands. Finally, we show that inducing such an alignment\nbetween motoric and linguistic similarities can be facilitated or hindered by\nthe mechanical structure of the robot. This points to future, large scale\nmethods that find and exploit relationships between action, language, and robot\nstructure.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 18:09:56 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Matthews", "David", ""], ["Kriegman", "Sam", ""], ["Cappelle", "Collin", ""], ["Bongard", "Josh", ""]]}, {"id": "1908.01294", "submitter": "Chanatip Saetia", "authors": "Chanatip Saetia, Ekapol Chuangsuwanich, Tawunrat Chalothorn, Peerapon\n  Vateekul", "title": "Semi-supervised Thai Sentence Segmentation Using Local and Distant Word\n  Representations", "comments": "19 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A sentence is typically treated as the minimal syntactic unit used for\nextracting valuable information from a longer piece of text. However, in\nwritten Thai, there are no explicit sentence markers. We proposed a deep\nlearning model for the task of sentence segmentation that includes three main\ncontributions. First, we integrate n-gram embedding as a local representation\nto capture word groups near sentence boundaries. Second, to focus on the\nkeywords of dependent clauses, we combine the model with a distant\nrepresentation obtained from self-attention modules. Finally, due to the\nscarcity of labeled data, for which annotation is difficult and time-consuming,\nwe also investigate and adapt Cross-View Training (CVT) as a semi-supervised\nlearning technique, allowing us to utilize unlabeled data to improve the model\nrepresentations. In the Thai sentence segmentation experiments, our model\nreduced the relative error by 7.4% and 10.5% compared with the baseline models\non the Orchid and UGWC datasets, respectively. We also applied our model to the\ntask of pronunciation recovery on the IWSLT English dataset. Our model\noutperformed the prior sequence tagging models, achieving a relative error\nreduction of 2.5%. Ablation studies revealed that utilizing n-gram\npresentations was the main contributing factor for Thai, while the\nsemi-supervised training helped the most for English.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 08:24:05 GMT"}, {"version": "v2", "created": "Sun, 25 Aug 2019 09:56:46 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Saetia", "Chanatip", ""], ["Chuangsuwanich", "Ekapol", ""], ["Chalothorn", "Tawunrat", ""], ["Vateekul", "Peerapon", ""]]}, {"id": "1908.01328", "submitter": "Georgi Karadzhov", "authors": "Pepa Atanasova, Preslav Nakov, Llu\\'is M\\`arquez, Alberto\n  Barr\\'on-Cede\\~no, Georgi Karadzhov, Tsvetomila Mihaylova, Mitra Mohtarami,\n  James Glass", "title": "Automatic Fact-Checking Using Context and Discourse Information", "comments": "JDIQ,Special Issue on Combating Digital Misinformation and\n  Disinformation", "journal-ref": "J. Data and Information Quality, Volume 11 Issue 3, July 2019,\n  Article No. 12", "doi": "10.1145/3297722", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of automatic fact-checking, paying special attention to\nthe impact of contextual and discourse information. We address two related\ntasks: (i) detecting check-worthy claims, and (ii) fact-checking claims. We\ndevelop supervised systems based on neural networks, kernel-based support\nvector machines, and combinations thereof, which make use of rich input\nrepresentations in terms of discourse cues and contextual features. For the\ncheck-worthiness estimation task, we focus on political debates, and we model\nthe target claim in the context of the full intervention of a participant and\nthe previous and the following turns in the debate, taking into account\ncontextual meta information. For the fact-checking task, we focus on answer\nverification in a community forum, and we model the veracity of the answer with\nrespect to the entire question--answer thread in which it occurs as well as\nwith respect to other related posts from the entire forum. We develop annotated\ndatasets for both tasks and we run extensive experimental evaluation,\nconfirming that both types of information ---but especially contextual\nfeatures--- play an important role.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 12:40:28 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Atanasova", "Pepa", ""], ["Nakov", "Preslav", ""], ["M\u00e0rquez", "Llu\u00eds", ""], ["Barr\u00f3n-Cede\u00f1o", "Alberto", ""], ["Karadzhov", "Georgi", ""], ["Mihaylova", "Tsvetomila", ""], ["Mohtarami", "Mitra", ""], ["Glass", "James", ""]]}, {"id": "1908.01349", "submitter": "Sainik Mahata", "authors": "Sainik Kumar Mahata, Avishek Garain, Adityar Rayala, Dipankar Das,\n  Sivaji Bandyopadhyay", "title": "JUMT at WMT2019 News Translation Task: A Hybrid approach to Machine\n  Translation for Lithuanian to English", "comments": "arXiv admin note: substantial text overlap with arXiv:1908.00323", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the current work, we present a description of the system submitted to WMT\n2019 News Translation Shared task. The system was created to translate news\ntext from Lithuanian to English. To accomplish the given task, our system used\na Word Embedding based Neural Machine Translation model to post edit the\noutputs generated by a Statistical Machine Translation model. The current paper\ndocuments the architecture of our model, descriptions of the various modules\nand the results produced using the same. Our system garnered a BLEU score of\n17.6.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 11:03:51 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Mahata", "Sainik Kumar", ""], ["Garain", "Avishek", ""], ["Rayala", "Adityar", ""], ["Das", "Dipankar", ""], ["Bandyopadhyay", "Sivaji", ""]]}, {"id": "1908.01355", "submitter": "Johan Bos", "authors": "Johan Bos", "title": "Separating Argument Structure from Logical Structure in AMR", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The AMR (Abstract Meaning Representation) formalism for representing meaning\nof natural language sentences was not designed to deal with scope and\nquantifiers. By extending AMR with indices for contexts and formulating\nconstraints on these contexts, a formalism is derived that makes correct\nprediction for inferences involving negation and bound variables. The\nattractive core predicate-argument structure of AMR is preserved. The resulting\nframework is similar to that of Discourse Representation Theory.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 14:46:35 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 14:54:01 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Bos", "Johan", ""]]}, {"id": "1908.01519", "submitter": "Momchil Hardalov", "authors": "Momchil Hardalov, Ivan Koychev, Preslav Nakov", "title": "Beyond English-Only Reading Comprehension: Experiments in Zero-Shot\n  Multilingual Transfer for Bulgarian", "comments": "Accepted at RANLP 2019 (13 pages, 2 figures, 6 tables)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, reading comprehension models achieved near-human performance on\nlarge-scale datasets such as SQuAD, CoQA, MS Macro, RACE, etc. This is largely\ndue to the release of pre-trained contextualized representations such as BERT\nand ELMo, which can be fine-tuned for the target task. Despite those advances\nand the creation of more challenging datasets, most of the work is still done\nfor English. Here, we study the effectiveness of multilingual BERT fine-tuned\non large-scale English datasets for reading comprehension (e.g., for RACE), and\nwe apply it to Bulgarian multiple-choice reading comprehension. We propose a\nnew dataset containing 2,221 questions from matriculation exams for twelfth\ngrade in various subjects -history, biology, geography and philosophy-, and 412\nadditional questions from online quizzes in history. While the quiz authors\ngave no relevant context, we incorporate knowledge from Wikipedia, retrieving\ndocuments matching the combination of question + each answer option. Moreover,\nwe experiment with different indexing and pre-training strategies. The\nevaluation results show accuracy of 42.23%, which is well above the baseline of\n24.89%.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 08:45:20 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 09:33:46 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Hardalov", "Momchil", ""], ["Koychev", "Ivan", ""], ["Nakov", "Preslav", ""]]}, {"id": "1908.01587", "submitter": "Amir Mosavi Prof", "authors": "Muhammad Zubair Asghar, Fazli Subhan, Muhammad Imran, Fazal Masud\n  Kundi, Shahboddin Shamshirband, Amir Mosavi, Peter Csiba, Annamaria R.\n  Varkonyi-Koczy", "title": "Performance Evaluation of Supervised Machine Learning Techniques for\n  Efficient Detection of Emotions from Online Content", "comments": "30 pages, 13 tables, 1 figure", "journal-ref": null, "doi": "10.20944/preprints201908.0019.v1", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Emotion detection from the text is an important and challenging problem in\ntext analytics. The opinion-mining experts are focusing on the development of\nemotion detection applications as they have received considerable attention of\nonline community including users and business organization for collecting and\ninterpreting public emotions. However, most of the existing works on emotion\ndetection used less efficient machine learning classifiers with limited\ndatasets, resulting in performance degradation. To overcome this issue, this\nwork aims at the evaluation of the performance of different machine learning\nclassifiers on a benchmark emotion dataset. The experimental results show the\nperformance of different machine learning classifiers in terms of different\nevaluation metrics like precision, recall ad f-measure. Finally, a classifier\nwith the best performance is recommended for the emotion classification.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 16:48:22 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Asghar", "Muhammad Zubair", ""], ["Subhan", "Fazli", ""], ["Imran", "Muhammad", ""], ["Kundi", "Fazal Masud", ""], ["Shamshirband", "Shahboddin", ""], ["Mosavi", "Amir", ""], ["Csiba", "Peter", ""], ["Varkonyi-Koczy", "Annamaria R.", ""]]}, {"id": "1908.01665", "submitter": "Zixiu Wu", "authors": "Zixiu Wu, Julia Ive, Josiah Wang, Pranava Madhyastha, Lucia Specia", "title": "Predicting Actions to Help Predict Translations", "comments": "Accepted to workshop \"The How2 Challenge: New Tasks for Vision &\n  Language\" of International Conference on Machine Learning 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the task of text translation on the How2 dataset using a state of\nthe art transformer-based multimodal approach. The question we ask ourselves is\nwhether visual features can support the translation process, in particular,\ngiven that this is a dataset extracted from videos, we focus on the translation\nof actions, which we believe are poorly captured in current static image-text\ndatasets currently used for multimodal translation. For that purpose, we\nextract different types of action features from the videos and carefully\ninvestigate how helpful this visual information is by testing whether it can\nincrease translation quality when used in conjunction with (i) the original\ntext and (ii) the original text where action-related words (or all verbs) are\nmasked out. The latter is a simulation that helps us assess the utility of the\nimage in cases where the text does not provide enough context about the action,\nor in the presence of noise in the input text.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 14:56:01 GMT"}, {"version": "v2", "created": "Sun, 18 Aug 2019 23:57:01 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Wu", "Zixiu", ""], ["Ive", "Julia", ""], ["Wang", "Josiah", ""], ["Madhyastha", "Pranava", ""], ["Specia", "Lucia", ""]]}, {"id": "1908.01674", "submitter": "Diogo Gomes", "authors": "Diogo Gomes, Alexandre Evsukoff", "title": "Processamento de linguagem natural em Portugu\\^es e aprendizagem\n  profunda para o dom\\'inio de \\'Oleo e G\\'as", "comments": "25 pages, in Portuguese. V2: added Evsukoff as co-author, mistakenly\n  omitted in the previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last few decades, institutions around the world have been challenged\nto deal with the sheer volume of information captured in unstructured formats,\nespecially in textual documents. The so called Digital Transformation age,\ncharacterized by important technological advances and the advent of disruptive\nmethods in Artificial Intelligence, offers opportunities to make better use of\nthis information. Recent techniques in Natural Language Processing (NLP) with\nDeep Learning approaches allow to efficiently process a large volume of data in\norder to obtain relevant information, to identify patterns, classify text,\namong other applications. In this context, the highly technical vocabulary of\nOil and Gas (O&G) domain represents a challenge for these NLP algorithms, in\nwhich terms can assume a very different meaning in relation to common sense\nunderstanding. The search for suitable mathematical representations and\nspecific models requires a large amount of representative corpora in the O&G\ndomain. However, public access to this material is scarce in the scientific\nliterature, especially considering the Portuguese language. This paper presents\na literature review about the main techniques for deep learning NLP and their\nmajor applications for O&G domain in Portuguese.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 15:05:48 GMT"}, {"version": "v2", "created": "Sat, 10 Aug 2019 13:46:25 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Gomes", "Diogo", ""], ["Evsukoff", "Alexandre", ""]]}, {"id": "1908.01699", "submitter": "David Awad", "authors": "David Awad", "title": "Thoth: Improved Rapid Serial Visual Presentation using Natural Language\n  Processing", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thoth is a tool designed to combine many different types of speed reading\ntechnology. The largest insight is using natural language parsing for more\noptimal rapid serial visual presentation and more effective reading\ninformation.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 15:45:39 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Awad", "David", ""]]}, {"id": "1908.01761", "submitter": "Shengbin Jia", "authors": "Shengbin Jia, Yang Xiang", "title": "Hybrid Neural Tagging Model for Open Relation Extraction", "comments": "arXiv admin note: substantial text overlap with arXiv:1809.09408", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open relation extraction (ORE) remains a challenge to obtain a semantic\nrepresentation by discovering arbitrary relation tuples from the unstructured\ntext. Conventional methods heavily depend on feature engineering or syntactic\nparsing, they are inefficient or error-cascading. Recently, leveraging\nsupervised deep learning structures to address the ORE task is an\nextraordinarily promising way. However, there are two main challenges: (1) The\nlack of enough labeled corpus to support supervised training; (2) The\nexploration of specific neural architecture that adapts to the characteristics\nof open relation extracting. In this paper, to overcome these difficulties, we\nbuild a large-scale, high-quality training corpus in a fully automated way, and\ndesign a tagging scheme to assist in transforming the ORE task into a sequence\ntagging processing. Furthermore, we propose a hybrid neural network model\n(HNN4ORT) for open relation tagging. The model employs the Ordered Neurons LSTM\nto encode potential syntactic information for capturing the associations among\nthe arguments and relations. It also emerges a novel Dual Aware Mechanism,\nincluding Local-aware Attention and Global-aware Convolution. The dual aware\nnesses complement each other so that the model can take the sentence-level\nsemantics as a global perspective, and at the same time implement salient local\nfeatures to achieve sparse annotation. Experimental results on various testing\nsets show that our model can achieve state-of-the-art performances compared to\nthe conventional methods or other neural models.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 11:29:37 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 08:47:24 GMT"}, {"version": "v3", "created": "Thu, 13 Feb 2020 08:59:31 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Jia", "Shengbin", ""], ["Xiang", "Yang", ""]]}, {"id": "1908.01765", "submitter": "Joseph Marvin Imperial", "authors": "Joseph Marvin Imperial, Jeyrome Orosco, Shiela Mae Mazo, Lany Maceda", "title": "Sentiment Analysis of Typhoon Related Tweets using Standard and\n  Bidirectional Recurrent Neural Networks", "comments": "5 figures, 2 tables, presented at the 14th National Natural Language\n  Processing Research Symposium - Student Research Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Philippines is a common ground to natural calamities like typhoons,\nfloods, volcanic eruptions and earthquakes. With Twitter as one of the most\nused social media platform in the Philippines, a total of 39,867 preprocessed\ntweets were obtained given a time frame starting from November 1, 2013 to\nJanuary 31, 2014. Sentiment analysis determines the underlying emotion given a\nseries of words. The main purpose of this study is to identify the sentiments\nexpressed in the tweets sent by the Filipino people before, during, and after\nTyphoon Yolanda using two variations of Recurrent Neural Networks; standard and\nbidirectional. The best generated models after training with various\nhyperparameters achieved a high accuracy of 81.79% for fine-grained\nclassification using standard RNN and 87.69% for binary classification using\nbidirectional RNN. Findings revealed that 51.1% of the tweets sent were\npositive expressing support, love, and words of courage to the victims; 19.8%\nwere negative stating sadness and despair for the loss of lives and hate for\ncorrupt officials; while the other 29% were neutral tweets from local news\nstations, announcements of relief operations, donation drives, and observations\nby citizens.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 23:48:05 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Imperial", "Joseph Marvin", ""], ["Orosco", "Jeyrome", ""], ["Mazo", "Shiela Mae", ""], ["Maceda", "Lany", ""]]}, {"id": "1908.01767", "submitter": "Suhas Gupta", "authors": "Suhas Gupta", "title": "Exploring Neural Net Augmentation to BERT for Question Answering on\n  SQUAD 2.0", "comments": "Code bug found", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enhancing machine capabilities to answer questions has been a topic of\nconsiderable focus in recent years of NLP research. Language models like\nEmbeddings from Language Models (ELMo)[1] and Bidirectional Encoder\nRepresentations from Transformers (BERT) [2] have been very successful in\ndeveloping general purpose language models that can be optimized for a large\nnumber of downstream language tasks. In this work, we focused on augmenting the\npre-trained BERT language model with different output neural net architectures\nand compared their performance on question answering task posed by the Stanford\nQuestion Answering Dataset 2.0 (SQUAD 2.0) [3]. Additionally, we also\nfine-tuned the pre-trained BERT model parameters to demonstrate its\neffectiveness in adapting to specialized language tasks. Our best output\nnetwork, is the contextualized CNN that performs on both the unanswerable and\nanswerable question answering tasks with F1 scores of 75.32 and 64.85\nrespectively.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 16:48:24 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 03:21:33 GMT"}, {"version": "v3", "created": "Sun, 8 Mar 2020 23:10:16 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Gupta", "Suhas", ""]]}, {"id": "1908.01798", "submitter": "Dar\\'io Garigliotti", "authors": "Dar\\'io Garigliotti and Dyaa Albakour and Miguel Martinez and\n  Krisztian Balog", "title": "Unsupervised Context Retrieval for Long-tail Entities", "comments": "Proceedings of the 2019 ACM International Conference on Theory of\n  Information Retrieval (ICTIR' 19)", "journal-ref": null, "doi": "10.1145/3341981.3344244", "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring entities in media streams often relies on rich entity\nrepresentations, like structured information available in a knowledge base\n(KB). For long-tail entities, such monitoring is highly challenging, due to\ntheir limited, if not entirely missing, representation in the reference KB. In\nthis paper, we address the problem of retrieving textual contexts for\nmonitoring long-tail entities. We propose an unsupervised method to overcome\nthe limited representation of long-tail entities by leveraging established\nentities and their contexts as support information. Evaluation on a\npurpose-built test collection shows the suitability of our approach and its\nrobustness for out-of-KB entities.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 18:28:09 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Garigliotti", "Dar\u00edo", ""], ["Albakour", "Dyaa", ""], ["Martinez", "Miguel", ""], ["Balog", "Krisztian", ""]]}, {"id": "1908.01801", "submitter": "Kushal Kafle", "authors": "Kushal Kafle, Robik Shrestha, Brian Price, Scott Cohen, Christopher\n  Kanan", "title": "Answering Questions about Data Visualizations using Efficient Bimodal\n  Fusion", "comments": "Presented at WACV, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chart question answering (CQA) is a newly proposed visual question answering\n(VQA) task where an algorithm must answer questions about data visualizations,\ne.g. bar charts, pie charts, and line graphs. CQA requires capabilities that\nnatural-image VQA algorithms lack: fine-grained measurements, optical character\nrecognition, and handling out-of-vocabulary words in both questions and\nanswers. Without modifications, state-of-the-art VQA algorithms perform poorly\non this task. Here, we propose a novel CQA algorithm called parallel recurrent\nfusion of image and language (PReFIL). PReFIL first learns bimodal embeddings\nby fusing question and image features and then intelligently aggregates these\nlearned embeddings to answer the given question. Despite its simplicity, PReFIL\ngreatly surpasses state-of-the art systems and human baselines on both the\nFigureQA and DVQA datasets. Additionally, we demonstrate that PReFIL can be\nused to reconstruct tables by asking a series of questions about a chart.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 18:47:30 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 15:10:29 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Kafle", "Kushal", ""], ["Shrestha", "Robik", ""], ["Price", "Brian", ""], ["Cohen", "Scott", ""], ["Kanan", "Christopher", ""]]}, {"id": "1908.01815", "submitter": "Taha Shangipour Ataei", "authors": "Taha Shangipour Ataei, Kamyar Darvishi, Soroush Javdan, Behrouz\n  Minaei-Bidgoli, Sauleh Eetemadi", "title": "Pars-ABSA: an Aspect-based Sentiment Analysis dataset for Persian", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the increased availability of online reviews, sentiment analysis had\nbeen witnessed a booming interest from the researchers. Sentiment analysis is a\ncomputational treatment of sentiment used to extract and understand the\nopinions of authors. While many systems were built to predict the sentiment of\na document or a sentence, many others provide the necessary detail on various\naspects of the entity (i.e. aspect-based sentiment analysis). Most of the\navailable data resources were tailored to English and the other popular\nEuropean languages. Although Persian is a language with more than 110 million\nspeakers, to the best of our knowledge, there is a lack of public dataset on\naspect-based sentiment analysis for Persian. This paper provides a manually\nannotated Persian dataset, Pars-ABSA, which is verified by 3 native Persian\nspeakers. The dataset consists of 5,114 positive, 3,061 negative and 1,827\nneutral data samples from 5,602 unique reviews. Moreover, as a baseline, this\npaper reports the performance of some state-of-the-art aspect-based sentiment\nanalysis methods with a focus on deep learning, on Pars-ABSA. The obtained\nresults are impressive compared to similar English state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 16:19:07 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 08:09:31 GMT"}, {"version": "v3", "created": "Wed, 11 Dec 2019 14:35:42 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Ataei", "Taha Shangipour", ""], ["Darvishi", "Kamyar", ""], ["Javdan", "Soroush", ""], ["Minaei-Bidgoli", "Behrouz", ""], ["Eetemadi", "Sauleh", ""]]}, {"id": "1908.01816", "submitter": "Boyuan Pan", "authors": "Boyuan Pan, Yazheng Yang, Hao Li, Zhou Zhao, Yueting Zhuang, Deng Cai,\n  Xiaofei He", "title": "MacNet: Transferring Knowledge from Machine Comprehension to\n  Sequence-to-Sequence Models", "comments": "Accepted In NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Comprehension (MC) is one of the core problems in natural language\nprocessing, requiring both understanding of the natural language and knowledge\nabout the world. Rapid progress has been made since the release of several\nbenchmark datasets, and recently the state-of-the-art models even surpass human\nperformance on the well-known SQuAD evaluation. In this paper, we transfer\nknowledge learned from machine comprehension to the sequence-to-sequence tasks\nto deepen the understanding of the text. We propose MacNet: a novel\nencoder-decoder supplementary architecture to the widely used attention-based\nsequence-to-sequence models. Experiments on neural machine translation (NMT)\nand abstractive text summarization show that our proposed framework can\nsignificantly improve the performance of the baseline models, and our method\nfor the abstractive text summarization achieves the state-of-the-art results on\nthe Gigaword dataset.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 04:38:09 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Pan", "Boyuan", ""], ["Yang", "Yazheng", ""], ["Li", "Hao", ""], ["Zhao", "Zhou", ""], ["Zhuang", "Yueting", ""], ["Cai", "Deng", ""], ["He", "Xiaofei", ""]]}, {"id": "1908.01817", "submitter": "Naomi Saphra", "authors": "Naomi Saphra, Adam Lopez", "title": "Sparsity Emerges Naturally in Neural Language Models", "comments": "Published in the ICML 2019 Workshop on Identifying and Understanding\n  Deep Learning Phenomena: https://openreview.net/forum?id=H1ets1h56E", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Concerns about interpretability, computational resources, and principled\ninductive priors have motivated efforts to engineer sparse neural models for\nNLP tasks. If sparsity is important for NLP, might well-trained neural models\nnaturally become roughly sparse? Using the Taxi-Euclidean norm to measure\nsparsity, we find that frequent input words are associated with concentrated or\nsparse activations, while frequent target words are associated with dispersed\nactivations but concentrated gradients. We find that gradients associated with\nfunction words are more concentrated than the gradients of content words, even\ncontrolling for word frequency.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 14:06:15 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Saphra", "Naomi", ""], ["Lopez", "Adam", ""]]}, {"id": "1908.01819", "submitter": "Andrea Zugarini", "authors": "Giuseppe Marra and Andrea Zugarini and Stefano Melacci and Marco\n  Maggini", "title": "An Unsupervised Character-Aware Neural Approach to Word and Context\n  Representation Learning", "comments": null, "journal-ref": "Lecture Notes in Computer Science, vol 11141. Springer, Cham 2018", "doi": "10.1007/978-3-030-01424-7_13", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years, neural networks have been intensively used to develop\nmeaningful distributed representations of words and contexts around them. When\nthese representations, also known as \"embeddings\", are learned from\nunsupervised large corpora, they can be transferred to different tasks with\npositive effects in terms of performances, especially when only a few\nsupervisions are available. In this work, we further extend this concept, and\nwe present an unsupervised neural architecture that jointly learns word and\ncontext embeddings, processing words as sequences of characters. This allows\nour model to spot the regularities that are due to the word morphology, and to\navoid the need of a fixed-sized input vocabulary of words. We show that we can\nlearn compact encoders that, despite the relatively small number of parameters,\nreach high-level performances in downstream tasks, comparing them with related\nstate-of-the-art approaches or with fully supervised methods.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 09:34:11 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Marra", "Giuseppe", ""], ["Zugarini", "Andrea", ""], ["Melacci", "Stefano", ""], ["Maggini", "Marco", ""]]}, {"id": "1908.01821", "submitter": "Ozan \\.Irsoy", "authors": "Ozan \\.Irsoy, Rakesh Gosangi, Haimin Zhang, Mu-Hsin Wei, Peter Lund,\n  Duccio Pappadopulo, Brendan Fahy, Neophytos Nephytou, Camilo Ortiz", "title": "Dialogue Act Classification in Group Chats with DAG-LSTMs", "comments": "Appeared in SIGIR 2019 Workshop on Conversational Interaction Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue act (DA) classification has been studied for the past two decades\nand has several key applications such as workflow automation and conversation\nanalytics. Researchers have used, to address this problem, various traditional\nmachine learning models, and more recently deep neural network models such as\nhierarchical convolutional neural networks (CNNs) and long short-term memory\n(LSTM) networks. In this paper, we introduce a new model architecture,\ndirected-acyclic-graph LSTM (DAG-LSTM) for DA classification. A DAG-LSTM\nexploits the turn-taking structure naturally present in a multi-party\nconversation, and encodes this relation in its model structure. Using the STAC\ncorpus, we show that the proposed method performs roughly 0.8% better in\naccuracy and 1.2% better in macro-F1 score when compared to existing methods.\nThe proposed method is generic and not limited to conversation applications.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 17:12:38 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["\u0130rsoy", "Ozan", ""], ["Gosangi", "Rakesh", ""], ["Zhang", "Haimin", ""], ["Wei", "Mu-Hsin", ""], ["Lund", "Peter", ""], ["Pappadopulo", "Duccio", ""], ["Fahy", "Brendan", ""], ["Nephytou", "Neophytos", ""], ["Ortiz", "Camilo", ""]]}, {"id": "1908.01832", "submitter": "Bilge Sipal", "authors": "Bilge Sipal, Ozcan Sari, Asena Teke, Nurullah Demirci", "title": "Word Sense Disambiguation using Diffusion Kernel PCA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major problems in natural language processing (NLP) is the word\nsense disambiguation (WSD) problem. It is the task of computationally\nidentifying the right sense of a polysemous word based on its context.\nResolving the WSD problem boosts the accuracy of many NLP focused algorithms\nsuch as text classification and machine translation. In this paper, we\nintroduce a new supervised algorithm for WSD, that is based on Kernel PCA and\nSemantic Diffusion Kernel, which is called Diffusion Kernel PCA (DKPCA). DKPCA\ngrasps the semantic similarities within terms, and it is based on PCA. These\nproperties enable us to perform feature extraction and dimension reduction\nguided by semantic similarities and within the algorithm. Our empirical results\non SensEval data demonstrate that DKPCA achieves higher or very close accuracy\nresults compared to SVM and KPCA with various well-known kernels when the\nlabeled data ratio is meager. Considering the scarcity of labeled data, whereas\nlarge quantities of unlabeled textual data are easily accessible, these are\nhighly encouraging first results to develop DKPCA further.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 07:16:55 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Sipal", "Bilge", ""], ["Sari", "Ozcan", ""], ["Teke", "Asena", ""], ["Demirci", "Nurullah", ""]]}, {"id": "1908.01837", "submitter": "Chenwei Zhang", "authors": "Chenwei Zhang", "title": "Structured Knowledge Discovery from Massive Text Corpus", "comments": "PhD Thesis, University of Illinois at Chicago, July 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, with the booming development of the Internet, people benefit from\nits convenience due to its open and sharing nature. A large volume of natural\nlanguage texts is being generated by users in various forms, such as search\nqueries, documents, and social media posts. As the unstructured text corpus is\nusually noisy and messy, it becomes imperative to correctly identify and\naccurately annotate structured information in order to obtain meaningful\ninsights or better understand unstructured texts. On the other hand, the\nexisting structured information, which embodies our knowledge such as entity or\nconcept relations, often suffers from incompleteness or quality-related issues.\nGiven a gigantic collection of texts which offers rich semantic information, it\nis also important to harness the massiveness of the unannotated text corpus to\nexpand and refine existing structured knowledge with fewer annotation efforts.\n  In this dissertation, I will introduce principles, models, and algorithms for\neffective structured knowledge discovery from the massive text corpus. We are\ngenerally interested in obtaining insights and better understanding\nunstructured texts with the help of structured annotations or by\nstructure-aware modeling. Also, given the existing structured knowledge, we are\ninterested in expanding its scale and improving its quality harnessing the\nmassiveness of the text corpus. In particular, four problems are studied in\nthis dissertation: Structured Intent Detection for Natural Language\nUnderstanding, Structure-aware Natural Language Modeling, Generative Structured\nKnowledge Expansion, and Synonym Refinement on Structured Knowledge.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 20:45:41 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Zhang", "Chenwei", ""]]}, {"id": "1908.01839", "submitter": "Ping Wang", "authors": "Ping Wang, Tian Shi, Chandan K. Reddy", "title": "Text-to-SQL Generation for Question Answering on Electronic Medical\n  Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic medical records (EMR) contain comprehensive patient information\nand are typically stored in a relational database with multiple tables.\nEffective and efficient patient information retrieval from EMR data is a\nchallenging task for medical experts. Question-to-SQL generation methods tackle\nthis problem by first predicting the SQL query for a given question about a\ndatabase, and then, executing the query on the database. However, most of the\nexisting approaches have not been adapted to the healthcare domain due to a\nlack of healthcare Question-to-SQL dataset for learning models specific to this\ndomain. In addition, wide use of the abbreviation of terminologies and possible\ntypos in questions introduce additional challenges for accurately generating\nthe corresponding SQL queries. In this paper, we tackle these challenges by\ndeveloping a deep learning based TRanslate-Edit Model for Question-to-SQL\n(TREQS) generation, which adapts the widely used sequence-to-sequence model to\ndirectly generate the SQL query for a given question, and further performs the\nrequired edits using an attentive-copying mechanism and task-specific look-up\ntables. Based on the widely used publicly available electronic medical\ndatabase, we create a new large-scale Question-SQL pair dataset, named\nMIMICSQL, in order to perform the Question-to-SQL generation task in healthcare\ndomain. An extensive set of experiments are conducted to evaluate the\nperformance of our proposed model on MIMICSQL. Both quantitative and\nqualitative experimental results indicate the flexibility and efficiency of our\nproposed method in predicting condition values and its robustness to random\nquestions with abbreviations and typos.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 21:04:05 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 04:20:44 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Wang", "Ping", ""], ["Shi", "Tian", ""], ["Reddy", "Chandan K.", ""]]}, {"id": "1908.01841", "submitter": "Oluwatobi Olabiyi", "authors": "Oluwatobi Olabiyi and Erik T. Mueller", "title": "DLGNet: A Transformer-based Model for Dialogue Response Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Neural dialogue models, despite their successes, still suffer from lack of\nrelevance, diversity, and in many cases coherence in their generated responses.\nThese issues can attributed to reasons including (1) short-range model\narchitectures that capture limited temporal dependencies, (2) limitations of\nthe maximum likelihood training objective, (3) the concave entropy profile of\ndialogue datasets resulting in short and generic responses, and (4) the\nout-of-vocabulary problem leading to generation of a large number of <UNK>\ntokens. On the other hand, transformer-based models such as GPT-2 have\ndemonstrated an excellent ability to capture long-range structures in language\nmodeling tasks. In this paper, we present DLGNet, a transformer-based model for\ndialogue modeling. We specifically examine the use of DLGNet for multi-turn\ndialogue response generation. In our experiments, we evaluate DLGNet on the\nopen-domain Movie Triples dataset and the closed-domain Ubuntu Dialogue\ndataset. DLGNet models, although trained with only the maximum likelihood\nobjective, achieve significant improvements over state-of-the-art multi-turn\ndialogue models. They also produce best performance to date on the two datasets\nbased on several metrics, including BLEU, ROUGE, and distinct n-gram. Our\nanalysis shows that the performance improvement is mostly due to the\ncombination of (1) the long-range transformer architecture with (2) the\ninjection of random informative paddings. Other contributing factors include\nthe joint modeling of dialogue context and response, and the 100% tokenization\ncoverage from the byte pair encoding (BPE).\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 21:53:09 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 23:08:10 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Olabiyi", "Oluwatobi", ""], ["Mueller", "Erik T.", ""]]}, {"id": "1908.01843", "submitter": "Jie Zhou", "authors": "Jie Zhou, Xu Han, Cheng Yang, Zhiyuan Liu, Lifeng Wang, Changcheng Li,\n  Maosong Sun", "title": "GEAR: Graph-based Evidence Aggregating and Reasoning for Fact\n  Verification", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fact verification (FV) is a challenging task which requires to retrieve\nrelevant evidence from plain text and use the evidence to verify given claims.\nMany claims require to simultaneously integrate and reason over several pieces\nof evidence for verification. However, previous work employs simple models to\nextract information from evidence without letting evidence communicate with\neach other, e.g., merely concatenate the evidence for processing. Therefore,\nthese methods are unable to grasp sufficient relational and logical information\namong the evidence. To alleviate this issue, we propose a graph-based evidence\naggregating and reasoning (GEAR) framework which enables information to\ntransfer on a fully-connected evidence graph and then utilizes different\naggregators to collect multi-evidence information. We further employ BERT, an\neffective pre-trained language representation model, to improve the\nperformance. Experimental results on a large-scale benchmark dataset FEVER have\ndemonstrated that GEAR could leverage multi-evidence information for FV and\nthus achieves the promising result with a test FEVER score of 67.10%. Our code\nis available at https://github.com/thunlp/GEAR.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 08:25:16 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Zhou", "Jie", ""], ["Han", "Xu", ""], ["Yang", "Cheng", ""], ["Liu", "Zhiyuan", ""], ["Wang", "Lifeng", ""], ["Li", "Changcheng", ""], ["Sun", "Maosong", ""]]}, {"id": "1908.01851", "submitter": "Sangchul Hahn", "authors": "Sangchul Hahn and Heeyoul Choi", "title": "Self-Knowledge Distillation in Natural Language Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since deep learning became a key player in natural language processing (NLP),\nmany deep learning models have been showing remarkable performances in a\nvariety of NLP tasks, and in some cases, they are even outperforming humans.\nSuch high performance can be explained by efficient knowledge representation of\ndeep learning models. While many methods have been proposed to learn more\nefficient representation, knowledge distillation from pretrained deep networks\nsuggest that we can use more information from the soft target probability to\ntrain other neural networks. In this paper, we propose a new knowledge\ndistillation method self-knowledge distillation, based on the soft target\nprobabilities of the training model itself, where multimode information is\ndistilled from the word embedding space right below the softmax layer. Due to\nthe time complexity, our method approximates the soft target probabilities. In\nexperiments, we applied the proposed method to two different and fundamental\nNLP tasks: language model and neural machine translation. The experiment\nresults show that our proposed method improves performance on the tasks.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 15:17:27 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Hahn", "Sangchul", ""], ["Choi", "Heeyoul", ""]]}, {"id": "1908.01853", "submitter": "Kun Han", "authors": "Kun Han, Junwen Chen, Hui Zhang, Haiyang Xu, Yiping Peng, Yun Wang,\n  Ning Ding, Hui Deng, Yonghu Gao, Tingwei Guo, Yi Zhang, Yahao He, Baochang\n  Ma, Yulong Zhou, Kangli Zhang, Chao Liu, Ying Lyu, Chenxi Wang, Cheng Gong,\n  Yunbo Wang, Wei Zou, Hui Song, and Xiangang Li", "title": "DELTA: A DEep learning based Language Technology plAtform", "comments": "White paper for an open source library:\n  https://github.com/didi/delta. 13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present DELTA, a deep learning based language technology\nplatform. DELTA is an end-to-end platform designed to solve industry level\nnatural language and speech processing problems. It integrates most popular\nneural network models for training as well as comprehensive deployment tools\nfor production. DELTA aims to provide easy and fast experiences for using,\ndeploying, and developing natural language processing and speech models for\nboth academia and industry use cases. We demonstrate the reliable performance\nwith DELTA on several natural language processing and speech tasks, including\ntext classification, named entity recognition, natural language inference,\nspeech recognition, speaker verification, etc. DELTA has been used for\ndeveloping several state-of-the-art algorithms for publications and delivering\nreal production to serve millions of users.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 01:13:50 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Han", "Kun", ""], ["Chen", "Junwen", ""], ["Zhang", "Hui", ""], ["Xu", "Haiyang", ""], ["Peng", "Yiping", ""], ["Wang", "Yun", ""], ["Ding", "Ning", ""], ["Deng", "Hui", ""], ["Gao", "Yonghu", ""], ["Guo", "Tingwei", ""], ["Zhang", "Yi", ""], ["He", "Yahao", ""], ["Ma", "Baochang", ""], ["Zhou", "Yulong", ""], ["Zhang", "Kangli", ""], ["Liu", "Chao", ""], ["Lyu", "Ying", ""], ["Wang", "Chenxi", ""], ["Gong", "Cheng", ""], ["Wang", "Yunbo", ""], ["Zou", "Wei", ""], ["Song", "Hui", ""], ["Li", "Xiangang", ""]]}, {"id": "1908.01946", "submitter": "Shuyang Gao", "authors": "Shuyang Gao, Abhishek Sethi, Sanchit Agarwal, Tagyoung Chung, Dilek\n  Hakkani-Tur", "title": "Dialog State Tracking: A Neural Reading Comprehension Approach", "comments": "10 pages, to appear in Special Interest Group on Discourse and\n  Dialogue (SIGDIAL) 2019 (ORAL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialog state tracking is used to estimate the current belief state of a\ndialog given all the preceding conversation. Machine reading comprehension, on\nthe other hand, focuses on building systems that read passages of text and\nanswer questions that require some understanding of passages. We formulate\ndialog state tracking as a reading comprehension task to answer the question\n$what\\ is\\ the\\ state\\ of\\ the\\ current\\ dialog?$ after reading conversational\ncontext. In contrast to traditional state tracking methods where the dialog\nstate is often predicted as a distribution over a closed set of all the\npossible slot values within an ontology, our method uses a simple\nattention-based neural network to point to the slot values within the\nconversation. Experiments on MultiWOZ-2.0 cross-domain dialog dataset show that\nour simple system can obtain similar accuracies compared to the previous more\ncomplex methods. By exploiting recent advances in contextual word embeddings,\nadding a model that explicitly tracks whether a slot value should be carried\nover to the next turn, and combining our method with a traditional joint state\ntracking method that relies on closed set vocabulary, we can obtain a\njoint-goal accuracy of $47.33\\%$ on the standard test split, exceeding current\nstate-of-the-art by $11.75\\%$**.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 04:01:42 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 01:21:21 GMT"}, {"version": "v3", "created": "Thu, 15 Aug 2019 01:37:56 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Gao", "Shuyang", ""], ["Sethi", "Abhishek", ""], ["Agarwal", "Sanchit", ""], ["Chung", "Tagyoung", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "1908.01968", "submitter": "Shen Li", "authors": "Shen Li, Chenhao Su, Renfen Hu, Zhengdong Lu", "title": "Self-Balanced Dropout", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout is known as an effective way to reduce overfitting via preventing\nco-adaptations of units. In this paper, we theoretically prove that the\nco-adaptation problem still exists after using dropout due to the correlations\namong the inputs. Based on the proof, we further propose Self-Balanced Dropout,\na novel dropout method which uses a trainable variable to balance the influence\nof the input correlation on parameter update. We evaluate Self-Balanced Dropout\non a range of tasks with both simple and complex models. The experimental\nresults show that the mechanism can effectively solve the co-adaption problem\nto some extent and significantly improve the performance on all tasks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 05:57:22 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Li", "Shen", ""], ["Su", "Chenhao", ""], ["Hu", "Renfen", ""], ["Lu", "Zhengdong", ""]]}, {"id": "1908.01969", "submitter": "Haoran Zhang", "authors": "Haoran Zhang and Diane Litman", "title": "Word Embedding for Response-To-Text Assessment of Evidence", "comments": "Published in the ACL 2017, Student Research Workshop", "journal-ref": "Proceedings of ACL 2017, Student Research Workshop (2017) 75-81", "doi": "10.18653/v1/P17-3013", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manually grading the Response to Text Assessment (RTA) is labor intensive.\nTherefore, an automatic method is being developed for scoring analytical\nwriting when the RTA is administered in large numbers of classrooms. Our\nlong-term goal is to also use this scoring method to provide formative feedback\nto students and teachers about students' writing quality. As a first step\ntowards this goal, interpretable features for automatically scoring the\nevidence rubric of the RTA have been developed. In this paper, we present a\nsimple but promising method for improving evidence scoring by employing the\nword embedding model. We evaluate our method on corpora of responses written by\nupper elementary students.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 05:58:06 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Zhang", "Haoran", ""], ["Litman", "Diane", ""]]}, {"id": "1908.01992", "submitter": "Haoran Zhang", "authors": "Haoran Zhang, Ahmed Magooda, Diane Litman, Richard Correnti, Elaine\n  Wang, Lindsay Clare Matsumura, Emily Howe, Rafael Quintana", "title": "eRevise: Using Natural Language Processing to Provide Formative Feedback\n  on Text Evidence Usage in Student Writing", "comments": "Published in IAAI 19", "journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence\n  (2019) vol. 33, 9619-9625", "doi": "10.1609/aaai.v33i01.33019619", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Writing a good essay typically involves students revising an initial paper\ndraft after receiving feedback. We present eRevise, a web-based writing and\nrevising environment that uses natural language processing features generated\nfor rubric-based essay scoring to trigger formative feedback messages regarding\nstudents' use of evidence in response-to-text writing. By helping students\nunderstand the criteria for using text evidence during writing, eRevise\nempowers students to better revise their paper drafts. In a pilot deployment of\neRevise in 7 classrooms spanning grades 5 and 6, the quality of text evidence\nusage in writing improved after students received formative feedback then\nengaged in paper revision.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 07:24:14 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Zhang", "Haoran", ""], ["Magooda", "Ahmed", ""], ["Litman", "Diane", ""], ["Correnti", "Richard", ""], ["Wang", "Elaine", ""], ["Matsumura", "Lindsay Clare", ""], ["Howe", "Emily", ""], ["Quintana", "Rafael", ""]]}, {"id": "1908.01993", "submitter": "Haoran Zhang", "authors": "Haoran Zhang and Diane Litman", "title": "Co-Attention Based Neural Network for Source-Dependent Essay Scoring", "comments": "Published in BEA 13 workshop", "journal-ref": "Proceedings of the Thirteenth Workshop on Innovative Use of NLP\n  for Building Educational Applications (2018) 399-409", "doi": "10.18653/v1/W18-0549", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an investigation of using a co-attention based neural\nnetwork for source-dependent essay scoring. We use a co-attention mechanism to\nhelp the model learn the importance of each part of the essay more accurately.\nAlso, this paper shows that the co-attention based neural network model\nprovides reliable score prediction of source-dependent responses. We evaluate\nour model on two source-dependent response corpora. Results show that our model\noutperforms the baseline on both corpora. We also show that the attention of\nthe model is similar to the expert opinions with examples.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 07:28:43 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Zhang", "Haoran", ""], ["Litman", "Diane", ""]]}, {"id": "1908.02127", "submitter": "Longteng Guo", "authors": "Longteng Guo, Jing Liu, Jinhui Tang, Jiangwei Li, Wei Luo, Hanqing Lu", "title": "Aligning Linguistic Words and Visual Semantic Units for Image Captioning", "comments": "8 pages, 5 figures. Accepted by ACM MM 2019", "journal-ref": null, "doi": "10.1145/3343031.3350943", "report-no": null, "categories": "cs.CV cs.CL cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image captioning attempts to generate a sentence composed of several\nlinguistic words, which are used to describe objects, attributes, and\ninteractions in an image, denoted as visual semantic units in this paper. Based\non this view, we propose to explicitly model the object interactions in\nsemantics and geometry based on Graph Convolutional Networks (GCNs), and fully\nexploit the alignment between linguistic words and visual semantic units for\nimage captioning. Particularly, we construct a semantic graph and a geometry\ngraph, where each node corresponds to a visual semantic unit, i.e., an object,\nan attribute, or a semantic (geometrical) interaction between two objects.\nAccordingly, the semantic (geometrical) context-aware embeddings for each unit\nare obtained through the corresponding GCN learning processers. At each time\nstep, a context gated attention module takes as inputs the embeddings of the\nvisual semantic units and hierarchically align the current word with these\nunits by first deciding which type of visual semantic unit (object, attribute,\nor interaction) the current word is about, and then finding the most correlated\nvisual semantic units under this type. Extensive experiments are conducted on\nthe challenging MS-COCO image captioning dataset, and superior results are\nreported when comparing to state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 13:19:24 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Guo", "Longteng", ""], ["Liu", "Jing", ""], ["Tang", "Jinhui", ""], ["Li", "Jiangwei", ""], ["Luo", "Wei", ""], ["Lu", "Hanqing", ""]]}, {"id": "1908.02262", "submitter": "Aarne Talman", "authors": "Aarne Talman, Antti Suni, Hande Celikkanat, Sofoklis Kakouros, J\\\"org\n  Tiedemann, Martti Vainio", "title": "Predicting Prosodic Prominence from Text with Pre-trained Contextualized\n  Word Representations", "comments": "NoDaLiDa 2019 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a new natural language processing dataset and\nbenchmark for predicting prosodic prominence from written text. To our\nknowledge this will be the largest publicly available dataset with prosodic\nlabels. We describe the dataset construction and the resulting benchmark\ndataset in detail and train a number of different models ranging from\nfeature-based classifiers to neural network systems for the prediction of\ndiscretized prosodic prominence. We show that pre-trained contextualized word\nrepresentations from BERT outperform the other models even with less than 10%\nof the training data. Finally we discuss the dataset in light of the results\nand point to future research and plans for further improving both the dataset\nand methods of predicting prosodic prominence from text. The dataset and the\ncode for the models are publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 17:19:46 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Talman", "Aarne", ""], ["Suni", "Antti", ""], ["Celikkanat", "Hande", ""], ["Kakouros", "Sofoklis", ""], ["Tiedemann", "J\u00f6rg", ""], ["Vainio", "Martti", ""]]}, {"id": "1908.02265", "submitter": "Jiasen Lu", "authors": "Jiasen Lu, Dhruv Batra, Devi Parikh, Stefan Lee", "title": "ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for\n  Vision-and-Language Tasks", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ViLBERT (short for Vision-and-Language BERT), a model for learning\ntask-agnostic joint representations of image content and natural language. We\nextend the popular BERT architecture to a multi-modal two-stream model,\npro-cessing both visual and textual inputs in separate streams that interact\nthrough co-attentional transformer layers. We pretrain our model through two\nproxy tasks on the large, automatically collected Conceptual Captions dataset\nand then transfer it to multiple established vision-and-language tasks --\nvisual question answering, visual commonsense reasoning, referring expressions,\nand caption-based image retrieval -- by making only minor additions to the base\narchitecture. We observe significant improvements across tasks compared to\nexisting task-specific models -- achieving state-of-the-art on all four tasks.\nOur work represents a shift away from learning groundings between vision and\nlanguage only as part of task training and towards treating visual grounding as\na pretrainable and transferable capability.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 17:33:52 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Lu", "Jiasen", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""], ["Lee", "Stefan", ""]]}, {"id": "1908.02282", "submitter": "Srijith Rajamohan", "authors": "Srijith Rajamohan, Alana Romanella, Amit Ramesh", "title": "A Weakly-Supervised Attention-based Visualization Tool for Assessing\n  Political Affiliation", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we seek to finetune a weakly-supervised expert-guided Deep\nNeural Network (DNN) for the purpose of determining political affiliations. In\nthis context, stance detection is used for determining political affiliation or\nideology which is framed in the form of relative proximities between entities\nin a low-dimensional space. An attention-based mechanism is used to provide\nmodel interpretability. A Deep Neural Network for Natural Language\nUnderstanding (NLU) using static and contextual embeddings is trained and\nevaluated. Various techniques to visualize the projections generated from the\nnetwork are evaluated for visualization efficiency. An overview of the pipeline\nfrom data ingestion, processing and generation of visualization is given here.\nA web-based framework created to faciliate this interaction and exploration is\npresented here. Preliminary results of this study are summarized and future\nwork is outlined.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 18:14:06 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Rajamohan", "Srijith", ""], ["Romanella", "Alana", ""], ["Ramesh", "Amit", ""]]}, {"id": "1908.02283", "submitter": "Zachary Ren", "authors": "Zongze Ren, Zhiyong Chen, Shugong Xu", "title": "Triplet Based Embedding Distance and Similarity Learning for\n  Text-independent Speaker Verification", "comments": "5 pages, Accepted to The Asia-Pacific Signal and Information\n  Processing Association Annual Summit and Conference 2019 (APSIPA ASC 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker embeddings become growing popular in the text-independent speaker\nverification task. In this paper, we propose two improvements during the\ntraining stage. The improvements are both based on triplet cause the training\nstage and the evaluation stage of the baseline x-vector system focus on\ndifferent aims. Firstly, we introduce triplet loss for optimizing the Euclidean\ndistances between embeddings while minimizing the multi-class cross entropy\nloss. Secondly, we design an embedding similarity measurement network for\ncontrolling the similarity between the two selected embeddings. We further\njointly train the two new methods with the original network and achieve\nstate-of-the-art. The multi-task training synergies are shown with a 9%\nreduction equal error rate (EER) and detected cost function (DCF) on the 2016\nNIST Speaker Recognition Evaluation (SRE) Test Set.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 04:23:27 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Ren", "Zongze", ""], ["Chen", "Zhiyong", ""], ["Xu", "Shugong", ""]]}, {"id": "1908.02284", "submitter": "Zachary Ren", "authors": "Zongze Ren, Guofu Yang, Shugong Xu", "title": "Two-stage Training for Chinese Dialect Recognition", "comments": "Accepted to Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a two-stage language identification (LID) system\nbased on a shallow ResNet14 followed by a simple 2-layer recurrent neural\nnetwork (RNN) architecture, which was used for Xunfei (iFlyTek) Chinese Dialect\nRecognition Challenge and won the first place among 110 teams. The system\ntrains an acoustic model (AM) firstly with connectionist temporal\nclassification (CTC) to recognize the given phonetic sequence annotation and\nthen train another RNN to classify dialect category by utilizing the\nintermediate features as inputs from the AM. Compared with a three-stage system\nwe further explore, our results show that the two-stage system can achieve high\naccuracy for Chinese dialects recognition under both short utterance and long\nutterance conditions with less training time.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 04:28:56 GMT"}, {"version": "v2", "created": "Sat, 10 Aug 2019 09:28:00 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Ren", "Zongze", ""], ["Yang", "Guofu", ""], ["Xu", "Shugong", ""]]}, {"id": "1908.02285", "submitter": "Milad Moradi", "authors": "Milad Moradi, Nasser Ghadiri", "title": "Text Summarization in the Biomedical Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter gives an overview of recent advances in the field of biomedical\ntext summarization. Different types of challenges are introduced, and methods\nare discussed concerning the type of challenge that they address. Biomedical\nliterature summarization is explored as a leading trend in the field, and some\nfuture lines of work are pointed out. Underlying methods of recent\nsummarization systems are briefly explained and the most significant evaluation\nresults are mentioned. The primary purpose of this chapter is to review the\nmost significant research efforts made in the current decade toward new methods\nof biomedical text summarization. As the main parts of this chapter, current\ntrends are discussed and new challenges are introduced.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 09:57:08 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Moradi", "Milad", ""], ["Ghadiri", "Nasser", ""]]}, {"id": "1908.02286", "submitter": "Milad Moradi", "authors": "Milad Moradi, Matthias Samwald", "title": "Clustering of Deep Contextualized Representations for Summarization of\n  Biomedical Texts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, summarizers that incorporate domain knowledge into the\nprocess of text summarization have outperformed generic methods, especially for\nsummarization of biomedical texts. However, construction and maintenance of\ndomain knowledge bases are resource-intense tasks requiring significant manual\nannotation. In this paper, we demonstrate that contextualized representations\nextracted from the pre-trained deep language model BERT, can be effectively\nused to measure the similarity between sentences and to quantify the\ninformative content. The results show that our BERT-based summarizer can\nimprove the performance of biomedical summarization. Although the summarizer\ndoes not use any sources of domain knowledge, it can capture the context of\nsentences more accurately than the comparison methods. The source code and data\nare available at https://github.com/BioTextSumm/BERT-based-Summ.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 10:18:20 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 09:57:43 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Moradi", "Milad", ""], ["Samwald", "Matthias", ""]]}, {"id": "1908.02322", "submitter": "Chia-Lun Yeh", "authors": "Chia-Lun Yeh, Babak Loni, Mari\\\"elle Hendriks, Henrike Reinhardt, Anne\n  Schuth", "title": "DpgMedia2019: A Dutch News Dataset for Partisanship Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new Dutch news dataset with labeled partisanship. The dataset\ncontains more than 100K articles that are labeled on the publisher level and\n776 articles that were crowdsourced using an internal survey platform and\nlabeled on the article level. In this paper, we document our original\nmotivation, the collection and annotation process, limitations, and\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 18:50:45 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Yeh", "Chia-Lun", ""], ["Loni", "Babak", ""], ["Hendriks", "Mari\u00eblle", ""], ["Reinhardt", "Henrike", ""], ["Schuth", "Anne", ""]]}, {"id": "1908.02367", "submitter": "Chaoyu Guan", "authors": "Chaoyu Guan, Yuhao Cheng, Hai Zhao", "title": "Semantic Role Labeling with Associated Memory Network", "comments": "Published at NAACL 2019; This is camera Ready version; Code is\n  available at https://github.com/Frozenmad/AMN_SRL", "journal-ref": null, "doi": "10.18653/v1/N19-1340", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic role labeling (SRL) is a task to recognize all the\npredicate-argument pairs of a sentence, which has been in a performance\nimprovement bottleneck after a series of latest works were presented. This\npaper proposes a novel syntax-agnostic SRL model enhanced by the proposed\nassociated memory network (AMN), which makes use of inter-sentence attention of\nlabel-known associated sentences as a kind of memory to further enhance\ndependency-based SRL. In detail, we use sentences and their labels from train\ndataset as an associated memory cue to help label the target sentence.\nFurthermore, we compare several associated sentences selecting strategies and\nlabel merging methods in AMN to find and utilize the label of associated\nsentences while attending them. By leveraging the attentive memory from known\ntraining data, Our full model reaches state-of-the-art on CoNLL-2009 benchmark\ndatasets for syntax-agnostic setting, showing a new effective research line of\nSRL enhancement other than exploiting external resources such as well\npre-trained language models.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 09:40:18 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Guan", "Chaoyu", ""], ["Cheng", "Yuhao", ""], ["Zhao", "Hai", ""]]}, {"id": "1908.02402", "submitter": "Lei Shu", "authors": "Lei Shu, Piero Molino, Mahdi Namazifar, Hu Xu, Bing Liu, Huaixiu\n  Zheng, Gokhan Tur", "title": "Flexibly-Structured Model for Task-Oriented Dialogues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel end-to-end architecture for task-oriented\ndialogue systems. It is based on a simple and practical yet very effective\nsequence-to-sequence approach, where language understanding and state tracking\ntasks are modeled jointly with a structured copy-augmented sequential decoder\nand a multi-label decoder for each slot. The policy engine and language\ngeneration tasks are modeled jointly following that. The copy-augmented\nsequential decoder deals with new or unknown values in the conversation, while\nthe multi-label decoder combined with the sequential decoder ensures the\nexplicit assignment of values to slots. On the generation part, slot binary\nclassifiers are used to improve performance. This architecture is scalable to\nreal-world scenarios and is shown through an empirical evaluation to achieve\nstate-of-the-art performance on both the Cambridge Restaurant dataset and the\nStanford in-car assistant dataset\\footnote{The code is available at\n\\url{https://github.com/uber-research/FSDM}}\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 23:56:25 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Shu", "Lei", ""], ["Molino", "Piero", ""], ["Namazifar", "Mahdi", ""], ["Xu", "Hu", ""], ["Liu", "Bing", ""], ["Zheng", "Huaixiu", ""], ["Tur", "Gokhan", ""]]}, {"id": "1908.02404", "submitter": "Binh Nguyen", "authors": "Binh Nguyen, Vu Bao Hung Nguyen, Hien Nguyen, Pham Ngoc Phuong,\n  The-Loc Nguyen, Quoc Truong Do, Luong Chi Mai", "title": "Fast and Accurate Capitalization and Punctuation for Automatic Speech\n  Recognition Using Transformer and Chunk Merging", "comments": "4 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, studies on automatic speech recognition (ASR) have shown\noutstanding results that reach human parity on short speech segments. However,\nthere are still difficulties in standardizing the output of ASR such as\ncapitalization and punctuation restoration for long-speech transcription. The\nproblems obstruct readers to understand the ASR output semantically and also\ncause difficulties for natural language processing models such as NER, POS and\nsemantic parsing. In this paper, we propose a method to restore the punctuation\nand capitalization for long-speech ASR transcription. The method is based on\nTransformer models and chunk merging that allows us to (1), build a single\nmodel that performs punctuation and capitalization in one go, and (2), perform\ndecoding in parallel while improving the prediction accuracy. Experiments on\nBritish National Corpus showed that the proposed approach outperforms existing\nmethods in both accuracy and decoding speed.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 00:04:58 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Nguyen", "Binh", ""], ["Nguyen", "Vu Bao Hung", ""], ["Nguyen", "Hien", ""], ["Phuong", "Pham Ngoc", ""], ["Nguyen", "The-Loc", ""], ["Do", "Quoc Truong", ""], ["Mai", "Luong Chi", ""]]}, {"id": "1908.02425", "submitter": "John Brandt", "authors": "John Brandt", "title": "Text mining policy: Classifying forest and landscape restoration policy\n  agenda with neural information retrieval", "comments": "In FEED 19 Workshop at KDD 2019. Anchorage, AK, USA, 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dozens of countries have committed to restoring the ecological functionality\nof 350 million hectares of land by 2030. In order to achieve such wide-scale\nimplementation of restoration, the values and priorities of multi-sectoral\nstakeholders must be aligned and integrated with national level commitments and\nother development agenda. Although misalignment across scales of policy and\nbetween stakeholders are well known barriers to implementing restoration,\nfast-paced policy making in multi-stakeholder environments complicates the\nmonitoring and analysis of governance and policy. In this work, we assess the\npotential of machine learning to identify restoration policy agenda across\ndiverse policy documents. An unsupervised neural information retrieval\narchitecture is introduced that leverages transfer learning and word embeddings\nto create high-dimensional representations of paragraphs. Policy agenda labels\nare recast as information retrieval queries in order to classify policies with\na cosine similarity threshold between paragraphs and query embeddings. This\napproach achieves a 0.83 F1-score measured across 14 policy agenda in 31 policy\ndocuments in Malawi, Kenya, and Rwanda, indicating that automated text mining\ncan provide reliable, generalizable, and efficient analyses of restoration\npolicy.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 02:58:24 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Brandt", "John", ""]]}, {"id": "1908.02451", "submitter": "Manish Patel", "authors": "Manish Patel", "title": "TinySearch -- Semantics based Search Engine using Bert Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing search engines use keyword matching or tf-idf based matching to map\nthe query to the web-documents and rank them. They also consider other factors\nsuch as page rank, hubs-and-authority scores, knowledge graphs to make the\nresults more meaningful. However, the existing search engines fail to capture\nthe meaning of query when it becomes large and complex. BERT, introduced by\nGoogle in 2018, provides embeddings for words as well as sentences. In this\npaper, I have developed a semantics-oriented search engine using neural\nnetworks and BERT embeddings that can search for query and rank the documents\nin the order of the most meaningful to least meaningful. The results shows\nimprovement over one existing search engine for complex queries for given set\nof documents.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 06:02:17 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Patel", "Manish", ""]]}, {"id": "1908.02477", "submitter": "Shauli Ravfogel", "authors": "Carlo Meloni, Shauli Ravfogel, Yoav Goldberg", "title": "Ab Antiquo: Neural Proto-language Reconstruction", "comments": "Accepted as a long paper in NAACL21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Historical linguists have identified regularities in the process of historic\nsound change. The comparative method utilizes those regularities to reconstruct\nproto-words based on observed forms in daughter languages. Can this process be\nefficiently automated? We address the task of proto-word reconstruction, in\nwhich the model is exposed to cognates in contemporary daughter languages, and\nhas to predict the proto word in the ancestor language. We provide a novel\ndataset for this task, encompassing over 8,000 comparative entries, and show\nthat neural sequence models outperform conventional methods applied to this\ntask so far. Error analysis reveals variability in the ability of neural model\nto capture different phonological changes, correlating with the complexity of\nthe changes. Analysis of learned embeddings reveals the models learn\nphonologically meaningful generalizations, corresponding to well-attested\nphonological shifts documented by historical linguistics.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 08:03:08 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 19:48:17 GMT"}, {"version": "v3", "created": "Sun, 9 May 2021 18:35:15 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Meloni", "Carlo", ""], ["Ravfogel", "Shauli", ""], ["Goldberg", "Yoav", ""]]}, {"id": "1908.02505", "submitter": "Dmytro Tkanov", "authors": "Volodymyr Sokhatskyi, Olga Zvyeryeva, Ievgen Karaulov, Dmytro Tkanov", "title": "Embedding-based system for the Text part of CALL v3 shared task", "comments": "SLaTE 2019, CALLv3, 4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a scoring system that has shown the top result on the\ntext subset of CALL v3 shared task. The presented system is based on text\nembeddings, namely NNLM~\\cite{nnlm} and BERT~\\cite{Bert}. The distinguishing\nfeature of the given approach is that it does not rely on the reference grammar\nfile for scoring. The model is compared against approaches that use the grammar\nfile and proves the possibility to achieve similar and even higher results\nwithout a predefined set of correct answers.\n  The paper describes the model itself and the data preparation process that\nplayed a crucial role in the model training.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 09:44:31 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Sokhatskyi", "Volodymyr", ""], ["Zvyeryeva", "Olga", ""], ["Karaulov", "Ievgen", ""], ["Tkanov", "Dmytro", ""]]}, {"id": "1908.02551", "submitter": "Renhao Cui", "authors": "Renhao Cui, Gagan Agrawal, Rajiv Ramnath", "title": "Tweets Can Tell: Activity Recognition using Hybrid Long Short-Term\n  Memory Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents techniques to detect the \"offline\" activity a person is\nengaged in when she is tweeting (such as dining, shopping or entertainment), in\norder to create a dynamic profile of the user, for uses such as better\ntargeting of advertisements. To this end, we propose a hybrid LSTM model for\nrich contextual learning, along with studies on the effects of applying and\ncombining multiple LSTM based methods with different contextual features. The\nhybrid model is shown to outperform a set of baselines and state-of-the-art\nmethods. Finally, this paper presents an orthogonal validation with a real-case\napplication. Our model generates an offline activity analysis for the followers\nof several well-known accounts, which is quite representative of the expected\ncharacteristics of these accounts.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 02:29:39 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Cui", "Renhao", ""], ["Agrawal", "Gagan", ""], ["Ramnath", "Rajiv", ""]]}, {"id": "1908.02579", "submitter": "Samhaa R El-Beltagy", "authors": "Amr Al-Khatib and Samhaa R. El-Beltagy", "title": "A Simple and Effective Approach for Fine Tuning Pre-trained Word\n  Embeddings for Improved Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a new and simple approach for fine-tuning pretrained word\nembeddings for text classification tasks. In this approach, the class in which\na term appears, acts as an additional contextual variable during the fine\ntuning process, and contributes to the final word vector for that term. As a\nresult, words that are used distinctively within a particular class, will bear\nvectors that are closer to each other in the embedding space and will be more\ndiscriminative towards that class. To validate this novel approach, it was\napplied to three Arabic and two English datasets that have been previously used\nfor text classification tasks such as sentiment analysis and emotion detection.\nIn the vast majority of cases, the results obtained using the proposed\napproach, improved considerably.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 12:32:33 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 10:00:33 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Al-Khatib", "Amr", ""], ["El-Beltagy", "Samhaa R.", ""]]}, {"id": "1908.02588", "submitter": "Luke Snyder", "authors": "Luke S. Snyder, Yi-Shan Lin, Morteza Karimzadeh, Dan Goldwasser, and\n  David S. Ebert", "title": "Interactive Learning for Identifying Relevant Tweets to Support\n  Real-time Situational Awareness", "comments": "12 pages, 8 figures, 3 tables, IEEE VIS VAST 2019, TVCG", "journal-ref": null, "doi": "10.1109/TVCG.2019.2934614", "report-no": null, "categories": "cs.SI cs.CL cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various domain users are increasingly leveraging real-time social media data\nto gain rapid situational awareness. However, due to the high noise in the\ndeluge of data, effectively determining semantically relevant information can\nbe difficult, further complicated by the changing definition of relevancy by\neach end user for different events. The majority of existing methods for short\ntext relevance classification fail to incorporate users' knowledge into the\nclassification process. Existing methods that incorporate interactive user\nfeedback focus on historical datasets. Therefore, classifiers cannot be\ninteractively retrained for specific events or user-dependent needs in\nreal-time. This limits real-time situational awareness, as streaming data that\nis incorrectly classified cannot be corrected immediately, permitting the\npossibility for important incoming data to be incorrectly classified as well.\nWe present a novel interactive learning framework to improve the classification\nprocess in which the user iteratively corrects the relevancy of tweets in\nreal-time to train the classification model on-the-fly for immediate predictive\nimprovements. We computationally evaluate our classification model adapted to\nlearn at interactive rates. Our results show that our approach outperforms\nstate-of-the-art machine learning models. In addition, we integrate our\nframework with the extended Social Media Analytics and Reporting Toolkit\n(SMART) 2.0 system, allowing the use of our interactive learning framework\nwithin a visual analytics system tailored for real-time situational awareness.\nTo demonstrate our framework's effectiveness, we provide domain expert feedback\nfrom first responders who used the extended SMART 2.0 system.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 09:01:19 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 19:11:52 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Snyder", "Luke S.", ""], ["Lin", "Yi-Shan", ""], ["Karimzadeh", "Morteza", ""], ["Goldwasser", "Dan", ""], ["Ebert", "David S.", ""]]}, {"id": "1908.02810", "submitter": "Nithum Thain", "authors": "Flavien Prost, Nithum Thain, Tolga Bolukbasi", "title": "Debiasing Embeddings for Reduced Gender Bias in Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  (Bolukbasi et al., 2016) demonstrated that pretrained word embeddings can\ninherit gender bias from the data they were trained on. We investigate how this\nbias affects downstream classification tasks, using the case study of\noccupation classification (De-Arteaga et al.,2019). We show that traditional\ntechniques for debiasing embeddings can actually worsen the bias of the\ndownstream classifier by providing a less noisy channel for communicating\ngender information. With a relatively minor adjustment, however, we show how\nthese same techniques can be used to simultaneously reduce bias and maintain\nhigh classification accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 19:46:11 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Prost", "Flavien", ""], ["Thain", "Nithum", ""], ["Bolukbasi", "Tolga", ""]]}, {"id": "1908.02895", "submitter": "Zhentao Xia", "authors": "Zhentao Xia, Likai Wang, Weiguang Qu, Junsheng Zhou, Yanhui Gu", "title": "Neural Network based Deep Transfer Learning for Cross-domain Dependency\n  Parsing", "comments": "paper for NLPCC 2019 Shared Task of Semi-supervised domain adaptation\n  subtask on Cross-domain Dependency Parsing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe the details of the neural dependency parser\nsub-mitted by our team to the NLPCC 2019 Shared Task of Semi-supervised do-main\nadaptation subtask on Cross-domain Dependency Parsing. Our system is based on\nthe stack-pointer networks(STACKPTR). Considering the im-portance of context,\nwe utilize self-attention mechanism for the representa-tion vectors to capture\nthe meaning of words. In addition, to adapt three dif-ferent domains, we\nutilize neural network based deep transfer learning which transfers the\npre-trained partial network in the source domain to be a part of deep neural\nnetwork in the three target domains (product comments, product blogs and web\nfiction) respectively. Results on the three target domains demonstrate that our\nmodel performs competitively.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 01:16:34 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Xia", "Zhentao", ""], ["Wang", "Likai", ""], ["Qu", "Weiguang", ""], ["Zhou", "Junsheng", ""], ["Gu", "Yanhui", ""]]}, {"id": "1908.02899", "submitter": "Maxwell Forbes", "authors": "Maxwell Forbes, Ari Holtzman, Yejin Choi", "title": "Do Neural Language Representations Learn Physical Commonsense?", "comments": "Published in The Proceedings of the 41st Annual Conference of the\n  Cognitive Science Society (CogSci 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans understand language based on the rich background knowledge about how\nthe physical world works, which in turn allows us to reason about the physical\nworld through language. In addition to the properties of objects (e.g., boats\nrequire fuel) and their affordances, i.e., the actions that are applicable to\nthem (e.g., boats can be driven), we can also reason about if-then inferences\nbetween what properties of objects imply the kind of actions that are\napplicable to them (e.g., that if we can drive something then it likely\nrequires fuel).\n  In this paper, we investigate the extent to which state-of-the-art neural\nlanguage representations, trained on a vast amount of natural language text,\ndemonstrate physical commonsense reasoning. While recent advancements of neural\nlanguage models have demonstrated strong performance on various types of\nnatural language inference tasks, our study based on a dataset of over 200k\nnewly collected annotations suggests that neural language representations still\nonly learn associations that are explicitly written down.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 01:41:16 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Forbes", "Maxwell", ""], ["Holtzman", "Ari", ""], ["Choi", "Yejin", ""]]}, {"id": "1908.02914", "submitter": "Denis Peskov", "authors": "Denis Peskov, Joe Barrow, Pedro Rodriguez, Graham Neubig, Jordan\n  Boyd-Graber", "title": "Mitigating Noisy Inputs for Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language processing systems are often downstream of unreliable\ninputs: machine translation, optical character recognition, or speech\nrecognition. For instance, virtual assistants can only answer your questions\nafter understanding your speech. We investigate and mitigate the effects of\nnoise from Automatic Speech Recognition systems on two factoid Question\nAnswering (QA) tasks. Integrating confidences into the model and forced\ndecoding of unknown words are empirically shown to improve the accuracy of\ndownstream neural QA systems. We create and train models on a synthetic corpus\nof over 500,000 noisy sentences and evaluate on two human corpora from Quizbowl\nand Jeopardy! competitions.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 03:31:11 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Peskov", "Denis", ""], ["Barrow", "Joe", ""], ["Rodriguez", "Pedro", ""], ["Neubig", "Graham", ""], ["Boyd-Graber", "Jordan", ""]]}, {"id": "1908.02923", "submitter": "Omid Mohamad Nezami", "authors": "Omid Mohamad Nezami, Mark Dras, Stephen Wan, Cecile Paris", "title": "Image Captioning using Facial Expression and Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Benefiting from advances in machine vision and natural language processing\ntechniques, current image captioning systems are able to generate detailed\nvisual descriptions. For the most part, these descriptions represent an\nobjective characterisation of the image, although some models do incorporate\nsubjective aspects related to the observer's view of the image, such as\nsentiment; current models, however, usually do not consider the emotional\ncontent of images during the caption generation process. This paper addresses\nthis issue by proposing novel image captioning models which use facial\nexpression features to generate image captions. The models generate image\ncaptions using long short-term memory networks applying facial features in\naddition to other visual features at different time steps. We compare a\ncomprehensive collection of image captioning models with and without facial\nfeatures using all standard evaluation metrics. The evaluation metrics indicate\nthat applying facial features with an attention mechanism achieves the best\nperformance, showing more expressive and more correlated image captions, on an\nimage caption dataset extracted from the standard Flickr 30K dataset,\nconsisting of around 11K images containing faces. An analysis of the generated\ncaptions finds that, perhaps unexpectedly, the improvement in caption quality\nappears to come not from the addition of adjectives linked to emotional aspects\nof the images, but from more variety in the actions described in the captions.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 04:07:39 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 02:39:46 GMT"}, {"version": "v3", "created": "Wed, 15 Apr 2020 02:01:07 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Nezami", "Omid Mohamad", ""], ["Dras", "Mark", ""], ["Wan", "Stephen", ""], ["Paris", "Cecile", ""]]}, {"id": "1908.02943", "submitter": "Omid Mohamad Nezami", "authors": "Omid Mohamad Nezami, Mark Dras, Stephen Wan, Cecile Paris, Len Hamey", "title": "Towards Generating Stylized Image Captions via Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While most image captioning aims to generate objective descriptions of\nimages, the last few years have seen work on generating visually grounded image\ncaptions which have a specific style (e.g., incorporating positive or negative\nsentiment). However, because the stylistic component is typically the last part\nof training, current models usually pay more attention to the style at the\nexpense of accurate content description. In addition, there is a lack of\nvariability in terms of the stylistic aspects. To address these issues, we\npropose an image captioning model called ATTEND-GAN which has two core\ncomponents: first, an attention-based caption generator to strongly correlate\ndifferent parts of an image with different parts of a caption; and second, an\nadversarial training mechanism to assist the caption generator to add diverse\nstylistic components to the generated captions. Because of these components,\nATTEND-GAN can generate correlated captions as well as more human-like\nvariability of stylistic patterns. Our system outperforms the state-of-the-art\nas well as a collection of our baseline models. A linguistic analysis of the\ngenerated captions demonstrates that captions generated using ATTEND-GAN have a\nwider range of stylistic adjectives and adjective-noun pairs.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 06:25:38 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Nezami", "Omid Mohamad", ""], ["Dras", "Mark", ""], ["Wan", "Stephen", ""], ["Paris", "Cecile", ""], ["Hamey", "Len", ""]]}, {"id": "1908.03043", "submitter": "Tom\\'a\\v{s} Musil", "authors": "Kate\\v{r}ina Rysov\\'a, Magdal\\'ena Rysov\\'a, Tom\\'a\\v{s} Musil, Lucie\n  Pol\\'akov\\'a, Ond\\v{r}ej Bojar", "title": "A Test Suite and Manual Evaluation of Document-Level NMT at WMT19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the quality of machine translation rises and neural machine translation\n(NMT) is moving from sentence to document level translations, it is becoming\nincreasingly difficult to evaluate the output of translation systems.\n  We provide a test suite for WMT19 aimed at assessing discourse phenomena of\nMT systems participating in the News Translation Task. We have manually checked\nthe outputs and identified types of translation errors that are relevant to\ndocument-level translation.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 12:50:23 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Rysov\u00e1", "Kate\u0159ina", ""], ["Rysov\u00e1", "Magdal\u00e9na", ""], ["Musil", "Tom\u00e1\u0161", ""], ["Pol\u00e1kov\u00e1", "Lucie", ""], ["Bojar", "Ond\u0159ej", ""]]}, {"id": "1908.03067", "submitter": "Shuming Ma", "authors": "Shuming Ma, Pengcheng Yang, Tianyu Liu, Peng Li, Jie Zhou, Xu Sun", "title": "Key Fact as Pivot: A Two-Stage Model for Low Resource Table-to-Text\n  Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Table-to-text generation aims to translate the structured data into the\nunstructured text. Most existing methods adopt the encoder-decoder framework to\nlearn the transformation, which requires large-scale training samples. However,\nthe lack of large parallel data is a major practical problem for many domains.\nIn this work, we consider the scenario of low resource table-to-text\ngeneration, where only limited parallel data is available. We propose a novel\nmodel to separate the generation into two stages: key fact prediction and\nsurface realization. It first predicts the key facts from the tables, and then\ngenerates the text with the key facts. The training of key fact prediction\nneeds much fewer annotated data, while surface realization can be trained with\npseudo parallel corpus. We evaluate our model on a biography generation\ndataset. Our model can achieve $27.34$ BLEU score with only $1,000$ parallel\ndata, while the baseline model only obtain the performance of $9.71$ BLEU\nscore.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 13:41:31 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Ma", "Shuming", ""], ["Yang", "Pengcheng", ""], ["Liu", "Tianyu", ""], ["Li", "Peng", ""], ["Zhou", "Jie", ""], ["Sun", "Xu", ""]]}, {"id": "1908.03142", "submitter": "Chen Ma", "authors": "Chen Ma", "title": "The Hitchhiker's Guide to LDA", "comments": "148 pages, in Chinese", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent Dirichlet Allocation (LDA) model is a famous model in the topic model\nfield, it has been studied for years due to its extensive application value in\nindustry and academia. However, the mathematical derivation of LDA model is\nchallenging and difficult, which makes it difficult for the beginners to learn.\nTo help the beginners in learning LDA, this book analyzes the mathematical\nderivation of LDA in detail, and it also introduces all the knowledge\nbackground to make it easy for beginners to understand. Thus, this book\ncontains the author's unique insights. It should be noted that this book is\nwritten in Chinese.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 03:59:19 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 12:41:30 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Ma", "Chen", ""]]}, {"id": "1908.03146", "submitter": "Abeer ALdayel", "authors": "Abeer Aldayel and Walid Magdy", "title": "Your Stance is Exposed! Analysing Possible Factors for Stance Detection\n  on Social Media", "comments": "Accepted as a full paper at CSCW 2019. Please cite the CSCW version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To what extent user's stance towards a given topic could be inferred? Most of\nthe studies on stance detection have focused on analysing user's posts on a\ngiven topic to predict the stance. However, the stance in social media can be\ninferred from a mixture of signals that might reflect user's beliefs including\nposts and online interactions. This paper examines various online features of\nusers to detect their stance towards different topics. We compare multiple set\nof features, including on-topic content, network interactions, user's\npreferences, and online network connections. Our objective is to understand the\nonline signals that can reveal the users' stance. Experimentation is applied on\ntweets dataset from the SemEval stance detection task, which covers five\ntopics. Results show that stance of a user can be detected with multiple\nsignals of user's online activity, including their posts on the topic, the\nnetwork they interact with or follow, the websites they visit, and the content\nthey like. The performance of the stance modelling using different network\nfeatures are comparable with the state-of-the-art reported model that used\ntextual content only. In addition, combining network and content features leads\nto the highest reported performance to date on the SemEval dataset with\nF-measure of 72.49%. We further present an extensive analysis to show how these\ndifferent set of features can reveal stance. Our findings have distinct privacy\nimplications, where they highlight that stance is strongly embedded in user's\nonline social network that, in principle, individuals can be profiled from\ntheir interactions and connections even when they do not post about the topic.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 16:18:30 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Aldayel", "Abeer", ""], ["Magdy", "Walid", ""]]}, {"id": "1908.03181", "submitter": "Abeer ALdayel", "authors": "Abeer Aldayel and Walid Magdy", "title": "Assessing Sentiment of the Expressed Stance on Social Media", "comments": "Accepted as a full paper at Socinfo 2019. Please cite the Socinfo\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stance detection is the task of inferring viewpoint towards a given topic or\nentity either being supportive or opposing. One may express a viewpoint towards\na topic by using positive or negative language. This paper examines how the\nstance is being expressed in social media according to the sentiment polarity.\nThere has been a noticeable misconception of the similarity between the stance\nand sentiment when it comes to viewpoint discovery, where negative sentiment is\nassumed to mean against stance, and positive sentiment means in-favour stance.\nTo analyze the relation between stance and sentiment, we construct a new\ndataset with four topics and examine how people express their viewpoint with\nregards these topics. We validate our results by carrying a further analysis of\nthe popular stance benchmark SemEval stance dataset. Our analyses reveal that\nsentiment and stance are not highly aligned, and hence the simple sentiment\npolarity cannot be used solely to denote a stance toward a given topic.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 17:21:16 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Aldayel", "Abeer", ""], ["Magdy", "Walid", ""]]}, {"id": "1908.03265", "submitter": "Liyuan Liu", "authors": "Liyuan Liu, Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu,\n  Jianfeng Gao, Jiawei Han", "title": "On the Variance of the Adaptive Learning Rate and Beyond", "comments": "ICLR 2020. Fix several typos in the previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The learning rate warmup heuristic achieves remarkable success in stabilizing\ntraining, accelerating convergence and improving generalization for adaptive\nstochastic optimization algorithms like RMSprop and Adam. Here, we study its\nmechanism in details. Pursuing the theory behind warmup, we identify a problem\nof the adaptive learning rate (i.e., it has problematically large variance in\nthe early stage), suggest warmup works as a variance reduction technique, and\nprovide both empirical and theoretical evidence to verify our hypothesis. We\nfurther propose RAdam, a new variant of Adam, by introducing a term to rectify\nthe variance of the adaptive learning rate. Extensive experimental results on\nimage classification, language modeling, and neural machine translation verify\nour intuition and demonstrate the effectiveness and robustness of our proposed\nmethod. All implementations are available at:\nhttps://github.com/LiyuanLucasLiu/RAdam.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 20:51:17 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 02:35:43 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 15:03:56 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Liu", "Liyuan", ""], ["Jiang", "Haoming", ""], ["He", "Pengcheng", ""], ["Chen", "Weizhu", ""], ["Liu", "Xiaodong", ""], ["Gao", "Jianfeng", ""], ["Han", "Jiawei", ""]]}, {"id": "1908.03313", "submitter": "Neelmadhav Gantayat", "authors": "Prateeti Mohapatra, Neelamadhav Gantayat, Gargi B. Dasgupta", "title": "Using Semantic Role Knowledge for Relevance Ranking of Key Phrases in\n  Documents: An Unsupervised Approach", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the integration of sentence position and\nsemantic role of words in a PageRank system to build a key phrase ranking\nmethod. We present the evaluation results of our approach on three scientific\narticles. We show that semantic role information, when integrated with a\nPageRank system, can become a new lexical feature. Our approach had an overall\nimprovement on all the data sets over the state-of-art baseline approaches.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 04:44:12 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Mohapatra", "Prateeti", ""], ["Gantayat", "Neelamadhav", ""], ["Dasgupta", "Gargi B.", ""]]}, {"id": "1908.03402", "submitter": "Hongfei Xu", "authors": "Hongfei Xu and Qiuhui Liu and Josef van Genabith", "title": "UdS Submission for the WMT 19 Automatic Post-Editing Task", "comments": "WMT 2019 Automatic Post-Editing Shared Task Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe our submission to the English-German APE shared\ntask at WMT 2019. We utilize and adapt an NMT architecture originally developed\nfor exploiting context information to APE, implement this in our own\ntransformer model and explore joint training of the APE task with a de-noising\nencoder.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 10:40:52 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Xu", "Hongfei", ""], ["Liu", "Qiuhui", ""], ["van Genabith", "Josef", ""]]}, {"id": "1908.03409", "submitter": "Eugene Ie", "authors": "Haoshuo Huang, Vihan Jain, Harsh Mehta, Alexander Ku, Gabriel\n  Magalhaes, Jason Baldridge, Eugene Ie", "title": "Transferable Representation Learning in Vision-and-Language Navigation", "comments": "To appear in ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Vision-and-Language Navigation (VLN) tasks such as Room-to-Room (R2R) require\nmachine agents to interpret natural language instructions and learn to act in\nvisually realistic environments to achieve navigation goals. The overall task\nrequires competence in several perception problems: successful agents combine\nspatio-temporal, vision and language understanding to produce appropriate\naction sequences. Our approach adapts pre-trained vision and language\nrepresentations to relevant in-domain tasks making them more effective for VLN.\nSpecifically, the representations are adapted to solve both a cross-modal\nsequence alignment and sequence coherence task. In the sequence alignment task,\nthe model determines whether an instruction corresponds to a sequence of visual\nframes. In the sequence coherence task, the model determines whether the\nperceptual sequences are predictive sequentially in the instruction-conditioned\nlatent space. By transferring the domain-adapted representations, we improve\ncompetitive agents in R2R as measured by the success rate weighted by path\nlength (SPL) metric.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 10:58:01 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 22:00:55 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Huang", "Haoshuo", ""], ["Jain", "Vihan", ""], ["Mehta", "Harsh", ""], ["Ku", "Alexander", ""], ["Magalhaes", "Gabriel", ""], ["Baldridge", "Jason", ""], ["Ie", "Eugene", ""]]}, {"id": "1908.03451", "submitter": "Wenmian Yang", "authors": "Wenmian Yang, Weijia Jia, Wenyuan Gao, Xiaojie Zhou, Yutao Luo", "title": "Interactive Variance Attention based Online Spoiler Detection for\n  Time-Sync Comments", "comments": "Accepted by CIKM 2019", "journal-ref": null, "doi": "10.1145/3357384.3357872", "report-no": null, "categories": "cs.IR cs.CL cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, time-sync comment (TSC), a new form of interactive comments, has\nbecome increasingly popular in Chinese video websites. By posting TSCs, people\ncan easily express their feelings and exchange their opinions with others when\nwatching online videos. However, some spoilers appear among the TSCs. These\nspoilers reveal crucial plots in videos that ruin people's surprise when they\nfirst watch the video. In this paper, we proposed a novel Similarity-Based\nNetwork with Interactive Variance Attention (SBN-IVA) to classify comments as\nspoilers or not. In this framework, we firstly extract textual features of TSCs\nthrough the word-level attentive encoder. We design Similarity-Based Network\n(SBN) to acquire neighbor and keyframe similarity according to semantic\nsimilarity and timestamps of TSCs. Then, we implement Interactive Variance\nAttention (IVA) to eliminate the impact of noise comments. Finally, we obtain\nthe likelihood of spoiler based on the difference between the neighbor and\nkeyframe similarity. Experiments show SBN-IVA is on average 11.2\\% higher than\nthe state-of-the-art method on F1-score in baselines.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 13:24:21 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 06:22:08 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Yang", "Wenmian", ""], ["Jia", "Weijia", ""], ["Gao", "Wenyuan", ""], ["Zhou", "Xiaojie", ""], ["Luo", "Yutao", ""]]}, {"id": "1908.03455", "submitter": "Michael Picheny", "authors": "Michael Picheny, Z\\'oltan T\\\"uske, Brian Kingsbury, Kartik Audhkhasi,\n  Xiaodong Cui, George Saon", "title": "Challenging the Boundaries of Speech Recognition: The MALACH Corpus", "comments": "Accepted for publication at INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been huge progress in speech recognition over the last several\nyears. Tasks once thought extremely difficult, such as SWITCHBOARD, now\napproach levels of human performance. The MALACH corpus (LDC catalog\nLDC2012S05), a 375-Hour subset of a large archive of Holocaust testimonies\ncollected by the Survivors of the Shoah Visual History Foundation, presents\nsignificant challenges to the speech community. The collection consists of\nunconstrained, natural speech filled with disfluencies, heavy accents,\nage-related coarticulations, un-cued speaker and language switching, and\nemotional speech - all still open problems for speech recognition systems.\nTranscription is challenging even for skilled human annotators. This paper\nproposes that the community place focus on the MALACH corpus to develop speech\nrecognition systems that are more robust with respect to accents, disfluencies\nand emotional speech. To reduce the barrier for entry, a lexicon and training\nand testing setups have been created and baseline results using current deep\nlearning technologies are presented. The metadata has just been released by LDC\n(LDC2019S11). It is hoped that this resource will enable the community to build\non top of these baselines so that the extremely important information in these\nand related oral histories becomes accessible to a wider audience.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 13:35:45 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Picheny", "Michael", ""], ["T\u00fcske", "Z\u00f3ltan", ""], ["Kingsbury", "Brian", ""], ["Audhkhasi", "Kartik", ""], ["Cui", "Xiaodong", ""], ["Saon", "George", ""]]}, {"id": "1908.03480", "submitter": "Mark Anderson", "authors": "Mark Anderson, David Vilares, and Carlos G\\'omez-Rodr\\'iguez", "title": "Artificially Evolved Chunks for Morphosyntactic Analysis", "comments": "To be published in proceedings of the 18th International Workshop on\n  Treebanks and Linguistic Theories", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a language-agnostic evolutionary technique for automatically\nextracting chunks from dependency treebanks. We evaluate these chunks on a\nnumber of morphosyntactic tasks, namely POS tagging, morphological feature\ntagging, and dependency parsing. We test the utility of these chunks in a host\nof different ways. We first learn chunking as one task in a shared multi-task\nframework together with POS and morphological feature tagging. The predictions\nfrom this network are then used as input to augment sequence-labelling\ndependency parsing. Finally, we investigate the impact chunks have on\ndependency parsing in a multi-task framework. Our results from these analyses\nshow that these chunks improve performance at different levels of syntactic\nabstraction on English UD treebanks and a small, diverse subset of non-English\nUD treebanks.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 14:43:36 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 10:36:40 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Anderson", "Mark", ""], ["Vilares", "David", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "1908.03538", "submitter": "Siyuan Feng", "authors": "Siyuan Feng, Tan Lee", "title": "Exploiting Cross-Lingual Speaker and Phonetic Diversity for Unsupervised\n  Subword Modeling", "comments": "12 pages, 6 figures. Manuscript published in the IEEE/ACM\n  Transactions on Audio, Speech and Language Processing (Volume: 27 , Issue: 12\n  , Dec. 2019)", "journal-ref": null, "doi": "10.1109/TASLP.2019.2937953", "report-no": null, "categories": "eess.AS cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research addresses the problem of acoustic modeling of low-resource\nlanguages for which transcribed training data is absent. The goal is to learn\nrobust frame-level feature representations that can be used to identify and\ndistinguish subword-level speech units. The proposed feature representations\ncomprise various types of multilingual bottleneck features (BNFs) that are\nobtained via multi-task learning of deep neural networks (MTL-DNN). One of the\nkey problems is how to acquire high-quality frame labels for untranscribed\ntraining data to facilitate supervised DNN training. It is shown that learning\nof robust BNF representations can be achieved by effectively leveraging\ntranscribed speech data and well-trained automatic speech recognition (ASR)\nsystems from one or more out-of-domain (resource-rich) languages. Out-of-domain\nASR systems can be applied to perform speaker adaptation with untranscribed\ntraining data of the target language, and to decode the training speech into\nframe-level labels for DNN training. It is also found that better frame labels\ncan be generated by considering temporal dependency in speech when performing\nframe clustering. The proposed methods of feature learning are evaluated on the\nstandard task of unsupervised subword modeling in Track 1 of the ZeroSpeech\n2017 Challenge. The best performance achieved by our system is $9.7\\%$ in terms\nof across-speaker triphone minimal-pair ABX error rate, which is comparable to\nthe best systems reported recently. Lastly, our investigation reveals that the\ncloseness between target languages and out-of-domain languages and the amount\nof available training data for individual target languages could have\nsignificant impact on the goodness of learned features.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 16:57:04 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 09:36:37 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Feng", "Siyuan", ""], ["Lee", "Tan", ""]]}, {"id": "1908.03548", "submitter": "Zongcheng Ji", "authors": "Zongcheng Ji, Qiang Wei, Hua Xu", "title": "BERT-based Ranking for Biomedical Entity Normalization", "comments": "9 pages, 1 figure, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing high-performance entity normalization algorithms that can\nalleviate the term variation problem is of great interest to the biomedical\ncommunity. Although deep learning-based methods have been successfully applied\nto biomedical entity normalization, they often depend on traditional\ncontext-independent word embeddings. Bidirectional Encoder Representations from\nTransformers (BERT), BERT for Biomedical Text Mining (BioBERT) and BERT for\nClinical Text Mining (ClinicalBERT) were recently introduced to pre-train\ncontextualized word representation models using bidirectional Transformers,\nadvancing the state-of-the-art for many natural language processing tasks. In\nthis study, we proposed an entity normalization architecture by fine-tuning the\npre-trained BERT / BioBERT / ClinicalBERT models and conducted extensive\nexperiments to evaluate the effectiveness of the pre-trained models for\nbiomedical entity normalization using three different types of datasets. Our\nexperimental results show that the best fine-tuned models consistently\noutperformed previous methods and advanced the state-of-the-art for biomedical\nentity normalization, with up to 1.17% increase in accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 17:19:43 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Ji", "Zongcheng", ""], ["Wei", "Qiang", ""], ["Xu", "Hua", ""]]}, {"id": "1908.03557", "submitter": "Mark Yatskar", "authors": "Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, Kai-Wei Chang", "title": "VisualBERT: A Simple and Performant Baseline for Vision and Language", "comments": "Work in Progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose VisualBERT, a simple and flexible framework for modeling a broad\nrange of vision-and-language tasks. VisualBERT consists of a stack of\nTransformer layers that implicitly align elements of an input text and regions\nin an associated input image with self-attention. We further propose two\nvisually-grounded language model objectives for pre-training VisualBERT on\nimage caption data. Experiments on four vision-and-language tasks including\nVQA, VCR, NLVR2, and Flickr30K show that VisualBERT outperforms or rivals with\nstate-of-the-art models while being significantly simpler. Further analysis\ndemonstrates that VisualBERT can ground elements of language to image regions\nwithout any explicit supervision and is even sensitive to syntactic\nrelationships, tracking, for example, associations between verbs and image\nregions corresponding to their arguments.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 17:57:13 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Li", "Liunian Harold", ""], ["Yatskar", "Mark", ""], ["Yin", "Da", ""], ["Hsieh", "Cho-Jui", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "1908.03594", "submitter": "Frank Meng", "authors": "Frank Meng, Craig A. Morioka, Danne C. Elbers", "title": "Generating Information Extraction Patterns from Overlapping and Variable\n  Length Annotations using Sequence Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence alignments are used to capture patterns composed of elements\nrepresenting multiple conceptual levels through the alignment of sequences that\ncontain overlapping and variable length annotations. The alignments also\ndetermine the proper context window of words and phrases that most directly\nimpact the meaning of a given target within a sentence, eliminating the need to\npredefine a fixed context window of words surrounding the targets. We evaluated\nthe system using the CoNLL-2003 named entity recognition (NER) task.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 18:51:30 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 15:19:26 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Meng", "Frank", ""], ["Morioka", "Craig A.", ""], ["Elbers", "Danne C.", ""]]}, {"id": "1908.03640", "submitter": "Jason R.C. Nurse Dr", "authors": "Lukas Halgas and Ioannis Agrafiotis and Jason R. C. Nurse", "title": "Catching the Phish: Detecting Phishing Attacks using Recurrent Neural\n  Networks (RNNs)", "comments": "13 pages", "journal-ref": "20th World Conference on Information Security Applications (WISA\n  2019)", "doi": "10.1007/978-3-030-39303-8_17", "report-no": null, "categories": "cs.CR cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of online services in our daily lives has been accompanied by a\nrange of malicious attempts to trick individuals into performing undesired\nactions, often to the benefit of the adversary. The most popular medium of\nthese attempts is phishing attacks, particularly through emails and websites.\nIn order to defend against such attacks, there is an urgent need for automated\nmechanisms to identify this malevolent content before it reaches users. Machine\nlearning techniques have gradually become the standard for such classification\nproblems. However, identifying common measurable features of phishing content\n(e.g., in emails) is notoriously difficult. To address this problem, we engage\nin a novel study into a phishing content classifier based on a recurrent neural\nnetwork (RNN), which identifies such features without human input. At this\nstage, we scope our research to emails, but our approach can be extended to\napply to websites. Our results show that the proposed system outperforms\nstate-of-the-art tools. Furthermore, our classifier is efficient and takes into\naccount only the text and, in particular, the textual structure of the email.\nSince these features are rarely considered in email classification, we argue\nthat our classifier can complement existing classifiers with high information\ngain.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 21:37:42 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Halgas", "Lukas", ""], ["Agrafiotis", "Ioannis", ""], ["Nurse", "Jason R. C.", ""]]}, {"id": "1908.03645", "submitter": "Arindam Mitra", "authors": "Arindam Mitra and Chitta Baral and Aurgho Bhattacharjee and Ishan\n  Shrivastava", "title": "A Generate-Validate Approach to Answering Questions about Qualitative\n  Relationships", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Qualitative relationships describe how increasing or decreasing one property\n(e.g. altitude) affects another (e.g. temperature). They are an important\naspect of natural language question answering and are crucial for building\nchatbots or voice agents where one may enquire about qualitative relationships.\nRecently a dataset about question answering involving qualitative relationships\nhas been proposed, and a few approaches to answer such questions have been\nexplored, in the heart of which lies a semantic parser that converts the\nnatural language input to a suitable logical form. A problem with existing\nsemantic parsers is that they try to directly convert the input sentences to a\nlogical form. Since the output language varies with each application, it forces\nthe semantic parser to learn almost everything from scratch. In this paper, we\nshow that instead of using a semantic parser to produce the logical form, if we\napply the generate-validate framework i.e. generate a natural language\ndescription of the logical form and validate if the natural language\ndescription is followed from the input text, we get a better scope for transfer\nlearning and our method outperforms the state-of-the-art by a large margin of\n7.93%.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 22:06:06 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Mitra", "Arindam", ""], ["Baral", "Chitta", ""], ["Bhattacharjee", "Aurgho", ""], ["Shrivastava", "Ishan", ""]]}, {"id": "1908.03650", "submitter": "Rishiraj Saha Roy", "authors": "Zhen Jia, Abdalghani Abujabal, Rishiraj Saha Roy, Jannik Stroetgen,\n  Gerhard Weikum", "title": "TEQUILA: Temporal Question Answering over Knowledge Bases", "comments": "CIKM 2018 Short Paper", "journal-ref": "CIKM 2018", "doi": "10.1145/3269206.3269247", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering over knowledge bases (KB-QA) poses challenges in handling\ncomplex questions that need to be decomposed into sub-questions. An important\ncase, addressed here, is that of temporal questions, where cues for temporal\nrelations need to be discovered and handled. We present TEQUILA, an enabler\nmethod for temporal QA that can run on top of any KB-QA engine. TEQUILA has\nfour stages. It detects if a question has temporal intent. It decomposes and\nrewrites the question into non-temporal sub-questions and temporal constraints.\nAnswers to sub-questions are then retrieved from the underlying KB-QA engine.\nFinally, TEQUILA uses constraint reasoning on temporal intervals to compute\nfinal answers to the full question. Comparisons against state-of-the-art\nbaselines show the viability of our method.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 22:41:20 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 15:35:36 GMT"}, {"version": "v3", "created": "Tue, 5 Nov 2019 15:32:19 GMT"}, {"version": "v4", "created": "Mon, 25 Jan 2021 09:20:05 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Jia", "Zhen", ""], ["Abujabal", "Abdalghani", ""], ["Roy", "Rishiraj Saha", ""], ["Stroetgen", "Jannik", ""], ["Weikum", "Gerhard", ""]]}, {"id": "1908.03734", "submitter": "Mythilisharan Pala", "authors": "Mythili Sharan Pala, Parayitam Laxminarayana, A.V. Ramana", "title": "Unsupervised Stemming based Language Model for Telugu Broadcast News\n  Transcription", "comments": "first draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Indian Languages , native speakers are able to understand new words formed\nby either combining or modifying root words with tense and / or gender. Due to\ndata insufficiency, Automatic Speech Recognition system (ASR) may not\naccommodate all the words in the language model irrespective of the size of the\ntext corpus. It also becomes computationally challenging if the volume of the\ndata increases exponentially due to morphological changes to the root word. In\nthis paper a new unsupervised method is proposed for a Indian language: Telugu,\nbased on the unsupervised method for Hindi, to generate the Out of Vocabulary\n(OOV) words in the language model. By using techniques like smoothing and\ninterpolation of pre-processed data with supervised and unsupervised stemming,\ndifferent issues in language model for Indian language: Telugu has been\naddressed. We observe that the smoothing techniques Witten-Bell and Kneser-Ney\nperform well when compared to other techniques on pre-processed data from\nsupervised learning. The ASRs accuracy is improved by 0.76% and 0.94% with\nsupervised and unsupervised stemming respectively.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 11:39:17 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Pala", "Mythili Sharan", ""], ["Laxminarayana", "Parayitam", ""], ["Ramana", "A. V.", ""]]}, {"id": "1908.03971", "submitter": "Sajad Darabi", "authors": "Sajad Darabi, Mohammad Kachuee, Shayan Fazeli, and Majid Sarrafzadeh", "title": "TAPER: Time-Aware Patient EHR Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective representation learning of electronic health records is a\nchallenging task and is becoming more important as the availability of such\ndata is becoming pervasive. The data contained in these records are irregular\nand contain multiple modalities such as notes, and medical codes. They are\npreempted by medical conditions the patient may have, and are typically jotted\ndown by medical staff. Accompanying codes are notes containing valuable\ninformation about patients beyond the structured information contained in\nelectronic health records. We use transformer networks and the recently\nproposed BERT language model to embed these data streams into a unified vector\nrepresentation. The presented approach effectively encodes a patient's visit\ndata into a single distributed representation, which can be used for downstream\ntasks. Our model demonstrates superior performance and generalization on\nmortality, readmission and length of stay tasks using the publicly available\nMIMIC-III ICU dataset. Code avaialble at\nhttps://github.com/sajaddarabi/TAPER-EHR\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 23:15:23 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 02:36:35 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2019 06:00:56 GMT"}, {"version": "v4", "created": "Sun, 3 May 2020 10:32:10 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Darabi", "Sajad", ""], ["Kachuee", "Mohammad", ""], ["Fazeli", "Shayan", ""], ["Sarrafzadeh", "Majid", ""]]}, {"id": "1908.04042", "submitter": "Dominik Kowald PhD", "authors": "Emanuel Lacic, Dominik Kowald, Dieter Theiler, Matthias Traub, Lucky\n  Kuffer, Stefanie Lindstaedt, Elisabeth Lex", "title": "Evaluating Tag Recommendations for E-Book Annotation Using a Semantic\n  Similarity Metric", "comments": "REVEAL Workshop @ RecSys'2019, Kopenhagen, Denmark", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present our work to support publishers and editors in\nfinding descriptive tags for e-books through tag recommendations. We propose a\nhybrid tag recommendation system for e-books, which leverages search query\nterms from Amazon users and e-book metadata, which is assigned by publishers\nand editors. Our idea is to mimic the vocabulary of users in Amazon, who search\nfor and review e-books, and to combine these search terms with editor tags in a\nhybrid tag recommendation approach. In total, we evaluate 19 tag recommendation\nalgorithms on the review content of Amazon users, which reflects the readers'\nvocabulary. Our results show that we can improve the performance of tag\nrecommender systems for e-books both concerning tag recommendation accuracy,\ndiversity as well as a novel semantic similarity metric, which we also propose\nin this paper.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 08:04:42 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Lacic", "Emanuel", ""], ["Kowald", "Dominik", ""], ["Theiler", "Dieter", ""], ["Traub", "Matthias", ""], ["Kuffer", "Lucky", ""], ["Lindstaedt", "Stefanie", ""], ["Lex", "Elisabeth", ""]]}, {"id": "1908.04092", "submitter": "Federico Marinelli", "authors": "Federico Marinelli, Alessandra Cervone, Giuliano Tortoreto, Evgeny A.\n  Stepanov, Giuseppe Di Fabbrizio, Giuseppe Riccardi", "title": "Active Annotation: bootstrapping annotation lexicon and guidelines for\n  supervised NLU learning", "comments": "4 pages", "journal-ref": "INTERSPEECH 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Natural Language Understanding (NLU) models are typically trained in a\nsupervised learning framework. In the case of intent classification, the\npredicted labels are predefined and based on the designed annotation schema\nwhile the labelling process is based on a laborious task where annotators\nmanually inspect each utterance and assign the corresponding label. We propose\nan Active Annotation (AA) approach where we combine an unsupervised learning\nmethod in the embedding space, a human-in-the-loop verification process, and\nlinguistic insights to create lexicons that can be open categories and adapted\nover time. In particular, annotators define the y-label space on-the-fly during\nthe annotation using an iterative process and without the need for prior\nknowledge about the input data. We evaluate the proposed annotation paradigm in\na real use-case NLU scenario. Results show that our Active Annotation paradigm\nachieves accurate and higher quality training data, with an annotation speed of\nan order of magnitude higher with respect to the traditional human-only driven\nbaseline annotation methodology.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 11:20:29 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Marinelli", "Federico", ""], ["Cervone", "Alessandra", ""], ["Tortoreto", "Giuliano", ""], ["Stepanov", "Evgeny A.", ""], ["Di Fabbrizio", "Giuseppe", ""], ["Riccardi", "Giuseppe", ""]]}, {"id": "1908.04200", "submitter": "Roman Vainshtein", "authors": "Roman Vainshtein, Gilad Katz, Bracha Shapira, Lior Rokach", "title": "Assessing the Quality of Scientific Papers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A multitude of factors are responsible for the overall quality of scientific\npapers, including readability, linguistic quality, fluency,semantic complexity,\nand of course domain-specific technical factors. These factors vary from one\nfield of study to another. In this paper, we propose a measure and method for\nassessing the overall quality of the scientific papers in a particular field of\nstudy. We evaluate our method in the computer science domain, but it can be\napplied to other technical and scientific fields.Our method is based on the\ncorpus linguistics technique. This technique enables the extraction of required\ninformation and knowledge associated with a specific domain. For this purpose,\nwe have created a large corpus, consisting of papers from very high impact\nconferences. First, we analyze this corpus in order to extract rich\ndomain-specific terminology and knowledge. Then we use the acquired knowledge\nto estimate the quality of scientific papers by applying our proposed measure.\nWe examine our measure on high and low scientific impact test corpora. Our\nresults show a significant difference in the measure scores of the high and low\nimpact test corpora. Second, we develop a classifier based on our proposed\nmeasure and compare it to the baseline classifier. Our results show that the\nclassifier based on our measure over-performed the baseline classifier. Based\non the presented results the proposed measure and the technique can be used for\nautomated assessment of scientific papers.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 15:32:10 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Vainshtein", "Roman", ""], ["Katz", "Gilad", ""], ["Shapira", "Bracha", ""], ["Rokach", "Lior", ""]]}, {"id": "1908.04211", "submitter": "Damian Pascual", "authors": "Gino Brunner, Yang Liu, Dami\\'an Pascual, Oliver Richter, Massimiliano\n  Ciaramita, Roger Wattenhofer", "title": "On Identifiability in Transformers", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we delve deep in the Transformer architecture by investigating\ntwo of its core components: self-attention and contextual embeddings. In\nparticular, we study the identifiability of attention weights and token\nembeddings, and the aggregation of context into hidden tokens. We show that,\nfor sequences longer than the attention head dimension, attention weights are\nnot identifiable. We propose effective attention as a complementary tool for\nimproving explanatory interpretations based on attention. Furthermore, we show\nthat input tokens retain to a large degree their identity across the model. We\nalso find evidence suggesting that identity information is mainly encoded in\nthe angle of the embeddings and gradually decreases with depth. Finally, we\ndemonstrate strong mixing of input information in the generation of contextual\nembeddings by means of a novel quantification method based on gradient\nattribution. Overall, we show that self-attention distributions are not\ndirectly interpretable and present tools to better understand and further\ninvestigate Transformer models.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 15:48:34 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 13:04:40 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 16:59:31 GMT"}, {"version": "v4", "created": "Fri, 7 Feb 2020 17:44:52 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Brunner", "Gino", ""], ["Liu", "Yang", ""], ["Pascual", "Dami\u00e1n", ""], ["Richter", "Oliver", ""], ["Ciaramita", "Massimiliano", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "1908.04212", "submitter": "Miikka Silfverberg", "authors": "Teemu Ruokolainen, Pekka Kauppinen, Miikka Silfverberg, Krister\n  Lind\\'en", "title": "A Finnish News Corpus for Named Entity Recognition", "comments": null, "journal-ref": null, "doi": "10.1007/s10579-019-09471-7", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a corpus of Finnish news articles with a manually prepared named\nentity annotation. The corpus consists of 953 articles (193,742 word tokens)\nwith six named entity classes (organization, location, person, product, event,\nand date). The articles are extracted from the archives of Digitoday, a Finnish\nonline technology news source. The corpus is available for research purposes.\nWe present baseline experiments on the corpus using a rule-based and two deep\nlearning systems on two, in-domain and out-of-domain, test sets.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 15:49:57 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Ruokolainen", "Teemu", ""], ["Kauppinen", "Pekka", ""], ["Silfverberg", "Miikka", ""], ["Lind\u00e9n", "Krister", ""]]}, {"id": "1908.04319", "submitter": "Sean Welleck", "authors": "Sean Welleck, Ilia Kulikov, Stephen Roller, Emily Dinan, Kyunghyun\n  Cho, Jason Weston", "title": "Neural Text Generation with Unlikelihood Training", "comments": "Sean Welleck and Ilia Kulikov contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural text generation is a key tool in natural language applications, but it\nis well known there are major problems at its core. In particular, standard\nlikelihood training and decoding leads to dull and repetitive outputs. While\nsome post-hoc fixes have been proposed, in particular top-$k$ and nucleus\nsampling, they do not address the fact that the token-level probabilities\npredicted by the model are poor. In this paper we show that the likelihood\nobjective itself is at fault, resulting in a model that assigns too much\nprobability to sequences containing repeats and frequent words, unlike those\nfrom the human training distribution. We propose a new objective, unlikelihood\ntraining, which forces unlikely generations to be assigned lower probability by\nthe model. We show that both token and sequence level unlikelihood training\ngive less repetitive, less dull text while maintaining perplexity, giving\nsuperior generations using standard greedy or beam search. According to human\nevaluations, our approach with standard beam search also outperforms the\ncurrently popular decoding methods of nucleus sampling or beam blocking, thus\nproviding a strong alternative to existing techniques.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 18:09:04 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 23:57:44 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Welleck", "Sean", ""], ["Kulikov", "Ilia", ""], ["Roller", "Stephen", ""], ["Dinan", "Emily", ""], ["Cho", "Kyunghyun", ""], ["Weston", "Jason", ""]]}, {"id": "1908.04332", "submitter": "Sanidhya Mangal", "authors": "Sanidhya Mangal, Poorva Joshi and Rahul Modak", "title": "LSTM vs. GRU vs. Bidirectional RNN for script generation", "comments": "7 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Scripts are an important part of any TV series. They narrate movements,\nactions and expressions of characters. In this paper, a case study is presented\non how different sequence to sequence deep learning models perform in the task\nof generating new conversations between characters as well as new scenarios on\nthe basis of a script (previous conversations). A comprehensive comparison\nbetween these models, namely, LSTM, GRU and Bidirectional RNN is presented. All\nthe models are designed to learn the sequence of recurring characters from the\ninput sequence. Each input sequence will contain, say \"n\" characters, and the\ncorresponding targets will contain the same number of characters, except, they\nwill be shifted one character to the right. In this manner, input and output\nsequences are generated and used to train the models. A closer analysis of\nexplored models performance and efficiency is delineated with the help of graph\nplots and generated texts by taking some input string. These graphs describe\nboth, intraneural performance and interneural model performance for each model.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 18:39:10 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Mangal", "Sanidhya", ""], ["Joshi", "Poorva", ""], ["Modak", "Rahul", ""]]}, {"id": "1908.04364", "submitter": "Nitish Kulkarni", "authors": "Mansi Gupta, Nitish Kulkarni, Raghuveer Chanda, Anirudha Rayasam and\n  Zachary C Lipton", "title": "AmazonQA: A Review-Based Question Answering Task", "comments": "8 pages, 7 figures; IJCAI-19; first three authors contribute equally.\n  Data and code available at https://github.com/amazonqa/amazonqa", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Every day, thousands of customers post questions on Amazon product pages.\nAfter some time, if they are fortunate, a knowledgeable customer might answer\ntheir question. Observing that many questions can be answered based upon the\navailable product reviews, we propose the task of review-based QA. Given a\ncorpus of reviews and a question, the QA system synthesizes an answer. To this\nend, we introduce a new dataset and propose a method that combines information\nretrieval techniques for selecting relevant reviews (given a question) and\n\"reading comprehension\" models for synthesizing an answer (given a question and\nreview). Our dataset consists of 923k questions, 3.6M answers and 14M reviews\nacross 156k products. Building on the well-known Amazon dataset, we collect\nadditional annotations, marking each question as either answerable or\nunanswerable based on the available reviews. A deployed system could first\nclassify a question as answerable and then attempt to generate an answer.\nNotably, unlike many popular QA datasets, here, the questions, passages, and\nanswers are all extracted from real human interactions. We evaluate numerous\nmodels for answer generation and propose strong baselines, demonstrating the\nchallenging nature of this new task.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 20:18:50 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 23:34:19 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Gupta", "Mansi", ""], ["Kulkarni", "Nitish", ""], ["Chanda", "Raghuveer", ""], ["Rayasam", "Anirudha", ""], ["Lipton", "Zachary C", ""]]}, {"id": "1908.04369", "submitter": "Fangzhou Xie", "authors": "Fangzhou Xie", "title": "Wasserstein Index Generation Model: Automatic Generation of Time-series\n  Index with Application to Economic Policy Uncertainty", "comments": "Accepted at Economics Letters, and will be available online soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.CL q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I propose a novel method, the Wasserstein Index Generation model (WIG), to\ngenerate a public sentiment index automatically. To test the model`s\neffectiveness, an application to generate Economic Policy Uncertainty (EPU)\nindex is showcased.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 20:25:41 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 21:45:14 GMT"}, {"version": "v3", "created": "Sat, 2 Nov 2019 18:41:09 GMT"}, {"version": "v4", "created": "Mon, 25 Nov 2019 20:48:26 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Xie", "Fangzhou", ""]]}, {"id": "1908.04485", "submitter": "Surabhi Datta", "authors": "Surabhi Datta, Yuqi Si, Laritza Rodriguez, Sonya E Shooshan, Dina\n  Demner-Fushman, Kirk Roberts", "title": "Understanding Spatial Language in Radiology: Representation Framework,\n  Annotation, and Spatial Relation Extraction from Chest X-ray Reports using\n  Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a representation framework for extracting spatial information from\nradiology reports (Rad-SpRL). We annotated a total of 2000 chest X-ray reports\nwith 4 spatial roles corresponding to the common radiology entities. Our focus\nis on extracting detailed information of a radiologist's interpretation\ncontaining a radiographic finding, its anatomical location, corresponding\nprobable diagnoses, as well as associated hedging terms. For this, we propose a\ndeep learning-based natural language processing (NLP) method involving both\nword and character-level encodings. Specifically, we utilize a bidirectional\nlong short-term memory (Bi-LSTM) conditional random field (CRF) model for\nextracting the spatial roles. The model achieved average F1 measures of 90.28\nand 94.61 for extracting the Trajector and Landmark roles respectively whereas\nthe performance was moderate for Diagnosis and Hedge roles with average F1 of\n71.47 and 73.27 respectively. The corpus will soon be made available upon\nrequest.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 04:44:22 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Datta", "Surabhi", ""], ["Si", "Yuqi", ""], ["Rodriguez", "Laritza", ""], ["Shooshan", "Sonya E", ""], ["Demner-Fushman", "Dina", ""], ["Roberts", "Kirk", ""]]}, {"id": "1908.04530", "submitter": "Chen Wu", "authors": "Jiangnan Xia, Chen Wu, Ming Yan", "title": "Incorporating Relation Knowledge into Commonsense Reading Comprehension\n  with Multi-task Learning", "comments": "Accepted at CIKM'19, 4 pages", "journal-ref": null, "doi": "10.1145/3357384.3358165", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on how to take advantage of external relational knowledge\nto improve machine reading comprehension (MRC) with multi-task learning. Most\nof the traditional methods in MRC assume that the knowledge used to get the\ncorrect answer generally exists in the given documents. However, in real-world\ntask, part of knowledge may not be mentioned and machines should be equipped\nwith the ability to leverage external knowledge. In this paper, we integrate\nrelational knowledge into MRC model for commonsense reasoning. Specifically,\nbased on a pre-trained language model (LM). We design two auxiliary\nrelation-aware tasks to predict if there exists any commonsense relation and\nwhat is the relation type between two words, in order to better model the\ninteractions between document and candidate answer option. We conduct\nexperiments on two multi-choice benchmark datasets: the SemEval-2018 Task 11\nand the Cloze Story Test. The experimental results demonstrate the\neffectiveness of the proposed method, which achieves superior performance\ncompared with the comparable baselines on both datasets.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 08:28:05 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 09:35:42 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Xia", "Jiangnan", ""], ["Wu", "Chen", ""], ["Yan", "Ming", ""]]}, {"id": "1908.04531", "submitter": "Leon Derczynski", "authors": "Gudbjartur Ingi Sigurbergsson, Leon Derczynski", "title": "Offensive Language and Hate Speech Detection for Danish", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The presence of offensive language on social media platforms and the\nimplications this poses is becoming a major concern in modern society. Given\nthe enormous amount of content created every day, automatic methods are\nrequired to detect and deal with this type of content. Until now, most of the\nresearch has focused on solving the problem for the English language, while the\nproblem is multilingual.\n  We construct a Danish dataset containing user-generated comments from\n\\textit{Reddit} and \\textit{Facebook}. It contains user generated comments from\nvarious social media platforms, and to our knowledge, it is the first of its\nkind. Our dataset is annotated to capture various types and target of offensive\nlanguage. We develop four automatic classification systems, each designed to\nwork for both the English and the Danish language. In the detection of\noffensive language in English, the best performing system achieves a macro\naveraged F1-score of $0.74$, and the best performing system for Danish achieves\na macro averaged F1-score of $0.70$. In the detection of whether or not an\noffensive post is targeted, the best performing system for English achieves a\nmacro averaged F1-score of $0.62$, while the best performing system for Danish\nachieves a macro averaged F1-score of $0.73$. Finally, in the detection of the\ntarget type in a targeted offensive post, the best performing system for\nEnglish achieves a macro averaged F1-score of $0.56$, and the best performing\nsystem for Danish achieves a macro averaged F1-score of $0.63$.\n  Our work for both the English and the Danish language captures the type and\ntargets of offensive language, and present automatic methods for detecting\ndifferent kinds of offensive language such as hate speech and cyberbullying.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 08:29:48 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Sigurbergsson", "Gudbjartur Ingi", ""], ["Derczynski", "Leon", ""]]}, {"id": "1908.04567", "submitter": "Fernando Alva-Manchego", "authors": "Fernando Alva-Manchego, Louis Martin, Carolina Scarton, Lucia Specia", "title": "EASSE: Easier Automatic Sentence Simplification Evaluation", "comments": "EMNLP-IJCNLP 2019 Demo (Camera-ready Version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce EASSE, a Python package aiming to facilitate and standardise\nautomatic evaluation and comparison of Sentence Simplification (SS) systems.\nEASSE provides a single access point to a broad range of evaluation resources:\nstandard automatic metrics for assessing SS outputs (e.g. SARI), word-level\naccuracy scores for certain simplification transformations,\nreference-independent quality estimation features (e.g. compression ratio), and\nstandard test data for SS evaluation (e.g. TurkCorpus). Finally, EASSE\ngenerates easy-to-visualise reports on the various metrics and features above\nand on how a particular SS output fares against reference simplifications.\nThrough experiments, we show that these functionalities allow for better\ncomparison and understanding of the performance of SS systems.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 10:17:11 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 09:11:47 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Alva-Manchego", "Fernando", ""], ["Martin", "Louis", ""], ["Scarton", "Carolina", ""], ["Specia", "Lucia", ""]]}, {"id": "1908.04577", "submitter": "Chen Wu", "authors": "Wei Wang, Bin Bi, Ming Yan, Chen Wu, Zuyi Bao, Jiangnan Xia, Liwei\n  Peng, Luo Si", "title": "StructBERT: Incorporating Language Structures into Pre-training for Deep\n  Language Understanding", "comments": "10 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the pre-trained language model, BERT (and its robustly optimized\nversion RoBERTa), has attracted a lot of attention in natural language\nunderstanding (NLU), and achieved state-of-the-art accuracy in various NLU\ntasks, such as sentiment classification, natural language inference, semantic\ntextual similarity and question answering. Inspired by the linearization\nexploration work of Elman [8], we extend BERT to a new model, StructBERT, by\nincorporating language structures into pre-training. Specifically, we pre-train\nStructBERT with two auxiliary tasks to make the most of the sequential order of\nwords and sentences, which leverage language structures at the word and\nsentence levels, respectively. As a result, the new model is adapted to\ndifferent levels of language understanding required by downstream tasks. The\nStructBERT with structural pre-training gives surprisingly good empirical\nresults on a variety of downstream tasks, including pushing the\nstate-of-the-art on the GLUE benchmark to 89.0 (outperforming all published\nmodels), the F1 score on SQuAD v1.1 question answering to 93.0, the accuracy on\nSNLI to 91.7.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 11:12:58 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 05:01:34 GMT"}, {"version": "v3", "created": "Fri, 27 Sep 2019 05:44:38 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Wang", "Wei", ""], ["Bi", "Bin", ""], ["Yan", "Ming", ""], ["Wu", "Chen", ""], ["Bao", "Zuyi", ""], ["Xia", "Jiangnan", ""], ["Peng", "Liwei", ""], ["Si", "Luo", ""]]}, {"id": "1908.04621", "submitter": "Chien-Sheng Wu", "authors": "Chien-Sheng Wu, Andrea Madotto, Zhaojiang Lin, Peng Xu, Pascale Fung", "title": "Getting To Know You: User Attribute Extraction from Dialogues", "comments": "1st Workshop on NLP for Conversational AI @ ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User attributes provide rich and useful information for user understanding,\nyet structured and easy-to-use attributes are often sparsely populated. In this\npaper, we leverage dialogues with conversational agents, which contain strong\nsuggestions of user information, to automatically extract user attributes.\nSince no existing dataset is available for this purpose, we apply distant\nsupervision to train our proposed two-stage attribute extractor, which\nsurpasses several retrieval and generation baselines on human evaluation.\nMeanwhile, we discuss potential applications (e.g., personalized recommendation\nand dialogue systems) of such extracted user attributes, and point out current\nlimitations to cast light on future work.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 13:03:58 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Wu", "Chien-Sheng", ""], ["Madotto", "Andrea", ""], ["Lin", "Zhaojiang", ""], ["Xu", "Peng", ""], ["Fung", "Pascale", ""]]}, {"id": "1908.04626", "submitter": "Yuval Pinter", "authors": "Sarah Wiegreffe and Yuval Pinter", "title": "Attention is not not Explanation", "comments": "Accepted to EMNLP 2019; related blog post at\n  https://medium.com/@yuvalpinter/attention-is-not-not-explanation-dbc25b534017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attention mechanisms play a central role in NLP systems, especially within\nrecurrent neural network (RNN) models. Recently, there has been increasing\ninterest in whether or not the intermediate representations offered by these\nmodules may be used to explain the reasoning for a model's prediction, and\nconsequently reach insights regarding the model's decision-making process. A\nrecent paper claims that `Attention is not Explanation' (Jain and Wallace,\n2019). We challenge many of the assumptions underlying this work, arguing that\nsuch a claim depends on one's definition of explanation, and that testing it\nneeds to take into account all elements of the model, using a rigorous\nexperimental design. We propose four alternative tests to determine\nwhen/whether attention can be used as explanation: a simple uniform-weights\nbaseline; a variance calibration based on multiple random seed runs; a\ndiagnostic framework using frozen weights from pretrained models; and an\nend-to-end adversarial attention training protocol. Each allows for meaningful\ninterpretation of attention mechanisms in RNN models. We show that even when\nreliable adversarial distributions can be found, they don't perform well on the\nsimple diagnostic, indicating that prior work does not disprove the usefulness\nof attention mechanisms for explainability.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 13:15:04 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 14:11:27 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Wiegreffe", "Sarah", ""], ["Pinter", "Yuval", ""]]}, {"id": "1908.04660", "submitter": "Peter Potash", "authors": "Peter Potash and Kaheer Suleman", "title": "Playing log(N)-Questions over Sentences", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a two-agent game wherein a questioner must be able to conjure\ndiscerning questions between sentences, incorporate responses from an answerer,\nand keep track of a hypothesis state. The questioner must be able to understand\nthe information required to make its final guess, while also being able to\nreason over the game's text environment based on the answerer's responses. We\nexperiment with an end-to-end model where both agents can learn simultaneously\nto play the game, showing that simultaneously achieving high game accuracy and\nproducing meaningful questions can be a difficult trade-off.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 14:31:05 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Potash", "Peter", ""], ["Suleman", "Kaheer", ""]]}, {"id": "1908.04664", "submitter": "Huayang Li", "authors": "Huayang Li, Guoping Huang, Deng Cai, Lemao Liu", "title": "Neural Machine Translation with Noisy Lexical Constraints", "comments": "This paper was accepted by TASLP. See\n  https://ieeexplore.ieee.org/document/9108255/ for the final version", "journal-ref": "TASLP 2020", "doi": "10.1109/TASLP.2020.2999724", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexically constrained decoding for machine translation has shown to be\nbeneficial in previous studies. Unfortunately, constraints provided by users\nmay contain mistakes in real-world situations. It is still an open question\nthat how to manipulate these noisy constraints in such practical scenarios. We\npresent a novel framework that treats constraints as external memories. In this\nsoft manner, a mistaken constraint can be corrected. Experiments demonstrate\nthat our approach can achieve substantial BLEU gains in handling noisy\nconstraints. These results motivate us to apply the proposed approach on a new\nscenario where constraints are generated without the help of users. Experiments\nshow that our approach can indeed improve the translation quality with the\nautomatically generated constraints.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 14:32:56 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 03:33:52 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2021 05:17:07 GMT"}, {"version": "v4", "created": "Tue, 26 Jan 2021 02:09:39 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Li", "Huayang", ""], ["Huang", "Guoping", ""], ["Cai", "Deng", ""], ["Liu", "Lemao", ""]]}, {"id": "1908.04728", "submitter": "Sanjay Subramanian", "authors": "Sanjay Subramanian and Dan Roth", "title": "Improving Generalization in Coreference Resolution via Adversarial\n  Training", "comments": "*SEM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order for coreference resolution systems to be useful in practice, they\nmust be able to generalize to new text. In this work, we demonstrate that the\nperformance of the state-of-the-art system decreases when the names of PER and\nGPE named entities in the CoNLL dataset are changed to names that do not occur\nin the training set. We use the technique of adversarial gradient-based\ntraining to retrain the state-of-the-art system and demonstrate that the\nretrained system achieves higher performance on the CoNLL dataset (both with\nand without the change of named entities) and the GAP dataset.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 16:39:48 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Subramanian", "Sanjay", ""], ["Roth", "Dan", ""]]}, {"id": "1908.04737", "submitter": "Pavel Denisov", "authors": "Pavel Denisov, Ngoc Thang Vu", "title": "End-to-End Multi-Speaker Speech Recognition using Speaker Embeddings and\n  Transfer Learning", "comments": "Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents our latest investigation on end-to-end automatic speech\nrecognition (ASR) for overlapped speech. We propose to train an end-to-end\nsystem conditioned on speaker embeddings and further improved by transfer\nlearning from clean speech. This proposed framework does not require any\nparallel non-overlapped speech materials and is independent of the number of\nspeakers. Our experimental results on overlapped speech datasets show that\njoint conditioning on speaker embeddings and transfer learning significantly\nimproves the ASR performance.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 16:56:41 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Denisov", "Pavel", ""], ["Vu", "Ngoc Thang", ""]]}, {"id": "1908.04743", "submitter": "Pavel Denisov", "authors": "Pavel Denisov, Ngoc Thang Vu", "title": "IMS-Speech: A Speech to Text Tool", "comments": "ESSV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present the IMS-Speech, a web based tool for German and English speech\ntranscription aiming to facilitate research in various disciplines which\nrequire accesses to lexical information in spoken language materials. This tool\nis based on modern open source software stack, advanced speech recognition\nmethods and public data resources and is freely available for academic\nresearchers. The utilized models are built to be generic in order to provide\ntranscriptions of competitive accuracy on a diverse set of tasks and\nconditions.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 17:03:24 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Denisov", "Pavel", ""], ["Vu", "Ngoc Thang", ""]]}, {"id": "1908.04755", "submitter": "Yufang Hou", "authors": "Yufang Hou", "title": "Fine-grained Information Status Classification Using Discourse\n  Context-Aware Self-Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work on bridging anaphora recognition (Hou et al., 2013a) casts the\nproblem as a subtask of learning fine-grained information status (IS). However,\nthese systems heavily depend on many hand-crafted linguistic features. In this\npaper, we propose a discourse context-aware self-attention neural network model\nfor fine-grained IS classification. On the ISNotes corpus (Markert et al.,\n2012), our model with the contextually-encoded word representations (BERT)\n(Devlin et al., 2018) achieves new state-of-the-art performances on\nfine-grained IS classification, obtaining a 4.1% absolute overall accuracy\nimprovement compared to Hou et al. (2013a). More importantly, we also show an\nimprovement of 3.9% F1 for bridging anaphora recognition without using any\ncomplex hand-crafted semantic features designed for capturing the bridging\nphenomenon.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 17:20:51 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Hou", "Yufang", ""]]}, {"id": "1908.04777", "submitter": "Xusen Yin", "authors": "Xusen Yin and Jonathan May", "title": "Learn How to Cook a New Recipe in a New House: Using Map\n  Familiarization, Curriculum Learning, and Bandit Feedback to Learn Families\n  of Text-Based Adventure Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of learning to play families of text-based computer\nadventure games, i.e., fully textual environments with a common theme (e.g.\ncooking) and goal (e.g. prepare a meal from a recipe) but with different\nspecifics; new instances of such games are relatively straightforward for\nhumans to master after a brief exposure to the genre but have been curiously\ndifficult for computer agents to learn. We find that the deep Q-learning\nstrategies that have been successfully leveraged for superhuman performance in\nsingle-instance action video games can be applied to learn families of text\nvideo games when adopting simple strategies that correlate with human-like\nlearning behavior. Specifically, we build agents that learn to tackle simple\nscenarios before more complex ones using curriculum learning, that familiarize\nthemselves in an unfamiliar environment by navigating before acting, and that\nexplore uncertain environments more thoroughly using contextual multi-armed\nbandit decision policies. We demonstrate improved task completion rates over\nreasonable baselines when evaluating on never-before-seen games of that theme.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 17:48:10 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 05:13:21 GMT"}, {"version": "v3", "created": "Mon, 20 Apr 2020 18:59:09 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Yin", "Xusen", ""], ["May", "Jonathan", ""]]}, {"id": "1908.04812", "submitter": "Taesun Whang", "authors": "Taesun Whang, Dongyub Lee, Chanhee Lee, Kisu Yang, Dongsuk Oh,\n  HeuiSeok Lim", "title": "An Effective Domain Adaptive Post-Training Method for BERT in Response\n  Selection", "comments": "INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on multi-turn response selection in a retrieval-based dialog system.\nIn this paper, we utilize the powerful pre-trained language model\nBi-directional Encoder Representations from Transformer (BERT) for a multi-turn\ndialog system and propose a highly effective post-training method on\ndomain-specific corpus. Although BERT is easily adopted to various NLP tasks\nand outperforms previous baselines of each task, it still has limitations if a\ntask corpus is too focused on a certain domain. Post-training on\ndomain-specific corpus (e.g., Ubuntu Corpus) helps the model to train\ncontextualized representations and words that do not appear in general corpus\n(e.g., English Wikipedia). Experimental results show that our approach achieves\nnew state-of-the-art on two response selection benchmarks (i.e., Ubuntu Corpus\nV1, Advising Corpus) performance improvement by 5.9% and 6% on R@1.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 18:24:29 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 02:37:49 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Whang", "Taesun", ""], ["Lee", "Dongyub", ""], ["Lee", "Chanhee", ""], ["Yang", "Kisu", ""], ["Oh", "Dongsuk", ""], ["Lim", "HeuiSeok", ""]]}, {"id": "1908.04832", "submitter": "Kevin Bowden", "authors": "Kevin K. Bowden, Jiaqi Wu, Wen Cui, Juraj Juraska, Vrindavan Harrison,\n  Brian Schwarzmann, Nicholas Santer, Steve Whittaker, Marilyn Walker", "title": "Entertaining and Opinionated but Too Controlling: A Large-Scale User\n  Study of an Open Domain Alexa Prize System", "comments": "To appear in 1st International Conference on Conversational User\n  Interfaces (CUI 2019)", "journal-ref": null, "doi": "10.1145/3342775.3342792", "report-no": null, "categories": "cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational systems typically focus on functional tasks such as scheduling\nappointments or creating todo lists. Instead we design and evaluate SlugBot\n(SB), one of 8 semifinalists in the 2018 AlexaPrize, whose goal is to support\ncasual open-domain social inter-action. This novel application requires both\nbroad topic coverage and engaging interactive skills. We developed a new\ntechnical approach to meet this demanding situation by crowd-sourcing novel\ncontent and introducing playful conversational strategies based on storytelling\nand games. We collected over 10,000 conversations during August 2018 as part of\nthe Alexa Prize competition. We also conducted an in-lab follow-up qualitative\nevaluation. Over-all users found SB moderately engaging; conversations averaged\n3.6 minutes and involved 26 user turns. However, users reacted very differently\nto different conversation subtypes. Storytelling and games were evaluated\npositively; these were seen as entertaining with predictable interactive\nstructure. They also led users to impute personality and intelligence to SB. In\ncontrast, search and general Chit-Chat induced coverage problems; here users\nfound it hard to infer what topics SB could understand, with these\nconversations seen as being too system-driven. Theoretical and design\nimplications suggest a move away from conversational systems that simply\nprovide factual information. Future systems should be designed to have their\nown opinions with personal stories to share, and SB provides an example of how\nwe might achieve this.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 19:10:36 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Bowden", "Kevin K.", ""], ["Wu", "Jiaqi", ""], ["Cui", "Wen", ""], ["Juraska", "Juraj", ""], ["Harrison", "Vrindavan", ""], ["Schwarzmann", "Brian", ""], ["Santer", "Nicholas", ""], ["Whittaker", "Steve", ""], ["Walker", "Marilyn", ""]]}, {"id": "1908.04877", "submitter": "Hong Wang", "authors": "Hong Wang, Wenhan Xiong, Mo Yu, Xiaoxiao Guo, Shiyu Chang, William\n  Yang Wang", "title": "Meta Reasoning over Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to reason over learned knowledge is an innate ability for humans\nand humans can easily master new reasoning rules with only a few\ndemonstrations. While most existing studies on knowledge graph (KG) reasoning\nassume enough training examples, we study the challenging and practical problem\nof few-shot knowledge graph reasoning under the paradigm of meta-learning. We\npropose a new meta learning framework that effectively utilizes the\ntask-specific meta information such as local graph neighbors and reasoning\npaths in KGs. Specifically, we design a meta-encoder that encodes the meta\ninformation into task-specific initialization parameters for different tasks.\nThis allows our reasoning module to have diverse starting points when learning\nto reason over different relations, which is expected to better fit the target\ntask. On two few-shot knowledge base completion benchmarks, we show that the\naugmented task-specific meta-encoder yields much better initial point than MAML\nand outperforms several few-shot learning baselines.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 22:21:25 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Wang", "Hong", ""], ["Xiong", "Wenhan", ""], ["Yu", "Mo", ""], ["Guo", "Xiaoxiao", ""], ["Chang", "Shiyu", ""], ["Wang", "William Yang", ""]]}, {"id": "1908.04895", "submitter": "Prodromos Kolyvakis Mr.", "authors": "Prodromos Kolyvakis, Alexandros Kalousis, Dimitris Kiritsis", "title": "HyperKG: Hyperbolic Knowledge Graph Embeddings for Knowledge Base\n  Completion", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning embeddings of entities and relations existing in knowledge bases\nallows the discovery of hidden patterns in data. In this work, we examine the\ngeometrical space's contribution to the task of knowledge base completion. We\nfocus on the family of translational models, whose performance has been\nlagging, and propose a model, dubbed HyperKG, which exploits the hyperbolic\nspace in order to better reflect the topological properties of knowledge bases.\nWe investigate the type of regularities that our model can capture and we show\nthat it is a prominent candidate for effectively representing a subset of\nDatalog rules. We empirically show, using a variety of link prediction\ndatasets, that hyperbolic space allows to narrow down significantly the\nperformance gap between translational and bilinear models.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 00:24:54 GMT"}, {"version": "v2", "created": "Sat, 17 Aug 2019 21:45:59 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Kolyvakis", "Prodromos", ""], ["Kalousis", "Alexandros", ""], ["Kiritsis", "Dimitris", ""]]}, {"id": "1908.04899", "submitter": "Jordhy Fernando", "authors": "Jordhy Fernando, Masayu Leylia Khodra, Ali Akbar Septiandri", "title": "Aspect and Opinion Terms Extraction Using Double Embeddings and\n  Attention Mechanism for Indonesian Hotel Reviews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect and opinion terms extraction from review texts is one of the key tasks\nin aspect-based sentiment analysis. In order to extract aspect and opinion\nterms for Indonesian hotel reviews, we adapt double embeddings feature and\nattention mechanism that outperform the best system at SemEval 2015 and 2016.\nWe conduct experiments using 4000 reviews to find the best configuration and\nshow the influences of double embeddings and attention mechanism toward model\nperformance. Using 1000 reviews for evaluation, we achieved F1-measure of 0.914\nand 0.90 for aspect and opinion terms extraction in token and entity (term)\nlevel respectively.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 00:38:13 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 13:12:20 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Fernando", "Jordhy", ""], ["Khodra", "Masayu Leylia", ""], ["Septiandri", "Ali Akbar", ""]]}, {"id": "1908.04911", "submitter": "Nicolas Christianson", "authors": "Nicolas H. Christianson, Ann Sizemore Blevins, Danielle S. Bassett", "title": "Architecture and evolution of semantic networks in mathematics texts", "comments": "22 pages, 5 figures", "journal-ref": null, "doi": "10.1098/rspa.2019.0741", "report-no": null, "categories": "cs.CL physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge is a network of interconnected concepts. Yet, precisely how the\ntopological structure of knowledge constrains its acquisition remains unknown,\nhampering the development of learning enhancement strategies. Here we study the\ntopological structure of semantic networks reflecting mathematical concepts and\ntheir relations in college-level linear algebra texts. We hypothesize that\nthese networks will exhibit structural order, reflecting the logical sequence\nof topics that ensures accessibility. We find that the networks exhibit strong\ncore-periphery architecture, where a dense core of concepts presented early is\ncomplemented with a sparse periphery presented evenly throughout the\nexposition; the latter is composed of many small modules each reflecting more\nnarrow domains. Using tools from applied topology, we find that the\nexpositional evolution of the semantic networks produces and subsequently fills\nknowledge gaps, and that the density of these gaps tracks negatively with\ncommunity ratings of each textbook. Broadly, our study lays the groundwork for\nfuture efforts developing optimal design principles for textbook exposition and\nteaching in a classroom setting.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 01:38:07 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 22:10:22 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Christianson", "Nicolas H.", ""], ["Blevins", "Ann Sizemore", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1908.04917", "submitter": "Ya Zhao", "authors": "Ya Zhao, Rui Xu, Mingli Song", "title": "A Cascade Sequence-to-Sequence Model for Chinese Mandarin Lip Reading", "comments": "ACM MM Asia 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lip reading aims at decoding texts from the movement of a speaker's mouth. In\nrecent years, lip reading methods have made great progress for English, at both\nword-level and sentence-level. Unlike English, however, Chinese Mandarin is a\ntone-based language and relies on pitches to distinguish lexical or grammatical\nmeaning, which significantly increases the ambiguity for the lip reading task.\nIn this paper, we propose a Cascade Sequence-to-Sequence Model for Chinese\nMandarin (CSSMCM) lip reading, which explicitly models tones when predicting\nsentence. Tones are modeled based on visual information and syntactic\nstructure, and are used to predict sentence along with visual information and\nsyntactic structure. In order to evaluate CSSMCM, a dataset called CMLR\n(Chinese Mandarin Lip Reading) is collected and released, consisting of over\n100,000 natural sentences from China Network Television website. When trained\non CMLR dataset, the proposed CSSMCM surpasses the performance of\nstate-of-the-art lip reading frameworks, which confirms the effectiveness of\nexplicit modeling of tones for Chinese Mandarin lip reading.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 01:49:32 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 01:31:38 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Zhao", "Ya", ""], ["Xu", "Rui", ""], ["Song", "Mingli", ""]]}, {"id": "1908.04919", "submitter": "Qingzhong Wang", "authors": "Qingzhong Wang and Antoni B. Chan", "title": "Towards Diverse and Accurate Image Captions via Reinforcing\n  Determinantal Point Process", "comments": "14 pages. Code is comming soon,please pay attention to my personal\n  page visal.cs.cityu.edu.hk/people/qingzhong-wang/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although significant progress has been made in the field of automatic image\ncaptioning, it is still a challenging task. Previous works normally pay much\nattention to improving the quality of the generated captions but ignore the\ndiversity of captions. In this paper, we combine determinantal point process\n(DPP) and reinforcement learning (RL) and propose a novel reinforcing DPP\n(R-DPP) approach to generate a set of captions with high quality and diversity\nfor an image. We show that R-DPP performs better on accuracy and diversity than\nusing noise as a control signal (GANs, VAEs). Moreover, R-DPP is able to\npreserve the modes of the learned distribution. Hence, beam search algorithm\ncan be applied to generate a single accurate caption, which performs better\nthan other RL-based models.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 01:51:49 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Wang", "Qingzhong", ""], ["Chan", "Antoni B.", ""]]}, {"id": "1908.04926", "submitter": "Daniel Khashabi Mr.", "authors": "Daniel Khashabi", "title": "Reasoning-Driven Question-Answering for Natural Language Understanding", "comments": "PhD Dissertation; Presented to Computer and Information Sciences\n  department, at the University of Pennsylvania", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Natural language understanding (NLU) of text is a fundamental challenge in\nAI, and it has received significant attention throughout the history of NLP\nresearch. This primary goal has been studied under different tasks, such as\nQuestion Answering (QA) and Textual Entailment (TE). In this thesis, we\ninvestigate the NLU problem through the QA task and focus on the aspects that\nmake it a challenge for the current state-of-the-art technology. This thesis is\norganized into three main parts:\n  In the first part, we explore multiple formalisms to improve existing machine\ncomprehension systems. We propose a formulation for abductive reasoning in\nnatural language and show its effectiveness, especially in domains with limited\ntraining data. Additionally, to help reasoning systems cope with irrelevant or\nredundant information, we create a supervised approach to learn and detect the\nessential terms in questions.\n  In the second part, we propose two new challenge datasets. In particular, we\ncreate two datasets of natural language questions where (i) the first one\nrequires reasoning over multiple sentences; (ii) the second one requires\ntemporal common sense reasoning. We hope that the two proposed datasets will\nmotivate the field to address more complex problems.\n  In the final part, we present the first formal framework for multi-step\nreasoning algorithms, in the presence of a few important properties of language\nuse, such as incompleteness, ambiguity, etc. We apply this framework to prove\nfundamental limitations for reasoning algorithms. These theoretical results\nprovide extra intuition into the existing empirical evidence in the field.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 02:07:02 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Khashabi", "Daniel", ""]]}, {"id": "1908.04942", "submitter": "Yu Chen", "authors": "Yu Chen, Lingfei Wu and Mohammed J. Zaki", "title": "Reinforcement Learning Based Graph-to-Sequence Model for Natural\n  Question Generation", "comments": "17 pages. Accepted by ICLR 2020. Final version (fix typo in figure)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural question generation (QG) aims to generate questions from a passage\nand an answer. Previous works on QG either (i) ignore the rich structure\ninformation hidden in text, (ii) solely rely on cross-entropy loss that leads\nto issues like exposure bias and inconsistency between train/test measurement,\nor (iii) fail to fully exploit the answer information. To address these\nlimitations, in this paper, we propose a reinforcement learning (RL) based\ngraph-to-sequence (Graph2Seq) model for QG. Our model consists of a Graph2Seq\ngenerator with a novel Bidirectional Gated Graph Neural Network based encoder\nto embed the passage, and a hybrid evaluator with a mixed objective combining\nboth cross-entropy and RL losses to ensure the generation of syntactically and\nsemantically valid text. We also introduce an effective Deep Alignment Network\nfor incorporating the answer information into the passage at both the word and\ncontextual levels. Our model is end-to-end trainable and achieves new\nstate-of-the-art scores, outperforming existing methods by a significant margin\non the standard SQuAD benchmark.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 03:40:04 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 22:07:00 GMT"}, {"version": "v3", "created": "Sun, 16 Feb 2020 05:09:26 GMT"}, {"version": "v4", "created": "Thu, 27 Aug 2020 15:49:08 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Chen", "Yu", ""], ["Wu", "Lingfei", ""], ["Zaki", "Mohammed J.", ""]]}, {"id": "1908.04943", "submitter": "Han He", "authors": "Han He, Jinho D. Choi", "title": "Establishing Strong Baselines for the New Decade: Sequence Tagging,\n  Syntactic and Semantic Parsing with BERT", "comments": "Accepted to the International Florida Artificial Intelligence\n  Research Society Conference, FLAIRS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents new state-of-the-art models for three tasks,\npart-of-speech tagging, syntactic parsing, and semantic parsing, using the\ncutting-edge contextualized embedding framework known as BERT. For each task,\nwe first replicate and simplify the current state-of-the-art approach to\nenhance its model efficiency. We then evaluate our simplified approaches on\nthose three tasks using token embeddings generated by BERT. 12 datasets in both\nEnglish and Chinese are used for our experiments. The BERT models outperform\nthe previously best-performing models by 2.5% on average (7.5% for the most\nsignificant case). Moreover, an in-depth analysis on the impact of BERT\nembeddings is provided using self-attention, which helps understanding in this\nrich yet representation. All models and source codes are available in public so\nthat researchers can improve upon and utilize them to establish strong\nbaselines for the next decade.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 03:45:15 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 05:03:05 GMT"}, {"version": "v3", "created": "Tue, 7 Apr 2020 17:10:30 GMT"}, {"version": "v4", "created": "Sat, 23 May 2020 04:25:58 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["He", "Han", ""], ["Choi", "Jinho D.", ""]]}, {"id": "1908.04950", "submitter": "C\\u{a}t\\u{a}lina Cangea", "authors": "C\\u{a}t\\u{a}lina Cangea, Eugene Belilovsky, Pietro Li\\`o, Aaron\n  Courville", "title": "VideoNavQA: Bridging the Gap between Visual and Embodied Question\n  Answering", "comments": "To appear at BMVC 2019. 15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embodied Question Answering (EQA) is a recently proposed task, where an agent\nis placed in a rich 3D environment and must act based solely on its egocentric\ninput to answer a given question. The desired outcome is that the agent learns\nto combine capabilities such as scene understanding, navigation and language\nunderstanding in order to perform complex reasoning in the visual world.\nHowever, initial advancements combining standard vision and language methods\nwith imitation and reinforcement learning algorithms have shown EQA might be\ntoo complex and challenging for these techniques. In order to investigate the\nfeasibility of EQA-type tasks, we build the VideoNavQA dataset that contains\npairs of questions and videos generated in the House3D environment. The goal of\nthis dataset is to assess question-answering performance from nearly-ideal\nnavigation paths, while considering a much more complete variety of questions\nthan current instantiations of the EQA task. We investigate several models,\nadapted from popular VQA methods, on this new benchmark. This establishes an\ninitial understanding of how well VQA-style methods can perform within this\nnovel EQA paradigm.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 04:44:26 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Cangea", "C\u0103t\u0103lina", ""], ["Belilovsky", "Eugene", ""], ["Li\u00f2", "Pietro", ""], ["Courville", "Aaron", ""]]}, {"id": "1908.05009", "submitter": "Hongyin Zhu", "authors": "Hongyin Zhu, Wenpeng Hu, Yi Zeng", "title": "FlexNER: A Flexible LSTM-CNN Stack Framework for Named Entity\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity recognition (NER) is a foundational technology for information\nextraction. This paper presents a flexible NER framework compatible with\ndifferent languages and domains. Inspired by the idea of distant supervision\n(DS), this paper enhances the representation by increasing the entity-context\ndiversity without relying on external resources. We choose different layer\nstacks and sub-network combinations to construct the bilateral networks. This\nstrategy can generally improve model performance on different datasets. We\nconduct experiments on five languages, such as English, German, Spanish, Dutch\nand Chinese, and biomedical fields, such as identifying the chemicals and\ngene/protein terms from scientific works. Experimental results demonstrate the\ngood performance of this framework.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 08:06:14 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Zhu", "Hongyin", ""], ["Hu", "Wenpeng", ""], ["Zeng", "Yi", ""]]}, {"id": "1908.05054", "submitter": "Chris Alberti", "authors": "Chris Alberti, Jeffrey Ling, Michael Collins, David Reitter", "title": "Fusion of Detected Objects in Text for Visual Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To advance models of multimodal context, we introduce a simple yet powerful\nneural architecture for data that combines vision and natural language. The\n\"Bounding Boxes in Text Transformer\" (B2T2) also leverages referential\ninformation binding words to portions of the image in a single unified\narchitecture. B2T2 is highly effective on the Visual Commonsense Reasoning\nbenchmark (https://visualcommonsense.com), achieving a new state-of-the-art\nwith a 25% relative reduction in error rate compared to published baselines and\nobtaining the best performance to date on the public leaderboard (as of May 22,\n2019). A detailed ablation analysis shows that the early integration of the\nvisual features into the text analysis is key to the effectiveness of the new\narchitecture. A reference implementation of our models is provided\n(https://github.com/google-research/language/tree/master/language/question_answering/b2t2).\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 10:03:12 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 05:04:09 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Alberti", "Chris", ""], ["Ling", "Jeffrey", ""], ["Collins", "Michael", ""], ["Reitter", "David", ""]]}, {"id": "1908.05067", "submitter": "Yi-Ting Yeh", "authors": "Yi-Ting Yeh, Tzu-Chuan Lin, Hsiao-Hua Cheng, Yu-Hsuan Deng, Shang-Yu\n  Su and Yun-Nung Chen", "title": "Reactive Multi-Stage Feature Fusion for Multimodal Dialogue Modeling", "comments": "Accepted for a poster session at the DSTC7 workshop at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual question answering and visual dialogue tasks have been increasingly\nstudied in the multimodal field towards more practical real-world scenarios. A\nmore challenging task, audio visual scene-aware dialogue (AVSD), is proposed to\nfurther advance the technologies that connect audio, vision, and language,\nwhich introduces temporal video information and dialogue interactions between a\nquestioner and an answerer. This paper proposes an intuitive mechanism that\nfuses features and attention in multiple stages in order to well integrate\nmultimodal features, and the results demonstrate its capability in the\nexperiments. Also, we apply several state-of-the-art models in other tasks to\nthe AVSD task, and further analyze their generalization across different tasks.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 10:58:14 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Yeh", "Yi-Ting", ""], ["Lin", "Tzu-Chuan", ""], ["Cheng", "Hsiao-Hua", ""], ["Deng", "Yu-Hsuan", ""], ["Su", "Shang-Yu", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1908.05098", "submitter": "Mohamad Yaser Jaradeh", "authors": "Kuldeep Singh, Mohamad Yaser Jaradeh, Saeedeh Shekarpour, Akash\n  Kulkarni, Arun Sethupat Radhakrishna, Ioanna Lytra, Maria-Esther Vidal, Jens\n  Lehmann", "title": "Towards Optimisation of Collaborative Question Answering over Knowledge\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative Question Answering (CQA) frameworks for knowledge graphs aim at\nintegrating existing question answering (QA) components for implementing\nsequences of QA tasks (i.e. QA pipelines). The research community has paid\nsubstantial attention to CQAs since they support reusability and scalability of\nthe available components in addition to the flexibility of pipelines. CQA\nframeworks attempt to build such pipelines automatically by solving two\noptimisation problems: 1) local collective performance of QA components per QA\ntask and 2) global performance of QA pipelines. In spite offering several\nadvantages over monolithic QA systems, the effectiveness and efficiency of CQA\nframeworks in answering questions is limited. In this paper, we tackle the\nproblem of local optimisation of CQA frameworks and propose a three fold\napproach, which applies feature selection techniques with supervised machine\nlearning approaches in order to identify the best performing components\nefficiently. We have empirically evaluated our approach over existing\nbenchmarks and compared to existing automatic CQA frameworks. The observed\nresults provide evidence that our approach answers a higher number of questions\nthan the state of the art while reducing: i) the number of used features by 50%\nand ii) the number of components used by 76%.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 12:42:48 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Singh", "Kuldeep", ""], ["Jaradeh", "Mohamad Yaser", ""], ["Shekarpour", "Saeedeh", ""], ["Kulkarni", "Akash", ""], ["Radhakrishna", "Arun Sethupat", ""], ["Lytra", "Ioanna", ""], ["Vidal", "Maria-Esther", ""], ["Lehmann", "Jens", ""]]}, {"id": "1908.05111", "submitter": "Mostafa Abdou", "authors": "Mostafa Abdou, Cezar Sas, Rahul Aralikatte, Isabelle Augenstein and\n  Anders S{\\o}gaard", "title": "X-WikiRE: A Large, Multilingual Resource for Relation Extraction as\n  Machine Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the vast majority of knowledge bases KBs are heavily biased towards\nEnglish, Wikipedias do cover very different topics in different languages.\nExploiting this, we introduce a new multilingual dataset (X-WikiRE), framing\nrelation extraction as a multilingual machine reading problem. We show that by\nleveraging this resource it is possible to robustly transfer models\ncross-lingually and that multilingual support significantly improves\n(zero-shot) relation extraction, enabling the population of low-resourced KBs\nfrom their well-populated counterparts.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 13:15:24 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 09:05:08 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Abdou", "Mostafa", ""], ["Sas", "Cezar", ""], ["Aralikatte", "Rahul", ""], ["Augenstein", "Isabelle", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "1908.05117", "submitter": "Yi-Ting Yeh", "authors": "Yi-Ting Yeh, Yun-Nung Chen", "title": "FlowDelta: Modeling Flow Information Gain in Reasoning for\n  Conversational Machine Comprehension", "comments": "Accepted by the 2nd Workshop on Machine Reading for Question\n  Answering (MRQA), EMNLP 2019 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational machine comprehension requires deep understanding of the\ndialogue flow, and the prior work proposed FlowQA to implicitly model the\ncontext representations in reasoning for better understanding. This paper\nproposes to explicitly model the information gain through dialogue reasoning in\norder to allow the model to focus on more informative cues. The proposed model\nachieves state-of-the-art performance in a conversational QA dataset QuAC and\nsequential instruction understanding dataset SCONE, which shows the\neffectiveness of the proposed mechanism and demonstrates its capability of\ngeneralization to different QA models and tasks.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 13:34:40 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 13:17:04 GMT"}, {"version": "v3", "created": "Fri, 17 Jan 2020 08:47:23 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Yeh", "Yi-Ting", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1908.05135", "submitter": "Elia Bruni", "authors": "Mathijs Mul, Diane Bouchacourt, Elia Bruni", "title": "Mastering emergent language: learning to guide in simulated navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To cooperate with humans effectively, virtual agents need to be able to\nunderstand and execute language instructions. A typical setup to achieve this\nis with a scripted teacher which guides a virtual agent using language\ninstructions. However, such setup has clear limitations in scalability and,\nmore importantly, it is not interactive. Here, we introduce an autonomous agent\nthat uses discrete communication to interactively guide other agents to\nnavigate and act on a simulated environment. The developed communication\nprotocol is trainable, emergent and requires no additional supervision. The\nemergent language speeds up learning of new agents, it generalizes across\nincrementally more difficult tasks and, contrary to most other emergent\nlanguages, it is highly interpretable. We demonstrate how the emitted messages\ncorrelate with particular actions and observations, and how new agents become\nless dependent on this guidance as training progresses. By exploiting the\ncorrelations identified in our analysis, we manage to successfully address the\nagents in their own language.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 14:10:21 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Mul", "Mathijs", ""], ["Bouchacourt", "Diane", ""], ["Bruni", "Elia", ""]]}, {"id": "1908.05138", "submitter": "Yifu Chen", "authors": "Yifu Chen, Zongsheng Wang, Bowen Wu, Mengyuan Li, Huan Zhang, Lin Ma,\n  Feng Liu, Qihang Feng, Baoxun Wang", "title": "MemeFaceGenerator: Adversarial Synthesis of Chinese Meme-face from\n  Natural Sentences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chinese meme-face is a special kind of internet subculture widely spread in\nChinese Social Community Networks. It usually consists of a template image\nmodified by some amusing details and a text caption. In this paper, we present\nMemeFaceGenerator, a Generative Adversarial Network with the attention module\nand template information as supplementary signals, to automatically generate\nmeme-faces from text inputs. We also develop a web service as system\ndemonstration of meme-face synthesis. MemeFaceGenerator has been shown to be\ncapable of generating high-quality meme-faces from random text inputs.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 14:15:24 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Chen", "Yifu", ""], ["Wang", "Zongsheng", ""], ["Wu", "Bowen", ""], ["Li", "Mengyuan", ""], ["Zhang", "Huan", ""], ["Ma", "Lin", ""], ["Liu", "Feng", ""], ["Feng", "Qihang", ""], ["Wang", "Baoxun", ""]]}, {"id": "1908.05147", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang, Yuwei Wu, Junru Zhou, Sufeng Duan, Hai Zhao, Rui Wang", "title": "SG-Net: Syntax-Guided Machine Reading Comprehension", "comments": "Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For machine reading comprehension, the capacity of effectively modeling the\nlinguistic knowledge from the detail-riddled and lengthy passages and getting\nride of the noises is essential to improve its performance. Traditional\nattentive models attend to all words without explicit constraint, which results\nin inaccurate concentration on some dispensable words. In this work, we propose\nusing syntax to guide the text modeling by incorporating explicit syntactic\nconstraints into attention mechanism for better linguistically motivated word\nrepresentations. In detail, for self-attention network (SAN) sponsored\nTransformer-based encoder, we introduce syntactic dependency of interest (SDOI)\ndesign into the SAN to form an SDOI-SAN with syntax-guided self-attention.\nSyntax-guided network (SG-Net) is then composed of this extra SDOI-SAN and the\nSAN from the original Transformer encoder through a dual contextual\narchitecture for better linguistics inspired representation. To verify its\neffectiveness, the proposed SG-Net is applied to typical pre-trained language\nmodel BERT which is right based on a Transformer encoder. Extensive experiments\non popular benchmarks including SQuAD 2.0 and RACE show that the proposed\nSG-Net design helps achieve substantial performance improvement over strong\nbaselines.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 14:28:07 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 10:50:46 GMT"}, {"version": "v3", "created": "Wed, 20 Nov 2019 10:21:30 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["Wu", "Yuwei", ""], ["Zhou", "Junru", ""], ["Duan", "Sufeng", ""], ["Zhao", "Hai", ""], ["Wang", "Rui", ""]]}, {"id": "1908.05161", "submitter": "Oren Barkan", "authors": "Oren Barkan, Noam Razin, Itzik Malkiel, Ori Katz, Avi Caciularu, Noam\n  Koenigstein", "title": "Scalable Attentive Sentence-Pair Modeling via Distilled Sentence\n  Embedding", "comments": "In Proceedings of AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent state-of-the-art natural language understanding models, such as BERT\nand XLNet, score a pair of sentences (A and B) using multiple cross-attention\noperations - a process in which each word in sentence A attends to all words in\nsentence B and vice versa. As a result, computing the similarity between a\nquery sentence and a set of candidate sentences, requires the propagation of\nall query-candidate sentence-pairs throughout a stack of cross-attention\nlayers. This exhaustive process becomes computationally prohibitive when the\nnumber of candidate sentences is large. In contrast, sentence embedding\ntechniques learn a sentence-to-vector mapping and compute the similarity\nbetween the sentence vectors via simple elementary operations. In this paper,\nwe introduce Distilled Sentence Embedding (DSE) - a model that is based on\nknowledge distillation from cross-attentive models, focusing on sentence-pair\ntasks. The outline of DSE is as follows: Given a cross-attentive teacher model\n(e.g. a fine-tuned BERT), we train a sentence embedding based student model to\nreconstruct the sentence-pair scores obtained by the teacher model. We\nempirically demonstrate the effectiveness of DSE on five GLUE sentence-pair\ntasks. DSE significantly outperforms several ELMO variants and other sentence\nembedding methods, while accelerating computation of the query-candidate\nsentence-pairs similarities by several orders of magnitude, with an average\nrelative degradation of 4.6% compared to BERT. Furthermore, we show that DSE\nproduces sentence embeddings that reach state-of-the-art performance on\nuniversal sentence representation benchmarks. Our code is made publicly\navailable at https://github.com/microsoft/Distilled-Sentence-Embedding.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 15:06:48 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 17:57:57 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 06:38:18 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Barkan", "Oren", ""], ["Razin", "Noam", ""], ["Malkiel", "Itzik", ""], ["Katz", "Ori", ""], ["Caciularu", "Avi", ""], ["Koenigstein", "Noam", ""]]}, {"id": "1908.05204", "submitter": "Myle Ott", "authors": "Sergey Edunov and Myle Ott and Marc'Aurelio Ranzato and Michael Auli", "title": "On The Evaluation of Machine Translation Systems Trained With\n  Back-Translation", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Back-translation is a widely used data augmentation technique which leverages\ntarget monolingual data. However, its effectiveness has been challenged since\nautomatic metrics such as BLEU only show significant improvements for test\nexamples where the source itself is a translation, or translationese. This is\nbelieved to be due to translationese inputs better matching the back-translated\ntraining data. In this work, we show that this conjecture is not empirically\nsupported and that back-translation improves translation quality of both\nnaturally occurring text as well as translationese according to professional\nhuman translators. We provide empirical evidence to support the view that\nback-translation is preferred by humans because it produces more fluent\noutputs. BLEU cannot capture human preferences because references are\ntranslationese when source sentences are natural text. We recommend\ncomplementing BLEU with a language model score to measure fluency.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 16:24:56 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 17:31:44 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Edunov", "Sergey", ""], ["Ott", "Myle", ""], ["Ranzato", "Marc'Aurelio", ""], ["Auli", "Michael", ""]]}, {"id": "1908.05253", "submitter": "Aaron Steven White", "authors": "Hannah Youngeun An, Aaron Steven White", "title": "The lexical and grammatical sources of neg-raising inferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate neg(ation)-raising inferences, wherein negation on a predicate\ncan be interpreted as though in that predicate's subordinate clause. To do\nthis, we collect a large-scale dataset of neg-raising judgments for effectively\nall English clause-embedding verbs and develop a model to jointly induce the\nsemantic types of verbs and their subordinate clauses and the relationship of\nthese types to neg-raising inferences. We find that some neg-raising inferences\nare attributable to properties of particular predicates, while others are\nattributable to subordinate clause structure.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 17:32:40 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 22:47:32 GMT"}, {"version": "v3", "created": "Thu, 17 Oct 2019 17:37:58 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["An", "Hannah Youngeun", ""], ["White", "Aaron Steven", ""]]}, {"id": "1908.05267", "submitter": "Tal Schuster", "authors": "Tal Schuster, Darsh J Shah, Yun Jie Serene Yeo, Daniel Filizzola,\n  Enrico Santus, Regina Barzilay", "title": "Towards Debiasing Fact Verification Models", "comments": "EMNLP IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fact verification requires validating a claim in the context of evidence. We\nshow, however, that in the popular FEVER dataset this might not necessarily be\nthe case. Claim-only classifiers perform competitively with top evidence-aware\nmodels. In this paper, we investigate the cause of this phenomenon, identifying\nstrong cues for predicting labels solely based on the claim, without\nconsidering any evidence. We create an evaluation set that avoids those\nidiosyncrasies. The performance of FEVER-trained models significantly drops\nwhen evaluated on this test set. Therefore, we introduce a regularization\nmethod which alleviates the effect of bias in the training data, obtaining\nimprovements on the newly created test set. This work is a step towards a more\nsound evaluation of reasoning capabilities in fact verification models.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 17:47:02 GMT"}, {"version": "v2", "created": "Sat, 31 Aug 2019 03:10:24 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Schuster", "Tal", ""], ["Shah", "Darsh J", ""], ["Yeo", "Yun Jie Serene", ""], ["Filizzola", "Daniel", ""], ["Santus", "Enrico", ""], ["Barzilay", "Regina", ""]]}, {"id": "1908.05344", "submitter": "Liyuan Liu", "authors": "Liyuan Liu, Zihan Wang, Jingbo Shang, Dandong Yin, Heng Ji, Xiang Ren,\n  Shaowen Wang and Jiawei Han", "title": "Raw-to-End Name Entity Recognition in Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taking word sequences as the input, typical named entity recognition (NER)\nmodels neglect errors from pre-processing (e.g., tokenization). However, these\nerrors can influence the model performance greatly, especially for noisy texts\nlike tweets. Here, we introduce Neural-Char-CRF, a raw-to-end framework that is\nmore robust to pre-processing errors. It takes raw character sequences as\ninputs and makes end-to-end predictions. Word embedding and contextualized\nrepresentation models are further tailored to capture textual signals for each\ncharacter instead of each word. Our model neither requires the conversion from\ncharacter sequences to word sequences, nor assumes tokenizer can correctly\ndetect all word boundaries. Moreover, we observe our model performance remains\nunchanged after replacing tokenization with string matching, which demonstrates\nits potential to be tokenization-free. Extensive experimental results on two\npublic datasets demonstrate the superiority of our proposed method over the\nstate of the art. The implementations and datasets are made available at:\nhttps://github.com/LiyuanLucasLiu/Raw-to-End.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 20:50:14 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Liu", "Liyuan", ""], ["Wang", "Zihan", ""], ["Shang", "Jingbo", ""], ["Yin", "Dandong", ""], ["Ji", "Heng", ""], ["Ren", "Xiang", ""], ["Wang", "Shaowen", ""], ["Han", "Jiawei", ""]]}, {"id": "1908.05378", "submitter": "Shaolei Wang", "authors": "Shaolei Wang, Wanxiang Che, Qi Liu, Pengda Qin, Ting Liu, William Yang\n  Wang", "title": "Multi-Task Self-Supervised Learning for Disfluency Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing approaches to disfluency detection heavily rely on\nhuman-annotated data, which is expensive to obtain in practice. To tackle the\ntraining data bottleneck, we investigate methods for combining multiple\nself-supervised tasks-i.e., supervised tasks where data can be collected\nwithout manual labeling. First, we construct large-scale pseudo training data\nby randomly adding or deleting words from unlabeled news data, and propose two\nself-supervised pre-training tasks: (i) tagging task to detect the added noisy\nwords. (ii) sentence classification to distinguish original sentences from\ngrammatically-incorrect sentences. We then combine these two tasks to jointly\ntrain a network. The pre-trained network is then fine-tuned using\nhuman-annotated disfluency detection training data. Experimental results on the\ncommonly used English Switchboard test set show that our approach can achieve\ncompetitive performance compared to the previous systems (trained using the\nfull dataset) by using less than 1% (1000 sentences) of the training data. Our\nmethod trained on the full dataset significantly outperforms previous methods,\nreducing the error by 21% on English Switchboard.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 00:22:38 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 05:47:51 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Wang", "Shaolei", ""], ["Che", "Wanxiang", ""], ["Liu", "Qi", ""], ["Qin", "Pengda", ""], ["Liu", "Ting", ""], ["Wang", "William Yang", ""]]}, {"id": "1908.05391", "submitter": "Qibin Chen", "authors": "Qibin Chen, Junyang Lin, Yichang Zhang, Ming Ding, Yukuo Cen, Hongxia\n  Yang, Jie Tang", "title": "Towards Knowledge-Based Recommender Dialog System", "comments": "To appear in EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel end-to-end framework called KBRD, which\nstands for Knowledge-Based Recommender Dialog System. It integrates the\nrecommender system and the dialog generation system. The dialog system can\nenhance the performance of the recommendation system by introducing\nknowledge-grounded information about users' preferences, and the recommender\nsystem can improve that of the dialog generation system by providing\nrecommendation-aware vocabulary bias. Experimental results demonstrate that our\nproposed model has significant advantages over the baselines in both the\nevaluation of dialog generation and recommendation. A series of analyses show\nthat the two systems can bring mutual benefits to each other, and the\nintroduced knowledge contributes to both their performances.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 01:49:19 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 04:38:02 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Chen", "Qibin", ""], ["Lin", "Junyang", ""], ["Zhang", "Yichang", ""], ["Ding", "Ming", ""], ["Cen", "Yukuo", ""], ["Yang", "Hongxia", ""], ["Tang", "Jie", ""]]}, {"id": "1908.05407", "submitter": "Yuqing Song", "authors": "Yuqing Song, Shizhe Chen, Yida Zhao, Qin Jin", "title": "Unpaired Cross-lingual Image Caption Generation with Self-Supervised\n  Rewards", "comments": "Accepted by ACMMM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating image descriptions in different languages is essential to satisfy\nusers worldwide. However, it is prohibitively expensive to collect large-scale\npaired image-caption dataset for every target language which is critical for\ntraining descent image captioning models. Previous works tackle the unpaired\ncross-lingual image captioning problem through a pivot language, which is with\nthe help of paired image-caption data in the pivot language and pivot-to-target\nmachine translation models. However, such language-pivoted approach suffers\nfrom inaccuracy brought by the pivot-to-target translation, including\ndisfluency and visual irrelevancy errors. In this paper, we propose to generate\ncross-lingual image captions with self-supervised rewards in the reinforcement\nlearning framework to alleviate these two types of errors. We employ\nself-supervision from mono-lingual corpus in the target language to provide\nfluency reward, and propose a multi-level visual semantic matching model to\nprovide both sentence-level and concept-level visual relevancy rewards. We\nconduct extensive experiments for unpaired cross-lingual image captioning in\nboth English and Chinese respectively on two widely used image caption corpora.\nThe proposed approach achieves significant performance improvement over\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 03:50:18 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Song", "Yuqing", ""], ["Chen", "Shizhe", ""], ["Zhao", "Yida", ""], ["Jin", "Qin", ""]]}, {"id": "1908.05408", "submitter": "Zhuoxuan Jiang", "authors": "Zhuoxuan Jiang and Xian-Ling Mao and Ziming Huang and Jie Ma and\n  Shaochun Li", "title": "Towards End-to-End Learning for Efficient Dialogue Agent by Modeling\n  Looking-ahead Ability", "comments": "To appear in Special Interest Group on Discourse and Dialogue\n  (SIGDIAL) 2019 (ORAL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning an efficient manager of dialogue agent from data with little manual\nintervention is important, especially for goal-oriented dialogues. However,\nexisting methods either take too many manual efforts (e.g. reinforcement\nlearning methods) or cannot guarantee the dialogue efficiency (e.g.\nsequence-to-sequence methods). In this paper, we address this problem by\nproposing a novel end-to-end learning model to train a dialogue agent that can\nlook ahead for several future turns and generate an optimal response to make\nthe dialogue efficient. Our method is data-driven and does not require too much\nmanual work for intervention during system design. We evaluate our method on\ntwo datasets of different scenarios and the experimental results demonstrate\nthe efficiency of our model.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 03:50:53 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Jiang", "Zhuoxuan", ""], ["Mao", "Xian-Ling", ""], ["Huang", "Ziming", ""], ["Ma", "Jie", ""], ["Li", "Shaochun", ""]]}, {"id": "1908.05416", "submitter": "Pengyuan Liu", "authors": "Pengyuan Liu, Yuning Deng, Chenghao Zhu, Han Hu", "title": "XCMRC: Evaluating Cross-lingual Machine Reading Comprehension", "comments": "NLPCC 2019(long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present XCMRC, the first public cross-lingual language understanding (XLU)\nbenchmark which aims to test machines on their cross-lingual reading\ncomprehension ability. To be specific, XCMRC is a Cross-lingual Cloze-style\nMachine Reading Comprehension task which requires the reader to fill in a\nmissing word (we additionally provide ten noun candidates) in a sentence\nwritten in target language (English / Chinese) by reading a given passage\nwritten in source language (Chinese / English). Chinese and English are\nrich-resource language pairs, in order to study low-resource cross-lingual\nmachine reading comprehension (XMRC), besides defining the common XCMRC task\nwhich has no restrictions on use of external language resources, we also define\nthe pseudo low-resource XCMRC task by limiting the language resources to be\nused. In addition, we provide two baselines for common XCMRC task and two for\npseudo XCMRC task respectively. We also provide an upper bound baseline for\nboth tasks. We found that for common XCMRC task, translation-based method and\nmultilingual sentence encoder-based method can obtain reasonable performance\nbut still have much room for improvement. As for pseudo low-resource XCMRC\ntask, due to strict restrictions on the use of language resources, our two\napproaches are far below the upper bound so there are many challenges ahead.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 04:40:27 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Liu", "Pengyuan", ""], ["Deng", "Yuning", ""], ["Zhu", "Chenghao", ""], ["Hu", "Han", ""]]}, {"id": "1908.05426", "submitter": "Yuze Gao", "authors": "Yuze Gao and Yu Yuan", "title": "Feature-Less End-to-End Nested Term Extraction", "comments": null, "journal-ref": "NLPCC XAI 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we proposed a deep learning-based end-to-end method on the\ndomain specified automatic term extraction (ATE), it considers possible term\nspans within a fixed length in the sentence and predicts them whether they can\nbe conceptual terms. In comparison with current ATE methods, the model supports\nnested term extraction and does not crucially need extra (extracted) features.\nResults show that it can achieve high recall and a comparable precision on term\nextraction task with inputting segmented raw text.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 05:38:14 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Gao", "Yuze", ""], ["Yuan", "Yu", ""]]}, {"id": "1908.05434", "submitter": "Longshaokan Wang", "authors": "Longshaokan Wang, Eric Laber, Yeng Saanchi, Sherrie Caltagirone", "title": "Sex Trafficking Detection with Ordinal Regression Neural Networks", "comments": "AAAI-20 workshop on Artificial Intelligence for Cyber Security (AICS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sex trafficking is a global epidemic. Escort websites are a primary vehicle\nfor selling the services of such trafficking victims and thus a major driver of\ntrafficker revenue. Many law enforcement agencies do not have the resources to\nmanually identify leads from the millions of escort ads posted across dozens of\npublic websites. We propose an ordinal regression neural network to identify\nescort ads that are likely linked to sex trafficking. Our model uses a modified\ncost function to mitigate inconsistencies in predictions often associated with\nnonparametric ordinal regression and leverages recent advancements in deep\nlearning to improve prediction accuracy. The proposed method significantly\nimproves on the previous state-of-the-art on Trafficking-10K, an\nexpert-annotated dataset of escort ads. Additionally, because traffickers use\nacronyms, deliberate typographical errors, and emojis to replace explicit\nkeywords, we demonstrate how to expand the lexicon of trafficking flags through\nword embeddings and t-SNE.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 06:25:46 GMT"}, {"version": "v2", "created": "Sun, 12 Jan 2020 02:17:39 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Wang", "Longshaokan", ""], ["Laber", "Eric", ""], ["Saanchi", "Yeng", ""], ["Caltagirone", "Sherrie", ""]]}, {"id": "1908.05441", "submitter": "Peter Jansen", "authors": "Dongfang Xu, Peter Jansen, Jaycie Martin, Zhengnan Xie, Vikas Yadav,\n  Harish Tayyar Madabushi, Oyvind Tafjord and Peter Clark", "title": "Multi-class Hierarchical Question Classification for Multiple Choice\n  Science Exams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work has demonstrated that question classification (QC), recognizing\nthe problem domain of a question, can help answer it more accurately. However,\ndeveloping strong QC algorithms has been hindered by the limited size and\ncomplexity of annotated data available. To address this, we present the largest\nchallenge dataset for QC, containing 7,787 science exam questions paired with\ndetailed classification labels from a fine-grained hierarchical taxonomy of 406\nproblem domains. We then show that a BERT-based model trained on this dataset\nachieves a large (+0.12 MAP) gain compared with previous methods, while also\nachieving state-of-the-art performance on benchmark open-domain and biomedical\nQC datasets. Finally, we show that using this model's predictions of question\ntopic significantly improves the accuracy of a question answering system by\n+1.7% P@1, with substantial future gains possible as QC performance improves.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 07:00:16 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Xu", "Dongfang", ""], ["Jansen", "Peter", ""], ["Martin", "Jaycie", ""], ["Xie", "Zhengnan", ""], ["Yadav", "Vikas", ""], ["Madabushi", "Harish Tayyar", ""], ["Tafjord", "Oyvind", ""], ["Clark", "Peter", ""]]}, {"id": "1908.05453", "submitter": "Stav Klein", "authors": "Reut Tsarfaty, Amit Seker, Shoval Sadde, Stav Klein", "title": "What's Wrong with Hebrew NLP? And How to Make it Right", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For languages with simple morphology, such as English, automatic annotation\npipelines such as spaCy or Stanford's CoreNLP successfully serve projects in\nacademia and the industry. For many morphologically-rich languages (MRLs),\nsimilar pipelines show sub-optimal performance that limits their applicability\nfor text analysis in research and the industry.The sub-optimal performance is\nmainly due to errors in early morphological disambiguation decisions, which\ncannot be recovered later in the pipeline, yielding incoherent annotations on\nthe whole. In this paper we describe the design and use of the Onlp suite, a\njoint morpho-syntactic parsing framework for processing Modern Hebrew texts.\nThe joint inference over morphology and syntax substantially limits error\npropagation, and leads to high accuracy. Onlp provides rich and expressive\noutput which already serves diverse academic and commercial needs. Its\naccompanying online demo further serves educational activities, introducing\nHebrew NLP intricacies to researchers and non-researchers alike.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 08:09:52 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Tsarfaty", "Reut", ""], ["Seker", "Amit", ""], ["Sadde", "Shoval", ""], ["Klein", "Stav", ""]]}, {"id": "1908.05490", "submitter": "Meghdad Farahmand", "authors": "Meghdad Farahmand", "title": "A Multivariate Model for Representing Semantic Non-compositionality", "comments": "11 content pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantically non-compositional phrases constitute an intriguing research\ntopic in Natural Language Processing. Semantic non-compositionality --the\nsituation when the meaning of a phrase cannot be derived from the meaning of\nits components, is the main characteristic of such phrases, however, they bear\nother characteristics such as high statistical association and\nnon-substitutability. In this work, we present a model for identifying\nnon-compositional phrases that takes into account all of these characteristics.\nWe show that the presented model remarkably outperforms the existing models of\nidentifying non-compositional phrases that mostly focus only on one of these\ncharacteristics.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 10:58:57 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Farahmand", "Meghdad", ""]]}, {"id": "1908.05514", "submitter": "Minghao Hu", "authors": "Minghao Hu, Yuxing Peng, Zhen Huang, Dongsheng Li", "title": "A Multi-Type Multi-Span Network for Reading Comprehension that Requires\n  Discrete Reasoning", "comments": "To appear at EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid progress has been made in the field of reading comprehension and\nquestion answering, where several systems have achieved human parity in some\nsimplified settings. However, the performance of these models degrades\nsignificantly when they are applied to more realistic scenarios, such as\nanswers involve various types, multiple text strings are correct answers, or\ndiscrete reasoning abilities are required. In this paper, we introduce the\nMulti-Type Multi-Span Network (MTMSN), a neural reading comprehension model\nthat combines a multi-type answer predictor designed to support various answer\ntypes (e.g., span, count, negation, and arithmetic expression) with a\nmulti-span extraction method for dynamically producing one or multiple text\nspans. In addition, an arithmetic expression reranking mechanism is proposed to\nrank expression candidates for further confirming the prediction. Experiments\nshow that our model achieves 79.9 F1 on the DROP hidden test set, creating new\nstate-of-the-art results. Source\ncode\\footnote{\\url{https://github.com/huminghao16/MTMSN}} is released to\nfacilitate future work.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 12:32:52 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 01:08:00 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Hu", "Minghao", ""], ["Peng", "Yuxing", ""], ["Huang", "Zhen", ""], ["Li", "Dongsheng", ""]]}, {"id": "1908.05528", "submitter": "Apostolos Tzimoulis", "authors": "Giuseppe Greco and Fei Liang and Michael Moortgat and Alessandra\n  Palmigiano and Apostolos Tzimoulis", "title": "Vector spaces as Kripke frames", "comments": "Fixed list of authors in metadata", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the compositional distributional approach in computational\nlinguistics has opened the way for an integration of the \\emph{lexical} aspects\nof meaning into Lambek's type-logical grammar program. This approach is based\non the observation that a sound semantics for the associative, commutative and\nunital Lambek calculus can be based on vector spaces by interpreting fusion as\nthe tensor product of vector spaces.\n  In this paper, we build on this observation and extend it to a `vector space\nsemantics' for the \\emph{general} Lambek calculus, based on \\emph{algebras over\na field} $\\mathbb{K}$ (or $\\mathbb{K}$-algebras), i.e. vector spaces endowed\nwith a bilinear binary product. Such structures are well known in algebraic\ngeometry and algebraic topology, since they are important instances of Lie\nalgebras and Hopf algebras. Applying results and insights from duality and\nrepresentation theory for the algebraic semantics of nonclassical logics, we\nregard $\\mathbb{K}$-algebras as `Kripke frames' the complex algebras of which\nare complete residuated lattices.\n  This perspective makes it possible to establish a systematic connection\nbetween vector space semantics and the standard Routley-Meyer semantics of\n(modal) substructural logics.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 13:26:44 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2020 15:16:04 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2020 18:09:06 GMT"}, {"version": "v4", "created": "Wed, 12 May 2021 11:30:37 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Greco", "Giuseppe", ""], ["Liang", "Fei", ""], ["Moortgat", "Michael", ""], ["Palmigiano", "Alessandra", ""], ["Tzimoulis", "Apostolos", ""]]}, {"id": "1908.05541", "submitter": "Felix Hamann", "authors": "Felix Hamann, Nadja Kurz, Adrian Ulges", "title": "Hamming Sentence Embeddings for Information Retrieval", "comments": "4 Pages, 9 Figures, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In retrieval applications, binary hashes are known to offer significant\nimprovements in terms of both memory and speed. We investigate the compression\nof sentence embeddings using a neural encoder-decoder architecture, which is\ntrained by minimizing reconstruction error. Instead of employing the original\nreal-valued embeddings, we use latent representations in Hamming space produced\nby the encoder for similarity calculations.\n  In quantitative experiments on several benchmarks for semantic similarity\ntasks, we show that our compressed hamming embeddings yield a comparable\nperformance to uncompressed embeddings (Sent2Vec, InferSent, Glove-BoW), at\ncompression ratios of up to 256:1. We further demonstrate that our model\nstrongly decorrelates input features, and that the compressor generalizes well\nwhen pre-trained on Wikipedia sentences. We publish the source code on Github\nand all experimental results.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 13:51:12 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Hamann", "Felix", ""], ["Kurz", "Nadja", ""], ["Ulges", "Adrian", ""]]}, {"id": "1908.05596", "submitter": "Timothy Miller", "authors": "Dianbo Liu, Dmitriy Dligach, Timothy Miller", "title": "Two-stage Federated Phenotyping and Patient Representation Learning", "comments": "9 pages; Proceedings of the 18th BioNLP Workshop and Shared Task", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large percentage of medical information is in unstructured text format in\nelectronic medical record systems. Manual extraction of information from\nclinical notes is extremely time consuming. Natural language processing has\nbeen widely used in recent years for automatic information extraction from\nmedical texts. However, algorithms trained on data from a single healthcare\nprovider are not generalizable and error-prone due to the heterogeneity and\nuniqueness of medical documents. We develop a two-stage federated natural\nlanguage processing method that enables utilization of clinical notes from\ndifferent hospitals or clinics without moving the data, and demonstrate its\nperformance using obesity and comorbities phenotyping as medical task. This\napproach not only improves the quality of a specific clinical task but also\nfacilitates knowledge progression in the whole healthcare system, which is an\nessential part of learning health system. To the best of our knowledge, this is\nthe first application of federated machine learning in clinical NLP.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 14:06:11 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Liu", "Dianbo", ""], ["Dligach", "Dmitriy", ""], ["Miller", "Timothy", ""]]}, {"id": "1908.05620", "submitter": "Li Dong", "authors": "Yaru Hao, Li Dong, Furu Wei, Ke Xu", "title": "Visualizing and Understanding the Effectiveness of BERT", "comments": "Accepted by EMNLP-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language model pre-training, such as BERT, has achieved remarkable results in\nmany NLP tasks. However, it is unclear why the pre-training-then-fine-tuning\nparadigm can improve performance and generalization capability across different\ntasks. In this paper, we propose to visualize loss landscapes and optimization\ntrajectories of fine-tuning BERT on specific datasets. First, we find that\npre-training reaches a good initial point across downstream tasks, which leads\nto wider optima and easier optimization compared with training from scratch. We\nalso demonstrate that the fine-tuning procedure is robust to overfitting, even\nthough BERT is highly over-parameterized for downstream tasks. Second, the\nvisualization results indicate that fine-tuning BERT tends to generalize better\nbecause of the flat and wide optima, and the consistency between the training\nloss surface and the generalization error surface. Third, the lower layers of\nBERT are more invariant during fine-tuning, which suggests that the layers that\nare close to input learn more transferable representations of language.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 16:11:45 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Hao", "Yaru", ""], ["Dong", "Li", ""], ["Wei", "Furu", ""], ["Xu", "Ke", ""]]}, {"id": "1908.05646", "submitter": "Yoav Levine", "authors": "Yoav Levine, Barak Lenz, Or Dagan, Ori Ram, Dan Padnos, Or Sharir,\n  Shai Shalev-Shwartz, Amnon Shashua, Yoav Shoham", "title": "SenseBERT: Driving Some Sense into BERT", "comments": "Accepted to ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to learn from large unlabeled corpora has allowed neural language\nmodels to advance the frontier in natural language understanding. However,\nexisting self-supervision techniques operate at the word form level, which\nserves as a surrogate for the underlying semantic content. This paper proposes\na method to employ weak-supervision directly at the word sense level. Our\nmodel, named SenseBERT, is pre-trained to predict not only the masked words but\nalso their WordNet supersenses. Accordingly, we attain a lexical-semantic level\nlanguage model, without the use of human annotation. SenseBERT achieves\nsignificantly improved lexical understanding, as we demonstrate by\nexperimenting on SemEval Word Sense Disambiguation, and by attaining a state of\nthe art result on the Word in Context task.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 17:20:20 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 16:40:41 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Levine", "Yoav", ""], ["Lenz", "Barak", ""], ["Dagan", "Or", ""], ["Ram", "Ori", ""], ["Padnos", "Dan", ""], ["Sharir", "Or", ""], ["Shalev-Shwartz", "Shai", ""], ["Shashua", "Amnon", ""], ["Shoham", "Yoav", ""]]}, {"id": "1908.05672", "submitter": "Mingxuan Wang", "authors": "Jiacheng Yang, Mingxuan Wang, Hao Zhou, Chengqi Zhao, Yong Yu, Weinan\n  Zhang, Lei Li", "title": "Towards Making the Most of BERT in Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GPT-2 and BERT demonstrate the effectiveness of using pre-trained language\nmodels (LMs) on various natural language processing tasks. However, LM\nfine-tuning often suffers from catastrophic forgetting when applied to\nresource-rich tasks. In this work, we introduce a concerted training framework\n(\\method) that is the key to integrate the pre-trained LMs to neural machine\ntranslation (NMT). Our proposed Cnmt consists of three techniques: a)\nasymptotic distillation to ensure that the NMT model can retain the previous\npre-trained knowledge; b) a dynamic switching gate to avoid catastrophic\nforgetting of pre-trained knowledge; and c) a strategy to adjust the learning\npaces according to a scheduled policy. Our experiments in machine translation\nshow \\method gains of up to 3 BLEU score on the WMT14 English-German language\npair which even surpasses the previous state-of-the-art pre-training aided NMT\nby 1.4 BLEU score. While for the large WMT14 English-French task with 40\nmillions of sentence-pairs, our base model still significantly improves upon\nthe state-of-the-art Transformer big model by more than 1 BLEU score.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 03:33:50 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 04:36:18 GMT"}, {"version": "v3", "created": "Fri, 30 Aug 2019 11:26:20 GMT"}, {"version": "v4", "created": "Thu, 26 Mar 2020 12:12:56 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Yang", "Jiacheng", ""], ["Wang", "Mingxuan", ""], ["Zhou", "Hao", ""], ["Zhao", "Chengqi", ""], ["Yu", "Yong", ""], ["Zhang", "Weinan", ""], ["Li", "Lei", ""]]}, {"id": "1908.05679", "submitter": "WonKee Lee", "authors": "WonKee Lee, Junsu Park, Byung-Hyun Go, Jong-Hyeok Lee", "title": "Transformer-based Automatic Post-Editing with a Context-Aware Encoding\n  Approach for Multi-Source Inputs", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent approaches to the Automatic Post-Editing (APE) research have shown\nthat better results are obtained by multi-source models, which jointly encode\nboth source (src) and machine translation output (mt) to produce post-edited\nsentence (pe). Along this trend, we present a new multi-source APE model based\non the Transformer. To construct effective joint representations, our model\ninternally learns to incorporate src context into mt representation. With this\napproach, we achieve a significant improvement over baseline systems, as well\nas the state-of-the-art multi-source APE model. Moreover, to demonstrate the\ncapability of our model to incorporate src context, we show that the word\nalignment of the unknown MT system is successfully captured in our encoding\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 14:08:24 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Lee", "WonKee", ""], ["Park", "Junsu", ""], ["Go", "Byung-Hyun", ""], ["Lee", "Jong-Hyeok", ""]]}, {"id": "1908.05691", "submitter": "Hamada Nayel", "authors": "Hamada A. Nayel, H. L. Shashirekha, Hiroyuki Shindo, Yuji Matsumoto", "title": "Improving Multi-Word Entity Recognition for Biomedical Texts", "comments": "13 pages, 2 figures, International Conference on Cognitive\n  Informatics and Soft Computing (ICCISC-2017)", "journal-ref": "International Journal of Pure and Applied Mathematics, Volume 118\n  No. 16, 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biomedical Named Entity Recognition (BioNER) is a crucial step for analyzing\nBiomedical texts, which aims at extracting biomedical named entities from a\ngiven text. Different supervised machine learning algorithms have been applied\nfor BioNER by various researchers. The main requirement of these approaches is\nan annotated dataset used for learning the parameters of machine learning\nalgorithms. Segment Representation (SR) models comprise of different tag sets\nused for representing the annotated data, such as IOB2, IOE2 and IOBES. In this\npaper, we propose an extension of IOBES model to improve the performance of\nBioNER. The proposed SR model, FROBES, improves the representation of\nmulti-word entities. We used Bidirectional Long Short-Term Memory (BiLSTM)\nnetwork; an instance of Recurrent Neural Networks (RNN), to design a baseline\nsystem for BioNER and evaluated the new SR model on two datasets, i2b2/VA 2010\nchallenge dataset and JNLPBA 2004 shared task dataset. The proposed SR model\noutperforms other models for multi-word entities with length greater than two.\nFurther, the outputs of different SR models have been combined using majority\nvoting ensemble method which outperforms the baseline models performance.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 18:04:39 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Nayel", "Hamada A.", ""], ["Shashirekha", "H. L.", ""], ["Shindo", "Hiroyuki", ""], ["Matsumoto", "Yuji", ""]]}, {"id": "1908.05731", "submitter": "Michael Auli", "authors": "Kyra Yee and Nathan Ng and Yann N. Dauphin and Michael Auli", "title": "Simple and Effective Noisy Channel Modeling for Neural Machine\n  Translation", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work on neural noisy channel modeling relied on latent variable\nmodels that incrementally process the source and target sentence. This makes\ndecoding decisions based on partial source prefixes even though the full source\nis available. We pursue an alternative approach based on standard sequence to\nsequence models which utilize the entire source. These models perform\nremarkably well as channel models, even though they have neither been trained\non, nor designed to factor over incomplete target sentences. Experiments with\nneural language models trained on billions of words show that noisy channel\nmodels can outperform a direct model by up to 3.2 BLEU on WMT'17 German-English\ntranslation. We evaluate on four language-pairs and our channel models\nconsistently outperform strong alternatives such right-to-left reranking models\nand ensembles of direct models.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 19:54:23 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Yee", "Kyra", ""], ["Ng", "Nathan", ""], ["Dauphin", "Yann N.", ""], ["Auli", "Michael", ""]]}, {"id": "1908.05739", "submitter": "Chandra Sekhar Bhagavatula", "authors": "Chandra Bhagavatula, Ronan Le Bras, Chaitanya Malaviya, Keisuke\n  Sakaguchi, Ari Holtzman, Hannah Rashkin, Doug Downey, Scott Wen-tau Yih and\n  Yejin Choi", "title": "Abductive Commonsense Reasoning", "comments": "ICLR 2020 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abductive reasoning is inference to the most plausible explanation. For\nexample, if Jenny finds her house in a mess when she returns from work, and\nremembers that she left a window open, she can hypothesize that a thief broke\ninto her house and caused the mess, as the most plausible explanation. While\nabduction has long been considered to be at the core of how people interpret\nand read between the lines in natural language (Hobbs et al., 1988), there has\nbeen relatively little research in support of abductive natural language\ninference and generation. We present the first study that investigates the\nviability of language-based abductive reasoning. We introduce a challenge\ndataset, ART, that consists of over 20k commonsense narrative contexts and 200k\nexplanations. Based on this dataset, we conceptualize two new tasks -- (i)\nAbductive NLI: a multiple-choice question answering task for choosing the more\nlikely explanation, and (ii) Abductive NLG: a conditional generation task for\nexplaining given observations in natural language. On Abductive NLI, the best\nmodel achieves 68.9% accuracy, well below human performance of 91.4%. On\nAbductive NLG, the current best language generators struggle even more, as they\nlack reasoning capabilities that are trivial for humans. Our analysis leads to\nnew insights into the types of reasoning that deep pre-trained language models\nfail to perform--despite their strong performance on the related but more\nnarrowly defined task of entailment NLI--pointing to interesting avenues for\nfuture research.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 20:03:10 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 02:52:27 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Bhagavatula", "Chandra", ""], ["Bras", "Ronan Le", ""], ["Malaviya", "Chaitanya", ""], ["Sakaguchi", "Keisuke", ""], ["Holtzman", "Ari", ""], ["Rashkin", "Hannah", ""], ["Downey", "Doug", ""], ["Yih", "Scott Wen-tau", ""], ["Choi", "Yejin", ""]]}, {"id": "1908.05757", "submitter": "Apik Zorian Mr", "authors": "Apik Ashod Zorian and Chandra Shekar Bikkanur", "title": "Debiasing Personal Identities in Toxicity Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Machine Learning models continue to be relied upon for making automated\ndecisions, the issue of model bias becomes more and more prevalent. In this\npaper, we approach training a text classifica-tion model and optimize on bias\nminimization by measuring not only the models performance on our dataset as a\nwhole, but also how it performs across different subgroups. This requires\nmeasuring per-formance independently for different demographic subgroups and\nmeasuring bias by comparing them to results from the rest of our data. We show\nhow unintended bias can be detected using these metrics and how removing bias\nfrom a dataset completely can result in worse results.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 17:37:31 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Zorian", "Apik Ashod", ""], ["Bikkanur", "Chandra Shekar", ""]]}, {"id": "1908.05758", "submitter": "Daniel Menezes", "authors": "Daniel Specht Menezes, Pedro Savarese, Ruy Luiz Milidi\\'u", "title": "Building a Massive Corpus for Named Entity Recognition using Free Open\n  Data Sources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent progress in machine learning, boosted by techniques such as\ndeep learning, many tasks can be successfully solved once a large enough\ndataset is available for training. Nonetheless, human-annotated datasets are\noften expensive to produce, especially when labels are fine-grained, as is the\ncase of Named Entity Recognition (NER), a task that operates with labels on a\nword-level.\n  In this paper, we propose a method to automatically generate labeled datasets\nfor NER from public data sources by exploiting links and structured data from\nDBpedia and Wikipedia. Due to the massive size of these data sources, the\nresulting dataset -- SESAME Available at https://sesame-pt.github.io -- is\ncomposed of millions of labeled sentences. We detail the method to generate the\ndataset, report relevant statistics, and design a baseline using a neural\nnetwork, showing that our dataset helps building better NER predictors.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 03:47:03 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Menezes", "Daniel Specht", ""], ["Savarese", "Pedro", ""], ["Milidi\u00fa", "Ruy Luiz", ""]]}, {"id": "1908.05760", "submitter": "Shreyas Sharma", "authors": "Shreyas Sharma and Ron Daniel Jr", "title": "BioFLAIR: Pretrained Pooled Contextualized Embeddings for Biomedical\n  Sequence Labeling Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biomedical Named Entity Recognition (NER) is a challenging problem in\nbiomedical information processing due to the widespread ambiguity of out of\ncontext terms and extensive lexical variations. Performance on bioNER\nbenchmarks continues to improve due to advances like BERT, GPT, and XLNet.\nFLAIR (1) is an alternative embedding model which is less computationally\nintensive than the others mentioned. We test FLAIR and its pretrained PubMed\nembeddings (which we term BioFLAIR) on a variety of bio NER tasks and compare\nthose with results from BERT-type networks. We also investigate the effects of\na small amount of additional pretraining on PubMed content, and of combining\nFLAIR and ELMO models. We find that with the provided embeddings, FLAIR\nperforms on-par with the BERT networks - even establishing a new state of the\nart on one benchmark. Additional pretraining did not provide a clear benefit,\nalthough this might change with even more pretraining being done. Stacking the\nFLAIR embeddings with others typically does provide a boost in the benchmark\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 13:55:48 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Sharma", "Shreyas", ""], ["Daniel", "Ron", "Jr"]]}, {"id": "1908.05762", "submitter": "Hamed Shahbazi", "authors": "Hamed Shahbazi, Xiaoli Z. Fern, Reza Ghaeini, Rasha Obeidat and Prasad\n  Tadepalli", "title": "Entity-aware ELMo: Learning Contextual Entity Representation for Entity\n  Disambiguation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new local entity disambiguation system. The key to our system is\na novel approach for learning entity representations. In our approach we learn\nan entity aware extension of Embedding for Language Model (ELMo) which we call\nEntity-ELMo (E-ELMo). Given a paragraph containing one or more named entity\nmentions, each mention is first defined as a function of the entire paragraph\n(including other mentions), then they predict the referent entities. Utilizing\nE-ELMo for local entity disambiguation, we outperform all of the\nstate-of-the-art local and global models on the popular benchmarks by improving\nabout 0.5\\% on micro average accuracy for AIDA test-b with Yago candidate set.\nThe evaluation setup of the training data and candidate set are the same as our\nbaselines for fair comparison.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 03:51:25 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 16:49:24 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Shahbazi", "Hamed", ""], ["Fern", "Xiaoli Z.", ""], ["Ghaeini", "Reza", ""], ["Obeidat", "Rasha", ""], ["Tadepalli", "Prasad", ""]]}, {"id": "1908.05763", "submitter": "Chinnadhurai Sankar", "authors": "Chinnadhurai Sankar, Sujith Ravi, Zornitsa Kozareva", "title": "On-Device Text Representations Robust To Misspellings via Projections", "comments": "EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been a strong interest in developing natural language\napplications that live on personal devices such as mobile phones, watches and\nIoT with the objective to preserve user privacy and have low memory. Advances\nin Locality-Sensitive Hashing (LSH)-based projection networks have demonstrated\nstate-of-the-art performance in various classification tasks without explicit\nword (or word-piece) embedding lookup tables by computing on-the-fly text\nrepresentations. In this paper, we show that the projection based neural\nclassifiers are inherently robust to misspellings and perturbations of the\ninput text. We empirically demonstrate that the LSH projection based\nclassifiers are more robust to common misspellings compared to BiLSTMs (with\nboth word-piece & word-only tokenization) and fine-tuned BERT based methods.\nWhen subject to misspelling attacks, LSH projection based classifiers had a\nsmall average accuracy drop of 2.94% across multiple classifications tasks,\nwhile the fine-tuned BERT model accuracy had a significant drop of 11.44%.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 14:48:07 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 08:20:32 GMT"}, {"version": "v3", "created": "Sat, 24 Apr 2021 00:34:01 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Sankar", "Chinnadhurai", ""], ["Ravi", "Sujith", ""], ["Kozareva", "Zornitsa", ""]]}, {"id": "1908.05780", "submitter": "Venet Osmani", "authors": "Seyedmostafa Sheikhalishahi, Riccardo Miotto, Joel T Dudley, Alberto\n  Lavelli, Fabio Rinaldi, Venet Osmani", "title": "Natural Language Processing of Clinical Notes on Chronic Diseases:\n  Systematic Review", "comments": "Supplementary material detailing articles reviewed, classification of\n  diseases and associated algorithms, can be found at:\n  http://venetosmani.com/research/publications.html", "journal-ref": "JMIR Medical Informatics 2019;7(2):e12239, PMID:31066697", "doi": "10.2196/12239", "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Of the 2652 articles considered, 106 met the inclusion criteria. Review of\nthe included papers resulted in identification of 43 chronic diseases, which\nwere then further classified into 10 disease categories using ICD-10. The\nmajority of studies focused on diseases of the circulatory system (n=38) while\nendocrine and metabolic diseases were fewest (n=14). This was due to the\nstructure of clinical records related to metabolic diseases, which typically\ncontain much more structured data, compared with medical records for diseases\nof the circulatory system, which focus more on unstructured data and\nconsequently have seen a stronger focus of NLP. The review has shown that there\nis a significant increase in the use of machine learning methods compared to\nrule-based approaches; however, deep learning methods remain emergent (n=3).\nConsequently, the majority of works focus on classification of disease\nphenotype with only a handful of papers addressing extraction of comorbidities\nfrom the free text or integration of clinical notes with structured data. There\nis a notable use of relatively simple methods, such as shallow classifiers (or\ncombination with rule-based methods), due to the interpretability of\npredictions, which still represents a significant issue for more complex\nmethods. Finally, scarcity of publicly available data may also have contributed\nto insufficient development of more advanced methods, such as extraction of\nword embeddings from clinical notes. Further efforts are still required to\nimprove (1) progression of clinical NLP methods from extraction toward\nunderstanding; (2) recognition of relations among entities rather than entities\nin isolation; (3) temporal extraction to understand past, current, and future\nclinical events; (4) exploitation of alternative sources of clinical knowledge;\nand (5) availability of large-scale, de-identified clinical corpora.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 21:54:06 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Sheikhalishahi", "Seyedmostafa", ""], ["Miotto", "Riccardo", ""], ["Dudley", "Joel T", ""], ["Lavelli", "Alberto", ""], ["Rinaldi", "Fabio", ""], ["Osmani", "Venet", ""]]}, {"id": "1908.05787", "submitter": "E M Wasifur Rahman Chowdhury", "authors": "Wasifur Rahman, Md. Kamrul Hasan, Sangwu Lee, Amir Zadeh, Chengfeng\n  Mao, Louis-Philippe Morency, Ehsan Hoque", "title": "Integrating Multimodal Information in Large Pretrained Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent Transformer-based contextual word representations, including BERT and\nXLNet, have shown state-of-the-art performance in multiple disciplines within\nNLP. Fine-tuning the trained contextual models on task-specific datasets has\nbeen the key to achieving superior performance downstream. While fine-tuning\nthese pre-trained models is straightforward for lexical applications\n(applications with only language modality), it is not trivial for multimodal\nlanguage (a growing area in NLP focused on modeling face-to-face\ncommunication). Pre-trained models don't have the necessary components to\naccept two extra modalities of vision and acoustic. In this paper, we proposed\nan attachment to BERT and XLNet called Multimodal Adaptation Gate (MAG). MAG\nallows BERT and XLNet to accept multimodal nonverbal data during fine-tuning.\nIt does so by generating a shift to internal representation of BERT and XLNet;\na shift that is conditioned on the visual and acoustic modalities. In our\nexperiments, we study the commonly used CMU-MOSI and CMU-MOSEI datasets for\nmultimodal sentiment analysis. Fine-tuning MAG-BERT and MAG-XLNet significantly\nboosts the sentiment analysis performance over previous baselines as well as\nlanguage-only fine-tuning of BERT and XLNet. On the CMU-MOSI dataset, MAG-XLNet\nachieves human-level multimodal sentiment analysis performance for the first\ntime in the NLP community.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 22:51:21 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 16:50:11 GMT"}, {"version": "v3", "created": "Sat, 21 Nov 2020 13:52:22 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Rahman", "Wasifur", ""], ["Hasan", "Md. Kamrul", ""], ["Lee", "Sangwu", ""], ["Zadeh", "Amir", ""], ["Mao", "Chengfeng", ""], ["Morency", "Louis-Philippe", ""], ["Hoque", "Ehsan", ""]]}, {"id": "1908.05803", "submitter": "Pradeep Dasigi", "authors": "Pradeep Dasigi, Nelson F. Liu, Ana Marasovi\\'c, Noah A. Smith, Matt\n  Gardner", "title": "Quoref: A Reading Comprehension Dataset with Questions Requiring\n  Coreferential Reasoning", "comments": "8 pages including appendix; EMNLP 2019 accepted paper camera ready\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Machine comprehension of texts longer than a single sentence often requires\ncoreference resolution. However, most current reading comprehension benchmarks\ndo not contain complex coreferential phenomena and hence fail to evaluate the\nability of models to resolve coreference. We present a new crowdsourced dataset\ncontaining more than 24K span-selection questions that require resolving\ncoreference among entities in over 4.7K English paragraphs from Wikipedia.\nObtaining questions focused on such phenomena is challenging, because it is\nhard to avoid lexical cues that shortcut complex reasoning. We deal with this\nissue by using a strong baseline model as an adversary in the crowdsourcing\nloop, which helps crowdworkers avoid writing questions with exploitable surface\ncues. We show that state-of-the-art reading comprehension models perform\nsignificantly worse than humans on this benchmark---the best model performance\nis 70.5 F1, while the estimated human performance is 93.4 F1.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 00:59:44 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 01:20:10 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Dasigi", "Pradeep", ""], ["Liu", "Nelson F.", ""], ["Marasovi\u0107", "Ana", ""], ["Smith", "Noah A.", ""], ["Gardner", "Matt", ""]]}, {"id": "1908.05828", "submitter": "Oyesh Singh", "authors": "Oyesh Mann Singh, Ankur Padia, Anupam Joshi", "title": "Named Entity Recognition for Nepali Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Named Entity Recognition have been studied for different languages like\nEnglish, German, Spanish and many others but no study have focused on Nepali\nlanguage. In this paper we propose a neural based Nepali NER using latest\nstate-of-the-art architecture based on grapheme-level which doesn't require any\nhand-crafted features and no data pre-processing. Our novel neural based model\ngained relative improvement of 33% to 50% compared to feature based SVM model\nand up to 10% improvement over state-of-the-art neural based model developed\nfor languages beside Nepali.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 03:14:43 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Singh", "Oyesh Mann", ""], ["Padia", "Ankur", ""], ["Joshi", "Anupam", ""]]}, {"id": "1908.05838", "submitter": "Antonios Anastasopoulos", "authors": "Antonios Anastasopoulos and Graham Neubig", "title": "Pushing the Limits of Low-Resource Morphological Inflection", "comments": "to appear at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen exceptional strides in the task of automatic\nmorphological inflection generation. However, for a long tail of languages the\nnecessary resources are hard to come by, and state-of-the-art neural methods\nthat work well under higher resource settings perform poorly in the face of a\npaucity of data. In response, we propose a battery of improvements that greatly\nimprove performance under such low-resource conditions. First, we present a\nnovel two-step attention architecture for the inflection decoder. In addition,\nwe investigate the effects of cross-lingual transfer from single and multiple\nlanguages, as well as monolingual data hallucination. The macro-averaged\naccuracy of our models outperforms the state-of-the-art by 15 percentage\npoints. Also, we identify the crucial factors for success with cross-lingual\ntransfer for morphological inflection: typological similarity and a common\nrepresentation across languages.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 04:15:32 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 14:15:58 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Anastasopoulos", "Antonios", ""], ["Neubig", "Graham", ""]]}, {"id": "1908.05848", "submitter": "Xi Ye", "authors": "Xi Ye, Qiaochu Chen, Xinyu Wang, Isil Dillig, Greg Durrett", "title": "Sketch-Driven Regular Expression Generation from Natural Language and\n  Examples", "comments": "TACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent systems for converting natural language descriptions into regular\nexpressions (regexes) have achieved some success, but typically deal with\nshort, formulaic text and can only produce simple regexes. Realworld regexes\nare complex, hard to describe with brief sentences, and sometimes require\nexamples to fully convey the user's intent. We present a framework for regex\nsynthesis in this setting where both natural language (NL) and examples are\navailable. First, a semantic parser (either grammar-based or neural) maps the\nnatural language description into an intermediate sketch, which is an\nincomplete regex containing holes to denote missing components. Then a program\nsynthesizer searches over the regex space defined by the sketch and finds a\nregex that is consistent with the given string examples. Our semantic parser\ncan be trained purely from weak supervision based on correctness of the\nsynthesized regex, or it can leverage heuristically-derived sketches. We\nevaluate on two prior datasets (Kushman and Barzilay, 2013; Locascio et al.,\n2016) and a real-world dataset from Stack Overflow. Our system achieves\nstate-of-the-art performance on the prior datasets and solves 57% of the\nreal-world dataset, which existing neural systems completely fail on.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 05:09:57 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 23:28:07 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Ye", "Xi", ""], ["Chen", "Qiaochu", ""], ["Wang", "Xinyu", ""], ["Dillig", "Isil", ""], ["Durrett", "Greg", ""]]}, {"id": "1908.05852", "submitter": "Kevin Lin", "authors": "Kevin Lin, Oyvind Tafjord, Peter Clark, Matt Gardner", "title": "Reasoning Over Paragraph Effects in Situations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key component of successfully reading a passage of text is the ability to\napply knowledge gained from the passage to a new situation. In order to\nfacilitate progress on this kind of reading, we present ROPES, a challenging\nbenchmark for reading comprehension targeting Reasoning Over Paragraph Effects\nin Situations. We target expository language describing causes and effects\n(e.g., \"animal pollinators increase efficiency of fertilization in flowers\"),\nas they have clear implications for new situations. A system is presented a\nbackground passage containing at least one of these relations, a novel\nsituation that uses this background, and questions that require reasoning about\neffects of the relationships in the background passage in the context of the\nsituation. We collect background passages from science textbooks and Wikipedia\nthat contain such phenomena, and ask crowd workers to author situations,\nquestions, and answers, resulting in a 14,322 question dataset. We analyze the\nchallenges of this task and evaluate the performance of state-of-the-art\nreading comprehension models. The best model performs only slightly better than\nrandomly guessing an answer of the correct type, at 61.6% F1, well below the\nhuman performance of 89.0%.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 05:36:04 GMT"}, {"version": "v2", "created": "Sun, 15 Dec 2019 17:32:45 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Lin", "Kevin", ""], ["Tafjord", "Oyvind", ""], ["Clark", "Peter", ""], ["Gardner", "Matt", ""]]}, {"id": "1908.05854", "submitter": "Igor Shalyminov", "authors": "Igor Shalyminov, Sungjin Lee, Arash Eshghi, and Oliver Lemon", "title": "Few-Shot Dialogue Generation Without Annotated Data: A Transfer Learning\n  Approach", "comments": "Accepted at SigDial 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning with minimal data is one of the key challenges in the development of\npractical, production-ready goal-oriented dialogue systems. In a real-world\nenterprise setting where dialogue systems are developed rapidly and are\nexpected to work robustly for an ever-growing variety of domains, products, and\nscenarios, efficient learning from a limited number of examples becomes\nindispensable.\n  In this paper, we introduce a technique to achieve state-of-the-art dialogue\ngeneration performance in a few-shot setup, without using any annotated data.\nWe do this by leveraging background knowledge from a larger, more highly\nrepresented dialogue source --- namely, the MetaLWOz dataset. We evaluate our\nmodel on the Stanford Multi-Domain Dialogue Dataset, consisting of human-human\ngoal-oriented dialogues in in-car navigation, appointment scheduling, and\nweather information domains.\n  We show that our few-shot approach achieves state-of-the art results on that\ndataset by consistently outperforming the previous best model in terms of BLEU\nand Entity F1 scores, while being more data-efficient by not requiring any data\nannotation.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 05:48:41 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Shalyminov", "Igor", ""], ["Lee", "Sungjin", ""], ["Eshghi", "Arash", ""], ["Lemon", "Oliver", ""]]}, {"id": "1908.05859", "submitter": "Jia-Chen Gu", "authors": "Jia-Chen Gu, Zhen-Hua Ling, Xiaodan Zhu, Quan Liu", "title": "Dually Interactive Matching Network for Personalized Response Selection\n  in Retrieval-Based Chatbots", "comments": "Accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a dually interactive matching network (DIM) for\npresenting the personalities of dialogue agents in retrieval-based chatbots.\nThis model develops from the interactive matching network (IMN) which models\nthe matching degree between a context composed of multiple utterances and a\nresponse candidate. Compared with previous persona fusion approaches which\nenhance the representation of a context by calculating its similarity with a\ngiven persona, the DIM model adopts a dual matching architecture, which\nperforms interactive matching between responses and contexts and between\nresponses and personas respectively for ranking response candidates.\nExperimental results on PERSONA-CHAT dataset show that the DIM model\noutperforms its baseline model, i.e., IMN with persona fusion, by a margin of\n14.5% and outperforms the current state-of-the-art model by a margin of 27.7%\nin terms of top-1 accuracy hits@1.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 06:15:18 GMT"}, {"version": "v2", "created": "Sat, 7 Sep 2019 10:50:40 GMT"}, {"version": "v3", "created": "Sat, 1 Feb 2020 21:21:16 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Gu", "Jia-Chen", ""], ["Ling", "Zhen-Hua", ""], ["Zhu", "Xiaodan", ""], ["Liu", "Quan", ""]]}, {"id": "1908.05908", "submitter": "Weipeng Huang", "authors": "Weipeng Huang and Xingyi Cheng and Taifeng Wang and Wei Chu", "title": "BERT-Based Multi-Head Selection for Joint Entity-Relation Extraction", "comments": "To appear at NLPCC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we report our method for the Information Extraction task in\n2019 Language and Intelligence Challenge. We incorporate BERT into the\nmulti-head selection framework for joint entity-relation extraction. This model\nextends existing approaches from three perspectives. First, BERT is adopted as\na feature extraction layer at the bottom of the multi-head selection framework.\nWe further optimize BERT by introducing a semantic-enhanced task during BERT\npre-training. Second, we introduce a large-scale Baidu Baike corpus for entity\nrecognition pre-training, which is of weekly supervised learning since there is\nno actual named entity label. Third, soft label embedding is proposed to\neffectively transmit information between entity recognition and relation\nextraction. Combining these three contributions, we enhance the information\nextracting ability of the multi-head selection model and achieve F1-score 0.876\non testset-1 with a single model. By ensembling four variants of our model, we\nfinally achieve F1 score 0.892 (1st place) on testset-1 and F1 score 0.8924\n(2nd place) on testset-2.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 09:29:43 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 07:56:07 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Huang", "Weipeng", ""], ["Cheng", "Xingyi", ""], ["Wang", "Taifeng", ""], ["Chu", "Wei", ""]]}, {"id": "1908.05915", "submitter": "Carolin Lawrence", "authors": "Carolin Lawrence, Bhushan Kotnis, Mathias Niepert", "title": "Attending to Future Tokens For Bidirectional Sequence Generation", "comments": "Conference on Empirical Methods in Natural Language Processing\n  (EMNLP), 2019, Hong Kong, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural sequence generation is typically performed token-by-token and\nleft-to-right. Whenever a token is generated only previously produced tokens\nare taken into consideration. In contrast, for problems such as sequence\nclassification, bidirectional attention, which takes both past and future\ntokens into consideration, has been shown to perform much better. We propose to\nmake the sequence generation process bidirectional by employing special\nplaceholder tokens. Treated as a node in a fully connected graph, a placeholder\ntoken can take past and future tokens into consideration when generating the\nactual output token. We verify the effectiveness of our approach experimentally\non two conversational tasks where the proposed bidirectional model outperforms\ncompetitive baselines by a large margin.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 10:00:45 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 13:50:11 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Lawrence", "Carolin", ""], ["Kotnis", "Bhushan", ""], ["Niepert", "Mathias", ""]]}, {"id": "1908.05925", "submitter": "Zihan Liu", "authors": "Zihan Liu, Yan Xu, Genta Indra Winata, Pascale Fung", "title": "Incorporating Word and Subword Units in Unsupervised Machine Translation\n  Using Language Model Rescoring", "comments": "Accepted at WMT 2019. (The first and second authors contributed\n  equally)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes CAiRE's submission to the unsupervised machine\ntranslation track of the WMT'19 news shared task from German to Czech. We\nleverage a phrase-based statistical machine translation (PBSMT) model and a\npre-trained language model to combine word-level neural machine translation\n(NMT) and subword-level NMT models without using any parallel data. We propose\nto solve the morphological richness problem of languages by training byte-pair\nencoding (BPE) embeddings for German and Czech separately, and they are aligned\nusing MUSE (Conneau et al., 2018). To ensure the fluency and consistency of\ntranslations, a rescoring mechanism is proposed that reuses the pre-trained\nlanguage model to select the translation candidates generated through beam\nsearch. Moreover, a series of pre-processing and post-processing approaches are\napplied to improve the quality of final translations.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 10:44:25 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 08:22:34 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Liu", "Zihan", ""], ["Xu", "Yan", ""], ["Winata", "Genta Indra", ""], ["Fung", "Pascale", ""]]}, {"id": "1908.05947", "submitter": "Ruozi Huang", "authors": "Ruozi Huang, Mi Zhang, Xudong Pan and Beina Sheng", "title": "How Sequence-to-Sequence Models Perceive Language Styles?", "comments": "12pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Style is ubiquitous in our daily language uses, while what is language style\nto learning machines? In this paper, by exploiting the second-order statistics\nof semantic vectors of different corpora, we present a novel perspective on\nthis question via style matrix, i.e. the covariance matrix of semantic vectors,\nand explain for the first time how Sequence-to-Sequence models encode style\ninformation innately in its semantic vectors. As an application, we devise a\nlearning-free text style transfer algorithm, which explicitly constructs a pair\nof transfer operators from the style matrices for style transfer. Moreover, our\nalgorithm is also observed to be flexible enough to transfer out-of-domain\nsentences. Extensive experimental evidence justifies the informativeness of\nstyle matrix and the competitive performance of our proposed style transfer\nalgorithm with the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 12:38:05 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Huang", "Ruozi", ""], ["Zhang", "Mi", ""], ["Pan", "Xudong", ""], ["Sheng", "Beina", ""]]}, {"id": "1908.05957", "submitter": "Zhijiang Guo", "authors": "Zhijiang Guo, Yan Zhang, Zhiyang Teng, Wei Lu", "title": "Densely Connected Graph Convolutional Networks for Graph-to-Sequence\n  Learning", "comments": "Conditional accepted by TACL on December 2018, accepted by TACL on\n  February 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on graph-to-sequence learning, which can be framed as transducing\ngraph structures to sequences for text generation. To capture structural\ninformation associated with graphs, we investigate the problem of encoding\ngraphs using graph convolutional networks (GCNs). Unlike various existing\napproaches where shallow architectures were used for capturing local structural\ninformation only, we introduce a dense connection strategy, proposing a novel\nDensely Connected Graph Convolutional Networks (DCGCNs). Such a deep\narchitecture is able to integrate both local and non-local features to learn a\nbetter structural representation of a graph. Our model outperforms the\nstate-of-the-art neural models significantly on AMRto-text generation and\nsyntax-based neural machine translation.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 12:58:16 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 09:43:49 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Guo", "Zhijiang", ""], ["Zhang", "Yan", ""], ["Teng", "Zhiyang", ""], ["Lu", "Wei", ""]]}, {"id": "1908.05969", "submitter": "Ruotian Ma", "authors": "Ruotian Ma, Minlong Peng, Qi Zhang, Xuanjing Huang", "title": "Simplify the Usage of Lexicon in Chinese NER", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, many works have tried to augment the performance of Chinese named\nentity recognition (NER) using word lexicons. As a representative, Lattice-LSTM\n(Zhang and Yang, 2018) has achieved new benchmark results on several public\nChinese NER datasets. However, Lattice-LSTM has a complex model architecture.\nThis limits its application in many industrial areas where real-time NER\nresponses are needed.\n  In this work, we propose a simple but effective method for incorporating the\nword lexicon into the character representations. This method avoids designing a\ncomplicated sequence modeling architecture, and for any neural NER model, it\nrequires only subtle adjustment of the character representation layer to\nintroduce the lexicon information. Experimental studies on four benchmark\nChinese NER datasets show that our method achieves an inference speed up to\n6.15 times faster than those of state-ofthe-art methods, along with a better\nperformance. The experimental results also show that the proposed method can be\neasily incorporated with pre-trained models like BERT.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 13:35:24 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 08:06:12 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Ma", "Ruotian", ""], ["Peng", "Minlong", ""], ["Zhang", "Qi", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1908.06006", "submitter": "Jean-Baptiste Remy", "authors": "Jean-Baptiste Remy and Antoine Jean-Pierre Tixier and Michalis\n  Vazirgiannis", "title": "Bidirectional Context-Aware Hierarchical Attention Network for Document\n  Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hierarchical Attention Network (HAN) has made great strides, but it\nsuffers a major limitation: at level 1, each sentence is encoded in complete\nisolation. In this work, we propose and compare several modifications of HAN in\nwhich the sentence encoder is able to make context-aware attentional decisions\n(CAHAN). Furthermore, we propose a bidirectional document encoder that\nprocesses the document forwards and backwards, using the preceding and\nfollowing sentences as context. Experiments on three large-scale sentiment and\ntopic classification datasets show that the bidirectional version of CAHAN\noutperforms HAN everywhere, with only a modest increase in computation time.\nWhile results are promising, we expect the superiority of CAHAN to be even more\nevident on tasks requiring a deeper understanding of the input documents, such\nas abstractive summarization. Code is publicly available.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 15:20:04 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Remy", "Jean-Baptiste", ""], ["Tixier", "Antoine Jean-Pierre", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "1908.06008", "submitter": "Soujanya Poria", "authors": "Navonil Majumder, Soujanya Poria, Gangeshwar Krishnamurthy, Niyati\n  Chhaya, Rada Mihalcea, Alexander Gelbukh", "title": "Variational Fusion for Multimodal Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Multimodal fusion is considered a key step in multimodal tasks such as\nsentiment analysis, emotion detection, question answering, and others. Most of\nthe recent work on multimodal fusion does not guarantee the fidelity of the\nmultimodal representation with respect to the unimodal representations. In this\npaper, we propose a variational autoencoder-based approach for modality fusion\nthat minimizes information loss between unimodal and multimodal\nrepresentations. We empirically show that this method outperforms the\nstate-of-the-art methods by a significant margin on several popular datasets.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 13:39:19 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Majumder", "Navonil", ""], ["Poria", "Soujanya", ""], ["Krishnamurthy", "Gangeshwar", ""], ["Chhaya", "Niyati", ""], ["Mihalcea", "Rada", ""], ["Gelbukh", "Alexander", ""]]}, {"id": "1908.06015", "submitter": "Ari Klein", "authors": "Ari Z. Klein, Abeselom Gebreyesus, Graciela Gonzalez-Hernandez", "title": "Automatically Identifying Comparator Groups on Twitter for Digital\n  Epidemiology of Pregnancy Outcomes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the prevalence of adverse pregnancy outcomes such as miscarriage,\nstillbirth, birth defects, and preterm birth, their causes are largely unknown.\nWe seek to advance the use of social media for observational studies of\npregnancy outcomes by developing a natural language processing pipeline for\nautomatically identifying users from which to select comparator groups on\nTwitter. We annotated 2361 tweets by users who have announced their pregnancy\non Twitter, which were used to train and evaluate supervised machine learning\nalgorithms as a basis for automatically detecting women who have reported that\ntheir pregnancy had reached term and their baby was born at a normal weight.\nUpon further processing the tweet-level predictions of a majority voting-based\nensemble classifier, the pipeline achieved a user-level F1-score of 0.933, with\na precision of 0.947 and a recall of 0.920. Our pipeline will be deployed to\nidentify large comparator groups for studying pregnancy outcomes on Twitter.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 15:21:34 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Klein", "Ari Z.", ""], ["Gebreyesus", "Abeselom", ""], ["Gonzalez-Hernandez", "Graciela", ""]]}, {"id": "1908.06024", "submitter": "Pushkar Mishra", "authors": "Pushkar Mishra, Helen Yannakoudakis and Ekaterina Shutova", "title": "Tackling Online Abuse: A Survey of Automated Abuse Detection Methods", "comments": "In preparation for Computational Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abuse on the Internet represents an important societal problem of our time.\nMillions of Internet users face harassment, racism, personal attacks, and other\ntypes of abuse on online platforms. The psychological effects of such abuse on\nindividuals can be profound and lasting. Consequently, over the past few years,\nthere has been a substantial research effort towards automated abuse detection\nin the field of natural language processing (NLP). In this paper, we present a\ncomprehensive survey of the methods that have been proposed to date, thus\nproviding a platform for further development of this area. We describe the\nexisting datasets and review the computational approaches to abuse detection,\nanalyzing their strengths and limitations. We discuss the main trends that\nemerge, highlight the challenges that remain, outline possible solutions, and\npropose guidelines for ethics and explainability\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 10:59:06 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 11:42:04 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Mishra", "Pushkar", ""], ["Yannakoudakis", "Helen", ""], ["Shutova", "Ekaterina", ""]]}, {"id": "1908.06039", "submitter": "Yujia Bao", "authors": "Yujia Bao, Menghua Wu, Shiyu Chang, Regina Barzilay", "title": "Few-shot Text Classification with Distributional Signatures", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore meta-learning for few-shot text classification.\nMeta-learning has shown strong performance in computer vision, where low-level\npatterns are transferable across learning tasks. However, directly applying\nthis approach to text is challenging--lexical features highly informative for\none task may be insignificant for another. Thus, rather than learning solely\nfrom words, our model also leverages their distributional signatures, which\nencode pertinent word occurrence patterns. Our model is trained within a\nmeta-learning framework to map these signatures into attention scores, which\nare then used to weight the lexical representations of words. We demonstrate\nthat our model consistently outperforms prototypical networks learned on\nlexical knowledge (Snell et al., 2017) in both few-shot text classification and\nrelation classification by a significant margin across six benchmark datasets\n(20.0% on average in 1-shot classification).\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 15:46:14 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 19:14:03 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 17:47:46 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Bao", "Yujia", ""], ["Wu", "Menghua", ""], ["Chang", "Shiyu", ""], ["Barzilay", "Regina", ""]]}, {"id": "1908.06082", "submitter": "Prathusha Kameswara Sarma", "authors": "Prathusha K Sarma, Yingyu Liang, William A Sethares", "title": "Shallow Domain Adaptive Embeddings for Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a way to improve the performance of existing algorithms\nfor text classification in domains with strong language semantics. We propose a\ndomain adaptation layer learns weights to combine a generic and a domain\nspecific (DS) word embedding into a domain adapted (DA) embedding. The DA word\nembeddings are then used as inputs to a generic encoder + classifier framework\nto perform a downstream task such as classification. This adaptation layer is\nparticularly suited to datasets that are modest in size, and which are,\ntherefore, not ideal candidates for (re)training a deep neural network\narchitecture. Results on binary and multi-class classification tasks using\npopular encoder architectures, including current state-of-the-art methods (with\nand without the shallow adaptation layer) show the effectiveness of the\nproposed approach.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 20:25:13 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Sarma", "Prathusha K", ""], ["Liang", "Yingyu", ""], ["Sethares", "William A", ""]]}, {"id": "1908.06083", "submitter": "Jason  Weston", "authors": "Emily Dinan, Samuel Humeau, Bharath Chintagunta, Jason Weston", "title": "Build it Break it Fix it for Dialogue Safety: Robustness from\n  Adversarial Human Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection of offensive language in the context of a dialogue has become\nan increasingly important application of natural language processing. The\ndetection of trolls in public forums (Gal\\'an-Garc\\'ia et al., 2016), and the\ndeployment of chatbots in the public domain (Wolf et al., 2017) are two\nexamples that show the necessity of guarding against adversarially offensive\nbehavior on the part of humans. In this work, we develop a training scheme for\na model to become robust to such human attacks by an iterative build it, break\nit, fix it strategy with humans and models in the loop. In detailed experiments\nwe show this approach is considerably more robust than previous systems.\nFurther, we show that offensive language used within a conversation critically\ndepends on the dialogue context, and cannot be viewed as a single sentence\noffensive detection task as in most previous work. Our newly collected tasks\nand methods will be made open source and publicly available.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 18:34:11 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Dinan", "Emily", ""], ["Humeau", "Samuel", ""], ["Chintagunta", "Bharath", ""], ["Weston", "Jason", ""]]}, {"id": "1908.06121", "submitter": "Rishav Chakravarti", "authors": "Rishav Chakravarti, Cezar Pendus, Andrzej Sakrajda, Anthony Ferritto,\n  Lin Pan, Michael Glass, Vittorio Castelli, J. William Murdock, Radu Florian,\n  Salim Roukos, Avirup Sil", "title": "CFO: A Framework for Building Production NLP Systems", "comments": "http://ibm.biz/cfo_framework", "journal-ref": "Proceedings of the 2019 Conference on Empirical Methods in Natural\n  Language Processing and the 9th International Joint Conference on Natural\n  Language Processing (EMNLP-IJCNLP): System Demonstrations", "doi": "10.18653/v1/D19-3006", "report-no": "D19-3006", "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel orchestration framework, called CFO\n(COMPUTATION FLOW ORCHESTRATOR), for building, experimenting with, and\ndeploying interactive NLP (Natural Language Processing) and IR (Information\nRetrieval) systems to production environments. We then demonstrate a question\nanswering system built using this framework which incorporates state-of-the-art\nBERT based MRC (Machine Reading Comprehension) with IR components to enable\nend-to-end answer retrieval. Results from the demo system are shown to be high\nquality in both academic and industry domain specific settings. Finally, we\ndiscuss best practices when (pre-)training BERT based MRC models for production\nsystems.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 18:19:59 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 15:01:20 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 20:24:05 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Chakravarti", "Rishav", ""], ["Pendus", "Cezar", ""], ["Sakrajda", "Andrzej", ""], ["Ferritto", "Anthony", ""], ["Pan", "Lin", ""], ["Glass", "Michael", ""], ["Castelli", "Vittorio", ""], ["Murdock", "J. William", ""], ["Florian", "Radu", ""], ["Roukos", "Salim", ""], ["Sil", "Avirup", ""]]}, {"id": "1908.06136", "submitter": "Johannes Bjerva", "authors": "Johannes Bjerva, Katharina Kann and Isabelle Augenstein", "title": "Transductive Auxiliary Task Self-Training for Neural Multi-Task Models", "comments": "Camera ready version, to appear at DeepLo 2019 (EMNLP workshop)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning and self-training are two common ways to improve a\nmachine learning model's performance in settings with limited training data.\nDrawing heavily on ideas from those two approaches, we suggest transductive\nauxiliary task self-training: training a multi-task model on (i) a combination\nof main and auxiliary task training data, and (ii) test instances with\nauxiliary task labels which a single-task version of the model has previously\ngenerated. We perform extensive experiments on 86 combinations of languages and\ntasks. Our results are that, on average, transductive auxiliary task\nself-training improves absolute accuracy by up to 9.56% over the pure\nmulti-task model for dependency relation tagging and by up to 13.03% for\nsemantic tagging.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 19:31:13 GMT"}, {"version": "v2", "created": "Sun, 22 Sep 2019 14:28:15 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Bjerva", "Johannes", ""], ["Kann", "Katharina", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "1908.06138", "submitter": "Santanu Pal", "authors": "Santanu Pal and Marcos Zampieri and Josef van Genabith", "title": "UDS--DFKI Submission to the WMT2019 Similar Language Translation Shared\n  Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the UDS-DFKI system submitted to the Similar\nLanguage Translation shared task at WMT 2019. The first edition of this shared\ntask featured data from three pairs of similar languages: Czech and Polish,\nHindi and Nepali, and Portuguese and Spanish. Participants could choose to\nparticipate in any of these three tracks and submit system outputs in any\ntranslation direction. We report the results obtained by our system in\ntranslating from Czech to Polish and comment on the impact of out-of-domain\ntest data in the performance of our system. UDS-DFKI achieved competitive\nperformance ranking second among ten teams in Czech to Polish translation.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 19:36:57 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Pal", "Santanu", ""], ["Zampieri", "Marcos", ""], ["van Genabith", "Josef", ""]]}, {"id": "1908.06140", "submitter": "Santanu Pal", "authors": "Mihaela Vela, Santanu Pal, Marcos Zampieri, Sudip Kumar Naskar, Josef\n  van Genabith", "title": "Improving CAT Tools in the Translation Workflow: New Approaches and\n  Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes strategies to improve an existing web-based\ncomputer-aided translation (CAT) tool entitled CATaLog Online. CATaLog Online\nprovides a post-editing environment with simple yet helpful project management\ntools. It offers translation suggestions from translation memories (TM),\nmachine translation (MT), and automatic post-editing (APE) and records detailed\nlogs of post-editing activities. To test the new approaches proposed in this\npaper, we carried out a user study on an English--German translation task using\nCATaLog Online. User feedback revealed that the users preferred using CATaLog\nOnline over existing CAT tools in some respects, especially by selecting the\noutput of the MT system and taking advantage of the color scheme for TM\nsuggestions.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 19:38:39 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Vela", "Mihaela", ""], ["Pal", "Santanu", ""], ["Zampieri", "Marcos", ""], ["Naskar", "Sudip Kumar", ""], ["van Genabith", "Josef", ""]]}, {"id": "1908.06151", "submitter": "Santanu Pal", "authors": "Santanu Pal, Hongfei Xu, Nico Herbig, Sudip Kumar Naskar, Antonio\n  Krueger, Josef van Genabith", "title": "The Transference Architecture for Automatic Post-Editing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In automatic post-editing (APE) it makes sense to condition post-editing (pe)\ndecisions on both the source (src) and the machine translated text (mt) as\ninput. This has led to multi-source encoder based APE approaches. A research\nchallenge now is the search for architectures that best support the capture,\npreparation and provision of src and mt information and its integration with pe\ndecisions. In this paper we present a new multi-source APE model, called\ntransference. Unlike previous approaches, it (i) uses a transformer encoder\nblock for src, (ii) followed by a decoder block, but without masking for\nself-attention on mt, which effectively acts as second encoder combining src ->\nmt, and (iii) feeds this representation into a final decoder block generating\npe. Our model outperforms the state-of-the-art by 1 BLEU point on the WMT 2016,\n2017, and 2018 English--German APE shared tasks (PBSMT and NMT). We further\ninvestigate the importance of our newly introduced second encoder and find that\na too small amount of layers does hurt the performance, while reducing the\nnumber of layers of the decoder does not matter much.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 20:09:11 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 15:57:02 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Pal", "Santanu", ""], ["Xu", "Hongfei", ""], ["Herbig", "Nico", ""], ["Naskar", "Sudip Kumar", ""], ["Krueger", "Antonio", ""], ["van Genabith", "Josef", ""]]}, {"id": "1908.06177", "submitter": "Koustuv Sinha", "authors": "Koustuv Sinha, Shagun Sodhani, Jin Dong, Joelle Pineau, William L.\n  Hamilton", "title": "CLUTRR: A Diagnostic Benchmark for Inductive Reasoning from Text", "comments": "Accepted at EMNLP 2019, 9 page content + Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent success of natural language understanding (NLU) systems has been\ntroubled by results highlighting the failure of these models to generalize in a\nsystematic and robust way. In this work, we introduce a diagnostic benchmark\nsuite, named CLUTRR, to clarify some key issues related to the robustness and\nsystematicity of NLU systems. Motivated by classic work on inductive logic\nprogramming, CLUTRR requires that an NLU system infer kinship relations between\ncharacters in short stories. Successful performance on this task requires both\nextracting relationships between entities, as well as inferring the logical\nrules governing these relationships. CLUTRR allows us to precisely measure a\nmodel's ability for systematic generalization by evaluating on held-out\ncombinations of logical rules, and it allows us to evaluate a model's\nrobustness by adding curated noise facts. Our empirical results highlight a\nsubstantial performance gap between state-of-the-art NLU models (e.g., BERT and\nMAC) and a graph neural network model that works directly with symbolic\ninputs---with the graph-based model exhibiting both stronger generalization and\ngreater robustness.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 21:12:15 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 00:14:56 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Sinha", "Koustuv", ""], ["Sodhani", "Shagun", ""], ["Dong", "Jin", ""], ["Pineau", "Joelle", ""], ["Hamilton", "William L.", ""]]}, {"id": "1908.06203", "submitter": "Xiao Zhang", "authors": "Xiao Zhang, Dejing Dou, Ji Wu", "title": "Learning Conceptual-Contextual Embeddings for Medical Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  External knowledge is often useful for natural language understanding tasks.\nWe introduce a contextual text representation model called\nConceptual-Contextual (CC) embeddings, which incorporates structured knowledge\ninto text representations. Unlike entity embedding methods, our approach\nencodes a knowledge graph into a context model. CC embeddings can be easily\nreused for a wide range of tasks just like pre-trained language models. Our\nmodel effectively encodes the huge UMLS database by leveraging semantic\ngeneralizability. Experiments on electronic health records (EHRs) and medical\ntext processing benchmarks showed our model gives a major boost to the\nperformance of supervised medical NLP tasks.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 23:27:25 GMT"}, {"version": "v2", "created": "Sun, 12 Jan 2020 14:24:33 GMT"}, {"version": "v3", "created": "Thu, 12 Mar 2020 02:54:11 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Zhang", "Xiao", ""], ["Dou", "Dejing", ""], ["Wu", "Ji", ""]]}, {"id": "1908.06216", "submitter": "Jingwen Wang", "authors": "Jingwen Wang, Hao Zhang, Cheng Zhang, Wenjing Yang, Liqun Shao, Jie\n  Wang", "title": "Generating an Overview Report over Many Documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to efficiently generate an accurate, well-structured overview report\n(ORPT) over thousands of related documents is challenging. A well-structured\nORPT consists of sections of multiple levels (e.g., sections and subsections).\nNone of the existing multi-document summarization (MDS) algorithms is directed\ntoward this task. To overcome this obstacle, we present NDORGS (Numerous\nDocuments' Overview Report Generation Scheme) that integrates text filtering,\nkeyword scoring, single-document summarization (SDS), topic modeling, MDS, and\ntitle generation to generate a coherent, well-structured ORPT. We then devise a\nmulti-criteria evaluation method using techniques of text mining and\nmulti-attribute decision making on a combination of human judgments, running\ntime, information coverage, and topic diversity. We evaluate ORPTs generated by\nNDORGS on two large corpora of documents, where one is classified and the other\nunclassified. We show that, using Saaty's pairwise comparison 9-point scale and\nunder TOPSIS, the ORPTs generated on SDS's with the length of 20% of the\noriginal documents are the best overall on both datasets.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 01:11:04 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Wang", "Jingwen", ""], ["Zhang", "Hao", ""], ["Zhang", "Cheng", ""], ["Yang", "Wenjing", ""], ["Shao", "Liqun", ""], ["Wang", "Jie", ""]]}, {"id": "1908.06258", "submitter": "Tianyu He", "authors": "Tianyu He, Jiale Chen, Xu Tan, Tao Qin", "title": "Language Graph Distillation for Low-Resource Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation on low-resource language is challenging due to the\nlack of bilingual sentence pairs. Previous works usually solve the low-resource\ntranslation problem with knowledge transfer in a multilingual setting. In this\npaper, we propose the concept of Language Graph and further design a novel\ngraph distillation algorithm that boosts the accuracy of low-resource\ntranslations in the graph with forward and backward knowledge distillation.\nPreliminary experiments on the TED talks multilingual dataset demonstrate the\neffectiveness of our proposed method. Specifically, we improve the low-resource\ntranslation pair by more than 3.13 points in terms of BLEU score.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 08:01:05 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["He", "Tianyu", ""], ["Chen", "Jiale", ""], ["Tan", "Xu", ""], ["Qin", "Tao", ""]]}, {"id": "1908.06259", "submitter": "Tianyu He", "authors": "Tianyu He, Xu Tan, Tao Qin", "title": "Hard but Robust, Easy but Sensitive: How Encoder and Decoder Perform in\n  Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) typically adopts the encoder-decoder\nframework. A good understanding of the characteristics and functionalities of\nthe encoder and decoder can help to explain the pros and cons of the framework,\nand design better models for NMT. In this work, we conduct an empirical study\non the encoder and the decoder in NMT, taking Transformer as an example. We\nfind that 1) the decoder handles an easier task than the encoder in NMT, 2) the\ndecoder is more sensitive to the input noise than the encoder, and 3) the\npreceding words/tokens in the decoder provide strong conditional information,\nwhich accounts for the two observations above. We hope those observations can\nshed light on the characteristics of the encoder and decoder and inspire future\nresearch on NMT.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 08:09:33 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["He", "Tianyu", ""], ["Tan", "Xu", ""], ["Qin", "Tao", ""]]}, {"id": "1908.06263", "submitter": "Yang Liu", "authors": "Yang Liu, Jianpeng Zhang, Chao Gao, Jinghua Qu, Lixin Ji", "title": "A Sensitivity Analysis of Attention-Gated Convolutional Neural Networks\n  for Sentence Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the effect of different hyperparameters as well\nas different combinations of hyperparameters settings on the performance of the\nAttention-Gated Convolutional Neural Networks (AGCNNs), e.g., the kernel window\nsize, the number of feature maps, the keep rate of the dropout layer, and the\nactivation function. We draw practical advice from a wide range of empirical\nresults. Through the sensitivity analysis, we further improve the\nhyperparameters settings of AGCNNs. Experiments show that our proposals could\nachieve an average of 0.81% and 0.67% improvements on AGCNN-NLReLU-rand and\nAGCNN-SELU-rand, respectively; and an average of 0.47% and 0.45% improvements\non AGCNN-NLReLU-static and AGCNN-SELU-static, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 08:40:18 GMT"}, {"version": "v2", "created": "Sun, 25 Aug 2019 02:22:44 GMT"}, {"version": "v3", "created": "Wed, 16 Oct 2019 02:30:43 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Liu", "Yang", ""], ["Zhang", "Jianpeng", ""], ["Gao", "Chao", ""], ["Qu", "Jinghua", ""], ["Ji", "Lixin", ""]]}, {"id": "1908.06264", "submitter": "Yen Hao Huang", "authors": "Yen-Hao Huang, Ssu-Rui Lee, Mau-Yun Ma, Yi-Hsin Chen, Ya-Wen Yu,\n  Yi-Shin Chen", "title": "EmotionX-IDEA: Emotion BERT -- an Affectional Model for Conversation", "comments": "EmotionX 2019, the shared task of SocialNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the emotion recognition ability of the\npre-training language model, namely BERT. By the nature of the framework of\nBERT, a two-sentence structure, we adapt BERT to continues dialogue emotion\nprediction tasks, which rely heavily on the sentence-level context-aware\nunderstanding. The experiments show that by mapping the continues dialogue into\na causal utterance pair, which is constructed by the utterance and the reply\nutterance, models can better capture the emotions of the reply utterance. The\npresent method has achieved 0.815 and 0.885 micro F1 score in the testing\ndataset of Friends and EmotionPush, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 08:59:51 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Huang", "Yen-Hao", ""], ["Lee", "Ssu-Rui", ""], ["Ma", "Mau-Yun", ""], ["Chen", "Yi-Hsin", ""], ["Yu", "Ya-Wen", ""], ["Chen", "Yi-Shin", ""]]}, {"id": "1908.06267", "submitter": "Giannis Nikolentzos", "authors": "Giannis Nikolentzos, Antoine J.-P. Tixier, Michalis Vazirgiannis", "title": "Message Passing Attention Networks for Document Understanding", "comments": "Accepted at AAAI'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks have recently emerged as a very effective framework for\nprocessing graph-structured data. These models have achieved state-of-the-art\nperformance in many tasks. Most graph neural networks can be described in terms\nof message passing, vertex update, and readout functions. In this paper, we\nrepresent documents as word co-occurrence networks and propose an application\nof the message passing framework to NLP, the Message Passing Attention network\nfor Document understanding (MPAD). We also propose several hierarchical\nvariants of MPAD. Experiments conducted on 10 standard text classification\ndatasets show that our architectures are competitive with the state-of-the-art.\nAblation studies reveal further insights about the impact of the different\ncomponents on performance. Code is publicly available at:\nhttps://github.com/giannisnik/mpad .\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 09:18:47 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 09:35:04 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Nikolentzos", "Giannis", ""], ["Tixier", "Antoine J. -P.", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "1908.06288", "submitter": "Sebastian Borgeaud", "authors": "Sebastian Borgeaud and Guy Emerson", "title": "Leveraging Sentence Similarity in Natural Language Generation: Improving\n  Beam Search using Range Voting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for natural language generation, choosing the most\nrepresentative output rather than the most likely output. By viewing the\nlanguage generation process from the voting theory perspective, we define\nrepresentativeness using range voting and a similarity measure. The proposed\nmethod can be applied when generating from any probabilistic language model,\nincluding n-gram models and neural network models. We evaluate different\nsimilarity measures on an image captioning task and a machine translation task,\nand show that our method generates longer and more diverse sentences, providing\na solution to the common problem of short outputs being preferred over longer\nand more informative ones. The generated sentences obtain higher BLEU scores,\nparticularly when the beam size is large. We also perform a human evaluation on\nboth tasks and find that the outputs generated using our method are rated\nhigher.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 10:36:43 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 21:25:50 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Borgeaud", "Sebastian", ""], ["Emerson", "Guy", ""]]}, {"id": "1908.06306", "submitter": "Badri Narayana Patro", "authors": "Badri N. Patro, Mayank Lunayach, Shivansh Patel and Vinay P.\n  Namboodiri", "title": "U-CAM: Visual Explanation using Uncertainty based Class Activation Maps", "comments": "ICCV 2019 (accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Understanding and explaining deep learning models is an imperative task.\nTowards this, we propose a method that obtains gradient-based certainty\nestimates that also provide visual attention maps. Particularly, we solve for\nvisual question answering task. We incorporate modern probabilistic deep\nlearning methods that we further improve by using the gradients for these\nestimates. These have two-fold benefits: a) improvement in obtaining the\ncertainty estimates that correlate better with misclassified samples and b)\nimproved attention maps that provide state-of-the-art results in terms of\ncorrelation with human attention regions. The improved attention maps result in\nconsistent improvement for various methods for visual question answering.\nTherefore, the proposed technique can be thought of as a recipe for obtaining\nimproved certainty estimates and explanation for deep learning models. We\nprovide detailed empirical analysis for the visual question answering task on\nall standard benchmarks and comparison with state of the art methods.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 14:39:36 GMT"}, {"version": "v2", "created": "Sun, 25 Aug 2019 19:07:15 GMT"}, {"version": "v3", "created": "Mon, 16 Sep 2019 15:04:57 GMT"}, {"version": "v4", "created": "Thu, 17 Oct 2019 07:20:32 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Patro", "Badri N.", ""], ["Lunayach", "Mayank", ""], ["Patel", "Shivansh", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "1908.06327", "submitter": "Andrea Burns", "authors": "Andrea Burns, Reuben Tan, Kate Saenko, Stan Sclaroff, Bryan A. Plummer", "title": "Language Features Matter: Effective Language Representations for\n  Vision-Language Tasks", "comments": "ICCV 2019 accepted paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shouldn't language and vision features be treated equally in vision-language\n(VL) tasks? Many VL approaches treat the language component as an afterthought,\nusing simple language models that are either built upon fixed word embeddings\ntrained on text-only data or are learned from scratch. We believe that language\nfeatures deserve more attention, and conduct experiments which compare\ndifferent word embeddings, language models, and embedding augmentation steps on\nfive common VL tasks: image-sentence retrieval, image captioning, visual\nquestion answering, phrase grounding, and text-to-clip retrieval. Our\nexperiments provide some striking results; an average embedding language model\noutperforms an LSTM on retrieval-style tasks; state-of-the-art representations\nsuch as BERT perform relatively poorly on vision-language tasks. From this\ncomprehensive set of experiments we propose a set of best practices for\nincorporating the language component of VL tasks. To further elevate language\nfeatures, we also show that knowledge in vision-language problems can be\ntransferred across tasks to gain performance with multi-task training. This\nmulti-task training is applied to a new Graph Oriented Vision-Language\nEmbedding (GrOVLE), which we adapt from Word2Vec using WordNet and an original\nvisual-language graph built from Visual Genome, providing a ready-to-use\nvision-language embedding: http://ai.bu.edu/grovle.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 18:01:27 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Burns", "Andrea", ""], ["Tan", "Reuben", ""], ["Saenko", "Kate", ""], ["Sclaroff", "Stan", ""], ["Plummer", "Bryan A.", ""]]}, {"id": "1908.06336", "submitter": "Alexander Kuhnle", "authors": "Alexander Kuhnle, Ann Copestake", "title": "What is needed for simple spatial language capabilities in VQA?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual question answering (VQA) comprises a variety of language capabilities.\nThe diagnostic benchmark dataset CLEVR has fueled progress by helping to better\nassess and distinguish models in basic abilities like counting, comparing and\nspatial reasoning in vitro. Following this approach, we focus on spatial\nlanguage capabilities and investigate the question: what are the key\ningredients to handle simple visual-spatial relations? We look at the SAN,\nRelNet, FiLM and MC models and evaluate their learning behavior on diagnostic\ndata which is solely focused on spatial relations. Via comparative analysis and\ntargeted model modification we identify what really is required to\nsubstantially improve upon the CNN-LSTM baseline.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 20:12:39 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 19:03:21 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Kuhnle", "Alexander", ""], ["Copestake", "Ann", ""]]}, {"id": "1908.06361", "submitter": "Kawin Ethayarajh", "authors": "Kawin Ethayarajh, David Duvenaud, and Graeme Hirst", "title": "Understanding Undesirable Word Embedding Associations", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are often criticized for capturing undesirable word\nassociations such as gender stereotypes. However, methods for measuring and\nremoving such biases remain poorly understood. We show that for any embedding\nmodel that implicitly does matrix factorization, debiasing vectors post hoc\nusing subspace projection (Bolukbasi et al., 2016) is, under certain\nconditions, equivalent to training on an unbiased corpus. We also prove that\nWEAT, the most common association test for word embeddings, systematically\noverestimates bias. Given that the subspace projection method is provably\neffective, we use it to derive a new measure of association called the\n$\\textit{relational inner product association}$ (RIPA). Experiments with RIPA\nreveal that, on average, skipgram with negative sampling (SGNS) does not make\nmost words any more gendered than they are in the training corpus. However, for\ngender-stereotyped words, SGNS actually amplifies the gender association in the\ncorpus.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 01:28:45 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Ethayarajh", "Kawin", ""], ["Duvenaud", "David", ""], ["Hirst", "Graeme", ""]]}, {"id": "1908.06379", "submitter": "Junru Zhou", "authors": "Junru Zhou, Shuailiang Zhang, Hai Zhao", "title": "Concurrent Parsing of Constituency and Dependency", "comments": "arXiv admin note: text overlap with arXiv:1907.02684", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constituent and dependency representation for syntactic structure share a lot\nof linguistic and computational characteristics, this paper thus makes the\nfirst attempt by introducing a new model that is capable of parsing constituent\nand dependency at the same time, so that lets either of the parsers enhance\neach other. Especially, we evaluate the effect of different shared network\ncomponents and empirically verify that dependency parsing may be much more\nbeneficial from constituent parsing structure.\n  The proposed parser achieves new state-of-the-art performance for both\nparsing tasks, constituent and dependency on PTB and CTB benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 05:10:59 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 03:54:49 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Zhou", "Junru", ""], ["Zhang", "Shuailiang", ""], ["Zhao", "Hai", ""]]}, {"id": "1908.06435", "submitter": "Gabriele Pergola", "authors": "Gabriele Pergola, Lin Gui, Yulan He", "title": "TDAM: a Topic-Dependent Attention Model for Sentiment Analysis", "comments": null, "journal-ref": "Information Processing & Management, 56 (6), 102084, July 2019", "doi": "10.1016/j.ipm.2019.102084", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a topic-dependent attention model for sentiment classification and\ntopic extraction. Our model assumes that a global topic embedding is shared\nacross documents and employs an attention mechanism to derive local topic\nembedding for words and sentences. These are subsequently incorporated in a\nmodified Gated Recurrent Unit (GRU) for sentiment classification and extraction\nof topics bearing different sentiment polarities. Those topics emerge from the\nwords' local topic embeddings learned by the internal attention of the GRU\ncells in the context of a multi-task learning framework. In this paper, we\npresent the hierarchical architecture, the new GRU unit and the experiments\nconducted on users' reviews which demonstrate classification performance on a\npar with the state-of-the-art methodologies for sentiment classification and\ntopic coherence outperforming the current approaches for supervised topic\nextraction. In addition, our model is able to extract coherent aspect-sentiment\nclusters despite using no aspect-level annotations for training.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 12:50:47 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Pergola", "Gabriele", ""], ["Gui", "Lin", ""], ["He", "Yulan", ""]]}, {"id": "1908.06449", "submitter": "Chuan Meng", "authors": "Chuan Meng, Pengjie Ren, Zhumin Chen, Christof Monz, Jun Ma, Maarten\n  de Rijke", "title": "RefNet: A Reference-aware Network for Background Based Conversation", "comments": "Accepted to AAAI 2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing conversational systems tend to generate generic responses. Recently,\nBackground Based Conversations (BBCs) have been introduced to address this\nissue. Here, the generated responses are grounded in some background\ninformation. The proposed methods for BBCs are able to generate more\ninformative responses, they either cannot generate natural responses or have\ndifficulty in locating the right background information. In this paper, we\npropose a Reference-aware Network (RefNet) to address the two issues. Unlike\nexisting methods that generate responses token by token, RefNet incorporates a\nnovel reference decoder that provides an alternative way to learn to directly\ncite a semantic unit (e.g., a span containing complete semantic information)\nfrom the background. Experimental results show that RefNet significantly\noutperforms state-of-the-art methods in terms of both automatic and human\nevaluations, indicating that RefNet can generate more appropriate and\nhuman-like responses.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 14:49:16 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 07:56:45 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Meng", "Chuan", ""], ["Ren", "Pengjie", ""], ["Chen", "Zhumin", ""], ["Monz", "Christof", ""], ["Ma", "Jun", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1908.06493", "submitter": "Fernando Benites De Azevedo E Souza", "authors": "Fernando Benites", "title": "TwistBytes -- Hierarchical Classification at GermEval 2019: walking the\n  fine line (of recall and precision)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present here our approach to the GermEval 2019 Task 1 - Shared Task on\nhierarchical classification of German blurbs. We achieved first place in the\nhierarchical subtask B and second place on the root node, flat classification\nsubtask A. In subtask A, we applied a simple multi-feature TF-IDF extraction\nmethod using different n-gram range and stopword removal, on each feature\nextraction module. The classifier on top was a standard linear SVM. For the\nhierarchical classification, we used a local approach, which was more\nlight-weighted but was similar to the one used in subtask A. The key point of\nour approach was the application of a post-processing to cope with the\nmulti-label aspect of the task, increasing the recall but not surpassing the\nprecision measure score.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 18:09:19 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Benites", "Fernando", ""]]}, {"id": "1908.06520", "submitter": "Ugur Kursuncu", "authors": "Ugur Kursuncu, Manas Gaur, Carlos Castillo, Amanuel Alambo, K.\n  Thirunarayan, Valerie Shalin, Dilshod Achilov, I. Budak Arpinar, Amit Sheth", "title": "Modeling Islamist Extremist Communications on Social Media using\n  Contextual Dimensions: Religion, Ideology, and Hate", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Terror attacks have been linked in part to online extremist content. Although\ntens of thousands of Islamist extremism supporters consume such content, they\nare a small fraction relative to peaceful Muslims. The efforts to contain the\never-evolving extremism on social media platforms have remained inadequate and\nmostly ineffective. Divergent extremist and mainstream contexts challenge\nmachine interpretation, with a particular threat to the precision of\nclassification algorithms. Our context-aware computational approach to the\nanalysis of extremist content on Twitter breaks down this persuasion process\ninto building blocks that acknowledge inherent ambiguity and sparsity that\nlikely challenge both manual and automated classification. We model this\nprocess using a combination of three contextual dimensions -- religion,\nideology, and hate -- each elucidating a degree of radicalization and\nhighlighting independent features to render them computationally accessible. We\nutilize domain-specific knowledge resources for each of these contextual\ndimensions such as Qur'an for religion, the books of extremist ideologues and\npreachers for political ideology and a social media hate speech corpus for\nhate. Our study makes three contributions to reliable analysis: (i) Development\nof a computational approach rooted in the contextual dimensions of religion,\nideology, and hate that reflects strategies employed by online Islamist\nextremist groups, (ii) An in-depth analysis of relevant tweet datasets with\nrespect to these dimensions to exclude likely mislabeled users, and (iii) A\nframework for understanding online radicalization as a process to assist\ncounter-programming. Given the potentially significant social impact, we\nevaluate the performance of our algorithms to minimize mislabeling, where our\napproach outperforms a competitive baseline by 10.2% in precision.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 21:46:19 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 21:28:01 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 22:31:08 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Kursuncu", "Ugur", ""], ["Gaur", "Manas", ""], ["Castillo", "Carlos", ""], ["Alambo", "Amanuel", ""], ["Thirunarayan", "K.", ""], ["Shalin", "Valerie", ""], ["Achilov", "Dilshod", ""], ["Arpinar", "I. Budak", ""], ["Sheth", "Amit", ""]]}, {"id": "1908.06556", "submitter": "Prithviraj Ammanabrolu", "authors": "Prithviraj Ammanabrolu and Mark O. Riedl", "title": "Transfer in Deep Reinforcement Learning using Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text adventure games, in which players must make sense of the world through\ntext descriptions and declare actions through text descriptions, provide a\nstepping stone toward grounding action in language. Prior work has demonstrated\nthat using a knowledge graph as a state representation and question-answering\nto pre-train a deep Q-network facilitates faster control policy transfer. In\nthis paper, we explore the use of knowledge graphs as a representation for\ndomain knowledge transfer for training text-adventure playing reinforcement\nlearning agents. Our methods are tested across multiple computer generated and\nhuman authored games, varying in domain and complexity, and demonstrate that\nour transfer learning methods let us learn a higher-quality control policy\nfaster.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 01:52:00 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Ammanabrolu", "Prithviraj", ""], ["Riedl", "Mark O.", ""]]}, {"id": "1908.06559", "submitter": "Liang Ding", "authors": "Liang Ding, Dacheng Tao", "title": "Recurrent Graph Syntax Encoder for Neural Machine Translation", "comments": "Work in Progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syntax-incorporated machine translation models have been proven successful in\nimproving the model's reasoning and meaning preservation ability. In this\npaper, we propose a simple yet effective graph-structured encoder, the\nRecurrent Graph Syntax Encoder, dubbed \\textbf{RGSE}, which enhances the\nability to capture useful syntactic information. The RGSE is done over a\nstandard encoder (recurrent or self-attention encoder), regarding recurrent\nnetwork units as graph nodes and injects syntactic dependencies as edges, such\nthat RGSE models syntactic dependencies and sequential information\n(\\textit{i.e.}, word order) simultaneously. Our approach achieves considerable\nimprovements over several syntax-aware NMT models in English$\\Rightarrow$German\nand English$\\Rightarrow$Czech translation tasks. And RGSE-equipped big model\nobtains competitive result compared with the state-of-the-art model in WMT14\nEn-De task. Extensive analysis further verifies that RGSE could benefit long\nsentence modeling, and produces better translations.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 02:10:39 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Ding", "Liang", ""], ["Tao", "Dacheng", ""]]}, {"id": "1908.06576", "submitter": "Xiangyang He", "authors": "Xiangyang He, Yubo Tao, Qirui Wang, Hai Lin", "title": "A Co-analysis Framework for Exploring Multivariate Scientific Data", "comments": "31 pages, 7 figures", "journal-ref": "Visual Informatics Volume 2, Issue 4, December 2018, Pages 254-263", "doi": "10.1016/j.visinf.2018.12.005", "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In complex multivariate data sets, different features usually include diverse\nassociations with different variables, and different variables are associated\nwithin different regions. Therefore, exploring the associations between\nvariables and voxels locally becomes necessary to better understand the\nunderlying phenomena. In this paper, we propose a co-analysis framework based\non biclusters, which are two subsets of variables and voxels with close\nscalar-value relationships, to guide the process of visually exploring\nmultivariate data. We first automatically extract all meaningful biclusters,\neach of which only contains voxels with a similar scalar-value pattern over a\nsubset of variables. These biclusters are organized according to their variable\nsets, and biclusters in each variable set are further grouped by a similarity\nmetric to reduce redundancy and support diversity during visual exploration.\nBiclusters are visually represented in coordinated views to facilitate\ninteractive exploration of multivariate data based on the similarity between\nbiclusters and the correlation of scalar values with different variables.\nExperiments on several representative multivariate scientific data sets\ndemonstrate the effectiveness of our framework in exploring local relationships\namong variables, biclusters and scalar values in the data.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 03:31:48 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["He", "Xiangyang", ""], ["Tao", "Yubo", ""], ["Wang", "Qirui", ""], ["Lin", "Hai", ""]]}, {"id": "1908.06601", "submitter": "Mike Ji", "authors": "Mike H. Ji", "title": "Implicit Recursive Characteristics of STOP", "comments": "5 pages. A proof that STOP itself is a recursive process.\n  STOP$_{\\alpha X} = \\mu$ X. nil $\\rightarrow$ X", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CL cs.FL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most important notations of Communicating Sequential Process(CSP) are the\nprocess and the prefix (event)$\\rightarrow$(process) operator. While we can\nformally apply the $\\rightarrow$ operator to define a live process's behavior,\nthe STOP process, which usually resulted from deadlock, starving or livelock,\nis lack of formal description, defined by most literatures as \"doing nothing\nbut halt\". In this paper, we argue that the STOP process should not be\nconsidered as a black box, it should follow the prefix $\\rightarrow$ schema and\nthe same inference rules so that a unified and consistent process algebra model\ncan be established. In order to achieve this goal, we introduce a special event\ncalled \"nil\" that any process can take. This nil event will do nothing\nmeaningful and leave nothing on a process's observable record. With the nil\nevent and its well-defined rules, we can successfully use the $\\rightarrow$\noperator to formally describe a process's complete behavior in its whole life\ncircle. More interestingly, we can use prefix $\\rightarrow$ and nil event to\nfully describe the STOP process's internal behavior and conclude that the\nSTOP's formal equation can be given as simple as STOP$_{\\alpha X} = \\mu$ X. nil\n$\\rightarrow$ X.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 05:43:13 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 03:22:01 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Ji", "Mike H.", ""]]}, {"id": "1908.06605", "submitter": "Zhihong Shao", "authors": "Zhihong Shao, Minlie Huang, Jiangtao Wen, Wenfei Xu, Xiaoyan Zhu", "title": "Long and Diverse Text Generation with Planning-based Hierarchical\n  Variational Model", "comments": "To appear in EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing neural methods for data-to-text generation are still struggling to\nproduce long and diverse texts: they are insufficient to model input data\ndynamically during generation, to capture inter-sentence coherence, or to\ngenerate diversified expressions. To address these issues, we propose a\nPlanning-based Hierarchical Variational Model (PHVM). Our model first plans a\nsequence of groups (each group is a subset of input items to be covered by a\nsentence) and then realizes each sentence conditioned on the planning result\nand the previously generated context, thereby decomposing long text generation\ninto dependent sentence generation sub-tasks. To capture expression diversity,\nwe devise a hierarchical latent structure where a global planning latent\nvariable models the diversity of reasonable planning and a sequence of local\nlatent variables controls sentence realization. Experiments show that our model\noutperforms state-of-the-art baselines in long and diverse text generation.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 06:20:38 GMT"}, {"version": "v2", "created": "Sun, 25 Aug 2019 01:57:50 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Shao", "Zhihong", ""], ["Huang", "Minlie", ""], ["Wen", "Jiangtao", ""], ["Xu", "Wenfei", ""], ["Zhu", "Xiaoyan", ""]]}, {"id": "1908.06606", "submitter": "Jiahui Qiu", "authors": "Jiahui Qiu, Yangming Zhou, Zhiyuan Ma, Tong Ruan, Jinlin Liu, Jing Sun", "title": "Question Answering based Clinical Text Structuring Using Pre-trained\n  Language Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical text structuring is a critical and fundamental task for clinical\nresearch. Traditional methods such as taskspecific end-to-end models and\npipeline models usually suffer from the lack of dataset and error propagation.\nIn this paper, we present a question answering based clinical text structuring\n(QA-CTS) task to unify different specific tasks and make dataset shareable. A\nnovel model that aims to introduce domain-specific features (e.g., clinical\nnamed entity information) into pre-trained language model is also proposed for\nQA-CTS task. Experimental results on Chinese pathology reports collected from\nRuijing Hospital demonstrate our presented QA-CTS task is very effective to\nimprove the performance on specific tasks. Our proposed model also competes\nfavorably with strong baseline models in specific tasks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 06:21:29 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 12:09:15 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Qiu", "Jiahui", ""], ["Zhou", "Yangming", ""], ["Ma", "Zhiyuan", ""], ["Ruan", "Tong", ""], ["Liu", "Jinlin", ""], ["Sun", "Jing", ""]]}, {"id": "1908.06625", "submitter": "Joel Ruben Antony Moniz", "authors": "Barun Patra, Joel Ruben Antony Moniz, Sarthak Garg, Matthew R.\n  Gormley, Graham Neubig", "title": "Bilingual Lexicon Induction with Semi-supervision in Non-Isometric\n  Embedding Spaces", "comments": "ACL 2019", "journal-ref": "Proceedings of the 57th Conference of the Association for\n  Computational Linguistics (2019) 184-193", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on bilingual lexicon induction (BLI) has frequently depended\neither on aligned bilingual lexicons or on distribution matching, often with an\nassumption about the isometry of the two spaces. We propose a technique to\nquantitatively estimate this assumption of the isometry between two embedding\nspaces and empirically show that this assumption weakens as the languages in\nquestion become increasingly etymologically distant. We then propose Bilingual\nLexicon Induction with Semi-Supervision (BLISS) --- a semi-supervised approach\nthat relaxes the isometric assumption while leveraging both limited aligned\nbilingual lexicons and a larger set of unaligned word embeddings, as well as a\nnovel hubness filtering technique. Our proposed method obtains state of the art\nresults on 15 of 18 language pairs on the MUSE dataset, and does particularly\nwell when the embedding spaces don't appear to be isometric. In addition, we\nalso show that adding supervision stabilizes the learning procedure, and is\neffective even with minimal supervision.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 07:36:19 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Patra", "Barun", ""], ["Moniz", "Joel Ruben Antony", ""], ["Garg", "Sarthak", ""], ["Gormley", "Matthew R.", ""], ["Neubig", "Graham", ""]]}, {"id": "1908.06629", "submitter": "Ramon Ferrer i Cancho", "authors": "Carlos G\\'omez-Rodr\\'iguez, Morten H. Christiansen and Ramon\n  Ferrer-i-Cancho", "title": "Memory limitations are hidden in grammar", "comments": "Version improved with reviewer feedback", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to produce and understand an unlimited number of different\nsentences is a hallmark of human language. Linguists have sought to define the\nessence of this generative capacity using formal grammars that describe the\nsyntactic dependencies between constituents, independent of the computational\nlimitations of the human brain. Here, we evaluate this independence assumption\nby sampling sentences uniformly from the space of possible syntactic\nstructures. We find that the average dependency distance between syntactically\nrelated words, a proxy for memory limitations, is less than expected by chance\nin a collection of state-of-the-art classes of dependency grammars. Our\nfindings indicate that memory limitations have permeated grammatical\ndescriptions, suggesting that it may be impossible to build a parsimonious\ntheory of human linguistic productivity independent of non-linguistic cognitive\nconstraints.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 07:56:46 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 18:40:31 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["G\u00f3mez-Rodr\u00edguez", "Carlos", ""], ["Christiansen", "Morten H.", ""], ["Ferrer-i-Cancho", "Ramon", ""]]}, {"id": "1908.06709", "submitter": "Michael Gref", "authors": "Michael Gref, Christoph Schmidt, Sven Behnke, Joachim K\\\"ohler", "title": "Two-Staged Acoustic Modeling Adaption for Robust Speech Recognition by\n  the Example of German Oral History Interviews", "comments": "Accepted for IEEE International Conference on Multimedia and Expo\n  (ICME), Shanghai, China, July 2019", "journal-ref": "IEEE International Conference on Multimedia and Expo (ICME),\n  Shanghai, China, July 2019", "doi": "10.1109/ICME.2019.00142", "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In automatic speech recognition, often little training data is available for\nspecific challenging tasks, but training of state-of-the-art automatic speech\nrecognition systems requires large amounts of annotated speech. To address this\nissue, we propose a two-staged approach to acoustic modeling that combines\nnoise and reverberation data augmentation with transfer learning to robustly\naddress challenges such as difficult acoustic recording conditions, spontaneous\nspeech, and speech of elderly people. We evaluate our approach using the\nexample of German oral history interviews, where a relative average reduction\nof the word error rate by 19.3% is achieved.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 11:45:11 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Gref", "Michael", ""], ["Schmidt", "Christoph", ""], ["Behnke", "Sven", ""], ["K\u00f6hler", "Joachim", ""]]}, {"id": "1908.06725", "submitter": "Zhi-Xiu Ye", "authors": "Zhi-Xiu Ye, Qian Chen, Wen Wang, Zhen-Hua Ling", "title": "Align, Mask and Select: A Simple Method for Incorporating Commonsense\n  Knowledge into Language Representation Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-the-art pre-trained language representation models, such as\nBidirectional Encoder Representations from Transformers (BERT), rarely\nincorporate commonsense knowledge or other knowledge explicitly. We propose a\npre-training approach for incorporating commonsense knowledge into language\nrepresentation models. We construct a commonsense-related multi-choice question\nanswering dataset for pre-training a neural language representation model. The\ndataset is created automatically by our proposed \"align, mask, and select\"\n(AMS) method. We also investigate different pre-training tasks. Experimental\nresults demonstrate that pre-training models using the proposed approach\nfollowed by fine-tuning achieve significant improvements over previous\nstate-of-the-art models on two commonsense-related benchmarks, including\nCommonsenseQA and Winograd Schema Challenge. We also observe that fine-tuned\nmodels after the proposed pre-training approach maintain comparable performance\non other NLP tasks, such as sentence classification and natural language\ninference tasks, compared to the original BERT models. These results verify\nthat the proposed approach, while significantly improving commonsense-related\nNLP tasks, does not degrade the general language representation capabilities.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 12:08:27 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 03:12:33 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2019 06:14:47 GMT"}, {"version": "v4", "created": "Tue, 12 Nov 2019 03:25:38 GMT"}, {"version": "v5", "created": "Wed, 6 May 2020 08:57:26 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Ye", "Zhi-Xiu", ""], ["Chen", "Qian", ""], ["Wang", "Wen", ""], ["Ling", "Zhen-Hua", ""]]}, {"id": "1908.06738", "submitter": "Muhammad Khalifa", "authors": "Muhammad Khalifa", "title": "Semantic Source Code Search: A Study of the Past and a Glimpse at the\n  Future", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent explosion in the size and complexity of source codebases and\nsoftware projects, the need for efficient source code search engines has\nincreased dramatically. Unfortunately, existing information retrieval-based\nmethods fail to capture the query semantics and perform well only when the\nquery contains syntax-based keywords. Consequently, such methods will perform\npoorly when given high-level natural language queries. In this paper, we review\nexisting methods for building code search engines. We also outline the open\nresearch directions and the various obstacles that stand in the way of having a\nuniversal source code search engine.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 12:50:51 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Khalifa", "Muhammad", ""]]}, {"id": "1908.06748", "submitter": "Zhiming Li", "authors": "Zhiming Li, Qing Wu and Kun Qian", "title": "Adabot: Fault-Tolerant Java Decompiler", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reverse Engineering(RE) has been a fundamental task in software engineering.\nHowever, most of the traditional Java reverse engineering tools are strictly\nrule defined, thus are not fault-tolerant, which pose serious problem when\nnoise and interference were introduced into the system. In this paper, we view\nreverse engineering as a statistical machine translation task instead of\nrule-based task, and propose a fault-tolerant Java decompiler based on machine\ntranslation models. Our model is based on attention-based Neural Machine\nTranslation (NMT) and Transformer architectures. First, we measure the\ntranslation quality on both the redundant and purified datasets. Next, we\nevaluate the fault-tolerance(anti-noise ability) of our framework on test sets\nwith different unit error probability (UEP). In addition, we compare the\nsuitability of different word segmentation algorithms for decompilation task.\nExperimental results demonstrate that our model is more robust and\nfault-tolerant compared to traditional Abstract Syntax Tree (AST) based\ndecompilers. Specifically, in terms of BLEU-4 and Word Error Rate (WER), our\nperformance has reached 94.50% and 2.65% on the redundant test set; 92.30% and\n3.48% on the purified test set.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 05:17:04 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 15:23:09 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Li", "Zhiming", ""], ["Wu", "Qing", ""], ["Qian", "Kun", ""]]}, {"id": "1908.06780", "submitter": "Yosi Mass", "authors": "Yosi Mass, Haggai Roitman, Shai Erera, Or Rivlin, Bar Weiner and David\n  Konopnicki", "title": "A Study of BERT for Non-Factoid Question-Answering under Passage Length\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the use of BERT for non-factoid question-answering, focusing on the\npassage re-ranking task under varying passage lengths. To this end, we explore\nthe fine-tuning of BERT in different learning-to-rank setups, comprising both\npoint-wise and pair-wise methods, resulting in substantial improvements over\nthe state-of-the-art. We then analyze the effectiveness of BERT for different\npassage lengths and suggest how to cope with large passages.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 13:14:02 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Mass", "Yosi", ""], ["Roitman", "Haggai", ""], ["Erera", "Shai", ""], ["Rivlin", "Or", ""], ["Weiner", "Bar", ""], ["Konopnicki", "David", ""]]}, {"id": "1908.06785", "submitter": "Yosi Mass", "authors": "Ilya Shnayderman, Liat Ein-Dor, Yosi Mass, Alon Halfon, Benjamin\n  Sznajder, Artem Spector, Yoav Katz, Dafna Sheinwald, Ranit Aharonov, Noam\n  Slonim", "title": "Fast End-to-End Wikification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wikification of large corpora is beneficial for various NLP applications.\nExisting methods focus on quality performance rather than run-time, and are\ntherefore non-feasible for large data. Here, we introduce RedW, a run-time\noriented Wikification solution, based on Wikipedia redirects, that can Wikify\nmassive corpora with competitive performance. We further propose an efficient\nmethod for estimating RedW confidence, opening the door for applying more\ndemanding methods only on top of RedW lower-confidence results. Our\nexperimental results support the validity of the proposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 13:21:10 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Shnayderman", "Ilya", ""], ["Ein-Dor", "Liat", ""], ["Mass", "Yosi", ""], ["Halfon", "Alon", ""], ["Sznajder", "Benjamin", ""], ["Spector", "Artem", ""], ["Katz", "Yoav", ""], ["Sheinwald", "Dafna", ""], ["Aharonov", "Ranit", ""], ["Slonim", "Noam", ""]]}, {"id": "1908.06809", "submitter": "Ivan P Yamshchikov", "authors": "Alexey Tikhonov, Viacheslav Shibaev, Aleksander Nagaev, Aigul\n  Nugmanova, Ivan P. Yamshchikov", "title": "Style Transfer for Texts: Retrain, Report Errors, Compare with Rewrites", "comments": null, "journal-ref": null, "doi": "10.18653/v1/D19-1406", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that standard assessment methodology for style transfer has\nseveral significant problems. First, the standard metrics for style accuracy\nand semantics preservation vary significantly on different re-runs. Therefore\none has to report error margins for the obtained results. Second, starting with\ncertain values of bilingual evaluation understudy (BLEU) between input and\noutput and accuracy of the sentiment transfer the optimization of these two\nstandard metrics diverge from the intuitive goal of the style transfer task.\nFinally, due to the nature of the task itself, there is a specific dependence\nbetween these two metrics that could be easily manipulated. Under these\ncircumstances, we suggest taking BLEU between input and human-written\nreformulations into consideration for benchmarks. We also propose three new\narchitectures that outperform state of the art in terms of this metric.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 14:01:18 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 20:16:09 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Tikhonov", "Alexey", ""], ["Shibaev", "Viacheslav", ""], ["Nagaev", "Aleksander", ""], ["Nugmanova", "Aigul", ""], ["Yamshchikov", "Ivan P.", ""]]}, {"id": "1908.06820", "submitter": "Weikang Wang", "authors": "Weikang Wang, Jiajun Zhang, Qian Li, Chengqing Zong and Zhifei Li", "title": "Are You for Real? Detecting Identity Fraud via Dialogue Interactions", "comments": "EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identity fraud detection is of great importance in many real-world scenarios\nsuch as the financial industry. However, few studies addressed this problem\nbefore. In this paper, we focus on identity fraud detection in loan\napplications and propose to solve this problem with a novel interactive\ndialogue system which consists of two modules. One is the knowledge graph (KG)\nconstructor organizing the personal information for each loan applicant. The\nother is structured dialogue management that can dynamically generate a series\nof questions based on the personal KG to ask the applicants and determine their\nidentity states. We also present a heuristic user simulator based on problem\nanalysis to evaluate our method. Experiments have shown that the trainable\ndialogue system can effectively detect fraudsters, and achieve higher\nrecognition accuracy compared with rule-based systems. Furthermore, our learned\ndialogue strategies are interpretable and flexible, which can help promote\nreal-world applications.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 14:13:24 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Wang", "Weikang", ""], ["Zhang", "Jiajun", ""], ["Li", "Qian", ""], ["Zong", "Chengqing", ""], ["Li", "Zhifei", ""]]}, {"id": "1908.06870", "submitter": "Ruiqi Zhong", "authors": "Ruiqi Zhong, Steven Shao, Kathleen McKeown", "title": "Fine-grained Sentiment Analysis with Faithful Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the general task of textual sentiment classification has been widely\nstudied, much less research looks specifically at sentiment between a specified\nsource and target. To tackle this problem, we experimented with a\nstate-of-the-art relation extraction model. Surprisingly, we found that despite\nreasonable performance, the model's attention was often systematically\nmisaligned with the words that contribute to sentiment. Thus, we directly\ntrained the model's attention with human rationales and improved our model\nperformance by a robust 4~8 points on all tasks we defined on our data sets. We\nalso present a rigorous analysis of the model's attention, both trained and\nuntrained, using novel and intuitive metrics. Our results show that untrained\nattention does not provide faithful explanations; however, trained attention\nwith concisely annotated human rationales not only increases performance, but\nalso brings faithful explanations. Encouragingly, a small amount of annotated\nhuman rationales suffice to correct the attention in our task.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 15:11:27 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Zhong", "Ruiqi", ""], ["Shao", "Steven", ""], ["McKeown", "Kathleen", ""]]}, {"id": "1908.06893", "submitter": "Avisha Das", "authors": "Avisha Das and Rakesh Verma", "title": "Automated email Generation for Targeted Attacks using Natural Language", "comments": "8 pages, Workshop on Text Analytics for Cybersecurity and Online\n  Safety 2018 (Co-located with Language Resources and Evaluation Conference\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With an increasing number of malicious attacks, the number of people and\norganizations falling prey to social engineering attacks is proliferating.\nDespite considerable research in mitigation systems, attackers continually\nimprove their modus operandi by using sophisticated machine learning, natural\nlanguage processing techniques with an intent to launch successful targeted\nattacks aimed at deceiving detection mechanisms as well as the victims. We\npropose a system for advanced email masquerading attacks using Natural Language\nGeneration (NLG) techniques. Using legitimate as well as an influx of varying\nmalicious content, the proposed deep learning system generates \\textit{fake}\nemails with malicious content, customized depending on the attacker's intent.\nThe system leverages Recurrent Neural Networks (RNNs) for automated text\ngeneration. We also focus on the performance of the generated emails in\ndefeating statistical detectors, and compare and analyze the emails using a\nproposed baseline.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 15:52:36 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Das", "Avisha", ""], ["Verma", "Rakesh", ""]]}, {"id": "1908.06917", "submitter": "Svitlana Vakulenko", "authors": "Svitlana Vakulenko, Javier David Fernandez Garcia, Axel Polleres,\n  Maarten de Rijke, Michael Cochez", "title": "Message Passing for Complex Question Answering over Knowledge Graphs", "comments": "Accepted in CIKM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering over knowledge graphs (KGQA) has evolved from simple\nsingle-fact questions to complex questions that require graph traversal and\naggregation. We propose a novel approach for complex KGQA that uses\nunsupervised message passing, which propagates confidence scores obtained by\nparsing an input question and matching terms in the knowledge graph to a set of\npossible answers. First, we identify entity, relationship, and class names\nmentioned in a natural language question, and map these to their counterparts\nin the graph. Then, the confidence scores of these mappings propagate through\nthe graph structure to locate the answer entities. Finally, these are\naggregated depending on the identified question type. This approach can be\nefficiently implemented as a series of sparse matrix multiplications mimicking\njoins over small local subgraphs. Our evaluation results show that the proposed\napproach outperforms the state-of-the-art on the LC-QuAD benchmark. Moreover,\nwe show that the performance of the approach depends only on the quality of the\nquestion interpretation results, i.e., given a correct relevance score\ndistribution, our approach always produces a correct answer ranking. Our error\nanalysis reveals correct answers missing from the benchmark dataset and\ninconsistencies in the DBpedia knowledge graph. Finally, we provide a\ncomprehensive evaluation of the proposed approach accompanied with an ablation\nstudy and an error analysis, which showcase the pitfalls for each of the\nquestion answering components in more detail.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 16:31:29 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Vakulenko", "Svitlana", ""], ["Garcia", "Javier David Fernandez", ""], ["Polleres", "Axel", ""], ["de Rijke", "Maarten", ""], ["Cochez", "Michael", ""]]}, {"id": "1908.06926", "submitter": "Milan Straka", "authors": "Jana Strakov\\'a, Milan Straka, Jan Haji\\v{c}", "title": "Neural Architectures for Nested NER through Linearization", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two neural network architectures for nested named entity\nrecognition (NER), a setting in which named entities may overlap and also be\nlabeled with more than one label. We encode the nested labels using a\nlinearized scheme. In our first proposed approach, the nested labels are\nmodeled as multilabels corresponding to the Cartesian product of the nested\nlabels in a standard LSTM-CRF architecture. In the second one, the nested NER\nis viewed as a sequence-to-sequence problem, in which the input sequence\nconsists of the tokens and output sequence of the labels, using hard attention\non the word whose label is being predicted. The proposed methods outperform the\nnested NER state of the art on four corpora: ACE-2004, ACE-2005, GENIA and\nCzech CNEC. We also enrich our architectures with the recently published\ncontextual embeddings: ELMo, BERT and Flair, reaching further improvements for\nthe four nested entity corpora. In addition, we report flat NER\nstate-of-the-art results for CoNLL-2002 Dutch and Spanish and for CoNLL-2003\nEnglish.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 16:54:53 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Strakov\u00e1", "Jana", ""], ["Straka", "Milan", ""], ["Haji\u010d", "Jan", ""]]}, {"id": "1908.06931", "submitter": "Milan Straka", "authors": "Milan Straka, Jana Strakov\\'a, Jan Haji\\v{c}", "title": "UDPipe at SIGMORPHON 2019: Contextualized Embeddings, Regularization\n  with Morphological Categories, Corpora Merging", "comments": "Accepted by SIGMORPHON 2019: 16th SIGMORPHON Workshop on\n  Computational Research in Phonetics, Phonology, and Morphology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our contribution to the SIGMORPHON 2019 Shared Task:\nCrosslinguality and Context in Morphology, Task 2: contextual morphological\nanalysis and lemmatization.\n  We submitted a modification of the UDPipe 2.0, one of best-performing systems\nof the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal\nDependencies and an overall winner of the The 2018 Shared Task on Extrinsic\nParser Evaluation.\n  As our first improvement, we use the pretrained contextualized embeddings\n(BERT) as additional inputs to the network; secondly, we use individual\nmorphological features as regularization; and finally, we merge the selected\ncorpora of the same language.\n  In the lemmatization task, our system exceeds all the submitted systems by a\nwide margin with lemmatization accuracy 95.78 (second best was 95.00, third\n94.46). In the morphological analysis, our system placed tightly second: our\nmorphological analysis accuracy was 93.19, the winning system's 93.23.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 17:03:03 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Straka", "Milan", ""], ["Strakov\u00e1", "Jana", ""], ["Haji\u010d", "Jan", ""]]}, {"id": "1908.06938", "submitter": "Zachary Ziegler", "authors": "Zachary M. Ziegler, Luke Melas-Kyriazi, Sebastian Gehrmann and\n  Alexander M. Rush", "title": "Encoder-Agnostic Adaptation for Conditional Language Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large pretrained language models have changed the way researchers approach\ndiscriminative natural language understanding tasks, leading to the dominance\nof approaches that adapt a pretrained model for arbitrary downstream tasks.\nHowever it is an open-question how to use similar techniques for language\ngeneration. Early results in the encoder-agnostic setting have been mostly\nnegative. In this work we explore methods for adapting a pretrained language\nmodel to arbitrary conditional input. We observe that pretrained transformer\nmodels are sensitive to large parameter changes during tuning. We therefore\npropose an adaptation that directly injects arbitrary conditioning into self\nattention, an approach we call pseudo self attention. Through experiments on\nfour diverse conditional text generation tasks we show that this\nencoder-agnostic technique outperforms strong baselines, produces coherent\ngenerations, and is data efficient.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 17:22:58 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 02:45:34 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Ziegler", "Zachary M.", ""], ["Melas-Kyriazi", "Luke", ""], ["Gehrmann", "Sebastian", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1908.06941", "submitter": "Alexandre Salle", "authors": "Alexandre Salle and Aline Villavicencio", "title": "Why So Down? The Role of Negative (and Positive) Pointwise Mutual\n  Information in Distributional Semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In distributional semantics, the pointwise mutual information\n($\\mathit{PMI}$) weighting of the cooccurrence matrix performs far better than\nraw counts. There is, however, an issue with unobserved pair cooccurrences as\n$\\mathit{PMI}$ goes to negative infinity. This problem is aggravated by\nunreliable statistics from finite corpora which lead to a large number of such\npairs. A common practice is to clip negative $\\mathit{PMI}$\n($\\mathit{\\texttt{-} PMI}$) at $0$, also known as Positive $\\mathit{PMI}$\n($\\mathit{PPMI}$). In this paper, we investigate alternative ways of dealing\nwith $\\mathit{\\texttt{-} PMI}$ and, more importantly, study the role that\nnegative information plays in the performance of a low-rank, weighted\nfactorization of different $\\mathit{PMI}$ matrices. Using various semantic and\nsyntactic tasks as probes into models which use either negative or positive\n$\\mathit{PMI}$ (or both), we find that most of the encoded semantics and syntax\ncome from positive $\\mathit{PMI}$, in contrast to $\\mathit{\\texttt{-} PMI}$\nwhich contributes almost exclusively syntactic information. Our findings deepen\nour understanding of distributional semantics, while also introducing novel\n$PMI$ variants and grounding the popular $PPMI$ measure.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 17:26:13 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Salle", "Alexandre", ""], ["Villavicencio", "Aline", ""]]}, {"id": "1908.07013", "submitter": "Peter Turney", "authors": "Peter D. Turney and Saif M. Mohammad", "title": "The Natural Selection of Words: Finding the Features of Fitness", "comments": null, "journal-ref": "Published in PLOS ONE, 14(1), e0211512, January 28, 2019", "doi": "10.1371/journal.pone.0211512", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a dataset for studying the evolution of words, constructed from\nWordNet and the Google Books Ngram Corpus. The dataset tracks the evolution of\n4,000 synonym sets (synsets), containing 9,000 English words, from 1800 AD to\n2000 AD. We present a supervised learning algorithm that is able to predict the\nfuture leader of a synset: the word in the synset that will have the highest\nfrequency. The algorithm uses features based on a word's length, the characters\nin the word, and the historical frequencies of the word. It can predict change\nof leadership (including the identity of the new leader) fifty years in the\nfuture, with an F-score considerably above random guessing. Analysis of the\nlearned models provides insight into the causes of change in the leader of a\nsynset. The algorithm confirms observations linguists have made, such as the\ntrend to replace the -ise suffix with -ize, the rivalry between the -ity and\n-ness suffixes, and the struggle between economy (shorter words are easier to\nremember and to write) and clarity (longer words are more distinctive and less\nlikely to be confused with one another). The results indicate that integration\nof the Google Books Ngram Corpus with WordNet has significant potential for\nimproving our understanding of how language evolves.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 18:28:59 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Turney", "Peter D.", ""], ["Mohammad", "Saif M.", ""]]}, {"id": "1908.07018", "submitter": "Ayush Maheshwari", "authors": "Ayush Maheshwari, Hrishikesh Patel, Nandan Rathod, Ritesh Kumar,\n  Ganesh Ramakrishnan and Pushpak Bhattacharyya", "title": "Tale of tails using rule augmented sequence labeling for event\n  extraction", "comments": "9 pages, 4 figures, 6 tables", "journal-ref": "StarAI Workshop at AAAI 2020", "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of event extraction is a relatively difficult task for low\nresource languages due to the non-availability of sufficient annotated data.\nMoreover, the task becomes complex for tail (rarely occurring) labels wherein\nextremely less data is available. In this paper, we present a new dataset\n(InDEE-2019) in the disaster domain for multiple Indic languages, collected\nfrom news websites. Using this dataset, we evaluate several rule-based\nmechanisms to augment deep learning based models. We formulate our problem of\nevent extraction as a sequence labeling task and perform extensive experiments\nto study and understand the effectiveness of different approaches. We further\nshow that tail labels can be easily incorporated by creating new rules without\nthe requirement of large annotated data.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 18:43:06 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 06:10:02 GMT"}, {"version": "v3", "created": "Fri, 31 Jan 2020 07:36:09 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Maheshwari", "Ayush", ""], ["Patel", "Hrishikesh", ""], ["Rathod", "Nandan", ""], ["Kumar", "Ritesh", ""], ["Ramakrishnan", "Ganesh", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1908.07064", "submitter": "Praveen Kumar Bodigutla", "authors": "Praveen Kumar Bodigutla, Longshaokan Wang, Kate Ridgeway, Joshua Levy,\n  Swanand Joshi, Alborz Geramifard, Spyros Matsoukas", "title": "Domain-Independent turn-level Dialogue Quality Evaluation via User\n  Satisfaction Estimation", "comments": "Implications of Deep Learning for Dialog Modeling - Special session\n  at SIGdial 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An automated metric to evaluate dialogue quality is vital for optimizing data\ndriven dialogue management. The common approach of relying on explicit user\nfeedback during a conversation is intrusive and sparse. Current models to\nestimate user satisfaction use limited feature sets and rely on annotation\nschemes with low inter-rater reliability, limiting generalizability to\nconversations spanning multiple domains. To address these gaps, we created a\nnew Response Quality annotation scheme, based on which we developed turn-level\nUser Satisfaction metric. We introduced five new domain-independent feature\nsets and experimented with six machine learning models to estimate the new\nsatisfaction metric.\n  Using Response Quality annotation scheme, across randomly sampled single and\nmulti-turn conversations from 26 domains, we achieved high inter-annotator\nagreement (Spearman's rho 0.94). The Response Quality labels were highly\ncorrelated (0.76) with explicit turn-level user ratings. Gradient boosting\nregression achieved best correlation of ~0.79 between predicted and annotated\nuser satisfaction labels. Multi Layer Perceptron and Gradient Boosting\nregression models generalized to an unseen domain better (linear correlation\n0.67) than other models. Finally, our ablation study verified that our novel\nfeatures significantly improved model performance.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 20:58:24 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Bodigutla", "Praveen Kumar", ""], ["Wang", "Longshaokan", ""], ["Ridgeway", "Kate", ""], ["Levy", "Joshua", ""], ["Joshi", "Swanand", ""], ["Geramifard", "Alborz", ""], ["Matsoukas", "Spyros", ""]]}, {"id": "1908.07069", "submitter": "Zulfat Miftahutdinov", "authors": "Sergey Nikolenko and Elena Tutubalina and Zulfat Miftahutdinov and\n  Eugene Beloded", "title": "CommentsRadar: Dive into Unique Data on All Comments on the Web", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an entity-centric search engineCommentsRadarthatpairs entity\nqueries with articles and user opinions covering a widerange of topics from top\ncommented sites. The engine aggregatesarticles and comments for these articles,\nextracts named entities,links them together and with knowledge base entries,\nperformssentiment analysis, and aggregates the results, aiming to mine\nfortemporal trends and other insights. In this work, we present thegeneral\nengine, discuss the models used for all steps of this pipeline,and introduce\nseveral case studies that discover important insightsfrom online commenting\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 13:01:30 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Nikolenko", "Sergey", ""], ["Tutubalina", "Elena", ""], ["Miftahutdinov", "Zulfat", ""], ["Beloded", "Eugene", ""]]}, {"id": "1908.07125", "submitter": "Eric Wallace", "authors": "Eric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner, Sameer Singh", "title": "Universal Adversarial Triggers for Attacking and Analyzing NLP", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples highlight model vulnerabilities and are useful for\nevaluation and interpretation. We define universal adversarial triggers:\ninput-agnostic sequences of tokens that trigger a model to produce a specific\nprediction when concatenated to any input from a dataset. We propose a\ngradient-guided search over tokens which finds short trigger sequences (e.g.,\none word for classification and four words for language modeling) that\nsuccessfully trigger the target prediction. For example, triggers cause SNLI\nentailment accuracy to drop from 89.94% to 0.55%, 72% of \"why\" questions in\nSQuAD to be answered \"to kill american people\", and the GPT-2 language model to\nspew racist output even when conditioned on non-racial contexts. Furthermore,\nalthough the triggers are optimized using white-box access to a specific model,\nthey transfer to other models for all tasks we consider. Finally, since\ntriggers are input-agnostic, they provide an analysis of global model behavior.\nFor instance, they confirm that SNLI models exploit dataset biases and help to\ndiagnose heuristics learned by reading comprehension models.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 01:51:40 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 20:39:20 GMT"}, {"version": "v3", "created": "Sun, 3 Jan 2021 19:58:55 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Wallace", "Eric", ""], ["Feng", "Shi", ""], ["Kandpal", "Nikhil", ""], ["Gardner", "Matt", ""], ["Singh", "Sameer", ""]]}, {"id": "1908.07129", "submitter": "Arka Sadhu", "authors": "Arka Sadhu, Kan Chen, Ram Nevatia", "title": "Zero-Shot Grounding of Objects from Natural Language Queries", "comments": "ICCV19 oral, camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A phrase grounding system localizes a particular object in an image referred\nto by a natural language query. In previous work, the phrases were restricted\nto have nouns that were encountered in training, we extend the task to\nZero-Shot Grounding(ZSG) which can include novel, \"unseen\" nouns. Current\nphrase grounding systems use an explicit object detection network in a 2-stage\nframework where one stage generates sparse proposals and the other stage\nevaluates them. In the ZSG setting, generating appropriate proposals itself\nbecomes an obstacle as the proposal generator is trained on the entities common\nin the detection and grounding datasets. We propose a new single-stage model\ncalled ZSGNet which combines the detector network and the grounding system and\npredicts classification scores and regression parameters. Evaluation of ZSG\nsystem brings additional subtleties due to the influence of the relationship\nbetween the query and learned categories; we define four distinct conditions\nthat incorporate different levels of difficulty. We also introduce new\ndatasets, sub-sampled from Flickr30k Entities and Visual Genome, that enable\nevaluations for the four conditions. Our experiments show that ZSGNet achieves\nstate-of-the-art performance on Flickr30k and ReferIt under the usual \"seen\"\nsettings and performs significantly better than baseline in the zero-shot\nsetting.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 02:07:14 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Sadhu", "Arka", ""], ["Chen", "Kan", ""], ["Nevatia", "Ram", ""]]}, {"id": "1908.07137", "submitter": "Feng Ji", "authors": "Shuke Peng, Xinjing Huang, Zehao Lin, Feng Ji, Haiqing Chen and Yin\n  Zhang", "title": "Teacher-Student Framework Enhanced Multi-domain Dialogue Generation", "comments": "Official Version: arXiv:2005.10450", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue systems dealing with multi-domain tasks are highly required. How to\nrecord the state remains a key problem in a task-oriented dialogue system.\nNormally we use human-defined features as dialogue states and apply a state\ntracker to extract these features. However, the performance of such a system is\nlimited by the error propagation of a state tracker. In this paper, we propose\na dialogue generation model that needs no external state trackers and still\nbenefits from human-labeled semantic data. By using a teacher-student\nframework, several teacher models are firstly trained in their individual\ndomains, learn dialogue policies from labeled states. And then the learned\nknowledge and experience are merged and transferred to a universal student\nmodel, which takes raw utterance as its input. Experiments show that the\ndialogue system trained under our framework outperforms the one uses a belief\ntracker.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 02:59:37 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 11:18:18 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Peng", "Shuke", ""], ["Huang", "Xinjing", ""], ["Lin", "Zehao", ""], ["Ji", "Feng", ""], ["Chen", "Haiqing", ""], ["Zhang", "Yin", ""]]}, {"id": "1908.07141", "submitter": "Mojtaba Nayyeri", "authors": "Mojtaba Nayyeri, Chengjin Xu, Jens Lehmann, Hamed Shariat Yazdi", "title": "LogicENN: A Neural Based Knowledge Graphs Embedding Model with Logical\n  Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph embedding models have gained significant attention in AI\nresearch. Recent works have shown that the inclusion of background knowledge,\nsuch as logical rules, can improve the performance of embeddings in downstream\nmachine learning tasks. However, so far, most existing models do not allow the\ninclusion of rules. We address the challenge of including rules and present a\nnew neural based embedding model (LogicENN). We prove that LogicENN can learn\nevery ground truth of encoded rules in a knowledge graph. To the best of our\nknowledge, this has not been proved so far for the neural based family of\nembedding models. Moreover, we derive formulae for the inclusion of various\nrules, including (anti-)symmetric, inverse, irreflexive and transitive,\nimplication, composition, equivalence and negation. Our formulation allows to\navoid grounding for implication and equivalence relations. Our experiments show\nthat LogicENN outperforms the state-of-the-art models in link prediction.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 03:12:13 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Nayyeri", "Mojtaba", ""], ["Xu", "Chengjin", ""], ["Lehmann", "Jens", ""], ["Yazdi", "Hamed Shariat", ""]]}, {"id": "1908.07147", "submitter": "Zhiyuan Ma", "authors": "Liang Zhao, Zhiyuan Ma, Yangming Zhou, Kai Wang, Shengping Liu, Ju Gao", "title": "CBOWRA: A Representation Learning Approach for Medication Anomaly\n  Detection", "comments": "8 pages, 6 figures, submitted to BIBM 2019, accepted in workshop BHI\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic health record is an important source for clinical researches and\napplications, and errors inevitably occur in the data, which could lead to\nsevere damages to both patients and hospital services. One of such error is the\nmismatches between diagnoses and prescriptions, which we address as 'medication\nanomaly' in the paper, and clinicians used to manually identify and correct\nthem. With the development of machine learning techniques, researchers are able\nto train specific model for the task, but the process still requires expert\nknowledge to construct proper features, and few semantic relations are\nconsidered. In this paper, we propose a simple, yet effective detection method\nthat tackles the problem by detecting the semantic inconsistency between\ndiagnoses and prescriptions. Unlike traditional outlier or anomaly detection,\nthe scheme uses continuous bag of words to construct the semantic connection\nbetween specific central words and their surrounding context. The detection of\nmedication anomaly is transformed into identifying the least possible central\nword based on given context. To help distinguish the anomaly from normal\ncontext, we also incorporate a ranking accumulation strategy. The experiments\nwere conducted on two real hospital electronic medical records, and the topN\naccuracy of the proposed method increased by 3.91 to 10.91% and 0.68 to 2.13%\non the datasets, respectively, which is highly competitive to other traditional\nmachine learning-based approaches.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 03:40:39 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 08:39:30 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Zhao", "Liang", ""], ["Ma", "Zhiyuan", ""], ["Zhou", "Yangming", ""], ["Wang", "Kai", ""], ["Liu", "Shengping", ""], ["Gao", "Ju", ""]]}, {"id": "1908.07162", "submitter": "Yu Meng", "authors": "Yu Meng, Jiaxin Huang, Guangyuan Wang, Zihan Wang, Chao Zhang, Yu\n  Zhang, Jiawei Han", "title": "Discriminative Topic Mining via Category-Name Guided Text Embedding", "comments": "WWW 2020. (Code: https://github.com/yumeng5/CatE)", "journal-ref": null, "doi": "10.1145/3366423.3380278", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining a set of meaningful and distinctive topics automatically from massive\ntext corpora has broad applications. Existing topic models, however, typically\nwork in a purely unsupervised way, which often generate topics that do not fit\nusers' particular needs and yield suboptimal performance on downstream tasks.\nWe propose a new task, discriminative topic mining, which leverages a set of\nuser-provided category names to mine discriminative topics from text corpora.\nThis new task not only helps a user understand clearly and distinctively the\ntopics he/she is most interested in, but also benefits directly keyword-driven\nclassification tasks. We develop CatE, a novel category-name guided text\nembedding method for discriminative topic mining, which effectively leverages\nminimal user guidance to learn a discriminative embedding space and discover\ncategory representative terms in an iterative manner. We conduct a\ncomprehensive set of experiments to show that CatE mines high-quality set of\ntopics guided by category names only, and benefits a variety of downstream\napplications including weakly-supervised classification and lexical entailment\ndirection identification.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 04:32:30 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 21:34:49 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Meng", "Yu", ""], ["Huang", "Jiaxin", ""], ["Wang", "Guangyuan", ""], ["Wang", "Zihan", ""], ["Zhang", "Chao", ""], ["Zhang", "Yu", ""], ["Han", "Jiawei", ""]]}, {"id": "1908.07181", "submitter": "Raphael Shu", "authors": "Raphael Shu, Jason Lee, Hideki Nakayama, Kyunghyun Cho", "title": "Latent-Variable Non-Autoregressive Neural Machine Translation with\n  Deterministic Inference Using a Delta Posterior", "comments": "This paper was accepted to AAAI 2020, the copyright is transferred to\n  AAAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although neural machine translation models reached high translation quality,\nthe autoregressive nature makes inference difficult to parallelize and leads to\nhigh translation latency. Inspired by recent refinement-based approaches, we\npropose LaNMT, a latent-variable non-autoregressive model with continuous\nlatent variables and deterministic inference procedure. In contrast to existing\napproaches, we use a deterministic inference algorithm to find the target\nsequence that maximizes the lowerbound to the log-probability. During\ninference, the length of translation automatically adapts itself. Our\nexperiments show that the lowerbound can be greatly increased by running the\ninference algorithm, resulting in significantly improved translation quality.\nOur proposed model closes the performance gap between non-autoregressive and\nautoregressive approaches on ASPEC Ja-En dataset with 8.6x faster decoding. On\nWMT'14 En-De dataset, our model narrows the gap with autoregressive baseline to\n2.0 BLEU points with 12.5x speedup. By decoding multiple initial latent\nvariables in parallel and rescore using a teacher model, the proposed model\nfurther brings the gap down to 1.0 BLEU point on WMT'14 En-De task with 6.8x\nspeedup.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 06:14:18 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 05:17:44 GMT"}, {"version": "v3", "created": "Tue, 10 Sep 2019 01:35:11 GMT"}, {"version": "v4", "created": "Sat, 5 Oct 2019 07:03:22 GMT"}, {"version": "v5", "created": "Thu, 21 Nov 2019 05:49:25 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Shu", "Raphael", ""], ["Lee", "Jason", ""], ["Nakayama", "Hideki", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1908.07195", "submitter": "Pei Ke", "authors": "Pei Ke, Fei Huang, Minlie Huang, Xiaoyan Zhu", "title": "ARAML: A Stable Adversarial Training Framework for Text Generation", "comments": "Accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing generative adversarial networks (GAN) for text\ngeneration suffer from the instability of reinforcement learning training\nalgorithms such as policy gradient, leading to unstable performance. To tackle\nthis problem, we propose a novel framework called Adversarial Reward Augmented\nMaximum Likelihood (ARAML). During adversarial training, the discriminator\nassigns rewards to samples which are acquired from a stationary distribution\nnear the data rather than the generator's distribution. The generator is\noptimized with maximum likelihood estimation augmented by the discriminator's\nrewards instead of policy gradient. Experiments show that our model can\noutperform state-of-the-art text GANs with a more stable training process.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 07:25:14 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Ke", "Pei", ""], ["Huang", "Fei", ""], ["Huang", "Minlie", ""], ["Zhu", "Xiaoyan", ""]]}, {"id": "1908.07218", "submitter": "Peng-Hsuan Li", "authors": "Peng-Hsuan Li, Tsan-Yu Yang, Wei-Yun Ma", "title": "CA-EHN: Commonsense Analogy from E-HowNet", "comments": "In proceedings of LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding commonsense knowledge is crucial for end-to-end models to\ngeneralize inference beyond training corpora. However, existing word analogy\ndatasets have tended to be handcrafted, involving permutations of hundreds of\nwords with only dozens of pre-defined relations, mostly morphological relations\nand named entities. In this work, we model commonsense knowledge down to\nword-level analogical reasoning by leveraging E-HowNet, an ontology that\nannotates 88K Chinese words with their structured sense definitions and English\ntranslations. We present CA-EHN, the first commonsense word analogy dataset\ncontaining 90,505 analogies covering 5,656 words and 763 relations. Experiments\nshow that CA-EHN stands out as a great indicator of how well word\nrepresentations embed commonsense knowledge. The dataset is publicly available\nat https://github.com/ckiplab/CA-EHN.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 08:33:58 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 01:27:17 GMT"}, {"version": "v3", "created": "Mon, 14 Oct 2019 09:27:09 GMT"}, {"version": "v4", "created": "Thu, 28 May 2020 03:58:46 GMT"}, {"version": "v5", "created": "Fri, 29 May 2020 01:52:46 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Li", "Peng-Hsuan", ""], ["Yang", "Tsan-Yu", ""], ["Ma", "Wei-Yun", ""]]}, {"id": "1908.07226", "submitter": "Alp \\\"Oktem", "authors": "Alp \\\"Oktem and Mireia Farr\\'us and Antonio Bonafonte", "title": "Prosodic Phrase Alignment for Machine Dubbing", "comments": "Interspeech 2019 pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.MM cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dubbing is a type of audiovisual translation where dialogues are translated\nand enacted so that they give the impression that the media is in the target\nlanguage. It requires a careful alignment of dubbed recordings with the lip\nmovements of performers in order to achieve visual coherence. In this paper, we\ndeal with the specific problem of prosodic phrase synchronization within the\nframework of machine dubbing. Our methodology exploits the attention mechanism\noutput in neural machine translation to find plausible phrasing for the\ntranslated dialogue lines and then uses them to condition their synthesis. Our\ninitial work in this field records comparable speech rate ratio to professional\ndubbing translation, and improvement in terms of lip-syncing of long dialogue\nlines.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 08:52:52 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["\u00d6ktem", "Alp", ""], ["Farr\u00fas", "Mireia", ""], ["Bonafonte", "Antonio", ""]]}, {"id": "1908.07245", "submitter": "Luyao Huang", "authors": "Luyao Huang, Chi Sun, Xipeng Qiu, Xuanjing Huang", "title": "GlossBERT: BERT for Word Sense Disambiguation with Gloss Knowledge", "comments": "EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word Sense Disambiguation (WSD) aims to find the exact sense of an ambiguous\nword in a particular context. Traditional supervised methods rarely take into\nconsideration the lexical resources like WordNet, which are widely utilized in\nknowledge-based methods. Recent studies have shown the effectiveness of\nincorporating gloss (sense definition) into neural networks for WSD. However,\ncompared with traditional word expert supervised methods, they have not\nachieved much improvement. In this paper, we focus on how to better leverage\ngloss knowledge in a supervised neural WSD system. We construct context-gloss\npairs and propose three BERT-based models for WSD. We fine-tune the pre-trained\nBERT model on SemCor3.0 training corpus and the experimental results on several\nEnglish all-words WSD benchmark datasets show that our approach outperforms the\nstate-of-the-art systems.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 09:37:42 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 16:38:11 GMT"}, {"version": "v3", "created": "Sat, 9 Nov 2019 08:45:42 GMT"}, {"version": "v4", "created": "Sun, 5 Jan 2020 11:33:23 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Huang", "Luyao", ""], ["Sun", "Chi", ""], ["Qiu", "Xipeng", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1908.07281", "submitter": "Sameh K. Mohamed", "authors": "Sameh K. Mohamed", "title": "Unsupervised Hierarchical Grouping of Knowledge Graph Entities", "comments": "10 pages - LASCAR@ESWC'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Knowledge graphs have attracted lots of attention in academic and industrial\nenvironments. Despite their usefulness, popular knowledge graphs suffer from\nincompleteness of information, especially in their type assertions. This has\nencouraged research in the automatic discovery of entity types. In this\ncontext, multiple works were developed to utilize logical inference on\nontologies and statistical machine learning methods to learn type assertion in\nknowledge graphs. However, these approaches suffer from limited performance on\nnoisy data, limited scalability and the dependence on labeled training samples.\nIn this work, we propose a new unsupervised approach that learns to categorize\nentities into a hierarchy of named groups. We show that our approach is able to\neffectively learn entity groups using a scalable procedure in noisy and sparse\ndatasets. We experiment our approach on a set of popular knowledge graph\nbenchmarking datasets, and we publish a collection of the outcome group\nhierarchies.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 11:40:16 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Mohamed", "Sameh K.", ""]]}, {"id": "1908.07347", "submitter": "Adriana Correia", "authors": "Adriana D. Correia, Michael Moortgat, Henk T. C. Stoof", "title": "Density Matrices with Metric for Derivational Ambiguity", "comments": "24 pages, 10 figures. SemSpace 2019, to appear in J. of Applied\n  Logics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on vector-based compositional natural language semantics has\nproposed the use of density matrices to model lexical ambiguity and (graded)\nentailment (e.g. Piedeleu et al 2015, Bankova et al 2019, Sadrzadeh et al\n2018). Ambiguous word meanings, in this work, are represented as mixed states,\nand the compositional interpretation of phrases out of their constituent parts\ntakes the form of a strongly monoidal functor sending the derivational\nmorphisms of a pregroup syntax to linear maps in FdHilb. Our aims in this paper\nare threefold. Firstly, we replace the pregroup front end by a Lambek\ncategorial grammar with directional implications expressing a word's\nselectional requirements. By the Curry-Howard correspondence, the derivations\nof the grammar's type logic are associated with terms of the (ordered) linear\nlambda calculus; these terms can be read as programs for compositional meaning\nassembly with density matrices as the target semantic spaces. Secondly, we\nextend on the existing literature and introduce a symmetric, nondegenerate\nbilinear form called a \"metric\" that defines a canonical isomorphism between a\nvector space and its dual, allowing us to keep a distinction between left and\nright implication. Thirdly, we use this metric to define density matrix spaces\nin a directional form, modeling the ubiquitous derivational ambiguity of\nnatural language syntax, and show how this alows an integrated treatment of\nlexical and derivational forms of ambiguity controlled at the level of the\ninterpretation.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 13:49:30 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 18:09:54 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 22:41:33 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Correia", "Adriana D.", ""], ["Moortgat", "Michael", ""], ["Stoof", "Henk T. C.", ""]]}, {"id": "1908.07397", "submitter": "Miryam de Lhoneux", "authors": "Artur Kulmizev, Miryam de Lhoneux, Johannes Gontrum, Elena Fano and\n  Joakim Nivre", "title": "Deep Contextualized Word Embeddings in Transition-Based and Graph-Based\n  Dependency Parsing -- A Tale of Two Parsers Revisited", "comments": "Accepted at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transition-based and graph-based dependency parsers have previously been\nshown to have complementary strengths and weaknesses: transition-based parsers\nexploit rich structural features but suffer from error propagation, while\ngraph-based parsers benefit from global optimization but have restricted\nfeature scope. In this paper, we show that, even though some details of the\npicture have changed after the switch to neural networks and continuous\nrepresentations, the basic trade-off between rich features and global\noptimization remains essentially the same. Moreover, we show that deep\ncontextualized word embeddings, which allow parsers to pack information about\nglobal sentence structure into local feature representations, benefit\ntransition-based parsers more than graph-based parsers, making the two\napproaches virtually equivalent in terms of both accuracy and error profile. We\nargue that the reason is that these representations help prevent search errors\nand thereby allow transition-based parsers to better exploit their inherent\nstrength of making accurate local decisions. We support this explanation by an\nerror analysis of parsing experiments on 13 languages.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 14:36:57 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 08:36:53 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Kulmizev", "Artur", ""], ["de Lhoneux", "Miryam", ""], ["Gontrum", "Johannes", ""], ["Fano", "Elena", ""], ["Nivre", "Joakim", ""]]}, {"id": "1908.07448", "submitter": "Milan Straka", "authors": "Milan Straka, Jana Strakov\\'a, Jan Haji\\v{c}", "title": "Evaluating Contextualized Embeddings on 54 Languages in POS Tagging,\n  Lemmatization and Dependency Parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an extensive evaluation of three recently proposed methods for\ncontextualized embeddings on 89 corpora in 54 languages of the Universal\nDependencies 2.3 in three tasks: POS tagging, lemmatization, and dependency\nparsing. Employing the BERT, Flair and ELMo as pretrained embedding inputs in a\nstrong baseline of UDPipe 2.0, one of the best-performing systems of the CoNLL\n2018 Shared Task and an overall winner of the EPE 2018, we present a one-to-one\ncomparison of the three contextualized word embedding methods, as well as a\ncomparison with word2vec-like pretrained embeddings and with end-to-end\ncharacter-level word embeddings. We report state-of-the-art results in all\nthree tasks as compared to results on UD 2.2 in the CoNLL 2018 Shared Task.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 15:52:59 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Straka", "Milan", ""], ["Strakov\u00e1", "Jana", ""], ["Haji\u010d", "Jan", ""]]}, {"id": "1908.07490", "submitter": "Hao Tan", "authors": "Hao Tan, Mohit Bansal", "title": "LXMERT: Learning Cross-Modality Encoder Representations from\n  Transformers", "comments": "EMNLP 2019 (14 pages; with new attention visualizations)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision-and-language reasoning requires an understanding of visual concepts,\nlanguage semantics, and, most importantly, the alignment and relationships\nbetween these two modalities. We thus propose the LXMERT (Learning\nCross-Modality Encoder Representations from Transformers) framework to learn\nthese vision-and-language connections. In LXMERT, we build a large-scale\nTransformer model that consists of three encoders: an object relationship\nencoder, a language encoder, and a cross-modality encoder. Next, to endow our\nmodel with the capability of connecting vision and language semantics, we\npre-train the model with large amounts of image-and-sentence pairs, via five\ndiverse representative pre-training tasks: masked language modeling, masked\nobject prediction (feature regression and label classification), cross-modality\nmatching, and image question answering. These tasks help in learning both\nintra-modality and cross-modality relationships. After fine-tuning from our\npre-trained parameters, our model achieves the state-of-the-art results on two\nvisual question answering datasets (i.e., VQA and GQA). We also show the\ngeneralizability of our pre-trained cross-modality model by adapting it to a\nchallenging visual-reasoning task, NLVR2, and improve the previous best result\nby 22% absolute (54% to 76%). Lastly, we demonstrate detailed ablation studies\nto prove that both our novel model components and pre-training strategies\nsignificantly contribute to our strong results; and also present several\nattention visualizations for the different encoders. Code and pre-trained\nmodels publicly available at: https://github.com/airsplay/lxmert\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 17:05:18 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 17:54:29 GMT"}, {"version": "v3", "created": "Tue, 3 Dec 2019 19:30:19 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Tan", "Hao", ""], ["Bansal", "Mohit", ""]]}, {"id": "1908.07491", "submitter": "Ella Rabinovich", "authors": "Benjamin Sznajder, Ariel Gera, Yonatan Bilu, Dafna Sheinwald, Ella\n  Rabinovich, Ranit Aharonov, David Konopnicki and Noam Slonim", "title": "Controversy in Context", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing interest in social applications of Natural Language\nProcessing and Computational Argumentation, a natural question is how\ncontroversial a given concept is. Prior works relied on Wikipedia's metadata\nand on content analysis of the articles pertaining to a concept in question.\nHere we show that the immediate textual context of a concept is strongly\nindicative of this property, and, using simple and language-independent\nmachine-learning tools, we leverage this observation to achieve\nstate-of-the-art results in controversiality prediction. In addition, we\nanalyze and make available a new dataset of concepts labeled for\ncontroversiality. It is significantly larger than existing datasets, and grades\nconcepts on a 0-10 scale, rather than treating controversiality as a binary\nlabel.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 17:07:52 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Sznajder", "Benjamin", ""], ["Gera", "Ariel", ""], ["Bilu", "Yonatan", ""], ["Sheinwald", "Dafna", ""], ["Rabinovich", "Ella", ""], ["Aharonov", "Ranit", ""], ["Konopnicki", "David", ""], ["Slonim", "Noam", ""]]}, {"id": "1908.07553", "submitter": "Josiah Wang", "authors": "Josiah Wang, Lucia Specia", "title": "Phrase Localization Without Paired Training Examples", "comments": "Accepted for oral presentation at the IEEE/CVF International\n  Conference on Computer Vision (ICCV) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Localizing phrases in images is an important part of image understanding and\ncan be useful in many applications that require mappings between textual and\nvisual information. Existing work attempts to learn these mappings from\nexamples of phrase-image region correspondences (strong supervision) or from\nphrase-image pairs (weak supervision). We postulate that such paired\nannotations are unnecessary, and propose the first method for the phrase\nlocalization problem where neither training procedure nor paired, task-specific\ndata is required. Our method is simple but effective: we use off-the-shelf\napproaches to detect objects, scenes and colours in images, and explore\ndifferent approaches to measure semantic similarity between the categories of\ndetected visual elements and words in phrases. Experiments on two well-known\nphrase localization datasets show that this approach surpasses all weakly\nsupervised methods by a large margin and performs very competitively to\nstrongly supervised methods, and can thus be considered a strong baseline to\nthe task. The non-paired nature of our method makes it applicable to any domain\nand where no paired phrase localization annotation is available.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 18:07:37 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Wang", "Josiah", ""], ["Specia", "Lucia", ""]]}, {"id": "1908.07590", "submitter": "Songwei Ge", "authors": "Songwei Ge, Curtis Xuan, Ruihua Song, Chao Zou, Wei Liu, Jin Zhou", "title": "From Text to Sound: A Preliminary Study on Retrieving Sound Effects to\n  Radio Stories", "comments": "In the Proceedings of the 42nd International ACM SIGIR Conference on\n  Research and Development in Information Retrieval (SIGIR 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sound effects play an essential role in producing high-quality radio stories\nbut require enormous labor cost to add. In this paper, we address the problem\nof automatically adding sound effects to radio stories with a retrieval-based\nmodel. However, directly implementing a tag-based retrieval model leads to high\nfalse positives due to the ambiguity of story contents. To solve this problem,\nwe introduce a retrieval-based framework hybridized with a semantic inference\nmodel which helps to achieve robust retrieval results. Our model relies on\nfine-designed features extracted from the context of candidate triggers. We\ncollect two story dubbing datasets through crowdsourcing to analyze the setting\nof adding sound effects and to train and test our proposed methods. We further\ndiscuss the importance of each feature and introduce several heuristic rules\nfor the trade-off between precision and recall. Together with the\ntext-to-speech technology, our results reveal a promising automatic pipeline on\nproducing high-quality radio stories.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 20:10:05 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Ge", "Songwei", ""], ["Xuan", "Curtis", ""], ["Song", "Ruihua", ""], ["Zou", "Chao", ""], ["Liu", "Wei", ""], ["Zhou", "Jin", ""]]}, {"id": "1908.07599", "submitter": "Santosh Kesiraju", "authors": "Santosh Kesiraju, Old\\v{r}ich Plchot, Luk\\'a\\v{s} Burget, and\n  Suryakanth V Gangashetty", "title": "Learning document embeddings along with their uncertainties", "comments": null, "journal-ref": null, "doi": "10.1109/TASLP.2020.3012062", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Majority of the text modelling techniques yield only point-estimates of\ndocument embeddings and lack in capturing the uncertainty of the estimates.\nThese uncertainties give a notion of how well the embeddings represent a\ndocument. We present Bayesian subspace multinomial model (Bayesian SMM), a\ngenerative log-linear model that learns to represent documents in the form of\nGaussian distributions, thereby encoding the uncertainty in its co-variance.\nAdditionally, in the proposed Bayesian SMM, we address a commonly encountered\nproblem of intractability that appears during variational inference in\nmixed-logit models. We also present a generative Gaussian linear classifier for\ntopic identification that exploits the uncertainty in document embeddings. Our\nintrinsic evaluation using perplexity measure shows that the proposed Bayesian\nSMM fits the data better as compared to the state-of-the-art neural variational\ndocument model on Fisher speech and 20Newsgroups text corpora. Our topic\nidentification experiments show that the proposed systems are robust to\nover-fitting on unseen test data. The topic ID results show that the proposed\nmodel is outperforms state-of-the-art unsupervised topic models and achieve\ncomparable results to the state-of-the-art fully supervised discriminative\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 20:31:51 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 12:09:18 GMT"}, {"version": "v3", "created": "Fri, 18 Oct 2019 09:31:42 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Kesiraju", "Santosh", ""], ["Plchot", "Old\u0159ich", ""], ["Burget", "Luk\u00e1\u0161", ""], ["Gangashetty", "Suryakanth V", ""]]}, {"id": "1908.07687", "submitter": "Zhaojiang Lin", "authors": "Zhaojiang Lin, Andrea Madotto, Jamin Shin, Peng Xu, Pascale Fung", "title": "MoEL: Mixture of Empathetic Listeners", "comments": "Accepted by EMNLP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous research on empathetic dialogue systems has mostly focused on\ngenerating responses given certain emotions. However, being empathetic not only\nrequires the ability of generating emotional responses, but more importantly,\nrequires the understanding of user emotions and replying appropriately. In this\npaper, we propose a novel end-to-end approach for modeling empathy in dialogue\nsystems: Mixture of Empathetic Listeners (MoEL). Our model first captures the\nuser emotions and outputs an emotion distribution. Based on this, MoEL will\nsoftly combine the output states of the appropriate Listener(s), which are each\noptimized to react to certain emotions, and generate an empathetic response.\nHuman evaluations on empathetic-dialogues (Rashkin et al., 2018) dataset\nconfirm that MoEL outperforms multitask training baseline in terms of empathy,\nrelevance, and fluency. Furthermore, the case study on generated responses of\ndifferent Listeners shows high interpretability of our model.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 03:02:56 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Lin", "Zhaojiang", ""], ["Madotto", "Andrea", ""], ["Shin", "Jamin", ""], ["Xu", "Peng", ""], ["Fung", "Pascale", ""]]}, {"id": "1908.07688", "submitter": "Rongxiang Weng", "authors": "Rongxiang Weng, Heng Yu, Shujian Huang, Weihua Luo, Jiajun Chen", "title": "Improving Neural Machine Translation with Pre-trained Representation", "comments": "In Progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monolingual data has been demonstrated to be helpful in improving the\ntranslation quality of neural machine translation (NMT). The current methods\nstay at the usage of word-level knowledge, such as generating synthetic\nparallel data or extracting information from word embedding. In contrast, the\npower of sentence-level contextual knowledge which is more complex and diverse,\nplaying an important role in natural language generation, has not been fully\nexploited. In this paper, we propose a novel structure which could leverage\nmonolingual data to acquire sentence-level contextual representations. Then, we\ndesign a framework for integrating both source and target sentence-level\nrepresentations into NMT model to improve the translation quality. Experimental\nresults on Chinese-English, German-English machine translation tasks show that\nour proposed model achieves improvement over strong Transformer baselines,\nwhile experiments on English-Turkish further demonstrate the effectiveness of\nour approach in the low-resource scenario.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 03:03:12 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Weng", "Rongxiang", ""], ["Yu", "Heng", ""], ["Huang", "Shujian", ""], ["Luo", "Weihua", ""], ["Chen", "Jiajun", ""]]}, {"id": "1908.07690", "submitter": "Hiroaki Hayashi", "authors": "Hiroaki Hayashi, Zecong Hu, Chenyan Xiong, Graham Neubig", "title": "Latent Relation Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Latent Relation Language Models (LRLMs), a class of\nlanguage models that parameterizes the joint distribution over the words in a\ndocument and the entities that occur therein via knowledge graph relations.\nThis model has a number of attractive properties: it not only improves language\nmodeling performance, but is also able to annotate the posterior probability of\nentity spans for a given text through relations. Experiments demonstrate\nempirical improvements over both a word-based baseline language model and a\nprevious approach that incorporates knowledge graph information. Qualitative\nanalysis further demonstrates the proposed model's ability to learn to predict\nappropriate relations in context.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 03:09:16 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Hayashi", "Hiroaki", ""], ["Hu", "Zecong", ""], ["Xiong", "Chenyan", ""], ["Neubig", "Graham", ""]]}, {"id": "1908.07705", "submitter": "Qingbin Liu", "authors": "Qingbin Liu, Shizhu He, Kang Liu, Shengping Liu, and Jun Zhao", "title": "Copy-Enhanced Heterogeneous Information Learning for Dialogue State\n  Tracking", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue state tracking (DST) is an essential component in task-oriented\ndialogue systems, which estimates user goals at every dialogue turn. However,\nmost previous approaches usually suffer from the following problems. Many\ndiscriminative models, especially end-to-end (E2E) models, are difficult to\nextract unknown values that are not in the candidate ontology; previous\ngenerative models, which can extract unknown values from utterances, degrade\nthe performance due to ignoring the semantic information of pre-defined\nontology. Besides, previous generative models usually need a hand-crafted list\nto normalize the generated values. How to integrate the semantic information of\npre-defined ontology and dialogue text (heterogeneous texts) to generate\nunknown values and improve performance becomes a severe challenge. In this\npaper, we propose a Copy-Enhanced Heterogeneous Information Learning model with\nmultiple encoder-decoder for DST (CEDST), which can effectively generate all\npossible values including unknown values by copying values from heterogeneous\ntexts. Meanwhile, CEDST can effectively decompose the large state space into\nseveral small state spaces through multi-encoder, and employ multi-decoder to\nmake full use of the reduced spaces to generate values. Multi-encoder-decoder\narchitecture can significantly improve performance. Experiments show that CEDST\ncan achieve state-of-the-art results on two datasets and our constructed\ndatasets with many unknown values.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 04:05:54 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Liu", "Qingbin", ""], ["He", "Shizhu", ""], ["Liu", "Kang", ""], ["Liu", "Shengping", ""], ["Zhao", "Jun", ""]]}, {"id": "1908.07721", "submitter": "Zhiyuan Ma", "authors": "Kui Xue, Yangming Zhou, Zhiyuan Ma, Tong Ruan, Huanhuan Zhang, Ping He", "title": "Fine-tuning BERT for Joint Entity and Relation Extraction in Chinese\n  Medical Text", "comments": "8 pages, 2 figures, submitted to BIBM 2019, accepted as a regular\n  paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity and relation extraction is the necessary step in structuring medical\ntext. However, the feature extraction ability of the bidirectional long short\nterm memory network in the existing model does not achieve the best effect. At\nthe same time, the language model has achieved excellent results in more and\nmore natural language processing tasks. In this paper, we present a focused\nattention model for the joint entity and relation extraction task. Our model\nintegrates well-known BERT language model into joint learning through dynamic\nrange attention mechanism, thus improving the feature representation ability of\nshared parameter layer. Experimental results on coronary angiography texts\ncollected from Shuguang Hospital show that the F1-score of named entity\nrecognition and relation classification tasks reach 96.89% and 88.51%, which\nare better than state-of-the-art methods 1.65% and 1.22%, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 06:56:08 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 08:51:17 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Xue", "Kui", ""], ["Zhou", "Yangming", ""], ["Ma", "Zhiyuan", ""], ["Ruan", "Tong", ""], ["Zhang", "Huanhuan", ""], ["He", "Ping", ""]]}, {"id": "1908.07724", "submitter": "Enmao Diao", "authors": "Enmao Diao, Jie Ding, Vahid Tarokh", "title": "Restricted Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1109/BigData47090.2019.9006257", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Network (RNN) and its variations such as Long Short-Term\nMemory (LSTM) and Gated Recurrent Unit (GRU), have become standard building\nblocks for learning online data of sequential nature in many research areas,\nincluding natural language processing and speech data analysis. In this paper,\nwe present a new methodology to significantly reduce the number of parameters\nin RNNs while maintaining performance that is comparable or even better than\nclassical RNNs. The new proposal, referred to as Restricted Recurrent Neural\nNetwork (RRNN), restricts the weight matrices corresponding to the input data\nand hidden states at each time step to share a large proportion of parameters.\nThe new architecture can be regarded as a compression of its classical\ncounterpart, but it does not require pre-training or sophisticated parameter\nfine-tuning, both of which are major issues in most existing compression\ntechniques. Experiments on natural language modeling show that compared with\nits classical counterpart, the restricted recurrent architecture generally\nproduces comparable results at about 50\\% compression rate. In particular, the\nRestricted LSTM can outperform classical RNN with even less number of\nparameters.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 07:12:31 GMT"}, {"version": "v2", "created": "Sun, 20 Oct 2019 19:53:20 GMT"}, {"version": "v3", "created": "Wed, 23 Oct 2019 09:25:22 GMT"}, {"version": "v4", "created": "Thu, 14 Nov 2019 21:52:34 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Diao", "Enmao", ""], ["Ding", "Jie", ""], ["Tarokh", "Vahid", ""]]}, {"id": "1908.07742", "submitter": "Yerai Doval", "authors": "Yerai Doval and Jose Camacho-Collados and Luis Espinosa-Anke and\n  Steven Schockaert", "title": "On the Robustness of Unsupervised and Semi-supervised Cross-lingual Word\n  Embedding Learning", "comments": "11 pages, 2 figures, 7 tables. Camera-ready submitted to LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual word embeddings are vector representations of words in\ndifferent languages where words with similar meaning are represented by similar\nvectors, regardless of the language. Recent developments which construct these\nembeddings by aligning monolingual spaces have shown that accurate alignments\ncan be obtained with little or no supervision. However, the focus has been on a\nparticular controlled scenario for evaluation, and there is no strong evidence\non how current state-of-the-art systems would fare with noisy text or for\nlanguage pairs with major linguistic differences. In this paper we present an\nextensive evaluation over multiple cross-lingual embedding models, analyzing\ntheir strengths and limitations with respect to different variables such as\ntarget language, training corpora and amount of supervision. Our conclusions\nput in doubt the view that high-quality cross-lingual embeddings can always be\nlearned without much supervision.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 08:01:13 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 15:34:48 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 09:13:05 GMT"}, {"version": "v4", "created": "Tue, 3 Mar 2020 11:49:06 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Doval", "Yerai", ""], ["Camacho-Collados", "Jose", ""], ["Espinosa-Anke", "Luis", ""], ["Schockaert", "Steven", ""]]}, {"id": "1908.07761", "submitter": "Wei-Tsung Lin", "authors": "Weitsung Lin, Tinghsuan Chao, Jianmin Wu and Tianhuang Su", "title": "Predict Emoji Combination with Retrieval Strategy", "comments": "4 pages, 2 figures, published in anlp.jp 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As emojis are widely used in social media, people not only use an emoji to\nexpress their emotions or mention things but also extend its usage to represent\ncomplicate emotions, concepts or activities by combining multiple emojis. In\nthis work, we study how emoji combination, a consecutive emoji sequence, is\nused like a new language. We propose a novel algorithm called Retrieval\nStrategy to predict what emoji combination follows given a short text as\ncontext. Our algorithm treats emoji combinations as phrase in language, ranking\nsets of emoji combinations like retrieving words from dictionary. We show that\nour algorithm largely improves the F1 score from 0.141 to 0.204 on emoji\ncombination prediction task.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 09:25:53 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Lin", "Weitsung", ""], ["Chao", "Tinghsuan", ""], ["Wu", "Jianmin", ""], ["Su", "Tianhuang", ""]]}, {"id": "1908.07795", "submitter": "Yichun Yin", "authors": "Yichun Yin, Lifeng Shang, Xin Jiang, Xiao Chen, Qun Liu", "title": "Dialog State Tracking with Reinforced Data Augmentation", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural dialog state trackers are generally limited due to the lack of\nquantity and diversity of annotated training data. In this paper, we address\nthis difficulty by proposing a reinforcement learning (RL) based framework for\ndata augmentation that can generate high-quality data to improve the neural\nstate tracker. Specifically, we introduce a novel contextual bandit generator\nto learn fine-grained augmentation policies that can generate new effective\ninstances by choosing suitable replacements for the specific context. Moreover,\nby alternately learning between the generator and the state tracker, we can\nkeep refining the generative policies to generate more high-quality training\ndata for neural state tracker. Experimental results on the WoZ and MultiWoZ\n(restaurant) datasets demonstrate that the proposed framework significantly\nimproves the performance over the state-of-the-art models, especially with\nlimited training data.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 11:07:14 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 03:21:21 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Yin", "Yichun", ""], ["Shang", "Lifeng", ""], ["Jiang", "Xin", ""], ["Chen", "Xiao", ""], ["Liu", "Qun", ""]]}, {"id": "1908.07810", "submitter": "Shiwan Zhao Mr", "authors": "Yike Wu, Shiwan Zhao, Jia Chen, Ying Zhang, Xiaojie Yuan, Zhong Su", "title": "Improving Captioning for Low-Resource Languages by Cycle Consistency", "comments": "Published in ICME 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving the captioning performance on low-resource languages by leveraging\nEnglish caption datasets has received increasing research interest in recent\nyears. Existing works mainly fall into two categories: translation-based and\nalignment-based approaches. In this paper, we propose to combine the merits of\nboth approaches in one unified architecture. Specifically, we use a pre-trained\nEnglish caption model to generate high-quality English captions, and then take\nboth the image and generated English captions to generate low-resource language\ncaptions. We improve the captioning performance by adding the cycle consistency\nconstraint on the cycle of image regions, English words, and low-resource\nlanguage words. Moreover, our architecture has a flexible design which enables\nit to benefit from large monolingual English caption datasets. Experimental\nresults demonstrate that our approach outperforms the state-of-the-art methods\non common evaluation metrics. The attention visualization also shows that the\nproposed approach really improves the fine-grained alignment between words and\nimage regions.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 12:15:35 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Wu", "Yike", ""], ["Zhao", "Shiwan", ""], ["Chen", "Jia", ""], ["Zhang", "Ying", ""], ["Yuan", "Xiaojie", ""], ["Su", "Zhong", ""]]}, {"id": "1908.07816", "submitter": "Yubo Xie", "authors": "Yubo Xie, Ekaterina Svikhnushina, Pearl Pu", "title": "A Multi-Turn Emotionally Engaging Dialog Model", "comments": "Accepted to IUI 2020 user2agent workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-domain dialog systems (also known as chatbots) have increasingly drawn\nattention in natural language processing. Some of the recent work aims at\nincorporating affect information into sequence-to-sequence neural dialog\nmodeling, making the response emotionally richer, while others use hand-crafted\nrules to determine the desired emotion response. However, they do not\nexplicitly learn the subtle emotional interactions captured in human dialogs.\nIn this paper, we propose a multi-turn dialog system aimed at learning and\ngenerating emotional responses that so far only humans know how to do. Compared\nwith two baseline models, offline experiments show that our method performs the\nbest in perplexity scores. Further human evaluations confirm that our chatbot\ncan keep track of the conversation context and generate emotionally more\nappropriate responses while performing equally well on grammar.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 12:52:53 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 17:00:07 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 16:30:45 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Xie", "Yubo", ""], ["Svikhnushina", "Ekaterina", ""], ["Pu", "Pearl", ""]]}, {"id": "1908.07817", "submitter": "Zhengxuan Wu", "authors": "Zhengxuan Wu and Yueyi Jiang", "title": "Disentangling Latent Emotions of Word Embeddings on Complex Emotional\n  Narratives", "comments": "9 pages, submitted and accepted by NLP conference 2019", "journal-ref": "NLPCC2019", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding models such as GloVe are widely used in natural language\nprocessing (NLP) research to convert words into vectors. Here, we provide a\npreliminary guide to probe latent emotions in text through GloVe word vectors.\nFirst, we trained a neural network model to predict continuous emotion valence\nratings by taking linguistic inputs from Stanford Emotional Narratives Dataset\n(SEND). After interpreting the weights in the model, we found that only a few\ndimensions of the word vectors contributed to expressing emotions in text, and\nwords were clustered on the basis of their emotional polarities. Furthermore,\nwe performed a linear transformation that projected high dimensional embedded\nvectors into an emotion space. Based on NRC Emotion Lexicon (EmoLex), we\nvisualized the entanglement of emotions in the lexicon by using both projected\nand raw GloVe word vectors. We showed that, in the proposed emotion space, we\nwere able to better disentangle emotions than using raw GloVe vectors alone. In\naddition, we found that the sum vectors of different pairs of emotion words\nsuccessfully captured expressed human feelings in the EmoLex. For example, the\nsum of two embedded word vectors expressing Joy and Trust which express Love\nshared high similarity (similarity score .62) with the embedded vector\nexpressing Optimism. On the contrary, this sum vector was dissimilar\n(similarity score -.19) with the the embedded vector expressing Remorse. In\nthis paper, we argue that through the proposed emotion space, arithmetic of\nemotions is preserved in the word vectors. The affective representation\nuncovered in emotion vector space could shed some light on how to help machines\nto disentangle emotion expressed in word embeddings.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 11:05:45 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Wu", "Zhengxuan", ""], ["Jiang", "Yueyi", ""]]}, {"id": "1908.07818", "submitter": "Shibamouli Lahiri", "authors": "Shibamouli Lahiri", "title": "Replication of the Keyword Extraction part of the paper \"'Without the\n  Clutter of Unimportant Words': Descriptive Keyphrases for Text Visualization\"", "comments": "36 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Keyword Extraction\" refers to the task of automatically identifying the most\nrelevant and informative phrases in natural language text. As we are deluged\nwith large amounts of text data in many different forms and content - emails,\nblogs, tweets, Facebook posts, academic papers, news articles - the task of\n\"making sense\" of all this text by somehow summarizing them into a coherent\nstructure assumes paramount importance. Keyword extraction - a well-established\nproblem in Natural Language Processing - can help us here. In this report, we\nconstruct and test three different hypotheses (all related to the task of\nkeyword extraction) that take us one step closer to understanding how to\nmeaningfully identify and extract \"descriptive\" keyphrases. The work reported\nhere was done as part of replicating the study by Chuang et al. [3].\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 04:09:12 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Lahiri", "Shibamouli", ""]]}, {"id": "1908.07819", "submitter": "Mahsa Shafaei", "authors": "Mahsa Shafaei and Niloofar Safi Samghabadi and Sudipta Kar and Thamar\n  Solorio", "title": "Rating for Parents: Predicting Children Suitability Rating for Movies\n  Based on Language of the Movies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The film culture has grown tremendously in recent years. The large number of\nstreaming services put films as one of the most convenient forms of\nentertainment in today's world. Films can help us learn and inspire societal\nchange. But they can also negatively affect viewers. In this paper, our goal is\nto predict the suitability of the movie content for children and young adults\nbased on scripts. The criterion that we use to measure suitability is the MPAA\nrating that is specifically designed for this purpose. We propose an RNN based\narchitecture with attention that jointly models the genre and the emotions in\nthe script to predict the MPAA rating. We achieve 78% weighted F1-score for the\nclassification model that outperforms the traditional machine learning method\nby 6%.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 15:18:10 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 02:00:11 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Shafaei", "Mahsa", ""], ["Samghabadi", "Niloofar Safi", ""], ["Kar", "Sudipta", ""], ["Solorio", "Thamar", ""]]}, {"id": "1908.07820", "submitter": "XiaoKang Liu", "authors": "Jianquan Li, Xiaokang Liu, Wenpeng Yin, Min Yang, Liqun Ma, Yaohong\n  Jin", "title": "Empirical Evaluation of Multi-task Learning in Deep Neural Networks for\n  Natural Language Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Task Learning (MTL) aims at boosting the overall performance of each\nindividual task by leveraging useful information contained in multiple related\ntasks. It has shown great success in natural language processing (NLP).\nCurrently, a number of MLT architectures and learning mechanisms have been\nproposed for various NLP tasks. However, there is no systematic exploration and\ncomparison of different MLT architectures and learning mechanisms for their\nstrong performance in-depth. In this paper, we conduct a thorough examination\nof typical MTL methods on a broad range of representative NLP tasks. Our\nprimary goal is to understand the merits and demerits of existing MTL methods\nin NLP tasks, thus devising new hybrid architectures intended to combine their\nstrengths.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 03:16:40 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 08:06:18 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Li", "Jianquan", ""], ["Liu", "Xiaokang", ""], ["Yin", "Wenpeng", ""], ["Yang", "Min", ""], ["Ma", "Liqun", ""], ["Jin", "Yaohong", ""]]}, {"id": "1908.07822", "submitter": "Shining Liang", "authors": "Shining Liang, Wanli Zuo, Zhenkun Shi, Sen Wang, Junhu Wang, Xianglin\n  Zuo", "title": "A Multi-level Neural Network for Implicit Causality Detection in Web\n  Texts", "comments": "31 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Mining causality from text is a complex and crucial natural language\nunderstanding task corresponding to the human cognition. Existing studies at\nits solution can be grouped into two primary categories: feature engineering\nbased and neural model based methods. In this paper, we find that the former\nhas incomplete coverage and inherent errors but provide prior knowledge; while\nthe latter leverages context information but causal inference of which is\ninsufficiency. To handle the limitations, we propose a novel causality\ndetection model named MCDN to explicitly model causal reasoning process, and\nfurthermore, to exploit the advantages of both methods. Specifically, we adopt\nmulti-head self-attention to acquire semantic feature at word level and develop\nthe SCRN to infer causality at segment level. To the best of our knowledge,\nwith regards to the causality tasks, this is the first time that the Relation\nNetwork is applied. The experimental results show that: 1) the proposed\napproach performs prominent performance on causality detection; 2) further\nanalysis manifests the effectiveness and robustness of MCDN.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 10:34:59 GMT"}, {"version": "v2", "created": "Sun, 8 Sep 2019 02:29:09 GMT"}, {"version": "v3", "created": "Thu, 27 May 2021 16:33:15 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Liang", "Shining", ""], ["Zuo", "Wanli", ""], ["Shi", "Zhenkun", ""], ["Wang", "Sen", ""], ["Wang", "Junhu", ""], ["Zuo", "Xianglin", ""]]}, {"id": "1908.07831", "submitter": "Hong-Ren Mao", "authors": "Hongren Mao, Hung-yi Lee", "title": "Polly Want a Cracker: Analyzing Performance of Parroting on Paraphrase\n  Generation Datasets", "comments": "Accepted for EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Paraphrase generation is an interesting and challenging NLP task which has\nnumerous practical applications. In this paper, we analyze datasets commonly\nused for paraphrase generation research, and show that simply parroting input\nsentences surpasses state-of-the-art models in the literature when evaluated on\nstandard metrics. Our findings illustrate that a model could be seemingly adept\nat generating paraphrases, despite only making trivial changes to the input\nsentence or even none at all.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 05:40:42 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Mao", "Hongren", ""], ["Lee", "Hung-yi", ""]]}, {"id": "1908.07832", "submitter": "Ahmed El-Kishky", "authors": "Ahmed El-Kishky, Frank Xu, Aston Zhang, Jiawei Han", "title": "Parsimonious Morpheme Segmentation with an Application to Enriching Word\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, many text-mining tasks treat individual word-tokens as the\nfinest meaningful semantic granularity. However, in many languages and\nspecialized corpora, words are composed by concatenating semantically\nmeaningful subword structures. Word-level analysis cannot leverage the semantic\ninformation present in such subword structures. With regard to word embedding\ntechniques, this leads to not only poor embeddings for infrequent words in\nlong-tailed text corpora but also weak capabilities for handling\nout-of-vocabulary words. In this paper we propose MorphMine for unsupervised\nmorpheme segmentation. MorphMine applies a parsimony criterion to\nhierarchically segment words into the fewest number of morphemes at each level\nof the hierarchy. This leads to longer shared morphemes at each level of\nsegmentation. Experiments show that MorphMine segments words in a variety of\nlanguages into human-verified morphemes. Additionally, we experimentally\ndemonstrate that utilizing MorphMine morphemes to enrich word embeddings\nconsistently improves embedding quality on a variety of of embedding\nevaluations and a downstream language modeling task.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 00:45:16 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 22:18:44 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["El-Kishky", "Ahmed", ""], ["Xu", "Frank", ""], ["Zhang", "Aston", ""], ["Han", "Jiawei", ""]]}, {"id": "1908.07836", "submitter": "Antonio Jose Jimeno Yepes", "authors": "Xu Zhong, Jianbin Tang, Antonio Jimeno Yepes", "title": "PubLayNet: largest dataset ever for document layout analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing the layout of unstructured digital documents is an important step\nwhen parsing the documents into structured machine-readable format for\ndownstream applications. Deep neural networks that are developed for computer\nvision have been proven to be an effective method to analyze layout of document\nimages. However, document layout datasets that are currently publicly available\nare several magnitudes smaller than established computing vision datasets.\nModels have to be trained by transfer learning from a base model that is\npre-trained on a traditional computer vision dataset. In this paper, we develop\nthe PubLayNet dataset for document layout analysis by automatically matching\nthe XML representations and the content of over 1 million PDF articles that are\npublicly available on PubMed Central. The size of the dataset is comparable to\nestablished computer vision datasets, containing over 360 thousand document\nimages, where typical document layout elements are annotated. The experiments\ndemonstrate that deep neural networks trained on PubLayNet accurately recognize\nthe layout of scientific articles. The pre-trained models are also a more\neffective base mode for transfer learning on a different document domain. We\nrelease the dataset (https://github.com/ibm-aur-nlp/PubLayNet) to support\ndevelopment and evaluation of more advanced models for document layout\nanalysis.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 00:40:08 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Zhong", "Xu", ""], ["Tang", "Jianbin", ""], ["Yepes", "Antonio Jimeno", ""]]}, {"id": "1908.07844", "submitter": "Benedikt Boenninghoff", "authors": "Benedikt Boenninghoff, Robert M. Nickel, Steffen Zeiler, Dorothea\n  Kolossa", "title": "Similarity Learning for Authorship Verification in Social Media", "comments": "5 pages, 3 figures, 1 table, presented on ICASSP 2019 in Brighton, UK", "journal-ref": null, "doi": "10.1109/ICASSP.2019.8683405", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authorship verification tries to answer the question if two documents with\nunknown authors were written by the same author or not. A range of successful\ntechnical approaches has been proposed for this task, many of which are based\non traditional linguistic features such as n-grams. These algorithms achieve\ngood results for certain types of written documents like books and novels.\nForensic authorship verification for social media, however, is a much more\nchallenging task since messages tend to be relatively short, with a large\nvariety of different genres and topics. At this point, traditional methods\nbased on features like n-grams have had limited success. In this work, we\npropose a new neural network topology for similarity learning that\nsignificantly improves the performance on the author verification task with\nsuch challenging data sets.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 04:08:58 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Boenninghoff", "Benedikt", ""], ["Nickel", "Robert M.", ""], ["Zeiler", "Steffen", ""], ["Kolossa", "Dorothea", ""]]}, {"id": "1908.07846", "submitter": "Stephen Petrie Dr", "authors": "Stephen M. Petrie and T'Mir D. Julius", "title": "Representing text as abstract images enables image classifiers to also\n  simultaneously classify text", "comments": "Minor changes in order to submit paper to a different conference\n  (e.g. made minor changes to writing in several places and added extra data to\n  Table 3 in order to make it clearer)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel method for converting text data into abstract image\nrepresentations, which allows image-based processing techniques (e.g. image\nclassification networks) to be applied to text-based comparison problems. We\napply the technique to entity disambiguation of inventor names in US patents.\nThe method involves converting text from each pairwise comparison between two\ninventor name records into a 2D RGB (stacked) image representation. We then\ntrain an image classification neural network to discriminate between such\npairwise comparison images, and use the trained network to label each pair of\nrecords as either matched (same inventor) or non-matched (different inventors),\nobtaining highly accurate results. Our new text-to-image representation method\ncould also be used more broadly for other NLP comparison problems, such as\ndisambiguation of academic publications, or for problems that require\nsimultaneous classification of both text and image datasets.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 17:28:29 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 08:39:41 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2020 07:28:03 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Petrie", "Stephen M.", ""], ["Julius", "T'Mir D.", ""]]}, {"id": "1908.07855", "submitter": "Gong Cheng", "authors": "Zixian Huang, Yulin Shen, Xiao Li, Yuang Wei, Gong Cheng, Lin Zhou,\n  Xinyu Dai, Yuzhong Qu", "title": "GeoSQA: A Benchmark for Scenario-based Question Answering in the\n  Geography Domain at High School Level", "comments": "6 pages, to appear at the 2019 Conference on Empirical Methods in\n  Natural Language Processing and 9th International Joint Conference on Natural\n  Language Processing (EMNLP-IJCNLP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Scenario-based question answering (SQA) has attracted increasing research\nattention. It typically requires retrieving and integrating knowledge from\nmultiple sources, and applying general knowledge to a specific case described\nby a scenario. SQA widely exists in the medical, geography, and legal\ndomains---both in practice and in the exams. In this paper, we introduce the\nGeoSQA dataset. It consists of 1,981 scenarios and 4,110 multiple-choice\nquestions in the geography domain at high school level, where diagrams (e.g.,\nmaps, charts) have been manually annotated with natural language descriptions\nto benefit NLP research. Benchmark results on a variety of state-of-the-art\nmethods for question answering, textual entailment, and reading comprehension\ndemonstrate the unique challenges presented by SQA for future research.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 15:11:06 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Huang", "Zixian", ""], ["Shen", "Yulin", ""], ["Li", "Xiao", ""], ["Wei", "Yuang", ""], ["Cheng", "Gong", ""], ["Zhou", "Lin", ""], ["Dai", "Xinyu", ""], ["Qu", "Yuzhong", ""]]}, {"id": "1908.07888", "submitter": "Piotr \\.Zelasko", "authors": "Piotr \\.Zelasko, Jan Mizgajski, Miko{\\l}aj Morzy, Adrian Szymczak,\n  Piotr Szyma\\'nski, {\\L}ukasz Augustyniak, Yishay Carmiel", "title": "Towards Better Understanding of Spontaneous Conversations: Overcoming\n  Automatic Speech Recognition Errors With Intent Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a method for correcting automatic speech\nrecognition (ASR) errors using a finite state transducer (FST) intent\nrecognition framework. Intent recognition is a powerful technique for dialog\nflow management in turn-oriented, human-machine dialogs. This technique can\nalso be very useful in the context of human-human dialogs, though it serves a\ndifferent purpose of key insight extraction from conversations. We argue that\ncurrently available intent recognition techniques are not applicable to\nhuman-human dialogs due to the complex structure of turn-taking and various\ndisfluencies encountered in spontaneous conversations, exacerbated by speech\nrecognition errors and scarcity of domain-specific labeled data. Without\nefficient key insight extraction techniques, raw human-human dialog transcripts\nremain significantly unexploited.\n  Our contribution consists of a novel FST for intent indexing and an algorithm\nfor fuzzy intent search over the lattice - a compact graph encoding of ASR's\nhypotheses. We also develop a pruning strategy to constrain the fuzziness of\nthe FST index search. Extracted intents represent linguistic domain knowledge\nand help us improve (rescore) the original transcript. We compare our method\nwith a baseline, which uses only the most likely transcript hypothesis (best\npath), and find an increase in the total number of recognized intents by 25%.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 14:20:35 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["\u017belasko", "Piotr", ""], ["Mizgajski", "Jan", ""], ["Morzy", "Miko\u0142aj", ""], ["Szymczak", "Adrian", ""], ["Szyma\u0144ski", "Piotr", ""], ["Augustyniak", "\u0141ukasz", ""], ["Carmiel", "Yishay", ""]]}, {"id": "1908.07898", "submitter": "Mor Geva", "authors": "Mor Geva, Yoav Goldberg and Jonathan Berant", "title": "Are We Modeling the Task or the Annotator? An Investigation of Annotator\n  Bias in Natural Language Understanding Datasets", "comments": "EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsourcing has been the prevalent paradigm for creating natural language\nunderstanding datasets in recent years. A common crowdsourcing practice is to\nrecruit a small number of high-quality workers, and have them massively\ngenerate examples. Having only a few workers generate the majority of examples\nraises concerns about data diversity, especially when workers freely generate\nsentences. In this paper, we perform a series of experiments showing these\nconcerns are evident in three recent NLP datasets. We show that model\nperformance improves when training with annotator identifiers as features, and\nthat models are able to recognize the most productive annotators. Moreover, we\nshow that often models do not generalize well to examples from annotators that\ndid not contribute to the training set. Our findings suggest that annotator\nbias should be monitored during dataset creation, and that test set annotators\nshould be disjoint from training set annotators.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 14:48:01 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 15:55:37 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Geva", "Mor", ""], ["Goldberg", "Yoav", ""], ["Berant", "Jonathan", ""]]}, {"id": "1908.07899", "submitter": "Tobias Hinz", "authors": "Marcus Soll, Tobias Hinz, Sven Magg, Stefan Wermter", "title": "Evaluating Defensive Distillation For Defending Text Processing Neural\n  Networks Against Adversarial Examples", "comments": "Published at the International Conference on Artificial Neural\n  Networks (ICANN) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are artificially modified input samples which lead to\nmisclassifications, while not being detectable by humans. These adversarial\nexamples are a challenge for many tasks such as image and text classification,\nespecially as research shows that many adversarial examples are transferable\nbetween different classifiers. In this work, we evaluate the performance of a\npopular defensive strategy for adversarial examples called defensive\ndistillation, which can be successful in hardening neural networks against\nadversarial examples in the image domain. However, instead of applying\ndefensive distillation to networks for image classification, we examine, for\nthe first time, its performance on text classification tasks and also evaluate\nits effect on the transferability of adversarial text examples. Our results\nindicate that defensive distillation only has a minimal impact on text\nclassifying neural networks and does neither help with increasing their\nrobustness against adversarial examples nor prevent the transferability of\nadversarial examples between neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 14:50:13 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Soll", "Marcus", ""], ["Hinz", "Tobias", ""], ["Magg", "Sven", ""], ["Wermter", "Stefan", ""]]}, {"id": "1908.07912", "submitter": "Preslav Nakov", "authors": "Slavena Vasileva, Pepa Atanasova, Llu\\'is M\\`arquez, Alberto\n  Barr\\'on-Cede\\~no, Preslav Nakov", "title": "It Takes Nine to Smell a Rat: Neural Multi-Task Learning for\n  Check-Worthiness Prediction", "comments": "Check-worthiness; Fact-Checking; Veracity; Multi-task Learning;\n  Neural Networks. arXiv admin note: text overlap with arXiv:1908.01328", "journal-ref": "RANLP-2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a multi-task deep-learning approach for estimating the\ncheck-worthiness of claims in political debates. Given a political debate, such\nas the 2016 US Presidential and Vice-Presidential ones, the task is to predict\nwhich statements in the debate should be prioritized for fact-checking. While\ndifferent fact-checking organizations would naturally make different choices\nwhen analyzing the same debate, we show that it pays to learn from multiple\nsources simultaneously (PolitiFact, FactCheck, ABC, CNN, NPR, NYT, Chicago\nTribune, The Guardian, and Washington Post) in a multi-task learning setup,\neven when a particular source is chosen as a target to imitate. Our evaluation\nshows state-of-the-art results on a standard dataset for the task of\ncheck-worthiness prediction.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 19:52:50 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Vasileva", "Slavena", ""], ["Atanasova", "Pepa", ""], ["M\u00e0rquez", "Llu\u00eds", ""], ["Barr\u00f3n-Cede\u00f1o", "Alberto", ""], ["Nakov", "Preslav", ""]]}, {"id": "1908.08025", "submitter": "Vid Kocijan", "authors": "Vid Kocijan, Oana-Maria Camburu, Ana-Maria Cretu, Yordan Yordanov,\n  Phil Blunsom, Thomas Lukasiewicz", "title": "WikiCREM: A Large Unsupervised Corpus for Coreference Resolution", "comments": "Accepted to the EMNLP 2019 conference", "journal-ref": "IJCNLP-EMNLP 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pronoun resolution is a major area of natural language understanding.\nHowever, large-scale training sets are still scarce, since manually labelling\ndata is costly. In this work, we introduce WikiCREM (Wikipedia CoREferences\nMasked) a large-scale, yet accurate dataset of pronoun disambiguation\ninstances. We use a language-model-based approach for pronoun resolution in\ncombination with our WikiCREM dataset. We compare a series of models on a\ncollection of diverse and challenging coreference resolution problems, where we\nmatch or outperform previous state-of-the-art approaches on 6 out of 7\ndatasets, such as GAP, DPR, WNLI, PDP, WinoBias, and WinoGender. We release our\nmodel to be used off-the-shelf for solving pronoun disambiguation.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 17:42:03 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 08:49:57 GMT"}, {"version": "v3", "created": "Sun, 13 Oct 2019 17:48:41 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Kocijan", "Vid", ""], ["Camburu", "Oana-Maria", ""], ["Cretu", "Ana-Maria", ""], ["Yordanov", "Yordan", ""], ["Blunsom", "Phil", ""], ["Lukasiewicz", "Thomas", ""]]}, {"id": "1908.08039", "submitter": "Wu Xing", "authors": "Xing Wu, Tao Zhang, Liangjun Zang, Jizhong Han and Songlin Hu", "title": "\"Mask and Infill\" : Applying Masked Language Model to Sentiment Transfer", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the task of sentiment transfer on non-parallel text,\nwhich modifies sentiment attributes (e.g., positive or negative) of sentences\nwhile preserving their attribute-independent content. Due to the limited\ncapability of RNNbased encoder-decoder structure to capture deep and long-range\ndependencies among words, previous works can hardly generate satisfactory\nsentences from scratch. When humans convert the sentiment attribute of a\nsentence, a simple but effective approach is to only replace the original\nsentimental tokens in the sentence with target sentimental expressions, instead\nof building a new sentence from scratch. Such a process is very similar to the\ntask of Text Infilling or Cloze, which could be handled by a deep bidirectional\nMasked Language Model (e.g. BERT). So we propose a two step approach \"Mask and\nInfill\". In the mask step, we separate style from content by masking the\npositions of sentimental tokens. In the infill step, we retrofit MLM to\nAttribute Conditional MLM, to infill the masked positions by predicting words\nor phrases conditioned on the context1 and target sentiment. We evaluate our\nmodel on two review datasets with quantitative, qualitative, and human\nevaluations. Experimental results demonstrate that our models improve\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 23:12:36 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Wu", "Xing", ""], ["Zhang", "Tao", ""], ["Zang", "Liangjun", ""], ["Han", "Jizhong", ""], ["Hu", "Songlin", ""]]}, {"id": "1908.08104", "submitter": "Mustafa Canim", "authors": "Sarthak Dash, Michael R. Glass, Alfio Gliozzo, Mustafa Canim", "title": "Populating Web Scale Knowledge Graphs using Distantly Supervised\n  Relation Extraction and Validation", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a fully automated system to extend knowledge graphs\nusing external information from web-scale corpora. The designed system\nleverages a deep learning based technology for relation extraction that can be\ntrained by a distantly supervised approach. In addition to that, the system\nuses a deep learning approach for knowledge base completion by utilizing the\nglobal structure information of the induced KG to further refine the confidence\nof the newly discovered relations. The designed system does not require any\neffort for adaptation to new languages and domains as it does not use any\nhand-labeled data, NLP analytics and inference rules. Our experiments,\nperformed on a popular academic benchmark demonstrate that the suggested system\nboosts the performance of relation extraction by a wide margin, reporting error\nreductions of 50%, resulting in relative improvement of up to 100%. Also, a\nweb-scale experiment conducted to extend DBPedia with knowledge from Common\nCrawl shows that our system is not only scalable but also does not require any\nadaptation cost, while yielding substantial accuracy gain.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 20:13:44 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 03:13:28 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Dash", "Sarthak", ""], ["Glass", "Michael R.", ""], ["Gliozzo", "Alfio", ""], ["Canim", "Mustafa", ""]]}, {"id": "1908.08113", "submitter": "Yi Mao", "authors": "Pengcheng He, Yi Mao, Kaushik Chakrabarti, Weizhu Chen", "title": "X-SQL: reinforce schema representation with context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present X-SQL, a new network architecture for the problem of\nparsing natural language to SQL query. X-SQL proposes to enhance the structural\nschema representation with the contextual output from BERT-style pre-training\nmodel, and together with type information to learn a new schema representation\nfor down-stream tasks. We evaluated X-SQL on the WikiSQL dataset and show its\nnew state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 20:52:53 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["He", "Pengcheng", ""], ["Mao", "Yi", ""], ["Chakrabarti", "Kaushik", ""], ["Chen", "Weizhu", ""]]}, {"id": "1908.08167", "submitter": "Zhiguo Wang", "authors": "Zhiguo Wang, Patrick Ng, Xiaofei Ma, Ramesh Nallapati, Bing Xiang", "title": "Multi-passage BERT: A Globally Normalized BERT Model for Open-domain\n  Question Answering", "comments": "To appear in EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  BERT model has been successfully applied to open-domain QA tasks. However,\nprevious work trains BERT by viewing passages corresponding to the same\nquestion as independent training instances, which may cause incomparable scores\nfor answers from different passages. To tackle this issue, we propose a\nmulti-passage BERT model to globally normalize answer scores across all\npassages of the same question, and this change enables our QA model find better\nanswers by utilizing more passages. In addition, we find that splitting\narticles into passages with the length of 100 words by sliding window improves\nperformance by 4%. By leveraging a passage ranker to select high-quality\npassages, multi-passage BERT gains additional 2%. Experiments on four standard\nbenchmarks showed that our multi-passage BERT outperforms all state-of-the-art\nmodels on all benchmarks. In particular, on the OpenSQuAD dataset, our model\ngains 21.4% EM and 21.5% $F_1$ over all non-BERT models, and 5.8% EM and 6.5%\n$F_1$ over BERT-based models.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 02:00:53 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 02:28:53 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Wang", "Zhiguo", ""], ["Ng", "Patrick", ""], ["Ma", "Xiaofei", ""], ["Nallapati", "Ramesh", ""], ["Xiang", "Bing", ""]]}, {"id": "1908.08191", "submitter": "Chao-Chun Hsu", "authors": "Kuan-Yen Lin, Chao-Chun Hsu, Yun-Nung Chen, Lun-Wei Ku", "title": "Entropy-Enhanced Multimodal Attention Model for Scene-Aware Dialogue\n  Generation", "comments": "DSTC7 collocated with AAAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With increasing information from social media, there are more and more videos\navailable. Therefore, the ability to reason on a video is important and\ndeserves to be discussed. TheDialog System Technology Challenge (DSTC7)\n(Yoshino et al. 2018) proposed an Audio Visual Scene-aware Dialog (AVSD) task,\nwhich contains five modalities including video, dialogue history, summary, and\ncaption, as a scene-aware environment. In this paper, we propose the\nentropy-enhanced dynamic memory network (DMN) to effectively model video\nmodality. The attention-based GRU in the proposed model can improve the model's\nability to comprehend and memorize sequential information. The entropy\nmechanism can control the attention distribution higher, so each to-be-answered\nquestion can focus more specifically on a small set of video segments. After\nthe entropy-enhanced DMN secures the video context, we apply an attention model\nthat in-corporates summary and caption to generate an accurate answer given the\nquestion about the video. In the official evaluation, our system can achieve\nimproved performance against the released baseline model for both subjective\nand objective evaluation metrics.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 03:53:36 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Lin", "Kuan-Yen", ""], ["Hsu", "Chao-Chun", ""], ["Chen", "Yun-Nung", ""], ["Ku", "Lun-Wei", ""]]}, {"id": "1908.08206", "submitter": "Liang Wang", "authors": "Liang Wang, Wei Zhao, Ruoyu Jia, Sujian Li, Jingming Liu", "title": "Denoising based Sequence-to-Sequence Pre-training for Text Generation", "comments": "Accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a new sequence-to-sequence (seq2seq) pre-training method\nPoDA (Pre-training of Denoising Autoencoders), which learns representations\nsuitable for text generation tasks. Unlike encoder-only (e.g., BERT) or\ndecoder-only (e.g., OpenAI GPT) pre-training approaches, PoDA jointly\npre-trains both the encoder and decoder by denoising the noise-corrupted text,\nand it also has the advantage of keeping the network architecture unchanged in\nthe subsequent fine-tuning stage. Meanwhile, we design a hybrid model of\nTransformer and pointer-generator networks as the backbone architecture for\nPoDA. We conduct experiments on two text generation tasks: abstractive\nsummarization, and grammatical error correction. Results on four datasets show\nthat PoDA can improve model performance over strong baselines without using any\ntask-specific techniques and significantly speed up convergence.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 05:26:25 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Wang", "Liang", ""], ["Zhao", "Wei", ""], ["Jia", "Ruoyu", ""], ["Li", "Sujian", ""], ["Liu", "Jingming", ""]]}, {"id": "1908.08210", "submitter": "Yuting Wu", "authors": "Yuting Wu, Xiao Liu, Yansong Feng, Zheng Wang, Rui Yan and Dongyan\n  Zhao", "title": "Relation-Aware Entity Alignment for Heterogeneous Knowledge Graphs", "comments": "Accepted by IJCAI 2019", "journal-ref": null, "doi": "10.24963/ijcai.2019/733", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity alignment is the task of linking entities with the same real-world\nidentity from different knowledge graphs (KGs), which has been recently\ndominated by embedding-based methods. Such approaches work by learning KG\nrepresentations so that entity alignment can be performed by measuring the\nsimilarities between entity embeddings. While promising, prior works in the\nfield often fail to properly capture complex relation information that commonly\nexists in multi-relational KGs, leaving much room for improvement. In this\npaper, we propose a novel Relation-aware Dual-Graph Convolutional Network\n(RDGCN) to incorporate relation information via attentive interactions between\nthe knowledge graph and its dual relation counterpart, and further capture\nneighboring structures to learn better entity representations. Experiments on\nthree real-world cross-lingual datasets show that our approach delivers better\nand more robust results over the state-of-the-art alignment methods by learning\nbetter KG representations.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 05:45:30 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Wu", "Yuting", ""], ["Liu", "Xiao", ""], ["Feng", "Yansong", ""], ["Wang", "Zheng", ""], ["Yan", "Rui", ""], ["Zhao", "Dongyan", ""]]}, {"id": "1908.08326", "submitter": "Huilin Gao", "authors": "Tong Guo, Huilin Gao", "title": "Revisiting Semantic Representation and Tree Search for Similar Question\n  Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the performances of BERT combined with tree structure in\nshort sentence ranking task. In retrieval-based question answering system, we\nretrieve the most similar question of the query question by ranking all the\nquestions in datasets. If we want to rank all the sentences by neural rankers,\nwe need to score all the sentence pairs. However it consumes large amount of\ntime. So we design a specific tree for searching and combine deep model to\nsolve this problem. We fine-tune BERT on the training data to get semantic\nvector or sentence embeddings on the test data. We use all the sentence\nembeddings of test data to build our tree based on k-means and do beam search\nat predicting time when given a sentence as query. We do the experiments on the\nsemantic textual similarity dataset, Quora Question Pairs, and process the\ndataset for sentence ranking. Experimental results show that our methods\noutperform the strong baseline. Our tree accelerate the predicting speed by\n500%-1000% without losing too much ranking accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 11:44:12 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 07:58:20 GMT"}, {"version": "v3", "created": "Mon, 26 Aug 2019 03:36:21 GMT"}, {"version": "v4", "created": "Tue, 27 Aug 2019 08:34:27 GMT"}, {"version": "v5", "created": "Thu, 29 Aug 2019 08:40:09 GMT"}, {"version": "v6", "created": "Fri, 30 Aug 2019 07:33:00 GMT"}, {"version": "v7", "created": "Tue, 3 Sep 2019 01:10:42 GMT"}, {"version": "v8", "created": "Fri, 6 Sep 2019 09:02:30 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Guo", "Tong", ""], ["Gao", "Huilin", ""]]}, {"id": "1908.08336", "submitter": "Yonatan Bilu", "authors": "Yonatan Bilu, Ariel Gera, Daniel Hershcovich, Benjamin Sznajder, Dan\n  Lahav, Guy Moshkowich, Anael Malet, Assaf Gavron, Noam Slonim", "title": "Argument Invention from First Principles", "comments": "Presented at ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Competitive debaters often find themselves facing a challenging task -- how\nto debate a topic they know very little about, with only minutes to prepare,\nand without access to books or the Internet? What they often do is rely on\n\"first principles\", commonplace arguments which are relevant to many topics,\nand which they have refined in past debates.\n  In this work we aim to explicitly define a taxonomy of such principled\nrecurring arguments, and, given a controversial topic, to automatically\nidentify which of these arguments are relevant to the topic.\n  As far as we know, this is the first time that this approach to argument\ninvention is formalized and made explicit in the context of NLP.\n  The main goal of this work is to show that it is possible to define such a\ntaxonomy. While the taxonomy suggested here should be thought of as a \"first\nattempt\" it is nonetheless coherent, covers well the relevant topics and\ncoincides with what professional debaters actually argue in their speeches, and\nfacilitates automatic argument invention for new topics.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 12:36:58 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Bilu", "Yonatan", ""], ["Gera", "Ariel", ""], ["Hershcovich", "Daniel", ""], ["Sznajder", "Benjamin", ""], ["Lahav", "Dan", ""], ["Moshkowich", "Guy", ""], ["Malet", "Anael", ""], ["Gavron", "Assaf", ""], ["Slonim", "Noam", ""]]}, {"id": "1908.08345", "submitter": "Yang Liu", "authors": "Yang Liu and Mirella Lapata", "title": "Text Summarization with Pretrained Encoders", "comments": "fix typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bidirectional Encoder Representations from Transformers (BERT) represents the\nlatest incarnation of pretrained language models which have recently advanced a\nwide range of natural language processing tasks. In this paper, we showcase how\nBERT can be usefully applied in text summarization and propose a general\nframework for both extractive and abstractive models. We introduce a novel\ndocument-level encoder based on BERT which is able to express the semantics of\na document and obtain representations for its sentences. Our extractive model\nis built on top of this encoder by stacking several inter-sentence Transformer\nlayers. For abstractive summarization, we propose a new fine-tuning schedule\nwhich adopts different optimizers for the encoder and the decoder as a means of\nalleviating the mismatch between the two (the former is pretrained while the\nlatter is not). We also demonstrate that a two-staged fine-tuning approach can\nfurther boost the quality of the generated summaries. Experiments on three\ndatasets show that our model achieves state-of-the-art results across the board\nin both extractive and abstractive settings. Our code is available at\nhttps://github.com/nlpyang/PreSumm\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 12:59:40 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 12:04:19 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Liu", "Yang", ""], ["Lapata", "Mirella", ""]]}, {"id": "1908.08351", "submitter": "Dieuwke Hupkes", "authors": "Dieuwke Hupkes, Verna Dankers, Mathijs Mul, Elia Bruni", "title": "Compositionality decomposed: how do neural networks generalise?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite a multitude of empirical studies, little consensus exists on whether\nneural networks are able to generalise compositionally, a controversy that, in\npart, stems from a lack of agreement about what it means for a neural model to\nbe compositional. As a response to this controversy, we present a set of tests\nthat provide a bridge between, on the one hand, the vast amount of linguistic\nand philosophical theory about compositionality of language and, on the other,\nthe successful neural models of language. We collect different interpretations\nof compositionality and translate them into five theoretically grounded tests\nfor models that are formulated on a task-independent level. In particular, we\nprovide tests to investigate (i) if models systematically recombine known parts\nand rules (ii) if models can extend their predictions beyond the length they\nhave seen in the training data (iii) if models' composition operations are\nlocal or global (iv) if models' predictions are robust to synonym substitutions\nand (v) if models favour rules or exceptions during training. To demonstrate\nthe usefulness of this evaluation paradigm, we instantiate these five tests on\na highly compositional data set which we dub PCFG SET and apply the resulting\ntests to three popular sequence-to-sequence models: a recurrent, a\nconvolution-based and a transformer model. We provide an in-depth analysis of\nthe results, which uncover the strengths and weaknesses of these three\narchitectures and point to potential areas of improvement.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 13:08:26 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 15:42:10 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Hupkes", "Dieuwke", ""], ["Dankers", "Verna", ""], ["Mul", "Mathijs", ""], ["Bruni", "Elia", ""]]}, {"id": "1908.08399", "submitter": "Fengshun Xiao", "authors": "Zuchao Li, Hai Zhao, Yingting Wu, Fengshun Xiao, Shu Jiang", "title": "Controllable Dual Skew Divergence Loss for Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In sequence prediction tasks like neural machine translation, training with\ncross-entropy loss often leads to models that overgeneralize and plunge into\nlocal optima. In this paper, we propose an extended loss function called\n\\emph{dual skew divergence} (DSD) that integrates two symmetric terms on KL\ndivergences with a balanced weight. We empirically discovered that such a\nbalanced weight plays a crucial role in applying the proposed DSD loss into\ndeep models. Thus we eventually develop a controllable DSD loss for\ngeneral-purpose scenarios. Our experiments indicate that switching to the DSD\nloss after the convergence of ML training helps models escape local optima and\nstimulates stable performance improvements. Our evaluations on the WMT 2014\nEnglish-German and English-French translation tasks demonstrate that the\nproposed loss as a general and convenient mean for NMT training indeed brings\nperformance improvement in comparison to strong baselines.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 14:16:20 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 06:21:13 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Li", "Zuchao", ""], ["Zhao", "Hai", ""], ["Wu", "Yingting", ""], ["Xiao", "Fengshun", ""], ["Jiang", "Shu", ""]]}, {"id": "1908.08419", "submitter": "Zhiyuan Ma", "authors": "Tingting Cai, Zhiyuan Ma, Hong Zheng, Yangming Zhou", "title": "NE-LP: Normalized Entropy and Loss Prediction based Sampling for Active\n  Learning in Chinese Word Segmentation on EHRs", "comments": "submitted to Neural Computing and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic Health Records (EHRs) in hospital information systems contain\npatients' diagnosis and treatments, so EHRs are essential to clinical data\nmining. Of all the tasks in the mining process, Chinese Word Segmentation (CWS)\nis a fundamental and important one, and most state-of-the-art methods greatly\nrely on large-scale of manually-annotated data. Since annotation is\ntime-consuming and expensive, efforts have been devoted to techniques, such as\nactive learning, to locate the most informative samples for modeling. In this\npaper, we follow the trend and present an active learning method for CWS in\nEHRs. Specically, a new sampling strategy combining Normalized Entropy with\nLoss Prediction (NE-LP) is proposed to select the most representative data.\nMeanwhile, to minimize the computational cost of learning, we propose a joint\nmodel including a word segmenter and a loss prediction model. Furthermore, to\ncapture interactions between adjacent characters, bigram features are also\napplied in the joint model. To illustrate the effectiveness of NE-LP, we\nconducted experiments on EHRs collected from the Shuguang Hospital Affiliated\nto Shanghai University of Traditional Chinese Medicine. The results demonstrate\nthat NE-LP consistently outperforms conventional uncertainty-based sampling\nstrategies for active learning in CWS.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 14:51:44 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 07:22:07 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 13:17:10 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Cai", "Tingting", ""], ["Ma", "Zhiyuan", ""], ["Zheng", "Hong", ""], ["Zhou", "Yangming", ""]]}, {"id": "1908.08486", "submitter": "Mohsen Mesgar", "authors": "Mohsen Mesgar, Sebastian B\\\"ucker, Iryna Gurevych", "title": "Dialogue Coherence Assessment Without Explicit Dialogue Act Labels", "comments": "Accepted at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent dialogue coherence models use the coherence features designed for\nmonologue texts, e.g. nominal entities, to represent utterances and then\nexplicitly augment them with dialogue-relevant features, e.g., dialogue act\nlabels. It indicates two drawbacks, (a) semantics of utterances is limited to\nentity mentions, and (b) the performance of coherence models strongly relies on\nthe quality of the input dialogue act labels. We address these issues by\nintroducing a novel approach to dialogue coherence assessment. We use dialogue\nact prediction as an auxiliary task in a multi-task learning scenario to obtain\ninformative utterance representations for coherence assessment. Our approach\nalleviates the need for explicit dialogue act labels during evaluation. The\nresults of our experiments show that our model substantially (more than 20\naccuracy points) outperforms its strong competitors on the DailyDialogue\ncorpus, and performs on par with them on the SwitchBoard corpus for ranking\ndialogues concerning their coherence.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 16:41:57 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 05:52:20 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Mesgar", "Mohsen", ""], ["B\u00fccker", "Sebastian", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1908.08507", "submitter": "Ningyu Zhang", "authors": "Ningyu Zhang, Shumin Deng, Zhanlin Sun, Jiaoyan Chen, Wei Zhang,\n  Huajun Chen", "title": "Transfer Learning for Relation Extraction via Relation-Gated Adversarial\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation extraction aims to extract relational facts from sentences. Previous\nmodels mainly rely on manually labeled datasets, seed instances or\nhuman-crafted patterns, and distant supervision. However, the human annotation\nis expensive, while human-crafted patterns suffer from semantic drift and\ndistant supervision samples are usually noisy. Domain adaptation methods enable\nleveraging labeled data from a different but related domain. However, different\ndomains usually have various textual relation descriptions and different label\nspace (the source label space is usually a superset of the target label space).\nTo solve these problems, we propose a novel model of relation-gated adversarial\nlearning for relation extraction, which extends the adversarial based domain\nadaptation. Experimental results have shown that the proposed approach\noutperforms previous domain adaptation methods regarding partial domain\nadaptation and can improve the accuracy of distance supervised relation\nextraction through fine-tuning.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 17:27:54 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Zhang", "Ningyu", ""], ["Deng", "Shumin", ""], ["Sun", "Zhanlin", ""], ["Chen", "Jiaoyan", ""], ["Zhang", "Wei", ""], ["Chen", "Huajun", ""]]}, {"id": "1908.08527", "submitter": "Tanmay Gupta", "authors": "Tanmay Gupta, Alexander Schwing and Derek Hoiem", "title": "ViCo: Word Embeddings from Visual Co-occurrences", "comments": "Accepted to ICCV 2019. Project Page: http://tanmaygupta.info/vico/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to learn word embeddings from visual co-occurrences. Two words\nco-occur visually if both words apply to the same image or image region.\nSpecifically, we extract four types of visual co-occurrences between object and\nattribute words from large-scale, textually-annotated visual databases like\nVisualGenome and ImageNet. We then train a multi-task log-bilinear model that\ncompactly encodes word \"meanings\" represented by each co-occurrence type into a\nsingle visual word-vector. Through unsupervised clustering, supervised\npartitioning, and a zero-shot-like generalization analysis we show that our\nword embeddings complement text-only embeddings like GloVe by better\nrepresenting similarities and differences between visual concepts that are\ndifficult to obtain from text corpora alone. We further evaluate our embeddings\non five downstream applications, four of which are vision-language tasks.\nAugmenting GloVe with our embeddings yields gains on all tasks. We also find\nthat random embeddings perform comparably to learned embeddings on all\nsupervised vision-language tasks, contrary to conventional wisdom.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 17:58:52 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Gupta", "Tanmay", ""], ["Schwing", "Alexander", ""], ["Hoiem", "Derek", ""]]}, {"id": "1908.08528", "submitter": "Rudolf Rosa", "authors": "Rudolf Rosa, Zden\\v{e}k \\v{Z}abokrtsk\\'y", "title": "Unsupervised Lemmatization as Embeddings-Based Word Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We focus on the task of unsupervised lemmatization, i.e. grouping together\ninflected forms of one word under one label (a lemma) without the use of\nannotated training data. We propose to perform agglomerative clustering of word\nforms with a novel distance measure. Our distance measure is based on the\nobservation that inflections of the same word tend to be similar both\nstring-wise and in meaning. We therefore combine word embedding cosine\nsimilarity, serving as a proxy to the meaning similarity, with Jaro-Winkler\nedit distance. Our experiments on 23 languages show our approach to be\npromising, surpassing the baseline on 23 of the 28 evaluation datasets.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 17:58:55 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Rosa", "Rudolf", ""], ["\u017dabokrtsk\u00fd", "Zden\u011bk", ""]]}, {"id": "1908.08529", "submitter": "Jyoti Aneja", "authors": "Jyoti Aneja, Harsh Agrawal, Dhruv Batra, Alexander Schwing", "title": "Sequential Latent Spaces for Modeling the Intention During Diverse Image\n  Captioning", "comments": "Accepted to ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diverse and accurate vision+language modeling is an important goal to retain\ncreative freedom and maintain user engagement. However, adequately capturing\nthe intricacies of diversity in language models is challenging. Recent works\ncommonly resort to latent variable models augmented with more or less\nsupervision from object detectors or part-of-speech tags. Common to all those\nmethods is the fact that the latent variable either only initializes the\nsentence generation process or is identical across the steps of generation.\nBoth methods offer no fine-grained control. To address this concern, we propose\nSeq-CVAE which learns a latent space for every word position. We encourage this\ntemporal latent space to capture the 'intention' about how to complete the\nsentence by mimicking a representation which summarizes the future. We\nillustrate the efficacy of the proposed approach to anticipate the sentence\ncontinuation on the challenging MSCOCO dataset, significantly improving\ndiversity metrics compared to baselines while performing on par w.r.t sentence\nquality.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 17:59:08 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Aneja", "Jyoti", ""], ["Agrawal", "Harsh", ""], ["Batra", "Dhruv", ""], ["Schwing", "Alexander", ""]]}, {"id": "1908.08530", "submitter": "Yue Cao", "authors": "Weijie Su, Xizhou Zhu, Yue Cao, Bin Li, Lewei Lu, Furu Wei, Jifeng Dai", "title": "VL-BERT: Pre-training of Generic Visual-Linguistic Representations", "comments": "Accepted by ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new pre-trainable generic representation for visual-linguistic\ntasks, called Visual-Linguistic BERT (VL-BERT for short). VL-BERT adopts the\nsimple yet powerful Transformer model as the backbone, and extends it to take\nboth visual and linguistic embedded features as input. In it, each element of\nthe input is either of a word from the input sentence, or a region-of-interest\n(RoI) from the input image. It is designed to fit for most of the\nvisual-linguistic downstream tasks. To better exploit the generic\nrepresentation, we pre-train VL-BERT on the massive-scale Conceptual Captions\ndataset, together with text-only corpus. Extensive empirical analysis\ndemonstrates that the pre-training procedure can better align the\nvisual-linguistic clues and benefit the downstream tasks, such as visual\ncommonsense reasoning, visual question answering and referring expression\ncomprehension. It is worth noting that VL-BERT achieved the first place of\nsingle model on the leaderboard of the VCR benchmark. Code is released at\n\\url{https://github.com/jackroos/VL-BERT}.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 17:59:30 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 11:18:38 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 09:42:53 GMT"}, {"version": "v4", "created": "Tue, 18 Feb 2020 02:59:17 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Su", "Weijie", ""], ["Zhu", "Xizhou", ""], ["Cao", "Yue", ""], ["Li", "Bin", ""], ["Lu", "Lewei", ""], ["Wei", "Furu", ""], ["Dai", "Jifeng", ""]]}, {"id": "1908.08566", "submitter": "Yacine Jernite", "authors": "Yacine Jernite", "title": "Unsupervised Text Summarization via Mixed Model Back-Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Back-translation based approaches have recently lead to significant progress\nin unsupervised sequence-to-sequence tasks such as machine translation or style\ntransfer. In this work, we extend the paradigm to the problem of learning a\nsentence summarization system from unaligned data. We present several initial\nmodels which rely on the asymmetrical nature of the task to perform the first\nback-translation step, and demonstrate the value of combining the data created\nby these diverse initialization methods. Our system outperforms the current\nstate-of-the-art for unsupervised sentence summarization from fully unaligned\ndata by over 2 ROUGE, and matches the performance of recent semi-supervised\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 19:07:34 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Jernite", "Yacine", ""]]}, {"id": "1908.08584", "submitter": "Beinan Wang", "authors": "Beinan Wang, John Glossner, Daniel Iancu, Georgi N. Gaydadjiev", "title": "Feedbackward Decoding for Semantic Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach for semantic segmentation that uses an encoder in\nthe reverse direction to decode. Many semantic segmentation networks adopt a\nfeedforward encoder-decoder architecture. Typically, an input is first\ndownsampled by the encoder to extract high-level semantic features and\ncontinues to be fed forward through the decoder module to recover low-level\nspatial clues. Our method works in an alternative direction that lets\ninformation flow backward from the last layer of the encoder towards the first.\nThe encoder performs encoding in the forward pass and the same network performs\ndecoding in the backward pass. Therefore, the encoder itself is also the\ndecoder. Compared to conventional encoder-decoder architectures, ours doesn't\nrequire additional layers for decoding and further reuses the encoder weights\nthereby reducing the total number of parameters required for processing. We\nshow by using only the 13 convolutional layers from VGG-16 plus one tiny\nclassification layer, our model significantly outperforms other frequently\ncited models that are also adapted from VGG-16. On the Cityscapes semantic\nsegmentation benchmark, our model uses 50.0% less parameters than SegNet and\nachieves an 18.1% higher \"IoU class\" score; it uses 28.3% less parameters than\nDeepLab LargeFOV and the achieved \"IoU class\" score is 3.9% higher; it uses\n89.1% fewer parameters than FCN-8s and the achieved \"IoU class\" score is 3.1%\nhigher. Our code will be publicly available on Github later.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 20:29:05 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Wang", "Beinan", ""], ["Glossner", "John", ""], ["Iancu", "Daniel", ""], ["Gaydadjiev", "Georgi N.", ""]]}, {"id": "1908.08593", "submitter": "Olga Kovaleva", "authors": "Olga Kovaleva, Alexey Romanov, Anna Rogers, Anna Rumshisky", "title": "Revealing the Dark Secrets of BERT", "comments": "Accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BERT-based architectures currently give state-of-the-art performance on many\nNLP tasks, but little is known about the exact mechanisms that contribute to\nits success. In the current work, we focus on the interpretation of\nself-attention, which is one of the fundamental underlying components of BERT.\nUsing a subset of GLUE tasks and a set of handcrafted features-of-interest, we\npropose the methodology and carry out a qualitative and quantitative analysis\nof the information encoded by the individual BERT's heads. Our findings suggest\nthat there is a limited set of attention patterns that are repeated across\ndifferent heads, indicating the overall model overparametrization. While\ndifferent heads consistently use the same attention patterns, they have varying\nimpact on performance across different tasks. We show that manually disabling\nattention in certain heads leads to a performance improvement over the regular\nfine-tuned BERT models.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 04:27:38 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 16:26:37 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Kovaleva", "Olga", ""], ["Romanov", "Alexey", ""], ["Rogers", "Anna", ""], ["Rumshisky", "Anna", ""]]}, {"id": "1908.08594", "submitter": "Matthias von Davier", "authors": "Matthias von Davier", "title": "Training Optimus Prime, M.D.: Generating Medical Certification Items by\n  Fine-Tuning OpenAI's gpt2 Transformer Model", "comments": "18 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes new results of an application using transformer-based\nlanguage models to automated item generation (AIG), an area of ongoing interest\nin the domain of certification testing as well as in educational measurement\nand psychological testing. OpenAI's gpt2 pre-trained 345M parameter language\nmodel was retrained using the public domain text mining set of PubMed articles\nand subsequently used to generate item stems (case vignettes) as well as\ndistractor proposals for multiple-choice items. This case study shows promise\nand produces draft text that can be used by human item writers as input for\nauthoring. Future experiments with more recent transformer models (such as\nGrover, TransformerXL) using existing item pools are expected to improve\nresults further and to facilitate the development of assessment materials.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 00:58:21 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 11:07:04 GMT"}, {"version": "v3", "created": "Thu, 29 Aug 2019 23:11:08 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["von Davier", "Matthias", ""]]}, {"id": "1908.08597", "submitter": "Danielle Bragg", "authors": "Danielle Bragg, Oscar Koller, Mary Bellard, Larwan Berke, Patrick\n  Boudrealt, Annelies Braffort, Naomi Caselli, Matt Huenerfauth, Hernisa\n  Kacorri, Tessa Verhoef, Christian Vogler, Meredith Ringel Morris", "title": "Sign Language Recognition, Generation, and Translation: An\n  Interdisciplinary Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.CY cs.GR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing successful sign language recognition, generation, and translation\nsystems requires expertise in a wide range of fields, including computer\nvision, computer graphics, natural language processing, human-computer\ninteraction, linguistics, and Deaf culture. Despite the need for deep\ninterdisciplinary knowledge, existing research occurs in separate disciplinary\nsilos, and tackles separate portions of the sign language processing pipeline.\nThis leads to three key questions: 1) What does an interdisciplinary view of\nthe current landscape reveal? 2) What are the biggest challenges facing the\nfield? and 3) What are the calls to action for people working in the field? To\nhelp answer these questions, we brought together a diverse group of experts for\na two-day workshop. This paper presents the results of that interdisciplinary\nworkshop, providing key background that is often overlooked by computer\nscientists, a review of the state-of-the-art, a set of pressing challenges, and\na call to action for the research community.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 21:05:17 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Bragg", "Danielle", ""], ["Koller", "Oscar", ""], ["Bellard", "Mary", ""], ["Berke", "Larwan", ""], ["Boudrealt", "Patrick", ""], ["Braffort", "Annelies", ""], ["Caselli", "Naomi", ""], ["Huenerfauth", "Matt", ""], ["Kacorri", "Hernisa", ""], ["Verhoef", "Tessa", ""], ["Vogler", "Christian", ""], ["Morris", "Meredith Ringel", ""]]}, {"id": "1908.08672", "submitter": "Zhepei Wei", "authors": "Zhepei Wei, Yantao Jia, Yuan Tian, Mohammad Javad Hosseini, Mark\n  Steedman, Yi Chang", "title": "Joint Extraction of Entities and Relations with a Hierarchical\n  Multi-task Tagging Model", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity extraction and relation extraction are two indispensable building\nblocks for knowledge graph construction. Recent works on entity and relation\nextraction have shown the superiority of solving the two problems in a joint\nmanner, where entities and relations are extracted simultaneously to form\nrelational triples in a knowledge graph. However, existing methods ignore the\nhierarchical semantic interdependency between entity extraction (EE) and joint\nextraction (JE), which leaves much to be desired in real applications. In this\nwork, we propose a hierarchical multi-task tagging model, called HMT, which\ncaptures such interdependency and achieves better performance for joint\nextraction of entities and relations. Specifically, the EE task is organized at\nthe bottom layer and JE task at the top layer in a hierarchical structure.\nFurthermore, the learned semantic representation at the lower level can be\nshared by the upper level via multi-task learning. Experimental results\ndemonstrate the effectiveness of the proposed model for joint extraction in\ncomparison with the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 05:36:45 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Wei", "Zhepei", ""], ["Jia", "Yantao", ""], ["Tian", "Yuan", ""], ["Hosseini", "Mohammad Javad", ""], ["Steedman", "Mark", ""], ["Chang", "Yi", ""]]}, {"id": "1908.08674", "submitter": "Debabrata Paul", "authors": "Debabrata Paul and Bidyut Baran Chaudhuri", "title": "A BLSTM Network for Printed Bengali OCR System with High Accuracy", "comments": "6 pages, 6 figures, This OCR system is available online at\n  https://banglaocr.nltr.org", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a printed Bengali and English text OCR system developed\nby us using a single hidden BLSTM-CTC architecture having 128 units. Here, we\ndid not use any peephole connection and dropout in the BLSTM, which helped us\nin getting better accuracy. This architecture was trained by 47,720 text lines\nthat include English words also. When tested over 20 different Bengali fonts,\nit has produced character level accuracy of 99.32% and word level accuracy of\n96.65%. A good Indic multi script OCR system is also developed by Google. It\nsometimes recognizes a character of Bengali into the same character of a\nnon-Bengali script, especially Assamese, which has no distinction from Bengali,\nexcept for a few characters. For example, Bengali character for 'RA' is\nsometimes recognized as that of Assamese, mainly in conjunct consonant forms.\nOur OCR is free from such errors. This OCR system is available online at\nhttps://banglaocr.nltr.org\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 05:45:27 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Paul", "Debabrata", ""], ["Chaudhuri", "Bidyut Baran", ""]]}, {"id": "1908.08676", "submitter": "Leyang Cui", "authors": "Leyang Cui and Yue Zhang", "title": "Hierarchically-Refined Label Attention Network for Sequence Labeling", "comments": "EMNLP 2019", "journal-ref": null, "doi": "10.18653/v1/D19-1422", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CRF has been used as a powerful model for statistical sequence labeling. For\nneural sequence labeling, however, BiLSTM-CRF does not always lead to better\nresults compared with BiLSTM-softmax local classification. This can be because\nthe simple Markov label transition model of CRF does not give much information\ngain over strong neural encoding. For better representing label sequences, we\ninvestigate a hierarchically-refined label attention network, which explicitly\nleverages label embeddings and captures potential long-term label dependency by\ngiving each word incrementally refined label distributions with hierarchical\nattention. Results on POS tagging, NER and CCG supertagging show that the\nproposed model not only improves the overall tagging accuracy with similar\nnumber of parameters, but also significantly speeds up the training and testing\ncompared to BiLSTM-CRF.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 05:55:46 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 10:58:02 GMT"}, {"version": "v3", "created": "Thu, 7 Nov 2019 01:58:58 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Cui", "Leyang", ""], ["Zhang", "Yue", ""]]}, {"id": "1908.08717", "submitter": "Mahault Garnerin", "authors": "Mahault Garnerin, Solange Rossato, Laurent Besacier", "title": "Gender Representation in French Broadcast Corpora and Its Impact on ASR\n  Performance", "comments": "Accepted to ACM Workshop AI4TV", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes the gender representation in four major corpora of French\nbroadcast. These corpora being widely used within the speech processing\ncommunity, they are a primary material for training automatic speech\nrecognition (ASR) systems. As gender bias has been highlighted in numerous\nnatural language processing (NLP) applications, we study the impact of the\ngender imbalance in TV and radio broadcast on the performance of an ASR system.\nThis analysis shows that women are under-represented in our data in terms of\nspeakers and speech turns. We introduce the notion of speaker role to refine\nour analysis and find that women are even fewer within the Anchor category\ncorresponding to prominent speakers. The disparity of available data for both\ngender causes performance to decrease on women. However this global trend can\nbe counterbalanced for speaker who are used to speak in the media when\nsufficient amount of data is available.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 08:51:19 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Garnerin", "Mahault", ""], ["Rossato", "Solange", ""], ["Besacier", "Laurent", ""]]}, {"id": "1908.08788", "submitter": "Ningyu Zhang", "authors": "Shumin Deng, Ningyu Zhang, Zhanlin Sun, Jiaoyan Chen, Huajun Chen", "title": "When Low Resource NLP Meets Unsupervised Language Model:\n  Meta-pretraining Then Meta-learning for Few-shot Text Classification", "comments": "AAAI student abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text classification tends to be difficult when data are deficient or when it\nis required to adapt to unseen classes. In such challenging scenarios, recent\nstudies have often used meta-learning to simulate the few-shot task, thus\nnegating implicit common linguistic features across tasks. This paper addresses\nsuch problems using meta-learning and unsupervised language models. Our\napproach is based on the insight that having a good generalization from a few\nexamples relies on both a generic model initialization and an effective\nstrategy for adapting this model to newly arising tasks. We show that our\napproach is not only simple but also produces a state-of-the-art performance on\na well-studied sentiment classification dataset. It can thus be further\nsuggested that pretraining could be a promising solution for few-shot learning\nof many other NLP tasks. The code and the dataset to replicate the experiments\nare made available at https://github.com/zxlzr/FewShotNLP.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 17:23:29 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 01:57:41 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Deng", "Shumin", ""], ["Zhang", "Ningyu", ""], ["Sun", "Zhanlin", ""], ["Chen", "Jiaoyan", ""], ["Chen", "Huajun", ""]]}, {"id": "1908.08835", "submitter": "Richard Csaky", "authors": "Richard Csaky", "title": "Deep Learning Based Chatbot Models", "comments": "67 pages. Written in October of 2017 for a university conference. In\n  April of 2019, it won first place at the Hungarian Scientific Students'\n  Associations Report, which is a national competition-like conference for\n  students", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A conversational agent (chatbot) is a piece of software that is able to\ncommunicate with humans using natural language. Modeling conversation is an\nimportant task in natural language processing and artificial intelligence.\nWhile chatbots can be used for various tasks, in general they have to\nunderstand users' utterances and provide responses that are relevant to the\nproblem at hand.\n  In my work, I conduct an in-depth survey of recent literature, examining over\n70 publications related to chatbots published in the last 3 years. Then, I\nproceed to make the argument that the very nature of the general conversation\ndomain demands approaches that are different from current state-of-of-the-art\narchitectures. Based on several examples from the literature I show why current\nchatbot models fail to take into account enough priors when generating\nresponses and how this affects the quality of the conversation. In the case of\nchatbots, these priors can be outside sources of information that the\nconversation is conditioned on like the persona or mood of the conversers. In\naddition to presenting the reasons behind this problem, I propose several ideas\non how it could be remedied.\n  The next section focuses on adapting the very recent Transformer model to the\nchatbot domain, which is currently state-of-the-art in neural machine\ntranslation. I first present experiments with the vanilla model, using\nconversations extracted from the Cornell Movie-Dialog Corpus. Secondly, I\naugment the model with some of my ideas regarding the issues of encoder-decoder\narchitectures. More specifically, I feed additional features into the model\nlike mood or persona together with the raw conversation data. Finally, I\nconduct a detailed analysis of how the vanilla model performs on conversational\ndata by comparing it to previous chatbot models and how the additional features\naffect the quality of the generated responses.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 14:09:37 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Csaky", "Richard", ""]]}, {"id": "1908.08861", "submitter": "Andrea Zugarini", "authors": "Andrea Zugarini, Stefano Melacci, Marco Maggini", "title": "Neural Poetry: Learning to Generate Poems using Syllables", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-30490-4_26", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the recent progresses on machine learning-based models that\nlearn artistic styles, in this paper we focus on the problem of poem\ngeneration. This is a challenging task in which the machine has to capture the\nlinguistic features that strongly characterize a certain poet, as well as the\nsemantics of the poet's production, that are influenced by his personal\nexperiences and by his literary background. Since poetry is constructed using\nsyllables, that regulate the form and structure of poems, we propose a\nsyllable-based neural language model, and we describe a poem generation\nmechanism that is designed around the poet style, automatically selecting the\nmost representative generations. The poetic work of a target author is usually\nnot enough to successfully train modern deep neural networks, so we propose a\nmulti-stage procedure that exploits non-poetic works of the same author, and\nalso other publicly available huge corpora to learn syntax and grammar of the\ntarget language. We focus on the Italian poet Dante Alighieri, widely famous\nfor his Divine Comedy. A quantitative and qualitative experimental analysis of\nthe generated tercets is reported, where we included expert judges with strong\nbackground in humanistic studies. The generated tercets are frequently\nconsidered to be real by a generic population of judges, with relative\ndifference of 56.25\\% with respect to the ones really authored by Dante, and\nexpert judges perceived Dante's style and rhymes in the generated text.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 15:09:07 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 09:37:05 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Zugarini", "Andrea", ""], ["Melacci", "Stefano", ""], ["Maggini", "Marco", ""]]}, {"id": "1908.08909", "submitter": "Hsin-Yuan Huang", "authors": "Hsin-Yuan Huang and Richard Kueng", "title": "Predicting Features of Quantum Systems from Very Few Measurements", "comments": "8 pages, 6 figures + 10 page appendix and one reference to Norse\n  mythology", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CL cs.IT cs.LG math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting features of complex, large-scale quantum systems is essential to\nthe characterization and engineering of quantum architectures. We present an\nefficient approach for constructing an approximate classical description,\ncalled the classical shadow, of a quantum system from very few quantum\nmeasurements that can later be used to predict a large collection of features.\nThis approach is guaranteed to accurately predict M linear functions with\nbounded Hilbert-Schmidt norm from only order of log(M) measurements. This is\ncompletely independent of the system size and saturates fundamental lower\nbounds from information theory. We support our theoretical findings with\nnumerical experiments over a wide range of problem sizes (2 to 162 qubits).\nThese highlight advantages compared to existing machine learning approaches.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 17:32:39 GMT"}, {"version": "v2", "created": "Sun, 24 Nov 2019 19:20:43 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Huang", "Hsin-Yuan", ""], ["Kueng", "Richard", ""]]}, {"id": "1908.08917", "submitter": "Sandro Skansi", "authors": "Sandro Skansi and Leo Mr\\v{s}i\\'c and Ines Skelac", "title": "A Lost Croatian Cybernetic Machine Translation Program", "comments": "To appear in \"A Guide to Deep Learning Basics: Historical, Logical\n  and Philosophical Perspectives\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We are exploring the historical significance of research in the field of\nmachine translation conducted by Bulcsu Laszlo, Croatian linguist, who was a\npioneer in machine translation in Yugoslavia during the 1950s. We are focused\non two important seminal papers written by members of his research group from\n1959 and 1962, as well as their legacy in establishing a Croatian machine\ntranslation program based around the Faculty of Humanities and Social Sciences\nof the University of Zagreb in the late 1950s and early 1960s. We are exploring\ntheir work in connection with the beginnings of machine translation in the USA\nand USSR, motivated by the Cold War and the intelligence needs of the period.\nWe also present the approach to machine translation advocated by the Croatian\ngroup in Yugoslavia, which is different from the usual logical approaches of\nthe period, and his advocacy of cybernetic methods, which would be adopted as a\ncanon by the mainstream AI community only decades later.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 05:27:34 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Skansi", "Sandro", ""], ["Mr\u0161i\u0107", "Leo", ""], ["Skelac", "Ines", ""]]}, {"id": "1908.08960", "submitter": "Wojciech Kryscinski", "authors": "Wojciech Kry\\'sci\\'nski, Nitish Shirish Keskar, Bryan McCann, Caiming\n  Xiong, Richard Socher", "title": "Neural Text Summarization: A Critical Evaluation", "comments": "To appear in EMNLP 2019, 13 pages, 2 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text summarization aims at compressing long documents into a shorter form\nthat conveys the most important parts of the original document. Despite\nincreased interest in the community and notable research effort, progress on\nbenchmark datasets has stagnated. We critically evaluate key ingredients of the\ncurrent research setup: datasets, evaluation metrics, and models, and highlight\nthree primary shortcomings: 1) automatically collected datasets leave the task\nunderconstrained and may contain noise detrimental to training and evaluation,\n2) current evaluation protocol is weakly correlated with human judgment and\ndoes not account for important characteristics such as factual correctness, 3)\nmodels overfit to layout biases of current datasets and offer limited diversity\nin their outputs.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 18:00:38 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Kry\u015bci\u0144ski", "Wojciech", ""], ["Keskar", "Nitish Shirish", ""], ["McCann", "Bryan", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1908.08962", "submitter": "Iulia Turc", "authors": "Iulia Turc, Ming-Wei Chang, Kenton Lee, Kristina Toutanova", "title": "Well-Read Students Learn Better: On the Importance of Pre-training\n  Compact Models", "comments": "Added comparison to concurrent work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in natural language representations have been accompanied\nby large and expensive models that leverage vast amounts of general-domain text\nthrough self-supervised pre-training. Due to the cost of applying such models\nto down-stream tasks, several model compression techniques on pre-trained\nlanguage representations have been proposed (Sun et al., 2019; Sanh, 2019).\nHowever, surprisingly, the simple baseline of just pre-training and fine-tuning\ncompact models has been overlooked. In this paper, we first show that\npre-training remains important in the context of smaller architectures, and\nfine-tuning pre-trained compact models can be competitive to more elaborate\nmethods proposed in concurrent work. Starting with pre-trained compact models,\nwe then explore transferring task knowledge from large fine-tuned models\nthrough standard knowledge distillation. The resulting simple, yet effective\nand general algorithm, Pre-trained Distillation, brings further improvements.\nThrough extensive experiments, we more generally explore the interaction\nbetween pre-training and distillation under two variables that have been\nunder-studied: model size and properties of unlabeled task data. One surprising\nobservation is that they have a compound effect even when sequentially applied\non the same data. To accelerate future research, we will make our 24\npre-trained miniature BERT models publicly available.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 18:02:05 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 22:55:20 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Turc", "Iulia", ""], ["Chang", "Ming-Wei", ""], ["Lee", "Kenton", ""], ["Toutanova", "Kristina", ""]]}, {"id": "1908.08971", "submitter": "Hilaria Cruz", "authors": "Hilaria Cruz, Joseph Waring", "title": "Deploying Technology to Save Endangered Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Computer scientists working on natural language processing, native speakers\nof endangered languages, and field linguists to discuss ways to harness\nAutomatic Speech Recognition, especially neural networks, to automate\nannotation, speech tagging, and text parsing on endangered languages.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 18:31:35 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2019 02:39:09 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Cruz", "Hilaria", ""], ["Waring", "Joseph", ""]]}, {"id": "1908.08979", "submitter": "Mimansa Jaiswal", "authors": "Mimansa Jaiswal, Zakaria Aldeneh, Emily Mower Provost", "title": "Controlling for Confounders in Multimodal Emotion Classification via\n  Adversarial Learning", "comments": "10 pages, ICMI 2019", "journal-ref": null, "doi": "10.1145/3340555.3353731", "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various psychological factors affect how individuals express emotions. Yet,\nwhen we collect data intended for use in building emotion recognition systems,\nwe often try to do so by creating paradigms that are designed just with a focus\non eliciting emotional behavior. Algorithms trained with these types of data\nare unlikely to function outside of controlled environments because our\nemotions naturally change as a function of these other factors. In this work,\nwe study how the multimodal expressions of emotion change when an individual is\nunder varying levels of stress. We hypothesize that stress produces modulations\nthat can hide the true underlying emotions of individuals and that we can make\nemotion recognition algorithms more generalizable by controlling for variations\nin stress. To this end, we use adversarial networks to decorrelate stress\nmodulations from emotion representations. We study how stress alters acoustic\nand lexical emotional predictions, paying special attention to how modulations\ndue to stress affect the transferability of learned emotion recognition models\nacross domains. Our results show that stress is indeed encoded in trained\nemotion classifiers and that this encoding varies across levels of emotions and\nacross the lexical and acoustic modalities. Our results also show that emotion\nrecognition models that control for stress during training have better\ngeneralizability when applied to new domains, compared to models that do not\ncontrol for stress during training. We conclude that is is necessary to\nconsider the effect of extraneous psychological factors when building and\ntesting emotion recognition models.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 19:00:18 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Jaiswal", "Mimansa", ""], ["Aldeneh", "Zakaria", ""], ["Provost", "Emily Mower", ""]]}, {"id": "1908.08983", "submitter": "Aditi Chaudhary", "authors": "Aditi Chaudhary, Jiateng Xie, Zaid Sheikh, Graham Neubig, Jaime G.\n  Carbonell", "title": "A Little Annotation does a Lot of Good: A Study in Bootstrapping\n  Low-resource Named Entity Recognizers", "comments": "Accepted at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most state-of-the-art models for named entity recognition (NER) rely on the\navailability of large amounts of labeled data, making them challenging to\nextend to new, lower-resourced languages. However, there are now several\nproposed approaches involving either cross-lingual transfer learning, which\nlearns from other highly resourced languages, or active learning, which\nefficiently selects effective training data based on model predictions. This\npaper poses the question: given this recent progress, and limited human\nannotation, what is the most effective method for efficiently creating\nhigh-quality entity recognizers in under-resourced languages? Based on\nextensive experimentation using both simulated and real human annotation, we\nfind a dual-strategy approach best, starting with a cross-lingual transferred\nmodel, then performing targeted annotation of only uncertain entity spans in\nthe target language, minimizing annotator effort. Results demonstrate that\ncross-lingual transfer is a powerful tool when very little data can be\nannotated, but an entity-targeted annotation strategy can achieve competitive\naccuracy quickly, with just one-tenth of training data.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 19:15:07 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Chaudhary", "Aditi", ""], ["Xie", "Jiateng", ""], ["Sheikh", "Zaid", ""], ["Neubig", "Graham", ""], ["Carbonell", "Jaime G.", ""]]}, {"id": "1908.09022", "submitter": "Thiago Castro Ferreira", "authors": "Thiago Castro Ferreira, Chris van der Lee, Emiel van Miltenburg, Emiel\n  Krahmer", "title": "Neural data-to-text generation: A comparison between pipeline and\n  end-to-end architectures", "comments": "Preprint version of the EMNLP 2019 article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, most data-to-text applications have been designed using a\nmodular pipeline architecture, in which non-linguistic input data is converted\ninto natural language through several intermediate transformations. In\ncontrast, recent neural models for data-to-text generation have been proposed\nas end-to-end approaches, where the non-linguistic input is rendered in natural\nlanguage with much less explicit intermediate representations in-between. This\nstudy introduces a systematic comparison between neural pipeline and end-to-end\ndata-to-text approaches for the generation of text from RDF triples. Both\narchitectures were implemented making use of state-of-the art deep learning\nmethods as the encoder-decoder Gated-Recurrent Units (GRU) and Transformer.\nAutomatic and human evaluations together with a qualitative analysis suggest\nthat having explicit intermediate steps in the generation process results in\nbetter texts than the ones generated by end-to-end approaches. Moreover, the\npipeline models generalize better to unseen inputs. Data and code are publicly\navailable.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 20:10:36 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 13:06:04 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Ferreira", "Thiago Castro", ""], ["van der Lee", "Chris", ""], ["van Miltenburg", "Emiel", ""], ["Krahmer", "Emiel", ""]]}, {"id": "1908.09080", "submitter": "Mohammad Reza Besharati", "authors": "MohammadReza Besharati, Mohammad Izadi", "title": "DAST Model: Deciding About Semantic Complexity of a Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring text complexity is an essential task in several fields and\napplications (such as NLP, semantic web, smart education, etc.). The semantic\nlayer of text is more tacit than its syntactic structure and, as a result,\ncalculation of semantic complexity is more difficult than syntactic complexity.\nWhile there are famous and powerful academic and commercial syntactic\ncomplexity measures, the problem of measuring semantic complexity is still a\nchallenging one. In this paper, we introduce the DAST model, which stands for\nDeciding About Semantic Complexity of a Text. DAST proposes an intuitionistic\napproach to semantics that lets us have a well-defined model for the semantics\nof a text and its complexity: semantic is considered as a lattice of intuitions\nand, as a result, semantic complexity is defined as the result of a calculation\non this lattice. A set theoretic formal definition of semantic complexity, as a\n6-tuple formal system, is provided. By using this formal system, a method for\nmeasuring semantic complexity is presented. The evaluation of the proposed\napproach is done by a set of three human-judgment experiments. The results show\nthat DAST model is capable of deciding about semantic complexity of text.\nFurthermore, the analysis of the results leads us to introduce a Markovian\nmodel for the process of common-sense, multiple-steps and semantic-complexity\nreasoning in people. The results of Experiments demonstrate that our method\noutperforms the random baseline with improvement in better precision and\ncompetes with other methods by less error percentage.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 03:10:38 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 08:10:24 GMT"}, {"version": "v3", "created": "Mon, 7 Oct 2019 21:09:09 GMT"}, {"version": "v4", "created": "Fri, 15 Nov 2019 21:16:18 GMT"}, {"version": "v5", "created": "Sat, 30 Nov 2019 23:23:09 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Besharati", "MohammadReza", ""], ["Izadi", "Mohammad", ""]]}, {"id": "1908.09083", "submitter": "Sudipta Kar", "authors": "Sudipta Kar and Gustavo Aguilar and Mirella Lapata and Thamar Solorio", "title": "Multi-view Story Characterization from Movie Plot Synopses and Reviews", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of characterizing stories by inferring\nproperties such as theme and style using written synopses and reviews of\nmovies. We experiment with a multi-label dataset of movie synopses and a tagset\nrepresenting various attributes of stories (e.g., genre, type of events). Our\nproposed multi-view model encodes the synopses and reviews using hierarchical\nattention and shows improvement over methods that only use synopses. Finally,\nwe demonstrate how can we take advantage of such a model to extract a\ncomplementary set of story-attributes from reviews without direct supervision.\nWe have made our dataset and source code publicly available at\nhttps://ritual.uh.edu/ multiview-tag-2020.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 03:27:43 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 22:16:46 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Kar", "Sudipta", ""], ["Aguilar", "Gustavo", ""], ["Lapata", "Mirella", ""], ["Solorio", "Thamar", ""]]}, {"id": "1908.09091", "submitter": "Mandar Joshi", "authors": "Mandar Joshi and Omer Levy and Daniel S. Weld and Luke Zettlemoyer", "title": "BERT for Coreference Resolution: Baselines and Analysis", "comments": "Fix test set numbers for e2e-coref on GAP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply BERT to coreference resolution, achieving strong improvements on the\nOntoNotes (+3.9 F1) and GAP (+11.5 F1) benchmarks. A qualitative analysis of\nmodel predictions indicates that, compared to ELMo and BERT-base, BERT-large is\nparticularly better at distinguishing between related but distinct entities\n(e.g., President and CEO). However, there is still room for improvement in\nmodeling document-level context, conversations, and mention paraphrasing. Our\ncode and models are publicly available.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 05:07:36 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 01:42:51 GMT"}, {"version": "v3", "created": "Sun, 1 Sep 2019 07:58:39 GMT"}, {"version": "v4", "created": "Sun, 22 Dec 2019 23:58:16 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Joshi", "Mandar", ""], ["Levy", "Omer", ""], ["Weld", "Daniel S.", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1908.09119", "submitter": "Varun Pandya", "authors": "Varun Pandya", "title": "Automatic Text Summarization of Legal Cases: A Hybrid Approach", "comments": "Part of 5th International Conference on Natural Language Processing\n  (NATP 2019) Proceedings", "journal-ref": null, "doi": "10.5121/csit.2019.91004", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manual Summarization of large bodies of text involves a lot of human effort\nand time, especially in the legal domain. Lawyers spend a lot of time preparing\nlegal briefs of their clients' case files. Automatic Text summarization is a\nconstantly evolving field of Natural Language Processing(NLP), which is a\nsubdiscipline of the Artificial Intelligence Field. In this paper a hybrid\nmethod for automatic text summarization of legal cases using k-means clustering\ntechnique and tf-idf(term frequency-inverse document frequency) word vectorizer\nis proposed. The summary generated by the proposed method is compared using\nROGUE evaluation parameters with the case summary as prepared by the lawyer for\nappeal in court. Further, suggestions for improving the proposed method are\nalso presented.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 10:05:40 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Pandya", "Varun", ""]]}, {"id": "1908.09122", "submitter": "Shiwan Zhao Mr", "authors": "Mengting Hu, Yike Wu, Shiwan Zhao, Honglei Guo, Renhong Cheng, Zhong\n  Su", "title": "Domain-Invariant Feature Distillation for Cross-Domain Sentiment\n  Classification", "comments": "Accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-domain sentiment classification has drawn much attention in recent\nyears. Most existing approaches focus on learning domain-invariant\nrepresentations in both the source and target domains, while few of them pay\nattention to the domain-specific information. Despite the non-transferability\nof the domain-specific information, simultaneously learning domain-dependent\nrepresentations can facilitate the learning of domain-invariant\nrepresentations. In this paper, we focus on aspect-level cross-domain sentiment\nclassification, and propose to distill the domain-invariant sentiment features\nwith the help of an orthogonal domain-dependent task, i.e. aspect detection,\nwhich is built on the aspects varying widely in different domains. We conduct\nextensive experiments on three public datasets and the experimental results\ndemonstrate the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 10:50:23 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Hu", "Mengting", ""], ["Wu", "Yike", ""], ["Zhao", "Shiwan", ""], ["Guo", "Honglei", ""], ["Cheng", "Renhong", ""], ["Su", "Zhong", ""]]}, {"id": "1908.09128", "submitter": "Wei Wei", "authors": "Wei Wei, Zanbo Wang, Xianling Mao, Guangyou Zhou, Pan Zhou, Sheng\n  Jiang", "title": "Enhancing Neural Sequence Labeling with Position-Aware Self-Attention", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence labeling is a fundamental task in natural language processing and\nhas been widely studied. Recently, RNN-based sequence labeling models have\nincreasingly gained attentions. Despite superior performance achieved by\nlearning the long short-term (i.e., successive) dependencies, the way of\nsequentially processing inputs might limit the ability to capture the\nnon-continuous relations over tokens within a sentence. To tackle the problem,\nwe focus on how to effectively model successive and discrete dependencies of\neach token for enhancing the sequence labeling performance. Specifically, we\npropose an innovative and well-designed attention-based model (called\nposition-aware self-attention, i.e., PSA) within a neural network architecture,\nto explore the positional information of an input sequence for capturing the\nlatent relations among tokens. Extensive experiments on three classical tasks\nin sequence labeling domain, i.e., part-of-speech (POS) tagging, named entity\nrecognition (NER) and phrase chunking, demonstrate our proposed model\noutperforms the state-of-the-arts without any external knowledge, in terms of\nvarious metrics.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 11:40:08 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Wei", "Wei", ""], ["Wang", "Zanbo", ""], ["Mao", "Xianling", ""], ["Zhou", "Guangyou", ""], ["Zhou", "Pan", ""], ["Jiang", "Sheng", ""]]}, {"id": "1908.09137", "submitter": "Seunghyun Yoon", "authors": "Seunghyun Yoon, Franck Dernoncourt, Doo Soon Kim, Trung Bui, Kyomin\n  Jung", "title": "Propagate-Selector: Detecting Supporting Sentences for Question\n  Answering via Graph Neural Networks", "comments": "8 pages, Accepted as a conference paper at LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we propose a novel graph neural network called\npropagate-selector (PS), which propagates information over sentences to\nunderstand information that cannot be inferred when considering sentences in\nisolation. First, we design a graph structure in which each node represents an\nindividual sentence, and some pairs of nodes are selectively connected based on\nthe text structure. Then, we develop an iterative attentive aggregation and a\nskip-combine method in which a node interacts with its neighborhood nodes to\naccumulate the necessary information. To evaluate the performance of the\nproposed approaches, we conduct experiments with the standard HotpotQA dataset.\nThe empirical results demonstrate the superiority of our proposed approach,\nwhich obtains the best performances, compared to the widely used\nanswer-selection models that do not consider the intersentential relationship.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 13:37:35 GMT"}, {"version": "v2", "created": "Sun, 16 Feb 2020 13:25:41 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Yoon", "Seunghyun", ""], ["Dernoncourt", "Franck", ""], ["Kim", "Doo Soon", ""], ["Bui", "Trung", ""], ["Jung", "Kyomin", ""]]}, {"id": "1908.09138", "submitter": "Jiwei Li", "authors": "Yuxian Meng, Xiaoya Li, Zijun Sun and Jiwei Li", "title": "Query-Based Named Entity Recognition", "comments": "Please refer to the full version of this paper: A unified framework\n  for named entity recognition arXiv:1910.11476", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new strategy for the task of named entity\nrecognition (NER). We cast the task as a query-based machine reading\ncomprehension task: e.g., the task of extracting entities with PER is\nformalized as answering the question of \"which person is mentioned in the text\n?\". Such a strategy comes with the advantage that it solves the long-standing\nissue of handling overlapping or nested entities (the same token that\nparticipates in more than one entity categories) with sequence-labeling\ntechniques for NER. Additionally, since the query encodes informative prior\nknowledge, this strategy facilitates the process of entity extraction, leading\nto better performances. We experiment the proposed model on five widely used\nNER datasets on English and Chinese, including MSRA, Resume, OntoNotes, ACE04\nand ACE05. The proposed model sets new SOTA results on all of these datasets.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 13:42:57 GMT"}, {"version": "v2", "created": "Sat, 2 Nov 2019 15:12:22 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Meng", "Yuxian", ""], ["Li", "Xiaoya", ""], ["Sun", "Zijun", ""], ["Li", "Jiwei", ""]]}, {"id": "1908.09156", "submitter": "Armineh Nourbakhsh", "authors": "Armineh Nourbakhsh, Grace Bang", "title": "A framework for anomaly detection using language modeling, and its\n  applications to finance", "comments": "5 pages, 2 figures, presented at the 2nd KDD Workshop on Anomaly\n  Detection in Finance, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the finance sector, studies focused on anomaly detection are often\nassociated with time-series and transactional data analytics. In this paper, we\nlay out the opportunities for applying anomaly and deviation detection methods\nto text corpora and challenges associated with them. We argue that language\nmodels that use distributional semantics can play a significant role in\nadvancing these studies in novel directions, with new applications in risk\nidentification, predictive modeling, and trend analysis.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 15:52:57 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Nourbakhsh", "Armineh", ""], ["Bang", "Grace", ""]]}, {"id": "1908.09174", "submitter": "Najibesadat Sadati Jafarkalaei", "authors": "Najibesadat Sadati, Milad Zafar Nezhad, Ratna Babu Chinnam, Dongxiao\n  Zhu", "title": "Representation Learning with Autoencoders for Electronic Health Records:\n  A Comparative Study", "comments": "Reason: This submission is the extension of our other research which\n  has already submitted in arXiv (arXiv:1801.02961), therefore we decided\n  update that version and withdraw this submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing volume of Electronic Health Records (EHR) in recent years provides\ngreat opportunities for data scientists to collaborate on different aspects of\nhealthcare research by applying advanced analytics to these EHR clinical data.\nA key requirement however is obtaining meaningful insights from high\ndimensional, sparse and complex clinical data. Data science approaches\ntypically address this challenge by performing feature learning in order to\nbuild more reliable and informative feature representations from clinical data\nfollowed by supervised learning. In this paper, we propose a predictive\nmodeling approach based on deep learning based feature representations and word\nembedding techniques. Our method uses different deep architectures (stacked\nsparse autoencoders, deep belief network, adversarial autoencoders and\nvariational autoencoders) for feature representation in higher-level\nabstraction to obtain effective and robust features from EHRs, and then build\nprediction models on top of them. Our approach is particularly useful when the\nunlabeled data is abundant whereas labeled data is scarce. We investigate the\nperformance of representation learning through a supervised learning approach.\nOur focus is to present a comparative study to evaluate the performance of\ndifferent deep architectures through supervised learning and provide insights\nin the choice of deep feature representation techniques. Our experiments\ndemonstrate that for small data sets, stacked sparse autoencoder demonstrates a\nsuperior generality performance in prediction due to sparsity regularization\nwhereas variational autoencoders outperform the competing approaches for large\ndata sets due to its capability of learning the representation distribution\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 17:38:30 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 02:17:16 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Sadati", "Najibesadat", ""], ["Nezhad", "Milad Zafar", ""], ["Chinnam", "Ratna Babu", ""], ["Zhu", "Dongxiao", ""]]}, {"id": "1908.09203", "submitter": "Amanda Askell", "authors": "Irene Solaiman, Miles Brundage, Jack Clark, Amanda Askell, Ariel\n  Herbert-Voss, Jeff Wu, Alec Radford, Gretchen Krueger, Jong Wook Kim, Sarah\n  Kreps, Miles McCain, Alex Newhouse, Jason Blazakis, Kris McGuffie, Jasmine\n  Wang", "title": "Release Strategies and the Social Impacts of Language Models", "comments": "71 pages, report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large language models have a range of beneficial uses: they can assist in\nprose, poetry, and programming; analyze dataset biases; and more. However,\ntheir flexibility and generative capabilities also raise misuse concerns. This\nreport discusses OpenAI's work related to the release of its GPT-2 language\nmodel. It discusses staged release, which allows time between model releases to\nconduct risk and benefit analyses as model sizes increased. It also discusses\nongoing partnership-based research and provides recommendations for better\ncoordination and responsible publication in AI.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 20:41:40 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 03:54:12 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Solaiman", "Irene", ""], ["Brundage", "Miles", ""], ["Clark", "Jack", ""], ["Askell", "Amanda", ""], ["Herbert-Voss", "Ariel", ""], ["Wu", "Jeff", ""], ["Radford", "Alec", ""], ["Krueger", "Gretchen", ""], ["Kim", "Jong Wook", ""], ["Kreps", "Sarah", ""], ["McCain", "Miles", ""], ["Newhouse", "Alex", ""], ["Blazakis", "Jason", ""], ["McGuffie", "Kris", ""], ["Wang", "Jasmine", ""]]}, {"id": "1908.09209", "submitter": "Zhe Gan", "authors": "Huazheng Wang, Zhe Gan, Xiaodong Liu, Jingjing Liu, Jianfeng Gao,\n  Hongning Wang", "title": "Adversarial Domain Adaptation for Machine Reading Comprehension", "comments": "Accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on unsupervised domain adaptation for Machine Reading\nComprehension (MRC), where the source domain has a large amount of labeled\ndata, while only unlabeled passages are available in the target domain. To this\nend, we propose an Adversarial Domain Adaptation framework (AdaMRC), where\n($i$) pseudo questions are first generated for unlabeled passages in the target\ndomain, and then ($ii$) a domain classifier is incorporated into an MRC model\nto predict which domain a given passage-question pair comes from. The\nclassifier and the passage-question encoder are jointly trained using\nadversarial learning to enforce domain-invariant representation learning.\nComprehensive evaluations demonstrate that our approach ($i$) is generalizable\nto different MRC models and datasets, ($ii$) can be combined with pre-trained\nlarge-scale language models (such as ELMo and BERT), and ($iii$) can be\nextended to semi-supervised learning.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 21:08:26 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Wang", "Huazheng", ""], ["Gan", "Zhe", ""], ["Liu", "Xiaodong", ""], ["Liu", "Jingjing", ""], ["Gao", "Jianfeng", ""], ["Wang", "Hongning", ""]]}, {"id": "1908.09246", "submitter": "Rui Wang", "authors": "Rui Wang and Deyu Zhou and Yulan He", "title": "Open Event Extraction from Online Text using a Generative Adversarial\n  Network", "comments": "Accepted by EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To extract the structured representations of open-domain events, Bayesian\ngraphical models have made some progress. However, these approaches typically\nassume that all words in a document are generated from a single event. While\nthis may be true for short text such as tweets, such an assumption does not\ngenerally hold for long text such as news articles. Moreover, Bayesian\ngraphical models often rely on Gibbs sampling for parameter inference which may\ntake long time to converge. To address these limitations, we propose an event\nextraction model based on Generative Adversarial Nets, called\nAdversarial-neural Event Model (AEM). AEM models an event with a Dirichlet\nprior and uses a generator network to capture the patterns underlying latent\nevents. A discriminator is used to distinguish documents reconstructed from the\nlatent events and the original documents. A byproduct of the discriminator is\nthat the features generated by the learned discriminator network allow the\nvisualization of the extracted events. Our model has been evaluated on two\nTwitter datasets and a news article dataset. Experimental results show that our\nmodel outperforms the baseline approaches on all the datasets, with more\nsignificant improvements observed on the news article dataset where an increase\nof 15\\% is observed in F-measure.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 03:17:38 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Wang", "Rui", ""], ["Zhou", "Deyu", ""], ["He", "Yulan", ""]]}, {"id": "1908.09282", "submitter": "Taeuk Kim", "authors": "Kang Min Yoo, Taeuk Kim, Sang-goo Lee", "title": "Don't Just Scratch the Surface: Enhancing Word Representations for\n  Korean with Hanja", "comments": "7 pages (5 main pages, 2 appendix pages), 1 figure, accepted in EMNLP\n  2019 (Conference on Empirical Methods in Natural Language Processing)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple yet effective approach for improving Korean word\nrepresentations using additional linguistic annotation (i.e. Hanja). We employ\ncross-lingual transfer learning in training word representations by leveraging\nthe fact that Hanja is closely related to Chinese. We evaluate the intrinsic\nquality of representations learned through our approach using the word analogy\nand similarity tests. In addition, we demonstrate their effectiveness on\nseveral downstream tasks, including a novel Korean news headline generation\ntask.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 08:57:50 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 06:35:15 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 01:47:24 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Yoo", "Kang Min", ""], ["Kim", "Taeuk", ""], ["Lee", "Sang-goo", ""]]}, {"id": "1908.09283", "submitter": "Yong Hu", "authors": "Yong Hu, Heyan Huang, Tian Lan, Xiaochi Wei, Yuxiang Nie, Jiarui Qi,\n  Liner Yang, Xian-Ling Mao", "title": "Multi-task Learning for Low-resource Second Language Acquisition\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Second language acquisition (SLA) modeling is to predict whether second\nlanguage learners could correctly answer the questions according to what they\nhave learned. It is a fundamental building block of the personalized learning\nsystem and has attracted more and more attention recently. However, as far as\nwe know, almost all existing methods cannot work well in low-resource scenarios\ndue to lacking of training data. Fortunately, there are some latent common\npatterns among different language-learning tasks, which gives us an opportunity\nto solve the low-resource SLA modeling problem. Inspired by this idea, in this\npaper, we propose a novel SLA modeling method, which learns the latent common\npatterns among different language-learning datasets by multi-task learning and\nare further applied to improving the prediction performance in low-resource\nscenarios. Extensive experiments show that the proposed method performs much\nbetter than the state-of-the-art baselines in the low-resource scenario.\nMeanwhile, it also obtains improvement slightly in the non-low-resource\nscenario.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 09:05:06 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 06:53:11 GMT"}, {"version": "v3", "created": "Tue, 19 May 2020 12:02:24 GMT"}, {"version": "v4", "created": "Mon, 31 Aug 2020 07:56:21 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Hu", "Yong", ""], ["Huang", "Heyan", ""], ["Lan", "Tian", ""], ["Wei", "Xiaochi", ""], ["Nie", "Yuxiang", ""], ["Qi", "Jiarui", ""], ["Yang", "Liner", ""], ["Mao", "Xian-Ling", ""]]}, {"id": "1908.09324", "submitter": "Xu Tan", "authors": "Xu Tan, Jiale Chen, Di He, Yingce Xia, Tao Qin and Tie-Yan Liu", "title": "Multilingual Neural Machine Translation with Language Clustering", "comments": "Accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual neural machine translation (NMT), which translates multiple\nlanguages using a single model, is of great practical importance due to its\nadvantages in simplifying the training process, reducing online maintenance\ncosts, and enhancing low-resource and zero-shot translation. Given there are\nthousands of languages in the world and some of them are very different, it is\nextremely burdensome to handle them all in a single model or use a separate\nmodel for each language pair. Therefore, given a fixed resource budget, e.g.,\nthe number of models, how to determine which languages should be supported by\none model is critical to multilingual NMT, which, unfortunately, has been\nignored by previous work. In this work, we develop a framework that clusters\nlanguages into different groups and trains one multilingual model for each\ncluster. We study two methods for language clustering: (1) using prior\nknowledge, where we cluster languages according to language family, and (2)\nusing language embedding, in which we represent each language by an embedding\nvector and cluster them in the embedding space. In particular, we obtain the\nembedding vectors of all the languages by training a universal neural machine\ntranslation model. Our experiments on 23 languages show that the first\nclustering method is simple and easy to understand but leading to suboptimal\ntranslation accuracy, while the second method sufficiently captures the\nrelationship among languages well and improves the translation accuracy for\nalmost all the languages over baseline methods\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 13:27:57 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Tan", "Xu", ""], ["Chen", "Jiale", ""], ["He", "Di", ""], ["Xia", "Yingce", ""], ["Qin", "Tao", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1908.09329", "submitter": "Xu Tan", "authors": "Xu Tan, Yingce Xia, Lijun Wu and Tao Qin", "title": "Efficient Bidirectional Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The encoder-decoder based neural machine translation usually generates a\ntarget sequence token by token from left to right. Due to error propagation,\nthe tokens in the right side of the generated sequence are usually of poorer\nquality than those in the left side. In this paper, we propose an efficient\nmethod to generate a sequence in both left-to-right and right-to-left manners\nusing a single encoder and decoder, combining the advantages of both generation\ndirections. Experiments on three translation tasks show that our method\nachieves significant improvements over conventional unidirectional approach.\nCompared with ensemble methods that train and combine two models with different\ngeneration directions, our method saves 50% model parameters and about 40%\ntraining time, and also improve inference speed.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 13:59:03 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Tan", "Xu", ""], ["Xia", "Yingce", ""], ["Wu", "Lijun", ""], ["Qin", "Tao", ""]]}, {"id": "1908.09341", "submitter": "Artem Artemov", "authors": "Artem Artemov, Boris Alekseev", "title": "A Method for Estimating the Proximity of Vector Representation Groups in\n  Multidimensional Space. On the Example of the Paraphrase Task", "comments": "8 pages, 1 figure, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The following paper presents a method of comparing two sets of vectors. The\nmethod can be applied in all tasks, where it is necessary to measure the\ncloseness of two objects presented as sets of vectors. It may be applicable\nwhen we compare the meanings of two sentences as part of the problem of\nparaphrasing. This is the problem of measuring semantic similarity of two\nsentences (group of words). The existing methods are not sensible for the word\norder or syntactic connections in the considered sentences. The method appears\nto be advantageous because it neither presents a group of words as one scalar\nvalue, nor does it try to show the closeness through an aggregation vector,\nwhich is mean for the set of vectors. Instead of that we measure the cosine of\nthe angle as the mean for the first group vectors projections (the context) on\none side and each vector of the second group on the other side. The similarity\nof two sentences defined by these means does not lose any semantic\ncharacteristics and takes account of the words traits. The method was verified\non the comparison of sentence pairs in Russian.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 14:54:49 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 13:22:14 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Artemov", "Artem", ""], ["Alekseev", "Boris", ""]]}, {"id": "1908.09355", "submitter": "Zhe Gan", "authors": "Siqi Sun, Yu Cheng, Zhe Gan, Jingjing Liu", "title": "Patient Knowledge Distillation for BERT Model Compression", "comments": "Accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language models such as BERT have proven to be highly effective\nfor natural language processing (NLP) tasks. However, the high demand for\ncomputing resources in training such models hinders their application in\npractice. In order to alleviate this resource hunger in large-scale model\ntraining, we propose a Patient Knowledge Distillation approach to compress an\noriginal large model (teacher) into an equally-effective lightweight shallow\nnetwork (student). Different from previous knowledge distillation methods,\nwhich only use the output from the last layer of the teacher network for\ndistillation, our student model patiently learns from multiple intermediate\nlayers of the teacher model for incremental knowledge extraction, following two\nstrategies: ($i$) PKD-Last: learning from the last $k$ layers; and ($ii$)\nPKD-Skip: learning from every $k$ layers. These two patient distillation\nschemes enable the exploitation of rich information in the teacher's hidden\nlayers, and encourage the student model to patiently learn from and imitate the\nteacher through a multi-layer distillation process. Empirically, this\ntranslates into improved results on multiple NLP tasks with significant gain in\ntraining efficiency, without sacrificing model accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 16:13:24 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Sun", "Siqi", ""], ["Cheng", "Yu", ""], ["Gan", "Zhe", ""], ["Liu", "Jingjing", ""]]}, {"id": "1908.09368", "submitter": "Akhilesh Sudhakar", "authors": "Akhilesh Sudhakar, Bhargav Upadhyay, Arjun Maheswaran", "title": "Transforming Delete, Retrieve, Generate Approach for Controlled Text\n  Style Transfer", "comments": "11 pages, 6 Tables, 2 Figures, Accepted at 2019 Conference on\n  Empirical Methods in Natural Language Processing (EMNLP - 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text style transfer is the task of transferring the style of text having\ncertain stylistic attributes, while preserving non-stylistic or content\ninformation. In this work we introduce the Generative Style Transformer (GST) -\na new approach to rewriting sentences to a target style in the absence of\nparallel style corpora. GST leverages the power of both, large unsupervised\npre-trained language models as well as the Transformer. GST is a part of a\nlarger `Delete Retrieve Generate' framework, in which we also propose a novel\nmethod of deleting style attributes from the source sentence by exploiting the\ninner workings of the Transformer. Our models outperform state-of-art systems\nacross 5 datasets on sentiment, gender and political slant transfer. We also\npropose the use of the GLEU metric as an automatic metric of evaluation of\nstyle transfer, which we found to compare better with human ratings than the\npredominantly used BLEU score.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 17:34:40 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Sudhakar", "Akhilesh", ""], ["Upadhyay", "Bhargav", ""], ["Maheswaran", "Arjun", ""]]}, {"id": "1908.09369", "submitter": "Sunipa Dev", "authors": "Sunipa Dev, Tao Li, Jeff Phillips, Vivek Srikumar", "title": "On Measuring and Mitigating Biased Inferences of Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Word embeddings carry stereotypical connotations from the text they are\ntrained on, which can lead to invalid inferences in downstream models that rely\non them. We use this observation to design a mechanism for measuring\nstereotypes using the task of natural language inference. We demonstrate a\nreduction in invalid inferences via bias mitigation strategies on static word\nembeddings (GloVe). Further, we show that for gender bias, these techniques\nextend to contextualized embeddings when applied selectively only to the static\ncomponents of contextualized embeddings (ELMo, BERT).\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 17:50:18 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 23:20:40 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2019 17:13:38 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Dev", "Sunipa", ""], ["Li", "Tao", ""], ["Phillips", "Jeff", ""], ["Srikumar", "Vivek", ""]]}, {"id": "1908.09395", "submitter": "Dianqi Li", "authors": "Dianqi Li, Yizhe Zhang, Zhe Gan, Yu Cheng, Chris Brockett, Ming-Ting\n  Sun, Bill Dolan", "title": "Domain Adaptive Text Style Transfer", "comments": "EMNLP 2019, long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text style transfer without parallel data has achieved some practical\nsuccess. However, in the scenario where less data is available, these methods\nmay yield poor performance. In this paper, we examine domain adaptation for\ntext style transfer to leverage massively available data from other domains.\nThese data may demonstrate domain shift, which impedes the benefits of\nutilizing such data for training. To address this challenge, we propose simple\nyet effective domain adaptive text style transfer models, enabling\ndomain-adaptive information exchange. The proposed models presumably learn from\nthe source domain to: (i) distinguish stylized information and generic content\ninformation; (ii) maximally preserve content information; and (iii) adaptively\ntransfer the styles in a domain-aware manner. We evaluate the proposed models\non two style transfer tasks (sentiment and formality) over multiple target\ndomains where only limited non-parallel data is available. Extensive\nexperiments demonstrate the effectiveness of the proposed model compared to the\nbaselines.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 21:29:28 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Li", "Dianqi", ""], ["Zhang", "Yizhe", ""], ["Gan", "Zhe", ""], ["Cheng", "Yu", ""], ["Brockett", "Chris", ""], ["Sun", "Ming-Ting", ""], ["Dolan", "Bill", ""]]}, {"id": "1908.09451", "submitter": "Huanru Henry Mao", "authors": "Huanru Henry Mao, Bodhisattwa Prasad Majumder, Julian McAuley,\n  Garrison W. Cottrell", "title": "Improving Neural Story Generation by Targeted Common Sense Grounding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stories generated with neural language models have shown promise in\ngrammatical and stylistic consistency. However, the generated stories are still\nlacking in common sense reasoning, e.g., they often contain sentences deprived\nof world knowledge. We propose a simple multi-task learning scheme to achieve\nquantitatively better common sense reasoning in language models by leveraging\nauxiliary training signals from datasets designed to provide common sense\ngrounding. When combined with our two-stage fine-tuning pipeline, our method\nachieves improved common sense reasoning and state-of-the-art perplexity on the\nWriting Prompts (Fan et al., 2018) story generation dataset.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 03:29:21 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 04:55:09 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Mao", "Huanru Henry", ""], ["Majumder", "Bodhisattwa Prasad", ""], ["McAuley", "Julian", ""], ["Cottrell", "Garrison W.", ""]]}, {"id": "1908.09507", "submitter": "Lesly Miculicich Werlen", "authors": "Lesly Miculicich, James Henderson", "title": "Partially-supervised Mention Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to detect entity mentions without using syntactic information can be\nuseful for integration and joint optimization with other tasks. However, it is\ncommon to have partially annotated data for this problem. Here, we investigate\ntwo approaches to deal with partial annotation of mentions: weighted loss and\nsoft-target classification. We also propose two neural mention detection\napproaches: a sequence tagging, and an exhaustive search. We evaluate our\nmethods with coreference resolution as a downstream task, using multitask\nlearning. The results show that the recall and F1 score improve for all\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 07:40:33 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Miculicich", "Lesly", ""], ["Henderson", "James", ""]]}, {"id": "1908.09528", "submitter": "Pengjie Ren", "authors": "Pengjie Ren, Zhumin Chen, Christof Monz, Jun Ma, Maarten de Rijke", "title": "Thinking Globally, Acting Locally: Distantly Supervised Global-to-Local\n  Knowledge Selection for Background Based Conversation", "comments": "accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background Based Conversations (BBCs) have been introduced to help\nconversational systems avoid generating overly generic responses. In a BBC, the\nconversation is grounded in a knowledge source. A key challenge in BBCs is\nKnowledge Selection (KS): given a conversational context, try to find the\nappropriate background knowledge (a text fragment containing related facts or\ncomments, etc.) based on which to generate the next response. Previous work\naddresses KS by employing attention and/or pointer mechanisms. These mechanisms\nuse a local perspective, i.e., they select a token at a time based solely on\nthe current decoding state. We argue for the adoption of a global perspective,\ni.e., pre-selecting some text fragments from the background knowledge that\ncould help determine the topic of the next response. We enhance KS in BBCs by\nintroducing a Global-to-Local Knowledge Selection (GLKS) mechanism. Given a\nconversational context and background knowledge, we first learn a topic\ntransition vector to encode the most likely text fragments to be used in the\nnext response, which is then used to guide the local KS at each decoding\ntimestamp. In order to effectively learn the topic transition vector, we\npropose a distantly supervised learning schema. Experimental results show that\nthe GLKS model significantly outperforms state-of-the-art methods in terms of\nboth automatic and human evaluation. More importantly, GLKS achieves this\nwithout requiring any extra annotations, which demonstrates its high degree of\nscalability.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 08:52:33 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 09:15:00 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Ren", "Pengjie", ""], ["Chen", "Zhumin", ""], ["Monz", "Christof", ""], ["Ma", "Jun", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1908.09532", "submitter": "Alberto Poncelas", "authors": "Alberto Poncelas, Gideon Maillette de Buy Wenniger, Andy Way", "title": "Transductive Data-Selection Algorithms for Fine-Tuning Neural Machine\n  Translation", "comments": "Proceedings of The 8th Workshop on Patent and Scientific Literature\n  Translation, 2019, pages 13--23, Dublin", "journal-ref": "Proceedings of The 8th Workshop on Patent and Scientific\n  Literature Translation, 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine Translation models are trained to translate a variety of documents\nfrom one language into another. However, models specifically trained for a\nparticular characteristics of the documents tend to perform better. Fine-tuning\nis a technique for adapting an NMT model to some domain. In this work, we want\nto use this technique to adapt the model to a given test set. In particular, we\nare using transductive data selection algorithms which take advantage the\ninformation of the test set to retrieve sentences from a larger parallel set.\n  In cases where the model is available at translation time (when the test set\nis provided), it can be adapted with a small subset of data, thereby achieving\nbetter performance than a generic model or a domain-adapted model.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 08:55:00 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 15:47:57 GMT"}, {"version": "v3", "created": "Tue, 8 Oct 2019 12:59:03 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Poncelas", "Alberto", ""], ["Wenniger", "Gideon Maillette de Buy", ""], ["Way", "Andy", ""]]}, {"id": "1908.09590", "submitter": "Reinald Kim Amplayo", "authors": "Reinald Kim Amplayo", "title": "Rethinking Attribute Representation and Injection for Sentiment\n  Classification", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text attributes, such as user and product information in product reviews,\nhave been used to improve the performance of sentiment classification models.\nThe de facto standard method is to incorporate them as additional biases in the\nattention mechanism, and more performance gains are achieved by extending the\nmodel architecture. In this paper, we show that the above method is the least\neffective way to represent and inject attributes. To demonstrate this\nhypothesis, unlike previous models with complicated architectures, we limit our\nbase model to a simple BiLSTM with attention classifier, and instead focus on\nhow and where the attributes should be incorporated in the model. We propose to\nrepresent attributes as chunk-wise importance weight matrices and consider four\nlocations in the model (i.e., embedding, encoding, attention, classifier) to\ninject attributes. Experiments show that our proposed method achieves\nsignificant improvements over the standard approach and that attention\nmechanism is the worst location to inject attributes, contradicting prior work.\nWe also outperform the state-of-the-art despite our use of a simple base model.\nFinally, we show that these representations transfer well to other tasks. Model\nimplementation and datasets are released here:\nhttps://github.com/rktamplayo/CHIM.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 10:55:42 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Amplayo", "Reinald Kim", ""]]}, {"id": "1908.09591", "submitter": "Jieh-Sheng Lee", "authors": "Jieh-Sheng Lee and Jieh Hsiang", "title": "Measuring Patent Claim Generation by Span Relevancy", "comments": "10 pages, 2 figures, 2 tables. To be published in the Proceedings of\n  the Thirteenth International Workshop on Juris-informatics (JURISIN 2019),\n  hosted by JSAI-isAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal of patent claim generation is to realize \"augmented inventing\" for\ninventors by leveraging latest Deep Learning techniques. We envision the\npossibility of building an \"auto-complete\" function for inventors to conceive\nbetter inventions in the era of artificial intelligence. In order to generate\npatent claims with good quality, a fundamental question is how to measure it.\nWe tackle the problem from a perspective of claim span relevancy. Patent claim\nlanguage was rarely explored in the NLP field. It is unique in its own way and\ncontains rich explicit and implicit human annotations. In this work, we propose\na span-based approach and a generic framework to measure patent claim\ngeneration quantitatively. In order to study the effectiveness of patent claim\ngeneration, we define a metric to measure whether two consecutive spans in a\ngenerated patent claims are relevant. We treat such relevancy measurement as a\nspan-pair classification problem, following the concept of natural language\ninference. Technically, the span-pair classifier is implemented by fine-tuning\na pre-trained language model. The patent claim generation is implemented by\nfine-tuning the other pre-trained model. Specifically, we fine-tune a\npre-trained Google BERT model to measure the patent claim spans generated by a\nfine-tuned OpenAI GPT-2 model. In this way, we re-use two of the\nstate-of-the-art pre-trained models in the NLP field. Our result shows the\neffectiveness of the span-pair classifier after fine-tuning the pre-trained\nmodel. It further validates the quantitative metric of span relevancy in patent\nclaim generation. Particularly, we found that the span relevancy ratio measured\nby BERT becomes lower when the diversity in GPT-2 text generation becomes\nhigher.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 10:59:55 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 12:20:49 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Lee", "Jieh-Sheng", ""], ["Hsiang", "Jieh", ""]]}, {"id": "1908.09605", "submitter": "Haipeng Sun", "authors": "Haipeng Sun, Rui Wang, Kehai Chen, Masao Utiyama, Eiichiro Sumita,\n  Tiejun Zhao, and Chenhui Chu", "title": "Revisiting Simple Domain Adaptation Methods in Unsupervised Neural\n  Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation has been well-studied in supervised neural machine\ntranslation (SNMT). However, it has not been well-studied for unsupervised\nneural machine translation (UNMT), although UNMT has recently achieved\nremarkable results in several domain-specific language pairs. Besides the\ninconsistent domains between training data and test data for SNMT, there\nsometimes exists an inconsistent domain between two monolingual training data\nfor UNMT. In this work, we empirically show different scenarios for\nunsupervised neural machine translation. Based on these scenarios, we revisit\nthe effect of the existing domain adaptation methods including batch weighting\nand fine tuning methods in UNMT. Finally, we propose modified methods to\nimprove the performances of domain-specific UNMT systems.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 11:36:16 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 05:49:23 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 04:05:26 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Sun", "Haipeng", ""], ["Wang", "Rui", ""], ["Chen", "Kehai", ""], ["Utiyama", "Masao", ""], ["Sumita", "Eiichiro", ""], ["Zhao", "Tiejun", ""], ["Chu", "Chenhui", ""]]}, {"id": "1908.09641", "submitter": "Dar\\'io Garigliotti", "authors": "Dar\\'io Garigliotti", "title": "Semi-supervised Learning for Word Sense Disambiguation", "comments": "This work was awarded the Third Place in the EST 2013 Contest (ISSN\n  1850-2946) at the 42nd JAIIO (Annals of 42nd JAIIO - Argentine Journals of\n  Informatics - ISSN 1850-2776)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is a study of the impact of multiple aspects in a classic\nunsupervised word sense disambiguation algorithm. We identify relevant factors\nin a decision rule algorithm, including the initial labeling of examples, the\nformalization of the rule confidence, and the criteria for accepting a decision\nrule. Some of these factors are only implicitly considered in the original\nliterature. We then propose a lightly supervised version of the algorithm, and\nemploy a pseudo-word-based strategy to evaluate the impact of these factors.\nThe obtained performances are comparable with those of highly optimized\nformulations of the word sense disambiguation method.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 12:35:28 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Garigliotti", "Dar\u00edo", ""]]}, {"id": "1908.09659", "submitter": "Yixin Cao", "authors": "Yixin Cao, Zikun Hu, Tat-Seng Chua, Zhiyuan Liu, Heng Ji", "title": "Low-Resource Name Tagging Learned with Weakly Labeled Data", "comments": "10 pages, 4 figures, EMNLP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Name tagging in low-resource languages or domains suffers from inadequate\ntraining data. Existing work heavily relies on additional information, while\nleaving those noisy annotations unexplored that extensively exist on the web.\nIn this paper, we propose a novel neural model for name tagging solely based on\nweakly labeled (WL) data, so that it can be applied in any low-resource\nsettings. To take the best advantage of all WL sentences, we split them into\nhigh-quality and noisy portions for two modules, respectively: (1) a\nclassification module focusing on the large portion of noisy data can\nefficiently and robustly pretrain the tag classifier by capturing textual\ncontext semantics; and (2) a costly sequence labeling module focusing on\nhigh-quality data utilizes Partial-CRFs with non-entity sampling to achieve\nglobal optimum. Two modules are combined via shared parameters. Extensive\nexperiments involving five low-resource languages and fine-grained food domain\ndemonstrate our superior performance (6% and 7.8% F1 gains on average) as well\nas efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 13:09:37 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Cao", "Yixin", ""], ["Hu", "Zikun", ""], ["Chua", "Tat-Seng", ""], ["Liu", "Zhiyuan", ""], ["Ji", "Heng", ""]]}, {"id": "1908.09716", "submitter": "Yingbo Gao", "authors": "Yingbo Gao, Weiyue Wang and Hermann Ney", "title": "uniblock: Scoring and Filtering Corpus with Unicode Block Information", "comments": "EMNLP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The preprocessing pipelines in Natural Language Processing usually involve a\nstep of removing sentences consisted of illegal characters. The definition of\nillegal characters and the specific removal strategy depend on the task,\nlanguage, domain, etc, which often lead to tiresome and repetitive scripting of\nrules. In this paper, we introduce a simple statistical method, uniblock, to\novercome this problem. For each sentence, uniblock generates a fixed-size\nfeature vector using Unicode block information of the characters. A Gaussian\nmixture model is then estimated on some clean corpus using variational\ninference. The learned model can then be used to score sentences and filter\ncorpus. We present experimental results on Sentiment Analysis, Language\nModeling and Machine Translation, and show the simplicity and effectiveness of\nour method.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 14:55:03 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Gao", "Yingbo", ""], ["Wang", "Weiyue", ""], ["Ney", "Hermann", ""]]}, {"id": "1908.09720", "submitter": "Marcin Pietron", "authors": "Anna Aniol and Marcin Pietron", "title": "Ensemble approach for natural language question answering problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine comprehension, answering a question depending on a given context\nparagraph is a typical task of Natural Language Understanding. It requires to\nmodel complex dependencies existing between the question and the context\nparagraph. There are many neural network models attempting to solve the problem\nof question answering. The best models have been selected, studied and compared\nwith each other. All the selected models are based on the neural attention\nmechanism concept. Additionally, studies on a SQUAD dataset were performed. The\nsubsets of queries were extracted and then each model was analyzed how it deals\nwith specific group of queries. Based on these three model ensemble model was\ncreated and tested on SQUAD dataset. It outperforms the best Mnemonic Reader\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 15:01:24 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 10:14:45 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Aniol", "Anna", ""], ["Pietron", "Marcin", ""]]}, {"id": "1908.09738", "submitter": "Ernest Pusateri", "authors": "Ernest Pusateri, Christophe Van Gysel, Rami Botros, Sameer Badaskar,\n  Mirko Hannemann, Youssef Oualil, Ilya Oparin", "title": "Connecting and Comparing Language Model Interpolation Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we uncover a theoretical connection between two language model\ninterpolation techniques, count merging and Bayesian interpolation. We compare\nthese techniques as well as linear interpolation in three scenarios with\nabundant training data per component model. Consistent with prior work, we show\nthat both count merging and Bayesian interpolation outperform linear\ninterpolation. We include the first (to our knowledge) published comparison of\ncount merging and Bayesian interpolation, showing that the two techniques\nperform similarly. Finally, we argue that other considerations will make\nBayesian interpolation the preferred approach in most circumstances.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 15:32:44 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Pusateri", "Ernest", ""], ["Van Gysel", "Christophe", ""], ["Botros", "Rami", ""], ["Badaskar", "Sameer", ""], ["Hannemann", "Mirko", ""], ["Oualil", "Youssef", ""], ["Oparin", "Ilya", ""]]}, {"id": "1908.09756", "submitter": "Ting Chen", "authors": "Ting Chen and Lala Li and Yizhou Sun", "title": "Differentiable Product Quantization for End-to-End Embedding Compression", "comments": "ICML'2020. Code at\n  https://github.com/chentingpc/dpq_embedding_compression", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding layers are commonly used to map discrete symbols into continuous\nembedding vectors that reflect their semantic meanings. Despite their\neffectiveness, the number of parameters in an embedding layer increases\nlinearly with the number of symbols and poses a critical challenge on memory\nand storage constraints. In this work, we propose a generic and end-to-end\nlearnable compression framework termed differentiable product quantization\n(DPQ). We present two instantiations of DPQ that leverage different\napproximation techniques to enable differentiability in end-to-end learning.\nOur method can readily serve as a drop-in alternative for any existing\nembedding layer. Empirically, DPQ offers significant compression ratios\n(14-238$\\times$) at negligible or no performance cost on 10 datasets across\nthree different language tasks.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 15:56:10 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 03:23:48 GMT"}, {"version": "v3", "created": "Thu, 25 Jun 2020 23:36:28 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Chen", "Ting", ""], ["Li", "Lala", ""], ["Sun", "Yizhou", ""]]}, {"id": "1908.09785", "submitter": "Preslav Nakov", "authors": "Yoan Dinkov, Ivan Koychev, Preslav Nakov", "title": "Detecting Toxicity in News Articles: Application to Bulgarian", "comments": "Fact-checking, source reliability, political ideology, news media,\n  Bulgarian, RANLP-2019. arXiv admin note: text overlap with arXiv:1810.01765", "journal-ref": "RANLP-2019", "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online media aim for reaching ever bigger audience and for attracting ever\nlonger attention span. This competition creates an environment that rewards\nsensational, fake, and toxic news. To help limit their spread and impact, we\npropose and develop a news toxicity detector that can recognize various types\nof toxic content. While previous research primarily focused on English, here we\ntarget Bulgarian. We created a new dataset by crawling a website that for five\nyears has been collecting Bulgarian news articles that were manually\ncategorized into eight toxicity groups. Then we trained a multi-class\nclassifier with nine categories: eight toxic and one non-toxic. We experimented\nwith different representations based on ElMo, BERT, and XLM, as well as with a\nvariety of domain-specific features. Due to the small size of our dataset, we\ncreated a separate model for each feature type, and we ultimately combined\nthese models into a meta-classifier. The evaluation results show an accuracy of\n59.0% and a macro-F1 score of 39.7%, which represent sizable improvements over\nthe majority-class baseline (Acc=30.3%, macro-F1=5.2%).\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 16:37:03 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Dinkov", "Yoan", ""], ["Koychev", "Ivan", ""], ["Nakov", "Preslav", ""]]}, {"id": "1908.09805", "submitter": "Tal Schuster", "authors": "Tal Schuster, Roei Schuster, Darsh J Shah, Regina Barzilay", "title": "The Limitations of Stylometry for Detecting Machine-Generated Fake News", "comments": "Accepted for Computational Linguistics journal (squib). Previously\n  posted with title \"Are We Safe Yet? The Limitations of Distributional\n  Features for Fake News Detection\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in neural language models (LMs) have raised concerns\nabout their potential misuse for automatically spreading misinformation. In\nlight of these concerns, several studies have proposed to detect\nmachine-generated fake news by capturing their stylistic differences from\nhuman-written text. These approaches, broadly termed stylometry, have found\nsuccess in source attribution and misinformation detection in human-written\ntexts. However, in this work, we show that stylometry is limited against\nmachine-generated misinformation. While humans speak differently when trying to\ndeceive, LMs generate stylistically consistent text, regardless of underlying\nmotive. Thus, though stylometry can successfully prevent impersonation by\nidentifying text provenance, it fails to distinguish legitimate LM applications\nfrom those that introduce false information. We create two benchmarks\ndemonstrating the stylistic similarity between malicious and legitimate uses of\nLMs, employed in auto-completion and editing-assistance settings. Our findings\nhighlight the need for non-stylometry approaches in detecting machine-generated\nmisinformation, and open up the discussion on the desired evaluation\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 17:23:22 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 18:32:33 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Schuster", "Tal", ""], ["Schuster", "Roei", ""], ["Shah", "Darsh J", ""], ["Barzilay", "Regina", ""]]}, {"id": "1908.09890", "submitter": "Shikib Mehri", "authors": "Shikib Mehri and Maxine Eskenazi", "title": "Multi-Granularity Representations of Dialog", "comments": "Accepted as a long paper at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural models of dialog rely on generalized latent representations of\nlanguage. This paper introduces a novel training procedure which explicitly\nlearns multiple representations of language at several levels of granularity.\nThe multi-granularity training algorithm modifies the mechanism by which\nnegative candidate responses are sampled in order to control the granularity of\nlearned latent representations. Strong performance gains are observed on the\nnext utterance retrieval task using both the MultiWOZ dataset and the Ubuntu\ndialog corpus. Analysis significantly demonstrates that multiple granularities\nof representation are being learned, and that multi-granularity training\nfacilitates better transfer to downstream tasks.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 19:41:21 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Mehri", "Shikib", ""], ["Eskenazi", "Maxine", ""]]}, {"id": "1908.09892", "submitter": "Geoff Bacon", "authors": "Geoff Bacon and Terry Regier", "title": "Does BERT agree? Evaluating knowledge of structure dependence through\n  agreement relations", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning representations that accurately model semantics is an important goal\nof natural language processing research. Many semantic phenomena depend on\nsyntactic structure. Recent work examines the extent to which state-of-the-art\nmodels for pre-training representations, such as BERT, capture such\nstructure-dependent phenomena, but is largely restricted to one phenomenon in\nEnglish: number agreement between subjects and verbs. We evaluate BERT's\nsensitivity to four types of structure-dependent agreement relations in a new\nsemi-automatically curated dataset across 26 languages. We show that both the\nsingle-language and multilingual BERT models capture syntax-sensitive agreement\npatterns well in general, but we also highlight the specific linguistic\ncontexts in which their performance degrades.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 19:56:08 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Bacon", "Geoff", ""], ["Regier", "Terry", ""]]}, {"id": "1908.09898", "submitter": "Yixin Cao", "authors": "Yixin Cao, Zhiyuan Liu, Chengjiang Li, Zhiyuan Liu, Juanzi Li,\n  Tat-Seng Chua", "title": "Multi-Channel Graph Neural Network for Entity Alignment", "comments": "10 pages, 4 figures, ACL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity alignment typically suffers from the issues of structural\nheterogeneity and limited seed alignments. In this paper, we propose a novel\nMulti-channel Graph Neural Network model (MuGNN) to learn alignment-oriented\nknowledge graph (KG) embeddings by robustly encoding two KGs via multiple\nchannels. Each channel encodes KGs via different relation weighting schemes\nwith respect to self-attention towards KG completion and cross-KG attention for\npruning exclusive entities respectively, which are further combined via pooling\ntechniques. Moreover, we also infer and transfer rule knowledge for completing\ntwo KGs consistently. MuGNN is expected to reconcile the structural differences\nof two KGs, and thus make better use of seed alignments. Extensive experiments\non five publicly available datasets demonstrate our superior performance (5%\nHits@1 up on average).\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 20:05:37 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Cao", "Yixin", ""], ["Liu", "Zhiyuan", ""], ["Li", "Chengjiang", ""], ["Liu", "Zhiyuan", ""], ["Li", "Juanzi", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "1908.09919", "submitter": "Erhan Sezerer", "authors": "Erhan Sezerer, Ozan Polatbilek, Selma Tekir", "title": "Gender Prediction from Tweets: Improving Neural Representations with\n  Hand-Crafted Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Author profiling is the characterization of an author through some key\nattributes such as gender, age, and language. In this paper, a RNN model with\nAttention (RNNwA) is proposed to predict the gender of a twitter user using\ntheir tweets. Both word level and tweet level attentions are utilized to learn\n'where to look'. This model\n(https://github.com/Darg-Iztech/gender-prediction-from-tweets) is improved by\nconcatenating LSA-reduced n-gram features with the learned neural\nrepresentation of a user. Both models are tested on three languages: English,\nSpanish, Arabic. The improved version of the proposed model (RNNwA + n-gram)\nachieves state-of-the-art performance on English and has competitive results on\nSpanish and Arabic.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 07:36:48 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 10:27:36 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Sezerer", "Erhan", ""], ["Polatbilek", "Ozan", ""], ["Tekir", "Selma", ""]]}, {"id": "1908.09920", "submitter": "Han Fu", "authors": "Han Fu, Chenghao Liu, Jianling Sun", "title": "Reference Network for Neural Machine Translation", "comments": "11 pages, 3 figures, accepted by ACL-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) has achieved notable success in recent\nyears. Such a framework usually generates translations in isolation. In\ncontrast, human translators often refer to reference data, either rephrasing\nthe intricate sentence fragments with common terms in source language, or just\naccessing to the golden translation directly. In this paper, we propose a\nReference Network to incorporate referring process into translation decoding of\nNMT. To construct a \\emph{reference book}, an intuitive way is to store the\ndetailed translation history with extra memory, which is computationally\nexpensive. Instead, we employ Local Coordinates Coding (LCC) to obtain global\ncontext vectors containing monolingual and bilingual contextual information for\nNMT decoding. Experimental results on Chinese-English and English-German tasks\ndemonstrate that our proposed model is effective in improving the translation\nquality with lightweight computation cost.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 08:58:49 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Fu", "Han", ""], ["Liu", "Chenghao", ""], ["Sun", "Jianling", ""]]}, {"id": "1908.09921", "submitter": "Maxime Amblard", "authors": "Maria-Andrea Cruz-Bland\\'on (IDMC), Gosse Minnema (IDMC), Aria\n  Nourbakhsh (IDMC), Maria Boritchev (ENS Lyon, LORIA, SEMAGRAMME), Maxime\n  Amblard (SEMAGRAMME, LORIA)", "title": "Toward Dialogue Modeling: A Semantic Annotation Scheme for Questions and\n  Answers", "comments": null, "journal-ref": "LAW XIII 2019 - Linguistic Annotation Workshop - ACL Workshop, Jul\n  2019, Florence, Italy", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present study proposes an annotation scheme for classifying the content\nand discourse contribution of question-answer pairs. We propose detailed\nguidelines for using the scheme and apply them to dialogues in English,\nSpanish, and Dutch. Finally, we report on initial machine learning experiments\nfor automatic annotation.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 11:04:48 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Cruz-Bland\u00f3n", "Maria-Andrea", "", "IDMC"], ["Minnema", "Gosse", "", "IDMC"], ["Nourbakhsh", "Aria", "", "IDMC"], ["Boritchev", "Maria", "", "ENS Lyon, LORIA, SEMAGRAMME"], ["Amblard", "Maxime", "", "SEMAGRAMME, LORIA"]]}, {"id": "1908.09936", "submitter": "Adrian De Wynter", "authors": "Adrian de Wynter and Lambert Mathias", "title": "Leveraging External Knowledge for Out-Of-Vocabulary Entity Labeling", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dealing with previously unseen slots is a challenging problem in a real-world\nmulti-domain dialogue state tracking task. Other approaches rely on predefined\nmappings to generate candidate slot keys, as well as their associated values.\nThis, however, may fail when the key, the value, or both, are not seen during\ntraining. To address this problem we introduce a neural network that leverages\nexternal knowledge bases (KBs) to better classify out-of-vocabulary slot keys\nand values. This network projects the slot into an attribute space derived from\nthe KB, and, by leveraging similarities in this space, we propose candidate\nslot keys and values to the dialogue state tracker. We provide extensive\nexperiments that demonstrate that our stratagem can improve upon a previous\napproach, which relies on predefined candidate mappings. In particular, we\nevaluate this approach by training a state-of-the-art model with candidates\ngenerated from our network, and obtained relative increases of 57.7% and 82.7%\nin F1 score and accuracy, respectively, for the aforementioned model, when\ncompared to the current candidate generation strategy.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 22:08:55 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["de Wynter", "Adrian", ""], ["Mathias", "Lambert", ""]]}, {"id": "1908.09940", "submitter": "Jonathan Herzig", "authors": "Jonathan Herzig, Jonathan Berant", "title": "Don't paraphrase, detect! Rapid and Effective Data Collection for\n  Semantic Parsing", "comments": "EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major hurdle on the road to conversational interfaces is the difficulty in\ncollecting data that maps language utterances to logical forms. One prominent\napproach for data collection has been to automatically generate pseudo-language\npaired with logical forms, and paraphrase the pseudo-language to natural\nlanguage through crowdsourcing (Wang et al., 2015). However, this data\ncollection procedure often leads to low performance on real data, due to a\nmismatch between the true distribution of examples and the distribution induced\nby the data collection procedure. In this paper, we thoroughly analyze two\nsources of mismatch in this process: the mismatch in logical form distribution\nand the mismatch in language distribution between the true and induced\ndistributions. We quantify the effects of these mismatches, and propose a new\ndata collection approach that mitigates them. Assuming access to unlabeled\nutterances from the true distribution, we combine crowdsourcing with a\nparaphrase model to detect correct logical forms for the unlabeled utterances.\nOn two datasets, our method leads to 70.6 accuracy on average on the true\ndistribution, compared to 51.3 in paraphrasing-based data collection.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 22:15:55 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 00:21:32 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Herzig", "Jonathan", ""], ["Berant", "Jonathan", ""]]}, {"id": "1908.09951", "submitter": "Bilal Ghanem", "authors": "Bilal Ghanem, Paolo Rosso, Francisco Rangel", "title": "An Emotional Analysis of False Information in Social Media and News\n  Articles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fake news is risky since it has been created to manipulate the readers'\nopinions and beliefs. In this work, we compared the language of false news to\nthe real one of real news from an emotional perspective, considering a set of\nfalse information types (propaganda, hoax, clickbait, and satire) from social\nmedia and online news articles sources. Our experiments showed that false\ninformation has different emotional patterns in each of its types, and emotions\nplay a key role in deceiving the reader. Based on that, we proposed a LSTM\nneural network model that is emotionally-infused to detect false news.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 22:49:35 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Ghanem", "Bilal", ""], ["Rosso", "Paolo", ""], ["Rangel", "Francisco", ""]]}, {"id": "1908.09964", "submitter": "Yijun Xiao", "authors": "Yijun Xiao, William Yang Wang", "title": "Text Modeling with Syntax-Aware Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syntactic information contains structures and rules about how text sentences\nare arranged. Incorporating syntax into text modeling methods can potentially\nbenefit both representation learning and generation. Variational autoencoders\n(VAEs) are deep generative models that provide a probabilistic way to describe\nobservations in the latent space. When applied to text data, the latent\nrepresentations are often unstructured. We propose syntax-aware variational\nautoencoders (SAVAEs) that dedicate a subspace in the latent dimensions dubbed\nsyntactic latent to represent syntactic structures of sentences. SAVAEs are\ntrained to infer syntactic latent from either text inputs or parsed syntax\nresults as well as reconstruct original text with inferred latent variables.\nExperiments show that SAVAEs are able to achieve lower reconstruction loss on\nfour different data sets. Furthermore, they are capable of generating examples\nwith modified target syntax.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 00:25:06 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Xiao", "Yijun", ""], ["Wang", "William Yang", ""]]}, {"id": "1908.09982", "submitter": "Genta Indra Winata", "authors": "Genta Indra Winata, Andrea Madotto, Jamin Shin, Elham J. Barezi,\n  Pascale Fung", "title": "On the Effectiveness of Low-Rank Matrix Factorization for LSTM Model\n  Compression", "comments": "Accepted in PACLIC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their ubiquity in NLP tasks, Long Short-Term Memory (LSTM) networks\nsuffer from computational inefficiencies caused by inherent unparallelizable\nrecurrences, which further aggravates as LSTMs require more parameters for\nlarger memory capacity. In this paper, we propose to apply low-rank matrix\nfactorization (MF) algorithms to different recurrences in LSTMs, and explore\nthe effectiveness on different NLP tasks and model components. We discover that\nadditive recurrence is more important than multiplicative recurrence, and\nexplain this by identifying meaningful correlations between matrix norms and\ncompression performance. We compare our approach across two settings: 1)\ncompressing core LSTM recurrences in language models, 2) compressing biLSTM\nlayers of ELMo evaluated in three downstream NLP tasks.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 01:52:07 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Winata", "Genta Indra", ""], ["Madotto", "Andrea", ""], ["Shin", "Jamin", ""], ["Barezi", "Elham J.", ""], ["Fung", "Pascale", ""]]}, {"id": "1908.10001", "submitter": "Bai Li", "authors": "Bai Li, Nanyi Jiang, Joey Sham, Henry Shi, Hussein Fazal", "title": "Real-world Conversational AI for Hotel Bookings", "comments": "Accepted to IEEE AI4I 2019 (International Conference on Artificial\n  Intelligence for Industries)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a real-world conversational AI system to search for\nand book hotels through text messaging. Our architecture consists of a\nframe-based dialogue management system, which calls machine learning models for\nintent classification, named entity recognition, and information retrieval\nsubtasks. Our chatbot has been deployed on a commercial scale, handling tens of\nthousands of hotel searches every day. We describe the various opportunities\nand challenges of developing a chatbot in the travel industry.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 03:13:53 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Li", "Bai", ""], ["Jiang", "Nanyi", ""], ["Sham", "Joey", ""], ["Shi", "Henry", ""], ["Fazal", "Hussein", ""]]}, {"id": "1908.10023", "submitter": "Dian Yu", "authors": "Dian Yu and Zhou Yu", "title": "MIDAS: A Dialog Act Annotation Scheme for Open Domain Human Machine\n  Spoken Conversations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialog act prediction is an essential language comprehension task for both\ndialog system building and discourse analysis. Previous dialog act schemes,\nsuch as SWBD-DAMSL, are designed for human-human conversations, in which\nconversation partners have perfect language understanding ability. In this\npaper, we design a dialog act annotation scheme, MIDAS (Machine Interaction\nDialog Act Scheme), targeted on open-domain human-machine conversations. MIDAS\nis designed to assist machines which have limited ability to understand their\nhuman partners. MIDAS has a hierarchical structure and supports multi-label\nannotations. We collected and annotated a large open-domain human-machine\nspoken conversation dataset (consists of 24K utterances). To show the\napplicability of the scheme, we leverage transfer learning methods to train a\nmulti-label dialog act prediction model and reach an F1 score of 0.79.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 04:36:31 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Yu", "Dian", ""], ["Yu", "Zhou", ""]]}, {"id": "1908.10063", "submitter": "Dogu Tan Araci", "authors": "Dogu Araci", "title": "FinBERT: Financial Sentiment Analysis with Pre-trained Language Models", "comments": "This thesis is submitted in partial fulfillment for the degree of\n  Master of Science in Information Studies: Data Science, University of\n  Amsterdam. June 25, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial sentiment analysis is a challenging task due to the specialized\nlanguage and lack of labeled data in that domain. General-purpose models are\nnot effective enough because of the specialized language used in a financial\ncontext. We hypothesize that pre-trained language models can help with this\nproblem because they require fewer labeled examples and they can be further\ntrained on domain-specific corpora. We introduce FinBERT, a language model\nbased on BERT, to tackle NLP tasks in the financial domain. Our results show\nimprovement in every measured metric on current state-of-the-art results for\ntwo financial sentiment analysis datasets. We find that even with a smaller\ntraining set and fine-tuning only a part of the model, FinBERT outperforms\nstate-of-the-art machine learning methods.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 07:40:48 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Araci", "Dogu", ""]]}, {"id": "1908.10084", "submitter": "Nils Reimers", "authors": "Nils Reimers and Iryna Gurevych", "title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks", "comments": "Published at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new\nstate-of-the-art performance on sentence-pair regression tasks like semantic\ntextual similarity (STS). However, it requires that both sentences are fed into\nthe network, which causes a massive computational overhead: Finding the most\nsimilar pair in a collection of 10,000 sentences requires about 50 million\ninference computations (~65 hours) with BERT. The construction of BERT makes it\nunsuitable for semantic similarity search as well as for unsupervised tasks\nlike clustering.\n  In this publication, we present Sentence-BERT (SBERT), a modification of the\npretrained BERT network that use siamese and triplet network structures to\nderive semantically meaningful sentence embeddings that can be compared using\ncosine-similarity. This reduces the effort for finding the most similar pair\nfrom 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while\nmaintaining the accuracy from BERT.\n  We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning\ntasks, where it outperforms other state-of-the-art sentence embeddings methods.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 08:50:17 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Reimers", "Nils", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1908.10090", "submitter": "Felix Stahlberg", "authors": "Felix Stahlberg and Bill Byrne", "title": "On NMT Search Errors and Model Errors: Cat Got Your Tongue?", "comments": "EMNLP-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on search errors and model errors in neural machine translation\n(NMT). We present an exact inference procedure for neural sequence models based\non a combination of beam search and depth-first search. We use our exact search\nto find the global best model scores under a Transformer base model for the\nentire WMT15 English-German test set. Surprisingly, beam search fails to find\nthese global best model scores in most cases, even with a very large beam size\nof 100. For more than 50% of the sentences, the model in fact assigns its\nglobal best score to the empty translation, revealing a massive failure of\nneural models in properly accounting for adequacy. We show by constraining\nsearch with a minimum translation length that at the root of the problem of\nempty translations lies an inherent bias towards shorter translations. We\nconclude that vanilla NMT in its current form requires just the right amount of\nbeam search errors, which, from a modelling perspective, is a highly\nunsatisfactory conclusion indeed, as the model often prefers an empty\ntranslation.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 09:08:12 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Stahlberg", "Felix", ""], ["Byrne", "Bill", ""]]}, {"id": "1908.10118", "submitter": "Prasanna Raj Noel Dabre", "authors": "Raj Dabre and Atsushi Fujita", "title": "Multi-Layer Softmaxing during Training Neural Machine Translation for\n  Flexible Decoding with Fewer Layers", "comments": "Fixed numeric typos and corresponding explanations in the running\n  text in the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper proposes a novel procedure for training an encoder-decoder based\ndeep neural network which compresses NxM models into a single model enabling us\nto dynamically choose the number of encoder and decoder layers for decoding.\nUsually, the output of the last layer of the N-layer encoder is fed to the\nM-layer decoder, and the output of the last decoder layer is used to compute\nsoftmax loss. Instead, our method computes a single loss consisting of NxM\nlosses: the softmax loss for the output of each of the M decoder layers derived\nusing the output of each of the N encoder layers. A single model trained by our\nmethod can be used for decoding with an arbitrary fewer number of encoder and\ndecoder layers. In practical scenarios, this (a) enables faster decoding with\ninsignificant losses in translation quality and (b) alleviates the need to\ntrain NxM models, thereby saving space. We take a case study of neural machine\ntranslation and show the advantage and give a cost-benefit analysis of our\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 10:17:24 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 09:11:47 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Dabre", "Raj", ""], ["Fujita", "Atsushi", ""]]}, {"id": "1908.10149", "submitter": "Michael Barz", "authors": "Michael Barz and Daniel Sonntag", "title": "Incremental Improvement of a Question Answering System by Re-ranking\n  Answer Candidates using Machine Learning", "comments": "Accepted for oral presentation at tenth International Workshop on\n  Spoken Dialogue Systems Technology (IWSDS) 2019", "journal-ref": null, "doi": "10.1007/978-981-15-9323-9_34", "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We implement a method for re-ranking top-10 results of a state-of-the-art\nquestion answering (QA) system. The goal of our re-ranking approach is to\nimprove the answer selection given the user question and the top-10 candidates.\nWe focus on improving deployed QA systems that do not allow re-training or\nre-training comes at a high cost. Our re-ranking approach learns a similarity\nfunction using n-gram based features using the query, the answer and the\ninitial system confidence as input. Our contributions are: (1) we generate a QA\ntraining corpus starting from 877 answers from the customer care domain of\nT-Mobile Austria, (2) we implement a state-of-the-art QA pipeline using neural\nsentence embeddings that encode queries in the same space than the answer\nindex, and (3) we evaluate the QA pipeline and our re-ranking approach using a\nseparately provided test set. The test set can be considered to be available\nafter deployment of the system, e.g., based on feedback of users. Our results\nshow that the system performance, in terms of top-n accuracy and the mean\nreciprocal rank, benefits from re-ranking using gradient boosted regression\ntrees. On average, the mean reciprocal rank improves by 9.15%.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 11:54:23 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Barz", "Michael", ""], ["Sonntag", "Daniel", ""]]}, {"id": "1908.10261", "submitter": "Preslav Nakov", "authors": "Lilia Simeonova, Kiril Simov, Petya Osenova, Preslav Nakov", "title": "A Morpho-Syntactically Informed LSTM-CRF Model for Named Entity\n  Recognition", "comments": "named entity recognition; Bulgarian NER; morphology; morpho-syntax", "journal-ref": "RANLP-2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a morphologically informed model for named entity recognition,\nwhich is based on LSTM-CRF architecture and combines word embeddings, Bi-LSTM\ncharacter embeddings, part-of-speech (POS) tags, and morphological information.\nWhile previous work has focused on learning from raw word input, using word and\ncharacter embeddings only, we show that for morphologically rich languages,\nsuch as Bulgarian, access to POS information contributes more to the\nperformance gains than the detailed morphological information. Thus, we show\nthat named entity recognition needs only coarse-grained POS tags, but at the\nsame time it can benefit from simultaneously using some POS information of\ndifferent granularity. Our evaluation results over a standard dataset show\nsizable improvements over the state-of-the-art for Bulgarian NER.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 15:10:24 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Simeonova", "Lilia", ""], ["Simov", "Kiril", ""], ["Osenova", "Petya", ""], ["Nakov", "Preslav", ""]]}, {"id": "1908.10275", "submitter": "Fabio Celli PhD", "authors": "Fabio Celli", "title": "The Wiki Music dataset: A tool for computational analysis of popular\n  music", "comments": "Copyright 2019, Fabio Celli. 5 pages. Keywords: Popular Music,\n  Computational Music analysis, Wikipedia, Natural Language Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Is it possible use algorithms to find trends in the history of popular music?\nAnd is it possible to predict the characteristics of future music genres? In\norder to answer these questions, we produced a hand-crafted dataset with the\nintent to put together features about style, psychology, sociology and\ntypology, annotated by music genre and indexed by time and decade. We collected\na list of popular genres by decade from Wikipedia and scored music genres based\non Wikipedia descriptions. Using statistical and machine learning techniques,\nwe find trends in the musical preferences and use time series forecasting to\nevaluate the prediction of future music genres.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 15:30:56 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Celli", "Fabio", ""]]}, {"id": "1908.10285", "submitter": "Sandro Pezzelle", "authors": "Sandro Pezzelle and Raquel Fern\\'andez", "title": "Is the Red Square Big? MALeViC: Modeling Adjectives Leveraging Visual\n  Contexts", "comments": "Accepted at EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work aims at modeling how the meaning of gradable adjectives of size\n(`big', `small') can be learned from visually-grounded contexts. Inspired by\ncognitive and linguistic evidence showing that the use of these expressions\nrelies on setting a threshold that is dependent on a specific context, we\ninvestigate the ability of multi-modal models in assessing whether an object is\n`big' or `small' in a given visual scene. In contrast with the standard\ncomputational approach that simplistically treats gradable adjectives as\n`fixed' attributes, we pose the problem as relational: to be successful, a\nmodel has to consider the full visual context. By means of four main tasks, we\nshow that state-of-the-art models (but not a relatively strong baseline) can\nlearn the function subtending the meaning of size adjectives, though their\nperformance is found to decrease while moving from simple to more complex\ntasks. Crucially, models fail in developing abstract representations of\ngradable adjectives that can be used compositionally.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 15:44:17 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Pezzelle", "Sandro", ""], ["Fern\u00e1ndez", "Raquel", ""]]}, {"id": "1908.10322", "submitter": "Dokook Choe", "authors": "Dokook Choe, Rami Al-Rfou, Mandy Guo, Heeyoung Lee, Noah Constant", "title": "Bridging the Gap for Tokenizer-Free Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purely character-based language models (LMs) have been lagging in quality on\nlarge scale datasets, and current state-of-the-art LMs rely on word\ntokenization. It has been assumed that injecting the prior knowledge of a\ntokenizer into the model is essential to achieving competitive results. In this\npaper, we show that contrary to this conventional wisdom, tokenizer-free LMs\nwith sufficient capacity can achieve competitive performance on a large scale\ndataset. We train a vanilla transformer network with 40 self-attention layers\non the One Billion Word (lm1b) benchmark and achieve a new state of the art for\ntokenizer-free LMs, pushing these models to be on par with their word-based\ncounterparts.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 16:53:59 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Choe", "Dokook", ""], ["Al-Rfou", "Rami", ""], ["Guo", "Mandy", ""], ["Lee", "Heeyoung", ""], ["Constant", "Noah", ""]]}, {"id": "1908.10328", "submitter": "Pinelopi Papalampidi", "authors": "Pinelopi Papalampidi, Frank Keller and Mirella Lapata", "title": "Movie Plot Analysis via Turning Point Identification", "comments": "Accepted to appear at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to screenwriting theory, turning points (e.g., change of plans,\nmajor setback, climax) are crucial narrative moments within a screenplay: they\ndefine the plot structure, determine its progression and segment the screenplay\ninto thematic units (e.g., setup, complications, aftermath). We propose the\ntask of turning point identification in movies as a means of analyzing their\nnarrative structure. We argue that turning points and the segmentation they\nprovide can facilitate processing long, complex narratives, such as\nscreenplays, for summarization and question answering. We introduce a dataset\nconsisting of screenplays and plot synopses annotated with turning points and\npresent an end-to-end neural network model that identifies turning points in\nplot synopses and projects them onto scenes in screenplays. Our model\noutperforms strong baselines based on state-of-the-art sentence representations\nand the expected position of turning points.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 16:59:18 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 12:41:26 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Papalampidi", "Pinelopi", ""], ["Keller", "Frank", ""], ["Lapata", "Mirella", ""]]}, {"id": "1908.10331", "submitter": "Heriberto Cuay\\'ahuitl", "authors": "Heriberto Cuay\\'ahuitl, Donghyeon Lee, Seonghan Ryu, Sungja Choi,\n  Inchul Hwang, Jihie Kim", "title": "Deep Reinforcement Learning for Chatbots Using Clustered Actions and\n  Human-Likeness Rewards", "comments": "In International Joint Conference of Neural Networks (IJCNN), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training chatbots using the reinforcement learning paradigm is challenging\ndue to high-dimensional states, infinite action spaces and the difficulty in\nspecifying the reward function. We address such problems using clustered\nactions instead of infinite actions, and a simple but promising reward function\nbased on human-likeness scores derived from human-human dialogue data. We train\nDeep Reinforcement Learning (DRL) agents using chitchat data in raw\ntext---without any manual annotations. Experimental results using different\nsplits of training data report the following. First, that our agents learn\nreasonable policies in the environments they get familiarised with, but their\nperformance drops substantially when they are exposed to a test set of unseen\ndialogues. Second, that the choice of sentence embedding size between 100 and\n300 dimensions is not significantly different on test data. Third, that our\nproposed human-likeness rewards are reasonable for training chatbots as long as\nthey use lengthy dialogue histories of >=10 sentences.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 17:06:15 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Cuay\u00e1huitl", "Heriberto", ""], ["Lee", "Donghyeon", ""], ["Ryu", "Seonghan", ""], ["Choi", "Sungja", ""], ["Hwang", "Inchul", ""], ["Kim", "Jihie", ""]]}, {"id": "1908.10383", "submitter": "Yuning Mao", "authors": "Yuning Mao, Liyuan Liu, Qi Zhu, Xiang Ren, Jiawei Han", "title": "Facet-Aware Evaluation for Extractive Summarization", "comments": "ACL 2020, Long Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonly adopted metrics for extractive summarization focus on lexical\noverlap at the token level. In this paper, we present a facet-aware evaluation\nsetup for better assessment of the information coverage in extracted summaries.\nSpecifically, we treat each sentence in the reference summary as a\n\\textit{facet}, identify the sentences in the document that express the\nsemantics of each facet as \\textit{support sentences} of the facet, and\nautomatically evaluate extractive summarization methods by comparing the\nindices of extracted sentences and support sentences of all the facets in the\nreference summary. To facilitate this new evaluation setup, we construct an\nextractive version of the CNN/Daily Mail dataset and perform a thorough\nquantitative investigation, through which we demonstrate that facet-aware\nevaluation manifests better correlation with human judgment than ROUGE, enables\nfine-grained evaluation as well as comparative analysis, and reveals valuable\ninsights of state-of-the-art summarization methods. Data can be found at\nhttps://github.com/morningmoni/FAR.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 18:03:12 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 04:12:38 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Mao", "Yuning", ""], ["Liu", "Liyuan", ""], ["Zhu", "Qi", ""], ["Ren", "Xiang", ""], ["Han", "Jiawei", ""]]}, {"id": "1908.10419", "submitter": "Yuning Mao", "authors": "Yuning Mao, Jingjing Tian, Jiawei Han, Xiang Ren", "title": "Hierarchical Text Classification with Reinforced Label Assignment", "comments": "EMNLP 2019", "journal-ref": null, "doi": "10.18653/v1/D19-1042", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While existing hierarchical text classification (HTC) methods attempt to\ncapture label hierarchies for model training, they either make local decisions\nregarding each label or completely ignore the hierarchy information during\ninference. To solve the mismatch between training and inference as well as\nmodeling label dependencies in a more principled way, we formulate HTC as a\nMarkov decision process and propose to learn a Label Assignment Policy via deep\nreinforcement learning to determine where to place an object and when to stop\nthe assignment process. The proposed method, HiLAP, explores the hierarchy\nduring both training and inference time in a consistent manner and makes\ninter-dependent decisions. As a general framework, HiLAP can incorporate\ndifferent neural encoders as base models for end-to-end training. Experiments\non five public datasets and four base models show that HiLAP yields an average\nimprovement of 33.4% in Macro-F1 over flat classifiers and outperforms\nstate-of-the-art HTC methods by a large margin. Data and code can be found at\nhttps://github.com/morningmoni/HiLAP.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 19:15:26 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Mao", "Yuning", ""], ["Tian", "Jingjing", ""], ["Han", "Jiawei", ""], ["Ren", "Xiang", ""]]}, {"id": "1908.10422", "submitter": "Heriberto Cuay\\'ahuitl", "authors": "Heriberto Cuay\\'ahuitl, Donghyeon Lee, Seonghan Ryu, Yongjin Cho,\n  Sungja Choi, Satish Indurthi, Seunghak Yu, Hyungtak Choi, Inchul Hwang, Jihie\n  Kim", "title": "Ensemble-Based Deep Reinforcement Learning for Chatbots", "comments": "arXiv admin note: text overlap with arXiv:1908.10331", "journal-ref": null, "doi": "10.1016/j.neucom.2019.08.007", "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trainable chatbots that exhibit fluent and human-like conversations remain a\nbig challenge in artificial intelligence. Deep Reinforcement Learning (DRL) is\npromising for addressing this challenge, but its successful application remains\nan open question. This article describes a novel ensemble-based approach\napplied to value-based DRL chatbots, which use finite action sets as a form of\nmeaning representation. In our approach, while dialogue actions are derived\nfrom sentence clustering, the training datasets in our ensemble are derived\nfrom dialogue clustering. The latter aim to induce specialised agents that\nlearn to interact in a particular style. In order to facilitate neural chatbot\ntraining using our proposed approach, we assume dialogue data in raw text only\n-- without any manually-labelled data. Experimental results using chitchat data\nreveal that (1) near human-like dialogue policies can be induced, (2)\ngeneralisation to unseen data is a difficult problem, and (3) training an\nensemble of chatbot agents is essential for improved performance over using a\nsingle agent. In addition to evaluations using held-out data, our results are\nfurther supported by a human evaluation that rated dialogues in terms of\nfluency, engagingness and consistency -- which revealed that our proposed\ndialogue rewards strongly correlate with human judgements.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 19:18:09 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Cuay\u00e1huitl", "Heriberto", ""], ["Lee", "Donghyeon", ""], ["Ryu", "Seonghan", ""], ["Cho", "Yongjin", ""], ["Choi", "Sungja", ""], ["Indurthi", "Satish", ""], ["Yu", "Seunghak", ""], ["Choi", "Hyungtak", ""], ["Hwang", "Inchul", ""], ["Kim", "Jihie", ""]]}, {"id": "1908.10423", "submitter": "Zi-Yi Dou", "authors": "Zi-Yi Dou, Keyi Yu, Antonios Anastasopoulos", "title": "Investigating Meta-Learning Algorithms for Low-Resource Natural Language\n  Understanding Tasks", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning general representations of text is a fundamental problem for many\nnatural language understanding (NLU) tasks. Previously, researchers have\nproposed to use language model pre-training and multi-task learning to learn\nrobust representations. However, these methods can achieve sub-optimal\nperformance in low-resource scenarios. Inspired by the recent success of\noptimization-based meta-learning algorithms, in this paper, we explore the\nmodel-agnostic meta-learning algorithm (MAML) and its variants for low-resource\nNLU tasks. We validate our methods on the GLUE benchmark and show that our\nproposed models can outperform several strong baselines. We further empirically\ndemonstrate that the learned representations can be adapted to new tasks\nefficiently and effectively.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 19:26:31 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Dou", "Zi-Yi", ""], ["Yu", "Keyi", ""], ["Anastasopoulos", "Antonios", ""]]}, {"id": "1908.10430", "submitter": "Zi-Yi Dou", "authors": "Zi-Yi Dou, Junjie Hu, Antonios Anastasopoulos, Graham Neubig", "title": "Unsupervised Domain Adaptation for Neural Machine Translation with\n  Domain-Aware Feature Embeddings", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent success of neural machine translation models relies on the\navailability of high quality, in-domain data. Domain adaptation is required\nwhen domain-specific data is scarce or nonexistent. Previous unsupervised\ndomain adaptation strategies include training the model with in-domain copied\nmonolingual or back-translated data. However, these methods use generic\nrepresentations for text regardless of domain shift, which makes it infeasible\nfor translation models to control outputs conditional on a specific domain. In\nthis work, we propose an approach that adapts models with domain-aware feature\nembeddings, which are learned via an auxiliary language modeling task. Our\napproach allows the model to assign domain-specific representations to words\nand output sentences in the desired domain. Our empirical results demonstrate\nthe effectiveness of the proposed strategy, achieving consistent improvements\nin multiple experimental settings. In addition, we show that combining our\nmethod with back translation can further improve the performance of the model.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 19:38:42 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Dou", "Zi-Yi", ""], ["Hu", "Junjie", ""], ["Anastasopoulos", "Antonios", ""], ["Neubig", "Graham", ""]]}, {"id": "1908.10449", "submitter": "Eric Yuan", "authors": "Xingdi Yuan, Jie Fu, Marc-Alexandre Cote, Yi Tay, Christopher Pal,\n  Adam Trischler", "title": "Interactive Machine Comprehension with Information Seeking Agents", "comments": "ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing machine reading comprehension (MRC) models do not scale effectively\nto real-world applications like web-level information retrieval and question\nanswering (QA). We argue that this stems from the nature of MRC datasets: most\nof these are static environments wherein the supporting documents and all\nnecessary information are fully observed. In this paper, we propose a simple\nmethod that reframes existing MRC datasets as interactive, partially observable\nenvironments. Specifically, we \"occlude\" the majority of a document's text and\nadd context-sensitive commands that reveal \"glimpses\" of the hidden text to a\nmodel. We repurpose SQuAD and NewsQA as an initial case study, and then show\nhow the interactive corpora can be used to train a model that seeks relevant\ninformation through sequential decision making. We believe that this setting\ncan contribute in scaling models to web-level QA scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 20:11:54 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 17:51:00 GMT"}, {"version": "v3", "created": "Thu, 16 Apr 2020 17:23:30 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Yuan", "Xingdi", ""], ["Fu", "Jie", ""], ["Cote", "Marc-Alexandre", ""], ["Tay", "Yi", ""], ["Pal", "Christopher", ""], ["Trischler", "Adam", ""]]}, {"id": "1908.10461", "submitter": "Federico Fancellu Dr.", "authors": "Jingfeng Yang, Federico Fancellu, Bonnie Webber", "title": "A survey of cross-lingual features for zero-shot cross-lingual semantic\n  parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The availability of corpora to train semantic parsers in English has lead to\nsignificant advances in the field. Unfortunately, for languages other than\nEnglish, annotation is scarce and so are developed parsers. We then ask: could\na parser trained in English be applied to language that it hasn't been trained\non? To answer this question we explore zero-shot cross-lingual semantic parsing\nwhere we train an available coarse-to-fine semantic parser (Liu et al., 2018)\nusing cross-lingual word embeddings and universal dependencies in English and\ntest it on Italian, German and Dutch. Results on the Parallel Meaning Bank - a\nmultilingual semantic graphbank, show that Universal Dependency features\nsignificantly boost performance when used in conjunction with other lexical\nfeatures but modelling the UD structure directly when encoding the input does\nnot.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 20:43:49 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Yang", "Jingfeng", ""], ["Fancellu", "Federico", ""], ["Webber", "Bonnie", ""]]}, {"id": "1908.10546", "submitter": "Bowen Shi", "authors": "Bowen Shi, Aurora Martinez Del Rio, Jonathan Keane, Diane Brentari,\n  Greg Shakhnarovich, Karen Livescu", "title": "Fingerspelling recognition in the wild with iterative visual attention", "comments": "ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sign language recognition is a challenging gesture sequence recognition\nproblem, characterized by quick and highly coarticulated motion. In this paper\nwe focus on recognition of fingerspelling sequences in American Sign Language\n(ASL) videos collected in the wild, mainly from YouTube and Deaf social media.\nMost previous work on sign language recognition has focused on controlled\nsettings where the data is recorded in a studio environment and the number of\nsigners is limited. Our work aims to address the challenges of real-life data,\nreducing the need for detection or segmentation modules commonly used in this\ndomain. We propose an end-to-end model based on an iterative attention\nmechanism, without explicit hand detection or segmentation. Our approach\ndynamically focuses on increasingly high-resolution regions of interest. It\noutperforms prior work by a large margin. We also introduce a newly collected\ndata set of crowdsourced annotations of fingerspelling in the wild, and show\nthat performance can be further improved with this additional data set.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 04:52:32 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Shi", "Bowen", ""], ["Del Rio", "Aurora Martinez", ""], ["Keane", "Jonathan", ""], ["Brentari", "Diane", ""], ["Shakhnarovich", "Greg", ""], ["Livescu", "Karen", ""]]}, {"id": "1908.10606", "submitter": "Chao-Lin Liu", "authors": "Chao-Lin Liu and Yi Chang", "title": "Classical Chinese Sentence Segmentation for Tomb Biographies of Tang\n  Dynasty", "comments": "6 pages, 3 figures, 2 tables, presented at the 2019 International\n  Conference on Digital Humanities (ADHO)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tomb biographies of the Tang dynasty provide invaluable information about\nChinese history. The original biographies are classical Chinese texts which\ncontain neither word boundaries nor sentence boundaries. Relying on three\npublished books of tomb biographies of the Tang dynasty, we investigated the\neffectiveness of employing machine-learning methods for algorithmically\nidentifying the pauses and terminals of sentences in the biographies.\n  We consider the segmentation task as a classification problem. Chinese\ncharacters that are and are not followed by a punctuation mark are classified\ninto two categories. We applied a machine-learning-based mechanism, the\nconditional random fields (CRF), to classify the characters (and words) in the\ntexts, and we studied the contributions of selected types of lexical\ninformation to the resulting quality of the segmentation recommendations.\n  This proposal presented at the DH 2018 conference discussed some of the basic\nexperiments and their evaluations. By considering the contextual information\nand employing the heuristics provided by experts of Chinese literature, we\nachieved F1 measures that were better than 80%. More complex experiments that\nemploy deep neural networks helped us further improve the results in recent\nwork.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 09:33:37 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Liu", "Chao-Lin", ""], ["Chang", "Yi", ""]]}, {"id": "1908.10621", "submitter": "Chao-Lin Liu", "authors": "Chao-Lin Liu", "title": "Onto Word Segmentation of the Complete Tang Poems", "comments": "5 pages, 2 tables, presented at the 2019 International Conference on\n  Digital Humanities (ADHO)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim at segmenting words in the Complete Tang Poems (CTP). Although it is\npossible to do some research about CTP without doing full-scale word\nsegmentation, we must move forward to word-level analysis of CTP for conducting\nadvanced research topics. In November 2018 when we submitted the manuscript for\nDH 2019 (ADHO), we collected only 2433 poems that were segmented by trained\nexperts, and used the segmented poems to evaluate the segmenter that considered\ndomain knowledge of Chinese poetry. We trained pointwise mutual information\n(PMI) between Chinese characters based on the CTP poems (excluding the 2433\npoems, which were used exclusively only for testing) and the domain knowledge.\nThe segmenter relied on the PMI information to the recover 85.7% of words in\nthe test poems. We could segment a poem completely correct only 17.8% of the\ntime, however. When we presented our work at DH 2019, we have annotated more\nthan 20000 poems. With a much larger amount of data, we were able to apply\nbiLSTM models for this word segmentation task, and we segmented a poem\ncompletely correct above 20% of the time. In contrast, human annotators\ncompletely agreed on their annotations about 40% of the time.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 10:06:19 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Liu", "Chao-Lin", ""]]}, {"id": "1908.10657", "submitter": "Canwen Xu", "authors": "Canwen Xu, Feiyang Wang, Jialong Han, Chenliang Li", "title": "Exploiting Multiple Embeddings for Chinese Named Entity Recognition", "comments": "accepted at CIKM 2019", "journal-ref": null, "doi": "10.1145/3357384.3358117", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying the named entities mentioned in text would enrich many semantic\napplications at the downstream level. However, due to the predominant usage of\ncolloquial language in microblogs, the named entity recognition (NER) in\nChinese microblogs experience significant performance deterioration, compared\nwith performing NER in formal Chinese corpus. In this paper, we propose a\nsimple yet effective neural framework to derive the character-level embeddings\nfor NER in Chinese text, named ME-CNER. A character embedding is derived with\nrich semantic information harnessed at multiple granularities, ranging from\nradical, character to word levels. The experimental results demonstrate that\nthe proposed approach achieves a large performance improvement on Weibo dataset\nand comparable performance on MSRA news dataset with lower computational cost\nagainst the existing state-of-the-art alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 11:47:39 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Xu", "Canwen", ""], ["Wang", "Feiyang", ""], ["Han", "Jialong", ""], ["Li", "Chenliang", ""]]}, {"id": "1908.10678", "submitter": "Yanshan Wang", "authors": "Krishna B. Soundararajan, Sunyang Fu, Luke A. Carlson, Rebecca A.\n  Smith, David S. Knopman, Hongfang Liu, Yanshan Wang", "title": "How Good is Artificial Intelligence at Automatically Answering Consumer\n  Questions Related to Alzheimer's Disease?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alzheimer's Disease (AD) is the most common type of dementia, comprising\n60-80% of cases. There were an estimated 5.8 million Americans living with\nAlzheimer's dementia in 2019, and this number will almost double every 20\nyears. The total lifetime cost of care for someone with dementia is estimated\nto be $350,174 in 2018, 70% of which is associated with family-provided care.\nMost family caregivers face emotional, financial and physical difficulties. As\na medium to relieve this burden, online communities in social media websites\nsuch as Twitter, Reddit, and Yahoo! Answers provide potential venues for\ncaregivers to search relevant questions and answers, or post questions and seek\nanswers from other members. However, there are often a limited number of\nrelevant questions and responses to search from, and posted questions are\nrarely answered immediately. Due to recent advancement in Artificial\nIntelligence (AI), particularly Natural Language Processing (NLP), we propose\nto utilize AI to automatically generate answers to AD-related consumer\nquestions posted by caregivers and evaluate how good AI is at answering those\nquestions. To the best of our knowledge, this is the first study in the\nliterature applying and evaluating AI models designed to automatically answer\nconsumer questions related to AD.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 19:08:56 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 15:57:49 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Soundararajan", "Krishna B.", ""], ["Fu", "Sunyang", ""], ["Carlson", "Luke A.", ""], ["Smith", "Rebecca A.", ""], ["Knopman", "David S.", ""], ["Liu", "Hongfang", ""], ["Wang", "Yanshan", ""]]}, {"id": "1908.10703", "submitter": "Xiabing Zhou", "authors": "Xiabing Zhou, Zhongqing Wang, Shoushan Li, Guodong Zhou, Min Zhang", "title": "Emotion Detection with Neural Personal Discrimination", "comments": "This paper has been accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been a recent line of works to automatically predict the emotions\nof posts in social media. Existing approaches consider the posts individually\nand predict their emotions independently. Different from previous researches,\nwe explore the dependence among relevant posts via the authors' backgrounds,\nsince the authors with similar backgrounds, e.g., gender, location, tend to\nexpress similar emotions. However, such personal attributes are not easy to\nobtain in most social media websites, and it is hard to capture\nattributes-aware words to connect similar people. Accordingly, we propose a\nNeural Personal Discrimination (NPD) approach to address above challenges by\ndetermining personal attributes from posts, and connecting relevant posts with\nsimilar attributes to jointly learn their emotions. In particular, we employ\nadversarial discriminators to determine the personal attributes, with attention\nmechanisms to aggregate attributes-aware words. In this way, social\ncorrelationship among different posts can be better addressed. Experimental\nresults show the usefulness of personal attributes, and the effectiveness of\nour proposed NPD approach in capturing such personal attributes with\nsignificant gains over the state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 13:07:05 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Zhou", "Xiabing", ""], ["Wang", "Zhongqing", ""], ["Li", "Shoushan", ""], ["Zhou", "Guodong", ""], ["Zhang", "Min", ""]]}, {"id": "1908.10719", "submitter": "Ryuichi Takanobu", "authors": "Ryuichi Takanobu, Hanlin Zhu, Minlie Huang", "title": "Guided Dialog Policy Learning: Reward Estimation for Multi-Domain\n  Task-Oriented Dialog", "comments": "EMNLP 2019 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialog policy decides what and how a task-oriented dialog system will\nrespond, and plays a vital role in delivering effective conversations. Many\nstudies apply Reinforcement Learning to learn a dialog policy with the reward\nfunction which requires elaborate design and pre-specified user goals. With the\ngrowing needs to handle complex goals across multiple domains, such manually\ndesigned reward functions are not affordable to deal with the complexity of\nreal-world tasks. To this end, we propose Guided Dialog Policy Learning, a\nnovel algorithm based on Adversarial Inverse Reinforcement Learning for joint\nreward estimation and policy optimization in multi-domain task-oriented dialog.\nThe proposed approach estimates the reward signal and infers the user goal in\nthe dialog sessions. The reward estimator evaluates the state-action pairs so\nthat it can guide the dialog policy at each dialog turn. Extensive experiments\non a multi-domain dialog dataset show that the dialog policy guided by the\nlearned reward function achieves remarkably higher task success than\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 13:36:25 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Takanobu", "Ryuichi", ""], ["Zhu", "Hanlin", ""], ["Huang", "Minlie", ""]]}, {"id": "1908.10721", "submitter": "Todor Mihaylov", "authors": "Todor Mihaylov and Anette Frank", "title": "Discourse-Aware Semantic Self-Attention for Narrative Reading\n  Comprehension", "comments": "Accepted as a long conference paper to EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose to use linguistic annotations as a basis for a\n\\textit{Discourse-Aware Semantic Self-Attention} encoder that we employ for\nreading comprehension on long narrative texts. We extract relations between\ndiscourse units, events and their arguments as well as coreferring mentions,\nusing available annotation tools. Our empirical evaluation shows that the\ninvestigated structures improve the overall performance, especially\nintra-sentential and cross-sentential discourse relations, sentence-internal\nsemantic role relations, and long-distance coreference relations. We show that\ndedicating self-attention heads to intra-sentential relations and relations\nconnecting neighboring sentences is beneficial for finding answers to questions\nin longer contexts. Our findings encourage the use of discourse-semantic\nannotations to enhance the generalization capacity of self-attention models for\nreading comprehension.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 13:40:43 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Mihaylov", "Todor", ""], ["Frank", "Anette", ""]]}, {"id": "1908.10731", "submitter": "Semih Yavuz", "authors": "Semih Yavuz, Abhinav Rastogi, Guan-Lin Chao, Dilek Hakkani-Tur", "title": "DeepCopy: Grounded Response Generation with Hierarchical Pointer\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances in neural sequence-to-sequence models have led to promising\nresults for several language generation-based tasks, including dialogue\nresponse generation, summarization, and machine translation. However, these\nmodels are known to have several problems, especially in the context of\nchit-chat based dialogue systems: they tend to generate short and dull\nresponses that are often too generic. Furthermore, these models do not ground\nconversational responses on knowledge and facts, resulting in turns that are\nnot accurate, informative and engaging for the users. In this paper, we propose\nand experiment with a series of response generation models that aim to serve in\nthe general scenario where in addition to the dialogue context, relevant\nunstructured external knowledge in the form of text is also assumed to be\navailable for models to harness. Our proposed approach extends\npointer-generator networks (See et al., 2017) by allowing the decoder to\nhierarchically attend and copy from external knowledge in addition to the\ndialogue context. We empirically show the effectiveness of the proposed model\ncompared to several baselines including (Ghazvininejad et al., 2018; Zhang et\nal., 2018) through both automatic evaluation metrics and human evaluation on\nCONVAI2 dataset.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 14:03:44 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Yavuz", "Semih", ""], ["Rastogi", "Abhinav", ""], ["Chao", "Guan-Lin", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "1908.10747", "submitter": "David Schlangen", "authors": "David Schlangen", "title": "Language Tasks and Language Games: On Methodology in Current Natural\n  Language Processing Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  \"This paper introduces a new task and a new dataset\", \"we improve the state\nof the art in X by Y\" -- it is rare to find a current natural language\nprocessing paper (or AI paper more generally) that does not contain such\nstatements. What is mostly left implicit, however, is the assumption that this\nnecessarily constitutes progress, and what it constitutes progress towards.\nHere, we make more precise the normally impressionistically used notions of\nlanguage task and language game and ask how a research programme built on these\nmight make progress towards the goal of modelling general language competence.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 14:29:13 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Schlangen", "David", ""]]}, {"id": "1908.10763", "submitter": "He He", "authors": "He He and Sheng Zha and Haohan Wang", "title": "Unlearn Dataset Bias in Natural Language Inference by Fitting the\n  Residual", "comments": "DeepLo at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical natural language inference (NLI) models are susceptible to\nlearning dataset bias: superficial cues that happen to associate with the label\non a particular dataset, but are not useful in general, e.g., negation words\nindicate contradiction. As exposed by several recent challenge datasets, these\nmodels perform poorly when such association is absent, e.g., predicting that \"I\nlove dogs\" contradicts \"I don't love cats\". Our goal is to design learning\nalgorithms that guard against known dataset bias. We formalize the concept of\ndataset bias under the framework of distribution shift and present a simple\ndebiasing algorithm based on residual fitting, which we call DRiFt. We first\nlearn a biased model that only uses features that are known to relate to\ndataset bias. Then, we train a debiased model that fits to the residual of the\nbiased model, focusing on examples that cannot be predicted well by biased\nfeatures only. We use DRiFt to train three high-performing NLI models on two\nbenchmark datasets, SNLI and MNLI. Our debiased models achieve significant\ngains over baseline models on two challenge test sets, while maintaining\nreasonable performance on the original test sets.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 15:02:45 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 04:22:40 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["He", "He", ""], ["Zha", "Sheng", ""], ["Wang", "Haohan", ""]]}, {"id": "1908.10770", "submitter": "Su Zhu", "authors": "Zijian Zhao, Su Zhu and Kai Yu", "title": "Data Augmentation with Atomic Templates for Spoken Language\n  Understanding", "comments": "To appear in EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken Language Understanding (SLU) converts user utterances into structured\nsemantic representations. Data sparsity is one of the main obstacles of SLU due\nto the high cost of human annotation, especially when domain changes or a new\ndomain comes. In this work, we propose a data augmentation method with atomic\ntemplates for SLU, which involves minimum human efforts. The atomic templates\nproduce exemplars for fine-grained constituents of semantic representations. We\npropose an encoder-decoder model to generate the whole utterance from atomic\nexemplars. Moreover, the generator could be transferred from source domains to\nhelp a new domain which has little data. Experimental results show that our\nmethod achieves significant improvements on DSTC 2\\&3 dataset which is a domain\nadaptation setting of SLU.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 15:17:33 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Zhao", "Zijian", ""], ["Zhu", "Su", ""], ["Yu", "Kai", ""]]}, {"id": "1908.10784", "submitter": "Camille Roth", "authors": "Telmo Menezes and Camille Roth", "title": "Semantic Hypergraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approaches to Natural language processing (NLP) may be classified along a\ndouble dichotomy open/opaque - strict/adaptive. The former axis relates to the\npossibility of inspecting the underlying processing rules, the latter to the\nuse of fixed or adaptive rules. We argue that many techniques fall into either\nthe open-strict or opaque-adaptive categories. Our contribution takes steps in\nthe open-adaptive direction, which we suggest is likely to provide key\ninstruments for interdisciplinary research. The central idea of our approach is\nthe Semantic Hypergraph (SH), a novel knowledge representation model that is\nintrinsically recursive and accommodates the natural hierarchical richness of\nnatural language. The SH model is hybrid in two senses. First, it attempts to\ncombine the strengths of ML and symbolic approaches. Second, it is a formal\nlanguage representation that reduces but tolerates ambiguity and structural\nvariability. We will see that SH enables simple yet powerful methods of pattern\ndetection, and features a good compromise for intelligibility both for humans\nand machines. It also provides a semantically deep starting point (in terms of\nexplicit meaning) for further algorithms to operate and collaborate on. We show\nhow modern NLP ML-based building blocks can be used in combination with a\nrandom forest classifier and a simple search tree to parse NL to SH, and that\nthis parser can achieve high precision in a diversity of text categories. We\ndefine a pattern language representable in SH itself, and a process to discover\nknowledge inference rules. We then illustrate the efficiency of the SH\nframework in a variety of tasks, including conjunction decomposition, open\ninformation extraction, concept taxonomy inference and co-reference resolution,\nand an applied example of claim and conflict analysis in a news corpus.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 15:39:02 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 14:26:53 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Menezes", "Telmo", ""], ["Roth", "Camille", ""]]}, {"id": "1908.10797", "submitter": "Jia Huei Tan", "authors": "Jia Huei Tan, Chee Seng Chan, Joon Huang Chuah", "title": "Image Captioning with Sparse Recurrent Neural Network", "comments": "Corrected Eq 11, updated Table 5", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Network (RNN) has been widely used to tackle a wide variety\nof language generation problems and are capable of attaining state-of-the-art\n(SOTA) performance. However despite its impressive results, the large number of\nparameters in the RNN model makes deployment to mobile and embedded devices\ninfeasible. Driven by this problem, many works have proposed a number of\npruning methods to reduce the sizes of the RNN model. In this work, we propose\nan end-to-end pruning method for image captioning models equipped with visual\nattention. Our proposed method is able to achieve sparsity levels up to 97.5%\nwithout significant performance loss relative to the baseline (~ 2% loss at 40x\ncompression after fine-tuning). Our method is also simple to use and tune,\nfacilitating faster development times for neural network practitioners. We\nperform extensive experiments on the popular MS-COCO dataset in order to\nempirically validate the efficacy of our proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 15:53:13 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 15:51:13 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Tan", "Jia Huei", ""], ["Chan", "Chee Seng", ""], ["Chuah", "Joon Huang", ""]]}, {"id": "1908.10835", "submitter": "Wanyu Du", "authors": "Wanyu Du, Yangfeng Ji", "title": "An Empirical Comparison on Imitation Learning and Reinforcement Learning\n  for Paraphrase Generation", "comments": "9 pages, 2 figures, EMNLP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating paraphrases from given sentences involves decoding words step by\nstep from a large vocabulary. To learn a decoder, supervised learning which\nmaximizes the likelihood of tokens always suffers from the exposure bias.\nAlthough both reinforcement learning (RL) and imitation learning (IL) have been\nwidely used to alleviate the bias, the lack of direct comparison leads to only\na partial image on their benefits. In this work, we present an empirical study\non how RL and IL can help boost the performance of generating paraphrases, with\nthe pointer-generator as a base model. Experiments on the benchmark datasets\nshow that (1) imitation learning is constantly better than reinforcement\nlearning; and (2) the pointer-generator models with imitation learning\noutperform the state-of-the-art methods with a large margin.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 17:10:06 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Du", "Wanyu", ""], ["Ji", "Yangfeng", ""]]}, {"id": "1908.10896", "submitter": "Stephan Baier", "authors": "Stephan Baier", "title": "Analyzing Customer Feedback for Product Fit Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the biggest hurdles for customers when purchasing fashion online, is\nthe difficulty of finding products with the right fit. In order to provide a\nbetter online shopping experience, platforms need to find ways to recommend the\nright product sizes and the best fitting products to their customers. These\nrecommendation systems, however, require customer feedback in order to estimate\nthe most suitable sizing options. Such feedback is rare and often only\navailable as natural text. In this paper, we examine the extraction of product\nfit feedback from customer reviews using natural language processing\ntechniques. In particular, we compare traditional methods with more recent\ntransfer learning techniques for text classification, and analyze their\nresults. Our evaluation shows, that the transfer learning approach ULMFit is\nnot only comparatively fast to train, but also achieves highest accuracy on\nthis task. The integration of the extracted information with actual size\nrecommendation systems is left for future work.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 18:22:26 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Baier", "Stephan", ""]]}, {"id": "1908.10909", "submitter": "Eric Yuan", "authors": "Xingdi Yuan, Marc-Alexandre Cote, Jie Fu, Zhouhan Lin, Christopher\n  Pal, Yoshua Bengio, Adam Trischler", "title": "Interactive Language Learning by Question Answering", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans observe and interact with the world to acquire knowledge. However,\nmost existing machine reading comprehension (MRC) tasks miss the interactive,\ninformation-seeking component of comprehension. Such tasks present models with\nstatic documents that contain all necessary information, usually concentrated\nin a single short substring. Thus, models can achieve strong performance\nthrough simple word- and phrase-based pattern matching. We address this problem\nby formulating a novel text-based question answering task: Question Answering\nwith Interactive Text (QAit). In QAit, an agent must interact with a partially\nobservable text-based environment to gather information required to answer\nquestions. QAit poses questions about the existence, location, and attributes\nof objects found in the environment. The data is built using a text-based game\ngenerator that defines the underlying dynamics of interaction with the\nenvironment. We propose and evaluate a set of baseline models for the QAit task\nthat includes deep reinforcement learning agents. Experiments show that the\ntask presents a major challenge for machine reading systems, while humans solve\nit with relative ease.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 19:10:08 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Yuan", "Xingdi", ""], ["Cote", "Marc-Alexandre", ""], ["Fu", "Jie", ""], ["Lin", "Zhouhan", ""], ["Pal", "Christopher", ""], ["Bengio", "Yoshua", ""], ["Trischler", "Adam", ""]]}, {"id": "1908.10917", "submitter": "Wenlu Wang", "authors": "Jingjing Li, Wenlu Wang, Wei-Shinn Ku, Yingtao Tian, Haixun Wang", "title": "SpatialNLI: A Spatial Domain Natural Language Interface to Databases\n  Using Spatial Comprehension", "comments": "10 pages", "journal-ref": "27th ACM SIGSPATIAL International Conference on Advances in\n  Geographic Information Systems (SIGSPATIAL '19), November 5-8, 2019, Chicago,\n  IL, USA", "doi": "10.1145/3347146.3359069", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A natural language interface (NLI) to databases is an interface that\ntranslates a natural language question to a structured query that is executable\nby database management systems (DBMS). However, an NLI that is trained in the\ngeneral domain is hard to apply in the spatial domain due to the idiosyncrasy\nand expressiveness of the spatial questions. Inspired by the machine\ncomprehension model, we propose a spatial comprehension model that is able to\nrecognize the meaning of spatial entities based on the semantics of the\ncontext. The spatial semantics learned from the spatial comprehension model is\nthen injected to the natural language question to ease the burden of capturing\nthe spatial-specific semantics. With our spatial comprehension model and\ninformation injection, our NLI for the spatial domain, named SpatialNLI, is\nable to capture the semantic structure of the question and translate it to the\ncorresponding syntax of an executable query accurately. We also experimentally\nascertain that SpatialNLI outperforms state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 19:32:00 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Li", "Jingjing", ""], ["Wang", "Wenlu", ""], ["Ku", "Wei-Shinn", ""], ["Tian", "Yingtao", ""], ["Wang", "Haixun", ""]]}, {"id": "1908.10924", "submitter": "Yuanliang Meng", "authors": "Yuanliang Meng and Anna Rumshisky", "title": "Solving Math Word Problems with Double-Decoder Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a Transformer-based model to generate equations for math\nword problems. It achieves much better results than RNN models when copy and\nalign mechanisms are not used, and can outperform complex copy and align RNN\nmodels. We also show that training a Transformer jointly in a generation task\nwith two decoders, left-to-right and right-to-left, is beneficial. Such a\nTransformer performs better than the one with just one decoder not only because\nof the ensemble effect, but also because it improves the encoder training\nprocedure. We also experiment with adding reinforcement learning to our model,\nshowing improved performance compared to MLE training.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 19:42:37 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Meng", "Yuanliang", ""], ["Rumshisky", "Anna", ""]]}, {"id": "1908.10940", "submitter": "Wei Wang", "authors": "Wei Wang, Ye Tian, Jiquan Ngiam, Yinfei Yang, Isaac Caswell, Zarana\n  Parekh", "title": "Learning a Multi-Domain Curriculum for Neural Machine Translation", "comments": "Accepted at ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most data selection research in machine translation focuses on improving a\nsingle domain. We perform data selection for multiple domains at once. This is\nachieved by carefully introducing instance-level domain-relevance features and\nautomatically constructing a training curriculum to gradually concentrate on\nmulti-domain relevant and noise-reduced data batches. Both the choice of\nfeatures and the use of curriculum are crucial for balancing and improving all\ndomains, including out-of-domain. In large-scale experiments, the multi-domain\ncurriculum simultaneously reaches or outperforms the individual performance and\nbrings solid gains over no-curriculum training.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 20:48:05 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 00:32:41 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Wang", "Wei", ""], ["Tian", "Ye", ""], ["Ngiam", "Jiquan", ""], ["Yang", "Yinfei", ""], ["Caswell", "Isaac", ""], ["Parekh", "Zarana", ""]]}, {"id": "1908.10970", "submitter": "Zhe Zhang", "authors": "Zhe Zhang and Munindar P. Singh", "title": "Leveraging Structural and Semantic Correspondence for Attribute-Oriented\n  Aspect Sentiment Discovery", "comments": "EMNLP 2019", "journal-ref": null, "doi": "10.18653/v1/D19-1555", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opinionated text often involves attributes such as authorship and location\nthat influence the sentiments expressed for different aspects. We posit that\nstructural and semantic correspondence is both prevalent in opinionated text,\nespecially when associated with attributes, and crucial in accurately revealing\nits latent aspect and sentiment structure. However, it is not recognized by\nexisting approaches.\n  We propose Trait, an unsupervised probabilistic model that discovers aspects\nand sentiments from text and associates them with different attributes. To this\nend, Trait infers and leverages structural and semantic correspondence using a\nMarkov Random Field. We show empirically that by incorporating attributes\nexplicitly Trait significantly outperforms state-of-the-art baselines both by\ngenerating attribute profiles that accord with our intuitions, as shown via\nvisualization, and yielding topics of greater semantic cohesion.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 22:18:03 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Zhang", "Zhe", ""], ["Singh", "Munindar P.", ""]]}, {"id": "1908.10992", "submitter": "Ruoming Pang", "authors": "Tara N. Sainath, Ruoming Pang, David Rybach, Yanzhang He, Rohit\n  Prabhavalkar, Wei Li, Mirk\\'o Visontai, Qiao Liang, Trevor Strohman, Yonghui\n  Wu, Ian McGraw, Chung-Cheng Chiu", "title": "Two-Pass End-to-End Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The requirements for many applications of state-of-the-art speech recognition\nsystems include not only low word error rate (WER) but also low latency.\nSpecifically, for many use-cases, the system must be able to decode utterances\nin a streaming fashion and faster than real-time. Recently, a streaming\nrecurrent neural network transducer (RNN-T) end-to-end (E2E) model has shown to\nbe a good candidate for on-device speech recognition, with improved WER and\nlatency metrics compared to conventional on-device models [1]. However, this\nmodel still lags behind a large state-of-the-art conventional model in quality\n[2]. On the other hand, a non-streaming E2E Listen, Attend and Spell (LAS)\nmodel has shown comparable quality to large conventional models [3]. This work\naims to bring the quality of an E2E streaming model closer to that of a\nconventional system by incorporating a LAS network as a second-pass component,\nwhile still abiding by latency constraints. Our proposed two-pass model\nachieves a 17%-22% relative reduction in WER compared to RNN-T alone and\nincreases latency by a small fraction over RNN-T.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 00:18:05 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Sainath", "Tara N.", ""], ["Pang", "Ruoming", ""], ["Rybach", "David", ""], ["He", "Yanzhang", ""], ["Prabhavalkar", "Rohit", ""], ["Li", "Wei", ""], ["Visontai", "Mirk\u00f3", ""], ["Liang", "Qiao", ""], ["Strohman", "Trevor", ""], ["Wu", "Yonghui", ""], ["McGraw", "Ian", ""], ["Chiu", "Chung-Cheng", ""]]}, {"id": "1908.10993", "submitter": "Deyan Ginev", "authors": "Deyan Ginev, Bruce R. Miller", "title": "Scientific Statement Classification over arXiv.org", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We introduce a new classification task for scientific statements and release\na large-scale dataset for supervised learning. Our resource is derived from a\nmachine-readable representation of the arXiv.org collection of preprint\narticles. We explore fifty author-annotated categories and empirically motivate\na task design of grouping 10.5 million annotated paragraphs into thirteen\nclasses. We demonstrate that the task setup aligns with known success rates\nfrom the state of the art, peaking at a 0.91 F1-score via a BiLSTM\nencoder-decoder model. Additionally, we introduce a lexeme serialization for\nmathematical formulas, and observe that context-aware models could improve when\nalso trained on the symbolic modality. Finally, we discuss the limitations of\nboth data and task design, and outline potential directions towards\nincreasingly complex models of scientific discourse, beyond isolated\nstatements.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 00:25:38 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Ginev", "Deyan", ""], ["Miller", "Bruce R.", ""]]}, {"id": "1908.11007", "submitter": "Tianyu Gao", "authors": "Tianyu Gao, Xu Han, Ruobing Xie, Zhiyuan Liu, Fen Lin, Leyu Lin,\n  Maosong Sun", "title": "Neural Snowball for Few-Shot Relation Learning", "comments": "Accepted by AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs typically undergo open-ended growth of new relations. This\ncannot be well handled by relation extraction that focuses on pre-defined\nrelations with sufficient training data. To address new relations with few-shot\ninstances, we propose a novel bootstrapping approach, Neural Snowball, to learn\nnew relations by transferring semantic knowledge about existing relations. More\nspecifically, we use Relational Siamese Networks (RSN) to learn the metric of\nrelational similarities between instances based on existing relations and their\nlabeled data. Afterwards, given a new relation and its few-shot instances, we\nuse RSN to accumulate reliable instances from unlabeled corpora; these\ninstances are used to train a relation classifier, which can further identify\nnew facts of the new relation. The process is conducted iteratively like a\nsnowball. Experiments show that our model can gather high-quality instances for\nbetter few-shot relation learning and achieves significant improvement compared\nto baselines. Codes and datasets are released on\nhttps://github.com/thunlp/Neural-Snowball.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 01:25:52 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 07:40:32 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Gao", "Tianyu", ""], ["Han", "Xu", ""], ["Xie", "Ruobing", ""], ["Liu", "Zhiyuan", ""], ["Lin", "Fen", ""], ["Lin", "Leyu", ""], ["Sun", "Maosong", ""]]}, {"id": "1908.11017", "submitter": "Yuncong Li", "authors": "Yuncong Li, Cunxiang Yin, Ting Wei, Huiqiang Zhong, Jinchang Luo, Siqi\n  Xu, Xiaohui Wu", "title": "A Joint Model for Aspect-Category Sentiment Analysis with Contextualized\n  Aspect Embedding", "comments": "This was accepted by CCL 2020 and renamed \"A Joint Model for\n  Aspect-Category Sentiment Analysis with Shared Sentiment Prediction Layer\"\n  (https://www.aclweb.org/anthology/2020.ccl-1.103/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-category sentiment analysis (ACSA) aims to identify all the aspect\ncategories mentioned in the text and their corresponding sentiment polarities.\nSome joint models have been proposed to address this task. However, these joint\nmodels do not solve the following two problems well: mismatching between the\naspect categories and the sentiment words, and data deficiency of some aspect\ncategories. To solve them, we propose a novel joint model which contains a\ncontextualized aspect embedding layer and a shared sentiment prediction layer.\nThe contextualized aspect embedding layer extracts the aspect category related\ninformation, which is used to generate aspect-specific representations for\nsentiment classification like traditional context-independent aspect embedding\n(CIAE) and is therefore called contextualized aspect embedding (CAE). The CAE\ncan mitigate the mismatching problem because it is semantically more related to\nsentiment words than CIAE. The shared sentiment prediction layer transfers\nsentiment knowledge between aspect categories and alleviates the problem caused\nby data deficiency. Experiments conducted on SemEval 2016 Datasets show that\nour proposed model achieves state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 02:00:37 GMT"}, {"version": "v2", "created": "Sun, 15 Dec 2019 10:12:33 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 06:41:10 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Li", "Yuncong", ""], ["Yin", "Cunxiang", ""], ["Wei", "Ting", ""], ["Zhong", "Huiqiang", ""], ["Luo", "Jinchang", ""], ["Xu", "Siqi", ""], ["Wu", "Xiaohui", ""]]}, {"id": "1908.11020", "submitter": "Xintong Li", "authors": "Xintong Li, Lemao Liu, Rui Wang, Guoping Huang, Max Meng", "title": "Regularized Context Gates on Transformer for Machine Translation", "comments": "Published in ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context gates are effective to control the contributions from the source and\ntarget contexts in the recurrent neural network (RNN) based neural machine\ntranslation (NMT). However, it is challenging to extend them into the advanced\nTransformer architecture, which is more complicated than RNN. This paper first\nprovides a method to identify source and target contexts and then introduce a\ngate mechanism to control the source and target contributions in Transformer.\nIn addition, to further reduce the bias problem in the gate mechanism, this\npaper proposes a regularization method to guide the learning of the gates with\nsupervision automatically generated using pointwise mutual information.\nExtensive experiments on 4 translation datasets demonstrate that the proposed\nmodel obtains an averaged gain of 1.0 BLEU score over a strong Transformer\nbaseline.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 02:20:26 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 02:17:02 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Li", "Xintong", ""], ["Liu", "Lemao", ""], ["Wang", "Rui", ""], ["Huang", "Guoping", ""], ["Meng", "Max", ""]]}, {"id": "1908.11030", "submitter": "Evan Crothers", "authors": "Evan Crothers, Nathalie Japkowicz, Herna Viktor", "title": "Towards Ethical Content-Based Detection of Online Influence Campaigns", "comments": "To appear in \"Special Session on Machine learning for Knowledge\n  Discovery in the Social Sciences\" at IEEE Machine Learning for Signal\n  Processing Workshop (MLSP) 2019", "journal-ref": "2019 IEEE 29th International Workshop on Machine Learning for\n  Signal Processing (MLSP), Pittsburgh, PA, USA, 2019, pp. 1-6", "doi": "10.1109/MLSP.2019.8918842", "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection of clandestine efforts to influence users in online communities\nis a challenging problem with significant active development. We demonstrate\nthat features derived from the text of user comments are useful for identifying\nsuspect activity, but lead to increased erroneous identifications when keywords\nover-represented in past influence campaigns are present. Drawing on research\nin native language identification (NLI), we use \"named entity masking\" (NEM) to\ncreate sentence features robust to this shortcoming, while maintaining\ncomparable classification accuracy. We demonstrate that while NEM consistently\nreduces false positives when key named entities are mentioned, both masked and\nunmasked models exhibit increased false positive rates on English sentences by\nRussian native speakers, raising ethical considerations that should be\naddressed in future research.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 03:18:21 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Crothers", "Evan", ""], ["Japkowicz", "Nathalie", ""], ["Viktor", "Herna", ""]]}, {"id": "1908.11046", "submitter": "Peng-Hsuan Li", "authors": "Peng-Hsuan Li, Tsu-Jui Fu, Wei-Yun Ma", "title": "Why Attention? Analyze BiLSTM Deficiency and Its Remedies in the Case of\n  NER", "comments": "In proceedings of AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BiLSTM has been prevalently used as a core module for NER in a\nsequence-labeling setup. State-of-the-art approaches use BiLSTM with additional\nresources such as gazetteers, language-modeling, or multi-task supervision to\nfurther improve NER. This paper instead takes a step back and focuses on\nanalyzing problems of BiLSTM itself and how exactly self-attention can bring\nimprovements. We formally show the limitation of (CRF-)BiLSTM in modeling\ncross-context patterns for each word -- the XOR limitation. Then, we show that\ntwo types of simple cross-structures -- self-attention and Cross-BiLSTM -- can\neffectively remedy the problem. We test the practical impacts of the deficiency\non real-world NER datasets, OntoNotes 5.0 and WNUT 2017, with clear and\nconsistent improvements over the baseline, up to 8.7% on some of the\nmulti-token entity mentions. We give in-depth analyses of the improvements\nacross several aspects of NER, especially the identification of multi-token\nmentions. This study should lay a sound foundation for future improvements on\nsequence-labeling NER. (Source codes:\nhttps://github.com/jacobvsdanniel/cross-ner)\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 04:36:30 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 10:08:43 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 08:27:20 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Li", "Peng-Hsuan", ""], ["Fu", "Tsu-Jui", ""], ["Ma", "Wei-Yun", ""]]}, {"id": "1908.11047", "submitter": "Swabha Swayamdipta", "authors": "Swabha Swayamdipta, Matthew Peters, Brendan Roof, Chris Dyer, Noah A.\n  Smith", "title": "Shallow Syntax in Deep Water", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Shallow syntax provides an approximation of phrase-syntactic structure of\nsentences; it can be produced with high accuracy, and is computationally cheap\nto obtain. We investigate the role of shallow syntax-aware representations for\nNLP tasks using two techniques. First, we enhance the ELMo architecture to\nallow pretraining on predicted shallow syntactic parses, instead of just raw\ntext, so that contextual embeddings make use of shallow syntactic context. Our\nsecond method involves shallow syntactic features obtained automatically on\ndownstream task data. Neither approach leads to a significant gain on any of\nthe four downstream tasks we considered relative to ELMo-only baselines.\nFurther analysis using black-box probes confirms that our shallow-syntax-aware\ncontextual embeddings do not transfer to linguistic tasks any more easily than\nELMo's embeddings. We take these findings as evidence that ELMo-style\npretraining discovers representations which make additional awareness of\nshallow syntax redundant.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 04:45:38 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Swayamdipta", "Swabha", ""], ["Peters", "Matthew", ""], ["Roof", "Brendan", ""], ["Dyer", "Chris", ""], ["Smith", "Noah A.", ""]]}, {"id": "1908.11049", "submitter": "Nedjma Ousidhoum", "authors": "Nedjma Ousidhoum, Zizheng Lin, Hongming Zhang, Yangqiu Song, Dit-Yan\n  Yeung", "title": "Multilingual and Multi-Aspect Hate Speech Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current research on hate speech analysis is typically oriented towards\nmonolingual and single classification tasks. In this paper, we present a new\nmultilingual multi-aspect hate speech analysis dataset and use it to test the\ncurrent state-of-the-art multilingual multitask learning approaches. We\nevaluate our dataset in various classification settings, then we discuss how to\nleverage our annotations in order to improve hate speech detection and\nclassification in general.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 04:53:29 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Ousidhoum", "Nedjma", ""], ["Lin", "Zizheng", ""], ["Zhang", "Hongming", ""], ["Song", "Yangqiu", ""], ["Yeung", "Dit-Yan", ""]]}, {"id": "1908.11052", "submitter": "Shuaichen Chang", "authors": "Shuaichen Chang, Pengfei Liu, Yun Tang, Jing Huang, Xiaodong He, Bowen\n  Zhou", "title": "Zero-shot Text-to-SQL Learning with Auxiliary Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen great success in the use of neural seq2seq models on\nthe text-to-SQL task. However, little work has paid attention to how these\nmodels generalize to realistic unseen data, which naturally raises a question:\ndoes this impressive performance signify a perfect generalization model, or are\nthere still some limitations?\n  In this paper, we first diagnose the bottleneck of text-to-SQL task by\nproviding a new testbed, in which we observe that existing models present poor\ngeneralization ability on rarely-seen data. The above analysis encourages us to\ndesign a simple but effective auxiliary task, which serves as a supportive\nmodel as well as a regularization term to the generation task to increase the\nmodels generalization. Experimentally, We evaluate our models on a large\ntext-to-SQL dataset WikiSQL. Compared to a strong baseline coarse-to-fine\nmodel, our models improve over the baseline by more than 3% absolute in\naccuracy on the whole dataset. More interestingly, on a zero-shot subset test\nof WikiSQL, our models achieve 5% absolute accuracy gain over the baseline,\nclearly demonstrating its superior generalizability.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 05:01:39 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Chang", "Shuaichen", ""], ["Liu", "Pengfei", ""], ["Tang", "Yun", ""], ["Huang", "Jing", ""], ["He", "Xiaodong", ""], ["Zhou", "Bowen", ""]]}, {"id": "1908.11053", "submitter": "Wei Hu", "authors": "Jiwei Ding and Wei Hu and Qixin Xu and Yuzhong Qu", "title": "Leveraging Frequent Query Substructures to Generate Formal Queries for\n  Complex Question Answering", "comments": "Accepted by the 2019 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal query generation aims to generate correct executable queries for\nquestion answering over knowledge bases (KBs), given entity and relation\nlinking results. Current approaches build universal paraphrasing or ranking\nmodels for the whole questions, which are likely to fail in generating queries\nfor complex, long-tail questions. In this paper, we propose SubQG, a new query\ngeneration approach based on frequent query substructures, which helps rank the\nexisting (but nonsignificant) query structures or build new query structures.\nOur experiments on two benchmark datasets show that our approach significantly\noutperforms the existing ones, especially for complex questions. Also, it\nachieves promising performance with limited training data and noisy\nentity/relation linking results.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 05:03:57 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Ding", "Jiwei", ""], ["Hu", "Wei", ""], ["Xu", "Qixin", ""], ["Qu", "Yuzhong", ""]]}, {"id": "1908.11057", "submitter": "Zenan Xu", "authors": "Zenan Xu, Qinliang Su, Xiaojun Quan, Weijia Zhang", "title": "A Deep Neural Information Fusion Architecture for Textual Network\n  Embeddings", "comments": "To appear at EMNLP-IJCNLP 2019 (Conference on Empirical Methods in\n  Natural Language Processing & International Joint Conference on Natural\n  Language Processing 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Textual network embeddings aim to learn a low-dimensional representation for\nevery node in the network so that both the structural and textual information\nfrom the networks can be well preserved in the representations. Traditionally,\nthe structural and textual embeddings were learned by models that rarely take\nthe mutual influences between them into account. In this paper, a deep neural\narchitecture is proposed to effectively fuse the two kinds of informations into\none representation. The novelties of the proposed architecture are manifested\nin the aspects of a newly defined objective function, the complementary\ninformation fusion method for structural and textual features, and the mutual\ngate mechanism for textual feature extraction. Experimental results show that\nthe proposed model outperforms the comparing methods on all three datasets.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 05:19:53 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Xu", "Zenan", ""], ["Su", "Qinliang", ""], ["Quan", "Xiaojun", ""], ["Zhang", "Weijia", ""]]}, {"id": "1908.11078", "submitter": "Wei Dong", "authors": "Wei Dong, Qinliang Su, Dinghan Shen and Changyou Chen", "title": "Document Hashing with Mixture-Prior Generative Models", "comments": "10 pages, 8 figures, to appear at EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hashing is promising for large-scale information retrieval tasks thanks to\nthe efficiency of distance evaluation between binary codes. Generative hashing\nis often used to generate hashing codes in an unsupervised way. However,\nexisting generative hashing methods only considered the use of simple priors,\nlike Gaussian and Bernoulli priors, which limits these methods to further\nimprove their performance. In this paper, two mixture-prior generative models\nare proposed, under the objective to produce high-quality hashing codes for\ndocuments. Specifically, a Gaussian mixture prior is first imposed onto the\nvariational auto-encoder (VAE), followed by a separate step to cast the\ncontinuous latent representation of VAE into binary code. To avoid the\nperformance loss caused by the separate casting, a model using a Bernoulli\nmixture prior is further developed, in which an end-to-end training is admitted\nby resorting to the straight-through (ST) discrete gradient estimator.\nExperimental results on several benchmark datasets demonstrate that the\nproposed methods, especially the one using Bernoulli mixture priors,\nconsistently outperform existing ones by a substantial margin.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 07:29:28 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Dong", "Wei", ""], ["Su", "Qinliang", ""], ["Shen", "Dinghan", ""], ["Chen", "Changyou", ""]]}, {"id": "1908.11125", "submitter": "Jind\\v{r}ich Libovick\\'y", "authors": "Jind\\v{r}ich Libovick\\'y, Pranava Madhyastha", "title": "Probing Representations Learned by Multimodal Recurrent and Transformer\n  Models", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent literature shows that large-scale language modeling provides excellent\nreusable sentence representations with both recurrent and self-attentive\narchitectures. However, there has been less clarity on the commonalities and\ndifferences in the representational properties induced by the two\narchitectures. It also has been shown that visual information serves as one of\nthe means for grounding sentence representations. In this paper, we present a\nmeta-study assessing the representational quality of models where the training\nsignal is obtained from different modalities, in particular, language modeling,\nimage features prediction, and both textual and multimodal machine translation.\nWe evaluate textual and visual features of sentence representations obtained\nusing predominant approaches on image retrieval and semantic textual\nsimilarity. Our experiments reveal that on moderate-sized datasets, a sentence\ncounterpart in a target language or visual modality provides much stronger\ntraining signal for sentence representation than language modeling.\nImportantly, we observe that while the Transformer models achieve superior\nmachine translation quality, representations from the recurrent neural network\nbased models perform significantly better over tasks focused on semantic\nrelevance.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 09:47:48 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Libovick\u00fd", "Jind\u0159ich", ""], ["Madhyastha", "Pranava", ""]]}, {"id": "1908.11135", "submitter": "Christoph Wernhard", "authors": "Jana Kittelmann and Christoph Wernhard", "title": "KBSET -- Knowledge-Based Support for Scholarly Editing and Text\n  Processing", "comments": "Part of DECLARE 19 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  KBSET supports a practical workflow for scholarly editing, based on using\nLaTeX with dedicated commands for semantics-oriented markup and a\nProlog-implemented core system. Prolog plays there various roles: as query\nlanguage and access mechanism for large Semantic Web fact bases, as data\nrepresentation of structured documents and as a workflow model for advanced\napplication tasks. The core system includes a LaTeX parser and a facility for\nthe identification of named entities. We also sketch future perspectives of\nthis approach to scholarly editing based on techniques of computational logic.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 10:14:40 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Kittelmann", "Jana", ""], ["Wernhard", "Christoph", ""]]}, {"id": "1908.11141", "submitter": "Rahul Aralikatte", "authors": "Rahul Aralikatte, Matthew Lamm, Daniel Hardt, Anders S{\\o}gaard", "title": "Ellipsis Resolution as Question Answering: An Evaluation", "comments": "To appear in EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most, if not all forms of ellipsis (e.g., so does Mary) are similar to\nreading comprehension questions (what does Mary do), in that in order to\nresolve them, we need to identify an appropriate text span in the preceding\ndiscourse. Following this observation, we present an alternative approach for\nEnglish ellipsis resolution relying on architectures developed for question\nanswering (QA). We present both single-task models, and joint models trained on\nauxiliary QA and coreference resolution datasets, clearly outperforming the\ncurrent state of the art for Sluice Ellipsis (from 70.00 to 86.01 F1) and Verb\nPhrase Ellipsis (from 72.89 to 78.66 F1).\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 10:25:10 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 11:48:34 GMT"}, {"version": "v3", "created": "Tue, 19 Jan 2021 11:48:27 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Aralikatte", "Rahul", ""], ["Lamm", "Matthew", ""], ["Hardt", "Daniel", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "1908.11152", "submitter": "Michal Shmueli-Scheuer", "authors": "Shai Erera, Michal Shmueli-Scheuer, Guy Feigenblat, Ora Peled Nakash,\n  Odellia Boni, Haggai Roitman, Doron Cohen, Bar Weiner, Yosi Mass, Or Rivlin,\n  Guy Lev, Achiya Jerbi, Jonathan Herzig, Yufang Hou, Charles Jochim, Martin\n  Gleize, Francesca Bonin, and David Konopnicki", "title": "A Summarization System for Scientific Documents", "comments": "Accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel system providing summaries for Computer Science\npublications. Through a qualitative user study, we identified the most valuable\nscenarios for discovery, exploration and understanding of scientific documents.\nBased on these findings, we built a system that retrieves and summarizes\nscientific documents for a given information need, either in form of a\nfree-text query or by choosing categorized values such as scientific tasks,\ndatasets and more. Our system ingested 270,000 papers, and its summarization\nmodule aims to generate concise yet detailed summaries. We validated our\napproach with human experts.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 11:17:33 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Erera", "Shai", ""], ["Shmueli-Scheuer", "Michal", ""], ["Feigenblat", "Guy", ""], ["Nakash", "Ora Peled", ""], ["Boni", "Odellia", ""], ["Roitman", "Haggai", ""], ["Cohen", "Doron", ""], ["Weiner", "Bar", ""], ["Mass", "Yosi", ""], ["Rivlin", "Or", ""], ["Lev", "Guy", ""], ["Jerbi", "Achiya", ""], ["Herzig", "Jonathan", ""], ["Hou", "Yufang", ""], ["Jochim", "Charles", ""], ["Gleize", "Martin", ""], ["Bonin", "Francesca", ""], ["Konopnicki", "David", ""]]}, {"id": "1908.11214", "submitter": "Ben Bogin", "authors": "Ben Bogin, Matt Gardner, Jonathan Berant", "title": "Global Reasoning over Database Structures for Text-to-SQL Parsing", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art semantic parsers rely on auto-regressive decoding, emitting\none symbol at a time. When tested against complex databases that are unobserved\nat training time (zero-shot), the parser often struggles to select the correct\nset of database constants in the new database, due to the local nature of\ndecoding. In this work, we propose a semantic parser that globally reasons\nabout the structure of the output query to make a more contextually-informed\nselection of database constants. We use message-passing through a graph neural\nnetwork to softly select a subset of database constants for the output query,\nconditioned on the question. Moreover, we train a model to rank queries based\non the global alignment of database constants to question words. We apply our\ntechniques to the current state-of-the-art model for Spider, a zero-shot\nsemantic parsing dataset with complex databases, increasing accuracy from 39.4%\nto 47.4%.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 13:29:36 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Bogin", "Ben", ""], ["Gardner", "Matt", ""], ["Berant", "Jonathan", ""]]}, {"id": "1908.11216", "submitter": "Alexandre Garcia", "authors": "Alexandre Garcia, Pierre Colombo, Slim Essid, Florence d'Alch\\'e-Buc,\n  Chlo\\'e Clavel", "title": "From the Token to the Review: A Hierarchical Multimodal approach to\n  Opinion Mining", "comments": "Accepted to 2019 Conference on Empirical Methods in Natural Language\n  Processing (EMNLP) and 9th International Joint Conference on Natural Language\n  Processing (IJCNLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of predicting fine grained user opinion based on spontaneous spoken\nlanguage is a key problem arising in the development of Computational Agents as\nwell as in the development of social network based opinion miners.\nUnfortunately, gathering reliable data on which a model can be trained is\nnotoriously difficult and existing works rely only on coarsely labeled\nopinions. In this work we aim at bridging the gap separating fine grained\nopinion models already developed for written language and coarse grained models\ndeveloped for spontaneous multimodal opinion mining. We take advantage of the\nimplicit hierarchical structure of opinions to build a joint fine and coarse\ngrained opinion model that exploits different views of the opinion expression.\nThe resulting model shares some properties with attention-based models and is\nshown to provide competitive results on a recently released multimodal fine\ngrained annotated corpus.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 13:34:50 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 11:07:23 GMT"}, {"version": "v3", "created": "Tue, 10 Sep 2019 08:29:00 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Garcia", "Alexandre", ""], ["Colombo", "Pierre", ""], ["Essid", "Slim", ""], ["d'Alch\u00e9-Buc", "Florence", ""], ["Clavel", "Chlo\u00e9", ""]]}, {"id": "1908.11254", "submitter": "Jonas Pfeiffer", "authors": "Jonas Pfeiffer, Christian M. Meyer, Claudia Schulz, Jan Kiesewetter,\n  Jan Zottmann, Michael Sailer, Elisabeth Bauer, Frank Fischer, Martin R.\n  Fischer, Iryna Gurevych", "title": "FAMULUS: Interactive Annotation and Feedback Generation for Teaching\n  Diagnostic Reasoning", "comments": "EMNLP 2019 - Demo", "journal-ref": "EMNLP-IJCNLP 2019: System Demonstrations", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our proposed system FAMULUS helps students learn to diagnose based on\nautomatic feedback in virtual patient simulations, and it supports instructors\nin labeling training data.\n  Diagnosing is an exceptionally difficult skill to obtain but vital for many\ndifferent professions (e.g., medical doctors, teachers).\n  Previous case simulation systems are limited to multiple-choice questions and\nthus cannot give constructive individualized feedback on a student's diagnostic\nreasoning process.\n  Given initially only limited data, we leverage a (replaceable) NLP model to\nboth support experts in their further data annotation with automatic\nsuggestions, and we provide automatic feedback for students.\n  We argue that because the central model consistently improves, our\ninteractive approach encourages both students and instructors to recurrently\nuse the tool, and thus accelerate the speed of data creation and annotation.\n  We show results from two user studies on diagnostic reasoning in medicine and\nteacher education and outline how our system can be extended to further use\ncases.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 14:25:23 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Pfeiffer", "Jonas", ""], ["Meyer", "Christian M.", ""], ["Schulz", "Claudia", ""], ["Kiesewetter", "Jan", ""], ["Zottmann", "Jan", ""], ["Sailer", "Michael", ""], ["Bauer", "Elisabeth", ""], ["Fischer", "Frank", ""], ["Fischer", "Martin R.", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1908.11279", "submitter": "David Schlangen", "authors": "David Schlangen", "title": "Grounded Agreement Games: Emphasizing Conversational Grounding in Visual\n  Dialogue Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Where early work on dialogue in Computational Linguistics put much emphasis\non dialogue structure and its relation to the mental states of the dialogue\nparticipants (e.g., Allen 1979, Grosz & Sidner 1986), current work mostly\nreduces dialogue to the task of producing at any one time a next utterance;\ne.g. in neural chatbot or Visual Dialogue settings. As a methodological\ndecision, this is sound: Even the longest journey is a sequence of steps. It\nbecomes detrimental, however, when the tasks and datasets from which dialogue\nbehaviour is to be learned are tailored too much to this framing of the\nproblem. In this short note, we describe a family of settings which still allow\nto keep dialogues simple, but add a constraint that makes participants care\nabout reaching mutual understanding. In such agreement games, there is a\nsecondary, but explicit goal besides the task level goal, and that is to reach\nmutual understanding about whether the task level goal has been reached. As we\nargue, this naturally triggers meta-semantic interaction and mutual engagement,\nand hence leads to richer data from which to induce models.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 15:05:52 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Schlangen", "David", ""]]}, {"id": "1908.11302", "submitter": "Denis Newman-Griffis", "authors": "Denis Newman-Griffis, Eric Fosler-Lussier", "title": "HARE: a Flexible Highlighting Annotator for Ranking and Exploration", "comments": "EMNLP 2019 Systems Demonstration. Online version including\n  supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration and analysis of potential data sources is a significant challenge\nin the application of NLP techniques to novel information domains. We describe\nHARE, a system for highlighting relevant information in document collections to\nsupport ranking and triage, which provides tools for post-processing and\nqualitative analysis for model development and tuning. We apply HARE to the use\ncase of narrative descriptions of mobility information in clinical data, and\ndemonstrate its utility in comparing candidate embedding features. We provide a\nweb-based interface for annotation visualization and document ranking, with a\nmodular backend to support interoperability with existing annotation tools. Our\nsystem is available online at https://github.com/OSU-slatelab/HARE.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 15:36:40 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Newman-Griffis", "Denis", ""], ["Fosler-Lussier", "Eric", ""]]}, {"id": "1908.11310", "submitter": "Koustav Ghosal", "authors": "Koustav Ghosal, Aakanksha Rana, Aljosa Smolic", "title": "Aesthetic Image Captioning From Weakly-Labelled Photographs", "comments": "International Workshop on Cross-Modal Learning in Real World, ICCV\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aesthetic image captioning (AIC) refers to the multi-modal task of generating\ncritical textual feedbacks for photographs. While in natural image captioning\n(NIC), deep models are trained in an end-to-end manner using large curated\ndatasets such as MS-COCO, no such large-scale, clean dataset exists for AIC.\nTowards this goal, we propose an automatic cleaning strategy to create a\nbenchmarking AIC dataset, by exploiting the images and noisy comments easily\navailable from photography websites. We propose a probabilistic\ncaption-filtering method for cleaning the noisy web-data, and compile a\nlarge-scale, clean dataset \"AVA-Captions\", (230, 000 images with 5 captions per\nimage). Additionally, by exploiting the latent associations between aesthetic\nattributes, we propose a strategy for training the convolutional neural network\n(CNN) based visual feature extractor, the first component of the AIC framework.\nThe strategy is weakly supervised and can be effectively used to learn rich\naesthetic representations, without requiring expensive ground-truth\nannotations. We finally show-case a thorough analysis of the proposed\ncontributions using automatic metrics and subjective evaluations.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 15:50:28 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Ghosal", "Koustav", ""], ["Rana", "Aakanksha", ""], ["Smolic", "Aljosa", ""]]}, {"id": "1908.11317", "submitter": "Hongxiao Bai", "authors": "Hongxiao Bai, Hai Zhao, Junhan Zhao", "title": "Memorizing All for Implicit Discourse Relation Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit discourse relation recognition is a challenging task due to the\nabsence of the necessary informative clue from explicit connectives. The\nprediction of relations requires a deep understanding of the semantic meanings\nof sentence pairs. As implicit discourse relation recognizer has to carefully\ntackle the semantic similarity of the given sentence pairs and the severe data\nsparsity issue exists in the meantime, it is supposed to be beneficial from\nmastering the entire training data. Thus in this paper, we propose a novel\nmemory mechanism to tackle the challenges for further performance improvement.\nThe memory mechanism is adequately memorizing information by pairing\nrepresentations and discourse relations of all training instances, which right\nfills the slot of the data-hungry issue in the current implicit discourse\nrelation recognizer. Our experiments show that our full model with memorizing\nthe entire training set reaches new state-of-the-art against strong baselines,\nwhich especially for the first time exceeds the milestone of 60% accuracy in\nthe 4-way task.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 16:00:25 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Bai", "Hongxiao", ""], ["Zhao", "Hai", ""], ["Zhao", "Junhan", ""]]}, {"id": "1908.11326", "submitter": "Angel Daza", "authors": "Angel Daza, Anette Frank", "title": "Translate and Label! An Encoder-Decoder Approach for Cross-lingual\n  Semantic Role Labeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Cross-lingual Encoder-Decoder model that simultaneously\ntranslates and generates sentences with Semantic Role Labeling annotations in a\nresource-poor target language. Unlike annotation projection techniques, our\nmodel does not need parallel data during inference time. Our approach can be\napplied in monolingual, multilingual and cross-lingual settings and is able to\nproduce dependency-based and span-based SRL annotations. We benchmark the\nlabeling performance of our model in different monolingual and multilingual\nsettings using well-known SRL datasets. We then train our model in a\ncross-lingual setting to generate new SRL labeled data. Finally, we measure the\neffectiveness of our method by using the generated data to augment the training\nbasis for resource-poor languages and perform manual evaluation to show that it\nproduces high-quality sentences and assigns accurate semantic role annotations.\nOur proposed architecture offers a flexible method for leveraging SRL data in\nmultiple languages.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 16:17:53 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Daza", "Angel", ""], ["Frank", "Anette", ""]]}, {"id": "1908.11337", "submitter": "Wenliang Chen", "authors": "Haitao Wang, Zhengqiu He, Tong Zhu, Hao Shao, Wenliang Chen, Min Zhang", "title": "CCKS 2019 Shared Task on Inter-Personal Relationship Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CCKS2019 shared task was devoted to inter-personal relationship\nextraction. Given two person entities and at least one sentence containing\nthese two entities, participating teams are asked to predict the relationship\nbetween the entities according to a given relation list. This year, 358 teams\nfrom various universities and organizations participated in this task. In this\npaper, we present the task definition, the description of data and the\nevaluation methodology used during this shared task. We also present a brief\noverview of the various methods adopted by the participating teams. Finally, we\npresent the evaluation results.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 16:42:19 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Wang", "Haitao", ""], ["He", "Zhengqiu", ""], ["Zhu", "Tong", ""], ["Shao", "Hao", ""], ["Chen", "Wenliang", ""], ["Zhang", "Min", ""]]}, {"id": "1908.11355", "submitter": "Piyawat Lertvittayakumjorn", "authors": "Piyawat Lertvittayakumjorn, Francesca Toni", "title": "Human-grounded Evaluations of Explanation Methods for Text\n  Classification", "comments": "17 pages including appendices; accepted to appear at EMNLP-IJCNLP\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the black-box nature of deep learning models, methods for explaining\nthe models' results are crucial to gain trust from humans and support\ncollaboration between AIs and humans. In this paper, we consider several\nmodel-agnostic and model-specific explanation methods for CNNs for text\nclassification and conduct three human-grounded evaluations, focusing on\ndifferent purposes of explanations: (1) revealing model behavior, (2)\njustifying model predictions, and (3) helping humans investigate uncertain\npredictions. The results highlight dissimilar qualities of the various\nexplanation methods we consider and show the degree to which these methods\ncould serve for each purpose.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 17:12:04 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Lertvittayakumjorn", "Piyawat", ""], ["Toni", "Francesca", ""]]}, {"id": "1908.11365", "submitter": "Biao Zhang", "authors": "Biao Zhang, Ivan Titov, Rico Sennrich", "title": "Improving Deep Transformer with Depth-Scaled Initialization and Merged\n  Attention", "comments": "EMNLP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The general trend in NLP is towards increasing model capacity and performance\nvia deeper neural networks. However, simply stacking more layers of the popular\nTransformer architecture for machine translation results in poor convergence\nand high computational overhead. Our empirical analysis suggests that\nconvergence is poor due to gradient vanishing caused by the interaction between\nresidual connections and layer normalization. We propose depth-scaled\ninitialization (DS-Init), which decreases parameter variance at the\ninitialization stage, and reduces output variance of residual connections so as\nto ease gradient back-propagation through normalization layers. To address\ncomputational cost, we propose a merged attention sublayer (MAtt) which\ncombines a simplified averagebased self-attention sublayer and the\nencoderdecoder attention sublayer on the decoder side. Results on WMT and IWSLT\ntranslation tasks with five translation directions show that deep Transformers\nwith DS-Init and MAtt can substantially outperform their base counterpart in\nterms of BLEU (+1.1 BLEU on average for 12-layer models), while matching the\ndecoding speed of the baseline model thanks to the efficiency improvements of\nMAtt.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 17:50:55 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Zhang", "Biao", ""], ["Titov", "Ivan", ""], ["Sennrich", "Rico", ""]]}, {"id": "1908.11421", "submitter": "John Lalor", "authors": "John P. Lalor, Hao Wu, Hong Yu", "title": "Learning Latent Parameters without Human Response Patterns: Item\n  Response Theory with Artificial Crowds", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating Item Response Theory (IRT) into NLP tasks can provide valuable\ninformation about model performance and behavior. Traditionally, IRT models are\nlearned using human response pattern (RP) data, presenting a significant\nbottleneck for large data sets like those required for training deep neural\nnetworks (DNNs). In this work we propose learning IRT models using RPs\ngenerated from artificial crowds of DNN models. We demonstrate the\neffectiveness of learning IRT models using DNN-generated data through\nquantitative and qualitative analyses for two NLP tasks. Parameters learned\nfrom human and machine RPs for natural language inference and sentiment\nanalysis exhibit medium to large positive correlations. We demonstrate a\nuse-case for latent difficulty item parameters, namely training set filtering,\nand show that using difficulty to sample training data outperforms baseline\nmethods. Finally, we highlight cases where human expectation about item\ndifficulty does not match difficulty as estimated from the machine RPs.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 18:50:51 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Lalor", "John P.", ""], ["Wu", "Hao", ""], ["Yu", "Hong", ""]]}, {"id": "1908.11425", "submitter": "Sameer Bansal", "authors": "Sameer Bansal, Herman Kamper, Adam Lopez, Sharon Goldwater", "title": "Cross-lingual topic prediction for speech using translations", "comments": "Accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a large amount of unannotated speech in a low-resource language, can we\nclassify the speech utterances by topic? We consider this question in the\nsetting where a small amount of speech in the low-resource language is paired\nwith text translations in a high-resource language. We develop an effective\ncross-lingual topic classifier by training on just 20 hours of translated\nspeech, using a recent model for direct speech-to-text translation. While the\ntranslations are poor, they are still good enough to correctly classify the\ntopic of 1-minute speech segments over 70% of the time - a 20% improvement over\na majority-class baseline. Such a system could be useful for humanitarian\napplications like crisis response, where incoming speech in a foreign\nlow-resource language must be quickly assessed for further action.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 19:11:26 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 12:01:24 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Bansal", "Sameer", ""], ["Kamper", "Herman", ""], ["Lopez", "Adam", ""], ["Goldwater", "Sharon", ""]]}, {"id": "1908.11439", "submitter": "Steven Derby Mr", "authors": "Steven Derby, Paul Miller and Barry Devereux", "title": "Feature2Vec: Distributional semantic modelling of human property\n  knowledge", "comments": "7 pages, Proceedings of the 2019 Conference on Empirical Methods in\n  Natural Language Processing (EMNLP 2019)", "journal-ref": "Proceedings of the 2019 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP 2019)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature norm datasets of human conceptual knowledge, collected in surveys of\nhuman volunteers, yield highly interpretable models of word meaning and play an\nimportant role in neurolinguistic research on semantic cognition. However,\nthese datasets are limited in size due to practical obstacles associated with\nexhaustively listing properties for a large number of words. In contrast, the\ndevelopment of distributional modelling techniques and the availability of vast\ntext corpora have allowed researchers to construct effective vector space\nmodels of word meaning over large lexicons. However, this comes at the cost of\ninterpretable, human-like information about word meaning. We propose a method\nfor mapping human property knowledge onto a distributional semantic space,\nwhich adapts the word2vec architecture to the task of modelling concept\nfeatures. Our approach gives a measure of concept and feature affinity in a\nsingle semantic space, which makes for easy and efficient ranking of candidate\nhuman-derived semantic properties for arbitrary words. We compare our model\nwith a previous approach, and show that it performs better on several\nevaluation tasks. Finally, we discuss how our method could be used to develop\nefficient sampling techniques to extend existing feature norm datasets in a\nreliable way.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 19:57:25 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Derby", "Steven", ""], ["Miller", "Paul", ""], ["Devereux", "Barry", ""]]}, {"id": "1908.11443", "submitter": "Anna Rogers", "authors": "Anna Rogers, Gregory Smelkov, Anna Rumshisky", "title": "NarrativeTime: Dense High-Speed Temporal Annotation on a Timeline", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present NarrativeTime, a new timeline-based annotation scheme for temporal\norder of events in text, and a new densely annotated fiction corpus comparable\nto TimeBank-Dense. NarrativeTime is considerably faster than schemes based on\nevent pairs such as TimeML, and it produces more temporal links between events\nthan TimeBank-Dense, while maintaining comparable agreement on temporal links.\nThis is achieved through new strategies for encoding vagueness in temporal\nrelations and an annotation workflow that takes into account the annotators'\nchunking and commonsense reasoning strategies. NarrativeTime comes with new\nspecialized web-based tools for annotation and adjudication.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 20:09:27 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Rogers", "Anna", ""], ["Smelkov", "Gregory", ""], ["Rumshisky", "Anna", ""]]}, {"id": "1908.11474", "submitter": "Ruiqi Zhong", "authors": "Ruiqi Zhong, Yanda Chen, Desmond Patton, Charlotte Selous, Kathy\n  McKeown", "title": "Detecting and Reducing Bias in a High Stakes Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gang-involved youth in cities such as Chicago sometimes post on social media\nto express their aggression towards rival gangs and previous research has\ndemonstrated that a deep learning approach can predict aggression and loss in\nposts. To address the possibility of bias in this sensitive application, we\ndeveloped an approach to systematically interpret the state of the art model.\nWe found, surprisingly, that it frequently bases its predictions on stop words\nsuch as \"a\" or \"on\", an approach that could harm social media users who have no\naggressive intentions. To tackle this bias, domain experts annotated the\nrationales, highlighting words that explain why a tweet is labeled as\n\"aggression\". These new annotations enable us to quantitatively measure how\njustified the model predictions are, and build models that drastically reduce\nbias. Our study shows that in high stake scenarios, accuracy alone cannot\nguarantee a good system and we need new evaluation methods.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 22:44:41 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 16:39:27 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Zhong", "Ruiqi", ""], ["Chen", "Yanda", ""], ["Patton", "Desmond", ""], ["Selous", "Charlotte", ""], ["McKeown", "Kathy", ""]]}, {"id": "1908.11487", "submitter": "Hugh Perkins", "authors": "Hugh Perkins and Yi Yang", "title": "Dialog Intent Induction with Deep Multi-View Clustering", "comments": "Original version appeared in EMNLP 2020. We have added an appendix\n  which includes experiments on a slightly larger AskUbuntu dataset, and\n  incorporating several post-publication code bug-fixes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the dialog intent induction task and present a novel deep\nmulti-view clustering approach to tackle the problem. Dialog intent induction\naims at discovering user intents from user query utterances in human-human\nconversations such as dialogs between customer support agents and customers.\nMotivated by the intuition that a dialog intent is not only expressed in the\nuser query utterance but also captured in the rest of the dialog, we split a\nconversation into two independent views and exploit multi-view clustering\ntechniques for inducing the dialog intent. In particular, we propose\nalternating-view k-means (AV-KMEANS) for joint multi-view representation\nlearning and clustering analysis. The key innovation is that the instance-view\nrepresentations are updated iteratively by predicting the cluster assignment\nobtained from the alternative view, so that the multi-view representations of\nthe instances lead to similar cluster assignments. Experiments on two public\ndatasets show that AV-KMEANS can induce better dialog intent clusters than\nstate-of-the-art unsupervised representation learning methods and standard\nmulti-view clustering approaches.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 00:08:06 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 19:04:59 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Perkins", "Hugh", ""], ["Yang", "Yi", ""]]}, {"id": "1908.11511", "submitter": "Shuailiang Zhang", "authors": "Shuailiang Zhang, Hai Zhao, Yuwei Wu, Zhuosheng Zhang, Xi Zhou, Xiang\n  Zhou", "title": "DCMN+: Dual Co-Matching Network for Multi-choice Reading Comprehension", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Multi-choice reading comprehension is a challenging task to select an answer\nfrom a set of candidate options when given passage and question. Previous\napproaches usually only calculate question-aware passage representation and\nignore passage-aware question representation when modeling the relationship\nbetween passage and question, which obviously cannot take the best of\ninformation between passage and question. In this work, we propose dual\nco-matching network (DCMN) which models the relationship among passage,\nquestion and answer options bidirectionally. Besides, inspired by how human\nsolve multi-choice questions, we integrate two reading strategies into our\nmodel: (i) passage sentence selection that finds the most salient supporting\nsentences to answer the question, (ii) answer option interaction that encodes\nthe comparison information between answer options. DCMN integrated with the two\nstrategies (DCMN+) obtains state-of-the-art results on five multi-choice\nreading comprehension datasets which are from different domains: RACE,\nSemEval-2018 Task 11, ROCStories, COIN, MCTest.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 02:30:28 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 08:16:19 GMT"}, {"version": "v3", "created": "Fri, 13 Dec 2019 07:00:37 GMT"}, {"version": "v4", "created": "Thu, 16 Jan 2020 07:56:14 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Zhang", "Shuailiang", ""], ["Zhao", "Hai", ""], ["Wu", "Yuwei", ""], ["Zhang", "Zhuosheng", ""], ["Zhou", "Xi", ""], ["Zhou", "Xiang", ""]]}, {"id": "1908.11521", "submitter": "Deng Cai", "authors": "Huajie Chen and Deng Cai and Wei Dai and Zehui Dai and Yadong Ding", "title": "Charge-Based Prison Term Prediction with Deep Gating Network", "comments": "EMNLP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Judgment prediction for legal cases has attracted much research efforts for\nits practice use, of which the ultimate goal is prison term prediction. While\nexisting work merely predicts the total prison term, in reality a defendant is\noften charged with multiple crimes. In this paper, we argue that charge-based\nprison term prediction (CPTP) not only better fits realistic needs, but also\nmakes the total prison term prediction more accurate and interpretable. We\ncollect the first large-scale structured data for CPTP and evaluate several\ncompetitive baselines. Based on the observation that fine-grained feature\nselection is the key to achieving good performance, we propose the Deep Gating\nNetwork (DGN) for charge-specific feature selection and aggregation.\nExperiments show that DGN achieves the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 03:44:10 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Chen", "Huajie", ""], ["Cai", "Deng", ""], ["Dai", "Wei", ""], ["Dai", "Zehui", ""], ["Ding", "Yadong", ""]]}, {"id": "1908.11522", "submitter": "Junru Zhou", "authors": "Junru Zhou, Zuchao Li, Hai Zhao", "title": "Parsing All: Syntax and Semantics, Dependencies and Spans", "comments": "EMNLP 2020, ACL Findings. arXiv admin note: text overlap with\n  arXiv:1907.02684", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both syntactic and semantic structures are key linguistic contextual clues,\nin which parsing the latter has been well shown beneficial from parsing the\nformer. However, few works ever made an attempt to let semantic parsing help\nsyntactic parsing. As linguistic representation formalisms, both syntax and\nsemantics may be represented in either span (constituent/phrase) or dependency,\non both of which joint learning was also seldom explored. In this paper, we\npropose a novel joint model of syntactic and semantic parsing on both span and\ndependency representations, which incorporates syntactic information\neffectively in the encoder of neural network and benefits from two\nrepresentation formalisms in a uniform way. The experiments show that semantics\nand syntax can benefit each other by optimizing joint objectives. Our single\nmodel achieves new state-of-the-art or competitive results on both span and\ndependency semantic parsing on Propbank benchmarks and both dependency and\nconstituent syntactic parsing on Penn Treebank.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 03:49:19 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 05:52:11 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 03:30:01 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Zhou", "Junru", ""], ["Li", "Zuchao", ""], ["Zhao", "Hai", ""]]}, {"id": "1908.11527", "submitter": "Le Fang", "authors": "Le Fang, Chunyuan Li, Jianfeng Gao, Wen Dong and Changyou Chen", "title": "Implicit Deep Latent Variable Models for Text Generation", "comments": "13 pages, 8 Tables, 1 Figure, Accepted at 2019 Conference on\n  Empirical Methods in Natural Language Processing (EMNLP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep latent variable models (LVM) such as variational auto-encoder (VAE) have\nrecently played an important role in text generation. One key factor is the\nexploitation of smooth latent structures to guide the generation. However, the\nrepresentation power of VAEs is limited due to two reasons: (1) the Gaussian\nassumption is often made on the variational posteriors; and meanwhile (2) a\nnotorious \"posterior collapse\" issue occurs. In this paper, we advocate\nsample-based representations of variational distributions for natural language,\nleading to implicit latent features, which can provide flexible representation\npower compared with Gaussian-based posteriors. We further develop an LVM to\ndirectly match the aggregated posterior to the prior. It can be viewed as a\nnatural extension of VAEs with a regularization of maximizing mutual\ninformation, mitigating the \"posterior collapse\" issue. We demonstrate the\neffectiveness and versatility of our models in various text generation\nscenarios, including language modeling, unaligned style transfer, and dialog\nresponse generation. The source code to reproduce our experimental results is\navailable on GitHub.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 04:12:08 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 05:48:05 GMT"}, {"version": "v3", "created": "Wed, 27 Nov 2019 19:53:57 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Fang", "Le", ""], ["Li", "Chunyuan", ""], ["Gao", "Jianfeng", ""], ["Dong", "Wen", ""], ["Chen", "Changyou", ""]]}, {"id": "1908.11535", "submitter": "Yusuke Yasuda", "authors": "Yusuke Yasuda, Xin Wang, Junichi Yamagishi", "title": "Initial investigation of an encoder-decoder end-to-end TTS framework\n  using marginalization of monotonic hard latent alignments", "comments": "To be appeared at SSW10", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end text-to-speech (TTS) synthesis is a method that directly converts\ninput text to output acoustic features using a single network. A recent advance\nof end-to-end TTS is due to a key technique called attention mechanisms, and\nall successful methods proposed so far have been based on soft attention\nmechanisms. However, although network structures are becoming increasingly\ncomplex, end-to-end TTS systems with soft attention mechanisms may still fail\nto learn and to predict accurate alignment between the input and output. This\nmay be because the soft attention mechanisms are too flexible. Therefore, we\npropose an approach that has more explicit but natural constraints suitable for\nspeech signals to make alignment learning and prediction of end-to-end TTS\nsystems more robust. The proposed system, with the constrained alignment scheme\nborrowed from segment-to-segment neural transduction (SSNT), directly\ncalculates the joint probability of acoustic features and alignment given an\ninput text. The alignment is designed to be hard and monotonically increase by\nconsidering the speech nature, and it is treated as a latent variable and\nmarginalized during training. During prediction, both the alignment and\nacoustic features can be generated from the probabilistic distributions. The\nadvantages of our approach are that we can simplify many modules for the soft\nattention and that we can train the end-to-end TTS model using a single\nlikelihood function. As far as we know, our approach is the first end-to-end\nTTS without a soft attention mechanism.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 05:00:06 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Yasuda", "Yusuke", ""], ["Wang", "Xin", ""], ["Yamagishi", "Junichi", ""]]}, {"id": "1908.11536", "submitter": "Izhak Shafran", "authors": "Nan Du, Mingqiu Wang, Linh Tran, Gang Li, Izhak Shafran", "title": "Learning to Infer Entities, Properties and their Relations from Clinical\n  Conversations", "comments": null, "journal-ref": "Proc. Empirical Methods in Natural Language Processing, 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently we proposed the Span Attribute Tagging (SAT) Model (Du et al., 2019)\nto infer clinical entities (e.g., symptoms) and their properties (e.g.,\nduration). It tackles the challenge of large label space and limited training\ndata using a hierarchical two-stage approach that identifies the span of\ninterest in a tagging step and assigns labels to the span in a classification\nstep.\n  We extend the SAT model to jointly infer not only entities and their\nproperties but also relations between them. Most relation extraction models\nrestrict inferring relations between tokens within a few neighboring sentences,\nmainly to avoid high computational complexity. In contrast, our proposed\nRelation-SAT (R-SAT) model is computationally efficient and can infer relations\nover the entire conversation, spanning an average duration of 10 minutes.\n  We evaluate our model on a corpus of clinical conversations. When the\nentities are given, the R-SAT outperforms baselines in identifying relations\nbetween symptoms and their properties by about 32% (0.82 vs 0.62 F-score) and\nby about 50% (0.60 vs 0.41 F-score) on medications and their properties. On the\nmore difficult task of jointly inferring entities and relations, the R-SAT\nmodel achieves a performance of 0.34 and 0.45 for symptoms and medications\nrespectively, which is significantly better than 0.18 and 0.35 for the baseline\nmodel. The contributions of different components of the model are quantified\nusing ablation analysis.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 05:27:39 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Du", "Nan", ""], ["Wang", "Mingqiu", ""], ["Tran", "Linh", ""], ["Li", "Gang", ""], ["Shafran", "Izhak", ""]]}, {"id": "1908.11540", "submitter": "Soujanya Poria", "authors": "Deepanway Ghosal, Navonil Majumder, Soujanya Poria, Niyati Chhaya and\n  Alexander Gelbukh", "title": "DialogueGCN: A Graph Convolutional Neural Network for Emotion\n  Recognition in Conversation", "comments": "Accepted at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Emotion recognition in conversation (ERC) has received much attention,\nlately, from researchers due to its potential widespread applications in\ndiverse areas, such as health-care, education, and human resources. In this\npaper, we present Dialogue Graph Convolutional Network (DialogueGCN), a graph\nneural network based approach to ERC. We leverage self and inter-speaker\ndependency of the interlocutors to model conversational context for emotion\nrecognition. Through the graph network, DialogueGCN addresses context\npropagation issues present in the current RNN-based methods. We empirically\nshow that this method alleviates such issues, while outperforming the current\nstate of the art on a number of benchmark emotion classification datasets.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 05:44:24 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Ghosal", "Deepanway", ""], ["Majumder", "Navonil", ""], ["Poria", "Soujanya", ""], ["Chhaya", "Niyati", ""], ["Gelbukh", "Alexander", ""]]}, {"id": "1908.11546", "submitter": "Lei Shu", "authors": "Lei Shu, Hu Xu, Bing Liu, Piero Molino", "title": "Modeling Multi-Action Policy for Task-Oriented Dialogues", "comments": "7", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue management (DM) plays a key role in the quality of the interaction\nwith the user in a task-oriented dialogue system. In most existing approaches,\nthe agent predicts only one DM policy action per turn. This significantly\nlimits the expressive power of the conversational agent and introduces unwanted\nturns of interactions that may challenge users' patience. Longer conversations\nalso lead to more errors and the system needs to be more robust to handle them.\nIn this paper, we compare the performance of several models on the task of\npredicting multiple acts for each turn. A novel policy model is proposed based\non a recurrent cell called gated Continue-Act-Slots (gCAS) that overcomes the\nlimitations of the existing models. Experimental results show that gCAS\noutperforms other approaches. The code is available at\nhttps://leishu02.github.io/\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 06:15:35 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Shu", "Lei", ""], ["Xu", "Hu", ""], ["Liu", "Bing", ""], ["Molino", "Piero", ""]]}, {"id": "1908.11561", "submitter": "Zhuoren Jiang", "authors": "Zhuoren Jiang, Zhe Gao, Guoxiu He, Yangyang Kang, Changlong Sun, Qiong\n  Zhang, Luo Si and Xiaozhong Liu", "title": "Detect Camouflaged Spam Content via StoneSkipping: Graph and Text Joint\n  Embedding for Chinese Character Variation Representation", "comments": "Accepted as a full paper of 2019 Conference on Empirical Methods in\n  Natural Language Processing and 9th International Joint Conference on Natural\n  Language Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of Chinese text spam detection is very challenging due to both glyph\nand phonetic variations of Chinese characters. This paper proposes a novel\nframework to jointly model Chinese variational, semantic, and contextualized\nrepresentations for Chinese text spam detection task. In particular, a\nVariation Family-enhanced Graph Embedding (VFGE) algorithm is designed based on\na Chinese character variation graph. The VFGE can learn both the graph\nembeddings of the Chinese characters (local) and the latent variation families\n(global). Furthermore, an enhanced bidirectional language model, with a\ncombination gate function and an aggregation learning function, is proposed to\nintegrate the graph and text information while capturing the sequential\ninformation. Extensive experiments have been conducted on both SMS and review\ndatasets, to show the proposed method outperforms a series of state-of-the-art\nmodels for Chinese spam detection.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 06:38:55 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Jiang", "Zhuoren", ""], ["Gao", "Zhe", ""], ["He", "Guoxiu", ""], ["Kang", "Yangyang", ""], ["Sun", "Changlong", ""], ["Zhang", "Qiong", ""], ["Si", "Luo", ""], ["Liu", "Xiaozhong", ""]]}, {"id": "1908.11571", "submitter": "Xiang Lin", "authors": "Linlin Liu, Xiang Lin, Shafiq Joty, Simeng Han, Lidong Bing", "title": "Hierarchical Pointer Net Parsing", "comments": "Accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transition-based top-down parsing with pointer networks has achieved\nstate-of-the-art results in multiple parsing tasks, while having a linear time\ncomplexity. However, the decoder of these parsers has a sequential structure,\nwhich does not yield the most appropriate inductive bias for deriving tree\nstructures. In this paper, we propose hierarchical pointer network parsers, and\napply them to dependency and sentence-level discourse parsing tasks. Our\nresults on standard benchmark datasets demonstrate the effectiveness of our\napproach, outperforming existing methods and setting a new state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 07:22:43 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Liu", "Linlin", ""], ["Lin", "Xiang", ""], ["Joty", "Shafiq", ""], ["Han", "Simeng", ""], ["Bing", "Lidong", ""]]}, {"id": "1908.11593", "submitter": "Anton Batliner", "authors": "Anton Batliner and Stefan Steidl and Florian Eyben and Bj\\\"orn\n  Schuller", "title": "On Laughter and Speech-Laugh, Based on Observations of Child-Robot\n  Interaction", "comments": "25 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we study laughter found in child-robot interaction where it\nhad not been prompted intentionally. Different types of laughter and\nspeech-laugh are annotated and processed. In a descriptive part, we report on\nthe position of laughter and speech-laugh in syntax and dialogue structure, and\non communicative functions. In a second part, we report on automatic\nclassification performance and on acoustic characteristics, based on extensive\nfeature selection procedures.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 08:32:10 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Batliner", "Anton", ""], ["Steidl", "Stefan", ""], ["Eyben", "Florian", ""], ["Schuller", "Bj\u00f6rn", ""]]}, {"id": "1908.11599", "submitter": "Isabelle van der Vegt", "authors": "Isabelle van der Vegt, Maximilian Mozes, Paul Gill, Bennett Kleinberg", "title": "Online influence, offline violence: Language Use on YouTube surrounding\n  the 'Unite the Right' rally", "comments": "pre-print (pre-peer review)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The media frequently describes the 2017 Charlottesville 'Unite the Right'\nrally as a turning point for the alt-right and white supremacist movements.\nSocial movement theory suggests that the media attention and public discourse\nconcerning the rally may have influenced the alt-right, but this has yet to be\nempirically tested. The current study investigates whether there are\ndifferences in language use between 7,142 alt-right and progressive YouTube\nchannels, in addition to measuring possible changes as a result of the rally.\nTo do so, we create structural topic models and measure bigram proportions in\nvideo transcripts, spanning eight weeks before to eight weeks after the rally.\nWe observe differences in topics between the two groups, with the 'alternative\ninfluencers' for example discussing topics related to race and free speech to\nan increasing and larger extent than progressive channels. We also observe\nstructural breakpoints in the use of bigrams at the time of the rally,\nsuggesting there are changes in language use within the two groups as a result\nof the rally. While most changes relate to mentions of the rally itself, the\nalternative group also shows an increase in promotion of their YouTube\nchannels. Results are discussed in light of social movement theory, followed by\na discussion of potential implications for understanding the alt-right and\ntheir language use on YouTube.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 08:58:11 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 08:58:27 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["van der Vegt", "Isabelle", ""], ["Mozes", "Maximilian", ""], ["Gill", "Paul", ""], ["Kleinberg", "Bennett", ""]]}, {"id": "1908.11610", "submitter": "Zhuoren Jiang", "authors": "Zhuoren Jiang, Jian Wang, Lujun Zhao, Changlong Sun, Yao Lu, Xiaozhong\n  Liu", "title": "Cross-domain Aspect Category Transfer and Detection via Traceable\n  Heterogeneous Graph Representation Learning", "comments": "Accepted as a full paper of The 28th ACM International Conference on\n  Information and Knowledge Management (CIKM '19)", "journal-ref": null, "doi": "10.1145/3357384.3357989", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect category detection is an essential task for sentiment analysis and\nopinion mining. However, the cost of categorical data labeling, e.g., label the\nreview aspect information for a large number of product domains, can be\ninevitable but unaffordable. In this study, we propose a novel problem,\ncross-domain aspect category transfer and detection, which faces three\nchallenges: various feature spaces, different data distributions, and diverse\noutput spaces. To address these problems, we propose an innovative solution,\nTraceable Heterogeneous Graph Representation Learning (THGRL). Unlike prior\ntext-based aspect detection works, THGRL explores latent domain aspect category\nconnections via massive user behavior information on a heterogeneous graph.\nMoreover, an innovative latent variable \"Walker Tracer\" is introduced to\ncharacterize the global semantic/aspect dependencies and capture the\ninformative vertexes on the random walk paths. By using THGRL, we project\ndifferent domains' feature spaces into a common one, while allowing data\ndistributions and output spaces stay differently. Experiment results show that\nthe proposed method outperforms a series of state-of-the-art baseline models.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 09:30:38 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Jiang", "Zhuoren", ""], ["Wang", "Jian", ""], ["Zhao", "Lujun", ""], ["Sun", "Changlong", ""], ["Lu", "Yao", ""], ["Liu", "Xiaozhong", ""]]}, {"id": "1908.11658", "submitter": "Florian Schmidt", "authors": "Florian Schmidt, Stephan Mandt, Thomas Hofmann", "title": "Autoregressive Text Generation Beyond Feedback Loops", "comments": "emnlp camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoregressive state transitions, where predictions are conditioned on past\npredictions, are the predominant choice for both deterministic and stochastic\nsequential models. However, autoregressive feedback exposes the evolution of\nthe hidden state trajectory to potential biases from well-known train-test\ndiscrepancies. In this paper, we combine a latent state space model with a CRF\nobservation model. We argue that such autoregressive observation models form an\ninteresting middle ground that expresses local correlations on the word level\nbut keeps the state evolution non-autoregressive. On unconditional sentence\ngeneration we show performance improvements compared to RNN and GAN baselines\nwhile avoiding some prototypical failure modes of autoregressive models.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 11:31:07 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Schmidt", "Florian", ""], ["Mandt", "Stephan", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1908.11664", "submitter": "Pengfei Liu", "authors": "Danqing Wang, Pengfei Liu, Ming Zhong, Jie Fu, Xipeng Qiu, Xuanjing\n  Huang", "title": "Exploring Domain Shift in Extractive Text Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although domain shift has been well explored in many NLP applications, it\nstill has received little attention in the domain of extractive text\nsummarization. As a result, the model is under-utilizing the nature of the\ntraining data due to ignoring the difference in the distribution of training\nsets and shows poor generalization on the unseen domain.\n  With the above limitation in mind, in this paper, we first extend the\nconventional definition of the domain from categories into data sources for the\ntext summarization task. Then we re-purpose a multi-domain summarization\ndataset and verify how the gap between different domains influences the\nperformance of neural summarization models.\n  Furthermore, we investigate four learning strategies and examine their\nabilities to deal with the domain shift problem.\n  Experimental results on three different settings show their different\ncharacteristics in our new testbed.\n  Our source code including \\textit{BERT-based}, \\textit{meta-learning} methods\nfor multi-domain summarization learning and the re-purposed dataset\n\\textsc{Multi-SUM} will be available on our project:\n\\url{http://pfliu.com/TransferSum/}.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 11:40:14 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Wang", "Danqing", ""], ["Liu", "Pengfei", ""], ["Zhong", "Ming", ""], ["Fu", "Jie", ""], ["Qiu", "Xipeng", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1908.11685", "submitter": "Brendon Boldt", "authors": "Brendon Boldt", "title": "Using LSTMs to Model the Java Programming Language", "comments": "9 pages, 2 figures", "journal-ref": "Artificial Neural Networks and Machine Learning -- ICANN 2017.\n  ICANN 2017. Lecture Notes in Computer Science, vol 10614", "doi": "10.1007/978-3-319-68612-7_31", "report-no": null, "categories": "cs.SE cs.CL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs), specifically long-short term memory\nnetworks (LSTMs), can model natural language effectively. This research\ninvestigates the ability for these same LSTMs to perform next \"word\" prediction\non the Java programming language. Java source code from four different\nrepositories undergoes a transformation that preserves the logical structure of\nthe source code and removes the code's various specificities such as variable\nnames and literal values. Such datasets and an additional English language\ncorpus are used to train and test standard LSTMs' ability to predict the next\nelement in a sequence. Results suggest that LSTMs can effectively model Java\ncode achieving perplexities under 22 and accuracies above 0.47, which is an\nimprovement over LSTM's performance on the English language which demonstrated\na perplexity of 85 and an accuracy of 0.27. This research can have\napplicability in other areas such as syntactic template suggestion and\nautomated bug patching.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 00:43:32 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Boldt", "Brendon", ""]]}, {"id": "1908.11722", "submitter": "Preslav Nakov", "authors": "Dimitrina Zlatkova, Preslav Nakov, Ivan Koychev", "title": "Fact-Checking Meets Fauxtography: Verifying Claims About Images", "comments": "Claims about Images; Fauxtography; Fact-Checking; Veracity; Fake News", "journal-ref": "EMNLP-2019", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent explosion of false claims in social media and on the Web in\ngeneral has given rise to a lot of manual fact-checking initiatives.\nUnfortunately, the number of claims that need to be fact-checked is several\norders of magnitude larger than what humans can handle manually. Thus, there\nhas been a lot of research aiming at automating the process. Interestingly,\nprevious work has largely ignored the growing number of claims about images.\nThis is despite the fact that visual imagery is more influential than text and\nnaturally appears alongside fake news. Here we aim at bridging this gap. In\nparticular, we create a new dataset for this problem, and we explore a variety\nof features modeling the claim, the image, and the relationship between the\nclaim and the image. The evaluation results show sizable improvements over the\nbaseline. We release our dataset, hoping to enable further research on\nfact-checking claims about images.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 13:12:21 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Zlatkova", "Dimitrina", ""], ["Nakov", "Preslav", ""], ["Koychev", "Ivan", ""]]}, {"id": "1908.11723", "submitter": "Dongyeop Kang", "authors": "Taehee Jung, Dongyeop Kang, Lucas Mentch, Eduard Hovy", "title": "Earlier Isn't Always Better: Sub-aspect Analysis on Corpus and System\n  Biases in Summarization", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent developments on neural summarization systems, the\nunderlying logic behind the improvements from the systems and its\ncorpus-dependency remains largely unexplored. Position of sentences in the\noriginal text, for example, is a well known bias for news summarization.\nFollowing in the spirit of the claim that summarization is a combination of\nsub-functions, we define three sub-aspects of summarization: position,\nimportance, and diversity and conduct an extensive analysis of the biases of\neach sub-aspect with respect to the domain of nine different summarization\ncorpora (e.g., news, academic papers, meeting minutes, movie script, books,\nposts). We find that while position exhibits substantial bias in news articles,\nthis is not the case, for example, with academic papers and meeting minutes.\nFurthermore, our empirical study shows that different types of summarization\nsystems (e.g., neural-based) are composed of different degrees of the\nsub-aspects. Our study provides useful lessons regarding consideration of\nunderlying sub-aspects when collecting a new summarization dataset or\ndeveloping a new system.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 13:16:18 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Jung", "Taehee", ""], ["Kang", "Dongyeop", ""], ["Mentch", "Lucas", ""], ["Hovy", "Eduard", ""]]}, {"id": "1908.11771", "submitter": "Gongbo Tang", "authors": "Gongbo Tang and Rico Sennrich and Joakim Nivre", "title": "Encoders Help You Disambiguate Word Senses in Neural Machine Translation", "comments": "Update with corrections. Here is the link to the erratum:\n  https://www.aclweb.org/anthology/D19-1149e1.pdf", "journal-ref": null, "doi": "10.18653/v1/d19-1149", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) has achieved new state-of-the-art\nperformance in translating ambiguous words. However, it is still unclear which\ncomponent dominates the process of disambiguation. In this paper, we explore\nthe ability of NMT encoders and decoders to disambiguate word senses by\nevaluating hidden states and investigating the distributions of self-attention.\nWe train a classifier to predict whether a translation is correct given the\nrepresentation of an ambiguous noun. We find that encoder hidden states\noutperform word embeddings significantly which indicates that encoders\nadequately encode relevant information for disambiguation into hidden states.\nDecoders could provide further relevant information for disambiguation.\nMoreover, the attention weights and attention entropy show that self-attention\ncan detect ambiguous nouns and distribute more attention to the context. Note\nthat this is a revised version. The content related to decoder hidden states\nhas been updated.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 15:00:19 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 15:13:57 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Tang", "Gongbo", ""], ["Sennrich", "Rico", ""], ["Nivre", "Joakim", ""]]}, {"id": "1908.11782", "submitter": "Xuewen Yang", "authors": "Xuewen Yang, Yingru Liu, Dongliang Xie, Xin Wang, and Niranjan\n  Balasubramanian", "title": "Latent Part-of-Speech Sequences for Neural Machine Translation", "comments": "In proceedings of EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning target side syntactic structure has been shown to improve Neural\nMachine Translation (NMT). However, incorporating syntax through latent\nvariables introduces additional complexity in inference, as the models need to\nmarginalize over the latent syntactic structures. To avoid this, models often\nresort to greedy search which only allows them to explore a limited portion of\nthe latent space. In this work, we introduce a new latent variable model,\nLaSyn, that captures the co-dependence between syntax and semantics, while\nallowing for effective and efficient inference over the latent space. LaSyn\ndecouples direct dependence between successive latent variables, which allows\nits decoder to exhaustively search through the latent syntactic choices, while\nkeeping decoding speed proportional to the size of the latent variable\nvocabulary. We implement LaSyn by modifying a transformer-based NMT system and\ndesign a neural expectation maximization algorithm that we regularize with\npart-of-speech information as the latent sequences. Evaluations on four\ndifferent MT tasks show that incorporating target side syntax with LaSyn\nimproves both translation quality, and also provides an opportunity to improve\ndiversity.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 15:21:28 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Yang", "Xuewen", ""], ["Liu", "Yingru", ""], ["Xie", "Dongliang", ""], ["Wang", "Xin", ""], ["Balasubramanian", "Niranjan", ""]]}, {"id": "1908.11787", "submitter": "Peter Shaw", "authors": "Thomas M\\\"uller, Francesco Piccinno, Massimo Nicosia, Peter Shaw,\n  Yasemin Altun", "title": "Answering Conversational Questions on Structured Data without Logical\n  Forms", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to answering sequential questions based on\nstructured objects such as knowledge bases or tables without using a logical\nform as an intermediate representation. We encode tables as graphs using a\ngraph neural network model based on the Transformer architecture. The answers\nare then selected from the encoded graph using a pointer network. This model is\nappropriate for processing conversations around structured data, where the\nattention mechanism that selects the answers to a question can also be used to\nresolve conversational references. We demonstrate the validity of this approach\nwith competitive results on the Sequential Question Answering (SQA) task (Iyyer\net al., 2017).\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 15:26:44 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["M\u00fcller", "Thomas", ""], ["Piccinno", "Francesco", ""], ["Nicosia", "Massimo", ""], ["Shaw", "Peter", ""], ["Altun", "Yasemin", ""]]}, {"id": "1908.11790", "submitter": "Dongyeop Kang", "authors": "Dongyeop Kang, Hiroaki Hayashi, Alan W Black, Eduard Hovy", "title": "Linguistic Versus Latent Relations for Modeling Coherent Flow in\n  Paragraphs", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating a long, coherent text such as a paragraph requires a high-level\ncontrol of different levels of relations between sentences (e.g., tense,\ncoreference). We call such a logical connection between sentences as a\n(paragraph) flow. In order to produce a coherent flow of text, we explore two\nforms of intersentential relations in a paragraph: one is a human-created\nlinguistical relation that forms a structure (e.g., discourse tree) and the\nother is a relation from latent representation learned from the sentences\nthemselves. Our two proposed models incorporate each form of relations into\ndocument-level language models: the former is a supervised model that jointly\nlearns a language model as well as discourse relation prediction, and the\nlatter is an unsupervised model that is hierarchically conditioned by a\nrecurrent neural network (RNN) over the latent information. Our proposed models\nwith both forms of relations outperform the baselines in partially conditioned\nparagraph generation task. Our codes and data are publicly available.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 15:30:11 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Kang", "Dongyeop", ""], ["Hayashi", "Hiroaki", ""], ["Black", "Alan W", ""], ["Hovy", "Eduard", ""]]}, {"id": "1908.11813", "submitter": "Wenjie Zhou", "authors": "Wenjie Zhou, Minghua Zhang, Yunfang Wu", "title": "Multi-Task Learning with Language Modeling for Question Generation", "comments": "Accepted by EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the task of answer-aware questions generation. Based on\nthe attention-based pointer generator model, we propose to incorporate an\nauxiliary task of language modeling to help question generation in a\nhierarchical multi-task learning structure. Our joint-learning model enables\nthe encoder to learn a better representation of the input sequence, which will\nguide the decoder to generate more coherent and fluent questions. On both SQuAD\nand MARCO datasets, our multi-task learning model boosts the performance,\nachieving state-of-the-art results. Moreover, human evaluation further proves\nthe high quality of our generated questions.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 16:10:20 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Zhou", "Wenjie", ""], ["Zhang", "Minghua", ""], ["Wu", "Yunfang", ""]]}, {"id": "1908.11828", "submitter": "Yinfei Yang", "authors": "Yinfei Yang, Yuan Zhang, Chris Tar and Jason Baldridge", "title": "PAWS-X: A Cross-lingual Adversarial Dataset for Paraphrase\n  Identification", "comments": "Accepted by EMNLP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing work on adversarial data generation focuses on English. For\nexample, PAWS (Paraphrase Adversaries from Word Scrambling) consists of\nchallenging English paraphrase identification pairs from Wikipedia and Quora.\nWe remedy this gap with PAWS-X, a new dataset of 23,659 human translated PAWS\nevaluation pairs in six typologically distinct languages: French, Spanish,\nGerman, Chinese, Japanese, and Korean. We provide baseline numbers for three\nmodels with different capacity to capture non-local context and sentence\nstructure, and using different multilingual training and evaluation regimes.\nMultilingual BERT fine-tuned on PAWS English plus machine-translated data\nperforms the best, with a range of 83.1-90.8 accuracy across the non-English\nlanguages and an average accuracy gain of 23% over the next best model. PAWS-X\nshows the effectiveness of deep, multilingual pre-training while also leaving\nconsiderable headroom as a new challenge to drive multilingual research that\nbetter captures structure and contextual information.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 16:40:00 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Yang", "Yinfei", ""], ["Zhang", "Yuan", ""], ["Tar", "Chris", ""], ["Baldridge", "Jason", ""]]}, {"id": "1908.11841", "submitter": "Ella Rabinovich", "authors": "Ella Rabinovich, Masih Sultani, Suzanne Stevenson", "title": "CodeSwitch-Reddit: Exploration of Written Multilingual Discourse in\n  Online Discussion Forums", "comments": "EMNLP2019, 11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In contrast to many decades of research on oral code-switching, the study of\nwritten multilingual productions has only recently enjoyed a surge of interest.\nMany open questions remain regarding the sociolinguistic underpinnings of\nwritten code-switching, and progress has been limited by a lack of suitable\nresources. We introduce a novel, large, and diverse dataset of written\ncode-switched productions, curated from topical threads of multiple bilingual\ncommunities on the Reddit discussion platform, and explore questions that were\nmainly addressed in the context of spoken language thus far. We investigate\nwhether findings in oral code-switching concerning content and style, as well\nas speaker proficiency, are carried over into written code-switching in\ndiscussion forums. The released dataset can further facilitate a range of\nresearch and practical activities.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 17:12:32 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Rabinovich", "Ella", ""], ["Sultani", "Masih", ""], ["Stevenson", "Suzanne", ""]]}, {"id": "1908.11860", "submitter": "Alexander Rietzler", "authors": "Alexander Rietzler, Sebastian Stabinger, Paul Opitz, Stefan Engl", "title": "Adapt or Get Left Behind: Domain Adaptation through BERT Language Model\n  Finetuning for Aspect-Target Sentiment Classification", "comments": "11 pages, 1 figure, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-Target Sentiment Classification (ATSC) is a subtask of Aspect-Based\nSentiment Analysis (ABSA), which has many applications e.g. in e-commerce,\nwhere data and insights from reviews can be leveraged to create value for\nbusinesses and customers. Recently, deep transfer-learning methods have been\napplied successfully to a myriad of Natural Language Processing (NLP) tasks,\nincluding ATSC. Building on top of the prominent BERT language model, we\napproach ATSC using a two-step procedure: self-supervised domain-specific BERT\nlanguage model finetuning, followed by supervised task-specific finetuning. Our\nfindings on how to best exploit domain-specific language model finetuning\nenable us to produce new state-of-the-art performance on the SemEval 2014 Task\n4 restaurants dataset. In addition, to explore the real-world robustness of our\nmodels, we perform cross-domain evaluation. We show that a cross-domain adapted\nBERT language model performs significantly better than strong baseline models\nlike vanilla BERT-base and XLNet-base. Finally, we conduct a case study to\ninterpret model prediction errors.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 17:44:30 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 10:17:52 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Rietzler", "Alexander", ""], ["Stabinger", "Sebastian", ""], ["Opitz", "Paul", ""], ["Engl", "Stefan", ""]]}]