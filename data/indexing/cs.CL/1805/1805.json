[{"id": "1805.00063", "submitter": "Igor Melnyk", "authors": "Pierre L. Dognin, Igor Melnyk, Youssef Mroueh, Jarret Ross, and Tom\n  Sercu (IBM Research, USA)", "title": "Adversarial Semantic Alignment for Improved Image Captions", "comments": "Authors Equal Contribution, CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study image captioning as a conditional GAN training,\nproposing both a context-aware LSTM captioner and co-attentive discriminator,\nwhich enforces semantic alignment between images and captions. We empirically\nfocus on the viability of two training methods: Self-critical Sequence Training\n(SCST) and Gumbel Straight-Through (ST) and demonstrate that SCST shows more\nstable gradient behavior and improved results over Gumbel ST, even without\naccessing discriminator gradients directly. We also address the problem of\nautomatic evaluation for captioning models and introduce a new semantic score,\nand show its correlation to human judgement. As an evaluation paradigm, we\nargue that an important criterion for a captioner is the ability to generalize\nto compositions of objects that do not usually co-occur together. To this end,\nwe introduce a small captioned Out of Context (OOC) test set. The OOC set,\ncombined with our semantic score, are the proposed new diagnosis tools for the\ncaptioning community. When evaluated on OOC and MS-COCO benchmarks, we show\nthat SCST-based training has a strong performance in both semantic score and\nhuman evaluation, promising to be a valuable new approach for efficient\ndiscrete GAN training.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 19:10:43 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 17:43:25 GMT"}, {"version": "v3", "created": "Thu, 6 Jun 2019 18:41:03 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Dognin", "Pierre L.", "", "IBM Research, USA"], ["Melnyk", "Igor", "", "IBM Research, USA"], ["Mroueh", "Youssef", "", "IBM Research, USA"], ["Ross", "Jarret", "", "IBM Research, USA"], ["Sercu", "Tom", "", "IBM Research, USA"]]}, {"id": "1805.00097", "submitter": "Roma Patel", "authors": "Roma Patel, Yinfei Yang, Iain Marshall, Ani Nenkova and Byron Wallace", "title": "Syntactic Patterns Improve Information Extraction for Medical Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical professionals search the published literature by specifying the type\nof patients, the medical intervention(s) and the outcome measure(s) of\ninterest. In this paper we demonstrate how features encoding syntactic patterns\nimprove the performance of state-of-the-art sequence tagging models (both\nlinear and neural) for information extraction of these medically relevant\ncategories. We present an analysis of the type of patterns exploited, and the\nsemantic space induced for these, i.e., the distributed representations learned\nfor identified multi-token patterns. We show that these learned representations\ndiffer substantially from those of the constituent unigrams, suggesting that\nthe patterns capture contextual information that is otherwise lost.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 21:00:03 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Patel", "Roma", ""], ["Yang", "Yinfei", ""], ["Marshall", "Iain", ""], ["Nenkova", "Ani", ""], ["Wallace", "Byron", ""]]}, {"id": "1805.00150", "submitter": "Zheng Zhang", "authors": "Zheng Zhang, Minlie Huang, Zhongzhou Zhao, Feng Ji, Haiqing Chen,\n  Xiaoyan Zhu", "title": "Memory-augmented Dialogue Management for Task-oriented Dialogue Systems", "comments": "25 pages, 9 figures, Under review of ACM Transactions on Information\n  Systems (TOIS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue management (DM) decides the next action of a dialogue system\naccording to the current dialogue state, and thus plays a central role in\ntask-oriented dialogue systems. Since dialogue management requires to have\naccess to not only local utterances, but also the global semantics of the\nentire dialogue session, modeling the long-range history information is a\ncritical issue. To this end, we propose a novel Memory-Augmented Dialogue\nmanagement model (MAD) which employs a memory controller and two additional\nmemory structures, i.e., a slot-value memory and an external memory. The\nslot-value memory tracks the dialogue state by memorizing and updating the\nvalues of semantic slots (for instance, cuisine, price, and location), and the\nexternal memory augments the representation of hidden states of traditional\nrecurrent neural networks through storing more context information. To update\nthe dialogue state efficiently, we also propose slot-level attention on user\nutterances to extract specific semantic information for each slot. Experiments\nshow that our model can obtain state-of-the-art performance and outperforms\nexisting baselines.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 02:14:00 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Zhang", "Zheng", ""], ["Huang", "Minlie", ""], ["Zhao", "Zhongzhou", ""], ["Ji", "Feng", ""], ["Chen", "Haiqing", ""], ["Zhu", "Xiaoyan", ""]]}, {"id": "1805.00178", "submitter": "Rui Wang", "authors": "Rui Wang, Masao Utiyama, and Eiichiro Sumita", "title": "Dynamic Sentence Sampling for Efficient Training of Neural Machine\n  Translation", "comments": "Revised version of ACL-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional Neural machine translation (NMT) involves a fixed training\nprocedure where each sentence is sampled once during each epoch. In reality,\nsome sentences are well-learned during the initial few epochs; however, using\nthis approach, the well-learned sentences would continue to be trained along\nwith those sentences that were not well learned for 10-30 epochs, which results\nin a wastage of time. Here, we propose an efficient method to dynamically\nsample the sentences in order to accelerate the NMT training. In this approach,\na weight is assigned to each sentence based on the measured difference between\nthe training costs of two iterations. Further, in each epoch, a certain\npercentage of sentences are dynamically sampled according to their weights.\nEmpirical results based on the NIST Chinese-to-English and the WMT\nEnglish-to-German tasks depict that the proposed method can significantly\naccelerate the NMT training and improve the NMT performance.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 04:09:09 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 00:12:50 GMT"}, {"version": "v3", "created": "Thu, 3 Oct 2019 02:45:00 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Wang", "Rui", ""], ["Utiyama", "Masao", ""], ["Sumita", "Eiichiro", ""]]}, {"id": "1805.00188", "submitter": "Liu Yang", "authors": "Liu Yang, Minghui Qiu, Chen Qu, Jiafeng Guo, Yongfeng Zhang, W. Bruce\n  Croft, Jun Huang, Haiqing Chen", "title": "Response Ranking with Deep Matching Networks and External Knowledge in\n  Information-seeking Conversation Systems", "comments": "Accepted by the 41th International ACM SIGIR Conference on Research\n  and Development in Information Retrieval (SIGIR 2018), Ann Arbor, Michigan,\n  U.S.A. July 8-12, 2018 (Full Oral Paper)", "journal-ref": null, "doi": "10.1145/3209978.3210011", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent personal assistant systems with either text-based or voice-based\nconversational interfaces are becoming increasingly popular around the world.\nRetrieval-based conversation models have the advantages of returning fluent and\ninformative responses. Most existing studies in this area are on open domain\n\"chit-chat\" conversations or task / transaction oriented conversations. More\nresearch is needed for information-seeking conversations. There is also a lack\nof modeling external knowledge beyond the dialog utterances among current\nconversational models. In this paper, we propose a learning framework on the\ntop of deep neural matching networks that leverages external knowledge for\nresponse ranking in information-seeking conversation systems. We incorporate\nexternal knowledge into deep neural models with pseudo-relevance feedback and\nQA correspondence knowledge distillation. Extensive experiments with three\ninformation-seeking conversation data sets including both open benchmarks and\ncommercial data show that, our methods outperform various baseline methods\nincluding several deep text matching models and the state-of-the-art method on\nresponse selection in multi-turn conversations. We also perform analysis over\ndifferent response types, model variations and ranking examples. Our models and\nresearch findings provide new insights on how to utilize external knowledge\nwith deep neural models for response selection and have implications for the\ndesign of the next generation of information-seeking conversation systems.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 05:05:05 GMT"}, {"version": "v2", "created": "Wed, 2 May 2018 00:28:53 GMT"}, {"version": "v3", "created": "Wed, 9 May 2018 05:09:40 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Yang", "Liu", ""], ["Qiu", "Minghui", ""], ["Qu", "Chen", ""], ["Guo", "Jiafeng", ""], ["Zhang", "Yongfeng", ""], ["Croft", "W. Bruce", ""], ["Huang", "Jun", ""], ["Chen", "Haiqing", ""]]}, {"id": "1805.00195", "submitter": "Chaitanya Kulkarni", "authors": "Chaitanya Kulkarni, Wei Xu, Alan Ritter, Raghu Machiraju", "title": "An Annotated Corpus for Machine Reading of Instructions in Wet Lab\n  Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an effort to annotate a corpus of natural language instructions\nconsisting of 622 wet lab protocols to facilitate automatic or semi-automatic\nconversion of protocols into a machine-readable format and benefit biological\nresearch. Experimental results demonstrate the utility of our corpus for\ndeveloping machine learning approaches to shallow semantic parsing of\ninstructional texts. We make our annotated Wet Lab Protocol Corpus available to\nthe research community.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 05:52:12 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Kulkarni", "Chaitanya", ""], ["Xu", "Wei", ""], ["Ritter", "Alan", ""], ["Machiraju", "Raghu", ""]]}, {"id": "1805.00249", "submitter": "Hongyu Lin", "authors": "Hongyu Lin, Yaojie Lu, Xianpei Han, Le Sun", "title": "Nugget Proposal Networks for Chinese Event Detection", "comments": "Accepted to ACL2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network based models commonly regard event detection as a word-wise\nclassification task, which suffer from the mismatch problem between words and\nevent triggers, especially in languages without natural word delimiters such as\nChinese. In this paper, we propose Nugget Proposal Networks (NPNs), which can\nsolve the word-trigger mismatch problem by directly proposing entire trigger\nnuggets centered at each character regardless of word boundaries. Specifically,\nNPNs perform event detection in a character-wise paradigm, where a hybrid\nrepresentation for each character is first learned to capture both structural\nand semantic information from both characters and words. Then based on learned\nrepresentations, trigger nuggets are proposed and categorized by exploiting\ncharacter compositional structures of Chinese event triggers. Experiments on\nboth ACE2005 and TAC KBP 2017 datasets show that NPNs significantly outperform\nthe state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 09:16:53 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Lin", "Hongyu", ""], ["Lu", "Yaojie", ""], ["Han", "Xianpei", ""], ["Sun", "Le", ""]]}, {"id": "1805.00250", "submitter": "Hongyu Lin", "authors": "Hongyu Lin, Yaojie Lu, Xianpei Han, Le Sun", "title": "Adaptive Scaling for Sparse Detection in Information Extraction", "comments": "Accepted to ACL2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on detection tasks in information extraction, where\npositive instances are sparsely distributed and models are usually evaluated\nusing F-measure on positive classes. These characteristics often result in\ndeficient performance of neural network based detection models. In this paper,\nwe propose adaptive scaling, an algorithm which can handle the positive\nsparsity problem and directly optimize over F-measure via dynamic\ncost-sensitive learning. To this end, we borrow the idea of marginal utility\nfrom economics and propose a theoretical framework for instance importance\nmeasuring without introducing any additional hyper-parameters. Experiments show\nthat our algorithm leads to a more effective and stable training of neural\nnetwork based detection models.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 09:21:34 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 06:39:34 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Lin", "Hongyu", ""], ["Lu", "Yaojie", ""], ["Han", "Xianpei", ""], ["Sun", "Le", ""]]}, {"id": "1805.00254", "submitter": "Pankaj Gupta", "authors": "Pankaj Gupta and Benjamin Roth and Hinrich Sch\\\"utze", "title": "Joint Bootstrapping Machines for High Confidence Relation Extraction", "comments": "In Proceedings of the 16th Annual Conference of the North American\n  Chapter of the Association for Computational Linguistics: Human Language\n  Technologies (NAACL-HLT 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised bootstrapping techniques for relationship extraction from\ntext iteratively expand a set of initial seed instances. Due to the lack of\nlabeled data, a key challenge in bootstrapping is semantic drift: if a false\npositive instance is added during an iteration, then all following iterations\nare contaminated. We introduce BREX, a new bootstrapping method that protects\nagainst such contamination by highly effective confidence assessment. This is\nachieved by using entity and template seeds jointly (as opposed to just one as\nin previous work), by expanding entities and templates in parallel and in a\nmutually constraining fashion in each iteration and by introducing\nhigherquality similarity measures for templates. Experimental results show that\nBREX achieves an F1 that is 0.13 (0.87 vs. 0.74) better than the state of the\nart for four relationships.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 09:39:19 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Gupta", "Pankaj", ""], ["Roth", "Benjamin", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1805.00270", "submitter": "Anca Dumitrache", "authors": "Anca Dumitrache, Lora Aroyo, Chris Welty", "title": "Capturing Ambiguity in Crowdsourcing Frame Disambiguation", "comments": "in publication at the sixth AAAI Conference on Human Computation and\n  Crowdsourcing (HCOMP) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  FrameNet is a computational linguistics resource composed of semantic frames,\nhigh-level concepts that represent the meanings of words. In this paper, we\npresent an approach to gather frame disambiguation annotations in sentences\nusing a crowdsourcing approach with multiple workers per sentence to capture\ninter-annotator disagreement. We perform an experiment over a set of 433\nsentences annotated with frames from the FrameNet corpus, and show that the\naggregated crowd annotations achieve an F1 score greater than 0.67 as compared\nto expert linguists. We highlight cases where the crowd annotation was correct\neven though the expert is in disagreement, arguing for the need to have\nmultiple annotators per sentence. Most importantly, we examine cases in which\ncrowd workers could not agree, and demonstrate that these cases exhibit\nambiguity, either in the sentence, frame, or the task itself, and argue that\ncollapsing such cases to a single, discrete truth value (i.e. correct or\nincorrect) is inappropriate, creating arbitrary targets for machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 11:08:00 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Dumitrache", "Anca", ""], ["Aroyo", "Lora", ""], ["Welty", "Chris", ""]]}, {"id": "1805.00287", "submitter": "Daniel Hershcovich", "authors": "Daniel Hershcovich, Omri Abend and Ari Rappoport", "title": "Multitask Parsing Across Semantic Representations", "comments": "Accepted to ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The ability to consolidate information of different types is at the core of\nintelligence, and has tremendous practical value in allowing learning for one\ntask to benefit from generalizations learned for others. In this paper we\ntackle the challenging task of improving semantic parsing performance, taking\nUCCA parsing as a test case, and AMR, SDP and Universal Dependencies (UD)\nparsing as auxiliary tasks. We experiment on three languages, using a uniform\ntransition-based system and learning architecture for all parsing tasks.\nDespite notable conceptual, formal and domain differences, we show that\nmultitask learning significantly improves UCCA parsing in both in-domain and\nout-of-domain settings.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 12:21:50 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Hershcovich", "Daniel", ""], ["Abend", "Omri", ""], ["Rappoport", "Ari", ""]]}, {"id": "1805.00314", "submitter": "Josiah Wang", "authors": "Josiah Wang, Pranava Madhyastha, Lucia Specia", "title": "Object Counts! Bringing Explicit Detections Back into Image Captioning", "comments": "Please cite: In Proceedings of 2018 Conference of the North American\n  Chapter of the Association for Computational Linguistics (NAACL 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of explicit object detectors as an intermediate step to image\ncaptioning - which used to constitute an essential stage in early work - is\noften bypassed in the currently dominant end-to-end approaches, where the\nlanguage model is conditioned directly on a mid-level image embedding. We argue\nthat explicit detections provide rich semantic information, and can thus be\nused as an interpretable representation to better understand why end-to-end\nimage captioning systems work well. We provide an in-depth analysis of\nend-to-end image captioning by exploring a variety of cues that can be derived\nfrom such object detections. Our study reveals that end-to-end image captioning\nsystems rely on matching image representations to generate captions, and that\nencoding the frequency, size and position of objects are complementary and all\nplay a role in forming a good image representation. It also reveals that\ndifferent object categories contribute in different ways towards image\ncaptioning.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 14:51:46 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Wang", "Josiah", ""], ["Madhyastha", "Pranava", ""], ["Specia", "Lucia", ""]]}, {"id": "1805.00352", "submitter": "Marina Sokolova", "authors": "Qufei Chen, Marina Sokolova", "title": "Word2Vec and Doc2Vec in Unsupervised Sentiment Analysis of Clinical\n  Discharge Summaries", "comments": "23 pages, 3 figures, 16 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we explored application of Word2Vec and Doc2Vec for sentiment\nanalysis of clinical discharge summaries. We applied unsupervised learning\nsince the data sets did not have sentiment annotations. Note that unsupervised\nlearning is a more realistic scenario than supervised learning which requires\nan access to a training set of sentiment-annotated data. We aim to detect if\nthere exists any underlying bias towards or against a certain disease. We used\nSentiWordNet to establish a gold sentiment standard for the data sets and\nevaluate performance of Word2Vec and Doc2Vec methods. We have shown that the\nWord2vec and Doc2Vec methods complement each other results in sentiment\nanalysis of the data sets.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 14:07:44 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Chen", "Qufei", ""], ["Sokolova", "Marina", ""]]}, {"id": "1805.00444", "submitter": "Steven Coats", "authors": "Steven Coats", "title": "Skin Tone Emoji and Sentiment on Twitter", "comments": "16 pages, 8 figures", "journal-ref": "Proc. 3rd DHN Conference, 122-138.\n  http://ceur-ws.org/Vol-2084/paper10.pdf", "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In 2015, the Unicode Consortium introduced five skin tone emoji that can be\nused in combination with emoji representing human figures and body parts. In\nthis study, use of the skin tone emoji is analyzed geographically in a large\nsample of data from Twitter. It can be shown that values for the skin tone\nemoji by country correspond approximately to the skin tone of the resident\npopulations, and that a negative correlation exists between tweet sentiment and\ndarker skin tone at the global level. In an era of large-scale migrations and\ncontinued sensitivity to questions of skin color and race, understanding how\nnew language elements such as skin tone emoji are used can help frame our\nunderstanding of how people represent themselves and others in terms of a\nsalient personal appearance attribute.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 12:25:59 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Coats", "Steven", ""]]}, {"id": "1805.00456", "submitter": "Danielle Saunders", "authors": "Danielle Saunders, Felix Stahlberg, Adria de Gispert and Bill Byrne", "title": "Multi-representation Ensembles and Delayed SGD Updates Improve\n  Syntax-based NMT", "comments": "to appear at ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore strategies for incorporating target syntax into Neural Machine\nTranslation. We specifically focus on syntax in ensembles containing multiple\nsentence representations. We formulate beam search over such ensembles using\nWFSTs, and describe a delayed SGD update training procedure that is especially\neffective for long representations like linearized syntax. Our approach gives\nstate-of-the-art performance on a difficult Japanese-English task.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 17:48:10 GMT"}, {"version": "v2", "created": "Wed, 2 May 2018 08:12:05 GMT"}, {"version": "v3", "created": "Fri, 11 May 2018 09:20:43 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Saunders", "Danielle", ""], ["Stahlberg", "Felix", ""], ["de Gispert", "Adria", ""], ["Byrne", "Bill", ""]]}, {"id": "1805.00460", "submitter": "Andrew Shin", "authors": "Andrew Shin, Yoshitaka Ushiku, Tatsuya Harada", "title": "Customized Image Narrative Generation via Interactive Visual Question\n  Generation and Answering", "comments": "To Appear at CVPR 2018 as spotlight presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image description task has been invariably examined in a static manner with\nqualitative presumptions held to be universally applicable, regardless of the\nscope or target of the description. In practice, however, different viewers may\npay attention to different aspects of the image, and yield different\ndescriptions or interpretations under various contexts. Such diversity in\nperspectives is difficult to derive with conventional image description\ntechniques. In this paper, we propose a customized image narrative generation\ntask, in which the users are interactively engaged in the generation process by\nproviding answers to the questions. We further attempt to learn the user's\ninterest via repeating such interactive stages, and to automatically reflect\nthe interest in descriptions for new images. Experimental results demonstrate\nthat our model can generate a variety of descriptions from single image that\ncover a wider range of topics than conventional models, while being\ncustomizable to the target user of interaction.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 11:27:45 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Shin", "Andrew", ""], ["Ushiku", "Yoshitaka", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1805.00462", "submitter": "Haichao Zhang", "authors": "Haichao Zhang, Haonan Yu and Wei Xu", "title": "Interactive Language Acquisition with One-shot Visual Concept Learning\n  through a Conversational Game", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building intelligent agents that can communicate with and learn from humans\nin natural language is of great value. Supervised language learning is limited\nby the ability of capturing mainly the statistics of training data, and is\nhardly adaptive to new scenarios or flexible for acquiring new knowledge\nwithout inefficient retraining or catastrophic forgetting. We highlight the\nperspective that conversational interaction serves as a natural interface both\nfor language learning and for novel knowledge acquisition and propose a joint\nimitation and reinforcement approach for grounded language learning through an\ninteractive conversational game. The agent trained with this approach is able\nto actively acquire information by asking questions about novel objects and use\nthe just-learned knowledge in subsequent conversations in a one-shot fashion.\nResults compared with other methods verified the effectiveness of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 07:14:59 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Zhang", "Haichao", ""], ["Yu", "Haonan", ""], ["Xu", "Wei", ""]]}, {"id": "1805.00471", "submitter": "Soumya Kambhampati", "authors": "Soumya Kambhampati", "title": "\"I ain't tellin' white folks nuthin\": A quantitative exploration of the\n  race-related problem of candour in the WPA slave narratives", "comments": "A thesis presented in partial fulfilment of the requirements of the\n  degree of Bachelor of Arts in Statistics & Data Science at Yale University", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From 1936-38, the Works Progress Administration interviewed thousands of\nformer slaves about their life experiences. While these interviews are crucial\nto understanding the \"peculiar institution\" from the standpoint of the slave\nhimself, issues relating to bias cloud analyses of these interviews. The\nproblem I investigate is the problem of candour in the WPA slave narratives: it\nis widely held in the historical community that the strict racial caste system\nof the Deep South compelled black ex-slaves to tell white interviewers what\nthey thought they wanted to hear, suggesting that there was a significant\ndifference candour depending on whether their interviewer was white or black.\nIn this work, I attempt to quantitatively characterise this race-related\nproblem of candour. Prior work has either been of an impressionistic,\nqualitative nature, or utilised exceedingly simple quantitative methodology. In\ncontrast, I use more sophisticated statistical methods: in particular word\nfrequency and sentiment analysis and comparative topic modelling with LDA to\ntry and identify differences in the content and sentiment expressed by\nex-slaves in front of white interviewers versus black interviewers. While my\nsentiment analysis methodology was ultimately unsuccessful due to the\ncomplexity of the task, my word frequency analysis and comparative topic\nmodelling methods both showed strong evidence that the content expressed in\nfront of white interviewers was different from that of black interviewers. In\nparticular, I found that the ex-slaves spoke much more about unfavourable\naspects of slavery like whipping and slave patrollers in front of interviewers\nof their own race. I hope that my more-sophisticated statistical methodology\nhelps improve the robustness of the argument for the existence of this problem\nof candour in the slave narratives, which some would seek to deny for\nrevisionist purposes.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 05:24:40 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Kambhampati", "Soumya", ""]]}, {"id": "1805.00551", "submitter": "Shereen Oraby", "authors": "Marilyn A. Walker, Albry Smither, Shereen Oraby, Vrindavan Harrison,\n  Hadar Shemtov", "title": "Exploring Conversational Language Generation for Rich Content about\n  Hotels", "comments": "This version contains updates to the version published at LREC '18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue systems for hotel and tourist information have typically simplified\nthe richness of the domain, focusing system utterances on only a few selected\nattributes such as price, location and type of rooms. However, much more\ncontent is typically available for hotels, often as many as 50 distinct\ninstantiated attributes for an individual entity. New methods are needed to use\nthis content to generate natural dialogues for hotel information, and in\ngeneral for any domain with such rich complex content. We describe three\nexperiments aimed at collecting data that can inform an NLG for hotels\ndialogues, and show, not surprisingly, that the sentences in the original\nwritten hotel descriptions provided on webpages for each hotel are\nstylistically not a very good match for conversational interaction. We quantify\nthe stylistic features that characterize the differences between the original\ntextual data and the collected dialogic data. We plan to use these in stylistic\nmodels for generation, and for scoring retrieved utterances for use in hotel\ndialogues\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 21:05:34 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Walker", "Marilyn A.", ""], ["Smither", "Albry", ""], ["Oraby", "Shereen", ""], ["Harrison", "Vrindavan", ""], ["Shemtov", "Hadar", ""]]}, {"id": "1805.00579", "submitter": "Han Zhao", "authors": "Han Zhao, Shuayb Zarar, Ivan Tashev, Chin-Hui Lee", "title": "Convolutional-Recurrent Neural Networks for Speech Enhancement", "comments": "ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an end-to-end model based on convolutional and recurrent neural\nnetworks for speech enhancement. Our model is purely data-driven and does not\nmake any assumptions about the type or the stationarity of the noise. In\ncontrast to existing methods that use multilayer perceptrons (MLPs), we employ\nboth convolutional and recurrent neural network architectures. Thus, our\napproach allows us to exploit local structures in both the frequency and\ntemporal domains. By incorporating prior knowledge of speech signals into the\ndesign of model structures, we build a model that is more data-efficient and\nachieves better generalization on both seen and unseen noise. Based on\nexperiments with synthetic data, we demonstrate that our model outperforms\nexisting methods, improving PESQ by up to 0.6 on seen noise and 0.64 on unseen\nnoise.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 00:06:53 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Zhao", "Han", ""], ["Zarar", "Shuayb", ""], ["Tashev", "Ivan", ""], ["Lee", "Chin-Hui", ""]]}, {"id": "1805.00604", "submitter": "Aryan Mobiny", "authors": "Aryan Mobiny, Mohammad Najarian", "title": "Text-Independent Speaker Verification Using Long Short-Term Memory\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an architecture based on Long Short-Term Memory Networks has\nbeen proposed for the text-independent scenario which is aimed to capture the\ntemporal speaker-related information by operating over traditional speech\nfeatures. For speaker verification, at first, a background model must be\ncreated for speaker representation. Then, in enrollment stage, the speaker\nmodels will be created based on the enrollment utterances. For this work, the\nmodel will be trained in an end-to-end fashion to combine the first two stages.\nThe main goal of end-to-end training is the model being optimized to be\nconsistent with the speaker verification protocol. The end- to-end training\njointly learns the background and speaker models by creating the representation\nspace. The LSTM architecture is trained to create a discrimination space for\nvalidating the match and non-match pairs for speaker verification. The proposed\narchitecture demonstrate its superiority in the text-independent compared to\nother traditional methods.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 02:30:20 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 18:26:32 GMT"}, {"version": "v3", "created": "Fri, 7 Sep 2018 14:41:25 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Mobiny", "Aryan", ""], ["Najarian", "Mohammad", ""]]}, {"id": "1805.00625", "submitter": "Didan Deng", "authors": "Didan Deng, Yuqian Zhou, Jimin Pi, Bertram E.Shi", "title": "Multimodal Utterance-level Affect Analysis using Visual, Audio and Text\n  Features", "comments": "5 pages, 1 figure, subject to the 2018 IJCNN challenge on One-Minute\n  Gradual-Emotion Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The integration of information across multiple modalities and across time is\na promising way to enhance the emotion recognition performance of affective\nsystems. Much previous work has focused on instantaneous emotion recognition.\nThe 2018 One-Minute Gradual-Emotion Recognition (OMG-Emotion) challenge, which\nwas held in conjunction with the IEEE World Congress on Computational\nIntelligence, encouraged participants to address long-term emotion recognition\nby integrating cues from multiple modalities, including facial expression,\naudio and language. Intuitively, a multi-modal inference network should be able\nto leverage information from each modality and their correlations to improve\nrecognition over that achievable by a single modality network. We describe here\na multi-modal neural architecture that integrates visual information over time\nusing an LSTM, and combines it with utterance level audio and text cues to\nrecognize human sentiment from multimodal clips. Our model outperforms the\nunimodal baseline, achieving the concordance correlation coefficients (CCC) of\n0.400 on the arousal task, and 0.353 on the valence task.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 05:05:32 GMT"}, {"version": "v2", "created": "Fri, 4 May 2018 11:24:41 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Deng", "Didan", ""], ["Zhou", "Yuqian", ""], ["Pi", "Jimin", ""], ["Shi", "Bertram E.", ""]]}, {"id": "1805.00631", "submitter": "Biao Zhang", "authors": "Biao Zhang, Deyi Xiong, Jinsong Su", "title": "Accelerating Neural Transformer via an Average Attention Network", "comments": "ACL 2018, long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With parallelizable attention networks, the neural Transformer is very fast\nto train. However, due to the auto-regressive architecture and self-attention\nin the decoder, the decoding procedure becomes slow. To alleviate this issue,\nwe propose an average attention network as an alternative to the self-attention\nnetwork in the decoder of the neural Transformer. The average attention network\nconsists of two layers, with an average layer that models dependencies on\nprevious positions and a gating layer that is stacked over the average layer to\nenhance the expressiveness of the proposed attention network. We apply this\nnetwork on the decoder part of the neural Transformer to replace the original\ntarget-side self-attention model. With masking tricks and dynamic programming,\nour model enables the neural Transformer to decode sentences over four times\nfaster than its original version with almost no loss in training time and\ntranslation performance. We conduct a series of experiments on WMT17\ntranslation tasks, where on 6 different language pairs, we obtain robust and\nconsistent speed-ups in decoding.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 05:25:43 GMT"}, {"version": "v2", "created": "Thu, 3 May 2018 05:44:38 GMT"}, {"version": "v3", "created": "Mon, 7 May 2018 03:45:42 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Zhang", "Biao", ""], ["Xiong", "Deyi", ""], ["Su", "Jinsong", ""]]}, {"id": "1805.00676", "submitter": "Cristian Bodnar", "authors": "Cristian Bodnar", "title": "Text to Image Synthesis Using Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.35817.39523", "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating images from natural language is one of the primary applications of\nrecent conditional generative models. Besides testing our ability to model\nconditional, highly dimensional distributions, text to image synthesis has many\nexciting and practical applications such as photo editing or computer-aided\ncontent creation. Recent progress has been made using Generative Adversarial\nNetworks (GANs). This material starts with a gentle introduction to these\ntopics and discusses the existent state of the art models. Moreover, I propose\nWasserstein GAN-CLS, a new model for conditional image generation based on the\nWasserstein distance which offers guarantees of stability. Then, I show how the\nnovel loss function of Wasserstein GAN-CLS can be used in a Conditional\nProgressive Growing GAN. In combination with the proposed loss, the model\nboosts by 7.07% the best Inception Score (on the Caltech birds dataset) of the\nmodels which use only the sentence-level visual semantics. The only model which\nperforms better than the Conditional Wasserstein Progressive Growing GAN is the\nrecently proposed AttnGAN which uses word-level visual semantics as well.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 08:47:38 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Bodnar", "Cristian", ""]]}, {"id": "1805.00731", "submitter": "Francesco Barbieri", "authors": "Francesco Barbieri, Luis Marujo, Pradeep Karuturi, William Brendel,\n  Horacio Saggion", "title": "Exploring Emoji Usage and Prediction Through a Temporal Variation Lens", "comments": "Emojis @ ICWSM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The frequent use of Emojis on social media platforms has created a new form\nof multimodal social interaction. Developing methods for the study and\nrepresentation of emoji semantics helps to improve future multimodal\ncommunication systems. In this paper, we explore the usage and semantics of\nemojis over time. We compare emoji embeddings trained on a corpus of different\nseasons and show that some emojis are used differently depending on the time of\nthe year. Moreover, we propose a method to take into account the time\ninformation for emoji prediction systems, outperforming state-of-the-art\nsystems. We show that, using the time information, the accuracy of some emojis\ncan be significantly improved.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 11:03:52 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Barbieri", "Francesco", ""], ["Marujo", "Luis", ""], ["Karuturi", "Pradeep", ""], ["Brendel", "William", ""], ["Saggion", "Horacio", ""]]}, {"id": "1805.00741", "submitter": "Hengyi Cai", "authors": "Hengyi Cai, Xingguang Ji, Yonghao Song, Yan Jin, Yang Zhang, Mairgup\n  Mansur, Xiaofang Zhao", "title": "KNPTC: Knowledge and Neural Machine Translation Powered Chinese Pinyin\n  Typo Correction", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chinese pinyin input methods are very important for Chinese language\nprocessing. Actually, users may make typos inevitably when they input pinyin.\nMoreover, pinyin typo correction has become an increasingly important task with\nthe popularity of smartphones and the mobile Internet. How to exploit the\nknowledge of users typing behaviors and support the typo correction for acronym\npinyin remains a challenging problem. To tackle these challenges, we propose\nKNPTC, a novel approach based on neural machine translation (NMT). In contrast\nto previous work, KNPTC is able to integrate explicit knowledge into NMT for\npinyin typo correction, and is able to learn to correct a variety of typos\nwithout the guidance of manually selected constraints or languagespecific\nfeatures. In this approach, we first obtain the transition probabilities\nbetween adjacent letters based on large-scale real-life datasets. Then, we\nconstruct the \"ground-truth\" alignments of training sentence pairs by utilizing\nthese probabilities. Furthermore, these alignments are integrated into NMT to\ncapture sensible pinyin typo correction patterns. KNPTC is applied to correct\ntypos in real-life datasets, which achieves 32.77% increment on average in\naccuracy rate of typo correction compared against the state-of-the-art system.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 11:33:45 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Cai", "Hengyi", ""], ["Ji", "Xingguang", ""], ["Song", "Yonghao", ""], ["Jin", "Yan", ""], ["Zhang", "Yang", ""], ["Mansur", "Mairgup", ""], ["Zhao", "Xiaofang", ""]]}, {"id": "1805.00760", "submitter": "Xin Li", "authors": "Xin Li, Lidong Bing, Piji Li, Wai Lam, Zhimou Yang", "title": "Aspect Term Extraction with History Attention and Selective\n  Transformation", "comments": "IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect Term Extraction (ATE), a key sub-task in Aspect-Based Sentiment\nAnalysis, aims to extract explicit aspect expressions from online user reviews.\nWe present a new framework for tackling ATE. It can exploit two useful clues,\nnamely opinion summary and aspect detection history. Opinion summary is\ndistilled from the whole input sentence, conditioned on each current token for\naspect prediction, and thus the tailor-made summary can help aspect prediction\non this token. Another clue is the information of aspect detection history, and\nit is distilled from the previous aspect predictions so as to leverage the\ncoordinate structure and tagging schema constraints to upgrade the aspect\nprediction. Experimental results over four benchmark datasets clearly\ndemonstrate that our framework can outperform all state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 12:14:11 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Li", "Xin", ""], ["Bing", "Lidong", ""], ["Li", "Piji", ""], ["Lam", "Wai", ""], ["Yang", "Zhimou", ""]]}, {"id": "1805.00879", "submitter": "Robert Litschko", "authors": "Robert Litschko, Goran Glava\\v{s}, Simone Paolo Ponzetto, Ivan Vuli\\'c", "title": "Unsupervised Cross-Lingual Information Retrieval using Monolingual Data\n  Only", "comments": "accepted at SIGIR'18 (preprint)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We propose a fully unsupervised framework for ad-hoc cross-lingual\ninformation retrieval (CLIR) which requires no bilingual data at all. The\nframework leverages shared cross-lingual word embedding spaces in which terms,\nqueries, and documents can be represented, irrespective of their actual\nlanguage. The shared embedding spaces are induced solely on the basis of\nmonolingual corpora in two languages through an iterative process based on\nadversarial neural networks. Our experiments on the standard CLEF CLIR\ncollections for three language pairs of varying degrees of language similarity\n(English-Dutch/Italian/Finnish) demonstrate the usefulness of the proposed\nfully unsupervised approach. Our CLIR models with unsupervised cross-lingual\nembeddings outperform baselines that utilize cross-lingual embeddings induced\nrelying on word-level and document-level alignments. We then demonstrate that\nfurther improvements can be achieved by unsupervised ensemble CLIR models. We\nbelieve that the proposed framework is the first step towards development of\neffective CLIR models for language pairs and domains where parallel data are\nscarce or non-existent.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 15:52:48 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Litschko", "Robert", ""], ["Glava\u0161", "Goran", ""], ["Ponzetto", "Simone Paolo", ""], ["Vuli\u0107", "Ivan", ""]]}, {"id": "1805.00900", "submitter": "Micael Carvalho", "authors": "Micael Carvalho, R\\'emi Cad\\`ene, David Picard, Laure Soulier,\n  Matthieu Cord", "title": "Images & Recipes: Retrieval in the cooking context", "comments": "Published at DECOR / ICDE 2018. Extended version accepted at SIGIR\n  2018, available here: arXiv:1804.11146", "journal-ref": null, "doi": "10.1109/ICDEW.2018.00035", "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in the machine learning community allowed different use cases\nto emerge, as its association to domains like cooking which created the\ncomputational cuisine. In this paper, we tackle the picture-recipe alignment\nproblem, having as target application the large-scale retrieval task (finding a\nrecipe given a picture, and vice versa). Our approach is validated on the\nRecipe1M dataset, composed of one million image-recipe pairs and additional\nclass information, for which we achieve state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 16:34:01 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Carvalho", "Micael", ""], ["Cad\u00e8ne", "R\u00e9mi", ""], ["Picard", "David", ""], ["Soulier", "Laure", ""], ["Cord", "Matthieu", ""]]}, {"id": "1805.00912", "submitter": "Tao Shen", "authors": "Tao Shen, Tianyi Zhou, Guodong Long, Jing Jiang, Chengqi Zhang", "title": "Tensorized Self-Attention: Efficiently Modeling Pairwise and Global\n  Dependencies Together", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks equipped with self-attention have parallelizable computation,\nlight-weight structure, and the ability to capture both long-range and local\ndependencies. Further, their expressive power and performance can be boosted by\nusing a vector to measure pairwise dependency, but this requires to expand the\nalignment matrix to a tensor, which results in memory and computation\nbottlenecks. In this paper, we propose a novel attention mechanism called\n\"Multi-mask Tensorized Self-Attention\" (MTSA), which is as fast and as\nmemory-efficient as a CNN, but significantly outperforms previous\nCNN-/RNN-/attention-based models. MTSA 1) captures both pairwise (token2token)\nand global (source2token) dependencies by a novel compatibility function\ncomposed of dot-product and additive attentions, 2) uses a tensor to represent\nthe feature-wise alignment scores for better expressive power but only requires\nparallelizable matrix multiplications, and 3) combines multi-head with\nmulti-dimensional attentions, and applies a distinct positional mask to each\nhead (subspace), so the memory and computation can be distributed to multiple\nheads, each with sequential information encoded independently. The experiments\nshow that a CNN/RNN-free model based on MTSA achieves state-of-the-art or\ncompetitive performance on nine NLP benchmarks with compelling memory- and\ntime-efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 17:16:48 GMT"}, {"version": "v2", "created": "Sun, 6 May 2018 05:49:30 GMT"}, {"version": "v3", "created": "Sun, 9 Sep 2018 06:58:09 GMT"}, {"version": "v4", "created": "Tue, 26 Mar 2019 09:07:00 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Shen", "Tao", ""], ["Zhou", "Tianyi", ""], ["Long", "Guodong", ""], ["Jiang", "Jing", ""], ["Zhang", "Chengqi", ""]]}, {"id": "1805.01035", "submitter": "Roee Aharoni", "authors": "Roee Aharoni and Yoav Goldberg", "title": "Split and Rephrase: Better Evaluation and a Stronger Baseline", "comments": "Accepted as a short paper in ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Splitting and rephrasing a complex sentence into several shorter sentences\nthat convey the same meaning is a challenging problem in NLP. We show that\nwhile vanilla seq2seq models can reach high scores on the proposed benchmark\n(Narayan et al., 2017), they suffer from memorization of the training set which\ncontains more than 89% of the unique simple sentences from the validation and\ntest sets. To aid this, we present a new train-development-test data split and\nneural models augmented with a copy-mechanism, outperforming the best reported\nbaseline by 8.68 BLEU and fostering further progress on the task.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 21:36:38 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Aharoni", "Roee", ""], ["Goldberg", "Yoav", ""]]}, {"id": "1805.01042", "submitter": "Adam Poliak", "authors": "Adam Poliak, Jason Naradowsky, Aparajita Haldar, Rachel Rudinger,\n  Benjamin Van Durme", "title": "Hypothesis Only Baselines in Natural Language Inference", "comments": "Accepted at *SEM 2018 as long paper. 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a hypothesis only baseline for diagnosing Natural Language\nInference (NLI). Especially when an NLI dataset assumes inference is occurring\nbased purely on the relationship between a context and a hypothesis, it follows\nthat assessing entailment relations while ignoring the provided context is a\ndegenerate solution. Yet, through experiments on ten distinct NLI datasets, we\nfind that this approach, which we refer to as a hypothesis-only model, is able\nto significantly outperform a majority class baseline across a number of NLI\ndatasets. Our analysis suggests that statistical irregularities may allow a\nmodel to perform NLI in some datasets beyond what should be achievable without\naccess to the context.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 22:16:21 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Poliak", "Adam", ""], ["Naradowsky", "Jason", ""], ["Haldar", "Aparajita", ""], ["Rudinger", "Rachel", ""], ["Van Durme", "Benjamin", ""]]}, {"id": "1805.01052", "submitter": "Nikita Kitaev", "authors": "Nikita Kitaev and Dan Klein", "title": "Constituency Parsing with a Self-Attentive Encoder", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that replacing an LSTM encoder with a self-attentive\narchitecture can lead to improvements to a state-of-the-art discriminative\nconstituency parser. The use of attention makes explicit the manner in which\ninformation is propagated between different locations in the sentence, which we\nuse to both analyze our model and propose potential improvements. For example,\nwe find that separating positional and content information in the encoder can\nlead to improved parsing accuracy. Additionally, we evaluate different\napproaches for lexical representation. Our parser achieves new state-of-the-art\nresults for single models trained on the Penn Treebank: 93.55 F1 without the\nuse of any external data, and 95.13 F1 when using pre-trained word\nrepresentations. Our parser also outperforms the previous best-published\naccuracy figures on 8 of the 9 languages in the SPMRL dataset.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 23:21:12 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Kitaev", "Nikita", ""], ["Klein", "Dan", ""]]}, {"id": "1805.01054", "submitter": "Scott Werwath", "authors": "Scott Werwath", "title": "Automatic Coding for Neonatal Jaundice From Free Text Data Using\n  Ensemble Methods", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study explores the creation of a machine learning model to automatically\nidentify whether a Neonatal Intensive Care Unit (NICU) patient was diagnosed\nwith neonatal jaundice during a particular hospitalization based on their\nassociated clinical notes. We develop a number of techniques for text\npreprocessing and feature selection and compare the effectiveness of different\nclassification models. We show that using ensemble decision tree\nclassification, both with AdaBoost and with bagging, outperforms support vector\nmachines (SVM), the current state-of-the-art technique for neonatal jaundice\ncoding.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 23:29:19 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Werwath", "Scott", ""]]}, {"id": "1805.01060", "submitter": "Ziqi Zheng", "authors": "Ziqi Zheng, Chenjie Cao, Xingwei Chen, Guoqiang Xu", "title": "Multimodal Emotion Recognition for One-Minute-Gradual Emotion Challenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The continuous dimensional emotion modelled by arousal and valence can depict\ncomplex changes of emotions. In this paper, we present our works on arousal and\nvalence predictions for One-Minute-Gradual (OMG) Emotion Challenge. Multimodal\nrepresentations are first extracted from videos using a variety of acoustic,\nvideo and textual models and support vector machine (SVM) is then used for\nfusion of multimodal signals to make final predictions. Our solution achieves\nConcordant Correlation Coefficient (CCC) scores of 0.397 and 0.520 on arousal\nand valence respectively for the validation dataset, which outperforms the\nbaseline systems with the best CCC scores of 0.15 and 0.23 on arousal and\nvalence by a large margin.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 00:10:10 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Zheng", "Ziqi", ""], ["Cao", "Chenjie", ""], ["Chen", "Xingwei", ""], ["Xu", "Guoqiang", ""]]}, {"id": "1805.01070", "submitter": "Alexis Conneau", "authors": "Alexis Conneau, German Kruszewski, Guillaume Lample, Lo\\\"ic Barrault,\n  Marco Baroni", "title": "What you can cram into a single vector: Probing sentence embeddings for\n  linguistic properties", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although much effort has recently been devoted to training high-quality\nsentence embeddings, we still have a poor understanding of what they are\ncapturing. \"Downstream\" tasks, often based on sentence classification, are\ncommonly used to evaluate the quality of sentence representations. The\ncomplexity of the tasks makes it however difficult to infer what kind of\ninformation is present in the representations. We introduce here 10 probing\ntasks designed to capture simple linguistic features of sentences, and we use\nthem to study embeddings generated by three different encoders trained in eight\ndistinct ways, uncovering intriguing properties of both encoders and training\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 00:46:56 GMT"}, {"version": "v2", "created": "Sun, 8 Jul 2018 21:42:31 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Conneau", "Alexis", ""], ["Kruszewski", "German", ""], ["Lample", "Guillaume", ""], ["Barrault", "Lo\u00efc", ""], ["Baroni", "Marco", ""]]}, {"id": "1805.01083", "submitter": "Xiaolan Wang", "authors": "Xiaolan Wang, Aaron Feng, Behzad Golshan, Alon Halevy, George Mihaila,\n  Hidekazu Oiwa, Wang-Chiew Tan", "title": "Scalable Semantic Querying of Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the KOKO system that takes declarative information extraction to a\nnew level by incorporating advances in natural language processing techniques\nin its extraction language. KOKO is novel in that its extraction language\nsimultaneously supports conditions on the surface of the text and on the\nstructure of the dependency parse tree of sentences, thereby allowing for more\nrefined extractions. KOKO also supports conditions that are forgiving to\nlinguistic variation of expressing concepts and allows to aggregate evidence\nfrom the entire document in order to filter extractions.\n  To scale up, KOKO exploits a multi-indexing scheme and heuristics for\nefficient extractions. We extensively evaluate KOKO over publicly available\ntext corpora. We show that KOKO indices take up the smallest amount of space,\nare notably faster and more effective than a number of prior indexing schemes.\nFinally, we demonstrate KOKO's scale up on a corpus of 5 million Wikipedia\narticles.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 01:57:31 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Wang", "Xiaolan", ""], ["Feng", "Aaron", ""], ["Golshan", "Behzad", ""], ["Halevy", "Alon", ""], ["Mihaila", "George", ""], ["Oiwa", "Hidekazu", ""], ["Tan", "Wang-Chiew", ""]]}, {"id": "1805.01086", "submitter": "Xin Li", "authors": "Xin Li, Lidong Bing, Wai Lam, Bei Shi", "title": "Transformation Networks for Target-Oriented Sentiment Classification", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Target-oriented sentiment classification aims at classifying sentiment\npolarities over individual opinion targets in a sentence. RNN with attention\nseems a good fit for the characteristics of this task, and indeed it achieves\nthe state-of-the-art performance. After re-examining the drawbacks of attention\nmechanism and the obstacles that block CNN to perform well in this\nclassification task, we propose a new model to overcome these issues. Instead\nof attention, our model employs a CNN layer to extract salient features from\nthe transformed word representations originated from a bi-directional RNN\nlayer. Between the two layers, we propose a component to generate\ntarget-specific representations of words in the sentence, meanwhile incorporate\na mechanism for preserving the original contextual information from the RNN\nlayer. Experiments show that our model achieves a new state-of-the-art\nperformance on a few benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 02:16:27 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Li", "Xin", ""], ["Bing", "Lidong", ""], ["Lam", "Wai", ""], ["Shi", "Bei", ""]]}, {"id": "1805.01087", "submitter": "Xuezhe Ma", "authors": "Xuezhe Ma, Zecong Hu, Jingzhou Liu, Nanyun Peng, Graham Neubig, Eduard\n  Hovy", "title": "Stack-Pointer Networks for Dependency Parsing", "comments": "Accepted by ACL-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel architecture for dependency parsing: \\emph{stack-pointer\nnetworks} (\\textbf{\\textsc{StackPtr}}). Combining pointer\nnetworks~\\citep{vinyals2015pointer} with an internal stack, the proposed model\nfirst reads and encodes the whole sentence, then builds the dependency tree\ntop-down (from root-to-leaf) in a depth-first fashion. The stack tracks the\nstatus of the depth-first search and the pointer networks select one child for\nthe word at the top of the stack at each step. The \\textsc{StackPtr} parser\nbenefits from the information of the whole sentence and all previously derived\nsubtree structures, and removes the left-to-right restriction in classical\ntransition-based parsers. Yet, the number of steps for building any (including\nnon-projective) parse tree is linear in the length of the sentence just as\nother transition-based parsers, yielding an efficient decoding algorithm with\n$O(n^2)$ time complexity. We evaluate our model on 29 treebanks spanning 20\nlanguages and different dependency annotation schemas, and achieve\nstate-of-the-art performance on 21 of them.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 02:23:28 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Ma", "Xuezhe", ""], ["Hu", "Zecong", ""], ["Liu", "Jingzhou", ""], ["Peng", "Nanyun", ""], ["Neubig", "Graham", ""], ["Hovy", "Eduard", ""]]}, {"id": "1805.01089", "submitter": "Shuming Ma", "authors": "Shuming Ma, Xu Sun, Junyang Lin, Xuancheng Ren", "title": "A Hierarchical End-to-End Model for Jointly Improving Text Summarization\n  and Sentiment Classification", "comments": "accepted by IJCAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text summarization and sentiment classification both aim to capture the main\nideas of the text but at different levels. Text summarization is to describe\nthe text within a few sentences, while sentiment classification can be regarded\nas a special type of summarization which \"summarizes\" the text into a even more\nabstract fashion, i.e., a sentiment class. Based on this idea, we propose a\nhierarchical end-to-end model for joint learning of text summarization and\nsentiment classification, where the sentiment classification label is treated\nas the further \"summarization\" of the text summarization output. Hence, the\nsentiment classification layer is put upon the text summarization layer, and a\nhierarchical structure is derived. Experimental results on Amazon online\nreviews datasets show that our model achieves better performance than the\nstrong baseline systems on both abstractive summarization and sentiment\nclassification.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 02:30:07 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 03:30:35 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Ma", "Shuming", ""], ["Sun", "Xu", ""], ["Lin", "Junyang", ""], ["Ren", "Xuancheng", ""]]}, {"id": "1805.01112", "submitter": "Muktabh Mayank Srivastava", "authors": "Nishant Nikhil, Muktabh Mayank Srivastava", "title": "Binarizer at SemEval-2018 Task 3: Parsing dependency and deep learning\n  for irony detection", "comments": "Solution to SemEval 2018 Task 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we describe the system submitted for the SemEval 2018 Task 3\n(Irony detection in English tweets) Subtask A by the team Binarizer. Irony\ndetection is a key task for many natural language processing works. Our method\ntreats ironical tweets to consist of smaller parts containing different\nemotions. We break down tweets into separate phrases using a dependency parser.\nWe then embed those phrases using an LSTM-based neural network model which is\npre-trained to predict emoticons for tweets. Finally, we train a\nfully-connected network to achieve classification.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 04:53:06 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Nikhil", "Nishant", ""], ["Srivastava", "Muktabh Mayank", ""]]}, {"id": "1805.01156", "submitter": "Ville Vestman", "authors": "Ville Vestman and Tomi Kinnunen", "title": "Supervector Compression Strategies to Speed up I-Vector System\n  Development", "comments": "To appear in Speaker Odyssey 2018: The Speaker and Language\n  Recognition Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The front-end factor analysis (FEFA), an extension of principal component\nanalysis (PPCA) tailored to be used with Gaussian mixture models (GMMs), is\ncurrently the prevalent approach to extract compact utterance-level features\n(i-vectors) for automatic speaker verification (ASV) systems. Little research\nhas been conducted comparing FEFA to the conventional PPCA applied to maximum a\nposteriori (MAP) adapted GMM supervectors. We study several alternative\nmethods, including PPCA, factor analysis (FA), and two supervised approaches,\nsupervised PPCA (SPPCA) and the recently proposed probabilistic partial least\nsquares (PPLS), to compress MAP-adapted GMM supervectors. The resulting\ni-vectors are used in ASV tasks with a probabilistic linear discriminant\nanalysis (PLDA) back-end. We experiment on two different datasets, on the\ntelephone condition of NIST SRE 2010 and on the recent VoxCeleb corpus\ncollected from YouTube videos containing celebrity interviews recorded in\nvarious acoustical and technical conditions. The results suggest that, in terms\nof ASV accuracy, the supervector compression approaches are on a par with FEFA.\nThe supervised approaches did not result in improved performance. In comparison\nto FEFA, we obtained more than hundred-fold (100x) speedups in the total\nvariability model (TVM) training using the PPCA and FA supervector compression\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 08:12:39 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Vestman", "Ville", ""], ["Kinnunen", "Tomi", ""]]}, {"id": "1805.01216", "submitter": "Dinesh Raghu", "authors": "Dinesh Raghu, Nikhil Gupta and Mausam", "title": "Disentangling Language and Knowledge in Task-Oriented Dialogs", "comments": "Published in NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Knowledge Base (KB) used for real-world applications, such as booking a\nmovie or restaurant reservation, keeps changing over time. End-to-end neural\nnetworks trained for these task-oriented dialogs are expected to be immune to\nany changes in the KB. However, existing approaches breakdown when asked to\nhandle such changes. We propose an encoder-decoder architecture (BoSsNet) with\na novel Bag-of-Sequences (BoSs) memory, which facilitates the disentangled\nlearning of the response's language model and its knowledge incorporation.\nConsequently, the KB can be modified with new knowledge without a drop in\ninterpretability. We find that BoSsNet outperforms state-of-the-art models,\nwith considerable improvements (> 10\\%) on bAbI OOV test sets and other\nhuman-human datasets. We also systematically modify existing datasets to\nmeasure disentanglement and show BoSsNet to be robust to KB modifications.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 10:52:26 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 17:50:13 GMT"}, {"version": "v3", "created": "Fri, 5 Apr 2019 17:24:32 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Raghu", "Dinesh", ""], ["Gupta", "Nikhil", ""], ["Mausam", "", ""]]}, {"id": "1805.01252", "submitter": "Carolin Lawrence", "authors": "Carolin Lawrence and Stefan Riezler", "title": "Improving a Neural Semantic Parser by Counterfactual Learning from Human\n  Bandit Feedback", "comments": "Conference of the Association for Computational Linguistics (ACL),\n  2018, Melbourne, Australia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual learning from human bandit feedback describes a scenario where\nuser feedback on the quality of outputs of a historic system is logged and used\nto improve a target system. We show how to apply this learning framework to\nneural semantic parsing. From a machine learning perspective, the key challenge\nlies in a proper reweighting of the estimator so as to avoid known degeneracies\nin counterfactual learning, while still being applicable to stochastic gradient\noptimization. To conduct experiments with human users, we devise an easy-to-use\ninterface to collect human feedback on semantic parses. Our work is the first\nto show that semantic parsers can be improved significantly by counterfactual\nlearning from logged human feedback data.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 12:24:39 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 07:04:53 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Lawrence", "Carolin", ""], ["Riezler", "Stefan", ""]]}, {"id": "1805.01334", "submitter": "Chenyan Xiong", "authors": "Chenyan Xiong and Zhengzhong Liu and Jamie Callan and Tie-Yan Liu", "title": "Towards Better Text Understanding and Retrieval through Kernel Entity\n  Salience Modeling", "comments": null, "journal-ref": "In proceedings of SIGIR 2018", "doi": "10.1145/3209978.3209982", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a Kernel Entity Salience Model (KESM) that improves text\nunderstanding and retrieval by better estimating entity salience (importance)\nin documents. KESM represents entities by knowledge enriched distributed\nrepresentations, models the interactions between entities and words by kernels,\nand combines the kernel scores to estimate entity salience. The whole model is\nlearned end-to-end using entity salience labels. The salience model also\nimproves ad hoc search accuracy, providing effective ranking features by\nmodeling the salience of query entities in candidate documents. Our experiments\non two entity salience corpora and two TREC ad hoc search datasets demonstrate\nthe effectiveness of KESM over frequency-based and feature-based methods. We\nalso provide examples showing how KESM conveys its text understanding ability\nlearned from entity salience to search.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 14:46:12 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Xiong", "Chenyan", ""], ["Liu", "Zhengzhong", ""], ["Callan", "Jamie", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1805.01369", "submitter": "Grigoriy Sterling", "authors": "Grigoriy Sterling, Andrey Belyaev, Maxim Ryabov", "title": "Framewise approach in multimodal emotion recognition in OMG challenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report we described our approach achieves $53\\%$ of unweighted\naccuracy over $7$ emotions and $0.05$ and $0.09$ mean squared errors for\narousal and valence in OMG emotion recognition challenge. Our results were\nobtained with ensemble of single modality models trained on voice and face data\nfrom video separately. We consider each stream as a sequence of frames. Next we\nestimated features from frames and handle it with recurrent neural network. As\naudio frame we mean short $0.4$ second spectrogram interval. For features\nestimation for face pictures we used own ResNet neural network pretrained on\nAffectNet database. Each short spectrogram was considered as a picture and\nprocessed by convolutional network too. As a base audio model we used ResNet\npretrained in speaker recognition task. Predictions from both modalities were\nfused on decision level and improve single-channel approaches by a few percent\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 15:21:44 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Sterling", "Grigoriy", ""], ["Belyaev", "Andrey", ""], ["Ryabov", "Maxim", ""]]}, {"id": "1805.01416", "submitter": "Pedro M. Ferreira", "authors": "Pedro M. Ferreira, Diogo Pernes, Kelwin Fernandes, Ana Rebelo and\n  Jaime S. Cardoso", "title": "Dimensional emotion recognition using visual and textual cues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of automatic emotion recognition in the\nscope of the One-Minute Gradual-Emotional Behavior challenge (OMG-Emotion\nchallenge). The underlying objective of the challenge is the automatic\nestimation of emotion expressions in the two-dimensional emotion representation\nspace (i.e., arousal and valence). The adopted methodology is a weighted\nensemble of several models from both video and text modalities. For video-based\nrecognition, two different types of visual cues (i.e., face and facial\nlandmarks) were considered to feed a multi-input deep neural network. Regarding\nthe text modality, a sequential model based on a simple recurrent architecture\nwas implemented. In addition, we also introduce a model based on high-level\nfeatures in order to embed domain knowledge in the learning process.\nExperimental results on the OMG-Emotion validation set demonstrate the\neffectiveness of the implemented ensemble model as it clearly outperforms the\ncurrent baseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 16:42:20 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Ferreira", "Pedro M.", ""], ["Pernes", "Diogo", ""], ["Fernandes", "Kelwin", ""], ["Rebelo", "Ana", ""], ["Cardoso", "Jaime S.", ""]]}, {"id": "1805.01445", "submitter": "Noah Weber", "authors": "Noah Weber, Leena Shekhar, Niranjan Balasubramanian", "title": "The Fine Line between Linguistic Generalization and Failure in\n  Seq2Seq-Attention Models", "comments": "Workshop on New Forms of Generalization in Deep Learning and NLP\n  (NAACL 2018), revised to update some references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seq2Seq based neural architectures have become the go-to architecture to\napply to sequence to sequence language tasks. Despite their excellent\nperformance on these tasks, recent work has noted that these models usually do\nnot fully capture the linguistic structure required to generalize beyond the\ndense sections of the data distribution \\cite{ettinger2017towards}, and as\nsuch, are likely to fail on samples from the tail end of the distribution (such\nas inputs that are noisy \\citep{belkinovnmtbreak} or of different lengths\n\\citep{bentivoglinmtlength}). In this paper, we look at a model's ability to\ngeneralize on a simple symbol rewriting task with a clearly defined structure.\nWe find that the model's ability to generalize this structure beyond the\ntraining distribution depends greatly on the chosen random seed, even when\nperformance on the standard test set remains the same. This suggests that a\nmodel's ability to capture generalizable structure is highly sensitive.\nMoreover, this sensitivity may not be apparent when evaluating it on standard\ntest sets.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 17:45:33 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 18:19:33 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Weber", "Noah", ""], ["Shekhar", "Leena", ""], ["Balasubramanian", "Niranjan", ""]]}, {"id": "1805.01460", "submitter": "Denner Serafim Vieira", "authors": "Denner S. Vieira, Sergio Picoli, and Renio S. Mendes", "title": "Robustness of sentence length measures in written texts", "comments": "9 pages, 5 figures, accepted for publication in Physica A", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hidden structural patterns in written texts have been subject of considerable\nresearch in the last decades. In particular, mapping a text into a time series\nof sentence lengths is a natural way to investigate text structure. Typically,\nsentence length has been quantified by using measures based on the number of\nwords and the number of characters, but other variations are possible. To\nquantify the robustness of different sentence length measures, we analyzed a\ndatabase containing about five hundred books in English. For each book, we\nextracted six distinct measures of sentence length, including number of words\nand number of characters (taking into account lemmatization and stop words\nremoval). We compared these six measures for each book by using i) Pearson's\ncoefficient to investigate linear correlations; ii) Kolmogorov--Smirnov test to\ncompare distributions; and iii) detrended fluctuation analysis (DFA) to\nquantify auto-correlations. We have found that all six measures exhibit very\nsimilar behavior, suggesting that sentence length is a robust measure related\nto text structure.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 23:07:31 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Vieira", "Denner S.", ""], ["Picoli", "Sergio", ""], ["Mendes", "Renio S.", ""]]}, {"id": "1805.01542", "submitter": "Anuj Goyal", "authors": "Anuj Goyal, Angeliki Metallinou, Spyros Matsoukas", "title": "Fast and Scalable Expansion of Natural Language Understanding\n  Functionality for Intelligent Agents", "comments": "To appear in the Proceedings of NAACL-HLT 2018 (Industry Track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast expansion of natural language functionality of intelligent virtual\nagents is critical for achieving engaging and informative interactions.\nHowever, developing accurate models for new natural language domains is a time\nand data intensive process. We propose efficient deep neural network\narchitectures that maximally re-use available resources through transfer\nlearning. Our methods are applied for expanding the understanding capabilities\nof a popular commercial agent and are evaluated on hundreds of new domains,\ndesigned by internal or external developers. We demonstrate that our proposed\nmethods significantly increase accuracy in low resource settings and enable\nrapid development of accurate models with less data.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 21:21:16 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Goyal", "Anuj", ""], ["Metallinou", "Angeliki", ""], ["Matsoukas", "Spyros", ""]]}, {"id": "1805.01553", "submitter": "Julia Kreutzer", "authors": "Tsz Kin Lam, Julia Kreutzer, Stefan Riezler", "title": "A Reinforcement Learning Approach to Interactive-Predictive Neural\n  Machine Translation", "comments": "Published at EAMT 2018; Updated algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an approach to interactive-predictive neural machine translation\nthat attempts to reduce human effort from three directions: Firstly, instead of\nrequiring humans to select, correct, or delete segments, we employ the idea of\nlearning from human reinforcements in form of judgments on the quality of\npartial translations. Secondly, human effort is further reduced by using the\nentropy of word predictions as uncertainty criterion to trigger feedback\nrequests. Lastly, online updates of the model parameters after every\ninteraction allow the model to adapt quickly. We show in simulation experiments\nthat reward signals on partial translations significantly improve character\nF-score and BLEU compared to feedback on full translations only, while human\neffort can be reduced to an average number of $5$ feedback requests for every\ninput.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 21:50:34 GMT"}, {"version": "v2", "created": "Mon, 7 May 2018 23:11:30 GMT"}, {"version": "v3", "created": "Tue, 5 Jun 2018 23:57:11 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Lam", "Tsz Kin", ""], ["Kreutzer", "Julia", ""], ["Riezler", "Stefan", ""]]}, {"id": "1805.01555", "submitter": "Puyang Xu", "authors": "Puyang Xu and Qi Hu", "title": "An End-to-end Approach for Handling Unknown Slot Values in Dialogue\n  State Tracking", "comments": "Accepted by ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We highlight a practical yet rarely discussed problem in dialogue state\ntracking (DST), namely handling unknown slot values. Previous approaches\ngenerally assume predefined candidate lists and thus are not designed to output\nunknown values, especially when the spoken language understanding (SLU) module\nis absent as in many end-to-end (E2E) systems. We describe in this paper an E2E\narchitecture based on the pointer network (PtrNet) that can effectively extract\nunknown slot values while still obtains state-of-the-art accuracy on the\nstandard DSTC2 benchmark. We also provide extensive empirical evidence to show\nthat tracking unknown values can be challenging and our approach can bring\nsignificant improvement with the help of an effective feature dropout\ntechnique.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 21:59:13 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Xu", "Puyang", ""], ["Hu", "Qi", ""]]}, {"id": "1805.01565", "submitter": "Lifeng Han", "authors": "Lifeng Han and Shaohui Kuang", "title": "Incorporating Chinese Radicals Into Neural Machine Translation: Deeper\n  Than Character Level", "comments": "In Proceedings of ESSLLI-2018: 30th European Summer School in Logic,\n  Language and Information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neural machine translation (NMT), researchers face the challenge of\nun-seen (or out-of-vocabulary OOV) words translation. To solve this, some\nresearchers propose the splitting of western languages such as English and\nGerman into sub-words or compounds. In this paper, we try to address this OOV\nissue and improve the NMT adequacy with a harder language Chinese whose\ncharacters are even more sophisticated in composition. We integrate the Chinese\nradicals into the NMT model with different settings to address the unseen words\nchallenge in Chinese to English translation. On the other hand, this also can\nbe considered as semantic part of the MT system since the Chinese radicals\nusually carry the essential meaning of the words they are constructed in.\nMeaningful radicals and new characters can be integrated into the NMT systems\nwith our models. We use an attention-based NMT system as a strong baseline\nsystem. The experiments on standard Chinese-to-English NIST translation shared\ntask data 2006 and 2008 show that our designed models outperform the baseline\nmodel in a wide range of state-of-the-art evaluation metrics including LEPOR,\nBEER, and CharacTER, in addition to BLEU and NIST scores, especially on the\nadequacy-level translation. We also have some interesting findings from the\nresults of our various experiment settings about the performance of words and\ncharacters in Chinese NMT, which is different with other languages. For\ninstance, the fully character level NMT may perform well or the state of the\nart in some other languages as researchers demonstrated recently, however, in\nthe Chinese NMT model, word boundary knowledge is important for the model\nlearning.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 22:58:54 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 15:27:38 GMT"}, {"version": "v3", "created": "Mon, 24 Jun 2019 17:15:10 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Han", "Lifeng", ""], ["Kuang", "Shaohui", ""]]}, {"id": "1805.01589", "submitter": "Lucas Oliveira", "authors": "Lucas S. Oliveira, Pedro O. S. Vaz de Melo, Marcelo S. Amaral, Jos\\'e\n  Ant\\^onio. G. Pinho", "title": "When Politicians Talk About Politics: Identifying Political Tweets of\n  Brazilian Congressmen", "comments": "4 pages, 7 figures, 2 tables", "journal-ref": "2018, THE 12TH INTERNATIONAL AAAI CONFERENCE ON WEB AND SOCIAL\n  MEDIA (ICWSM-18)", "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since June 2013, when Brazil faced the largest and most significant mass\nprotests in a generation, a political crisis is in course. In midst of this\ncrisis, Brazilian politicians use social media to communicate with the\nelectorate in order to retain or to grow their political capital. The problem\nis that many controversial topics are in course and deputies may prefer to\navoid such themes in their messages. To characterize this behavior, we propose\na method to accurately identify political and non-political tweets\nindependently of the deputy who posted it and of the time it was posted.\nMoreover, we collected tweets of all congressmen who were active on Twitter and\nworked in the Brazilian parliament from October 2013 to October 2017. To\nevaluate our method, we used word clouds and a topic model to identify the main\npolitical and non-political latent topics in parliamentarian tweets. Both\nresults indicate that our proposal is able to accurately distinguish political\nfrom non-political tweets. Moreover, our analyses revealed a striking fact:\nmore than half of the messages posted by Brazilian deputies are non-political.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 02:26:21 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Oliveira", "Lucas S.", ""], ["de Melo", "Pedro O. S. Vaz", ""], ["Amaral", "Marcelo S.", ""], ["Pinho", "Jos\u00e9 Ant\u00f4nio. G.", ""]]}, {"id": "1805.01646", "submitter": "Roland Roller", "authors": "Roland Roller, Madeleine Kittner, Dirk Weissenborn, Ulf Leser", "title": "Cross-lingual Candidate Search for Biomedical Concept Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biomedical concept normalization links concept mentions in texts to a\nsemantically equivalent concept in a biomedical knowledge base. This task is\nchallenging as concepts can have different expressions in natural languages,\ne.g. paraphrases, which are not necessarily all present in the knowledge base.\nConcept normalization of non-English biomedical text is even more challenging\nas non-English resources tend to be much smaller and contain less synonyms. To\novercome the limitations of non-English terminologies we propose a\ncross-lingual candidate search for concept normalization using a\ncharacter-based neural translation model trained on a multilingual biomedical\nterminology. Our model is trained with Spanish, French, Dutch and German\nversions of UMLS. The evaluation of our model is carried out on the French\nQuaero corpus, showing that it outperforms most teams of CLEF eHealth 2015 and\n2016. Additionally, we compare performance to commercial translators on\nSpanish, French, Dutch and German versions of Mantra. Our model performs\nsimilarly well, but is free of charge and can be run locally. This is\nparticularly important for clinical NLP applications as medical documents\nunderlay strict privacy restrictions.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 08:11:09 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Roller", "Roland", ""], ["Kittner", "Madeleine", ""], ["Weissenborn", "Dirk", ""], ["Leser", "Ulf", ""]]}, {"id": "1805.01676", "submitter": "Christian Hadiwinoto", "authors": "Christian Hadiwinoto, Hwee Tou Ng", "title": "Upping the Ante: Towards a Better Benchmark for Chinese-to-English\n  Machine Translation", "comments": "LREC 2018 (8 pages, 2 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many machine translation (MT) papers that propose novel approaches\nand show improvements over their self-defined baselines. The experimental\nsetting in each paper often differs from one another. As such, it is hard to\ndetermine if a proposed approach is really useful and advances the state of the\nart. Chinese-to-English translation is a common translation direction in MT\npapers, although there is not one widely accepted experimental setting in\nChinese-to-English MT. Our goal in this paper is to propose a benchmark in\nevaluation setup for Chinese-to-English machine translation, such that the\neffectiveness of a new proposed MT approach can be directly compared to\nprevious approaches. Towards this end, we also built a highly competitive\nstate-of-the-art MT system trained on a large-scale training set. Our system\noutperforms reported results on NIST OpenMT test sets in almost all papers\npublished in major conferences and journals in computational linguistics and\nartificial intelligence in the past 11 years. We argue that a standardized\nbenchmark on data and performance is important for meaningful comparison.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 09:22:13 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Hadiwinoto", "Christian", ""], ["Ng", "Hwee Tou", ""]]}, {"id": "1805.01817", "submitter": "Paul Michel", "authors": "Paul Michel and Graham Neubig", "title": "Extreme Adaptation for Personalized Neural Machine Translation", "comments": "Accepted as a short paper at ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every person speaks or writes their own flavor of their native language,\ninfluenced by a number of factors: the content they tend to talk about, their\ngender, their social status, or their geographical origin.\n  When attempting to perform Machine Translation (MT), these variations have a\nsignificant effect on how the system should perform translation, but this is\nnot captured well by standard one-size-fits-all models.\n  In this paper, we propose a simple and parameter-efficient adaptation\ntechnique that only requires adapting the bias of the output softmax to each\nparticular user of the MT system, either directly or through a factored\napproximation.\n  Experiments on TED talks in three languages demonstrate improvements in\ntranslation accuracy, and better reflection of speaker traits in the target\ntext.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 15:07:25 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Michel", "Paul", ""], ["Neubig", "Graham", ""]]}, {"id": "1805.01923", "submitter": "Enrico Santus", "authors": "Enrico Santus, Hongmin Wang, Emmanuele Chersoni and Yue Zhang", "title": "A Rank-Based Similarity Metric for Word Embeddings", "comments": "5 pages, 1 figure, 4 tables, ACL, ACL2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word Embeddings have recently imposed themselves as a standard for\nrepresenting word meaning in NLP. Semantic similarity between word pairs has\nbecome the most common evaluation benchmark for these representations, with\nvector cosine being typically used as the only similarity metric. In this\npaper, we report experiments with a rank-based metric for WE, which performs\ncomparably to vector cosine in similarity estimation and outperforms it in the\nrecently-introduced and challenging task of outlier detection, thus suggesting\nthat rank-based measures can improve clustering quality.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 19:48:36 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Santus", "Enrico", ""], ["Wang", "Hongmin", ""], ["Chersoni", "Emmanuele", ""], ["Zhang", "Yue", ""]]}, {"id": "1805.01984", "submitter": "Amlaan Bhoi", "authors": "Amlaan Bhoi, Sandeep Joshi", "title": "Various Approaches to Aspect-based Sentiment Analysis", "comments": "3 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of aspect-based sentiment analysis deals with classifying\nsentiments (negative, neutral, positive) for a given aspect in a sentence. A\ntraditional sentiment classification task involves treating the entire sentence\nas a text document and classifying sentiments based on all the words. Let us\nassume, we have a sentence such as \"the acceleration of this car is fast, but\nthe reliability is horrible\". This can be a difficult sentence because it has\ntwo aspects with conflicting sentiments about the same entity. Considering\nmachine learning techniques (or deep learning), how do we encode the\ninformation that we are interested in one aspect and its sentiment but not the\nother? Let us explore various pre-processing steps, features, and methods used\nto facilitate in solving this task.\n", "versions": [{"version": "v1", "created": "Sat, 5 May 2018 02:44:51 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Bhoi", "Amlaan", ""], ["Joshi", "Sandeep", ""]]}, {"id": "1805.02023", "submitter": "Jie Yang", "authors": "Yue Zhang and Jie Yang", "title": "Chinese NER Using Lattice LSTM", "comments": "Accepted at ACL 2018 as Long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a lattice-structured LSTM model for Chinese NER, which encodes\na sequence of input characters as well as all potential words that match a\nlexicon. Compared with character-based methods, our model explicitly leverages\nword and word sequence information. Compared with word-based methods, lattice\nLSTM does not suffer from segmentation errors. Gated recurrent cells allow our\nmodel to choose the most relevant characters and words from a sentence for\nbetter NER results. Experiments on various datasets show that lattice LSTM\noutperforms both word-based and character-based LSTM baselines, achieving the\nbest results.\n", "versions": [{"version": "v1", "created": "Sat, 5 May 2018 08:48:32 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 15:34:28 GMT"}, {"version": "v3", "created": "Thu, 31 May 2018 13:10:52 GMT"}, {"version": "v4", "created": "Thu, 5 Jul 2018 16:02:59 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Zhang", "Yue", ""], ["Yang", "Jie", ""]]}, {"id": "1805.02036", "submitter": "Duygu Ataman", "authors": "Duygu Ataman and Marcello Federico", "title": "Compositional Representation of Morphologically-Rich Input for Neural\n  Machine Translation", "comments": "Accepted at ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) models are typically trained with fixed-size\ninput and output vocabularies, which creates an important bottleneck on their\naccuracy and generalization capability. As a solution, various studies proposed\nsegmenting words into sub-word units and performing translation at the\nsub-lexical level. However, statistical word segmentation methods have recently\nshown to be prone to morphological errors, which can lead to inaccurate\ntranslations. In this paper, we propose to overcome this problem by replacing\nthe source-language embedding layer of NMT with a bi-directional recurrent\nneural network that generates compositional representations of the input at any\ndesired level of granularity. We test our approach in a low-resource setting\nwith five languages from different morphological typologies, and under\ndifferent composition assumptions. By training NMT to compose word\nrepresentations from character n-grams, our approach consistently outperforms\n(from 1.71 to 2.48 BLEU points) NMT learning embeddings of statistically\ngenerated sub-word units.\n", "versions": [{"version": "v1", "created": "Sat, 5 May 2018 10:27:32 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Ataman", "Duygu", ""], ["Federico", "Marcello", ""]]}, {"id": "1805.02094", "submitter": "Robert Lim", "authors": "Robert Lim, Kenneth Heafield, Hieu Hoang, Mark Briers and Allen Malony", "title": "Exploring Hyper-Parameter Optimization for Neural Machine Translation on\n  GPU Architectures", "comments": "2018 2nd Naval Applications for Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) has been accelerated by deep learning neural\nnetworks over statistical-based approaches, due to the plethora and\nprogrammability of commodity heterogeneous computing architectures such as\nFPGAs and GPUs and the massive amount of training corpuses generated from news\noutlets, government agencies and social media. Training a learning classifier\nfor neural networks entails tuning hyper-parameters that would yield the best\nperformance. Unfortunately, the number of parameters for machine translation\ninclude discrete categories as well as continuous options, which makes for a\ncombinatorial explosive problem. This research explores optimizing\nhyper-parameters when training deep learning neural networks for machine\ntranslation. Specifically, our work investigates training a language model with\nMarian NMT. Results compare NMT under various hyper-parameter settings across a\nvariety of modern GPU architecture generations in single node and multi-node\nsettings, revealing insights on which hyper-parameters matter most in terms of\nperformance, such as words processed per second, convergence rates, and\ntranslation accuracy, and provides insights on how to best achieve\nhigh-performing NMT systems.\n", "versions": [{"version": "v1", "created": "Sat, 5 May 2018 18:13:41 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Lim", "Robert", ""], ["Heafield", "Kenneth", ""], ["Hoang", "Hieu", ""], ["Briers", "Mark", ""], ["Malony", "Allen", ""]]}, {"id": "1805.02096", "submitter": "Dmitriy Dligach", "authors": "Dmitriy Dligach and Timothy Miller", "title": "Learning Patient Representations from Text", "comments": "Accepted to *SEM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining electronic health records for patients who satisfy a set of predefined\ncriteria is known in medical informatics as phenotyping. Phenotyping has\nnumerous applications such as outcome prediction, clinical trial recruitment,\nand retrospective studies. Supervised machine learning for phenotyping\ntypically relies on sparse patient representations such as bag-of-words. We\nconsider an alternative that involves learning patient representations. We\ndevelop a neural network model for learning patient representations and show\nthat the learned representations are general enough to obtain state-of-the-art\nperformance on a standard comorbidity detection task.\n", "versions": [{"version": "v1", "created": "Sat, 5 May 2018 18:20:48 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Dligach", "Dmitriy", ""], ["Miller", "Timothy", ""]]}, {"id": "1805.02203", "submitter": "Rem Hida", "authors": "Rem Hida, Naoya Takeishi, Takehisa Yairi, Koichi Hori", "title": "Dynamic and Static Topic Model for Analyzing Time-Series Document\n  Collections", "comments": "6 pages, 2 figures, Accepted as ACL 2018 short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For extracting meaningful topics from texts, their structures should be\nconsidered properly. In this paper, we aim to analyze structured time-series\ndocuments such as a collection of news articles and a series of scientific\npapers, wherein topics evolve along time depending on multiple topics in the\npast and are also related to each other at each time. To this end, we propose a\ndynamic and static topic model, which simultaneously considers the dynamic\nstructures of the temporal topic evolution and the static structures of the\ntopic hierarchy at each time. We show the results of experiments on collections\nof scientific papers, in which the proposed method outperformed conventional\nmodels. Moreover, we show an example of extracted topic structures, which we\nfound helpful for analyzing research activities.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 12:41:47 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Hida", "Rem", ""], ["Takeishi", "Naoya", ""], ["Yairi", "Takehisa", ""], ["Hori", "Koichi", ""]]}, {"id": "1805.02214", "submitter": "Marek Rei", "authors": "Marek Rei, Anders S{\\o}gaard", "title": "Zero-shot Sequence Labeling: Transferring Knowledge from Sentences to\n  Tokens", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can attention- or gradient-based visualization techniques be used to infer\ntoken-level labels for binary sequence tagging problems, using networks trained\nonly on sentence-level labels? We construct a neural network architecture based\non soft attention, train it as a binary sentence classifier and evaluate\nagainst token-level annotation on four different datasets. Inferring token\nlabels from a network provides a method for quantitatively evaluating what the\nmodel is learning, along with generating useful feedback in assistance systems.\nOur results indicate that attention-based methods are able to predict\ntoken-level labels more accurately, compared to gradient-based methods,\nsometimes even rivaling the supervised oracle network.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 13:53:50 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Rei", "Marek", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "1805.02220", "submitter": "Yizhong Wang", "authors": "Yizhong Wang, Kai Liu, Jing Liu, Wei He, Yajuan Lyu, Hua Wu, Sujian Li\n  and Haifeng Wang", "title": "Multi-Passage Machine Reading Comprehension with Cross-Passage Answer\n  Verification", "comments": "10 pages, ACL 2018 camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine reading comprehension (MRC) on real web data usually requires the\nmachine to answer a question by analyzing multiple passages retrieved by search\nengine. Compared with MRC on a single passage, multi-passage MRC is more\nchallenging, since we are likely to get multiple confusing answer candidates\nfrom different passages. To address this problem, we propose an end-to-end\nneural model that enables those answer candidates from different passages to\nverify each other based on their content representations. Specifically, we\njointly train three modules that can predict the final answer based on three\nfactors: the answer boundary, the answer content and the cross-passage answer\nverification. The experimental results show that our method outperforms the\nbaseline by a large margin and achieves the state-of-the-art performance on the\nEnglish MS-MARCO dataset and the Chinese DuReader dataset, both of which are\ndesigned for MRC in real-world settings.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 14:26:35 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 07:03:24 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Wang", "Yizhong", ""], ["Liu", "Kai", ""], ["Liu", "Jing", ""], ["He", "Wei", ""], ["Lyu", "Yajuan", ""], ["Wu", "Hua", ""], ["Li", "Sujian", ""], ["Wang", "Haifeng", ""]]}, {"id": "1805.02258", "submitter": "Andrey Kutuzov", "authors": "Andrey Kutuzov", "title": "Russian word sense induction by clustering averaged word embeddings", "comments": "Proceedings of the 24rd International Conference on Computational\n  Linguistics and Intellectual Technologies (Dialogue-2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The paper reports our participation in the shared task on word sense\ninduction and disambiguation for the Russian language (RUSSE-2018). Our team\nwas ranked 2nd for the wiki-wiki dataset (containing mostly homonyms) and 5th\nfor the bts-rnc and active-dict datasets (containing mostly polysemous words)\namong all 19 participants.\n  The method we employed was extremely naive. It implied representing contexts\nof ambiguous words as averaged word embedding vectors, using off-the-shelf\npre-trained distributional models. Then, these vector representations were\nclustered with mainstream clustering techniques, thus producing the groups\ncorresponding to the ambiguous word senses. As a side result, we show that word\nembedding models trained on small but balanced corpora can be superior to those\ntrained on large but noisy data - not only in intrinsic evaluation, but also in\ndownstream tasks like word sense induction.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 18:25:12 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Kutuzov", "Andrey", ""]]}, {"id": "1805.02262", "submitter": "Waleed Ammar", "authors": "Waleed Ammar, Dirk Groeneveld, Chandra Bhagavatula, Iz Beltagy, Miles\n  Crawford, Doug Downey, Jason Dunkelberger, Ahmed Elgohary, Sergey Feldman, Vu\n  Ha, Rodney Kinney, Sebastian Kohlmeier, Kyle Lo, Tyler Murray, Hsu-Han Ooi,\n  Matthew Peters, Joanna Power, Sam Skjonsberg, Lucy Lu Wang, Chris Wilhelm,\n  Zheng Yuan, Madeleine van Zuylen, Oren Etzioni", "title": "Construction of the Literature Graph in Semantic Scholar", "comments": "To appear in NAACL 2018 industry track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a deployed scalable system for organizing published scientific\nliterature into a heterogeneous graph to facilitate algorithmic manipulation\nand discovery. The resulting literature graph consists of more than 280M nodes,\nrepresenting papers, authors, entities and various interactions between them\n(e.g., authorships, citations, entity mentions). We reduce literature graph\nconstruction into familiar NLP tasks (e.g., entity extraction and linking),\npoint out research challenges due to differences from standard formulations of\nthese tasks, and report empirical results for each task. The methods described\nin this paper are used to enable semantic features in www.semanticscholar.org\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 18:35:48 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Ammar", "Waleed", ""], ["Groeneveld", "Dirk", ""], ["Bhagavatula", "Chandra", ""], ["Beltagy", "Iz", ""], ["Crawford", "Miles", ""], ["Downey", "Doug", ""], ["Dunkelberger", "Jason", ""], ["Elgohary", "Ahmed", ""], ["Feldman", "Sergey", ""], ["Ha", "Vu", ""], ["Kinney", "Rodney", ""], ["Kohlmeier", "Sebastian", ""], ["Lo", "Kyle", ""], ["Murray", "Tyler", ""], ["Ooi", "Hsu-Han", ""], ["Peters", "Matthew", ""], ["Power", "Joanna", ""], ["Skjonsberg", "Sam", ""], ["Wang", "Lucy Lu", ""], ["Wilhelm", "Chris", ""], ["Yuan", "Zheng", ""], ["van Zuylen", "Madeleine", ""], ["Etzioni", "Oren", ""]]}, {"id": "1805.02266", "submitter": "Vered Shwartz", "authors": "Max Glockner, Vered Shwartz, and Yoav Goldberg", "title": "Breaking NLI Systems with Sentences that Require Simple Lexical\n  Inferences", "comments": "6 pages, short paper at ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We create a new NLI test set that shows the deficiency of state-of-the-art\nmodels in inferences that require lexical and world knowledge. The new examples\nare simpler than the SNLI test set, containing sentences that differ by at most\none word from sentences in the training set. Yet, the performance on the new\ntest set is substantially worse across systems trained on SNLI, demonstrating\nthat these systems are limited in their generalization ability, failing to\ncapture many simple inferences.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 18:49:48 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Glockner", "Max", ""], ["Shwartz", "Vered", ""], ["Goldberg", "Yoav", ""]]}, {"id": "1805.02275", "submitter": "Dat Tien Nguyen", "authors": "Tasnim Mohiuddin, Shafiq Joty and Dat Tien Nguyen", "title": "Coherence Modeling of Asynchronous Conversations: A Neural Entity Grid\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel coherence model for written asynchronous conversations\n(e.g., forums, emails), and show its applications in coherence assessment and\nthread reconstruction tasks. We conduct our research in two steps. First, we\npropose improvements to the recently proposed neural entity grid model by\nlexicalizing its entity transitions. Then, we extend the model to asynchronous\nconversations by incorporating the underlying conversational structure in the\nentity grid representation and feature computation. Our model achieves state of\nthe art results on standard coherence assessment tasks in monologue and\nconversations outperforming existing models. We also demonstrate its\neffectiveness in reconstructing thread structures.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 20:40:19 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Mohiuddin", "Tasnim", ""], ["Joty", "Shafiq", ""], ["Nguyen", "Dat Tien", ""]]}, {"id": "1805.02282", "submitter": "Mark Fishel", "authors": "Sander Tars and Mark Fishel", "title": "Multi-Domain Neural Machine Translation", "comments": "Accepted to EAMT'2018, In Proceedings of the 21st Annual Conference\n  of the European Association for Machine Translation (EAMT'2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to neural machine translation (NMT) that supports\nmultiple domains in a single model and allows switching between the domains\nwhen translating. The core idea is to treat text domains as distinct languages\nand use multilingual NMT methods to create multi-domain translation systems, we\nshow that this approach results in significant translation quality gains over\nfine-tuning. We also explore whether the knowledge of pre-specified text\ndomains is necessary, turns out that it is after all, but also that when it is\nnot known quite high translation quality can be reached.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 22:14:47 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Tars", "Sander", ""], ["Fishel", "Mark", ""]]}, {"id": "1805.02333", "submitter": "Yu Wu", "authors": "Yu Wu, Wei Wu, Zhoujun Li, Ming Zhou", "title": "Learning Matching Models with Weak Supervision for Response Selection in\n  Retrieval-based Chatbots", "comments": "accepted by ACL 2018 as a short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method that can leverage unlabeled data to learn a matching\nmodel for response selection in retrieval-based chatbots. The method employs a\nsequence-to-sequence architecture (Seq2Seq) model as a weak annotator to judge\nthe matching degree of unlabeled pairs, and then performs learning with both\nthe weak signals and the unlabeled data. Experimental results on two public\ndata sets indicate that matching models get significant improvements when they\nare learned with the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 03:31:00 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 04:20:56 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Wu", "Yu", ""], ["Wu", "Wei", ""], ["Li", "Zhoujun", ""], ["Zhou", "Ming", ""]]}, {"id": "1805.02356", "submitter": "Jieli Zhou", "authors": "Xin Qian, Ziyi Zhong, Jieli Zhou", "title": "Multimodal Machine Translation with Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.MA cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal machine translation is one of the applications that integrates\ncomputer vision and language processing. It is a unique task given that in the\nfield of machine translation, many state-of-the-arts algorithms still only\nemploy textual information. In this work, we explore the effectiveness of\nreinforcement learning in multimodal machine translation. We present a novel\nalgorithm based on the Advantage Actor-Critic (A2C) algorithm that specifically\ncater to the multimodal machine translation task of the EMNLP 2018 Third\nConference on Machine Translation (WMT18). We experiment our proposed algorithm\non the Multi30K multilingual English-German image description dataset and the\nFlickr30K image entity dataset. Our model takes two channels of inputs, image\nand text, uses translation evaluation metrics as training rewards, and achieves\nbetter results than supervised learning MLE baseline models. Furthermore, we\ndiscuss the prospects and limitations of using reinforcement learning for\nmachine translation. Our experiment results suggest a promising reinforcement\nlearning solution to the general task of multimodal sequence to sequence\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 06:12:32 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Qian", "Xin", ""], ["Zhong", "Ziyi", ""], ["Zhou", "Jieli", ""]]}, {"id": "1805.02400", "submitter": "Mika Juuti Mr", "authors": "Mika Juuti, Bo Sun, Tatsuya Mori, and N. Asokan", "title": "Stay On-Topic: Generating Context-specific Fake Restaurant Reviews", "comments": "21 pages, 5 figures, 6 tables. Accepted for publication in the\n  European Symposium on Research in Computer Security (ESORICS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically generated fake restaurant reviews are a threat to online review\nsystems. Recent research has shown that users have difficulties in detecting\nmachine-generated fake reviews hiding among real restaurant reviews. The method\nused in this work (char-LSTM ) has one drawback: it has difficulties staying in\ncontext, i.e. when it generates a review for specific target entity, the\nresulting review may contain phrases that are unrelated to the target, thus\nincreasing its detectability. In this work, we present and evaluate a more\nsophisticated technique based on neural machine translation (NMT) with which we\ncan generate reviews that stay on-topic. We test multiple variants of our\ntechnique using native English speakers on Amazon Mechanical Turk. We\ndemonstrate that reviews generated by the best variant have almost optimal\nundetectability (class-averaged F-score 47%). We conduct a user study with\nskeptical users and show that our method evades detection more frequently\ncompared to the state-of-the-art (average evasion 3.2/4 vs 1.5/4) with\nstatistical significance, at level {\\alpha} = 1% (Section 4.3). We develop very\neffective detection tools and reach average F-score of 97% in classifying\nthese. Although fake reviews are very effective in fooling people, effective\nautomatic detection is still feasible.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 08:37:04 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 14:46:09 GMT"}, {"version": "v3", "created": "Wed, 9 May 2018 06:44:38 GMT"}, {"version": "v4", "created": "Thu, 28 Jun 2018 07:55:31 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Juuti", "Mika", ""], ["Sun", "Bo", ""], ["Mori", "Tatsuya", ""], ["Asokan", "N.", ""]]}, {"id": "1805.02408", "submitter": "Shu Guo", "authors": "Boyang Ding, Quan Wang, Bin Wang, Li Guo", "title": "Improving Knowledge Graph Embedding Using Simple Constraints", "comments": "To appear in ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding knowledge graphs (KGs) into continuous vector spaces is a focus of\ncurrent research. Early works performed this task via simple models developed\nover KG triples. Recent attempts focused on either designing more complicated\ntriple scoring models, or incorporating extra information beyond triples. This\npaper, by contrast, investigates the potential of using very simple constraints\nto improve KG embedding. We examine non-negativity constraints on entity\nrepresentations and approximate entailment constraints on relation\nrepresentations. The former help to learn compact and interpretable\nrepresentations for entities. The latter further encode regularities of logical\nentailment between relations into their distributed representations. These\nconstraints impose prior beliefs upon the structure of the embedding space,\nwithout negative impacts on efficiency or scalability. Evaluation on WordNet,\nFreebase, and DBpedia shows that our approach is simple yet surprisingly\neffective, significantly and consistently outperforming competitive baselines.\nThe constraints imposed indeed improve model interpretability, leading to a\nsubstantially increased structuring of the embedding space. Code and data are\navailable at https://github.com/iieir-km/ComplEx-NNE_AER.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 09:03:14 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 03:30:46 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Ding", "Boyang", ""], ["Wang", "Quan", ""], ["Wang", "Bin", ""], ["Guo", "Li", ""]]}, {"id": "1805.02442", "submitter": "Vered Shwartz", "authors": "Vered Shwartz and Ido Dagan", "title": "Paraphrase to Explicate: Revealing Implicit Noun-Compound Relations", "comments": "Long paper at ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Revealing the implicit semantic relation between the constituents of a\nnoun-compound is important for many NLP applications. It has been addressed in\nthe literature either as a classification task to a set of pre-defined\nrelations or by producing free text paraphrases explicating the relations. Most\nexisting paraphrasing methods lack the ability to generalize, and have a hard\ntime interpreting infrequent or new noun-compounds. We propose a neural model\nthat generalizes better by representing paraphrases in a continuous space,\ngeneralizing for both unseen noun-compounds and rare paraphrases. Our model\nhelps improving performance on both the noun-compound paraphrasing and\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 11:14:07 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Shwartz", "Vered", ""], ["Dagan", "Ido", ""]]}, {"id": "1805.02473", "submitter": "Linfeng Song", "authors": "Linfeng Song, Yue Zhang, Zhiguo Wang and Daniel Gildea", "title": "A Graph-to-Sequence Model for AMR-to-Text Generation", "comments": "ACL 2018 camera-ready, Proceedings of ACL 2018 with updated\n  performance", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of AMR-to-text generation is to recover a text representing the\nsame meaning as an input AMR graph. The current state-of-the-art method uses a\nsequence-to-sequence model, leveraging LSTM for encoding a linearized AMR\nstructure. Although being able to model non-local semantic information, a\nsequence LSTM can lose information from the AMR graph structure, and thus faces\nchallenges with large graphs, which result in long sequences. We introduce a\nneural graph-to-sequence model, using a novel LSTM structure for directly\nencoding graph-level semantics. On a standard benchmark, our model shows\nsuperior results to existing methods in the literature.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 12:31:27 GMT"}, {"version": "v2", "created": "Sat, 12 May 2018 02:55:44 GMT"}, {"version": "v3", "created": "Mon, 27 Aug 2018 20:44:03 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Song", "Linfeng", ""], ["Zhang", "Yue", ""], ["Wang", "Zhiguo", ""], ["Gildea", "Daniel", ""]]}, {"id": "1805.02474", "submitter": "Linfeng Song", "authors": "Yue Zhang, Qi Liu and Linfeng Song", "title": "Sentence-State LSTM for Text Representation", "comments": "ACL 18 camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bi-directional LSTMs are a powerful tool for text representation. On the\nother hand, they have been shown to suffer various limitations due to their\nsequential nature. We investigate an alternative LSTM structure for encoding\ntext, which consists of a parallel state for each word. Recurrent steps are\nused to perform local and global information exchange between words\nsimultaneously, rather than incremental reading of a sequence of words. Results\non various classification and sequence labelling benchmarks show that the\nproposed model has strong representation power, giving highly competitive\nperformances compared to stacked BiLSTM models with similar parameter numbers.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 12:36:54 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Zhang", "Yue", ""], ["Liu", "Qi", ""], ["Song", "Linfeng", ""]]}, {"id": "1805.02823", "submitter": "Shivashankar Subramanian", "authors": "Shivashankar Subramanian, Trevor Cohn, Timothy Baldwin", "title": "Hierarchical Structured Model for Fine-to-coarse Manifesto Text Analysis", "comments": "NAACL 2018 (camera ready pre-print)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Election manifestos document the intentions, motives, and views of political\nparties. They are often used for analysing a party's fine-grained position on a\nparticular issue, as well as for coarse-grained positioning of a party on the\nleft--right spectrum. In this paper we propose a two-stage model for\nautomatically performing both levels of analysis over manifestos. In the first\nstep we employ a hierarchical multi-task structured deep model to predict fine-\nand coarse-grained positions, and in the second step we perform post-hoc\ncalibration of coarse-grained positions using probabilistic soft logic. We\nempirically show that the proposed model outperforms state-of-art approaches at\nboth granularities using manifestos from twelve countries, written in ten\ndifferent languages.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 04:05:54 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Subramanian", "Shivashankar", ""], ["Cohn", "Trevor", ""], ["Baldwin", "Timothy", ""]]}, {"id": "1805.02856", "submitter": "Yi Tay", "authors": "Yi Tay, Luu Anh Tuan, Siu Cheung Hui, Jian Su", "title": "Reasoning with Sarcasm by Reading In-between", "comments": "Accepted to ACL2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sarcasm is a sophisticated speech act which commonly manifests on social\ncommunities such as Twitter and Reddit. The prevalence of sarcasm on the social\nweb is highly disruptive to opinion mining systems due to not only its tendency\nof polarity flipping but also usage of figurative language. Sarcasm commonly\nmanifests with a contrastive theme either between positive-negative sentiments\nor between literal-figurative scenarios. In this paper, we revisit the notion\nof modeling contrast in order to reason with sarcasm. More specifically, we\npropose an attention-based neural model that looks in-between instead of\nacross, enabling it to explicitly model contrast and incongruity. We conduct\nextensive experiments on six benchmark datasets from Twitter, Reddit and the\nInternet Argument Corpus. Our proposed model not only achieves state-of-the-art\nperformance on all datasets but also enjoys improved interpretability.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 06:46:03 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Tay", "Yi", ""], ["Tuan", "Luu Anh", ""], ["Hui", "Siu Cheung", ""], ["Su", "Jian", ""]]}, {"id": "1805.02867", "submitter": "Maxim Milakov", "authors": "Maxim Milakov (NVIDIA), Natalia Gimelshein (NVIDIA)", "title": "Online normalizer calculation for softmax", "comments": "1) Added link to the benchmark code, 2) Benchmarked Safe Softmax +\n  Top-K fused and attributed part of 5x explicitly to fusion in sections 5.2\n  and 6, 3) Stylistic changes, 4) Minor clarifications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Softmax function is ubiquitous in machine learning, multiple previous\nworks suggested faster alternatives for it. In this paper we propose a way to\ncompute classical Softmax with fewer memory accesses and hypothesize that this\nreduction in memory accesses should improve Softmax performance on actual\nhardware. The benchmarks confirm this hypothesis: Softmax accelerates by up to\n1.3x and Softmax+TopK combined and fused by up to 5x.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 07:34:17 GMT"}, {"version": "v2", "created": "Sat, 28 Jul 2018 06:51:27 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Milakov", "Maxim", "", "NVIDIA"], ["Gimelshein", "Natalia", "", "NVIDIA"]]}, {"id": "1805.02914", "submitter": "Xiaowei Tong", "authors": "Xiaowei Tong, Zhenxin Fu, Mingyue Shang, Dongyan Zhao, Rui Yan", "title": "One \"Ruler\" for All Languages: Multi-Lingual Dialogue Evaluation with\n  Adversarial Multi-Task Learning", "comments": "To appear in IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic evaluating the performance of Open-domain dialogue system is a\nchallenging problem. Recent work in neural network-based metrics has shown\npromising opportunities for automatic dialogue evaluation. However, existing\nmethods mainly focus on monolingual evaluation, in which the trained metric is\nnot flexible enough to transfer across different languages. To address this\nissue, we propose an adversarial multi-task neural metric (ADVMT) for\nmulti-lingual dialogue evaluation, with shared feature extraction across\nlanguages. We evaluate the proposed model in two different languages.\nExperiments show that the adversarial multi-task neural metric achieves a high\ncorrelation with human annotation, which yields better performance than\nmonolingual ones and various existing metrics.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 09:24:32 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Tong", "Xiaowei", ""], ["Fu", "Zhenxin", ""], ["Shang", "Mingyue", ""], ["Zhao", "Dongyan", ""], ["Yan", "Rui", ""]]}, {"id": "1805.02917", "submitter": "Motoki Sato", "authors": "Motoki Sato, Jun Suzuki, Hiroyuki Shindo, Yuji Matsumoto", "title": "Interpretable Adversarial Perturbation in Input Embedding Space for Text", "comments": "8 pages, 4 figures", "journal-ref": "IJCAI-ECAI-2018", "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following great success in the image processing field, the idea of\nadversarial training has been applied to tasks in the natural language\nprocessing (NLP) field. One promising approach directly applies adversarial\ntraining developed in the image processing field to the input word embedding\nspace instead of the discrete input space of texts. However, this approach\nabandons such interpretability as generating adversarial texts to significantly\nimprove the performance of NLP tasks. This paper restores interpretability to\nsuch methods by restricting the directions of perturbations toward the existing\nwords in the input embedding space. As a result, we can straightforwardly\nreconstruct each input with perturbations to an actual text by considering the\nperturbations to be the replacement of words in the sentence while maintaining\nor even improving the task performance.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 09:27:46 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Sato", "Motoki", ""], ["Suzuki", "Jun", ""], ["Shindo", "Hiroyuki", ""], ["Matsumoto", "Yuji", ""]]}, {"id": "1805.02924", "submitter": "Helen L Bear", "authors": "Kwanchiva Thangthai, Helen L Bear and Richard Harvey", "title": "Comparing phonemes and visemes with DNN-based lipreading", "comments": null, "journal-ref": "BMVC Lipreading Workshop 2017", "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.SD eess.AS eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is debate if phoneme or viseme units are the most effective for a\nlipreading system. Some studies use phoneme units even though phonemes describe\nunique short sounds; other studies tried to improve lipreading accuracy by\nfocusing on visemes with varying results. We compare the performance of a\nlipreading system by modeling visual speech using either 13 viseme or 38\nphoneme units. We report the accuracy of our system at both word and unit\nlevels. The evaluation task is large vocabulary continuous speech using the\nTCD-TIMIT corpus. We complete our visual speech modeling via hybrid DNN-HMMs\nand our visual speech decoder is a Weighted Finite-State Transducer (WFST). We\nuse DCT and Eigenlips as a representation of mouth ROI image. The phoneme\nlipreading system word accuracy outperforms the viseme based system word\naccuracy. However, the phoneme system achieved lower accuracy at the unit level\nwhich shows the importance of the dictionary for decoding classification\noutputs into words.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 09:51:34 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Thangthai", "Kwanchiva", ""], ["Bear", "Helen L", ""], ["Harvey", "Richard", ""]]}, {"id": "1805.02937", "submitter": "Jinyi Zhang", "authors": "Jinyi Zhang and Tadahiro Matsumoto", "title": "Improving Character-level Japanese-Chinese Neural Machine Translation\n  with Radicals as an Additional Input Feature", "comments": "4 pages,1 figure. IALP2017 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Neural Machine Translation (NMT) has been proven to get\nimpressive results. While some additional linguistic features of input words\nimprove word-level NMT, any additional character features have not been used to\nimprove character-level NMT so far. In this paper, we show that the radicals of\nChinese characters (or kanji), as a character feature information, can be\neasily provide further improvements in the character-level NMT. In experiments\non WAT2016 Japanese-Chinese scientific paper excerpt corpus (ASPEC-JP), we find\nthat the proposed method improves the translation quality according to two\naspects: perplexity and BLEU. The character-level NMT with the radical input\nfeature's model got a state-of-the-art result of 40.61 BLEU points in the test\nset, which is an improvement of about 8.6 BLEU points over the best system on\nthe WAT2016 Japanese-to-Chinese translation subtask with ASPEC-JP. The\nimprovements over the character-level NMT with no additional input feature are\nup to about 1.5 and 1.4 BLEU points in the development-test set and the test\nset of the corpus, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 10:39:45 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Zhang", "Jinyi", ""], ["Matsumoto", "Tadahiro", ""]]}, {"id": "1805.02958", "submitter": "Akihiro Kato", "authors": "Akihiro Kato and Tomi Kinnunen", "title": "A Regression Model of Recurrent Deep Neural Networks for Noise Robust\n  Estimation of the Fundamental Frequency Contour of Speech", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fundamental frequency (F0) contour of speech is a key aspect to represent\nspeech prosody that finds use in speech and spoken language analysis such as\nvoice conversion and speech synthesis as well as speaker and language\nidentification. This work proposes new methods to estimate the F0 contour of\nspeech using deep neural networks (DNNs) and recurrent neural networks (RNNs).\nThey are trained using supervised learning with the ground truth of F0\ncontours. The latest prior research addresses this problem first as a\nframe-by-frame-classification problem followed by sequence tracking using deep\nneural network hidden Markov model (DNN-HMM) hybrid architecture. This study,\nhowever, tackles the problem as a regression problem instead, in order to\nobtain F0 contours with higher frequency resolution from clean and noisy\nspeech. Experiments using PTDB-TUG corpus contaminated with additive noise\n(NOISEX-92) show the proposed method improves gross pitch error (GPE) by more\nthan 25 % at signal-to-noise ratios (SNRs) between -10 dB and +10 dB as\ncompared with one of the most noise-robust F0 trackers, PEFAC. Furthermore, the\nperformance on fine pitch error (FPE) is improved by approximately 20 % against\na state-of-the-art DNN-HMM-based approach.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 11:54:06 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Kato", "Akihiro", ""], ["Kinnunen", "Tomi", ""]]}, {"id": "1805.03122", "submitter": "Rob van der Goot", "authors": "Rob van der Goot, Nikola Ljube\\v{s}i\\'c, Ian Matroos, Malvina Nissim,\n  Barbara Plank", "title": "Bleaching Text: Abstract Features for Cross-lingual Gender Prediction", "comments": "Proceedings of the 56th Annual Meeting of the Association for\n  Computational Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gender prediction has typically focused on lexical and social network\nfeatures, yielding good performance, but making systems highly language-,\ntopic-, and platform-dependent. Cross-lingual embeddings circumvent some of\nthese limitations, but capture gender-specific style less. We propose an\nalternative: bleaching text, i.e., transforming lexical strings into more\nabstract features. This study provides evidence that such features allow for\nbetter transfer across languages. Moreover, we present a first study on the\nability of humans to perform cross-lingual gender prediction. We find that\nhuman predictive power proves similar to that of our bleached models, and both\nperform better than lexical models.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 15:50:32 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["van der Goot", "Rob", ""], ["Ljube\u0161i\u0107", "Nikola", ""], ["Matroos", "Ian", ""], ["Nissim", "Malvina", ""], ["Plank", "Barbara", ""]]}, {"id": "1805.03162", "submitter": "Tong Niu", "authors": "Tong Niu, Mohit Bansal", "title": "Polite Dialogue Generation Without Parallel Data", "comments": "To Appear in TACL Journal (16 pages) (first submission cycle: Oct1\n  2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stylistic dialogue response generation, with valuable applications in\npersonality-based conversational agents, is a challenging task because the\nresponse needs to be fluent, contextually-relevant, as well as\nparalinguistically accurate. Moreover, parallel datasets for\nregular-to-stylistic pairs are usually unavailable. We present three\nweakly-supervised models that can generate diverse polite (or rude) dialogue\nresponses without parallel data. Our late fusion model (Fusion) merges the\ndecoder of an encoder-attention-decoder dialogue model with a language model\ntrained on stand-alone polite utterances. Our label-fine-tuning (LFT) model\nprepends to each source sequence a politeness-score scaled label (predicted by\nour state-of-the-art politeness classifier) during training, and at test time\nis able to generate polite, neutral, and rude responses by simply scaling the\nlabel embedding by the corresponding score. Our reinforcement learning model\n(Polite-RL) encourages politeness generation by assigning rewards proportional\nto the politeness classifier score of the sampled response. We also present two\nretrieval-based polite dialogue model baselines. Human evaluation validates\nthat while the Fusion and the retrieval-based models achieve politeness with\npoorer context-relevance, the LFT and Polite-RL models can produce\nsignificantly more polite responses without sacrificing dialogue quality.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 16:56:15 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Niu", "Tong", ""], ["Bansal", "Mohit", ""]]}, {"id": "1805.03228", "submitter": "Ivan Vuli\\'c", "authors": "Ivan Vuli\\'c, Goran Glava\\v{s}, Nikola Mrk\\v{s}i\\'c, Anna Korhonen", "title": "Post-Specialisation: Retrofitting Vectors of Words Unseen in Lexical\n  Resources", "comments": "NAACL 2018 (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word vector specialisation (also known as retrofitting) is a portable,\nlight-weight approach to fine-tuning arbitrary distributional word vector\nspaces by injecting external knowledge from rich lexical resources such as\nWordNet. By design, these post-processing methods only update the vectors of\nwords occurring in external lexicons, leaving the representations of all unseen\nwords intact. In this paper, we show that constraint-driven vector space\nspecialisation can be extended to unseen words. We propose a novel\npost-specialisation method that: a) preserves the useful linguistic knowledge\nfor seen words; while b) propagating this external signal to unseen words in\norder to improve their vector representations as well. Our post-specialisation\napproach explicits a non-linear specialisation function in the form of a deep\nneural network by learning to predict specialised vectors from their original\ndistributional counterparts. The learned function is then used to specialise\nvectors of unseen words. This approach, applicable to any post-processing\nmodel, yields considerable gains over the initial specialisation models both in\nintrinsic word similarity tasks, and in two downstream tasks: dialogue state\ntracking and lexical text simplification. The positive effects persist across\nthree languages, demonstrating the importance of specialising the full\nvocabulary of distributional word vector spaces.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 18:46:24 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Vuli\u0107", "Ivan", ""], ["Glava\u0161", "Goran", ""], ["Mrk\u0161i\u0107", "Nikola", ""], ["Korhonen", "Anna", ""]]}, {"id": "1805.03257", "submitter": "Jiaping Zhang", "authors": "Jiaping Zhang, Tiancheng Zhao and Zhou Yu", "title": "Multimodal Hierarchical Reinforcement Learning Policy for Task-Oriented\n  Visual Dialog", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Creating an intelligent conversational system that understands vision and\nlanguage is one of the ultimate goals in Artificial Intelligence\n(AI)~\\cite{winograd1972understanding}. Extensive research has focused on\nvision-to-language generation, however, limited research has touched on\ncombining these two modalities in a goal-driven dialog context. We propose a\nmultimodal hierarchical reinforcement learning framework that dynamically\nintegrates vision and language for task-oriented visual dialog. The framework\njointly learns the multimodal dialog state representation and the hierarchical\ndialog policy to improve both dialog task success and efficiency. We also\npropose a new technique, state adaptation, to integrate context awareness in\nthe dialog state representation. We evaluate the proposed framework and the\nstate adaptation technique in an image guessing game and achieve promising\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 19:54:47 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Zhang", "Jiaping", ""], ["Zhao", "Tiancheng", ""], ["Yu", "Zhou", ""]]}, {"id": "1805.03294", "submitter": "Albert Zeyer", "authors": "Albert Zeyer, and Kazuki Irie, and Ralf Schl\\\"uter, and Hermann Ney", "title": "Improved training of end-to-end attention models for speech recognition", "comments": "submitted to Interspeech 2018", "journal-ref": null, "doi": "10.21437/Interspeech.2018-1616", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence attention-based models on subword units allow simple\nopen-vocabulary end-to-end speech recognition. In this work, we show that such\nmodels can achieve competitive results on the Switchboard 300h and LibriSpeech\n1000h tasks. In particular, we report the state-of-the-art word error rates\n(WER) of 3.54% on the dev-clean and 3.82% on the test-clean evaluation subsets\nof LibriSpeech. We introduce a new pretraining scheme by starting with a high\ntime reduction factor and lowering it during training, which is crucial both\nfor convergence and final performance. In some experiments, we also use an\nauxiliary CTC loss function to help the convergence. In addition, we train long\nshort-term memory (LSTM) language models on subword units. By shallow fusion,\nwe report up to 27% relative improvements in WER over the attention baseline\nwithout a language model.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 21:27:04 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Zeyer", "Albert", ""], ["Irie", "Kazuki", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "1805.03308", "submitter": "Nicolas Pr\\\"ollochs", "authors": "Stefan Feuerriegel, Nicolas Pr\\\"ollochs", "title": "Investor Reaction to Financial Disclosures Across Topics: An Application\n  of Latent Dirichlet Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a holistic study of how stock prices vary in their\nresponse to financial disclosures across different topics. Thereby, we\nspecifically shed light into the extensive amount of filings for which no a\npriori categorization of their content exists. For this purpose, we utilize an\napproach from data mining - namely, latent Dirichlet allocation - as a means of\ntopic modeling. This technique facilitates our task of automatically\ncategorizing, ex ante, the content of more than 70,000 regulatory 8-K filings\nfrom U.S. companies. We then evaluate the subsequent stock market reaction. Our\nempirical evidence suggests a considerable discrepancy among various types of\nnews stories in terms of their relevance and impact on financial markets. For\ninstance, we find a statistically significant abnormal return in response to\nearnings results and credit rating, but also for disclosures regarding business\nstrategy, the health sector, as well as mergers and acquisitions. Our results\nyield findings that benefit managers, investors and policy-makers by indicating\nhow regulatory filings should be structured and the topics most likely to\nprecede changes in stock valuations.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 22:22:26 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Feuerriegel", "Stefan", ""], ["Pr\u00f6llochs", "Nicolas", ""]]}, {"id": "1805.03322", "submitter": "Panayiotis Georgiou", "authors": "Prashanth Gurunath Shivakumar and Panayiotis Georgiou", "title": "Transfer Learning from Adult to Children for Speech Recognition:\n  Evaluation, Analysis and Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Children speech recognition is challenging mainly due to the inherent high\nvariability in children's physical and articulatory characteristics and\nexpressions. This variability manifests in both acoustic constructs and\nlinguistic usage due to the rapidly changing developmental stage in children's\nlife. Part of the challenge is due to the lack of large amounts of available\nchildren speech data for efficient modeling. This work attempts to address the\nkey challenges using transfer learning from adult's models to children's models\nin a Deep Neural Network (DNN) framework for children's Automatic Speech\nRecognition (ASR) task evaluating on multiple children's speech corpora with a\nlarge vocabulary. The paper presents a systematic and an extensive analysis of\nthe proposed transfer learning technique considering the key factors affecting\nchildren's speech recognition from prior literature. Evaluations are presented\non (i) comparisons of earlier GMM-HMM and the newer DNN Models, (ii)\neffectiveness of standard adaptation techniques versus transfer learning, (iii)\nvarious adaptation configurations in tackling the variabilities present in\nchildren speech, in terms of (a) acoustic spectral variability, and (b)\npronunciation variability and linguistic constraints. Our Analysis spans over\n(i) number of DNN model parameters (for adaptation), (ii) amount of adaptation\ndata, (iii) ages of children, (iv) age dependent-independent adaptation.\nFinally, we provide Recommendations on (i) the favorable strategies over\nvarious aforementioned - analyzed parameters, and (ii) potential future\nresearch directions and relevant challenges/problems persisting in DNN based\nASR for children's speech.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 23:59:04 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Shivakumar", "Prashanth Gurunath", ""], ["Georgiou", "Panayiotis", ""]]}, {"id": "1805.03330", "submitter": "Nikola Nikolov", "authors": "Nikola I. Nikolov, Yuhuang Hu, Mi Xue Tan, Richard H.R. Hahnloser", "title": "Character-level Chinese-English Translation through ASCII Encoding", "comments": "7 pages, 3 figures, 3rd Conference on Machine Translation (WMT18),\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Character-level Neural Machine Translation (NMT) models have recently\nachieved impressive results on many language pairs. They mainly do well for\nIndo-European language pairs, where the languages share the same writing\nsystem. However, for translating between Chinese and English, the gap between\nthe two different writing systems poses a major challenge because of a lack of\nsystematic correspondence between the individual linguistic units. In this\npaper, we enable character-level NMT for Chinese, by breaking down Chinese\ncharacters into linguistic units similar to that of Indo-European languages. We\nuse the Wubi encoding scheme, which preserves the original shape and semantic\ninformation of the characters, while also being reversible. We show promising\nresults from training Wubi-based models on the character- and subword-level\nwith recurrent as well as convolutional models.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 00:44:59 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 11:49:48 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Nikolov", "Nikola I.", ""], ["Hu", "Yuhuang", ""], ["Tan", "Mi Xue", ""], ["Hahnloser", "Richard H. R.", ""]]}, {"id": "1805.03366", "submitter": "Kai-Wei Chang", "authors": "Chao Jiang, Hsiang-Fu Yu, Cho-Jui Hsieh, Kai-Wei Chang", "title": "LearningWord Embeddings for Low-resource Languages by PU Learning", "comments": "Published in NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding is a key component in many downstream applications in\nprocessing natural languages. Existing approaches often assume the existence of\na large collection of text for learning effective word embedding. However, such\na corpus may not be available for some low-resource languages. In this paper,\nwe study how to effectively learn a word embedding model on a corpus with only\na few million tokens. In such a situation, the co-occurrence matrix is sparse\nas the co-occurrences of many word pairs are unobserved. In contrast to\nexisting approaches often only sample a few unobserved word pairs as negative\nsamples, we argue that the zero entries in the co-occurrence matrix also\nprovide valuable information. We then design a Positive-Unlabeled Learning\n(PU-Learning) approach to factorize the co-occurrence matrix and validate the\nproposed approaches in four different languages.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 04:05:37 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Jiang", "Chao", ""], ["Yu", "Hsiang-Fu", ""], ["Hsieh", "Cho-Jui", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "1805.03379", "submitter": "Manqing Dong", "authors": "Manqing Dong, Lina Yao, Xianzhi Wang, Boualem Benatallah, Chaoran\n  Huang, Xiaodong Ning", "title": "Opinion Fraud Detection via Neural Autoencoder Decision Forest", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online reviews play an important role in influencing buyers' daily purchase\ndecisions. However, fake and meaningless reviews, which cannot reflect users'\ngenuine purchase experience and opinions, widely exist on the Web and pose\ngreat challenges for users to make right choices. Therefore,it is desirable to\nbuild a fair model that evaluates the quality of products by distinguishing\nspamming reviews. We present an end-to-end trainable unified model to leverage\nthe appealing properties from Autoencoder and random forest. A stochastic\ndecision tree model is implemented to guide the global parameter learning\nprocess. Extensive experiments were conducted on a large Amazon review dataset.\nThe proposed model consistently outperforms a series of compared methods.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 05:44:19 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Dong", "Manqing", ""], ["Yao", "Lina", ""], ["Wang", "Xianzhi", ""], ["Benatallah", "Boualem", ""], ["Huang", "Chaoran", ""], ["Ning", "Xiaodong", ""]]}, {"id": "1805.03435", "submitter": "Dan Busbridge", "authors": "Vitalii Zhelezniak, Dan Busbridge, April Shen, Samuel L. Smith and\n  Nils Y. Hammerla", "title": "Decoding Decoders: Finding Optimal Representation Spaces for\n  Unsupervised Similarity Tasks", "comments": "ICLR 2018 Workshop Track, 15 pages, 3 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental evidence indicates that simple models outperform complex deep\nnetworks on many unsupervised similarity tasks. We provide a simple yet\nrigorous explanation for this behaviour by introducing the concept of an\noptimal representation space, in which semantically close symbols are mapped to\nrepresentations that are close under a similarity measure induced by the\nmodel's objective function. In addition, we present a straightforward procedure\nthat, without any retraining or architectural modifications, allows deep\nrecurrent models to perform equally well (and sometimes better) when compared\nto shallow models. To validate our analysis, we conduct a set of consistent\nempirical evaluations and introduce several new sentence embedding models in\nthe process. Even though this work is presented within the context of natural\nlanguage processing, the insights are readily applicable to other domains that\nrely on distributed representations for transfer tasks.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 09:41:51 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Zhelezniak", "Vitalii", ""], ["Busbridge", "Dan", ""], ["Shen", "April", ""], ["Smith", "Samuel L.", ""], ["Hammerla", "Nils Y.", ""]]}, {"id": "1805.03616", "submitter": "Yunzhe Tao", "authors": "Li Wang, Junlin Yao, Yunzhe Tao, Li Zhong, Wei Liu, Qiang Du", "title": "A Reinforced Topic-Aware Convolutional Sequence-to-Sequence Model for\n  Abstractive Text Summarization", "comments": "International Joint Conference on Artificial Intelligence and\n  European Conference on Artificial Intelligence (IJCAI-ECAI), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a deep learning approach to tackle the automatic\nsummarization tasks by incorporating topic information into the convolutional\nsequence-to-sequence (ConvS2S) model and using self-critical sequence training\n(SCST) for optimization. Through jointly attending to topics and word-level\nalignment, our approach can improve coherence, diversity, and informativeness\nof generated summaries via a biased probability generation mechanism. On the\nother hand, reinforcement training, like SCST, directly optimizes the proposed\nmodel with respect to the non-differentiable metric ROUGE, which also avoids\nthe exposure bias during inference. We carry out the experimental evaluation\nwith state-of-the-art methods over the Gigaword, DUC-2004, and LCSTS datasets.\nThe empirical results demonstrate the superiority of our proposed method in the\nabstractive summarization.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 16:56:41 GMT"}, {"version": "v2", "created": "Sat, 2 Jun 2018 14:51:32 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 06:42:49 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Wang", "Li", ""], ["Yao", "Junlin", ""], ["Tao", "Yunzhe", ""], ["Zhong", "Li", ""], ["Liu", "Wei", ""], ["Du", "Qiang", ""]]}, {"id": "1805.03620", "submitter": "Sebastian Ruder", "authors": "Anders S{\\o}gaard, Sebastian Ruder, Ivan Vuli\\'c", "title": "On the Limitations of Unsupervised Bilingual Dictionary Induction", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised machine translation---i.e., not assuming any cross-lingual\nsupervision signal, whether a dictionary, translations, or comparable\ncorpora---seems impossible, but nevertheless, Lample et al. (2018) recently\nproposed a fully unsupervised machine translation (MT) model. The model relies\nheavily on an adversarial, unsupervised alignment of word embedding spaces for\nbilingual dictionary induction (Conneau et al., 2018), which we examine here.\nOur results identify the limitations of current unsupervised MT: unsupervised\nbilingual dictionary induction performs much worse on morphologically rich\nlanguages that are not dependent marking, when monolingual corpora from\ndifferent domains or different embedding algorithms are used. We show that a\nsimple trick, exploiting a weak supervision signal from identical words,\nenables more robust induction, and establish a near-perfect correlation between\nunsupervised bilingual dictionary induction performance and a previously\nunexplored graph similarity metric.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 17:08:03 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["S\u00f8gaard", "Anders", ""], ["Ruder", "Sebastian", ""], ["Vuli\u0107", "Ivan", ""]]}, {"id": "1805.03642", "submitter": "Yanshuai Cao", "authors": "Avishek Joey Bose, Huan Ling, Yanshuai Cao", "title": "Adversarial Contrastive Estimation", "comments": "Association for Computational Linguistics, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning by contrasting positive and negative samples is a general strategy\nadopted by many methods. Noise contrastive estimation (NCE) for word embeddings\nand translating embeddings for knowledge graphs are examples in NLP employing\nthis approach. In this work, we view contrastive learning as an abstraction of\nall such methods and augment the negative sampler into a mixture distribution\ncontaining an adversarially learned sampler. The resulting adaptive sampler\nfinds harder negative examples, which forces the main model to learn a better\nrepresentation of the data. We evaluate our proposal on learning word\nembeddings, order embeddings and knowledge graph embeddings and observe both\nfaster convergence and improved results on multiple metrics.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 04:06:30 GMT"}, {"version": "v2", "created": "Fri, 11 May 2018 20:20:39 GMT"}, {"version": "v3", "created": "Thu, 2 Aug 2018 20:34:14 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Bose", "Avishek Joey", ""], ["Ling", "Huan", ""], ["Cao", "Yanshuai", ""]]}, {"id": "1805.03645", "submitter": "Taraka Rama Kasicheyanula", "authors": "Taraka Rama", "title": "Three tree priors and five datasets: A study of the effect of tree\n  priors in Indo-European phylogenetics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The age of the root of the Indo-European language family has received much\nattention since the application of Bayesian phylogenetic methods by Gray and\nAtkinson(2003). The root age of the Indo-European family has tended to decrease\nfrom an age that supported the Anatolian origin hypothesis to an age that\nsupports the Steppe origin hypothesis with the application of new models (Chang\net al., 2015). However, none of the published work in the Indo-European\nphylogenetics studied the effect of tree priors on phylogenetic analyses of the\nIndo-European family. In this paper, I intend to fill this gap by exploring the\neffect of tree priors on different aspects of the Indo-European family's\nphylogenetic inference. I apply three tree priors---Uniform, Fossilized\nBirth-Death (FBD), and Coalescent---to five publicly available datasets of the\nIndo-European language family. I evaluate the posterior distribution of the\ntrees from the Bayesian analysis using Bayes Factor, and find that there is\nsupport for the Steppe origin hypothesis in the case of two tree priors. I\nreport the median and 95% highest posterior density (HPD) interval of the root\nages for all the three tree priors. A model comparison suggested that either\nUniform prior or FBD prior is more suitable than the Coalescent prior to the\ndatasets belonging to the Indo-European language family.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 07:56:06 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Rama", "Taraka", ""]]}, {"id": "1805.03668", "submitter": "Lianhui Qin", "authors": "Lianhui Qin, Lemao Liu, Victoria Bi, Yan Wang, Xiaojiang Liu, Zhiting\n  Hu, Hai Zhao, Shuming Shi", "title": "Automatic Article Commenting: the Task and Dataset", "comments": "ACL2018; with supplements; Dataset link available in the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comments of online articles provide extended views and improve user\nengagement. Automatically making comments thus become a valuable functionality\nfor online forums, intelligent chatbots, etc. This paper proposes the new task\nof automatic article commenting, and introduces a large-scale Chinese dataset\nwith millions of real comments and a human-annotated subset characterizing the\ncomments' varying quality. Incorporating the human bias of comment quality, we\nfurther develop automatic metrics that generalize a broad set of popular\nreference-based metrics and exhibit greatly improved correlations with human\nevaluations.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 18:00:15 GMT"}, {"version": "v2", "created": "Fri, 11 May 2018 00:44:02 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Qin", "Lianhui", ""], ["Liu", "Lemao", ""], ["Bi", "Victoria", ""], ["Wang", "Yan", ""], ["Liu", "Xiaojiang", ""], ["Hu", "Zhiting", ""], ["Zhao", "Hai", ""], ["Shi", "Shuming", ""]]}, {"id": "1805.03687", "submitter": "Abien Fred Agarap", "authors": "Abien Fred Agarap", "title": "Statistical Analysis on E-Commerce Reviews, with Sentiment\n  Classification using Bidirectional Recurrent Neural Network (RNN)", "comments": "21 pages, 29 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Understanding customer sentiments is of paramount importance in marketing\nstrategies today. Not only will it give companies an insight as to how\ncustomers perceive their products and/or services, but it will also give them\nan idea on how to improve their offers. This paper attempts to understand the\ncorrelation of different variables in customer reviews on a women clothing\ne-commerce, and to classify each review whether it recommends the reviewed\nproduct or not and whether it consists of positive, negative, or neutral\nsentiment. To achieve these goals, we employed univariate and multivariate\nanalyses on dataset features except for review titles and review texts, and we\nimplemented a bidirectional recurrent neural network (RNN) with long-short term\nmemory unit (LSTM) for recommendation and sentiment classification. Results\nhave shown that a recommendation is a strong indicator of a positive sentiment\nscore, and vice-versa. On the other hand, ratings in product reviews are fuzzy\nindicators of sentiment scores. We also found out that the bidirectional LSTM\nwas able to reach an F1-score of 0.88 for recommendation classification, and\n0.93 for sentiment classification.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 11:58:20 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 12:10:51 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Agarap", "Abien Fred", ""]]}, {"id": "1805.03710", "submitter": "Alexandre Salle", "authors": "Alexandre Salle and Aline Villavicencio", "title": "Incorporating Subword Information into Matrix Factorization Word\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The positive effect of adding subword information to word embeddings has been\ndemonstrated for predictive models. In this paper we investigate whether\nsimilar benefits can also be derived from incorporating subwords into counting\nmodels. We evaluate the impact of different types of subwords (n-grams and\nunsupervised morphemes), with results confirming the importance of subword\ninformation in learning representations of rare and out-of-vocabulary words.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 19:54:58 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Salle", "Alexandre", ""], ["Villavicencio", "Aline", ""]]}, {"id": "1805.03716", "submitter": "Omer Levy", "authors": "Omer Levy, Kenton Lee, Nicholas FitzGerald, Luke Zettlemoyer", "title": "Long Short-Term Memory as a Dynamically Computed Element-wise Weighted\n  Sum", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LSTMs were introduced to combat vanishing gradients in simple RNNs by\naugmenting them with gated additive recurrent connections. We present an\nalternative view to explain the success of LSTMs: the gates themselves are\nversatile recurrent models that provide more representational power than\npreviously appreciated. We do this by decoupling the LSTM's gates from the\nembedded simple RNN, producing a new class of RNNs where the recurrence\ncomputes an element-wise weighted sum of context-independent functions of the\ninput. Ablations on a range of problems demonstrate that the gating mechanism\nalone performs as well as an LSTM in most settings, strongly suggesting that\nthe gates are doing much more in practice than just alleviating vanishing\ngradients.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 20:05:58 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Levy", "Omer", ""], ["Lee", "Kenton", ""], ["FitzGerald", "Nicholas", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1805.03750", "submitter": "Eva Hasler", "authors": "Eva Hasler, Adri\\`a De Gispert, Gonzalo Iglesias, Bill Byrne", "title": "Neural Machine Translation Decoding with Terminology Constraints", "comments": "Proceedings of NAACL-HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the impressive quality improvements yielded by neural machine\ntranslation (NMT) systems, controlling their translation output to adhere to\nuser-provided terminology constraints remains an open problem. We describe our\napproach to constrained neural decoding based on finite-state machines and\nmulti-stack decoding which supports target-side constraints as well as\nconstraints with corresponding aligned input text spans. We demonstrate the\nperformance of our framework on multiple translation tasks and motivate the\nneed for constrained decoding with attentions as a means of reducing\nmisplacement and duplication when translating user constraints.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 22:47:30 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Hasler", "Eva", ""], ["De Gispert", "Adri\u00e0", ""], ["Iglesias", "Gonzalo", ""], ["Byrne", "Bill", ""]]}, {"id": "1805.03766", "submitter": "Antoine Bosselut", "authors": "Antoine Bosselut, Asli Celikyilmaz, Xiaodong He, Jianfeng Gao, Po-Sen\n  Huang, Yejin Choi", "title": "Discourse-Aware Neural Rewards for Coherent Text Generation", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the use of discourse-aware rewards with\nreinforcement learning to guide a model to generate long, coherent text. In\nparticular, we propose to learn neural rewards to model cross-sentence ordering\nas a means to approximate desired discourse structure. Empirical results\ndemonstrate that a generator trained with the learned reward produces more\ncoherent and less repetitive text than models trained with cross-entropy or\nwith reinforcement learning with commonly used scores as rewards.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 00:51:06 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Bosselut", "Antoine", ""], ["Celikyilmaz", "Asli", ""], ["He", "Xiaodong", ""], ["Gao", "Jianfeng", ""], ["Huang", "Po-Sen", ""], ["Choi", "Yejin", ""]]}, {"id": "1805.03774", "submitter": "Fan Bu", "authors": "Fan Bu", "title": "The Evolution of Popularity and Images of Characters in Marvel Cinematic\n  Universe Fanfictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This analysis proposes a new topic model to study the yearly trends in Marvel\nCinematic Universe fanfictions on three levels: character popularity, character\nimages/topics, and vocabulary pattern of topics. It is found that character\nappearances in fanfictions have become more diverse over the years thanks to\nconstant introduction of new characters in feature films, and in the case of\nCaptain America, multi-dimensional character development is well-received by\nthe fanfiction world.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 01:27:58 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Bu", "Fan", ""]]}, {"id": "1805.03784", "submitter": "Kevin Bowden", "authors": "Kevin K. Bowden, Jiaqi Wu, Shereen Oraby, Amita Misra, and Marilyn\n  Walker", "title": "SlugNERDS: A Named Entity Recognition Tool for Open Domain Dialogue\n  Systems", "comments": "Resources can be found: https://nlds.soe.ucsc.edu/node/56", "journal-ref": "Kevin K. Bowden, Jiaqi Wu, Shereen Oraby, Amita Misra, and Marilyn\n  Walker. SlugNERDS: A Named Entity Recognition Tool for Open Domain Dialogue\n  Systems. Language Resources and Evaluation Conference (LREC), Miyazaki,\n  Japan, 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In dialogue systems, the tasks of named entity recognition (NER) and named\nentity linking (NEL) are vital preprocessing steps for understanding user\nintent, especially in open domain interaction where we cannot rely on\ndomain-specific inference. UCSC's effort as one of the funded teams in the 2017\nAmazon Alexa Prize Contest has yielded Slugbot, an open domain social bot,\naimed at casual conversation. We discovered several challenges specifically\nassociated with both NER and NEL when building Slugbot, such as that the NE\nlabels are too coarse-grained or the entity types are not linked to a useful\nontology. Moreover, we have discovered that traditional approaches do not\nperform well in our context: even systems designed to operate on tweets or\nother social media data do not work well in dialogue systems. In this paper, we\nintroduce Slugbot's Named Entity Recognition for dialogue Systems (SlugNERDS),\na NER and NEL tool which is optimized to address these issues. We describe two\nnew resources that we are building as part of this work: SlugEntityDB and\nSchemaActuator. We believe these resources will be useful for the research\ncommunity.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 02:07:02 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Bowden", "Kevin K.", ""], ["Wu", "Jiaqi", ""], ["Oraby", "Shereen", ""], ["Misra", "Amita", ""], ["Walker", "Marilyn", ""]]}, {"id": "1805.03793", "submitter": "Jialong Han", "authors": "Jialong Han, Yan Song, Wayne Xin Zhao, Shuming Shi, Haisong Zhang", "title": "hyperdoc2vec: Distributed Representations of Hypertext Documents", "comments": "Accepted to ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypertext documents, such as web pages and academic papers, are of great\nimportance in delivering information in our daily life. Although being\neffective on plain documents, conventional text embedding methods suffer from\ninformation loss if directly adapted to hyper-documents. In this paper, we\npropose a general embedding approach for hyper-documents, namely, hyperdoc2vec,\nalong with four criteria characterizing necessary information that\nhyper-document embedding models should preserve. Systematic comparisons are\nconducted between hyperdoc2vec and several competitors on two tasks, i.e.,\npaper classification and citation recommendation, in the academic paper domain.\nAnalyses and experiments both validate the superiority of hyperdoc2vec to other\nmodels w.r.t. the four criteria.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 02:42:03 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Han", "Jialong", ""], ["Song", "Yan", ""], ["Zhao", "Wayne Xin", ""], ["Shi", "Shuming", ""], ["Zhang", "Haisong", ""]]}, {"id": "1805.03801", "submitter": "Bei Shi", "authors": "Bei Shi, Zihao Fu, Lidong Bing and Wai Lam", "title": "Learning Domain-Sensitive and Sentiment-Aware Word Embeddings", "comments": "11 pages, published in ACL2018", "journal-ref": "ACL2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings have been widely used in sentiment classification because of\ntheir efficacy for semantic representations of words. Given reviews from\ndifferent domains, some existing methods for word embeddings exploit sentiment\ninformation, but they cannot produce domain-sensitive embeddings. On the other\nhand, some other existing methods can generate domain-sensitive word\nembeddings, but they cannot distinguish words with similar contexts but\nopposite sentiment polarity. We propose a new method for learning\ndomain-sensitive and sentiment-aware embeddings that simultaneously capture the\ninformation of sentiment semantics and domain sensitivity of individual words.\nOur method can automatically determine and produce domain-common embeddings and\ndomain-specific embeddings. The differentiation of domain-common and\ndomain-specific words enables the advantage of data augmentation of common\nsemantics from multiple domains and capture the varied semantics of specific\nwords from different domains at the same time. Experimental results show that\nour model provides an effective way to learn domain-sensitive and\nsentiment-aware word embeddings which benefit sentiment classification at both\nsentence level and lexicon term level.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 03:39:32 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Shi", "Bei", ""], ["Fu", "Zihao", ""], ["Bing", "Lidong", ""], ["Lam", "Wai", ""]]}, {"id": "1805.03818", "submitter": "Braden Hancock", "authors": "Braden Hancock, Paroma Varma, Stephanie Wang, Martin Bringmann, Percy\n  Liang and Christopher R\\'e", "title": "Training Classifiers with Natural Language Explanations", "comments": "ACL 2018; v4 adds references and link to code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training accurate classifiers requires many labels, but each label provides\nonly limited information (one bit for binary classification). In this work, we\npropose BabbleLabble, a framework for training classifiers in which an\nannotator provides a natural language explanation for each labeling decision. A\nsemantic parser converts these explanations into programmatic labeling\nfunctions that generate noisy labels for an arbitrary amount of unlabeled data,\nwhich is used to train a classifier. On three relation extraction tasks, we\nfind that users are able to train classifiers with comparable F1 scores from\n5-100$\\times$ faster by providing explanations instead of just labels.\nFurthermore, given the inherent imperfection of labeling functions, we find\nthat a simple rule-based semantic parser suffices.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 04:59:59 GMT"}, {"version": "v2", "created": "Sat, 26 May 2018 19:56:07 GMT"}, {"version": "v3", "created": "Sat, 14 Jul 2018 17:10:42 GMT"}, {"version": "v4", "created": "Sat, 25 Aug 2018 23:50:10 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Hancock", "Braden", ""], ["Varma", "Paroma", ""], ["Wang", "Stephanie", ""], ["Bringmann", "Martin", ""], ["Liang", "Percy", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "1805.03830", "submitter": "Varsha Embar", "authors": "Soumya Wadhwa and Varsha Embar and Matthias Grabmair and Eric Nyberg", "title": "Towards Inference-Oriented Reading Comprehension: ParallelQA", "comments": "Accepted at Workshop on New Forms of Generalization in Deep Learning\n  and Natural Language Processing, NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the tendency of end-to-end neural Machine\nReading Comprehension (MRC) models to match shallow patterns rather than\nperform inference-oriented reasoning on RC benchmarks. We aim to test the\nability of these systems to answer questions which focus on referential\ninference. We propose ParallelQA, a strategy to formulate such questions using\nparallel passages. We also demonstrate that existing neural models fail to\ngeneralize well to this setting.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 05:47:46 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Wadhwa", "Soumya", ""], ["Embar", "Varsha", ""], ["Grabmair", "Matthias", ""], ["Nyberg", "Eric", ""]]}, {"id": "1805.03832", "submitter": "Wei Zou", "authors": "Wei Zou, Dongwei Jiang, Shuaijiang Zhao, Xiangang Li", "title": "A comparable study of modeling units for end-to-end Mandarin speech\n  recognition", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-To-End speech recognition have become increasingly popular in mandarin\nspeech recognition and achieved delightful performance.\n  Mandarin is a tonal language which is different from English and requires\nspecial treatment for the acoustic modeling units. There have been several\ndifferent kinds of modeling units for mandarin such as phoneme, syllable and\nChinese character.\n  In this work, we explore two major end-to-end models: connectionist temporal\nclassification (CTC) model and attention based encoder-decoder model for\nmandarin speech recognition. We compare the performance of three different\nscaled modeling units: context dependent phoneme(CDP), syllable with tone and\nChinese character.\n  We find that all types of modeling units can achieve approximate character\nerror rate (CER) in CTC model and the performance of Chinese character\nattention model is better than syllable attention model. Furthermore, we find\nthat Chinese character is a reasonable unit for mandarin speech recognition. On\nDidiCallcenter task, Chinese character attention model achieves a CER of 5.68%\nand CTC model gets a CER of 7.29%, on the other DidiReading task, CER are 4.89%\nand 5.79%, respectively. Moreover, attention model achieves a better\nperformance than CTC model on both datasets.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 05:54:32 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 02:02:02 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Zou", "Wei", ""], ["Jiang", "Dongwei", ""], ["Zhao", "Shuaijiang", ""], ["Li", "Xiangang", ""]]}, {"id": "1805.03838", "submitter": "Ye Zhixiu", "authors": "Zhi-Xiu Ye and Zhen-Hua Ling", "title": "Hybrid semi-Markov CRF for Neural Sequence Labeling", "comments": "This paper has been accepted by ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes hybrid semi-Markov conditional random fields (SCRFs) for\nneural sequence labeling in natural language processing. Based on conventional\nconditional random fields (CRFs), SCRFs have been designed for the tasks of\nassigning labels to segments by extracting features from and describing\ntransitions between segments instead of words. In this paper, we improve the\nexisting SCRF methods by employing word-level and segment-level information\nsimultaneously. First, word-level labels are utilized to derive the segment\nscores in SCRFs. Second, a CRF output layer and an SCRF output layer are\nintegrated into an unified neural network and trained jointly. Experimental\nresults on CoNLL 2003 named entity recognition (NER) shared task show that our\nmodel achieves state-of-the-art performance when no external knowledge is used.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 06:14:36 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Ye", "Zhi-Xiu", ""], ["Ling", "Zhen-Hua", ""]]}, {"id": "1805.03871", "submitter": "Ilias Chalkidis", "authors": "Ilias Chalkidis and Ion Androutsopoulos and Achilleas Michos", "title": "Obligation and Prohibition Extraction Using Hierarchical RNNs", "comments": "6 pages, short paper at ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of detecting contractual obligations and prohibitions.\nWe show that a self-attention mechanism improves the performance of a BILSTM\nclassifier, the previous state of the art for this task, by allowing it to\nfocus on indicative tokens. We also introduce a hierarchical BILSTM, which\nconverts each sentence to an embedding, and processes the sentence embeddings\nto classify each sentence. Apart from being faster to train, the hierarchical\nBILSTM outperforms the flat one, even when the latter considers surrounding\nsentences, because the hierarchical model has a broader discourse view.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 08:04:17 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Chalkidis", "Ilias", ""], ["Androutsopoulos", "Ion", ""], ["Michos", "Achilleas", ""]]}, {"id": "1805.03900", "submitter": "Furu Wei", "authors": "Furu Wei", "title": "Improv Chat: Second Response Generation for Chatbot", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing research on response generation for chatbot focuses on \\textbf{First\nResponse Generation} which aims to teach the chatbot to say the first response\n(e.g. a sentence) appropriate to the conversation context (e.g. the user's\nquery). In this paper, we introduce a new task \\textbf{Second Response\nGeneration}, termed as Improv chat, which aims to teach the chatbot to say the\nsecond response after saying the first response with respect the conversation\ncontext, so as to lighten the burden on the user to keep the conversation\ngoing. Specifically, we propose a general learning based framework and develop\na retrieval based system which can generate the second responses with the\nusers' query and the chatbot's first response as input. We present the approach\nto building the conversation corpus for Improv chat from public forums and\nsocial networks, as well as the neural networks based models for response\nmatching and ranking. We include the preliminary experiments and results in\nthis paper. This work could be further advanced with better deep matching\nmodels for retrieval base systems or generative models for generation based\nsystems as well as extensive evaluations in real-life applications.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 09:22:56 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Wei", "Furu", ""]]}, {"id": "1805.03977", "submitter": "Pengcheng Yang", "authors": "Pengcheng Yang, Xu Sun, Wei Li, Shuming Ma", "title": "Automatic Academic Paper Rating Based on Modularized Hierarchical\n  Convolutional Neural Network", "comments": "Accepted by ACL2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As more and more academic papers are being submitted to conferences and\njournals, evaluating all these papers by professionals is time-consuming and\ncan cause inequality due to the personal factors of the reviewers. In this\npaper, in order to assist professionals in evaluating academic papers, we\npropose a novel task: automatic academic paper rating (AAPR), which\nautomatically determine whether to accept academic papers. We build a new\ndataset for this task and propose a novel modularized hierarchical\nconvolutional neural network to achieve automatic academic paper rating.\nEvaluation results show that the proposed model outperforms the baselines by a\nlarge margin. The dataset and code are available at\n\\url{https://github.com/lancopku/AAPR}\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 13:42:29 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Yang", "Pengcheng", ""], ["Sun", "Xu", ""], ["Li", "Wei", ""], ["Ma", "Shuming", ""]]}, {"id": "1805.03989", "submitter": "Junyang Lin", "authors": "Junyang Lin, Xu Sun, Shuming Ma and Qi Su", "title": "Global Encoding for Abstractive Summarization", "comments": "Accepted by ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neural abstractive summarization, the conventional sequence-to-sequence\n(seq2seq) model often suffers from repetition and semantic irrelevance. To\ntackle the problem, we propose a global encoding framework, which controls the\ninformation flow from the encoder to the decoder based on the global\ninformation of the source context. It consists of a convolutional gated unit to\nperform global encoding to improve the representations of the source-side\ninformation. Evaluations on the LCSTS and the English Gigaword both demonstrate\nthat our model outperforms the baseline models, and the analysis shows that our\nmodel is capable of reducing repetition.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 14:11:51 GMT"}, {"version": "v2", "created": "Sun, 10 Jun 2018 15:29:18 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Lin", "Junyang", ""], ["Sun", "Xu", ""], ["Ma", "Shuming", ""], ["Su", "Qi", ""]]}, {"id": "1805.04016", "submitter": "Craig Stewart", "authors": "Craig Stewart, Nikolai Vogler, Junjie Hu, Jordan Boyd-Graber, Graham\n  Neubig", "title": "Automatic Estimation of Simultaneous Interpreter Performance", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneous interpretation, translation of the spoken word in real-time, is\nboth highly challenging and physically demanding. Methods to predict\ninterpreter confidence and the adequacy of the interpreted message have a\nnumber of potential applications, such as in computer-assisted interpretation\ninterfaces or pedagogical tools. We propose the task of predicting simultaneous\ninterpreter performance by building on existing methodology for quality\nestimation (QE) of machine translation output. In experiments over five\nsettings in three language pairs, we extend a QE pipeline to estimate\ninterpreter performance (as approximated by the METEOR evaluation metric) and\npropose novel features reflecting interpretation strategy and evaluation\nmeasures that further improve prediction accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 15:07:22 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2018 14:53:49 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Stewart", "Craig", ""], ["Vogler", "Nikolai", ""], ["Hu", "Junjie", ""], ["Boyd-Graber", "Jordan", ""], ["Neubig", "Graham", ""]]}, {"id": "1805.04032", "submitter": "Jose Camacho-Collados", "authors": "Jose Camacho-Collados and Mohammad Taher Pilehvar", "title": "From Word to Sense Embeddings: A Survey on Vector Representations of\n  Meaning", "comments": "46 pages, 8 figures. Published in Journal of Artificial Intelligence\n  Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past years, distributed semantic representations have proved to be\neffective and flexible keepers of prior knowledge to be integrated into\ndownstream applications. This survey focuses on the representation of meaning.\nWe start from the theoretical background behind word vector space models and\nhighlight one of their major limitations: the meaning conflation deficiency,\nwhich arises from representing a word with all its possible meanings as a\nsingle vector. Then, we explain how this deficiency can be addressed through a\ntransition from the word level to the more fine-grained level of word senses\n(in its broader acceptation) as a method for modelling unambiguous lexical\nmeaning. We present a comprehensive overview of the wide range of techniques in\nthe two main branches of sense representation, i.e., unsupervised and\nknowledge-based. Finally, this survey covers the main evaluation procedures and\napplications for this type of representation, and provides an analysis of four\nof its important aspects: interpretability, sense granularity, adaptability to\ndifferent domains and compositionality.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 15:56:48 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 08:18:28 GMT"}, {"version": "v3", "created": "Fri, 26 Oct 2018 09:34:36 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Camacho-Collados", "Jose", ""], ["Pilehvar", "Mohammad Taher", ""]]}, {"id": "1805.04033", "submitter": "Bingzhen Wei", "authors": "Bingzhen Wei, Xuancheng Ren, Xu Sun, Yi Zhang, Xiaoyan Cai, Qi Su", "title": "Regularizing Output Distribution of Abstractive Chinese Social Media\n  Text Summarization for Improved Semantic Consistency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstractive text summarization is a highly difficult problem, and the\nsequence-to-sequence model has shown success in improving the performance on\nthe task. However, the generated summaries are often inconsistent with the\nsource content in semantics. In such cases, when generating summaries, the\nmodel selects semantically unrelated words with respect to the source content\nas the most probable output. The problem can be attributed to heuristically\nconstructed training data, where summaries can be unrelated to the source\ncontent, thus containing semantically unrelated words and spurious word\ncorrespondence. In this paper, we propose a regularization approach for the\nsequence-to-sequence model and make use of what the model has learned to\nregularize the learning objective to alleviate the effect of the problem. In\naddition, we propose a practical human evaluation method to address the problem\nthat the existing automatic evaluation method does not evaluate the semantic\nconsistency with the source content properly. Experimental results demonstrate\nthe effectiveness of the proposed approach, which outperforms almost all the\nexisting models. Especially, the proposed approach improves the semantic\nconsistency by 4\\% in terms of human evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 15:58:09 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Wei", "Bingzhen", ""], ["Ren", "Xuancheng", ""], ["Sun", "Xu", ""], ["Zhang", "Yi", ""], ["Cai", "Xiaoyan", ""], ["Su", "Qi", ""]]}, {"id": "1805.04044", "submitter": "Yuning Mao", "authors": "Yuning Mao, Xiang Ren, Jiaming Shen, Xiaotao Gu, Jiawei Han", "title": "End-to-End Reinforcement Learning for Automatic Taxonomy Induction", "comments": "11 Pages. ACL 2018 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel end-to-end reinforcement learning approach to automatic\ntaxonomy induction from a set of terms. While prior methods treat the problem\nas a two-phase task (i.e., detecting hypernymy pairs followed by organizing\nthese pairs into a tree-structured hierarchy), we argue that such two-phase\nmethods may suffer from error propagation, and cannot effectively optimize\nmetrics that capture the holistic structure of a taxonomy. In our approach, the\nrepresentations of term pairs are learned using multiple sources of information\nand used to determine \\textit{which} term to select and \\textit{where} to place\nit on the taxonomy via a policy network. All components are trained in an\nend-to-end manner with cumulative rewards, measured by a holistic tree metric\nover the training taxonomies. Experiments on two public datasets of different\ndomains show that our approach outperforms prior state-of-the-art taxonomy\ninduction methods up to 19.6\\% on ancestor F1.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 16:19:14 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Mao", "Yuning", ""], ["Ren", "Xiang", ""], ["Shen", "Jiaming", ""], ["Gu", "Xiaotao", ""], ["Han", "Jiawei", ""]]}, {"id": "1805.04174", "submitter": "Guoyin Wang", "authors": "Guoyin Wang, Chunyuan Li, Wenlin Wang, Yizhe Zhang, Dinghan Shen,\n  Xinyuan Zhang, Ricardo Henao, Lawrence Carin", "title": "Joint Embedding of Words and Labels for Text Classification", "comments": "Published in ACL 2018; Code: https://github.com/guoyinwang/LEAM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are effective intermediate representations for capturing\nsemantic regularities between words, when learning the representations of text\nsequences. We propose to view text classification as a label-word joint\nembedding problem: each label is embedded in the same space with the word\nvectors. We introduce an attention framework that measures the compatibility of\nembeddings between text sequences and labels. The attention is learned on a\ntraining set of labeled samples to ensure that, given a text sequence, the\nrelevant words are weighted higher than the irrelevant ones. Our method\nmaintains the interpretability of word embeddings, and enjoys a built-in\nability to leverage alternative sources of information, in addition to input\ntext sequences. Extensive results on the several large text datasets show that\nthe proposed framework outperforms the state-of-the-art methods by a large\nmargin, in terms of both accuracy and speed.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 20:42:52 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Wang", "Guoyin", ""], ["Li", "Chunyuan", ""], ["Wang", "Wenlin", ""], ["Zhang", "Yizhe", ""], ["Shen", "Dinghan", ""], ["Zhang", "Xinyuan", ""], ["Henao", "Ricardo", ""], ["Carin", "Lawrence", ""]]}, {"id": "1805.04185", "submitter": "Mattia Antonino Di Gangi", "authors": "Mattia Antonino Di Gangi and Marcello Federico", "title": "Deep Neural Machine Translation with Weakly-Recurrent Units", "comments": "10 pages, 3 figures, accepted as a conference paper at the 21st\n  Annual Conference of the European Association for Machine Translation (EAMT)\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) have represented for years the state of the\nart in neural machine translation. Recently, new architectures have been\nproposed, which can leverage parallel computation on GPUs better than classical\nRNNs. Faster training and inference combined with different\nsequence-to-sequence modeling also lead to performance improvements. While the\nnew models completely depart from the original recurrent architecture, we\ndecided to investigate how to make RNNs more efficient. In this work, we\npropose a new recurrent NMT architecture, called Simple Recurrent NMT, built on\na class of fast and weakly-recurrent units that use layer normalization and\nmultiple attentions. Our experiments on the WMT14 English-to-German and WMT16\nEnglish-Romanian benchmarks show that our model represents a valid alternative\nto LSTMs, as it can achieve better results at a significantly lower\ncomputational cost.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 21:55:32 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Di Gangi", "Mattia Antonino", ""], ["Federico", "Marcello", ""]]}, {"id": "1805.04212", "submitter": "Vicente Ivan Sanchez Carmona", "authors": "Vicente Ivan Sanchez Carmona, Jeff Mitchell, Sebastian Riedel", "title": "Behavior Analysis of NLI Models: Uncovering the Influence of Three\n  Factors on Robustness", "comments": "Accepted at NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Language Inference is a challenging task that has received\nsubstantial attention, and state-of-the-art models now achieve impressive test\nset performance in the form of accuracy scores. Here, we go beyond this single\nevaluation metric to examine robustness to semantically-valid alterations to\nthe input data. We identify three factors - insensitivity, polarity and unseen\npairs - and compare their impact on three SNLI models under a variety of\nconditions. Our results demonstrate a number of strengths and weaknesses in the\nmodels' ability to generalise to new in-domain instances. In particular, while\nstrong performance is possible on unseen hypernyms, unseen antonyms are more\nchallenging for all the models. More generally, the models suffer from an\ninsensitivity to certain small but semantically significant alterations, and\nare also often influenced by simple statistical correlations between words and\ntraining labels. Overall, we show that evaluations of NLI models can benefit\nfrom studying the influence of factors intrinsic to the models or found in the\ndataset used.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 00:43:59 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Carmona", "Vicente Ivan Sanchez", ""], ["Mitchell", "Jeff", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1805.04218", "submitter": "Terra Blevins", "authors": "Terra Blevins, Omer Levy, Luke Zettlemoyer", "title": "Deep RNNs Encode Soft Hierarchical Syntax", "comments": "Accepted to ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a set of experiments to demonstrate that deep recurrent neural\nnetworks (RNNs) learn internal representations that capture soft hierarchical\nnotions of syntax from highly varied supervision. We consider four syntax tasks\nat different depths of the parse tree; for each word, we predict its part of\nspeech as well as the first (parent), second (grandparent) and third level\n(great-grandparent) constituent labels that appear above it. These predictions\nare made from representations produced at different depths in networks that are\npretrained with one of four objectives: dependency parsing, semantic role\nlabeling, machine translation, or language modeling. In every case, we find a\ncorrespondence between network depth and syntactic depth, suggesting that a\nsoft syntactic hierarchy emerges. This effect is robust across all conditions,\nindicating that the models encode significant amounts of syntax even in the\nabsence of an explicit syntactic training supervision.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 01:34:52 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Blevins", "Terra", ""], ["Levy", "Omer", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1805.04237", "submitter": "Poorya Zaremoodi", "authors": "Poorya Zaremoodi and Gholamreza Haffari", "title": "Neural Machine Translation for Bilingually Scarce Scenarios: A Deep\n  Multi-task Learning Approach", "comments": "NAACL 2018 (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation requires large amounts of parallel training text\nto learn a reasonable-quality translation model. This is particularly\ninconvenient for language pairs for which enough parallel text is not\navailable. In this paper, we use monolingual linguistic resources in the source\nside to address this challenging problem based on a multi-task learning\napproach. More specifically, we scaffold the machine translation task on\nauxiliary tasks including semantic parsing, syntactic parsing, and named-entity\nrecognition. This effectively injects semantic and/or syntactic knowledge into\nthe translation model, which would otherwise require a large amount of training\nbitext. We empirically evaluate and show the effectiveness of our multi-task\nlearning approach on three translation tasks: English-to-French,\nEnglish-to-Farsi, and English-to-Vietnamese.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 03:36:32 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Zaremoodi", "Poorya", ""], ["Haffari", "Gholamreza", ""]]}, {"id": "1805.04247", "submitter": "Moshiur R Farazi", "authors": "Moshiur R Farazi, Salman H Khan", "title": "Reciprocal Attention Fusion for Visual Question Answering", "comments": "To appear in the British Machine Vision Conference (BMVC), September\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing attention mechanisms either attend to local image grid or object\nlevel features for Visual Question Answering (VQA). Motivated by the\nobservation that questions can relate to both object instances and their parts,\nwe propose a novel attention mechanism that jointly considers reciprocal\nrelationships between the two levels of visual details. The bottom-up attention\nthus generated is further coalesced with the top-down information to only focus\non the scene elements that are most relevant to a given question. Our design\nhierarchically fuses multi-modal information i.e., language, object- and\ngird-level features, through an efficient tensor decomposition scheme. The\nproposed model improves the state-of-the-art single model performances from\n67.9% to 68.2% on VQAv1 and from 65.7% to 67.4% on VQAv2, demonstrating a\nsignificant boost.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 06:13:56 GMT"}, {"version": "v2", "created": "Sun, 22 Jul 2018 06:16:54 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Farazi", "Moshiur R", ""], ["Khan", "Salman H", ""]]}, {"id": "1805.04264", "submitter": "Lyan Verwimp", "authors": "Lyan Verwimp, Hugo Van hamme, Vincent Renkens, Patrick Wambacq", "title": "State Gradients for RNN Memory Analysis", "comments": "Accepted for Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for analyzing what the state in RNNs remembers from\nits input embeddings. Our approach is inspired by backpropagation, in the sense\nthat we compute the gradients of the states with respect to the input\nembeddings. The gradient matrix is decomposed with Singular Value Decomposition\nto analyze which directions in the embedding space are best transferred to the\nhidden state space, characterized by the largest singular values. We apply our\napproach to LSTM language models and investigate to what extent and for how\nlong certain classes of words are remembered on average for a certain corpus.\nAdditionally, the extent to which a specific property or relationship is\nremembered by the RNN can be tracked by comparing a vector characterizing that\nproperty with the direction(s) in embedding space that are best preserved in\nhidden state space.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 07:51:28 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 09:05:30 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Verwimp", "Lyan", ""], ["Van hamme", "Hugo", ""], ["Renkens", "Vincent", ""], ["Wambacq", "Patrick", ""]]}, {"id": "1805.04270", "submitter": "Lei Cui", "authors": "Lei Cui, Furu Wei and Ming Zhou", "title": "Neural Open Information Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional Open Information Extraction (Open IE) systems are usually built\non hand-crafted patterns from other NLP tools such as syntactic parsing, yet\nthey face problems of error propagation. In this paper, we propose a neural\nOpen IE approach with an encoder-decoder framework. Distinct from existing\nmethods, the neural Open IE approach learns highly confident arguments and\nrelation tuples bootstrapped from a state-of-the-art Open IE system. An\nempirical study on a large benchmark dataset shows that the neural Open IE\nsystem significantly outperforms several baselines, while maintaining\ncomparable computational efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 08:17:49 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Cui", "Lei", ""], ["Wei", "Furu", ""], ["Zhou", "Ming", ""]]}, {"id": "1805.04277", "submitter": "Aitor Soroa Dr.", "authors": "Eneko Agirre, Oier L\\'opez de Lacalle, Aitor Soroa", "title": "The risk of sub-optimal use of Open Source NLP Software: UKB is\n  inadvertently state-of-the-art in knowledge-based WSD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  UKB is an open source collection of programs for performing, among other\ntasks, knowledge-based Word Sense Disambiguation (WSD). Since it was released\nin 2009 it has been often used out-of-the-box in sub-optimal settings. We show\nthat nine years later it is the state-of-the-art on knowledge-based WSD. This\ncase shows the pitfalls of releasing open source NLP software without optimal\ndefault settings and precise instructions for reproducibility.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 08:46:15 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Agirre", "Eneko", ""], ["de Lacalle", "Oier L\u00f3pez", ""], ["Soroa", "Aitor", ""]]}, {"id": "1805.04402", "submitter": "Tobias Kapp\\'e", "authors": "Makoto Kanazawa and Tobias Kapp\\'e", "title": "Decision problems for Clark-congruential languages", "comments": "Version 2 incorporates revisions prompted by the comments of\n  anonymous referees at ICGI and LearnAut", "journal-ref": "PMLR 93:3-16, 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common question when studying a class of context-free grammars is whether\nequivalence is decidable within this class. We answer this question positively\nfor the class of Clark-congruential grammars, which are of interest to\ngrammatical inference. We also consider the problem of checking whether a given\nCFG is Clark-congruential, and show that it is decidable given that the CFG is\na DCFG.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 13:50:26 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 14:05:33 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Kanazawa", "Makoto", ""], ["Kapp\u00e9", "Tobias", ""]]}, {"id": "1805.04437", "submitter": "Georgios Balikas", "authors": "Georgios Balikas, Charlotte Laclau, Ievgen Redko, Massih-Reza Amini", "title": "Cross-lingual Document Retrieval using Regularized Wasserstein Distance", "comments": "ECIR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many information retrieval algorithms rely on the notion of a good distance\nthat allows to efficiently compare objects of different nature. Recently, a new\npromising metric called Word Mover's Distance was proposed to measure the\ndivergence between text passages. In this paper, we demonstrate that this\nmetric can be extended to incorporate term-weighting schemes and provide more\naccurate and computationally efficient matching between documents using\nentropic regularization. We evaluate the benefits of both extensions in the\ntask of cross-lingual document retrieval (CLDR). Our experimental results on\neight CLDR problems suggest that the proposed methods achieve remarkable\nimprovements in terms of Mean Reciprocal Rank compared to several baselines.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 15:01:00 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Balikas", "Georgios", ""], ["Laclau", "Charlotte", ""], ["Redko", "Ievgen", ""], ["Amini", "Massih-Reza", ""]]}, {"id": "1805.04453", "submitter": "Nicholas Ruiz", "authors": "Nicholas Ruiz, Srinivas Bangalore, John Chen", "title": "Bootstrapping Multilingual Intent Models via Machine Translation for\n  Dialog Automation", "comments": "6 pages, 3 figures, accepted for publication at the 2018 European\n  Association for Machine Translation Conference (EAMT 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the resurgence of chat-based dialog systems in consumer and enterprise\napplications, there has been much success in developing data-driven and\nrule-based natural language models to understand human intent. Since these\nmodels require large amounts of data and in-domain knowledge, expanding an\nequivalent service into new markets is disrupted by language barriers that\ninhibit dialog automation.\n  This paper presents a user study to evaluate the utility of out-of-the-box\nmachine translation technology to (1) rapidly bootstrap multilingual spoken\ndialog systems and (2) enable existing human analysts to understand foreign\nlanguage utterances. We additionally evaluate the utility of machine\ntranslation in human assisted environments, where a portion of the traffic is\nprocessed by analysts. In English->Spanish experiments, we observe a high\npotential for dialog automation, as well as the potential for human analysts to\nprocess foreign language utterances with high accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 15:42:27 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Ruiz", "Nicholas", ""], ["Bangalore", "Srinivas", ""], ["Chen", "John", ""]]}, {"id": "1805.04508", "submitter": "Svetlana Kiritchenko", "authors": "Svetlana Kiritchenko and Saif M. Mohammad", "title": "Examining Gender and Race Bias in Two Hundred Sentiment Analysis Systems", "comments": "In Proceedings of the 7th Joint Conference on Lexical and\n  Computational Semantics (*SEM), New Orleans, USA, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic machine learning systems can inadvertently accentuate and\nperpetuate inappropriate human biases. Past work on examining inappropriate\nbiases has largely focused on just individual systems. Further, there is no\nbenchmark dataset for examining inappropriate biases in systems. Here for the\nfirst time, we present the Equity Evaluation Corpus (EEC), which consists of\n8,640 English sentences carefully chosen to tease out biases towards certain\nraces and genders. We use the dataset to examine 219 automatic sentiment\nanalysis systems that took part in a recent shared task, SemEval-2018 Task 1\n'Affect in Tweets'. We find that several of the systems show statistically\nsignificant bias; that is, they consistently provide slightly higher sentiment\nintensity predictions for one race or one gender. We make the EEC freely\navailable.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 17:57:40 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Kiritchenko", "Svetlana", ""], ["Mohammad", "Saif M.", ""]]}, {"id": "1805.04542", "submitter": "Svetlana Kiritchenko", "authors": "Svetlana Kiritchenko and Saif M. Mohammad", "title": "Sentiment Composition of Words with Opposing Polarities", "comments": "In Proceedings of the 15th Annual Conference of the North American\n  Chapter of the Association for Computational Linguistics: Human Language\n  Technologies (NAACL), San Diego, California, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore sentiment composition in phrases that have at least\none positive and at least one negative word---phrases like 'happy accident' and\n'best winter break'. We compiled a dataset of such opposing polarity phrases\nand manually annotated them with real-valued scores of sentiment association.\nUsing this dataset, we analyze the linguistic patterns present in opposing\npolarity phrases. Finally, we apply several unsupervised and supervised\ntechniques of sentiment composition to determine their efficacy on this\ndataset. Our best system, which incorporates information from the phrase's\nconstituents, their parts of speech, their sentiment association scores, and\ntheir embedding vectors, obtains an accuracy of over 80% on the opposing\npolarity phrases.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 18:16:54 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Kiritchenko", "Svetlana", ""], ["Mohammad", "Saif M.", ""]]}, {"id": "1805.04558", "submitter": "Svetlana Kiritchenko", "authors": "Svetlana Kiritchenko, Saif M. Mohammad, Jason Morin, and Berry de\n  Bruijn", "title": "NRC-Canada at SMM4H Shared Task: Classifying Tweets Mentioning Adverse\n  Drug Reactions and Medication Intake", "comments": "In Proceedings of the Social Media Mining for Health Applications\n  Workshop at AMIA-2017, Washington, DC, USA, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our team, NRC-Canada, participated in two shared tasks at the AMIA-2017\nWorkshop on Social Media Mining for Health Applications (SMM4H): Task 1 -\nclassification of tweets mentioning adverse drug reactions, and Task 2 -\nclassification of tweets describing personal medication intake. For both tasks,\nwe trained Support Vector Machine classifiers using a variety of surface-form,\nsentiment, and domain-specific features. With nine teams participating in each\ntask, our submissions ranked first on Task 1 and third on Task 2. Handling\nconsiderable class imbalance proved crucial for Task 1. We applied an\nunder-sampling technique to reduce class imbalance (from about 1:10 to 1:2).\nStandard n-gram features, n-grams generalized over domain terms, as well as\ngeneral-domain and domain-specific word embeddings had a substantial impact on\nthe overall performance in both tasks. On the other hand, including sentiment\nlexicon features did not result in any improvement.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 19:01:49 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Kiritchenko", "Svetlana", ""], ["Mohammad", "Saif M.", ""], ["Morin", "Jason", ""], ["de Bruijn", "Berry", ""]]}, {"id": "1805.04570", "submitter": "Chaitanya Malaviya", "authors": "Chaitanya Malaviya, Matthew R. Gormley, Graham Neubig", "title": "Neural Factor Graph Models for Cross-lingual Morphological Tagging", "comments": "Proceedings of ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Morphological analysis involves predicting the syntactic traits of a word\n(e.g. {POS: Noun, Case: Acc, Gender: Fem}). Previous work in morphological\ntagging improves performance for low-resource languages (LRLs) through\ncross-lingual training with a high-resource language (HRL) from the same\nfamily, but is limited by the strict, often false, assumption that tag sets\nexactly overlap between the HRL and LRL. In this paper we propose a method for\ncross-lingual morphological tagging that aims to improve information sharing\nbetween languages by relaxing this assumption. The proposed model uses\nfactorial conditional random fields with neural network potentials, making it\npossible to (1) utilize the expressive power of neural network representations\nto smooth over superficial differences in the surface forms, (2) model pairwise\nand transitive relationships between tags, and (3) accurately generate tag sets\nthat are unseen or rare in the training data. Experiments on four languages\nfrom the Universal Dependencies Treebank demonstrate superior tagging\naccuracies over existing cross-lingual approaches.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 19:27:07 GMT"}, {"version": "v2", "created": "Sun, 10 Jun 2018 01:47:13 GMT"}, {"version": "v3", "created": "Wed, 11 Jul 2018 03:04:44 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Malaviya", "Chaitanya", ""], ["Gormley", "Matthew R.", ""], ["Neubig", "Graham", ""]]}, {"id": "1805.04576", "submitter": "Prathusha Kameswara Sarma", "authors": "Prathusha K Sarma, YIngyu Liang, William A Sethares", "title": "Domain Adapted Word Embeddings for Improved Sentiment Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generic word embeddings are trained on large-scale generic corpora; Domain\nSpecific (DS) word embeddings are trained only on data from a domain of\ninterest. This paper proposes a method to combine the breadth of generic\nembeddings with the specificity of domain specific embeddings. The resulting\nembeddings, called Domain Adapted (DA) word embeddings, are formed by aligning\ncorresponding word vectors using Canonical Correlation Analysis (CCA) or the\nrelated nonlinear Kernel CCA. Evaluation results on sentiment classification\ntasks show that the DA embeddings substantially outperform both generic and DS\nembeddings when used as input features to standard or state-of-the-art sentence\nencoding algorithms for classification.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 19:58:59 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Sarma", "Prathusha K", ""], ["Liang", "YIngyu", ""], ["Sethares", "William A", ""]]}, {"id": "1805.04579", "submitter": "Anukarsh Singh", "authors": "Divyanshu Daiya, Anukarsh Singh, Mukesh Jadon", "title": "Using Statistical and Semantic Models for Multi-Document Summarization", "comments": "9 pages; DD and AS have contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report a series of experiments with different semantic models on top of\nvarious statistical models for extractive text summarization. Though\nstatistical models may better capture word co-occurrences and distribution\naround the text, they fail to detect the context and the sense of sentences\n/words as a whole. Semantic models help us gain better insight into the context\nof sentences. We show that how tuning weights between different models can help\nus achieve significant results on various benchmarks. Learning pre-trained\nvectors used in semantic models further, on given corpus, can give addition\nspike in performance. Using weighing techniques in between different\nstatistical models too further refines our result. For Statistical models, we\nhave used TF/IDF, TextRAnk, Jaccard/Cosine Similarities. For Semantic Models,\nwe have used WordNet-based Model and proposed two models based on Glove Vectors\nand Facebook's InferSent. We tested our approach on DUC 2004 dataset,\ngenerating 100-word summaries. We have discussed the system, algorithms,\nanalysis and also proposed and tested possible improvements. ROUGE scores were\nused to compare to other summarizers.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 20:15:52 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 21:35:56 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Daiya", "Divyanshu", ""], ["Singh", "Anukarsh", ""], ["Jadon", "Mukesh", ""]]}, {"id": "1805.04601", "submitter": "Hu Xu", "authors": "Hu Xu, Bing Liu, Lei Shu, Philip S. Yu", "title": "Double Embeddings and CNN-based Sequence Labeling for Aspect Extraction", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One key task of fine-grained sentiment analysis of product reviews is to\nextract product aspects or features that users have expressed opinions on. This\npaper focuses on supervised aspect extraction using deep learning. Unlike other\nhighly sophisticated supervised deep learning models, this paper proposes a\nnovel and yet simple CNN model employing two types of pre-trained embeddings\nfor aspect extraction: general-purpose embeddings and domain-specific\nembeddings. Without using any additional supervision, this model achieves\nsurprisingly good results, outperforming state-of-the-art sophisticated\nexisting methods. To our knowledge, this paper is the first to report such\ndouble embeddings based CNN model for aspect extraction and achieve very good\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 21:53:23 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Xu", "Hu", ""], ["Liu", "Bing", ""], ["Shu", "Lei", ""], ["Yu", "Philip S.", ""]]}, {"id": "1805.04604", "submitter": "Li Dong", "authors": "Li Dong, Chris Quirk, Mirella Lapata", "title": "Confidence Modeling for Neural Semantic Parsing", "comments": "Accepted by ACL-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we focus on confidence modeling for neural semantic parsers\nwhich are built upon sequence-to-sequence models. We outline three major causes\nof uncertainty, and design various metrics to quantify these factors. These\nmetrics are then used to estimate confidence scores that indicate whether model\npredictions are likely to be correct. Beyond confidence estimation, we identify\nwhich parts of the input contribute to uncertain predictions allowing users to\ninterpret their model, and verify or refine its input. Experimental results\nshow that our confidence model significantly outperforms a widely used method\nthat relies on posterior probability, and improves the quality of\ninterpretation compared to simply relying on attention scores.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 22:09:37 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Dong", "Li", ""], ["Quirk", "Chris", ""], ["Lapata", "Mirella", ""]]}, {"id": "1805.04609", "submitter": "Jonathan Zarecki", "authors": "Jonathan Zarecki, Shaul Markovitch", "title": "Textual Membership Queries", "comments": "Accepted to IJCAI 2020. Code is available at\n  github.com/jonzarecki/textual-mqs . Additional material is available at\n  tinyurl.com/sup-textualmqs . SOLE copyright holder is IJCAI (International\n  Joint Conferences on Artificial Intelligence), all rights reserved", "journal-ref": null, "doi": "10.24963/ijcai.2020/369", "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human labeling of data can be very time-consuming and expensive, yet, in many\ncases it is critical for the success of the learning process. In order to\nminimize human labeling efforts, we propose a novel active learning solution\nthat does not rely on existing sources of unlabeled data. It uses a small\namount of labeled data as the core set for the synthesis of useful membership\nqueries (MQs) - unlabeled instances generated by an algorithm for human\nlabeling. Our solution uses modification operators, functions that modify\ninstances to some extent. We apply the operators on a small set of instances\n(core set), creating a set of new membership queries. Using this framework, we\nlook at the instance space as a search space and apply search algorithms in\norder to generate new examples highly relevant to the learner. We implement\nthis framework in the textual domain and test it on several text classification\ntasks and show improved classifier performance as more MQs are labeled and\nincorporated into the training set. To the best of our knowledge, this is the\nfirst work on membership queries in the textual domain.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 22:40:59 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 14:58:06 GMT"}, {"version": "v3", "created": "Fri, 7 Aug 2020 14:03:52 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Zarecki", "Jonathan", ""], ["Markovitch", "Shaul", ""]]}, {"id": "1805.04617", "submitter": "Alexander Fabbri", "authors": "Alexander R. Fabbri, Irene Li, Prawat Trairatvorakul, Yijiao He, Wei\n  Tai Ting, Robert Tung, Caitlin Westerfield, Dragomir R. Radev", "title": "TutorialBank: A Manually-Collected Corpus for Prerequisite Chains,\n  Survey Extraction and Resource Recommendation", "comments": "ACL 2018, 56th Annual Meeting of the Association for Computational\n  Linguistics, Melbourne, Australia, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of Natural Language Processing (NLP) is growing rapidly, with new\nresearch published daily along with an abundance of tutorials, codebases and\nother online resources. In order to learn this dynamic field or stay up-to-date\non the latest research, students as well as educators and researchers must\nconstantly sift through multiple sources to find valuable, relevant\ninformation. To address this situation, we introduce TutorialBank, a new,\npublicly available dataset which aims to facilitate NLP education and research.\nWe have manually collected and categorized over 6,300 resources on NLP as well\nas the related fields of Artificial Intelligence (AI), Machine Learning (ML)\nand Information Retrieval (IR). Our dataset is notably the largest\nmanually-picked corpus of resources intended for NLP education which does not\ninclude only academic papers. Additionally, we have created both a search\nengine and a command-line tool for the resources and have annotated the corpus\nto include lists of research topics, relevant resources for each topic,\nprerequisite relations among topics, relevant sub-parts of individual\nresources, among other annotations. We are releasing the dataset and present\nseveral avenues for further research.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 23:13:34 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Fabbri", "Alexander R.", ""], ["Li", "Irene", ""], ["Trairatvorakul", "Prawat", ""], ["He", "Yijiao", ""], ["Ting", "Wei Tai", ""], ["Tung", "Robert", ""], ["Westerfield", "Caitlin", ""], ["Radev", "Dragomir R.", ""]]}, {"id": "1805.04623", "submitter": "Urvashi Khandelwal", "authors": "Urvashi Khandelwal, He He, Peng Qi, Dan Jurafsky", "title": "Sharp Nearby, Fuzzy Far Away: How Neural Language Models Use Context", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We know very little about how neural language models (LM) use prior\nlinguistic context. In this paper, we investigate the role of context in an\nLSTM LM, through ablation studies. Specifically, we analyze the increase in\nperplexity when prior context words are shuffled, replaced, or dropped. On two\nstandard datasets, Penn Treebank and WikiText-2, we find that the model is\ncapable of using about 200 tokens of context on average, but sharply\ndistinguishes nearby context (recent 50 tokens) from the distant history. The\nmodel is highly sensitive to the order of words within the most recent\nsentence, but ignores word order in the long-range context (beyond 50 tokens),\nsuggesting the distant past is modeled only as a rough semantic field or topic.\nWe further find that the neural caching model (Grave et al., 2017b) especially\nhelps the LSTM to copy words from within this distant context. Overall, our\nanalysis not only provides a better understanding of how neural LMs use their\ncontext, but also sheds light on recent success from cache-based models.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 00:26:29 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Khandelwal", "Urvashi", ""], ["He", "He", ""], ["Qi", "Peng", ""], ["Jurafsky", "Dan", ""]]}, {"id": "1805.04655", "submitter": "Sudha Rao", "authors": "Sudha Rao and Hal Daum\\'e III", "title": "Learning to Ask Good Questions: Ranking Clarification Questions using\n  Neural Expected Value of Perfect Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inquiry is fundamental to communication, and machines cannot effectively\ncollaborate with humans unless they can ask questions. In this work, we build a\nneural network model for the task of ranking clarification questions. Our model\nis inspired by the idea of expected value of perfect information: a good\nquestion is one whose expected answer will be useful. We study this problem\nusing data from StackExchange, a plentiful online resource in which people\nroutinely ask clarifying questions to posts so that they can better offer\nassistance to the original poster. We create a dataset of clarification\nquestions consisting of ~77K posts paired with a clarification question (and\nanswer) from three domains of StackExchange: askubuntu, unix and superuser. We\nevaluate our model on 500 samples of this dataset against expert human\njudgments and demonstrate significant improvements over controlled baselines.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 05:11:07 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 21:39:45 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Rao", "Sudha", ""], ["Daum\u00e9", "Hal", "III"]]}, {"id": "1805.04658", "submitter": "Hao Peng", "authors": "Hao Peng, Sam Thomson, and Noah A. Smith", "title": "Backpropagating through Structured Argmax using a SPIGOT", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the structured projection of intermediate gradients optimization\ntechnique (SPIGOT), a new method for backpropagating through neural networks\nthat include hard-decision structured predictions (e.g., parsing) in\nintermediate layers. SPIGOT requires no marginal inference, unlike structured\nattention networks (Kim et al., 2017) and some reinforcement learning-inspired\nsolutions (Yogatama et al., 2017). Like so-called straight-through estimators\n(Hinton, 2012), SPIGOT defines gradient-like quantities associated with\nintermediate nondifferentiable operations, allowing backpropagation before and\nafter them; SPIGOT's proxy aims to ensure that, after a parameter update, the\nintermediate structure will remain well-formed.\n  We experiment on two structured NLP pipelines: syntactic-then-semantic\ndependency parsing, and semantic parsing followed by sentiment classification.\nWe show that training with SPIGOT leads to a larger improvement on the\ndownstream task than a modularly-trained pipeline, the straight-through\nestimator, and structured attention, reaching a new state of the art on\nsemantic dependency parsing.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 05:27:45 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Peng", "Hao", ""], ["Thomson", "Sam", ""], ["Smith", "Noah A.", ""]]}, {"id": "1805.04661", "submitter": "Filip Klubi\\v{c}ka", "authors": "Filip Klubi\\v{c}ka and Raquel Fern\\'andez", "title": "Examining a hate speech corpus for hate speech detection and popularity\n  prediction", "comments": "8 pages, 1 figure, 10 tables, published in proceedings of 4REAL2018:\n  Workshop on Replicability and Reproducibility of Research Results in Science\n  and Technology of Language", "journal-ref": "In Proceedings of 4REAL Workshop 9-16 (2018)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As research on hate speech becomes more and more relevant every day, most of\nit is still focused on hate speech detection. By attempting to replicate a hate\nspeech detection experiment performed on an existing Twitter corpus annotated\nfor hate speech, we highlight some issues that arise from doing research in the\nfield of hate speech, which is essentially still in its infancy. We take a\ncritical look at the training corpus in order to understand its biases, while\nalso using it to venture beyond hate speech detection and investigate whether\nit can be used to shed light on other facets of research, such as popularity of\nhate tweets.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 06:00:47 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Klubi\u010dka", "Filip", ""], ["Fern\u00e1ndez", "Raquel", ""]]}, {"id": "1805.04680", "submitter": "Dongyeop Kang", "authors": "Dongyeop Kang and Tushar Khot and Ashish Sabharwal and Eduard Hovy", "title": "AdvEntuRe: Adversarial Training for Textual Entailment with\n  Knowledge-Guided Examples", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning textual entailment models with limited\nsupervision (5K-10K training examples), and present two complementary\napproaches for it. First, we propose knowledge-guided adversarial example\ngenerators for incorporating large lexical resources in entailment models via\nonly a handful of rule templates. Second, to make the entailment model - a\ndiscriminator - more robust, we propose the first GAN-style approach for\ntraining it using a natural language example generator that iteratively adjusts\nbased on the discriminator's performance. We demonstrate effectiveness using\ntwo entailment datasets, where the proposed methods increase accuracy by 4.7%\non SciTail and by 2.8% on a 1% training sub-sample of SNLI. Notably, even a\nsingle hand-written rule, negate, improves the accuracy on the negation\nexamples in SNLI by 6.1%.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 07:52:59 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Kang", "Dongyeop", ""], ["Khot", "Tushar", ""], ["Sabharwal", "Ashish", ""], ["Hovy", "Eduard", ""]]}, {"id": "1805.04685", "submitter": "Tommaso Pasini", "authors": "Tommaso Pasini, Francesco Maria Elia, Roberto Navigli", "title": "Huge Automatically Extracted Training Sets for Multilingual Word Sense\n  Disambiguation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We release to the community six large-scale sense-annotated datasets in\nmultiple language to pave the way for supervised multilingual Word Sense\nDisambiguation. Our datasets cover all the nouns in the English WordNet and\ntheir translations in other languages for a total of millions of sense-tagged\nsentences. Experiments prove that these corpora can be effectively used as\ntraining sets for supervised WSD systems, surpassing the state of the art for\nlow-resourced languages and providing competitive results for English, where\nmanually annotated training sets are accessible. The data is available at\ntrainomatic.org.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 08:25:33 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Pasini", "Tommaso", ""], ["Elia", "Francesco Maria", ""], ["Navigli", "Roberto", ""]]}, {"id": "1805.04688", "submitter": "Yanpeng Zhao", "authors": "Yanpeng Zhao, Liwen Zhang, Kewei Tu", "title": "Gaussian Mixture Latent Vector Grammars", "comments": "Accepted to ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce Latent Vector Grammars (LVeGs), a new framework that extends\nlatent variable grammars such that each nonterminal symbol is associated with a\ncontinuous vector space representing the set of (infinitely many) subtypes of\nthe nonterminal. We show that previous models such as latent variable grammars\nand compositional vector grammars can be interpreted as special cases of LVeGs.\nWe then present Gaussian Mixture LVeGs (GM-LVeGs), a new special case of LVeGs\nthat uses Gaussian mixtures to formulate the weights of production rules over\nsubtypes of nonterminals. A major advantage of using Gaussian mixtures is that\nthe partition function and the expectations of subtype rules can be computed\nusing an extension of the inside-outside algorithm, which enables efficient\ninference and learning. We apply GM-LVeGs to part-of-speech tagging and\nconstituency parsing and show that GM-LVeGs can achieve competitive accuracies.\nOur code is available at https://github.com/zhaoyanpeng/lveg.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 09:27:53 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Zhao", "Yanpeng", ""], ["Zhang", "Liwen", ""], ["Tu", "Kewei", ""]]}, {"id": "1805.04699", "submitter": "Fran\\c{c}ois Hernandez", "authors": "Fran\\c{c}ois Hernandez and Vincent Nguyen and Sahar Ghannay and\n  Natalia Tomashenko and Yannick Est\\`eve", "title": "TED-LIUM 3: twice as much data and corpus repartition for experiments on\n  speaker adaptation", "comments": "Submitted to SPECOM 2018, 20th International Conference on Speech and\n  Computer; TED-LIUM 3 corpus available on\n  https://lium.univ-lemans.fr/en/ted-lium3/", "journal-ref": "SPECOM 2018. Lecture Notes in Computer Science, vol 11096, pp\n  198-208", "doi": "10.1007/978-3-319-99579-3_21", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present TED-LIUM release 3 corpus dedicated to speech\nrecognition in English, that multiplies by more than two the available data to\ntrain acoustic models in comparison with TED-LIUM 2. We present the recent\ndevelopment on Automatic Speech Recognition (ASR) systems in comparison with\nthe two previous releases of the TED-LIUM Corpus from 2012 and 2014. We\ndemonstrate that, passing from 207 to 452 hours of transcribed speech training\ndata is really more useful for end-to-end ASR systems than for HMM-based\nstate-of-the-art ones, even if the HMM-based ASR system still outperforms\nend-to-end ASR system when the size of audio training data is 452 hours, with\nrespectively a Word Error Rate (WER) of 6.6% and 13.7%. Last, we propose two\nrepartitions of the TED-LIUM release 3 corpus: the legacy one that is the same\nas the one existing in release 2, and a new one, calibrated and designed to\nmake experiments on speaker adaptation. Like the two first releases, TED-LIUM 3\ncorpus will be freely available for the research community.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 11:06:47 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 21:37:19 GMT"}, {"version": "v3", "created": "Tue, 3 Jul 2018 09:02:38 GMT"}, {"version": "v4", "created": "Thu, 13 Jun 2019 17:35:04 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Hernandez", "Fran\u00e7ois", ""], ["Nguyen", "Vincent", ""], ["Ghannay", "Sahar", ""], ["Tomashenko", "Natalia", ""], ["Est\u00e8ve", "Yannick", ""]]}, {"id": "1805.04715", "submitter": "Dmitry Ustalov", "authors": "Dmitry Ustalov and Alexander Panchenko and Andrei Kutuzov and Chris\n  Biemann and Simone Paolo Ponzetto", "title": "Unsupervised Semantic Frame Induction using Triclustering", "comments": "8 pages, 1 figure, 4 tables, accepted at ACL 2018", "journal-ref": null, "doi": "10.18653/v1/P18-2010", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use dependency triples automatically extracted from a Web-scale corpus to\nperform unsupervised semantic frame induction. We cast the frame induction\nproblem as a triclustering problem that is a generalization of clustering for\ntriadic data. Our replicable benchmarks demonstrate that the proposed\ngraph-based approach, Triframes, shows state-of-the art results on this task on\na FrameNet-derived dataset and performing on par with competitive methods on a\nverb class clustering task.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 12:55:31 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 16:17:39 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Ustalov", "Dmitry", ""], ["Panchenko", "Alexander", ""], ["Kutuzov", "Andrei", ""], ["Biemann", "Chris", ""], ["Ponzetto", "Simone Paolo", ""]]}, {"id": "1805.04787", "submitter": "Luheng He", "authors": "Luheng He, Kenton Lee, Omer Levy, Luke Zettlemoyer", "title": "Jointly Predicting Predicates and Arguments in Neural Semantic Role\n  Labeling", "comments": "5 pages, ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent BIO-tagging-based neural semantic role labeling models are very high\nperforming, but assume gold predicates as part of the input and cannot\nincorporate span-level features. We propose an end-to-end approach for jointly\npredicting all predicates, arguments spans, and the relations between them. The\nmodel makes independent decisions about what relationship, if any, holds\nbetween every possible word-span pair, and learns contextualized span\nrepresentations that provide rich, shared input features for each decision.\nExperiments demonstrate that this approach sets a new state of the art on\nPropBank SRL without gold predicates.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 21:32:50 GMT"}, {"version": "v2", "created": "Mon, 13 Aug 2018 04:02:25 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["He", "Luheng", ""], ["Lee", "Kenton", ""], ["Levy", "Omer", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1805.04793", "submitter": "Li Dong", "authors": "Li Dong, Mirella Lapata", "title": "Coarse-to-Fine Decoding for Neural Semantic Parsing", "comments": "Accepted by ACL-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic parsing aims at mapping natural language utterances into structured\nmeaning representations. In this work, we propose a structure-aware neural\narchitecture which decomposes the semantic parsing process into two stages.\nGiven an input utterance, we first generate a rough sketch of its meaning,\nwhere low-level information (such as variable names and arguments) is glossed\nover. Then, we fill in missing details by taking into account the natural\nlanguage input and the sketch itself. Experimental results on four datasets\ncharacteristic of different domains and meaning representations show that our\napproach consistently improves performance, achieving competitive results\ndespite the use of relatively simple decoders.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 22:06:17 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Dong", "Li", ""], ["Lapata", "Mirella", ""]]}, {"id": "1805.04803", "submitter": "Tiancheng Zhao", "authors": "Tiancheng Zhao and Maxine Eskenazi", "title": "Zero-Shot Dialog Generation with Cross-Domain Latent Actions", "comments": "Accepted as a long paper in SIGDIAL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces zero-shot dialog generation (ZSDG), as a step towards\nneural dialog systems that can instantly generalize to new situations with\nminimal data. ZSDG enables an end-to-end generative dialog system to generalize\nto a new domain for which only a domain description is provided and no training\ndialogs are available. Then a novel learning framework, Action Matching, is\nproposed. This algorithm can learn a cross-domain embedding space that models\nthe semantics of dialog responses which, in turn, lets a neural dialog\ngeneration model generalize to new domains. We evaluate our methods on a new\nsynthetic dialog dataset, and an existing human-human dialog dataset. Results\nshow that our method has superior performance in learning dialog models that\nrapidly adapt their behavior to new domains and suggests promising future\nresearch.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 01:07:32 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Zhao", "Tiancheng", ""], ["Eskenazi", "Maxine", ""]]}, {"id": "1805.04813", "submitter": "Wenhu Chen", "authors": "Shuo Ren, Wenhu Chen, Shujie Liu, Mu Li, Ming Zhou, Shuai Ma", "title": "Triangular Architecture for Rare Language Translation", "comments": "Accepted to ACL 2018, 10 pages, 5 figures, 5 tables (with 5-5-5-5\n  high score)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) performs poor on the low-resource language\npair $(X,Z)$, especially when $Z$ is a rare language. By introducing another\nrich language $Y$, we propose a novel triangular training architecture (TA-NMT)\nto leverage bilingual data $(Y,Z)$ (may be small) and $(X,Y)$ (can be rich) to\nimprove the translation performance of low-resource pairs. In this triangular\narchitecture, $Z$ is taken as the intermediate latent variable, and translation\nmodels of $Z$ are jointly optimized with a unified bidirectional EM algorithm\nunder the goal of maximizing the translation likelihood of $(X,Y)$. Empirical\nresults demonstrate that our method significantly improves the translation\nquality of rare languages on MultiUN and IWSLT2012 datasets, and achieves even\nbetter performance combining back-translation methods.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 03:35:09 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 04:56:06 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Ren", "Shuo", ""], ["Chen", "Wenhu", ""], ["Liu", "Shujie", ""], ["Li", "Mu", ""], ["Zhou", "Ming", ""], ["Ma", "Shuai", ""]]}, {"id": "1805.04827", "submitter": "Yangming Zhou", "authors": "Qi Wang, Chenming Xu, Yangming Zhou, Tong Ruan, Daqi Gao, Ping He", "title": "An attention-based Bi-GRU-CapsNet model for hypernymy detection between\n  compound entities", "comments": "5 pages, 3 figures. Accepted as short paper by 2018 International\n  Conference on Bioinformatics and Biomedicine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entities are usually composable and extensible. Typical examples are\nnames of symptoms and diseases in medical areas. To distinguish these entities\nfrom general entities, we name them \\textit{compound entities}. In this paper,\nwe present an attention-based Bi-GRU-CapsNet model to detect hypernymy\nrelationship between compound entities. Our model consists of several important\ncomponents. To avoid the out-of-vocabulary problem, English words or Chinese\ncharacters in compound entities are fed into the bidirectional gated recurrent\nunits. An attention mechanism is designed to focus on the differences between\nthe two compound entities. Since there are some different cases in hypernymy\nrelationship between compound entities, capsule network is finally employed to\ndecide whether the hypernymy relationship exists or not. Experimental results\ndemonstrate\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 06:09:40 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 09:05:09 GMT"}, {"version": "v3", "created": "Tue, 27 Nov 2018 13:38:37 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Wang", "Qi", ""], ["Xu", "Chenming", ""], ["Zhou", "Yangming", ""], ["Ruan", "Tong", ""], ["Gao", "Daqi", ""], ["He", "Ping", ""]]}, {"id": "1805.04833", "submitter": "Angela Fan", "authors": "Angela Fan, Mike Lewis, Yann Dauphin", "title": "Hierarchical Neural Story Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore story generation: creative systems that can build coherent and\nfluent passages of text about a topic. We collect a large dataset of 300K\nhuman-written stories paired with writing prompts from an online forum. Our\ndataset enables hierarchical story generation, where the model first generates\na premise, and then transforms it into a passage of text. We gain further\nimprovements with a novel form of model fusion that improves the relevance of\nthe story to the prompt, and adding a new gated multi-scale self-attention\nmechanism to model long-range context. Experiments show large improvements over\nstrong baselines on both automated and human evaluations. Human judges prefer\nstories generated by our approach to those from a strong non-hierarchical model\nby a factor of two to one.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 07:07:08 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Fan", "Angela", ""], ["Lewis", "Mike", ""], ["Dauphin", "Yann", ""]]}, {"id": "1805.04836", "submitter": "Md Rizwan Parvez", "authors": "Md Rizwan Parvez, Saikat Chakraborty, Baishakhi Ray, Kai-Wei Chang", "title": "Building Language Models for Text with Named Entities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text in many domains involves a significant amount of named entities.\nPredict- ing the entity names is often challenging for a language model as they\nappear less frequent on the training corpus. In this paper, we propose a novel\nand effective approach to building a discriminative language model which can\nlearn the entity names by leveraging their entity type information. We also\nintroduce two benchmark datasets based on recipes and Java programming codes,\non which we evalu- ate the proposed model. Experimental re- sults show that our\nmodel achieves 52.2% better perplexity in recipe generation and 22.06% on code\ngeneration than the state-of-the-art language models.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 07:46:12 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Parvez", "Md Rizwan", ""], ["Chakraborty", "Saikat", ""], ["Ray", "Baishakhi", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "1805.04843", "submitter": "Yansen Wang", "authors": "Yansen Wang, Chenyi Liu, Minlie Huang, Liqiang Nie", "title": "Learning to Ask Questions in Open-domain Conversational Systems with\n  Typed Decoders", "comments": "ACL2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asking good questions in large-scale, open-domain conversational systems is\nquite significant yet rather untouched. This task, substantially different from\ntraditional question generation, requires to question not only with various\npatterns but also on diverse and relevant topics. We observe that a good\nquestion is a natural composition of {\\it interrogatives}, {\\it topic words},\nand {\\it ordinary words}. Interrogatives lexicalize the pattern of questioning,\ntopic words address the key information for topic transition in dialogue, and\nordinary words play syntactical and grammatical roles in making a natural\nsentence. We devise two typed decoders (\\textit{soft typed decoder} and\n\\textit{hard typed decoder}) in which a type distribution over the three types\nis estimated and used to modulate the final generation distribution. Extensive\nexperiments show that the typed decoders outperform state-of-the-art baselines\nand can generate more meaningful questions.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 08:38:20 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Wang", "Yansen", ""], ["Liu", "Chenyi", ""], ["Huang", "Minlie", ""], ["Nie", "Liqiang", ""]]}, {"id": "1805.04869", "submitter": "Shuming Ma", "authors": "Shuming Ma, Xu Sun, Junyang Lin, Houfeng Wang", "title": "Autoencoder as Assistant Supervisor: Improving Text Representation for\n  Chinese Social Media Text Summarization", "comments": "accepted by ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the current abstractive text summarization models are based on the\nsequence-to-sequence model (Seq2Seq). The source content of social media is\nlong and noisy, so it is difficult for Seq2Seq to learn an accurate semantic\nrepresentation. Compared with the source content, the annotated summary is\nshort and well written. Moreover, it shares the same meaning as the source\ncontent. In this work, we supervise the learning of the representation of the\nsource content with that of the summary. In implementation, we regard a summary\nautoencoder as an assistant supervisor of Seq2Seq. Following previous work, we\nevaluate our model on a popular Chinese social media dataset. Experimental\nresults show that our model achieves the state-of-the-art performances on the\nbenchmark dataset.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 12:23:44 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Ma", "Shuming", ""], ["Sun", "Xu", ""], ["Lin", "Junyang", ""], ["Wang", "Houfeng", ""]]}, {"id": "1805.04871", "submitter": "Shuming Ma", "authors": "Shuming Ma, Xu Sun, Yizhong Wang, Junyang Lin", "title": "Bag-of-Words as Target for Neural Machine Translation", "comments": "accepted by ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A sentence can be translated into more than one correct sentences. However,\nmost of the existing neural machine translation models only use one of the\ncorrect translations as the targets, and the other correct sentences are\npunished as the incorrect sentences in the training stage. Since most of the\ncorrect translations for one sentence share the similar bag-of-words, it is\npossible to distinguish the correct translations from the incorrect ones by the\nbag-of-words. In this paper, we propose an approach that uses both the\nsentences and the bag-of-words as targets in the training stage, in order to\nencourage the model to generate the potentially correct sentences that are not\nappeared in the training set. We evaluate our model on a Chinese-English\ntranslation dataset, and experiments show our model outperforms the strong\nbaselines by the BLEU score of 4.55.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 12:24:20 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Ma", "Shuming", ""], ["Sun", "Xu", ""], ["Wang", "Yizhong", ""], ["Lin", "Junyang", ""]]}, {"id": "1805.04876", "submitter": "Radu Tudor Ionescu", "authors": "Andrei M. Butnaru and Radu Tudor Ionescu", "title": "UnibucKernel Reloaded: First Place in Arabic Dialect Identification for\n  the Second Year in a Row", "comments": "This paper presents the UnibucKernel team's participation at the 2018\n  Arabic Dialect Identification Shared Task. Accepted at the VarDial Workshop\n  of COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a machine learning approach that ranked on the first place in the\nArabic Dialect Identification (ADI) Closed Shared Tasks of the 2018 VarDial\nEvaluation Campaign. The proposed approach combines several kernels using\nmultiple kernel learning. While most of our kernels are based on character\np-grams (also known as n-grams) extracted from speech or phonetic transcripts,\nwe also use a kernel based on dialectal embeddings generated from audio\nrecordings by the organizers. In the learning stage, we independently employ\nKernel Discriminant Analysis (KDA) and Kernel Ridge Regression (KRR).\nPreliminary experiments indicate that KRR provides better classification\nresults. Our approach is shallow and simple, but the empirical results obtained\nin the 2018 ADI Closed Shared Task prove that it achieves the best performance.\nFurthermore, our top macro-F1 score (58.92%) is significantly better than the\nsecond best score (57.59%) in the 2018 ADI Shared Task, according to the\nstatistical significance test performed by the organizers. Nevertheless, we\nobtain even better post-competition results (a macro-F1 score of 62.28%) using\nthe audio embeddings released by the organizers after the competition. With a\nvery similar approach (that did not include phonetic features), we also ranked\nfirst in the ADI Closed Shared Tasks of the 2017 VarDial Evaluation Campaign,\nsurpassing the second best method by 4.62%. We therefore conclude that our\nmultiple kernel learning method is the best approach to date for Arabic dialect\nidentification.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 12:53:47 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 12:48:33 GMT"}, {"version": "v3", "created": "Thu, 21 Jun 2018 16:24:46 GMT"}, {"version": "v4", "created": "Sat, 28 Jul 2018 11:03:54 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Butnaru", "Andrei M.", ""], ["Ionescu", "Radu Tudor", ""]]}, {"id": "1805.04893", "submitter": "Rui Zhang", "authors": "Rui Zhang, Cicero Nogueira dos Santos, Michihiro Yasunaga, Bing Xiang,\n  Dragomir Radev", "title": "Neural Coreference Resolution with Deep Biaffine Attention by Joint\n  Mention Detection and Mention Clustering", "comments": "ACL2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coreference resolution aims to identify in a text all mentions that refer to\nthe same real-world entity. The state-of-the-art end-to-end neural coreference\nmodel considers all text spans in a document as potential mentions and learns\nto link an antecedent for each possible mention. In this paper, we propose to\nimprove the end-to-end coreference resolution system by (1) using a biaffine\nattention model to get antecedent scores for each possible mention, and (2)\njointly optimizing the mention detection accuracy and the mention clustering\nlog-likelihood given the mention cluster labels. Our model achieves the\nstate-of-the-art performance on the CoNLL-2012 Shared Task English test set.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 14:24:31 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Zhang", "Rui", ""], ["Santos", "Cicero Nogueira dos", ""], ["Yasunaga", "Michihiro", ""], ["Xiang", "Bing", ""], ["Radev", "Dragomir", ""]]}, {"id": "1805.04905", "submitter": "Nathan Schneider", "authors": "Nathan Schneider, Jena D. Hwang, Vivek Srikumar, Jakob Prange, Austin\n  Blodgett, Sarah R. Moeller, Aviram Stern, Adi Bitan, Omri Abend", "title": "Comprehensive Supersense Disambiguation of English Prepositions and\n  Possessives", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic relations are often signaled with prepositional or possessive\nmarking--but extreme polysemy bedevils their analysis and automatic\ninterpretation. We introduce a new annotation scheme, corpus, and task for the\ndisambiguation of prepositions and possessives in English. Unlike previous\napproaches, our annotations are comprehensive with respect to types and tokens\nof these markers; use broadly applicable supersense classes rather than\nfine-grained dictionary definitions; unite prepositions and possessives under\nthe same class inventory; and distinguish between a marker's lexical\ncontribution and the role it marks in the context of a predicate or scene.\nStrong interannotator agreement rates, as well as encouraging disambiguation\nresults with established supervised methods, speak to the viability of the\nscheme and task.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 16:08:57 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Schneider", "Nathan", ""], ["Hwang", "Jena D.", ""], ["Srikumar", "Vivek", ""], ["Prange", "Jakob", ""], ["Blodgett", "Austin", ""], ["Moeller", "Sarah R.", ""], ["Stern", "Aviram", ""], ["Bitan", "Adi", ""], ["Abend", "Omri", ""]]}, {"id": "1805.04908", "submitter": "Gail Weiss", "authors": "Gail Weiss, Yoav Goldberg, Eran Yahav", "title": "On the Practical Computational Power of Finite Precision RNNs for\n  Language Recognition", "comments": "Accepted as a short paper in ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Recurrent Neural Networks (RNNs) are famously known to be Turing\ncomplete, this relies on infinite precision in the states and unbounded\ncomputation time. We consider the case of RNNs with finite precision whose\ncomputation time is linear in the input length. Under these limitations, we\nshow that different RNN variants have different computational power. In\nparticular, we show that the LSTM and the Elman-RNN with ReLU activation are\nstrictly stronger than the RNN with a squashing activation and the GRU. This is\nachieved because LSTMs and ReLU-RNNs can easily implement counting behavior. We\nshow empirically that the LSTM does indeed learn to effectively use the\ncounting mechanism.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 16:28:32 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Weiss", "Gail", ""], ["Goldberg", "Yoav", ""], ["Yahav", "Eran", ""]]}, {"id": "1805.04988", "submitter": "Jon Gauthier", "authors": "Jon Gauthier, Roger Levy, Joshua B. Tenenbaum", "title": "Word learning and the acquisition of syntactic--semantic overhypotheses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Children learning their first language face multiple problems of induction:\nhow to learn the meanings of words, and how to build meaningful phrases from\nthose words according to syntactic rules. We consider how children might solve\nthese problems efficiently by solving them jointly, via a computational model\nthat learns the syntax and semantics of multi-word utterances in a grounded\nreference game. We select a well-studied empirical case in which children are\naware of patterns linking the syntactic and semantic properties of words ---\nthat the properties picked out by base nouns tend to be related to shape, while\nprenominal adjectives tend to refer to other properties such as color. We show\nthat children applying such inductive biases are accurately reflecting the\nstatistics of child-directed speech, and that inducing similar biases in our\ncomputational model captures children's behavior in a classic adjective\nlearning experiment. Our model incorporating such biases also demonstrates a\nclear data efficiency in learning, relative to a baseline model that learns\nwithout forming syntax-sensitive overhypotheses of word meaning. Thus solving a\nmore complex joint inference problem may make the full problem of language\nacquisition easier, not harder.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 02:20:07 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Gauthier", "Jon", ""], ["Levy", "Roger", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1805.04993", "submitter": "Alice Lai", "authors": "Alice Lai, Joel Tetreault", "title": "Discourse Coherence in the Wild: A Dataset, Evaluation and Methods", "comments": "Accepted at SIGDIAL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To date there has been very little work on assessing discourse coherence\nmethods on real-world data. To address this, we present a new corpus of\nreal-world texts (GCDC) as well as the first large-scale evaluation of leading\ndiscourse coherence algorithms. We show that neural models, including two that\nwe introduce here (SentAvg and ParSeq), tend to perform best. We analyze these\nperformance differences and discuss patterns we observed in low coherence texts\nin four domains.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 02:48:29 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Lai", "Alice", ""], ["Tetreault", "Joel", ""]]}, {"id": "1805.05062", "submitter": "Maha Elbayad", "authors": "Maha Elbayad and Laurent Besacier and Jakob Verbeek", "title": "Token-level and sequence-level loss smoothing for RNN language models", "comments": "Accepted by ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the effectiveness of recurrent neural network language models, their\nmaximum likelihood estimation suffers from two limitations. It treats all\nsentences that do not match the ground truth as equally poor, ignoring the\nstructure of the output space. Second, it suffers from \"exposure bias\": during\ntraining tokens are predicted given ground-truth sequences, while at test time\nprediction is conditioned on generated output sequences. To overcome these\nlimitations we build upon the recent reward augmented maximum likelihood\napproach \\ie sequence-level smoothing that encourages the model to predict\nsentences close to the ground truth according to a given performance metric. We\nextend this approach to token-level loss smoothing, and propose improvements to\nthe sequence-level smoothing approach. Our experiments on two different tasks,\nimage captioning and machine translation, show that token-level and\nsequence-level loss smoothing are complementary, and significantly improve\nresults.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 08:37:50 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Elbayad", "Maha", ""], ["Besacier", "Laurent", ""], ["Verbeek", "Jakob", ""]]}, {"id": "1805.05081", "submitter": "Zhongyang Li", "authors": "Zhongyang Li, Xiao Ding, Ting Liu", "title": "Constructing Narrative Event Evolutionary Graph for Script Event\n  Prediction", "comments": "This paper has been accepted by IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Script event prediction requires a model to predict the subsequent event\ngiven an existing event context. Previous models based on event pairs or event\nchains cannot make full use of dense event connections, which may limit their\ncapability of event prediction. To remedy this, we propose constructing an\nevent graph to better utilize the event network information for script event\nprediction. In particular, we first extract narrative event chains from large\nquantities of news corpus, and then construct a narrative event evolutionary\ngraph (NEEG) based on the extracted chains. NEEG can be seen as a knowledge\nbase that describes event evolutionary principles and patterns. To solve the\ninference problem on NEEG, we present a scaled graph neural network (SGNN) to\nmodel event interactions and learn better event representations. Instead of\ncomputing the representations on the whole graph, SGNN processes only the\nconcerned nodes each time, which makes our model feasible to large-scale\ngraphs. By comparing the similarity between input context event representations\nand candidate event representations, we can choose the most reasonable\nsubsequent event. Experimental results on widely used New York Times corpus\ndemonstrate that our model significantly outperforms state-of-the-art baseline\nmethods, by using standard multiple choice narrative cloze evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 09:23:26 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 13:53:08 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Li", "Zhongyang", ""], ["Ding", "Xiao", ""], ["Liu", "Ting", ""]]}, {"id": "1805.05089", "submitter": "Sara Stymne", "authors": "Sara Stymne, Miryam de Lhoneux, Aaron Smith, and Joakim Nivre", "title": "Parser Training with Heterogeneous Treebanks", "comments": "7 pages. Accepted to ACL 2018, short papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to make the most of multiple heterogeneous treebanks when training a\nmonolingual dependency parser is an open question. We start by investigating\npreviously suggested, but little evaluated, strategies for exploiting multiple\ntreebanks based on concatenating training sets, with or without fine-tuning. We\ngo on to propose a new method based on treebank embeddings. We perform\nexperiments for several languages and show that in many cases fine-tuning and\ntreebank embeddings lead to substantial improvements over single treebanks or\nconcatenation, with average gains of 2.0--3.5 LAS points. We argue that\ntreebank embeddings should be preferred due to their conceptual simplicity,\nflexibility and extensibility.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 09:52:27 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Stymne", "Sara", ""], ["de Lhoneux", "Miryam", ""], ["Smith", "Aaron", ""], ["Nivre", "Joakim", ""]]}, {"id": "1805.05091", "submitter": "Jos\\'e David Lopes", "authors": "Jos\\'e Lopes, Nils Hemmingsson, Oliver \\r{A}strand", "title": "The Spot the Difference corpus: a multi-modal corpus of spontaneous task\n  oriented spoken interactions", "comments": "Proceedings of the Language Evaluation and Resources Conference\n  (LREC) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the Spot the Difference Corpus which contains 54\ninteractions between pairs of subjects interacting to find differences in two\nvery similar scenes. The setup used, the participants' metadata and details\nabout collection are described. We are releasing this corpus of task-oriented\nspontaneous dialogues. This release includes rich transcriptions, annotations,\naudio and video. We believe that this dataset constitutes a valuable resource\nto study several dimensions of human communication that go from turn-taking to\nthe study of referring expressions. In our preliminary analyses we have looked\nat task success (how many differences were found out of the total number of\ndifferences) and how it evolves over time. In addition we have looked at scene\ncomplexity provided by the RGB components' entropy and how it could relate to\nspeech overlaps, interruptions and the expression of uncertainty. We found\nthere is a tendency that more complex scenes have more competitive\ninterruptions.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 09:57:47 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Lopes", "Jos\u00e9", ""], ["Hemmingsson", "Nils", ""], ["\u00c5strand", "Oliver", ""]]}, {"id": "1805.05095", "submitter": "Duygu Ataman", "authors": "Duygu Ataman", "title": "Bianet: A Parallel News Corpus in Turkish, Kurdish and English", "comments": "Published at the LREC Workshop MLP-MomenT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new open-source parallel corpus consisting of news articles\ncollected from the Bianet magazine, an online newspaper that publishes Turkish\nnews, often along with their translations in English and Kurdish. In this\npaper, we describe the collection process of the corpus and its statistical\nproperties. We validate the benefit of using the Bianet corpus by evaluating\nbilingual and multilingual neural machine translation models in English-Turkish\nand English-Kurdish directions.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 10:07:51 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Ataman", "Duygu", ""]]}, {"id": "1805.05181", "submitter": "Jingjing Xu", "authors": "Jingjing Xu, Xu Sun, Qi Zeng, Xuancheng Ren, Xiaodong Zhang, Houfeng\n  Wang, Wenjie Li", "title": "Unpaired Sentiment-to-Sentiment Translation: A Cycled Reinforcement\n  Learning Approach", "comments": "Accepted by ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of sentiment-to-sentiment \"translation\" is to change the underlying\nsentiment of a sentence while keeping its content. The main challenge is the\nlack of parallel data. To solve this problem, we propose a cycled reinforcement\nlearning method that enables training on unpaired data by collaboration between\na neutralization module and an emotionalization module. We evaluate our\napproach on two review datasets, Yelp and Amazon. Experimental results show\nthat our approach significantly outperforms the state-of-the-art systems.\nEspecially, the proposed method substantially improves the content preservation\nperformance. The BLEU score is improved from 1.64 to 22.46 and from 0.56 to\n14.06 on the two datasets, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 14:17:03 GMT"}, {"version": "v2", "created": "Sun, 5 Aug 2018 08:00:35 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Xu", "Jingjing", ""], ["Sun", "Xu", ""], ["Zeng", "Qi", ""], ["Ren", "Xuancheng", ""], ["Zhang", "Xiaodong", ""], ["Wang", "Houfeng", ""], ["Li", "Wenjie", ""]]}, {"id": "1805.05202", "submitter": "Daniel Fern\\'andez-Gonz\\'alez", "authors": "Daniel Fern\\'andez-Gonz\\'alez and Carlos G\\'omez-Rodr\\'iguez", "title": "A Dynamic Oracle for Linear-Time 2-Planar Dependency Parsing", "comments": "Proceedings of NAACL-HLT 2018. 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient dynamic oracle for training the 2-Planar\ntransition-based parser, a linear-time parser with over 99% coverage on\nnon-projective syntactic corpora. This novel approach outperforms the static\ntraining strategy in the vast majority of languages tested and scored better on\nmost datasets than the arc-hybrid parser enhanced with the SWAP transition,\nwhich can handle unrestricted non-projectivity.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 14:46:18 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 18:40:56 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Fern\u00e1ndez-Gonz\u00e1lez", "Daniel", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "1805.05225", "submitter": "Tamer Alkhouli", "authors": "Albert Zeyer, Tamer Alkhouli, and Hermann Ney", "title": "RETURNN as a Generic Flexible Neural Toolkit with Application to\n  Translation and Speech Recognition", "comments": "accepted as demo paper on ACL 2018", "journal-ref": null, "doi": "10.18653/v1/P18-4022", "report-no": null, "categories": "cs.NE cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare the fast training and decoding speed of RETURNN of attention\nmodels for translation, due to fast CUDA LSTM kernels, and a fast pure\nTensorFlow beam search decoder. We show that a layer-wise pretraining scheme\nfor recurrent attention models gives over 1% BLEU improvement absolute and it\nallows to train deeper recurrent encoder networks. Promising preliminary\nresults on max. expected BLEU training are presented. We are able to train\nstate-of-the-art models for translation and end-to-end models for speech\nrecognition and show results on WMT 2017 and Switchboard. The flexibility of\nRETURNN allows a fast research feedback loop to experiment with alternative\narchitectures, and its generality allows to use it on a wide range of\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 15:23:40 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 13:33:46 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Zeyer", "Albert", ""], ["Alkhouli", "Tamer", ""], ["Ney", "Hermann", ""]]}, {"id": "1805.05237", "submitter": "Sabrina Stehwien", "authors": "Sabrina Stehwien, Ngoc Thang Vu, Antje Schweitzer", "title": "Effects of Word Embeddings on Neural Network-based Pitch Accent\n  Detection", "comments": "This is an updated version of the paper that has been accepted at\n  Speech Prosody 2018 and published on the ISCA archive. The updates consist of\n  minor corrections that do not change the main conclusions in this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pitch accent detection often makes use of both acoustic and lexical features\nbased on the fact that pitch accents tend to correlate with certain words. In\nthis paper, we extend a pitch accent detector that involves a convolutional\nneural network to include word embeddings, which are state-of-the-art vector\nrepresentations of words. We examine the effect these features have on\nwithin-corpus and cross-corpus experiments on three English datasets. The\nresults show that while word embeddings can improve the performance in\ncorpus-dependent experiments, they also have the potential to make\ngeneralization to unseen data more challenging.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 15:40:31 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 12:32:17 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Stehwien", "Sabrina", ""], ["Vu", "Ngoc Thang", ""], ["Schweitzer", "Antje", ""]]}, {"id": "1805.05271", "submitter": "Guokan Shang", "authors": "Guokan Shang (1 and 2), Wensi Ding (1), Zekun Zhang (1), Antoine\n  Jean-Pierre Tixier (1), Polykarpos Meladianos (1 and 3), Michalis\n  Vazirgiannis (1 and 3), Jean-Pierre Lorr\\'e (2) ((1) \\'Ecole Polytechnique,\n  (2) Linagora, (3) AUEB)", "title": "Unsupervised Abstractive Meeting Summarization with Multi-Sentence\n  Compression and Budgeted Submodular Maximization", "comments": "Published as a long paper at ACL 2018. v2: updated Figure 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel graph-based framework for abstractive meeting speech\nsummarization that is fully unsupervised and does not rely on any annotations.\nOur work combines the strengths of multiple recent approaches while addressing\ntheir weaknesses. Moreover, we leverage recent advances in word embeddings and\ngraph degeneracy applied to NLP to take exterior semantic knowledge into\naccount, and to design custom diversity and informativeness measures.\nExperiments on the AMI and ICSI corpus show that our system improves on the\nstate-of-the-art. Code and data are publicly available, and our system can be\ninteractively tested.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 16:36:11 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 15:12:47 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Shang", "Guokan", "", "1 and 2"], ["Ding", "Wensi", "", "1 and 3"], ["Zhang", "Zekun", "", "1 and 3"], ["Tixier", "Antoine Jean-Pierre", "", "1 and 3"], ["Meladianos", "Polykarpos", "", "1 and 3"], ["Vazirgiannis", "Michalis", "", "1 and 3"], ["Lorr\u00e9", "Jean-Pierre", ""]]}, {"id": "1805.05286", "submitter": "Chunchuan Lyu Mr.", "authors": "Chunchuan Lyu and Ivan Titov", "title": "AMR Parsing as Graph Prediction with Latent Alignment", "comments": "Accepted to ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract meaning representations (AMRs) are broad-coverage sentence-level\nsemantic representations. AMRs represent sentences as rooted labeled directed\nacyclic graphs. AMR parsing is challenging partly due to the lack of annotated\nalignments between nodes in the graphs and words in the corresponding\nsentences. We introduce a neural parser which treats alignments as latent\nvariables within a joint probabilistic model of concepts, relations and\nalignments. As exact inference requires marginalizing over alignments and is\ninfeasible, we use the variational auto-encoding framework and a continuous\nrelaxation of the discrete alignments. We show that joint modeling is\npreferable to using a pipeline of align and parse. The parser achieves the best\nreported results on the standard benchmark (74.4% on LDC2016E25).\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 16:56:36 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Lyu", "Chunchuan", ""], ["Titov", "Ivan", ""]]}, {"id": "1805.05345", "submitter": "Cristian Danescu-Niculescu-Mizil", "authors": "Justine Zhang, Jonathan P. Chang, Cristian Danescu-Niculescu-Mizil,\n  Lucas Dixon, Yiqing Hua, Nithum Thain, Dario Taraborelli", "title": "Conversations Gone Awry: Detecting Early Signs of Conversational Failure", "comments": "To appear in the Proceedings of ACL 2018, 15 pages, 1 figure. Data,\n  quiz, code and additional information at\n  http://www.cs.cornell.edu/~cristian/Conversations_gone_awry.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.HC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main challenges online social systems face is the prevalence of\nantisocial behavior, such as harassment and personal attacks. In this work, we\nintroduce the task of predicting from the very start of a conversation whether\nit will get out of hand. As opposed to detecting undesirable behavior after the\nfact, this task aims to enable early, actionable prediction at a time when the\nconversation might still be salvaged.\n  To this end, we develop a framework for capturing pragmatic devices---such as\npoliteness strategies and rhetorical prompts---used to start a conversation,\nand analyze their relation to its future trajectory. Applying this framework in\na controlled setting, we demonstrate the feasibility of detecting early warning\nsigns of antisocial behavior in online discussions.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 18:00:03 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Zhang", "Justine", ""], ["Chang", "Jonathan P.", ""], ["Danescu-Niculescu-Mizil", "Cristian", ""], ["Dixon", "Lucas", ""], ["Hua", "Yiqing", ""], ["Thain", "Nithum", ""], ["Taraborelli", "Dario", ""]]}, {"id": "1805.05361", "submitter": "Dinghan Shen", "authors": "Dinghan Shen, Qinliang Su, Paidamoyo Chapfuwa, Wenlin Wang, Guoyin\n  Wang, Lawrence Carin, Ricardo Henao", "title": "NASH: Toward End-to-End Neural Architecture for Generative Semantic\n  Hashing", "comments": "To appear at ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic hashing has become a powerful paradigm for fast similarity search in\nmany information retrieval systems. While fairly successful, previous\ntechniques generally require two-stage training, and the binary constraints are\nhandled ad-hoc. In this paper, we present an end-to-end Neural Architecture for\nSemantic Hashing (NASH), where the binary hashing codes are treated as\nBernoulli latent variables. A neural variational inference framework is\nproposed for training, where gradients are directly back-propagated through the\ndiscrete latent variable to optimize the hash function. We also draw\nconnections between proposed method and rate-distortion theory, which provides\na theoretical foundation for the effectiveness of the proposed framework.\nExperimental results on three public datasets demonstrate that our method\nsignificantly outperforms several state-of-the-art models on both unsupervised\nand supervised scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 18:04:28 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Shen", "Dinghan", ""], ["Su", "Qinliang", ""], ["Chapfuwa", "Paidamoyo", ""], ["Wang", "Wenlin", ""], ["Wang", "Guoyin", ""], ["Carin", "Lawrence", ""], ["Henao", "Ricardo", ""]]}, {"id": "1805.05370", "submitter": "Ionu\\c{t} Teodor \\c{S}orodoc", "authors": "Laura Aina, Carina Silberer, Ionut-Teodor Sorodoc, Matthijs Westera,\n  Gemma Boleda", "title": "AMORE-UPF at SemEval-2018 Task 4: BiLSTM with Entity Library", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes our winning contribution to SemEval 2018 Task 4:\nCharacter Identification on Multiparty Dialogues. It is a simple, standard\nmodel with one key innovation, an entity library. Our results show that this\ninnovation greatly facilitates the identification of infrequent characters.\nBecause of the generic nature of our model, this finding is potentially\nrelevant to any task that requires effective learning from sparse or unbalanced\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 18:17:12 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Aina", "Laura", ""], ["Silberer", "Carina", ""], ["Sorodoc", "Ionut-Teodor", ""], ["Westera", "Matthijs", ""], ["Boleda", "Gemma", ""]]}, {"id": "1805.05377", "submitter": "Nicholas FitzGerald", "authors": "Nicholas FitzGerald, Julian Michael, Luheng He, Luke Zettlemoyer", "title": "Large-Scale QA-SRL Parsing", "comments": "10 pages, 3 figures, 8 tables. Accepted to ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new large-scale corpus of Question-Answer driven Semantic Role\nLabeling (QA-SRL) annotations, and the first high-quality QA-SRL parser. Our\ncorpus, QA-SRL Bank 2.0, consists of over 250,000 question-answer pairs for\nover 64,000 sentences across 3 domains and was gathered with a new\ncrowd-sourcing scheme that we show has high precision and good recall at modest\ncost. We also present neural models for two QA-SRL subtasks: detecting argument\nspans for a predicate and generating questions to label the semantic\nrelationship. The best models achieve question accuracy of 82.6% and span-level\naccuracy of 77.6% (under human evaluation) on the full pipelined QA-SRL\nprediction task. They can also, as we show, be used to gather additional\nannotations at low cost.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 18:50:11 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["FitzGerald", "Nicholas", ""], ["Michael", "Julian", ""], ["He", "Luheng", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1805.05388", "submitter": "Nikunj Saunshi", "authors": "Mikhail Khodak, Nikunj Saunshi, Yingyu Liang, Tengyu Ma, Brandon\n  Stewart, Sanjeev Arora", "title": "A La Carte Embedding: Cheap but Effective Induction of Semantic Feature\n  Vectors", "comments": "11 pages, 2 figures, To appear in ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivations like domain adaptation, transfer learning, and feature learning\nhave fueled interest in inducing embeddings for rare or unseen words, n-grams,\nsynsets, and other textual features. This paper introduces a la carte\nembedding, a simple and general alternative to the usual word2vec-based\napproaches for building such representations that is based upon recent\ntheoretical results for GloVe-like embeddings. Our method relies mainly on a\nlinear transformation that is efficiently learnable using pretrained word\nvectors and linear regression. This transform is applicable on the fly in the\nfuture when a new text feature or rare word is encountered, even if only a\nsingle usage example is available. We introduce a new dataset showing how the a\nla carte method requires fewer examples of words in context to learn\nhigh-quality embeddings and we obtain state-of-the-art results on a nonce task\nand some unsupervised document classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 19:11:33 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Khodak", "Mikhail", ""], ["Saunshi", "Nikunj", ""], ["Liang", "Yingyu", ""], ["Ma", "Tengyu", ""], ["Stewart", "Brandon", ""], ["Arora", "Sanjeev", ""]]}, {"id": "1805.05470", "submitter": "Davide Frazzetto", "authors": "Davide Frazzetto, Bijay Neupane, Torben Bach Pedersen, Thomas Dyhre\n  Nielsen", "title": "Adaptive User-Oriented Direct Load-Control of Residential Flexible\n  Devices", "comments": "10 pages plus 1 page references, 11 figures, conference: ACM e-Energy\n  2018", "journal-ref": null, "doi": "10.1145/3208903.3208924", "report-no": null, "categories": "cs.CY cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Demand Response (DR) schemes are effective tools to maintain a dynamic\nbalance in energy markets with higher integration of fluctuating renewable\nenergy sources. DR schemes can be used to harness residential devices'\nflexibility and to utilize it to achieve social and financial objectives.\nHowever, existing DR schemes suffer from low user participation as they fail at\ntaking into account the users' requirements. First, DR schemes are highly\ndemanding for the users, as users need to provide direct information, e.g. via\nsurveys, on their energy consumption preferences. Second, the user utility\nmodels based on these surveys are hard-coded and do not adapt over time. Third,\nthe existing scheduling techniques require the users to input their energy\nrequirements on a daily basis. As an alternative, this paper proposes a DR\nscheme for user-oriented direct load-control of residential appliances\noperations. Instead of relying on user surveys to evaluate the user utility, we\npropose an online data-driven approach for estimating user utility functions,\npurely based on available load consumption data, that adaptively models the\nusers' preference over time. Our scheme is based on a day-ahead scheduling\ntechnique that transparently prescribes the users with optimal device operation\nschedules that take into account both financial benefits and user-perceived\nquality of service. To model day-ahead user energy demand and flexibility, we\npropose a probabilistic approach for generating flexibility models under\nuncertainty. Results on both real-world and simulated datasets show that our DR\nscheme can provide significant financial benefits while preserving the\nuser-perceived quality of service.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 12:36:04 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Frazzetto", "Davide", ""], ["Neupane", "Bijay", ""], ["Pedersen", "Torben Bach", ""], ["Nielsen", "Thomas Dyhre", ""]]}, {"id": "1805.05491", "submitter": "Martin Mueller", "authors": "Martin Mueller, Marcel Salath\\'e", "title": "Crowdbreaks: Tracking Health Trends using Public Social Media Data and\n  Crowdsourcing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the past decade, tracking health trends using social media data has shown\ngreat promise, due to a powerful combination of massive adoption of social\nmedia around the world, and increasingly potent hardware and software that\nenables us to work with these new big data streams. At the same time, many\nchallenging problems have been identified. First, there is often a mismatch\nbetween how rapidly online data can change, and how rapidly algorithms are\nupdated, which means that there is limited reusability for algorithms trained\non past data as their performance decreases over time. Second, much of the work\nis focusing on specific issues during a specific past period in time, even\nthough public health institutions would need flexible tools to assess multiple\nevolving situations in real time. Third, most tools providing such capabilities\nare proprietary systems with little algorithmic or data transparency, and thus\nlittle buy-in from the global public health and research community. Here, we\nintroduce Crowdbreaks, an open platform which allows tracking of health trends\nby making use of continuous crowdsourced labelling of public social media\ncontent. The system is built in a way which automatizes the typical workflow\nfrom data collection, filtering, labelling and training of machine learning\nclassifiers and therefore can greatly accelerate the research process in the\npublic health domain. This work introduces the technical aspects of the\nplatform and explores its future use cases.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 22:59:56 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Mueller", "Martin", ""], ["Salath\u00e9", "Marcel", ""]]}, {"id": "1805.05492", "submitter": "Pramod Kaushik Mudrakarta", "authors": "Pramod Kaushik Mudrakarta, Ankur Taly, Mukund Sundararajan, Kedar\n  Dhamdhere", "title": "Did the Model Understand the Question?", "comments": "ACL 2018 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze state-of-the-art deep learning models for three tasks: question\nanswering on (1) images, (2) tables, and (3) passages of text. Using the notion\nof \\emph{attribution} (word importance), we find that these deep networks often\nignore important question terms. Leveraging such behavior, we perturb questions\nto craft a variety of adversarial examples. Our strongest attacks drop the\naccuracy of a visual question answering model from $61.1\\%$ to $19\\%$, and that\nof a tabular question answering model from $33.5\\%$ to $3.3\\%$. Additionally,\nwe show how attributions can strengthen attacks proposed by Jia and Liang\n(2017) on paragraph comprehension models. Our results demonstrate that\nattributions can augment standard measures of accuracy and empower\ninvestigation of model performance. When a model is accurate but for the wrong\nreasons, attributions can surface erroneous logic in the model that indicates\ninadequacies in the test data.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 23:10:28 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Mudrakarta", "Pramod Kaushik", ""], ["Taly", "Ankur", ""], ["Sundararajan", "Mukund", ""], ["Dhamdhere", "Kedar", ""]]}, {"id": "1805.05542", "submitter": "Jing Li", "authors": "Jing Li, Yan Song, Haisong Zhang, Shuming Shi", "title": "A Manually Annotated Chinese Corpus for Non-task-oriented Dialogue\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a large-scale corpus for non-task-oriented dialogue\nresponse selection, which contains over 27K distinct prompts more than 82K\nresponses collected from social media. To annotate this corpus, we define a\n5-grade rating scheme: bad, mediocre, acceptable, good, and excellent,\naccording to the relevance, coherence, informativeness, interestingness, and\nthe potential to move a conversation forward. To test the validity and\nusefulness of the produced corpus, we compare various unsupervised and\nsupervised models for response selection. Experimental results confirm that the\nproposed corpus is helpful in training response selection models.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 03:06:04 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Li", "Jing", ""], ["Song", "Yan", ""], ["Zhang", "Haisong", ""], ["Shi", "Shuming", ""]]}, {"id": "1805.05557", "submitter": "Alexander Mathews", "authors": "Alexander Mathews, Lexing Xie, Xuming He", "title": "Simplifying Sentences with Sequence to Sequence Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We simplify sentences with an attentive neural network sequence to sequence\nmodel, dubbed S4. The model includes a novel word-copy mechanism and loss\nfunction to exploit linguistic similarities between the original and simplified\nsentences. It also jointly uses pre-trained and fine-tuned word embeddings to\ncapture the semantics of complex sentences and to mitigate the effects of\nlimited data. When trained and evaluated on pairs of sentences from thousands\nof news articles, we observe a 8.8 point improvement in BLEU score over a\nsequence to sequence baseline; however, learning word substitutions remains\ndifficult. Such sequence to sequence models are promising for other text\ngeneration tasks such as style transfer.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 04:49:55 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Mathews", "Alexander", ""], ["Xie", "Lexing", ""], ["He", "Xuming", ""]]}, {"id": "1805.05574", "submitter": "Xuesong Yang", "authors": "Di He, Boon Pang Lim, Xuesong Yang, Mark Hasegawa-Johnson, Deming Chen", "title": "Improved ASR for Under-Resourced Languages Through Multi-Task Learning\n  with Acoustic Landmarks", "comments": "Submitted in Interspeech2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Furui first demonstrated that the identity of both consonant and vowel can be\nperceived from the C-V transition; later, Stevens proposed that acoustic\nlandmarks are the primary cues for speech perception, and that steady-state\nregions are secondary or supplemental. Acoustic landmarks are perceptually\nsalient, even in a language one doesn't speak, and it has been demonstrated\nthat non-speakers of the language can identify features such as the primary\narticulator of the landmark. These factors suggest a strategy for developing\nlanguage-independent automatic speech recognition: landmarks can potentially be\nlearned once from a suitably labeled corpus and rapidly applied to many other\nlanguages. This paper proposes enhancing the cross-lingual portability of a\nneural network by using landmarks as the secondary task in multi-task learning\n(MTL). The network is trained in a well-resourced source language with both\nphone and landmark labels (English), then adapted to an under-resourced target\nlanguage with only word labels (Iban). Landmark-tasked MTL reduces\nsource-language phone error rate by 2.9% relative, and reduces target-language\nword error rate by 1.9%-5.9% depending on the amount of target-language\ntraining data. These results suggest that landmark-tasked MTL causes the DNN to\nlearn hidden-node features that are useful for cross-lingual adaptation.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 05:46:23 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["He", "Di", ""], ["Lim", "Boon Pang", ""], ["Yang", "Xuesong", ""], ["Hasegawa-Johnson", "Mark", ""], ["Chen", "Deming", ""]]}, {"id": "1805.05581", "submitter": "Reina Akama", "authors": "Reina Akama, Kento Watanabe, Sho Yokoi, Sosuke Kobayashi, Kentaro Inui", "title": "Unsupervised Learning of Style-sensitive Word Vectors", "comments": "7 pages, Accepted at The 56th Annual Meeting of the Association for\n  Computational Linguistics (ACL 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the first study aimed at capturing stylistic similarity\nbetween words in an unsupervised manner. We propose extending the continuous\nbag of words (CBOW) model (Mikolov et al., 2013) to learn style-sensitive word\nvectors using a wider context window under the assumption that the style of all\nthe words in an utterance is consistent. In addition, we introduce a novel task\nto predict lexical stylistic similarity and to create a benchmark dataset for\nthis task. Our experiment with this dataset supports our assumption and\ndemonstrates that the proposed extensions contribute to the acquisition of\nstyle-sensitive word embeddings.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 06:19:12 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Akama", "Reina", ""], ["Watanabe", "Kento", ""], ["Yokoi", "Sho", ""], ["Kobayashi", "Sosuke", ""], ["Inui", "Kentaro", ""]]}, {"id": "1805.05588", "submitter": "Bingfeng Luo", "authors": "Bingfeng Luo, Yansong Feng, Zheng Wang, Songfang Huang, Rui Yan and\n  Dongyan Zhao", "title": "Marrying up Regular Expressions with Neural Networks: A Case Study for\n  Spoken Language Understanding", "comments": "11 Pages, 2 Figures, Accepted by ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of many natural language processing (NLP) tasks is bound by the\nnumber and quality of annotated data, but there is often a shortage of such\ntraining data. In this paper, we ask the question: \"Can we combine a neural\nnetwork (NN) with regular expressions (RE) to improve supervised learning for\nNLP?\". In answer, we develop novel methods to exploit the rich expressiveness\nof REs at different levels within a NN, showing that the combination\nsignificantly enhances the learning effectiveness when a small number of\ntraining examples are available. We evaluate our approach by applying it to\nspoken language understanding for intent detection and slot filling.\nExperimental results show that our approach is highly effective in exploiting\nthe available training data, giving a clear boost to the RE-unaware NN.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 06:40:44 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Luo", "Bingfeng", ""], ["Feng", "Yansong", ""], ["Wang", "Zheng", ""], ["Huang", "Songfang", ""], ["Yan", "Rui", ""], ["Zhao", "Dongyan", ""]]}, {"id": "1805.05593", "submitter": "Masaki Asada", "authors": "Masaki Asada, Makoto Miwa and Yutaka Sasaki", "title": "Enhancing Drug-Drug Interaction Extraction from Texts by Molecular\n  Structure Information", "comments": "accepted as a short paper at ACL2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel neural method to extract drug-drug interactions (DDIs)\nfrom texts using external drug molecular structure information. We encode\ntextual drug pairs with convolutional neural networks and their molecular pairs\nwith graph convolutional networks (GCNs), and then we concatenate the outputs\nof these two networks. In the experiments, we show that GCNs can predict DDIs\nfrom the molecular structures of drugs in high accuracy and the molecular\ninformation can enhance text-based DDI extraction by 2.39 percent points in the\nF-score on the DDIExtraction 2013 shared task data set.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 07:03:21 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Asada", "Masaki", ""], ["Miwa", "Makoto", ""], ["Sasaki", "Yutaka", ""]]}, {"id": "1805.05622", "submitter": "Marko Smilevski", "authors": "Marko Smilevski, Ilija Lalkovski, Gjorgji Madjarov", "title": "Stories for Images-in-Sequence by using Visual and Narrative Components", "comments": "12 pages, 4 figures, ICT Innovations 2018", "journal-ref": "ICT Innovations 2018. Engineering and Life Sciences. ICT 2018.\n  Communications in Computer and Information Science, vol 940. Springer, Cham\n  (2018) pp. 148-159", "doi": "10.1007/978-3-030-00825-3_13", "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research in AI is focusing towards generating narrative stories about\nvisual scenes. It has the potential to achieve more human-like understanding\nthan just basic description generation of images- in-sequence. In this work, we\npropose a solution for generating stories for images-in-sequence that is based\non the Sequence to Sequence model. As a novelty, our encoder model is composed\nof two separate encoders, one that models the behaviour of the image sequence\nand other that models the sentence-story generated for the previous image in\nthe sequence of images. By using the image sequence encoder we capture the\ntemporal dependencies between the image sequence and the sentence-story and by\nusing the previous sentence-story encoder we achieve a better story flow. Our\nsolution generates long human-like stories that not only describe the visual\ncontext of the image sequence but also contains narrative and evaluative\nlanguage. The obtained results were confirmed by manual human evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 08:15:40 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2018 20:36:51 GMT"}, {"version": "v3", "created": "Sat, 22 Sep 2018 23:49:05 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Smilevski", "Marko", ""], ["Lalkovski", "Ilija", ""], ["Madjarov", "Gjorgji", ""]]}, {"id": "1805.05631", "submitter": "William Schueller", "authors": "William Schueller, Vittorio Loreto and Pierre-Yves Oudeyer", "title": "Complexity Reduction in the Negotiation of New Lexical Conventions", "comments": "Published at CogSci 2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the process of collectively inventing new words for new concepts in a\npopulation, conflicts can quickly become numerous, in the form of synonymy and\nhomonymy. Remembering all of them could cost too much memory, and remembering\ntoo few may slow down the overall process. Is there an efficient behavior that\ncould help balance the two? The Naming Game is a multi-agent computational\nmodel for the emergence of language, focusing on the negotiation of new lexical\nconventions, where a common lexicon self-organizes but going through a phase of\nhigh complexity. Previous work has been done on the control of complexity\ngrowth in this particular model, by allowing agents to actively choose what\nthey talk about. However, those strategies were relying on ad hoc heuristics\nhighly dependent on fine-tuning of parameters. We define here a new principled\nmeasure and a new strategy, based on the beliefs of each agent on the global\nstate of the population. The measure does not rely on heavy computation, and is\ncognitively plausible. The new strategy yields an efficient control of\ncomplexity growth, along with a faster agreement process. Also, we show that\nshort-term memory is enough to build relevant beliefs about the global lexicon.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 08:23:56 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 17:00:18 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Schueller", "William", ""], ["Loreto", "Vittorio", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1805.05691", "submitter": "Graham Spinks", "authors": "Graham Spinks and Marie-Francine Moens", "title": "Generating Continuous Representations of Medical Texts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an architecture that generates medical texts while learning an\ninformative, continuous representation with discriminative features. During\ntraining the input to the system is a dataset of captions for medical X-Rays.\nThe acquired continuous representations are of particular interest for use in\nmany machine learning techniques where the discrete and high-dimensional nature\nof textual input is an obstacle. We use an Adversarially Regularized\nAutoencoder to create realistic text in both an unconditional and conditional\nsetting. We show that this technique is applicable to medical texts which often\ncontain syntactic and domain-specific shorthands. A quantitative evaluation\nshows that we achieve a lower model perplexity than a traditional LSTM\ngenerator.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 10:32:53 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Spinks", "Graham", ""], ["Moens", "Marie-Francine", ""]]}, {"id": "1805.05758", "submitter": "Thomas Wolf", "authors": "Thomas Wolf, Julien Chaumond, Clement Delangue", "title": "Continuous Learning in a Hierarchical Multiscale Neural Network", "comments": "5 pages, 2 figures, accepted as short paper at ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We reformulate the problem of encoding a multi-scale representation of a\nsequence in a language model by casting it in a continuous learning framework.\nWe propose a hierarchical multi-scale language model in which short time-scale\ndependencies are encoded in the hidden state of a lower-level recurrent neural\nnetwork while longer time-scale dependencies are encoded in the dynamic of the\nlower-level network by having a meta-learner update the weights of the\nlower-level neural network in an online meta-learning fashion. We use elastic\nweights consolidation as a higher-level to prevent catastrophic forgetting in\nour continuous learning framework.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 13:37:33 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Wolf", "Thomas", ""], ["Chaumond", "Julien", ""], ["Delangue", "Clement", ""]]}, {"id": "1805.05826", "submitter": "Jonathan Le Roux", "authors": "Hiroshi Seki, Takaaki Hori, Shinji Watanabe, Jonathan Le Roux, John R.\n  Hershey", "title": "A Purely End-to-end System for Multi-speaker Speech Recognition", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been growing interest in multi-speaker speech\nrecognition, where the utterances of multiple speakers are recognized from\ntheir mixture. Promising techniques have been proposed for this task, but\nearlier works have required additional training data such as isolated source\nsignals or senone alignments for effective learning. In this paper, we propose\na new sequence-to-sequence framework to directly decode multiple label\nsequences from a single speech sequence by unifying source separation and\nspeech recognition functions in an end-to-end manner. We further propose a new\nobjective function to improve the contrast between the hidden vectors to avoid\ngenerating similar hypotheses. Experimental results show that the model is\ndirectly able to learn a mapping from a speech mixture to multiple label\nsequences, achieving 83.1 % relative improvement compared to a model trained\nwithout the proposed objective. Interestingly, the results are comparable to\nthose produced by previous end-to-end works featuring explicit separation and\nrecognition modules.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 14:45:33 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Seki", "Hiroshi", ""], ["Hori", "Takaaki", ""], ["Watanabe", "Shinji", ""], ["Roux", "Jonathan Le", ""], ["Hershey", "John R.", ""]]}, {"id": "1805.05927", "submitter": "Abdul Hai Zahid Mohammed", "authors": "M A H Zahid, Ankush Mittal, R.C. Joshi, and G. Atluri", "title": "CLINIQA: A Machine Intelligence Based Clinical Question Answering System", "comments": "This manuscript was submitted to IEEE Transactions on Information\n  Technology in Biomedicine in 2007 and was in second revision when it was\n  withdrawn. As I moved to industry and could not get enough time to revise it.\n  I am uploading it here for anyone interested in conventional ML based\n  approach to NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent developments in the field of biomedicine have made large volumes\nof biomedical literature available to the medical practitioners. Due to the\nlarge size and lack of efficient searching strategies, medical practitioners\nstruggle to obtain necessary information available in the biomedical\nliterature. Moreover, the most sophisticated search engines of age are not\nintelligent enough to interpret the clinicians' questions. These facts reflect\nthe urgent need of an information retrieval system that accepts the queries\nfrom medical practitioners' in natural language and returns the answers quickly\nand efficiently. In this paper, we present an implementation of a machine\nintelligence based CLINIcal Question Answering system (CLINIQA) to answer\nmedical practitioner's questions. The system was rigorously evaluated on\ndifferent text mining algorithms and the best components for the system were\nselected. The system makes use of Unified Medical Language System for semantic\nanalysis of both questions and medical documents. In addition, the system\nemploys supervised machine learning algorithms for classification of the\ndocuments, identifying the focus of the question and answer selection.\nEffective domain-specific heuristics are designed for answer ranking. The\nperformance evaluation on hundred clinical questions shows the effectiveness of\nour approach.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 17:45:25 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Zahid", "M A H", ""], ["Mittal", "Ankush", ""], ["Joshi", "R. C.", ""], ["Atluri", "G.", ""]]}, {"id": "1805.05942", "submitter": "Xinya Du", "authors": "Xinya Du and Claire Cardie", "title": "Harvesting Paragraph-Level Question-Answer Pairs from Wikipedia", "comments": "Accepted to ACL 2018 (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the task of generating from Wikipedia articles question-answer pairs\nthat cover content beyond a single sentence. We propose a neural network\napproach that incorporates coreference knowledge via a novel gating mechanism.\nCompared to models that only take into account sentence-level information\n(Heilman and Smith, 2010; Du et al., 2017; Zhou et al., 2017), we find that the\nlinguistic knowledge introduced by the coreference representation aids question\ngeneration significantly, producing models that outperform the current\nstate-of-the-art. We apply our system (composed of an answer span extraction\nsystem and the passage-level QG system) to the 10,000 top-ranking Wikipedia\narticles and create a corpus of over one million question-answer pairs. We also\nprovide a qualitative analysis for this large-scale generated corpus from\nWikipedia.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 17:58:25 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Du", "Xinya", ""], ["Cardie", "Claire", ""]]}, {"id": "1805.06016", "submitter": "Vinodkumar Prabhakaran", "authors": "Vinodkumar Prabhakaran, Premkumar Ganeshkumar, Owen Rambow", "title": "Author Commitment and Social Power: Automatic Belief Tagging to Infer\n  the Social Context of Interactions", "comments": "NAACL 2018 long paper. 9 pages plus references", "journal-ref": "North American Chapter of the Association for Computational\n  Linguistics: Human Language Technologies (NAACL-HLT). 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding how social power structures affect the way we interact with one\nanother is of great interest to social scientists who want to answer\nfundamental questions about human behavior, as well as to computer scientists\nwho want to build automatic methods to infer the social contexts of\ninteractions. In this paper, we employ advancements in extra-propositional\nsemantics extraction within NLP to study how author commitment reflects the\nsocial context of an interaction. Specifically, we investigate whether the\nlevel of commitment expressed by individuals in an organizational interaction\nreflects the hierarchical power structures they are part of. We find that\nsubordinates use significantly more instances of non-commitment than superiors.\nMore importantly, we also find that subordinates attribute propositions to\nother agents more often than superiors do --- an aspect that has not been\nstudied before. Finally, we show that enriching lexical features with\ncommitment labels captures important distinctions in social meanings.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 20:05:58 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Prabhakaran", "Vinodkumar", ""], ["Ganeshkumar", "Premkumar", ""], ["Rambow", "Owen", ""]]}, {"id": "1805.06061", "submitter": "Roy Schwartz", "authors": "Roy Schwartz, Sam Thomson, and Noah A. Smith", "title": "SoPa: Bridging CNNs, RNNs, and Weighted Finite-State Machines", "comments": "ACL 2018, 12 pages. Code available at\n  https://github.com/Noahs-ARK/soft_patterns", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent and convolutional neural networks comprise two distinct families of\nmodels that have proven to be useful for encoding natural language utterances.\nIn this paper we present SoPa, a new model that aims to bridge these two\napproaches. SoPa combines neural representation learning with weighted\nfinite-state automata (WFSAs) to learn a soft version of traditional surface\npatterns. We show that SoPa is an extension of a one-layer CNN, and that such\nCNNs are equivalent to a restricted version of SoPa, and accordingly, to a\nrestricted form of WFSA. Empirically, on three text classification tasks, SoPa\nis comparable or better than both a BiLSTM (RNN) baseline and a CNN baseline,\nand is particularly useful in small data settings.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 23:03:01 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Schwartz", "Roy", ""], ["Thomson", "Sam", ""], ["Smith", "Noah A.", ""]]}, {"id": "1805.06064", "submitter": "Qingyun Wang", "authors": "Qingyun Wang, Zhihao Zhou, Lifu Huang, Spencer Whitehead, Boliang\n  Zhang, Heng Ji, Kevin Knight", "title": "Paper Abstract Writing through Editing Mechanism", "comments": "* Equal contribution. 6 pages. Accepted by ACL 2018; The code and\n  dataset are available at https://github.com/EagleW/Writing-editing-Network", "journal-ref": null, "doi": "10.18653/v1/P18-2042", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a paper abstract writing system based on an attentive neural\nsequence-to-sequence model that can take a title as input and automatically\ngenerate an abstract. We design a novel Writing-editing Network that can attend\nto both the title and the previously generated abstract drafts and then\niteratively revise and polish the abstract. With two series of Turing tests,\nwhere the human judges are asked to distinguish the system-generated abstracts\nfrom human-written ones, our system passes Turing tests by junior domain\nexperts at a rate up to 30% and by non-expert at a rate up to 80%.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 23:13:23 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Wang", "Qingyun", ""], ["Zhou", "Zhihao", ""], ["Huang", "Lifu", ""], ["Whitehead", "Spencer", ""], ["Zhang", "Boliang", ""], ["Ji", "Heng", ""], ["Knight", "Kevin", ""]]}, {"id": "1805.06087", "submitter": "Ari Holtzman", "authors": "Ari Holtzman, Jan Buys, Maxwell Forbes, Antoine Bosselut, David Golub,\n  and Yejin Choi", "title": "Learning to Write with Cooperative Discriminators", "comments": "In Proceedings of ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recurrent Neural Networks (RNNs) are powerful autoregressive sequence models,\nbut when used to generate natural language their output tends to be overly\ngeneric, repetitive, and self-contradictory. We postulate that the objective\nfunction optimized by RNN language models, which amounts to the overall\nperplexity of a text, is not expressive enough to capture the notion of\ncommunicative goals described by linguistic principles such as Grice's Maxims.\nWe propose learning a mixture of multiple discriminative models that can be\nused to complement the RNN generator and guide the decoding process. Human\nevaluation demonstrates that text generated by our system is preferred over\nthat of baselines by a large margin and significantly enhances the overall\ncoherence, style, and information content of the generated text.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 01:27:58 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Holtzman", "Ari", ""], ["Buys", "Jan", ""], ["Forbes", "Maxwell", ""], ["Bosselut", "Antoine", ""], ["Golub", "David", ""], ["Choi", "Yejin", ""]]}, {"id": "1805.06088", "submitter": "Yitong Li", "authors": "Yitong Li and Timothy Baldwin and Trevor Cohn", "title": "What's in a Domain? Learning Domain-Robust Text Representations using\n  Adversarial Training", "comments": "Accepted to NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most real world language problems require learning from heterogenous corpora,\nraising the problem of learning robust models which generalise well to both\nsimilar (in domain) and dissimilar (out of domain) instances to those seen in\ntraining. This requires learning an underlying task, while not learning\nirrelevant signals and biases specific to individual domains. We propose a\nnovel method to optimise both in- and out-of-domain accuracy based on joint\nlearning of a structured neural model with domain-specific and domain-general\ncomponents, coupled with adversarial training for domain. Evaluating on\nmulti-domain language identification and multi-domain sentiment analysis, we\nshow substantial improvements over standard domain adaptation techniques, and\ndomain-adversarial training.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 01:29:14 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Li", "Yitong", ""], ["Baldwin", "Timothy", ""], ["Cohn", "Trevor", ""]]}, {"id": "1805.06093", "submitter": "Yitong Li", "authors": "Yitong Li, Timothy Baldwin, and Trevor Cohn", "title": "Towards Robust and Privacy-preserving Text Representations", "comments": "Accepted to ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Written text often provides sufficient clues to identify the author, their\ngender, age, and other important attributes. Consequently, the authorship of\ntraining and evaluation corpora can have unforeseen impacts, including\ndiffering model performance for different user groups, as well as privacy\nimplications. In this paper, we propose an approach to explicitly obscure\nimportant author characteristics at training time, such that representations\nlearned are invariant to these attributes. Evaluating on two tasks, we show\nthat this leads to increased privacy in the learned representations, as well as\nmore robust models to varying evaluation conditions, including out-of-domain\ncorpora.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 01:57:47 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Li", "Yitong", ""], ["Baldwin", "Timothy", ""], ["Cohn", "Trevor", ""]]}, {"id": "1805.06122", "submitter": "Fei Liu", "authors": "Fei Liu, Trevor Cohn, Timothy Baldwin", "title": "Narrative Modeling with Memory Chains and Semantic Supervision", "comments": "Accepted to ACL 2018 (camera-ready)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Story comprehension requires a deep semantic understanding of the narrative,\nmaking it a challenging task. Inspired by previous studies on ROC Story Cloze\nTest, we propose a novel method, tracking various semantic aspects with\nexternal neural memory chains while encouraging each to focus on a particular\nsemantic aspect. Evaluated on the task of story ending prediction, our model\ndemonstrates superior performance to a collection of competitive baselines,\nsetting a new state of the art.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 04:17:18 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Liu", "Fei", ""], ["Cohn", "Trevor", ""], ["Baldwin", "Timothy", ""]]}, {"id": "1805.06130", "submitter": "Yong Cheng", "authors": "Yong Cheng, Zhaopeng Tu, Fandong Meng, Junjie Zhai, Yang Liu", "title": "Towards Robust Neural Machine Translation", "comments": "Accepted by ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Small perturbations in the input can severely distort intermediate\nrepresentations and thus impact translation quality of neural machine\ntranslation (NMT) models. In this paper, we propose to improve the robustness\nof NMT models with adversarial stability training. The basic idea is to make\nboth the encoder and decoder in NMT models robust against input perturbations\nby enabling them to behave similarly for the original input and its perturbed\ncounterpart. Experimental results on Chinese-English, English-German and\nEnglish-French translation tasks show that our approaches can not only achieve\nsignificant improvements over strong NMT systems but also improve the\nrobustness of NMT models.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 04:51:29 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Cheng", "Yong", ""], ["Tu", "Zhaopeng", ""], ["Meng", "Fandong", ""], ["Zhai", "Junjie", ""], ["Liu", "Yang", ""]]}, {"id": "1805.06145", "submitter": "Zhen Wang", "authors": "Zhen Wang, Jiachen Liu, Xinyan Xiao, Yajuan Lyu, Tian Wu", "title": "Joint Training of Candidate Extraction and Answer Selection for Reading\n  Comprehension", "comments": "10 pages, Accepted by ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While sophisticated neural-based techniques have been developed in reading\ncomprehension, most approaches model the answer in an independent manner,\nignoring its relations with other answer candidates. This problem can be even\nworse in open-domain scenarios, where candidates from multiple passages should\nbe combined to answer a single question. In this paper, we formulate reading\ncomprehension as an extract-then-select two-stage procedure. We first extract\nanswer candidates from passages, then select the final answer by combining\ninformation from all the candidates. Furthermore, we regard candidate\nextraction as a latent variable and train the two-stage process jointly with\nreinforcement learning. As a result, our approach has improved the\nstate-of-the-art performance significantly on two challenging open-domain\nreading comprehension datasets. Further analysis demonstrates the effectiveness\nof our model components, especially the information fusion of all the\ncandidates and the joint training of the extract-then-select procedure.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 06:14:31 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Wang", "Zhen", ""], ["Liu", "Jiachen", ""], ["Xiao", "Xinyan", ""], ["Lyu", "Yajuan", ""], ["Wu", "Tian", ""]]}, {"id": "1805.06150", "submitter": "Aleksandra Faust", "authors": "Pararth Shah, Marek Fiser, Aleksandra Faust, J. Chase Kew, and Dilek\n  Hakkani-Tur", "title": "FollowNet: Robot Navigation by Following Natural Language Directions\n  with Deep Reinforcement Learning", "comments": "7 pages, 8 figures", "journal-ref": "Third Workshop in Machine Learning in the Planning and Control of\n  Robot Motion at ICRA, 2018", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and following directions provided by humans can enable robots\nto navigate effectively in unknown situations. We present FollowNet, an\nend-to-end differentiable neural architecture for learning multi-modal\nnavigation policies. FollowNet maps natural language instructions as well as\nvisual and depth inputs to locomotion primitives. FollowNet processes\ninstructions using an attention mechanism conditioned on its visual and depth\ninput to focus on the relevant parts of the command while performing the\nnavigation task. Deep reinforcement learning (RL) a sparse reward learns\nsimultaneously the state representation, the attention function, and control\npolicies. We evaluate our agent on a dataset of complex natural language\ndirections that guide the agent through a rich and realistic dataset of\nsimulated homes. We show that the FollowNet agent learns to execute previously\nunseen instructions described with a similar vocabulary, and successfully\nnavigates along paths not encountered during training. The agent shows 30%\nimprovement over a baseline model without the attention mechanism, with 52%\nsuccess rate at novel instructions.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 06:29:18 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Shah", "Pararth", ""], ["Fiser", "Marek", ""], ["Faust", "Aleksandra", ""], ["Kew", "J. Chase", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "1805.06165", "submitter": "Noga Zaslavsky", "authors": "Noga Zaslavsky, Charles Kemp, Naftali Tishby, Terry Regier", "title": "Color naming reflects both perceptual structure and communicative need", "comments": null, "journal-ref": "Proceedings of the 40th Annual Conference of the Cognitive Science\n  Society (pp. 1250 - 1255), 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gibson et al. (2017) argued that color naming is shaped by patterns of\ncommunicative need. In support of this claim, they showed that color naming\nsystems across languages support more precise communication about warm colors\nthan cool colors, and that the objects we talk about tend to be warm-colored\nrather than cool-colored. Here, we present new analyses that alter this\npicture. We show that greater communicative precision for warm than for cool\ncolors, and greater communicative need, may both be explained by perceptual\nstructure. However, using an information-theoretic analysis, we also show that\ncolor naming across languages bears signs of communicative need beyond what\nwould be predicted by perceptual structure alone. We conclude that color naming\nis shaped both by perceptual structure, as has traditionally been argued, and\nby patterns of communicative need, as argued by Gibson et al. - although for\nreasons other than those they advanced.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 07:34:00 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2018 05:09:33 GMT"}, {"version": "v3", "created": "Fri, 3 Aug 2018 00:30:34 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Zaslavsky", "Noga", ""], ["Kemp", "Charles", ""], ["Tishby", "Naftali", ""], ["Regier", "Terry", ""]]}, {"id": "1805.06201", "submitter": "Sosuke Kobayashi", "authors": "Sosuke Kobayashi", "title": "Contextual Augmentation: Data Augmentation by Words with Paradigmatic\n  Relations", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel data augmentation for labeled sentences called contextual\naugmentation. We assume an invariance that sentences are natural even if the\nwords in the sentences are replaced with other words with paradigmatic\nrelations. We stochastically replace words with other words that are predicted\nby a bi-directional language model at the word positions. Words predicted\naccording to a context are numerous but appropriate for the augmentation of the\noriginal words. Furthermore, we retrofit a language model with a\nlabel-conditional architecture, which allows the model to augment sentences\nwithout breaking the label-compatibility. Through the experiments for six\nvarious different text classification tasks, we demonstrate that the proposed\nmethod improves classifiers based on the convolutional or recurrent neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 09:10:21 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Kobayashi", "Sosuke", ""]]}, {"id": "1805.06239", "submitter": "Shiyu Zhou", "authors": "Shiyu Zhou, Linhao Dong, Shuang Xu, Bo Xu", "title": "A Comparison of Modeling Units in Sequence-to-Sequence Speech\n  Recognition with the Transformer on Mandarin Chinese", "comments": "arXiv admin note: substantial text overlap with arXiv:1804.10752", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of modeling units is critical to automatic speech recognition\n(ASR) tasks. Conventional ASR systems typically choose context-dependent states\n(CD-states) or context-dependent phonemes (CD-phonemes) as their modeling\nunits. However, it has been challenged by sequence-to-sequence attention-based\nmodels, which integrate an acoustic, pronunciation and language model into a\nsingle neural network. On English ASR tasks, previous attempts have already\nshown that the modeling unit of graphemes can outperform that of phonemes by\nsequence-to-sequence attention-based model.\n  In this paper, we are concerned with modeling units on Mandarin Chinese ASR\ntasks using sequence-to-sequence attention-based models with the Transformer.\nFive modeling units are explored including context-independent phonemes\n(CI-phonemes), syllables, words, sub-words and characters. Experiments on HKUST\ndatasets demonstrate that the lexicon free modeling units can outperform\nlexicon related modeling units in terms of character error rate (CER). Among\nfive modeling units, character based model performs best and establishes a new\nstate-of-the-art CER of $26.64\\%$ on HKUST datasets without a hand-designed\nlexicon and an extra language model integration, which corresponds to a $4.8\\%$\nrelative improvement over the existing best CER of $28.0\\%$ by the joint\nCTC-attention based encoder-decoder network.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 10:43:47 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 12:46:54 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Zhou", "Shiyu", ""], ["Dong", "Linhao", ""], ["Xu", "Shuang", ""], ["Xu", "Bo", ""]]}, {"id": "1805.06242", "submitter": "Chandrakant Bothe", "authors": "Chandrakant Bothe, Sven Magg, Cornelius Weber and Stefan Wermter", "title": "Conversational Analysis using Utterance-level Attention-based\n  Bidirectional Recurrent Neural Networks", "comments": "Proceedings of INTERSPEECH 2018", "journal-ref": null, "doi": "10.21437/Interspeech.2018-2527", "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent approaches for dialogue act recognition have shown that context from\npreceding utterances is important to classify the subsequent one. It was shown\nthat the performance improves rapidly when the context is taken into account.\nWe propose an utterance-level attention-based bidirectional recurrent neural\nnetwork (Utt-Att-BiRNN) model to analyze the importance of preceding utterances\nto classify the current one. In our setup, the BiRNN is given the input set of\ncurrent and preceding utterances. Our model outperforms previous models that\nuse only preceding utterances as context on the used corpus. Another\ncontribution of the article is to discover the amount of information in each\nutterance to classify the subsequent one and to show that context-based\nlearning not only improves the performance but also achieves higher confidence\nin the classification. We use character- and word-level features to represent\nthe utterances. The results are presented for character and word feature\nrepresentations and as an ensemble model of both representations. We found that\nwhen classifying short utterances, the closest preceding utterances contributes\nto a higher degree.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 10:51:56 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 12:11:59 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Bothe", "Chandrakant", ""], ["Magg", "Sven", ""], ["Weber", "Cornelius", ""], ["Wermter", "Stefan", ""]]}, {"id": "1805.06266", "submitter": "Wan-Ting Hsu", "authors": "Wan-Ting Hsu, Chieh-Kai Lin, Ming-Ying Lee, Kerui Min, Jing Tang, Min\n  Sun", "title": "A Unified Model for Extractive and Abstractive Summarization using\n  Inconsistency Loss", "comments": "9 pages, ACL 2018 oral. Project page:\n  https://hsuwanting.github.io/unified_summ/. Code:\n  https://github.com/HsuWanTing/unified-summarization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a unified model combining the strength of extractive and\nabstractive summarization. On the one hand, a simple extractive model can\nobtain sentence-level attention with high ROUGE scores but less readable. On\nthe other hand, a more complicated abstractive model can obtain word-level\ndynamic attention to generate a more readable paragraph. In our model,\nsentence-level attention is used to modulate the word-level attention such that\nwords in less attended sentences are less likely to be generated. Moreover, a\nnovel inconsistency loss function is introduced to penalize the inconsistency\nbetween two levels of attentions. By end-to-end training our model with the\ninconsistency loss and original losses of extractive and abstractive models, we\nachieve state-of-the-art ROUGE scores while being the most informative and\nreadable summarization on the CNN/Daily Mail dataset in a solid human\nevaluation.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 12:17:09 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 07:51:44 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Hsu", "Wan-Ting", ""], ["Lin", "Chieh-Kai", ""], ["Lee", "Ming-Ying", ""], ["Min", "Kerui", ""], ["Tang", "Jing", ""], ["Sun", "Min", ""]]}, {"id": "1805.06280", "submitter": "Chandrakant Bothe", "authors": "Chandrakant Bothe, Cornelius Weber, Sven Magg, and Stefan Wermter", "title": "A Context-based Approach for Dialogue Act Recognition using Simple\n  Recurrent Neural Networks", "comments": "Proceedings of the Eleventh International Conference on Language\n  Resources and Evaluation (LREC 2018)", "journal-ref": null, "doi": null, "report-no": "id:525, pages:1952--1957", "categories": "cs.CL cs.AI cs.HC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue act recognition is an important part of natural language\nunderstanding. We investigate the way dialogue act corpora are annotated and\nthe learning approaches used so far. We find that the dialogue act is\ncontext-sensitive within the conversation for most of the classes.\nNevertheless, previous models of dialogue act classification work on the\nutterance-level and only very few consider context. We propose a novel\ncontext-based learning method to classify dialogue acts using a character-level\nlanguage model utterance representation, and we notice significant improvement.\nWe evaluate this method on the Switchboard Dialogue Act corpus, and our results\nshow that the consideration of the preceding utterances as a context of the\ncurrent utterance improves dialogue act detection.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 12:58:18 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Bothe", "Chandrakant", ""], ["Weber", "Cornelius", ""], ["Magg", "Sven", ""], ["Wermter", "Stefan", ""]]}, {"id": "1805.06289", "submitter": "Firoj Alam", "authors": "Firoj Alam, Shafiq Joty, Muhammad Imran", "title": "Graph Based Semi-supervised Learning with Convolution Neural Networks to\n  Classify Crisis Related Tweets", "comments": "5 pages. arXiv admin note: substantial text overlap with\n  arXiv:1805.05151", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During time-critical situations such as natural disasters, rapid\nclassification of data posted on social networks by affected people is useful\nfor humanitarian organizations to gain situational awareness and to plan\nresponse efforts. However, the scarcity of labeled data in the early hours of a\ncrisis hinders machine learning tasks thus delays crisis response. In this\nwork, we propose to use an inductive semi-supervised technique to utilize\nunlabeled data, which is often abundant at the onset of a crisis event, along\nwith fewer labeled data. Specif- ically, we adopt a graph-based deep learning\nframework to learn an inductive semi-supervised model. We use two real-world\ncrisis datasets from Twitter to evaluate the proposed approach. Our results\nshow significant improvements using unlabeled data as compared to only using\nlabeled data.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 10:38:57 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Alam", "Firoj", ""], ["Joty", "Shafiq", ""], ["Imran", "Muhammad", ""]]}, {"id": "1805.06297", "submitter": "Mikel Artetxe", "authors": "Mikel Artetxe, Gorka Labaka, Eneko Agirre", "title": "A robust self-learning method for fully unsupervised cross-lingual\n  mappings of word embeddings", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has managed to learn cross-lingual word embeddings without\nparallel data by mapping monolingual embeddings to a shared space through\nadversarial training. However, their evaluation has focused on favorable\nconditions, using comparable corpora or closely-related languages, and we show\nthat they often fail in more realistic scenarios. This work proposes an\nalternative approach based on a fully unsupervised initialization that\nexplicitly exploits the structural similarity of the embeddings, and a robust\nself-learning algorithm that iteratively improves this solution. Our method\nsucceeds in all tested scenarios and obtains the best published results in\nstandard datasets, even surpassing previous supervised systems. Our\nimplementation is released as an open source project at\nhttps://github.com/artetxem/vecmap\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 13:23:48 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 17:21:53 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Artetxe", "Mikel", ""], ["Labaka", "Gorka", ""], ["Agirre", "Eneko", ""]]}, {"id": "1805.06344", "submitter": "Moustafa Al-Hajj", "authors": "Rita Hijazi, Amani Sabra, Moustafa Al-Hajj", "title": "Automatic Annotation of Locative and Directional Expressions in Arabic", "comments": "20 pages, in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we introduce a rule-based approach to annotate Locative and\nDirectional Expressions in Arabic natural language text. The annotation is\nbased on a constructed semantic map of the spatiality domain. Challenges are\ntwofold: first, we need to study how locative and directional expressions are\nexpressed linguistically in these texts; and second, we need to automatically\nannotate the relevant textual segments accordingly. The research method we will\nuse in this article is analytic-descriptive. We will validate this approach on\nspecific novel rich with these expressions and show that it has very promising\nresults. We will be using NOOJ as a software tool to implement finite-state\ntransducers to annotate linguistic elements according to Locative and\nDirectional Expressions. In conclusion, NOOJ allowed us to write linguistic\nrules for the automatic annotation in Arabic text of Locative and Directional\nExpressions.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 14:26:32 GMT"}, {"version": "v2", "created": "Sat, 26 May 2018 13:30:58 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Hijazi", "Rita", ""], ["Sabra", "Amani", ""], ["Al-Hajj", "Moustafa", ""]]}, {"id": "1805.06375", "submitter": "Debanjan Mahata", "authors": "Debanjan Mahata, Jasper Friedrichs, Hitkul, Rajiv Ratn Shah", "title": "#phramacovigilance - Exploring Deep Learning Techniques for Identifying\n  Mentions of Medication Intake from Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining social media messages for health and drug related information has\nreceived significant interest in pharmacovigilance research. Social media sites\n(e.g., Twitter), have been used for monitoring drug abuse, adverse reactions of\ndrug usage and analyzing expression of sentiments related to drugs. Most of\nthese studies are based on aggregated results from a large population rather\nthan specific sets of individuals. In order to conduct studies at an individual\nlevel or specific cohorts, identifying posts mentioning intake of medicine by\nthe user is necessary. Towards this objective, we train different deep neural\nnetwork classification models on a publicly available annotated dataset and\nstudy their performances on identifying mentions of personal intake of medicine\nin tweets. We also design and train a new architecture of a stacked ensemble of\nshallow convolutional neural network (CNN) ensembles. We use random search for\ntuning the hyperparameters of the models and share the details of the values\ntaken by the hyperparameters for the best learnt model in different deep neural\nnetwork architectures. Our system produces state-of-the-art results, with a\nmicro- averaged F-score of 0.693.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 15:43:21 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Mahata", "Debanjan", ""], ["Friedrichs", "Jasper", ""], ["Hitkul", "", ""], ["Shah", "Rajiv Ratn", ""]]}, {"id": "1805.06383", "submitter": "Arturo Argueta", "authors": "Arturo Argueta, David Chiang", "title": "Composing Finite State Transducers on GPUs", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighted finite-state transducers (FSTs) are frequently used in language\nprocessing to handle tasks such as part-of-speech tagging and speech\nrecognition. There has been previous work using multiple CPU cores to\naccelerate finite state algorithms, but limited attention has been given to\nparallel graphics processing unit (GPU) implementations. In this paper, we\nintroduce the first (to our knowledge) GPU implementation of the FST\ncomposition operation, and we also discuss the optimizations used to achieve\nthe best performance on this architecture. We show that our approach obtains\nspeedups of up to 6x over our serial implementation and 4.5x over OpenFST.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 15:56:17 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Argueta", "Arturo", ""], ["Chiang", "David", ""]]}, {"id": "1805.06413", "submitter": "Soujanya Poria", "authors": "Devamanyu Hazarika, Soujanya Poria, Sruthi Gorantla, Erik Cambria,\n  Roger Zimmermann, Rada Mihalcea", "title": "CASCADE: Contextual Sarcasm Detection in Online Discussion Forums", "comments": "Accepted in COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The literature in automated sarcasm detection has mainly focused on lexical,\nsyntactic and semantic-level analysis of text. However, a sarcastic sentence\ncan be expressed with contextual presumptions, background and commonsense\nknowledge. In this paper, we propose CASCADE (a ContextuAl SarCasm DEtector)\nthat adopts a hybrid approach of both content and context-driven modeling for\nsarcasm detection in online social media discussions. For the latter, CASCADE\naims at extracting contextual information from the discourse of a discussion\nthread. Also, since the sarcastic nature and form of expression can vary from\nperson to person, CASCADE utilizes user embeddings that encode stylometric and\npersonality features of the users. When used along with content-based feature\nextractors such as Convolutional Neural Networks (CNNs), we see a significant\nboost in the classification performance on a large Reddit corpus.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 16:38:38 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Hazarika", "Devamanyu", ""], ["Poria", "Soujanya", ""], ["Gorantla", "Sruthi", ""], ["Cambria", "Erik", ""], ["Zimmermann", "Roger", ""], ["Mihalcea", "Rada", ""]]}, {"id": "1805.06502", "submitter": "Qingxiang Wang", "authors": "Qingxiang Wang, Cezary Kaliszyk, Josef Urban", "title": "First Experiments with Neural Translation of Informal to Formal\n  Mathematics", "comments": "Submission to CICM'2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on our experiments to train deep neural networks that automatically\ntranslate informalized LaTeX-written Mizar texts into the formal Mizar\nlanguage. To the best of our knowledge, this is the first time when neural\nnetworks have been adopted in the formalization of mathematics. Using Luong et\nal.'s neural machine translation model (NMT), we tested our aligned\ninformal-formal corpora against various hyperparameters and evaluated their\nresults. Our experiments show that our best performing model configurations are\nable to generate correct Mizar statements on 65.73\\% of the inference data,\nwith the union of all models covering 79.17\\%. These results indicate that\nformalization through artificial neural network is a promising approach for\nautomated formalization of mathematics. We present several case studies to\nillustrate our results.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 09:11:43 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 10:02:22 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Wang", "Qingxiang", ""], ["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""]]}, {"id": "1805.06503", "submitter": "Ameet Deshpande", "authors": "Ameet Deshpande and Vedant Somani", "title": "Weight Initialization in Neural Language Models", "comments": "17 pages, 20 figures and/or tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic Similarity is an important application which finds its use in many\ndownstream NLP applications. Though the task is mathematically defined,\nsemantic similarity's essence is to capture the notions of similarity\nimpregnated in humans. Machines use some heuristics to calculate the similarity\nbetween words, but these are typically corpus dependent or are useful for\nspecific domains. The difference between Semantic Similarity and Semantic\nRelatedness motivates the development of new algorithms. For a human, the word\ncar and road are probably as related as car and bus. But this may not be the\ncase for computational methods. Ontological methods are good at encoding\nSemantic Similarity and Vector Space models are better at encoding Semantic\nRelatedness. There is a dearth of methods which leverage ontologies to create\nbetter vector representations. The aim of this proposal is to explore in the\ndirection of a hybrid method which combines statistical/vector space methods\nlike Word2Vec and Ontological methods like WordNet to leverage the advantages\nprovided by both.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 03:08:58 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Deshpande", "Ameet", ""], ["Somani", "Vedant", ""]]}, {"id": "1805.06504", "submitter": "Shen Li", "authors": "Shen Li, Zhe Zhao, Renfen Hu, Wensi Li, Tao Liu, Xiaoyong Du", "title": "Analogical Reasoning on Chinese Morphological and Semantic Relations", "comments": null, "journal-ref": "Proceedings of the 56th Annual Meeting of the Association for\n  Computational Linguistics (Volume 2: Short Papers), 138--143, 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analogical reasoning is effective in capturing linguistic regularities. This\npaper proposes an analogical reasoning task on Chinese. After delving into\nChinese lexical knowledge, we sketch 68 implicit morphological relations and 28\nexplicit semantic relations. A big and balanced dataset CA8 is then built for\nthis task, including 17813 questions. Furthermore, we systematically explore\nthe influences of vector representations, context features, and corpora on\nanalogical reasoning. With the experiments, CA8 is proved to be a reliable\nbenchmark for evaluating Chinese word embeddings.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 15:24:32 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Li", "Shen", ""], ["Zhao", "Zhe", ""], ["Hu", "Renfen", ""], ["Li", "Wensi", ""], ["Liu", "Tao", ""], ["Du", "Xiaoyong", ""]]}, {"id": "1805.06510", "submitter": "Fernando Henrique Calderon Alvarado", "authors": "Po Chen Kuo, Fernando H. Calderon Alvarado, Yi-Shin Chen", "title": "Facebook Reaction-Based Emotion Classifier as Cue for Sarcasm Detection", "comments": "10 pages ACM format", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online social media users react to content in them based on context. Emotions\nor mood play a significant part of these reactions, which has filled these\nplatforms with opinionated content. Different approaches and applications to\nmake better use of this data are continuously being developed. However, due to\nthe nature of the data, the variety of platforms, and dynamic online user\nbehavior, there are still many issues to be dealt with. It remains a challenge\nto properly obtain a reliable emotional status from a user prior to posting a\ncomment. This work introduces a methodology that explores semi-supervised\nmultilingual emotion detection based on the overlap of Facebook reactions and\ntextual data. With the resulting emotion detection system we evaluate the\npossibility of using emotions and user behavior features for the task of\nsarcasm detection. More than 1 million English and Chinese comments from over\n62,000 public Facebook pages posts have been collected and processed, conducted\nexperiments show acceptable performance metrics.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 04:46:07 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Kuo", "Po Chen", ""], ["Alvarado", "Fernando H. Calderon", ""], ["Chen", "Yi-Shin", ""]]}, {"id": "1805.06511", "submitter": "Zakaria Aldeneh", "authors": "Zakaria Aldeneh, Dimitrios Dimitriadis, Emily Mower Provost", "title": "Improving End-of-turn Detection in Spoken Dialogues by Detecting Speaker\n  Intentions as a Secondary Task", "comments": "ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work focuses on the use of acoustic cues for modeling turn-taking in\ndyadic spoken dialogues. Previous work has shown that speaker intentions (e.g.,\nasking a question, uttering a backchannel, etc.) can influence turn-taking\nbehavior and are good predictors of turn-transitions in spoken dialogues.\nHowever, speaker intentions are not readily available for use by automated\nsystems at run-time; making it difficult to use this information to anticipate\na turn-transition. To this end, we propose a multi-task neural approach for\npredicting turn- transitions and speaker intentions simultaneously. Our results\nshow that adding the auxiliary task of speaker intention prediction improves\nthe performance of turn-transition prediction in spoken dialogues, without\nrelying on additional input features during run-time.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 05:38:14 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Aldeneh", "Zakaria", ""], ["Dimitriadis", "Dimitrios", ""], ["Provost", "Emily Mower", ""]]}, {"id": "1805.06521", "submitter": "Siamak Barzegar", "authors": "Siamak Barzegar, Andre Freitas, Siegfried Handschuh and Brian Davis", "title": "Composite Semantic Relation Classification", "comments": "12 pages, 3 figures, conference", "journal-ref": null, "doi": "10.1007/978-3-319-59569-6_49", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different semantic interpretation tasks such as text entailment and question\nanswering require the classification of semantic relations between terms or\nentities within text. However, in most cases it is not possible to assign a\ndirect semantic relation between entities/terms. This paper proposes an\napproach for composite semantic relation classification, extending the\ntraditional semantic relation classification task. Different from existing\napproaches, which use machine learning models built over lexical and\ndistributional word vector features, the proposed model uses the combination of\na large commonsense knowledge base of binary relations, a distributional\nnavigational algorithm and sequence classification to provide a solution for\nthe composite semantic relation classification problem.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 20:41:33 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Barzegar", "Siamak", ""], ["Freitas", "Andre", ""], ["Handschuh", "Siegfried", ""], ["Davis", "Brian", ""]]}, {"id": "1805.06522", "submitter": "Siamak Barzegar", "authors": "Andre Freitas, Siamak Barzegar, Juliano Efson Sales, Siegfried\n  Handschuh and Brian Davis", "title": "Semantic Relatedness for All (Languages): A Comparative Analysis of\n  Multilingual Semantic Relatedness Using Machine Translation", "comments": "10 pages, 1 figure, conference", "journal-ref": null, "doi": "10.1007/978-3-319-49004-5_14", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a comparative analysis of the performance of four\nstate-of-the-art distributional semantic models (DSMs) over 11 languages,\ncontrasting the native language-specific models with the use of machine\ntranslation over English-based DSMs. The experimental results show that there\nis a significant improvement (average of 16.7% for the Spearman correlation) by\nusing state-of-the-art machine translation approaches. The results also show\nthat the benefit of using the most informative corpus outweighs the possible\nerrors introduced by the machine translation. For all languages, the\ncombination of machine translation over the Word2Vec English distributional\nmodel provided the best results consistently (average Spearman correlation of\n0.68).\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 20:43:45 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Freitas", "Andre", ""], ["Barzegar", "Siamak", ""], ["Sales", "Juliano Efson", ""], ["Handschuh", "Siegfried", ""], ["Davis", "Brian", ""]]}, {"id": "1805.06524", "submitter": "Ming Li", "authors": "Ming Li, Peilun Xiao, and Ju Zhang", "title": "Hybrid Adaptive Fuzzy Extreme Learning Machine for text classification", "comments": "2 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In traditional ELM and its improved versions suffer from the problems of\noutliers or noises due to overfitting and imbalance due to distribution. We\npropose a novel hybrid adaptive fuzzy ELM(HA-FELM), which introduces a fuzzy\nmembership function to the traditional ELM method to deal with the above\nproblems. We define the fuzzy membership function not only basing on the\ndistance between each sample and the center of the class but also the density\namong samples which based on the quantum harmonic oscillator model. The\nproposed fuzzy membership function overcomes the shortcoming of the traditional\nfuzzy membership function and could make itself adjusted according to the\nspecific distribution of different samples adaptively. Experiments show the\nproposed HA-FELM can produce better performance than SVM, ELM, and RELM in text\nclassification.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 06:11:27 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Li", "Ming", ""], ["Xiao", "Peilun", ""], ["Zhang", "Ju", ""]]}, {"id": "1805.06525", "submitter": "Ming Li", "authors": "Ming Li, Peilun Xiao, and Ju Zhang", "title": "Text classification based on ensemble extreme learning machine", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel approach based on cost-sensitive ensemble\nweighted extreme learning machine; we call this approach AE1-WELM. We apply\nthis approach to text classification. AE1-WELM is an algorithm including\nbalanced and imbalanced multiclassification for text classification. Weighted\nELM assigning the different weights to the different samples improves the\nclassification accuracy to a certain extent, but weighted ELM considers the\ndifferences between samples in the different categories only and ignores the\ndifferences between samples within the same categories. We measure the\nimportance of the documents by the sample information entropy, and generate\ncost-sensitive matrix and factor based on the document importance, then embed\nthe cost-sensitive weighted ELM into the AdaBoost.M1 framework seamlessly.\nVector space model(VSM) text representation produces the high dimensions and\nsparse features which increase the burden of ELM. To overcome this problem, we\ndevelop a text classification framework combining the word vector and AE1-WELM.\nThe experimental results show that our method provides an accurate, reliable\nand effective solution for text classification.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 06:10:46 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Li", "Ming", ""], ["Xiao", "Peilun", ""], ["Zhang", "Ju", ""]]}, {"id": "1805.06533", "submitter": "Hannah Rashkin", "authors": "Hannah Rashkin, Antoine Bosselut, Maarten Sap, Kevin Knight and Yejin\n  Choi", "title": "Modeling Naive Psychology of Characters in Simple Commonsense Stories", "comments": "Accepted to ACL 2018 (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding a narrative requires reading between the lines and reasoning\nabout the unspoken but obvious implications about events and people's mental\nstates - a capability that is trivial for humans but remarkably hard for\nmachines. To facilitate research addressing this challenge, we introduce a new\nannotation framework to explain naive psychology of story characters as\nfully-specified chains of mental states with respect to motivations and\nemotional reactions. Our work presents a new large-scale dataset with rich\nlow-level annotations and establishes baseline performance on several new\ntasks, suggesting avenues for future research.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 21:39:02 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Rashkin", "Hannah", ""], ["Bosselut", "Antoine", ""], ["Sap", "Maarten", ""], ["Knight", "Kevin", ""], ["Choi", "Yejin", ""]]}, {"id": "1805.06536", "submitter": "Ond\\v{r}ej C\\'ifka", "authors": "Ond\\v{r}ej C\\'ifka, Ond\\v{r}ej Bojar", "title": "Are BLEU and Meaning Representation in Opposition?", "comments": "ACL 2018; 10 pages + 2 page supplementary", "journal-ref": "Proceedings of the 56th Annual Meeting of the Association for\n  Computational Linguistics (Volume 1: Long Papers) (2018) 1362-1371", "doi": "10.18653/v1/P18-1126", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of possible ways of obtaining continuous-space sentence representations\nis by training neural machine translation (NMT) systems. The recent attention\nmechanism however removes the single point in the neural network from which the\nsource sentence representation can be extracted. We propose several variations\nof the attentive NMT architecture bringing this meeting point back. Empirical\nevaluation suggests that the better the translation quality, the worse the\nlearned sentence representations serve in a wide range of classification and\nsimilarity tasks.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 21:42:21 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["C\u00edfka", "Ond\u0159ej", ""], ["Bojar", "Ond\u0159ej", ""]]}, {"id": "1805.06549", "submitter": "Josiah Wang", "authors": "Pranava Madhyastha, Josiah Wang, Lucia Specia", "title": "Defoiling Foiled Image Captions", "comments": "In Proceedings of the 2018 Conference of the North American Chapter\n  of the Association for Computational Linguistics (NAACL 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the task of detecting foiled image captions, i.e. identifying\nwhether a caption contains a word that has been deliberately replaced by a\nsemantically similar word, thus rendering it inaccurate with respect to the\nimage being described. Solving this problem should in principle require a\nfine-grained understanding of images to detect linguistically valid\nperturbations in captions. In such contexts, encoding sufficiently descriptive\nimage information becomes a key challenge. In this paper, we demonstrate that\nit is possible to solve this task using simple, interpretable yet powerful\nrepresentations based on explicit object information. Our models achieve\nstate-of-the-art performance on a standard dataset, with scores exceeding those\nachieved by humans on the task. We also measure the upper-bound performance of\nour models using gold standard annotations. Our analysis reveals that the\nsimpler model performs well even without image information, suggesting that the\ndataset contains strong linguistic bias.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 22:50:17 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Madhyastha", "Pranava", ""], ["Wang", "Josiah", ""], ["Specia", "Lucia", ""]]}, {"id": "1805.06553", "submitter": "Juraj Juraska", "authors": "Juraj Juraska, Panagiotis Karagiannis, Kevin K. Bowden, Marilyn A.\n  Walker", "title": "A Deep Ensemble Model with Slot Alignment for Sequence-to-Sequence\n  Natural Language Generation", "comments": "Accepted to NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language generation lies at the core of generative dialogue systems\nand conversational agents. We describe an ensemble neural language generator,\nand present several novel methods for data representation and augmentation that\nyield improved results in our model. We test the model on three datasets in the\nrestaurant, TV and laptop domains, and report both objective and subjective\nevaluations of our best model. Using a range of automatic metrics, as well as\nhuman evaluators, we show that our approach achieves better results than\nstate-of-the-art models on the same datasets.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 23:30:01 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Juraska", "Juraj", ""], ["Karagiannis", "Panagiotis", ""], ["Bowden", "Kevin K.", ""], ["Walker", "Marilyn A.", ""]]}, {"id": "1805.06556", "submitter": "Vidur Joshi", "authors": "Vidur Joshi, Matthew Peters, Mark Hopkins", "title": "Extending a Parser to Distant Domains Using a Few Dozen Partially\n  Annotated Examples", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit domain adaptation for parsers in the neural era. First we show\nthat recent advances in word representations greatly diminish the need for\ndomain adaptation when the target domain is syntactically similar to the source\ndomain. As evidence, we train a parser on the Wall Street Jour- nal alone that\nachieves over 90% F1 on the Brown corpus. For more syntactically dis- tant\ndomains, we provide a simple way to adapt a parser using only dozens of partial\nannotations. For instance, we increase the percentage of error-free\ngeometry-domain parses in a held-out set from 45% to 73% using approximately\nfive dozen training examples. In the process, we demon- strate a new\nstate-of-the-art single model result on the Wall Street Journal test set of\n94.3%. This is an absolute increase of 1.7% over the previous state-of-the-art\nof 92.6%.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 23:42:04 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Joshi", "Vidur", ""], ["Peters", "Matthew", ""], ["Hopkins", "Mark", ""]]}, {"id": "1805.06566", "submitter": "Shivashankar Subramanian", "authors": "Shivashankar Subramanian, Timothy Baldwin, Trevor Cohn", "title": "Content-based Popularity Prediction of Online Petitions Using a Deep\n  Regression Model", "comments": null, "journal-ref": "ACL 2018 (camera ready pre-print)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Online petitions are a cost-effective way for citizens to collectively engage\nwith policy-makers in a democracy. Predicting the popularity of a petition ---\ncommonly measured by its signature count --- based on its textual content has\nutility for policy-makers as well as those posting the petition. In this work,\nwe model this task using CNN regression with an auxiliary ordinal regression\nobjective. We demonstrate the effectiveness of our proposed approach using UK\nand US government petition datasets.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 00:59:22 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Subramanian", "Shivashankar", ""], ["Baldwin", "Timothy", ""], ["Cohn", "Trevor", ""]]}, {"id": "1805.06593", "submitter": "Chang Xu", "authors": "Chang Xu, Cecile Paris, Surya Nepal, Ross Sparks", "title": "Cross-Target Stance Classification with Self-Attention Networks", "comments": "In Proceedings of the 56th Annual Meeting of the Association for\n  Computational Linguistics (ACL2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In stance classification, the target on which the stance is made defines the\nboundary of the task, and a classifier is usually trained for prediction on the\nsame target. In this work, we explore the potential for generalizing\nclassifiers between different targets, and propose a neural model that can\napply what has been learned from a source target to a destination target. We\nshow that our model can find useful information shared between relevant targets\nwhich improves generalization in certain scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 03:39:23 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 10:49:28 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Xu", "Chang", ""], ["Paris", "Cecile", ""], ["Nepal", "Surya", ""], ["Sparks", "Ross", ""]]}, {"id": "1805.06606", "submitter": "Woo Yong Choi", "authors": "Chan Woo Lee, Kyu Ye Song, Jihoon Jeong, Woo Yong Choi", "title": "Convolutional Attention Networks for Multimodal Emotion Recognition from\n  Speech and Text Data", "comments": "Inaccurate scientific facts listed in document", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion recognition has become a popular topic of interest, especially in the\nfield of human computer interaction. Previous works involve unimodal analysis\nof emotion, while recent efforts focus on multi-modal emotion recognition from\nvision and speech. In this paper, we propose a new method of learning about the\nhidden representations between just speech and text data using convolutional\nattention networks. Compared to the shallow model which employs simple\nconcatenation of feature vectors, the proposed attention model performs much\nbetter in classifying emotion from speech and text data contained in the\nCMU-MOSEI dataset.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 05:51:00 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 07:04:40 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Lee", "Chan Woo", ""], ["Song", "Kyu Ye", ""], ["Jeong", "Jihoon", ""], ["Choi", "Woo Yong", ""]]}, {"id": "1805.06648", "submitter": "Jeff Mitchell", "authors": "Jeff Mitchell, Pasquale Minervini, Pontus Stenetorp and Sebastian\n  Riedel", "title": "Extrapolation in NLP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue that extrapolation to examples outside the training space will often\nbe easier for models that capture global structures, rather than just maximise\ntheir local fit to the training data. We show that this is true for two popular\nmodels: the Decomposable Attention Model and word2vec.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 08:29:09 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Mitchell", "Jeff", ""], ["Minervini", "Pasquale", ""], ["Stenetorp", "Pontus", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1805.06665", "submitter": "Bin He", "authors": "Bin He, Yi Guan, Rui Dai", "title": "Classifying medical relations in clinical text via convolutional neural\n  networks", "comments": "Accepted by Artificial Intelligence In Medicine", "journal-ref": null, "doi": "10.1016/j.artmed.2018.05.001", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning research on relation classification has achieved solid\nperformance in the general domain. This study proposes a convolutional neural\nnetwork (CNN) architecture with a multi-pooling operation for medical relation\nclassification on clinical records and explores a loss function with a\ncategory-level constraint matrix. Experiments using the 2010 i2b2/VA relation\ncorpus demonstrate these models, which do not depend on any external features,\noutperform previous single-model methods and our best model is competitive with\nthe existing ensemble-based method.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 09:20:52 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["He", "Bin", ""], ["Guan", "Yi", ""], ["Dai", "Rui", ""]]}, {"id": "1805.06816", "submitter": "Preethi Raghavan", "authors": "Preethi Raghavan, Siddharth Patwardhan, Jennifer J. Liang, Murthy V.\n  Devarakonda", "title": "Annotating Electronic Medical Records for Question Answering", "comments": "10 pages, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our research is in the relatively unexplored area of question answering\ntechnologies for patient-specific questions over their electronic health\nrecords. A large dataset of human expert curated question and answer pairs is\nan important pre-requisite for developing, training and evaluating any question\nanswering system that is powered by machine learning. In this paper, we\ndescribe a process for creating such a dataset of questions and answers. Our\nmethodology is replicable, can be conducted by medical students as annotators,\nand results in high inter-annotator agreement (0.71 Cohen's kappa). Over the\ncourse of 11 months, 11 medical students followed our annotation methodology,\nresulting in a question answering dataset of 5696 questions over 71 patient\nrecords, of which 1747 questions have corresponding answers generated by the\nmedical students.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 15:18:20 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Raghavan", "Preethi", ""], ["Patwardhan", "Siddharth", ""], ["Liang", "Jennifer J.", ""], ["Devarakonda", "Murthy V.", ""]]}, {"id": "1805.06879", "submitter": "James Bagrow", "authors": "James P. Bagrow and Daniel Berenberg and Joshua Bongard", "title": "Neural language representations predict outcomes of scientific research", "comments": "8 pages, 3 figures, plus supporting material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many research fields codify their findings in standard formats, often by\nreporting correlations between quantities of interest. But the space of all\ntestable correlates is far larger than scientific resources can currently\naddress, so the ability to accurately predict correlations would be useful to\nplan research and allocate resources. Using a dataset of approximately 170,000\ncorrelational findings extracted from leading social science journals, we show\nthat a trained neural network can accurately predict the reported correlations\nusing only the text descriptions of the correlates. Accurate predictive models\nsuch as these can guide scientists towards promising untested correlates,\nbetter quantify the information gained from new findings, and has implications\nfor moving artificial intelligence systems from predicting structures to\npredicting relationships in the real world.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 17:40:12 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Bagrow", "James P.", ""], ["Berenberg", "Daniel", ""], ["Bongard", "Joshua", ""]]}, {"id": "1805.06939", "submitter": "Hannah Rashkin", "authors": "Hannah Rashkin, Maarten Sap, Emily Allaway, Noah A. Smith and Yejin\n  Choi", "title": "Event2Mind: Commonsense Inference on Events, Intents, and Reactions", "comments": "Accepted to ACL 2018 (long paper). First two authors contributed\n  equally. arXiv admin note: text overlap with arXiv:1903.06901 by other\n  authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a new commonsense inference task: given an event described in\na short free-form text (\"X drinks coffee in the morning\"), a system reasons\nabout the likely intents (\"X wants to stay awake\") and reactions (\"X feels\nalert\") of the event's participants. To support this study, we construct a new\ncrowdsourced corpus of 25,000 event phrases covering a diverse range of\neveryday events and situations. We report baseline performance on this task,\ndemonstrating that neural encoder-decoder models can successfully compose\nembedding representations of previously unseen events and reason about the\nlikely intents and reactions of the event participants. In addition, we\ndemonstrate how commonsense inference on people's intents and reactions can\nhelp unveil the implicit gender inequality prevalent in modern movie scripts.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 19:18:57 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 22:06:57 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Rashkin", "Hannah", ""], ["Sap", "Maarten", ""], ["Allaway", "Emily", ""], ["Smith", "Noah A.", ""], ["Choi", "Yejin", ""]]}, {"id": "1805.06960", "submitter": "Ravi Shekhar", "authors": "Ravi Shekhar, Tim Baumgartner, Aashish Venkatesh, Elia Bruni,\n  Raffaella Bernardi, Raquel Fernandez", "title": "Ask No More: Deciding when to guess in referential visual dialogue", "comments": "COLING 2018 (accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.MM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Our goal is to explore how the abilities brought in by a dialogue manager can\nbe included in end-to-end visually grounded conversational agents. We make\ninitial steps towards this general goal by augmenting a task-oriented visual\ndialogue model with a decision-making component that decides whether to ask a\nfollow-up question to identify a target referent in an image, or to stop the\nconversation to make a guess. Our analyses show that adding a decision making\ncomponent produces dialogues that are less repetitive and that include fewer\nunnecessary questions, thus potentially leading to more efficient and less\nunnatural interactions.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 20:32:08 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 10:43:56 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Shekhar", "Ravi", ""], ["Baumgartner", "Tim", ""], ["Venkatesh", "Aashish", ""], ["Bruni", "Elia", ""], ["Bernardi", "Raffaella", ""], ["Fernandez", "Raquel", ""]]}, {"id": "1805.06966", "submitter": "Florian Kreyssig", "authors": "Florian Kreyssig, Inigo Casanueva, Pawel Budzianowski, Milica Gasic", "title": "Neural User Simulation for Corpus-based Policy Optimisation for Spoken\n  Dialogue Systems", "comments": "Accepted to SIGDIAL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User Simulators are one of the major tools that enable offline training of\ntask-oriented dialogue systems. For this task the Agenda-Based User Simulator\n(ABUS) is often used. The ABUS is based on hand-crafted rules and its output is\nin semantic form. Issues arise from both properties such as limited diversity\nand the inability to interface a text-level belief tracker. This paper\nintroduces the Neural User Simulator (NUS) whose behaviour is learned from a\ncorpus and which generates natural language, hence needing a less labelled\ndataset than simulators generating a semantic output. In comparison to much of\nthe past work on this topic, which evaluates user simulators on corpus-based\nmetrics, we use the NUS to train the policy of a reinforcement learning based\nSpoken Dialogue System. The NUS is compared to the ABUS by evaluating the\npolicies that were trained using the simulators. Cross-model evaluation is\nperformed i.e. training on one simulator and testing on the other. Furthermore,\nthe trained policies are tested on real users. In both evaluation tasks the NUS\noutperformed the ABUS.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 21:00:03 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Kreyssig", "Florian", ""], ["Casanueva", "Inigo", ""], ["Budzianowski", "Pawel", ""], ["Gasic", "Milica", ""]]}, {"id": "1805.06975", "submitter": "Peter Clark", "authors": "Bhavana Dalvi Mishra, Lifu Huang, Niket Tandon, Wen-tau Yih, Peter\n  Clark", "title": "Tracking State Changes in Procedural Text: A Challenge Dataset and\n  Models for Process Paragraph Comprehension", "comments": "In Proc. NAACL'2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new dataset and models for comprehending paragraphs about\nprocesses (e.g., photosynthesis), an important genre of text describing a\ndynamic world. The new dataset, ProPara, is the first to contain natural\n(rather than machine-generated) text about a changing world along with a full\nannotation of entity states (location and existence) during those changes (81k\ndatapoints). The end-task, tracking the location and existence of entities\nthrough the text, is challenging because the causal effects of actions are\noften implicit and need to be inferred. We find that previous models that have\nworked well on synthetic data achieve only mediocre performance on ProPara, and\nintroduce two new neural models that exploit alternative mechanisms for state\nprediction, in particular using LSTM input encoding and span prediction. The\nnew models improve accuracy by up to 19%. The dataset and models are available\nto the community at http://data.allenai.org/propara.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 21:42:04 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Mishra", "Bhavana Dalvi", ""], ["Huang", "Lifu", ""], ["Tandon", "Niket", ""], ["Yih", "Wen-tau", ""], ["Clark", "Peter", ""]]}, {"id": "1805.06995", "submitter": "Juneki Hong", "authors": "Juneki Hong and Liang Huang", "title": "Linear-Time Constituency Parsing with RNNs and Dynamic Programming", "comments": "Needs revisions, especially in the experiments section, discussing\n  which models are WSJ-only, single-model, end-to-end", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, span-based constituency parsing has achieved competitive accuracies\nwith extremely simple models by using bidirectional RNNs to model \"spans\".\nHowever, the minimal span parser of Stern et al (2017a) which holds the current\nstate of the art accuracy is a chart parser running in cubic time, $O(n^3)$,\nwhich is too slow for longer sentences and for applications beyond sentence\nboundaries such as end-to-end discourse parsing and joint sentence boundary\ndetection and parsing. We propose a linear-time constituency parser with RNNs\nand dynamic programming using graph-structured stack and beam search, which\nruns in time $O(n b^2)$ where $b$ is the beam size. We further speed this up to\n$O(n b\\log b)$ by integrating cube pruning. Compared with chart parsing\nbaselines, this linear-time parser is substantially faster for long sentences\non the Penn Treebank and orders of magnitude faster for discourse parsing, and\nachieves the highest F1 accuracy on the Penn Treebank among single model\nend-to-end systems.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 23:40:06 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 23:20:37 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Hong", "Juneki", ""], ["Huang", "Liang", ""]]}, {"id": "1805.07024", "submitter": "Jie Li", "authors": "Jie Li, Xiaorui Wang, Yuanyuan Zhao, Yan Li", "title": "Gated Recurrent Unit Based Acoustic Modeling with Future Context", "comments": "Submitted to INTERSPEECH 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of future contextual information is typically shown to be helpful for\nacoustic modeling. However, for the recurrent neural network (RNN), it's not so\neasy to model the future temporal context effectively, meanwhile keep lower\nmodel latency. In this paper, we attempt to design a RNN acoustic model that\nbeing capable of utilizing the future context effectively and directly, with\nthe model latency and computation cost as low as possible. The proposed model\nis based on the minimal gated recurrent unit (mGRU) with an input projection\nlayer inserted in it. Two context modules, temporal encoding and temporal\nconvolution, are specifically designed for this architecture to model the\nfuture context. Experimental results on the Switchboard task and an internal\nMandarin ASR task show that, the proposed model performs much better than long\nshort-term memory (LSTM) and mGRU models, whereas enables online decoding with\na maximum latency of 170 ms. This model even outperforms a very strong\nbaseline, TDNN-LSTM, with smaller model latency and almost half less\nparameters.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 02:33:53 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Li", "Jie", ""], ["Wang", "Xiaorui", ""], ["Zhao", "Yuanyuan", ""], ["Li", "Yan", ""]]}, {"id": "1805.07043", "submitter": "Wei Xue", "authors": "Wei Xue and Tao Li", "title": "Aspect Based Sentiment Analysis with Gated Convolutional Networks", "comments": "Accepted in ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect based sentiment analysis (ABSA) can provide more detailed information\nthan general sentiment analysis, because it aims to predict the sentiment\npolarities of the given aspects or entities in text. We summarize previous\napproaches into two subtasks: aspect-category sentiment analysis (ACSA) and\naspect-term sentiment analysis (ATSA). Most previous approaches employ long\nshort-term memory and attention mechanisms to predict the sentiment polarity of\nthe concerned targets, which are often complicated and need more training time.\nWe propose a model based on convolutional neural networks and gating\nmechanisms, which is more accurate and efficient. First, the novel Gated\nTanh-ReLU Units can selectively output the sentiment features according to the\ngiven aspect or entity. The architecture is much simpler than attention layer\nused in the existing models. Second, the computations of our model could be\neasily parallelized during training, because convolutional layers do not have\ntime dependency as in LSTM layers, and gating units also work independently.\nThe experiments on SemEval datasets demonstrate the efficiency and\neffectiveness of our models.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 04:24:52 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Xue", "Wei", ""], ["Li", "Tao", ""]]}, {"id": "1805.07049", "submitter": "Jihun Choi", "authors": "Taeuk Kim, Jihun Choi, Sang-goo Lee", "title": "SNU_IDS at SemEval-2018 Task 12: Sentence Encoder with Contextualized\n  Vectors for Argument Reasoning Comprehension", "comments": "SemEval 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel neural architecture for the Argument Reasoning\nComprehension task of SemEval 2018. It is a simple neural network consisting of\nthree parts, collectively judging whether the logic built on a set of given\nsentences (a claim, reason, and warrant) is plausible or not. The model\nutilizes contextualized word vectors pre-trained on large machine translation\n(MT) datasets as a form of transfer learning, which can help to mitigate the\nlack of training data. Quantitative analysis shows that simply leveraging LSTMs\ntrained on MT datasets outperforms several baselines and non-transferred\nmodels, achieving accuracies of about 70% on the development set and about 60%\non the test set.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 05:19:49 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Kim", "Taeuk", ""], ["Choi", "Jihun", ""], ["Lee", "Sang-goo", ""]]}, {"id": "1805.07133", "submitter": "Ngo Thi-Vinh", "authors": "Thi-Vinh Ngo, Thanh-Le Ha, Phuong-Thai Nguyen, Le-Minh Nguyen", "title": "Combining Advanced Methods in Japanese-Vietnamese Neural Machine\n  Translation", "comments": null, "journal-ref": "2018 10th International Conference on Knowledge and Systems\n  Engineering (KSE)", "doi": "10.1109/KSE.2018.8573329", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Neural machine translation (NMT) systems have recently obtained state-of-the\nart in many machine translation systems between popular language pairs because\nof the availability of data. For low-resourced language pairs, there are few\nresearches in this field due to the lack of bilingual data. In this paper, we\nattempt to build the first NMT systems for a low-resourced language\npairs:Japanese-Vietnamese. We have also shown significant improvements when\ncombining advanced methods to reduce the adverse impacts of data sparsity and\nimprove the quality of NMT systems. In addition, we proposed a variant of\nByte-Pair Encoding algorithm to perform effective word segmentation for\nVietnamese texts and alleviate the rare-word problem that persists in NMT\nsystems.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 10:36:37 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Ngo", "Thi-Vinh", ""], ["Ha", "Thanh-Le", ""], ["Nguyen", "Phuong-Thai", ""], ["Nguyen", "Le-Minh", ""]]}, {"id": "1805.07143", "submitter": "Enrique Manjavacas Ar\\'evalo", "authors": "Chris Emmery, Enrique Manjavacas, Grzegorz Chrupa{\\l}a", "title": "Style Obfuscation by Invariance", "comments": "Accepted for presentation at COLING18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The task of obfuscating writing style using sequence models has previously\nbeen investigated under the framework of obfuscation-by-transfer, where the\ninput text is explicitly rewritten in another style. These approaches also\noften lead to major alterations to the semantic content of the input. In this\nwork, we propose obfuscation-by-invariance, and investigate to what extent\nmodels trained to be explicitly style-invariant preserve semantics. We evaluate\nour architectures on parallel and non-parallel corpora, and compare automatic\nand human evaluations on the obfuscated sentences. Our experiments show that\nstyle classifier performance can be reduced to chance level, whilst the\nautomatic evaluation of the output is seemingly equal to models applying\nstyle-transfer. However, based on human evaluation we demonstrate a trade-off\nbetween the level of obfuscation and the observed quality of the output in\nterms of meaning preservation and grammaticality.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 11:09:28 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Emmery", "Chris", ""], ["Manjavacas", "Enrique", ""], ["Chrupa\u0142a", "Grzegorz", ""]]}, {"id": "1805.07231", "submitter": "Eug\\'enio Ribeiro", "authors": "Eug\\'enio Ribeiro, Ricardo Ribeiro, and David Martins de Matos", "title": "A Study on Dialog Act Recognition using Character-Level Tokenization", "comments": "11 pages, 2 figures, 4 tables, AIMSA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialog act recognition is an important step for dialog systems since it\nreveals the intention behind the uttered words. Most approaches on the task use\nword-level tokenization. In contrast, this paper explores the use of\ncharacter-level tokenization. This is relevant since there is information at\nthe sub-word level that is related to the function of the words and, thus,\ntheir intention. We also explore the use of different context windows around\neach token, which are able to capture important elements, such as affixes.\nFurthermore, we assess the importance of punctuation and capitalization. We\nperformed experiments on both the Switchboard Dialog Act Corpus and the DIHANA\nCorpus. In both cases, the experiments not only show that character-level\ntokenization leads to better performance than the typical word-level\napproaches, but also that both approaches are able to capture complementary\ninformation. Thus, the best results are achieved by combining tokenization at\nboth levels.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 14:17:07 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2018 13:28:56 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Ribeiro", "Eug\u00e9nio", ""], ["Ribeiro", "Ricardo", ""], ["de Matos", "David Martins", ""]]}, {"id": "1805.07274", "submitter": "Ghulam Ahmed Ansari", "authors": "Ghulam Ahmed Ansari, Sagar J P, Sarath Chandar, Balaraman Ravindran", "title": "Language Expansion In Text-Based Games", "comments": "9 pages. arXiv admin note: text overlap with arXiv:1511.06295 by\n  other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-based games are suitable test-beds for designing agents that can learn\nby interaction with the environment in the form of natural language text. Very\nrecently, deep reinforcement learning based agents have been successfully\napplied for playing text-based games. In this paper, we explore the possibility\nof designing a single agent to play several text-based games and of expanding\nthe agent's vocabulary using the vocabulary of agents trained for multiple\ngames. To this extent, we explore the application of recently proposed policy\ndistillation method for video games to the text-based game setting. We also use\ntext-based games as a test-bed to analyze and hence understand policy\ndistillation approach in detail.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 10:43:04 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Ansari", "Ghulam Ahmed", ""], ["P", "Sagar J", ""], ["Chandar", "Sarath", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1805.07340", "submitter": "Siddhartha Brahma", "authors": "Siddhartha Brahma", "title": "Improved Sentence Modeling using Suffix Bidirectional LSTM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks have become ubiquitous in computing representations\nof sequential data, especially textual data in natural language processing. In\nparticular, Bidirectional LSTMs are at the heart of several neural models\nachieving state-of-the-art performance in a wide variety of tasks in NLP.\nHowever, BiLSTMs are known to suffer from sequential bias - the contextual\nrepresentation of a token is heavily influenced by tokens close to it in a\nsentence. We propose a general and effective improvement to the BiLSTM model\nwhich encodes each suffix and prefix of a sequence of tokens in both forward\nand reverse directions. We call our model Suffix Bidirectional LSTM or\nSuBiLSTM. This introduces an alternate bias that favors long range\ndependencies. We apply SuBiLSTMs to several tasks that require sentence\nmodeling. We demonstrate that using SuBiLSTM instead of a BiLSTM in existing\nmodels leads to improvements in performance in learning general sentence\nrepresentations, text classification, textual entailment and paraphrase\ndetection. Using SuBiLSTM we achieve new state-of-the-art results for\nfine-grained sentiment classification and question classification.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 17:46:25 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 22:16:36 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Brahma", "Siddhartha", ""]]}, {"id": "1805.07398", "submitter": "Abhijit Mahabal", "authors": "Abhijit Mahabal, Dan Roth, Sid Mittal", "title": "Robust Handling of Polysemy via Sparse Representations", "comments": "*Sem 2018, New Orleans. 9 pages plus references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Words are polysemous and multi-faceted, with many shades of meanings. We\nsuggest that sparse distributed representations are more suitable than other,\ncommonly used, (dense) representations to express these multiple facets, and\npresent Category Builder, a working system that, as we show, makes use of\nsparse representations to support multi-faceted lexical representations. We\nargue that the set expansion task is well suited to study these meaning\ndistinctions since a word may belong to multiple sets with a different reason\nfor membership in each. We therefore exhibit the performance of Category\nBuilder on this task, while showing that our representation captures at the\nsame time analogy problems such as \"the Ganga of Egypt\" or \"the Voldemort of\nTolkien\". Category Builder is shown to be a more expressive lexical\nrepresentation and to outperform dense representations such as Word2Vec in some\nanalogy classes despite being shown only two of the three input terms.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 18:58:38 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Mahabal", "Abhijit", ""], ["Roth", "Dan", ""], ["Mittal", "Sid", ""]]}, {"id": "1805.07443", "submitter": "Shuai Tang", "authors": "Shuai Tang, Virginia R. de Sa", "title": "Multi-view Sentence Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view learning can provide self-supervision when different views are\navailable of the same data. The distributional hypothesis provides another form\nof useful self-supervision from adjacent sentences which are plentiful in large\nunlabelled corpora. Motivated by the asymmetry in the two hemispheres of the\nhuman brain as well as the observation that different learning architectures\ntend to emphasise different aspects of sentence meaning, we create a unified\nmulti-view sentence representation learning framework, in which, one view\nencodes the input sentence with a Recurrent Neural Network (RNN), and the other\nview encodes it with a simple linear model, and the training objective is to\nmaximise the agreement specified by the adjacent context information between\ntwo views. We show that, after training, the vectors produced from our\nmulti-view training provide improved representations over the single-view\ntraining, and the combination of different views gives further representational\nimprovement and demonstrates solid transferability on standard downstream\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 21:04:08 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Tang", "Shuai", ""], ["de Sa", "Virginia R.", ""]]}, {"id": "1805.07467", "submitter": "Yu-An Chung", "authors": "Yu-An Chung and Wei-Hung Weng and Schrasing Tong and James Glass", "title": "Unsupervised Cross-Modal Alignment of Speech and Text Embedding Spaces", "comments": "Accepted to NIPS 2018. v2 added the majority word baseline results\n  and other minor fixes. arXiv admin note: text overlap with arXiv:1710.04087\n  by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has shown that word embedding spaces learned from text\ncorpora of different languages can be aligned without any parallel data\nsupervision. Inspired by the success in unsupervised cross-lingual word\nembeddings, in this paper we target learning a cross-modal alignment between\nthe embedding spaces of speech and text learned from corpora of their\nrespective modalities in an unsupervised fashion. The proposed framework learns\nthe individual speech and text embedding spaces, and attempts to align the two\nspaces via adversarial training, followed by a refinement procedure. We show\nhow our framework could be used to perform spoken word classification and\ntranslation, and the results on these two tasks demonstrate that the\nperformance of our unsupervised alignment approach is comparable to its\nsupervised counterpart. Our framework is especially useful for developing\nautomatic speech recognition (ASR) and speech-to-text translation systems for\nlow- or zero-resource languages, which have little parallel audio-text data for\ntraining modern supervised ASR and speech-to-text translation models, but\naccount for the majority of the languages spoken across the world.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 22:59:18 GMT"}, {"version": "v2", "created": "Thu, 20 Sep 2018 11:28:22 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Chung", "Yu-An", ""], ["Weng", "Wei-Hung", ""], ["Tong", "Schrasing", ""], ["Glass", "James", ""]]}, {"id": "1805.07469", "submitter": "Mamoru Komachi", "authors": "Hiroki Shimanaka, Tomoyuki Kajiwara, Mamoru Komachi", "title": "Metric for Automatic Machine Translation Evaluation based on Universal\n  Sentence Representations", "comments": "NAACL 2018 Student Research Workshop; 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentence representations can capture a wide range of information that cannot\nbe captured by local features based on character or word N-grams. This paper\nexamines the usefulness of universal sentence representations for evaluating\nthe quality of machine translation. Although it is difficult to train sentence\nrepresentations using small-scale translation datasets with manual evaluation,\nsentence representations trained from large-scale data in other tasks can\nimprove the automatic evaluation of machine translation. Experimental results\nof the WMT-2016 dataset show that the proposed method achieves state-of-the-art\nperformance with sentence representation features only.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 23:05:18 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Shimanaka", "Hiroki", ""], ["Kajiwara", "Tomoyuki", ""], ["Komachi", "Mamoru", ""]]}, {"id": "1805.07475", "submitter": "Jacob Harer", "authors": "Jacob Harer, Onur Ozdemir, Tomo Lazovich, Christopher P. Reale,\n  Rebecca L. Russell, Louis Y. Kim, Peter Chin", "title": "Learning to Repair Software Vulnerabilities with Generative Adversarial\n  Networks", "comments": "Presented at 32nd Conference on Neural Information Processing Systems\n  (nips 2018), Montreal Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the problem of automated repair of software vulnerabilities, we\npropose an adversarial learning approach that maps from one discrete source\ndomain to another target domain without requiring paired labeled examples or\nsource and target domains to be bijections. We demonstrate that the proposed\nadversarial learning approach is an effective technique for repairing software\nvulnerabilities, performing close to seq2seq approaches that require labeled\npairs. The proposed Generative Adversarial Network approach is\napplication-agnostic in that it can be applied to other problems similar to\ncode repair, such as grammar correction or sentiment translation.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 23:31:03 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 16:09:33 GMT"}, {"version": "v3", "created": "Sun, 28 Oct 2018 18:22:18 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Harer", "Jacob", ""], ["Ozdemir", "Onur", ""], ["Lazovich", "Tomo", ""], ["Reale", "Christopher P.", ""], ["Russell", "Rebecca L.", ""], ["Kim", "Louis Y.", ""], ["Chin", "Peter", ""]]}, {"id": "1805.07513", "submitter": "Mo Yu", "authors": "Mo Yu, Xiaoxiao Guo, Jinfeng Yi, Shiyu Chang, Saloni Potdar, Yu Cheng,\n  Gerald Tesauro, Haoyu Wang, Bowen Zhou", "title": "Diverse Few-Shot Text Classification with Multiple Metrics", "comments": "NAACL 2018. 11+5 pages. arXiv admin note: text overlap with\n  arXiv:1708.07918", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study few-shot learning in natural language domains. Compared to many\nexisting works that apply either metric-based or optimization-based\nmeta-learning to image domain with low inter-task variance, we consider a more\nrealistic setting, where tasks are diverse. However, it imposes tremendous\ndifficulties to existing state-of-the-art metric-based algorithms since a\nsingle metric is insufficient to capture complex task variations in natural\nlanguage domain. To alleviate the problem, we propose an adaptive metric\nlearning approach that automatically determines the best weighted combination\nfrom a set of metrics obtained from meta-training tasks for a newly seen\nfew-shot task. Extensive quantitative evaluations on real-world sentiment\nanalysis and dialog intent classification datasets demonstrate that the\nproposed method performs favorably against state-of-the-art few shot learning\nalgorithms in terms of predictive accuracy. We make our code and data available\nfor further study.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 04:45:04 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Yu", "Mo", ""], ["Guo", "Xiaoxiao", ""], ["Yi", "Jinfeng", ""], ["Chang", "Shiyu", ""], ["Potdar", "Saloni", ""], ["Cheng", "Yu", ""], ["Tesauro", "Gerald", ""], ["Wang", "Haoyu", ""], ["Zhou", "Bowen", ""]]}, {"id": "1805.07616", "submitter": "Guillem Collell", "authors": "Guillem Collell and Marie-Francine Moens", "title": "Do Neural Network Cross-Modal Mappings Really Bridge Modalities?", "comments": "To appear at ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feed-forward networks are widely used in cross-modal applications to bridge\nmodalities by mapping distributed vectors of one modality to the other, or to a\nshared space. The predicted vectors are then used to perform e.g., retrieval or\nlabeling. Thus, the success of the whole system relies on the ability of the\nmapping to make the neighborhood structure (i.e., the pairwise similarities) of\nthe predicted vectors akin to that of the target vectors. However, whether this\nis achieved has not been investigated yet. Here, we propose a new similarity\nmeasure and two ad hoc experiments to shed light on this issue. In three\ncross-modal benchmarks we learn a large number of language-to-vision and\nvision-to-language neural network mappings (up to five layers) using a rich\ndiversity of image and text features and loss functions. Our results reveal\nthat, surprisingly, the neighborhood structure of the predicted vectors\nconsistently resembles more that of the input vectors than that of the target\nvectors. In a second experiment, we further show that untrained nets do not\nsignificantly disrupt the neighborhood (i.e., semantic) structure of the input\nvectors.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 15:51:43 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2018 16:16:37 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Collell", "Guillem", ""], ["Moens", "Marie-Francine", ""]]}, {"id": "1805.07685", "submitter": "Cicero Nogueira Dos Santos", "authors": "Cicero Nogueira dos Santos, Igor Melnyk, Inkit Padhi", "title": "Fighting Offensive Language on Social Media with Unsupervised Text Style\n  Transfer", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new approach to tackle the problem of offensive language in\nonline social media. Our approach uses unsupervised text style transfer to\ntranslate offensive sentences into non-offensive ones. We propose a new method\nfor training encoder-decoders using non-parallel data that combines a\ncollaborative classifier, attention and the cycle consistency loss.\nExperimental results on data from Twitter and Reddit show that our method\noutperforms a state-of-the-art text style transfer system in two out of three\nquantitative metrics and produces reliable non-offensive transferred sentences.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 00:57:43 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Santos", "Cicero Nogueira dos", ""], ["Melnyk", "Igor", ""], ["Padhi", "Inkit", ""]]}, {"id": "1805.07697", "submitter": "Ella Rabinovich", "authors": "Elad Tolochinsky, Ohad Mosafi, Ella Rabinovich, Shuly Wintner", "title": "The UN Parallel Corpus Annotated for Translation Direction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work distinguishes between translated and original text in the UN\nprotocol corpus. By modeling the problem as classification problem, we can\nachieve up to 95% classification accuracy. We begin by deriving a parallel\ncorpus for different language-pairs annotated for translation direction, and\nthen classify the data by using various feature extraction methods. We compare\nthe different methods as well as the ability to distinguish between translated\nand original texts in the different languages. The annotated corpus is publicly\navailable.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 03:42:50 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Tolochinsky", "Elad", ""], ["Mosafi", "Ohad", ""], ["Rabinovich", "Ella", ""], ["Wintner", "Shuly", ""]]}, {"id": "1805.07719", "submitter": "Rosario Scalise", "authors": "Rosario Scalise, Yonatan Bisk, Maxwell Forbes, Daqing Yi, Yejin Choi,\n  Siddhartha Srinivasa", "title": "Balancing Shared Autonomy with Human-Robot Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic agents that share autonomy with a human should leverage human domain\nknowledge and account for their preferences when completing a task. This extra\nknowledge can dramatically improve plan efficiency and user-satisfaction, but\nthese gains are lost if communicating with a robot is taxing and unnatural. In\nthis paper, we show how viewing humanrobot language through the lens of shared\nautonomy explains the efficiency versus cognitive load trade-offs humans make\nwhen deciding how cooperative and explicit to make their instructions.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 07:19:10 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Scalise", "Rosario", ""], ["Bisk", "Yonatan", ""], ["Forbes", "Maxwell", ""], ["Yi", "Daqing", ""], ["Choi", "Yejin", ""], ["Srinivasa", "Siddhartha", ""]]}, {"id": "1805.07731", "submitter": "Henry Elder", "authors": "Henry Elder, Chris Hokamp", "title": "Generating High-Quality Surface Realizations Using Data Augmentation and\n  Factored Sequence Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a new state of the art in reconstruction of surface\nrealizations from obfuscated text. We identify the lack of sufficient training\ndata as the major obstacle to training high-performing models, and solve this\nissue by generating large amounts of synthetic training data. We also propose\npreprocessing techniques which make the structure contained in the input\nfeatures more accessible to sequence models. Our models were ranked first on\nall evaluation metrics in the English portion of the 2018 Surface Realization\nshared task.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 08:40:06 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Elder", "Henry", ""], ["Hokamp", "Chris", ""]]}, {"id": "1805.07745", "submitter": "Taehoon Kim", "authors": "Taehoon Kim and Jihoon Yang", "title": "Abstractive Text Classification Using Sequence-to-convolution Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new deep neural network model and its training scheme for text\nclassification. Our model Sequence-to-convolution Neural Networks(Seq2CNN)\nconsists of two blocks: Sequential Block that summarizes input texts and\nConvolution Block that receives summary of input and classifies it to a label.\nSeq2CNN is trained end-to-end to classify various-length texts without\npreprocessing inputs into fixed length. We also present Gradual Weight\nShift(GWS) method that stabilizes training. GWS is applied to our model's loss\nfunction. We compared our model with word-based TextCNN trained with different\ndata preprocessing methods. We obtained significant improvement in\nclassification accuracy over word-based TextCNN without any ensemble or data\naugmentation.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 09:34:20 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 03:06:23 GMT"}, {"version": "v3", "created": "Wed, 23 May 2018 14:58:49 GMT"}, {"version": "v4", "created": "Sun, 24 Jun 2018 06:18:53 GMT"}, {"version": "v5", "created": "Sun, 23 Jun 2019 04:37:59 GMT"}, {"version": "v6", "created": "Tue, 2 Jun 2020 22:34:56 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Kim", "Taehoon", ""], ["Yang", "Jihoon", ""]]}, {"id": "1805.07799", "submitter": "Kamal Alsabahi Ph.D.", "authors": "Kamal Al-Sabahi, Zhang Zuping, and Mohammed Nadher", "title": "A Hierarchical Structured Self-Attentive Model for Extractive Document\n  Summarization (HSSAS)", "comments": "8 pages, 4 figures, 2 tables, IEEE Access, pp. 1-1, 2018", "journal-ref": null, "doi": "10.1109/ACCESS.2018.2829199", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advance in neural network architecture and training algorithms\nhave shown the effectiveness of representation learning. The neural\nnetwork-based models generate better representation than the traditional ones.\nThey have the ability to automatically learn the distributed representation for\nsentences and documents. To this end, we proposed a novel model that addresses\nseveral issues that are not adequately modeled by the previously proposed\nmodels, such as the memory problem and incorporating the knowledge of document\nstructure. Our model uses a hierarchical structured self-attention mechanism to\ncreate the sentence and document embeddings. This architecture mirrors the\nhierarchical structure of the document and in turn enables us to obtain better\nfeature representation. The attention mechanism provides extra source of\ninformation to guide the summary extraction. The new model treated the\nsummarization task as a classification problem in which the model computes the\nrespective probabilities of sentence-summary membership. The model predictions\nare broken up by several features such as information content, salience,\nnovelty and positional representation. The proposed model was evaluated on two\nwell-known datasets, the CNN / Daily Mail, and DUC 2002. The experimental\nresults show that our model outperforms the current extractive state-of-the-art\nby a considerable margin.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 17:16:49 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Al-Sabahi", "Kamal", ""], ["Zuping", "Zhang", ""], ["Nadher", "Mohammed", ""]]}, {"id": "1805.07819", "submitter": "Abhishek Kumar", "authors": "Abhishek Kumar, Daisuke Kawahara, Sadao Kurohashi", "title": "Knowledge-enriched Two-layered Attention Network for Sentiment Analysis", "comments": "Accepted in NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We propose a novel two-layered attention network based on Bidirectional Long\nShort-Term Memory for sentiment analysis. The novel two-layered attention\nnetwork takes advantage of the external knowledge bases to improve the\nsentiment prediction. It uses the Knowledge Graph Embedding generated using the\nWordNet. We build our model by combining the two-layered attention network with\nthe supervised model based on Support Vector Regression using a Multilayer\nPerceptron network for sentiment analysis. We evaluate our model on the\nbenchmark dataset of SemEval 2017 Task 5. Experimental results show that the\nproposed model surpasses the top system of SemEval 2017 Task 5. The model\nperforms significantly better by improving the state-of-the-art system at\nSemEval 2017 Task 5 by 1.7 and 3.7 points for sub-tracks 1 and 2 respectively.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 20:00:27 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 23:54:18 GMT"}, {"version": "v3", "created": "Fri, 25 May 2018 10:08:40 GMT"}, {"version": "v4", "created": "Sat, 16 Jun 2018 00:22:30 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Kumar", "Abhishek", ""], ["Kawahara", "Daisuke", ""], ["Kurohashi", "Sadao", ""]]}, {"id": "1805.07824", "submitter": "Javier \\'Alvez", "authors": "Javier \\'Alvez and Itziar Gonzalez-Dios and German Rigau", "title": "Validating WordNet Meronymy Relations using Adimen-SUMO", "comments": "14 pages, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we report on the practical application of a novel approach for\nvalidating the knowledge of WordNet using Adimen-SUMO. In particular, this\npaper focuses on cross-checking the WordNet meronymy relations against the\nknowledge encoded in Adimen-SUMO. Our validation approach tests a large set of\ncompetency questions (CQs), which are derived (semi)-automatically from the\nknowledge encoded in WordNet, SUMO and their mapping, by applying efficient\nfirst-order logic automated theorem provers. Unfortunately, despite of being\ncreated manually, these knowledge resources are not free of errors and\ndiscrepancies. In consequence, some of the resulting CQs are not plausible\naccording to the knowledge included in Adimen-SUMO. Thus, first we focus on\n(semi)-automatically improving the alignment between these knowledge resources,\nand second, we perform a minimal set of corrections in the ontology. Our aim is\nto minimize the manual effort required for an extensive validation process. We\nreport on the strategies followed, the changes made, the effort needed and its\nimpact when validating the WordNet meronymy relations using improved versions\nof the mapping and the ontology. Based on the new results, we discuss the\nimplications of the appropriate corrections and the need of future\nenhancements.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 20:50:17 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["\u00c1lvez", "Javier", ""], ["Gonzalez-Dios", "Itziar", ""], ["Rigau", "German", ""]]}, {"id": "1805.07851", "submitter": "Harish Gandhi Ramachandran", "authors": "Harish Gandhi Ramachandran, Dan DeRose Jr", "title": "A Text Analysis of Federal Reserve meeting minutes", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Recent developments in monetary policy by the Federal Reserve has created a\nneed for an objective method of communication analysis.Using methods developed\nfor text analysis, we present a novel technique of analysis which creates a\nsemantic space defined by various policymakers public comments and places the\ncommittee consensus in the appropriate location. Its then possible to determine\nwhich member of the committee is most closely aligned with the committee\nconsensus over time and create a foundation for further actionable research.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 00:27:05 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Ramachandran", "Harish Gandhi", ""], ["DeRose", "Dan", "Jr"]]}, {"id": "1805.07858", "submitter": "Todor Mihaylov", "authors": "Todor Mihaylov and Anette Frank", "title": "Knowledgeable Reader: Enhancing Cloze-Style Reading Comprehension with\n  External Commonsense Knowledge", "comments": "Accepted as long paper at ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a neural reading comprehension model that integrates external\ncommonsense knowledge, encoded as a key-value memory, in a cloze-style setting.\nInstead of relying only on document-to-question interaction or discrete\nfeatures as in prior work, our model attends to relevant external knowledge and\ncombines this knowledge with the context representation before inferring the\nanswer. This allows the model to attract and imply knowledge from an external\nknowledge source that is not explicitly stated in the text, but that is\nrelevant for inferring the answer. Our model improves results over a very\nstrong baseline on a hard Common Nouns dataset, making it a strong competitor\nof much more complex models. By including knowledge explicitly, our model can\nalso provide evidence about the background knowledge used in the RC process.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 01:13:42 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Mihaylov", "Todor", ""], ["Frank", "Anette", ""]]}, {"id": "1805.07882", "submitter": "Huy Nguyen Tien", "authors": "Huy Nguyen Tien, Minh Nguyen Le, Yamasaki Tomohiro, Izuha Tatsuya", "title": "Sentence Modeling via Multiple Word Embeddings and Multi-level\n  Comparison for Semantic Textual Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different word embedding models capture different aspects of linguistic\nproperties. This inspired us to propose a model (M-MaxLSTM-CNN) for employing\nmultiple sets of word embeddings for evaluating sentence similarity/relation.\nRepresenting each word by multiple word embeddings, the MaxLSTM-CNN encoder\ngenerates a novel sentence embedding. We then learn the similarity/relation\nbetween our sentence embeddings via Multi-level comparison. Our method\nM-MaxLSTM-CNN consistently shows strong performances in several tasks (i.e.,\nmeasure textual similarity, identify paraphrase, recognize textual entailment).\nAccording to the experimental results on STS Benchmark dataset and SICK dataset\nfrom SemEval, M-MaxLSTM-CNN outperforms the state-of-the-art methods for\ntextual similarity tasks. Our model does not use hand-crafted features (e.g.,\nalignment features, Ngram overlaps, dependency features) as well as does not\nrequire pre-trained word embeddings to have the same dimension.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 03:54:39 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Tien", "Huy Nguyen", ""], ["Le", "Minh Nguyen", ""], ["Tomohiro", "Yamasaki", ""], ["Tatsuya", "Izuha", ""]]}, {"id": "1805.07889", "submitter": "Huaishao Luo", "authors": "Huaishao Luo, Tianrui Li, Bing Liu, Bin Wang, and Herwig Unger", "title": "Improving Aspect Term Extraction with Bidirectional Dependency Tree\n  Representation", "comments": "Accepted by TASLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect term extraction is one of the important subtasks in aspect-based\nsentiment analysis. Previous studies have shown that using dependency tree\nstructure representation is promising for this task. However, most dependency\ntree structures involve only one directional propagation on the dependency\ntree. In this paper, we first propose a novel bidirectional dependency tree\nnetwork to extract dependency structure features from the given sentences. The\nkey idea is to explicitly incorporate both representations gained separately\nfrom the bottom-up and top-down propagation on the given dependency syntactic\ntree. An end-to-end framework is then developed to integrate the embedded\nrepresentations and BiLSTM plus CRF to learn both tree-structured and\nsequential features to solve the aspect term extraction problem. Experimental\nresults demonstrate that the proposed model outperforms state-of-the-art\nbaseline models on four benchmark SemEval datasets.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 04:49:53 GMT"}, {"version": "v2", "created": "Sun, 5 May 2019 05:44:24 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Luo", "Huaishao", ""], ["Li", "Tianrui", ""], ["Liu", "Bing", ""], ["Wang", "Bin", ""], ["Unger", "Herwig", ""]]}, {"id": "1805.07932", "submitter": "Jin-Hwa Kim", "authors": "Jin-Hwa Kim, Jaehyun Jun, Byoung-Tak Zhang", "title": "Bilinear Attention Networks", "comments": "Accepted by NIPS 2018; Figure 1 was updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention networks in multimodal learning provide an efficient way to utilize\ngiven visual information selectively. However, the computational cost to learn\nattention distributions for every pair of multimodal input channels is\nprohibitively expensive. To solve this problem, co-attention builds two\nseparate attention distributions for each modality neglecting the interaction\nbetween multimodal inputs. In this paper, we propose bilinear attention\nnetworks (BAN) that find bilinear attention distributions to utilize given\nvision-language information seamlessly. BAN considers bilinear interactions\namong two groups of input channels, while low-rank bilinear pooling extracts\nthe joint representations for each pair of channels. Furthermore, we propose a\nvariant of multimodal residual networks to exploit eight-attention maps of the\nBAN efficiently. We quantitatively and qualitatively evaluate our model on\nvisual question answering (VQA 2.0) and Flickr30k Entities datasets, showing\nthat BAN significantly outperforms previous methods and achieves new\nstate-of-the-arts on both datasets.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 07:58:31 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 11:29:49 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Kim", "Jin-Hwa", ""], ["Jun", "Jaehyun", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1805.07946", "submitter": "Deniz Yuret", "authors": "Ekin Aky\\\"urek, Erenay Dayan{\\i}k, Deniz Yuret", "title": "Morphological analysis using a sequence decoder", "comments": "Final TACL version", "journal-ref": "Transactions Of The Association For Computational Linguistics, 7,\n  567-579 (2019)", "doi": "10.1162/tacl_a_00286", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Morse, a recurrent encoder-decoder model that produces\nmorphological analyses of each word in a sentence. The encoder turns the\nrelevant information about the word and its context into a fixed size vector\nrepresentation and the decoder generates the sequence of characters for the\nlemma followed by a sequence of individual morphological features. We show that\ngenerating morphological features individually rather than as a combined tag\nallows the model to handle rare or unseen tags and outperform whole-tag models.\nIn addition, generating morphological features as a sequence rather than e.g.\\\nan unordered set allows our model to produce an arbitrary number of features\nthat represent multiple inflectional groups in morphologically complex\nlanguages. We obtain state-of-the art results in nine languages of different\nmorphological complexity under low-resource, high-resource and transfer\nlearning settings. We also introduce TrMor2018, a new high accuracy Turkish\nmorphology dataset. Our Morse implementation and the TrMor2018 dataset are\navailable online to support future research\\footnote{See\n\\url{https://github.com/ai-ku/Morse.jl} for a Morse implementation in\nJulia/Knet \\cite{knet2016mlsys} and \\url{https://github.com/ai-ku/TrMor2018}\nfor the new Turkish dataset.}.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 08:49:32 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 14:30:35 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Aky\u00fcrek", "Ekin", ""], ["Dayan\u0131k", "Erenay", ""], ["Yuret", "Deniz", ""]]}, {"id": "1805.07952", "submitter": "Deniz Yuret", "authors": "Ozan Arkan Can, Deniz Yuret", "title": "A new dataset and model for learning to understand navigational\n  instructions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a state-of-the-art model and introduce a new\ndataset for grounded language learning. Our goal is to develop a model that can\nlearn to follow new instructions given prior instruction-perception-action\nexamples. We based our work on the SAIL dataset which consists of navigational\ninstructions and actions in a maze-like environment. The new model we propose\nachieves the best results to date on the SAIL dataset by using an improved\nperceptual component that can represent relative positions of objects. We also\nanalyze the problems with the SAIL dataset regarding its size and balance. We\nargue that performance on a small, fixed-size dataset is no longer a good\nmeasure to differentiate state-of-the-art models. We introduce SAILx, a\nsynthetic dataset generator, and perform experiments where the size and balance\nof the dataset are controlled.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 09:01:31 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Can", "Ozan Arkan", ""], ["Yuret", "Deniz", ""]]}, {"id": "1805.07966", "submitter": "Sopan Khosla", "authors": "Sopan Khosla, Niyati Chhaya, Kushal Chawla", "title": "Aff2Vec: Affect--Enriched Distributional Word Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human communication includes information, opinions, and reactions. Reactions\nare often captured by the affective-messages in written as well as verbal\ncommunications. While there has been work in affect modeling and to some extent\naffective content generation, the area of affective word distributions in not\nwell studied. Synsets and lexica capture semantic relationships across words.\nThese models however lack in encoding affective or emotional word\ninterpretations. Our proposed model, Aff2Vec provides a method for enriched\nword embeddings that are representative of affective interpretations of words.\nAff2Vec outperforms the state--of--the--art in intrinsic word-similarity tasks.\nFurther, the use of Aff2Vec representations outperforms baseline embeddings in\ndownstream natural language understanding tasks including sentiment analysis,\npersonality detection, and frustration prediction.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 10:10:16 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Khosla", "Sopan", ""], ["Chhaya", "Niyati", ""], ["Chawla", "Kushal", ""]]}, {"id": "1805.08028", "submitter": "Fuli Luo", "authors": "Fuli Luo, Tianyu Liu, Qiaolin Xia, Baobao Chang and Zhifang Sui", "title": "Incorporating Glosses into Neural Word Sense Disambiguation", "comments": "Accepted to ACL 2018 (long paper), added code link", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word Sense Disambiguation (WSD) aims to identify the correct meaning of\npolysemous words in the particular context. Lexical resources like WordNet\nwhich are proved to be of great help for WSD in the knowledge-based methods.\nHowever, previous neural networks for WSD always rely on massive labeled data\n(context), ignoring lexical resources like glosses (sense definitions). In this\npaper, we integrate the context and glosses of the target word into a unified\nframework in order to make full use of both labeled data and lexical knowledge.\nTherefore, we propose GAS: a gloss-augmented WSD neural network which jointly\nencodes the context and glosses of the target word. GAS models the semantic\nrelationship between the context and the gloss in an improved memory network\nframework, which breaks the barriers of the previous supervised methods and\nknowledge-based methods. We further extend the original gloss of word sense via\nits semantic relations in WordNet to enrich the gloss information. The\nexperimental results show that our model outperforms the state-of-theart\nsystems on several English all-words WSD datasets.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 12:59:17 GMT"}, {"version": "v2", "created": "Mon, 16 Jul 2018 14:58:30 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Luo", "Fuli", ""], ["Liu", "Tianyu", ""], ["Xia", "Qiaolin", ""], ["Chang", "Baobao", ""], ["Sui", "Zhifang", ""]]}, {"id": "1805.08032", "submitter": "Jan Chorowski", "authors": "Jan Chorowski, Adrian {\\L}a\\'ncucki, Szymon Malik, Maciej Pawlikowski,\n  Pawe{\\l} Rychlikowski, Pawe{\\l} Zykowski", "title": "A Talker Ensemble: the University of Wroc{\\l}aw's Entry to the NIPS 2017\n  Conversational Intelligence Challenge", "comments": "To appear in NIPS 2017 Competition track Springer Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Poetwannabe, a chatbot submitted by the University of Wroc{\\l}aw\nto the NIPS 2017 Conversational Intelligence Challenge, in which it ranked\nfirst ex-aequo. It is able to conduct a conversation with a user in a natural\nlanguage. The primary functionality of our dialogue system is context-aware\nquestion answering (QA), while its secondary function is maintaining user\nengagement. The chatbot is composed of a number of sub-modules, which\nindependently prepare replies to user's prompts and assess their own\nconfidence. To answer questions, our dialogue system relies heavily on factual\ndata, sourced mostly from Wikipedia and DBpedia, data of real user interactions\nin public forums, as well as data concerning general literature. Where\napplicable, modules are trained on large datasets using GPUs. However, to\ncomply with the competition's requirements, the final system is compact and\nruns on commodity hardware.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 13:07:31 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Chorowski", "Jan", ""], ["\u0141a\u0144cucki", "Adrian", ""], ["Malik", "Szymon", ""], ["Pawlikowski", "Maciej", ""], ["Rychlikowski", "Pawe\u0142", ""], ["Zykowski", "Pawe\u0142", ""]]}, {"id": "1805.08092", "submitter": "Sewon Min", "authors": "Sewon Min, Victor Zhong, Richard Socher, Caiming Xiong", "title": "Efficient and Robust Question Answering from Minimal Context over\n  Documents", "comments": "Published as a conference paper at ACL 2018 (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural models for question answering (QA) over documents have achieved\nsignificant performance improvements. Although effective, these models do not\nscale to large corpora due to their complex modeling of interactions between\nthe document and the question. Moreover, recent work has shown that such models\nare sensitive to adversarial inputs. In this paper, we study the minimal\ncontext required to answer the question, and find that most questions in\nexisting datasets can be answered with a small set of sentences. Inspired by\nthis observation, we propose a simple sentence selector to select the minimal\nset of sentences to feed into the QA model. Our overall system achieves\nsignificant reductions in training (up to 15 times) and inference times (up to\n13 times), with accuracy comparable to or better than the state-of-the-art on\nSQuAD, NewsQA, TriviaQA and SQuAD-Open. Furthermore, our experimental results\nand analyses show that our approach is more robust to adversarial inputs.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 14:48:08 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Min", "Sewon", ""], ["Zhong", "Victor", ""], ["Socher", "Richard", ""], ["Xiong", "Caiming", ""]]}, {"id": "1805.08093", "submitter": "Thiago Castro Ferreira", "authors": "Thiago Castro Ferreira, Diego Moussallem, \\'Akos K\\'ad\\'ar, Sander\n  Wubben and Emiel Krahmer", "title": "NeuralREG: An end-to-end approach to referring expression generation", "comments": "Accepted for presentation at ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Traditionally, Referring Expression Generation (REG) models first decide on\nthe form and then on the content of references to discourse entities in text,\ntypically relying on features such as salience and grammatical function. In\nthis paper, we present a new approach (NeuralREG), relying on deep neural\nnetworks, which makes decisions about form and content in one go without\nexplicit feature extraction. Using a delexicalized version of the WebNLG\ncorpus, we show that the neural model substantially improves over two strong\nbaselines. Data and models are publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 14:48:14 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Ferreira", "Thiago Castro", ""], ["Moussallem", "Diego", ""], ["K\u00e1d\u00e1r", "\u00c1kos", ""], ["Wubben", "Sander", ""], ["Krahmer", "Emiel", ""]]}, {"id": "1805.08099", "submitter": "Gerhard J\\\"ager", "authors": "Gerhard J\\\"ager", "title": "Computational Historical Linguistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational approaches to historical linguistics have been proposed since\nhalf a century. Within the last decade, this line of research has received a\nmajor boost, owing both to the transfer of ideas and software from\ncomputational biology and to the release of several large electronic data\nresources suitable for systematic comparative work.\n  In this article, some of the central research topic of this new wave of\ncomputational historical linguistics are introduced and discussed. These are\nautomatic assessment of genetic relatedness, automatic cognate detection,\nphylogenetic inference and ancestral state reconstruction. They will be\ndemonstrated by means of a case study of automatically reconstructing a\nProto-Romance word list from lexical data of 50 modern Romance languages and\ndialects.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 14:57:38 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["J\u00e4ger", "Gerhard", ""]]}, {"id": "1805.08154", "submitter": "Georgios Spithourakis", "authors": "Georgios P. Spithourakis and Sebastian Riedel", "title": "Numeracy for Language Models: Evaluating and Improving their Ability to\n  Predict Numbers", "comments": "accepted at ACL 2018", "journal-ref": null, "doi": "10.18653/v1/P18-1196", "report-no": null, "categories": "cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numeracy is the ability to understand and work with numbers. It is a\nnecessary skill for composing and understanding documents in clinical,\nscientific, and other technical domains. In this paper, we explore different\nstrategies for modelling numerals with language models, such as memorisation\nand digit-by-digit composition, and propose a novel neural architecture that\nuses a continuous probability density function to model numerals from an open\nvocabulary. Our evaluation on clinical and scientific datasets shows that using\nhierarchical models to distinguish numerals from words improves a perplexity\nmetric on the subset of numerals by 2 and 4 orders of magnitude, respectively,\nover non-hierarchical models. A combination of strategies can further improve\nperplexity. Our continuous probability density function model reduces mean\nabsolute percentage errors by 18% and 54% in comparison to the second best\nstrategy for each dataset, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 16:18:41 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Spithourakis", "Georgios P.", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1805.08159", "submitter": "Jinfeng Rao", "authors": "Jinfeng Rao, Wei Yang, Yuhao Zhang, Ferhan Ture, Jimmy Lin", "title": "Multi-Perspective Relevance Matching with Hierarchical ConvNets for\n  Social Media Search", "comments": "AAAI 2019, 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite substantial interest in applications of neural networks to\ninformation retrieval, neural ranking models have only been applied to standard\nad hoc retrieval tasks over web pages and newswire documents. This paper\nproposes MP-HCNN (Multi-Perspective Hierarchical Convolutional Neural Network)\na novel neural ranking model specifically designed for ranking short social\nmedia posts. We identify document length, informal language, and heterogeneous\nrelevance signals as features that distinguish documents in our domain, and\npresent a model specifically designed with these characteristics in mind. Our\nmodel uses hierarchical convolutional layers to learn latent semantic\nsoft-match relevance signals at the character, word, and phrase levels. A\npooling-based similarity measurement layer integrates evidence from multiple\ntypes of matches between the query, the social media post, as well as URLs\ncontained in the post. Extensive experiments using Twitter data from the TREC\nMicroblog Tracks 2011--2014 show that our model significantly outperforms prior\nfeature-based as well and existing neural ranking models. To our best\nknowledge, this paper presents the first substantial work tackling search over\nsocial media posts using neural ranking models.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 16:25:15 GMT"}, {"version": "v2", "created": "Sat, 22 Jun 2019 00:14:49 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Rao", "Jinfeng", ""], ["Yang", "Wei", ""], ["Zhang", "Yuhao", ""], ["Ture", "Ferhan", ""], ["Lin", "Jimmy", ""]]}, {"id": "1805.08174", "submitter": "Shagun Sodhani", "authors": "Shagun Sodhani, Vardaan Pahuja", "title": "Reproducibility Report for \"Learning To Count Objects In Natural Images\n  For Visual Question Answering\"", "comments": "Submitted to Reproducibility in ML Workshop, ICML'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This is the reproducibility report for the paper \"Learning To Count Objects\nIn Natural Images For Visual QuestionAnswering\"\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 16:50:55 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Sodhani", "Shagun", ""], ["Pahuja", "Vardaan", ""]]}, {"id": "1805.08182", "submitter": "Anastassia Kornilova", "authors": "Anastassia Kornilova, Daniel Argyle and Vlad Eidelman", "title": "Party Matters: Enhancing Legislative Embeddings with Author Attributes\n  for Vote Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting how Congressional legislators will vote is important for\nunderstanding their past and future behavior. However, previous work on\nroll-call prediction has been limited to single session settings, thus did not\nconsider generalization across sessions. In this paper, we show that metadata\nis crucial for modeling voting outcomes in new contexts, as changes between\nsessions lead to changes in the underlying data generation process. We show how\naugmenting bill text with the sponsors' ideologies in a neural network model\ncan achieve an average of a 4% boost in accuracy over the previous\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 17:03:13 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Kornilova", "Anastassia", ""], ["Argyle", "Daniel", ""], ["Eidelman", "Vlad", ""]]}, {"id": "1805.08237", "submitter": "Bernd Bohnet", "authors": "Bernd Bohnet, Ryan McDonald, Goncalo Simoes, Daniel Andor, Emily\n  Pitler, Joshua Maynez", "title": "Morphosyntactic Tagging with a Meta-BiLSTM Model over Context Sensitive\n  Token Encodings", "comments": null, "journal-ref": "ACL 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of neural networks, and particularly recurrent neural networks, has\nproduced significant advances in part-of-speech tagging accuracy. One\ncharacteristic common among these models is the presence of rich initial word\nencodings. These encodings typically are composed of a recurrent\ncharacter-based representation with learned and pre-trained word embeddings.\nHowever, these encodings do not consider a context wider than a single word and\nit is only through subsequent recurrent layers that word or sub-word\ninformation interacts. In this paper, we investigate models that use recurrent\nneural networks with sentence-level context for initial character and\nword-based representations. In particular we show that optimal results are\nobtained by integrating these context sensitive representations through\nsynchronized training with a meta-model that learns to combine their states. We\npresent results on part-of-speech and morphological tagging with\nstate-of-the-art performance on a number of languages.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 18:09:23 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Bohnet", "Bernd", ""], ["McDonald", "Ryan", ""], ["Simoes", "Goncalo", ""], ["Andor", "Daniel", ""], ["Pitler", "Emily", ""], ["Maynez", "Joshua", ""]]}, {"id": "1805.08241", "submitter": "Chaitanya Malaviya", "authors": "Chaitanya Malaviya, Pedro Ferreira, Andr\\'e F. T. Martins", "title": "Sparse and Constrained Attention for Neural Machine Translation", "comments": "Proceedings of ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In NMT, words are sometimes dropped from the source or generated repeatedly\nin the translation. We explore novel strategies to address the coverage problem\nthat change only the attention transformation. Our approach allocates\nfertilities to source words, used to bound the attention each word can receive.\nWe experiment with various sparse and constrained attention transformations and\npropose a new one, constrained sparsemax, shown to be differentiable and\nsparse. Empirical evaluation is provided in three languages pairs.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 18:14:35 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Malaviya", "Chaitanya", ""], ["Ferreira", "Pedro", ""], ["Martins", "Andr\u00e9 F. T.", ""]]}, {"id": "1805.08271", "submitter": "Hongyuan Mei", "authors": "Hongyuan Mei, Sheng Zhang, Kevin Duh, Benjamin Van Durme", "title": "Halo: Learning Semantics-Aware Representations for Cross-Lingual\n  Information Extraction", "comments": "*SEM 2018 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual information extraction (CLIE) is an important and challenging\ntask, especially in low resource scenarios. To tackle this challenge, we\npropose a training method, called Halo, which enforces the local region of each\nhidden state of a neural model to only generate target tokens with the same\nsemantic structure tag. This simple but powerful technique enables a neural\nmodel to learn semantics-aware representations that are robust to noise,\nwithout introducing any extra parameter, thus yielding better generalization in\nboth high and low resource settings.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 19:57:23 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Mei", "Hongyuan", ""], ["Zhang", "Sheng", ""], ["Duh", "Kevin", ""], ["Van Durme", "Benjamin", ""]]}, {"id": "1805.08297", "submitter": "Wuwei Lan", "authors": "Wuwei Lan and Wei Xu", "title": "Character-based Neural Networks for Sentence Pair Modeling", "comments": "7 pages; Accepted in NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence pair modeling is critical for many NLP tasks, such as paraphrase\nidentification, semantic textual similarity, and natural language inference.\nMost state-of-the-art neural models for these tasks rely on pretrained word\nembedding and compose sentence-level semantics in varied ways; however, few\nworks have attempted to verify whether we really need pretrained embeddings in\nthese tasks. In this paper, we study how effective subword-level (character and\ncharacter n-gram) representations are in sentence pair modeling. Though it is\nwell-known that subword models are effective in tasks with single sentence\ninput, including language modeling and machine translation, they have not been\nsystematically studied in sentence pair modeling tasks where the semantic and\nstring similarities between texts matter. Our experiments show that subword\nmodels without any pretrained word embedding can achieve new state-of-the-art\nresults on two social media datasets and competitive results on news data for\nparaphrase identification.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 21:36:09 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Lan", "Wuwei", ""], ["Xu", "Wei", ""]]}, {"id": "1805.08329", "submitter": "Haonan Yu", "authors": "Haonan Yu, Xiaochen Lian, Haichao Zhang, Wei Xu", "title": "Guided Feature Transformation (GFT): A Neural Language Grounding Module\n  for Embodied Agents", "comments": "CoRL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been a rising interest in training agents, embodied in\nvirtual environments, to perform language-directed tasks by deep reinforcement\nlearning. In this paper, we propose a simple but effective neural language\ngrounding module for embodied agents that can be trained end to end from\nscratch taking raw pixels, unstructured linguistic commands, and sparse rewards\nas the inputs. We model the language grounding process as a language-guided\ntransformation of visual features, where latent sentence embeddings are used as\nthe transformation matrices. In several language-directed navigation tasks that\nfeature challenging partial observability and require simple reasoning, our\nmodule significantly outperforms the state of the art. We also release\nXWorld3D, an easy-to-customize 3D environment that can potentially be modified\nto evaluate a variety of embodied agents.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 00:16:39 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 18:16:40 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Yu", "Haonan", ""], ["Lian", "Xiaochen", ""], ["Zhang", "Haichao", ""], ["Xu", "Wei", ""]]}, {"id": "1805.08352", "submitter": "Shereen Oraby", "authors": "Shereen Oraby, Lena Reed, Shubhangi Tandon, T. S. Sharath, Stephanie\n  Lukin, Marilyn Walker", "title": "Controlling Personality-Based Stylistic Variation with Neural Natural\n  Language Generators", "comments": "To appear at SIGDIAL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language generators for task-oriented dialogue must effectively\nrealize system dialogue actions and their associated semantics. In many\napplications, it is also desirable for generators to control the style of an\nutterance. To date, work on task-oriented neural generation has primarily\nfocused on semantic fidelity rather than achieving stylistic goals, while work\non style has been done in contexts where it is difficult to measure content\npreservation. Here we present three different sequence-to-sequence models and\ncarefully test how well they disentangle content and style. We use a\nstatistical generator, Personage, to synthesize a new corpus of over 88,000\nrestaurant domain utterances whose style varies according to models of\npersonality, giving us total control over both the semantic content and the\nstylistic variation in the training data. We then vary the amount of explicit\nstylistic supervision given to the three models. We show that our most explicit\nmodel can simultaneously achieve high fidelity to both semantic and stylistic\ngoals: this model adds a context vector of 36 stylistic parameters as input to\nthe hidden state of the encoder at each time step, showing the benefits of\nexplicit stylistic supervision, even when the amount of training data is large.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 02:07:32 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Oraby", "Shereen", ""], ["Reed", "Lena", ""], ["Tandon", "Shubhangi", ""], ["Sharath", "T. S.", ""], ["Lukin", "Stephanie", ""], ["Walker", "Marilyn", ""]]}, {"id": "1805.08353", "submitter": "Anson Bastos", "authors": "Anson Bastos", "title": "Learning sentence embeddings using Recursive Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Learning sentence vectors that generalise well is a challenging task. In this\npaper we compare three methods of learning phrase embeddings: 1) Using LSTMs,\n2) using recursive nets, 3) A variant of the method 2 using the POS information\nof the phrase. We train our models on dictionary definitions of words to obtain\na reverse dictionary application similar to Felix et al. [1]. To see if our\nembeddings can be transferred to a new task we also train and test on the\nrotten tomatoes dataset [2]. We train keeping the sentence embeddings fixed as\nwell as with fine tuning.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 02:09:02 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Bastos", "Anson", ""]]}, {"id": "1805.08389", "submitter": "Jialin Wu", "authors": "Jialin Wu, Zeyuan Hu, Raymond J. Mooney", "title": "Joint Image Captioning and Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering visual questions need acquire daily common knowledge and model the\nsemantic connection among different parts in images, which is too difficult for\nVQA systems to learn from images with the only supervision from answers.\nMeanwhile, image captioning systems with beam search strategy tend to generate\nsimilar captions and fail to diversely describe images. To address the\naforementioned issues, we present a system to have these two tasks compensate\nwith each other, which is capable of jointly producing image captions and\nanswering visual questions. In particular, we utilize question and image\nfeatures to generate question-related captions and use the generated captions\nas additional features to provide new knowledge to the VQA system. For image\ncaptioning, our system attains more informative results in term of the relative\nimprovements on VQA tasks as well as competitive results using automated\nmetrics. Applying our system to the VQA tasks, our results on VQA v2 dataset\nachieve 65.8% using generated captions and 69.1% using annotated captions in\nvalidation set and 68.4% in the test-standard set. Further, an ensemble of 10\nmodels results in 69.7% in the test-standard split.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 04:41:37 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Wu", "Jialin", ""], ["Hu", "Zeyuan", ""], ["Mooney", "Raymond J.", ""]]}, {"id": "1805.08415", "submitter": "Mohammadamir Kavousi", "authors": "Mohammadamir Kavousi, Sepehr Saadatmand", "title": "Estimating the Rating of Reviewers Based on the Text", "comments": "Accepted in the First International Conference on DATA ANALYTICS &\n  LEARNING 2018 http://www.dal-conference.org/2018/acceptedPapers.html You can\n  find this paper at the above link, paper ID: 76", "journal-ref": "First International Conference on Data Analytics & Learning 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User-generated texts such as reviews and social media are valuable sources of\ninformation. Online reviews are important assets for users to buy a product,\nsee a movie, or make a decision. Therefore, rating of a review is one of the\nreliable factors for all users to read and trust the reviews. This paper\nanalyzes the texts of the reviews to evaluate and predict the ratings.\nMoreover, we study the effect of lexical features generated from text as well\nas sentimental words on the accuracy of rating prediction. Our analysis show\nthat words with high information gain score are more efficient compared to\nwords with high TF-IDF value. In addition, we explore the best number of\nfeatures for predicting the ratings of the reviews.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 06:09:39 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Kavousi", "Mohammadamir", ""], ["Saadatmand", "Sepehr", ""]]}, {"id": "1805.08438", "submitter": "Cem Bozsahin", "authors": "Cem Bozsahin and Arzu Burcu Guven", "title": "Paracompositionality, MWEs and Argument Substitution", "comments": "accepted version (pre-final) for 23rd Formal Grammar Conference,\n  August 2018, Sofia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-word expressions, verb-particle constructions, idiomatically combining\nphrases, and phrasal idioms have something in common: not all of their elements\ncontribute to the argument structure of the predicate implicated by the\nexpression.\n  Radically lexicalized theories of grammar that avoid string-, term-, logical\nform-, and tree-writing, and categorial grammars that avoid wrap operation,\nmake predictions about the categories involved in verb-particles and phrasal\nidioms. They may require singleton types, which can only substitute for one\nvalue, not just for one kind of value. These types are asymmetric: they can be\narguments only. They also narrowly constrain the kind of semantic value that\ncan correspond to such syntactic categories. Idiomatically combining phrases do\nnot subcategorize for singleton types, and they exploit another locally\ncomputable and compositional property of a correspondence, that every syntactic\nexpression can project its head word. Such MWEs can be seen as empirically\nrealized categorial possibilities, rather than lacuna in a theory of\nlexicalizable syntactic categories.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 07:59:53 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Bozsahin", "Cem", ""], ["Guven", "Arzu Burcu", ""]]}, {"id": "1805.08455", "submitter": "Massimiliano Ruocco", "authors": "Silje Christensen, Simen Johnsrud, Massimiliano Ruocco, Heri\n  Ramampiaro", "title": "Context-Aware Sequence-to-Sequence Models for Conversational Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work proposes a novel approach based on sequence-to-sequence (seq2seq)\nmodels for context-aware conversational systems. Exist- ing seq2seq models have\nbeen shown to be good for generating natural responses in a data-driven\nconversational system. However, they still lack mechanisms to incorporate\nprevious conversation turns. We investigate RNN-based methods that efficiently\nintegrate previous turns as a context for generating responses. Overall, our\nexperimental results based on human judgment demonstrate the feasibility and\neffectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 08:34:10 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Christensen", "Silje", ""], ["Johnsrud", "Simen", ""], ["Ruocco", "Massimiliano", ""], ["Ramampiaro", "Heri", ""]]}, {"id": "1805.08533", "submitter": "Nora Al-Twairesh", "authors": "Nora Al-Twairesh, Hend Al-Khalifa, AbdulMalik Alsalman, Yousef\n  Al-Ohali", "title": "Sentiment Analysis of Arabic Tweets: Feature Engineering and A Hybrid\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Sentiment Analysis in Arabic is a challenging task due to the rich morphology\nof the language. Moreover, the task is further complicated when applied to\nTwitter data that is known to be highly informal and noisy. In this paper, we\ndevelop a hybrid method for sentiment analysis for Arabic tweets for a specific\nArabic dialect which is the Saudi Dialect. Several features were engineered and\nevaluated using a feature backward selection method. Then a hybrid method that\ncombines a corpus-based and lexicon-based method was developed for several\nclassification models (two-way, three-way, four-way). The best F1-score for\neach of these models was (69.9,61.63,55.07) respectively.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 12:08:22 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Al-Twairesh", "Nora", ""], ["Al-Khalifa", "Hend", ""], ["Alsalman", "AbdulMalik", ""], ["Al-Ohali", "Yousef", ""]]}, {"id": "1805.08660", "submitter": "Yue Gu", "authors": "Yue Gu, Kangning Yang, Shiyu Fu, Shuhong Chen, Xinyu Li and Ivan\n  Marsic", "title": "Multimodal Affective Analysis Using Hierarchical Attention Strategy with\n  Word-Level Alignment", "comments": "Accepted by ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal affective computing, learning to recognize and interpret human\naffects and subjective information from multiple data sources, is still\nchallenging because: (i) it is hard to extract informative features to\nrepresent human affects from heterogeneous inputs; (ii) current fusion\nstrategies only fuse different modalities at abstract level, ignoring\ntime-dependent interactions between modalities. Addressing such issues, we\nintroduce a hierarchical multimodal architecture with attention and word-level\nfusion to classify utter-ance-level sentiment and emotion from text and audio\ndata. Our introduced model outperforms the state-of-the-art approaches on\npublished datasets and we demonstrated that our model is able to visualize and\ninterpret the synchronized attention over modalities.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 15:25:29 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Gu", "Yue", ""], ["Yang", "Kangning", ""], ["Fu", "Shiyu", ""], ["Chen", "Shuhong", ""], ["Li", "Xinyu", ""], ["Marsic", "Ivan", ""]]}, {"id": "1805.08661", "submitter": "Xirong Li", "authors": "Xirong Li and Chaoxi Xu and Xiaoxu Wang and Weiyu Lan and Zhengxiong\n  Jia and Gang Yang and Jieping Xu", "title": "COCO-CN for Cross-Lingual Image Tagging, Captioning and Retrieval", "comments": "accepted for publication as a regular paper in the IEEE Transactions\n  on Multimedia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper contributes to cross-lingual image annotation and retrieval in\nterms of data and baseline methods. We propose COCO-CN, a novel dataset\nenriching MS-COCO with manually written Chinese sentences and tags. For more\neffective annotation acquisition, we develop a recommendation-assisted\ncollective annotation system, automatically providing an annotator with several\ntags and sentences deemed to be relevant with respect to the pictorial content.\nHaving 20,342 images annotated with 27,218 Chinese sentences and 70,993 tags,\nCOCO-CN is currently the largest Chinese-English dataset that provides a\nunified and challenging platform for cross-lingual image tagging, captioning\nand retrieval. We develop conceptually simple yet effective methods per task\nfor learning from cross-lingual resources. Extensive experiments on the three\ntasks justify the viability of the proposed dataset and methods. Data and code\nare publicly available at https://github.com/li-xirong/coco-cn\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 15:26:15 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 00:24:08 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Li", "Xirong", ""], ["Xu", "Chaoxi", ""], ["Wang", "Xiaoxu", ""], ["Lan", "Weiyu", ""], ["Jia", "Zhengxiong", ""], ["Yang", "Gang", ""], ["Xu", "Jieping", ""]]}, {"id": "1805.08701", "submitter": "Soumil Mandal", "authors": "Soumil Mandal, Karthick Nanmaran", "title": "Normalization of Transliterated Words in Code-Mixed Data Using Seq2Seq\n  Model & Levenshtein Distance", "comments": "5 pages, 1 figure, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Building tools for code-mixed data is rapidly gaining popularity in the NLP\nresearch community as such data is exponentially rising on social media.\nWorking with code-mixed data contains several challenges, especially due to\ngrammatical inconsistencies and spelling variations in addition to all the\nprevious known challenges for social media scenarios. In this article, we\npresent a novel architecture focusing on normalizing phonetic typing\nvariations, which is commonly seen in code-mixed data. One of the main features\nof our architecture is that in addition to normalizing, it can also be utilized\nfor back-transliteration and word identification in some cases. Our model\nachieved an accuracy of 90.27% on the test data.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 16:11:12 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Mandal", "Soumil", ""], ["Nanmaran", "Karthick", ""]]}, {"id": "1805.08707", "submitter": "Pasquale Iero", "authors": "Pasquale Iero, Allan Third, Paul Piwek", "title": "A syllogistic system for propositions with intermediate quantifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper describes a formalism that subsumes Peterson's intermediate\nquantifier syllogistic system, and extends the ideas by van Eijck on\nAristotle's logic. Syllogisms are expressed in a concise form making use of and\nextending the Monotonicity Calculus. Contradictory and contrary relationships\nare added so that deduction can derive propositions expressing a form of\nnegation.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 19:33:04 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Iero", "Pasquale", ""], ["Third", "Allan", ""], ["Piwek", "Paul", ""]]}, {"id": "1805.08914", "submitter": "Ruixi Lin", "authors": "Ruixi Lin, Charles Costello, Charles Jankowski", "title": "Enhancing Chinese Intent Classification by Dynamically Integrating\n  Character Features into Word Embeddings with Ensemble Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intent classification has been widely researched on English data with deep\nlearning approaches that are based on neural networks and word embeddings. The\nchallenge for Chinese intent classification stems from the fact that, unlike\nEnglish where most words are made up of 26 phonologic alphabet letters, Chinese\nis logographic, where a Chinese character is a more basic semantic unit that\ncan be informative and its meaning does not vary too much in contexts. Chinese\nword embeddings alone can be inadequate for representing words, and pre-trained\nembeddings can suffer from not aligning well with the task at hand. To account\nfor the inadequacy and leverage Chinese character information, we propose a\nlow-effort and generic way to dynamically integrate character embedding based\nfeature maps with word embedding based inputs, whose resulting word-character\nembeddings are stacked with a contextual information extraction module to\nfurther incorporate context information for predictions. On top of the proposed\nmodel, we employ an ensemble method to combine single models and obtain the\nfinal result. The approach is data-independent without relying on external\nsources like pre-trained word embeddings. The proposed model outperforms\nbaseline models and existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 00:18:42 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Lin", "Ruixi", ""], ["Costello", "Charles", ""], ["Jankowski", "Charles", ""]]}, {"id": "1805.08949", "submitter": "Pengcheng Yin", "authors": "Pengcheng Yin, Bowen Deng, Edgar Chen, Bogdan Vasilescu, Graham Neubig", "title": "Learning to Mine Aligned Code and Natural Language Pairs from Stack\n  Overflow", "comments": "MSR '18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For tasks like code synthesis from natural language, code retrieval, and code\nsummarization, data-driven models have shown great promise. However, creating\nthese models require parallel data between natural language (NL) and code with\nfine-grained alignments. Stack Overflow (SO) is a promising source to create\nsuch a data set: the questions are diverse and most of them have corresponding\nanswers with high-quality code snippets. However, existing heuristic methods\n(e.g., pairing the title of a post with the code in the accepted answer) are\nlimited both in their coverage and the correctness of the NL-code pairs\nobtained. In this paper, we propose a novel method to mine high-quality aligned\ndata from SO using two sets of features: hand-crafted features considering the\nstructure of the extracted snippets, and correspondence features obtained by\ntraining a probabilistic model to capture the correlation between NL and code\nusing neural networks. These features are fed into a classifier that determines\nthe quality of mined NL-code pairs. Experiments using Python and Java as test\nbeds show that the proposed method greatly expands coverage and accuracy over\nexisting mining methods, even when using only a small number of labeled\nexamples. Further, we find that reasonable results are achieved even when\ntraining the classifier on one language and testing on another, showing promise\nfor scaling NL-code mining to a wide variety of programming languages beyond\nthose for which we are able to annotate data.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 03:39:04 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Yin", "Pengcheng", ""], ["Deng", "Bowen", ""], ["Chen", "Edgar", ""], ["Vasilescu", "Bogdan", ""], ["Neubig", "Graham", ""]]}, {"id": "1805.08983", "submitter": "Jonggu Kim", "authors": "Jonggu Kim, Doyeon Kong, Jong-Hyeok Lee", "title": "Self-Attention-Based Message-Relevant Response Generation for Neural\n  Conversation Model", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using a sequence-to-sequence framework, many neural conversation models for\nchit-chat succeed in naturalness of the response. Nevertheless, the neural\nconversation models tend to give generic responses which are not specific to\ngiven messages, and it still remains as a challenge. To alleviate the tendency,\nwe propose a method to promote message-relevant and diverse responses for\nneural conversation model by using self-attention, which is time-efficient as\nwell as effective. Furthermore, we present an investigation of why and how\neffective self-attention is in deep comparison with the standard dialogue\ngeneration. The experiment results show that the proposed method improves the\nstandard dialogue generation in various evaluation metrics.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 07:14:21 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Kim", "Jonggu", ""], ["Kong", "Doyeon", ""], ["Lee", "Jong-Hyeok", ""]]}, {"id": "1805.09007", "submitter": "David Vilares", "authors": "David Vilares and Carlos G\\'omez-Rodr\\'iguez", "title": "A Transition-based Algorithm for Unrestricted AMR Parsing", "comments": "In NAACL 2018 (short papers): 8 pages, 1 Figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-projective parsing can be useful to handle cycles and reentrancy in AMR\ngraphs. We explore this idea and introduce a greedy left-to-right\nnon-projective transition-based parser. At each parsing configuration, an\noracle decides whether to create a concept or whether to connect a pair of\nexisting concepts. The algorithm handles reentrancy and arbitrary cycles\nnatively, i.e. within the transition system itself. The model is evaluated on\nthe LDC2015E86 corpus, obtaining results close to the state of the art,\nincluding a Smatch of 64%, and showing good behavior on reentrant edges.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 08:20:06 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Vilares", "David", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "1805.09016", "submitter": "Jeremy Barnes", "authors": "Jeremy Barnes and Roman Klinger and Sabine Schulte im Walde", "title": "Bilingual Sentiment Embeddings: Joint Projection of Sentiment Across\n  Languages", "comments": "Accepted to ACL 2018 (Long Papers)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Sentiment analysis in low-resource languages suffers from a lack of annotated\ncorpora to estimate high-performing models. Machine translation and bilingual\nword embeddings provide some relief through cross-lingual sentiment approaches.\nHowever, they either require large amounts of parallel data or do not\nsufficiently capture sentiment information. We introduce Bilingual Sentiment\nEmbeddings (BLSE), which jointly represent sentiment information in a source\nand target language. This model only requires a small bilingual lexicon, a\nsource-language corpus annotated for sentiment, and monolingual word embeddings\nfor each language. We perform experiments on three language combinations\n(Spanish, Catalan, Basque) for sentence-level cross-lingual sentiment\nclassification and find that our model significantly outperforms\nstate-of-the-art methods on four out of six experimental setups, as well as\ncapturing complementary information to machine translation. Our analysis of the\nresulting embedding space provides evidence that it represents sentiment\ninformation in the resource-poor target language without any annotated data in\nthat language.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 08:56:15 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Barnes", "Jeremy", ""], ["Klinger", "Roman", ""], ["Walde", "Sabine Schulte im", ""]]}, {"id": "1805.09055", "submitter": "David Vilares", "authors": "David Vilares and Carlos G\\'omez-Rodr\\'iguez", "title": "Grounding the Semantics of Part-of-Day Nouns Worldwide using Twitter", "comments": "In PEOPLES2018 short papers (NAACL workshop), 6 pages, 5 figures, 1\n  table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The usage of part-of-day nouns, such as 'night', and their time-specific\ngreetings ('good night'), varies across languages and cultures. We show the\npossibilities that Twitter offers for studying the semantics of these terms and\nits variability between countries. We mine a worldwide sample of multilingual\ntweets with temporal greetings, and study how their frequencies vary in\nrelation with local time. The results provide insights into the semantics of\nthese temporal expressions and the cultural and sociological factors\ninfluencing their usage.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 11:04:46 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Vilares", "David", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "1805.09119", "submitter": "Penny Karanasou", "authors": "Judith Gaspers and Penny Karanasou and Rajen Chatterjee", "title": "Selecting Machine-Translated Data for Quick Bootstrapping of a Natural\n  Language Understanding System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the use of Machine Translation (MT) to bootstrap a\nNatural Language Understanding (NLU) system for a new language for the use case\nof a large-scale voice-controlled device. The goal is to decrease the cost and\ntime needed to get an annotated corpus for the new language, while still having\na large enough coverage of user requests. Different methods of filtering MT\ndata in order to keep utterances that improve NLU performance and\nlanguage-specific post-processing methods are investigated. These methods are\ntested in a large-scale NLU task with translating around 10 millions training\nutterances from English to German. The results show a large improvement for\nusing MT data over a grammar-based and over an in-house data collection\nbaseline, while reducing the manual effort greatly. Both filtering and\npost-processing approaches improve results further.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 13:20:16 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Gaspers", "Judith", ""], ["Karanasou", "Penny", ""], ["Chatterjee", "Rajen", ""]]}, {"id": "1805.09145", "submitter": "Matthias Jurisch", "authors": "Matthias Jurisch, Bodo Igler", "title": "RDF2Vec-based Classification of Ontology Alignment Changes", "comments": "6 pages, accepted at Workshop on Deep Learning for Knowledge Graphs\n  and Semantic Technologies (DL4KGS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When ontologies cover overlapping topics, the overlap can be represented\nusing ontology alignments. These alignments need to be continuously adapted to\nchanging ontologies. Especially for large ontologies this is a costly task\noften consisting of manual work. Finding changes that do not lead to an\nadaption of the alignment can potentially make this process significantly\neasier. This work presents an approach to finding these changes based on RDF\nembeddings and common classification techniques. To examine the feasibility of\nthis approach, an evaluation on a real-world dataset is presented. In this\nevaluation, the best classifiers reached a precision of 0.8.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 13:34:51 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Jurisch", "Matthias", ""], ["Igler", "Bodo", ""]]}, {"id": "1805.09197", "submitter": "No\\'e Tits", "authors": "No\\'e Tits, Kevin El Haddad, Thierry Dutoit", "title": "ASR-based Features for Emotion Recognition: A Transfer Learning Approach", "comments": "Accepted to be published in the First Workshop on Computational\n  Modeling of Human Multimodal Language - ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last decade, the applications of signal processing have\ndrastically improved with deep learning. However areas of affecting computing\nsuch as emotional speech synthesis or emotion recognition from spoken language\nremains challenging. In this paper, we investigate the use of a neural\nAutomatic Speech Recognition (ASR) as a feature extractor for emotion\nrecognition. We show that these features outperform the eGeMAPS feature set to\npredict the valence and arousal emotional dimensions, which means that the\naudio-to-text mapping learning by the ASR system contain information related to\nthe emotional dimensions in spontaneous speech. We also examine the\nrelationship between first layers (closer to speech) and last layers (closer to\ntext) of the ASR and valence/arousal.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 14:38:39 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 16:50:08 GMT"}, {"version": "v3", "created": "Fri, 1 Jun 2018 08:14:19 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Tits", "No\u00e9", ""], ["Haddad", "Kevin El", ""], ["Dutoit", "Thierry", ""]]}, {"id": "1805.09208", "submitter": "G\\'abor Melis", "authors": "G\\'abor Melis, Charles Blundell, Tom\\'a\\v{s} Ko\\v{c}isk\\'y, Karl\n  Moritz Hermann, Chris Dyer, Phil Blunsom", "title": "Pushing the bounds of dropout", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that dropout training is best understood as performing MAP estimation\nconcurrently for a family of conditional models whose objectives are themselves\nlower bounded by the original dropout objective. This discovery allows us to\npick any model from this family after training, which leads to a substantial\nimprovement on regularisation-heavy language modelling. The family includes\nmodels that compute a power mean over the sampled dropout masks, and their less\nstochastic subvariants with tighter and higher lower bounds than the fully\nstochastic dropout objective. We argue that since the deterministic\nsubvariant's bound is equal to its objective, and the highest amongst these\nmodels, the predominant view of it as a good approximation to MC averaging is\nmisleading. Rather, deterministic dropout is the best available approximation\nto the true objective.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 14:55:39 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2018 15:19:20 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Melis", "G\u00e1bor", ""], ["Blundell", "Charles", ""], ["Ko\u010disk\u00fd", "Tom\u00e1\u0161", ""], ["Hermann", "Karl Moritz", ""], ["Dyer", "Chris", ""], ["Blunsom", "Phil", ""]]}, {"id": "1805.09209", "submitter": "Alexander Panchenko", "authors": "Nikolay Arefyev, Pavel Ermolaev, Alexander Panchenko", "title": "How much does a word weigh? Weighting word embeddings for word sense\n  induction", "comments": "In the Proceedings of the 24rd International Conference on\n  Computational Linguistics and Intellectual Technologies (Dialogue'2018),\n  Moscow, Russia. RGGU", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper describes our participation in the first shared task on word sense\ninduction and disambiguation for the Russian language RUSSE'2018 (Panchenko et\nal., 2018). For each of several dozens of ambiguous words, the participants\nwere asked to group text fragments containing it according to the senses of\nthis word, which were not provided beforehand, therefore the \"induction\" part\nof the task. For instance, a word \"bank\" and a set of text fragments (also\nknown as \"contexts\") in which this word occurs, e.g. \"bank is a financial\ninstitution that accepts deposits\" and \"river bank is a slope beside a body of\nwater\" were given. A participant was asked to cluster such contexts in the\nunknown in advance number of clusters corresponding to, in this case, the\n\"company\" and the \"area\" senses of the word \"bank\". The organizers proposed\nthree evaluation datasets of varying complexity and text genres based\nrespectively on texts of Wikipedia, Web pages, and a dictionary of the Russian\nlanguage. We present two experiments: a positive and a negative one, based\nrespectively on clustering of contexts represented as a weighted average of\nword embeddings and on machine translation using two state-of-the-art\nproduction neural machine translation systems. Our team showed the second best\nresult on two datasets and the third best result on the remaining one dataset\namong 18 participating teams. We managed to substantially outperform\ncompetitive state-of-the-art baselines from the previous years based on sense\nembeddings.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 14:58:13 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 15:23:44 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Arefyev", "Nikolay", ""], ["Ermolaev", "Pavel", ""], ["Panchenko", "Alexander", ""]]}, {"id": "1805.09354", "submitter": "Juan Pavez", "authors": "Juan Pavez, H\\'ector Allende and H\\'ector Allende-Cid", "title": "Working Memory Networks: Augmenting Memory Networks with a Relational\n  Reasoning Module", "comments": "Published in ACL 2018. The code for these studies is available at\n  https://github.com/jgpavez/Working-Memory-Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last years, there has been a lot of interest in achieving some\nkind of complex reasoning using deep neural networks. To do that, models like\nMemory Networks (MemNNs) have combined external memory storages and attention\nmechanisms. These architectures, however, lack of more complex reasoning\nmechanisms that could allow, for instance, relational reasoning. Relation\nNetworks (RNs), on the other hand, have shown outstanding results in relational\nreasoning tasks. Unfortunately, their computational cost grows quadratically\nwith the number of memories, something prohibitive for larger problems. To\nsolve these issues, we introduce the Working Memory Network, a MemNN\narchitecture with a novel working memory storage and reasoning module. Our\nmodel retains the relational reasoning abilities of the RN while reducing its\ncomputational complexity from quadratic to linear. We tested our model on the\ntext QA dataset bAbI and the visual QA dataset NLVR. In the jointly trained\nbAbI-10k, we set a new state-of-the-art, achieving a mean error of less than\n0.5%. Moreover, a simple ensemble of two of our models solves all 20 tasks in\nthe joint version of the benchmark.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 18:03:08 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Pavez", "Juan", ""], ["Allende", "H\u00e9ctor", ""], ["Allende-Cid", "H\u00e9ctor", ""]]}, {"id": "1805.09355", "submitter": "Marek Rei", "authors": "Marek Rei, Daniela Gerz, Ivan Vuli\\'c", "title": "Scoring Lexical Entailment with a Supervised Directional Similarity\n  Network", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Supervised Directional Similarity Network (SDSN), a novel\nneural architecture for learning task-specific transformation functions on top\nof general-purpose word embeddings. Relying on only a limited amount of\nsupervision from task-specific scores on a subset of the vocabulary, our\narchitecture is able to generalise and transform a general-purpose\ndistributional vector space to model the relation of lexical entailment.\nExperiments show excellent performance on scoring graded lexical entailment,\nraising the state-of-the-art on the HyperLex dataset by approximately 25%.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 18:03:40 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Rei", "Marek", ""], ["Gerz", "Daniela", ""], ["Vuli\u0107", "Ivan", ""]]}, {"id": "1805.09389", "submitter": "Hongyu Gong", "authors": "Hongyu Gong, Suma Bhat, Pramod Viswanath", "title": "Embedding Syntax and Semantics of Prepositions via Tensor Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prepositions are among the most frequent words in English and play complex\nroles in the syntax and semantics of sentences. Not surprisingly, they pose\nwell-known difficulties in automatic processing of sentences (prepositional\nattachment ambiguities and idiosyncratic uses in phrases). Existing methods on\npreposition representation treat prepositions no different from content words\n(e.g., word2vec and GloVe). In addition, recent studies aiming at solving\nprepositional attachment and preposition selection problems depend heavily on\nexternal linguistic resources and use dataset-specific word representations. In\nthis paper we use word-triple counts (one of the triples being a preposition)\nto capture a preposition's interaction with its attachment and complement. We\nthen derive preposition embeddings via tensor decomposition on a large\nunlabeled corpus. We reveal a new geometry involving Hadamard products and\nempirically demonstrate its utility in paraphrasing phrasal verbs. Furthermore,\nour preposition embeddings are used as simple features in two challenging\ndownstream tasks: preposition selection and prepositional attachment\ndisambiguation. We achieve results comparable to or better than the\nstate-of-the-art on multiple standardized datasets.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 19:20:43 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Gong", "Hongyu", ""], ["Bhat", "Suma", ""], ["Viswanath", "Pramod", ""]]}, {"id": "1805.09436", "submitter": "Panayiotis Georgiou", "authors": "Sandeep Nallan Chakravarthula, Brian Baucom, Panayiotis Georgiou", "title": "Modeling Interpersonal Influence of Verbal Behavior in Couples Therapy\n  Dyadic Interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dyadic interactions among humans are marked by speakers continuously\ninfluencing and reacting to each other in terms of responses and behaviors,\namong others. Understanding how interpersonal dynamics affect behavior is\nimportant for successful treatment in psychotherapy domains. Traditional\nschemes that automatically identify behavior for this purpose have often looked\nat only the target speaker. In this work, we propose a Markov model of how a\ntarget speaker's behavior is influenced by their own past behavior as well as\ntheir perception of their partner's behavior, based on lexical features. Apart\nfrom incorporating additional potentially useful information, our model can\nalso control the degree to which the partner affects the target speaker. We\nevaluate our proposed model on the task of classifying Negative behavior in\nCouples Therapy and show that it is more accurate than the single-speaker\nmodel. Furthermore, we investigate the degree to which the optimal influence\nrelates to how well a couple does on the long-term, via relating to\nrelationship outcomes\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 21:38:45 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Chakravarthula", "Sandeep Nallan", ""], ["Baucom", "Brian", ""], ["Georgiou", "Panayiotis", ""]]}, {"id": "1805.09559", "submitter": "Alexander Kirillov", "authors": "Alexander Kirillov and Natalia Krizhanovsky and Andrew Krizhanovsky", "title": "WSD algorithm based on a new method of vector-word contexts proximity\n  calculation via epsilon-filtration", "comments": "15 pages, 1 table, 15 figures, accepted in the journal Transactions\n  of Karelian Research Centre of the Russian Academy of Sciences", "journal-ref": "Transactions of Karelian Research Centre RAS. No. 7. 2018. P.\n  149-163", "doi": "10.17076/mat829", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The problem of word sense disambiguation (WSD) is considered in the article.\nGiven a set of synonyms (synsets) and sentences with these synonyms. It is\nnecessary to select the meaning of the word in the sentence automatically. 1285\nsentences were tagged by experts, namely, one of the dictionary meanings was\nselected by experts for target words. To solve the WSD-problem, an algorithm\nbased on a new method of vector-word contexts proximity calculation is\nproposed. In order to achieve higher accuracy, a preliminary epsilon-filtering\nof words is performed, both in the sentence and in the set of synonyms. An\nextensive program of experiments was carried out. Four algorithms are\nimplemented, including a new algorithm. Experiments have shown that in a number\nof cases the new algorithm shows better results. The developed software and the\ntagged corpus have an open license and are available online. Wiktionary and\nWikisource are used. A brief description of this work can be viewed in slides\n(https://goo.gl/9ak6Gt). Video lecture in Russian on this research is available\nonline (https://youtu.be/-DLmRkepf58).\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 09:04:44 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 09:53:08 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Kirillov", "Alexander", ""], ["Krizhanovsky", "Natalia", ""], ["Krizhanovsky", "Andrew", ""]]}, {"id": "1805.09590", "submitter": "Ella Rabinovich", "authors": "Ella Rabinovich, Yulia Tsvetkov, Shuly Wintner", "title": "Native Language Cognate Effects on Second Language Lexical Choice", "comments": "Transactions of the Association for Computational Linguistics (TACL),\n  2018; 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a computational analysis of cognate effects on the spontaneous\nlinguistic productions of advanced non-native speakers. Introducing a large\ncorpus of highly competent non-native English speakers, and using a set of\ncarefully selected lexical items, we show that the lexical choices of\nnon-natives are affected by cognates in their native language. This effect is\nso powerful that we are able to reconstruct the phylogenetic language tree of\nthe Indo-European language family solely from the frequencies of specific\nlexical items in the English of authors with various native languages. We\nquantitatively analyze non-native lexical choice, highlighting cognate\nfacilitation as one of the important phenomena shaping the language of\nnon-native speakers.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 10:24:47 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Rabinovich", "Ella", ""], ["Tsvetkov", "Yulia", ""], ["Wintner", "Shuly", ""]]}, {"id": "1805.09644", "submitter": "Siamak Barzegar", "authors": "Siamak Barzegar, Juliano Efson Sales, Andre Freitas, Siegfried\n  Handschuh and Brian Davis", "title": "DINFRA: A One Stop Shop for Computing Multilingual Semantic Relatedness", "comments": "2 pages, 2 figures, SIGIR Conference", "journal-ref": null, "doi": "10.1145/2766462.2767870", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This demonstration presents an infrastructure for computing multilingual\nsemantic relatedness and correlation for twelve natural languages by using\nthree distributional semantic models (DSMs). Our demonsrator - DInfra\n(Distributional Infrastructure) provides researchers and developers with a\nhighly useful platform for processing large-scale corpora and conducting\nexperiments with distributional semantics. We integrate several multilingual\nDSMs in our webservice so the end user can obtain a result without worrying\nabout the complexities involved in building DSMs. Our webservice allows the\nusers to have easy access to a wide range of comparisons of DSMs with different\nparameters. In addition, users can configure and access DSM parameters using an\neasy to use API.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 21:06:59 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Barzegar", "Siamak", ""], ["Sales", "Juliano Efson", ""], ["Freitas", "Andre", ""], ["Handschuh", "Siegfried", ""], ["Davis", "Brian", ""]]}, {"id": "1805.09648", "submitter": "Iurii Chernushenko", "authors": "Iurii Chernushenko, Felix A. Gers, Alexander L\\\"oser, Alessandro\n  Checco", "title": "Crowd-Labeling Fashion Reviews with Quality Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a new methodology for high-quality labeling in the fashion domain\nwith crowd workers instead of experts. We focus on the Aspect-Based Sentiment\nAnalysis task. Our methods filter out inaccurate input from crowd workers but\nwe preserve different worker labeling to capture the inherent high variability\nof the opinions. We demonstrate the quality of labeled data based on Facebook's\nFastText framework as a baseline.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 16:07:08 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Chernushenko", "Iurii", ""], ["Gers", "Felix A.", ""], ["L\u00f6ser", "Alexander", ""], ["Checco", "Alessandro", ""]]}, {"id": "1805.09655", "submitter": "Victor Zhong", "authors": "Victor Zhong, Caiming Xiong, Richard Socher", "title": "Global-Locally Self-Attentive Dialogue State Tracker", "comments": "ACL 2018. 10 pages, 5 figures. Source code:\n  https://github.com/salesforce/glad", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue state tracking, which estimates user goals and requests given the\ndialogue context, is an essential part of task-oriented dialogue systems. In\nthis paper, we propose the Global-Locally Self-Attentive Dialogue State Tracker\n(GLAD), which learns representations of the user utterance and previous system\nactions with global-local modules. Our model uses global modules to share\nparameters between estimators for different types (called slots) of dialogue\nstates, and uses local modules to learn slot-specific features. We show that\nthis significantly improves tracking of rare states and achieves\nstate-of-the-art performance on the WoZ and DSTC2 state tracking tasks. GLAD\nobtains 88.1% joint goal accuracy and 97.1% request accuracy on WoZ,\noutperforming prior work by 3.7% and 5.5%. On DSTC2, our model obtains 74.5%\njoint goal accuracy and 97.5% request accuracy, outperforming prior work by\n1.1% and 1.0%.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 19:23:38 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 22:11:50 GMT"}, {"version": "v3", "created": "Thu, 6 Sep 2018 23:58:53 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Zhong", "Victor", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1805.09657", "submitter": "Dieuwke Hupkes", "authors": "Dieuwke Hupkes, Anand Singh, Kris Korrel, German Kruszewski, Elia\n  Bruni", "title": "Learning compositionally through attentive guidance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural network models have been successfully applied to domains that\nrequire substantial generalisation skills, recent studies have implied that\nthey struggle when solving the task they are trained on requires inferring its\nunderlying compositional structure. In this paper, we introduce Attentive\nGuidance, a mechanism to direct a sequence to sequence model equipped with\nattention to find more compositional solutions. We test it on two tasks,\ndevised precisely to assess the compositional capabilities of neural models,\nand we show that vanilla sequence to sequence models with attention overfit the\ntraining distribution, while the guided versions come up with compositional\nsolutions that fit the training and testing distributions almost equally well.\nMoreover, the learned solutions generalise even in cases where the training and\ntesting distributions strongly diverge. In this way, we demonstrate that\nsequence to sequence models are capable of finding compositional solutions\nwithout requiring extra components. These results helps to disentangle the\ncauses for the lack of systematic compositionality in neural networks, which\ncan in turn fuel future work.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 10:33:00 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 09:46:30 GMT"}, {"version": "v3", "created": "Mon, 10 Sep 2018 12:02:27 GMT"}, {"version": "v4", "created": "Fri, 5 Jul 2019 12:41:30 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Hupkes", "Dieuwke", ""], ["Singh", "Anand", ""], ["Korrel", "Kris", ""], ["Kruszewski", "German", ""], ["Bruni", "Elia", ""]]}, {"id": "1805.09687", "submitter": "Michele Dolfi", "authors": "Peter W J Staar, Michele Dolfi, Christoph Auer, Costas Bekas", "title": "Corpus Conversion Service: A machine learning platform to ingest\n  documents at scale [Poster abstract]", "comments": "Accepted in SysML 2018 (www.sysml.cc)", "journal-ref": null, "doi": "10.13140/RG.2.2.10858.82888", "report-no": null, "categories": "cs.DL cs.CL cs.CV cs.DC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few decades, the amount of scientific articles and technical\nliterature has increased exponentially in size. Consequently, there is a great\nneed for systems that can ingest these documents at scale and make their\ncontent discoverable. Unfortunately, both the format of these documents (e.g.\nthe PDF format or bitmap images) as well as the presentation of the data (e.g.\ncomplex tables) make the extraction of qualitative and quantitive data\nextremely challenging. We present a platform to ingest documents at scale which\nis powered by Machine Learning techniques and allows the user to train custom\nmodels on document collections. We show precision/recall results greater than\n97% with regard to conversion to structured formats, as well as scaling\nevidence for each of the microservices constituting the platform.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 07:05:52 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Staar", "Peter W J", ""], ["Dolfi", "Michele", ""], ["Auer", "Christoph", ""], ["Bekas", "Costas", ""]]}, {"id": "1805.09701", "submitter": "Pan Lu", "authors": "Pan Lu, Lei Ji, Wei Zhang, Nan Duan, Ming Zhou, Jianyong Wang", "title": "R-VQA: Learning Visual Relation Facts with Semantic Attention for Visual\n  Question Answering", "comments": "10 pages, 5 figures, accepted as an oral paper in SIGKDD 2018", "journal-ref": null, "doi": "10.1145/3219819.3220036", "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Visual Question Answering (VQA) has emerged as one of the most\nsignificant tasks in multimodal learning as it requires understanding both\nvisual and textual modalities. Existing methods mainly rely on extracting image\nand question features to learn their joint feature embedding via multimodal\nfusion or attention mechanism. Some recent studies utilize external\nVQA-independent models to detect candidate entities or attributes in images,\nwhich serve as semantic knowledge complementary to the VQA task. However, these\ncandidate entities or attributes might be unrelated to the VQA task and have\nlimited semantic capacities. To better utilize semantic knowledge in images, we\npropose a novel framework to learn visual relation facts for VQA. Specifically,\nwe build up a Relation-VQA (R-VQA) dataset based on the Visual Genome dataset\nvia a semantic similarity module, in which each data consists of an image, a\ncorresponding question, a correct answer and a supporting relation fact. A\nwell-defined relation detector is then adopted to predict visual\nquestion-related relation facts. We further propose a multi-step attention\nmodel composed of visual attention and semantic attention sequentially to\nextract related visual knowledge and semantic knowledge. We conduct\ncomprehensive experiments on the two benchmark datasets, demonstrating that our\nmodel achieves state-of-the-art performance and verifying the benefit of\nconsidering visual relation facts.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 14:43:30 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 03:45:04 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Lu", "Pan", ""], ["Ji", "Lei", ""], ["Zhang", "Wei", ""], ["Duan", "Nan", ""], ["Zhou", "Ming", ""], ["Wang", "Jianyong", ""]]}, {"id": "1805.09746", "submitter": "Sudipta Kar", "authors": "Suraj Maharjan, Sudipta Kar, Manuel Montes-y-Gomez, Fabio A. Gonzalez,\n  Thamar Solorio", "title": "Letting Emotions Flow: Success Prediction by Modeling the Flow of\n  Emotions in Books", "comments": "NAACL 2018, 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Books have the power to make us feel happiness, sadness, pain, surprise, or\nsorrow. An author's dexterity in the use of these emotions captivates readers\nand makes it difficult for them to put the book down. In this paper, we model\nthe flow of emotions over a book using recurrent neural networks and quantify\nits usefulness in predicting success in books. We obtained the best weighted\nF1-score of 69% for predicting books' success in a multitask setting\n(simultaneously predicting success and genre of books).\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 15:56:08 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 02:43:43 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Maharjan", "Suraj", ""], ["Kar", "Sudipta", ""], ["Montes-y-Gomez", "Manuel", ""], ["Gonzalez", "Fabio A.", ""], ["Solorio", "Thamar", ""]]}, {"id": "1805.09772", "submitter": "Hamid Tizhoosh", "authors": "Graham Bleaney, Matthew Kuzyk, Julian Man, Hossein Mayanloo,\n  H.R.Tizhoosh", "title": "Auto-Detection of Safety Issues in Baby Products", "comments": "To appear in proceedings of The 31st IEA-AIE 2018, June 25-28, 2018,\n  Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every year, thousands of people receive consumer product related injuries.\nResearch indicates that online customer reviews can be processed to\nautonomously identify product safety issues. Early identification of safety\nissues can lead to earlier recalls, and thus fewer injuries and deaths. A\ndataset of product reviews from Amazon.com was compiled, along with\n\\emph{SaferProducts.gov} complaints and recall descriptions from the Consumer\nProduct Safety Commission (CPSC) and European Commission Rapid Alert system. A\nsystem was built to clean the collected text and to extract relevant features.\nDimensionality reduction was performed by computing feature relevance through a\nRandom Forest and discarding features with low information gain. Various\nclassifiers were analyzed, including Logistic Regression, SVMs,\nNa{\\\"i}ve-Bayes, Random Forests, and an Ensemble classifier. Experimentation\nwith various features and classifier combinations resulted in a logistic\nregression model with 66\\% precision in the top 50 reviews surfaced. This\nclassifier outperforms all benchmarks set by related literature and consumer\nproduct safety professionals.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 15:33:50 GMT"}, {"version": "v2", "created": "Sat, 21 Jul 2018 23:43:59 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Bleaney", "Graham", ""], ["Kuzyk", "Matthew", ""], ["Man", "Julian", ""], ["Mayanloo", "Hossein", ""], ["Tizhoosh", "H. R.", ""]]}, {"id": "1805.09780", "submitter": "Abhirut Gupta", "authors": "Abhirut Gupta, Abhay Khosla, Gautam Singh, Gargi Dasgupta", "title": "Mining Procedures from Technical Support Documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Guided troubleshooting is an inherent task in the domain of technical support\nservices. When a customer experiences an issue with the functioning of a\ntechnical service or a product, an expert user helps guide the customer through\na set of steps comprising a troubleshooting procedure. The objective is to\nidentify the source of the problem through a set of diagnostic steps and\nobservations, and arrive at a resolution. Procedures containing these set of\ndiagnostic steps and observations in response to different problems are common\nartifacts in the body of technical support documentation. The ability to use\nmachine learning and linguistics to understand and leverage these procedures\nfor applications like intelligent chatbots or robotic process automation, is\ncrucial. Existing research on question answering or intelligent chatbots does\nnot look within procedures or deep-understand them. In this paper, we outline a\nsystem for mining procedures from technical support documents. We create models\nfor solving important subproblems like extraction of procedures, identifying\ndecision points within procedures, identifying blocks of instructions\ncorresponding to these decision points and mapping instructions within a\ndecision block. We also release a dataset containing our manual annotations on\npublicly available support documents, to promote further research on the\nproblem.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 16:58:24 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Gupta", "Abhirut", ""], ["Khosla", "Abhay", ""], ["Singh", "Gautam", ""], ["Dasgupta", "Gargi", ""]]}, {"id": "1805.09821", "submitter": "Holger Schwenk", "authors": "Holger Schwenk and Xian Li", "title": "A Corpus for Multilingual Document Classification in Eight Languages", "comments": "4 pages", "journal-ref": "LREC, May 2018, Miyazaki, Japan", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual document classification aims at training a document classifier\non resources in one language and transferring it to a different language\nwithout any additional resources. Several approaches have been proposed in the\nliterature and the current best practice is to evaluate them on a subset of the\nReuters Corpus Volume 2. However, this subset covers only few languages\n(English, German, French and Spanish) and almost all published works focus on\nthe the transfer between English and German. In addition, we have observed that\nthe class prior distributions differ significantly between the languages. We\nargue that this complicates the evaluation of the multilinguality. In this\npaper, we propose a new subset of the Reuters corpus with balanced class priors\nfor eight languages. By adding Italian, Russian, Japanese and Chinese, we cover\nlanguages which are very different with respect to syntax, morphology, etc. We\nprovide strong baselines for all language transfer directions using\nmultilingual word and sentence embeddings respectively. Our goal is to offer a\nfreely available framework to evaluate cross-lingual document classification,\nand we hope to foster by these means, research in this important area.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 10:36:20 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Schwenk", "Holger", ""], ["Li", "Xian", ""]]}, {"id": "1805.09822", "submitter": "Holger Schwenk", "authors": "Holger Schwenk", "title": "Filtering and Mining Parallel Data in a Joint Multilingual Space", "comments": "8 pages", "journal-ref": "ACL, July 2018, Melbourne", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We learn a joint multilingual sentence embedding and use the distance between\nsentences in different languages to filter noisy parallel data and to mine for\nparallel data in large news collections. We are able to improve a competitive\nbaseline on the WMT'14 English to German task by 0.3 BLEU by filtering out 25%\nof the training data. The same approach is used to mine additional bitexts for\nthe WMT'14 system and to obtain competitive results on the BUCC shared task to\nidentify parallel sentences in comparable corpora. The approach is generic, it\ncan be applied to many language pairs and it is independent of the architecture\nof the machine translation system.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 13:09:59 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Schwenk", "Holger", ""]]}, {"id": "1805.09843", "submitter": "Dinghan Shen", "authors": "Dinghan Shen, Guoyin Wang, Wenlin Wang, Martin Renqiang Min, Qinliang\n  Su, Yizhe Zhang, Chunyuan Li, Ricardo Henao, Lawrence Carin", "title": "Baseline Needs More Love: On Simple Word-Embedding-Based Models and\n  Associated Pooling Mechanisms", "comments": "To appear at ACL 2018 (code: https://github.com/dinghanshen/SWEM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many deep learning architectures have been proposed to model the\ncompositionality in text sequences, requiring a substantial number of\nparameters and expensive computations. However, there has not been a rigorous\nevaluation regarding the added value of sophisticated compositional functions.\nIn this paper, we conduct a point-by-point comparative study between Simple\nWord-Embedding-based Models (SWEMs), consisting of parameter-free pooling\noperations, relative to word-embedding-based RNN/CNN models. Surprisingly,\nSWEMs exhibit comparable or even superior performance in the majority of cases\nconsidered. Based upon this understanding, we propose two additional pooling\nstrategies over learned word embeddings: (i) a max-pooling operation for\nimproved interpretability; and (ii) a hierarchical pooling operation, which\npreserves spatial (n-gram) information within text sequences. We present\nexperiments on 17 datasets encompassing three tasks: (i) (long) document\nclassification; (ii) text sequence matching; and (iii) short text tasks,\nincluding classification and tagging. The source code and datasets can be\nobtained from https:// github.com/dinghanshen/SWEM.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 18:27:21 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Shen", "Dinghan", ""], ["Wang", "Guoyin", ""], ["Wang", "Wenlin", ""], ["Min", "Martin Renqiang", ""], ["Su", "Qinliang", ""], ["Zhang", "Yizhe", ""], ["Li", "Chunyuan", ""], ["Henao", "Ricardo", ""], ["Carin", "Lawrence", ""]]}, {"id": "1805.09863", "submitter": "Hieu Hoang", "authors": "Hieu Hoang, Tomasz Dwojak, Rihards Krislauks, Daniel Torregrosa,\n  Kenneth Heafield", "title": "Fast Neural Machine Translation Implementation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the submissions to the efficiency track for GPUs at the\nWorkshop for Neural Machine Translation and Generation by members of the\nUniversity of Edinburgh, Adam Mickiewicz University, Tilde and University of\nAlicante. We focus on efficient implementation of the recurrent deep-learning\nmodel as implemented in Amun, the fast inference engine for neural machine\ntranslation. We improve the performance with an efficient mini-batching\nalgorithm, and by fusing the softmax operation with the k-best extraction\nalgorithm. Submissions using Amun were first, second and third fastest in the\nGPU efficiency track.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 19:33:03 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 09:45:33 GMT"}, {"version": "v3", "created": "Thu, 7 Jun 2018 18:00:16 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Hoang", "Hieu", ""], ["Dwojak", "Tomasz", ""], ["Krislauks", "Rihards", ""], ["Torregrosa", "Daniel", ""], ["Heafield", "Kenneth", ""]]}, {"id": "1805.09906", "submitter": "Xinyuan Zhang", "authors": "Xinyuan Zhang, Yitong Li, Dinghan Shen, Lawrence Carin", "title": "Diffusion Maps for Textual Network Embedding", "comments": "This paper is a spotlight paper of NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Textual network embedding leverages rich text information associated with the\nnetwork to learn low-dimensional vectorial representations of vertices. Rather\nthan using typical natural language processing (NLP) approaches, recent\nresearch exploits the relationship of texts on the same edge to graphically\nembed text. However, these models neglect to measure the complete level of\nconnectivity between any two texts in the graph. We present diffusion maps for\ntextual network embedding (DMTE), integrating global structural information of\nthe graph to capture the semantic relatedness between texts, with a\ndiffusion-convolution operation applied on the text inputs. In addition, a new\nobjective function is designed to efficiently preserve the high-order proximity\nusing the graph diffusion. Experimental results show that the proposed approach\noutperforms state-of-the-art methods on the vertex-classification and\nlink-prediction tasks.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 21:24:14 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 16:42:26 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Zhang", "Xinyuan", ""], ["Li", "Yitong", ""], ["Shen", "Dinghan", ""], ["Carin", "Lawrence", ""]]}, {"id": "1805.09927", "submitter": "Pengda Qin", "authors": "Pengda Qin, Weiran Xu, William Yang Wang", "title": "Robust Distant Supervision Relation Extraction via Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distant supervision has become the standard method for relation extraction.\nHowever, even though it is an efficient method, it does not come at no\ncost---The resulted distantly-supervised training samples are often very noisy.\nTo combat the noise, most of the recent state-of-the-art approaches focus on\nselecting one-best sentence or calculating soft attention weights over the set\nof the sentences of one specific entity pair. However, these methods are\nsuboptimal, and the false positive problem is still a key stumbling bottleneck\nfor the performance. We argue that those incorrectly-labeled candidate\nsentences must be treated with a hard decision, rather than being dealt with\nsoft attention weights. To do this, our paper describes a radical solution---We\nexplore a deep reinforcement learning strategy to generate the false-positive\nindicator, where we automatically recognize false positives for each relation\ntype without any supervised information. Unlike the removal operation in the\nprevious studies, we redistribute them into the negative examples. The\nexperimental results show that the proposed strategy significantly improves the\nperformance of distant supervision comparing to state-of-the-art systems.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 22:32:55 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Qin", "Pengda", ""], ["Xu", "Weiran", ""], ["Wang", "William Yang", ""]]}, {"id": "1805.09929", "submitter": "Pengda Qin", "authors": "Pengda Qin, Weiran Xu, William Yang Wang", "title": "DSGAN: Generative Adversarial Training for Distant Supervision Relation\n  Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distant supervision can effectively label data for relation extraction, but\nsuffers from the noise labeling problem. Recent works mainly perform soft\nbag-level noise reduction strategies to find the relatively better samples in a\nsentence bag, which is suboptimal compared with making a hard decision of false\npositive samples in sentence level. In this paper, we introduce an adversarial\nlearning framework, which we named DSGAN, to learn a sentence-level\ntrue-positive generator. Inspired by Generative Adversarial Networks, we regard\nthe positive samples generated by the generator as the negative samples to\ntrain the discriminator. The optimal generator is obtained until the\ndiscrimination ability of the discriminator has the greatest decline. We adopt\nthe generator to filter distant supervision training dataset and redistribute\nthe false positive instances into the negative set, in which way to provide a\ncleaned dataset for relation classification. The experimental results show that\nthe proposed strategy significantly improves the performance of distant\nsupervision relation extraction comparing to state-of-the-art systems.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 22:37:59 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Qin", "Pengda", ""], ["Xu", "Weiran", ""], ["Wang", "William Yang", ""]]}, {"id": "1805.09959", "submitter": "Eric Clark Mr.", "authors": "Eric M. Clark, Ted James, Chris A. Jones, Amulya Alapati, Promise\n  Ukandu, Christopher M. Danforth, Peter Sheridan Dodds", "title": "A Sentiment Analysis of Breast Cancer Treatment Experiences and\n  Healthcare Perceptions Across Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Social media has the capacity to afford the healthcare industry\nwith valuable feedback from patients who reveal and express their medical\ndecision-making process, as well as self-reported quality of life indicators\nboth during and post treatment. In prior work, [Crannell et. al.], we have\nstudied an active cancer patient population on Twitter and compiled a set of\ntweets describing their experience with this disease. We refer to these online\npublic testimonies as \"Invisible Patient Reported Outcomes\" (iPROs), because\nthey carry relevant indicators, yet are difficult to capture by conventional\nmeans of self-report. Methods: Our present study aims to identify tweets\nrelated to the patient experience as an additional informative tool for\nmonitoring public health. Using Twitter's public streaming API, we compiled\nover 5.3 million \"breast cancer\" related tweets spanning September 2016 until\nmid December 2017. We combined supervised machine learning methods with natural\nlanguage processing to sift tweets relevant to breast cancer patient\nexperiences. We analyzed a sample of 845 breast cancer patient and survivor\naccounts, responsible for over 48,000 posts. We investigated tweet content with\na hedonometric sentiment analysis to quantitatively extract emotionally charged\ntopics. Results: We found that positive experiences were shared regarding\npatient treatment, raising support, and spreading awareness. Further\ndiscussions related to healthcare were prevalent and largely negative focusing\non fear of political legislation that could result in loss of coverage.\nConclusions: Social media can provide a positive outlet for patients to discuss\ntheir needs and concerns regarding their healthcare coverage and treatment\nneeds. Capturing iPROs from online communication can help inform healthcare\nprofessionals and lead to more connected and personalized treatment regimens.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 03:13:49 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 23:45:08 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Clark", "Eric M.", ""], ["James", "Ted", ""], ["Jones", "Chris A.", ""], ["Alapati", "Amulya", ""], ["Ukandu", "Promise", ""], ["Danforth", "Christopher M.", ""], ["Dodds", "Peter Sheridan", ""]]}, {"id": "1805.09960", "submitter": "Yang Zhao", "authors": "Yang Zhao, Yining Wang, Jiajun Zhang and Chengqing Zong", "title": "Phrase Table as Recommendation Memory for Neural Machine Translation", "comments": "accepted by IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) has drawn much attention due to its\npromising translation performance recently. However, several studies indicate\nthat NMT often generates fluent but unfaithful translations. In this paper, we\npropose a method to alleviate this problem by using a phrase table as\nrecommendation memory. The main idea is to add bonus to words worthy of\nrecommendation, so that NMT can make correct predictions. Specifically, we\nfirst derive a prefix tree to accommodate all the candidate target phrases by\nsearching the phrase translation table according to the source sentence. Then,\nwe construct a recommendation word set by matching between candidate target\nphrases and previously translated target words by NMT. After that, we determine\nthe specific bonus value for each recommendable word by using the attention\nvector and phrase translation probability. Finally, we integrate this bonus\nvalue into NMT to improve the translation results. The extensive experiments\ndemonstrate that the proposed methods obtain remarkable improvements over the\nstrong attentionbased NMT.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 03:14:27 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Zhao", "Yang", ""], ["Wang", "Yining", ""], ["Zhang", "Jiajun", ""], ["Zong", "Chengqing", ""]]}, {"id": "1805.09991", "submitter": "Hu Xu", "authors": "Hu Xu, Bing Liu, Lei Shu, Philip S. Yu", "title": "Lifelong Domain Word Embedding via Meta-Learning", "comments": "7 pages", "journal-ref": "IJCAI 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning high-quality domain word embeddings is important for achieving good\nperformance in many NLP tasks. General-purpose embeddings trained on\nlarge-scale corpora are often sub-optimal for domain-specific applications.\nHowever, domain-specific tasks often do not have large in-domain corpora for\ntraining high-quality domain embeddings. In this paper, we propose a novel\nlifelong learning setting for domain embedding. That is, when performing the\nnew domain embedding, the system has seen many past domains, and it tries to\nexpand the new in-domain corpus by exploiting the corpora from the past domains\nvia meta-learning. The proposed meta-learner characterizes the similarities of\nthe contexts of the same word in many domain corpora, which helps retrieve\nrelevant data from the past domains to expand the new domain corpus.\nExperimental results show that domain embeddings produced from such a process\nimprove the performance of the downstream tasks.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 06:10:54 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Xu", "Hu", ""], ["Liu", "Bing", ""], ["Shu", "Lei", ""], ["Yu", "Philip S.", ""]]}, {"id": "1805.10047", "submitter": "Mamoru Komachi", "authors": "Michiki Kurosawa, Yukio Matsumura, Hayahide Yamagishi, Mamoru Komachi", "title": "Japanese Predicate Conjugation for Neural Machine Translation", "comments": "6 pages; NAACL 2018 Student Research Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural machine translation (NMT) has a drawback in that can generate only\nhigh-frequency words owing to the computational costs of the softmax function\nin the output layer.\n  In Japanese-English NMT, Japanese predicate conjugation causes an increase in\nvocabulary size. For example, one verb can have as many as 19 surface\nvarieties. In this research, we focus on predicate conjugation for compressing\nthe vocabulary size in Japanese. The vocabulary list is filled with the various\nforms of verbs. We propose methods using predicate conjugation information\nwithout discarding linguistic information. The proposed methods can generate\nlow-frequency words and deal with unknown words. Two methods were considered to\nintroduce conjugation information: the first considers it as a token\n(conjugation token) and the second considers it as an embedded vector\n(conjugation feature).\n  The results using these methods demonstrate that the vocabulary size can be\ncompressed by approximately 86.1% (Tanaka corpus) and the NMT models can output\nthe words not in the training data set. Furthermore, BLEU scores improved by\n0.91 points in Japanese-to-English translation, and 0.32 points in\nEnglish-to-Japanese translation with ASPEC.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 08:56:43 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Kurosawa", "Michiki", ""], ["Matsumura", "Yukio", ""], ["Yamagishi", "Hayahide", ""], ["Komachi", "Mamoru", ""]]}, {"id": "1805.10163", "submitter": "Elena Voita", "authors": "Elena Voita, Pavel Serdyukov, Rico Sennrich, Ivan Titov", "title": "Context-Aware Neural Machine Translation Learns Anaphora Resolution", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard machine translation systems process sentences in isolation and hence\nignore extra-sentential information, even though extended context can both\nprevent mistakes in ambiguous cases and improve translation coherence. We\nintroduce a context-aware neural machine translation model designed in such way\nthat the flow of information from the extended context to the translation model\ncan be controlled and analyzed. We experiment with an English-Russian subtitles\ndataset, and observe that much of what is captured by our model deals with\nimproving pronoun translation. We measure correspondences between induced\nattention distributions and coreference relations and observe that the model\nimplicitly captures anaphora. It is consistent with gains for sentences where\npronouns need to be gendered in translation. Beside improvements in anaphoric\ncases, the model also improves in overall BLEU, both over its context-agnostic\nversion (+0.7) and over simple concatenation of the context and source\nsentences (+0.6).\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 14:03:27 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Voita", "Elena", ""], ["Serdyukov", "Pavel", ""], ["Sennrich", "Rico", ""], ["Titov", "Ivan", ""]]}, {"id": "1805.10187", "submitter": "Yuki Kawara", "authors": "Yuki Kawara, Chenhui Chu, Yuki Arase", "title": "Recursive Neural Network Based Preordering for English-to-Japanese\n  Machine Translation", "comments": "ACL-SRW 2018. 7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The word order between source and target languages significantly influences\nthe translation quality in machine translation. Preordering can effectively\naddress this problem. Previous preordering methods require a manual feature\ndesign, making language dependent design costly. In this paper, we propose a\npreordering method with a recursive neural network that learns features from\nraw inputs. Experiments show that the proposed method achieves comparable gain\nin translation quality to the state-of-the-art method but without a manual\nfeature design.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 15:00:30 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Kawara", "Yuki", ""], ["Chu", "Chenhui", ""], ["Arase", "Yuki", ""]]}, {"id": "1805.10190", "submitter": "Alice Coucke", "authors": "Alice Coucke, Alaa Saade, Adrien Ball, Th\\'eodore Bluche, Alexandre\n  Caulier, David Leroy, Cl\\'ement Doumouro, Thibault Gisselbrecht, Francesco\n  Caltagirone, Thibaut Lavril, Ma\\\"el Primet, Joseph Dureau", "title": "Snips Voice Platform: an embedded Spoken Language Understanding system\n  for private-by-design voice interfaces", "comments": "29 pages, 9 figures, 17 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the machine learning architecture of the Snips Voice\nPlatform, a software solution to perform Spoken Language Understanding on\nmicroprocessors typical of IoT devices. The embedded inference is fast and\naccurate while enforcing privacy by design, as no personal user data is ever\ncollected. Focusing on Automatic Speech Recognition and Natural Language\nUnderstanding, we detail our approach to training high-performance Machine\nLearning models that are small enough to run in real-time on small devices.\nAdditionally, we describe a data generation procedure that provides sufficient,\nhigh-quality training data without compromising user privacy.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 15:04:17 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 17:52:08 GMT"}, {"version": "v3", "created": "Thu, 6 Dec 2018 16:34:25 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Coucke", "Alice", ""], ["Saade", "Alaa", ""], ["Ball", "Adrien", ""], ["Bluche", "Th\u00e9odore", ""], ["Caulier", "Alexandre", ""], ["Leroy", "David", ""], ["Doumouro", "Cl\u00e9ment", ""], ["Gisselbrecht", "Thibault", ""], ["Caltagirone", "Francesco", ""], ["Lavril", "Thibaut", ""], ["Primet", "Ma\u00ebl", ""], ["Dureau", "Joseph", ""]]}, {"id": "1805.10209", "submitter": "Alane Suhr", "authors": "Alane Suhr and Yoav Artzi", "title": "Situated Mapping of Sequential Instructions to Actions with Single-step\n  Reward Observation", "comments": "ACL 2018 Long Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a learning approach for mapping context-dependent sequential\ninstructions to actions. We address the problem of discourse and state\ndependencies with an attention-based model that considers both the history of\nthe interaction and the state of the world. To train from start and goal states\nwithout access to demonstrations, we propose SESTRA, a learning algorithm that\ntakes advantage of single-step reward observations and immediate expected\nreward maximization. We evaluate on the SCONE domains, and show absolute\naccuracy improvements of 9.8%-25.3% across the domains over approaches that use\nhigh-level logical representations.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 15:47:38 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 21:29:05 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Suhr", "Alane", ""], ["Artzi", "Yoav", ""]]}, {"id": "1805.10254", "submitter": "Xinyu Hua", "authors": "Xinyu Hua and Lu Wang", "title": "Neural Argument Generation Augmented with Externally Retrieved Evidence", "comments": "This paper is accepted as to ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High quality arguments are essential elements for human reasoning and\ndecision-making processes. However, effective argument construction is a\nchallenging task for both human and machines. In this work, we study a novel\ntask on automatically generating arguments of a different stance for a given\nstatement. We propose an encoder-decoder style neural network-based argument\ngeneration model enriched with externally retrieved evidence from Wikipedia.\nOur model first generates a set of talking point phrases as intermediate\nrepresentation, followed by a separate decoder producing the final argument\nbased on both input and the keyphrases. Experiments on a large-scale dataset\ncollected from Reddit show that our model constructs arguments with more\ntopic-relevant content than a popular sequence-to-sequence generation model\naccording to both automatic evaluation and human assessments.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 17:12:03 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Hua", "Xinyu", ""], ["Wang", "Lu", ""]]}, {"id": "1805.10267", "submitter": "Ted Pedersen", "authors": "Shuning Jin and Ted Pedersen", "title": "Duluth UROP at SemEval-2018 Task 2: Multilingual Emoji Prediction with\n  Ensemble Learning and Oversampling", "comments": "4 pages, to Appear in the Proceedings of the 12th International\n  Workshop on Semantic Evaluation (SemEval 2018), June 2018, New Orleans, LA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper describes the Duluth UROP systems that participated in\nSemEval--2018 Task 2, Multilingual Emoji Prediction. We relied on a variety of\nensembles made up of classifiers using Naive Bayes, Logistic Regression, and\nRandom Forests. We used unigram and bigram features and tried to offset the\nskewness of the data through the use of oversampling. Our task evaluation\nresults place us 19th of 48 systems in the English evaluation, and 5th of 21 in\nthe Spanish. After the evaluation we realized that some simple changes to\npreprocessing could significantly improve our results. After making these\nchanges we attained results that would have placed us sixth in the English\nevaluation, and second in the Spanish.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 17:36:51 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Jin", "Shuning", ""], ["Pedersen", "Ted", ""]]}, {"id": "1805.10271", "submitter": "Ted Pedersen", "authors": "Arshia Z. Hassan and Manikya S. Vallabhajosyula and Ted Pedersen", "title": "UMDuluth-CS8761 at SemEval-2018 Task 9: Hypernym Discovery using Hearst\n  Patterns, Co-occurrence frequencies and Word Embeddings", "comments": "5 pages, to Appear in the Proceedings of the 12th International\n  Workshop on Semantic Evaluation (SemEval 2018), June 2018, New Orleans, LA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Hypernym Discovery is the task of identifying potential hypernyms for a given\nterm. A hypernym is a more generalized word that is super-ordinate to more\nspecific words. This paper explores several approaches that rely on\nco-occurrence frequencies of word pairs, Hearst Patterns based on regular\nexpressions, and word embeddings created from the UMBC corpus. Our system\nBabbage participated in Subtask 1A for English and placed 6th of 19 systems\nwhen identifying concept hypernyms, and 12th of 18 systems for entity\nhypernyms.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 17:44:03 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Hassan", "Arshia Z.", ""], ["Vallabhajosyula", "Manikya S.", ""], ["Pedersen", "Ted", ""]]}, {"id": "1805.10274", "submitter": "Ted Pedersen", "authors": "Zhenduo Wang and Ted Pedersen", "title": "UMDSub at SemEval-2018 Task 2: Multilingual Emoji Prediction\n  Multi-channel Convolutional Neural Network on Subword Embedding", "comments": "5 pages, to Appear in the Proceedings of the 12th International\n  Workshop on Semantic Evaluation (SemEval 2018), June 2018, New Orleans, LA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper describes the UMDSub system that participated in Task 2 of\nSemEval-2018. We developed a system that predicts an emoji given the raw text\nin a English tweet. The system is a Multi-channel Convolutional Neural Network\nbased on subword embeddings for the representation of tweets. This model\nimproves on character or word based methods by about 2\\%. Our system placed\n21st of 48 participating systems in the official evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 17:48:20 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Wang", "Zhenduo", ""], ["Pedersen", "Ted", ""]]}, {"id": "1805.10338", "submitter": "Lierni Sestorain", "authors": "Lierni Sestorain and Massimiliano Ciaramita and Christian Buck and\n  Thomas Hofmann", "title": "Zero-Shot Dual Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) systems rely on large amounts of parallel\ndata. This is a major challenge for low-resource languages. Building on recent\nwork on unsupervised and semi-supervised methods, we present an approach that\ncombines zero-shot and dual learning. The latter relies on reinforcement\nlearning, to exploit the duality of the machine translation task, and requires\nonly monolingual data for the target language pair. Experiments show that a\nzero-shot dual system, trained on English-French and English-Spanish,\noutperforms by large margins a standard NMT system in zero-shot translation\nperformance on Spanish-French (both directions). The zero-shot dual method\napproaches the performance, within 2.2 BLEU points, of a comparable supervised\nsetting. Our method can obtain improvements also on the setting where a small\namount of parallel data for the zero-shot language pair is available. Adding\nRussian, to extend our experiments to jointly modeling 6 zero-shot translation\ndirections, all directions improve between 4 and 15 BLEU points, again,\nreaching performance near that of the supervised setting.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 19:27:43 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Sestorain", "Lierni", ""], ["Ciaramita", "Massimiliano", ""], ["Buck", "Christian", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1805.10364", "submitter": "Hojjat Aghakhani", "authors": "Hojjat Aghakhani, Aravind Machiry, Shirin Nilizadeh, Christopher\n  Kruegel, and Giovanni Vigna", "title": "Detecting Deceptive Reviews using Generative Adversarial Networks", "comments": "accepted at 1st Deep Learning and Security Workshop co-located with\n  the 39th IEEE Symposium on Security and Privacy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, consumer review sites have become the main target of\ndeceptive opinion spam, where fictitious opinions or reviews are deliberately\nwritten to sound authentic. Most of the existing work to detect the deceptive\nreviews focus on building supervised classifiers based on syntactic and lexical\npatterns of an opinion. With the successful use of Neural Networks on various\nclassification applications, in this paper, we propose FakeGAN a system that\nfor the first time augments and adopts Generative Adversarial Networks (GANs)\nfor a text classification task, in particular, detecting deceptive reviews.\nUnlike standard GAN models which have a single Generator and Discriminator\nmodel, FakeGAN uses two discriminator models and one generative model. The\ngenerator is modeled as a stochastic policy agent in reinforcement learning\n(RL), and the discriminators use Monte Carlo search algorithm to estimate and\npass the intermediate action-value as the RL reward to the generator. Providing\nthe generator model with two discriminator models avoids the mod collapse issue\nby learning from both distributions of truthful and deceptive reviews. Indeed,\nour experiments show that using two discriminators provides FakeGAN high\nstability, which is a known issue for GAN architectures. While FakeGAN is built\nupon a semi-supervised classifier, known for less accuracy, our evaluation\nresults on a dataset of TripAdvisor hotel reviews show the same performance in\nterms of accuracy as of the state-of-the-art approaches that apply supervised\nmachine learning. These results indicate that GANs can be effective for text\nclassification tasks. Specifically, FakeGAN is effective at detecting deceptive\nreviews.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 21:06:56 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Aghakhani", "Hojjat", ""], ["Machiry", "Aravind", ""], ["Nilizadeh", "Shirin", ""], ["Kruegel", "Christopher", ""], ["Vigna", "Giovanni", ""]]}, {"id": "1805.10387", "submitter": "Oleksii Kuchaiev", "authors": "Oleksii Kuchaiev, Boris Ginsburg, Igor Gitman, Vitaly Lavrukhin, Jason\n  Li, Huyen Nguyen, Carl Case, Paulius Micikevicius", "title": "Mixed-Precision Training for NLP and Speech Recognition with OpenSeq2Seq", "comments": "Presented at Workshop for Natural Language Processing Open Source\n  Software (NLP-OSS), co-located with ACL2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present OpenSeq2Seq - a TensorFlow-based toolkit for training\nsequence-to-sequence models that features distributed and mixed-precision\ntraining. Benchmarks on machine translation and speech recognition tasks show\nthat models built using OpenSeq2Seq give state-of-the-art performance at 1.5-3x\nless training time. OpenSeq2Seq currently provides building blocks for models\nthat solve a wide range of tasks including neural machine translation,\nautomatic speech recognition, and speech synthesis.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 22:54:38 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 17:48:55 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Kuchaiev", "Oleksii", ""], ["Ginsburg", "Boris", ""], ["Gitman", "Igor", ""], ["Lavrukhin", "Vitaly", ""], ["Li", "Jason", ""], ["Nguyen", "Huyen", ""], ["Case", "Carl", ""], ["Micikevicius", "Paulius", ""]]}, {"id": "1805.10389", "submitter": "Fei Liu", "authors": "Kristjan Arumae, Guo-Jun Qi, Fei Liu", "title": "A Study of Question Effectiveness Using Reddit \"Ask Me Anything\" Threads", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asking effective questions is a powerful social skill. In this paper we seek\nto build computational models that learn to discriminate effective questions\nfrom ineffective ones. Armed with such a capability, future advanced systems\ncan evaluate the quality of questions and provide suggestions for effective\nquestion wording. We create a large-scale, real-world dataset that contains\nover 400,000 questions collected from Reddit \"Ask Me Anything\" threads. Each\nthread resembles an online press conference where questions compete with each\nother for attention from the host. This dataset enables the development of a\nclass of computational models for predicting whether a question will be\nanswered. We develop a new convolutional neural network architecture with\nvariable-length context and demonstrate the efficacy of the model by comparing\nit with state-of-the-art baselines and human judges.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 23:00:03 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Arumae", "Kristjan", ""], ["Qi", "Guo-Jun", ""], ["Liu", "Fei", ""]]}, {"id": "1805.10390", "submitter": "Fei Liu", "authors": "Sansiri Tarnpradab, Fei Liu, Kien A. Hua", "title": "Toward Extractive Summarization of Online Forum Discussions via\n  Hierarchical Attention Networks", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forum threads are lengthy and rich in content. Concise thread summaries will\nbenefit both newcomers seeking information and those who participate in the\ndiscussion. Few studies, however, have examined the task of forum thread\nsummarization. In this work we make the first attempt to adapt the hierarchical\nattention networks for thread summarization. The model draws on the recent\ndevelopment of neural attention mechanisms to build sentence and thread\nrepresentations and use them for summarization. Our results indicate that the\nproposed approach can outperform a range of competitive baselines. Further, a\nredundancy removal step is crucial for achieving outstanding results.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 23:01:01 GMT"}, {"version": "v2", "created": "Wed, 26 Dec 2018 23:40:49 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Tarnpradab", "Sansiri", ""], ["Liu", "Fei", ""], ["Hua", "Kien A.", ""]]}, {"id": "1805.10392", "submitter": "Fei Liu", "authors": "Kristjan Arumae, Fei Liu", "title": "Reinforced Extractive Summarization with Question-Focused Rewards", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a new training paradigm for extractive summarization.\nTraditionally, human abstracts are used to derive goldstandard labels for\nextraction units. However, the labels are often inaccurate, because human\nabstracts and source documents cannot be easily aligned at the word level. In\nthis paper we convert human abstracts to a set of Cloze-style comprehension\nquestions. System summaries are encouraged to preserve salient source content\nuseful for answering questions and share common words with the abstracts. We\nuse reinforcement learning to explore the space of possible extractive\nsummaries and introduce a question-focused reward function to promote concise,\nfluent, and informative summaries. Our experiments show that the proposed\nmethod is effective. It surpasses state-of-the-art systems on the standard\nsummarization dataset.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 23:05:48 GMT"}, {"version": "v2", "created": "Thu, 21 Jun 2018 02:35:13 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Arumae", "Kristjan", ""], ["Liu", "Fei", ""]]}, {"id": "1805.10393", "submitter": "Fei Liu", "authors": "Fei Liu, Nicole Lee Fella, Kexin Liao", "title": "Modeling Language Vagueness in Privacy Policies using Deep Neural\n  Networks", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Website privacy policies are too long to read and difficult to understand.\nThe over-sophisticated language makes privacy notices to be less effective than\nthey should be. People become even less willing to share their personal\ninformation when they perceive the privacy policy as vague. This paper focuses\non decoding vagueness from a natural language processing perspective. While\nthoroughly identifying the vague terms and their linguistic scope remains an\nelusive challenge, in this work we seek to learn vector representations of\nwords in privacy policies using deep neural networks. The vector\nrepresentations are fed to an interactive visualization tool (LSTMVis) to test\non their ability to discover syntactically and semantically related vague\nterms. The approach holds promise for modeling and understanding language\nvagueness.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 23:13:41 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Liu", "Fei", ""], ["Fella", "Nicole Lee", ""], ["Liao", "Kexin", ""]]}, {"id": "1805.10395", "submitter": "Fei Liu", "authors": "Wencan Luo, Fei Liu, Zitao Liu, Diane Litman", "title": "Automatic Summarization of Student Course Feedback", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Student course feedback is generated daily in both classrooms and online\ncourse discussion forums. Traditionally, instructors manually analyze these\nresponses in a costly manner. In this work, we propose a new approach to\nsummarizing student course feedback based on the integer linear programming\n(ILP) framework. Our approach allows different student responses to share\nco-occurrence statistics and alleviates sparsity issues. Experimental results\non a student feedback corpus show that our approach outperforms a range of\nbaselines in terms of both ROUGE scores and human evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 23:36:33 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Luo", "Wencan", ""], ["Liu", "Fei", ""], ["Liu", "Zitao", ""], ["Litman", "Diane", ""]]}, {"id": "1805.10396", "submitter": "Fei Liu", "authors": "Wencan Luo, Fei Liu, Diane Litman", "title": "An Improved Phrase-based Approach to Annotating and Summarizing Student\n  Course Responses", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Teaching large classes remains a great challenge, primarily because it is\ndifficult to attend to all the student needs in a timely manner. Automatic text\nsummarization systems can be leveraged to summarize the student feedback,\nsubmitted immediately after each lecture, but it is left to be discovered what\nmakes a good summary for student responses. In this work we explore a new\nmethodology that effectively extracts summary phrases from the student\nresponses. Each phrase is tagged with the number of students who raise the\nissue. The phrases are evaluated along two dimensions: with respect to text\ncontent, they should be informative and well-formed, measured by the ROUGE\nmetric; additionally, they shall attend to the most pressing student needs,\nmeasured by a newly proposed metric. This work is enabled by a phrase-based\nannotation and highlighting scheme, which is new to the summarization task. The\nphrase-based framework allows us to summarize the student responses into a set\nof bullet points and present to the instructor promptly.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 23:38:36 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Luo", "Wencan", ""], ["Liu", "Fei", ""], ["Litman", "Diane", ""]]}, {"id": "1805.10399", "submitter": "Fei Liu", "authors": "Fei Liu, Jeffrey Flanigan, Sam Thomson, Norman Sadeh, Noah A. Smith", "title": "Toward Abstractive Summarization Using Semantic Representations", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel abstractive summarization framework that draws on the\nrecent development of a treebank for the Abstract Meaning Representation (AMR).\nIn this framework, the source text is parsed to a set of AMR graphs, the graphs\nare transformed into a summary graph, and then text is generated from the\nsummary graph. We focus on the graph-to-graph transformation that reduces the\nsource semantic graph into a summary graph, making use of an existing AMR\nparser and assuming the eventual availability of an AMR-to-text generator. The\nframework is data-driven, trainable, and not specifically designed for a\nparticular domain. Experiments on gold-standard AMR annotations and system\nparses show promising results. Code is available at:\nhttps://github.com/summarization\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 23:46:11 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Liu", "Fei", ""], ["Flanigan", "Jeffrey", ""], ["Thomson", "Sam", ""], ["Sadeh", "Norman", ""], ["Smith", "Noah A.", ""]]}, {"id": "1805.10414", "submitter": "Wangjin Lee", "authors": "Wangjin Lee and Jinwook Choi", "title": "Connecting Distant Entities with Induction through Conditional Random\n  Fields for Named Entity Recognition: Precursor-Induced CRF", "comments": "To appear in the 7th Named Entities Workshop (co-located with ACL\n  2018). 2018/07, Melbourne, Australia. (Short paper) 5 pages including 1\n  reference page, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a method of designing specific high-order dependency\nfactor on the linear chain conditional random fields (CRFs) for named entity\nrecognition (NER). Named entities tend to be separated from each other by\nmultiple outside tokens in a text, and thus the first-order CRF, as well as the\nsecond-order CRF, may innately lose transition information between distant\nnamed entities. The proposed design uses outside label in NER as a transmission\nmedium of precedent entity information on the CRF. Then, empirical results\napparently demonstrate that it is possible to exploit long-distance label\ndependency in the original first-order linear chain CRF structure upon NER\nwhile reducing computational loss rather than in the second-order CRF.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 02:39:10 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Lee", "Wangjin", ""], ["Choi", "Jinwook", ""]]}, {"id": "1805.10465", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang, Jiangtong Li, Hai Zhao, Bingjie Tang", "title": "SJTU-NLP at SemEval-2018 Task 9: Neural Hypernym Discovery with Term\n  Embeddings", "comments": "SemEval-2018, Workshop of NAACL-HLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a hypernym discovery system for our participation in the\nSemEval-2018 Task 9, which aims to discover the best (set of) candidate\nhypernyms for input concepts or entities, given the search space of a\npre-defined vocabulary. We introduce a neural network architecture for the\nconcerned task and empirically study various neural network models to build the\nrepresentations in latent space for words and phrases. The evaluated models\ninclude convolutional neural network, long-short term memory network, gated\nrecurrent unit and recurrent convolutional neural network. We also explore\ndifferent embedding methods, including word embedding and sense embedding for\nbetter performance.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 11:55:59 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["Li", "Jiangtong", ""], ["Zhao", "Hai", ""], ["Tang", "Bingjie", ""]]}, {"id": "1805.10528", "submitter": "Reza Ghaeini", "authors": "Reza Ghaeini, Xiaoli Z. Fern, Hamed Shahbazi, Prasad Tadepalli", "title": "Dependent Gated Reading for Cloze-Style Question Answering", "comments": "Accepted as a long paper at COLING 2018, 16 pages, 12 figures", "journal-ref": "COLING 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel deep learning architecture to address the cloze-style\nquestion answering task. Existing approaches employ reading mechanisms that do\nnot fully exploit the interdependency between the document and the query. In\nthis paper, we propose a novel \\emph{dependent gated reading} bidirectional GRU\nnetwork (DGR) to efficiently model the relationship between the document and\nthe query during encoding and decision making. Our evaluation shows that DGR\nobtains highly competitive performance on well-known machine comprehension\nbenchmarks such as the Children's Book Test (CBT-NE and CBT-CN) and Who DiD\nWhat (WDW, Strict and Relaxed). Finally, we extensively analyze and validate\nour model by ablation and attention studies.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 19:26:35 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 21:38:49 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Ghaeini", "Reza", ""], ["Fern", "Xiaoli Z.", ""], ["Shahbazi", "Hamed", ""], ["Tadepalli", "Prasad", ""]]}, {"id": "1805.10547", "submitter": "Volkan Cirik", "authors": "Volkan Cirik, Taylor Berg-Kirkpatrick, Louis-Philippe Morency", "title": "Using Syntax to Ground Referring Expressions in Natural Images", "comments": "AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce GroundNet, a neural network for referring expression recognition\n-- the task of localizing (or grounding) in an image the object referred to by\na natural language expression. Our approach to this task is the first to rely\non a syntactic analysis of the input referring expression in order to inform\nthe structure of the computation graph. Given a parse tree for an input\nexpression, we explicitly map the syntactic constituents and relationships\npresent in the tree to a composed graph of neural modules that defines our\narchitecture for performing localization. This syntax-based approach aids\nlocalization of \\textit{both} the target object and auxiliary supporting\nobjects mentioned in the expression. As a result, GroundNet is more\ninterpretable than previous methods: we can (1) determine which phrase of the\nreferring expression points to which object in the image and (2) track how the\nlocalization of the target object is determined by the network. We study this\nproperty empirically by introducing a new set of annotations on the GoogleRef\ndataset to evaluate localization of supporting objects. Our experiments show\nthat GroundNet achieves state-of-the-art accuracy in identifying supporting\nobjects, while maintaining comparable performance in the localization of target\nobjects.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 22:02:05 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Cirik", "Volkan", ""], ["Berg-Kirkpatrick", "Taylor", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1805.10564", "submitter": "Rajarshi Bhowmik", "authors": "Rajarshi Bhowmik and Gerard de Melo", "title": "Generating Fine-Grained Open Vocabulary Entity Type Descriptions", "comments": "Published in ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While large-scale knowledge graphs provide vast amounts of structured facts\nabout entities, a short textual description can often be useful to succinctly\ncharacterize an entity and its type. Unfortunately, many knowledge graph\nentities lack such textual descriptions. In this paper, we introduce a dynamic\nmemory-based network that generates a short open vocabulary description of an\nentity by jointly leveraging induced fact embeddings as well as the dynamic\ncontext of the generated sequence of words. We demonstrate the ability of our\narchitecture to discern relevant information for more accurate generation of\ntype description by pitting the system against several strong baselines.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 01:58:39 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Bhowmik", "Rajarshi", ""], ["de Melo", "Gerard", ""]]}, {"id": "1805.10586", "submitter": "Dat Quoc Nguyen", "authors": "Dat Quoc Nguyen and Karin Verspoor", "title": "Convolutional neural networks for chemical-disease relation extraction\n  are improved with character-based word embeddings", "comments": "To appear in Proceedings of the 2018 Workshop on Biomedical Natural\n  Language Processing, BioNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the incorporation of character-based word representations into\na standard CNN-based relation extraction model. We experiment with two common\nneural architectures, CNN and LSTM, to learn word vector representations from\ncharacter embeddings. Through a task on the BioCreative-V CDR corpus,\nextracting relationships between chemicals and diseases, we show that models\nexploiting the character-based word representations improve on models that do\nnot use this information, obtaining state-of-the-art result relative to\nprevious neural approaches.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 06:25:11 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Nguyen", "Dat Quoc", ""], ["Verspoor", "Karin", ""]]}, {"id": "1805.10627", "submitter": "Julia Kreutzer", "authors": "Julia Kreutzer, Joshua Uyheng, Stefan Riezler", "title": "Reliability and Learnability of Human Bandit Feedback for\n  Sequence-to-Sequence Reinforcement Learning", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a study on reinforcement learning (RL) from human bandit feedback\nfor sequence-to-sequence learning, exemplified by the task of bandit neural\nmachine translation (NMT). We investigate the reliability of human bandit\nfeedback, and analyze the influence of reliability on the learnability of a\nreward estimator, and the effect of the quality of reward estimates on the\noverall RL task. Our analysis of cardinal (5-point ratings) and ordinal\n(pairwise preferences) feedback shows that their intra- and inter-annotator\n$\\alpha$-agreement is comparable. Best reliability is obtained for standardized\ncardinal feedback, and cardinal feedback is also easiest to learn and\ngeneralize from. Finally, improvements of over 1 BLEU can be obtained by\nintegrating a regression-based reward estimator trained on cardinal feedback\nfor 800 translations into RL for NMT. This shows that RL is possible even from\nsmall amounts of fairly reliable human feedback, pointing to a great potential\nfor applications at larger scale.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 13:51:48 GMT"}, {"version": "v2", "created": "Thu, 19 Jul 2018 07:25:10 GMT"}, {"version": "v3", "created": "Thu, 13 Dec 2018 16:58:22 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Kreutzer", "Julia", ""], ["Uyheng", "Joshua", ""], ["Riezler", "Stefan", ""]]}, {"id": "1805.10796", "submitter": "Micha{\\l} Karwatowski", "authors": "Krzysztof Wr\\'obel, Marcin Pietro\\'n, Maciej Wielgosz, Micha{\\l}\n  Karwatowski and Kazimierz Wiatr", "title": "Convolutional neural network compression for natural language processing", "comments": "7 pages, 4 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks are modern models that are very efficient in\nmany classification tasks. They were originally created for image processing\npurposes. Then some trials were performed to use them in different domains like\nnatural language processing. The artificial intelligence systems (like humanoid\nrobots) are very often based on embedded systems with constraints on memory,\npower consumption etc. Therefore convolutional neural network because of its\nmemory capacity should be reduced to be mapped to given hardware. In this\npaper, results are presented of compressing the efficient convolutional neural\nnetworks for sentiment analysis. The main steps are quantization and pruning\nprocesses. The method responsible for mapping compressed network to FPGA and\nresults of this implementation are presented. The described simulations showed\nthat 5-bit width is enough to have no drop in accuracy from floating point\nversion of the network. Additionally, significant memory footprint reduction\nwas achieved (from 85% up to 93%).\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 07:40:33 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Wr\u00f3bel", "Krzysztof", ""], ["Pietro\u0144", "Marcin", ""], ["Wielgosz", "Maciej", ""], ["Karwatowski", "Micha\u0142", ""], ["Wiatr", "Kazimierz", ""]]}, {"id": "1805.10799", "submitter": "Hyemin Ahn", "authors": "Hyemin Ahn, Sungjoon Choi, Nuri Kim, Geonho Cha, Songhwai Oh", "title": "Interactive Text2Pickup Network for Natural Language based Human-Robot\n  Collaboration", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the Interactive Text2Pickup (IT2P) network for\nhuman-robot collaboration which enables an effective interaction with a human\nuser despite the ambiguity in user's commands. We focus on the task where a\nrobot is expected to pick up an object instructed by a human, and to interact\nwith the human when the given instruction is vague. The proposed network\nunderstands the command from the human user and estimates the position of the\ndesired object first. To handle the inherent ambiguity in human language\ncommands, a suitable question which can resolve the ambiguity is generated. The\nuser's answer to the question is combined with the initial command and given\nback to the network, resulting in more accurate estimation. The experiment\nresults show that given unambiguous commands, the proposed method can estimate\nthe position of the requested object with an accuracy of 98.49% based on our\ntest dataset. Given ambiguous language commands, we show that the accuracy of\nthe pick up task increases by 1.94 times after incorporating the information\nobtained from the interaction.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 07:52:42 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Ahn", "Hyemin", ""], ["Choi", "Sungjoon", ""], ["Kim", "Nuri", ""], ["Cha", "Geonho", ""], ["Oh", "Songhwai", ""]]}, {"id": "1805.10824", "submitter": "Rik van Noord", "authors": "Marloes Kuijper, Mike van Lenthe, Rik van Noord", "title": "UG18 at SemEval-2018 Task 1: Generating Additional Training Data for\n  Predicting Emotion Intensity in Spanish", "comments": "Accepted at SemEval 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present study describes our submission to SemEval 2018 Task 1: Affect in\nTweets. Our Spanish-only approach aimed to demonstrate that it is beneficial to\nautomatically generate additional training data by (i) translating training\ndata from other languages and (ii) applying a semi-supervised learning method.\nWe find strong support for both approaches, with those models outperforming our\nregular models in all subtasks. However, creating a stepwise ensemble of\ndifferent models as opposed to simply averaging did not result in an increase\nin performance. We placed second (EI-Reg), second (EI-Oc), fourth (V-Reg) and\nfifth (V-Oc) in the four Spanish subtasks we participated in.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 09:02:18 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Kuijper", "Marloes", ""], ["van Lenthe", "Mike", ""], ["van Noord", "Rik", ""]]}, {"id": "1805.10844", "submitter": "Philip Schulz", "authors": "Philip Schulz, Wilker Aziz, Trevor Cohn", "title": "A Stochastic Decoder for Neural Machine Translation", "comments": "Accepted at ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The process of translation is ambiguous, in that there are typically many\nvalid trans- lations for a given sentence. This gives rise to significant\nvariation in parallel cor- pora, however, most current models of machine\ntranslation do not account for this variation, instead treating the prob- lem\nas a deterministic process. To this end, we present a deep generative model of\nmachine translation which incorporates a chain of latent variables, in order to\nac- count for local lexical and syntactic varia- tion in parallel corpora. We\nprovide an in- depth analysis of the pitfalls encountered in variational\ninference for training deep generative models. Experiments on sev- eral\ndifferent language pairs demonstrate that the model consistently improves over\nstrong baselines.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 09:49:56 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Schulz", "Philip", ""], ["Aziz", "Wilker", ""], ["Cohn", "Trevor", ""]]}, {"id": "1805.10850", "submitter": "Ke Tran", "authors": "Ke Tran and Yonatan Bisk", "title": "Inducing Grammars with and for Neural Machine Translation", "comments": "accepted at NMT workshop (WNMT 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine translation systems require semantic knowledge and grammatical\nunderstanding. Neural machine translation (NMT) systems often assume this\ninformation is captured by an attention mechanism and a decoder that ensures\nfluency. Recent work has shown that incorporating explicit syntax alleviates\nthe burden of modeling both types of knowledge. However, requiring parses is\nexpensive and does not explore the question of what syntax a model needs during\ntranslation. To address both of these issues we introduce a model that\nsimultaneously translates while inducing dependency trees. In this way, we\nleverage the benefits of structure while investigating what syntax NMT must\ninduce to maximize performance. We show that our dependency trees are 1.\nlanguage pair dependent and 2. improve translation quality.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 10:19:38 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Tran", "Ke", ""], ["Bisk", "Yonatan", ""]]}, {"id": "1805.10856", "submitter": "Yang Yang", "authors": "Yang Yang, Haoyan Liu, Xia Hu, Jiawei Zhang, Xiaoming Zhang, Zhoujun\n  Li, Philip S. Yu", "title": "r-Instance Learning for Missing People Tweets Identification", "comments": "10 pages, 6 figures. arXiv admin note: text overlap with\n  arXiv:1805.10617", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of missing people (i.e., people who get lost) greatly increases in\nrecent years. It is a serious worldwide problem, and finding the missing people\nconsumes a large amount of social resources. In tracking and finding these\nmissing people, timely data gathering and analysis actually play an important\nrole. With the development of social media, information about missing people\ncan get propagated through the web very quickly, which provides a promising way\nto solve the problem. The information in online social media is usually of\nheterogeneous categories, involving both complex social interactions and\ntextual data of diverse structures. Effective fusion of these different types\nof information for addressing the missing people identification problem can be\na great challenge. Motivated by the multi-instance learning problem and\nexisting social science theory of \"homophily\", in this paper, we propose a\nnovel r-instance (RI) learning model.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 10:36:41 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 03:52:45 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Yang", "Yang", ""], ["Liu", "Haoyan", ""], ["Hu", "Xia", ""], ["Zhang", "Jiawei", ""], ["Zhang", "Xiaoming", ""], ["Li", "Zhoujun", ""], ["Yu", "Philip S.", ""]]}, {"id": "1805.10956", "submitter": "Wenlin Yao", "authors": "Wenlin Yao and Ruihong Huang", "title": "Temporal Event Knowledge Acquisition via Identifying Narratives", "comments": "11 pages, accepted by ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the double temporality characteristic of narrative texts, we\npropose a novel approach for acquiring rich temporal \"before/after\" event\nknowledge across sentences in narrative stories. The double temporality states\nthat a narrative story often describes a sequence of events following the\nchronological order and therefore, the temporal order of events matches with\ntheir textual order. We explored narratology principles and built a weakly\nsupervised approach that identifies 287k narrative paragraphs from three large\ntext corpora. We then extracted rich temporal event knowledge from these\nnarrative paragraphs. Such event knowledge is shown useful to improve temporal\nrelation classification and outperform several recent neural network models on\nthe narrative cloze task.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 14:51:27 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Yao", "Wenlin", ""], ["Huang", "Ruihong", ""]]}, {"id": "1805.10959", "submitter": "Han Xu", "authors": "Xu Han, Zhiyuan Liu, Maosong Sun", "title": "Denoising Distant Supervision for Relation Extraction via Instance-Level\n  Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing neural relation extraction (NRE) models rely on distant supervision\nand suffer from wrong labeling problems. In this paper, we propose a novel\nadversarial training mechanism over instances for relation extraction to\nalleviate the noise issue. As compared with previous denoising methods, our\nproposed method can better discriminate those informative instances from noisy\nones. Our method is also efficient and flexible to be applied to various NRE\narchitectures. As shown in the experiments on a large-scale benchmark dataset\nin relation extraction, our denoising method can effectively filter out noisy\ninstances and achieve significant improvements as compared with the\nstate-of-the-art models.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 14:56:35 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Han", "Xu", ""], ["Liu", "Zhiyuan", ""], ["Sun", "Maosong", ""]]}, {"id": "1805.10973", "submitter": "Taehyeong Kim", "authors": "Taehyeong Kim, Min-Oh Heo, Seonil Son, Kyoung-Wha Park, Byoung-Tak\n  Zhang", "title": "GLAC Net: GLocal Attention Cascading Networks for Multi-image Cued Story\n  Generation", "comments": "6 pages, 3 figures, paper for Visual Storytelling Challenge in\n  Storytelling Workshop co-located with NAACL 2018, source code and pre-trained\n  models are available at https://github.com/tkim-snu/GLACNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of multi-image cued story generation, such as visual storytelling\ndataset (VIST) challenge, is to compose multiple coherent sentences from a\ngiven sequence of images. The main difficulty is how to generate image-specific\nsentences within the context of overall images. Here we propose a deep learning\nnetwork model, GLAC Net, that generates visual stories by combining\nglobal-local (glocal) attention and context cascading mechanisms. The model\nincorporates two levels of attention, i.e., overall encoding level and image\nfeature level, to construct image-dependent sentences. While standard attention\nconfiguration needs a large number of parameters, the GLAC Net implements them\nin a very simple way via hard connections from the outputs of encoders or image\nfeatures onto the sentence generators. The coherency of the generated story is\nfurther improved by conveying (cascading) the information of the previous\nsentence to the next sentence serially. We evaluate the performance of the GLAC\nNet on the visual storytelling dataset (VIST) and achieve very competitive\nresults compared to the state-of-the-art techniques. Our code and pre-trained\nmodels are available here.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 15:30:21 GMT"}, {"version": "v2", "created": "Sun, 24 Jun 2018 09:17:46 GMT"}, {"version": "v3", "created": "Wed, 13 Feb 2019 05:27:28 GMT"}], "update_date": "2019-02-14", "authors_parsed": [["Kim", "Taehyeong", ""], ["Heo", "Min-Oh", ""], ["Son", "Seonil", ""], ["Park", "Kyoung-Wha", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1805.10985", "submitter": "Kian Kenyon-Dean", "authors": "Kian Kenyon-Dean, Jackie Chi Kit Cheung, Doina Precup", "title": "Resolving Event Coreference with Supervised Representation Learning and\n  Clustering-Oriented Regularization", "comments": "10 pages, 2 figures; to be published in the Proceedings of the\n  Seventh Joint Conference on Lexical and Computational Semantics (*SEM 2018),\n  June 2018, New Orleans, LA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to event coreference resolution by developing a\ngeneral framework for clustering that uses supervised representation learning.\nWe propose a neural network architecture with novel Clustering-Oriented\nRegularization (CORE) terms in the objective function. These terms encourage\nthe model to create embeddings of event mentions that are amenable to\nclustering. We then use agglomerative clustering on these embeddings to build\nevent coreference chains. For both within- and cross-document coreference on\nthe ECB+ corpus, our model obtains better results than models that require\nsignificantly more pre-annotated information. This work provides insight and\nmotivating results for a new general approach to solving coreference and\nclustering problems with representation learning.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 15:48:39 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Kenyon-Dean", "Kian", ""], ["Cheung", "Jackie Chi Kit", ""], ["Precup", "Doina", ""]]}, {"id": "1805.11004", "submitter": "Han Guo", "authors": "Han Guo, Ramakanth Pasunuru, Mohit Bansal", "title": "Soft Layer-Specific Multi-Task Summarization with Entailment and\n  Question Generation", "comments": "ACL 2018 (16 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An accurate abstractive summary of a document should contain all its salient\ninformation and should be logically entailed by the input document. We improve\nthese important aspects of abstractive summarization via multi-task learning\nwith the auxiliary tasks of question generation and entailment generation,\nwhere the former teaches the summarization model how to look for salient\nquestioning-worthy details, and the latter teaches the model how to rewrite a\nsummary which is a directed-logical subset of the input document. We also\npropose novel multi-task architectures with high-level (semantic)\nlayer-specific sharing across multiple encoder and decoder layers of the three\ntasks, as well as soft-sharing mechanisms (and show performance ablations and\nanalysis examples of each contribution). Overall, we achieve statistically\nsignificant improvements over the state-of-the-art on both the CNN/DailyMail\nand Gigaword datasets, as well as on the DUC-2002 transfer setup. We also\npresent several quantitative and qualitative analysis studies of our model's\nlearned saliency and entailment skills.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 16:05:39 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Guo", "Han", ""], ["Pasunuru", "Ramakanth", ""], ["Bansal", "Mohit", ""]]}, {"id": "1805.11025", "submitter": "Ankit Goyal", "authors": "Ankit Goyal, Jian Wang and Jia Deng", "title": "Think Visually: Question Answering through Virtual Imagery", "comments": "Accepted in ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of geometric reasoning in the context of\nquestion-answering. We introduce Dynamic Spatial Memory Network (DSMN), a new\ndeep network architecture designed for answering questions that admit latent\nvisual representations. DSMN learns to generate and reason over such\nrepresentations. Further, we propose two synthetic benchmarks, FloorPlanQA and\nShapeIntersection, to evaluate the geometric reasoning capability of QA\nsystems. Experimental results validate the effectiveness of our proposed DSMN\nfor visual thinking tasks.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 13:43:56 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Goyal", "Ankit", ""], ["Wang", "Jian", ""], ["Deng", "Jia", ""]]}, {"id": "1805.11080", "submitter": "Yen-Chun Chen", "authors": "Yen-Chun Chen, Mohit Bansal", "title": "Fast Abstractive Summarization with Reinforce-Selected Sentence\n  Rewriting", "comments": "ACL 2018 (17 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by how humans summarize long documents, we propose an accurate and\nfast summarization model that first selects salient sentences and then rewrites\nthem abstractively (i.e., compresses and paraphrases) to generate a concise\noverall summary. We use a novel sentence-level policy gradient method to bridge\nthe non-differentiable computation between these two neural networks in a\nhierarchical way, while maintaining language fluency. Empirically, we achieve\nthe new state-of-the-art on all metrics (including human evaluation) on the\nCNN/Daily Mail dataset, as well as significantly higher abstractiveness scores.\nMoreover, by first operating at the sentence-level and then the word-level, we\nenable parallel decoding of our neural generative model that results in\nsubstantially faster (10-20x) inference speed as well as 4x faster training\nconvergence than previous long-paragraph encoder-decoder models. We also\ndemonstrate the generalization of our model on the test-only DUC-2002 dataset,\nwhere we achieve higher scores than a state-of-the-art model.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 17:49:10 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Chen", "Yen-Chun", ""], ["Bansal", "Mohit", ""]]}, {"id": "1805.11140", "submitter": "Fionn Murtagh", "authors": "Fionn Murtagh, Giuseppe Iurato", "title": "Core Conflictual Relationship: Text Mining to Discover What and When", "comments": "25 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following detailed presentation of the Core Conflictual Relationship Theme\n(CCRT), there is the objective of relevant methods for what has been described\nas verbalization and visualization of data. Such is also termed data mining and\ntext mining, and knowledge discovery in data. The Correspondence Analysis\nmethodology, also termed Geometric Data Analysis, is shown in a case study to\nbe comprehensive and revealing. Computational efficiency depends on how the\nanalysis process is structured. For both illustrative and revealing aspects of\nthe case study here, relatively extensive dream reports are used. This\nGeometric Data Analysis confirms the validity of CCRT method.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 19:21:59 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Murtagh", "Fionn", ""], ["Iurato", "Giuseppe", ""]]}, {"id": "1805.11154", "submitter": "Wen Zhang", "authors": "Wen Zhang, Jiawei Hu, Yang Feng and Qun Liu", "title": "Refining Source Representations with Relation Networks for Neural\n  Machine Translation", "comments": "12pages, 7 figures, accepted for COLING-2018. arXiv admin note:\n  substantial text overlap with arXiv:1709.03980", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although neural machine translation with the encoder-decoder framework has\nachieved great success recently, it still suffers drawbacks of forgetting\ndistant information, which is an inherent disadvantage of recurrent neural\nnetwork structure, and disregarding relationship between source words during\nencoding step. Whereas in practice, the former information and relationship are\noften useful in current step. We target on solving these problems and thus\nintroduce relation networks to learn better representations of the source. The\nrelation networks are able to facilitate memorization capability of recurrent\nneural network via associating source words with each other, this would also\nhelp retain their relationships. Then the source representations and all the\nrelations are fed into the attention component together while decoding, with\nthe main encoder-decoder framework unchanged. Experiments on several datasets\nshow that our method can improve the translation performance significantly over\nthe conventional encoder-decoder model and even outperform the approach\ninvolving supervised syntactic knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 13:34:52 GMT"}, {"version": "v2", "created": "Sun, 9 Sep 2018 16:26:43 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Zhang", "Wen", ""], ["Hu", "Jiawei", ""], ["Feng", "Yang", ""], ["Liu", "Qun", ""]]}, {"id": "1805.11166", "submitter": "Hugo Jair  Escalante", "authors": "Miguel A. Alvarez-Carmona, Luis Pellegrin, Manuel Montes-y-G\\'omez,\n  Fernando S\\'anchez-Vega, Hugo Jair Escalante, A. Pastor L\\'opez-Monroy, Luis\n  Villase\\~nor-Pineda, Esa\\'u Villatoro-Tello", "title": "A visual approach for age and gender identification on Twitter", "comments": null, "journal-ref": "Miguel A. Alvarez-Carmona, Luis Pellegrin et al. A visual approach\n  for age and gender identification on Twitter. Journal of Intelligent and\n  Fuzzy Systems, vol. 34, no. 5, pp. 3133-3145, 2018", "doi": "10.3233/JIFS-169497", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of Author Profiling (AP) is to identify demographic aspects (e.g.,\nage, gender) from a given set of authors by analyzing their written texts.\nRecently, the AP task has gained interest in many problems related to computer\nforensics, psychology, marketing, but specially in those related with social\nmedia exploitation. As known, social media data is shared through a wide range\nof modalities (e.g., text, images and audio), representing valuable information\nto be exploited for extracting valuable insights from users. Nevertheless, most\nof the current work in AP using social media data has been devoted to analyze\ntextual information only, and there are very few works that have started\nexploring the gender identification using visual information. Contrastingly,\nthis paper focuses in exploiting the visual modality to perform both age and\ngender identification in social media, specifically in Twitter. Our goal is to\nevaluate the pertinence of using visual information in solving the AP task.\nAccordingly, we have extended the Twitter corpus from PAN 2014, incorporating\nposted images from all the users, making a distinction between tweeted and\nretweeted images. Performed experiments provide interesting evidence on the\nusefulness of visual information in comparison with traditional textual\nrepresentations for the AP task.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 20:31:18 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Alvarez-Carmona", "Miguel A.", ""], ["Pellegrin", "Luis", ""], ["Montes-y-G\u00f3mez", "Manuel", ""], ["S\u00e1nchez-Vega", "Fernando", ""], ["Escalante", "Hugo Jair", ""], ["L\u00f3pez-Monroy", "A. Pastor", ""], ["Villase\u00f1or-Pineda", "Luis", ""], ["Villatoro-Tello", "Esa\u00fa", ""]]}, {"id": "1805.11189", "submitter": "Mamoru Komachi", "authors": "Satoru Katsumata, Yukio Matsumura, Hayahide Yamagishi, Mamoru Komachi", "title": "Graph-based Filtering of Out-of-Vocabulary Words for Encoder-Decoder\n  Models", "comments": "8 pages; 2018 ACL Student Research Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Encoder-decoder models typically only employ words that are frequently used\nin the training corpus to reduce the computational costs and exclude noise.\nHowever, this vocabulary set may still include words that interfere with\nlearning in encoder-decoder models. This paper proposes a method for selecting\nmore suitable words for learning encoders by utilizing not only frequency, but\nalso co-occurrence information, which we capture using the HITS algorithm. We\napply our proposed method to two tasks: machine translation and grammatical\nerror correction. For Japanese-to-English translation, this method achieves a\nBLEU score that is 0.56 points more than that of a baseline. It also\noutperforms the baseline method for English grammatical error correction, with\nan F0.5-measure that is 1.48 points higher.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 22:09:49 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Katsumata", "Satoru", ""], ["Matsumura", "Yukio", ""], ["Yamagishi", "Hayahide", ""], ["Komachi", "Mamoru", ""]]}, {"id": "1805.11213", "submitter": "Xing Niu", "authors": "Xing Niu, Michael Denkowski, Marine Carpuat", "title": "Bi-Directional Neural Machine Translation with Synthetic Parallel Data", "comments": "Accepted at the 2nd Workshop on Neural Machine Translation and\n  Generation (WNMT 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite impressive progress in high-resource settings, Neural Machine\nTranslation (NMT) still struggles in low-resource and out-of-domain scenarios,\noften failing to match the quality of phrase-based translation. We propose a\nnovel technique that combines back-translation and multilingual NMT to improve\nperformance in these difficult cases. Our technique trains a single model for\nboth directions of a language pair, allowing us to back-translate source or\ntarget monolingual data without requiring an auxiliary model. We then continue\ntraining on the augmented parallel data, enabling a cycle of improvement for a\nsingle model that can incorporate any source, target, or parallel data to\nimprove both translation directions. As a byproduct, these models can reduce\ntraining and deployment costs significantly compared to uni-directional models.\nExtensive experiments show that our technique outperforms standard\nback-translation in low-resource scenarios, improves quality on cross-domain\ntasks, and effectively reduces costs across the board.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 01:45:22 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 15:54:48 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Niu", "Xing", ""], ["Denkowski", "Michael", ""], ["Carpuat", "Marine", ""]]}, {"id": "1805.11222", "submitter": "Edouard Grave", "authors": "Edouard Grave, Armand Joulin, Quentin Berthet", "title": "Unsupervised Alignment of Embeddings with Wasserstein Procrustes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of aligning two sets of points in high dimension, which\nhas many applications in natural language processing and computer vision. As an\nexample, it was recently shown that it is possible to infer a bilingual\nlexicon, without supervised data, by aligning word embeddings trained on\nmonolingual data. These recent advances are based on adversarial training to\nlearn the mapping between the two embeddings. In this paper, we propose to use\nan alternative formulation, based on the joint estimation of an orthogonal\nmatrix and a permutation matrix. While this problem is not convex, we propose\nto initialize our optimization algorithm by using a convex relaxation,\ntraditionally considered for the graph isomorphism problem. We propose a\nstochastic algorithm to minimize our cost function on large scale problems.\nFinally, we evaluate our method on the problem of unsupervised word\ntranslation, by aligning word embeddings trained on monolingual data. On this\ntask, our method obtains state of the art results, while requiring less\ncomputational resources than competing approaches.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 02:35:15 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Grave", "Edouard", ""], ["Joulin", "Armand", ""], ["Berthet", "Quentin", ""]]}, {"id": "1805.11224", "submitter": "Yijia Liu", "authors": "Yijia Liu, Wanxiang Che, Huaipeng Zhao, Bing Qin, Ting Liu", "title": "Distilling Knowledge for Search-based Structured Prediction", "comments": "To appear at ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many natural language processing tasks can be modeled into structured\nprediction and solved as a search problem. In this paper, we distill an\nensemble of multiple models trained with different initialization into a single\nmodel. In addition to learning to match the ensemble's probability output on\nthe reference states, we also use the ensemble to explore the search space and\nlearn from the encountered states in the exploration. Experimental results on\ntwo typical search-based structured prediction tasks -- transition-based\ndependency parsing and neural machine translation show that distillation can\neffectively improve the single model's performance and the final model achieves\nimprovements of 1.32 in LAS and 2.65 in BLEU score on these two tasks\nrespectively over strong baselines and it outperforms the greedy structured\nprediction models in previous literatures.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 02:39:43 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Liu", "Yijia", ""], ["Che", "Wanxiang", ""], ["Zhao", "Huaipeng", ""], ["Qin", "Bing", ""], ["Liu", "Ting", ""]]}, {"id": "1805.11234", "submitter": "Junwei Bao", "authors": "Junwei Bao, Duyu Tang, Nan Duan, Zhao Yan, Yuanhua Lv, Ming Zhou,\n  Tiejun Zhao", "title": "Table-to-Text: Describing Table Region with Natural Language", "comments": "9 pages, 4 figures. This paper has been published by AAAI2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a generative model to generate a natural language\nsentence describing a table region, e.g., a row. The model maps a row from a\ntable to a continuous vector and then generates a natural language sentence by\nleveraging the semantics of a table. To deal with rare words appearing in a\ntable, we develop a flexible copying mechanism that selectively replicates\ncontents from the table in the output sequence. Extensive experiments\ndemonstrate the accuracy of the model and the power of the copying mechanism.\nOn two synthetic datasets, WIKIBIO and SIMPLEQUESTIONS, our model improves the\ncurrent state-of-the-art BLEU-4 score from 34.70 to 40.26 and from 33.32 to\n39.12, respectively. Furthermore, we introduce an open-domain dataset\nWIKITABLETEXT including 13,318 explanatory sentences for 4,962 tables. Our\nmodel achieves a BLEU-4 score of 38.23, which outperforms template based and\nlanguage model based approaches.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 03:39:35 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Bao", "Junwei", ""], ["Tang", "Duyu", ""], ["Duan", "Nan", ""], ["Yan", "Zhao", ""], ["Lv", "Yuanhua", ""], ["Zhou", "Ming", ""], ["Zhao", "Tiejun", ""]]}, {"id": "1805.11264", "submitter": "Wei-Ning Hsu", "authors": "Wei-Ning Hsu, James Glass", "title": "Disentangling by Partitioning: A Representation Learning Framework for\n  Multimodal Sensory Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal sensory data resembles the form of information perceived by humans\nfor learning, and are easy to obtain in large quantities. Compared to unimodal\ndata, synchronization of concepts between modalities in such data provides\nsupervision for disentangling the underlying explanatory factors of each\nmodality. Previous work leveraging multimodal data has mainly focused on\nretaining only the modality-invariant factors while discarding the rest. In\nthis paper, we present a partitioned variational autoencoder (PVAE) and several\ntraining objectives to learn disentangled representations, which encode not\nonly the shared factors, but also modality-dependent ones, into separate latent\nvariables. Specifically, PVAE integrates a variational inference framework and\na multimodal generative model that partitions the explanatory factors and\nconditions only on the relevant subset of them for generation. We evaluate our\nmodel on two parallel speech/image datasets, and demonstrate its ability to\nlearn disentangled representations by qualitatively exploring within-modality\nand cross-modality conditional generation with semantics and styles specified\nby examples. For quantitative analysis, we evaluate the classification accuracy\nof automatically discovered semantic units. Our PVAE can achieve over 99%\naccuracy on both modalities.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 06:45:02 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Hsu", "Wei-Ning", ""], ["Glass", "James", ""]]}, {"id": "1805.11267", "submitter": "Peter Jansen", "authors": "Peter Jansen", "title": "Multi-hop Inference for Sentence-level TextGraphs: How Challenging is\n  Meaningfully Combining Information for Science Question Answering?", "comments": "Accepted to TextGraphs 2018. Expanded version with Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question Answering for complex questions is often modeled as a graph\nconstruction or traversal task, where a solver must build or traverse a graph\nof facts that answer and explain a given question. This \"multi-hop\" inference\nhas been shown to be extremely challenging, with few models able to aggregate\nmore than two facts before being overwhelmed by \"semantic drift\", or the\ntendency for long chains of facts to quickly drift off topic. This is a major\nbarrier to current inference models, as even elementary science questions\nrequire an average of 4 to 6 facts to answer and explain. In this work we\nempirically characterize the difficulty of building or traversing a graph of\nsentences connected by lexical overlap, by evaluating chance sentence\naggregation quality through 9,784 manually-annotated judgments across knowledge\ngraphs built from three free-text corpora (including study guides and Simple\nWikipedia). We demonstrate semantic drift tends to be high and aggregation\nquality low, at between 0.04% and 3%, and highlight scenarios that maximize the\nlikelihood of meaningfully combining information.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 06:52:29 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Jansen", "Peter", ""]]}, {"id": "1805.11295", "submitter": "Jean-Fran\\c{c}ois Delpech", "authors": "Jean-Fran\\c{c}ois Delpech", "title": "Unsupervised detection of diachronic word sense evolution", "comments": "10 pages, 1 figure, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most words have several senses and connotations which evolve in time due to\nsemantic shift, so that closely related words may gain different or even\nopposite meanings over the years. This evolution is very relevant to the study\nof language and of cultural changes, but the tools currently available for\ndiachronic semantic analysis have significant, inherent limitations and are not\nsuitable for real-time analysis. In this article, we demonstrate how the\nlinearity of random vectors techniques enables building time series of\ncongruent word embeddings (or semantic spaces) which can then be compared and\ncombined linearly without loss of precision over any time period to detect\ndiachronic semantic shifts. We show how this approach yields time trajectories\nof polysemous words such as amazon or apple, enables following semantic drifts\nand gender bias across time, reveals the shifting instantiations of stable\nconcepts such as hurricane or president. This very fast, linear approach can\neasily be distributed over many processors to follow in real time streams of\nsocial media such as Twitter or Facebook; the resulting, time-dependent\nsemantic spaces can then be combined at will by simple additions or\nsubtractions.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 08:22:50 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 12:21:12 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Delpech", "Jean-Fran\u00e7ois", ""]]}, {"id": "1805.11350", "submitter": "Nikola Mrk\\v{s}i\\'c", "authors": "Nikola Mrk\\v{s}i\\'c and Ivan Vuli\\'c", "title": "Fully Statistical Neural Belief Tracking", "comments": "Accepted as a short paper for the 56th Annual Meeting of the\n  Association for Computational Linguistics (ACL 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an improvement to the existing data-driven Neural Belief\nTracking (NBT) framework for Dialogue State Tracking (DST). The existing NBT\nmodel uses a hand-crafted belief state update mechanism which involves an\nexpensive manual retuning step whenever the model is deployed to a new dialogue\ndomain. We show that this update mechanism can be learned jointly with the\nsemantic decoding and context modelling parts of the NBT model, eliminating the\nlast rule-based module from this DST framework. We propose two different\nstatistical update mechanisms and show that dialogue dynamics can be modelled\nwith a very small number of additional model parameters. In our DST evaluation\nover three languages, we show that this model achieves competitive performance\nand provides a robust framework for building resource-light DST models.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 10:41:08 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Mrk\u0161i\u0107", "Nikola", ""], ["Vuli\u0107", "Ivan", ""]]}, {"id": "1805.11351", "submitter": "Qiuchi Li", "authors": "Qiuchi Li, Sagar Uprety, Benyou Wang, Dawei Song", "title": "Quantum-inspired Complex Word Embedding", "comments": "This paper has been accepted by the 3rd Workshop on Representation\n  Learning for NLP (RepL4NLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A challenging task for word embeddings is to capture the emergent meaning or\npolarity of a combination of individual words. For example, existing approaches\nin word embeddings will assign high probabilities to the words \"Penguin\" and\n\"Fly\" if they frequently co-occur, but it fails to capture the fact that they\noccur in an opposite sense - Penguins do not fly. We hypothesize that humans do\nnot associate a single polarity or sentiment to each word. The word contributes\nto the overall polarity of a combination of words depending upon which other\nwords it is combined with. This is analogous to the behavior of microscopic\nparticles which exist in all possible states at the same time and interfere\nwith each other to give rise to new states depending upon their relative\nphases. We make use of the Hilbert Space representation of such particles in\nQuantum Mechanics where we subscribe a relative phase to each word, which is a\ncomplex number, and investigate two such quantum inspired models to derive the\nmeaning of a combination of words. The proposed models achieve better\nperformances than state-of-the-art non-quantum models on the binary sentence\nclassification task.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 10:46:30 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Li", "Qiuchi", ""], ["Uprety", "Sagar", ""], ["Wang", "Benyou", ""], ["Song", "Dawei", ""]]}, {"id": "1805.11360", "submitter": "Seonhoon Kim", "authors": "Seonhoon Kim, Inho Kang, Nojun Kwak", "title": "Semantic Sentence Matching with Densely-connected Recurrent and\n  Co-attentive Information", "comments": "Accepted at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence matching is widely used in various natural language tasks such as\nnatural language inference, paraphrase identification, and question answering.\nFor these tasks, understanding logical and semantic relationship between two\nsentences is required but it is yet challenging. Although attention mechanism\nis useful to capture the semantic relationship and to properly align the\nelements of two sentences, previous methods of attention mechanism simply use a\nsummation operation which does not retain original features enough. Inspired by\nDenseNet, a densely connected convolutional network, we propose a\ndensely-connected co-attentive recurrent neural network, each layer of which\nuses concatenated information of attentive features as well as hidden features\nof all the preceding recurrent layers. It enables preserving the original and\nthe co-attentive feature information from the bottommost word embedding layer\nto the uppermost recurrent layer. To alleviate the problem of an\never-increasing size of feature vectors due to dense concatenation operations,\nwe also propose to use an autoencoder after dense concatenation. We evaluate\nour proposed architecture on highly competitive benchmark datasets related to\nsentence matching. Experimental results show that our architecture, which\nretains recurrent and attentive features, achieves state-of-the-art\nperformances for most of the tasks.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 11:29:56 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 09:20:01 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Kim", "Seonhoon", ""], ["Kang", "Inho", ""], ["Kwak", "Nojun", ""]]}, {"id": "1805.11404", "submitter": "Arnim Bleier", "authors": "Andreas Niekler, Arnim Bleier, Christian Kahmann, Lisa Posch, Gregor\n  Wiedemann, Kenan Erdogan, Gerhard Heyer, Markus Strohmaier", "title": "iLCM - A Virtual Research Infrastructure for Large-Scale Qualitative\n  Data", "comments": "11th edition of the Language Resources and Evaluation Conference\n  (LREC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The iLCM project pursues the development of an integrated research\nenvironment for the analysis of structured and unstructured data in a \"Software\nas a Service\" architecture (SaaS). The research environment addresses\nrequirements for the quantitative evaluation of large amounts of qualitative\ndata with text mining methods as well as requirements for the reproducibility\nof data-driven research designs in the social sciences. For this, the iLCM\nresearch environment comprises two central components. First, the Leipzig\nCorpus Miner (LCM), a decentralized SaaS application for the analysis of large\namounts of news texts developed in a previous Digital Humanities project.\nSecond, the text mining tools implemented in the LCM are extended by an \"Open\nResearch Computing\" (ORC) environment for executable script documents,\nso-called \"notebooks\". This novel integration allows to combine generic,\nhigh-performance methods to process large amounts of unstructured text data and\nwith individual program scripts to address specific research requirements in\ncomputational social science and digital humanities.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 10:24:11 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Niekler", "Andreas", ""], ["Bleier", "Arnim", ""], ["Kahmann", "Christian", ""], ["Posch", "Lisa", ""], ["Wiedemann", "Gregor", ""], ["Erdogan", "Kenan", ""], ["Heyer", "Gerhard", ""], ["Strohmaier", "Markus", ""]]}, {"id": "1805.11461", "submitter": "Farhad Nooralahzadeh", "authors": "Farhad Nooralahzadeh, Lilja {\\O}vrelid", "title": "Syntactic Dependency Representations in Neural Relation Classification", "comments": "arXiv admin note: text overlap with arXiv:1804.08887", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the use of different syntactic dependency representations in a\nneural relation classification task and compare the CoNLL, Stanford Basic and\nUniversal Dependencies schemes. We further compare with a syntax-agnostic\napproach and perform an error analysis in order to gain a better understanding\nof the results.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 16:17:27 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Nooralahzadeh", "Farhad", ""], ["\u00d8vrelid", "Lilja", ""]]}, {"id": "1805.11462", "submitter": "Vincent Nguyen", "authors": "Guillaume Klein, Yoon Kim, Yuntian Deng, Vincent Nguyen, Jean\n  Senellart, Alexander M. Rush", "title": "OpenNMT: Neural Machine Translation Toolkit", "comments": "Presentation to AMTA 2018 - Boston. arXiv admin note: substantial\n  text overlap with arXiv:1701.02810", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OpenNMT is an open-source toolkit for neural machine translation (NMT). The\nsystem prioritizes efficiency, modularity, and extensibility with the goal of\nsupporting NMT research into model architectures, feature representations, and\nsource modalities, while maintaining competitive performance and reasonable\ntraining requirements. The toolkit consists of modeling and translation\nsupport, as well as detailed pedagogical documentation about the underlying\ntechniques. OpenNMT has been used in several production MT systems, modified\nfor numerous research papers, and is implemented across several deep learning\nframeworks.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 07:58:46 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Klein", "Guillaume", ""], ["Kim", "Yoon", ""], ["Deng", "Yuntian", ""], ["Nguyen", "Vincent", ""], ["Senellart", "Jean", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1805.11465", "submitter": "Jonas Groschwitz", "authors": "Jonas Groschwitz, Matthias Lindemann, Meaghan Fowlie, Mark Johnson,\n  Alexander Koller", "title": "AMR Dependency Parsing with a Typed Semantic Algebra", "comments": "This paper will be presented at ACL 2018 (see\n  https://acl2018.org/programme/papers/)", "journal-ref": "Proceedings of the 56th Annual Meeting of the Association for\n  Computational Linguistics (Volume 1: Long Papers), 2018", "doi": "10.18653/v1/P18-1170", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a semantic parser for Abstract Meaning Representations which\nlearns to parse strings into tree representations of the compositional\nstructure of an AMR graph. This allows us to use standard neural techniques for\nsupertagging and dependency tree parsing, constrained by a linguistically\nprincipled type system. We present two approximative decoding algorithms, which\nachieve state-of-the-art accuracy and outperform strong baselines.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 13:44:19 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Groschwitz", "Jonas", ""], ["Lindemann", "Matthias", ""], ["Fowlie", "Meaghan", ""], ["Johnson", "Mark", ""], ["Koller", "Alexander", ""]]}, {"id": "1805.11467", "submitter": "Diego Moussallem", "authors": "Diego Moussallem, Ricardo Usbeck, Michael R\\\"oder, Axel-Cyrille Ngonga\n  Ngomo", "title": "Entity Linking in 40 Languages using MAG", "comments": "Accepted at ESWC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A plethora of Entity Linking (EL) approaches has recently been developed.\nWhile many claim to be multilingual, the MAG (Multilingual AGDISTIS) approach\nhas been shown recently to outperform the state of the art in multilingual EL\non 7 languages. With this demo, we extend MAG to support EL in 40 different\nlanguages, including especially low-resources languages such as Ukrainian,\nGreek, Hungarian, Croatian, Portuguese, Japanese and Korean. Our demo relies on\nonline web services which allow for an easy access to our entity linking\napproaches and can disambiguate against DBpedia and Wikidata. During the demo,\nwe will show how to use MAG by means of POST requests as well as using its\nuser-friendly web interface. All data used in the demo is available at\nhttps://hobbitdata.informatik.uni-leipzig.de/agdistis/\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 13:46:27 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Moussallem", "Diego", ""], ["Usbeck", "Ricardo", ""], ["R\u00f6der", "Michael", ""], ["Ngomo", "Axel-Cyrille Ngonga", ""]]}, {"id": "1805.11474", "submitter": "Anastasia Shimorina", "authors": "Anastasia Shimorina", "title": "Human vs Automatic Metrics: on the Importance of Correlation Design", "comments": "accepted for the WiNLP workshop at NAACL 2018; 3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper discusses two existing approaches to the correlation analysis\nbetween automatic evaluation metrics and human scores in the area of natural\nlanguage generation. Our experiments show that depending on the usage of a\nsystem- or sentence-level correlation analysis, correlation results between\nautomatic scores and human judgments are inconsistent.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 13:53:16 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 16:31:26 GMT"}, {"version": "v3", "created": "Fri, 12 Mar 2021 20:16:34 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Shimorina", "Anastasia", ""]]}, {"id": "1805.11535", "submitter": "Yi Tay", "authors": "Yi Tay, Anh Tuan Luu, Siu Cheung Hui", "title": "CoupleNet: Paying Attention to Couples with Coupled Attention for\n  Relationship Recommendation", "comments": "Accepted at ICWSM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dating and romantic relationships not only play a huge role in our personal\nlives but also collectively influence and shape society. Today, many romantic\npartnerships originate from the Internet, signifying the importance of\ntechnology and the web in modern dating. In this paper, we present a text-based\ncomputational approach for estimating the relationship compatibility of two\nusers on social media. Unlike many previous works that propose reciprocal\nrecommender systems for online dating websites, we devise a distant supervision\nheuristic to obtain real world couples from social platforms such as Twitter.\nOur approach, the CoupleNet is an end-to-end deep learning based estimator that\nanalyzes the social profiles of two users and subsequently performs a\nsimilarity match between the users. Intuitively, our approach performs both\nuser profiling and match-making within a unified end-to-end framework.\nCoupleNet utilizes hierarchical recurrent neural models for learning\nrepresentations of user profiles and subsequently coupled attention mechanisms\nto fuse information aggregated from two users. To the best of our knowledge,\nour approach is the first data-driven deep learning approach for our novel\nrelationship recommendation problem. We benchmark our CoupleNet against several\nmachine learning and deep learning baselines. Experimental results show that\nour approach outperforms all approaches significantly in terms of precision.\nQualitative analysis shows that our model is capable of also producing\nexplainable results to users.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 15:14:41 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Tay", "Yi", ""], ["Luu", "Anh Tuan", ""], ["Hui", "Siu Cheung", ""]]}, {"id": "1805.11545", "submitter": "Marco Antonio Valenzuela-Esc\\'arcega", "authors": "Marco A. Valenzuela-Esc\\'arcega and Ajay Nagesh and Mihai Surdeanu", "title": "Lightly-supervised Representation Learning with Global Interpretability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a lightly-supervised approach for information extraction, in\nparticular named entity classification, which combines the benefits of\ntraditional bootstrapping, i.e., use of limited annotations and\ninterpretability of extraction patterns, with the robust learning approaches\nproposed in representation learning. Our algorithm iteratively learns custom\nembeddings for both the multi-word entities to be extracted and the patterns\nthat match them from a few example entities per category. We demonstrate that\nthis representation-based approach outperforms three other state-of-the-art\nbootstrapping approaches on two datasets: CoNLL-2003 and OntoNotes.\nAdditionally, using these embeddings, our approach outputs a\nglobally-interpretable model consisting of a decision list, by ranking patterns\nbased on their proximity to the average entity embedding in a given class. We\nshow that this interpretable model performs close to our complete bootstrapping\nmodel, proving that representation learning can be used to produce\ninterpretable models with small loss in performance.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 15:49:11 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Valenzuela-Esc\u00e1rcega", "Marco A.", ""], ["Nagesh", "Ajay", ""], ["Surdeanu", "Mihai", ""]]}, {"id": "1805.11546", "submitter": "Alexander Ororbia", "authors": "Alexander G. Ororbia, Ankur Mali, Matthew A. Kelly, and David Reitter", "title": "Like a Baby: Visually Situated Neural Language Acquisition", "comments": "Final submission (camera-ready), accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the benefits of visual context in training neural language models\nto perform next-word prediction. A multi-modal neural architecture is\nintroduced that outperform its equivalent trained on language alone with a 2\\%\ndecrease in perplexity, even when no visual context is available at test.\nFine-tuning the embeddings of a pre-trained state-of-the-art bidirectional\nlanguage model (BERT) in the language modeling framework yields a 3.5\\%\nimprovement. The advantage for training with visual context when testing\nwithout is robust across different languages (English, German and Spanish) and\ndifferent models (GRU, LSTM, $\\Delta$-RNN, as well as those that use BERT\nembeddings). Thus, language models perform better when they learn like a baby,\ni.e, in a multi-modal environment. This finding is compatible with the theory\nof situated cognition: language is inseparable from its physical context.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 15:53:30 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 05:11:20 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Ororbia", "Alexander G.", ""], ["Mali", "Ankur", ""], ["Kelly", "Matthew A.", ""], ["Reitter", "David", ""]]}, {"id": "1805.11564", "submitter": "Uwe Reichel", "authors": "Uwe D. Reichel, \\v{S}tefan Be\\v{n}u\\v{s}, Katalin M\\'ady", "title": "Entrainment profiles: Comparison by gender, role, and feature set", "comments": "Accepted Manuscript for Speech Communication (Elsevier), 25 April\n  2018", "journal-ref": "U.D. Reichel, \\v{S}. Be\\v{n}u\\v{s}, K. M\\'ady. Entrainment\n  profiles: Comparison by gender, role, and feature set. Speech Communication,\n  100:46-57, 2018", "doi": "10.1016/j.specom.2018.04.009", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine prosodic entrainment in cooperative game dialogs for new feature\nsets describing register, pitch accent shape, and rhythmic aspects of\nutterances. For these as well as for established features we present\nentrainment profiles to detect within- and across-dialog entrainment by the\nspeakers' gender and role in the game. It turned out, that feature sets undergo\nentrainment in different quantitative and qualitative ways, which can partly be\nattributed to their different functions. Furthermore, interactions between\nspeaker gender and role (describer vs. follower) suggest gender-dependent\nstrategies in cooperative solution-oriented interactions: female describers\nentrain most, male describers least. Our data suggests a slight advantage of\nthe latter strategy on task success.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 16:22:42 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Reichel", "Uwe D.", ""], ["Be\u0148u\u0161", "\u0160tefan", ""], ["M\u00e1dy", "Katalin", ""]]}, {"id": "1805.11598", "submitter": "Phoebe Mulcaire", "authors": "Phoebe Mulcaire, Swabha Swayamdipta, Noah Smith", "title": "Polyglot Semantic Role Labeling", "comments": "To appear at ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous approaches to multilingual semantic dependency parsing treat\nlanguages independently, without exploiting the similarities between semantic\nstructures across languages. We experiment with a new approach where we combine\nresources from a pair of languages in the CoNLL 2009 shared task to build a\npolyglot semantic role labeler. Notwithstanding the absence of parallel data,\nand the dissimilarity in annotations between languages, our approach results in\nan improvement in SRL performance on multiple languages over a monolingual\nbaseline. Analysis of the polyglot model shows it to be advantageous in\nlower-resource settings.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 17:29:55 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Mulcaire", "Phoebe", ""], ["Swayamdipta", "Swabha", ""], ["Smith", "Noah", ""]]}, {"id": "1805.11603", "submitter": "Moustafa Al-Hajj", "authors": "Moustafa Al-Hajj, Amani Sabra", "title": "Automatic Identification of Arabic expressions related to future events\n  in Lebanon's economy", "comments": "5 pages", "journal-ref": "International Journal of Science and Research (IJSR),\n  https://www.ijsr.net/archive/v7i4/ART20182042.pdf, Volume 7 Issue 4, April\n  2018, 1656 - 1660", "doi": "10.21275/ART20182042", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a method to automatically identify future events in\nLebanon's economy from Arabic texts. Challenges are threefold: first, we need\nto build a corpus of Arabic texts that covers Lebanon's economy; second, we\nneed to study how future events are expressed linguistically in these texts;\nand third, we need to automatically identify the relevant textual segments\naccordingly. We will validate this method on a constructed corpus form the web\nand show that it has very promising results. To do so, we will be using SLCSAS,\na system for semantic analysis, based on the Contextual Explorer method, and\n\"AlKhalil Morpho Sys\" system for morpho-syntactic analysis.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 17:41:52 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Al-Hajj", "Moustafa", ""], ["Sabra", "Amani", ""]]}, {"id": "1805.11611", "submitter": "Miguel Angel Alvarez", "authors": "Miguel A. \\'Alvarez-Carmona, Marc Franco-Salvador, Esa\\'u\n  Villatoro-Tello, Manuel Montes-y-G\\'omez, Paolo Rosso and Luis\n  Villase\\~nor-Pineda", "title": "Semantically-informed distance and similarity measures for paraphrase\n  plagiarism identification", "comments": null, "journal-ref": "Journal of Intelligent & Fuzzy Systems, vol. 34, no. 5, pp.\n  2983-2990, 2018", "doi": "10.3233/JIFS-169483", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paraphrase plagiarism identification represents a very complex task given\nthat plagiarized texts are intentionally modified through several rewording\ntechniques. Accordingly, this paper introduces two new measures for evaluating\nthe relatedness of two given texts: a semantically-informed similarity measure\nand a semantically-informed edit distance. Both measures are able to extract\nsemantic information from either an external resource or a distributed\nrepresentation of words, resulting in informative features for training a\nsupervised classifier for detecting paraphrase plagiarism. Obtained results\nindicate that the proposed metrics are consistently good in detecting different\ntypes of paraphrase plagiarism. In addition, results are very competitive\nagainst state-of-the art methods having the advantage of representing a much\nmore simple but equally effective solution.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 17:54:52 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["\u00c1lvarez-Carmona", "Miguel A.", ""], ["Franco-Salvador", "Marc", ""], ["Villatoro-Tello", "Esa\u00fa", ""], ["Montes-y-G\u00f3mez", "Manuel", ""], ["Rosso", "Paolo", ""], ["Villase\u00f1or-Pineda", "Luis", ""]]}, {"id": "1805.11651", "submitter": "Vadim Markovtsev", "authors": "Vadim Markovtsev, Waren Long, Egor Bulychev, Romain Keramitas,\n  Konstantin Slavnov, Gabor Markowski", "title": "Splitting source code identifiers using Bidirectional LSTM Recurrent\n  Neural Network", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.PL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Programmers make rich use of natural language in the source code they write\nthrough identifiers and comments. Source code identifiers are selected from a\npool of tokens which are strongly related to the meaning, naming conventions,\nand context. These tokens are often combined to produce more precise and\nobvious designations. Such multi-part identifiers count for 97% of all naming\ntokens in the Public Git Archive - the largest dataset of Git repositories to\ndate. We introduce a bidirectional LSTM recurrent neural network to detect\nsubtokens in source code identifiers. We trained that network on 41.7 million\ndistinct splittable identifiers collected from 182,014 open source projects in\nPublic Git Archive, and show that it outperforms several other machine learning\nmodels. The proposed network can be used to improve the upstream models which\nare based on source code identifiers, as well as improving developer experience\nallowing writing code without switching the keyboard case.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 06:46:55 GMT"}, {"version": "v2", "created": "Thu, 19 Jul 2018 08:05:03 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Markovtsev", "Vadim", ""], ["Long", "Waren", ""], ["Bulychev", "Egor", ""], ["Keramitas", "Romain", ""], ["Slavnov", "Konstantin", ""], ["Markowski", "Gabor", ""]]}, {"id": "1805.11653", "submitter": "Nelson F. Liu", "authors": "Nelson F. Liu, Omer Levy, Roy Schwartz, Chenhao Tan, and Noah A. Smith", "title": "LSTMs Exploit Linguistic Attributes of Data", "comments": "7 pages, 4 figures; accepted to ACL 2018 RepL4NLP workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While recurrent neural networks have found success in a variety of natural\nlanguage processing applications, they are general models of sequential data.\nWe investigate how the properties of natural language data affect an LSTM's\nability to learn a nonlinguistic task: recalling elements from its input. We\nfind that models trained on natural language data are able to recall tokens\nfrom much longer sequences than models trained on non-language sequential data.\nFurthermore, we show that the LSTM learns to solve the memorization task by\nexplicitly using a subset of its neurons to count timesteps in the input. We\nhypothesize that the patterns and structure in natural language data enable\nLSTMs to learn by providing approximate ways of reducing loss, but\nunderstanding the effect of different training data on the learnability of\nLSTMs remains an open question.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 18:44:31 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 18:45:26 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Liu", "Nelson F.", ""], ["Levy", "Omer", ""], ["Schwartz", "Roy", ""], ["Tan", "Chenhao", ""], ["Smith", "Noah A.", ""]]}, {"id": "1805.11749", "submitter": "Zichao Yang", "authors": "Zichao Yang, Zhiting Hu, Chris Dyer, Eric P. Xing, Taylor\n  Berg-Kirkpatrick", "title": "Unsupervised Text Style Transfer using Language Models as Discriminators", "comments": "NeurIPS camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary classifiers are often employed as discriminators in GAN-based\nunsupervised style transfer systems to ensure that transferred sentences are\nsimilar to sentences in the target domain. One difficulty with this approach is\nthat the error signal provided by the discriminator can be unstable and is\nsometimes insufficient to train the generator to produce fluent language. In\nthis paper, we propose a new technique that uses a target domain language model\nas the discriminator, providing richer and more stable token-level feedback\nduring the learning process. We train the generator to minimize the negative\nlog likelihood (NLL) of generated sentences, evaluated by the language model.\nBy using a continuous approximation of discrete sampling under the generator,\nour model can be trained using back-propagation in an end- to-end fashion.\nMoreover, our empirical results show that when using a language model as a\nstructured discriminator, it is possible to forgo adversarial steps during\ntraining, making the process more stable. We compare our model with previous\nwork using convolutional neural networks (CNNs) as discriminators and show that\nour approach leads to improved performance on three tasks: word substitution\ndecipherment, sentiment modification, and related language translation.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 00:02:59 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 17:09:13 GMT"}, {"version": "v3", "created": "Tue, 29 Jan 2019 21:52:49 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Yang", "Zichao", ""], ["Hu", "Zhiting", ""], ["Dyer", "Chris", ""], ["Xing", "Eric P.", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}, {"id": "1805.11752", "submitter": "Oluwatobi Olabiyi", "authors": "Oluwatobi Olabiyi, Alan Salimov, Anish Khazane, Erik T. Mueller", "title": "Multi-turn Dialogue Response Generation in an Adversarial Learning\n  Framework", "comments": "Accepted at ACL 2019 Workshop on NLP for Conversational AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We propose an adversarial learning approach for generating multi-turn\ndialogue responses. Our proposed framework, hredGAN, is based on conditional\ngenerative adversarial networks (GANs). The GAN's generator is a modified\nhierarchical recurrent encoder-decoder network (HRED) and the discriminator is\na word-level bidirectional RNN that shares context and word embeddings with the\ngenerator. During inference, noise samples conditioned on the dialogue history\nare used to perturb the generator's latent space to generate several possible\nresponses. The final response is the one ranked best by the discriminator. The\nhredGAN shows improved performance over existing methods: (1) it generalizes\nbetter than networks trained using only the log-likelihood criterion, and (2)\nit generates longer, more informative and more diverse responses with high\nutterance and topic relevance even with limited training data. This improvement\nis demonstrated on the Movie triples and Ubuntu dialogue datasets using both\nautomatic and human evaluations.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 00:05:53 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 20:49:03 GMT"}, {"version": "v3", "created": "Wed, 19 Sep 2018 13:35:08 GMT"}, {"version": "v4", "created": "Tue, 18 Jun 2019 13:26:28 GMT"}, {"version": "v5", "created": "Wed, 26 Jun 2019 14:39:24 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Olabiyi", "Oluwatobi", ""], ["Salimov", "Alan", ""], ["Khazane", "Anish", ""], ["Mueller", "Erik T.", ""]]}, {"id": "1805.11762", "submitter": "Bing Liu", "authors": "Bing Liu, Ian Lane", "title": "Adversarial Learning of Task-Oriented Neural Dialog Models", "comments": "To appear at SIGDIAL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose an adversarial learning method for reward estimation\nin reinforcement learning (RL) based task-oriented dialog models. Most of the\ncurrent RL based task-oriented dialog systems require the access to a reward\nsignal from either user feedback or user ratings. Such user ratings, however,\nmay not always be consistent or available in practice. Furthermore, online\ndialog policy learning with RL typically requires a large number of queries to\nusers, suffering from sample efficiency problem. To address these challenges,\nwe propose an adversarial learning method to learn dialog rewards directly from\ndialog samples. Such rewards are further used to optimize the dialog policy\nwith policy gradient based RL. In the evaluation in a restaurant search domain,\nwe show that the proposed adversarial dialog learning method achieves advanced\ndialog success rate comparing to strong baseline methods. We further discuss\nthe covariate shift problem in online adversarial dialog learning and show how\nwe can address that with partial access to user feedback.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 00:48:44 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Liu", "Bing", ""], ["Lane", "Ian", ""]]}, {"id": "1805.11774", "submitter": "Fereshte Khani", "authors": "Fereshte Khani, Noah D. Goodman, Percy Liang", "title": "Planning, Inference and Pragmatics in Sequential Language Games", "comments": "In proceedings of TACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study sequential language games in which two players, each with private\ninformation, communicate to achieve a common goal. In such games, a successful\nplayer must (i) infer the partner's private information from the partner's\nmessages, (ii) generate messages that are most likely to help with the goal,\nand (iii) reason pragmatically about the partner's strategy. We propose a model\nthat captures all three characteristics and demonstrate their importance in\ncapturing human behavior on a new goal-oriented dataset we collected using\ncrowdsourcing.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 02:04:30 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Khani", "Fereshte", ""], ["Goodman", "Noah D.", ""], ["Liang", "Percy", ""]]}, {"id": "1805.11818", "submitter": "Volkan Cirik", "authors": "Volkan Cirik, Louis-Philippe Morency, Taylor Berg-Kirkpatrick", "title": "Visual Referring Expression Recognition: What Do Systems Actually Learn?", "comments": "NAACL2018 short", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an empirical analysis of the state-of-the-art systems for\nreferring expression recognition -- the task of identifying the object in an\nimage referred to by a natural language expression -- with the goal of gaining\ninsight into how these systems reason about language and vision. Surprisingly,\nwe find strong evidence that even sophisticated and linguistically-motivated\nmodels for this task may ignore the linguistic structure, instead relying on\nshallow correlations introduced by unintended biases in the data selection and\nannotation process. For example, we show that a system trained and tested on\nthe input image $\\textit{without the input referring expression}$ can achieve a\nprecision of 71.2% in top-2 predictions. Furthermore, a system that predicts\nonly the object category given the input can achieve a precision of 84.2% in\ntop-2 predictions. These surprisingly positive results for what should be\ndeficient prediction scenarios suggest that careful analysis of what our models\nare learning -- and further, how our data is constructed -- is critical as we\nseek to make substantive progress on grounded language tasks.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 06:03:21 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Cirik", "Volkan", ""], ["Morency", "Louis-Philippe", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}, {"id": "1805.11824", "submitter": "Soujanya Poria", "authors": "Rhea Sukthanker, Soujanya Poria, Erik Cambria, Ramkumar\n  Thirunavukarasu", "title": "Anaphora and Coreference Resolution: A Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Entity resolution aims at resolving repeated references to an entity in a\ndocument and forms a core component of natural language processing (NLP)\nresearch. This field possesses immense potential to improve the performance of\nother NLP fields like machine translation, sentiment analysis, paraphrase\ndetection, summarization, etc. The area of entity resolution in NLP has seen\nproliferation of research in two separate sub-areas namely: anaphora resolution\nand coreference resolution. Through this review article, we aim at clarifying\nthe scope of these two tasks in entity resolution. We also carry out a detailed\nanalysis of the datasets, evaluation metrics and research methods that have\nbeen adopted to tackle this NLP problem. This survey is motivated with the aim\nof providing the reader with a clear understanding of what constitutes this NLP\nproblem and the issues that require attention.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 06:49:15 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Sukthanker", "Rhea", ""], ["Poria", "Soujanya", ""], ["Cambria", "Erik", ""], ["Thirunavukarasu", "Ramkumar", ""]]}, {"id": "1805.11850", "submitter": "Kota Yoshida", "authors": "Kota Yoshida, Munetaka Minoguchi, Kenichiro Wani, Akio Nakamura and\n  Hirokatsu Kataoka", "title": "Neural Joking Machine : Humorous image captioning", "comments": "Accepted to CVPR 2018 Language & Vision Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What is an effective expression that draws laughter from human beings? In the\npresent paper, in order to consider this question from an academic standpoint,\nwe generate an image caption that draws a \"laugh\" by a computer. A system that\noutputs funny captions based on the image caption proposed in the computer\nvision field is constructed. Moreover, we also propose the Funny Score, which\nflexibly gives weights according to an evaluation database. The Funny Score\nmore effectively brings out \"laughter\" to optimize a model. In addition, we\nbuild a self-collected BoketeDB, which contains a theme (image) and funny\ncaption (text) posted on \"Bokete\", which is an image Ogiri website. In an\nexperiment, we use BoketeDB to verify the effectiveness of the proposed method\nby comparing the results obtained using the proposed method and those obtained\nusing MS COCO Pre-trained CNN+LSTM, which is the baseline and idiot created by\nhumans. We refer to the proposed method, which uses the BoketeDB pre-trained\nmodel, as the Neural Joking Machine (NJM).\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 08:20:55 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Yoshida", "Kota", ""], ["Minoguchi", "Munetaka", ""], ["Wani", "Kenichiro", ""], ["Nakamura", "Akio", ""], ["Kataoka", "Hirokatsu", ""]]}, {"id": "1805.11867", "submitter": "Chao-Chun Hsu", "authors": "Chao-Chun Hsu, Szu-Min Chen, Ming-Hsun Hsieh, Lun-Wei Ku", "title": "Using Inter-Sentence Diverse Beam Search to Reduce Redundancy in Visual\n  Storytelling", "comments": "Challenge paper in storytelling workshop co-located with NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual storytelling includes two important parts: coherence between the story\nand images as well as the story structure. For image to text neural network\nmodels, similar images in the sequence would provide close information for\nstory generator to obtain almost identical sentence. However, repeatedly\nnarrating same objects or events will undermine a good story structure. In this\npaper, we proposed an inter-sentence diverse beam search to generate a more\nexpressive story. Comparing to some recent models of visual storytelling task,\nwhich generate story without considering the generated sentence of the previous\npicture, our proposed method can avoid generating identical sentence even given\na sequence of similar pictures.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 08:59:44 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Hsu", "Chao-Chun", ""], ["Chen", "Szu-Min", ""], ["Hsieh", "Ming-Hsun", ""], ["Ku", "Lun-Wei", ""]]}, {"id": "1805.11868", "submitter": "Sahil Swami", "authors": "Sahil Swami, Ankush Khandelwal, Vinay Singh, Syed Sarfaraz Akhtar,\n  Manish Shrivastava", "title": "An English-Hindi Code-Mixed Corpus: Stance Annotation and Baseline\n  System", "comments": "9 pages, CICling 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media has become one of the main channels for peo- ple to communicate\nand share their views with the society. We can often detect from these views\nwhether the person is in favor, against or neu- tral towards a given topic.\nThese opinions from social media are very useful for various companies. We\npresent a new dataset that consists of 3545 English-Hindi code-mixed tweets\nwith opinion towards Demoneti- sation that was implemented in India in 2016\nwhich was followed by a large countrywide debate. We present a baseline\nsupervised classification system for stance detection developed using the same\ndataset that uses various machine learning techniques to achieve an accuracy of\n58.7% on 10-fold cross validation.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 09:03:50 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Swami", "Sahil", ""], ["Khandelwal", "Ankush", ""], ["Singh", "Vinay", ""], ["Akhtar", "Syed Sarfaraz", ""], ["Shrivastava", "Manish", ""]]}, {"id": "1805.11869", "submitter": "Sahil Swami", "authors": "Sahil Swami, Ankush Khandelwal, Vinay Singh, Syed Sarfaraz Akhtar,\n  Manish Shrivastava", "title": "A Corpus of English-Hindi Code-Mixed Tweets for Sarcasm Detection", "comments": "9 pages, CICLing 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media platforms like twitter and facebook have be- come two of the\nlargest mediums used by people to express their views to- wards different\ntopics. Generation of such large user data has made NLP tasks like sentiment\nanalysis and opinion mining much more important. Using sarcasm in texts on\nsocial media has become a popular trend lately. Using sarcasm reverses the\nmeaning and polarity of what is implied by the text which poses challenge for\nmany NLP tasks. The task of sarcasm detection in text is gaining more and more\nimportance for both commer- cial and security services. We present the first\nEnglish-Hindi code-mixed dataset of tweets marked for presence of sarcasm and\nirony where each token is also annotated with a language tag. We present a\nbaseline su- pervised classification system developed using the same dataset\nwhich achieves an average F-score of 78.4 after using random forest classifier\nand performing 10-fold cross validation.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 09:08:54 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Swami", "Sahil", ""], ["Khandelwal", "Ankush", ""], ["Singh", "Vinay", ""], ["Akhtar", "Syed Sarfaraz", ""], ["Shrivastava", "Manish", ""]]}, {"id": "1805.11937", "submitter": "G\\\"ozde G\\\"ul \\c{S}ahin", "authors": "G\\\"ozde G\\\"ul \\c{S}ahin and Mark Steedman", "title": "Character-Level Models versus Morphology in Semantic Role Labeling", "comments": "Accepted for publication at the 56th Annual Meeting of the\n  Association for Computational Linguistics (ACL 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Character-level models have become a popular approach specially for their\naccessibility and ability to handle unseen data. However, little is known on\ntheir ability to reveal the underlying morphological structure of a word, which\nis a crucial skill for high-level semantic analysis tasks, such as semantic\nrole labeling (SRL). In this work, we train various types of SRL models that\nuse word, character and morphology level information and analyze how\nperformance of characters compare to words and morphology for several\nlanguages. We conduct an in-depth error analysis for each morphological\ntypology and analyze the strengths and limitations of character-level models\nthat relate to out-of-domain data, training data size, long range dependencies\nand model complexity. Our exhaustive analyses shed light on important\ncharacteristics of character-level models and their semantic capability.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 13:22:02 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["\u015eahin", "G\u00f6zde G\u00fcl", ""], ["Steedman", "Mark", ""]]}, {"id": "1805.12032", "submitter": "Maria Glenski", "authors": "Maria Glenski, Tim Weninger, and Svitlana Volkova", "title": "Identifying and Understanding User Reactions to Deceptive and Trusted\n  Social News Sources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the age of social news, it is important to understand the types of\nreactions that are evoked from news sources with various levels of credibility.\nIn the present work we seek to better understand how users react to trusted and\ndeceptive news sources across two popular, and very different, social media\nplatforms. To that end, (1) we develop a model to classify user reactions into\none of nine types, such as answer, elaboration, and question, etc, and (2) we\nmeasure the speed and the type of reaction for trusted and deceptive news\nsources for 10.8M Twitter posts and 6.2M Reddit comments. We show that there\nare significant differences in the speed and the type of reactions between\ntrusted and deceptive news sources on Twitter, but far smaller differences on\nReddit.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 15:20:14 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Glenski", "Maria", ""], ["Weninger", "Tim", ""], ["Volkova", "Svitlana", ""]]}, {"id": "1805.12045", "submitter": "Yannick Est\\`eve", "authors": "Sahar Ghannay and Antoine Caubri\\`ere and Yannick Est\\`eve and Antoine\n  Laurent and Emmanuel Morin", "title": "End-to-end named entity extraction from speech", "comments": "Submitted to Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity recognition (NER) is among SLU tasks that usually extract\nsemantic information from textual documents. Until now, NER from speech is made\nthrough a pipeline process that consists in processing first an automatic\nspeech recognition (ASR) on the audio and then processing a NER on the ASR\noutputs. Such approach has some disadvantages (error propagation, metric to\ntune ASR systems sub-optimal in regards to the final task, reduced space search\nat the ASR output level...) and it is known that more integrated approaches\noutperform sequential ones, when they can be applied. In this paper, we present\na first study of end-to-end approach that directly extracts named entities from\nspeech, though a unique neural architecture. On a such way, a joint\noptimization is able for both ASR and NER. Experiments are carried on French\ndata easily accessible, composed of data distributed in several evaluation\ncampaign. Experimental results show that this end-to-end approach provides\nbetter results (F-measure=0.69 on test data) than a classical pipeline approach\nto detect named entity categories (F-measure=0.65).\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 15:56:22 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Ghannay", "Sahar", ""], ["Caubri\u00e8re", "Antoine", ""], ["Est\u00e8ve", "Yannick", ""], ["Laurent", "Antoine", ""], ["Morin", "Emmanuel", ""]]}, {"id": "1805.12061", "submitter": "Genta Indra Winata", "authors": "Genta Indra Winata, Chien-Sheng Wu, Andrea Madotto, Pascale Fung", "title": "Bilingual Character Representation for Efficiently Addressing\n  Out-of-Vocabulary Words in Code-Switching Named Entity Recognition", "comments": "Accepted in \"3rd Workshop in Computational Approaches in Linguistic\n  Code-switching\", ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an LSTM-based model with hierarchical architecture on named entity\nrecognition from code-switching Twitter data. Our model uses bilingual\ncharacter representation and transfer learning to address out-of-vocabulary\nwords. In order to mitigate data noise, we propose to use token replacement and\nnormalization. In the 3rd Workshop on Computational Approaches to Linguistic\nCode-Switching Shared Task, we achieved second place with 62.76% harmonic mean\nF1-score for English-Spanish language pair without using any gazetteer and\nknowledge-based information.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 16:29:32 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 14:43:38 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Winata", "Genta Indra", ""], ["Wu", "Chien-Sheng", ""], ["Madotto", "Andrea", ""], ["Fung", "Pascale", ""]]}, {"id": "1805.12070", "submitter": "Genta Indra Winata", "authors": "Genta Indra Winata, Andrea Madotto, Chien-Sheng Wu, Pascale Fung", "title": "Code-Switching Language Modeling using Syntax-Aware Multi-Task Learning", "comments": "Accepted in 3rd Workshop in Computational Approaches in Linguistic\n  Code-switching, ACL 2018 with Supplementary Materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lack of text data has been the major issue on code-switching language\nmodeling. In this paper, we introduce multi-task learning based language model\nwhich shares syntax representation of languages to leverage linguistic\ninformation and tackle the low resource data issue. Our model jointly learns\nboth language modeling and Part-of-Speech tagging on code-switched utterances.\nIn this way, the model is able to identify the location of code-switching\npoints and improves the prediction of next word. Our approach outperforms\nstandard LSTM based language model, with an improvement of 9.7% and 7.4% in\nperplexity on SEAME Phase I and Phase II dataset respectively.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 16:37:43 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 04:52:52 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Winata", "Genta Indra", ""], ["Madotto", "Andrea", ""], ["Wu", "Chien-Sheng", ""], ["Fung", "Pascale", ""]]}, {"id": "1805.12096", "submitter": "Marcin Junczys-Dowmunt", "authors": "Marcin Junczys-Dowmunt, Kenneth Heafield, Hieu Hoang, Roman\n  Grundkiewicz, Anthony Aue", "title": "Marian: Cost-effective High-Quality Neural Machine Translation in C++", "comments": "System submission to the Workshop for Neural Machine Translation\n  2018, efficiency task", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the submissions of the \"Marian\" team to the WNMT 2018\nshared task. We investigate combinations of teacher-student training,\nlow-precision matrix products, auto-tuning and other methods to optimize the\nTransformer model on GPU and CPU. By further integrating these methods with the\nnew averaging attention networks, a recently introduced faster Transformer\nvariant, we create a number of high-quality, high-performance models on the GPU\nand CPU, dominating the Pareto frontier for this shared task.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 17:23:24 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Junczys-Dowmunt", "Marcin", ""], ["Heafield", "Kenneth", ""], ["Hoang", "Hieu", ""], ["Grundkiewicz", "Roman", ""], ["Aue", "Anthony", ""]]}, {"id": "1805.12115", "submitter": "Mehwish Alam Miss", "authors": "Aldo Gangemi, Mehwish Alam, Valentina Presutti", "title": "Amnestic Forgery: an Ontology of Conceptual Metaphors", "comments": null, "journal-ref": null, "doi": "10.3233/978-1-61499-910-2-159", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents Amnestic Forgery, an ontology for metaphor semantics,\nbased on MetaNet, which is inspired by the theory of Conceptual Metaphor.\nAmnestic Forgery reuses and extends the Framester schema, as an ideal ontology\ndesign framework to deal with both semiotic and referential aspects of frames,\nroles, mappings, and eventually blending. The description of the resource is\nsupplied by a discussion of its applications, with examples taken from metaphor\ngeneration, and the referential problems of metaphoric mappings. Both schema\nand data are available from the Framester SPARQL endpoint.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 17:56:32 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Gangemi", "Aldo", ""], ["Alam", "Mehwish", ""], ["Presutti", "Valentina", ""]]}, {"id": "1805.12164", "submitter": "Carl Allen", "authors": "Carl Allen, Ivana Bala\\v{z}evi\\'c, Timothy Hospedales", "title": "What the Vec? Towards Probabilistically Grounded Embeddings", "comments": "Advances in Neural Information Processing, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word2Vec (W2V) and GloVe are popular, fast and efficient word embedding\nalgorithms. Their embeddings are widely used and perform well on a variety of\nnatural language processing tasks. Moreover, W2V has recently been adopted in\nthe field of graph embedding, where it underpins several leading algorithms.\nHowever, despite their ubiquity and relatively simple model architecture, a\ntheoretical understanding of what the embedding parameters of W2V and GloVe\nlearn and why that is useful in downstream tasks has been lacking. We show that\ndifferent interactions between PMI vectors reflect semantic word relationships,\nsuch as similarity and paraphrasing, that are encoded in low dimensional word\nembeddings under a suitable projection, theoretically explaining why embeddings\nof W2V and GloVe work. As a consequence, we also reveal an interesting\nmathematical interconnection between the considered semantic relationships\nthemselves.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 18:19:38 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 14:38:29 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2019 15:11:25 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Allen", "Carl", ""], ["Bala\u017eevi\u0107", "Ivana", ""], ["Hospedales", "Timothy", ""]]}, {"id": "1805.12216", "submitter": "Zhihong (Iris) Shen", "authors": "Zhihong Shen, Hao Ma, Kuansan Wang", "title": "A Web-scale system for scientific knowledge exploration", "comments": "6 pages, accepted for ACL 2018 demo paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To enable efficient exploration of Web-scale scientific knowledge, it is\nnecessary to organize scientific publications into a hierarchical concept\nstructure. In this work, we present a large-scale system to (1) identify\nhundreds of thousands of scientific concepts, (2) tag these identified concepts\nto hundreds of millions of scientific publications by leveraging both text and\ngraph structure, and (3) build a six-level concept hierarchy with a\nsubsumption-based model. The system builds the most comprehensive cross-domain\nscientific concept ontology published to date, with more than 200 thousand\nconcepts and over one million relationships.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 20:28:36 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Shen", "Zhihong", ""], ["Ma", "Hao", ""], ["Wang", "Kuansan", ""]]}, {"id": "1805.12282", "submitter": "Huda Khayrallah", "authors": "Huda Khayrallah, Philipp Koehn", "title": "On the Impact of Various Types of Noise on Neural Machine Translation", "comments": "Please cite as: @InProceedings{khayrallah-koehn:2018:WNMT, author =\n  {Khayrallah, Huda and Koehn, Philipp}, title = {On the Impact of Various\n  Types of Noise on Neural Machine Translation}, booktitle = {Proceedings of\n  the Second Workshop on Neural Machine Translation and Generation}, year =\n  {2018}, address = {Melbourne}, publisher = {Association for Computational\n  Linguistics} }", "journal-ref": null, "doi": "10.18653/v1/W18-2709", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine how various types of noise in the parallel training data impact\nthe quality of neural machine translation systems. We create five types of\nartificial noise and analyze how they degrade performance in neural and\nstatistical machine translation. We find that neural models are generally more\nharmed by noise than statistical models. For one especially egregious type of\nnoise they learn to just copy the input sentence.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 01:33:19 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Khayrallah", "Huda", ""], ["Koehn", "Philipp", ""]]}, {"id": "1805.12291", "submitter": "Kemal Kurniawan", "authors": "Kemal Kurniawan and Samuel Louvan", "title": "Empirical Evaluation of Character-Based Model on Neural Named-Entity\n  Recognition in Indonesian Conversational Texts", "comments": "Accepted in EMNLP 2018 Workshop on Noisy User-generated Text (W-NUT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the long history of named-entity recognition (NER) task in the\nnatural language processing community, previous work rarely studied the task on\nconversational texts. Such texts are challenging because they contain a lot of\nword variations which increase the number of out-of-vocabulary (OOV) words. The\nhigh number of OOV words poses a difficulty for word-based neural models.\nMeanwhile, there is plenty of evidence to the effectiveness of character-based\nneural models in mitigating this OOV problem. We report an empirical evaluation\nof neural sequence labeling models with character embedding to tackle NER task\nin Indonesian conversational texts. Our experiments show that (1) character\nmodels outperform word embedding-only models by up to 4 $F_1$ points, (2)\ncharacter models perform better in OOV cases with an improvement of as high as\n15 $F_1$ points, and (3) character models are robust against a very high OOV\nrate.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 02:21:39 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 08:22:58 GMT"}, {"version": "v3", "created": "Wed, 19 Sep 2018 08:13:38 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Kurniawan", "Kemal", ""], ["Louvan", "Samuel", ""]]}, {"id": "1805.12307", "submitter": "Genta Indra Winata", "authors": "Genta Indra Winata, Onno Pepijn Kampman, Pascale Fung", "title": "Attention-Based LSTM for Psychological Stress Detection from Spoken\n  Language Using Distant Supervision", "comments": "Accepted in ICASSP 2018", "journal-ref": null, "doi": "10.1109/ICASSP.2018.8461990", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Long Short-Term Memory (LSTM) with attention mechanism to\nclassify psychological stress from self-conducted interview transcriptions. We\napply distant supervision by automatically labeling tweets based on their\nhashtag content, which complements and expands the size of our corpus. This\nadditional data is used to initialize the model parameters, and which it is\nfine-tuned using the interview data. This improves the model's robustness,\nespecially by expanding the vocabulary size. The bidirectional LSTM model with\nattention is found to be the best model in terms of accuracy (74.1%) and\nf-score (74.3%). Furthermore, we show that distant supervision fine-tuning\nenhances the model's performance by 1.6% accuracy and 2.1% f-score. The\nattention mechanism helps the model to select informative words.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 03:27:53 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Winata", "Genta Indra", ""], ["Kampman", "Onno Pepijn", ""], ["Fung", "Pascale", ""]]}, {"id": "1805.12316", "submitter": "Puyudi Yang", "authors": "Puyudi Yang, Jianbo Chen, Cho-Jui Hsieh, Jane-Ling Wang, Michael I.\n  Jordan", "title": "Greedy Attack and Gumbel Attack: Generating Adversarial Examples for\n  Discrete Data", "comments": "The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a probabilistic framework for studying adversarial attacks on\ndiscrete data. Based on this framework, we derive a perturbation-based method,\nGreedy Attack, and a scalable learning-based method, Gumbel Attack, that\nillustrate various tradeoffs in the design of attacks. We demonstrate the\neffectiveness of these methods using both quantitative metrics and human\nevaluation on various state-of-the-art models for text classification,\nincluding a word-based CNN, a character-based CNN and an LSTM. As as example of\nour results, we show that the accuracy of character-based convolutional\nnetworks drops to the level of random selection by modifying only five\ncharacters through Greedy Attack.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 04:40:32 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Yang", "Puyudi", ""], ["Chen", "Jianbo", ""], ["Hsieh", "Cho-Jui", ""], ["Wang", "Jane-Ling", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1805.12352", "submitter": "Xiaodong Gu", "authors": "Xiaodong Gu, Kyunghyun Cho, Jung-Woo Ha, Sunghun Kim", "title": "DialogWAE: Multimodal Response Generation with Conditional Wasserstein\n  Auto-Encoder", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders~(VAEs) have shown a promise in data-driven\nconversation modeling. However, most VAE conversation models match the\napproximate posterior distribution over the latent variables to a simple prior\nsuch as standard normal distribution, thereby restricting the generated\nresponses to a relatively simple (e.g., unimodal) scope. In this paper, we\npropose DialogWAE, a conditional Wasserstein autoencoder~(WAE) specially\ndesigned for dialogue modeling. Unlike VAEs that impose a simple distribution\nover the latent variables, DialogWAE models the distribution of data by\ntraining a GAN within the latent variable space. Specifically, our model\nsamples from the prior and posterior distributions over the latent variables by\ntransforming context-dependent random noise using neural networks and minimizes\nthe Wasserstein distance between the two distributions. We further develop a\nGaussian mixture prior network to enrich the latent space. Experiments on two\npopular datasets show that DialogWAE outperforms the state-of-the-art\napproaches in generating more coherent, informative and diverse responses.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 07:25:04 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 02:32:44 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Gu", "Xiaodong", ""], ["Cho", "Kyunghyun", ""], ["Ha", "Jung-Woo", ""], ["Kim", "Sunghun", ""]]}, {"id": "1805.12386", "submitter": "Daniel Hershcovich", "authors": "Daniel Hershcovich, Leshem Choshen, Elior Sulem, Zohar Aizenbud, Ari\n  Rappoport and Omri Abend", "title": "SemEval 2019 Shared Task: Cross-lingual Semantic Parsing with UCCA -\n  Call for Participation", "comments": "Not an actual paper. The shared task summary is at arXiv:1903.02953", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We announce a shared task on UCCA parsing in English, German and French, and\ncall for participants to submit their systems. UCCA is a cross-linguistically\napplicable framework for semantic representation, which builds on extensive\ntypological work and supports rapid annotation. UCCA poses a challenge for\nexisting parsing techniques, as it exhibits reentrancy (resulting in DAG\nstructures), discontinuous structures and non-terminal nodes corresponding to\ncomplex semantic units. Given the success of recent semantic parsing shared\ntasks (on SDP and AMR), we expect the task to have a significant contribution\nto the advancement of UCCA parsing in particular, and semantic parsing in\ngeneral. Furthermore, existing applications for semantic evaluation that are\nbased on UCCA will greatly benefit from better automatic methods for UCCA\nparsing. The competition website is\nhttps://competitions.codalab.org/competitions/19160\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 09:11:16 GMT"}, {"version": "v2", "created": "Sun, 19 Aug 2018 11:25:34 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 12:58:22 GMT"}, {"version": "v4", "created": "Wed, 3 Feb 2021 10:30:22 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Hershcovich", "Daniel", ""], ["Choshen", "Leshem", ""], ["Sulem", "Elior", ""], ["Aizenbud", "Zohar", ""], ["Rappoport", "Ari", ""], ["Abend", "Omri", ""]]}, {"id": "1805.12393", "submitter": "Yuyu Zhang", "authors": "Yuyu Zhang, Hanjun Dai, Kamil Toraman, Le Song", "title": "KG^2: Learning to Reason Science Exam Questions with Contextual\n  Knowledge Graph Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The AI2 Reasoning Challenge (ARC), a new benchmark dataset for question\nanswering (QA) has been recently released. ARC only contains natural science\nquestions authored for human exams, which are hard to answer and require\nadvanced logic reasoning. On the ARC Challenge Set, existing state-of-the-art\nQA systems fail to significantly outperform random baseline, reflecting the\ndifficult nature of this task. In this paper, we propose a novel framework for\nanswering science exam questions, which mimics human solving process in an\nopen-book exam. To address the reasoning challenge, we construct contextual\nknowledge graphs respectively for the question itself and supporting sentences.\nOur model learns to reason with neural embeddings of both knowledge graphs.\nExperiments on the ARC Challenge Set show that our model outperforms the\nprevious state-of-the-art QA systems.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 09:39:14 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Zhang", "Yuyu", ""], ["Dai", "Hanjun", ""], ["Toraman", "Kamil", ""], ["Song", "Le", ""]]}, {"id": "1805.12471", "submitter": "Alex Warstadt", "authors": "Alex Warstadt, Amanpreet Singh, Samuel R. Bowman", "title": "Neural Network Acceptability Judgments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the ability of artificial neural networks to judge\nthe grammatical acceptability of a sentence, with the goal of testing their\nlinguistic competence. We introduce the Corpus of Linguistic Acceptability\n(CoLA), a set of 10,657 English sentences labeled as grammatical or\nungrammatical from published linguistics literature. As baselines, we train\nseveral recurrent neural network models on acceptability classification, and\nfind that our models outperform unsupervised models by Lau et al (2016) on\nCoLA. Error-analysis on specific grammatical phenomena reveals that both Lau et\nal.'s models and ours learn systematic generalizations like subject-verb-object\norder. However, all models we test perform far below human level on a wide\nrange of grammatical constructions.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 13:52:06 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 03:34:37 GMT"}, {"version": "v3", "created": "Tue, 1 Oct 2019 18:41:05 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Warstadt", "Alex", ""], ["Singh", "Amanpreet", ""], ["Bowman", "Samuel R.", ""]]}, {"id": "1805.12501", "submitter": "Li Zhang", "authors": "Li Zhang, Steven R. Wilson, Rada Mihalcea", "title": "Multi-Label Transfer Learning for Multi-Relational Semantic Similarity", "comments": "Accepted to *SEM 2019", "journal-ref": "Proceedings of the Eighth Joint Conference on Lexical and\n  Computational Semantics (SEM 2019) (2019) 44-50", "doi": "10.18653/v1/S19-1005", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-relational semantic similarity datasets define the semantic relations\nbetween two short texts in multiple ways, e.g., similarity, relatedness, and so\non. Yet, all the systems to date designed to capture such relations target one\nrelation at a time. We propose a multi-label transfer learning approach based\non LSTM to make predictions for several relations simultaneously and aggregate\nthe losses to update the parameters. This multi-label regression approach\njointly learns the information provided by the multiple relations, rather than\ntreating them as separate tasks. Not only does this approach outperform the\nsingle-task approach and the traditional multi-task learning approach, but it\nalso achieves state-of-the-art performance on all but one relation of the Human\nActivity Phrase dataset.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 14:54:33 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 04:07:32 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Zhang", "Li", ""], ["Wilson", "Steven R.", ""], ["Mihalcea", "Rada", ""]]}, {"id": "1805.12518", "submitter": "Arne K\\\"ohn", "authors": "Arne K\\\"ohn", "title": "Incremental Natural Language Processing: Challenges, Strategies, and\n  Evaluation", "comments": "COLING 2018 (accepted), camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Incrementality is ubiquitous in human-human interaction and beneficial for\nhuman-computer interaction. It has been a topic of research in different parts\nof the NLP community, mostly with focus on the specific topic at hand even\nthough incremental systems have to deal with similar challenges regardless of\ndomain. In this survey, I consolidate and categorize the approaches,\nidentifying similarities and differences in the computation and data, and show\ntrade-offs that have to be considered. A focus lies on evaluating incremental\nsystems because the standard metrics often fail to capture the incremental\nproperties of a system and coming up with a suitable evaluation scheme is\nnon-trivial.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 15:29:32 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2018 08:04:51 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["K\u00f6hn", "Arne", ""]]}]