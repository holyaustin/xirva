[{"id": "1708.00055", "submitter": "Daniel Cer", "authors": "Daniel Cer, Mona Diab, Eneko Agirre, I\\~nigo Lopez-Gazpio and Lucia\n  Specia", "title": "SemEval-2017 Task 1: Semantic Textual Similarity - Multilingual and\n  Cross-lingual Focused Evaluation", "comments": "To appear in proceedings of the SemEval workshop at ACL 2017; 14\n  pages, 14 Tables, 1 Figure", "journal-ref": null, "doi": "10.18653/v1/S17-2001", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic Textual Similarity (STS) measures the meaning similarity of\nsentences. Applications include machine translation (MT), summarization,\ngeneration, question answering (QA), short answer grading, semantic search,\ndialog and conversational systems. The STS shared task is a venue for assessing\nthe current state-of-the-art. The 2017 task focuses on multilingual and\ncross-lingual pairs with one sub-track exploring MT quality estimation (MTQE)\ndata. The task obtained strong participation from 31 teams, with 17\nparticipating in all language tracks. We summarize performance and review a\nselection of well performing methods. Analysis highlights common errors,\nproviding insight into the limitations of existing models. To support ongoing\nwork on semantic representations, the STS Benchmark is introduced as a new\nshared training and evaluation set carefully selected from the corpus of\nEnglish STS shared task data (2012-2017).\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 20:12:06 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Cer", "Daniel", ""], ["Diab", "Mona", ""], ["Agirre", "Eneko", ""], ["Lopez-Gazpio", "I\u00f1igo", ""], ["Specia", "Lucia", ""]]}, {"id": "1708.00077", "submitter": "Ekaterina Lobacheva Ms", "authors": "Ekaterina Lobacheva, Nadezhda Chirkova, Dmitry Vetrov", "title": "Bayesian Sparsification of Recurrent Neural Networks", "comments": "Published in Workshop on Learning to Generate Natural Language, ICML,\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks show state-of-the-art results in many text analysis\ntasks but often require a lot of memory to store their weights. Recently\nproposed Sparse Variational Dropout eliminates the majority of the weights in a\nfeed-forward neural network without significant loss of quality. We apply this\ntechnique to sparsify recurrent neural networks. To account for recurrent\nspecifics we also rely on Binary Variational Dropout for RNN. We report 99.5%\nsparsity level on sentiment analysis task without a quality drop and up to 87%\nsparsity level on language modeling task with slight loss of accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 21:33:42 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Lobacheva", "Ekaterina", ""], ["Chirkova", "Nadezhda", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1708.00098", "submitter": "Kyle Richardson", "authors": "Kyle Richardson, Sina Zarrie{\\ss} and Jonas Kuhn", "title": "The Code2Text Challenge: Text Generation in Source Code Libraries", "comments": "Proceedings of INLG 2017, shared task track", "journal-ref": null, "doi": "10.18653/v1/W17-3516", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new shared task for tactical data-to-text generation in the\ndomain of source code libraries. Specifically, we focus on text generation of\nfunction descriptions from example software projects. Data is drawn from\nexisting resources used for studying the related problem of semantic parser\ninduction (Richardson and Kuhn, 2017b; Richardson and Kuhn, 2017a), and spans a\nwide variety of both natural languages and programming languages. In this\npaper, we describe these existing resources, which will serve as training and\ndevelopment data for the task, and discuss plans for building new independent\ntest sets.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 23:29:41 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Richardson", "Kyle", ""], ["Zarrie\u00df", "Sina", ""], ["Kuhn", "Jonas", ""]]}, {"id": "1708.00107", "submitter": "Bryan McCann", "authors": "Bryan McCann, James Bradbury, Caiming Xiong and Richard Socher", "title": "Learned in Translation: Contextualized Word Vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer vision has benefited from initializing multiple deep layers with\nweights pretrained on large supervised training sets like ImageNet. Natural\nlanguage processing (NLP) typically sees initialization of only the lowest\nlayer of deep models with pretrained word vectors. In this paper, we use a deep\nLSTM encoder from an attentional sequence-to-sequence model trained for machine\ntranslation (MT) to contextualize word vectors. We show that adding these\ncontext vectors (CoVe) improves performance over using only unsupervised word\nand character vectors on a wide variety of common NLP tasks: sentiment analysis\n(SST, IMDb), question classification (TREC), entailment (SNLI), and question\nanswering (SQuAD). For fine-grained sentiment analysis and entailment, CoVe\nimproves performance of our baseline models to the state of the art.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 00:05:34 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 13:15:06 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["McCann", "Bryan", ""], ["Bradbury", "James", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1708.00111", "submitter": "Kartik Goyal", "authors": "Kartik Goyal, Graham Neubig, Chris Dyer and Taylor Berg-Kirkpatrick", "title": "A Continuous Relaxation of Beam Search for End-to-end Training of Neural\n  Sequence Models", "comments": "Updated for clarity and notational consistency", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beam search is a desirable choice of test-time decoding algorithm for neural\nsequence models because it potentially avoids search errors made by simpler\ngreedy methods. However, typical cross entropy training procedures for these\nmodels do not directly consider the behaviour of the final decoding method. As\na result, for cross-entropy trained models, beam decoding can sometimes yield\nreduced test performance when compared with greedy decoding. In order to train\nmodels that can more effectively make use of beam search, we propose a new\ntraining procedure that focuses on the final loss metric (e.g. Hamming loss)\nevaluated on the output of beam search. While well-defined, this \"direct loss\"\nobjective is itself discontinuous and thus difficult to optimize. Hence, in our\napproach, we form a sub-differentiable surrogate objective by introducing a\nnovel continuous approximation of the beam search decoding procedure. In\nexperiments, we show that optimizing this new training objective yields\nsubstantially better results on two sequence tasks (Named Entity Recognition\nand CCG Supertagging) when compared with both cross entropy trained greedy\ndecoding and cross entropy trained beam decoding baselines.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 00:16:08 GMT"}, {"version": "v2", "created": "Fri, 6 Oct 2017 19:29:30 GMT"}], "update_date": "2017-10-10", "authors_parsed": [["Goyal", "Kartik", ""], ["Neubig", "Graham", ""], ["Dyer", "Chris", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}, {"id": "1708.00112", "submitter": "Benjamin Lengerich", "authors": "Benjamin J. Lengerich, Andrew L. Maas, Christopher Potts", "title": "Retrofitting Distributional Embeddings to Knowledge Graphs with\n  Functional Relations", "comments": "COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs are a versatile framework to encode richly structured data\nrelationships, but it can be challenging to combine these graphs with\nunstructured data. Methods for retrofitting pre-trained entity representations\nto the structure of a knowledge graph typically assume that entities are\nembedded in a connected space and that relations imply similarity. However,\nuseful knowledge graphs often contain diverse entities and relations (with\npotentially disjoint underlying corpora) which do not accord with these\nassumptions. To overcome these limitations, we present Functional Retrofitting,\na framework that generalizes current retrofitting methods by explicitly\nmodeling pairwise relations. Our framework can directly incorporate a variety\nof pairwise penalty functions previously developed for knowledge graph\ncompletion. Further, it allows users to encode, learn, and extract information\nabout relation semantics. We present both linear and neural instantiations of\nthe framework. Functional Retrofitting significantly outperforms existing\nretrofitting methods on complex knowledge graphs and loses no accuracy on\nsimpler graphs (in which relations do imply similarity). Finally, we\ndemonstrate the utility of the framework by predicting new drug--disease\ntreatment pairs in a large, complex health knowledge graph.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 00:23:03 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 18:13:26 GMT"}, {"version": "v3", "created": "Sat, 16 Jun 2018 13:01:49 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Lengerich", "Benjamin J.", ""], ["Maas", "Andrew L.", ""], ["Potts", "Christopher", ""]]}, {"id": "1708.00133", "submitter": "Karthik Narasimhan", "authors": "Karthik Narasimhan, Regina Barzilay and Tommi Jaakkola", "title": "Grounding Language for Transfer in Deep Reinforcement Learning", "comments": "JAIR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore the utilization of natural language to drive\ntransfer for reinforcement learning (RL). Despite the wide-spread application\nof deep RL techniques, learning generalized policy representations that work\nacross domains remains a challenging problem. We demonstrate that textual\ndescriptions of environments provide a compact intermediate channel to\nfacilitate effective policy transfer. Specifically, by learning to ground the\nmeaning of text to the dynamics of the environment such as transitions and\nrewards, an autonomous agent can effectively bootstrap policy learning on a new\ndomain given its description. We employ a model-based RL approach consisting of\na differentiable planning module, a model-free component and a factorized state\nrepresentation to effectively use entity descriptions. Our model outperforms\nprior work on both transfer and multi-task scenarios in a variety of different\nenvironments. For instance, we achieve up to 14% and 11.5% absolute improvement\nover previously existing models in terms of average and initial rewards,\nrespectively.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 02:20:00 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 22:14:04 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Narasimhan", "Karthik", ""], ["Barzilay", "Regina", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "1708.00154", "submitter": "Piji Li", "authors": "Piji Li, Zihao Wang, Zhaochun Ren, Lidong Bing, Wai Lam", "title": "Neural Rating Regression with Abstractive Tips Generation for\n  Recommendation", "comments": "SIGIR 2017", "journal-ref": null, "doi": "10.1145/3077136.3080822", "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, some E-commerce sites launch a new interaction box called Tips on\ntheir mobile apps. Users can express their experience and feelings or provide\nsuggestions using short texts typically several words or one sentence. In\nessence, writing some tips and giving a numerical rating are two facets of a\nuser's product assessment action, expressing the user experience and feelings.\nJointly modeling these two facets is helpful for designing a better\nrecommendation system. While some existing models integrate text information\nsuch as item specifications or user reviews into user and item latent factors\nfor improving the rating prediction, no existing works consider tips for\nimproving recommendation quality. We propose a deep learning based framework\nnamed NRT which can simultaneously predict precise ratings and generate\nabstractive tips with good linguistic quality simulating user experience and\nfeelings. For abstractive tips generation, gated recurrent neural networks are\nemployed to \"translate\" user and item latent representations into a concise\nsentence. Extensive experiments on benchmark datasets from different domains\nshow that NRT achieves significant improvements over the state-of-the-art\nmethods. Moreover, the generated tips can vividly predict the user experience\nand feelings.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 04:25:17 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Li", "Piji", ""], ["Wang", "Zihao", ""], ["Ren", "Zhaochun", ""], ["Bing", "Lidong", ""], ["Lam", "Wai", ""]]}, {"id": "1708.00160", "submitter": "Nafise Sadat Moosavi", "authors": "Nafise Sadat Moosavi and Michael Strube", "title": "Using Linguistic Features to Improve the Generalization Capability of\n  Neural Coreference Resolvers", "comments": "EMNLP 2018 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coreference resolution is an intermediate step for text understanding. It is\nused in tasks and domains for which we do not necessarily have coreference\nannotated corpora. Therefore, generalization is of special importance for\ncoreference resolution. However, while recent coreference resolvers have\nnotable improvements on the CoNLL dataset, they struggle to generalize properly\nto new domains or datasets. In this paper, we investigate the role of\nlinguistic features in building more generalizable coreference resolvers. We\nshow that generalization improves only slightly by merely using a set of\nadditional linguistic features. However, employing features and subsets of\ntheir values that are informative for coreference resolution, considerably\nimproves generalization. Thanks to better generalization, our system achieves\nstate-of-the-art results in out-of-domain evaluations, e.g., on WikiCoref, our\nsystem, which is trained on CoNLL, achieves on-par performance with a system\ndesigned for this dataset.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 05:09:34 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 09:20:53 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Moosavi", "Nafise Sadat", ""], ["Strube", "Michael", ""]]}, {"id": "1708.00179", "submitter": "Emily Sheng", "authors": "Emily Sheng, Prem Natarajan, Jonathan Gordon, and Gully Burns", "title": "An Investigation into the Pedagogical Features of Documents", "comments": "12th Workshop on Innovative Use of NLP for Building Educational\n  Applications (BEA) at EMNLP 2017; 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterizing the content of a technical document in terms of its learning\nutility can be useful for applications related to education, such as generating\nreading lists from large collections of documents. We refer to this learning\nutility as the \"pedagogical value\" of the document to the learner. While\npedagogical value is an important concept that has been studied extensively\nwithin the education domain, there has been little work exploring it from a\ncomputational, i.e., natural language processing (NLP), perspective. To allow a\ncomputational exploration of this concept, we introduce the notion of\n\"pedagogical roles\" of documents (e.g., Tutorial and Survey) as an intermediary\ncomponent for the study of pedagogical value. Given the lack of available\ncorpora for our exploration, we create the first annotated corpus of\npedagogical roles and use it to test baseline techniques for automatic\nprediction of such roles.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 06:35:24 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Sheng", "Emily", ""], ["Natarajan", "Prem", ""], ["Gordon", "Jonathan", ""], ["Burns", "Gully", ""]]}, {"id": "1708.00214", "submitter": "Jan Botha", "authors": "Jan A. Botha, Emily Pitler, Ji Ma, Anton Bakalov, Alex Salcianu, David\n  Weiss, Ryan McDonald, Slav Petrov", "title": "Natural Language Processing with Small Feed-Forward Networks", "comments": "EMNLP 2017 short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that small and shallow feed-forward neural networks can achieve near\nstate-of-the-art results on a range of unstructured and structured language\nprocessing tasks while being considerably cheaper in memory and computational\nrequirements than deep recurrent models. Motivated by resource-constrained\nenvironments like mobile phones, we showcase simple techniques for obtaining\nsuch small neural network models, and investigate different tradeoffs when\ndeciding how to allocate a small memory budget.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 09:13:44 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Botha", "Jan A.", ""], ["Pitler", "Emily", ""], ["Ma", "Ji", ""], ["Bakalov", "Anton", ""], ["Salcianu", "Alex", ""], ["Weiss", "David", ""], ["McDonald", "Ryan", ""], ["Petrov", "Slav", ""]]}, {"id": "1708.00241", "submitter": "Vishaal Jatav", "authors": "Vishaal Jatav, Ravi Teja, Srini Bharadwaj and Venkat Srinivasan", "title": "Improving Part-of-Speech Tagging for NLP Pipelines", "comments": "Computational Linguistics, Natural Language Understanding, RAGE AI,\n  Part-of-Speech Tagging, Evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper outlines the results of sentence level linguistics based rules for\nimproving part-of-speech tagging. It is well known that the performance of\ncomplex NLP systems is negatively affected if one of the preliminary stages is\nless than perfect. Errors in the initial stages in the pipeline have a\nsnowballing effect on the pipeline's end performance. We have created a set of\nlinguistics based rules at the sentence level which adjust part-of-speech tags\nfrom state-of-the-art taggers. Comparison with state-of-the-art taggers on\nwidely used benchmarks demonstrate significant improvements in tagging accuracy\nand consequently in the quality and accuracy of NLP systems.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 10:56:17 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Jatav", "Vishaal", ""], ["Teja", "Ravi", ""], ["Bharadwaj", "Srini", ""], ["Srinivasan", "Venkat", ""]]}, {"id": "1708.00308", "submitter": "Igor Melnyk", "authors": "Ramesh Nallapati, Igor Melnyk, Abhishek Kumar and Bowen Zhou", "title": "SenGen: Sentence Generating Neural Variational Topic Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new topic model that generates documents by sampling a topic for\none whole sentence at a time, and generating the words in the sentence using an\nRNN decoder that is conditioned on the topic of the sentence. We argue that\nthis novel formalism will help us not only visualize and model the topical\ndiscourse structure in a document better, but also potentially lead to more\ninterpretable topics since we can now illustrate topics by sampling\nrepresentative sentences instead of bag of words or phrases. We present a\nvariational auto-encoder approach for learning in which we use a factorized\nvariational encoder that independently models the posterior over topical\nmixture vectors of documents using a feed-forward network, and the posterior\nover topic assignments to sentences using an RNN. Our preliminary experiments\non two different datasets indicate early promise, but also expose many\nchallenges that remain to be addressed.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 13:31:24 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Nallapati", "Ramesh", ""], ["Melnyk", "Igor", ""], ["Kumar", "Abhishek", ""], ["Zhou", "Bowen", ""]]}, {"id": "1708.00391", "submitter": "Wuwei Lan", "authors": "Wuwei Lan, Siyu Qiu, Hua He and Wei Xu", "title": "A Continuously Growing Dataset of Sentential Paraphrases", "comments": "11 pages, accepted to EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in paraphrase research is the lack of parallel corpora. In\nthis paper, we present a new method to collect large-scale sentential\nparaphrases from Twitter by linking tweets through shared URLs. The main\nadvantage of our method is its simplicity, as it gets rid of the classifier or\nhuman in the loop needed to select data before annotation and subsequent\napplication of paraphrase identification algorithms in the previous work. We\npresent the largest human-labeled paraphrase corpus to date of 51,524 sentence\npairs and the first cross-domain benchmarking for automatic paraphrase\nidentification. In addition, we show that more than 30,000 new sentential\nparaphrases can be easily and continuously captured every month at ~70%\nprecision, and demonstrate their utility for downstream NLP tasks through\nphrasal paraphrase extraction. We make our code and data freely available.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 15:41:51 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Lan", "Wuwei", ""], ["Qiu", "Siyu", ""], ["He", "Hua", ""], ["Xu", "Wei", ""]]}, {"id": "1708.00415", "submitter": "Jianpeng Cheng J", "authors": "Jianpeng Cheng, Adam Lopez and Mirella Lapata", "title": "A Generative Parser with a Discriminative Recognition Algorithm", "comments": "ACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative models defining joint distributions over parse trees and sentences\nare useful for parsing and language modeling, but impose restrictions on the\nscope of features and are often outperformed by discriminative models. We\npropose a framework for parsing and language modeling which marries a\ngenerative model with a discriminative recognition model in an encoder-decoder\nsetting. We provide interpretations of the framework based on expectation\nmaximization and variational inference, and show that it enables parsing and\nlanguage modeling within a single implementation. On the English Penn\nTreen-bank, our framework obtains competitive performance on constituency\nparsing while matching the state-of-the-art single-model language modeling\nscore.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 17:02:45 GMT"}, {"version": "v2", "created": "Thu, 17 Aug 2017 13:39:14 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Cheng", "Jianpeng", ""], ["Lopez", "Adam", ""], ["Lapata", "Mirella", ""]]}, {"id": "1708.00416", "submitter": "Jo\\~ao Sedoc", "authors": "Joao Sedoc, Derry Wijaya, Masoud Rouhizadeh, Andy Schwartz, Lyle Ungar", "title": "Deriving Verb Predicates By Clustering Verbs with Arguments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hand-built verb clusters such as the widely used Levin classes (Levin, 1993)\nhave proved useful, but have limited coverage. Verb classes automatically\ninduced from corpus data such as those from VerbKB (Wijaya, 2016), on the other\nhand, can give clusters with much larger coverage, and can be adapted to\nspecific corpora such as Twitter. We present a method for clustering the\noutputs of VerbKB: verbs with their multiple argument types, e.g.\n\"marry(person, person)\", \"feel(person, emotion).\" We make use of a novel\nlow-dimensional embedding of verbs and their arguments to produce high quality\nclusters in which the same verb can be in different clusters depending on its\nargument type. The resulting verb clusters do a better job than hand-built\nclusters of predicting sarcasm, sentiment, and locus of control in tweets.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 17:05:32 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Sedoc", "Joao", ""], ["Wijaya", "Derry", ""], ["Rouhizadeh", "Masoud", ""], ["Schwartz", "Andy", ""], ["Ungar", "Lyle", ""]]}, {"id": "1708.00481", "submitter": "Hidekazu Oiwa", "authors": "Hidekazu Oiwa, Yoshihiko Suhara, Jiyu Komiya, Andrei Lopatenko", "title": "A Lightweight Front-end Tool for Interactive Entity Population", "comments": "ICML Workshop on Interactive Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity population, a task of collecting entities that belong to a particular\ncategory, has attracted attention from vertical domains. There is still a high\ndemand for creating entity dictionaries in vertical domains, which are not\ncovered by existing knowledge bases. We develop a lightweight front-end tool\nfor facilitating interactive entity population. We implement key components\nnecessary for effective interactive entity population: 1) GUI-based dashboards\nto quickly modify an entity dictionary, and 2) entity highlighting on documents\nfor quickly viewing the current progress. We aim to reduce user cost from\nbeginning to end, including package installation and maintenance. The\nimplementation enables users to use this tool on their web browsers without any\nadditional packages --- users can focus on their missions to create entity\ndictionaries. Moreover, an entity expansion module is implemented as external\nAPIs. This design makes it easy to continuously improve interactive entity\npopulation pipelines. We are making our demo publicly available\n(http://bit.ly/luwak-demo).\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 19:27:02 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Oiwa", "Hidekazu", ""], ["Suhara", "Yoshihiko", ""], ["Komiya", "Jiyu", ""], ["Lopatenko", "Andrei", ""]]}, {"id": "1708.00531", "submitter": "Hao Tang", "authors": "Hao Tang, Liang Lu, Lingpeng Kong, Kevin Gimpel, Karen Livescu, Chris\n  Dyer, Noah A. Smith, Steve Renals", "title": "End-to-End Neural Segmental Models for Speech Recognition", "comments": null, "journal-ref": null, "doi": "10.1109/JSTSP.2017.2752462", "report-no": null, "categories": "cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmental models are an alternative to frame-based models for sequence\nprediction, where hypothesized path weights are based on entire segment scores\nrather than a single frame at a time. Neural segmental models are segmental\nmodels that use neural network-based weight functions. Neural segmental models\nhave achieved competitive results for speech recognition, and their end-to-end\ntraining has been explored in several studies. In this work, we review neural\nsegmental models, which can be viewed as consisting of a neural network-based\nacoustic encoder and a finite-state transducer decoder. We study end-to-end\nsegmental models with different weight functions, including ones based on\nframe-level neural classifiers and on segmental recurrent neural networks. We\nstudy how reducing the search space size impacts performance under different\nweight functions. We also compare several loss functions for end-to-end\ntraining. Finally, we explore training approaches, including multi-stage vs.\nend-to-end training and multitask training that combines segmental and\nframe-level losses.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 21:53:56 GMT"}, {"version": "v2", "created": "Tue, 15 Aug 2017 16:29:05 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Tang", "Hao", ""], ["Lu", "Liang", ""], ["Kong", "Lingpeng", ""], ["Gimpel", "Kevin", ""], ["Livescu", "Karen", ""], ["Dyer", "Chris", ""], ["Smith", "Noah A.", ""], ["Renals", "Steve", ""]]}, {"id": "1708.00549", "submitter": "Luke Vilnis", "authors": "Xiang Li, Luke Vilnis, Andrew McCallum", "title": "Improved Representation Learning for Predicting Commonsense Ontologies", "comments": "4 pages, ICML 2017 DeepStruct Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in learning ontologies (hierarchical and partially-ordered\nstructures) has leveraged the intrinsic geometry of spaces of learned\nrepresentations to make predictions that automatically obey complex structural\nconstraints. We explore two extensions of one such model, the order-embedding\nmodel for hierarchical relation learning, with an aim towards improved\nperformance on text data for commonsense knowledge representation. Our first\nmodel jointly learns ordering relations and non-hierarchical knowledge in the\nform of raw text. Our second extension exploits the partial order structure of\nthe training data to find long-distance triplet constraints among embeddings\nwhich are poorly enforced by the pairwise training procedure. We find that both\nincorporating free text and augmented training constraints improve over the\noriginal order-embedding model and other strong baselines.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 23:05:57 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Li", "Xiang", ""], ["Vilnis", "Luke", ""], ["McCallum", "Andrew", ""]]}, {"id": "1708.00553", "submitter": "Luke Vilnis", "authors": "Dung Thai, Shikhar Murty, Trapit Bansal, Luke Vilnis, David Belanger,\n  Andrew McCallum", "title": "Low-Rank Hidden State Embeddings for Viterbi Sequence Labeling", "comments": "4 pages, ICML 2017 DeepStruct Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In textual information extraction and other sequence labeling tasks it is now\ncommon to use recurrent neural networks (such as LSTM) to form rich embedded\nrepresentations of long-term input co-occurrence patterns. Representation of\noutput co-occurrence patterns is typically limited to a hand-designed graphical\nmodel, such as a linear-chain CRF representing short-term Markov dependencies\namong successive labels. This paper presents a method that learns embedded\nrepresentations of latent output structure in sequence data. Our model takes\nthe form of a finite-state machine with a large number of latent states per\nlabel (a latent variable CRF), where the state-transition matrix is\nfactorized---effectively forming an embedded representation of\nstate-transitions capable of enforcing long-term label dependencies, while\nsupporting exact Viterbi inference over output labels. We demonstrate accuracy\nimprovements and interpretable latent structure in a synthetic but complex task\nbased on CoNLL named entity recognition.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 00:05:10 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Thai", "Dung", ""], ["Murty", "Shikhar", ""], ["Bansal", "Trapit", ""], ["Vilnis", "Luke", ""], ["Belanger", "David", ""], ["McCallum", "Andrew", ""]]}, {"id": "1708.00563", "submitter": "Jan Niehues", "authors": "Jan Niehues, Eunah Cho, Thanh-Le Ha, Alex Waibel", "title": "Analyzing Neural MT Search and Model Performance", "comments": "7 pages, First Workshop on Neural Machine Translation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we offer an in-depth analysis about the modeling and search\nperformance. We address the question if a more complex search algorithm is\nnecessary. Furthermore, we investigate the question if more complex models\nwhich might only be applicable during rescoring are promising.\n  By separating the search space and the modeling using $n$-best list\nreranking, we analyze the influence of both parts of an NMT system\nindependently. By comparing differently performing NMT systems, we show that\nthe better translation is already in the search space of the translation\nsystems with less performance. This results indicate that the current search\nalgorithms are sufficient for the NMT systems. Furthermore, we could show that\neven a relatively small $n$-best list of $50$ hypotheses already contain\nnotably better translations.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 00:48:35 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Niehues", "Jan", ""], ["Cho", "Eunah", ""], ["Ha", "Thanh-Le", ""], ["Waibel", "Alex", ""]]}, {"id": "1708.00625", "submitter": "Piji Li", "authors": "Piji Li, Wai Lam, Lidong Bing, Zihao Wang", "title": "Deep Recurrent Generative Decoder for Abstractive Text Summarization", "comments": "10 pages, EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework for abstractive text summarization based on a\nsequence-to-sequence oriented encoder-decoder model equipped with a deep\nrecurrent generative decoder (DRGN).\n  Latent structure information implied in the target summaries is learned based\non a recurrent latent random model for improving the summarization quality.\n  Neural variational inference is employed to address the intractable posterior\ninference for the recurrent latent variables.\n  Abstractive summaries are generated based on both the generative latent\nvariables and the discriminative deterministic states.\n  Extensive experiments on some benchmark datasets in different languages show\nthat DRGN achieves improvements over the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 07:47:14 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Li", "Piji", ""], ["Lam", "Wai", ""], ["Bing", "Lidong", ""], ["Wang", "Zihao", ""]]}, {"id": "1708.00667", "submitter": "Takuya Hiraoka", "authors": "Takuya Hiraoka, Masaaki Tsuchida, Yotaro Watanabe", "title": "Deep Reinforcement Learning for Inquiry Dialog Policies with Logical\n  Formula Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is the first attempt to learn the policy of an inquiry dialog\nsystem (IDS) by using deep reinforcement learning (DRL). Most IDS frameworks\nrepresent dialog states and dialog acts with logical formulae. In order to make\nlearning inquiry dialog policies more effective, we introduce a logical formula\nembedding framework based on a recursive neural network. The results of\nexperiments to evaluate the effect of 1) the DRL and 2) the logical formula\nembedding framework show that the combination of the two are as effective or\neven better than existing rule-based methods for inquiry dialog policies.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 09:40:42 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Hiraoka", "Takuya", ""], ["Tsuchida", "Masaaki", ""], ["Watanabe", "Yotaro", ""]]}, {"id": "1708.00712", "submitter": "Marlies Van Der Wees", "authors": "Marlies van der Wees, Arianna Bisazza and Christof Monz", "title": "Dynamic Data Selection for Neural Machine Translation", "comments": "Accepted at EMNLP2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent selection of training data has proven a successful technique to\nsimultaneously increase training efficiency and translation performance for\nphrase-based machine translation (PBMT). With the recent increase in popularity\nof neural machine translation (NMT), we explore in this paper to what extent\nand how NMT can also benefit from data selection. While state-of-the-art data\nselection (Axelrod et al., 2011) consistently performs well for PBMT, we show\nthat gains are substantially lower for NMT. Next, we introduce dynamic data\nselection for NMT, a method in which we vary the selected subset of training\ndata between different training epochs. Our experiments show that the best\nresults are achieved when applying a technique we call gradual fine-tuning,\nwith improvements up to +2.6 BLEU over the original data selection approach and\nup to +3.1 BLEU over a general baseline.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 11:55:57 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["van der Wees", "Marlies", ""], ["Bisazza", "Arianna", ""], ["Monz", "Christof", ""]]}, {"id": "1708.00726", "submitter": "Rico Sennrich", "authors": "Rico Sennrich, Alexandra Birch, Anna Currey, Ulrich Germann, Barry\n  Haddow, Kenneth Heafield, Antonio Valerio Miceli Barone and Philip Williams", "title": "The University of Edinburgh's Neural MT Systems for WMT17", "comments": "WMT 2017 shared task track; for Bibtex, see\n  http://homepages.inf.ed.ac.uk/rsennric/bib.html#uedin-nmt:2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes the University of Edinburgh's submissions to the WMT17\nshared news translation and biomedical translation tasks. We participated in 12\ntranslation directions for news, translating between English and Czech, German,\nLatvian, Russian, Turkish and Chinese. For the biomedical task we submitted\nsystems for English to Czech, German, Polish and Romanian. Our systems are\nneural machine translation systems trained with Nematus, an attentional\nencoder-decoder. We follow our setup from last year and build BPE-based models\nwith parallel and back-translated monolingual training data. Novelties this\nyear include the use of deep architectures, layer normalization, and more\ncompact models due to weight tying and improvements in BPE segmentations. We\nperform extensive ablative experiments, reporting on the effectivenes of layer\nnormalization, deep architectures, and different ensembling techniques.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 12:48:32 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Sennrich", "Rico", ""], ["Birch", "Alexandra", ""], ["Currey", "Anna", ""], ["Germann", "Ulrich", ""], ["Haddow", "Barry", ""], ["Heafield", "Kenneth", ""], ["Barone", "Antonio Valerio Miceli", ""], ["Williams", "Philip", ""]]}, {"id": "1708.00781", "submitter": "Yangfeng Ji", "authors": "Yangfeng Ji, Chenhao Tan, Sebastian Martschat, Yejin Choi, Noah A.\n  Smith", "title": "Dynamic Entity Representations in Neural Language Models", "comments": "EMNLP 2017 camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding a long document requires tracking how entities are introduced\nand evolve over time. We present a new type of language model, EntityNLM, that\ncan explicitly model entities, dynamically update their representations, and\ncontextually generate their mentions. Our model is generative and flexible; it\ncan model an arbitrary number of entities in context while generating each\nentity mention at an arbitrary length. In addition, it can be used for several\ndifferent tasks such as language modeling, coreference resolution, and entity\nprediction. Experimental results with all these tasks demonstrate that our\nmodel consistently outperforms strong baselines and prior work.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 14:49:03 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Ji", "Yangfeng", ""], ["Tan", "Chenhao", ""], ["Martschat", "Sebastian", ""], ["Choi", "Yejin", ""], ["Smith", "Noah A.", ""]]}, {"id": "1708.00790", "submitter": "Yong Jiang", "authors": "Yong Jiang, Wenjuan Han, Kewei Tu", "title": "Combining Generative and Discriminative Approaches to Unsupervised\n  Dependency Parsing via Dual Decomposition", "comments": "In EMNLP 2017. A typo fixed in Algo 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised dependency parsing aims to learn a dependency parser from\nunannotated sentences. Existing work focuses on either learning generative\nmodels using the expectation-maximization algorithm and its variants, or\nlearning discriminative models using the discriminative clustering algorithm.\nIn this paper, we propose a new learning strategy that learns a generative\nmodel and a discriminative model jointly based on the dual decomposition\nmethod. Our method is simple and general, yet effective to capture the\nadvantages of both models and improve their learning results. We tested our\nmethod on the UD treebank and achieved a state-of-the-art performance on thirty\nlanguages.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 15:10:28 GMT"}, {"version": "v2", "created": "Sun, 24 Sep 2017 14:30:34 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Jiang", "Yong", ""], ["Han", "Wenjuan", ""], ["Tu", "Kewei", ""]]}, {"id": "1708.00801", "submitter": "Wenjuan Han", "authors": "Wenjuan Han, Yong Jiang, Kewei Tu", "title": "Dependency Grammar Induction with Neural Lexicalization and Big Training\n  Data", "comments": "EMNLP 2017", "journal-ref": null, "doi": null, "report-no": "654", "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the impact of big models (in terms of the degree of lexicalization)\nand big data (in terms of the training corpus size) on dependency grammar\ninduction. We experimented with L-DMV, a lexicalized version of Dependency\nModel with Valence and L-NDMV, our lexicalized extension of the Neural\nDependency Model with Valence. We find that L-DMV only benefits from very small\ndegrees of lexicalization and moderate sizes of training corpora. L-NDMV can\nbenefit from big training data and lexicalization of greater degrees,\nespecially when enhanced with good model initialization, and it achieves a\nresult that is competitive with the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 15:43:30 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Han", "Wenjuan", ""], ["Jiang", "Yong", ""], ["Tu", "Kewei", ""]]}, {"id": "1708.00818", "submitter": "Jo\\~ao Sedoc", "authors": "Grishma Jena, Mansi Vashisht, Abheek Basu, Lyle Ungar, Jo\\~ao Sedoc", "title": "Enterprise to Computer: Star Trek chatbot", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human interactions and human-computer interactions are strongly influenced by\nstyle as well as content. Adding a persona to a chatbot makes it more\nhuman-like and contributes to a better and more engaging user experience. In\nthis work, we propose a design for a chatbot that captures the \"style\" of Star\nTrek by incorporating references from the show along with peculiar tones of the\nfictional characters therein. Our Enterprise to Computer bot (E2Cbot) treats\nStar Trek dialog style and general dialog style differently, using two\nrecurrent neural network Encoder-Decoder models. The Star Trek dialog style\nuses sequence to sequence (SEQ2SEQ) models (Sutskever et al., 2014; Bahdanau et\nal., 2014) trained on Star Trek dialogs. The general dialog style uses Word\nGraph to shift the response of the SEQ2SEQ model into the Star Trek domain. We\nevaluate the bot both in terms of perplexity and word overlap with Star Trek\nvocabulary and subjectively using human evaluators.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 16:51:01 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Jena", "Grishma", ""], ["Vashisht", "Mansi", ""], ["Basu", "Abheek", ""], ["Ungar", "Lyle", ""], ["Sedoc", "Jo\u00e3o", ""]]}, {"id": "1708.00850", "submitter": "Wlodek Zadrozny", "authors": "Wlodek Zadrozny, Hossein Hematialam and Luciana Garbayo", "title": "Towards Semantic Modeling of Contradictions and Disagreements: A Case\n  Study of Medical Guidelines", "comments": "5 pages, 1 figure, accepted at 12th International Conference on\n  Computational Semantics (IWCS-2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a formal distinction between contradictions and disagreements in\nnatural language texts, motivated by the need to formally reason about\ncontradictory medical guidelines. This is a novel and potentially very useful\ndistinction, and has not been discussed so far in NLP and logic. We also\ndescribe a NLP system capable of automated finding contradictory medical\nguidelines; the system uses a combination of text analysis and information\nretrieval modules. We also report positive evaluation results on a small corpus\nof contradictory medical recommendations.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 17:54:32 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Zadrozny", "Wlodek", ""], ["Hematialam", "Hossein", ""], ["Garbayo", "Luciana", ""]]}, {"id": "1708.00897", "submitter": "Jo\\~ao Sedoc", "authors": "Sajal Choudhary, Prerna Srivastava, Lyle Ungar, Jo\\~ao Sedoc", "title": "Domain Aware Neural Dialog System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the task of building a domain aware chat system which\ngenerates intelligent responses in a conversation comprising of different\ndomains. The domain, in this case, is the topic or theme of the conversation.\nTo achieve this, we present DOM-Seq2Seq, a domain aware neural network model\nbased on the novel technique of using domain-targeted sequence-to-sequence\nmodels (Sutskever et al., 2014) and a domain classifier. The model captures\nfeatures from current utterance and domains of the previous utterances to\nfacilitate the formation of relevant responses. We evaluate our model on\nautomatic metrics and compare our performance with the Seq2Seq model.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 19:04:52 GMT"}], "update_date": "2017-08-04", "authors_parsed": [["Choudhary", "Sajal", ""], ["Srivastava", "Prerna", ""], ["Ungar", "Lyle", ""], ["Sedoc", "Jo\u00e3o", ""]]}, {"id": "1708.00993", "submitter": "Jan Niehues", "authors": "Jan Niehues, Eunah Cho", "title": "Exploiting Linguistic Resources for Neural Machine Translation Using\n  Multi-task Learning", "comments": "9 pages, Second Conference on Machine Translation(WMT17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linguistic resources such as part-of-speech (POS) tags have been extensively\nused in statistical machine translation (SMT) frameworks and have yielded\nbetter performances. However, usage of such linguistic annotations in neural\nmachine translation (NMT) systems has been left under-explored.\n  In this work, we show that multi-task learning is a successful and a easy\napproach to introduce an additional knowledge into an end-to-end neural\nattentional model. By jointly training several natural language processing\n(NLP) tasks in one system, we are able to leverage common information and\nimprove the performance of the individual task.\n  We analyze the impact of three design decisions in multi-task learning: the\ntasks used in training, the training schedule, and the degree of parameter\nsharing across the tasks, which is defined by the network architecture. The\nexperiments are conducted for an German to English translation task. As\nadditional linguistic resources, we exploit POS information and named-entities\n(NE). Experiments show that the translation quality can be improved by up to\n1.5 BLEU points under the low-resource condition. The performance of the POS\ntagger is also improved using the multi-task learning scheme.\n", "versions": [{"version": "v1", "created": "Thu, 3 Aug 2017 04:30:37 GMT"}], "update_date": "2017-08-04", "authors_parsed": [["Niehues", "Jan", ""], ["Cho", "Eunah", ""]]}, {"id": "1708.01009", "submitter": "Stephen Merity", "authors": "Stephen Merity, Bryan McCann, Richard Socher", "title": "Revisiting Activation Regularization for Language RNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) serve as a fundamental building block for\nmany sequence tasks across natural language processing. Recent research has\nfocused on recurrent dropout techniques or custom RNN cells in order to improve\nperformance. Both of these can require substantial modifications to the machine\nlearning model or to the underlying RNN configurations. We revisit traditional\nregularization techniques, specifically L2 regularization on RNN activations\nand slowness regularization over successive hidden states, to improve the\nperformance of RNNs on the task of language modeling. Both of these techniques\nrequire minimal modification to existing RNN architectures and result in\nperformance improvements comparable or superior to more complicated\nregularization techniques or custom cell architectures. These regularization\ntechniques can be used without any modification on optimized LSTM\nimplementations such as the NVIDIA cuDNN LSTM.\n", "versions": [{"version": "v1", "created": "Thu, 3 Aug 2017 05:53:53 GMT"}], "update_date": "2017-08-04", "authors_parsed": [["Merity", "Stephen", ""], ["McCann", "Bryan", ""], ["Socher", "Richard", ""]]}, {"id": "1708.01018", "submitter": "Jiong Cai", "authors": "Jiong Cai, Yong Jiang, Kewei Tu", "title": "CRF Autoencoder for Unsupervised Dependency Parsing", "comments": "EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised dependency parsing, which tries to discover linguistic\ndependency structures from unannotated data, is a very challenging task. Almost\nall previous work on this task focuses on learning generative models. In this\npaper, we develop an unsupervised dependency parsing model based on the CRF\nautoencoder. The encoder part of our model is discriminative and globally\nnormalized which allows us to use rich features as well as universal linguistic\npriors. We propose an exact algorithm for parsing as well as a tractable\nlearning algorithm. We evaluated the performance of our model on eight\nmultilingual treebanks and found that our model achieved comparable performance\nwith state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Thu, 3 Aug 2017 06:45:31 GMT"}], "update_date": "2017-08-04", "authors_parsed": [["Cai", "Jiong", ""], ["Jiang", "Yong", ""], ["Tu", "Kewei", ""]]}, {"id": "1708.01065", "submitter": "Piji Li", "authors": "Piji Li, Lidong Bing, Wai Lam", "title": "Reader-Aware Multi-Document Summarization: An Enhanced Model and The\n  First Dataset", "comments": "EMNLP 2017 Workshop on New Frontiers in Summarization; Dataset:\n  http://www.se.cuhk.edu.hk/~textmine/dataset/ra-mds/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of reader-aware multi-document summarization\n(RA-MDS) and introduce a new dataset for this problem. To tackle RA-MDS, we\nextend a variational auto-encodes (VAEs) based MDS framework by jointly\nconsidering news documents and reader comments. To conduct evaluation for\nsummarization performance, we prepare a new dataset. We describe the methods\nfor data collection, aspect annotation, and summary writing as well as\nscrutinizing by experts. Experimental results show that reader comments can\nimprove the summarization performance, which also demonstrates the usefulness\nof the proposed dataset. The annotated dataset for RA-MDS is available online.\n", "versions": [{"version": "v1", "created": "Thu, 3 Aug 2017 09:18:16 GMT"}], "update_date": "2017-08-04", "authors_parsed": [["Li", "Piji", ""], ["Bing", "Lidong", ""], ["Lam", "Wai", ""]]}, {"id": "1708.01318", "submitter": "Khanh Nguyen", "authors": "Amr Sharaf, Shi Feng, Khanh Nguyen, Kiant\\'e Brantley, Hal Daum\\'e III", "title": "The UMD Neural Machine Translation Systems at WMT17 Bandit Learning Task", "comments": "7 pages, 1 figure, WMT 2017 Bandit Learning Task", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the University of Maryland machine translation systems submitted\nto the WMT17 German-English Bandit Learning Task. The task is to adapt a\ntranslation system to a new domain, using only bandit feedback: the system\nreceives a German sentence to translate, produces an English sentence, and only\ngets a scalar score as feedback. Targeting these two challenges (adaptation and\nbandit learning), we built a standard neural machine translation system and\nextended it in two ways: (1) robust reinforcement learning techniques to learn\neffectively from the bandit feedback, and (2) domain adaptation using data\nselection from a large corpus of parallel data.\n", "versions": [{"version": "v1", "created": "Thu, 3 Aug 2017 21:42:46 GMT"}, {"version": "v2", "created": "Mon, 7 Aug 2017 20:45:50 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Sharaf", "Amr", ""], ["Feng", "Shi", ""], ["Nguyen", "Khanh", ""], ["Brantley", "Kiant\u00e9", ""], ["Daum\u00e9", "Hal", "III"]]}, {"id": "1708.01336", "submitter": "Yannis Kalantidis", "authors": "Lu Jiang, Junwei Liang, Liangliang Cao, Yannis Kalantidis, Sachin\n  Farfade, Alexander Hauptmann", "title": "MemexQA: Visual Memex Question Answering", "comments": "https://memexqa.cs.cmu.edu/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new task, MemexQA: given a collection of photos or\nvideos from a user, the goal is to automatically answer questions that help\nusers recover their memory about events captured in the collection. Towards\nsolving the task, we 1) present the MemexQA dataset, a large, realistic\nmultimodal dataset consisting of real personal photos and crowd-sourced\nquestions/answers, 2) propose MemexNet, a unified, end-to-end trainable network\narchitecture for image, text and video question answering. Experimental results\non the MemexQA dataset demonstrate that MemexNet outperforms strong baselines\nand yields the state-of-the-art on this novel and challenging task. The\npromising results on TextQA and VideoQA suggest MemexNet's efficacy and\nscalability across various QA tasks.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 00:17:48 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["Jiang", "Lu", ""], ["Liang", "Junwei", ""], ["Cao", "Liangliang", ""], ["Kalantidis", "Yannis", ""], ["Farfade", "Sachin", ""], ["Hauptmann", "Alexander", ""]]}, {"id": "1708.01353", "submitter": "Qian Chen", "authors": "Qian Chen, Xiaodan Zhu, Zhen-Hua Ling, Si Wei, Hui Jiang, Diana Inkpen", "title": "Recurrent Neural Network-Based Sentence Encoder with Gated Attention for\n  Natural Language Inference", "comments": "RepEval 2017 workshop paper at EMNLP 2017, Copenhagen", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The RepEval 2017 Shared Task aims to evaluate natural language understanding\nmodels for sentence representation, in which a sentence is represented as a\nfixed-length vector with neural networks and the quality of the representation\nis tested with a natural language inference task. This paper describes our\nsystem (alpha) that is ranked among the top in the Shared Task, on both the\nin-domain test set (obtaining a 74.9% accuracy) and on the cross-domain test\nset (also attaining a 74.9% accuracy), demonstrating that the model generalizes\nwell to the cross-domain data. Our model is equipped with intra-sentence\ngated-attention composition which helps achieve a better performance. In\naddition to submitting our model to the Shared Task, we have also tested it on\nthe Stanford Natural Language Inference (SNLI) dataset. We obtain an accuracy\nof 85.5%, which is the best reported result on SNLI when cross-sentence\nattention is not allowed, the same condition enforced in RepEval 2017.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 01:55:18 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["Chen", "Qian", ""], ["Zhu", "Xiaodan", ""], ["Ling", "Zhen-Hua", ""], ["Wei", "Si", ""], ["Jiang", "Hui", ""], ["Inkpen", "Diana", ""]]}, {"id": "1708.01372", "submitter": "Benjamin Shickel", "authors": "Benjamin Shickel, Martin Heesacker, Sherry Benton, Parisa Rashidi", "title": "Hashtag Healthcare: From Tweets to Mental Health Journals Using Deep\n  Transfer Learning", "comments": "Under review with Scientific Reports", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the popularity of social media platforms continues to rise, an\never-increasing amount of human communication and self- expression takes place\nonline. Most recent research has focused on mining social media for public user\nopinion about external entities such as product reviews or sentiment towards\npolitical news. However, less attention has been paid to analyzing users'\ninternalized thoughts and emotions from a mental health perspective. In this\npaper, we quantify the semantic difference between public Tweets and private\nmental health journals used in online cognitive behavioral therapy. We will use\ndeep transfer learning techniques for analyzing the semantic gap between the\ntwo domains. We show that for the task of emotional valence prediction, social\nmedia can be successfully harnessed to create more accurate, robust, and\npersonalized mental health models. Our results suggest that the semantic gap\nbetween public and private self-expression is small, and that utilizing the\nabundance of available social media is one way to overcome the small sample\nsizes of mental health data, which are commonly limited by availability and\nprivacy concerns.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 03:47:35 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["Shickel", "Benjamin", ""], ["Heesacker", "Martin", ""], ["Benton", "Sherry", ""], ["Rashidi", "Parisa", ""]]}, {"id": "1708.01425", "submitter": "Ivan Habernal", "authors": "Ivan Habernal and Henning Wachsmuth and Iryna Gurevych and Benno Stein", "title": "The Argument Reasoning Comprehension Task: Identification and\n  Reconstruction of Implicit Warrants", "comments": "Accepted as NAACL 2018 Long Paper; see details on the front page", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning is a crucial part of natural language argumentation. To comprehend\nan argument, one must analyze its warrant, which explains why its claim follows\nfrom its premises. As arguments are highly contextualized, warrants are usually\npresupposed and left implicit. Thus, the comprehension does not only require\nlanguage understanding and logic skills, but also depends on common sense. In\nthis paper we develop a methodology for reconstructing warrants systematically.\nWe operationalize it in a scalable crowdsourcing process, resulting in a freely\nlicensed dataset with warrants for 2k authentic arguments from news comments.\nOn this basis, we present a new challenging task, the argument reasoning\ncomprehension task. Given an argument with a claim and a premise, the goal is\nto choose the correct implicit warrant from two options. Both warrants are\nplausible and lexically close, but lead to contradicting claims. A solution to\nthis task will define a substantial step towards automatic warrant\nreconstruction. However, experiments with several neural attention and language\nmodels reveal that current approaches do not suffice.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 08:46:03 GMT"}, {"version": "v2", "created": "Tue, 22 Aug 2017 13:34:24 GMT"}, {"version": "v3", "created": "Mon, 19 Feb 2018 12:34:20 GMT"}, {"version": "v4", "created": "Tue, 27 Feb 2018 12:53:48 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Habernal", "Ivan", ""], ["Wachsmuth", "Henning", ""], ["Gurevych", "Iryna", ""], ["Stein", "Benno", ""]]}, {"id": "1708.01464", "submitter": "Ben Peters", "authors": "Ben Peters, Jon Dehdari and Josef van Genabith", "title": "Massively Multilingual Neural Grapheme-to-Phoneme Conversion", "comments": "EMNLP 2017 Workshop on Building Linguisically Generalizable NLP\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grapheme-to-phoneme conversion (g2p) is necessary for text-to-speech and\nautomatic speech recognition systems. Most g2p systems are monolingual: they\nrequire language-specific data or handcrafting of rules. Such systems are\ndifficult to extend to low resource languages, for which data and handcrafted\nrules are not available. As an alternative, we present a neural\nsequence-to-sequence approach to g2p which is trained on\nspelling--pronunciation pairs in hundreds of languages. The system shares a\nsingle encoder and decoder across all languages, allowing it to utilize the\nintrinsic similarities between different writing systems. We show an 11%\nimprovement in phoneme error rate over an approach based on adapting\nhigh-resource monolingual g2p models to low-resource languages. Our model is\nalso much more compact relative to previous approaches.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 11:57:02 GMT"}], "update_date": "2017-10-05", "authors_parsed": [["Peters", "Ben", ""], ["Dehdari", "Jon", ""], ["van Genabith", "Josef", ""]]}, {"id": "1708.01525", "submitter": "Roman Orus", "authors": "Angel J. Gallego, Roman Orus", "title": "Language Design as Information Renormalization", "comments": "23 pages, 21 figures, 1 table. New version, including proof of\n  long-range correlations, justification of \"good and bad\" neural networks for\n  language, and other improvements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cond-mat.str-el physics.hist-ph quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we consider some well-known facts in syntax from a physics perspective,\nallowing us to establish equivalences between both fields with many\nconsequences. Mainly, we observe that the operation MERGE, put forward by N.\nChomsky in 1995, can be interpreted as a physical information coarse-graining.\nThus, MERGE in linguistics entails information renormalization in physics,\naccording to different time scales. We make this point mathematically formal in\nterms of language models. In this setting, MERGE amounts to a probability\ntensor implementing a coarse-graining, akin to a probabilistic context-free\ngrammar. The probability vectors of meaningful sentences are given by\nstochastic tensor networks (TN) built from diagonal tensors and which are\nmostly loop-free, such as Tree Tensor Networks and Matrix Product States, thus\nbeing computationally very efficient to manipulate. We show that this implies\nthe polynomially-decaying (long-range) correlations experimentally observed in\nlanguage, and also provides arguments in favour of certain types of neural\nnetworks for language processing. Moreover, we show how to obtain such language\nmodels from quantum states that can be efficiently prepared on a quantum\ncomputer, and use this to find bounds on the perplexity of the probability\ndistribution of words in a sentence. Implications of our results are discussed\nacross several ambits.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 14:35:38 GMT"}, {"version": "v2", "created": "Fri, 25 Aug 2017 16:04:57 GMT"}, {"version": "v3", "created": "Thu, 15 Mar 2018 09:49:56 GMT"}, {"version": "v4", "created": "Tue, 19 Mar 2019 11:15:28 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Gallego", "Angel J.", ""], ["Orus", "Roman", ""]]}, {"id": "1708.01565", "submitter": "Michael Wand", "authors": "Michael Wand, Juergen Schmidhuber", "title": "Improving Speaker-Independent Lipreading with Domain-Adversarial\n  Training", "comments": "Accepted at Interspeech 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Lipreading system, i.e. a speech recognition system using only\nvisual features, which uses domain-adversarial training for speaker\nindependence. Domain-adversarial training is integrated into the optimization\nof a lipreader based on a stack of feedforward and LSTM (Long Short-Term\nMemory) recurrent neural networks, yielding an end-to-end trainable system\nwhich only requires a very small number of frames of untranscribed target data\nto substantially improve the recognition accuracy on the target speaker. On\npairs of different source and target speakers, we achieve a relative accuracy\nimprovement of around 40% with only 15 to 20 seconds of untranscribed target\nspeech data. On multi-speaker training setups, the accuracy improvements are\nsmaller but still substantial.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 15:57:38 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["Wand", "Michael", ""], ["Schmidhuber", "Juergen", ""]]}, {"id": "1708.01677", "submitter": "Martin Gerlach", "authors": "Martin Gerlach and Tiago P. Peixoto and Eduardo G. Altmann", "title": "A network approach to topic models", "comments": "22 pages, 10 figures, code available at https://topsbm.github.io/", "journal-ref": "Science Advances 4, eaaq1360 (2018)", "doi": "10.1126/sciadv.aaq1360", "report-no": null, "categories": "stat.ML cs.CL physics.data-an physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main computational and scientific challenges in the modern age is\nto extract useful information from unstructured texts. Topic models are one\npopular machine-learning approach which infers the latent topical structure of\na collection of documents. Despite their success --- in particular of its most\nwidely used variant called Latent Dirichlet Allocation (LDA) --- and numerous\napplications in sociology, history, and linguistics, topic models are known to\nsuffer from severe conceptual and practical problems, e.g. a lack of\njustification for the Bayesian priors, discrepancies with statistical\nproperties of real texts, and the inability to properly choose the number of\ntopics. Here we obtain a fresh view on the problem of identifying topical\nstructures by relating it to the problem of finding communities in complex\nnetworks. This is achieved by representing text corpora as bipartite networks\nof documents and words. By adapting existing community-detection methods --\nusing a stochastic block model (SBM) with non-parametric priors -- we obtain a\nmore versatile and principled framework for topic modeling (e.g., it\nautomatically detects the number of topics and hierarchically clusters both the\nwords and documents). The analysis of artificial and real corpora demonstrates\nthat our SBM approach leads to better topic models than LDA in terms of\nstatistical model selection. More importantly, our work shows how to formally\nrelate methods from community detection and topic modeling, opening the\npossibility of cross-fertilization between these two fields.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 22:35:50 GMT"}, {"version": "v2", "created": "Thu, 19 Jul 2018 13:14:31 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Gerlach", "Martin", ""], ["Peixoto", "Tiago P.", ""], ["Altmann", "Eduardo G.", ""]]}, {"id": "1708.01681", "submitter": "Marcos Zampieri", "authors": "Octavia-Maria Sulea, Marcos Zampieri, Mihaela Vela, Josef van Genabith", "title": "Predicting the Law Area and Decisions of French Supreme Court Cases", "comments": "RANLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the application of text classification methods\nto predict the law area and the decision of cases judged by the French Supreme\nCourt. We also investigate the influence of the time period in which a ruling\nwas made over the textual form of the case description and the extent to which\nit is necessary to mask the judge's motivation for a ruling to emulate a\nreal-world test scenario. We report results of 96% f1 score in predicting a\ncase ruling, 90% f1 score in predicting the law area of a case, and 75.9% f1\nscore in estimating the time span when a ruling has been issued using a linear\nSupport Vector Machine (SVM) classifier trained on lexical features.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 23:10:31 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Sulea", "Octavia-Maria", ""], ["Zampieri", "Marcos", ""], ["Vela", "Mihaela", ""], ["van Genabith", "Josef", ""]]}, {"id": "1708.01713", "submitter": "Shervin Minaee", "authors": "Shervin Minaee, Zhu Liu", "title": "Automatic Question-Answering Using A Deep Similarity Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic question-answering is a classical problem in natural language\nprocessing, which aims at designing systems that can automatically answer a\nquestion, in the same way as human does. In this work, we propose a deep\nlearning based model for automatic question-answering. First the questions and\nanswers are embedded using neural probabilistic modeling. Then a deep\nsimilarity neural network is trained to find the similarity score of a pair of\nanswer and question. Then for each question, the best answer is found as the\none with the highest similarity score. We first train this model on a\nlarge-scale public question-answering database, and then fine-tune it to\ntransfer to the customer-care chat data. We have also tested our framework on a\npublic question-answering database and achieved very good performance.\n", "versions": [{"version": "v1", "created": "Sat, 5 Aug 2017 05:50:44 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Minaee", "Shervin", ""], ["Liu", "Zhu", ""]]}, {"id": "1708.01759", "submitter": "Ond\\v{r}ej Du\\v{s}ek", "authors": "Ond\\v{r}ej Du\\v{s}ek, Jekaterina Novikova, Verena Rieser", "title": "Referenceless Quality Estimation for Natural Language Generation", "comments": "Accepted as a regular paper to 1st Workshop on Learning to Generate\n  Natural Language (LGNL), Sydney, 10 August 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional automatic evaluation measures for natural language generation\n(NLG) use costly human-authored references to estimate the quality of a system\noutput. In this paper, we propose a referenceless quality estimation (QE)\napproach based on recurrent neural networks, which predicts a quality score for\na NLG system output by comparing it to the source meaning representation only.\nOur method outperforms traditional metrics and a constant baseline in most\nrespects; we also show that synthetic data helps to increase correlation\nresults by 21% compared to the base system. Our results are comparable to\nresults obtained in similar QE tasks despite the more challenging setting.\n", "versions": [{"version": "v1", "created": "Sat, 5 Aug 2017 12:24:04 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Du\u0161ek", "Ond\u0159ej", ""], ["Novikova", "Jekaterina", ""], ["Rieser", "Verena", ""]]}, {"id": "1708.01766", "submitter": "Jamie Seol", "authors": "Sanghyuk Choi, Taeuk Kim, Jinseok Seol, Sang-goo Lee", "title": "A Syllable-based Technique for Word Embeddings of Korean Words", "comments": "5 pages, 3 figures, 1 table. Accepted for EMNLP 2017 Workshop - The\n  1st Workshop on Subword and Character level models in NLP (SCLeM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding has become a fundamental component to many NLP tasks such as\nnamed entity recognition and machine translation. However, popular models that\nlearn such embeddings are unaware of the morphology of words, so it is not\ndirectly applicable to highly agglutinative languages such as Korean. We\npropose a syllable-based learning model for Korean using a convolutional neural\nnetwork, in which word representation is composed of trained syllable vectors.\nOur model successfully produces morphologically meaningful representation of\nKorean words compared to the original Skip-gram embeddings. The results also\nshow that it is quite robust to the Out-of-Vocabulary problem.\n", "versions": [{"version": "v1", "created": "Sat, 5 Aug 2017 13:21:01 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Choi", "Sanghyuk", ""], ["Kim", "Taeuk", ""], ["Seol", "Jinseok", ""], ["Lee", "Sang-goo", ""]]}, {"id": "1708.01769", "submitter": "Diego Amancio Dr.", "authors": "Jorge V. Tohalino and Diego R. Amancio", "title": "Extractive Multi Document Summarization using Dynamical Measurements of\n  Complex Networks", "comments": "Accepted for publication in BRACIS 2017 (Brazilian Conference on\n  Intelligent Systems)", "journal-ref": "2017 Brazilian Conference on Intelligent Systems (BRACIS),\n  Uberlandia, 2017, pp. 366-371", "doi": "10.1109/BRACIS.2017.41", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the large amount of textual information available on Internet, it is\nof paramount relevance to use techniques that find relevant and concise\ncontent. A typical task devoted to the identification of informative sentences\nin documents is the so called extractive document summarization task. In this\npaper, we use complex network concepts to devise an extractive Multi Document\nSummarization (MDS) method, which extracts the most central sentences from\nseveral textual sources. In the proposed model, texts are represented as\nnetworks, where nodes represent sentences and the edges are established based\non the number of shared words. Differently from previous works, the\nidentification of relevant terms is guided by the characterization of nodes via\ndynamical measurements of complex networks, including symmetry, accessibility\nand absorption time. The evaluation of the proposed system revealed that\nexcellent results were obtained with particular dynamical measurements,\nincluding those based on the exploration of networks via random walks.\n", "versions": [{"version": "v1", "created": "Sat, 5 Aug 2017 13:32:58 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Tohalino", "Jorge V.", ""], ["Amancio", "Diego R.", ""]]}, {"id": "1708.01771", "submitter": "Rongxiang Weng", "authors": "Rongxiang Weng, Shujian Huang, Zaixiang Zheng, Xinyu Dai and Jiajun\n  Chen", "title": "Neural Machine Translation with Word Predictions", "comments": "Accepted at EMNLP2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the encoder-decoder architecture for neural machine translation (NMT), the\nhidden states of the recurrent structures in the encoder and decoder carry the\ncrucial information about the sentence.These vectors are generated by\nparameters which are updated by back-propagation of translation errors through\ntime. We argue that propagating errors through the end-to-end recurrent\nstructures are not a direct way of control the hidden vectors. In this paper,\nwe propose to use word predictions as a mechanism for direct supervision. More\nspecifically, we require these vectors to be able to predict the vocabulary in\ntarget sentence. Our simple mechanism ensures better representations in the\nencoder and decoder without using any extra data or annotation. It is also\nhelpful in reducing the target side vocabulary and improving the decoding\nefficiency. Experiments on Chinese-English and German-English machine\ntranslation tasks show BLEU improvements by 4.53 and 1.3, respectively\n", "versions": [{"version": "v1", "created": "Sat, 5 Aug 2017 13:38:10 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Weng", "Rongxiang", ""], ["Huang", "Shujian", ""], ["Zheng", "Zaixiang", ""], ["Dai", "Xinyu", ""], ["Chen", "Jiajun", ""]]}, {"id": "1708.01776", "submitter": "Clemens Rosenbaum", "authors": "Clemens Rosenbaum, Tian Gao, Tim Klinger", "title": "e-QRAQ: A Multi-turn Reasoning Dataset and Simulator with Explanations", "comments": "7 pages, 3 figures, presented at 2017 ICML Workshop on Human\n  Interpretability in Machine Learning (WHI 2017), Sydney, NSW, Australia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a new dataset and user simulator e-QRAQ (explainable\nQuery, Reason, and Answer Question) which tests an Agent's ability to read an\nambiguous text; ask questions until it can answer a challenge question; and\nexplain the reasoning behind its questions and answer. The User simulator\nprovides the Agent with a short, ambiguous story and a challenge question about\nthe story. The story is ambiguous because some of the entities have been\nreplaced by variables. At each turn the Agent may ask for the value of a\nvariable or try to answer the challenge question. In response the User\nsimulator provides a natural language explanation of why the Agent's query or\nanswer was useful in narrowing down the set of possible answers, or not. To\ndemonstrate one potential application of the e-QRAQ dataset, we train a new\nneural architecture based on End-to-End Memory Networks to successfully\ngenerate both predictions and partial explanations of its current understanding\nof the problem. We observe a strong correlation between the quality of the\nprediction and explanation.\n", "versions": [{"version": "v1", "created": "Sat, 5 Aug 2017 15:06:56 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Rosenbaum", "Clemens", ""], ["Gao", "Tian", ""], ["Klinger", "Tim", ""]]}, {"id": "1708.01809", "submitter": "Eva Hasler", "authors": "Eva Hasler, Felix Stahlberg, Marcus Tomalin, Adri`a de Gispert, Bill\n  Byrne", "title": "A Comparison of Neural Models for Word Ordering", "comments": "Accepted for publication at INLG 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare several language models for the word-ordering task and propose a\nnew bag-to-sequence neural model based on attention-based sequence-to-sequence\nmodels. We evaluate the model on a large German WMT data set where it\nsignificantly outperforms existing models. We also describe a novel search\nstrategy for LM-based word ordering and report results on the English Penn\nTreebank. Our best model setup outperforms prior work both in terms of speed\nand quality.\n", "versions": [{"version": "v1", "created": "Sat, 5 Aug 2017 19:06:00 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Hasler", "Eva", ""], ["Stahlberg", "Felix", ""], ["Tomalin", "Marcus", ""], ["de Gispert", "Adri`a", ""], ["Byrne", "Bill", ""]]}, {"id": "1708.01944", "submitter": "Abram Handler", "authors": "Abram Handler, Brendan O'Connor", "title": "Rookie: A unique approach for exploring news archives", "comments": "Presented at KDD 2017: Data Science + Journalism workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  News archives are an invaluable primary source for placing current events in\nhistorical context. But current search engine tools do a poor job at uncovering\nbroad themes and narratives across documents. We present Rookie: a practical\nsoftware system which uses natural language processing (NLP) to help readers,\nreporters and editors uncover broad stories in news archives. Unlike prior\nwork, Rookie's design emerged from 18 months of iterative development in\nconsultation with editors and computational journalists. This process lead to a\ndramatically different approach from previous academic systems with similar\ngoals. Our efforts offer a generalizable case study for others building\nreal-world journalism software using NLP.\n", "versions": [{"version": "v1", "created": "Sun, 6 Aug 2017 22:20:02 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Handler", "Abram", ""], ["O'Connor", "Brendan", ""]]}, {"id": "1708.01980", "submitter": "Xing Wang", "authors": "Xing Wang, Zhaopeng Tu, Deyi Xiong and Min Zhang", "title": "Translating Phrases in Neural Machine Translation", "comments": "Accepted by EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phrases play an important role in natural language understanding and machine\ntranslation (Sag et al., 2002; Villavicencio et al., 2005). However, it is\ndifficult to integrate them into current neural machine translation (NMT) which\nreads and generates sentences word by word. In this work, we propose a method\nto translate phrases in NMT by integrating a phrase memory storing target\nphrases from a phrase-based statistical machine translation (SMT) system into\nthe encoder-decoder architecture of NMT. At each decoding step, the phrase\nmemory is first re-written by the SMT model, which dynamically generates\nrelevant target phrases with contextual information provided by the NMT model.\nThen the proposed model reads the phrase memory to make probability estimations\nfor all phrases in the phrase memory. If phrase generation is carried on, the\nNMT decoder selects an appropriate phrase from the memory to perform phrase\ntranslation and updates its decoding state by consuming the words in the\nselected phrase. Otherwise, the NMT decoder generates a word from the\nvocabulary as the general NMT decoder does. Experiment results on the Chinese\nto English translation show that the proposed model achieves significant\nimprovements over the baseline on various test sets.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 03:46:48 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Wang", "Xing", ""], ["Tu", "Zhaopeng", ""], ["Xiong", "Deyi", ""], ["Zhang", "Min", ""]]}, {"id": "1708.02005", "submitter": "Yang Feng", "authors": "Yang Feng, Shiyue Zhang, Andi Zhang, Dong Wang, Andrew Abel", "title": "Memory-augmented Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) has achieved notable success in recent\ntimes, however it is also widely recognized that this approach has limitations\nwith handling infrequent words and word pairs. This paper presents a novel\nmemory-augmented NMT (M-NMT) architecture, which stores knowledge about how\nwords (usually infrequently encountered ones) should be translated in a memory\nand then utilizes them to assist the neural model. We use this memory mechanism\nto combine the knowledge learned from a conventional statistical machine\ntranslation system and the rules learned by an NMT system, and also propose a\nsolution for out-of-vocabulary (OOV) words based on this framework. Our\nexperiments on two Chinese-English translation tasks demonstrated that the\nM-NMT architecture outperformed the NMT baseline by $9.0$ and $2.7$ BLEU points\non the two tasks, respectively. Additionally, we found this architecture\nresulted in a much more effective OOV treatment compared to competitive\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 06:47:23 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Feng", "Yang", ""], ["Zhang", "Shiyue", ""], ["Zhang", "Andi", ""], ["Wang", "Dong", ""], ["Abel", "Andrew", ""]]}, {"id": "1708.02043", "submitter": "Albert Gatt", "authors": "Marc Tanti, Albert Gatt and Kenneth P. Camilleri", "title": "What is the Role of Recurrent Neural Networks (RNNs) in an Image Caption\n  Generator?", "comments": "Appears in: Proceedings of the 10th International Conference on\n  Natural Language Generation (INLG'17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neural image captioning systems, a recurrent neural network (RNN) is\ntypically viewed as the primary `generation' component. This view suggests that\nthe image features should be `injected' into the RNN. This is in fact the\ndominant view in the literature. Alternatively, the RNN can instead be viewed\nas only encoding the previously generated words. This view suggests that the\nRNN should only be used to encode linguistic features and that only the final\nrepresentation should be `merged' with the image features at a later stage.\nThis paper compares these two architectures. We find that, in general, late\nmerging outperforms injection, suggesting that RNNs are better viewed as\nencoders, rather than generators.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 09:01:35 GMT"}, {"version": "v2", "created": "Fri, 25 Aug 2017 15:40:00 GMT"}], "update_date": "2017-08-28", "authors_parsed": [["Tanti", "Marc", ""], ["Gatt", "Albert", ""], ["Camilleri", "Kenneth P.", ""]]}, {"id": "1708.02099", "submitter": "Chi Thang Duong", "authors": "Chi Thang Duong, Remi Lebret, Karl Aberer", "title": "Multimodal Classification for Analysing Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Classification of social media data is an important approach in understanding\nuser behavior on the Web. Although information on social media can be of\ndifferent modalities such as texts, images, audio or videos, traditional\napproaches in classification usually leverage only one prominent modality.\nTechniques that are able to leverage multiple modalities are often complex and\nsusceptible to the absence of some modalities. In this paper, we present simple\nmodels that combine information from different modalities to classify social\nmedia content and are able to handle the above problems with existing\ntechniques. Our models combine information from different modalities using a\npooling layer and an auxiliary learning task is used to learn a common feature\nspace. We demonstrate the performance of our models and their robustness to the\nmissing of some modalities in the emotion classification domain. Our\napproaches, although being simple, can not only achieve significantly higher\naccuracies than traditional fusion approaches but also have comparable results\nwhen only one modality is available.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 12:50:09 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Duong", "Chi Thang", ""], ["Lebret", "Remi", ""], ["Aberer", "Karl", ""]]}, {"id": "1708.02182", "submitter": "Stephen Merity", "authors": "Stephen Merity, Nitish Shirish Keskar, Richard Socher", "title": "Regularizing and Optimizing LSTM Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs), such as long short-term memory networks\n(LSTMs), serve as a fundamental building block for many sequence learning\ntasks, including machine translation, language modeling, and question\nanswering. In this paper, we consider the specific problem of word-level\nlanguage modeling and investigate strategies for regularizing and optimizing\nLSTM-based models. We propose the weight-dropped LSTM which uses DropConnect on\nhidden-to-hidden weights as a form of recurrent regularization. Further, we\nintroduce NT-ASGD, a variant of the averaged stochastic gradient method,\nwherein the averaging trigger is determined using a non-monotonic condition as\nopposed to being tuned by the user. Using these and other regularization\nstrategies, we achieve state-of-the-art word level perplexities on two data\nsets: 57.3 on Penn Treebank and 65.8 on WikiText-2. In exploring the\neffectiveness of a neural cache in conjunction with our proposed model, we\nachieve an even lower state-of-the-art perplexity of 52.8 on Penn Treebank and\n52.0 on WikiText-2.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 16:03:44 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Merity", "Stephen", ""], ["Keskar", "Nitish Shirish", ""], ["Socher", "Richard", ""]]}, {"id": "1708.02210", "submitter": "Qing Ping", "authors": "Qing Ping, Chaomei Chen", "title": "Video Highlights Detection and Summarization with Lag-Calibration based\n  on Concept-Emotion Mapping of Crowd-sourced Time-Sync Comments", "comments": "Accepted in EMNLP 2017 Workshop on New Frontiers in Summarization.\n  Please include \"EMNLP 2017 Workshop on New Frontiers in Summarization\" in any\n  citations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the prevalence of video sharing, there are increasing demands for\nautomatic video digestion such as highlight detection. Recently, platforms with\ncrowdsourced time-sync video comments have emerged worldwide, providing a good\nopportunity for highlight detection. However, this task is non-trivial: (1)\ntime-sync comments often lag behind their corresponding shot; (2) time-sync\ncomments are semantically sparse and noisy; (3) to determine which shots are\nhighlights is highly subjective. The present paper aims to tackle these\nchallenges by proposing a framework that (1) uses concept-mapped lexical-chains\nfor lag calibration; (2) models video highlights based on comment intensity and\ncombination of emotion and concept concentration of each shot; (3) summarize\neach detected highlight using improved SumBasic with emotion and concept\nmapping. Experiments on large real-world datasets show that our highlight\ndetection method and summarization method both outperform other benchmarks with\nconsiderable margins.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 17:21:20 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Ping", "Qing", ""], ["Chen", "Chaomei", ""]]}, {"id": "1708.02214", "submitter": "Qing Ping", "authors": "Qing Ping, Chaomei Chen", "title": "LitStoryTeller: An Interactive System for Visual Exploration of\n  Scientific Papers Leveraging Named entities and Comparative Sentences", "comments": "Accepted at the 16th International Conference On Scientometrics &\n  Informetrics (ISSI 2017). Please include ISSI 2017 in any citations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present study proposes LitStoryTeller, an interactive system for visually\nexploring the semantic structure of a scientific article. We demonstrate how\nLitStoryTeller could be used to answer some of the most fundamental research\nquestions, such as how a new method was built on top of existing methods, based\non what theoretical proof and experimental evidences. More importantly,\nLitStoryTeller can assist users to understand the full and interesting story a\nscientific paper, with a concise outline and important details. The proposed\nsystem borrows a metaphor from screen play, and visualizes the storyline of a\nscientific paper by arranging its characters (scientific concepts or\nterminologies) and scenes (paragraphs/sentences) into a progressive and\ninteractive storyline. Such storylines help to preserve the semantic structure\nand logical thinking process of a scientific paper. Semantic structures, such\nas scientific concepts and comparative sentences, are extracted using existing\nnamed entity recognition APIs and supervised classifiers, from a scientific\npaper automatically. Two supplementary views, ranked entity frequency view and\nentity co-occurrence network view, are provided to help users identify the\n\"main plot\" of such scientific storylines. When collective documents are ready,\nLitStoryTeller also provides a temporal entity evolution view and entity\ncommunity view for collection digestion.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 17:32:56 GMT"}, {"version": "v2", "created": "Fri, 8 Sep 2017 19:04:17 GMT"}, {"version": "v3", "created": "Tue, 12 Sep 2017 14:06:54 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Ping", "Qing", ""], ["Chen", "Chaomei", ""]]}, {"id": "1708.02254", "submitter": "Cristian Danescu-Niculescu-Mizil", "authors": "Justine Zhang, Arthur Spirling, Cristian Danescu-Niculescu-Mizil", "title": "Asking Too Much? The Rhetorical Role of Questions in Political Discourse", "comments": "To appear at EMNLP 2017; 15 pages including appendix; 3 figures;\n  parliament data and code available at\n  http://www.cs.cornell.edu/~cristian/Asking_too_much.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Questions play a prominent role in social interactions, performing rhetorical\nfunctions that go beyond that of simple informational exchange. The surface\nform of a question can signal the intention and background of the person asking\nit, as well as the nature of their relation with the interlocutor. While the\ninformational nature of questions has been extensively examined in the context\nof question-answering applications, their rhetorical aspects have been largely\nunderstudied.\n  In this work we introduce an unsupervised methodology for extracting surface\nmotifs that recur in questions, and for grouping them according to their latent\nrhetorical role. By applying this framework to the setting of question sessions\nin the UK parliament, we show that the resulting typology encodes key aspects\nof the political discourse---such as the bifurcation in questioning behavior\nbetween government and opposition parties---and reveals new insights into the\neffects of a legislator's tenure and political career ambitions.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 18:00:32 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Zhang", "Justine", ""], ["Spirling", "Arthur", ""], ["Danescu-Niculescu-Mizil", "Cristian", ""]]}, {"id": "1708.02255", "submitter": "Eita Nakamura", "authors": "Hiroaki Tsushima, Eita Nakamura, Katsutoshi Itoyama, Kazuyoshi Yoshii", "title": "Generative Statistical Models with Self-Emergent Grammar of Chord\n  Sequences", "comments": "22 pages, 14 figures, version accepted to JNMR, minor revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative statistical models of chord sequences play crucial roles in music\nprocessing. To capture syntactic similarities among certain chords (e.g. in C\nmajor key, between G and G7 and between F and Dm), we study hidden Markov\nmodels and probabilistic context-free grammar models with latent variables\ndescribing syntactic categories of chord symbols and their unsupervised\nlearning techniques for inducing the latent grammar from data. Surprisingly, we\nfind that these models often outperform conventional Markov models in\npredictive power, and the self-emergent categories often correspond to\ntraditional harmonic functions. This implies the need for chord categories in\nharmony models from the informatics perspective.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 18:00:42 GMT"}, {"version": "v2", "created": "Tue, 15 Aug 2017 01:36:14 GMT"}, {"version": "v3", "created": "Fri, 2 Mar 2018 14:54:25 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Tsushima", "Hiroaki", ""], ["Nakamura", "Eita", ""], ["Itoyama", "Katsutoshi", ""], ["Yoshii", "Kazuyoshi", ""]]}, {"id": "1708.02267", "submitter": "Ali Ahmadvand", "authors": "Ali Ahmadvand and Jinho D. Choi", "title": "ISS-MULT: Intelligent Sample Selection for Multi-Task Learning in\n  Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transferring knowledge from a source domain to another domain is useful,\nespecially when gathering new data is very expensive and time-consuming. Deep\nnetworks have been well-studied for question answering tasks in recent years;\nhowever, no prominent research for transfer learning through deep neural\nnetworks exists in the question answering field. In this paper, two main\nmethods (INIT and MULT) in this field are examined. Then, a new method named\nIntelligent sample selection (ISS-MULT) is proposed to improve the MULT method\nfor question answering tasks. Different datasets, specificay SQuAD, SelQA,\nWikiQA, NewWikiQA and InforBoxQA, are used for evaluation. Moreover, two\ndifferent tasks of question answering - answer selection and answer triggering\n- are evaluated to examine the effectiveness of transfer learning. The results\nshow that using transfer learning generally improves the performance if the\ncorpora are related and are based on the same policy. In addition, using\nISS-MULT could finely improve the MULT method for question answering tasks, and\nthese improvements prove more significant in the answer triggering task.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 19:00:25 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 17:23:02 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Ahmadvand", "Ali", ""], ["Choi", "Jinho D.", ""]]}, {"id": "1708.02275", "submitter": "Yadollah Yaghoobzadeh", "authors": "Yadollah Yaghoobzadeh, Heike Adel and Hinrich Sch\\\"utze", "title": "Corpus-level Fine-grained Entity Typing", "comments": "24 pages. arXiv admin note: text overlap with arXiv:1701.02025,\n  arXiv:1606.07901", "journal-ref": "JAIR, Vol 61 (2018)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of corpus-level entity typing, i.e.,\ninferring from a large corpus that an entity is a member of a class such as\n\"food\" or \"artist\". The application of entity typing we are interested in is\nknowledge base completion, specifically, to learn which classes an entity is a\nmember of. We propose FIGMENT to tackle this problem. FIGMENT is embedding-\nbased and combines (i) a global model that scores based on aggregated\ncontextual information of an entity and (ii) a context model that first scores\nthe individual occurrences of an entity and then aggregates the scores. Each of\nthe two proposed models has some specific properties. For the global model,\nlearning high quality entity representations is crucial because it is the only\nsource used for the predictions. Therefore, we introduce representations using\nname and contexts of entities on the three levels of entity, word, and\ncharacter. We show each has complementary information and a multi-level\nrepresentation is the best. For the context model, we need to use distant\nsupervision since the context-level labels are not available for entities.\nDistant supervised labels are noisy and this harms the performance of models.\nTherefore, we introduce and apply new algorithms for noise mitigation using\nmulti-instance learning. We show the effectiveness of our models in a large\nentity typing dataset, built from Freebase.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 19:41:42 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 03:13:55 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Yaghoobzadeh", "Yadollah", ""], ["Adel", "Heike", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1708.02300", "submitter": "Ramakanth Pasunuru", "authors": "Ramakanth Pasunuru, Mohit Bansal", "title": "Reinforced Video Captioning with Entailment Rewards", "comments": "EMNLP 2017 (9 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence models have shown promising improvements on the temporal\ntask of video captioning, but they optimize word-level cross-entropy loss\nduring training. First, using policy gradient and mixed-loss methods for\nreinforcement learning, we directly optimize sentence-level task-based metrics\n(as rewards), achieving significant improvements over the baseline, based on\nboth automatic metrics and human evaluation on multiple datasets. Next, we\npropose a novel entailment-enhanced reward (CIDEnt) that corrects\nphrase-matching based metrics (such as CIDEr) to only allow for\nlogically-implied partial matches and avoid contradictions, achieving further\nsignificant improvements over the CIDEr-reward model. Overall, our\nCIDEnt-reward model achieves the new state-of-the-art on the MSR-VTT dataset.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 20:50:24 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Pasunuru", "Ramakanth", ""], ["Bansal", "Mohit", ""]]}, {"id": "1708.02312", "submitter": "Yixin Nie", "authors": "Yixin Nie, Mohit Bansal", "title": "Shortcut-Stacked Sentence Encoders for Multi-Domain Inference", "comments": "EMNLP 2017 RepEval Multi-NLI Shared Task (6 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple sequential sentence encoder for multi-domain natural\nlanguage inference. Our encoder is based on stacked bidirectional LSTM-RNNs\nwith shortcut connections and fine-tuning of word embeddings. The overall\nsupervised model uses the above encoder to encode two input sentences into two\nvectors, and then uses a classifier over the vector combination to label the\nrelationship between these two sentences as that of entailment, contradiction,\nor neural. Our Shortcut-Stacked sentence encoders achieve strong improvements\nover existing encoders on matched and mismatched multi-domain natural language\ninference (top non-ensemble single-model result in the EMNLP RepEval 2017\nShared Task (Nangia et al., 2017)). Moreover, they achieve the new\nstate-of-the-art encoding result on the original SNLI dataset (Bowman et al.,\n2015).\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 21:33:11 GMT"}, {"version": "v2", "created": "Tue, 28 Nov 2017 18:15:47 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Nie", "Yixin", ""], ["Bansal", "Mohit", ""]]}, {"id": "1708.02383", "submitter": "Meng Fang", "authors": "Meng Fang, Yuan Li and Trevor Cohn", "title": "Learning how to Active Learn: A Deep Reinforcement Learning Approach", "comments": "To appear in EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning aims to select a small subset of data for annotation such\nthat a classifier learned on the data is highly accurate. This is usually done\nusing heuristic selection methods, however the effectiveness of such methods is\nlimited and moreover, the performance of heuristics varies between datasets. To\naddress these shortcomings, we introduce a novel formulation by reframing the\nactive learning as a reinforcement learning problem and explicitly learning a\ndata selection policy, where the policy takes the role of the active learning\nheuristic. Importantly, our method allows the selection policy learned using\nsimulation on one language to be transferred to other languages. We demonstrate\nour method using cross-lingual named entity recognition, observing uniform\nimprovements over traditional active learning.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 07:06:48 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Fang", "Meng", ""], ["Li", "Yuan", ""], ["Cohn", "Trevor", ""]]}, {"id": "1708.02420", "submitter": "Edison Marrese-Taylor", "authors": "Edison Marrese-Taylor, Jorge A. Balazs, Yutaka Matsuo", "title": "Mining fine-grained opinions on closed captions of YouTube videos with\n  an attention-RNN", "comments": "8th Workshop on Computational Approaches to Subjectivity, Sentiment &\n  Social Media Analysis (WASSA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video reviews are the natural evolution of written product reviews. In this\npaper we target this phenomenon and introduce the first dataset created from\nclosed captions of YouTube product review videos as well as a new attention-RNN\nmodel for aspect extraction and joint aspect extraction and sentiment\nclassification. Our model provides state-of-the-art performance on aspect\nextraction without requiring the usage of hand-crafted features on the SemEval\nABSA corpus, while it outperforms the baseline on the joint task. In our\ndataset, the attention-RNN model outperforms the baseline for both tasks, but\nwe observe important performance drops for all models in comparison to SemEval.\nThese results, as well as further experiments on domain adaptation for aspect\nextraction, suggest that differences between speech and written text, which\nhave been discussed extensively in the literature, also extend to the domain of\nproduct reviews, where they are relevant for fine-grained opinion mining.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 09:27:55 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Marrese-Taylor", "Edison", ""], ["Balazs", "Jorge A.", ""], ["Matsuo", "Yutaka", ""]]}, {"id": "1708.02561", "submitter": "Daniel Ortega", "authors": "Daniel Ortega and Ngoc Thang Vu", "title": "Neural-based Context Representation Learning for Dialog Act\n  Classification", "comments": "5 pages, 1 figure, SIGDIAL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore context representation learning methods in neural-based models for\ndialog act classification. We propose and compare extensively different methods\nwhich combine recurrent neural network architectures and attention mechanisms\n(AMs) at different context levels. Our experimental results on two benchmark\ndatasets show consistent improvements compared to the models without contextual\ninformation and reveal that the most suitable AM in the architecture depends on\nthe nature of the dataset.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 17:03:25 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Ortega", "Daniel", ""], ["Vu", "Ngoc Thang", ""]]}, {"id": "1708.02657", "submitter": "Xiang Zhang", "authors": "Xiang Zhang, Yann LeCun", "title": "Which Encoding is the Best for Text Classification in Chinese, English,\n  Japanese and Korean?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article offers an empirical study on the different ways of encoding\nChinese, Japanese, Korean (CJK) and English languages for text classification.\nDifferent encoding levels are studied, including UTF-8 bytes, characters,\nwords, romanized characters and romanized words. For all encoding levels,\nwhenever applicable, we provide comparisons with linear models, fastText and\nconvolutional networks. For convolutional networks, we compare between encoding\nmechanisms using character glyph images, one-hot (or one-of-n) encoding, and\nembedding. In total there are 473 models, using 14 large-scale text\nclassification datasets in 4 languages including Chinese, English, Japanese and\nKorean. Some conclusions from these results include that byte-level one-hot\nencoding based on UTF-8 consistently produces competitive results for\nconvolutional networks, that word-level n-grams linear models are competitive\neven without perfect word segmentation, and that fastText provides the best\nresult using character-level n-gram encoding but can overfit when the features\nare overly rich.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 21:24:44 GMT"}, {"version": "v2", "created": "Thu, 17 Aug 2017 00:34:08 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Zhang", "Xiang", ""], ["LeCun", "Yann", ""]]}, {"id": "1708.02702", "submitter": "Christophe Van Gysel", "authors": "Christophe Van Gysel, Maarten de Rijke and Evangelos Kanoulas", "title": "Neural Vector Spaces for Unsupervised Information Retrieval", "comments": "TOIS 2018", "journal-ref": null, "doi": "10.1145/3196826", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Neural Vector Space Model (NVSM), a method that learns\nrepresentations of documents in an unsupervised manner for news article\nretrieval. In the NVSM paradigm, we learn low-dimensional representations of\nwords and documents from scratch using gradient descent and rank documents\naccording to their similarity with query representations that are composed from\nword representations. We show that NVSM performs better at document ranking\nthan existing latent semantic vector space methods. The addition of NVSM to a\nmixture of lexical language models and a state-of-the-art baseline vector space\nmodel yields a statistically significant increase in retrieval effectiveness.\nConsequently, NVSM adds a complementary relevance signal. Next to semantic\nmatching, we find that NVSM performs well in cases where lexical matching is\nneeded.\n  NVSM learns a notion of term specificity directly from the document\ncollection without feature engineering. We also show that NVSM learns\nregularities related to Luhn significance. Finally, we give advice on how to\ndeploy NVSM in situations where model selection (e.g., cross-validation) is\ninfeasible. We find that an unsupervised ensemble of multiple models trained\nwith different hyperparameter values performs better than a single\ncross-validated model. Therefore, NVSM can safely be used for ranking documents\nwithout supervised relevance judgments.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 03:21:20 GMT"}, {"version": "v2", "created": "Mon, 13 Nov 2017 14:26:58 GMT"}, {"version": "v3", "created": "Wed, 11 Apr 2018 07:51:23 GMT"}, {"version": "v4", "created": "Sat, 18 Aug 2018 13:44:56 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Van Gysel", "Christophe", ""], ["de Rijke", "Maarten", ""], ["Kanoulas", "Evangelos", ""]]}, {"id": "1708.02709", "submitter": "Soujanya Poria", "authors": "Tom Young, Devamanyu Hazarika, Soujanya Poria and Erik Cambria", "title": "Recent Trends in Deep Learning Based Natural Language Processing", "comments": "Added BERT, ELMo, Transformer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Deep learning methods employ multiple processing layers to learn hierarchical\nrepresentations of data and have produced state-of-the-art results in many\ndomains. Recently, a variety of model designs and methods have blossomed in the\ncontext of natural language processing (NLP). In this paper, we review\nsignificant deep learning related models and methods that have been employed\nfor numerous NLP tasks and provide a walk-through of their evolution. We also\nsummarize, compare and contrast the various models and put forward a detailed\nunderstanding of the past, present and future of deep learning in NLP.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 04:02:17 GMT"}, {"version": "v2", "created": "Mon, 14 Aug 2017 15:48:19 GMT"}, {"version": "v3", "created": "Tue, 15 Aug 2017 15:28:21 GMT"}, {"version": "v4", "created": "Wed, 16 Aug 2017 04:11:12 GMT"}, {"version": "v5", "created": "Tue, 20 Feb 2018 08:08:36 GMT"}, {"version": "v6", "created": "Sat, 4 Aug 2018 10:22:09 GMT"}, {"version": "v7", "created": "Wed, 10 Oct 2018 13:46:59 GMT"}, {"version": "v8", "created": "Sun, 25 Nov 2018 03:26:49 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Young", "Tom", ""], ["Hazarika", "Devamanyu", ""], ["Poria", "Soujanya", ""], ["Cambria", "Erik", ""]]}, {"id": "1708.02711", "submitter": "Damien Teney", "authors": "Damien Teney, Peter Anderson, Xiaodong He, Anton van den Hengel", "title": "Tips and Tricks for Visual Question Answering: Learnings from the 2017\n  Challenge", "comments": "Winner of the 2017 Visual Question Answering (VQA) Challenge at CVPR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a state-of-the-art model for visual question answering\n(VQA), which won the first place in the 2017 VQA Challenge. VQA is a task of\nsignificant importance for research in artificial intelligence, given its\nmultimodal nature, clear evaluation protocol, and potential real-world\napplications. The performance of deep neural networks for VQA is very dependent\non choices of architectures and hyperparameters. To help further research in\nthe area, we describe in detail our high-performing, though relatively simple\nmodel. Through a massive exploration of architectures and hyperparameters\nrepresenting more than 3,000 GPU-hours, we identified tips and tricks that lead\nto its success, namely: sigmoid outputs, soft training targets, image features\nfrom bottom-up attention, gated tanh activations, output embeddings initialized\nusing GloVe and Google Images, large mini-batches, and smart shuffling of\ntraining data. We provide a detailed analysis of their impact on performance to\nassist others in making an appropriate selection.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 04:19:42 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Teney", "Damien", ""], ["Anderson", "Peter", ""], ["He", "Xiaodong", ""], ["Hengel", "Anton van den", ""]]}, {"id": "1708.02912", "submitter": "Tharindu Weerasooriya", "authors": "Tharindu Weerasooriya, Nandula Perera and S.R. Liyanage", "title": "KeyXtract Twitter Model - An Essential Keywords Extraction Model for\n  Twitter Designed using NLP Tools", "comments": "7 Pages, 5 Figures, Proceedings of the 10th KDU International\n  Research Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since a tweet is limited to 140 characters, it is ambiguous and difficult for\ntraditional Natural Language Processing (NLP) tools to analyse. This research\npresents KeyXtract which enhances the machine learning based Stanford CoreNLP\nPart-of-Speech (POS) tagger with the Twitter model to extract essential\nkeywords from a tweet. The system was developed using rule-based parsers and\ntwo corpora. The data for the research was obtained from a Twitter profile of a\ntelecommunication company. The system development consisted of two stages. At\nthe initial stage, a domain specific corpus was compiled after analysing the\ntweets. The POS tagger extracted the Noun Phrases and Verb Phrases while the\nparsers removed noise and extracted any other keywords missed by the POS\ntagger. The system was evaluated using the Turing Test. After it was tested and\ncompared against Stanford CoreNLP, the second stage of the system was developed\naddressing the shortcomings of the first stage. It was enhanced using Named\nEntity Recognition and Lemmatization. The second stage was also tested using\nthe Turing test and its pass rate increased from 50.00% to 83.33%. The\nperformance of the final system output was measured using the F1 score.\nStanford CoreNLP with the Twitter model had an average F1 of 0.69 while the\nimproved system had a F1 of 0.77. The accuracy of the system could be improved\nby using a complete domain specific corpus. Since the system used linguistic\nfeatures of a sentence, it could be applied to other NLP tools.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 17:04:34 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Weerasooriya", "Tharindu", ""], ["Perera", "Nandula", ""], ["Liyanage", "S. R.", ""]]}, {"id": "1708.02977", "submitter": "Licheng Yu", "authors": "Licheng Yu and Mohit Bansal and Tamara L. Berg", "title": "Hierarchically-Attentive RNN for Album Summarization and Storytelling", "comments": "To appear at EMNLP-2017 (7 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of end-to-end visual storytelling. Given a photo\nalbum, our model first selects the most representative (summary) photos, and\nthen composes a natural language story for the album. For this task, we make\nuse of the Visual Storytelling dataset and a model composed of three\nhierarchically-attentive Recurrent Neural Nets (RNNs) to: encode the album\nphotos, select representative (summary) photos, and compose the story.\nAutomatic and human evaluations show our model achieves better performance on\nselection, generation, and retrieval than baselines.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 19:26:47 GMT"}], "update_date": "2017-08-11", "authors_parsed": [["Yu", "Licheng", ""], ["Bansal", "Mohit", ""], ["Berg", "Tamara L.", ""]]}, {"id": "1708.02989", "submitter": "Luis Moraes", "authors": "Luis Moraes, Shahryar Baki, Rakesh Verma, Daniel Lee", "title": "Identifying Reference Spans: Topic Modeling and Word Embeddings help IR", "comments": null, "journal-ref": null, "doi": "10.1007/s00799-017-0220-z", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CL-SciSumm 2016 shared task introduced an interesting problem: given a\ndocument D and a piece of text that cites D, how do we identify the text spans\nof D being referenced by the piece of text? The shared task provided the first\nannotated dataset for studying this problem. We present an analysis of our\ncontinued work in improving our system's performance on this task. We\ndemonstrate how topic models and word embeddings can be used to surpass the\npreviously best performing system.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 19:58:55 GMT"}], "update_date": "2017-08-11", "authors_parsed": [["Moraes", "Luis", ""], ["Baki", "Shahryar", ""], ["Verma", "Rakesh", ""], ["Lee", "Daniel", ""]]}, {"id": "1708.03044", "submitter": "Ting-Hao Huang", "authors": "Ting-Hao Kenneth Huang and Walter S. Lasecki and Amos Azaria and\n  Jeffrey P. Bigham", "title": "\"Is there anything else I can help you with?\": Challenges in Deploying\n  an On-Demand Crowd-Powered Conversational Agent", "comments": "10 pages. In Proceedings of Conference on Human Computation &\n  Crowdsourcing (HCOMP 2016), 2016, Austin, TX, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent conversational assistants, such as Apple's Siri, Microsoft's\nCortana, and Amazon's Echo, have quickly become a part of our digital life.\nHowever, these assistants have major limitations, which prevents users from\nconversing with them as they would with human dialog partners. This limits our\nability to observe how users really want to interact with the underlying\nsystem. To address this problem, we developed a crowd-powered conversational\nassistant, Chorus, and deployed it to see how users and workers would interact\ntogether when mediated by the system. Chorus sophisticatedly converses with end\nusers over time by recruiting workers on demand, which in turn decide what\nmight be the best response for each user sentence. Up to the first month of our\ndeployment, 59 users have held conversations with Chorus during 320\nconversational sessions. In this paper, we present an account of Chorus'\ndeployment, with a focus on four challenges: (i) identifying when conversations\nare over, (ii) malicious users and workers, (iii) on-demand recruiting, and\n(iv) settings in which consensus is not enough. Our observations could assist\nthe deployment of crowd-powered conversation systems and crowd-powered systems\nin general.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 01:40:49 GMT"}], "update_date": "2017-08-11", "authors_parsed": [["Huang", "Ting-Hao Kenneth", ""], ["Lasecki", "Walter S.", ""], ["Azaria", "Amos", ""], ["Bigham", "Jeffrey P.", ""]]}, {"id": "1708.03052", "submitter": "Lee Gao", "authors": "Lee Gao, Ronghuo Zheng", "title": "Communication-Free Parallel Supervised Topic Models", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embarrassingly (communication-free) parallel Markov chain Monte Carlo (MCMC)\nmethods are commonly used in learning graphical models. However, MCMC cannot be\ndirectly applied in learning topic models because of the quasi-ergodicity\nproblem caused by multimodal distribution of topics. In this paper, we develop\nan embarrassingly parallel MCMC algorithm for sLDA. Our algorithm works by\nswitching the order of sampled topics combination and labeling variable\nprediction in sLDA, in which it overcomes the quasi-ergodicity problem because\nhigh-dimension topics that follow a multimodal distribution are projected into\none-dimension document labels that follow a unimodal distribution. Our\nempirical experiments confirm that the out-of-sample prediction performance\nusing our embarrassingly parallel algorithm is comparable to non-parallel sLDA\nwhile the computation time is significantly reduced.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 02:03:52 GMT"}], "update_date": "2017-08-11", "authors_parsed": [["Gao", "Lee", ""], ["Zheng", "Ronghuo", ""]]}, {"id": "1708.03105", "submitter": "Hussein S. Al-Olimat", "authors": "Hussein S. Al-Olimat, Krishnaprasad Thirunarayan, Valerie Shalin, and\n  Amit Sheth", "title": "Location Name Extraction from Targeted Text Streams using\n  Gazetteer-based Statistical Language Models", "comments": "https://www.aclweb.org/anthology/C18-1169.pdf", "journal-ref": "In The 27th International Conference on Computational Linguistics\n  (COLING 2018)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Extracting location names from informal and unstructured social media data\nrequires the identification of referent boundaries and partitioning compound\nnames. Variability, particularly systematic variability in location names\n(Carroll, 1983), challenges the identification task. Some of this variability\ncan be anticipated as operations within a statistical language model, in this\ncase drawn from gazetteers such as OpenStreetMap (OSM), Geonames, and DBpedia.\nThis permits evaluation of an observed n-gram in Twitter targeted text as a\nlegitimate location name variant from the same location-context. Using n-gram\nstatistics and location-related dictionaries, our Location Name Extraction tool\n(LNEx) handles abbreviations and automatically filters and augments the\nlocation names in gazetteers (handling name contractions and auxiliary\ncontents) to help detect the boundaries of multi-word location names and\nthereby delimit them in texts.\n  We evaluated our approach on 4,500 event-specific tweets from three targeted\nstreams to compare the performance of LNEx against that of ten state-of-the-art\ntaggers that rely on standard semantic, syntactic and/or orthographic features.\nLNEx improved the average F-Score by 33-179%, outperforming all taggers.\nFurther, LNEx is capable of stream processing.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 07:43:13 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 23:00:29 GMT"}, {"version": "v3", "created": "Sun, 26 Apr 2020 19:25:09 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Al-Olimat", "Hussein S.", ""], ["Thirunarayan", "Krishnaprasad", ""], ["Shalin", "Valerie", ""], ["Sheth", "Amit", ""]]}, {"id": "1708.03152", "submitter": "Zhao Meng", "authors": "Zhao Meng, Lili Mou, Zhi Jin", "title": "Towards Neural Speaker Modeling in Multi-Party Conversation: The Task,\n  Dataset, and Models", "comments": "In Proceedings of the Language Resources and Evaluation Conference\n  (LREC), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network-based dialog systems are attracting increasing attention in\nboth academia and industry. Recently, researchers have begun to realize the\nimportance of speaker modeling in neural dialog systems, but there lacks\nestablished tasks and datasets. In this paper, we propose speaker\nclassification as a surrogate task for general speaker modeling, and collect\nmassive data to facilitate research in this direction. We further investigate\ntemporal-based and content-based models of speakers, and propose several\nhybrids of them. Experiments show that speaker classification is feasible, and\nthat hybrid models outperform each single component.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 10:21:31 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 17:51:57 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Meng", "Zhao", ""], ["Mou", "Lili", ""], ["Jin", "Zhi", ""]]}, {"id": "1708.03186", "submitter": "Evgeny Matusov", "authors": "Shahram Khadivi, Patrick Wilken, Leonard Dahlmann, Evgeny Matusov", "title": "Neural and Statistical Methods for Leveraging Meta-information in\n  Machine Translation", "comments": "To appear in MT Summit 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss different methods which use meta information and\nricher context that may accompany source language input to improve machine\ntranslation quality. We focus on category information of input text as meta\ninformation, but the proposed methods can be extended to all textual and\nnon-textual meta information that might be available for the input text or\nautomatically predicted using the text content. The main novelty of this work\nis to use state-of-the-art neural network methods to tackle this problem within\na statistical machine translation (SMT) framework. We observe translation\nquality improvements up to 3% in terms of BLEU score in some text categories.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 12:48:07 GMT"}], "update_date": "2017-08-11", "authors_parsed": [["Khadivi", "Shahram", ""], ["Wilken", "Patrick", ""], ["Dahlmann", "Leonard", ""], ["Matusov", "Evgeny", ""]]}, {"id": "1708.03246", "submitter": "Dasha Bogdanova", "authors": "Dasha Bogdanova, Majid Yazdani", "title": "SESA: Supervised Explicit Semantic Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years supervised representation learning has provided state of the\nart or close to the state of the art results in semantic analysis tasks\nincluding ranking and information retrieval. The core idea is to learn how to\nembed items into a latent space such that they optimize a supervised objective\nin that latent space. The dimensions of the latent space have no clear\nsemantics, and this reduces the interpretability of the system. For example, in\npersonalization models, it is hard to explain why a particular item is ranked\nhigh for a given user profile. We propose a novel model of representation\nlearning called Supervised Explicit Semantic Analysis (SESA) that is trained in\na supervised fashion to embed items to a set of dimensions with explicit\nsemantics. The model learns to compare two objects by representing them in this\nexplicit space, where each dimension corresponds to a concept from a knowledge\nbase. This work extends Explicit Semantic Analysis (ESA) with a supervised\nmodel for ranking problems. We apply this model to the task of Job-Profile\nrelevance in LinkedIn in which a set of skills defines our explicit dimensions\nof the space. Every profile and job are encoded to this set of skills their\nsimilarity is calculated in this space. We use RNNs to embed text input into\nthis space. In addition to interpretability, our model makes use of the\nweb-scale collaborative skills data that is provided by users for each LinkedIn\nprofile. Our model provides state of the art result while it remains\ninterpretable.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 15:03:12 GMT"}], "update_date": "2017-08-11", "authors_parsed": [["Bogdanova", "Dasha", ""], ["Yazdani", "Majid", ""]]}, {"id": "1708.03271", "submitter": "Evgeny Matusov", "authors": "Leonard Dahlmann, Evgeny Matusov, Pavel Petrushkov, Shahram Khadivi", "title": "Neural Machine Translation Leveraging Phrase-based Models in a Hybrid\n  Search", "comments": "To appear in Proceedings of EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a hybrid search for attention-based neural\nmachine translation (NMT). A target phrase learned with statistical MT models\nextends a hypothesis in the NMT beam search when the attention of the NMT model\nfocuses on the source words translated by this phrase. Phrases added in this\nway are scored with the NMT model, but also with SMT features including\nphrase-level translation probabilities and a target language model.\nExperimental results on German->English news domain and English->Russian\ne-commerce domain translation tasks show that using phrase-based models in NMT\nsearch improves MT quality by up to 2.3% BLEU absolute as compared to a strong\nNMT baseline.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 15:48:33 GMT"}], "update_date": "2017-08-11", "authors_parsed": [["Dahlmann", "Leonard", ""], ["Matusov", "Evgeny", ""], ["Petrushkov", "Pavel", ""], ["Khadivi", "Shahram", ""]]}, {"id": "1708.03312", "submitter": "Yuanzhi Ke", "authors": "Yuanzhi Ke and Masafumi Hagiwara", "title": "Radical-level Ideograph Encoder for RNN-based Sentiment Analysis of\n  Chinese and Japanese", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The character vocabulary can be very large in non-alphabetic languages such\nas Chinese and Japanese, which makes neural network models huge to process such\nlanguages. We explored a model for sentiment classification that takes the\nembeddings of the radicals of the Chinese characters, i.e, hanzi of Chinese and\nkanji of Japanese. Our model is composed of a CNN word feature encoder and a\nbi-directional RNN document feature encoder. The results achieved are on par\nwith the character embedding-based models, and close to the state-of-the-art\nword embedding-based models, with 90% smaller vocabulary, and at least 13% and\n80% fewer parameters than the character embedding-based models and word\nembedding-based models respectively. The results suggest that the radical\nembedding-based approach is cost-effective for machine learning on Chinese and\nJapanese.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 17:46:28 GMT"}], "update_date": "2017-08-11", "authors_parsed": [["Ke", "Yuanzhi", ""], ["Hagiwara", "Masafumi", ""]]}, {"id": "1708.03390", "submitter": "Alexander Panchenko", "authors": "Maria Pelevina, Nikolay Arefyev, Chris Biemann, Alexander Panchenko", "title": "Making Sense of Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a simple yet effective approach for learning word sense\nembeddings. In contrast to existing techniques, which either directly learn\nsense representations from corpora or rely on sense inventories from lexical\nresources, our approach can induce a sense inventory from existing word\nembeddings via clustering of ego-networks of related words. An integrated WSD\nmechanism enables labeling of words in context with learned sense vectors,\nwhich gives rise to downstream applications. Experiments show that the\nperformance of our method is comparable to state-of-the-art unsupervised WSD\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 21:27:57 GMT"}], "update_date": "2017-08-14", "authors_parsed": [["Pelevina", "Maria", ""], ["Arefyev", "Nikolay", ""], ["Biemann", "Chris", ""], ["Panchenko", "Alexander", ""]]}, {"id": "1708.03418", "submitter": "Mostafa Dehghani", "authors": "Mostafa Dehghani, Sascha Rothe, Enrique Alfonseca, Pascal Fleury", "title": "Learning to Attend, Copy, and Generate for Session-Based Query\n  Suggestion", "comments": "Accepted to be published at The 26th ACM International Conference on\n  Information and Knowledge Management (CIKM2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users try to articulate their complex information needs during search\nsessions by reformulating their queries. To make this process more effective,\nsearch engines provide related queries to help users in specifying the\ninformation need in their search process. In this paper, we propose a\ncustomized sequence-to-sequence model for session-based query suggestion. In\nour model, we employ a query-aware attention mechanism to capture the structure\nof the session context. is enables us to control the scope of the session from\nwhich we infer the suggested next query, which helps not only handle the noisy\ndata but also automatically detect session boundaries. Furthermore, we observe\nthat, based on the user query reformulation behavior, within a single session a\nlarge portion of query terms is retained from the previously submitted queries\nand consists of mostly infrequent or unseen terms that are usually not included\nin the vocabulary. We therefore empower the decoder of our model to access the\nsource words from the session context during decoding by incorporating a copy\nmechanism. Moreover, we propose evaluation metrics to assess the quality of the\ngenerative models for query suggestion. We conduct an extensive set of\nexperiments and analysis. e results suggest that our model outperforms the\nbaselines both in terms of the generating queries and scoring candidate queries\nfor the task of query suggestion.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 00:55:57 GMT"}, {"version": "v2", "created": "Thu, 7 Sep 2017 12:02:09 GMT"}, {"version": "v3", "created": "Tue, 19 Sep 2017 10:43:53 GMT"}, {"version": "v4", "created": "Mon, 13 Nov 2017 11:29:43 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Dehghani", "Mostafa", ""], ["Rothe", "Sascha", ""], ["Alfonseca", "Enrique", ""], ["Fleury", "Pascal", ""]]}, {"id": "1708.03421", "submitter": "Leila Kosseim", "authors": "Andre Cianflone and Leila Kosseim", "title": "N-gram and Neural Language Models for Discriminating Similar Languages", "comments": "8 pages", "journal-ref": "Proceedings of the Third Workshop on NLP for Similar Languages,\n  Varieties and Dialects (VarDial3). A workshop of the 26th International\n  Conference on Computational Linguistics (COLING 2016, Osaka, Japan), pp\n  243-250 (2016)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our submission (named clac) to the 2016 Discriminating\nSimilar Languages (DSL) shared task. We participated in the closed Sub-task 1\n(Set A) with two separate machine learning techniques. The first approach is a\ncharacter based Convolution Neural Network with a bidirectional long short term\nmemory (BiLSTM) layer (CLSTM), which achieved an accuracy of 78.45% with\nminimal tuning. The second approach is a character-based n-gram model. This\nlast approach achieved an accuracy of 88.45% which is close to the accuracy of\n89.38% achieved by the best submission, and allowed us to rank #7 overall.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 02:27:26 GMT"}], "update_date": "2017-08-14", "authors_parsed": [["Cianflone", "Andre", ""], ["Kosseim", "Leila", ""]]}, {"id": "1708.03425", "submitter": "Leila Kosseim", "authors": "Sohail Hooda and Leila Kosseim", "title": "Argument Labeling of Explicit Discourse Relations using LSTM Neural\n  Networks", "comments": "Proceedings of Recent Advances in Natural Language Processing (RANLP\n  2017), pp. 309-315, 4-6 September, Varna, Bulgaria", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Argument labeling of explicit discourse relations is a challenging task. The\nstate of the art systems achieve slightly above 55% F-measure but require\nhand-crafted features. In this paper, we propose a Long Short Term Memory\n(LSTM) based model for argument labeling. We experimented with multiple\nconfigurations of our model. Using the PDTB dataset, our best model achieved an\nF1 measure of 23.05% without any feature engineering. This is significantly\nhigher than the 20.52% achieved by the state of the art RNN approach, but\nsignificantly lower than the feature based state of the art systems. On the\nother hand, because our approach learns only from the raw dataset, it is more\nwidely applicable to multiple textual genres and languages.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 03:46:31 GMT"}, {"version": "v2", "created": "Thu, 7 Sep 2017 17:48:50 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Hooda", "Sohail", ""], ["Kosseim", "Leila", ""]]}, {"id": "1708.03446", "submitter": "Sunil Sahu", "authors": "Sunil Kumar Sahu, Ashish Anand", "title": "What matters in a transferable neural network model for relation\n  classification in the biomedical domain?", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lack of sufficient labeled data often limits the applicability of advanced\nmachine learning algorithms to real life problems. However efficient use of\nTransfer Learning (TL) has been shown to be very useful across domains. TL\nutilizes valuable knowledge learned in one task (source task), where sufficient\ndata is available, to the task of interest (target task). In biomedical and\nclinical domain, it is quite common that lack of sufficient training data do\nnot allow to fully exploit machine learning models. In this work, we present\ntwo unified recurrent neural models leading to three transfer learning\nframeworks for relation classification tasks. We systematically investigate\neffectiveness of the proposed frameworks in transferring the knowledge under\nmultiple aspects related to source and target tasks, such as, similarity or\nrelatedness between source and target tasks, and size of training data for\nsource task. Our empirical results show that the proposed frameworks in general\nimprove the model performance, however these improvements do depend on aspects\nrelated to source and target tasks. This dependence then finally determine the\nchoice of a particular TL framework.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 06:21:22 GMT"}, {"version": "v2", "created": "Mon, 14 Aug 2017 04:53:48 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Sahu", "Sunil Kumar", ""], ["Anand", "Ashish", ""]]}, {"id": "1708.03447", "submitter": "Sunil Sahu", "authors": "Sunil Kumar Sahu, Ashish Anand", "title": "Unified Neural Architecture for Drug, Disease and Clinical Entity\n  Recognition", "comments": "23 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing methods for biomedical entity recognition task rely on explicit\nfeature engineering where many features either are specific to a particular\ntask or depends on output of other existing NLP tools. Neural architectures\nhave been shown across various domains that efforts for explicit feature design\ncan be reduced. In this work we propose an unified framework using\nbi-directional long short term memory network (BLSTM) for named entity\nrecognition (NER) tasks in biomedical and clinical domains. Three important\ncharacteristics of the framework are as follows - (1) model learns contextual\nas well as morphological features using two different BLSTM in hierarchy, (2)\nmodel uses first order linear conditional random field (CRF) in its output\nlayer in cascade of BLSTM to infer label or tag sequence, (3) model does not\nuse any domain specific features or dictionary, i.e., in another words, same\nset of features are used in the three NER tasks, namely, disease name\nrecognition (Disease NER), drug name recognition (Drug NER) and clinical entity\nrecognition (Clinical NER). We compare performance of the proposed model with\nexisting state-of-the-art models on the standard benchmark datasets of the\nthree tasks. We show empirically that the proposed framework outperforms all\nexisting models. Further our analysis of CRF layer and word-embedding obtained\nusing character based embedding show their importance.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 06:30:23 GMT"}], "update_date": "2017-08-14", "authors_parsed": [["Sahu", "Sunil Kumar", ""], ["Anand", "Ashish", ""]]}, {"id": "1708.03492", "submitter": "Lucas Sterckx", "authors": "Lucas Sterckx, Jason Naradowsky, Bill Byrne, Thomas Demeester and\n  Chris Develder", "title": "Break it Down for Me: A Study in Automated Lyric Annotation", "comments": "To appear in Proceedings of EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comprehending lyrics, as found in songs and poems, can pose a challenge to\nhuman and machine readers alike. This motivates the need for systems that can\nunderstand the ambiguity and jargon found in such creative texts, and provide\ncommentary to aid readers in reaching the correct interpretation. We introduce\nthe task of automated lyric annotation (ALA). Like text simplification, a goal\nof ALA is to rephrase the original text in a more easily understandable manner.\nHowever, in ALA the system must often include additional information to clarify\nniche terminology and abstract concepts. To stimulate research on this task, we\nrelease a large collection of crowdsourced annotations for song lyrics. We\nanalyze the performance of translation and retrieval models on this task,\nmeasuring performance with both automated and human evaluation. We find that\neach model captures a unique type of information important to the task.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 09:58:39 GMT"}], "update_date": "2017-08-14", "authors_parsed": [["Sterckx", "Lucas", ""], ["Naradowsky", "Jason", ""], ["Byrne", "Bill", ""], ["Demeester", "Thomas", ""], ["Develder", "Chris", ""]]}, {"id": "1708.03541", "submitter": "Leila Kosseim", "authors": "Elnaz Davoodi and Leila Kosseim", "title": "Automatic Identification of AltLexes using Monolingual Parallel Corpora", "comments": "6 pages, Proceedings of Recent Advances in Natural Language\n  Processing (RANLP 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automatic identification of discourse relations is still a challenging\ntask in natural language processing. Discourse connectives, such as \"since\" or\n\"but\", are the most informative cues to identify explicit relations; however\ndiscourse parsers typically use a closed inventory of such connectives. As a\nresult, discourse relations signaled by markers outside these inventories (i.e.\nAltLexes) are not detected as effectively. In this paper, we propose a novel\nmethod to leverage parallel corpora in text simplification and lexical\nresources to automatically identify alternative lexicalizations that signal\ndiscourse relation. When applied to the Simple Wikipedia and Newsela corpora\nalong with WordNet and the PPDB, the method allowed the automatic discovery of\n91 AltLexes.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 13:45:48 GMT"}], "update_date": "2017-08-14", "authors_parsed": [["Davoodi", "Elnaz", ""], ["Kosseim", "Leila", ""]]}, {"id": "1708.03569", "submitter": "Erich Schubert", "authors": "Erich Schubert and Andreas Spitz and Michael Weiler and Johanna\n  Gei{\\ss} and Michael Gertz", "title": "Semantic Word Clouds with Background Corpus Normalization and\n  t-distributed Stochastic Neighbor Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many word clouds provide no semantics to the word placement, but use a random\nlayout optimized solely for aesthetic purposes. We propose a novel approach to\nmodel word significance and word affinity within a document, and in comparison\nto a large background corpus. We demonstrate its usefulness for generating more\nmeaningful word clouds as a visual summary of a given document. We then select\nkeywords based on their significance and construct the word cloud based on the\nderived affinity. Based on a modified t-distributed stochastic neighbor\nembedding (t-SNE), we generate a semantic word placement. For words that\ncooccur significantly, we include edges, and cluster the words according to\ntheir cooccurrence. For this we designed a scalable and memory-efficient\nsketch-based approach usable on commodity hardware to aggregate the required\ncorpus statistics needed for normalization, and for identifying keywords as\nwell as significant cooccurences. We empirically validate our approch using a\nlarge Wikipedia corpus.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 15:19:53 GMT"}], "update_date": "2017-08-14", "authors_parsed": [["Schubert", "Erich", ""], ["Spitz", "Andreas", ""], ["Weiler", "Michael", ""], ["Gei\u00df", "Johanna", ""], ["Gertz", "Michael", ""]]}, {"id": "1708.03629", "submitter": "Vikas Raunak", "authors": "Vikas Raunak", "title": "Simple and Effective Dimensionality Reduction for Word Embeddings", "comments": "Accepted at NIPS 2017 LLD Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings have become the basic building blocks for several natural\nlanguage processing and information retrieval tasks. Pre-trained word\nembeddings are used in several downstream applications as well as for\nconstructing representations for sentences, paragraphs and documents. Recently,\nthere has been an emphasis on further improving the pre-trained word vectors\nthrough post-processing algorithms. One such area of improvement is the\ndimensionality reduction of the word embeddings. Reducing the size of word\nembeddings through dimensionality reduction can improve their utility in memory\nconstrained devices, benefiting several real-world applications. In this work,\nwe present a novel algorithm that effectively combines PCA based dimensionality\nreduction with a recently proposed post-processing algorithm, to construct word\nembeddings of lower dimensions. Empirical evaluations on 12 standard word\nsimilarity benchmarks show that our algorithm reduces the embedding\ndimensionality by 50%, while achieving similar or (more often) better\nperformance than the higher dimension embeddings.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 17:52:36 GMT"}, {"version": "v2", "created": "Sun, 19 Nov 2017 09:01:16 GMT"}, {"version": "v3", "created": "Tue, 21 Nov 2017 14:06:32 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Raunak", "Vikas", ""]]}, {"id": "1708.03696", "submitter": "Saif Mohammad Dr.", "authors": "Saif M. Mohammad and Felipe Bravo-Marquez", "title": "Emotion Intensities in Tweets", "comments": "http://saifmohammad.com/WebPages/EmotionIntensity-SharedTask.html\n  http://saifmohammad.com/WebPages/ResearchAreas.html, In Proceedings of the\n  Sixth Joint Conference on Lexical and Computational Semantics (*Sem), August\n  2017, Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines the task of detecting intensity of emotion from text. We\ncreate the first datasets of tweets annotated for anger, fear, joy, and sadness\nintensities. We use a technique called best--worst scaling (BWS) that improves\nannotation consistency and obtains reliable fine-grained scores. We show that\nemotion-word hashtags often impact emotion intensity, usually conveying a more\nintense emotion. Finally, we create a benchmark regression system and conduct\nexperiments to determine: which features are useful for detecting emotion\nintensity, and, the extent to which two emotions are similar in terms of how\nthey manifest in language.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 20:33:02 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Mohammad", "Saif M.", ""], ["Bravo-Marquez", "Felipe", ""]]}, {"id": "1708.03699", "submitter": "Prodromos Malakasiotis", "authors": "John Pavlopoulos, Prodromos Malakasiotis, Juli Bakagianni, Ion\n  Androutsopoulos", "title": "Improved Abusive Comment Moderation with User Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimenting with a dataset of approximately 1.6M user comments from a Greek\nnews sports portal, we explore how a state of the art RNN-based moderation\nmethod can be improved by adding user embeddings, user type embeddings, user\nbiases, or user type biases. We observe improvements in all cases, with user\nembeddings leading to the biggest performance gains.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 20:37:27 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Pavlopoulos", "John", ""], ["Malakasiotis", "Prodromos", ""], ["Bakagianni", "Juli", ""], ["Androutsopoulos", "Ion", ""]]}, {"id": "1708.03700", "submitter": "Saif Mohammad Dr.", "authors": "Saif M. Mohammad and Felipe Bravo-Marquez", "title": "WASSA-2017 Shared Task on Emotion Intensity", "comments": "http://saifmohammad.com/WebPages/EmotionIntensity-SharedTask.html, In\n  Proceedings of the EMNLP 2017 Workshop on Computational Approaches to\n  Subjectivity, Sentiment, and Social Media (WASSA), September 2017,\n  Copenhagen, Denmark", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first shared task on detecting the intensity of emotion felt\nby the speaker of a tweet. We create the first datasets of tweets annotated for\nanger, fear, joy, and sadness intensities using a technique called best--worst\nscaling (BWS). We show that the annotations lead to reliable fine-grained\nintensity scores (rankings of tweets by intensity). The data was partitioned\ninto training, development, and test sets for the competition. Twenty-two teams\nparticipated in the shared task, with the best system obtaining a Pearson\ncorrelation of 0.747 with the gold intensity scores. We summarize the machine\nlearning setups, resources, and tools used by the participating teams, with a\nfocus on the techniques and resources that are particularly useful for the\ntask. The emotion intensity dataset and the shared task are helping improve our\nunderstanding of how we convey more or less intense emotions through language.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 20:40:07 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Mohammad", "Saif M.", ""], ["Bravo-Marquez", "Felipe", ""]]}, {"id": "1708.03743", "submitter": "Hoifung Poon", "authors": "Nanyun Peng, Hoifung Poon, Chris Quirk, Kristina Toutanova, Wen-tau\n  Yih", "title": "Cross-Sentence N-ary Relation Extraction with Graph LSTMs", "comments": "Conditional accepted by TACL in December 2016; published in April\n  2017; presented at ACL in August 2017", "journal-ref": "Transactions of the Association for Computational Linguistics\n  (TACL) 2017, Vol 5", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Past work in relation extraction has focused on binary relations in single\nsentences. Recent NLP inroads in high-value domains have sparked interest in\nthe more general setting of extracting n-ary relations that span multiple\nsentences. In this paper, we explore a general relation extraction framework\nbased on graph long short-term memory networks (graph LSTMs) that can be easily\nextended to cross-sentence n-ary relation extraction. The graph formulation\nprovides a unified way of exploring different LSTM approaches and incorporating\nvarious intra-sentential and inter-sentential dependencies, such as sequential,\nsyntactic, and discourse relations. A robust contextual representation is\nlearned for the entities, which serves as input to the relation classifier.\nThis simplifies handling of relations with arbitrary arity, and enables\nmulti-task learning with related relations. We evaluate this framework in two\nimportant precision medicine settings, demonstrating its effectiveness with\nboth conventional supervised learning and distant supervision. Cross-sentence\nextraction produced larger knowledge bases. and multi-task learning\nsignificantly improved extraction accuracy. A thorough analysis of various LSTM\napproaches yielded useful insight the impact of linguistic analysis on\nextraction accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 12 Aug 2017 04:33:52 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Peng", "Nanyun", ""], ["Poon", "Hoifung", ""], ["Quirk", "Chris", ""], ["Toutanova", "Kristina", ""], ["Yih", "Wen-tau", ""]]}, {"id": "1708.03892", "submitter": "Fabio Calefato", "authors": "Fabio Calefato, Filippo Lanubile, Nicole Novielli", "title": "EmoTxt: A Toolkit for Emotion Recognition from Text", "comments": "In Proc. 7th Affective Computing and Intelligent Interaction\n  (ACII'17), San Antonio, TX, USA, Oct. 23-26, 2017, p. 79-80, ISBN:\n  978-1-5386-0563-9", "journal-ref": "In Proc. 7th Affective Computing and Intelligent Interaction\n  (ACII'17), San Antonio, TX, USA, Oct. 23-26, 2017, p. 79-80, ISBN:\n  978-1-5386-0563-9", "doi": null, "report-no": null, "categories": "cs.HC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present EmoTxt, a toolkit for emotion recognition from text, trained and\ntested on a gold standard of about 9K question, answers, and comments from\nonline interactions. We provide empirical evidence of the performance of\nEmoTxt. To the best of our knowledge, EmoTxt is the first open-source toolkit\nsupporting both emotion recognition from text and training of custom emotion\nclassification models.\n", "versions": [{"version": "v1", "created": "Sun, 13 Aug 2017 11:55:02 GMT"}, {"version": "v2", "created": "Fri, 19 Jan 2018 09:21:05 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Calefato", "Fabio", ""], ["Lanubile", "Filippo", ""], ["Novielli", "Nicole", ""]]}, {"id": "1708.03910", "submitter": "Mario Giulianelli", "authors": "Mario Giulianelli", "title": "Semi-supervised emotion lexicon expansion with label propagation and\n  specialized word embeddings", "comments": null, "journal-ref": "Computational Linguistics in the Netherlands Journal, 8, 99-121\n  (2018). Retrieved from https://clinjournal.org/clinj/article/view/82", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There exist two main approaches to automatically extract affective\norientation: lexicon-based and corpus-based. In this work, we argue that these\ntwo methods are compatible and show that combining them can improve the\naccuracy of emotion classifiers. In particular, we introduce a novel variant of\nthe Label Propagation algorithm that is tailored to distributed word\nrepresentations, we apply batch gradient descent to accelerate the optimization\nof label propagation and to make the optimization feasible for large graphs,\nand we propose a reproducible method for emotion lexicon expansion. We conclude\nthat label propagation can expand an emotion lexicon in a meaningful way and\nthat the expanded emotion lexicon can be leveraged to improve the accuracy of\nan emotion classifier.\n", "versions": [{"version": "v1", "created": "Sun, 13 Aug 2017 14:09:22 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Giulianelli", "Mario", ""]]}, {"id": "1708.03920", "submitter": "Jaebok Kim", "authors": "Jaebok Kim, Gwenn Englebienne, Khiet P. Truong, Vanessa Evers", "title": "Towards Speech Emotion Recognition \"in the wild\" using Aggregated\n  Corpora and Deep Multi-Task Learning", "comments": "Published in the proceedings of INTERSPEECH, Stockholm, September,\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the challenges in Speech Emotion Recognition (SER) \"in the wild\" is\nthe large mismatch between training and test data (e.g. speakers and tasks). In\norder to improve the generalisation capabilities of the emotion models, we\npropose to use Multi-Task Learning (MTL) and use gender and naturalness as\nauxiliary tasks in deep neural networks. This method was evaluated in\nwithin-corpus and various cross-corpus classification experiments that simulate\nconditions \"in the wild\". In comparison to Single-Task Learning (STL) based\nstate of the art methods, we found that our MTL method proposed improved\nperformance significantly. Particularly, models using both gender and\nnaturalness achieved more gains than those using either gender or naturalness\nseparately. This benefit was also found in the high-level representations of\nthe feature space, obtained from our method proposed, where discriminative\nemotional clusters could be observed.\n", "versions": [{"version": "v1", "created": "Sun, 13 Aug 2017 15:09:47 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Kim", "Jaebok", ""], ["Englebienne", "Gwenn", ""], ["Truong", "Khiet P.", ""], ["Evers", "Vanessa", ""]]}, {"id": "1708.03940", "submitter": "Tao Yu", "authors": "Tao Yu, Christopher Hidey, Owen Rambow and Kathleen McKeown", "title": "Leveraging Sparse and Dense Feature Combinations for Sentiment\n  Classification", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are one of the most popular approaches for many natural\nlanguage processing tasks such as sentiment analysis. They often outperform\ntraditional machine learning models and achieve the state-of-art results on\nmost tasks. However, many existing deep learning models are complex, difficult\nto train and provide a limited improvement over simpler methods. We propose a\nsimple, robust and powerful model for sentiment classification. This model\noutperforms many deep learning models and achieves comparable results to other\ndeep learning models with complex architectures on sentiment analysis datasets.\nWe publish the code online.\n", "versions": [{"version": "v1", "created": "Sun, 13 Aug 2017 17:38:17 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Yu", "Tao", ""], ["Hidey", "Christopher", ""], ["Rambow", "Owen", ""], ["McKeown", "Kathleen", ""]]}, {"id": "1708.03994", "submitter": "Xiaomo Liu", "authors": "Quanzhi Li, Sameena Shah, Xiaomo Liu, Armineh Nourbakhsh", "title": "Data Sets: Word Embeddings Learned from Tweets and General Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A word embedding is a low-dimensional, dense and real- valued vector\nrepresentation of a word. Word embeddings have been used in many NLP tasks.\nThey are usually gener- ated from a large text corpus. The embedding of a word\ncap- tures both its syntactic and semantic aspects. Tweets are short, noisy and\nhave unique lexical and semantic features that are different from other types\nof text. Therefore, it is necessary to have word embeddings learned\nspecifically from tweets. In this paper, we present ten word embedding data\nsets. In addition to the data sets learned from just tweet data, we also built\nembedding sets from the general data and the combination of tweets with the\ngeneral data. The general data consist of news articles, Wikipedia data and\nother web data. These ten embedding models were learned from about 400 million\ntweets and 7 billion words from the general text. In this paper, we also\npresent two experiments demonstrating how to use the data sets in some NLP\ntasks, such as tweet sentiment analysis and tweet topic classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 02:34:17 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Li", "Quanzhi", ""], ["Shah", "Sameena", ""], ["Liu", "Xiaomo", ""], ["Nourbakhsh", "Armineh", ""]]}, {"id": "1708.03995", "submitter": "Prathusha Kameswara Sarma", "authors": "Prathusha Kameswara Sarma, Bill Sethares", "title": "Sentiment Analysis by Joint Learning of Word Embeddings and Classifier", "comments": "10 pages. Under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are representations of individual words of a text document in\na vector space and they are often use- ful for performing natural language pro-\ncessing tasks. Current state of the art al- gorithms for learning word\nembeddings learn vector representations from large corpora of text documents in\nan unsu- pervised fashion. This paper introduces SWESA (Supervised Word\nEmbeddings for Sentiment Analysis), an algorithm for sentiment analysis via\nword embeddings. SWESA leverages document label infor- mation to learn vector\nrepresentations of words from a modest corpus of text doc- uments by solving an\noptimization prob- lem that minimizes a cost function with respect to both word\nembeddings as well as classification accuracy. Analysis re- veals that SWESA\nprovides an efficient way of estimating the dimension of the word embeddings\nthat are to be learned. Experiments on several real world data sets show that\nSWESA has superior per- formance when compared to previously suggested\napproaches to word embeddings and sentiment analysis tasks.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 02:40:20 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Sarma", "Prathusha Kameswara", ""], ["Sethares", "Bill", ""]]}, {"id": "1708.04120", "submitter": "Marc Szafraniec", "authors": "Marc Szafraniec, Gautier Marti, Philippe Donnat", "title": "Putting Self-Supervised Token Embedding on the Tables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information distribution by electronic messages is a privileged means of\ntransmission for many businesses and individuals, often under the form of\nplain-text tables. As their number grows, it becomes necessary to use an\nalgorithm to extract text and numbers instead of a human. Usual methods are\nfocused on regular expressions or on a strict structure in the data, but are\nnot efficient when we have many variations, fuzzy structure or implicit labels.\nIn this paper we introduce SC2T, a totally self-supervised model for\nconstructing vector representations of tokens in semi-structured messages by\nusing characters and context levels that address these issues. It can then be\nused for an unsupervised labeling of tokens, or be the basis for a\nsemi-supervised information extraction system.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jul 2017 09:35:45 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 12:53:55 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Szafraniec", "Marc", ""], ["Marti", "Gautier", ""], ["Donnat", "Philippe", ""]]}, {"id": "1708.04134", "submitter": "Biplav Srivastava", "authors": "Q Vera Liao, Biplav Srivastava, Pavan Kapanipathi", "title": "A Measure for Dialog Complexity and its Application in Streamlining\n  Service Operations", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialog is a natural modality for interaction between customers and businesses\nin the service industry. As customers call up the service provider, their\ninteractions may be routine or extraordinary. We believe that these\ninteractions, when seen as dialogs, can be analyzed to obtain a better\nunderstanding of customer needs and how to efficiently address them. We\nintroduce the idea of a dialog complexity measure to characterize multi-party\ninteractions, propose a general data-driven method to calculate it, use it to\ndiscover insights in public and enterprise dialog datasets, and demonstrate its\nbeneficial usage in facilitating better handling of customer requests and\nevaluating service agents.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 03:44:35 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Liao", "Q Vera", ""], ["Srivastava", "Biplav", ""], ["Kapanipathi", "Pavan", ""]]}, {"id": "1708.04299", "submitter": "Sayyed Zahiri", "authors": "Sayyed M. Zahiri and Jinho D. Choi", "title": "Emotion Detection on TV Show Transcripts with Sequence-based\n  Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While there have been significant advances in detecting emotions from speech\nand image recognition, emotion detection on text is still under-explored and\nremained as an active research field. This paper introduces a corpus for\ntext-based emotion detection on multiparty dialogue as well as deep neural\nmodels that outperform the existing approaches for document classification. We\nfirst present a new corpus that provides annotation of seven emotions on\nconsecutive utterances in dialogues extracted from the show, Friends. We then\nsuggest four types of sequence-based convolutional neural network models with\nattention that leverage the sequence information encapsulated in dialogue. Our\nbest model shows the accuracies of 37.9% and 54% for fine- and coarse-grained\nemotions, respectively. Given the difficulty of this task, this is promising.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 20:01:44 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Zahiri", "Sayyed M.", ""], ["Choi", "Jinho D.", ""]]}, {"id": "1708.04358", "submitter": "Afshin Rahimi", "authors": "Afshin Rahimi, Timothy Baldwin and Trevor Cohn", "title": "Continuous Representation of Location for Geolocation and Lexical\n  Dialectology using Mixture Density Networks", "comments": "Conference on Empirical Methods in Natural Language Processing (EMNLP\n  2017) September 2017, Copenhagen, Denmark", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for embedding two-dimensional locations in a continuous\nvector space using a neural network-based model incorporating mixtures of\nGaussian distributions, presenting two model variants for text-based\ngeolocation and lexical dialectology. Evaluated over Twitter data, the proposed\nmodel outperforms conventional regression-based geolocation and provides a\nbetter estimate of uncertainty. We also show the effectiveness of the\nrepresentation for predicting words from location in lexical dialectology, and\nevaluate it using the DARE dataset.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 23:52:02 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Rahimi", "Afshin", ""], ["Baldwin", "Timothy", ""], ["Cohn", "Trevor", ""]]}, {"id": "1708.04390", "submitter": "Xirong Li", "authors": "Weiyu Lan, Xirong Li and Jianfeng Dong", "title": "Fluency-Guided Cross-Lingual Image Captioning", "comments": "9 pages, 2 figures, accepted as ORAL by ACM Multimedia 2017", "journal-ref": null, "doi": "10.1145/3123266.3123366", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image captioning has so far been explored mostly in English, as most\navailable datasets are in this language. However, the application of image\ncaptioning should not be restricted by language. Only few studies have been\nconducted for image captioning in a cross-lingual setting. Different from these\nworks that manually build a dataset for a target language, we aim to learn a\ncross-lingual captioning model fully from machine-translated sentences. To\nconquer the lack of fluency in the translated sentences, we propose in this\npaper a fluency-guided learning framework. The framework comprises a module to\nautomatically estimate the fluency of the sentences and another module to\nutilize the estimated fluency scores to effectively train an image captioning\nmodel for the target language. As experiments on two bilingual\n(English-Chinese) datasets show, our approach improves both fluency and\nrelevance of the generated captions in Chinese, but without using any manually\nwritten sentences from the target language.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 03:46:31 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Lan", "Weiyu", ""], ["Li", "Xirong", ""], ["Dong", "Jianfeng", ""]]}, {"id": "1708.04439", "submitter": "Sukriti Verma", "authors": "Sukriti Verma and Vagisha Nidhi", "title": "Extractive Summarization using Deep Learning", "comments": "Accepted to 18th International Conference on Computational\n  Linguistics and Intelligent Text Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a text summarization approach for factual reports using a\ndeep learning model. This approach consists of three phases: feature\nextraction, feature enhancement, and summary generation, which work together to\nassimilate core information and generate a coherent, understandable summary. We\nare exploring various features to improve the set of sentences selected for the\nsummary, and are using a Restricted Boltzmann Machine to enhance and abstract\nthose features to improve resultant accuracy without losing any important\ninformation. The sentences are scored based on those enhanced features and an\nextractive summary is constructed. Experimentation carried out on several\narticles demonstrates the effectiveness of the proposed approach. Source code\navailable at: https://github.com/vagisha-nidhi/TextSummarizer\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 09:08:50 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 07:30:40 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Verma", "Sukriti", ""], ["Nidhi", "Vagisha", ""]]}, {"id": "1708.04469", "submitter": "Thomas Zenkel", "authors": "Thomas Zenkel, Ramon Sanabria, Florian Metze, Jan Niehues, Matthias\n  Sperber, Sebastian St\\\"uker, Alex Waibel", "title": "Comparison of Decoding Strategies for CTC Acoustic Models", "comments": "5 pages. To appear in Interspeech 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connectionist Temporal Classification has recently attracted a lot of\ninterest as it offers an elegant approach to building acoustic models (AMs) for\nspeech recognition. The CTC loss function maps an input sequence of observable\nfeature vectors to an output sequence of symbols. Output symbols are\nconditionally independent of each other under CTC loss, so a language model\n(LM) can be incorporated conveniently during decoding, retaining the\ntraditional separation of acoustic and linguistic components in ASR. For fixed\nvocabularies, Weighted Finite State Transducers provide a strong baseline for\nefficient integration of CTC AMs with n-gram LMs. Character-based neural LMs\nprovide a straight forward solution for open vocabulary speech recognition and\nall-neural models, and can be decoded with beam search. Finally,\nsequence-to-sequence models can be used to translate a sequence of individual\nsounds into a word string. We compare the performance of these three\napproaches, and analyze their error patterns, which provides insightful\nguidance for future research and development in this important area.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 12:05:02 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Zenkel", "Thomas", ""], ["Sanabria", "Ramon", ""], ["Metze", "Florian", ""], ["Niehues", "Jan", ""], ["Sperber", "Matthias", ""], ["St\u00fcker", "Sebastian", ""], ["Waibel", "Alex", ""]]}, {"id": "1708.04557", "submitter": "Slava Mikhaylov", "authors": "Alexander Herzog and Slava J. Mikhaylov", "title": "Database of Parliamentary Speeches in Ireland, 1919-2013", "comments": "The database is made available on the Harvard Dataverse at\n  http://dx.doi.org/10.7910/DVN/6MZN76", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a database of parliamentary debates that contains the complete\nrecord of parliamentary speeches from D\\'ail \\'Eireann, the lower house and\nprincipal chamber of the Irish parliament, from 1919 to 2013. In addition, the\ndatabase contains background information on all TDs (Teachta D\\'ala, members of\nparliament), such as their party affiliations, constituencies and office\npositions. The current version of the database includes close to 4.5 million\nspeeches from 1,178 TDs. The speeches were downloaded from the official\nparliament website and further processed and parsed with a Python script.\nBackground information on TDs was collected from the member database of the\nparliament website. Data on cabinet positions (ministers and junior ministers)\nwas collected from the official website of the government. A record linkage\nalgorithm and human coders were used to match TDs and ministers.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 15:34:33 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Herzog", "Alexander", ""], ["Mikhaylov", "Slava J.", ""]]}, {"id": "1708.04559", "submitter": "Sreelekha S", "authors": "Sreelekha S", "title": "Statistical Vs Rule Based Machine Translation; A Case Study on Indian\n  Language Perspective", "comments": "arXiv admin note: text overlap with arXiv:1703.03666,\n  arXiv:1702.08217", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present our work on a case study between Statistical Machien\nTransaltion (SMT) and Rule-Based Machine Translation (RBMT) systems on\nEnglish-Indian langugae and Indian to Indian langugae perspective. Main\nobjective of our study is to make a five way performance compariosn; such as,\na) SMT and RBMT b) SMT on English-Indian langugae c) RBMT on English-Indian\nlangugae d) SMT on Indian to Indian langugae perspective e) RBMT on Indian to\nIndian langugae perspective. Through a detailed analysis we describe the Rule\nBased and the Statistical Machine Translation system developments and its\nevaluations. Through a detailed error analysis, we point out the relative\nstrengths and weaknesses of both systems. The observations based on our study\nare: a) SMT systems outperforms RBMT b) In the case of SMT, English to Indian\nlanguage MT systmes performs better than Indian to English langugae MT systems\nc) In the case of RBMT, English to Indian langugae MT systems perofrms better\nthan Indian to Englsih Language MT systems d) SMT systems performs better for\nIndian to Indian language MT systems compared to RBMT. Effectively, we shall\nsee that even with a small amount of training corpus a statistical machine\ntranslation system has many advantages for high quality domain specific machine\ntranslation over that of a rule-based counterpart.\n", "versions": [{"version": "v1", "created": "Sat, 12 Aug 2017 18:55:12 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["S", "Sreelekha", ""]]}, {"id": "1708.04587", "submitter": "Nattapong Sanchan", "authors": "Nattapong Sanchan, Ahmet Aker and Kalina Bontcheva", "title": "Automatic Summarization of Online Debates", "comments": "Accepted and to be published in Natural Language Processing and\n  Information Retrieval workshop, Recent Advances in Natural Language\n  Processing 2017 (RANLP 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Debate summarization is one of the novel and challenging research areas in\nautomatic text summarization which has been largely unexplored. In this paper,\nwe develop a debate summarization pipeline to summarize key topics which are\ndiscussed or argued in the two opposing sides of online debates. We view that\nthe generation of debate summaries can be achieved by clustering, cluster\nlabeling, and visualization. In our work, we investigate two different\nclustering approaches for the generation of the summaries. In the first\napproach, we generate the summaries by applying purely term-based clustering\nand cluster labeling. The second approach makes use of X-means for clustering\nand Mutual Information for labeling the clusters. Both approaches are driven by\nontologies. We visualize the results using bar charts. We think that our\nresults are a smooth entry for users aiming to receive the first impression\nabout what is discussed within a debate topic containing waste number of\nargumentations.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 16:44:28 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Sanchan", "Nattapong", ""], ["Aker", "Ahmet", ""], ["Bontcheva", "Kalina", ""]]}, {"id": "1708.04592", "submitter": "Nattapong Sanchan", "authors": "Nattapong Sanchan, Ahmet Aker and Kalina Bontcheva", "title": "Gold Standard Online Debates Summaries and First Experiments Towards\n  Automatic Summarization of Online Debate Data", "comments": "accepted and presented at the CICLING 2017 - 18th International\n  Conference on Intelligent Text Processing and Computational Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Usage of online textual media is steadily increasing. Daily, more and more\nnews stories, blog posts and scientific articles are added to the online\nvolumes. These are all freely accessible and have been employed extensively in\nmultiple research areas, e.g. automatic text summarization, information\nretrieval, information extraction, etc. Meanwhile, online debate forums have\nrecently become popular, but have remained largely unexplored. For this reason,\nthere are no sufficient resources of annotated debate data available for\nconducting research in this genre. In this paper, we collected and annotated\ndebate data for an automatic summarization task. Similar to extractive gold\nstandard summary generation our data contains sentences worthy to include into\na summary. Five human annotators performed this task. Inter-annotator\nagreement, based on semantic similarity, is 36% for Cohen's kappa and 48% for\nKrippendorff's alpha. Moreover, we also implement an extractive summarization\nsystem for online debates and discuss prominent features for the task of\nsummarizing online debate data automatically.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 16:52:22 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Sanchan", "Nattapong", ""], ["Aker", "Ahmet", ""], ["Bontcheva", "Kalina", ""]]}, {"id": "1708.04681", "submitter": "Arman Cohan", "authors": "Arman Cohan, Allan Fong, Raj Ratwani, Nazli Goharian", "title": "Identifying Harm Events in Clinical Care through Medical Narratives", "comments": "ACM-BCB 2017", "journal-ref": null, "doi": "10.1145/3107411.3107485", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preventable medical errors are estimated to be among the leading causes of\ninjury and death in the United States. To prevent such errors, healthcare\nsystems have implemented patient safety and incident reporting systems. These\nsystems enable clinicians to report unsafe conditions and cases where patients\nhave been harmed due to errors in medical care. These reports are narratives in\nnatural language and while they provide detailed information about the\nsituation, it is non-trivial to perform large scale analysis for identifying\ncommon causes of errors and harm to the patients. In this work, we present a\nmethod based on attentive convolutional and recurrent networks for identifying\nharm events in patient care and categorize the harm based on its severity\nlevel. We demonstrate that our methods can significantly improve the\nperformance over existing methods in identifying harm in clinical care.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 20:38:37 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Cohan", "Arman", ""], ["Fong", "Allan", ""], ["Ratwani", "Raj", ""], ["Goharian", "Nazli", ""]]}, {"id": "1708.04686", "submitter": "Chuang Gan", "authors": "Chuang Gan, Yandong Li, Haoxiang Li, Chen Sun, Boqing Gong", "title": "VQS: Linking Segmentations to Questions and Answers for Supervised\n  Attention in VQA and Question-Focused Semantic Segmentation", "comments": "To appear on ICCV 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rich and dense human labeled datasets are among the main enabling factors for\nthe recent advance on vision-language understanding. Many seemingly distant\nannotations (e.g., semantic segmentation and visual question answering (VQA))\nare inherently connected in that they reveal different levels and perspectives\nof human understandings about the same visual scenes --- and even the same set\nof images (e.g., of COCO). The popularity of COCO correlates those annotations\nand tasks. Explicitly linking them up may significantly benefit both individual\ntasks and the unified vision and language modeling. We present the preliminary\nwork of linking the instance segmentations provided by COCO to the questions\nand answers (QAs) in the VQA dataset, and name the collected links visual\nquestions and segmentation answers (VQS). They transfer human supervision\nbetween the previously separate tasks, offer more effective leverage to\nexisting problems, and also open the door for new research problems and models.\nWe study two applications of the VQS data in this paper: supervised attention\nfor VQA and a novel question-focused semantic segmentation task. For the\nformer, we obtain state-of-the-art results on the VQA real multiple-choice task\nby simply augmenting the multilayer perceptrons with some attention features\nthat are learned using the segmentation-QA links as explicit supervision. To\nput the latter in perspective, we study two plausible methods and compare them\nto an oracle method assuming that the instance segmentations are given at the\ntest stage.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 20:47:02 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Gan", "Chuang", ""], ["Li", "Yandong", ""], ["Li", "Haoxiang", ""], ["Sun", "Chen", ""], ["Gong", "Boqing", ""]]}, {"id": "1708.04704", "submitter": "Marcos Vin\\'icius Treviso", "authors": "Marcos V. Treviso, Christopher D. Shulby, Sandra M. Aluisio", "title": "Evaluating Word Embeddings for Sentence Boundary Detection in Speech\n  Transcripts", "comments": "Accepted on STIL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is motivated by the automation of neuropsychological tests\ninvolving discourse analysis in the retellings of narratives by patients with\npotential cognitive impairment. In this scenario the task of sentence boundary\ndetection in speech transcripts is important as discourse analysis involves the\napplication of Natural Language Processing tools, such as taggers and parsers,\nwhich depend on the sentence as a processing unit. Our aim in this paper is to\nverify which embedding induction method works best for the sentence boundary\ndetection task, specifically whether it be those which were proposed to capture\nsemantic, syntactic or morphological similarities.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 22:12:59 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Treviso", "Marcos V.", ""], ["Shulby", "Christopher D.", ""], ["Aluisio", "Sandra M.", ""]]}, {"id": "1708.04729", "submitter": "Yizhe Zhang", "authors": "Yizhe Zhang, Dinghan Shen, Guoyin Wang, Zhe Gan, Ricardo Henao,\n  Lawrence Carin", "title": "Deconvolutional Paragraph Representation Learning", "comments": "Accepted by NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning latent representations from long text sequences is an important\nfirst step in many natural language processing applications. Recurrent Neural\nNetworks (RNNs) have become a cornerstone for this challenging task. However,\nthe quality of sentences during RNN-based decoding (reconstruction) decreases\nwith the length of the text. We propose a sequence-to-sequence, purely\nconvolutional and deconvolutional autoencoding framework that is free of the\nabove issue, while also being computationally efficient. The proposed method is\nsimple, easy to implement and can be leveraged as a building block for many\napplications. We show empirically that compared to RNNs, our framework is\nbetter at reconstructing and correcting long paragraphs. Quantitative\nevaluation on semi-supervised text classification and summarization tasks\ndemonstrate the potential for better utilization of long unlabeled text data.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 00:52:32 GMT"}, {"version": "v2", "created": "Fri, 8 Sep 2017 17:13:13 GMT"}, {"version": "v3", "created": "Fri, 22 Sep 2017 15:20:27 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Zhang", "Yizhe", ""], ["Shen", "Dinghan", ""], ["Wang", "Guoyin", ""], ["Gan", "Zhe", ""], ["Henao", "Ricardo", ""], ["Carin", "Lawrence", ""]]}, {"id": "1708.04755", "submitter": "Tzu Ray Su", "authors": "Tzu-Ray Su and Hung-Yi Lee", "title": "Learning Chinese Word Representations From Glyphs Of Characters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose new methods to learn Chinese word representations.\nChinese characters are composed of graphical components, which carry rich\nsemantics. It is common for a Chinese learner to comprehend the meaning of a\nword from these graphical components. As a result, we propose models that\nenhance word representations by character glyphs. The character glyph features\nare directly learned from the bitmaps of characters by convolutional\nauto-encoder(convAE), and the glyph features improve Chinese word\nrepresentations which are already enhanced by character embeddings. Another\ncontribution in this paper is that we created several evaluation datasets in\ntraditional Chinese and made them public.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 03:17:57 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Su", "Tzu-Ray", ""], ["Lee", "Hung-Yi", ""]]}, {"id": "1708.04765", "submitter": "Thi Lan Ngo", "authors": "Thi Lan Ngo, Khac Linh Pham, Minh Son Cao, Son Bao Pham, Xuan Hieu\n  Phan", "title": "Dialogue Act Segmentation for Vietnamese Human-Human Conversational\n  Texts", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialog act identification plays an important role in understanding\nconversations. It has been widely applied in many fields such as dialogue\nsystems, automatic machine translation, automatic speech recognition, and\nespecially useful in systems with human-computer natural language dialogue\ninterfaces such as virtual assistants and chatbots. The first step of\nidentifying dialog act is identifying the boundary of the dialog act in\nutterances. In this paper, we focus on segmenting the utterance according to\nthe dialog act boundaries, i.e. functional segments identification, for\nVietnamese utterances. We investigate carefully functional segment\nidentification in two approaches: (1) machine learning approach using maximum\nentropy (ME) and conditional random fields (CRFs); (2) deep learning approach\nusing bidirectional Long Short-Term Memory (LSTM) with a CRF layer\n(Bi-LSTM-CRF) on two different conversational datasets: (1) Facebook messages\n(Message data); (2) transcription from phone conversations (Phone data). To the\nbest of our knowledge, this is the first work that applies deep learning based\napproach to dialog act segmentation. As the results show, deep learning\napproach performs appreciably better as to compare with traditional machine\nlearning approaches. Moreover, it is also the first study that tackles dialog\nact and functional segment identification for Vietnamese.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 04:27:09 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Ngo", "Thi Lan", ""], ["Pham", "Khac Linh", ""], ["Cao", "Minh Son", ""], ["Pham", "Son Bao", ""], ["Phan", "Xuan Hieu", ""]]}, {"id": "1708.04776", "submitter": "Yuxin Peng", "authors": "Yuxin Peng, Jinwei Qi and Yuxin Yuan", "title": "Modality-specific Cross-modal Similarity Measurement with Recurrent\n  Attention Network", "comments": "13 pages, submitted to IEEE Transactions on Image Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, cross-modal retrieval plays an indispensable role to flexibly find\ninformation across different modalities of data. Effectively measuring the\nsimilarity between different modalities of data is the key of cross-modal\nretrieval. Different modalities such as image and text have imbalanced and\ncomplementary relationships, which contain unequal amount of information when\ndescribing the same semantics. For example, images often contain more details\nthat cannot be demonstrated by textual descriptions and vice versa. Existing\nworks based on Deep Neural Network (DNN) mostly construct one common space for\ndifferent modalities to find the latent alignments between them, which lose\ntheir exclusive modality-specific characteristics. Different from the existing\nworks, we propose modality-specific cross-modal similarity measurement (MCSM)\napproach by constructing independent semantic space for each modality, which\nadopts end-to-end framework to directly generate modality-specific cross-modal\nsimilarity without explicit common representation. For each semantic space,\nmodality-specific characteristics within one modality are fully exploited by\nrecurrent attention network, while the data of another modality is projected\ninto this space with attention based joint embedding to utilize the learned\nattention weights for guiding the fine-grained cross-modal correlation\nlearning, which can capture the imbalanced and complementary relationships\nbetween different modalities. Finally, the complementarity between the semantic\nspaces for different modalities is explored by adaptive fusion of the\nmodality-specific cross-modal similarities to perform cross-modal retrieval.\nExperiments on the widely-used Wikipedia and Pascal Sentence datasets as well\nas our constructed large-scale XMediaNet dataset verify the effectiveness of\nour proposed approach, outperforming 9 state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 05:43:54 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Peng", "Yuxin", ""], ["Qi", "Jinwei", ""], ["Yuan", "Yuxin", ""]]}, {"id": "1708.04923", "submitter": "Rahul Aralikatte", "authors": "Naveen Panwar, Shreya Khare, Neelamadhav Gantayat, Rahul Aralikatte,\n  Senthil Mani, Anush Sankaran", "title": "mAnI: Movie Amalgamation using Neural Imitation", "comments": "Accepted in ML4Creativity workshop in KDD 2017. Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-modal data retrieval has been the basis of various creative tasks\nperformed by Artificial Intelligence (AI). One such highly challenging task for\nAI is to convert a book into its corresponding movie, which most of the\ncreative film makers do as of today. In this research, we take the first step\ntowards it by visualizing the content of a book using its corresponding movie\nvisuals. Given a set of sentences from a book or even a fan-fiction written in\nthe same universe, we employ deep learning models to visualize the input by\nstitching together relevant frames from the movie. We studied and compared\nthree different types of setting to match the book with the movie content: (i)\nDialog model: using only the dialog from the movie, (ii) Visual model: using\nonly the visual content from the movie, and (iii) Hybrid model: using the\ndialog and the visual content from the movie. Experiments on the publicly\navailable MovieBook dataset shows the effectiveness of the proposed models.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 15:12:20 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Panwar", "Naveen", ""], ["Khare", "Shreya", ""], ["Gantayat", "Neelamadhav", ""], ["Aralikatte", "Rahul", ""], ["Mani", "Senthil", ""], ["Sankaran", "Anush", ""]]}, {"id": "1708.04968", "submitter": "Rahul Aralikatte", "authors": "Rahul Aralikatte, Giriprasad Sridhara, Neelamadhav Gantayat, Senthil\n  Mani", "title": "Fault in your stars: An Analysis of Android App Reviews", "comments": "Accepted in CoDS-COMAD 2018. Preprint", "journal-ref": null, "doi": "10.1145/3152494.3152500", "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile app distribution platforms such as Google Play Store allow users to\nshare their feedback about downloaded apps in the form of a review comment and\na corresponding star rating. Typically, the star rating ranges from one to five\nstars, with one star denoting a high sense of dissatisfaction with the app and\nfive stars denoting a high sense of satisfaction.\n  Unfortunately, due to a variety of reasons, often the star rating provided by\na user is inconsistent with the opinion expressed in the review. For example,\nconsider the following review for the Facebook App on Android; \"Awesome App\".\nOne would reasonably expect the rating for this review to be five stars, but\nthe actual rating is one star!\n  Such inconsistent ratings can lead to a deflated (or inflated) overall\naverage rating of an app which can affect user downloads, as typically users\nlook at the average star ratings while making a decision on downloading an app.\nAlso, the app developers receive a biased feedback about the application that\ndoes not represent ground reality. This is especially significant for small\napps with a few thousand downloads as even a small number of mismatched reviews\ncan bring down the average rating drastically.\n  In this paper, we conducted a study on this review-rating mismatch problem.\nWe manually examined 8600 reviews from 10 popular Android apps and found that\n20% of the ratings in our dataset were inconsistent with the review. Further,\nwe developed three systems; two of which were based on traditional machine\nlearning and one on deep learning to automatically identify reviews whose\nrating did not match with the opinion expressed in the review. Our deep\nlearning system performed the best and had an accuracy of 92% in identifying\nthe correct star rating to be associated with a given review.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 16:37:52 GMT"}, {"version": "v2", "created": "Sat, 11 Aug 2018 06:56:39 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Aralikatte", "Rahul", ""], ["Sridhara", "Giriprasad", ""], ["Gantayat", "Neelamadhav", ""], ["Mani", "Senthil", ""]]}, {"id": "1708.05045", "submitter": "Wei Hu", "authors": "Zequn Sun, Wei Hu, Chengkai Li", "title": "Cross-lingual Entity Alignment via Joint Attribute-Preserving Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity alignment is the task of finding entities in two knowledge bases (KBs)\nthat represent the same real-world object. When facing KBs in different natural\nlanguages, conventional cross-lingual entity alignment methods rely on machine\ntranslation to eliminate the language barriers. These approaches often suffer\nfrom the uneven quality of translations between languages. While recent\nembedding-based techniques encode entities and relationships in KBs and do not\nneed machine translation for cross-lingual entity alignment, a significant\nnumber of attributes remain largely unexplored. In this paper, we propose a\njoint attribute-preserving embedding model for cross-lingual entity alignment.\nIt jointly embeds the structures of two KBs into a unified vector space and\nfurther refines it by leveraging attribute correlations in the KBs. Our\nexperimental results on real-world datasets show that this approach\nsignificantly outperforms the state-of-the-art embedding approaches for\ncross-lingual entity alignment and could be complemented with methods based on\nmachine translation.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 19:30:17 GMT"}, {"version": "v2", "created": "Tue, 26 Sep 2017 02:06:08 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Sun", "Zequn", ""], ["Hu", "Wei", ""], ["Li", "Chengkai", ""]]}, {"id": "1708.05071", "submitter": "Jaebok Kim", "authors": "Jaebok Kim, Khiet P. Truong, Gwenn Englebienne, and Vanessa Evers", "title": "Learning spectro-temporal features with 3D CNNs for speech emotion\n  recognition", "comments": "ACII, 2017, San Antonio", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose to use deep 3-dimensional convolutional networks\n(3D CNNs) in order to address the challenge of modelling spectro-temporal\ndynamics for speech emotion recognition (SER). Compared to a hybrid of\nConvolutional Neural Network and Long-Short-Term-Memory (CNN-LSTM), our\nproposed 3D CNNs simultaneously extract short-term and long-term spectral\nfeatures with a moderate number of parameters. We evaluated our proposed and\nother state-of-the-art methods in a speaker-independent manner using aggregated\ncorpora that give a large and diverse set of speakers. We found that 1) shallow\ntemporal and moderately deep spectral kernels of a homogeneous architecture are\noptimal for the task; and 2) our 3D CNNs are more effective for\nspectro-temporal feature learning compared to other methods. Finally, we\nvisualised the feature space obtained with our proposed method using\nt-distributed stochastic neighbour embedding (T-SNE) and could observe distinct\nclusters of emotions.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 17:32:06 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Kim", "Jaebok", ""], ["Truong", "Khiet P.", ""], ["Englebienne", "Gwenn", ""], ["Evers", "Vanessa", ""]]}, {"id": "1708.05122", "submitter": "Prithvijit Chattopadhyay Chattopadhyay", "authors": "Prithvijit Chattopadhyay, Deshraj Yadav, Viraj Prabhu, Arjun\n  Chandrasekaran, Abhishek Das, Stefan Lee, Dhruv Batra, Devi Parikh", "title": "Evaluating Visual Conversational Agents via Cooperative Human-AI Games", "comments": "HCOMP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As AI continues to advance, human-AI teams are inevitable. However, progress\nin AI is routinely measured in isolation, without a human in the loop. It is\ncrucial to benchmark progress in AI, not just in isolation, but also in terms\nof how it translates to helping humans perform certain tasks, i.e., the\nperformance of human-AI teams.\n  In this work, we design a cooperative game - GuessWhich - to measure human-AI\nteam performance in the specific context of the AI being a visual\nconversational agent. GuessWhich involves live interaction between the human\nand the AI. The AI, which we call ALICE, is provided an image which is unseen\nby the human. Following a brief description of the image, the human questions\nALICE about this secret image to identify it from a fixed pool of images.\n  We measure performance of the human-ALICE team by the number of guesses it\ntakes the human to correctly identify the secret image after a fixed number of\ndialog rounds with ALICE. We compare performance of the human-ALICE teams for\ntwo versions of ALICE. Our human studies suggest a counterintuitive trend -\nthat while AI literature shows that one version outperforms the other when\npaired with an AI questioner bot, we find that this improvement in AI-AI\nperformance does not translate to improved human-AI performance. This suggests\na mismatch between benchmarking of AI in isolation and in the context of\nhuman-AI teams.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 03:27:53 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Chattopadhyay", "Prithvijit", ""], ["Yadav", "Deshraj", ""], ["Prabhu", "Viraj", ""], ["Chandrasekaran", "Arjun", ""], ["Das", "Abhishek", ""], ["Lee", "Stefan", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""]]}, {"id": "1708.05148", "submitter": "Sukhdev Singh", "authors": "Diksha Khurana, Aditya Koli, Kiran Khatter and Sukhdev Singh", "title": "Natural Language Processing: State of The Art, Current Trends and\n  Challenges", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language processing (NLP) has recently gained much attention for\nrepresenting and analysing human language computationally. It has spread its\napplications in various fields such as machine translation, email spam\ndetection, information extraction, summarization, medical, and question\nanswering etc. The paper distinguishes four phases by discussing different\nlevels of NLP and components of Natural Language Generation (NLG) followed by\npresenting the history and evolution of NLP, state of the art presenting the\nvarious applications of NLP and current trends and challenges.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 06:42:03 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Khurana", "Diksha", ""], ["Koli", "Aditya", ""], ["Khatter", "Kiran", ""], ["Singh", "Sukhdev", ""]]}, {"id": "1708.05269", "submitter": "David Vilares", "authors": "David Vilares, Marcos Garcia, Miguel A. Alonso, Carlos\n  G\\'omez-Rodr\\'iguez", "title": "Towards Syntactic Iberian Polarity Classification", "comments": "7 pages, 5 tables. Contribution to the 8th Workshop on Computational\n  Approaches to Subjectivity, Sentiment and Social Media Analysis (WASSA-2017)\n  at EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexicon-based methods using syntactic rules for polarity classification rely\non parsers that are dependent on the language and on treebank guidelines. Thus,\nrules are also dependent and require adaptation, especially in multilingual\nscenarios. We tackle this challenge in the context of the Iberian Peninsula,\nreleasing the first symbolic syntax-based Iberian system with rules shared\nacross five official languages: Basque, Catalan, Galician, Portuguese and\nSpanish. The model is made available.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 13:50:39 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Vilares", "David", ""], ["Garcia", "Marcos", ""], ["Alonso", "Miguel A.", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "1708.05271", "submitter": "Ting Yao", "authors": "Ting Yao and Yingwei Pan and Yehao Li and Tao Mei", "title": "Incorporating Copying Mechanism in Image Captioning for Learning Novel\n  Objects", "comments": "CVPR17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image captioning often requires a large set of training image-sentence pairs.\nIn practice, however, acquiring sufficient training pairs is always expensive,\nmaking the recent captioning models limited in their ability to describe\nobjects outside of training corpora (i.e., novel objects). In this paper, we\npresent Long Short-Term Memory with Copying Mechanism (LSTM-C) --- a new\narchitecture that incorporates copying into the Convolutional Neural Networks\n(CNN) plus Recurrent Neural Networks (RNN) image captioning framework, for\ndescribing novel objects in captions. Specifically, freely available object\nrecognition datasets are leveraged to develop classifiers for novel objects.\nOur LSTM-C then nicely integrates the standard word-by-word sentence generation\nby a decoder RNN with copying mechanism which may instead select words from\nnovel objects at proper places in the output sentence. Extensive experiments\nare conducted on both MSCOCO image captioning and ImageNet datasets,\ndemonstrating the ability of our proposed LSTM-C architecture to describe novel\nobjects. Furthermore, superior results are reported when compared to\nstate-of-the-art deep models.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 13:51:39 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Yao", "Ting", ""], ["Pan", "Yingwei", ""], ["Li", "Yehao", ""], ["Mei", "Tao", ""]]}, {"id": "1708.05286", "submitter": "Leon Derczynski", "authors": "Ahmet Aker, Leon Derczynski, Kalina Bontcheva", "title": "Simple Open Stance Classification for Rumour Analysis", "comments": null, "journal-ref": "In RANLP 2017", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stance classification determines the attitude, or stance, in a (typically\nshort) text. The task has powerful applications, such as the detection of fake\nnews or the automatic extraction of attitudes toward entities or events in the\nmedia. This paper describes a surprisingly simple and efficient classification\napproach to open stance classification in Twitter, for rumour and veracity\nclassification. The approach profits from a novel set of automatically\nidentifiable problem-specific features, which significantly boost classifier\naccuracy and achieve above state-of-the-art results on recent benchmark\ndatasets. This calls into question the value of using complex sophisticated\nmodels for stance classification without first doing informed feature\nextraction.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 14:06:58 GMT"}, {"version": "v2", "created": "Thu, 14 Sep 2017 13:42:56 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Aker", "Ahmet", ""], ["Derczynski", "Leon", ""], ["Bontcheva", "Kalina", ""]]}, {"id": "1708.05449", "submitter": "Ian Beaver", "authors": "Ian Beaver, Cynthia Freeman, Abdullah Mueen", "title": "An Annotated Corpus of Relational Strategies in Customer Service", "comments": "Submitted to Language Resources and Evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We create and release the first publicly available commercial customer\nservice corpus with annotated relational segments. Human-computer data from\nthree live customer service Intelligent Virtual Agents (IVAs) in the domains of\ntravel and telecommunications were collected, and reviewers marked all text\nthat was deemed unnecessary to the determination of user intention. After\nmerging the selections of multiple reviewers to create highlighted texts, a\nsecond round of annotation was done to determine the classes of language\npresent in the highlighted sections such as the presence of Greetings,\nBackstory, Justification, Gratitude, Rants, or Emotions. This resulting corpus\nis a valuable resource for improving the quality and relational abilities of\nIVAs. As well as discussing the corpus itself, we compare the usage of such\nlanguage in human-human interactions on TripAdvisor forums. We show that\nremoval of this language from task-based inputs has a positive effect on IVA\nunderstanding by both an increase in confidence and improvement in responses,\ndemonstrating the need for automated methods of its discovery.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 21:57:47 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Beaver", "Ian", ""], ["Freeman", "Cynthia", ""], ["Mueen", "Abdullah", ""]]}, {"id": "1708.05466", "submitter": "Jinyu Li", "authors": "Jinyu Li, Michael L. Seltzer, Xi Wang, Rui Zhao, and Yifan Gong", "title": "Large-Scale Domain Adaptation via Teacher-Student Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High accuracy speech recognition requires a large amount of transcribed data\nfor supervised training. In the absence of such data, domain adaptation of a\nwell-trained acoustic model can be performed, but even here, high accuracy\nusually requires significant labeled data from the target domain. In this work,\nwe propose an approach to domain adaptation that does not require\ntranscriptions but instead uses a corpus of unlabeled parallel data, consisting\nof pairs of samples from the source domain of the well-trained model and the\ndesired target domain. To perform adaptation, we employ teacher/student (T/S)\nlearning, in which the posterior probabilities generated by the source-domain\nmodel can be used in lieu of labels to train the target-domain model. We\nevaluate the proposed approach in two scenarios, adapting a clean acoustic\nmodel to noisy speech and adapting an adults speech acoustic model to children\nspeech. Significant improvements in accuracy are obtained, with reductions in\nword error rate of up to 44% over the original source model without the need\nfor transcribed data in the target domain. Moreover, we show that increasing\nthe amount of unlabeled data results in additional model robustness, which is\nparticularly beneficial when using simulated training data in the\ntarget-domain.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 23:37:18 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Li", "Jinyu", ""], ["Seltzer", "Michael L.", ""], ["Wang", "Xi", ""], ["Zhao", "Rui", ""], ["Gong", "Yifan", ""]]}, {"id": "1708.05482", "submitter": "Lin Gui", "authors": "Lin Gui and Jiannan Hu and Yulan He and Ruifeng Xu and Qin Lu and\n  Jiachen Du", "title": "A Question Answering Approach to Emotion Cause Extraction", "comments": "Accepted by EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion cause extraction aims to identify the reasons behind a certain\nemotion expressed in text. It is a much more difficult task compared to emotion\nclassification. Inspired by recent advances in using deep memory networks for\nquestion answering (QA), we propose a new approach which considers emotion\ncause identification as a reading comprehension task in QA. Inspired by\nconvolutional neural networks, we propose a new mechanism to store relevant\ncontext in different memory slots to model context information. Our proposed\napproach can extract both word level sequence features and lexical features.\nPerformance evaluation shows that our method achieves the state-of-the-art\nperformance on a recently released emotion cause dataset, outperforming a\nnumber of competitive baselines by at least 3.01% in F-measure.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 02:07:36 GMT"}, {"version": "v2", "created": "Sun, 24 Sep 2017 01:43:43 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Gui", "Lin", ""], ["Hu", "Jiannan", ""], ["He", "Yulan", ""], ["Xu", "Ruifeng", ""], ["Lu", "Qin", ""], ["Du", "Jiachen", ""]]}, {"id": "1708.05515", "submitter": "Seunghak Yu", "authors": "Seunghak Yu, Nilesh Kulkarni, Haejun Lee, Jihie Kim", "title": "Syllable-level Neural Language Model for Agglutinative Language", "comments": "Accepted at EMNLP 2017 workshop on Subword and Character level models\n  in NLP (SCLeM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language models for agglutinative languages have always been hindered in past\ndue to myriad of agglutinations possible to any given word through various\naffixes. We propose a method to diminish the problem of out-of-vocabulary words\nby introducing an embedding derived from syllables and morphemes which\nleverages the agglutinative property. Our model outperforms character-level\nembedding in perplexity by 16.87 with 9.50M parameters. Proposed method\nachieves state of the art performance over existing input prediction methods in\nterms of Key Stroke Saving and has been commercialized.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 06:02:16 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Yu", "Seunghak", ""], ["Kulkarni", "Nilesh", ""], ["Lee", "Haejun", ""], ["Kim", "Jihie", ""]]}, {"id": "1708.05521", "submitter": "Edison Marrese-Taylor", "authors": "Edison Marrese-Taylor, Yutaka Matsuo", "title": "EmoAtt at EmoInt-2017: Inner attention sentence embedding for Emotion\n  Intensity", "comments": "WASSA 2017 Shared Task on Emotion Intensity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe a deep learning system that has been designed and\nbuilt for the WASSA 2017 Emotion Intensity Shared Task. We introduce a\nrepresentation learning approach based on inner attention on top of an RNN.\nResults show that our model offers good capabilities and is able to\nsuccessfully identify emotion-bearing words to predict intensity without\nleveraging on lexicons, obtaining the 13th place among 22 shared task\ncompetitors.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 06:59:16 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Marrese-Taylor", "Edison", ""], ["Matsuo", "Yutaka", ""]]}, {"id": "1708.05536", "submitter": "Enrique Manjavacas Ar\\'evalo", "authors": "E. Manjavacas and J. de Gussem and W. Daelemans and M. Kestemont", "title": "Assessing the Stylistic Properties of Neurally Generated Text in\n  Authorship Attribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent applications of neural language models have led to an increased\ninterest in the automatic generation of natural language. However impressive,\nthe evaluation of neurally generated text has so far remained rather informal\nand anecdotal. Here, we present an attempt at the systematic assessment of one\naspect of the quality of neurally generated text. We focus on a specific aspect\nof neural language generation: its ability to reproduce authorial writing\nstyles. Using established models for authorship attribution, we empirically\nassess the stylistic qualities of neurally generated text. In comparison to\nconventional language models, neural models generate fuzzier text that is\nrelatively harder to attribute correctly. Nevertheless, our results also\nsuggest that neurally generated text offers more valuable perspectives for the\naugmentation of training data.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 08:43:52 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Manjavacas", "E.", ""], ["de Gussem", "J.", ""], ["Daelemans", "W.", ""], ["Kestemont", "M.", ""]]}, {"id": "1708.05565", "submitter": "Yu Wang", "authors": "Yu Wang, Jiayi Liu, Yuxiang Liu, Jun Hao, Yang He, Jinghe Hu, Weipeng\n  P. Yan, Mantian Li", "title": "LADDER: A Human-Level Bidding Agent for Large-Scale Real-Time Online\n  Auctions", "comments": "8 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present LADDER, the first deep reinforcement learning agent that can\nsuccessfully learn control policies for large-scale real-world problems\ndirectly from raw inputs composed of high-level semantic information. The agent\nis based on an asynchronous stochastic variant of DQN (Deep Q Network) named\nDASQN. The inputs of the agent are plain-text descriptions of states of a game\nof incomplete information, i.e. real-time large scale online auctions, and the\nrewards are auction profits of very large scale. We apply the agent to an\nessential portion of JD's online RTB (real-time bidding) advertising business\nand find that it easily beats the former state-of-the-art bidding policy that\nhad been carefully engineered and calibrated by human experts: during JD.com's\nJune 18th anniversary sale, the agent increased the company's ads revenue from\nthe portion by more than 50%, while the advertisers' ROI (return on investment)\nalso improved significantly.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 11:25:30 GMT"}, {"version": "v2", "created": "Fri, 1 Sep 2017 14:05:09 GMT"}], "update_date": "2017-09-04", "authors_parsed": [["Wang", "Yu", ""], ["Liu", "Jiayi", ""], ["Liu", "Yuxiang", ""], ["Hao", "Jun", ""], ["He", "Yang", ""], ["Hu", "Jinghe", ""], ["Yan", "Weipeng P.", ""], ["Li", "Mantian", ""]]}, {"id": "1708.05582", "submitter": "Venkatesh Duppada", "authors": "Sushant Hiray, Venkatesh Duppada", "title": "Agree to Disagree: Improving Disagreement Detection with Dual GRUs", "comments": "In Proc. 7th Affective Computing and Intelligent Interaction\n  (ACII'17), San Antonio, TX, USA, Oct. 23-26, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents models for detecting agreement/disagreement in online\ndiscussions. In this work we show that by using a Siamese inspired architecture\nto encode the discussions, we no longer need to rely on hand-crafted features\nto exploit the meta thread structure. We evaluate our model on existing online\ndiscussion corpora - ABCD, IAC and AWTP. Experimental results on ABCD dataset\nshow that by fusing lexical and word embedding features, our model achieves the\nstate of the art performance of 0.804 average F1 score. We also show that the\nmodel trained on ABCD dataset performs competitively on relatively smaller\nannotated datasets (IAC and AWTP).\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 12:34:11 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Hiray", "Sushant", ""], ["Duppada", "Venkatesh", ""]]}, {"id": "1708.05592", "submitter": "Xie Chen", "authors": "Xie Chen, Xunying Liu, Anton Ragni, Yu Wang, Mark Gales", "title": "Future Word Contexts in Neural Network Language Models", "comments": "Submitted to ASRU2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, bidirectional recurrent network language models (bi-RNNLMs) have\nbeen shown to outperform standard, unidirectional, recurrent neural network\nlanguage models (uni-RNNLMs) on a range of speech recognition tasks. This\nindicates that future word context information beyond the word history can be\nuseful. However, bi-RNNLMs pose a number of challenges as they make use of the\ncomplete previous and future word context information. This impacts both\ntraining efficiency and their use within a lattice rescoring framework. In this\npaper these issues are addressed by proposing a novel neural network structure,\nsucceeding word RNNLMs (su-RNNLMs). Instead of using a recurrent unit to\ncapture the complete future word contexts, a feedforward unit is used to model\na finite number of succeeding, future, words. This model can be trained much\nmore efficiently than bi-RNNLMs and can also be used for lattice rescoring.\nExperimental results on a meeting transcription task (AMI) show the proposed\nmodel consistently outperformed uni-RNNLMs and yield only a slight degradation\ncompared to bi-RNNLMs in N-best rescoring. Additionally, performance\nimprovements can be obtained using lattice rescoring and subsequent confusion\nnetwork decoding.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 13:11:22 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Chen", "Xie", ""], ["Liu", "Xunying", ""], ["Ragni", "Anton", ""], ["Wang", "Yu", ""], ["Gales", "Mark", ""]]}, {"id": "1708.05682", "submitter": "Lu Huang", "authors": "Lu Huang, Jiasong Sun, Ji Xu and Yi Yang", "title": "An Improved Residual LSTM Architecture for Acoustic Modeling", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long Short-Term Memory (LSTM) is the primary recurrent neural networks\narchitecture for acoustic modeling in automatic speech recognition systems.\nResidual learning is an efficient method to help neural networks converge\neasier and faster. In this paper, we propose several types of residual LSTM\nmethods for our acoustic modeling. Our experiments indicate that, compared with\nclassic LSTM, our architecture shows more than 8% relative reduction in Phone\nError Rate (PER) on TIMIT tasks. At the same time, our residual fast LSTM\napproach shows 4% relative reduction in PER on the same task. Besides, we find\nthat all this architecture could have good results on THCHS-30, Librispeech and\nSwitchboard corpora.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 01:37:21 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Huang", "Lu", ""], ["Sun", "Jiasong", ""], ["Xu", "Ji", ""], ["Yang", "Yi", ""]]}, {"id": "1708.05719", "submitter": "J\\\"org Tiedemann", "authors": "J\\\"org Tiedemann", "title": "Cross-Lingual Dependency Parsing for Closely Related Languages -\n  Helsinki's Submission to VarDial 2017", "comments": null, "journal-ref": "In Proceedings of the Fourth Workshop on NLP for Similar\n  Languages, Varieties and Dialects at EACL 2017, Valencia/Spain, pp. 131-136", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the submission from the University of Helsinki to the\nshared task on cross-lingual dependency parsing at VarDial 2017. We present\nwork on annotation projection and treebank translation that gave good results\nfor all three target languages in the test set. In particular, Slovak seems to\nwork well with information coming from the Czech treebank, which is in line\nwith related work. The attachment scores for cross-lingual models even surpass\nthe fully supervised models trained on the target language treebank. Croatian\nis the most difficult language in the test set and the improvements over the\nbaseline are rather modest. Norwegian works best with information coming from\nSwedish whereas Danish contributes surprisingly little.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 18:00:05 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Tiedemann", "J\u00f6rg", ""]]}, {"id": "1708.05729", "submitter": "J\\\"org Tiedemann", "authors": "Robert \\\"Ostling and J\\\"org Tiedemann", "title": "Neural machine translation for low-resource languages", "comments": "rejected from EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) approaches have improved the state of the\nart in many machine translation settings over the last couple of years, but\nthey require large amounts of training data to produce sensible output. We\ndemonstrate that NMT can be used for low-resource languages as well, by\nintroducing more local dependencies and using word alignments to learn sentence\nreordering during translation. In addition to our novel model, we also present\nan empirical evaluation of low-resource phrase-based statistical machine\ntranslation (SMT) and NMT to investigate the lower limits of the respective\ntechnologies. We find that while SMT remains the best option for low-resource\nsettings, our method can produce acceptable translations with only 70000 tokens\nof training data, a level where the baseline NMT system fails completely.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 18:16:23 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["\u00d6stling", "Robert", ""], ["Tiedemann", "J\u00f6rg", ""]]}, {"id": "1708.05763", "submitter": "Richard Futrell", "authors": "Richard Futrell, Edward Gibson, Hal Tily, Idan Blank, Anastasia\n  Vishnevetsky, Steven T. Piantadosi, Evelina Fedorenko", "title": "The Natural Stories Corpus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is now a common practice to compare models of human language processing by\npredicting participant reactions (such as reading times) to corpora consisting\nof rich naturalistic linguistic materials. However, many of the corpora used in\nthese studies are based on naturalistic text and thus do not contain many of\nthe low-frequency syntactic constructions that are often required to\ndistinguish processing theories. Here we describe a new corpus consisting of\nEnglish texts edited to contain many low-frequency syntactic constructions\nwhile still sounding fluent to native speakers. The corpus is annotated with\nhand-corrected parse trees and includes self-paced reading time data. Here we\ngive an overview of the content of the corpus and release the data.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 21:27:34 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Futrell", "Richard", ""], ["Gibson", "Edward", ""], ["Tily", "Hal", ""], ["Blank", "Idan", ""], ["Vishnevetsky", "Anastasia", ""], ["Piantadosi", "Steven T.", ""], ["Fedorenko", "Evelina", ""]]}, {"id": "1708.05797", "submitter": "Leila Kosseim", "authors": "Elnaz Davoodi and Leila Kosseim", "title": "CLaC @ QATS: Quality Assessment for Text Simplification", "comments": "In Proceedings of the Workshop Shared task on Quality Assessment for\n  Text Simplification (QATS-2016), a workshop of the 10th Language Resources\n  and Evaluation Conference (LREC-2016), pp. 53-56, May 23-28, Portoroz,\n  Slovenia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our approach to the 2016 QATS quality assessment shared\ntask. We trained three independent Random Forest classifiers in order to assess\nthe quality of the simplified texts in terms of grammaticality, meaning\npreservation and simplicity. We used the language model of Google-Ngram as\nfeature to predict the grammaticality. Meaning preservation is predicted using\ntwo complementary approaches based on word embedding and WordNet synonyms. A\nwider range of features including TF-IDF, sentence length and frequency of cue\nphrases are used to evaluate the simplicity aspect. Overall, the accuracy of\nthe system ranges from 33.33% for the overall aspect to 58.73% for\ngrammaticality.\n", "versions": [{"version": "v1", "created": "Sat, 19 Aug 2017 03:18:50 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Davoodi", "Elnaz", ""], ["Kosseim", "Leila", ""]]}, {"id": "1708.05798", "submitter": "Leila Kosseim", "authors": "Majid Laali, Andre Cianflone and Leila Kosseim", "title": "The CLaC Discourse Parser at CoNLL-2016", "comments": "In Proceedings of the Twentieth Conference on Computational Natural\n  Language Learning: Shared Task. pp 92-99. July 7-12, 2016. Berlin, Germany", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our submission \"CLaC\" to the CoNLL-2016 shared task on\nshallow discourse parsing. We used two complementary approaches for the task. A\nstandard machine learning approach for the parsing of explicit relations, and a\ndeep learning approach for non-explicit relations. Overall, our parser achieves\nan F1-score of 0.2106 on the identification of discourse relations (0.3110 for\nexplicit relations and 0.1219 for non-explicit relations) on the blind\nCoNLL-2016 test set.\n", "versions": [{"version": "v1", "created": "Sat, 19 Aug 2017 03:19:40 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Laali", "Majid", ""], ["Cianflone", "Andre", ""], ["Kosseim", "Leila", ""]]}, {"id": "1708.05800", "submitter": "Leila Kosseim", "authors": "Elnaz Davoodi and Leila Kosseim", "title": "On the Contribution of Discourse Structure on Text Complexity Assessment", "comments": "In Proceedings of the 17th Annual SigDial Meeting on Discourse and\n  Dialogue (SigDial 2016). pp 166-174. September 13-15. Los Angeles, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the influence of discourse features on text\ncomplexity assessment. To do so, we created two data sets based on the Penn\nDiscourse Treebank and the Simple English Wikipedia corpora and compared the\ninfluence of coherence, cohesion, surface, lexical and syntactic features to\nassess text complexity.\n  Results show that with both data sets coherence features are more correlated\nto text complexity than the other types of features. In addition, feature\nselection revealed that with both data sets the top most discriminating feature\nis a coherence feature.\n", "versions": [{"version": "v1", "created": "Sat, 19 Aug 2017 03:20:43 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Davoodi", "Elnaz", ""], ["Kosseim", "Leila", ""]]}, {"id": "1708.05801", "submitter": "Leila Kosseim", "authors": "Reda Siblini and Leila Kosseim", "title": "ClaC: Semantic Relatedness of Words and Phrases", "comments": "In Proceedings of the Second Joint Conference on Lexical and\n  Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh\n  International Workshop on Semantic Evaluation (SemEval 2013),June, Atlanta,\n  Georgia, USA, pp. 108-113", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The measurement of phrasal semantic relatedness is an important metric for\nmany natural language processing applications. In this paper, we present three\napproaches for measuring phrasal semantics, one based on a semantic network\nmodel, another on a distributional similarity model, and a hybrid between the\ntwo. Our hybrid approach achieved an F-measure of 77.4% on the task of\nevaluating the semantic similarity of words and compositional phrases.\n", "versions": [{"version": "v1", "created": "Sat, 19 Aug 2017 03:37:38 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Siblini", "Reda", ""], ["Kosseim", "Leila", ""]]}, {"id": "1708.05803", "submitter": "Leila Kosseim", "authors": "Shamima Mithun and Leila Kosseim", "title": "Measuring the Effect of Discourse Relations on Blog Summarization", "comments": "In Proceedings of the 6th International Joint Conference on Natural\n  Language Processing (IJCNLP 2013), pages 1401-1409, October 2013, Nagoya,\n  Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The work presented in this paper attempts to evaluate and quantify the use of\ndiscourse relations in the context of blog summarization and compare their use\nto more traditional and factual texts. Specifically, we measured the usefulness\nof 6 discourse relations - namely comparison, contingency, illustration,\nattribution, topic-opinion, and attributive for the task of text summarization\nfrom blogs. We have evaluated the effect of each relation using the TAC 2008\nopinion summarization dataset and compared them with the results with the DUC\n2007 dataset. The results show that in both textual genres, contingency,\ncomparison, and illustration relations provide a significant improvement on\nsummarization content; while attribution, topic-opinion, and attributive\nrelations do not provide a consistent and significant improvement. These\nresults indicate that, at least for summarization, discourse relations are just\nas useful for informal and affective texts as for more traditional news\narticles.\n", "versions": [{"version": "v1", "created": "Sat, 19 Aug 2017 04:01:43 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Mithun", "Shamima", ""], ["Kosseim", "Leila", ""]]}, {"id": "1708.05857", "submitter": "Majid Laali", "authors": "Majid Laali, Elnaz Davoodi and Leila Kosseim", "title": "The CLaC Discourse Parser at CoNLL-2015", "comments": "Proceedings of the Nineteenth Conference on Computational Natural\n  Language Learning Shared Task (CoNLL 2015). Beijing, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our submission (kosseim15) to the CoNLL-2015 shared task\non shallow discourse parsing. We used the UIMA framework to develop our parser\nand used ClearTK to add machine learning functionality to the UIMA framework.\nOverall, our parser achieves a result of 17.3 F1 on the identification of\ndiscourse relations on the blind CoNLL-2015 test set, ranking in sixth place.\n", "versions": [{"version": "v1", "created": "Sat, 19 Aug 2017 14:43:50 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Laali", "Majid", ""], ["Davoodi", "Elnaz", ""], ["Kosseim", "Leila", ""]]}, {"id": "1708.05873", "submitter": "Slava Mikhaylov", "authors": "Alexander Baturo and Niheer Dasandi and Slava J. Mikhaylov", "title": "What Drives the International Development Agenda? An NLP Analysis of the\n  United Nations General Debate 1970-2016", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is surprisingly little known about agenda setting for international\ndevelopment in the United Nations (UN) despite it having a significant\ninfluence on the process and outcomes of development efforts. This paper\naddresses this shortcoming using a novel approach that applies natural language\nprocessing techniques to countries' annual statements in the UN General Debate.\nEvery year UN member states deliver statements during the General Debate on\ntheir governments' perspective on major issues in world politics. These\nspeeches provide invaluable information on state preferences on a wide range of\nissues, including international development, but have largely been overlooked\nin the study of global politics. This paper identifies the main international\ndevelopment topics that states raise in these speeches between 1970 and 2016,\nand examine the country-specific drivers of international development rhetoric.\n", "versions": [{"version": "v1", "created": "Sat, 19 Aug 2017 16:39:19 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Baturo", "Alexander", ""], ["Dasandi", "Niheer", ""], ["Mikhaylov", "Slava J.", ""]]}, {"id": "1708.05891", "submitter": "Mohamed Eldesouki", "authors": "Mohamed Eldesouki, Younes Samih, Ahmed Abdelali, Mohammed Attia, Hamdy\n  Mubarak, Kareem Darwish, Kallmeyer Laura", "title": "Arabic Multi-Dialect Segmentation: bi-LSTM-CRF vs. SVM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arabic word segmentation is essential for a variety of NLP applications such\nas machine translation and information retrieval. Segmentation entails breaking\nwords into their constituent stems, affixes and clitics. In this paper, we\ncompare two approaches for segmenting four major Arabic dialects using only\nseveral thousand training examples for each dialect. The two approaches involve\nposing the problem as a ranking problem, where an SVM ranker picks the best\nsegmentation, and as a sequence labeling problem, where a bi-LSTM RNN coupled\nwith CRF determines where best to segment words. We are able to achieve solid\nsegmentation results for all dialects using rather limited training data. We\nalso show that employing Modern Standard Arabic data for domain adaptation and\nassuming context independence improve overall results.\n", "versions": [{"version": "v1", "created": "Sat, 19 Aug 2017 19:52:36 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Eldesouki", "Mohamed", ""], ["Samih", "Younes", ""], ["Abdelali", "Ahmed", ""], ["Attia", "Mohammed", ""], ["Mubarak", "Hamdy", ""], ["Darwish", "Kareem", ""], ["Laura", "Kallmeyer", ""]]}, {"id": "1708.05942", "submitter": "J\\\"org Tiedemann", "authors": "Robert \\\"Ostling and Yves Scherrer and J\\\"org Tiedemann and Gongbo\n  Tang and Tommi Nieminen", "title": "The Helsinki Neural Machine Translation System", "comments": "Proceedings of the Second Conference on Machine Translation (WMT\n  2017) at EMNLP 2017, Copenhagen/Danmark", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Helsinki Neural Machine Translation system (HNMT) and how it\nis applied in the news translation task at WMT 2017, where it ranked first in\nboth the human and automatic evaluations for English--Finnish. We discuss the\nsuccess of English--Finnish translations and the overall advantage of NMT over\na strong SMT baseline. We also discuss our submissions for English--Latvian,\nEnglish--Chinese and Chinese--English.\n", "versions": [{"version": "v1", "created": "Sun, 20 Aug 2017 09:24:46 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["\u00d6stling", "Robert", ""], ["Scherrer", "Yves", ""], ["Tiedemann", "J\u00f6rg", ""], ["Tang", "Gongbo", ""], ["Nieminen", "Tommi", ""]]}, {"id": "1708.05943", "submitter": "J\\\"org Tiedemann", "authors": "J\\\"org Tiedemann and Yves Scherrer", "title": "Neural Machine Translation with Extended Context", "comments": "Proceedings of the Third Workshop on Discourse in Machine Translation\n  (DiscoMT 2017) at EMNLP 2017, Copenhagen/Danmark", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the use of extended context in attention-based neural machine\ntranslation. We base our experiments on translated movie subtitles and discuss\nthe effect of increasing the segments beyond single translation units. We study\nthe use of extended source language context as well as bilingual context\nextensions. The models learn to distinguish between information from different\nsegments and are surprisingly robust with respect to translation quality. In\nthis pilot study, we observe interesting cross-sentential attention patterns\nthat improve textual coherence in translation at least in some selected cases.\n", "versions": [{"version": "v1", "created": "Sun, 20 Aug 2017 09:31:49 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Tiedemann", "J\u00f6rg", ""], ["Scherrer", "Yves", ""]]}, {"id": "1708.05956", "submitter": "Bing Liu", "authors": "Bing Liu, Ian Lane", "title": "An End-to-End Trainable Neural Network Model with Belief Tracking for\n  Task-Oriented Dialog", "comments": "Published at Interspeech 2017", "journal-ref": null, "doi": "10.21437/Interspeech.2017-1326", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel end-to-end trainable neural network model for\ntask-oriented dialog systems. The model is able to track dialog state, issue\nAPI calls to knowledge base (KB), and incorporate structured KB query results\ninto system responses to successfully complete task-oriented dialogs. The\nproposed model produces well-structured system responses by jointly learning\nbelief tracking and KB result processing conditioning on the dialog history. We\nevaluate the model in a restaurant search domain using a dataset that is\nconverted from the second Dialog State Tracking Challenge (DSTC2) corpus.\nExperiment results show that the proposed model can robustly track dialog state\ngiven the dialog history. Moreover, our model demonstrates promising results in\nproducing appropriate system responses, outperforming prior end-to-end\ntrainable neural network models using per-response accuracy evaluation metrics.\n", "versions": [{"version": "v1", "created": "Sun, 20 Aug 2017 12:00:16 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Liu", "Bing", ""], ["Lane", "Ian", ""]]}, {"id": "1708.05963", "submitter": "Dmitry Ignatov", "authors": "Artem M. Grachev, Dmitry I. Ignatov, Andrey V. Savchenko", "title": "Neural Networks Compression for Language Modeling", "comments": "Keywords: LSTM, RNN, language modeling, low-rank factorization,\n  pruning, quantization. Published by Springer in the LNCS series, 7th\n  International Conference on Pattern Recognition and Machine Intelligence,\n  2017", "journal-ref": null, "doi": "10.1007/978-3-319-69900-4_44", "report-no": null, "categories": "stat.ML cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider several compression techniques for the language\nmodeling problem based on recurrent neural networks (RNNs). It is known that\nconventional RNNs, e.g, LSTM-based networks in language modeling, are\ncharacterized with either high space complexity or substantial inference time.\nThis problem is especially crucial for mobile applications, in which the\nconstant interaction with the remote server is inappropriate. By using the Penn\nTreebank (PTB) dataset we compare pruning, quantization, low-rank\nfactorization, tensor train decomposition for LSTM networks in terms of model\nsize and suitability for fast inference.\n", "versions": [{"version": "v1", "created": "Sun, 20 Aug 2017 13:37:06 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Grachev", "Artem M.", ""], ["Ignatov", "Dmitry I.", ""], ["Savchenko", "Andrey V.", ""]]}, {"id": "1708.05992", "submitter": "Piotr \\.Zelasko", "authors": "Piotr \\.Zelasko", "title": "Expanding Abbreviations in a Strongly Inflected Language: Are\n  Morphosyntactic Tags Sufficient?", "comments": "Presented on 11th May 2018 at Language Resources and Evaluation\n  Conference in Miyazaki, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the problem of recovery of morphological information lost in\nabbreviated forms is addressed with a focus on highly inflected languages.\nEvidence is presented that the correct inflected form of an expanded\nabbreviation can in many cases be deduced solely from the morphosyntactic tags\nof the context. The prediction model is a deep bidirectional LSTM network with\ntag embedding. The training and evaluation data are gathered by finding the\nwords which could have been abbreviated and using their corresponding\nmorphosyntactic tags as the labels, while the tags of the context words are\nused as the input features for classification. The network is trained on over\n10 million words from the Polish Sejm Corpus and achieves 74.2% prediction\naccuracy on a smaller, but more general National Corpus of Polish. The analysis\nof errors suggests that performance in this task may improve if some prior\nknowledge about the abbreviated word is incorporated into the model.\n", "versions": [{"version": "v1", "created": "Sun, 20 Aug 2017 16:29:54 GMT"}, {"version": "v2", "created": "Sun, 27 May 2018 10:46:24 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["\u017belasko", "Piotr", ""]]}, {"id": "1708.05997", "submitter": "Youssef Oualil", "authors": "Youssef Oualil, Dietrich Klakow", "title": "A Batch Noise Contrastive Estimation Approach for Training Large\n  Vocabulary Language Models", "comments": "Accepted for publication at INTERSPEECH'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training large vocabulary Neural Network Language Models (NNLMs) is a\ndifficult task due to the explicit requirement of the output layer\nnormalization, which typically involves the evaluation of the full softmax\nfunction over the complete vocabulary. This paper proposes a Batch Noise\nContrastive Estimation (B-NCE) approach to alleviate this problem. This is\nachieved by reducing the vocabulary, at each time step, to the target words in\nthe batch and then replacing the softmax by the noise contrastive estimation\napproach, where these words play the role of targets and noise samples at the\nsame time. In doing so, the proposed approach can be fully formulated and\nimplemented using optimal dense matrix operations. Applying B-NCE to train\ndifferent NNLMs on the Large Text Compression Benchmark (LTCB) and the One\nBillion Word Benchmark (OBWB) shows a significant reduction of the training\ntime with no noticeable degradation of the models performance. This paper also\npresents a new baseline comparative study of different standard NNLMs on the\nlarge OBWB on a single Titan-X GPU.\n", "versions": [{"version": "v1", "created": "Sun, 20 Aug 2017 17:48:35 GMT"}, {"version": "v2", "created": "Tue, 22 Aug 2017 09:15:38 GMT"}], "update_date": "2017-08-23", "authors_parsed": [["Oualil", "Youssef", ""], ["Klakow", "Dietrich", ""]]}, {"id": "1708.06000", "submitter": "Wei Wei", "authors": "Wei Wei, Kennth Joseph, Kathleen Carley", "title": "Efficient Online Inference for Infinite Evolutionary Cluster models with\n  Applications to Latent Social Event Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Recurrent Chinese Restaurant Process (RCRP) is a powerful statistical\nmethod for modeling evolving clusters in large scale social media data. With\nthe RCRP, one can allow both the number of clusters and the cluster parameters\nin a model to change over time. However, application of the RCRP has largely\nbeen limited due to the non-conjugacy between the cluster evolutionary priors\nand the Multinomial likelihood. This non-conjugacy makes inference di cult and\nrestricts the scalability of models which use the RCRP, leading to the RCRP\nbeing applied only in simple problems, such as those that can be approximated\nby a single Gaussian emission. In this paper, we provide a novel solution for\nthe non-conjugacy issues for the RCRP and an example of how to leverage our\nsolution for one speci c problem - the social event discovery problem. By\nutilizing Sequential Monte Carlo methods in inference, our approach can be\nmassively paralleled and is highly scalable, to the extent it can work on tens\nof millions of documents. We are able to generate high quality topical and\nlocation distributions of the clusters that can be directly interpreted as real\nsocial events, and our experimental results suggest that the approaches\nproposed achieve much better predictive performance than techniques reported in\nprior work. We also demonstrate how the techniques we develop can be used in a\nmuch more general ways toward similar problems.\n", "versions": [{"version": "v1", "created": "Sun, 20 Aug 2017 18:17:27 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Wei", "Wei", ""], ["Joseph", "Kennth", ""], ["Carley", "Kathleen", ""]]}, {"id": "1708.06022", "submitter": "Li Dong", "authors": "Li Dong, Jonathan Mallinson, Siva Reddy, Mirella Lapata", "title": "Learning to Paraphrase for Question Answering", "comments": "EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering (QA) systems are sensitive to the many different ways\nnatural language expresses the same information need. In this paper we turn to\nparaphrases as a means of capturing this knowledge and present a general\nframework which learns felicitous paraphrases for various QA tasks. Our method\nis trained end-to-end using question-answer pairs as a supervision signal. A\nquestion and its paraphrases serve as input to a neural scoring model which\nassigns higher weights to linguistic expressions most likely to yield correct\nanswers. We evaluate our approach on QA over Freebase and answer sentence\nselection. Experimental results on three datasets show that our framework\nconsistently improves performance, achieving competitive results despite the\nuse of simple QA models.\n", "versions": [{"version": "v1", "created": "Sun, 20 Aug 2017 21:19:01 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Dong", "Li", ""], ["Mallinson", "Jonathan", ""], ["Reddy", "Siva", ""], ["Lapata", "Mirella", ""]]}, {"id": "1708.06025", "submitter": "Nathan Hartmann", "authors": "Nathan Hartmann and Erick Fonseca and Christopher Shulby and Marcos\n  Treviso and Jessica Rodrigues and Sandra Aluisio", "title": "Portuguese Word Embeddings: Evaluating on Word Analogies and Natural\n  Language Tasks", "comments": "7 pages, STIL 2017 Full paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings have been found to provide meaningful representations for\nwords in an efficient way; therefore, they have become common in Natural\nLanguage Processing sys- tems. In this paper, we evaluated different word\nembedding models trained on a large Portuguese corpus, including both Brazilian\nand European variants. We trained 31 word embedding models using FastText,\nGloVe, Wang2Vec and Word2Vec. We evaluated them intrinsically on syntactic and\nsemantic analogies and extrinsically on POS tagging and sentence semantic\nsimilarity tasks. The obtained results suggest that word analogies are not\nappropriate for word embedding evaluation; task-specific evaluations appear to\nbe a better option.\n", "versions": [{"version": "v1", "created": "Sun, 20 Aug 2017 21:21:37 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Hartmann", "Nathan", ""], ["Fonseca", "Erick", ""], ["Shulby", "Christopher", ""], ["Treviso", "Marcos", ""], ["Rodrigues", "Jessica", ""], ["Aluisio", "Sandra", ""]]}, {"id": "1708.06068", "submitter": "Barathi Ganesh H B", "authors": "Barathi Ganesh HB and Anand Kumar M and Soman KP", "title": "Vector Space Model as Cognitive Space for Text Classification", "comments": "6 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this era of digitization, knowing the user's sociolect aspects have become\nessential features to build the user specific recommendation systems. These\nsociolect aspects could be found by mining the user's language sharing in the\nform of text in social media and reviews. This paper describes about the\nexperiment that was performed in PAN Author Profiling 2017 shared task. The\nobjective of the task is to find the sociolect aspects of the users from their\ntweets. The sociolect aspects considered in this experiment are user's gender\nand native language information. Here user's tweets written in a different\nlanguage from their native language are represented as Document - Term Matrix\nwith document frequency as the constraint. Further classification is done using\nthe Support Vector Machine by taking gender and native language as target\nclasses. This experiment attains the average accuracy of 73.42% in gender\nprediction and 76.26% in the native language identification task.\n", "versions": [{"version": "v1", "created": "Mon, 21 Aug 2017 03:06:07 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["HB", "Barathi Ganesh", ""], ["M", "Anand Kumar", ""], ["KP", "Soman", ""]]}, {"id": "1708.06073", "submitter": "Andreas Stolcke", "authors": "W. Xiong, L. Wu, F. Alleva, J. Droppo, X. Huang, A. Stolcke", "title": "The Microsoft 2017 Conversational Speech Recognition System", "comments": null, "journal-ref": null, "doi": null, "report-no": "Microsoft Technical Report MSR-TR-2017-39", "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the 2017 version of Microsoft's conversational speech recognition\nsystem, in which we update our 2016 system with recent developments in\nneural-network-based acoustic and language modeling to further advance the\nstate of the art on the Switchboard speech recognition task. The system adds a\nCNN-BLSTM acoustic model to the set of model architectures we combined\npreviously, and includes character-based and dialog session aware LSTM language\nmodels in rescoring. For system combination we adopt a two-stage approach,\nwhereby subsets of acoustic models are first combined at the senone/frame\nlevel, followed by a word-level voting via confusion networks. We also added a\nconfusion network rescoring step after system combination. The resulting system\nyields a 5.1\\% word error rate on the 2000 Switchboard evaluation set.\n", "versions": [{"version": "v1", "created": "Mon, 21 Aug 2017 03:17:23 GMT"}, {"version": "v2", "created": "Thu, 24 Aug 2017 23:30:37 GMT"}], "update_date": "2017-08-28", "authors_parsed": [["Xiong", "W.", ""], ["Wu", "L.", ""], ["Alleva", "F.", ""], ["Droppo", "J.", ""], ["Huang", "X.", ""], ["Stolcke", "A.", ""]]}, {"id": "1708.06075", "submitter": "Yi Luan", "authors": "Yi Luan, Mari Ostendorf and Hannaneh Hajishirzi", "title": "Scientific Information Extraction with Semi-supervised Neural Tagging", "comments": "accepted by EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of extracting keyphrases from scientific\narticles and categorizing them as corresponding to a task, process, or\nmaterial. We cast the problem as sequence tagging and introduce semi-supervised\nmethods to a neural tagging model, which builds on recent advances in named\nentity recognition. Since annotated training data is scarce in this domain, we\nintroduce a graph-based semi-supervised algorithm together with a data\nselection scheme to leverage unannotated articles. Both inductive and\ntransductive semi-supervised learning strategies outperform state-of-the-art\ninformation extraction performance on the 2017 SemEval Task 10 ScienceIE task.\n", "versions": [{"version": "v1", "created": "Mon, 21 Aug 2017 03:33:58 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Luan", "Yi", ""], ["Ostendorf", "Mari", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "1708.06185", "submitter": "Venkatesh Duppada", "authors": "Venkatesh Duppada, Sushant Hiray", "title": "Seernet at EmoInt-2017: Tweet Emotion Intensity Estimator", "comments": "In Proceedings of the EMNLP 2017 Workshop on Computational Approaches\n  to Subjectivity, Sentiment, and Social Media (WASSA), September 2017,\n  Copenhagen, Denmark", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper describes experiments on estimating emotion intensity in tweets\nusing a generalized regressor system. The system combines lexical, syntactic\nand pre-trained word embedding features, trains them on general regressors and\nfinally combines the best performing models to create an ensemble. The proposed\nsystem stood 3rd out of 22 systems in the leaderboard of WASSA-2017 Shared Task\non Emotion Intensity.\n", "versions": [{"version": "v1", "created": "Mon, 21 Aug 2017 12:30:48 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Duppada", "Venkatesh", ""], ["Hiray", "Sushant", ""]]}, {"id": "1708.06266", "submitter": "Zied Bouraoui", "authors": "Zied Bouraoui, Shoaib Jameel, Steven Schockaert", "title": "Probabilistic Relation Induction in Vector Space Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings have been found to capture a surprisingly rich amount of\nsyntactic and semantic knowledge. However, it is not yet sufficiently\nwell-understood how the relational knowledge that is implicitly encoded in word\nembeddings can be extracted in a reliable way. In this paper, we propose two\nprobabilistic models to address this issue. The first model is based on the\ncommon relations-as-translations view, but is cast in a probabilistic setting.\nOur second model is based on the much weaker assumption that there is a linear\nrelationship between the vector representations of related words. Compared to\nexisting approaches, our models lead to more accurate predictions, and they are\nmore explicit about what can and cannot be extracted from the word embedding.\n", "versions": [{"version": "v1", "created": "Mon, 21 Aug 2017 14:52:10 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Bouraoui", "Zied", ""], ["Jameel", "Shoaib", ""], ["Schockaert", "Steven", ""]]}, {"id": "1708.06426", "submitter": "Anuroop Sriram", "authors": "Anuroop Sriram, Heewoo Jun, Sanjeev Satheesh, Adam Coates", "title": "Cold Fusion: Training Seq2Seq Models Together with Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence (Seq2Seq) models with attention have excelled at tasks\nwhich involve generating natural language sentences such as machine\ntranslation, image captioning and speech recognition. Performance has further\nbeen improved by leveraging unlabeled data, often in the form of a language\nmodel. In this work, we present the Cold Fusion method, which leverages a\npre-trained language model during training, and show its effectiveness on the\nspeech recognition task. We show that Seq2Seq models with Cold Fusion are able\nto better utilize language information enjoying i) faster convergence and\nbetter generalization, and ii) almost complete transfer to a new domain while\nusing less than 10% of the labeled training data.\n", "versions": [{"version": "v1", "created": "Mon, 21 Aug 2017 21:28:07 GMT"}], "update_date": "2017-08-23", "authors_parsed": [["Sriram", "Anuroop", ""], ["Jun", "Heewoo", ""], ["Satheesh", "Sanjeev", ""], ["Coates", "Adam", ""]]}, {"id": "1708.06510", "submitter": "Frederick Liu", "authors": "Frederick Liu, Han Lu, Graham Neubig", "title": "Handling Homographs in Neural Machine Translation", "comments": "NAACL2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Homographs, words with different meanings but the same surface form, have\nlong caused difficulty for machine translation systems, as it is difficult to\nselect the correct translation based on the context. However, with the advent\nof neural machine translation (NMT) systems, which can theoretically take into\naccount global sentential context, one may hypothesize that this problem has\nbeen alleviated. In this paper, we first provide empirical evidence that\nexisting NMT systems in fact still have significant problems in properly\ntranslating ambiguous words. We then proceed to describe methods, inspired by\nthe word sense disambiguation literature, that model the context of the input\nword with context-aware word embeddings that help to differentiate the word\nsense be- fore feeding it into the encoder. Experiments on three language pairs\ndemonstrate that such models improve the performance of NMT systems both in\nterms of BLEU score and in the accuracy of translating homographs.\n", "versions": [{"version": "v1", "created": "Tue, 22 Aug 2017 06:48:27 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 05:32:19 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Liu", "Frederick", ""], ["Lu", "Han", ""], ["Neubig", "Graham", ""]]}, {"id": "1708.06550", "submitter": "Bart{\\l}omiej Balcerzak", "authors": "Bart{\\l}omiej Balcerzak, Rados{\\l}aw Nielek", "title": "Golden Years, Golden Shores: A Study of Elders in Online Travel\n  Communities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present our exploratory findings related to extracting\nknowledge and experiences from a community of senior tourists. By using tools\nof qualitative analysis as well as review of literature, we managed to verify a\nset of hypotheses related to the content created by senior tourists when\nparticipating in on-line communities. We also produced a codebook, representing\nvarious themes one may encounter in such communities. This codebook, derived\nfrom our own qualitative research, as well a literature review will serve as a\nbasis for further development of automated tools of knowledge extraction. We\nalso managed to find that older adults more often than other poster in tourists\nforums, mention their age in discussion, more often share their experiences and\nmotivation to travel, however they do not differ in relation to describing\nbarriers encountered while traveling.\n", "versions": [{"version": "v1", "created": "Tue, 22 Aug 2017 09:39:29 GMT"}], "update_date": "2017-08-23", "authors_parsed": [["Balcerzak", "Bart\u0142omiej", ""], ["Nielek", "Rados\u0142aw", ""]]}, {"id": "1708.06555", "submitter": "Youssef Oualil", "authors": "Youssef Oualil, Mittul Singh, Clayton Greenberg, Dietrich Klakow", "title": "Long-Short Range Context Neural Networks for Language Modeling", "comments": "Published at EMNLP'16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of language modeling techniques is to capture the statistical and\nstructural properties of natural languages from training corpora. This task\ntypically involves the learning of short range dependencies, which generally\nmodel the syntactic properties of a language and/or long range dependencies,\nwhich are semantic in nature. We propose in this paper a new multi-span\narchitecture, which separately models the short and long context information\nwhile it dynamically merges them to perform the language modeling task. This is\ndone through a novel recurrent Long-Short Range Context (LSRC) network, which\nexplicitly models the local (short) and global (long) context using two\nseparate hidden states that evolve in time. This new architecture is an\nadaptation of the Long-Short Term Memory network (LSTM) to take into account\nthe linguistic properties. Extensive experiments conducted on the Penn Treebank\n(PTB) and the Large Text Compression Benchmark (LTCB) corpus showed a\nsignificant reduction of the perplexity when compared to state-of-the-art\nlanguage modeling techniques.\n", "versions": [{"version": "v1", "created": "Tue, 22 Aug 2017 10:26:41 GMT"}], "update_date": "2017-08-23", "authors_parsed": [["Oualil", "Youssef", ""], ["Singh", "Mittul", ""], ["Greenberg", "Clayton", ""], ["Klakow", "Dietrich", ""]]}, {"id": "1708.06708", "submitter": "Adel Rahimi", "authors": "Reza Takhshid, Adel Rahimi", "title": "A rule based algorithm for detecting negative words in Persian", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a novel method for detecting negative words in\nPersian. We first used an algorithm to an exceptions list which was later\nmodified by hand. We then used the mentioned lists and a Persian polarity\ncorpus in our rule based algorithm to detect negative words.\n", "versions": [{"version": "v1", "created": "Sat, 19 Aug 2017 18:18:22 GMT"}], "update_date": "2017-08-23", "authors_parsed": [["Takhshid", "Reza", ""], ["Rahimi", "Adel", ""]]}, {"id": "1708.06828", "submitter": "Bonggun Shin", "authors": "Bonggun Shin, Falgun H. Chokshi, Timothy Lee and Jinho D. Choi", "title": "Classification of Radiology Reports Using Neural Attention Models", "comments": null, "journal-ref": "In Proceedings of the International Joint Conference on Neural\n  Networks, of IJCNN'17, pages 4363--4370, Anchorage, AK, 2017", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The electronic health record (EHR) contains a large amount of\nmulti-dimensional and unstructured clinical data of significant operational and\nresearch value. Distinguished from previous studies, our approach embraces a\ndouble-annotated dataset and strays away from obscure \"black-box\" models to\ncomprehensive deep learning models. In this paper, we present a novel neural\nattention mechanism that not only classifies clinically important findings.\nSpecifically, convolutional neural networks (CNN) with attention analysis are\nused to classify radiology head computed tomography reports based on five\ncategories that radiologists would account for in assessing acute and\ncommunicable findings in daily practice. The experiments show that our CNN\nattention models outperform non-neural models, especially when trained on a\nlarger dataset. Our attention analysis demonstrates the intuition behind the\nclassifier's decision by generating a heatmap that highlights attended terms\nused by the CNN model; this is valuable when potential downstream medical\ndecisions are to be performed by human experts or the classifier information is\nto be used in cohort construction such as for epidemiological studies.\n", "versions": [{"version": "v1", "created": "Tue, 22 Aug 2017 21:30:23 GMT"}], "update_date": "2017-08-24", "authors_parsed": [["Shin", "Bonggun", ""], ["Chokshi", "Falgun H.", ""], ["Lee", "Timothy", ""], ["Choi", "Jinho D.", ""]]}, {"id": "1708.06872", "submitter": "Yilin Zhang", "authors": "Yilin Zhang, Marie Poux-Berthe, Chris Wells, Karolina Koc-Michalska,\n  and Karl Rohe", "title": "Discovering Political Topics in Facebook Discussion threads with Graph\n  Contextualization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a graph contextualization method, pairGraphText, to study\npolitical engagement on Facebook during the 2012 French presidential election.\nIt is a spectral algorithm that contextualizes graph data with text data for\nonline discussion thread. In particular, we examine the Facebook posts of the\neight leading candidates and the comments beneath these posts. We find evidence\nof both (i) candidate-centered structure, where citizens primarily comment on\nthe wall of one candidate and (ii) issue-centered structure (i.e. on political\ntopics), where citizens' attention and expression is primarily directed towards\na specific set of issues (e.g. economics, immigration, etc). To identify\nissue-centered structure, we develop pairGraphText, to analyze a network with\nhigh-dimensional features on the interactions (i.e. text). This technique\nscales to hundreds of thousands of nodes and thousands of unique words. In the\nFacebook data, spectral clustering without the contextualizing text information\nfinds a mixture of (i) candidate and (ii) issue clusters. The contextualized\ninformation with text data helps to separate these two structures. We conclude\nby showing that the novel methodology is consistent under a statistical model.\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2017 02:42:59 GMT"}, {"version": "v2", "created": "Fri, 25 Aug 2017 17:00:57 GMT"}, {"version": "v3", "created": "Sat, 24 Mar 2018 03:04:03 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Zhang", "Yilin", ""], ["Poux-Berthe", "Marie", ""], ["Wells", "Chris", ""], ["Koc-Michalska", "Karolina", ""], ["Rohe", "Karl", ""]]}, {"id": "1708.06989", "submitter": "Youssef Oualil", "authors": "Youssef Oualil and Dietrich Klakow", "title": "A Neural Network Approach for Mixing Language Models", "comments": "Published at IEEE International Conference on Acoustics, Speech and\n  Signal Processing (ICASSP) 2017. arXiv admin note: text overlap with\n  arXiv:1703.08068", "journal-ref": "IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP), New Orleans, LA, 2017, pp. 5710-5714", "doi": "10.1109/ICASSP.2017.7953250", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of Neural Network (NN)-based language models is steadily\nimproving due to the emergence of new architectures, which are able to learn\ndifferent natural language characteristics. This paper presents a novel\nframework, which shows that a significant improvement can be achieved by\ncombining different existing heterogeneous models in a single architecture.\nThis is done through 1) a feature layer, which separately learns different\nNN-based models and 2) a mixture layer, which merges the resulting model\nfeatures. In doing so, this architecture benefits from the learning\ncapabilities of each model with no noticeable increase in the number of model\nparameters or the training time. Extensive experiments conducted on the Penn\nTreebank (PTB) and the Large Text Compression Benchmark (LTCB) corpus showed a\nsignificant reduction of the perplexity when compared to state-of-the-art\nfeedforward as well as recurrent neural network architectures.\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2017 13:27:16 GMT"}], "update_date": "2017-08-24", "authors_parsed": [["Oualil", "Youssef", ""], ["Klakow", "Dietrich", ""]]}, {"id": "1708.07104", "submitter": "Veronica Perez-Rosas", "authors": "Ver\\'onica P\\'erez-Rosas, Bennett Kleinberg, Alexandra Lefevre, Rada\n  Mihalcea", "title": "Automatic Detection of Fake News", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of misleading information in everyday access media outlets\nsuch as social media feeds, news blogs, and online newspapers have made it\nchallenging to identify trustworthy news sources, thus increasing the need for\ncomputational tools able to provide insights into the reliability of online\ncontent. In this paper, we focus on the automatic identification of fake\ncontent in online news. Our contribution is twofold. First, we introduce two\nnovel datasets for the task of fake news detection, covering seven different\nnews domains. We describe the collection, annotation, and validation process in\ndetail and present several exploratory analysis on the identification of\nlinguistic differences in fake and legitimate news content. Second, we conduct\na set of learning experiments to build accurate fake news detectors. In\naddition, we provide comparative analyses of the automatic and manual\nidentification of fake news.\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2017 17:12:03 GMT"}], "update_date": "2017-08-24", "authors_parsed": [["P\u00e9rez-Rosas", "Ver\u00f3nica", ""], ["Kleinberg", "Bennett", ""], ["Lefevre", "Alexandra", ""], ["Mihalcea", "Rada", ""]]}, {"id": "1708.07149", "submitter": "Ryan Lowe T.", "authors": "Ryan Lowe, Michael Noseworthy, Iulian V. Serban, Nicolas\n  Angelard-Gontier, Yoshua Bengio, Joelle Pineau", "title": "Towards an Automatic Turing Test: Learning to Evaluate Dialogue\n  Responses", "comments": "ACL 2017", "journal-ref": "Proceedings of the 55th annual meeting on Association for\n  Computational Linguistics (2017), pp. 1116-1126", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically evaluating the quality of dialogue responses for unstructured\ndomains is a challenging problem. Unfortunately, existing automatic evaluation\nmetrics are biased and correlate very poorly with human judgements of response\nquality. Yet having an accurate automatic evaluation procedure is crucial for\ndialogue research, as it allows rapid prototyping and testing of new models\nwith fewer expensive human evaluations. In response to this challenge, we\nformulate automatic dialogue evaluation as a learning problem. We present an\nevaluation model (ADEM) that learns to predict human-like scores to input\nresponses, using a new dataset of human response scores. We show that the ADEM\nmodel's predictions correlate significantly, and at a level much higher than\nword-overlap metrics such as BLEU, with human judgements at both the utterance\nand system-level. We also show that ADEM can generalize to evaluating dialogue\nmodels unseen during training, an important step for automatic dialogue\nevaluation.\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2017 18:56:00 GMT"}, {"version": "v2", "created": "Tue, 16 Jan 2018 23:29:14 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Lowe", "Ryan", ""], ["Noseworthy", "Michael", ""], ["Serban", "Iulian V.", ""], ["Angelard-Gontier", "Nicolas", ""], ["Bengio", "Yoshua", ""], ["Pineau", "Joelle", ""]]}, {"id": "1708.07241", "submitter": "Hoang Pham", "authors": "Thai-Hoang Pham, Xuan-Khoai Pham, Tuan-Anh Nguyen, Phuong Le-Hong", "title": "NNVLP: A Neural Network-Based Vietnamese Language Processing Toolkit", "comments": "4 pages, 5 figures, 6 tables, accepted to IJCNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates neural network-based toolkit namely NNVLP for\nessential Vietnamese language processing tasks including part-of-speech (POS)\ntagging, chunking, named entity recognition (NER). Our toolkit is a combination\nof bidirectional Long Short-Term Memory (Bi-LSTM), Convolutional Neural Network\n(CNN), Conditional Random Field (CRF), using pre-trained word embeddings as\ninput, which achieves state-of-the-art results on these three tasks. We provide\nboth API and web demo for this toolkit.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 01:26:48 GMT"}, {"version": "v2", "created": "Mon, 28 Aug 2017 15:16:26 GMT"}, {"version": "v3", "created": "Wed, 20 Sep 2017 03:58:42 GMT"}, {"version": "v4", "created": "Thu, 21 Sep 2017 17:07:41 GMT"}, {"version": "v5", "created": "Thu, 19 Oct 2017 14:26:43 GMT"}], "update_date": "2017-10-20", "authors_parsed": [["Pham", "Thai-Hoang", ""], ["Pham", "Xuan-Khoai", ""], ["Nguyen", "Tuan-Anh", ""], ["Le-Hong", "Phuong", ""]]}, {"id": "1708.07252", "submitter": "Dengliang Shi", "authors": "Dengliang Shi", "title": "A Study on Neural Network Language Modeling", "comments": "20 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An exhaustive study on neural network language modeling (NNLM) is performed\nin this paper. Different architectures of basic neural network language models\nare described and examined. A number of different improvements over basic\nneural network language models, including importance sampling, word classes,\ncaching and bidirectional recurrent neural network (BiRNN), are studied\nseparately, and the advantages and disadvantages of every technique are\nevaluated. Then, the limits of neural network language modeling are explored\nfrom the aspects of model architecture and knowledge representation. Part of\nthe statistical information from a word sequence will loss when it is processed\nword by word in a certain order, and the mechanism of training neural network\nby updating weight matrixes and vectors imposes severe restrictions on any\nsignificant enhancement of NNLM. For knowledge representation, the knowledge\nrepresented by neural network language models is the approximate probabilistic\ndistribution of word sequences from a certain training data set rather than the\nknowledge of a language itself or the information conveyed by word sequences in\na natural language. Finally, some directions for improving neural network\nlanguage modeling further is discussed.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 02:14:50 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["Shi", "Dengliang", ""]]}, {"id": "1708.07265", "submitter": "Diego Amancio Dr.", "authors": "Henrique F. de Arruda, Vanessa Q. Marinho, Thales S. Lima, Diego R.\n  Amancio, Luciano da F. Costa", "title": "An Image Analysis Approach to the Calligraphy of Books", "comments": null, "journal-ref": "Physica A 510, 110--120 (2018)", "doi": "10.1016/j.physa.2018.06.110", "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text network analysis has received increasing attention as a consequence of\nits wide range of applications. In this work, we extend a previous work founded\non the study of topological features of mesoscopic networks. Here, the\ngeometrical properties of visualized networks are quantified in terms of\nseveral image analysis techniques and used as subsidies for authorship\nattribution. It was found that the visual features account for performance\nsimilar to that achieved by using topological measurements. In addition, the\ncombination of these two types of features improved the performance.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 03:12:22 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["de Arruda", "Henrique F.", ""], ["Marinho", "Vanessa Q.", ""], ["Lima", "Thales S.", ""], ["Amancio", "Diego R.", ""], ["Costa", "Luciano da F.", ""]]}, {"id": "1708.07279", "submitter": "Jie Yang", "authors": "Jie Yang, Zhiyang Teng, Meishan Zhang, and Yue Zhang", "title": "Combining Discrete and Neural Features for Sequence Labeling", "comments": "Accepted by International Conference on Computational Linguistics and\n  Intelligent Text Processing (CICLing) 2016, April", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network models have recently received heated research attention in the\nnatural language processing community. Compared with traditional models with\ndiscrete features, neural models have two main advantages. First, they take\nlow-dimensional, real-valued embedding vectors as inputs, which can be trained\nover large raw data, thereby addressing the issue of feature sparsity in\ndiscrete models. Second, deep neural networks can be used to automatically\ncombine input features, and including non-local features that capture semantic\npatterns that cannot be expressed using discrete indicator features. As a\nresult, neural network models have achieved competitive accuracies compared\nwith the best discrete models for a range of NLP tasks.\n  On the other hand, manual feature templates have been carefully investigated\nfor most NLP tasks over decades and typically cover the most useful indicator\npattern for solving the problems. Such information can be complementary the\nfeatures automatically induced from neural networks, and therefore combining\ndiscrete and neural features can potentially lead to better accuracy compared\nwith models that leverage discrete or neural features only.\n  In this paper, we systematically investigate the effect of discrete and\nneural feature combination for a range of fundamental NLP tasks based on\nsequence labeling, including word segmentation, POS tagging and named entity\nrecognition for Chinese and English, respectively. Our results on standard\nbenchmarks show that state-of-the-art neural models can give accuracies\ncomparable to the best discrete models in the literature for most tasks and\ncombing discrete and neural features unanimously yield better results.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 05:24:26 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["Yang", "Jie", ""], ["Teng", "Zhiyang", ""], ["Zhang", "Meishan", ""], ["Zhang", "Yue", ""]]}, {"id": "1708.07403", "submitter": "Rasmus Berg Palm", "authors": "Rasmus Berg Palm, Ole Winther, Florian Laws", "title": "CloudScan - A configuration-free invoice analysis system using recurrent\n  neural networks", "comments": "Presented at ICDAR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present CloudScan; an invoice analysis system that requires zero\nconfiguration or upfront annotation. In contrast to previous work, CloudScan\ndoes not rely on templates of invoice layout, instead it learns a single global\nmodel of invoices that naturally generalizes to unseen invoice layouts. The\nmodel is trained using data automatically extracted from end-user provided\nfeedback. This automatic training data extraction removes the requirement for\nusers to annotate the data precisely. We describe a recurrent neural network\nmodel that can capture long range context and compare it to a baseline logistic\nregression model corresponding to the current CloudScan production system. We\ntrain and evaluate the system on 8 important fields using a dataset of 326,471\ninvoices. The recurrent neural network and baseline model achieve 0.891 and\n0.887 average F1 scores respectively on seen invoice layouts. For the harder\ntask of unseen invoice layouts, the recurrent neural network model outperforms\nthe baseline with 0.840 average F1 compared to 0.788.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 13:40:06 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["Palm", "Rasmus Berg", ""], ["Winther", "Ole", ""], ["Laws", "Florian", ""]]}, {"id": "1708.07476", "submitter": "Kevin Bowden", "authors": "Kevin K. Bowden, Grace I. Lin, Lena I. Reed, Marilyn A. Walker", "title": "M2D: Monolog to Dialog Generation for Conversational Story Telling", "comments": null, "journal-ref": "ICIDS 2016", "doi": "10.1007/978-3-319-48279-8_2", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Storytelling serves many different social functions, e.g. stories are used to\npersuade, share troubles, establish shared values, learn social behaviors, and\nentertain. Moreover, stories are often told conversationally through dialog,\nand previous work suggests that information provided dialogically is more\nengaging than when provided in monolog. In this paper, we present algorithms\nfor converting a deep representation of a story into a dialogic storytelling,\nthat can vary aspects of the telling, including the personality of the\nstorytellers. We conduct several experiments to test whether dialogic\nstorytellings are more engaging, and whether automatically generated variants\nin linguistic form that correspond to personality differences can be recognized\nin an extended storytelling dialog.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 16:06:18 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Bowden", "Kevin K.", ""], ["Lin", "Grace I.", ""], ["Reed", "Lena I.", ""], ["Walker", "Marilyn A.", ""]]}, {"id": "1708.07524", "submitter": "Jitong Chen", "authors": "DeLiang Wang and Jitong Chen", "title": "Supervised Speech Separation Based on Deep Learning: An Overview", "comments": "27 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech separation is the task of separating target speech from background\ninterference. Traditionally, speech separation is studied as a signal\nprocessing problem. A more recent approach formulates speech separation as a\nsupervised learning problem, where the discriminative patterns of speech,\nspeakers, and background noise are learned from training data. Over the past\ndecade, many supervised separation algorithms have been put forward. In\nparticular, the recent introduction of deep learning to supervised speech\nseparation has dramatically accelerated progress and boosted separation\nperformance. This article provides a comprehensive overview of the research on\ndeep learning based supervised speech separation in the last several years. We\nfirst introduce the background of speech separation and the formulation of\nsupervised separation. Then we discuss three main components of supervised\nseparation: learning machines, training targets, and acoustic features. Much of\nthe overview is on separation algorithms where we review monaural methods,\nincluding speech enhancement (speech-nonspeech separation), speaker separation\n(multi-talker separation), and speech dereverberation, as well as\nmulti-microphone techniques. The important issue of generalization, unique to\nsupervised learning, is discussed. This overview provides a historical\nperspective on how advances are made. In addition, we discuss a number of\nconceptual issues, including what constitutes the target source.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 18:51:50 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 03:28:26 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Wang", "DeLiang", ""], ["Chen", "Jitong", ""]]}, {"id": "1708.07624", "submitter": "Tommaso Soru", "authors": "Tommaso Soru, Edgard Marx, Diego Moussallem, Gustavo Publio, Andr\\'e\n  Valdestilhas, Diego Esteves, Ciro Baron Neto", "title": "SPARQL as a Foreign Language", "comments": "SEMANTiCS 2017; 13th International Conference on Semantic Systems,\n  2017", "journal-ref": "SEMANTiCS CEUR Workshop Proceedings 2044 (2017) Paper 14", "doi": null, "report-no": null, "categories": "cs.CL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last years, the Linked Data Cloud has achieved a size of more than 100\nbillion facts pertaining to a multitude of domains. However, accessing this\ninformation has been significantly challenging for lay users. Approaches to\nproblems such as Question Answering on Linked Data and Link Discovery have\nnotably played a role in increasing information access. These approaches are\noften based on handcrafted and/or statistical models derived from data\nobservation. Recently, Deep Learning architectures based on Neural Networks\ncalled seq2seq have shown to achieve state-of-the-art results at translating\nsequences into sequences. In this direction, we propose Neural SPARQL Machines,\nend-to-end deep architectures to translate any natural language expression into\nsentences encoding SPARQL queries. Our preliminary results, restricted on\nselected DBpedia classes, show that Neural SPARQL Machines are a promising\napproach for Question Answering on Linked Data, as they can deal with known\nproblems such as vocabulary mismatch and perform graph pattern composition.\n", "versions": [{"version": "v1", "created": "Fri, 25 Aug 2017 06:41:55 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 18:13:19 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Soru", "Tommaso", ""], ["Marx", "Edgard", ""], ["Moussallem", "Diego", ""], ["Publio", "Gustavo", ""], ["Valdestilhas", "Andr\u00e9", ""], ["Esteves", "Diego", ""], ["Neto", "Ciro Baron", ""]]}, {"id": "1708.07690", "submitter": "Demian Gholipour", "authors": "Demian Gholipour Ghalandari", "title": "Revisiting the Centroid-based Method: A Strong Baseline for\n  Multi-Document Summarization", "comments": "EMNLP 2017 Workshop on New Frontiers in Summarization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The centroid-based model for extractive document summarization is a simple\nand fast baseline that ranks sentences based on their similarity to a centroid\nvector. In this paper, we apply this ranking to possible summaries instead of\nsentences and use a simple greedy algorithm to find the best summary.\nFurthermore, we show possi- bilities to scale up to larger input docu- ment\ncollections by selecting a small num- ber of sentences from each document prior\nto constructing the summary. Experiments were done on the DUC2004 dataset for\nmulti-document summarization. We ob- serve a higher performance over the orig-\ninal model, on par with more complex state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 25 Aug 2017 11:21:44 GMT"}], "update_date": "2017-08-28", "authors_parsed": [["Ghalandari", "Demian Gholipour", ""]]}, {"id": "1708.07722", "submitter": "Ramon Ferrer i Cancho", "authors": "Xinying Chen, Carlos G\\'omez-Rodr\\'iguez and Ramon Ferrer-i-Cancho", "title": "A dependency look at the reality of constituency", "comments": "Final version", "journal-ref": "Glottometrics 40, 104-106 (2018)", "doi": null, "report-no": null, "categories": "cs.CL cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A comment on \"Neurophysiological dynamics of phrase-structure building during\nsentence processing\" by Nelson et al (2017), Proceedings of the National\nAcademy of Sciences USA 114(18), E3669-E3678.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 04:59:53 GMT"}, {"version": "v2", "created": "Mon, 11 Sep 2017 08:27:18 GMT"}, {"version": "v3", "created": "Fri, 16 Mar 2018 08:17:18 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Chen", "Xinying", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""], ["Ferrer-i-Cancho", "Ramon", ""]]}, {"id": "1708.07863", "submitter": "Zhiguo Wang", "authors": "Zhiguo Wang, Wael Hamza, Linfeng Song", "title": "$k$-Nearest Neighbor Augmented Neural Networks for Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, many deep-learning based models are proposed for text\nclassification. This kind of models well fits the training set from the\nstatistical point of view. However, it lacks the capacity of utilizing\ninstance-level information from individual instances in the training set. In\nthis work, we propose to enhance neural network models by allowing them to\nleverage information from $k$-nearest neighbor (kNN) of the input text. Our\nmodel employs a neural network that encodes texts into text embeddings.\nMoreover, we also utilize $k$-nearest neighbor of the input text as an external\nmemory, and utilize it to capture instance-level information from the training\nset. The final prediction is made based on features from both the neural\nnetwork encoder and the kNN memory. Experimental results on several standard\nbenchmark datasets show that our model outperforms the baseline model on all\nthe datasets, and it even beats a very deep neural network model (with 29\nlayers) in several datasets. Our model also shows superior performance when\ntraining instances are scarce, and when the training set is severely\nunbalanced. Our model also leverages techniques such as semi-supervised\ntraining and transfer learning quite well.\n", "versions": [{"version": "v1", "created": "Fri, 25 Aug 2017 19:04:25 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Wang", "Zhiguo", ""], ["Hamza", "Wael", ""], ["Song", "Linfeng", ""]]}, {"id": "1708.07903", "submitter": "Junting Ye", "authors": "Junting Ye, Shuchu Han, Yifan Hu, Baris Coskun, Meizhu Liu, Hong Qin,\n  Steven Skiena", "title": "Nationality Classification Using Name Embeddings", "comments": "10 pages, 9 figures, 4 table, accepted by CIKM 2017, Demo and free\n  API: www.name-prism.com", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nationality identification unlocks important demographic information, with\nmany applications in biomedical and sociological research. Existing name-based\nnationality classifiers use name substrings as features and are trained on\nsmall, unrepresentative sets of labeled names, typically extracted from\nWikipedia. As a result, these methods achieve limited performance and cannot\nsupport fine-grained classification.\n  We exploit the phenomena of homophily in communication patterns to learn name\nembeddings, a new representation that encodes gender, ethnicity, and\nnationality which is readily applicable to building classifiers and other\nsystems. Through our analysis of 57M contact lists from a major Internet\ncompany, we are able to design a fine-grained nationality classifier covering\n39 groups representing over 90% of the world population. In an evaluation\nagainst other published systems over 13 common classes, our F1 score (0.795) is\nsubstantial better than our closest competitor Ethnea (0.580). To the best of\nour knowledge, this is the most accurate, fine-grained nationality classifier\navailable.\n  As a social media application, we apply our classifiers to the followers of\nmajor Twitter celebrities over six different domains. We demonstrate stark\ndifferences in the ethnicities of the followers of Trump and Obama, and in the\nsports and entertainments favored by different groups. Finally, we identify an\nanomalous political figure whose presumably inflated following appears largely\nincapable of reading the language he posts in.\n", "versions": [{"version": "v1", "created": "Fri, 25 Aug 2017 22:03:09 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Ye", "Junting", ""], ["Han", "Shuchu", ""], ["Hu", "Yifan", ""], ["Coskun", "Baris", ""], ["Liu", "Meizhu", ""], ["Qin", "Hong", ""], ["Skiena", "Steven", ""]]}, {"id": "1708.07918", "submitter": "Mo Yu", "authors": "Mo Yu, Xiaoxiao Guo, Jinfeng Yi, Shiyu Chang, Saloni Potdar, Gerald\n  Tesauro, Haoyu Wang, Bowen Zhou", "title": "Robust Task Clustering for Deep Many-Task Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate task clustering for deep-learning based multi-task and\nfew-shot learning in a many-task setting. We propose a new method to measure\ntask similarities with cross-task transfer performance matrix for the deep\nlearning scenario. Although this matrix provides us critical information\nregarding similarity between tasks, its asymmetric property and unreliable\nperformance scores can affect conventional clustering methods adversely.\nAdditionally, the uncertain task-pairs, i.e., the ones with extremely\nasymmetric transfer scores, may collectively mislead clustering algorithms to\noutput an inaccurate task-partition. To overcome these limitations, we propose\na novel task-clustering algorithm by using the matrix completion technique. The\nproposed algorithm constructs a partially-observed similarity matrix based on\nthe certainty of cluster membership of the task-pairs. We then use a matrix\ncompletion algorithm to complete the similarity matrix. Our theoretical\nanalysis shows that under mild constraints, the proposed algorithm will\nperfectly recover the underlying \"true\" similarity matrix with a high\nprobability. Our results show that the new task clustering method can discover\ntask clusters for training flexible and superior neural network models in a\nmulti-task learning setup for sentiment classification and dialog intent\nclassification tasks. Our task clustering approach also extends metric-based\nfew-shot learning methods to adapt multiple metrics, which demonstrates\nempirical advantages when the tasks are diverse.\n", "versions": [{"version": "v1", "created": "Sat, 26 Aug 2017 02:29:50 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 00:53:48 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Yu", "Mo", ""], ["Guo", "Xiaoxiao", ""], ["Yi", "Jinfeng", ""], ["Chang", "Shiyu", ""], ["Potdar", "Saloni", ""], ["Tesauro", "Gerald", ""], ["Wang", "Haoyu", ""], ["Zhou", "Bowen", ""]]}, {"id": "1708.07950", "submitter": "Raj Nath Patel", "authors": "Raj Nath Patel, Prakash B. Pimpale, M Sasikumar", "title": "Machine Translation in Indian Languages: Challenges and Resolution", "comments": "11 pages journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  English to Indian language machine translation poses the challenge of\nstructural and morphological divergence. This paper describes English to Indian\nlanguage statistical machine translation using pre-ordering and suffix\nseparation. The pre-ordering uses rules to transfer the structure of the source\nsentences prior to training and translation. This syntactic restructuring helps\nstatistical machine translation to tackle the structural divergence and hence\nbetter translation quality. The suffix separation is used to tackle the\nmorphological divergence between English and highly agglutinative Indian\nlanguages. We demonstrate that the use of pre-ordering and suffix separation\nhelps in improving the quality of English to Indian Language machine\ntranslation.\n", "versions": [{"version": "v1", "created": "Sat, 26 Aug 2017 08:12:35 GMT"}, {"version": "v2", "created": "Sat, 16 Jun 2018 12:57:03 GMT"}, {"version": "v3", "created": "Wed, 1 Aug 2018 18:30:48 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Patel", "Raj Nath", ""], ["Pimpale", "Prakash B.", ""], ["Sasikumar", "M", ""]]}, {"id": "1708.08123", "submitter": "Ankit Vadehra", "authors": "Ankit Vadehra, Maura R. Grossman and Gordon V. Cormack", "title": "Impact of Feature Selection on Micro-Text Classification", "comments": "4 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media datasets, especially Twitter tweets, are popular in the field of\ntext classification. Tweets are a valuable source of micro-text (sometimes\nreferred to as \"micro-blogs\"), and have been studied in domains such as\nsentiment analysis, recommendation systems, spam detection, clustering, among\nothers. Tweets often include keywords referred to as \"Hashtags\" that can be\nused as labels for the tweet. Using tweets encompassing 50 labels, we studied\nthe impact of word versus character-level feature selection and extraction on\ndifferent learners to solve a multi-class classification task. We show that\nfeature extraction of simple character-level groups performs better than simple\nword groups and pre-processing methods like normalizing using Porter's Stemming\nand Part-of-Speech (\"POS\")-Lemmatization.\n", "versions": [{"version": "v1", "created": "Sun, 27 Aug 2017 18:50:48 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Vadehra", "Ankit", ""], ["Grossman", "Maura R.", ""], ["Cormack", "Gordon V.", ""]]}, {"id": "1708.08289", "submitter": "Dar\\'io Garigliotti", "authors": "Dar\\'io Garigliotti and Krisztian Balog", "title": "Generating Query Suggestions to Support Task-Based Search", "comments": "Proceedings of the 40th International ACM SIGIR Conference on\n  Research and Development in Information Retrieval (SIGIR '17), 2017", "journal-ref": null, "doi": "10.1145/3077136.3080745", "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of generating query suggestions to support users in\ncompleting their underlying tasks (which motivated them to search in the first\nplace). Given an initial query, these query suggestions should provide a\ncoverage of possible subtasks the user might be looking for. We propose a\nprobabilistic modeling framework that obtains keyphrases from multiple sources\nand generates query suggestions from these keyphrases. Using the test suites of\nthe TREC Tasks track, we evaluate and analyze each component of our model.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2017 12:44:14 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Garigliotti", "Dar\u00edo", ""], ["Balog", "Krisztian", ""]]}, {"id": "1708.08291", "submitter": "Dar\\'io Garigliotti", "authors": "Dar\\'io Garigliotti and Krisztian Balog", "title": "On Type-Aware Entity Retrieval", "comments": "Proceedings of the 3rd ACM International Conference on the Theory of\n  Information Retrieval (ICTIR '17), 2017", "journal-ref": null, "doi": "10.1145/3121050.3121054", "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, the practice of returning entities from a knowledge base in response\nto search queries has become widespread. One of the distinctive characteristics\nof entities is that they are typed, i.e., assigned to some hierarchically\norganized type system (type taxonomy). The primary objective of this paper is\nto gain a better understanding of how entity type information can be utilized\nin entity retrieval. We perform this investigation in an idealized \"oracle\"\nsetting, assuming that we know the distribution of target types of the relevant\nentities for a given query. We perform a thorough analysis of three main\naspects: (i) the choice of type taxonomy, (ii) the representation of\nhierarchical type information, and (iii) the combination of type-based and\nterm-based similarity in the retrieval model. Using a standard entity search\ntest collection based on DBpedia, we find that type information proves most\nuseful when using large type taxonomies that provide very specific types. We\nprovide further insights on the extensional coverage of entities and on the\nutility of target types.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2017 12:47:04 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Garigliotti", "Dar\u00edo", ""], ["Balog", "Krisztian", ""]]}, {"id": "1708.08484", "submitter": "Kai Zhao", "authors": "Kai Zhao and Liang Huang", "title": "Joint Syntacto-Discourse Parsing and the Syntacto-Discourse Treebank", "comments": "Accepted at EMNLP 2017", "journal-ref": "Proceedings of EMNLP 2017", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discourse parsing has long been treated as a stand-alone problem independent\nfrom constituency or dependency parsing. Most attempts at this problem are\npipelined rather than end-to-end, sophisticated, and not self-contained: they\nassume gold-standard text segmentations (Elementary Discourse Units), and use\nexternal parsers for syntactic features. In this paper we propose the first\nend-to-end discourse parser that jointly parses in both syntax and discourse\nlevels, as well as the first syntacto-discourse treebank by integrating the\nPenn Treebank with the RST Treebank. Built upon our recent span-based\nconstituency parser, this joint syntacto-discourse parser requires no\npreprocessing whatsoever (such as segmentation or feature extraction), achieves\nthe state-of-the-art end-to-end discourse parsing accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2017 18:57:50 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Zhao", "Kai", ""], ["Huang", "Liang", ""]]}, {"id": "1708.08572", "submitter": "Stephanie Lukin", "authors": "Stephanie Lukin and Marilyn Walker", "title": "Really? Well. Apparently Bootstrapping Improves the Performance of\n  Sarcasm and Nastiness Classifiers for Online Dialogue", "comments": "Workshop on Language Analysis in Social Media (LASM 2013), at the\n  North American Chapter of the Association for Computational Linguistics\n  (NAACL 2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More and more of the information on the web is dialogic, from Facebook\nnewsfeeds, to forum conversations, to comment threads on news articles. In\ncontrast to traditional, monologic Natural Language Processing resources such\nas news, highly social dialogue is frequent in social media, making it a\nchallenging context for NLP. This paper tests a bootstrapping method,\noriginally proposed in a monologic domain, to train classifiers to identify two\ndifferent types of subjective language in dialogue: sarcasm and nastiness. We\nexplore two methods of developing linguistic indicators to be used in a first\nlevel classifier aimed at maximizing precision at the expense of recall. The\nbest performing classifier for the first phase achieves 54% precision and 38%\nrecall for sarcastic utterances. We then use general syntactic patterns from\nprevious work to create more general sarcasm indicators, improving precision to\n62% and recall to 52%. To further test the generality of the method, we then\napply it to bootstrapping a classifier for nastiness dialogic acts. Our first\nphase, using crowdsourced nasty indicators, achieves 58% precision and 49%\nrecall, which increases to 75% precision and 62% recall when we bootstrap over\nthe first level with generalized syntactic patterns.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 02:05:14 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Lukin", "Stephanie", ""], ["Walker", "Marilyn", ""]]}, {"id": "1708.08573", "submitter": "Stephanie Lukin", "authors": "Elena Rishes and Stephanie M. Lukin and David K. Elson and Marilyn A.\n  Walker", "title": "Generating Different Story Tellings from Semantic Representations of\n  Narrative", "comments": "International Conference on Interactive Digital Storytelling (ICIDS\n  2013)", "journal-ref": null, "doi": "10.1007/978-3-319-02756-2_24", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to tell stories in different voices for different audiences,\ninteractive story systems require: (1) a semantic representation of story\nstructure, and (2) the ability to automatically generate story and dialogue\nfrom this semantic representation using some form of Natural Language\nGeneration (NLG). However, there has been limited research on methods for\nlinking story structures to narrative descriptions of scenes and story events.\nIn this paper we present an automatic method for converting from Scheherazade's\nstory intention graph, a semantic representation, to the input required by the\nPersonage NLG engine. Using 36 Aesop Fables distributed in DramaBank, a\ncollection of story encodings, we train translation rules on one story and then\ntest these rules by generating text for the remaining 35. The results are\nmeasured in terms of the string similarity metrics Levenshtein Distance and\nBLEU score. The results show that we can generate the 35 stories with correct\ncontent: the test set stories on average are close to the output of the\nScheherazade realizer, which was customized to this semantic representation. We\nprovide some examples of story variations generated by personage. In future\nwork, we will experiment with measuring the quality of the same stories\ngenerated in different voices, and with techniques for making storytelling\ninteractive.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 02:05:56 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Rishes", "Elena", ""], ["Lukin", "Stephanie M.", ""], ["Elson", "David K.", ""], ["Walker", "Marilyn A.", ""]]}, {"id": "1708.08575", "submitter": "Stephanie Lukin", "authors": "Stephanie M. Lukin and Luke Eisenberg and Thomas Corcoran and Marilyn\n  A. Walker", "title": "Identifying Subjective and Figurative Language in Online Dialogue", "comments": "Pacific Northwest Natural Language Processing Workshop (NWNLP 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More and more of the information on the web is dialogic, from Facebook\nnewsfeeds, to forum conversations, to comment threads on news articles. In\ncontrast to traditional, monologic resources such as news, highly social\ndialogue is very frequent in social media. We aim to automatically identify\nsarcastic and nasty utterances in unannotated online dialogue, extending a\nbootstrapping method previously applied to the classification of monologic\nsubjective sentences in Riloff and Weibe 2003. We have adapted the method to\nfit the sarcastic and nasty dialogic domain. Our method is as follows: 1)\nExplore methods for identifying sarcastic and nasty cue words and phrases in\ndialogues; 2) Use the learned cues to train a sarcastic (nasty) Cue-Based\nClassifier; 3) Learn general syntactic extraction patterns from the sarcastic\n(nasty) utterances and define fine-tuned sarcastic patterns to create a\nPattern-Based Classifier; 4) Combine both Cue-Based and fine-tuned\nPattern-Based Classifiers to maximize precision at the expense of recall and\ntest on unannotated utterances.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 02:21:48 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Lukin", "Stephanie M.", ""], ["Eisenberg", "Luke", ""], ["Corcoran", "Thomas", ""], ["Walker", "Marilyn A.", ""]]}, {"id": "1708.08580", "submitter": "Stephanie Lukin", "authors": "Stephanie M. Lukin and Lena I. Reed and Marilyn A. Walker", "title": "Generating Sentence Planning Variations for Story Telling", "comments": "SIGdial Meeting on Discourse and Dialogue (SIGDIAL 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a recent explosion in applications for dialogue interaction\nranging from direction-giving and tourist information to interactive story\nsystems. Yet the natural language generation (NLG) component for many of these\nsystems remains largely handcrafted. This limitation greatly restricts the\nrange of applications; it also means that it is impossible to take advantage of\nrecent work in expressive and statistical language generation that can\ndynamically and automatically produce a large number of variations of given\ncontent. We propose that a solution to this problem lies in new methods for\ndeveloping language generation resources. We describe the ES-Translator, a\ncomputational language generator that has previously been applied only to\nfables, and quantitatively evaluate the domain independence of the EST by\napplying it to personal narratives from weblogs. We then take advantage of\nrecent work on language generation to create a parameterized sentence planner\nfor story generation that provides aggregation operations, variations in\ndiscourse and in point of view. Finally, we present a user evaluation of\ndifferent personal narrative retellings.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 03:11:20 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Lukin", "Stephanie M.", ""], ["Reed", "Lena I.", ""], ["Walker", "Marilyn A.", ""]]}, {"id": "1708.08585", "submitter": "Stephanie Lukin", "authors": "Stephanie M. Lukin and Marilyn A. Walker", "title": "Narrative Variations in a Virtual Storyteller", "comments": "Intelligent Virtual Agents (IVA 2015)", "journal-ref": null, "doi": "10.1007/978-3-319-21996-7_34", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on storytelling over the last 100 years has distinguished at least\ntwo levels of narrative representation (1) story, or fabula; and (2) discourse,\nor sujhet. We use this distinction to create Fabula Tales, a computational\nframework for a virtual storyteller that can tell the same story in different\nways through the implementation of general narratological variations, such as\nvarying direct vs. indirect speech, character voice (style), point of view, and\nfocalization. A strength of our computational framework is that it is based on\nvery general methods for re-using existing story content, either from fables or\nfrom personal narratives collected from blogs. We first explain how a simple\nannotation tool allows naive annotators to easily create a deep representation\nof fabula called a story intention graph, and show how we use this\nrepresentation to generate story tellings automatically. Then we present\nresults of two studies testing our narratological parameters, and showing that\ndifferent tellings affect the reader's perception of the story and characters.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 03:51:56 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Lukin", "Stephanie M.", ""], ["Walker", "Marilyn A.", ""]]}, {"id": "1708.08615", "submitter": "Andreas Stolcke", "authors": "Andreas Stolcke and Jasha Droppo", "title": "Comparing Human and Machine Errors in Conversational Speech\n  Transcription", "comments": null, "journal-ref": "Proc. Interspeech 2017, pp. 137-141", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in automatic recognition of conversational telephone speech (CTS)\nhas achieved accuracy levels comparable to human transcribers, although there\nis some debate how to precisely quantify human performance on this task, using\nthe NIST 2000 CTS evaluation set. This raises the question what systematic\ndifferences, if any, may be found differentiating human from machine\ntranscription errors. In this paper we approach this question by comparing the\noutput of our most accurate CTS recognition system to that of a standard speech\ntranscription vendor pipeline. We find that the most frequent substitution,\ndeletion and insertion error types of both outputs show a high degree of\noverlap. The only notable exception is that the automatic recognizer tends to\nconfuse filled pauses (\"uh\") and backchannel acknowledgments (\"uhhuh\"). Humans\ntend not to make this error, presumably due to the distinctive and opposing\npragmatic functions attached to these words. Furthermore, we quantify the\ncorrelation between human and machine errors at the speaker level, and\ninvestigate the effect of speaker overlap between training and test data.\nFinally, we report on an informal \"Turing test\" asking humans to discriminate\nbetween automatic and human transcription error cases.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 07:21:39 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Stolcke", "Andreas", ""], ["Droppo", "Jasha", ""]]}, {"id": "1708.08712", "submitter": "Hassan Sajjad", "authors": "Hassan Sajjad and Nadir Durrani and Fahim Dalvi and Yonatan Belinkov\n  and Stephan Vogel", "title": "Neural Machine Translation Training in a Multi-Domain Scenario", "comments": "8 pages", "journal-ref": "Proceedings of the 14th International Workshop on Spoken Language\n  Translation (IWSLT), 2017", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore alternative ways to train a neural machine\ntranslation system in a multi-domain scenario. We investigate data\nconcatenation (with fine tuning), model stacking (multi-level fine tuning),\ndata selection and multi-model ensemble. Our findings show that the best\ntranslation quality can be achieved by building an initial system on a\nconcatenation of available out-of-domain data and then fine-tuning it on\nin-domain data. Model stacking works best when training begins with the\nfurthest out-of-domain data and the model is incrementally fine-tuned with the\nnext furthest domain and so on. Data selection did not give the best results,\nbut can be considered as a decent compromise between training time and\ntranslation quality. A weighted ensemble of different individual models\nperformed better than data selection. It is beneficial in a scenario when there\nis no time for fine-tuning an already trained model.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 11:56:41 GMT"}, {"version": "v2", "created": "Sun, 3 Sep 2017 13:01:59 GMT"}, {"version": "v3", "created": "Tue, 20 Nov 2018 12:11:17 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Sajjad", "Hassan", ""], ["Durrani", "Nadir", ""], ["Dalvi", "Fahim", ""], ["Belinkov", "Yonatan", ""], ["Vogel", "Stephan", ""]]}, {"id": "1708.08959", "submitter": "Mohab Elkaref", "authors": "Mohab Elkaref and Bernd Bohnet", "title": "A Simple LSTM model for Transition-based Dependency Parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple LSTM-based transition-based dependency parser. Our model\nis composed of a single LSTM hidden layer replacing the hidden layer in the\nusual feed-forward network architecture. We also propose a new initialization\nmethod that uses the pre-trained weights from a feed-forward neural network to\ninitialize our LSTM-based model. We also show that using dropout on the input\nlayer has a positive effect on performance. Our final parser achieves a 93.06%\nunlabeled and 91.01% labeled attachment score on the Penn Treebank. We\nadditionally replace LSTMs with GRUs and Elman units in our model and explore\nthe effectiveness of our initialization method on individual gates constituting\nall three types of RNN units.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 18:25:35 GMT"}, {"version": "v2", "created": "Fri, 8 Sep 2017 22:46:59 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Elkaref", "Mohab", ""], ["Bohnet", "Bernd", ""]]}, {"id": "1708.09025", "submitter": "Xiaofeng Zhu", "authors": "Xiaofeng Zhu, Diego Klabjan, Patrick Bless", "title": "Unsupervised Terminological Ontology Learning based on Hierarchical\n  Topic Modeling", "comments": null, "journal-ref": "IRI 2017", "doi": "10.1109/IRI.2017.18", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present hierarchical relationbased latent Dirichlet\nallocation (hrLDA), a data-driven hierarchical topic model for extracting\nterminological ontologies from a large number of heterogeneous documents. In\ncontrast to traditional topic models, hrLDA relies on noun phrases instead of\nunigrams, considers syntax and document structures, and enriches topic\nhierarchies with topic relations. Through a series of experiments, we\ndemonstrate the superiority of hrLDA over existing topic models, especially for\nbuilding hierarchies. Furthermore, we illustrate the robustness of hrLDA in the\nsettings of noisy data sets, which are likely to occur in many practical\nscenarios. Our ontology evaluation results show that ontologies extracted from\nhrLDA are very competitive with the ontologies created by domain experts.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 21:04:11 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Zhu", "Xiaofeng", ""], ["Klabjan", "Diego", ""], ["Bless", "Patrick", ""]]}, {"id": "1708.09040", "submitter": "Elahe Rahimtoroghi", "authors": "Elahe Rahimtoroghi, Jiaqi Wu, Ruimin Wang, Pranav Anand, Marilyn A\n  Walker", "title": "Modelling Protagonist Goals and Desires in First-Person Narrative", "comments": "10 pages, 18th Annual SIGdial Meeting on Discourse and Dialogue\n  (SIGDIAL 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many genres of natural language text are narratively structured, a testament\nto our predilection for organizing our experiences as narratives. There is\nbroad consensus that understanding a narrative requires identifying and\ntracking the goals and desires of the characters and their narrative outcomes.\nHowever, to date, there has been limited work on computational models for this\nproblem. We introduce a new dataset, DesireDB, which includes gold-standard\nlabels for identifying statements of desire, textual evidence for desire\nfulfillment, and annotations for whether the stated desire is fulfilled given\nthe evidence in the narrative context. We report experiments on tracking desire\nfulfillment using different methods, and show that LSTM Skip-Thought model\nachieves F-measure of 0.7 on our corpus.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 21:40:22 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Rahimtoroghi", "Elahe", ""], ["Wu", "Jiaqi", ""], ["Wang", "Ruimin", ""], ["Anand", "Pranav", ""], ["Walker", "Marilyn A", ""]]}, {"id": "1708.09082", "submitter": "Stephanie Lukin", "authors": "Stephanie M. Lukin, Kevin Bowden, Casey Barackman and Marilyn A.\n  Walker", "title": "PersonaBank: A Corpus of Personal Narratives and Their Story Intention\n  Graphs", "comments": "International Conference on Language Resources and Evaluation (LREC\n  2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new corpus, PersonaBank, consisting of 108 personal stories from\nweblogs that have been annotated with their Story Intention Graphs, a deep\nrepresentation of the fabula of a story. We describe the topics of the stories\nand the basis of the Story Intention Graph representation, as well as the\nprocess of annotating the stories to produce the Story Intention Graphs and the\nchallenges of adapting the tool to this new personal narrative domain We also\ndiscuss how the corpus can be used in applications that retell the story using\ndifferent styles of tellings, co-tellings, or as a content planner.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 01:56:23 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Lukin", "Stephanie M.", ""], ["Bowden", "Kevin", ""], ["Barackman", "Casey", ""], ["Walker", "Marilyn A.", ""]]}, {"id": "1708.09085", "submitter": "Stephanie Lukin", "authors": "Stephanie M. Lukin, Pranav Anand, Marilyn Walker and Steve Whittaker", "title": "Argument Strength is in the Eye of the Beholder: Audience Effects in\n  Persuasion", "comments": "European Chapter of the Association for Computational Linguistics\n  (EACL 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Americans spend about a third of their time online, with many participating\nin online conversations on social and political issues. We hypothesize that\nsocial media arguments on such issues may be more engaging and persuasive than\ntraditional media summaries, and that particular types of people may be more or\nless convinced by particular styles of argument, e.g. emotional arguments may\nresonate with some personalities while factual arguments resonate with others.\nWe report a set of experiments testing at large scale how audience variables\ninteract with argument style to affect the persuasiveness of an argument, an\nunder-researched topic within natural language processing. We show that belief\nchange is affected by personality factors, with conscientious, open and\nagreeable people being more convinced by emotional arguments.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 02:01:30 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Lukin", "Stephanie M.", ""], ["Anand", "Pranav", ""], ["Walker", "Marilyn", ""], ["Whittaker", "Steve", ""]]}, {"id": "1708.09090", "submitter": "Stephanie Lukin", "authors": "Stephanie M. Lukin, James O. Ryan and Marilyn A. Walker", "title": "Automating Direct Speech Variations in Stories and Games", "comments": "3rd Workshop on Games and NLP (GAMNLP 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue authoring in large games requires not only content creation but the\nsubtlety of its delivery, which can vary from character to character. Manually\nauthoring this dialogue can be tedious, time-consuming, or even altogether\ninfeasible. This paper utilizes a rich narrative representation for modeling\ndialogue and an expressive natural language generation engine for realizing it,\nand expands upon a translation tool that bridges the two. We add functionality\nto the translator to allow direct speech to be modeled by the narrative\nrepresentation, whereas the original translator supports only narratives told\nby a third person narrator. We show that we can perform character substitution\nin dialogues. We implement and evaluate a potential application to dialogue\nimplementation: generating dialogue for games with big, dynamic, or\nprocedurally-generated open worlds. We present a pilot study on human\nperceptions of the personalities of characters using direct speech, assuming\nunknown personality types at the time of authoring.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 02:19:39 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Lukin", "Stephanie M.", ""], ["Ryan", "James O.", ""], ["Walker", "Marilyn A.", ""]]}, {"id": "1708.09151", "submitter": "Ryan Cotterell Ryan D Cotterell", "authors": "Ryan Cotterell, Ekaterina Vylomova, Huda Khayrallah, Christo Kirov and\n  David Yarowsky", "title": "Paradigm Completion for Derivational Morphology", "comments": "EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generation of complex derived word forms has been an overlooked problem\nin NLP; we fill this gap by applying neural sequence-to-sequence models to the\ntask. We overview the theoretical motivation for a paradigmatic treatment of\nderivational morphology, and introduce the task of derivational paradigm\ncompletion as a parallel to inflectional paradigm completion. State-of-the-art\nneural models, adapted from the inflection task, are able to learn a range of\nderivation patterns, and outperform a non-neural baseline by 16.4%. However,\ndue to semantic, historical, and lexical considerations involved in\nderivational morphology, future work will be needed to achieve performance\nparity with inflection-generating systems.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 07:55:57 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Cotterell", "Ryan", ""], ["Vylomova", "Ekaterina", ""], ["Khayrallah", "Huda", ""], ["Kirov", "Christo", ""], ["Yarowsky", "David", ""]]}, {"id": "1708.09157", "submitter": "Ryan D. Cotterell", "authors": "Ryan Cotterell and Georg Heigold", "title": "Cross-lingual, Character-Level Neural Morphological Tagging", "comments": "Published as a conference paper at EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even for common NLP tasks, sufficient supervision is not available in many\nlanguages -- morphological tagging is no exception. In the work presented here,\nwe explore a transfer learning scheme, whereby we train character-level\nrecurrent neural taggers to predict morphological taggings for high-resource\nlanguages and low-resource languages together. Learning joint character\nrepresentations among multiple related languages successfully enables knowledge\ntransfer from the high-resource languages to the low-resource ones, improving\naccuracy by up to 30%\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 08:14:34 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 13:53:42 GMT"}, {"version": "v3", "created": "Mon, 13 Jan 2020 10:30:21 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Cotterell", "Ryan", ""], ["Heigold", "Georg", ""]]}, {"id": "1708.09163", "submitter": "Phuong Le-Hong", "authors": "Phuong Le-Hong, Minh Pham Quang Nhat, Thai-Hoang Pham, Tuan-Anh Tran,\n  Dang-Minh Nguyen", "title": "An Empirical Study of Discriminative Sequence Labeling Models for\n  Vietnamese Text Processing", "comments": "To appear in the Proceedings of the 9th International Conference on\n  Knowledge and Systems Engineering (KSE) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an empirical study of two widely-used sequence prediction\nmodels, Conditional Random Fields (CRFs) and Long Short-Term Memory Networks\n(LSTMs), on two fundamental tasks for Vietnamese text processing, including\npart-of-speech tagging and named entity recognition. We show that a strong\nlower bound for labeling accuracy can be obtained by relying only on simple\nword-based features with minimal hand-crafted feature engineering, of 90.65\\%\nand 86.03\\% performance scores on the standard test sets for the two tasks\nrespectively. In particular, we demonstrate empirically the surprising\nefficiency of word embeddings in both of the two tasks, with both of the two\nmodels. We point out that the state-of-the-art LSTMs model does not always\noutperform significantly the traditional CRFs model, especially on\nmoderate-sized data sets. Finally, we give some suggestions and discussions for\nefficient use of sequence labeling models in practical applications.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 08:32:32 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Le-Hong", "Phuong", ""], ["Nhat", "Minh Pham Quang", ""], ["Pham", "Thai-Hoang", ""], ["Tran", "Tuan-Anh", ""], ["Nguyen", "Dang-Minh", ""]]}, {"id": "1708.09217", "submitter": "Long Zhou", "authors": "Long Zhou, Jiajun Zhang, Chengqing Zong", "title": "Look-ahead Attention for Generation in Neural Machine Translation", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The attention model has become a standard component in neural machine\ntranslation (NMT) and it guides translation process by selectively focusing on\nparts of the source sentence when predicting each target word. However, we find\nthat the generation of a target word does not only depend on the source\nsentence, but also rely heavily on the previous generated target words,\nespecially the distant words which are difficult to model by using recurrent\nneural networks. To solve this problem, we propose in this paper a novel\nlook-ahead attention mechanism for generation in NMT, which aims at directly\ncapturing the dependency relationship between target words. We further design\nthree patterns to integrate our look-ahead attention into the conventional\nattention model. Experiments on NIST Chinese-to-English and WMT\nEnglish-to-German translation tasks show that our proposed look-ahead attention\nmechanism achieves substantial improvements over state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 11:27:02 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Zhou", "Long", ""], ["Zhang", "Jiajun", ""], ["Zong", "Chengqing", ""]]}, {"id": "1708.09230", "submitter": "Diego Moussallem", "authors": "Sandro A. Coelho, Diego Moussallem, Gustavo C. Publio and Diego\n  Esteves", "title": "TANKER: Distributed Architecture for Named Entity Recognition and\n  Disambiguation", "comments": "SEMANTiCS 2017; 13th International Conference on Semantic Systems,\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named Entity Recognition and Disambiguation (NERD) systems have recently been\nwidely researched to deal with the significant growth of the Web. NERD systems\nare crucial for several Natural Language Processing (NLP) tasks such as\nsummarization, understanding, and machine translation. However, there is no\nstandard interface specification, i.e. these systems may vary significantly\neither for exporting their outputs or for processing the inputs. Thus, when a\ngiven company desires to implement more than one NERD system, the process is\nquite exhaustive and prone to failure. In addition, industrial solutions demand\ncritical requirements, e.g., large-scale processing, completeness, versatility,\nand licenses. Commonly, these requirements impose a limitation, making good\nNERD models to be ignored by companies. This paper presents TANKER, a\ndistributed architecture which aims to overcome scalability, reliability and\nfailure tolerance limitations related to industrial needs by combining NERD\nsystems. To this end, TANKER relies on a micro-services oriented architecture,\nwhich enables agile development and delivery of complex enterprise\napplications. In addition, TANKER provides a standardized API which makes\npossible to combine several NERD systems at once.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 12:10:20 GMT"}, {"version": "v2", "created": "Tue, 5 Sep 2017 11:59:13 GMT"}, {"version": "v3", "created": "Wed, 25 Oct 2017 09:34:18 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Coelho", "Sandro A.", ""], ["Moussallem", "Diego", ""], ["Publio", "Gustavo C.", ""], ["Esteves", "Diego", ""]]}, {"id": "1708.09234", "submitter": "Alexander Panchenko", "authors": "Dmitry Ustalov, Mikhail Chernoskutov, Chris Biemann, and Alexander\n  Panchenko", "title": "Fighting with the Sparsity of Synonymy Dictionaries", "comments": "In Proceedings of the 6th Conference on Analysis of Images, Social\n  Networks, and Texts (AIST'2017): Springer Lecture Notes in Computer Science\n  (LNCS)", "journal-ref": null, "doi": "10.1007/978-3-319-73013-4_9", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph-based synset induction methods, such as MaxMax and Watset, induce\nsynsets by performing a global clustering of a synonymy graph. However, such\nmethods are sensitive to the structure of the input synonymy graph: sparseness\nof the input dictionary can substantially reduce the quality of the extracted\nsynsets. In this paper, we propose two different approaches designed to\nalleviate the incompleteness of the input dictionaries. The first one performs\na pre-processing of the graph by adding missing edges, while the second one\nperforms a post-processing by merging similar synset clusters. We evaluate\nthese approaches on two datasets for the Russian language and discuss their\nimpact on the performance of synset induction methods. Finally, we perform an\nextensive error analysis of each approach and discuss prominent alternative\nmethods for coping with the problem of the sparsity of the synonymy\ndictionaries.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 12:29:04 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Ustalov", "Dmitry", ""], ["Chernoskutov", "Mikhail", ""], ["Biemann", "Chris", ""], ["Panchenko", "Alexander", ""]]}, {"id": "1708.09403", "submitter": "Tianze Shi", "authors": "Tianze Shi, Liang Huang, Lillian Lee", "title": "Fast(er) Exact Decoding and Global Training for Transition-Based\n  Dependency Parsing via a Minimal Feature Set", "comments": "Proceedings of EMNLP, 2017. 12 pages", "journal-ref": "Proceedings of EMNLP, 2017", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We first present a minimal feature set for transition-based dependency\nparsing, continuing a recent trend started by Kiperwasser and Goldberg (2016a)\nand Cross and Huang (2016a) of using bi-directional LSTM features. We plug our\nminimal feature set into the dynamic-programming framework of Huang and Sagae\n(2010) and Kuhlmann et al. (2011) to produce the first implementation of\nworst-case O(n^3) exact decoders for arc-hybrid and arc-eager transition\nsystems. With our minimal features, we also present O(n^3) global training\nmethods. Finally, using ensembles including our new parsers, we achieve the\nbest unlabeled attachment score reported (to our knowledge) on the Chinese\nTreebank and the \"second-best-in-class\" result on the English Penn Treebank.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 18:01:08 GMT"}], "update_date": "2017-09-01", "authors_parsed": [["Shi", "Tianze", ""], ["Huang", "Liang", ""], ["Lee", "Lillian", ""]]}, {"id": "1708.09417", "submitter": "Lasha Abziandize", "authors": "Lasha Abzianidze", "title": "LangPro: Natural Language Theorem Prover", "comments": "6 pages, 8 figures, Conference on Empirical Methods in Natural\n  Language Processing (EMNLP) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LangPro is an automated theorem prover for natural language\n(https://github.com/kovvalsky/LangPro). Given a set of premises and a\nhypothesis, it is able to prove semantic relations between them. The prover is\nbased on a version of analytic tableau method specially designed for natural\nlogic. The proof procedure operates on logical forms that preserve linguistic\nexpressions to a large extent. %This property makes the logical forms easily\nobtainable from syntactic trees. %, in particular, Combinatory Categorial\nGrammar derivation trees. The nature of proofs is deductive and transparent. On\nthe FraCaS and SICK textual entailment datasets, the prover achieves high\nresults comparable to state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 18:22:28 GMT"}], "update_date": "2017-09-01", "authors_parsed": [["Abzianidze", "Lasha", ""]]}, {"id": "1708.09450", "submitter": "Elahe Rahimtoroghi", "authors": "Elahe Rahimtoroghi, Ernesto Hernandez, Marilyn A Walker", "title": "Learning Fine-Grained Knowledge about Contingent Relations between\n  Everyday Events", "comments": "SIGDIAL 2016", "journal-ref": "17th Annual SIGdial Meeting on Discourse and Dialogue (SIGDIAL\n  2016)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of the user-generated content on social media is provided by ordinary\npeople telling stories about their daily lives. We develop and test a novel\nmethod for learning fine-grained common-sense knowledge from these stories\nabout contingent (causal and conditional) relationships between everyday\nevents. This type of knowledge is useful for text and story understanding,\ninformation extraction, question answering, and text summarization. We test and\ncompare different methods for learning contingency relation, and compare what\nis learned from topic-sorted story collections vs. general-domain stories. Our\nexperiments show that using topic-specific datasets enables learning\nfiner-grained knowledge about events and results in significant improvement\nover the baselines. An evaluation on Amazon Mechanical Turk shows 82% of the\nrelations between events that we learn from topic-sorted stories are judged as\ncontingent.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 20:01:34 GMT"}], "update_date": "2017-09-01", "authors_parsed": [["Rahimtoroghi", "Elahe", ""], ["Hernandez", "Ernesto", ""], ["Walker", "Marilyn A", ""]]}, {"id": "1708.09453", "submitter": "Elahe Rahimtoroghi", "authors": "Zhichao Hu, Elahe Rahimtoroghi, Marilyn A Walker", "title": "Inference of Fine-Grained Event Causality from Blogs and Films", "comments": "Events and Stories in the News Workshop, ACL 2017", "journal-ref": "Events and Stories in the News Workshop, ACL 2017", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human understanding of narrative is mainly driven by reasoning about causal\nrelations between events and thus recognizing them is a key capability for\ncomputational models of language understanding. Computational work in this area\nhas approached this via two different routes: by focusing on acquiring a\nknowledge base of common causal relations between events, or by attempting to\nunderstand a particular story or macro-event, along with its storyline. In this\nposition paper, we focus on knowledge acquisition approach and claim that\nnewswire is a relatively poor source for learning fine-grained causal relations\nbetween everyday events. We describe experiments using an unsupervised method\nto learn causal relations between events in the narrative genres of\nfirst-person narratives and film scene descriptions. We show that our method\nlearns fine-grained causal relations, judged by humans as likely to be causal\nover 80% of the time. We also demonstrate that the learned event pairs do not\nexist in publicly available event-pair datasets extracted from newswire.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 20:12:01 GMT"}], "update_date": "2017-09-01", "authors_parsed": [["Hu", "Zhichao", ""], ["Rahimtoroghi", "Elahe", ""], ["Walker", "Marilyn A", ""]]}, {"id": "1708.09492", "submitter": "Siyuan Jiang", "authors": "Siyuan Jiang, Ameer Armaly, Collin McMillan", "title": "Automatically Generating Commit Messages from Diffs using Neural Machine\n  Translation", "comments": "Preprint version. Accepted in ASE 2017, the 32nd IEEE/ACM\n  International Conference on Automated Software Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commit messages are a valuable resource in comprehension of software\nevolution, since they provide a record of changes such as feature additions and\nbug repairs. Unfortunately, programmers often neglect to write good commit\nmessages. Different techniques have been proposed to help programmers by\nautomatically writing these messages. These techniques are effective at\ndescribing what changed, but are often verbose and lack context for\nunderstanding the rationale behind a change. In contrast, humans write messages\nthat are short and summarize the high level rationale. In this paper, we adapt\nNeural Machine Translation (NMT) to automatically \"translate\" diffs into commit\nmessages. We trained an NMT algorithm using a corpus of diffs and human-written\ncommit messages from the top 1k Github projects. We designed a filter to help\nensure that we only trained the algorithm on higher-quality commit messages.\nOur evaluation uncovered a pattern in which the messages we generate tend to be\neither very high or very low quality. Therefore, we created a quality-assurance\nfilter to detect cases in which we are unable to produce good messages, and\nreturn a warning instead.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 22:26:48 GMT"}], "update_date": "2017-09-01", "authors_parsed": [["Jiang", "Siyuan", ""], ["Armaly", "Ameer", ""], ["McMillan", "Collin", ""]]}, {"id": "1708.09496", "submitter": "Zhichao Hu", "authors": "Zhichao Hu and Marilyn A. Walker", "title": "Inferring Narrative Causality between Event Pairs in Films", "comments": null, "journal-ref": "Proceedings of the SIGDIAL 2017 Conference pages 342-351", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand narrative, humans draw inferences about the underlying\nrelations between narrative events. Cognitive theories of narrative\nunderstanding define these inferences as four different types of causality,\nthat include pairs of events A, B where A physically causes B (X drop, X\nbreak), to pairs of events where A causes emotional state B (Y saw X, Y felt\nfear). Previous work on learning narrative relations from text has either\nfocused on \"strict\" physical causality, or has been vague about what relation\nis being learned. This paper learns pairs of causal events from a corpus of\nfilm scene descriptions which are action rich and tend to be told in\nchronological order. We show that event pairs induced using our methods are of\nhigh quality and are judged to have a stronger causal relation than event pairs\nfrom Rel-grams.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 22:51:08 GMT"}], "update_date": "2017-09-01", "authors_parsed": [["Hu", "Zhichao", ""], ["Walker", "Marilyn A.", ""]]}, {"id": "1708.09497", "submitter": "Zhichao Hu", "authors": "Zhichao Hu, Elahe Rahimtoroghi, Larissa Munishkina, Reid Swanson and\n  Marilyn A. Walker", "title": "Unsupervised Induction of Contingent Event Pairs from Film Scenes", "comments": null, "journal-ref": "In Proceedings of Conference on Empirical Methods in Natural\n  Language Processing (EMNLP 2013)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human engagement in narrative is partially driven by reasoning about\ndiscourse relations between narrative events, and the expectations about what\nis likely to happen next that results from such reasoning. Researchers in NLP\nhave tackled modeling such expectations from a range of perspectives, including\ntreating it as the inference of the contingent discourse relation, or as a type\nof common-sense causal reasoning. Our approach is to model likelihood between\nevents by drawing on several of these lines of previous work. We implement and\nevaluate different unsupervised methods for learning event pairs that are\nlikely to be contingent on one another. We refine event pairs that we learn\nfrom a corpus of film scene descriptions utilizing web search counts, and\nevaluate our results by collecting human judgments of contingency. Our results\nindicate that the use of web search counts increases the average accuracy of\nour best method to 85.64% over a baseline of 50%, as compared to an average\naccuracy of 75.15% without web search.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 23:02:06 GMT"}], "update_date": "2017-09-01", "authors_parsed": [["Hu", "Zhichao", ""], ["Rahimtoroghi", "Elahe", ""], ["Munishkina", "Larissa", ""], ["Swanson", "Reid", ""], ["Walker", "Marilyn A.", ""]]}, {"id": "1708.09516", "submitter": "Vikramjit Mitra", "authors": "Vikramjit Mitra and Horacio Franco", "title": "Leveraging Deep Neural Network Activation Entropy to cope with Unseen\n  Data in Speech Recognition", "comments": "7 pages, Index Terms: automatic speech recognition, robust speech\n  recognition, unsupervised adaptation, neural network activations, confidence\n  measures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unseen data conditions can inflict serious performance degradation on systems\nrelying on supervised machine learning algorithms. Because data can often be\nunseen, and because traditional machine learning algorithms are trained in a\nsupervised manner, unsupervised adaptation techniques must be used to adapt the\nmodel to the unseen data conditions. However, unsupervised adaptation is often\nchallenging, as one must generate some hypothesis given a model and then use\nthat hypothesis to bootstrap the model to the unseen data conditions.\nUnfortunately, reliability of such hypotheses is often poor, given the mismatch\nbetween the training and testing datasets. In such cases, a model hypothesis\nconfidence measure enables performing data selection for the model adaptation.\nUnderlying this approach is the fact that for unseen data conditions, data\nvariability is introduced to the model, which the model propagates to its\noutput decision, impacting decision reliability. In a fully connected network,\nthis data variability is propagated as distortions from one layer to the next.\nThis work aims to estimate the propagation of such distortion in the form of\nnetwork activation entropy, which is measured over a short- time running window\non the activation from each neuron of a given hidden layer, and these\nmeasurements are then used to compute summary entropy. This work demonstrates\nthat such an entropy measure can help to select data for unsupervised model\nadaptation, resulting in performance gains in speech recognition tasks. Results\nfrom standard benchmark speech recognition tasks show that the proposed\napproach can alleviate the performance degradation experienced under unseen\ndata conditions by iteratively adapting the model to the unseen datas acoustic\ncondition.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 01:00:19 GMT"}], "update_date": "2017-09-01", "authors_parsed": [["Mitra", "Vikramjit", ""], ["Franco", "Horacio", ""]]}, {"id": "1708.09609", "submitter": "Jonathan K Kummerfeld", "authors": "Greg Durrett, Jonathan K. Kummerfeld, Taylor Berg-Kirkpatrick, Rebecca\n  S. Portnoff, Sadia Afroz, Damon McCoy, Kirill Levchenko, Vern Paxson", "title": "Identifying Products in Online Cybercrime Marketplaces: A Dataset for\n  Fine-grained Domain Adaptation", "comments": "To appear at EMNLP 2017", "journal-ref": "EMNLP (2017) 2598-2607", "doi": "10.18653/v1/D17-1275", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One weakness of machine-learned NLP models is that they typically perform\npoorly on out-of-domain data. In this work, we study the task of identifying\nproducts being bought and sold in online cybercrime forums, which exhibits\nparticularly challenging cross-domain effects. We formulate a task that\nrepresents a hybrid of slot-filling information extraction and named entity\nrecognition and annotate data from four different forums. Each of these forums\nconstitutes its own \"fine-grained domain\" in that the forums cover different\nmarket sectors with different properties, even though all forums are in the\nbroad domain of cybercrime. We characterize these domain differences in the\ncontext of a learning-based system: supervised models see decreased accuracy\nwhen applied to new forums, and standard techniques for semi-supervised\nlearning and domain adaptation have limited effectiveness on this data, which\nsuggests the need to improve these techniques. We release a dataset of 1,938\nannotated posts from across the four forums.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 08:18:12 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Durrett", "Greg", ""], ["Kummerfeld", "Jonathan K.", ""], ["Berg-Kirkpatrick", "Taylor", ""], ["Portnoff", "Rebecca S.", ""], ["Afroz", "Sadia", ""], ["McCoy", "Damon", ""], ["Levchenko", "Kirill", ""], ["Paxson", "Vern", ""]]}, {"id": "1708.09666", "submitter": "Shizhe Chen", "authors": "Shizhe Chen, Jia Chen, Qin Jin", "title": "Generating Video Descriptions with Topic Guidance", "comments": "Appeared at ICMR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating video descriptions in natural language (a.k.a. video captioning)\nis a more challenging task than image captioning as the videos are\nintrinsically more complicated than images in two aspects. First, videos cover\na broader range of topics, such as news, music, sports and so on. Second,\nmultiple topics could coexist in the same video. In this paper, we propose a\nnovel caption model, topic-guided model (TGM), to generate topic-oriented\ndescriptions for videos in the wild via exploiting topic information. In\naddition to predefined topics, i.e., category tags crawled from the web, we\nalso mine topics in a data-driven way based on training captions by an\nunsupervised topic mining model. We show that data-driven topics reflect a\nbetter topic schema than the predefined topics. As for testing video topic\nprediction, we treat the topic mining model as teacher to train the student,\nthe topic prediction model, by utilizing the full multi-modalities in the video\nespecially the speech modality. We propose a series of caption models to\nexploit topic guidance, including implicitly using the topics as input features\nto generate words related to the topic and explicitly modifying the weights in\nthe decoder with topics to function as an ensemble of topic-aware language\ndecoders. Our comprehensive experimental results on the current largest video\ncaption dataset MSR-VTT prove the effectiveness of our topic-guided model,\nwhich significantly surpasses the winning performance in the 2016 MSR video to\nlanguage challenge.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 11:17:53 GMT"}, {"version": "v2", "created": "Mon, 4 Sep 2017 11:38:38 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Chen", "Shizhe", ""], ["Chen", "Jia", ""], ["Jin", "Qin", ""]]}, {"id": "1708.09667", "submitter": "Shizhe Chen", "authors": "Shizhe Chen, Jia Chen, Qin Jin, Alexander Hauptmann", "title": "Video Captioning with Guidance of Multimodal Latent Topics", "comments": "ACM Multimedia 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The topic diversity of open-domain videos leads to various vocabularies and\nlinguistic expressions in describing video contents, and therefore, makes the\nvideo captioning task even more challenging. In this paper, we propose an\nunified caption framework, M&M TGM, which mines multimodal topics in\nunsupervised fashion from data and guides the caption decoder with these\ntopics. Compared to pre-defined topics, the mined multimodal topics are more\nsemantically and visually coherent and can reflect the topic distribution of\nvideos better. We formulate the topic-aware caption generation as a multi-task\nlearning problem, in which we add a parallel task, topic prediction, in\naddition to the caption task. For the topic prediction task, we use the mined\ntopics as the teacher to train a student topic prediction model, which learns\nto predict the latent topics from multimodal contents of videos. The topic\nprediction provides intermediate supervision to the learning process. As for\nthe caption task, we propose a novel topic-aware decoder to generate more\naccurate and detailed video descriptions with the guidance from latent topics.\nThe entire learning procedure is end-to-end and it optimizes both tasks\nsimultaneously. The results from extensive experiments conducted on the MSR-VTT\nand Youtube2Text datasets demonstrate the effectiveness of our proposed model.\nM&M TGM not only outperforms prior state-of-the-art methods on multiple\nevaluation metrics and on both benchmark datasets, but also achieves better\ngeneralization ability.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 11:18:28 GMT"}, {"version": "v2", "created": "Sat, 2 Sep 2017 15:34:44 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Chen", "Shizhe", ""], ["Chen", "Jia", ""], ["Jin", "Qin", ""], ["Hauptmann", "Alexander", ""]]}, {"id": "1708.09702", "submitter": "Alexander Panchenko", "authors": "Alexander Panchenko, Dmitry Ustalov, Nikolay Arefyev, Denis Paperno,\n  Natalia Konstantinova, Natalia Loukachevitch, and Chris Biemann", "title": "Human and Machine Judgements for Russian Semantic Relatedness", "comments": null, "journal-ref": "In Proceedings of the 5th Conference on Analysis of Images, Social\n  Networks, and Texts (AIST'2016): Springer Communications in Computer and\n  Information Sciences (CCIS)", "doi": "10.1007/978-3-319-52920-2_21", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Semantic relatedness of terms represents similarity of meaning by a numerical\nscore. On the one hand, humans easily make judgments about semantic\nrelatedness. On the other hand, this kind of information is useful in language\nprocessing systems. While semantic relatedness has been extensively studied for\nEnglish using numerous language resources, such as associative norms, human\njudgments, and datasets generated from lexical databases, no evaluation\nresources of this kind have been available for Russian to date. Our\ncontribution addresses this problem. We present five language resources of\ndifferent scale and purpose for Russian semantic relatedness, each being a list\nof triples (word_i, word_j, relatedness_ij). Four of them are designed for\nevaluation of systems for computing semantic relatedness, complementing each\nother in terms of the semantic relation type they represent. These benchmarks\nwere used to organize a shared task on Russian semantic relatedness, which\nattracted 19 teams. We use one of the best approaches identified in this\ncompetition to generate the fifth high-coverage resource, the first open\ndistributional thesaurus of Russian. Multiple evaluations of this thesaurus,\nincluding a large-scale crowdsourcing study involving native speakers, indicate\nits high accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 13:33:04 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Panchenko", "Alexander", ""], ["Ustalov", "Dmitry", ""], ["Arefyev", "Nikolay", ""], ["Paperno", "Denis", ""], ["Konstantinova", "Natalia", ""], ["Loukachevitch", "Natalia", ""], ["Biemann", "Chris", ""]]}, {"id": "1708.09789", "submitter": "Lena Reed", "authors": "Lena Reed, Jiaqi Wu, Shereen Oraby, Pranav Anand, Marilyn Walker", "title": "Learning Lexico-Functional Patterns for First-Person Affect", "comments": "7 pages, Association for Computational Linguistics (ACL) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Informal first-person narratives are a unique resource for computational\nmodels of everyday events and people's affective reactions to them. People\nblogging about their day tend not to explicitly say I am happy. Instead they\ndescribe situations from which other humans can readily infer their affective\nreactions. However current sentiment dictionaries are missing much of the\ninformation needed to make similar inferences. We build on recent work that\nmodels affect in terms of lexical predicate functions and affect on the\npredicate's arguments. We present a method to learn proxies for these functions\nfrom first-person narratives. We construct a novel fine-grained test set, and\nshow that the patterns we learn improve our ability to predict first-person\naffective reactions to everyday events, from a Stanford sentiment baseline of\n.67F to .75F.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 16:04:26 GMT"}], "update_date": "2017-09-01", "authors_parsed": [["Reed", "Lena", ""], ["Wu", "Jiaqi", ""], ["Oraby", "Shereen", ""], ["Anand", "Pranav", ""], ["Walker", "Marilyn", ""]]}, {"id": "1708.09803", "submitter": "Toan Nguyen", "authors": "Toan Q. Nguyen, David Chiang", "title": "Transfer Learning across Low-Resource, Related Languages for Neural\n  Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple method to improve neural translation of a low-resource\nlanguage pair using parallel data from a related, also low-resource, language\npair. The method is based on the transfer method of Zoph et al., but whereas\ntheir method ignores any source vocabulary overlap, ours exploits it. First, we\nsplit words using Byte Pair Encoding (BPE) to increase vocabulary overlap.\nThen, we train a model on the first language pair and transfer its parameters,\nincluding its source word embeddings, to another model and continue training on\nthe second language pair. Our experiments show that transfer learning helps\nword-based translation only slightly, but when used on top of a much stronger\nBPE baseline, it yields larger improvements of up to 4.3 BLEU.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 16:34:38 GMT"}, {"version": "v2", "created": "Thu, 21 Sep 2017 17:04:20 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Nguyen", "Toan Q.", ""], ["Chiang", "David", ""]]}]