[{"id": "1006.0153", "submitter": "Solomija Buk N", "authors": "Solomiya Buk", "title": "Ivan Franko's novel Dlja domashnjoho ohnyshcha (For the Hearth) in the\n  light of the frequency dictionary", "comments": "11 pages, in Ukrainian", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the article, the methodology and the principles of the compilation of the\nFrequency dictionary for Ivan Franko's novel Dlja domashnjoho ohnyshcha (For\nthe Hearth) are described. The following statistical parameters of the novel\nvocabulary are obtained: variety, exclusiveness, concentration indexes,\ncorrelation between word rank and text coverage, etc. The main quantitative\ncharacteristics of Franko's novels Perekhresni stezhky (The Cross-Paths) and\nDlja domashnjoho ohnyshcha are compared on the basis of their frequency\ndictionaries.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2010 15:20:59 GMT"}], "update_date": "2010-06-02", "authors_parsed": [["Buk", "Solomiya", ""]]}, {"id": "1006.1343", "submitter": "Fionn Murtagh", "authors": "Fionn Murtagh and Adam Ganz", "title": "Segmentation and Nodal Points in Narrative: Study of Multiple Variations\n  of a Ballad", "comments": "27 pp., 13 figures. Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lady Maisry ballads afford us a framework within which to segment a\nstoryline into its major components. Segments and as a consequence nodal points\nare discussed for nine different variants of the Lady Maisry story of a (young)\nwoman being burnt to death by her family, on account of her becoming pregnant\nby a foreign personage. We motivate the importance of nodal points in textual\nand literary analysis. We show too how the openings of the nine variants can be\nanalyzed comparatively, and also the conclusions of the ballads.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2010 19:36:18 GMT"}], "update_date": "2010-06-08", "authors_parsed": [["Murtagh", "Fionn", ""], ["Ganz", "Adam", ""]]}, {"id": "1006.1786", "submitter": "Diederik Aerts", "authors": "Diederik Aerts", "title": "Measuring Meaning on the World-Wide Web", "comments": "5 pages", "journal-ref": "In D. Aerts, J. Broekaert, B. D'Hooghe and N. Note (Eds.),\n  Worldviews, Science and Us: Bridging Knowledge and Its Implications for Our\n  Perspectives of the World. Singapore: World Scientific (2011)", "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the notion of the 'meaning bound' of a word with respect to\nanother word by making use of the World-Wide Web as a conceptual environment\nfor meaning. The meaning of a word with respect to another word is established\nby multiplying the product of the number of webpages containing both words by\nthe total number of webpages of the World-Wide Web, and dividing the result by\nthe product of the number of webpages for each of the single words. We\ncalculate the meaning bounds for several words and analyze different aspects of\nthese by looking at specific examples.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2010 12:24:54 GMT"}], "update_date": "2012-03-28", "authors_parsed": [["Aerts", "Diederik", ""]]}, {"id": "1006.1930", "submitter": "Diederik Aerts", "authors": "Diederik Aerts, Marek Czachor, Bart D'Hooghe and Sandro Sozzo", "title": "The Pet-Fish problem on the World-Wide Web", "comments": "8 pages", "journal-ref": "Proceedings of the AAAI Fall Symposium (FS-10-08), Quantum\n  Informatics for Cognitive, Social, and Semantic Processes, pp. 17-21, (2010)", "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify the presence of Pet-Fish problem situations and the corresponding\nGuppy effect of concept theory on the World-Wide Web. For this purpose, we\nintroduce absolute weights for words expressing concepts and relative weights\nbetween words expressing concepts, and the notion of 'meaning bound' between\ntwo words expressing concepts, making explicit use of the conceptual structure\nof the World-Wide Web. The Pet-Fish problem occurs whenever there are exemplars\n- in the case of Pet and Fish these can be Guppy or Goldfish - for which the\nmeaning bound with respect to the conjunction is stronger than the meaning\nbounds with respect to the individual concepts.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2010 00:39:33 GMT"}], "update_date": "2011-05-13", "authors_parsed": [["Aerts", "Diederik", ""], ["Czachor", "Marek", ""], ["D'Hooghe", "Bart", ""], ["Sozzo", "Sandro", ""]]}, {"id": "1006.2809", "submitter": "Jenny Blight", "authors": "A.A Zaidan, B.B Zaidan, Hamid.A.Jalab, Hamdan.O.Alanazi and Rami\n  Alnaqeib", "title": "Offline Arabic Handwriting Recognition Using Artificial Neural Network", "comments": "Submitted to Journal of Computer Science and Engineering, see\n  http://sites.google.com/site/jcseuk/volume-1-issue-1-may-2010", "journal-ref": "Journal of Computer Science and Engineering, Volume 1, Issue 1,\n  p55-58, May 2010", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ambition of a character recognition system is to transform a text\ndocument typed on paper into a digital format that can be manipulated by word\nprocessor software Unlike other languages, Arabic has unique features, while\nother language doesn't have, from this language these are seven or eight\nlanguage such as ordo, jewie and Persian writing, Arabic has twenty eight\nletters, each of which can be linked in three different ways or separated\ndepending on the case. The difficulty of the Arabic handwriting recognition is\nthat, the accuracy of the character recognition which affects on the accuracy\nof the word recognition, in additional there is also two or three from for each\ncharacter, the suggested solution by using artificial neural network can solve\nthe problem and overcome the difficulty of Arabic handwriting recognition.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2010 19:20:31 GMT"}], "update_date": "2010-06-15", "authors_parsed": [["Zaidan", "A. A", ""], ["Zaidan", "B. B", ""], ["Jalab", "Hamid. A.", ""], ["Alanazi", "Hamdan. O.", ""], ["Alnaqeib", "Rami", ""]]}, {"id": "1006.2835", "submitter": "Jenny Blight", "authors": "P. Venkata Subba Reddy", "title": "Fuzzy Modeling and Natural Language Processing for Panini's Sanskrit\n  Grammar", "comments": "Submitted to Journal of Computer Science and Engineering, see\n  http://sites.google.com/site/jcseuk/volume-1-issue-1-may-2010", "journal-ref": "Journal of Computer Science and Engineering, Volume 1, Issue 1,\n  p99-101, May 2010", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Indian languages have long history in World Natural languages. Panini was the\nfirst to define Grammar for Sanskrit language with about 4000 rules in fifth\ncentury. These rules contain uncertainty information. It is not possible to\nComputer processing of Sanskrit language with uncertain information. In this\npaper, fuzzy logic and fuzzy reasoning are proposed to deal to eliminate\nuncertain information for reasoning with Sanskrit grammar. The Sanskrit\nlanguage processing is also discussed in this paper.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2010 20:07:32 GMT"}], "update_date": "2010-06-16", "authors_parsed": [["Reddy", "P. Venkata Subba", ""]]}, {"id": "1006.3271", "submitter": "Paul Vitanyi", "authors": "Anne S. Hsu (Univ. College, University London), Nick Chater (Univ.\n  College, University London), Paul M.B. Vitanyi (CWI, Amsterdam)", "title": "The probabilistic analysis of language acquisition: Theoretical,\n  computational, and experimental analysis", "comments": "26 pages, pdf, 4 figures, Submitted to \"Cognition\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL physics.data-an q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is much debate over the degree to which language learning is governed\nby innate language-specific biases, or acquired through cognition-general\nprinciples. Here we examine the probabilistic language acquisition hypothesis\non three levels: We outline a novel theoretical result showing that it is\npossible to learn the exact generative model underlying a wide class of\nlanguages, purely from observing samples of the language. We then describe a\nrecently proposed practical framework, which quantifies natural language\nlearnability, allowing specific learnability predictions to be made for the\nfirst time. In previous work, this framework was used to make learnability\npredictions for a wide variety of linguistic constructions, for which\nlearnability has been much debated. Here, we present a new experiment which\ntests these learnability predictions. We find that our experimental results\nsupport the possibility that these linguistic constructions are acquired\nprobabilistically from cognition-general principles.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2010 16:48:30 GMT"}], "update_date": "2010-06-17", "authors_parsed": [["Hsu", "Anne S.", "", "Univ. College, University London"], ["Chater", "Nick", "", "Univ.\n  College, University London"], ["Vitanyi", "Paul M. B.", "", "CWI, Amsterdam"]]}, {"id": "1006.3787", "submitter": "Serguei Mokhov", "authors": "Serguei A. Mokhov", "title": "Complete Complementary Results Report of the MARF's NLP Approach to the\n  DEFT 2010 Competition", "comments": "550 pages; 683 tables; index; v6 adds some stats. NLP pipeline\n  results, reduces the page and table count by collapsing more tables together,\n  corrections to some references and text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This companion paper complements the main DEFT'10 article describing the MARF\napproach (arXiv:0905.1235) to the DEFT'10 NLP challenge (described at\nhttp://www.groupes.polymtl.ca/taln2010/deft.php in French). This paper is aimed\nto present the complete result sets of all the conducted experiments and their\nsettings in the resulting tables highlighting the approach and the best\nresults, but also showing the worse and the worst and their subsequent\nanalysis. This particular work focuses on application of the MARF's classical\nand NLP pipelines to identification tasks within various francophone corpora to\nidentify decades when certain articles were published for the first track\n(Piste 1) and place of origin of a publication (Piste 2), such as the journal\nand location (France vs. Quebec). This is the sixth iteration of the release of\nthe results.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2010 19:54:29 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2010 15:28:52 GMT"}, {"version": "v3", "created": "Mon, 28 Jun 2010 19:57:32 GMT"}, {"version": "v4", "created": "Thu, 1 Jul 2010 19:08:10 GMT"}, {"version": "v5", "created": "Sat, 10 Jul 2010 19:43:34 GMT"}, {"version": "v6", "created": "Sun, 18 Jul 2010 03:59:42 GMT"}, {"version": "v7", "created": "Sat, 19 Apr 2014 20:46:02 GMT"}], "update_date": "2014-04-22", "authors_parsed": [["Mokhov", "Serguei A.", ""]]}, {"id": "1006.5827", "submitter": "Sergio Guadarrama", "authors": "Sergio Guadarrama and Antonio Ruiz-Mayor", "title": "Approximate Robotic Mapping from sonar data by modeling Perceptions with\n  Antonyms", "comments": "To appear in Information Sciences", "journal-ref": null, "doi": null, "report-no": "FSC-2008-14", "categories": "cs.RO cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work, inspired by the idea of \"Computing with Words and Perceptions\"\nproposed by Zadeh in 2001, focuses on how to transform measurements into\nperceptions for the problem of map building by Autonomous Mobile Robots. We\npropose to model the perceptions obtained from sonar-sensors as two grid maps:\none for obstacles and another for empty spaces. The rules used to build and\nintegrate these maps are expressed by linguistic descriptions and modeled by\nfuzzy rules. The main difference of this approach from other studies reported\nin the literature is that the method presented here is based on the hypothesis\nthat the concepts \"occupied\" and \"empty\" are antonyms rather than complementary\n(as it happens in probabilistic approaches), or independent (as it happens in\nthe previous fuzzy models).\n  Controlled experimentation with a real robot in three representative indoor\nenvironments has been performed and the results presented. We offer a\nqualitative and quantitative comparison of the estimated maps obtained by the\nprobabilistic approach, the previous fuzzy method and the new antonyms-based\nfuzzy approach. It is shown that the maps obtained with the antonyms-based\napproach are better defined, capture better the shape of the walls and of the\nempty-spaces, and contain less errors due to rebounds and short-echoes.\nFurthermore, in spite of noise and low resolution inherent to the sonar-sensors\nused, the maps obtained are accurate and tolerant to imprecision.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2010 10:28:56 GMT"}], "update_date": "2010-07-01", "authors_parsed": [["Guadarrama", "Sergio", ""], ["Ruiz-Mayor", "Antonio", ""]]}, {"id": "1006.5880", "submitter": "Stergos Afantenos", "authors": "Stergos Afantenos and Nicholas Asher", "title": "Testing SDRT's Right Frontier", "comments": null, "journal-ref": "Proceedings of COLING 2010", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Right Frontier Constraint (RFC), as a constraint on the attachment of new\nconstituents to an existing discourse structure, has important implications for\nthe interpretation of anaphoric elements in discourse and for Machine Learning\n(ML) approaches to learning discourse structures. In this paper we provide\nstrong empirical support for SDRT's version of RFC. The analysis of about 100\ndoubly annotated documents by five different naive annotators shows that SDRT's\nRFC is respected about 95% of the time. The qualitative analysis of presumed\nviolations that we have performed shows that they are either click-errors or\nstructural misconceptions.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2010 15:10:33 GMT"}], "update_date": "2010-07-01", "authors_parsed": [["Afantenos", "Stergos", ""], ["Asher", "Nicholas", ""]]}]