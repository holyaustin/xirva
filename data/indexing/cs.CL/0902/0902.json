[{"id": "0902.0606", "submitter": "M. Angeles Serrano", "authors": "M. Angeles Serrano, Alessandro Flammini, and Filippo Menczer", "title": "Beyond Zipf's law: Modeling the structure of human language", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human language, the most powerful communication system in history, is closely\nassociated with cognition. Written text is one of the fundamental\nmanifestations of language, and the study of its universal regularities can\ngive clues about how our brains process information and how we, as a society,\norganize and share it. Still, only classical patterns such as Zipf's law have\nbeen explored in depth. In contrast, other basic properties like the existence\nof bursts of rare words in specific documents, the topical organization of\ncollections, or the sublinear growth of vocabulary size with the length of a\ndocument, have only been studied one by one and mainly applying heuristic\nmethodologies rather than basic principles and general mechanisms. As a\nconsequence, there is a lack of understanding of linguistic processes as\ncomplex emergent phenomena. Beyond Zipf's law for word frequencies, here we\nfocus on Heaps' law, burstiness, and the topicality of document collections,\nwhich encode correlations within and across documents absent in random null\nmodels. We introduce and validate a generative model that explains the\nsimultaneous emergence of all these patterns from simple rules. As a result, we\nfind a connection between the bursty nature of rare words and the topical\norganization of texts and identify dynamic word ranking and memory across\ndocuments as key mechanisms explaining the non trivial organization of written\ntext. Our research can have broad implications and practical applications in\ncomputer science, cognitive science, and linguistics.\n", "versions": [{"version": "v1", "created": "Tue, 3 Feb 2009 21:04:33 GMT"}], "update_date": "2009-02-05", "authors_parsed": [["Serrano", "M. Angeles", ""], ["Flammini", "Alessandro", ""], ["Menczer", "Filippo", ""]]}, {"id": "0902.1033", "submitter": "Sylvain Raybaud", "authors": "Sylvain Raybaud (INRIA Lorraine - LORIA), Caroline Lavecchia (INRIA\n  Lorraine - LORIA), David Langlois (INRIA Lorraine - LORIA), Kamel Sma\\\"ili\n  (INRIA Lorraine - LORIA)", "title": "New Confidence Measures for Statistical Machine Translation", "comments": null, "journal-ref": "International Conference On Agents and Artificial Intelligence -\n  ICAART 09 (2009)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A confidence measure is able to estimate the reliability of an hypothesis\nprovided by a machine translation system. The problem of confidence measure can\nbe seen as a process of testing : we want to decide whether the most probable\nsequence of words provided by the machine translation system is correct or not.\nIn the following we describe several original word-level confidence measures\nfor machine translation, based on mutual information, n-gram language model and\nlexical features language model. We evaluate how well they perform individually\nor together, and show that using a combination of confidence measures based on\nmutual information yields a classification error rate as low as 25.1% with an\nF-measure of 0.708.\n", "versions": [{"version": "v1", "created": "Fri, 6 Feb 2009 09:28:58 GMT"}], "update_date": "2009-02-09", "authors_parsed": [["Raybaud", "Sylvain", "", "INRIA Lorraine - LORIA"], ["Lavecchia", "Caroline", "", "INRIA\n  Lorraine - LORIA"], ["Langlois", "David", "", "INRIA Lorraine - LORIA"], ["Sma\u00efli", "Kamel", "", "INRIA Lorraine - LORIA"]]}, {"id": "0902.2230", "submitter": "Ama\\c{c} Herda\\u{g}delen", "authors": "Ama\\c{c} Herda\\u{g}delen and Marco Baroni", "title": "BagPack: A general framework to represent semantic relations", "comments": "Long paper presented at GEMS - Geometric Models of Natural Language\n  Semantics, workshop held in conjunction with the 12th Conference of the\n  European Chapter of the Association for Computational Linguistics (EACL-09),\n  Athens, Greece", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a way to represent word pairs instantiating arbitrary semantic\nrelations that keeps track of the contexts in which the words in the pair occur\nboth together and independently. The resulting features are of sufficient\ngenerality to allow us, with the help of a standard supervised machine learning\nalgorithm, to tackle a variety of unrelated semantic tasks with good results\nand almost no task-specific tailoring.\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2009 23:02:06 GMT"}], "update_date": "2009-02-16", "authors_parsed": [["Herda\u011fdelen", "Ama\u00e7", ""], ["Baroni", "Marco", ""]]}, {"id": "0902.2345", "submitter": "Stergos Afantenos", "authors": "Stergos D. Afantenos and Nicolas Hernandez", "title": "What's in a Message?", "comments": null, "journal-ref": "12th Conference of the European Chapter of the Association for\n  Computational Linguistics (EACL 2009), workshop on Cognitive Aspects of\n  Computational Language Acquisition. Athens, Greece", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the first step in a larger series of experiments for\nthe induction of predicate/argument structures. The structures that we are\ninducing are very similar to the conceptual structures that are used in Frame\nSemantics (such as FrameNet). Those structures are called messages and they\nwere previously used in the context of a multi-document summarization system of\nevolving events. The series of experiments that we are proposing are\nessentially composed from two stages. In the first stage we are trying to\nextract a representative vocabulary of words. This vocabulary is later used in\nthe second stage, during which we apply to it various clustering approaches in\norder to identify the clusters of predicates and arguments--or frames and\nsemantic roles, to use the jargon of Frame Semantics. This paper presents in\ndetail and evaluates the first stage.\n", "versions": [{"version": "v1", "created": "Fri, 13 Feb 2009 17:08:10 GMT"}], "update_date": "2009-02-16", "authors_parsed": [["Afantenos", "Stergos D.", ""], ["Hernandez", "Nicolas", ""]]}, {"id": "0902.3072", "submitter": "Eric Laporte", "authors": "Eric Laporte (IGM-LabInfo), Elisabete Ranchhod (ONSET-CEL), Anastasia\n  Yannacopoulou (IGM-LabInfo)", "title": "Syntactic variation of support verb constructions", "comments": null, "journal-ref": "Lingvisticae Investigationes 31, 2 (2008) 173-185", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report experiments about the syntactic variations of support verb\nconstructions, a special type of multiword expressions (MWEs) containing\npredicative nouns. In these expressions, the noun can occur with or without the\nverb, with no clear-cut semantic difference. We extracted from a large French\ncorpus a set of examples of the two situations and derived statistical results\nfrom these data. The extraction involved large-coverage language resources and\nfinite-state techniques. The results show that, most frequently, predicative\nnouns occur without a support verb. This fact has consequences on methods of\nextracting or recognising MWEs.\n", "versions": [{"version": "v1", "created": "Wed, 18 Feb 2009 08:51:28 GMT"}], "update_date": "2009-02-19", "authors_parsed": [["Laporte", "Eric", "", "IGM-LabInfo"], ["Ranchhod", "Elisabete", "", "ONSET-CEL"], ["Yannacopoulou", "Anastasia", "", "IGM-LabInfo"]]}, {"id": "0902.4060", "submitter": "Ken Yamamoto", "authors": "Ken Yamamoto, Yoshihiro Yamazaki", "title": "Network of two-Chinese-character compound words in Japanese language", "comments": null, "journal-ref": "Physica A 388, 2555-2560 (2009)", "doi": "10.1016/j.physa.2009.02.032", "report-no": null, "categories": "cs.CL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some statistical properties of a network of two-Chinese-character compound\nwords in Japanese language are reported. In this network, a node represents a\nChinese character and an edge represents a two-Chinese-character compound word.\nIt is found that this network has properties of \"small-world\" and \"scale-free.\"\nA network formed by only Chinese characters for common use ({\\it joyo-kanji} in\nJapanese), which is regarded as a subclass of the original network, also has\nsmall-world property. However, a degree distribution of the network exhibits no\nclear power law. In order to reproduce disappearance of the power-law property,\na model for a selecting process of the Chinese characters for common use is\nproposed.\n", "versions": [{"version": "v1", "created": "Tue, 24 Feb 2009 04:53:49 GMT"}], "update_date": "2012-05-15", "authors_parsed": [["Yamamoto", "Ken", ""], ["Yamazaki", "Yoshihiro", ""]]}]