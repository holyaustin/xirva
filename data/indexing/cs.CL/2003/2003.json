[{"id": "2003.00104", "submitter": "Wissam Antoun", "authors": "Wissam Antoun, Fady Baly, Hazem Hajj", "title": "AraBERT: Transformer-based Model for Arabic Language Understanding", "comments": "Proceedings of the Twelfth International Conference on Language\n  Resources and Evaluation (LREC 2020), Marseille, France (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Arabic language is a morphologically rich language with relatively few\nresources and a less explored syntax compared to English. Given these\nlimitations, Arabic Natural Language Processing (NLP) tasks like Sentiment\nAnalysis (SA), Named Entity Recognition (NER), and Question Answering (QA),\nhave proven to be very challenging to tackle. Recently, with the surge of\ntransformers based models, language-specific BERT based models have proven to\nbe very efficient at language understanding, provided they are pre-trained on a\nvery large corpus. Such models were able to set new standards and achieve\nstate-of-the-art results for most NLP tasks. In this paper, we pre-trained BERT\nspecifically for the Arabic language in the pursuit of achieving the same\nsuccess that BERT did for the English language. The performance of AraBERT is\ncompared to multilingual BERT from Google and other state-of-the-art\napproaches. The results showed that the newly developed AraBERT achieved\nstate-of-the-art performance on most tested Arabic NLP tasks. The pretrained\naraBERT models are publicly available on https://github.com/aub-mind/arabert\nhoping to encourage research and applications for Arabic NLP.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 22:59:24 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 12:34:28 GMT"}, {"version": "v3", "created": "Sun, 28 Jun 2020 10:16:04 GMT"}, {"version": "v4", "created": "Sun, 7 Mar 2021 13:37:01 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Antoun", "Wissam", ""], ["Baly", "Fady", ""], ["Hajj", "Hazem", ""]]}, {"id": "2003.00166", "submitter": "Yijin Liu", "authors": "Yijin Liu, Fandong Meng, Yufeng Chen, Jinan Xu and Jie Zhou", "title": "Depth-Adaptive Graph Recurrent Network for Text Classification", "comments": "Code at: https://github.com/Adaxry/Depth-Adaptive-GRN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Sentence-State LSTM (S-LSTM) is a powerful and high efficient graph\nrecurrent network, which views words as nodes and performs layer-wise recurrent\nsteps between them simultaneously. Despite its successes on text\nrepresentations, the S-LSTM still suffers from two drawbacks. Firstly, given a\nsentence, certain words are usually more ambiguous than others, and thus more\ncomputation steps need to be taken for these difficult words and vice versa.\nHowever, the S-LSTM takes fixed computation steps for all words, irrespective\nof their hardness. The secondary one comes from the lack of sequential\ninformation (e.g., word order) that is inherently important for natural\nlanguage. In this paper, we try to address these issues and propose a\ndepth-adaptive mechanism for the S-LSTM, which allows the model to learn how\nmany computational steps to conduct for different words as required. In\naddition, we integrate an extra RNN layer to inject sequential information,\nwhich also serves as an input feature for the decision of adaptive depths.\nResults on the classic text classification task (24 datasets in various sizes\nand domains) show that our model brings significant improvements against the\nconventional S-LSTM and other high-performance models (e.g., the Transformer),\nmeanwhile achieving a good accuracy-speed trade off.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 03:09:55 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Liu", "Yijin", ""], ["Meng", "Fandong", ""], ["Chen", "Yufeng", ""], ["Xu", "Jinan", ""], ["Zhou", "Jie", ""]]}, {"id": "2003.00201", "submitter": "Chaehan So", "authors": "Chaehan So", "title": "What Emotions Make One or Five Stars? Understanding Ratings of Online\n  Product Reviews by Sentiment Analysis and XAI", "comments": "To be published in: Lecture Notes in Artificial Intelligence, 1st\n  International Conference on Artificial Intelligence in HCI, AI-HCI, Held as\n  Part of HCI International 2020, Kopenhagen, Denmark, July 19-24, Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When people buy products online, they primarily base their decisions on the\nrecommendations of others given in online reviews. The current work analyzed\nthese online reviews by sentiment analysis and used the extracted sentiments as\nfeatures to predict the product ratings by several machine learning algorithms.\nThese predictions were disentangled by various meth-ods of explainable AI (XAI)\nto understand whether the model showed any bias during prediction. Study 1\nbenchmarked these algorithms (knn, support vector machines, random forests,\ngradient boosting machines, XGBoost) and identified random forests and XGBoost\nas best algorithms for predicting the product ratings. In Study 2, the analysis\nof global feature importance identified the sentiment joy and the emotional\nvalence negative as most predictive features. Two XAI visualization methods,\nlocal feature attributions and partial dependency plots, revealed several\nincorrect prediction mechanisms on the instance-level. Performing the\nbenchmarking as classification, Study 3 identified a high no-information rate\nof 64.4% that indicated high class imbalance as underlying reason for the\nidentified problems. In conclusion, good performance by machine learning\nalgorithms must be taken with caution because the dataset, as encountered in\nthis work, could be biased towards certain predictions. This work demonstrates\nhow XAI methods reveal such prediction bias.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 07:39:35 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["So", "Chaehan", ""]]}, {"id": "2003.00304", "submitter": "Woojay Jeon", "authors": "Woojay Jeon, Leo Liu, Henry Mason", "title": "Voice trigger detection from LVCSR hypothesis lattices using\n  bidirectional lattice recurrent neural networks", "comments": "Presented at IEEE ICASSP, May 2019", "journal-ref": "ICASSP 2019 - 2019 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP), Brighton, United Kingdom, 2019, pp.\n  6356-6360", "doi": "10.1109/ICASSP.2019.8682617", "report-no": null, "categories": "cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to reduce false voice triggers of a speech-enabled\npersonal assistant by post-processing the hypothesis lattice of a server-side\nlarge-vocabulary continuous speech recognizer (LVCSR) via a neural network. We\nfirst discuss how an estimate of the posterior probability of the trigger\nphrase can be obtained from the hypothesis lattice using known techniques to\nperform detection, then investigate a statistical model that processes the\nlattice in a more explicitly data-driven, discriminative manner. We propose\nusing a Bidirectional Lattice Recurrent Neural Network (LatticeRNN) for the\ntask, and show that it can significantly improve detection accuracy over using\nthe 1-best result or the posterior.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 17:02:41 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Jeon", "Woojay", ""], ["Liu", "Leo", ""], ["Mason", "Henry", ""]]}, {"id": "2003.00330", "submitter": "Luis Lamb", "authors": "Luis C. Lamb, Artur Garcez, Marco Gori, Marcelo Prates, Pedro Avelar,\n  Moshe Vardi", "title": "Graph Neural Networks Meet Neural-Symbolic Computing: A Survey and\n  Perspective", "comments": "Updated version, draft of accepted IJCAI2020 Survey Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural-symbolic computing has now become the subject of interest of both\nacademic and industry research laboratories. Graph Neural Networks (GNN) have\nbeen widely used in relational and symbolic domains, with widespread\napplication of GNNs in combinatorial optimization, constraint satisfaction,\nrelational reasoning and other scientific domains. The need for improved\nexplainability, interpretability and trust of AI systems in general demands\nprincipled methodologies, as suggested by neural-symbolic computing. In this\npaper, we review the state-of-the-art on the use of GNNs as a model of\nneural-symbolic computing. This includes the application of GNNs in several\ndomains as well as its relationship to current developments in neural-symbolic\ncomputing.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 18:55:13 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 20:00:26 GMT"}, {"version": "v3", "created": "Fri, 6 Mar 2020 12:14:42 GMT"}, {"version": "v4", "created": "Wed, 11 Mar 2020 20:33:01 GMT"}, {"version": "v5", "created": "Sat, 16 May 2020 20:44:26 GMT"}, {"version": "v6", "created": "Thu, 21 May 2020 17:11:36 GMT"}, {"version": "v7", "created": "Sat, 12 Jun 2021 23:05:33 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Lamb", "Luis C.", ""], ["Garcez", "Artur", ""], ["Gori", "Marco", ""], ["Prates", "Marcelo", ""], ["Avelar", "Pedro", ""], ["Vardi", "Moshe", ""]]}, {"id": "2003.00353", "submitter": "Wei-Hung Weng", "authors": "Wei-Hung Weng, Yu-An Chung, Schrasing Tong", "title": "Clinical Text Summarization with Syntax-Based Negation and Semantic\n  Concept Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of clinical information explosion, a good strategy for clinical\ntext summarization is helpful to improve the clinical workflow. The ideal\nsummarization strategy can preserve important information in the informative\nbut less organized, ill-structured clinical narrative texts. Instead of using\npure statistical learning approaches, which are difficult to interpret and\nexplain, we utilized knowledge of computational linguistics with human\nexperts-curated biomedical knowledge base to achieve the interpretable and\nmeaningful clinical text summarization. Our research objective is to use the\nbiomedical ontology with semantic information, and take the advantage from the\nlanguage hierarchical structure, the constituency tree, in order to identify\nthe correct clinical concepts and the corresponding negation information, which\nis critical for summarizing clinical concepts from narrative text. We achieved\nthe clinically acceptable performance for both negation detection and concept\nidentification, and the clinical concepts with common negated patterns can be\nidentified and negated by the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 22:15:15 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Weng", "Wei-Hung", ""], ["Chung", "Yu-An", ""], ["Tong", "Schrasing", ""]]}, {"id": "2003.00443", "submitter": "Xin Eric Wang", "authors": "Xin Eric Wang, Vihan Jain, Eugene Ie, William Yang Wang, Zornitsa\n  Kozareva, Sujith Ravi", "title": "Environment-agnostic Multitask Learning for Natural Language Grounded\n  Navigation", "comments": "ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent research efforts enable study for natural language grounded navigation\nin photo-realistic environments, e.g., following natural language instructions\nor dialog. However, existing methods tend to overfit training data in seen\nenvironments and fail to generalize well in previously unseen environments. To\nclose the gap between seen and unseen environments, we aim at learning a\ngeneralized navigation model from two novel perspectives: (1) we introduce a\nmultitask navigation model that can be seamlessly trained on both\nVision-Language Navigation (VLN) and Navigation from Dialog History (NDH)\ntasks, which benefits from richer natural language guidance and effectively\ntransfers knowledge across tasks; (2) we propose to learn environment-agnostic\nrepresentations for the navigation policy that are invariant among the\nenvironments seen during training, thus generalizing better on unseen\nenvironments. Extensive experiments show that environment-agnostic multitask\nlearning significantly reduces the performance gap between seen and unseen\nenvironments, and the navigation agent trained so outperforms baselines on\nunseen environments by 16% (relative measure on success rate) on VLN and 120%\n(goal progress) on NDH. Our submission to the CVDN leaderboard establishes a\nnew state-of-the-art for the NDH task on the holdout test set. Code is\navailable at https://github.com/google-research/valan.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 09:06:31 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 22:06:54 GMT"}, {"version": "v3", "created": "Thu, 12 Mar 2020 18:20:39 GMT"}, {"version": "v4", "created": "Fri, 17 Jul 2020 23:54:02 GMT"}, {"version": "v5", "created": "Tue, 21 Jul 2020 02:54:38 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Wang", "Xin Eric", ""], ["Jain", "Vihan", ""], ["Ie", "Eugene", ""], ["Wang", "William Yang", ""], ["Kozareva", "Zornitsa", ""], ["Ravi", "Sujith", ""]]}, {"id": "2003.00576", "submitter": "Vidhisha Balachandran", "authors": "Vidhisha Balachandran, Artidoro Pagnoni, Jay Yoon Lee, Dheeraj\n  Rajagopal, Jaime Carbonell, Yulia Tsvetkov", "title": "StructSum: Summarization via Structured Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstractive text summarization aims at compressing the information of a long\nsource document into a rephrased, condensed summary. Despite advances in\nmodeling techniques, abstractive summarization models still suffer from several\nkey challenges: (i) layout bias: they overfit to the style of training corpora;\n(ii) limited abstractiveness: they are optimized to copying n-grams from the\nsource rather than generating novel abstractive summaries; (iii) lack of\ntransparency: they are not interpretable. In this work, we propose a framework\nbased on document-level structure induction for summarization to address these\nchallenges. To this end, we propose incorporating latent and explicit\ndependencies across sentences in the source document into end-to-end\nsingle-document summarization models. Our framework complements standard\nencoder-decoder summarization models by augmenting them with rich\nstructure-aware document representations based on implicitly learned (latent)\nstructures and externally-derived linguistic (explicit) structures. We show\nthat our summarization framework, trained on the CNN/DM dataset, improves the\ncoverage of content in the source documents, generates more abstractive\nsummaries by generating more novel n-grams, and incorporates interpretable\nsentence-level structures, while performing on par with standard baselines.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 20:32:51 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 18:59:36 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Balachandran", "Vidhisha", ""], ["Pagnoni", "Artidoro", ""], ["Lee", "Jay Yoon", ""], ["Rajagopal", "Dheeraj", ""], ["Carbonell", "Jaime", ""], ["Tsvetkov", "Yulia", ""]]}, {"id": "2003.00639", "submitter": "Hengyi Cai", "authors": "Hengyi Cai, Hongshen Chen, Cheng Zhang, Yonghao Song, Xiaofang Zhao,\n  Yangxi Li, Dongsheng Duan, Dawei Yin", "title": "Learning from Easy to Complex: Adaptive Multi-curricula Learning for\n  Neural Dialogue Generation", "comments": "Accepted to AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current state-of-the-art neural dialogue systems are mainly data-driven and\nare trained on human-generated responses. However, due to the subjectivity and\nopen-ended nature of human conversations, the complexity of training dialogues\nvaries greatly. The noise and uneven complexity of query-response pairs impede\nthe learning efficiency and effects of the neural dialogue generation models.\nWhat is more, so far, there are no unified dialogue complexity measurements,\nand the dialogue complexity embodies multiple aspects of\nattributes---specificity, repetitiveness, relevance, etc. Inspired by human\nbehaviors of learning to converse, where children learn from easy dialogues to\ncomplex ones and dynamically adjust their learning progress, in this paper, we\nfirst analyze five dialogue attributes to measure the dialogue complexity in\nmultiple perspectives on three publicly available corpora. Then, we propose an\nadaptive multi-curricula learning framework to schedule a committee of the\norganized curricula. The framework is established upon the reinforcement\nlearning paradigm, which automatically chooses different curricula at the\nevolving learning process according to the learning status of the neural\ndialogue generation model. Extensive experiments conducted on five\nstate-of-the-art models demonstrate its learning efficiency and effectiveness\nwith respect to 13 automatic evaluation metrics and human judgments.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 03:09:28 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 16:54:14 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Cai", "Hengyi", ""], ["Chen", "Hongshen", ""], ["Zhang", "Cheng", ""], ["Song", "Yonghao", ""], ["Zhao", "Xiaofang", ""], ["Li", "Yangxi", ""], ["Duan", "Dongsheng", ""], ["Yin", "Dawei", ""]]}, {"id": "2003.00674", "submitter": "Mohammad Shoeybi", "authors": "Kuo-Hao Zeng and Mohammad Shoeybi and Ming-Yu Liu", "title": "Style Example-Guided Text Generation using Generative Adversarial\n  Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a language generative model framework for generating a styled\nparagraph based on a context sentence and a style reference example. The\nframework consists of a style encoder and a texts decoder. The style encoder\nextracts a style code from the reference example, and the text decoder\ngenerates texts based on the style code and the context. We propose a novel\nobjective function to train our framework. We also investigate different\nnetwork design choices. We conduct extensive experimental validation with\ncomparison to strong baselines to validate the effectiveness of the proposed\nframework using a newly collected dataset with diverse text styles. Both code\nand dataset will be released upon publication.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 05:40:57 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Zeng", "Kuo-Hao", ""], ["Shoeybi", "Mohammad", ""], ["Liu", "Ming-Yu", ""]]}, {"id": "2003.00739", "submitter": "Liang Jiang", "authors": "Liang Jiang, Zujie Wen, Zhongping Liang, Yafang Wang, Gerard de Melo,\n  Zhe Li, Liangzhuang Ma, Jiaxing Zhang, Xiaolong Li, Yuan Qi", "title": "Long Short-Term Sample Distillation", "comments": "published as a conference paper at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decade, there has been substantial progress at training\nincreasingly deep neural networks. Recent advances within the teacher--student\ntraining paradigm have established that information about past training updates\nshow promise as a source of guidance during subsequent training steps. Based on\nthis notion, in this paper, we propose Long Short-Term Sample Distillation, a\nnovel training policy that simultaneously leverages multiple phases of the\nprevious training process to guide the later training updates to a neural\nnetwork, while efficiently proceeding in just one single generation pass. With\nLong Short-Term Sample Distillation, the supervision signal for each sample is\ndecomposed into two parts: a long-term signal and a short-term one. The\nlong-term teacher draws on snapshots from several epochs ago in order to\nprovide steadfast guidance and to guarantee teacher--student differences, while\nthe short-term one yields more up-to-date cues with the goal of enabling\nhigher-quality updates. Moreover, the teachers for each sample are unique, such\nthat, overall, the model learns from a very diverse set of teachers.\nComprehensive experimental results across a range of vision and NLP tasks\ndemonstrate the effectiveness of this new training method.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 10:03:14 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Jiang", "Liang", ""], ["Wen", "Zujie", ""], ["Liang", "Zhongping", ""], ["Wang", "Yafang", ""], ["de Melo", "Gerard", ""], ["Li", "Zhe", ""], ["Ma", "Liangzhuang", ""], ["Zhang", "Jiaxing", ""], ["Li", "Xiaolong", ""], ["Qi", "Yuan", ""]]}, {"id": "2003.00744", "submitter": "Dat Quoc Nguyen", "authors": "Dat Quoc Nguyen and Anh Tuan Nguyen", "title": "PhoBERT: Pre-trained language models for Vietnamese", "comments": "EMNLP 2020 (Findings)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present PhoBERT with two versions, PhoBERT-base and PhoBERT-large, the\nfirst public large-scale monolingual language models pre-trained for\nVietnamese. Experimental results show that PhoBERT consistently outperforms the\nrecent best pre-trained multilingual model XLM-R (Conneau et al., 2020) and\nimproves the state-of-the-art in multiple Vietnamese-specific NLP tasks\nincluding Part-of-speech tagging, Dependency parsing, Named-entity recognition\nand Natural language inference. We release PhoBERT to facilitate future\nresearch and downstream applications for Vietnamese NLP. Our PhoBERT models are\navailable at https://github.com/VinAIResearch/PhoBERT\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 10:21:17 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 17:36:29 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 09:53:19 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Nguyen", "Dat Quoc", ""], ["Nguyen", "Anh Tuan", ""]]}, {"id": "2003.00857", "submitter": "Qiaolin Xia", "authors": "Qiaolin Xia, Xiujun Li, Chunyuan Li, Yonatan Bisk, Zhifang Sui,\n  Jianfeng Gao, Yejin Choi, Noah A. Smith", "title": "Multi-View Learning for Vision-and-Language Navigation", "comments": "16 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to navigate in a visual environment following natural language\ninstructions is a challenging task because natural language instructions are\nhighly variable, ambiguous, and under-specified. In this paper, we present a\nnovel training paradigm, Learn from EveryOne (LEO), which leverages multiple\ninstructions (as different views) for the same trajectory to resolve language\nambiguity and improve generalization. By sharing parameters across\ninstructions, our approach learns more effectively from limited training data\nand generalizes better in unseen environments. On the recent Room-to-Room (R2R)\nbenchmark dataset, LEO achieves 16% improvement (absolute) over a greedy agent\nas the base agent (25.3% $\\rightarrow$ 41.4%) in Success Rate weighted by Path\nLength (SPL). Further, LEO is complementary to most existing models for\nvision-and-language navigation, allowing for easy integration with the existing\ntechniques, leading to LEO+, which creates the new state of the art, pushing\nthe R2R benchmark to 62% (9% absolute improvement).\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 13:07:46 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 02:21:21 GMT"}, {"version": "v3", "created": "Mon, 9 Mar 2020 21:15:55 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Xia", "Qiaolin", ""], ["Li", "Xiujun", ""], ["Li", "Chunyuan", ""], ["Bisk", "Yonatan", ""], ["Sui", "Zhifang", ""], ["Gao", "Jianfeng", ""], ["Choi", "Yejin", ""], ["Smith", "Noah A.", ""]]}, {"id": "2003.00864", "submitter": "Francisco Sep\\'ulveda Teixeira", "authors": "Catarina Botelho, Francisco Teixeira, Thomas Rolland, Alberto Abad,\n  Isabel Trancoso", "title": "Pathological speech detection using x-vector embeddings", "comments": "Rejected for publication by peer review", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The potential of speech as a non-invasive biomarker to assess a speaker's\nhealth has been repeatedly supported by the results of multiple works, for both\nphysical and psychological conditions. Traditional systems for speech-based\ndisease classification have focused on carefully designed knowledge-based\nfeatures. However, these features may not represent the disease's full\nsymptomatology, and may even overlook its more subtle manifestations. This has\nprompted researchers to move in the direction of general speaker\nrepresentations that inherently model symptoms, such as Gaussian Supervectors,\ni-vectors and, x-vectors. In this work, we focus on the latter, to assess their\napplicability as a general feature extraction method to the detection of\nParkinson's disease (PD) and obstructive sleep apnea (OSA). We test our\napproach against knowledge-based features and i-vectors, and report results for\ntwo European Portuguese corpora, for OSA and PD, as well as for an additional\nSpanish corpus for PD. Both x-vector and i-vector models were trained with an\nout-of-domain European Portuguese corpus. Our results show that x-vectors are\nable to perform better than knowledge-based features in same-language corpora.\nMoreover, while x-vectors performed similarly to i-vectors in matched\nconditions, they significantly outperform them when domain-mismatch occurs.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 13:10:18 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 16:38:15 GMT"}, {"version": "v3", "created": "Sun, 31 May 2020 14:31:31 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Botelho", "Catarina", ""], ["Teixeira", "Francisco", ""], ["Rolland", "Thomas", ""], ["Abad", "Alberto", ""], ["Trancoso", "Isabel", ""]]}, {"id": "2003.01006", "submitter": "Jennifer D'Souza", "authors": "Jennifer D'Souza, Anett Hoppe, Arthur Brack, Mohamad Yaser Jaradeh,\n  S\\\"oren Auer, Ralph Ewerth", "title": "The STEM-ECR Dataset: Grounding Scientific Entity References in STEM\n  Scholarly Content to Authoritative Encyclopedic and Lexicographic Sources", "comments": "Published in LREC 2020. Publication URL\n  https://www.aclweb.org/anthology/2020.lrec-1.268/; Dataset DOI\n  https://doi.org/10.25835/0017546", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the STEM (Science, Technology, Engineering, and Medicine)\nDataset for Scientific Entity Extraction, Classification, and Resolution,\nversion 1.0 (STEM-ECR v1.0). The STEM-ECR v1.0 dataset has been developed to\nprovide a benchmark for the evaluation of scientific entity extraction,\nclassification, and resolution tasks in a domain-independent fashion. It\ncomprises abstracts in 10 STEM disciplines that were found to be the most\nprolific ones on a major publishing platform. We describe the creation of such\na multidisciplinary corpus and highlight the obtained findings in terms of the\nfollowing features: 1) a generic conceptual formalism for scientific entities\nin a multidisciplinary scientific context; 2) the feasibility of the\ndomain-independent human annotation of scientific entities under such a generic\nformalism; 3) a performance benchmark obtainable for automatic extraction of\nmultidisciplinary scientific entities using BERT-based neural models; 4) a\ndelineated 3-step entity resolution procedure for human annotation of the\nscientific entities via encyclopedic entity linking and lexicographic word\nsense disambiguation; and 5) human evaluations of Babelfy returned encyclopedic\nlinks and lexicographic senses for our entities. Our findings cumulatively\nindicate that human annotation and automatic learning of multidisciplinary\nscientific concepts as well as their semantic disambiguation in a wide-ranging\nsetting as STEM is reasonable.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 16:35:17 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 11:38:40 GMT"}, {"version": "v3", "created": "Fri, 6 Mar 2020 08:58:48 GMT"}, {"version": "v4", "created": "Tue, 28 Jul 2020 09:45:52 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["D'Souza", "Jennifer", ""], ["Hoppe", "Anett", ""], ["Brack", "Arthur", ""], ["Jaradeh", "Mohamad Yaser", ""], ["Auer", "S\u00f6ren", ""], ["Ewerth", "Ralph", ""]]}, {"id": "2003.01018", "submitter": "Rachid Riad", "authors": "Rachid Riad, Anne-Catherine Bachoud-L\\'evi, Frank Rudzicz, Emmanuel\n  Dupoux", "title": "Identification of primary and collateral tracks in stuttered speech", "comments": "To be published in LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Disfluent speech has been previously addressed from two main perspectives:\nthe clinical perspective focusing on diagnostic, and the Natural Language\nProcessing (NLP) perspective aiming at modeling these events and detect them\nfor downstream tasks. In addition, previous works often used different metrics\ndepending on whether the input features are text or speech, making it difficult\nto compare the different contributions. Here, we introduce a new evaluation\nframework for disfluency detection inspired by the clinical and NLP perspective\ntogether with the theory of performance from \\cite{clark1996using} which\ndistinguishes between primary and collateral tracks. We introduce a novel\nforced-aligned disfluency dataset from a corpus of semi-directed interviews,\nand present baseline results directly comparing the performance of text-based\nfeatures (word and span information) and speech-based (acoustic-prosodic\ninformation). Finally, we introduce new audio features inspired by the\nword-based span features. We show experimentally that using these features\noutperformed the baselines for speech-based predictions on the present dataset.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 16:50:33 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Riad", "Rachid", ""], ["Bachoud-L\u00e9vi", "Anne-Catherine", ""], ["Rudzicz", "Frank", ""], ["Dupoux", "Emmanuel", ""]]}, {"id": "2003.01043", "submitter": "Ayush Kumar", "authors": "Ayush Kumar, Jithendra Vepa", "title": "Gated Mechanism for Attention Based Multimodal Sentiment Analysis", "comments": "Accepted to appear in ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal sentiment analysis has recently gained popularity because of its\nrelevance to social media posts, customer service calls and video blogs. In\nthis paper, we address three aspects of multimodal sentiment analysis; 1. Cross\nmodal interaction learning, i.e. how multiple modalities contribute to the\nsentiment, 2. Learning long-term dependencies in multimodal interactions and 3.\nFusion of unimodal and cross modal cues. Out of these three, we find that\nlearning cross modal interactions is beneficial for this problem. We perform\nexperiments on two benchmark datasets, CMU Multimodal Opinion level Sentiment\nIntensity (CMU-MOSI) and CMU Multimodal Opinion Sentiment and Emotion Intensity\n(CMU-MOSEI) corpus. Our approach on both these tasks yields accuracies of 83.9%\nand 81.1% respectively, which is 1.6% and 1.34% absolute improvement over\ncurrent state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 06:58:03 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Kumar", "Ayush", ""], ["Vepa", "Jithendra", ""]]}, {"id": "2003.01200", "submitter": "Nader Tavaf", "authors": "Amirsina Torfi, Rouzbeh A. Shirvani, Yaser Keneshloo, Nader Tavaf,\n  Edward A. Fox", "title": "Natural Language Processing Advancements By Deep Learning: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Natural Language Processing (NLP) helps empower intelligent machines by\nenhancing a better understanding of the human language for linguistic-based\nhuman-computer communication. Recent developments in computational power and\nthe advent of large amounts of linguistic data have heightened the need and\ndemand for automating semantic analysis using data-driven approaches. The\nutilization of data-driven strategies is pervasive now due to the significant\nimprovements demonstrated through the usage of deep learning methods in areas\nsuch as Computer Vision, Automatic Speech Recognition, and in particular, NLP.\nThis survey categorizes and addresses the different aspects and applications of\nNLP that have benefited from deep learning. It covers core NLP tasks and\napplications and describes how deep learning methods and models advance these\nareas. We further analyze and compare different approaches and state-of-the-art\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 21:32:05 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 19:15:30 GMT"}, {"version": "v3", "created": "Sat, 27 Jun 2020 16:58:54 GMT"}, {"version": "v4", "created": "Sat, 27 Feb 2021 14:02:09 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Torfi", "Amirsina", ""], ["Shirvani", "Rouzbeh A.", ""], ["Keneshloo", "Yaser", ""], ["Tavaf", "Nader", ""], ["Fox", "Edward A.", ""]]}, {"id": "2003.01271", "submitter": "Andrey Kormilitzin", "authors": "Andrey Kormilitzin, Nemanja Vaci, Qiang Liu, Alejo Nevado-Holgado", "title": "Med7: a transferable clinical natural language processing model for\n  electronic health records", "comments": "16 pages, 1 figure, 15 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of clinical natural language processing has been advanced\nsignificantly since the introduction of deep learning models. The\nself-supervised representation learning and the transfer learning paradigm\nbecame the methods of choice in many natural language processing application,\nin particular in the settings with the dearth of high quality manually\nannotated data. Electronic health record systems are ubiquitous and the\nmajority of patients' data are now being collected electronically and in\nparticular in the form of free text. Identification of medical concepts and\ninformation extraction is a challenging task, yet important ingredient for\nparsing unstructured data into structured and tabulated format for downstream\nanalytical tasks. In this work we introduced a named-entity recognition model\nfor clinical natural language processing. The model is trained to recognise\nseven categories: drug names, route, frequency, dosage, strength, form,\nduration. The model was first self-supervisedly pre-trained by predicting the\nnext word, using a collection of 2 million free-text patients' records from\nMIMIC-III corpora and then fine-tuned on the named-entity recognition task. The\nmodel achieved a lenient (strict) micro-averaged F1 score of 0.957 (0.893)\nacross all seven categories. Additionally, we evaluated the transferability of\nthe developed model using the data from the Intensive Care Unit in the US to\nsecondary care mental health records (CRIS) in the UK. A direct application of\nthe trained NER model to CRIS data resulted in reduced performance of F1=0.762,\nhowever after fine-tuning on a small sample from CRIS, the model achieved a\nreasonable performance of F1=0.944. This demonstrated that despite a close\nsimilarity between the data sets and the NER tasks, it is essential to\nfine-tune on the target domain data in order to achieve more accurate results.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 00:55:43 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 13:16:15 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Kormilitzin", "Andrey", ""], ["Vaci", "Nemanja", ""], ["Liu", "Qiang", ""], ["Nevado-Holgado", "Alejo", ""]]}, {"id": "2003.01305", "submitter": "Qian Chen", "authors": "Qian Chen, Zhu Zhuo, Wen Wang, Qiuyun Xu", "title": "Transfer Learning for Context-Aware Spoken Language Understanding", "comments": "6 pages, 3 figures, ASRU2019", "journal-ref": "2019 IEEE Automatic Speech Recognition and Understanding Workshop\n  (ASRU), SG, Singapore, 2019, pp. 779-786", "doi": "10.1109/ASRU46091.2019.9003902", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken language understanding (SLU) is a key component of task-oriented\ndialogue systems. SLU parses natural language user utterances into semantic\nframes. Previous work has shown that incorporating context information\nsignificantly improves SLU performance for multi-turn dialogues. However,\ncollecting a large-scale human-labeled multi-turn dialogue corpus for the\ntarget domains is complex and costly. To reduce dependency on the collection\nand annotation effort, we propose a Context Encoding Language Transformer\n(CELT) model facilitating exploiting various context information for SLU. We\nexplore different transfer learning approaches to reduce dependency on data\ncollection and annotation. In addition to unsupervised pre-training using\nlarge-scale general purpose unlabeled corpora, such as Wikipedia, we explore\nunsupervised and supervised adaptive training approaches for transfer learning\nto benefit from other in-domain and out-of-domain dialogue corpora.\nExperimental results demonstrate that the proposed model with the proposed\ntransfer learning approaches achieves significant improvement on the SLU\nperformance over state-of-the-art models on two large-scale single-turn\ndialogue benchmarks and one large-scale multi-turn dialogue benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 02:56:36 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Chen", "Qian", ""], ["Zhuo", "Zhu", ""], ["Wang", "Wen", ""], ["Xu", "Qiuyun", ""]]}, {"id": "2003.01309", "submitter": "Qian Chen", "authors": "Qian Chen, Mengzhe Chen, Bo Li, Wen Wang", "title": "Controllable Time-Delay Transformer for Real-Time Punctuation Prediction\n  and Disfluency Detection", "comments": "4 pages, 2 figures, accepted by ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increased applications of automatic speech recognition (ASR) in\nrecent years, it is essential to automatically insert punctuation marks and\nremove disfluencies in transcripts, to improve the readability of the\ntranscripts as well as the performance of subsequent applications, such as\nmachine translation, dialogue systems, and so forth. In this paper, we propose\na Controllable Time-delay Transformer (CT-Transformer) model that jointly\ncompletes the punctuation prediction and disfluency detection tasks in real\ntime. The CT-Transformer model facilitates freezing partial outputs with\ncontrollable time delay to fulfill the real-time constraints in partial\ndecoding required by subsequent applications. We further propose a fast\ndecoding strategy to minimize latency while maintaining competitive\nperformance. Experimental results on the IWSLT2011 benchmark dataset and an\nin-house Chinese annotated dataset demonstrate that the proposed approach\noutperforms the previous state-of-the-art models on F-scores and achieves a\ncompetitive inference speed.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 03:17:29 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Chen", "Qian", ""], ["Chen", "Mengzhe", ""], ["Li", "Bo", ""], ["Wang", "Wen", ""]]}, {"id": "2003.01338", "submitter": "Guang Liu", "authors": "Jingyuan Yang, Guang Liu, Yuzhao Mao, Zhiwei Zhao, Weiguo Gao, Xuan\n  Li, Haiqin Yang, Jianping Shen", "title": "Hierarchical Context Enhanced Multi-Domain Dialogue System for\n  Multi-domain Task Completion", "comments": "Presented at DSTC workshop, AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task 1 of the DSTC8-track1 challenge aims to develop an end-to-end\nmulti-domain dialogue system to accomplish complex users' goals under tourist\ninformation desk settings. This paper describes our submitted solution,\nHierarchical Context Enhanced Dialogue System (HCEDS), for this task. The main\nmotivation of our system is to comprehensively explore the potential of\nhierarchical context for sufficiently understanding complex dialogues. More\nspecifically, we apply BERT to capture token-level information and employ the\nattention mechanism to capture sentence-level information. The results listed\nin the leaderboard show that our system achieves first place in automatic\nevaluation and the second place in human evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 05:10:13 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Yang", "Jingyuan", ""], ["Liu", "Guang", ""], ["Mao", "Yuzhao", ""], ["Zhao", "Zhiwei", ""], ["Gao", "Weiguo", ""], ["Li", "Xuan", ""], ["Yang", "Haiqin", ""], ["Shen", "Jianping", ""]]}, {"id": "2003.01343", "submitter": "Shuyan Zhou", "authors": "Shuyan Zhou and Shruti Rijhwani and John Wieting and Jaime Carbonell\n  and Graham Neubig", "title": "Improving Candidate Generation for Low-resource Cross-lingual Entity\n  Linking", "comments": "Accepted to TACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual entity linking (XEL) is the task of finding referents in a\ntarget-language knowledge base (KB) for mentions extracted from source-language\ntexts. The first step of (X)EL is candidate generation, which retrieves a list\nof plausible candidate entities from the target-language KB for each mention.\nApproaches based on resources from Wikipedia have proven successful in the\nrealm of relatively high-resource languages (HRL), but these do not extend well\nto low-resource languages (LRL) with few, if any, Wikipedia pages. Recently,\ntransfer learning methods have been shown to reduce the demand for resources in\nthe LRL by utilizing resources in closely-related languages, but the\nperformance still lags far behind their high-resource counterparts. In this\npaper, we first assess the problems faced by current entity candidate\ngeneration methods for low-resource XEL, then propose three improvements that\n(1) reduce the disconnect between entity mentions and KB entries, and (2)\nimprove the robustness of the model to low-resource scenarios. The methods are\nsimple, but effective: we experiment with our approach on seven XEL datasets\nand find that they yield an average gain of 16.9% in Top-30 gold candidate\nrecall, compared to state-of-the-art baselines. Our improved model also yields\nan average gain of 7.9% in in-KB accuracy of end-to-end XEL.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 05:32:09 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Zhou", "Shuyan", ""], ["Rijhwani", "Shruti", ""], ["Wieting", "John", ""], ["Carbonell", "Jaime", ""], ["Neubig", "Graham", ""]]}, {"id": "2003.01345", "submitter": "Muhammad Nabeel Asim", "authors": "Muhammad Nabeel Asim, Muhammad Usman Ghani, Muhammad Ali Ibrahim,\n  Sheraz Ahmad, Waqar Mahmood, Andreas Dengel", "title": "Benchmark Performance of Machine And Deep Learning Based Methodologies\n  for Urdu Text Document Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In order to provide benchmark performance for Urdu text document\nclassification, the contribution of this paper is manifold. First, it pro-vides\na publicly available benchmark dataset manually tagged against 6 classes.\nSecond, it investigates the performance impact of traditional machine learning\nbased Urdu text document classification methodologies by embedding 10\nfilter-based feature selection algorithms which have been widely used for other\nlanguages. Third, for the very first time, it as-sesses the performance of\nvarious deep learning based methodologies for Urdu text document\nclassification. In this regard, for experimentation, we adapt 10 deep learning\nclassification methodologies which have pro-duced best performance figures for\nEnglish text classification. Fourth, it also investigates the performance\nimpact of transfer learning by utiliz-ing Bidirectional Encoder Representations\nfrom Transformers approach for Urdu language. Fifth, it evaluates the integrity\nof a hybrid approach which combines traditional machine learning based feature\nengineering and deep learning based automated feature engineering. Experimental\nresults show that feature selection approach named as Normalised Dif-ference\nMeasure along with Support Vector Machine outshines state-of-the-art\nperformance on two closed source benchmark datasets CLE Urdu Digest 1000k, and\nCLE Urdu Digest 1Million with a significant margin of 32%, and 13%\nrespectively. Across all three datasets, Normalised Differ-ence Measure\noutperforms other filter based feature selection algorithms as it significantly\nuplifts the performance of all adopted machine learning, deep learning, and\nhybrid approaches. The source code and presented dataset are available at\nGithub repository.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 05:49:55 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Asim", "Muhammad Nabeel", ""], ["Ghani", "Muhammad Usman", ""], ["Ibrahim", "Muhammad Ali", ""], ["Ahmad", "Sheraz", ""], ["Mahmood", "Waqar", ""], ["Dengel", "Andreas", ""]]}, {"id": "2003.01355", "submitter": "Liang  Xu", "authors": "Liang Xu, Xuanwei Zhang, Qianqian Dong", "title": "CLUECorpus2020: A Large-scale Chinese Corpus for Pre-training Language\n  Model", "comments": "8 pages, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we introduce the Chinese corpus from CLUE organization,\nCLUECorpus2020, a large-scale corpus that can be used directly for\nself-supervised learning such as pre-training of a language model, or language\ngeneration. It has 100G raw corpus with 35 billion Chinese characters, which is\nretrieved from Common Crawl. To better understand this corpus, we conduct\nlanguage understanding experiments on both small and large scale, and results\nshow that the models trained on this corpus can achieve excellent performance\non Chinese. We release a new Chinese vocabulary with a size of 8K, which is\nonly one-third of the vocabulary size used in Chinese Bert released by Google.\nIt saves computational cost and memory while works as good as original\nvocabulary. We also release both large and tiny versions of the pre-trained\nmodel on this corpus. The former achieves the state-of-the-art result, and the\nlatter retains most precision while accelerating training and prediction speed\nfor eight times compared to Bert-base. To facilitate future work on\nself-supervised learning on Chinese, we release our dataset, new vocabulary,\ncodes, and pre-trained models on Github.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 06:39:27 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 03:20:33 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Xu", "Liang", ""], ["Zhang", "Xuanwei", ""], ["Dong", "Qianqian", ""]]}, {"id": "2003.01371", "submitter": "Qichen Li", "authors": "Qichen Li, Yuanqing Lin, Luofeng Zhou, Jian Li", "title": "Meta-Embeddings Based On Self-Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating meta-embeddings for better performance in language modelling has\nreceived attention lately, and methods based on concatenation or merely\ncalculating the arithmetic mean of more than one separately trained embeddings\nto perform meta-embeddings have shown to be beneficial. In this paper, we\ndevise a new meta-embedding model based on the self-attention mechanism, namely\nthe Duo. With less than 0.4M parameters, the Duo mechanism achieves\nstate-of-the-art accuracy in text classification tasks such as 20NG.\nAdditionally, we propose a new meta-embedding sequece-to-sequence model for\nmachine translation, which to the best of our knowledge, is the first machine\ntranslation model based on more than one word-embedding. Furthermore, it has\nturned out that our model outperform the Transformer not only in terms of\nachieving a better result, but also a faster convergence on recognized\nbenchmarks, such as the WMT 2014 English-to-French translation task.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 07:34:24 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 05:31:58 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 07:00:30 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Li", "Qichen", ""], ["Lin", "Yuanqing", ""], ["Zhou", "Luofeng", ""], ["Li", "Jian", ""]]}, {"id": "2003.01425", "submitter": "Chaehan So", "authors": "Chaehan So", "title": "Understanding the Prediction Mechanism of Sentiments by XAI\n  Visualization", "comments": "This is the author's prefinal version be published in conference\n  proceedings: 4th International Conference on Natural Language Processing and\n  Information Retrieval, Sejong, South Korea, 26-28 June, 2020, ACM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People often rely on online reviews to make purchase decisions. The present\nwork aimed to gain an understanding of a machine learning model's prediction\nmechanism by visualizing the effect of sentiments extracted from online hotel\nreviews with explainable AI (XAI) methodology. Study 1 used the extracted\nsentiments as features to predict the review ratings by five machine learning\nalgorithms (knn, CART decision trees, support vector machines, random forests,\ngradient boosting machines) and identified random forests as best algorithm.\nStudy 2 analyzed the random forests model by feature importance and revealed\nthe sentiments joy, disgust, positive and negative as the most predictive\nfeatures. Furthermore, the visualization of additive variable attributions and\ntheir prediction distribution showed correct prediction in direction and effect\nsize for the 5-star rating but partially wrong direction and insufficient\neffect size for the 1-star rating. These prediction details were corroborated\nby a what-if analysis for the four top features. In conclusion, the prediction\nmechanism of a machine learning model can be uncovered by visualization of\nparticular observations. Comparing instances of contrasting ground truth values\ncan draw a differential picture of the prediction mechanism and inform\ndecisions for model improvement.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 10:25:50 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["So", "Chaehan", ""]]}, {"id": "2003.01472", "submitter": "Hadrien Titeux", "authors": "Hadrien Titeux (LSCP, CoML), Rachid Riad (LSCP, CoML), Xuan-Nga Cao\n  (LSCP, CoML), Nicolas Hamilakis (LSCP, CoML), Kris Madden (CoML), Alejandrina\n  Cristia (LSCP), Anne-Catherine Bachoud-L\\'evi (INSERM, PSL, UPEC M\\'edecine),\n  Emmanuel Dupoux (LSCP, CoML, PSL, Inria, CNRS, EHESS)", "title": "Seshat: A tool for managing and verifying annotation campaigns of audio\n  data", "comments": null, "journal-ref": "LREC 2020 - 12th Language Resources and Evaluation Conference, May\n  2020, Marseille, France. pp.6976-6982", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Seshat, a new, simple and open-source software to efficiently\nmanage annotations of speech corpora. The Seshat software allows users to\neasily customise and manage annotations of large audio corpora while ensuring\ncompliance with the formatting and naming conventions of the annotated output\nfiles. In addition, it includes procedures for checking the content of\nannotations following specific rules that can be implemented in personalised\nparsers. Finally, we propose a double-annotation mode, for which Seshat\ncomputes automatically an associated inter-annotator agreement with the\n$\\gamma$ measure taking into account the categorisation and segmentation\ndiscrepancies.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 12:11:12 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 09:58:17 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Titeux", "Hadrien", "", "LSCP, CoML"], ["Riad", "Rachid", "", "LSCP, CoML"], ["Cao", "Xuan-Nga", "", "LSCP, CoML"], ["Hamilakis", "Nicolas", "", "LSCP, CoML"], ["Madden", "Kris", "", "CoML"], ["Cristia", "Alejandrina", "", "LSCP"], ["Bachoud-L\u00e9vi", "Anne-Catherine", "", "INSERM, PSL, UPEC M\u00e9decine"], ["Dupoux", "Emmanuel", "", "LSCP, CoML, PSL, Inria, CNRS, EHESS"]]}, {"id": "2003.01473", "submitter": "Qiaolin Xia", "authors": "Qiaolin Xia, Haoyang Huang, Nan Duan, Dongdong Zhang, Lei Ji, Zhifang\n  Sui, Edward Cui, Taroon Bharti, Xin Liu, Ming Zhou", "title": "XGPT: Cross-modal Generative Pre-Training for Image Captioning", "comments": "12 pages, 3 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While many BERT-based cross-modal pre-trained models produce excellent\nresults on downstream understanding tasks like image-text retrieval and VQA,\nthey cannot be applied to generation tasks directly. In this paper, we propose\nXGPT, a new method of Cross-modal Generative Pre-Training for Image Captioning\nthat is designed to pre-train text-to-image caption generators through three\nnovel generation tasks, including Image-conditioned Masked Language Modeling\n(IMLM), Image-conditioned Denoising Autoencoding (IDA), and Text-conditioned\nImage Feature Generation (TIFG). As a result, the pre-trained XGPT can be\nfine-tuned without any task-specific architecture modifications to create\nstate-of-the-art models for image captioning. Experiments show that XGPT\nobtains new state-of-the-art results on the benchmark datasets, including COCO\nCaptions and Flickr30k Captions. We also use XGPT to generate new image\ncaptions as data augmentation for the image retrieval task and achieve\nsignificant improvement on all recall metrics.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 12:13:06 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 07:56:09 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Xia", "Qiaolin", ""], ["Huang", "Haoyang", ""], ["Duan", "Nan", ""], ["Zhang", "Dongdong", ""], ["Ji", "Lei", ""], ["Sui", "Zhifang", ""], ["Cui", "Edward", ""], ["Bharti", "Taroon", ""], ["Liu", "Xin", ""], ["Zhou", "Ming", ""]]}, {"id": "2003.01478", "submitter": "Jingye Li", "authors": "Jingye Li, Meishan Zhang, Donghong Ji, Yijiang Liu", "title": "Multi-Task Learning with Auxiliary Speaker Identification for\n  Conversational Emotion Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational emotion recognition (CER) has attracted increasing interests\nin the natural language processing (NLP) community. Different from the vanilla\nemotion recognition, effective speaker-sensitive utterance representation is\none major challenge for CER. In this paper, we exploit speaker identification\n(SI) as an auxiliary task to enhance the utterance representation in\nconversations. By this method, we can learn better speaker-aware contextual\nrepresentations from the additional SI corpus. Experiments on two benchmark\ndatasets demonstrate that the proposed architecture is highly effective for\nCER, obtaining new state-of-the-art results on two datasets.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 12:25:03 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 01:35:36 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Li", "Jingye", ""], ["Zhang", "Meishan", ""], ["Ji", "Donghong", ""], ["Liu", "Yijiang", ""]]}, {"id": "2003.01509", "submitter": "Zicheng Qiu Dr.", "authors": "Zicheng Qiu, Wei Jiang, Turghunjan Mamut", "title": "Improving Uyghur ASR systems with decoders using morpheme-based language\n  models", "comments": "4 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uyghur is a minority language, and its resources for Automatic Speech\nRecognition (ASR) research are always insufficient. THUYG-20 is currently the\nonly open-sourced dataset of Uyghur speeches. State-of-the-art results of its\nclean and noiseless speech test task haven't been updated since the first\nrelease, which shows a big gap in the development of ASR between mainstream\nlanguages and Uyghur. In this paper, we try to bridge the gap by ultimately\noptimizing the ASR systems, and by developing a morpheme-based decoder,\nMLDG-Decoder (Morpheme Lattice Dynamically Generating Decoder for Uyghur\nDNN-HMM systems), which has long been missing. We have open-sourced the\ndecoder. The MLDG-Decoder employs an algorithm, named as \"on-the-fly\ncomposition with FEBABOS\", to allow the back-off states and transitions to play\nthe role of a relay station in on-the-fly composition. The algorithm empowers\nthe dynamically generated graph to constrain the morpheme sequences in the\nlattices as effectively as the static and fully composed graph does when a\n4-Gram morpheme-based Language Model (LM) is used. We have trained deeper and\nwider neural network acoustic models, and experimented with three kinds of\ndecoding schemes. The experimental results show that the decoding based on the\nstatic and fully composed graph reduces state-of-the-art Word Error Rate (WER)\non the clean and noiseless speech test task in THUYG-20 to 14.24%. The\nMLDG-Decoder reduces the WER to 14.54% while keeping the memory consumption\nreasonable. Based on the open-sourced MLDG-Decoder, readers can easily\nreproduce the experimental results in this paper.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 14:11:45 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 06:53:00 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Qiu", "Zicheng", ""], ["Jiang", "Wei", ""], ["Mamut", "Turghunjan", ""]]}, {"id": "2003.01680", "submitter": "Igor Shalyminov", "authors": "Igor Shalyminov, Alessandro Sordoni, Adam Atkinson, Hannes Schulz", "title": "Hybrid Generative-Retrieval Transformers for Dialogue Domain Adaptation", "comments": "Presented at DSTC8@AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation has recently become a key problem in dialogue systems\nresearch. Deep learning, while being the preferred technique for modeling such\nsystems, works best given massive training data. However, in the real-world\nscenario, such resources aren't available for every new domain, so the ability\nto train with a few dialogue examples can be considered essential. Pre-training\non large data sources and adapting to the target data has become the standard\nmethod for few-shot problems within the deep learning framework. In this paper,\nwe present the winning entry at the fast domain adaptation task of DSTC8, a\nhybrid generative-retrieval model based on GPT-2 fine-tuned to the multi-domain\nMetaLWOz dataset. Robust and diverse in response generation, our model uses\nretrieval logic as a fallback, being SoTA on MetaLWOz in human evaluation (>4%\nimprovement over the 2nd place system) and attaining competitive generalization\nperformance in adaptation to the unseen MultiWOZ dataset.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 18:07:42 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 16:01:31 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Shalyminov", "Igor", ""], ["Sordoni", "Alessandro", ""], ["Atkinson", "Adam", ""], ["Schulz", "Hannes", ""]]}, {"id": "2003.01765", "submitter": "Peter Plantinga", "authors": "Peter Plantinga, Eric Fosler-Lussier", "title": "Towards Real-time Mispronunciation Detection in Kids' Speech", "comments": "6 pages + 1 page for references, accepted at ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern mispronunciation detection and diagnosis systems have seen significant\ngains in accuracy due to the introduction of deep learning. However, these\nsystems have not been evaluated for the ability to be run in real-time, an\nimportant factor in applications that provide rapid feedback. In particular,\nthe state-of-the-art uses bi-directional recurrent networks, where a\nuni-directional network may be more appropriate. Teacher-student learning is a\nnatural approach to use to improve a uni-directional model, but when using a\nCTC objective, this is limited by poor alignment of outputs to evidence. We\naddress this limitation by trying two loss terms for improving the alignments\nof our models. One loss is an \"alignment loss\" term that encourages outputs\nonly when features do not resemble silence. The other loss term uses a\nuni-directional model as teacher model to align the bi-directional model. Our\nproposed model uses these aligned bi-directional models as teacher models.\nExperiments on the CSLU kids' corpus show that these changes decrease the\nlatency of the outputs, and improve the detection rates, with a trade-off\nbetween these goals.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 19:58:43 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Plantinga", "Peter", ""], ["Fosler-Lussier", "Eric", ""]]}, {"id": "2003.01769", "submitter": "Peter Plantinga", "authors": "Peter Plantinga, Deblin Bagchi, Eric Fosler-Lussier", "title": "Phonetic Feedback for Speech Enhancement With and Without Parallel\n  Speech Data", "comments": "4 pages + 1 page for references, accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning systems have gained significant ground in speech\nenhancement research, these systems have yet to make use of the full potential\nof deep learning systems to provide high-level feedback. In particular,\nphonetic feedback is rare in speech enhancement research even though it\nincludes valuable top-down information. We use the technique of mimic loss to\nprovide phonetic feedback to an off-the-shelf enhancement system, and find\ngains in objective intelligibility scores on CHiME-4 data. This technique takes\na frozen acoustic model trained on clean speech to provide valuable feedback to\nthe enhancement model, even in the case where no parallel speech data is\navailable. Our work is one of the first to show intelligibility improvement for\nneural enhancement systems without parallel speech data, and we show phonetic\nfeedback can improve a state-of-the-art neural enhancement system trained with\nparallel speech data.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 20:06:24 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Plantinga", "Peter", ""], ["Bagchi", "Deblin", ""], ["Fosler-Lussier", "Eric", ""]]}, {"id": "2003.01787", "submitter": "Cory Stephenson", "authors": "Cory Stephenson, Jenelle Feather, Suchismita Padhy, Oguz Elibol,\n  Hanlin Tang, Josh McDermott, SueYeon Chung", "title": "Untangling in Invariant Speech Recognition", "comments": "Advances in Neural Information Processing Systems. 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Encouraged by the success of deep neural networks on a variety of visual\ntasks, much theoretical and experimental work has been aimed at understanding\nand interpreting how vision networks operate. Meanwhile, deep neural networks\nhave also achieved impressive performance in audio processing applications,\nboth as sub-components of larger systems and as complete end-to-end systems by\nthemselves. Despite their empirical successes, comparatively little is\nunderstood about how these audio models accomplish these tasks. In this work,\nwe employ a recently developed statistical mechanical theory that connects\ngeometric properties of network representations and the separability of classes\nto probe how information is untangled within neural networks trained to\nrecognize speech. We observe that speaker-specific nuisance variations are\ndiscarded by the network's hierarchy, whereas task-relevant properties such as\nwords and phonemes are untangled in later layers. Higher level concepts such as\nparts-of-speech and context dependence also emerge in the later layers of the\nnetwork. Finally, we find that the deep representations carry out significant\ntemporal untangling by efficiently extracting task-relevant features at each\ntime step of the computation. Taken together, these findings shed light on how\ndeep auditory models process time dependent input signals to achieve invariant\nspeech recognition, and show how different concepts emerge through the layers\nof the network.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 20:48:43 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Stephenson", "Cory", ""], ["Feather", "Jenelle", ""], ["Padhy", "Suchismita", ""], ["Elibol", "Oguz", ""], ["Tang", "Hanlin", ""], ["McDermott", "Josh", ""], ["Chung", "SueYeon", ""]]}, {"id": "2003.01797", "submitter": "Binxuan Huang", "authors": "Binxuan Huang and Kathleen M. Carley", "title": "Discover Your Social Identity from What You Tweet: a Content Based\n  Approach", "comments": "This is a preprint of a chapter published in Disinformation,\n  Misinformation, and Fake News in Social Media: Emerging Research Challenges\n  and Opportunities, edited by Kai, S., Suhang, W., Dongwon, L., Huan, L, 2020,\n  Springer reproduced with permission of Springer Nature Switzerland AG. The\n  final authenticated version is available online at:\n  http://dx.doi.org/10.1007/978-3-030-42699-6", "journal-ref": null, "doi": "10.1007/978-3-030-42699-6", "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An identity denotes the role an individual or a group plays in highly\ndifferentiated contemporary societies. In this paper, our goal is to classify\nTwitter users based on their role identities. We first collect a coarse-grained\npublic figure dataset automatically, then manually label a more fine-grained\nidentity dataset. We propose a hierarchical self-attention neural network for\nTwitter user role identity classification. Our experiments demonstrate that the\nproposed model significantly outperforms multiple baselines. We further propose\na transfer learning scheme that improves our model's performance by a large\nmargin. Such transfer learning also greatly reduces the need for a large amount\nof human labeled data.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 21:13:12 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Huang", "Binxuan", ""], ["Carley", "Kathleen M.", ""]]}, {"id": "2003.01821", "submitter": "Denis Kleyko", "authors": "Pedro Alonso, Kumar Shridhar, Denis Kleyko, Evgeny Osipov, Marcus\n  Liwicki", "title": "HyperEmbed: Tradeoffs Between Resources and Performance in NLP Tasks\n  with Hyperdimensional Computing enabled Embedding of n-gram Statistics", "comments": "9 pages, 1 figure, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Deep Learning have led to a significant performance\nincrease on several NLP tasks, however, the models become more and more\ncomputationally demanding. Therefore, this paper tackles the domain of\ncomputationally efficient algorithms for NLP tasks. In particular, it\ninvestigates distributed representations of n-gram statistics of texts. The\nrepresentations are formed using hyperdimensional computing enabled embedding.\nThese representations then serve as features, which are used as input to\nstandard classifiers. We investigate the applicability of the embedding on one\nlarge and three small standard datasets for classification tasks using nine\nclassifiers. The embedding achieved on par F1 scores while decreasing the time\nand memory requirements by several times compared to the conventional n-gram\nstatistics, e.g., for one of the classifiers on a small dataset, the memory\nreduction was 6.18 times; while train and test speed-ups were 4.62 and 3.84\ntimes, respectively. For many classifiers on the large dataset, memory\nreduction was ca. 100 times and train and test speed-ups were over 100 times.\nImportantly, the usage of distributed representations formed via\nhyperdimensional computing allows dissecting strict dependency between the\ndimensionality of the representation and n-gram size, thus, opening a room for\ntradeoffs.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 22:44:10 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 19:28:49 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Alonso", "Pedro", ""], ["Shridhar", "Kumar", ""], ["Kleyko", "Denis", ""], ["Osipov", "Evgeny", ""], ["Liwicki", "Marcus", ""]]}, {"id": "2003.01848", "submitter": "Paul Pu Liang", "authors": "Paul Pu Liang, Jeffrey Chen, Ruslan Salakhutdinov, Louis-Philippe\n  Morency, Satwik Kottur", "title": "On Emergent Communication in Competitive Multi-Agent Teams", "comments": "AAMAS 2020, code:\n  https://github.com/pliang279/Competitive-Emergent-Communication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recent works have found the emergence of grounded compositional\nlanguage in the communication protocols developed by mostly cooperative\nmulti-agent systems when learned end-to-end to maximize performance on a\ndownstream task. However, human populations learn to solve complex tasks\ninvolving communicative behaviors not only in fully cooperative settings but\nalso in scenarios where competition acts as an additional external pressure for\nimprovement. In this work, we investigate whether competition for performance\nfrom an external, similar agent team could act as a social influence that\nencourages multi-agent populations to develop better communication protocols\nfor improved performance, compositionality, and convergence speed. We start\nfrom Task & Talk, a previously proposed referential game between two\ncooperative agents as our testbed and extend it into Task, Talk & Compete, a\ngame involving two competitive teams each consisting of two aforementioned\ncooperative agents. Using this new setting, we provide an empirical study\ndemonstrating the impact of competitive influence on multi-agent teams. Our\nresults show that an external competitive influence leads to improved accuracy\nand generalization, as well as faster emergence of communicative languages that\nare more informative and compositional.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 01:14:27 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 04:15:59 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Liang", "Paul Pu", ""], ["Chen", "Jeffrey", ""], ["Salakhutdinov", "Ruslan", ""], ["Morency", "Louis-Philippe", ""], ["Kottur", "Satwik", ""]]}, {"id": "2003.01857", "submitter": "Changzeng Fu", "authors": "Changzeng Fu, Chaoran Liu, Carlos Toshinori Ishi, Yuichiro Yoshikawa,\n  Hiroshi Ishiguro", "title": "SeMemNN: A Semantic Matrix-Based Memory Neural Network for Text\n  Classification", "comments": null, "journal-ref": null, "doi": "10.1109/ICSC.2020.00076", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text categorization is the task of assigning labels to documents written in a\nnatural language, and it has numerous real-world applications including\nsentiment analysis as well as traditional topic assignment tasks. In this\npaper, we propose 5 different configurations for the semantic matrix-based\nmemory neural network with end-to-end learning manner and evaluate our proposed\nmethod on two corpora of news articles (AG news, Sogou news). The best\nperformance of our proposed method outperforms the baseline VDCNN models on the\ntext classification task and gives a faster speed for learning semantics.\nMoreover, we also evaluate our model on small scale datasets. The results show\nthat our proposed method can still achieve better results in comparison to\nVDCNN on the small scale dataset. This paper is to appear in the Proceedings of\nthe 2020 IEEE 14th International Conference on Semantic Computing (ICSC 2020),\nSan Diego, California, 2020.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 02:00:57 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Fu", "Changzeng", ""], ["Liu", "Chaoran", ""], ["Ishi", "Carlos Toshinori", ""], ["Yoshikawa", "Yuichiro", ""], ["Ishiguro", "Hiroshi", ""]]}, {"id": "2003.01912", "submitter": "Ethan Fetaya", "authors": "Ethan Fetaya, Yonatan Lifshitz, Elad Aaron and Shai Gordin", "title": "Restoration of Fragmentary Babylonian Texts Using Recurrent Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main source of information regarding ancient Mesopotamian history and\nculture are clay cuneiform tablets. Despite being an invaluable resource, many\ntablets are fragmented leading to missing information. Currently these missing\nparts are manually completed by experts. In this work we investigate the\npossibility of assisting scholars and even automatically completing the breaks\nin ancient Akkadian texts from Achaemenid period Babylonia by modelling the\nlanguage using recurrent neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 06:36:50 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Fetaya", "Ethan", ""], ["Lifshitz", "Yonatan", ""], ["Aaron", "Elad", ""], ["Gordin", "Shai", ""]]}, {"id": "2003.01924", "submitter": "Aolan Sun", "authors": "Aolan Sun, Jianzong Wang, Ning Cheng, Huayi Peng, Zhen Zeng, Jing Xiao", "title": "GraphTTS: graph-to-sequence modelling in neural text-to-speech", "comments": "Accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper leverages the graph-to-sequence method in neural text-to-speech\n(GraphTTS), which maps the graph embedding of the input sequence to\nspectrograms. The graphical inputs consist of node and edge representations\nconstructed from input texts. The encoding of these graphical inputs\nincorporates syntax information by a GNN encoder module. Besides, applying the\nencoder of GraphTTS as a graph auxiliary encoder (GAE) can analyse prosody\ninformation from the semantic structure of texts. This can remove the manual\nselection of reference audios process and makes prosody modelling an end-to-end\nprocedure. Experimental analysis shows that GraphTTS outperforms the\nstate-of-the-art sequence-to-sequence models by 0.24 in Mean Opinion Score\n(MOS). GAE can adjust the pause, ventilation and tones of synthesised audios\nautomatically. This experimental conclusion may give some inspiration to\nresearchers working on improving speech synthesis prosody.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 07:44:55 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Sun", "Aolan", ""], ["Wang", "Jianzong", ""], ["Cheng", "Ning", ""], ["Peng", "Huayi", ""], ["Zeng", "Zhen", ""], ["Xiao", "Jing", ""]]}, {"id": "2003.01950", "submitter": "Jianzong Wang", "authors": "Zhen Zeng, Jianzong Wang, Ning Cheng, Tian Xia, Jing Xiao", "title": "AlignTTS: Efficient Feed-Forward Text-to-Speech System without Explicit\n  Alignment", "comments": "will be presented in ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Targeting at both high efficiency and performance, we propose AlignTTS to\npredict the mel-spectrum in parallel. AlignTTS is based on a Feed-Forward\nTransformer which generates mel-spectrum from a sequence of characters, and the\nduration of each character is determined by a duration predictor.Instead of\nadopting the attention mechanism in Transformer TTS to align text to\nmel-spectrum, the alignment loss is presented to consider all possible\nalignments in training by use of dynamic programming. Experiments on the\nLJSpeech dataset show that our model achieves not only state-of-the-art\nperformance which outperforms Transformer TTS by 0.03 in mean option score\n(MOS), but also a high efficiency which is more than 50 times faster than\nreal-time.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 08:44:32 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Zeng", "Zhen", ""], ["Wang", "Jianzong", ""], ["Cheng", "Ning", ""], ["Xia", "Tian", ""], ["Xiao", "Jing", ""]]}, {"id": "2003.02020", "submitter": "Shaoxiong Feng", "authors": "Shaoxiong Feng, Hongshen Chen, Kan Li, Dawei Yin", "title": "Posterior-GAN: Towards Informative and Coherent Response Generation with\n  Posterior Generative Adversarial Network", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural conversational models learn to generate responses by taking into\naccount the dialog history. These models are typically optimized over the\nquery-response pairs with a maximum likelihood estimation objective. However,\nthe query-response tuples are naturally loosely coupled, and there exist\nmultiple responses that can respond to a given query, which leads the\nconversational model learning burdensome. Besides, the general dull response\nproblem is even worsened when the model is confronted with meaningless response\ntraining instances. Intuitively, a high-quality response not only responds to\nthe given query but also links up to the future conversations, in this paper,\nwe leverage the query-response-future turn triples to induce the generated\nresponses that consider both the given context and the future conversations. To\nfacilitate the modeling of these triples, we further propose a novel\nencoder-decoder based generative adversarial learning framework, Posterior\nGenerative Adversarial Network (Posterior-GAN), which consists of a forward and\na backward generative discriminator to cooperatively encourage the generated\nresponse to be informative and coherent by two complementary assessment\nperspectives. Experimental results demonstrate that our method effectively\nboosts the informativeness and coherence of the generated response on both\nautomatic and human evaluation, which verifies the advantages of considering\ntwo assessment perspectives.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 11:57:53 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Feng", "Shaoxiong", ""], ["Chen", "Hongshen", ""], ["Li", "Kan", ""], ["Yin", "Dawei", ""]]}, {"id": "2003.02126", "submitter": "Qian Chen", "authors": "Qian Chen, Wen Wang", "title": "Sequential Neural Networks for Noetic End-to-End Response Selection", "comments": "26 pages, 3 figures, Computer Speech & Language. arXiv admin note:\n  substantial text overlap with arXiv:1901.02609", "journal-ref": "Computer Speech & Language, Volume 62, July 2020, 101072", "doi": "10.1016/j.csl.2020.101072", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The noetic end-to-end response selection challenge as one track in the 7th\nDialog System Technology Challenges (DSTC7) aims to push the state of the art\nof utterance classification for real world goal-oriented dialog systems, for\nwhich participants need to select the correct next utterances from a set of\ncandidates for the multi-turn context. This paper presents our systems that are\nranked top 1 on both datasets under this challenge, one focused and small\n(Advising) and the other more diverse and large (Ubuntu). Previous\nstate-of-the-art models use hierarchy-based (utterance-level and token-level)\nneural networks to explicitly model the interactions among different turns'\nutterances for context modeling. In this paper, we investigate a sequential\nmatching model based only on chain sequence for multi-turn response selection.\nOur results demonstrate that the potentials of sequential matching approaches\nhave not yet been fully exploited in the past for multi-turn response\nselection. In addition to ranking top 1 in the challenge, the proposed model\noutperforms all previous models, including state-of-the-art hierarchy-based\nmodels, on two large-scale public multi-turn response selection benchmark\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 04:36:33 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Chen", "Qian", ""], ["Wang", "Wen", ""]]}, {"id": "2003.02197", "submitter": "Hongzheng Li", "authors": "Hongzheng Li and Heyan Huang", "title": "Evaluating Low-Resource Machine Translation between Chinese and\n  Vietnamese with Back-Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Back translation (BT) has been widely used and become one of standard\ntechniques for data augmentation in Neural Machine Translation (NMT), BT has\nproven to be helpful for improving the performance of translation effectively,\nespecially for low-resource scenarios. While most works related to BT mainly\nfocus on European languages, few of them study languages in other areas around\nthe world. In this paper, we investigate the impacts of BT on Asia language\ntranslations between the extremely low-resource Chinese and Vietnamese language\npair. We evaluate and compare the effects of different sizes of synthetic data\non both NMT and Statistical Machine Translation (SMT) models for Chinese to\nVietnamese and Vietnamese to Chinese, with character-based and word-based\nsettings. Some conclusions from previous works are partially confirmed and we\nalso draw some other interesting findings and conclusions, which are beneficial\nto understand BT further.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 17:10:10 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 04:09:27 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Li", "Hongzheng", ""], ["Huang", "Heyan", ""]]}, {"id": "2003.02244", "submitter": "Junyi Jessy Li", "authors": "Hsin-Ping Huang, Junyi Jessy Li", "title": "Unsupervised Adversarial Domain Adaptation for Implicit Discourse\n  Relation Classification", "comments": "CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit discourse relations are not only more challenging to classify, but\nalso to annotate, than their explicit counterparts. We tackle situations where\ntraining data for implicit relations are lacking, and exploit domain adaptation\nfrom explicit relations (Ji et al., 2015). We present an unsupervised\nadversarial domain adaptive network equipped with a reconstruction component.\nOur system outperforms prior works and other adversarial benchmarks for\nunsupervised domain adaptation. Additionally, we extend our system to take\nadvantage of labeled data if some are available.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 18:31:32 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 20:32:03 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Huang", "Hsin-Ping", ""], ["Li", "Junyi Jessy", ""]]}, {"id": "2003.02245", "submitter": "Varun Kumar", "authors": "Varun Kumar, Ashutosh Choudhary, Eunah Cho", "title": "Data Augmentation using Pre-trained Transformer Models", "comments": "In Proceedings of the 2nd Workshop on Life-long Learning for Spoken\n  Language Systems @ AACL 2020; Code:\n  https://github.com/varinf/TransformersDataAugmentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language model based pre-trained models such as BERT have provided\nsignificant gains across different NLP tasks. In this paper, we study different\ntypes of transformer based pre-trained models such as auto-regressive models\n(GPT-2), auto-encoder models (BERT), and seq2seq models (BART) for conditional\ndata augmentation. We show that prepending the class labels to text sequences\nprovides a simple yet effective way to condition the pre-trained models for\ndata augmentation. Additionally, on three classification benchmarks,\npre-trained Seq2Seq model outperforms other data augmentation methods in a\nlow-resource setting. Further, we explore how different pre-trained model based\ndata augmentation differs in-terms of data diversity, and how well such methods\npreserve the class-label information.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 18:35:19 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2021 15:52:08 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Kumar", "Varun", ""], ["Choudhary", "Ashutosh", ""], ["Cho", "Eunah", ""]]}, {"id": "2003.02249", "submitter": "Phil Yeres", "authors": "Yada Pruksachatkun, Phil Yeres, Haokun Liu, Jason Phang, Phu Mon Htut,\n  Alex Wang, Ian Tenney and Samuel R. Bowman", "title": "jiant: A Software Toolkit for Research on General-Purpose Text\n  Understanding Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce jiant, an open source toolkit for conducting multitask and\ntransfer learning experiments on English NLU tasks. jiant enables modular and\nconfiguration-driven experimentation with state-of-the-art models and\nimplements a broad set of tasks for probing, transfer learning, and multitask\ntraining experiments. jiant implements over 50 NLU tasks, including all GLUE\nand SuperGLUE benchmark tasks. We demonstrate that jiant reproduces published\nperformance on a variety of tasks and models, including BERT and RoBERTa. jiant\nis available at https://jiant.info.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 18:41:10 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 16:33:56 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Pruksachatkun", "Yada", ""], ["Yeres", "Phil", ""], ["Liu", "Haokun", ""], ["Phang", "Jason", ""], ["Htut", "Phu Mon", ""], ["Wang", "Alex", ""], ["Tenney", "Ian", ""], ["Bowman", "Samuel R.", ""]]}, {"id": "2003.02301", "submitter": "Yi Xie", "authors": "Yi Xie, Cong Shi, Zhuohang Li, Jian Liu, Yingying Chen, Bo Yuan", "title": "Real-time, Universal, and Robust Adversarial Attacks Against Speaker\n  Recognition Systems", "comments": "Published as a conference paper at ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the popularity of voice user interface (VUI) exploded in recent years,\nspeaker recognition system has emerged as an important medium of identifying a\nspeaker in many security-required applications and services. In this paper, we\npropose the first real-time, universal, and robust adversarial attack against\nthe state-of-the-art deep neural network (DNN) based speaker recognition\nsystem. Through adding an audio-agnostic universal perturbation on arbitrary\nenrolled speaker's voice input, the DNN-based speaker recognition system would\nidentify the speaker as any target (i.e., adversary-desired) speaker label. In\naddition, we improve the robustness of our attack by modeling the sound\ndistortions caused by the physical over-the-air propagation through estimating\nroom impulse response (RIR). Experiment using a public dataset of 109 English\nspeakers demonstrates the effectiveness and robustness of our proposed attack\nwith a high attack success rate of over 90%. The attack launching time also\nachieves a 100X speedup over contemporary non-universal attacks.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 19:30:15 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 02:33:22 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Xie", "Yi", ""], ["Shi", "Cong", ""], ["Li", "Zhuohang", ""], ["Liu", "Jian", ""], ["Chen", "Yingying", ""], ["Yuan", "Bo", ""]]}, {"id": "2003.02349", "submitter": "Daniele Bonadiman", "authors": "Daniele Bonadiman and Alessandro Moschitti", "title": "A Study on Efficiency, Accuracy and Document Structure for Answer\n  Sentence Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An essential task of most Question Answering (QA) systems is to re-rank the\nset of answer candidates, i.e., Answer Sentence Selection (A2S). These\ncandidates are typically sentences either extracted from one or more documents\npreserving their natural order or retrieved by a search engine. Most\nstate-of-the-art approaches to the task use huge neural models, such as BERT,\nor complex attentive architectures. In this paper, we argue that by exploiting\nthe intrinsic structure of the original rank together with an effective\nword-relatedness encoder, we can achieve competitive results with respect to\nthe state of the art while retaining high efficiency. Our model takes 9.5\nseconds to train on the WikiQA dataset, i.e., very fast in comparison with the\n$\\sim 18$ minutes required by a standard BERT-base fine-tuning.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 22:12:18 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Bonadiman", "Daniele", ""], ["Moschitti", "Alessandro", ""]]}, {"id": "2003.02356", "submitter": "Filip Grali\\'nski", "authors": "Filip Grali\\'nski, Tomasz Stanis{\\l}awek, Anna Wr\\'oblewska, Dawid\n  Lipi\\'nski, Agnieszka Kaliska, Paulina Rosalska, Bartosz Topolski,\n  Przemys{\\l}aw Biecek", "title": "Kleister: A novel task for Information Extraction involving Long\n  Documents with Complex Layout", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art solutions for Natural Language Processing (NLP) are able to\ncapture a broad range of contexts, like the sentence-level context or\ndocument-level context for short documents. But these solutions are still\nstruggling when it comes to longer, real-world documents with the information\nencoded in the spatial structure of the document, such as page elements like\ntables, forms, headers, openings or footers; complex page layout or presence of\nmultiple pages.\n  To encourage progress on deeper and more complex Information Extraction (IE)\nwe introduce a new task (named Kleister) with two new datasets. Utilizing both\ntextual and structural layout features, an NLP system must find the most\nimportant information, about various types of entities, in long formal\ndocuments. We propose Pipeline method as a text-only baseline with different\nNamed Entity Recognition architectures (Flair, BERT, RoBERTa). Moreover, we\nchecked the most popular PDF processing tools for text extraction (pdf2djvu,\nTesseract and Textract) in order to analyze behavior of IE system in presence\nof errors introduced by these tools.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 22:45:22 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 18:51:54 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Grali\u0144ski", "Filip", ""], ["Stanis\u0142awek", "Tomasz", ""], ["Wr\u00f3blewska", "Anna", ""], ["Lipi\u0144ski", "Dawid", ""], ["Kaliska", "Agnieszka", ""], ["Rosalska", "Paulina", ""], ["Topolski", "Bartosz", ""], ["Biecek", "Przemys\u0142aw", ""]]}, {"id": "2003.02498", "submitter": "Palakorn Achananuparp", "authors": "Helena H. Lee, Ke Shu, Palakorn Achananuparp, Philips Kokoh Prasetyo,\n  Yue Liu, Ee-Peng Lim, Lav R. Varshney", "title": "RecipeGPT: Generative Pre-training Based Cooking Recipe Generation and\n  Evaluation System", "comments": "Accepted to WWW 2020. Demo track paper", "journal-ref": null, "doi": "10.1145/3366424.3383536", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interests in the automatic generation of cooking recipes have been growing\nsteadily over the past few years thanks to a large amount of online cooking\nrecipes. We present RecipeGPT, a novel online recipe generation and evaluation\nsystem. The system provides two modes of text generations: (1) instruction\ngeneration from given recipe title and ingredients; and (2) ingredient\ngeneration from recipe title and cooking instructions. Its back-end text\ngeneration module comprises a generative pre-trained language model GPT-2\nfine-tuned on a large cooking recipe dataset. Moreover, the recipe evaluation\nmodule allows the users to conveniently inspect the quality of the generated\nrecipe contents and store the results for future reference. RecipeGPT can be\naccessed online at https://recipegpt.org/.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 09:25:30 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Lee", "Helena H.", ""], ["Shu", "Ke", ""], ["Achananuparp", "Palakorn", ""], ["Prasetyo", "Philips Kokoh", ""], ["Liu", "Yue", ""], ["Lim", "Ee-Peng", ""], ["Varshney", "Lav R.", ""]]}, {"id": "2003.02599", "submitter": "Evangelia Kyrimi", "authors": "Evangelia Kyrimi, Somayyeh Mossadegh, Nigel Tai, William Marsh", "title": "An Incremental Explanation of Inference in Hybrid Bayesian Networks for\n  Increasing Model Trustworthiness and Supporting Clinical Decision Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Various AI models are increasingly being considered as part of clinical\ndecision-support tools. However, the trustworthiness of such models is rarely\nconsidered. Clinicians are more likely to use a model if they can understand\nand trust its predictions. Key to this is if its underlying reasoning can be\nexplained. A Bayesian network (BN) model has the advantage that it is not a\nblack-box and its reasoning can be explained. In this paper, we propose an\nincremental explanation of inference that can be applied to hybrid BNs, i.e.\nthose that contain both discrete and continuous nodes. The key questions that\nwe answer are: (1) which important evidence supports or contradicts the\nprediction, and (2) through which intermediate variables does the information\nflow. The explanation is illustrated using a real clinical case study. A small\nevaluation study is also conducted.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 13:22:23 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 10:33:23 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Kyrimi", "Evangelia", ""], ["Mossadegh", "Somayyeh", ""], ["Tai", "Nigel", ""], ["Marsh", "William", ""]]}, {"id": "2003.02639", "submitter": "Felipe  Urbina FelipeUrbina <", "authors": "Javier Vera, Felipe Urbina and Wenceslao Palma", "title": "Phase transitions in a decentralized graph-based approach to human\n  language", "comments": null, "journal-ref": "Phys. Rev. E 103, 022129 (2021)", "doi": "10.1103/PhysRevE.103.022129", "report-no": null, "categories": "physics.soc-ph cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zipf's law establishes a scaling behavior for word-frequencies in large text\ncorpora. The appearance of Zipfian properties in human language has been\npreviously explained as an optimization problem for the interests of speakers\nand hearers. On the other hand, human-like vocabularies can be viewed as\nbipartite graphs. The aim here is double: within a bipartite-graph approach to\nhuman vocabularies, to propose a decentralized language game model for the\nformation of Zipfian properties. To do this, we define a language game, in\nwhich a population of artificial agents is involved in idealized linguistic\ninteractions. Numerical simulations show the appearance of a phase transition\nfrom an initially disordered state to three possible phases for language\nformation. Our results suggest that Zipfian properties in language seem to\narise partly from decentralized linguistic interactions between agents endowed\nwith bipartite word-meaning mappings.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 15:07:03 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Vera", "Javier", ""], ["Urbina", "Felipe", ""], ["Palma", "Wenceslao", ""]]}, {"id": "2003.02645", "submitter": "Micha Livne", "authors": "Micha Livne, Kevin Swersky, David J. Fleet", "title": "SentenceMIM: A Latent Variable Language Model", "comments": "Preprint. Demo: https://github.com/seraphlabs-ca/SentenceMIM-demo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SentenceMIM is a probabilistic auto-encoder for language data, trained with\nMutual Information Machine (MIM) learning to provide a fixed length\nrepresentation of variable length language observations (i.e., similar to VAE).\nPrevious attempts to learn VAEs for language data faced challenges due to\nposterior collapse. MIM learning encourages high mutual information between\nobservations and latent variables, and is robust against posterior collapse. As\nsuch, it learns informative representations whose dimension can be an order of\nmagnitude higher than existing language VAEs. Importantly, the SentenceMIM loss\nhas no hyper-parameters, simplifying optimization. We compare sentenceMIM with\nVAE, and AE on multiple datasets. SentenceMIM yields excellent reconstruction,\ncomparable to AEs, with a rich structured latent space, comparable to VAEs. The\nstructured latent representation is demonstrated with interpolation between\nsentences of different lengths. We demonstrate the versatility of sentenceMIM\nby utilizing a trained model for question-answering and transfer learning,\nwithout fine-tuning, outperforming VAE and AE with similar architectures.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 15:34:29 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 02:41:29 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2021 15:20:13 GMT"}, {"version": "v4", "created": "Sun, 14 Feb 2021 11:24:11 GMT"}, {"version": "v5", "created": "Wed, 21 Apr 2021 20:02:00 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Livne", "Micha", ""], ["Swersky", "Kevin", ""], ["Fleet", "David J.", ""]]}, {"id": "2003.02736", "submitter": "Dustin Wright", "authors": "Dustin Wright and Isabelle Augenstein", "title": "Claim Check-Worthiness Detection as Positive Unlabelled Learning", "comments": "13 pages, 2 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the first step of automatic fact checking, claim check-worthiness\ndetection is a critical component of fact checking systems. There are multiple\nlines of research which study this problem: check-worthiness ranking from\npolitical speeches and debates, rumour detection on Twitter, and citation\nneeded detection from Wikipedia. To date, there has been no structured\ncomparison of these various tasks to understand their relatedness, and no\ninvestigation into whether or not a unified approach to all of them is\nachievable. In this work, we illuminate a central challenge in claim\ncheck-worthiness detection underlying all of these tasks, being that they hinge\nupon detecting both how factual a sentence is, as well as how likely a sentence\nis to be believed without verification. As such, annotators only mark those\ninstances they judge to be clear-cut check-worthy. Our best performing method\nis a unified approach which automatically corrects for this using a variant of\npositive unlabelled learning that finds instances which were incorrectly\nlabelled as not check-worthy. In applying this, we out-perform the state of the\nart in two of the three tasks studied for claim check-worthiness detection in\nEnglish.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 16:06:07 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 16:52:15 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Wright", "Dustin", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "2003.02738", "submitter": "Florian Schmidt", "authors": "Florian Schmidt and Thomas Hofmann", "title": "BERT as a Teacher: Contextual Embeddings for Sequence-Level Reward", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring the quality of a generated sequence against a set of references is\na central problem in many learning frameworks, be it to compute a score, to\nassign a reward, or to perform discrimination. Despite great advances in model\narchitectures, metrics that scale independently of the number of references are\nstill based on n-gram estimates. We show that the underlying operations,\ncounting words and comparing counts, can be lifted to embedding words and\ncomparing embeddings. An in-depth analysis of BERT embeddings shows empirically\nthat contextual embeddings can be employed to capture the required dependencies\nwhile maintaining the necessary scalability through appropriate pruning and\nsmoothing techniques. We cast unconditional generation as a reinforcement\nlearning problem and show that our reward function indeed provides a more\neffective learning signal than n-gram reward in this challenging setting.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 16:06:37 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Schmidt", "Florian", ""], ["Hofmann", "Thomas", ""]]}, {"id": "2003.02739", "submitter": "Farhad Nooralahzadeh", "authors": "Farhad Nooralahzadeh, Giannis Bekoulis, Johannes Bjerva, Isabelle\n  Augenstein", "title": "Zero-Shot Cross-Lingual Transfer with Meta Learning", "comments": "Accepted as long paper in EMNLP2020 main conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning what to share between tasks has been a topic of great importance\nrecently, as strategic sharing of knowledge has been shown to improve\ndownstream task performance. This is particularly important for multilingual\napplications, as most languages in the world are under-resourced. Here, we\nconsider the setting of training models on multiple different languages at the\nsame time, when little or no data is available for languages other than\nEnglish. We show that this challenging setup can be approached using\nmeta-learning, where, in addition to training a source language model, another\nmodel learns to select which training instances are the most beneficial to the\nfirst. We experiment using standard supervised, zero-shot cross-lingual, as\nwell as few-shot cross-lingual settings for different natural language\nunderstanding tasks (natural language inference, question answering). Our\nextensive experimental setup demonstrates the consistent effectiveness of\nmeta-learning for a total of 15 languages. We improve upon the state-of-the-art\nfor zero-shot and few-shot NLI (on MultiNLI and XNLI) and QA (on the MLQA\ndataset). A comprehensive error analysis indicates that the correlation of\ntypological features between languages can partly explain when parameter\nsharing learned via meta-learning is beneficial.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 16:07:32 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 14:40:52 GMT"}, {"version": "v3", "created": "Wed, 29 Apr 2020 09:12:11 GMT"}, {"version": "v4", "created": "Mon, 5 Oct 2020 13:18:00 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Nooralahzadeh", "Farhad", ""], ["Bekoulis", "Giannis", ""], ["Bjerva", "Johannes", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "2003.02756", "submitter": "Tianyu Liu", "authors": "Tianyu Liu, Xin Zheng, Baobao Chang and Zhifang Sui", "title": "HypoNLI: Exploring the Artificial Patterns of Hypothesis-only Bias in\n  Natural Language Inference", "comments": "LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent studies have shown that for models trained on datasets for\nnatural language inference (NLI), it is possible to make correct predictions by\nmerely looking at the hypothesis while completely ignoring the premise. In this\nwork, we manage to derive adversarial examples in terms of the hypothesis-only\nbias and explore eligible ways to mitigate such bias. Specifically, we extract\nvarious phrases from the hypotheses (artificial patterns) in the training sets,\nand show that they have been strong indicators to the specific labels. We then\nfigure out `hard' and `easy' instances from the original test sets whose labels\nare opposite to or consistent with those indications. We also set up baselines\nincluding both pretrained models (BERT, RoBERTa, XLNet) and competitive\nnon-pretrained models (InferSent, DAM, ESIM). Apart from the benchmark and\nbaselines, we also investigate two debiasing approaches which exploit the\nartificial pattern modeling to mitigate such hypothesis-only bias:\ndown-sampling and adversarial training. We believe those methods can be treated\nas competitive baselines in NLI debiasing tasks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 16:46:35 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 02:47:53 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Liu", "Tianyu", ""], ["Zheng", "Xin", ""], ["Chang", "Baobao", ""], ["Sui", "Zhifang", ""]]}, {"id": "2003.02817", "submitter": "Lucas Nunes Sequeira", "authors": "Lucas Nunes Sequeira, Bruno Moreschi, Fabio Gagliardi Cozman and\n  Bernardo Fontes", "title": "An Empirical Accuracy Law for Sequential Machine Translation: the Case\n  of Google Translate", "comments": "11 pages, 8 figures (mostly graphs), a few mathematical functions and\n  samples of the experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research, we have established, through empirical testing, a law that\nrelates the number of translating hops to translation accuracy in sequential\nmachine translation in Google Translate. Both accuracy and size decrease with\nthe number of hops; the former displays a decrease closely following a power\nlaw. Such a law allows one to predict the behavior of translation chains that\nmay be built as society increasingly depends on automated devices.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 18:40:44 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 18:22:36 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Sequeira", "Lucas Nunes", ""], ["Moreschi", "Bruno", ""], ["Cozman", "Fabio Gagliardi", ""], ["Fontes", "Bernardo", ""]]}, {"id": "2003.02877", "submitter": "Mitchell Gordon", "authors": "Mitchell A. Gordon, Kevin Duh", "title": "Distill, Adapt, Distill: Training Small, In-Domain Models for Neural\n  Machine Translation", "comments": "Accepted to WNGT 2020 Workshop at ACL 2020 Conference. Code is at\n  http://github.com/mitchellgordon95/kd-aug", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore best practices for training small, memory efficient machine\ntranslation models with sequence-level knowledge distillation in the domain\nadaptation setting. While both domain adaptation and knowledge distillation are\nwidely-used, their interaction remains little understood. Our large-scale\nempirical results in machine translation (on three language pairs with three\ndomains each) suggest distilling twice for best performance: once using\ngeneral-domain data and again using in-domain data with an adapted teacher.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 19:14:33 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 18:39:02 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 17:21:56 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Gordon", "Mitchell A.", ""], ["Duh", "Kevin", ""]]}, {"id": "2003.02912", "submitter": "Federico Bianchi", "authors": "Debora Nozza, Federico Bianchi, Dirk Hovy", "title": "What the [MASK]? Making Sense of Language-Specific BERT Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Natural Language Processing (NLP) has witnessed an impressive\nprogress in many areas, due to the advent of novel, pretrained contextual\nrepresentation models. In particular, Devlin et al. (2019) proposed a model,\ncalled BERT (Bidirectional Encoder Representations from Transformers), which\nenables researchers to obtain state-of-the art performance on numerous NLP\ntasks by fine-tuning the representations on their data set and task, without\nthe need for developing and training highly-specific architectures. The authors\nalso released multilingual BERT (mBERT), a model trained on a corpus of 104\nlanguages, which can serve as a universal language model. This model obtained\nimpressive results on a zero-shot cross-lingual natural inference task. Driven\nby the potential of BERT models, the NLP community has started to investigate\nand generate an abundant number of BERT models that are trained on a particular\nlanguage, and tested on a specific data domain and task. This allows us to\nevaluate the true potential of mBERT as a universal language model, by\ncomparing it to the performance of these more specific models. This paper\npresents the current state of the art in language-specific BERT models,\nproviding an overall picture with respect to different dimensions (i.e.\narchitectures, data domains, and tasks). Our aim is to provide an immediate and\nstraightforward overview of the commonalities and differences between\nLanguage-Specific (language-specific) BERT models and mBERT. We also provide an\ninteractive and constantly updated website that can be used to explore the\ninformation we have collected, at https://bertlang.unibocconi.it.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 20:42:51 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Nozza", "Debora", ""], ["Bianchi", "Federico", ""], ["Hovy", "Dirk", ""]]}, {"id": "2003.02931", "submitter": "Barbara Plank", "authors": "Barbara Plank", "title": "Neural Cross-Lingual Transfer and Limited Annotated Data for Named\n  Entity Recognition in Danish", "comments": "Published at NoDaLiDa 2019; updated (system, data and repository\n  details)", "journal-ref": "NoDaLiDa, 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named Entity Recognition (NER) has greatly advanced by the introduction of\ndeep neural architectures. However, the success of these methods depends on\nlarge amounts of training data. The scarcity of publicly-available\nhuman-labeled datasets has resulted in limited evaluation of existing NER\nsystems, as is the case for Danish. This paper studies the effectiveness of\ncross-lingual transfer for Danish, evaluates its complementarity to limited\ngold data, and sheds light on performance of Danish NER.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 21:25:00 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Plank", "Barbara", ""]]}, {"id": "2003.02955", "submitter": "Seid Muhie Yimam", "authors": "Seid Muhie Yimam and Gopalakrishnan Venkatesh and John Sie Yuen Lee\n  and Chris Biemann", "title": "Automatic Compilation of Resources for Academic Writing and Evaluating\n  with Informal Word Identification and Paraphrasing System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present the first approach to automatically building resources for\nacademic writing. The aim is to build a writing aid system that automatically\nedits a text so that it better adheres to the academic style of writing. On top\nof existing academic resources, such as the Corpus of Contemporary American\nEnglish (COCA) academic Word List, the New Academic Word List, and the Academic\nCollocation List, we also explore how to dynamically build such resources that\nwould be used to automatically identify informal or non-academic words or\nphrases. The resources are compiled using different generic approaches that can\nbe extended for different domains and languages. We describe the evaluation of\nresources with a system implementation. The system consists of an informal word\nidentification (IWI), academic candidate paraphrase generation, and paraphrase\nranking components. To generate candidates and rank them in context, we have\nused the PPDB and WordNet paraphrase resources. We use the Concepts in Context\n(CoInCO) \"All-Words\" lexical substitution dataset both for the informal word\nidentification and paraphrase generation experiments. Our informal word\nidentification component achieves an F-1 score of 82%, significantly\noutperforming a stratified classifier baseline. The main contribution of this\nwork is a domain-independent methodology to build targeted resources for\nwriting aids.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 22:55:45 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Yimam", "Seid Muhie", ""], ["Venkatesh", "Gopalakrishnan", ""], ["Lee", "John Sie Yuen", ""], ["Biemann", "Chris", ""]]}, {"id": "2003.02958", "submitter": "Rohola Zandie", "authors": "Rohola Zandie and Mohammad H. Mahoor", "title": "EmpTransfo: A Multi-head Transformer Architecture for Creating\n  Empathetic Dialog Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding emotions and responding accordingly is one of the biggest\nchallenges of dialog systems. This paper presents EmpTransfo, a multi-head\nTransformer architecture for creating an empathetic dialog system. EmpTransfo\nutilizes state-of-the-art pre-trained models (e.g., OpenAI-GPT) for language\ngeneration, though models with different sizes can be used. We show that\nutilizing the history of emotions and other metadata can improve the quality of\ngenerated conversations by the dialog system. Our experimental results using a\nchallenging language corpus show that the proposed approach outperforms other\nmodels in terms of Hit@1 and PPL (Perplexity).\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 23:09:24 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Zandie", "Rohola", ""], ["Mahoor", "Mohammad H.", ""]]}, {"id": "2003.02966", "submitter": "Yusuke Fujita", "authors": "Yusuke Fujita, Shinji Watanabe, Shota Horiguchi, Yawen Xue, Kenji\n  Nagamatsu", "title": "End-to-End Neural Diarization: Reformulating Speaker Diarization as\n  Simple Multi-label Classification", "comments": "Submission to IEEE TASLP. This article draws from our previous\n  conference papers: arxiv:1909.06247 and arxiv:1909.05952", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most common approach to speaker diarization is clustering of speaker\nembeddings. However, the clustering-based approach has a number of problems;\ni.e., (i) it is not optimized to minimize diarization errors directly, (ii) it\ncannot handle speaker overlaps correctly, and (iii) it has trouble adapting\ntheir speaker embedding models to real audio recordings with speaker overlaps.\nTo solve these problems, we propose the End-to-End Neural Diarization (EEND),\nin which a neural network directly outputs speaker diarization results given a\nmulti-speaker recording. To realize such an end-to-end model, we formulate the\nspeaker diarization problem as a multi-label classification problem and\nintroduce a permutation-free objective function to directly minimize\ndiarization errors. Besides its end-to-end simplicity, the EEND method can\nexplicitly handle speaker overlaps during training and inference. Just by\nfeeding multi-speaker recordings with corresponding speaker segment labels, our\nmodel can be easily adapted to real conversations. We evaluated our method on\nsimulated speech mixtures and real conversation datasets. The results showed\nthat the EEND method outperformed the state-of-the-art x-vector\nclustering-based method, while it correctly handled speaker overlaps. We\nexplored the neural network architecture for the EEND method, and found that\nthe self-attention-based neural network was the key to achieving excellent\nperformance. In contrast to conditioning the network only on its previous and\nnext hidden states, as is done using bidirectional long short-term memory\n(BLSTM), self-attention is directly conditioned on all the frames. By\nvisualizing the attention weights, we show that self-attention captures global\nspeaker characteristics in addition to local speech activity dynamics, making\nit especially suitable for dealing with the speaker diarization problem.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 14:53:32 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Fujita", "Yusuke", ""], ["Watanabe", "Shinji", ""], ["Horiguchi", "Shota", ""], ["Xue", "Yawen", ""], ["Nagamatsu", "Kenji", ""]]}, {"id": "2003.02973", "submitter": "Kazuhiro Seki", "authors": "Kazuhiro Seki and Yusuke Ikuta", "title": "S-APIR: News-based Business Sentiment Index", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our work on developing a new business sentiment index\nusing daily newspaper articles. We adopt a recurrent neural network (RNN) with\nGated Recurrent Units to predict the business sentiment of a given text. An RNN\nis initially trained on Economy Watchers Survey and then fine-tuned on news\ntexts for domain adaptation. Also, a one-class support vector machine is\napplied to filter out texts deemed irrelevant to business sentiment. Moreover,\nwe propose a simple approach to temporally analyzing how much and when any\ngiven factor influences the predicted business sentiment. The validity and\nutility of the proposed approaches are empirically demonstrated through a\nseries of experiments on Nikkei Newspaper articles published from 2013 to 2018.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 00:18:50 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Seki", "Kazuhiro", ""], ["Ikuta", "Yusuke", ""]]}, {"id": "2003.03014", "submitter": "Julia Mendelsohn", "authors": "Julia Mendelsohn, Yulia Tsvetkov, Dan Jurafsky", "title": "A Framework for the Computational Linguistic Analysis of Dehumanization", "comments": "31 pages, 6 figures (Appendix is 4 pages, 4 figures). Submitted to\n  Frontiers in Artificial Intelligence (Language and Computation)", "journal-ref": "Frontiers in Artificial Intelligence 3 (2020):55", "doi": "10.3389/frai.2020.00055", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dehumanization is a pernicious psychological process that often leads to\nextreme intergroup bias, hate speech, and violence aimed at targeted social\ngroups. Despite these serious consequences and the wealth of available data,\ndehumanization has not yet been computationally studied on a large scale.\nDrawing upon social psychology research, we create a computational linguistic\nframework for analyzing dehumanizing language by identifying linguistic\ncorrelates of salient components of dehumanization. We then apply this\nframework to analyze discussions of LGBTQ people in the New York Times from\n1986 to 2015. Overall, we find increasingly humanizing descriptions of LGBTQ\npeople over time. However, we find that the label homosexual has emerged to be\nmuch more strongly associated with dehumanizing attitudes than other labels,\nsuch as gay. Our proposed techniques highlight processes of linguistic\nvariation and change in discourses surrounding marginalized groups.\nFurthermore, the ability to analyze dehumanizing language at a large scale has\nimplications for automatically detecting and understanding media bias as well\nas abusive language online.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 03:02:12 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 20:00:19 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Mendelsohn", "Julia", ""], ["Tsvetkov", "Yulia", ""], ["Jurafsky", "Dan", ""]]}, {"id": "2003.03044", "submitter": "Franck Dernoncourt", "authors": "Edward T. Moseley, Joy T. Wu, Jonathan Welt, John Foote, Patrick D.\n  Tyler, David W. Grant, Eric T. Carlson, Sebastian Gehrmann, Franck\n  Dernoncourt and Leo Anthony Celi", "title": "A Corpus for Detecting High-Context Medical Conditions in Intensive Care\n  Patient Notes Focusing on Frequently Readmitted Patients", "comments": "Accepted at LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A crucial step within secondary analysis of electronic health records (EHRs)\nis to identify the patient cohort under investigation. While EHRs contain\nmedical billing codes that aim to represent the conditions and treatments\npatients may have, much of the information is only present in the patient\nnotes. Therefore, it is critical to develop robust algorithms to infer\npatients' conditions and treatments from their written notes. In this paper, we\nintroduce a dataset for patient phenotyping, a task that is defined as the\nidentification of whether a patient has a given medical condition (also\nreferred to as clinical indication or phenotype) based on their patient note.\nNursing Progress Notes and Discharge Summaries from the Intensive Care Unit of\na large tertiary care hospital were manually annotated for the presence of\nseveral high-context phenotypes relevant to treatment and risk of\nre-hospitalization. This dataset contains 1102 Discharge Summaries and 1000\nNursing Progress Notes. Each Discharge Summary and Progress Note has been\nannotated by at least two expert human annotators (one clinical researcher and\none resident physician). Annotated phenotypes include treatment non-adherence,\nchronic pain, advanced/metastatic cancer, as well as 10 other phenotypes. This\ndataset can be utilized for academic and industrial research in medicine and\ncomputer science, particularly within the field of medical natural language\nprocessing.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 05:56:49 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Moseley", "Edward T.", ""], ["Wu", "Joy T.", ""], ["Welt", "Jonathan", ""], ["Foote", "John", ""], ["Tyler", "Patrick D.", ""], ["Grant", "David W.", ""], ["Carlson", "Eric T.", ""], ["Gehrmann", "Sebastian", ""], ["Dernoncourt", "Franck", ""], ["Celi", "Leo Anthony", ""]]}, {"id": "2003.03064", "submitter": "Minh-Tien Nguyen", "authors": "Minh-Tien Nguyen, Viet-Anh Phan, Le Thai Linh, Nguyen Hong Son, Le\n  Tien Dung, Miku Hirano and Hajime Hotta", "title": "Transfer Learning for Information Extraction with Limited Data", "comments": "14 pages, 5 figures, PACLING conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a practical approach to fine-grained information\nextraction. Through plenty of experiences of authors in practically applying\ninformation extraction to business process automation, there can be found a\ncouple of fundamental technical challenges: (i) the availability of labeled\ndata is usually limited and (ii) highly detailed classification is required.\nThe main idea of our proposal is to leverage the concept of transfer learning,\nwhich is to reuse the pre-trained model of deep neural networks, with a\ncombination of common statistical classifiers to determine the class of each\nextracted term. To do that, we first exploit BERT to deal with the limitation\nof training data in real scenarios, then stack BERT with Convolutional Neural\nNetworks to learn hidden representation for classification. To validate our\napproach, we applied our model to an actual case of document processing, which\nis a process of competitive bids for government projects in Japan. We used 100\ndocuments for training and testing and confirmed that the model enables to\nextract fine-grained named entities with a detailed level of information\npreciseness specialized in the targeted business process, such as a department\nname of application receivers.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 08:08:20 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 13:56:57 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Nguyen", "Minh-Tien", ""], ["Phan", "Viet-Anh", ""], ["Linh", "Le Thai", ""], ["Son", "Nguyen Hong", ""], ["Dung", "Le Tien", ""], ["Hirano", "Miku", ""], ["Hotta", "Hajime", ""]]}, {"id": "2003.03069", "submitter": "Sattaya Singkul", "authors": "Sattaya Singkul, Borirat Khampingyot, Nattasit Maharattamalai, Supawat\n  Taerungruang and Tawunrat Chalothorn", "title": "Parsing Thai Social Data: A New Challenge for Thai NLP", "comments": "7 Pages, 8 figures, to be published in The 14th International Joint\n  Symposium on Artificial Intelligence and Natural Language Processing\n  (iSAI-NLP 2019)", "journal-ref": null, "doi": "10.1109/iSAI-NLP48611.2019.9045639", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Dependency parsing (DP) is a task that analyzes text for syntactic structure\nand relationship between words. DP is widely used to improve natural language\nprocessing (NLP) applications in many languages such as English. Previous works\non DP are generally applicable to formally written languages. However, they do\nnot apply to informal languages such as the ones used in social networks.\nTherefore, DP has to be researched and explored with such social network data.\nIn this paper, we explore and identify a DP model that is suitable for Thai\nsocial network data. After that, we will identify the appropriate linguistic\nunit as an input. The result showed that, the transition based model called,\nimprove Elkared dependency parser outperform the others at UAS of 81.42%.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 08:18:13 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Singkul", "Sattaya", ""], ["Khampingyot", "Borirat", ""], ["Maharattamalai", "Nattasit", ""], ["Taerungruang", "Supawat", ""], ["Chalothorn", "Tawunrat", ""]]}, {"id": "2003.03072", "submitter": "Chan Hee Song", "authors": "Chan Hee Song, Dawn Lawrie, Tim Finin, James Mayfield", "title": "Improving Neural Named Entity Recognition with Gazetteers", "comments": "Short version accepted to the 33rd FLAIRS conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The goal of this work is to improve the performance of a neural named entity\nrecognition system by adding input features that indicate a word is part of a\nname included in a gazetteer. This article describes how to generate gazetteers\nfrom the Wikidata knowledge graph as well as how to integrate the information\ninto a neural NER system. Experiments reveal that the approach yields\nperformance gains in two distinct languages: a high-resource, word-based\nlanguage, English and a high-resource, character-based language, Chinese.\nExperiments were also performed in a low-resource language, Russian on a newly\nannotated Russian NER corpus from Reddit tagged with four core types and twelve\nextended types. This article reports a baseline score. It is a longer version\nof a paper in the 33rd FLAIRS conference (Song et al. 2020).\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 08:29:37 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Song", "Chan Hee", ""], ["Lawrie", "Dawn", ""], ["Finin", "Tim", ""], ["Mayfield", "James", ""]]}, {"id": "2003.03106", "submitter": "Aitor Garc\\'ia-Pablos", "authors": "Aitor Garc\\'ia-Pablos, Naiara Perez, Montse Cuadros", "title": "Sensitive Data Detection and Classification in Spanish Clinical Text:\n  Experiments with BERT", "comments": "Accepted at 12th Edition of Language Resources and Evaluation\n  Conference (LREC2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive digital data processing provides a wide range of opportunities and\nbenefits, but at the cost of endangering personal data privacy. Anonymisation\nconsists in removing or replacing sensitive information from data, enabling its\nexploitation for different purposes while preserving the privacy of\nindividuals. Over the years, a lot of automatic anonymisation systems have been\nproposed; however, depending on the type of data, the target language or the\navailability of training documents, the task remains challenging still. The\nemergence of novel deep-learning models during the last two years has brought\nlarge improvements to the state of the art in the field of Natural Language\nProcessing. These advancements have been most noticeably led by BERT, a model\nproposed by Google in 2018, and the shared language models pre-trained on\nmillions of documents. In this paper, we use a BERT-based sequence labelling\nmodel to conduct a series of anonymisation experiments on several clinical\ndatasets in Spanish. We also compare BERT to other algorithms. The experiments\nshow that a simple BERT-based model with general-domain pre-training obtains\nhighly competitive results without any domain specific feature engineering.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 09:46:51 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 13:16:41 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Garc\u00eda-Pablos", "Aitor", ""], ["Perez", "Naiara", ""], ["Cuadros", "Montse", ""]]}, {"id": "2003.03131", "submitter": "Stig-Arne Gr\\\"onroos", "authors": "Stig-Arne Gr\\\"onroos, Sami Virpioja, Mikko Kurimo", "title": "Morfessor EM+Prune: Improved Subword Segmentation with Expectation\n  Maximization and Pruning", "comments": "Accepted for publication in LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Data-driven segmentation of words into subword units has been used in various\nnatural language processing applications such as automatic speech recognition\nand statistical machine translation for almost 20 years. Recently it has became\nmore widely adopted, as models based on deep neural networks often benefit from\nsubword units even for morphologically simpler languages. In this paper, we\ndiscuss and compare training algorithms for a unigram subword model, based on\nthe Expectation Maximization algorithm and lexicon pruning. Using English,\nFinnish, North Sami, and Turkish data sets, we show that this approach is able\nto find better solutions to the optimization problem defined by the Morfessor\nBaseline model than its original recursive training algorithm. The improved\noptimization also leads to higher morphological segmentation accuracy when\ncompared to a linguistic gold standard. We publish implementations of the new\nalgorithms in the widely-used Morfessor software package.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 10:58:59 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Gr\u00f6nroos", "Stig-Arne", ""], ["Virpioja", "Sami", ""], ["Kurimo", "Mikko", ""]]}, {"id": "2003.03204", "submitter": "Houquan Zhou", "authors": "Houquan Zhou, Yu Zhang, Zhenghua Li, Min Zhang", "title": "Is POS Tagging Necessary or Even Helpful for Neural Dependency Parsing?", "comments": "NLPCC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the pre deep learning era, part-of-speech tags have been considered as\nindispensable ingredients for feature engineering in dependency parsing. But\nquite a few works focus on joint tagging and parsing models to avoid error\npropagation. In contrast, recent studies suggest that POS tagging becomes much\nless important or even useless for neural parsing, especially when using\ncharacter-based word representations. Yet there are not enough investigations\nfocusing on this issue, both empirically and linguistically. To answer this, we\ndesign and compare three typical multi-task learning framework, i.e.,\nShare-Loose, Share-Tight, and Stack, for joint tagging and parsing based on the\nstate-of-the-art biaffine parser. Considering that it is much cheaper to\nannotate POS tags than parse trees, we also investigate the utilization of\nlarge-scale heterogeneous POS tag data. We conduct experiments on both English\nand Chinese datasets, and the results clearly show that POS tagging (both\nhomogeneous and heterogeneous) can still significantly improve parsing\nperformance when using the Stack joint framework. We conduct detailed analysis\nand gain more insights from the linguistic aspect.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 13:47:30 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 06:41:31 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Zhou", "Houquan", ""], ["Zhang", "Yu", ""], ["Li", "Zhenghua", ""], ["Zhang", "Min", ""]]}, {"id": "2003.03235", "submitter": "Bernhard Kratzwald", "authors": "Bernhard Kratzwald, Xiang Yue, Huan Sun, Stefan Feuerriegel", "title": "Practical Annotation Strategies for Question Answering Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Annotating datasets for question answering (QA) tasks is very costly, as it\nrequires intensive manual labor and often domain-specific knowledge. Yet\nstrategies for annotating QA datasets in a cost-effective manner are scarce. To\nprovide a remedy for practitioners, our objective is to develop heuristic rules\nfor annotating a subset of questions, so that the annotation cost is reduced\nwhile maintaining both in- and out-of-domain performance. For this, we conduct\na large-scale analysis in order to derive practical recommendations. First, we\ndemonstrate experimentally that more training samples contribute often only to\na higher in-domain test-set performance, but do not help the model in\ngeneralizing to unseen datasets. Second, we develop a model-guided annotation\nstrategy: it makes a recommendation with regard to which subset of samples\nshould be annotated. Its effectiveness is demonstrated in a case study based on\ndomain customization of QA to a clinical setting. Here, remarkably, annotating\na stratified subset with only 1.2% of the original training set achieves 97.7%\nof the performance as if the complete dataset was annotated. Hence, the\nlabeling effort can be reduced immensely. Altogether, our work fulfills a\ndemand in practice when labeling budgets are limited and where thus\nrecommendations are needed for annotating QA datasets more cost-effectively.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 14:25:50 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Kratzwald", "Bernhard", ""], ["Yue", "Xiang", ""], ["Sun", "Huan", ""], ["Feuerriegel", "Stefan", ""]]}, {"id": "2003.03239", "submitter": "Mutian He", "authors": "Mutian He, Yangqiu Song, Kun Xu, Dong Yu", "title": "On the Role of Conceptualization in Commonsense Knowledge Graph\n  Construction", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Commonsense knowledge graphs (CKGs) like Atomic and ASER are substantially\ndifferent from conventional KGs as they consist of much larger number of nodes\nformed by loosely-structured text, which, though, enables them to handle highly\ndiverse queries in natural language related to commonsense, leads to unique\nchallenges for automatic KG construction methods. Besides identifying relations\nabsent from the KG between nodes, such methods are also expected to explore\nabsent nodes represented by text, in which different real-world things, or\nentities, may appear. To deal with the innumerable entities involved with\ncommonsense in the real world, we introduce to CKG construction methods\nconceptualization, i.e., to view entities mentioned in text as instances of\nspecific concepts or vice versa. We build synthetic triples by\nconceptualization, and further formulate the task as triple classification,\nhandled by a discriminatory model with knowledge transferred from pretrained\nlanguage models and fine-tuned by negative sampling. Experiments demonstrate\nthat our methods can effectively identify plausible triples and expand the KG\nby triples of both new nodes and edges of high diversity and novelty.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 14:35:20 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 17:31:10 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["He", "Mutian", ""], ["Song", "Yangqiu", ""], ["Xu", "Kun", ""], ["Yu", "Dong", ""]]}, {"id": "2003.03264", "submitter": "Erion \\c{C}ano", "authors": "Erion \\c{C}ano and Maurizio Morisio", "title": "Quality of Word Embeddings on Sentiment Analysis Tasks", "comments": "6 pages, 4 figures, 2 tables. Published in proceedings of NLDB 2017,\n  the 22nd Conference of Natural Language Processing and Information Systems,\n  Liege, Belgium", "journal-ref": null, "doi": "10.1007/978-3-319-59569-6_42", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings or distributed representations of words are being used in\nvarious applications like machine translation, sentiment analysis, topic\nidentification etc. Quality of word embeddings and performance of their\napplications depends on several factors like training method, corpus size and\nrelevance etc. In this study we compare performance of a dozen of pretrained\nword embedding models on lyrics sentiment analysis and movie review polarity\ntasks. According to our results, Twitter Tweets is the best on lyrics sentiment\nanalysis, whereas Google News and Common Crawl are the top performers on movie\npolarity analysis. Glove trained models slightly outrun those trained with\nSkipgram. Also, factors like topic relevance and size of corpus significantly\nimpact the quality of the models. When medium or large-sized text sets are\navailable, obtaining word embeddings from same training dataset is usually the\nbest choice.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 15:03:08 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["\u00c7ano", "Erion", ""], ["Morisio", "Maurizio", ""]]}, {"id": "2003.03350", "submitter": "Kyrylo Malakhov", "authors": "Oleksandr Palagin, Vitalii Velychko, Kyrylo Malakhov and Oleksandr\n  Shchurov", "title": "Distributional semantic modeling: a revised technique to train term/word\n  vector space models applying the ontology-related approach", "comments": "In English, 9 pages, 2 figures. Not published yet. Prepared for\n  special issue (UkrPROG 2020 conference) of the scientific journal \"Problems\n  in programming\" (Founder: National Academy of Sciences of Ukraine, Institute\n  of Software Systems of NAS Ukraine)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a new technique for the distributional semantic modeling with a\nneural network-based approach to learn distributed term representations (or\nterm embeddings) - term vector space models as a result, inspired by the recent\nontology-related approach (using different types of contextual knowledge such\nas syntactic knowledge, terminological knowledge, semantic knowledge, etc.) to\nthe identification of terms (term extraction) and relations between them\n(relation extraction) called semantic pre-processing technology - SPT. Our\nmethod relies on automatic term extraction from the natural language texts and\nsubsequent formation of the problem-oriented or application-oriented (also\ndeeply annotated) text corpora where the fundamental entity is the term\n(includes non-compositional and compositional terms). This gives us an\nopportunity to changeover from distributed word representations (or word\nembeddings) to distributed term representations (or term embeddings). This\ntransition will allow to generate more accurate semantic maps of different\nsubject domains (also, of relations between input terms - it is useful to\nexplore clusters and oppositions, or to test your hypotheses about them). The\nsemantic map can be represented as a graph using Vec2graph - a Python library\nfor visualizing word embeddings (term embeddings in our case) as dynamic and\ninteractive graphs. The Vec2graph library coupled with term embeddings will not\nonly improve accuracy in solving standard NLP tasks, but also update the\nconventional concept of automated ontology development. The main practical\nresult of our work is the development kit (set of toolkits represented as web\nservice APIs and web application), which provides all necessary routines for\nthe basic linguistic pre-processing and the semantic pre-processing of the\nnatural language texts in Ukrainian for future training of term vector space\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 18:27:39 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Palagin", "Oleksandr", ""], ["Velychko", "Vitalii", ""], ["Malakhov", "Kyrylo", ""], ["Shchurov", "Oleksandr", ""]]}, {"id": "2003.03444", "submitter": "Yuval Pinter", "authors": "Yuval Pinter and Cassandra L. Jacobs and Max Bittker", "title": "NYTWIT: A Dataset of Novel Words in the New York Times", "comments": "COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present the New York Times Word Innovation Types dataset, or NYTWIT, a\ncollection of over 2,500 novel English words published in the New York Times\nbetween November 2017 and March 2019, manually annotated for their class of\nnovelty (such as lexical derivation, dialectal variation, blending, or\ncompounding). We present baseline results for both uncontextual and contextual\nprediction of novelty class, showing that there is room for improvement even\nfor state-of-the-art NLP systems. We hope this resource will prove useful for\nlinguists and NLP practitioners by providing a real-world environment of novel\nword appearance.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 21:19:44 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 03:54:35 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 18:54:48 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Pinter", "Yuval", ""], ["Jacobs", "Cassandra L.", ""], ["Bittker", "Max", ""]]}, {"id": "2003.03446", "submitter": "Pratyay Banerjee", "authors": "Chitta Baral, Pratyay Banerjee, Kuntal Kumar Pal, Arindam Mitra", "title": "Natural Language QA Approaches using Reasoning with External Knowledge", "comments": "6 pages, 3 figures, Work in Progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering (QA) in natural language (NL) has been an important aspect\nof AI from its early days. Winograd's ``councilmen'' example in his 1972 paper\nand McCarthy's Mr. Hug example of 1976 highlights the role of external\nknowledge in NL understanding. While Machine Learning has been the go-to\napproach in NL processing as well as NL question answering (NLQA) for the last\n30 years, recently there has been an increasingly emphasized thread on NLQA\nwhere external knowledge plays an important role. The challenges inspired by\nWinograd's councilmen example, and recent developments such as the Rebooting AI\nbook, various NLQA datasets, research on knowledge acquisition in the NLQA\ncontext, and their use in various NLQA models have brought the issue of NLQA\nusing ``reasoning'' with external knowledge to the forefront. In this paper, we\npresent a survey of the recent work on them. We believe our survey will help\nestablish a bridge between multiple fields of AI, especially between (a) the\ntraditional fields of knowledge representation and reasoning and (b) the field\nof NL understanding and NLQA.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 21:28:44 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Baral", "Chitta", ""], ["Banerjee", "Pratyay", ""], ["Pal", "Kuntal Kumar", ""], ["Mitra", "Arindam", ""]]}, {"id": "2003.03484", "submitter": "Chowdhury Rahman", "authors": "Md. Habibur Rahman Sifat, Chowdhury Rafeed Rahman, Mohammad Rafsan,\n  Md. Hasibur Rahman", "title": "Synthetic Error Dataset Generation Mimicking Bengali Writing Pattern", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While writing Bengali using English keyboard, users often make spelling\nmistakes. The accuracy of any Bengali spell checker or paragraph correction\nmodule largely depends on the kind of error dataset it is based on. Manual\ngeneration of such error dataset is a cumbersome process. In this research, We\npresent an algorithm for automatic misspelled Bengali word generation from\ncorrect word through analyzing Bengali writing pattern using QWERTY layout\nEnglish keyboard. As part of our analysis, we have formed a list of most\ncommonly used Bengali words, phonetically similar replaceable clusters,\nfrequently mispressed replaceable clusters, frequently mispressed insertion\nprone clusters and some rules for Juktakkhar (constant letter clusters)\nhandling while generating errors.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 01:52:19 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 15:49:16 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Sifat", "Md. Habibur Rahman", ""], ["Rahman", "Chowdhury Rafeed", ""], ["Rafsan", "Mohammad", ""], ["Rahman", "Md. Hasibur", ""]]}, {"id": "2003.03504", "submitter": "Ting-En Lin", "authors": "Ting-En Lin, Hua Xu", "title": "A Post-processing Method for Detecting Unknown Intent of Dialogue System\n  via Pre-trained Deep Neural Network Classifier", "comments": "Published in Knowledge-Based Systems 2019", "journal-ref": null, "doi": "10.1016/j.knosys.2019.104979", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the maturity and popularity of dialogue systems, detecting user's\nunknown intent in dialogue systems has become an important task. It is also one\nof the most challenging tasks since we can hardly get examples, prior knowledge\nor the exact numbers of unknown intents. In this paper, we propose SofterMax\nand deep novelty detection (SMDN), a simple yet effective post-processing\nmethod for detecting unknown intent in dialogue systems based on pre-trained\ndeep neural network classifiers. Our method can be flexibly applied on top of\nany classifiers trained in deep neural networks without changing the model\narchitecture. We calibrate the confidence of the softmax outputs to compute the\ncalibrated confidence score (i.e., SofterMax) and use it to calculate the\ndecision boundary for unknown intent detection. Furthermore, we feed the\nfeature representations learned by the deep neural networks into traditional\nnovelty detection algorithm to detect unknown intents from different\nperspectives. Finally, we combine the methods above to perform the joint\nprediction. Our method classifies examples that differ from known intents as\nunknown and does not require any examples or prior knowledge of it. We have\nconducted extensive experiments on three benchmark dialogue datasets. The\nresults show that our method can yield significant improvements compared with\nthe state-of-the-art baselines\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 03:29:01 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Lin", "Ting-En", ""], ["Xu", "Hua", ""]]}, {"id": "2003.03507", "submitter": "Hongliang Bi", "authors": "Hongliang Bi, Pengyuan Liu", "title": "ECSP: A New Task for Emotion-Cause Span-Pair Extraction and\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion cause analysis such as emotion cause extraction (ECE) and\nemotion-cause pair extraction (ECPE) have gradually attracted the attention of\nmany researchers. However, there are still two shortcomings in the existing\nresearch: 1) In most cases, emotion expression and cause are not the whole\nclause, but the span in the clause, so extracting the clause-pair rather than\nthe span-pair greatly limits its applications in real-world scenarios; 2) It is\nnot enough to extract the emotion expression clause without identifying the\nemotion categories, the presence of emotion clause does not necessarily convey\nemotional information explicitly due to different possible causes. In this\npaper, we propose a new task: Emotion-Cause Span-Pair extraction and\nclassification (ECSP), which aims to extract the potential span-pair of emotion\nand corresponding causes in a document, and make emotion classification for\neach pair. In the new ECSP task, ECE and ECPE can be regarded as two special\ncases at the clause-level. We propose a span-based extract-then-classify (ETC)\nmodel, where emotion and cause are directly extracted and paired from the\ndocument under the supervision of target span boundaries, and corresponding\ncategories are then classified using their pair representations and localized\ncontext. Experiments show that our proposed ETC model outperforms the SOTA\nmodel of ECE and ECPE task respectively and gets a fair-enough results on ECSP\ntask.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 03:36:47 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Bi", "Hongliang", ""], ["Liu", "Pengyuan", ""]]}, {"id": "2003.03556", "submitter": "Eug\\'enio Ribeiro", "authors": "Eug\\'enio Ribeiro, Ricardo Ribeiro, and David Martins de Matos", "title": "Automatic Recognition of the General-Purpose Communicative Functions\n  defined by the ISO 24617-2 Standard for Dialog Act Annotation", "comments": "30 pages, 4 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ISO 24617-2, the standard for dialog act annotation, defines a hierarchically\norganized set of general-purpose communicative functions. The automatic\nrecognition of these functions, although practically unexplored, is relevant\nfor a dialog system, since they provide cues regarding the intention behind the\nsegments and how they should be interpreted. We explore the recognition of\ngeneral-purpose communicative functions in the DialogBank, which is a reference\nset of dialogs annotated according to this standard. To do so, we propose\nadaptations of existing approaches to flat dialog act recognition that allow\nthem to deal with the hierarchical classification problem. More specifically,\nwe propose the use of a hierarchical network with cascading outputs and maximum\na posteriori path estimation to predict the communicative function at each\nlevel of the hierarchy, preserve the dependencies between the functions in the\npath, and decide at which level to stop. Furthermore, since the amount of\ndialogs in the DialogBank is reduced, we rely on transfer learning processes to\nreduce overfitting and improve performance. The results of our experiments show\nthat the hierarchical approach outperforms a flat one and that each of its\ncomponents plays an important role towards the recognition of general-purpose\ncommunicative functions.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 11:21:03 GMT"}, {"version": "v2", "created": "Sat, 16 Jan 2021 14:00:27 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Ribeiro", "Eug\u00e9nio", ""], ["Ribeiro", "Ricardo", ""], ["de Matos", "David Martins", ""]]}, {"id": "2003.03612", "submitter": "Katherine Van Koevering", "authors": "Katherine Van Koevering, Austin R. Benson, Jon Kleinberg", "title": "Frozen Binomials on the Web: Word Ordering and Language Conventions in\n  Online Text", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is inherent information captured in the order in which we write words\nin a list. The orderings of binomials --- lists of two words separated by `and'\nor `or' --- has been studied for more than a century. These binomials are\ncommon across many areas of speech, in both formal and informal text. In the\nlast century, numerous explanations have been given to describe what order\npeople use for these binomials, from differences in semantics to differences in\nphonology. These rules describe primarily `frozen' binomials that exist in\nexactly one ordering and have lacked large-scale trials to determine efficacy.\n  Online text provides a unique opportunity to study these lists in the context\nof informal text at a very large scale. In this work, we expand the view of\nbinomials to include a large-scale analysis of both frozen and non-frozen\nbinomials in a quantitative way. Using this data, we then demonstrate that most\npreviously proposed rules are ineffective at predicting binomial ordering. By\ntracking the order of these binomials across time and communities we are able\nto establish additional, unexplored dimensions central to these predictions.\n  Expanding beyond the question of individual binomials, we also explore the\nglobal structure of binomials in various communities, establishing a new model\nfor these lists and analyzing this structure for non-frozen and frozen\nbinomials. Additionally, novel analysis of trinomials --- lists of length three\n--- suggests that none of the binomials analysis applies in these cases.\nFinally, we demonstrate how large data sets gleaned from the web can be used in\nconjunction with older theories to expand and improve on old questions.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 17:22:52 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Van Koevering", "Katherine", ""], ["Benson", "Austin R.", ""], ["Kleinberg", "Jon", ""]]}, {"id": "2003.03623", "submitter": "Swati Padhee", "authors": "Amit Sheth, Swati Padhee, Amelie Gyrard", "title": "Knowledge Graphs and Knowledge Networks: The Story in Brief", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graphs (KGs) represent real-world noisy raw information in a\nstructured form, capturing relationships between entities. However, for dynamic\nreal-world applications such as social networks, recommender systems,\ncomputational biology, relational knowledge representation has emerged as a\nchallenging research problem where there is a need to represent the changing\nnodes, attributes, and edges over time. The evolution of search engine\nresponses to user queries in the last few years is partly because of the role\nof KGs such as Google KG. KGs are significantly contributing to various AI\napplications from link prediction, entity relations prediction, node\nclassification to recommendation and question answering systems. This article\nis an attempt to summarize the journey of KG for AI.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 18:09:18 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Sheth", "Amit", ""], ["Padhee", "Swati", ""], ["Gyrard", "Amelie", ""]]}, {"id": "2003.03645", "submitter": "Nabiha Asghar", "authors": "Nabiha Asghar, Ivan Kobyzev, Jesse Hoey, Pascal Poupart, and Muhammad\n  Bilal Sheikh", "title": "Generating Emotionally Aligned Responses in Dialogues using Affect\n  Control Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art neural dialogue systems excel at syntactic and semantic\nmodelling of language, but often have a hard time establishing emotional\nalignment with the human interactant during a conversation. In this work, we\nbring Affect Control Theory (ACT), a socio-mathematical model of emotions for\nhuman-human interactions, to the neural dialogue generation setting. ACT makes\npredictions about how humans respond to emotional stimuli in social situations.\nDue to this property, ACT and its derivative probabilistic models have been\nsuccessfully deployed in several applications of Human-Computer Interaction,\nincluding empathetic tutoring systems, assistive healthcare devices and\ntwo-person social dilemma games. We investigate how ACT can be used to develop\naffect-aware neural conversational agents, which produce emotionally aligned\nresponses to prompts and take into consideration the affective identities of\nthe interactants.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 19:31:08 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 06:46:25 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Asghar", "Nabiha", ""], ["Kobyzev", "Ivan", ""], ["Hoey", "Jesse", ""], ["Poupart", "Pascal", ""], ["Sheikh", "Muhammad Bilal", ""]]}, {"id": "2003.03654", "submitter": "Noel Kennedy", "authors": "Noel Kennedy, Imogen Schofield, Dave C. Brodbelt, David B. Church, Dan\n  G. O'Neill", "title": "Discovering linguistic (ir)regularities in word embeddings through\n  max-margin separating hyperplanes", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We experiment with new methods for learning how related words are positioned\nrelative to each other in word embedding spaces. Previous approaches learned\nconstant vector offsets: vectors that point from source tokens to target tokens\nwith an assumption that these offsets were parallel to each other. We show that\nthe offsets between related tokens are closer to orthogonal than parallel, and\nthat they have low cosine similarities. We proceed by making a different\nassumption; target tokens are linearly separable from source and un-labeled\ntokens. We show that a max-margin hyperplane can separate target tokens and\nthat vectors orthogonal to this hyperplane represent the relationship between\nsource and targets. We find that this representation of the relationship\nobtains the best results in dis-covering linguistic regularities. We experiment\nwith vector space models trained by a variety of algorithms (Word2vec:\nCBOW/skip-gram, fastText, or GloVe), and various word context choices such as\nlinear word-order, syntax dependency grammars, and with and without knowledge\nof word position. These experiments show that our model, SVMCos, is robust to a\nrange of experimental choices when training word embeddings.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 20:21:50 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Kennedy", "Noel", ""], ["Schofield", "Imogen", ""], ["Brodbelt", "Dave C.", ""], ["Church", "David B.", ""], ["O'Neill", "Dan G.", ""]]}, {"id": "2003.03666", "submitter": "Juntao Yu", "authors": "Juntao Yu and Massimo Poesio", "title": "Multi-task Learning Based Neural Bridging Reference Resolution", "comments": "accepted by COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a multi task learning-based neural model for resolving bridging\nreferences tackling two key challenges. The first challenge is the lack of\nlarge corpora annotated with bridging references. To address this, we use\nmulti-task learning to help bridging reference resolution with coreference\nresolution. We show that substantial improvements of up to 8 p.p. can be\nachieved on full bridging resolution with this architecture. The second\nchallenge is the different definitions of bridging used in different corpora,\nmeaning that hand-coded systems or systems using special features designed for\none corpus do not work well with other corpora. Our neural model only uses a\nsmall number of corpus independent features, thus can be applied to different\ncorpora. Evaluations with very different bridging corpora (ARRAU, ISNOTES,\nBASHI and SCICORP) suggest that our architecture works equally well on all\ncorpora, and achieves the SoTA results on full bridging resolution for all\ncorpora, outperforming the best reported results by up to 36.3 p.p..\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 21:21:29 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2020 11:09:40 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Yu", "Juntao", ""], ["Poesio", "Massimo", ""]]}, {"id": "2003.03667", "submitter": "Thayer Alshaabi", "authors": "Thayer Alshaabi, David R. Dewhurst, Joshua R. Minot, Michael V.\n  Arnold, Jane L. Adams, Christopher M. Danforth, and Peter Sheridan Dodds", "title": "The growing amplification of social media: Measuring temporal and social\n  contagion dynamics for over 150 languages on Twitter for 2009-2020", "comments": "26 pages (15 main, 11 appendix), 13 figures (6 main, 7 appendix), and\n  4 online appendices available at\n  http://compstorylab.org/storywrangler/papers/tlid/", "journal-ref": null, "doi": "10.1140/epjds/s13688-021-00271-0", "report-no": null, "categories": "cs.CL cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Working from a dataset of 118 billion messages running from the start of 2009\nto the end of 2019, we identify and explore the relative daily use of over 150\nlanguages on Twitter. We find that eight languages comprise 80% of all tweets,\nwith English, Japanese, Spanish, and Portuguese being the most dominant. To\nquantify social spreading in each language over time, we compute the 'contagion\nratio': The balance of retweets to organic messages. We find that for the most\ncommon languages on Twitter there is a growing tendency, though not universal,\nto retweet rather than share new content. By the end of 2019, the contagion\nratios for half of the top 30 languages, including English and Spanish, had\nreached above 1 -- the naive contagion threshold. In 2019, the top 5 languages\nwith the highest average daily ratios were, in order, Thai (7.3), Hindi, Tamil,\nUrdu, and Catalan, while the bottom 5 were Russian, Swedish, Esperanto,\nCebuano, and Finnish (0.26). Further, we show that over time, the contagion\nratios for most common languages are growing more strongly than those of rare\nlanguages.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 21:42:50 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 04:43:52 GMT"}, {"version": "v3", "created": "Fri, 10 Jul 2020 14:49:46 GMT"}, {"version": "v4", "created": "Wed, 30 Sep 2020 21:40:16 GMT"}, {"version": "v5", "created": "Mon, 16 Nov 2020 22:44:32 GMT"}, {"version": "v6", "created": "Mon, 7 Dec 2020 20:29:26 GMT"}, {"version": "v7", "created": "Wed, 20 Jan 2021 16:21:27 GMT"}, {"version": "v8", "created": "Tue, 9 Mar 2021 03:32:41 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Alshaabi", "Thayer", ""], ["Dewhurst", "David R.", ""], ["Minot", "Joshua R.", ""], ["Arnold", "Michael V.", ""], ["Adams", "Jane L.", ""], ["Danforth", "Christopher M.", ""], ["Dodds", "Peter Sheridan", ""]]}, {"id": "2003.03716", "submitter": "Yu-Siang Wang", "authors": "Yu-Siang Wang, Yen-Ling Kuo, Boris Katz", "title": "Investigating the Decoders of Maximum Likelihood Sequence Models: A\n  Look-ahead Approach", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate how we can practically incorporate multi-step future\ninformation into a decoder of maximum likelihood sequence models. We propose a\n\"k-step look-ahead\" module to consider the likelihood information of a rollout\nup to k steps. Unlike other approaches that need to train another value network\nto evaluate the rollouts, we can directly apply this look-ahead module to\nimprove the decoding of any sequence model trained in a maximum likelihood\nframework. We evaluate our look-ahead module on three datasets of varying\ndifficulties: IM2LATEX-100k OCR image to LaTeX, WMT16 multimodal machine\ntranslation, and WMT14 machine translation. Our look-ahead module improves the\nperformance of the simpler datasets such as IM2LATEX-100k and WMT16 multimodal\nmachine translation. However, the improvement of the more difficult dataset\n(e.g., containing longer sequences), WMT14 machine translation, becomes\nmarginal. Our further investigation using the k-step look-ahead suggests that\nthe more difficult tasks suffer from the overestimated EOS (end-of-sentence)\nprobability. We argue that the overestimated EOS probability also causes the\ndecreased performance of beam search when increasing its beam width. We tackle\nthe EOS problem by integrating an auxiliary EOS loss into the training to\nestimate if the model should emit EOS or other words. Our experiments show that\nimproving EOS estimation not only increases the performance of our proposed\nlook-ahead module but also the robustness of the beam search.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 04:36:04 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Wang", "Yu-Siang", ""], ["Kuo", "Yen-Ling", ""], ["Katz", "Boris", ""]]}, {"id": "2003.03728", "submitter": "Joo-Kyung Kim", "authors": "Joo-Kyung Kim and Young-Bum Kim", "title": "Pseudo Labeling and Negative Feedback Learning for Large-scale\n  Multi-label Domain Classification", "comments": "ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In large-scale domain classification, an utterance can be handled by multiple\ndomains with overlapped capabilities. However, only a limited number of\nground-truth domains are provided for each training utterance in practice while\nknowing as many as correct target labels is helpful for improving the model\nperformance. In this paper, given one ground-truth domain for each training\nutterance, we regard domains consistently predicted with the highest\nconfidences as additional pseudo labels for the training. In order to reduce\nprediction errors due to incorrect pseudo labels, we leverage utterances with\nnegative system responses to decrease the confidences of the incorrectly\npredicted domains. Evaluating on user utterances from an intelligent\nconversational system, we show that the proposed approach significantly\nimproves the performance of domain classification with hypothesis reranking.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 06:00:15 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Kim", "Joo-Kyung", ""], ["Kim", "Young-Bum", ""]]}, {"id": "2003.03734", "submitter": "Gong Cheng", "authors": "Qingxia Liu, Gong Cheng, Kalpa Gunaratna, Yuzhong Qu", "title": "ESBM: An Entity Summarization BenchMark", "comments": "16 pages, accepted to the Resource Track of ESWC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Entity summarization is the problem of computing an optimal compact summary\nfor an entity by selecting a size-constrained subset of triples from RDF data.\nEntity summarization supports a multiplicity of applications and has led to\nfruitful research. However, there is a lack of evaluation efforts that cover\nthe broad spectrum of existing systems. One reason is a lack of benchmarks for\nevaluation. Some benchmarks are no longer available, while others are small and\nhave limitations. In this paper, we create an Entity Summarization BenchMark\n(ESBM) which overcomes the limitations of existing benchmarks and meets\nstandard desiderata for a benchmark. Using this largest available benchmark for\nevaluating general-purpose entity summarizers, we perform the most extensive\nexperiment to date where 9~existing systems are compared. Considering that all\nof these systems are unsupervised, we also implement and evaluate a supervised\nlearning based system for reference.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 07:12:20 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Liu", "Qingxia", ""], ["Cheng", "Gong", ""], ["Gunaratna", "Kalpa", ""], ["Qu", "Yuzhong", ""]]}, {"id": "2003.03736", "submitter": "Gong Cheng", "authors": "Qingxia Liu, Gong Cheng, Yuzhong Qu", "title": "DeepLENS: Deep Learning for Entity Summarization", "comments": "6 pages, submitted to DL4KG 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Entity summarization has been a prominent task over knowledge graphs. While\nexisting methods are mainly unsupervised, we present DeepLENS, a simple yet\neffective deep learning model where we exploit textual semantics for encoding\ntriples and we score each candidate triple based on its interdependence on\nother triples. DeepLENS significantly outperformed existing methods on a public\nbenchmark.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 07:15:48 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Liu", "Qingxia", ""], ["Cheng", "Gong", ""], ["Qu", "Yuzhong", ""]]}, {"id": "2003.03813", "submitter": "Petar Milin", "authors": "Petar Milin, Harish Tayyar Madabushi, Michael Croucher, Dagmar Divjak", "title": "Keeping it simple: Implementation and performance of the proto-principle\n  of adaptation and learning in the language sciences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the Widrow-Hoff rule and its applications to\nlanguage data. After contextualizing the rule historically and placing it in\nthe chain of neurally inspired artificial learning models, we explain its\nrationale and implementational considerations. Using a number of case studies\nwe illustrate how the Widrow-Hoff rule offers unexpected opportunities for the\ncomputational simulation of a range of language phenomena that make it possible\nto approach old problems from a novel perspective.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 17:07:08 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Milin", "Petar", ""], ["Madabushi", "Harish Tayyar", ""], ["Croucher", "Michael", ""], ["Divjak", "Dagmar", ""]]}, {"id": "2003.03862", "submitter": "Abubakar Abid", "authors": "Abubakar Abid, James Zou", "title": "Improving Training on Noisy Stuctured Labels", "comments": "8 pages main text, 13 pages total", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-grained annotations---e.g. dense image labels, image segmentation and\ntext tagging---are useful in many ML applications but they are labor-intensive\nto generate. Moreover there are often systematic, structured errors in these\nfine-grained annotations. For example, a car might be entirely unannotated in\nthe image, or the boundary between a car and street might only be coarsely\nannotated. Standard ML training on data with such structured errors produces\nmodels with biases and poor performance. In this work, we propose a novel\nframework of Error-Correcting Networks (ECN) to address the challenge of\nlearning in the presence structured error in fine-grained annotations. Given a\nlarge noisy dataset with commonly occurring structured errors, and a much\nsmaller dataset with more accurate annotations, ECN is able to substantially\nimprove the prediction of fine-grained annotations compared to standard\napproaches for training on noisy data. It does so by learning to leverage the\nstructures in the annotations and in the noisy labels. Systematic experiments\non image segmentation and text tagging demonstrate the strong performance of\nECN in improving training on noisy structured labels.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 22:55:11 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Abid", "Abubakar", ""], ["Zou", "James", ""]]}, {"id": "2003.03875", "submitter": "Xianpei Han", "authors": "Xianpei Han, Zhichun Wang, Jiangtao Zhang, Qinghua Wen, Wenqi Li,\n  Buzhou Tang, Qi Wang, Zhifan Feng, Yang Zhang, Yajuan Lu, Haitao Wang,\n  Wenliang Chen, Hao Shao, Yubo Chen, Kang Liu, Jun Zhao, Taifeng Wang, Kezun\n  Zhang, Meng Wang, Yinlin Jiang, Guilin Qi, Lei Zou, Sen Hu, Minhao Zhang,\n  Yinnian Lin", "title": "Overview of the CCKS 2019 Knowledge Graph Evaluation Track: Entity,\n  Relation, Event and QA", "comments": "21 pages, in Chinese, 9 figures and 17 tables, CCKS 2019 held an\n  evaluation track about knowledge graph with 6 tasks and attracted more than\n  1,600 teams", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph models world knowledge as concepts, entities, and the\nrelationships between them, which has been widely used in many real-world\ntasks. CCKS 2019 held an evaluation track with 6 tasks and attracted more than\n1,600 teams. In this paper, we give an overview of the knowledge graph\nevaluation tract at CCKS 2019. By reviewing the task definition, successful\nmethods, useful resources, good strategies and research challenges associated\nwith each task in CCKS 2019, this paper can provide a helpful reference for\ndeveloping knowledge graph applications and conducting future knowledge graph\nresearches.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 00:32:13 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Han", "Xianpei", ""], ["Wang", "Zhichun", ""], ["Zhang", "Jiangtao", ""], ["Wen", "Qinghua", ""], ["Li", "Wenqi", ""], ["Tang", "Buzhou", ""], ["Wang", "Qi", ""], ["Feng", "Zhifan", ""], ["Zhang", "Yang", ""], ["Lu", "Yajuan", ""], ["Wang", "Haitao", ""], ["Chen", "Wenliang", ""], ["Shao", "Hao", ""], ["Chen", "Yubo", ""], ["Liu", "Kang", ""], ["Zhao", "Jun", ""], ["Wang", "Taifeng", ""], ["Zhang", "Kezun", ""], ["Wang", "Meng", ""], ["Jiang", "Yinlin", ""], ["Qi", "Guilin", ""], ["Zou", "Lei", ""], ["Hu", "Sen", ""], ["Zhang", "Minhao", ""], ["Lin", "Yinnian", ""]]}, {"id": "2003.04032", "submitter": "Xinyi Cai", "authors": "Wanqiu Long, Xinyi Cai, James E. M. Reid, Bonnie Webber, Deyi Xiong", "title": "Shallow Discourse Annotation for Chinese TED Talks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text corpora annotated with language-related properties are an important\nresource for the development of Language Technology. The current work\ncontributes a new resource for Chinese Language Technology and for\nChinese-English translation, in the form of a set of TED talks (some originally\ngiven in English, some in Chinese) that have been annotated with discourse\nrelations in the style of the Penn Discourse TreeBank, adapted to properties of\nChinese text that are not present in English. The resource is currently unique\nin annotating discourse-level properties of planned spoken monologues rather\nthan of written text. An inter-annotator agreement study demonstrates that the\nannotation scheme is able to achieve highly reliable results.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 10:50:16 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 15:05:37 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Long", "Wanqiu", ""], ["Cai", "Xinyi", ""], ["Reid", "James E. M.", ""], ["Webber", "Bonnie", ""], ["Xiong", "Deyi", ""]]}, {"id": "2003.04036", "submitter": "Gerard De Melo", "authors": "Xunjie Zhu, Gerard de Melo", "title": "Sentence Analogies: Exploring Linguistic Relationships and Regularities\n  in Sentence Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While important properties of word vector representations have been studied\nextensively, far less is known about the properties of sentence vector\nrepresentations. Word vectors are often evaluated by assessing to what degree\nthey exhibit regularities with regard to relationships of the sort considered\nin word analogies. In this paper, we investigate to what extent commonly used\nsentence vector representation spaces as well reflect certain kinds of\nregularities. We propose a number of schemes to induce evaluation data, based\non lexical analogy data as well as semantic relationships between sentences.\nOur experiments consider a wide range of sentence embedding methods, including\nones based on BERT-style contextual embeddings. We find that different models\ndiffer substantially in their ability to reflect such regularities.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 10:58:38 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Zhu", "Xunjie", ""], ["de Melo", "Gerard", ""]]}, {"id": "2003.04038", "submitter": "Peng Wang", "authors": "Xiang Li and Peng Wang", "title": "TEDL: A Text Encryption Method Based on Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen an increasing emphasis on information security, and\nvarious encryption methods have been proposed. However, for symmetric\nencryption methods, the well-known encryption techniques still rely on the key\nspace to guarantee security and suffer from frequent key updating. Aiming to\nsolve those problems, this paper proposes a novel text encryption method based\non deep learning called TEDL, where the secret key includes hyperparameters in\ndeep learning model and the core step of encryption is transforming input data\ninto weights trained under hyperparameters. Firstly, both communication parties\nestablish a word vector table by training a deep learning model according to\nspecified hyperparameters. Then, a self-update codebook is constructed on the\nword vector table with the SHA-256 function and other tricks. When\ncommunication starts, encryption and decryption are equivalent to indexing and\ninverted indexing on the codebook, respectively, thus achieving the\ntransformation between plaintext and ciphertext. Results of experiments and\nrelevant analyses show that TEDL performs well for security, efficiency,\ngenerality, and has a lower demand for the frequency of key redistribution.\nEspecially, as a supplement to current encryption methods, the time-consuming\nprocess of constructing a codebook increases the difficulty of brute-force\nattacks while not degrade the communication efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 11:04:36 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 03:47:14 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Li", "Xiang", ""], ["Wang", "Peng", ""]]}, {"id": "2003.04073", "submitter": "Tobias Daudert", "authors": "Tobias Daudert", "title": "A Multi-Source Entity-Level Sentiment Corpus for the Financial Domain:\n  The FinLin Corpus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce FinLin, a novel corpus containing investor reports, company\nreports, news articles, and microblogs from StockTwits, targeting multiple\nentities stemming from the automobile industry and covering a 3-month period.\nFinLin was annotated with a sentiment score and a relevance score in the range\n[-1.0, 1.0] and [0.0, 1.0], respectively. The annotations also include the text\nspans selected for the sentiment, thus, providing additional insight into the\nannotators' reasoning. Overall, FinLin aims to complement the current knowledge\nby providing a novel and publicly available financial sentiment corpus and to\nfoster research on the topic of financial sentiment analysis and potential\napplications in behavioural science.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 12:34:48 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Daudert", "Tobias", ""]]}, {"id": "2003.04195", "submitter": "Piji Li", "authors": "Piji Li", "title": "An Empirical Investigation of Pre-Trained Transformer Language Models\n  for Open-Domain Dialogue Generation", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an empirical investigation of pre-trained Transformer-based\nauto-regressive language models for the task of open-domain dialogue\ngeneration. Training paradigm of pre-training and fine-tuning is employed to\nconduct the parameter learning. Corpora of News and Wikipedia in Chinese and\nEnglish are collected for the pre-training stage respectively. Dialogue context\nand response are concatenated into a single sequence utilized as the input of\nthe models during the fine-tuning stage. A weighted joint prediction paradigm\nfor both context and response is designed to evaluate the performance of models\nwith or without the loss term for context prediction. Various of decoding\nstrategies such as greedy search, beam search, top-k sampling, etc. are\nemployed to conduct the response text generation. Extensive experiments are\nconducted on the typical single-turn and multi-turn dialogue corpora such as\nWeibo, Douban, Reddit, DailyDialog, and Persona-Chat. Detailed numbers of\nautomatic evaluation metrics on relevance and diversity of the generated\nresults for the languages models as well as the baseline approaches are\nreported.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 15:20:21 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Li", "Piji", ""]]}, {"id": "2003.04360", "submitter": "Pushpender Singh", "authors": "Vaishali Ingale, Pushpender Singh", "title": "GenNet : Reading Comprehension with Multiple Choice Questions using\n  Generation and Selection model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multiple-choice machine reading comprehension is difficult task as its\nrequired machines to select the correct option from a set of candidate or\npossible options using the given passage and question.Reading Comprehension\nwith Multiple Choice Questions task,required a human (or machine) to read a\ngiven passage, question pair and select the best one option from n given\noptions. There are two different ways to select the correct answer from the\ngiven passage. Either by selecting the best match answer to by eliminating the\nworst match answer. Here we proposed GenNet model, a neural network-based\nmodel. In this model first we will generate the answer of the question from the\npassage and then will matched the generated answer with given answer, the best\nmatched option will be our answer. For answer generation we used S-net (Tan et\nal., 2017) model trained on SQuAD and to evaluate our model we used Large-scale\nRACE (ReAding Comprehension Dataset From Examinations) (Lai et al.,2017).\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 20:35:36 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 06:49:32 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Ingale", "Vaishali", ""], ["Singh", "Pushpender", ""]]}, {"id": "2003.04419", "submitter": "Machel Reid", "authors": "Machel Reid, Edison Marrese-Taylor and Yutaka Matsuo", "title": "Combining Pretrained High-Resource Embeddings and Subword\n  Representations for Low-Resource Languages", "comments": "Accepted to the \"AfricaNLP - Unlocking Local Languages\" workshop at\n  ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The contrast between the need for large amounts of data for current Natural\nLanguage Processing (NLP) techniques, and the lack thereof, is accentuated in\nthe case of African languages, most of which are considered low-resource. To\nhelp circumvent this issue, we explore techniques exploiting the qualities of\nmorphologically rich languages (MRLs), while leveraging pretrained word vectors\nin well-resourced languages. In our exploration, we show that a meta-embedding\napproach combining both pretrained and morphologically-informed word embeddings\nperforms best in the downstream task of Xhosa-English translation.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 21:30:55 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 07:34:52 GMT"}, {"version": "v3", "created": "Tue, 21 Apr 2020 09:43:53 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Reid", "Machel", ""], ["Marrese-Taylor", "Edison", ""], ["Matsuo", "Yutaka", ""]]}, {"id": "2003.04567", "submitter": "Ronen Tamari", "authors": "Ronen Tamari, Gabriel Stanovsky, Dafna Shahaf and Reut Tsarfaty", "title": "Ecological Semantics: Programming Environments for Situated Language\n  Understanding", "comments": "Camera ready for Bridging AI and Cognitive Science (BAICS) workshop\n  at ICLR2020. For interactive demos, see https://eco-sem.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale natural language understanding (NLU) systems have made impressive\nprogress: they can be applied flexibly across a variety of tasks, and employ\nminimal structural assumptions. However, extensive empirical research has shown\nthis to be a double-edged sword, coming at the cost of shallow understanding:\ninferior generalization, grounding and explainability. Grounded language\nlearning approaches offer the promise of deeper understanding by situating\nlearning in richer, more structured training environments, but are limited in\nscale to relatively narrow, predefined domains. How might we enjoy the best of\nboth worlds: grounded, general NLU? Following extensive contemporary cognitive\nscience, we propose treating environments as \"first-class citizens\" in semantic\nrepresentations, worthy of research and development in their own right.\nImportantly, models should also be partners in the creation and configuration\nof environments, rather than just actors within them, as in existing\napproaches. To do so, we argue that models must begin to understand and program\nin the language of affordances (which define possible actions in a given\nsituation) both for online, situated discourse comprehension, as well as\nlarge-scale, offline common-sense knowledge mining. To this end we propose an\nenvironment-oriented ecological semantics, outlining theoretical and practical\napproaches towards implementation. We further provide actual demonstrations\nbuilding upon interactive fiction programming languages.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 08:24:41 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 07:48:05 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Tamari", "Ronen", ""], ["Stanovsky", "Gabriel", ""], ["Shahaf", "Dafna", ""], ["Tsarfaty", "Reut", ""]]}, {"id": "2003.04642", "submitter": "Viktor Schlegel", "authors": "Viktor Schlegel, Marco Valentino, Andr\\'e Freitas, Goran Nenadic, Riza\n  Batista-Navarro", "title": "A Framework for Evaluation of Machine Reading Comprehension Gold\n  Standards", "comments": "In Proceedings of the 12th International Conference on Language\n  Resources and Evaluation (LREC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Reading Comprehension (MRC) is the task of answering a question over\na paragraph of text. While neural MRC systems gain popularity and achieve\nnoticeable performance, issues are being raised with the methodology used to\nestablish their performance, particularly concerning the data design of gold\nstandards that are used to evaluate them. There is but a limited understanding\nof the challenges present in this data, which makes it hard to draw comparisons\nand formulate reliable hypotheses. As a first step towards alleviating the\nproblem, this paper proposes a unifying framework to systematically investigate\nthe present linguistic features, required reasoning and background knowledge\nand factual correctness on one hand, and the presence of lexical cues as a\nlower bound for the requirement of understanding on the other hand. We propose\na qualitative annotation schema for the first and a set of approximative\nmetrics for the latter. In a first application of the framework, we analyse\nmodern MRC gold standards and present our findings: the absence of features\nthat contribute towards lexical ambiguity, the varying factual correctness of\nthe expected answers and the presence of lexical cues, all of which potentially\nlower the reading comprehension complexity and quality of the evaluation data.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 11:30:22 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Schlegel", "Viktor", ""], ["Valentino", "Marco", ""], ["Freitas", "Andr\u00e9", ""], ["Nenadic", "Goran", ""], ["Batista-Navarro", "Riza", ""]]}, {"id": "2003.04679", "submitter": "Shen Gao", "authors": "Shen Gao, Xiuying Chen, Chang Liu, Li Liu, Dongyan Zhao and Rui Yan", "title": "Learning to Respond with Stickers: A Framework of Unifying\n  Multi-Modality in Multi-Turn Dialog", "comments": "Accepted by The Web Conference 2020 (WWW 2020). Equal contribution\n  from first two authors. Dataset and code are released at\n  https://github.com/gsh199449/stickerchat", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stickers with vivid and engaging expressions are becoming increasingly\npopular in online messaging apps, and some works are dedicated to automatically\nselect sticker response by matching text labels of stickers with previous\nutterances. However, due to their large quantities, it is impractical to\nrequire text labels for the all stickers. Hence, in this paper, we propose to\nrecommend an appropriate sticker to user based on multi-turn dialog context\nhistory without any external labels. Two main challenges are confronted in this\ntask. One is to learn semantic meaning of stickers without corresponding text\nlabels. Another challenge is to jointly model the candidate sticker with the\nmulti-turn dialog context. To tackle these challenges, we propose a sticker\nresponse selector (SRS) model. Specifically, SRS first employs a convolutional\nbased sticker image encoder and a self-attention based multi-turn dialog\nencoder to obtain the representation of stickers and utterances. Next, deep\ninteraction network is proposed to conduct deep matching between the sticker\nwith each utterance in the dialog history. SRS then learns the short-term and\nlong-term dependency between all interaction results by a fusion network to\noutput the the final matching score. To evaluate our proposed method, we\ncollect a large-scale real-world dialog dataset with stickers from one of the\nmost popular online chatting platform. Extensive experiments conducted on this\ndataset show that our model achieves the state-of-the-art performance for all\ncommonly-used metrics. Experiments also verify the effectiveness of each\ncomponent of SRS. To facilitate further research in sticker selection field, we\nrelease this dataset of 340K multi-turn dialog and sticker pairs.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 13:10:26 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Gao", "Shen", ""], ["Chen", "Xiuying", ""], ["Liu", "Chang", ""], ["Liu", "Li", ""], ["Zhao", "Dongyan", ""], ["Yan", "Rui", ""]]}, {"id": "2003.04707", "submitter": "Jonathan Francis", "authors": "Alessandro Oltramari, Jonathan Francis, Cory Henson, Kaixin Ma, and\n  Ruwan Wickramarachchi", "title": "Neuro-symbolic Architectures for Context Understanding", "comments": "In: Ilaria Tiddi, Freddy Lecue, Pascal Hitzler (eds.), Knowledge\n  Graphs for eXplainable AI -- Foundations, Applications and Challenges.\n  Studies on the Semantic Web, IOS Press, Amsterdam, 2020. arXiv admin note:\n  text overlap with arXiv:1910.14087", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational context understanding refers to an agent's ability to fuse\ndisparate sources of information for decision-making and is, therefore,\ngenerally regarded as a prerequisite for sophisticated machine reasoning\ncapabilities, such as in artificial intelligence (AI). Data-driven and\nknowledge-driven methods are two classical techniques in the pursuit of such\nmachine sense-making capability. However, while data-driven methods seek to\nmodel the statistical regularities of events by making observations in the\nreal-world, they remain difficult to interpret and they lack mechanisms for\nnaturally incorporating external knowledge. Conversely, knowledge-driven\nmethods, combine structured knowledge bases, perform symbolic reasoning based\non axiomatic principles, and are more interpretable in their inferential\nprocessing; however, they often lack the ability to estimate the statistical\nsalience of an inference. To combat these issues, we propose the use of hybrid\nAI methodology as a general framework for combining the strengths of both\napproaches. Specifically, we inherit the concept of neuro-symbolism as a way of\nusing knowledge-bases to guide the learning progress of deep neural networks.\nWe further ground our discussion in two applications of neuro-symbolism and, in\nboth cases, show that our systems maintain interpretability while achieving\ncomparable performance, relative to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 15:04:07 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Oltramari", "Alessandro", ""], ["Francis", "Jonathan", ""], ["Henson", "Cory", ""], ["Ma", "Kaixin", ""], ["Wickramarachchi", "Ruwan", ""]]}, {"id": "2003.04748", "submitter": "Jean-Marc Luck", "authors": "Jean-Marc Luck and Anita Mehta", "title": "On the coexistence of competing languages", "comments": "18 pages, 12 figures, 47 references. To appear in EPJ B", "journal-ref": "Eur. Phys. J. B (2020) 93, 73", "doi": "10.1140/epjb/e2020-10038-1", "report-no": null, "categories": "cond-mat.stat-mech cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the evolution of competing languages, a subject where much\nprevious literature suggests that the outcome is always the domination of one\nlanguage over all the others. Since coexistence of languages is observed in\nreality, we here revisit the question of language competition, with an emphasis\non uncovering the ways in which coexistence might emerge. We find that this\nemergence is related to symmetry breaking, and explore two particular scenarios\n-- the first relating to an imbalance in the population dynamics of language\nspeakers in a single geographical area, and the second to do with spatial\nheterogeneity, where language preferences are specific to different\ngeographical regions. For each of these, the investigation of paradigmatic\nsituations leads us to a quantitative understanding of the conditions leading\nto language coexistence. We also obtain predictions of the number of surviving\nlanguages as a function of various model parameters.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 14:06:55 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Luck", "Jean-Marc", ""], ["Mehta", "Anita", ""]]}, {"id": "2003.04807", "submitter": "Ivan Vuli\\'c", "authors": "I\\~nigo Casanueva, Tadas Tem\\v{c}inas, Daniela Gerz, Matthew\n  Henderson, Ivan Vuli\\'c", "title": "Efficient Intent Detection with Dual Sentence Encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building conversational systems in new domains and with added functionality\nrequires resource-efficient models that work under low-data regimes (i.e., in\nfew-shot setups). Motivated by these requirements, we introduce intent\ndetection methods backed by pretrained dual sentence encoders such as USE and\nConveRT. We demonstrate the usefulness and wide applicability of the proposed\nintent detectors, showing that: 1) they outperform intent detectors based on\nfine-tuning the full BERT-Large model or using BERT as a fixed black-box\nencoder on three diverse intent detection data sets; 2) the gains are\nespecially pronounced in few-shot setups (i.e., with only 10 or 30 annotated\nexamples per intent); 3) our intent detectors can be trained in a matter of\nminutes on a single CPU; and 4) they are stable across different hyperparameter\nsettings. In hope of facilitating and democratizing research focused on\nintention detection, we release our code, as well as a new challenging\nsingle-domain intent detection dataset comprising 13,083 annotated examples\nover 77 intents.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 15:33:54 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Casanueva", "I\u00f1igo", ""], ["Tem\u010dinas", "Tadas", ""], ["Gerz", "Daniela", ""], ["Henderson", "Matthew", ""], ["Vuli\u0107", "Ivan", ""]]}, {"id": "2003.04808", "submitter": "Johannes Welbl", "authors": "Johannes Welbl, Pasquale Minervini, Max Bartolo, Pontus Stenetorp,\n  Sebastian Riedel", "title": "Undersensitivity in Neural Reading Comprehension", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Current reading comprehension models generalise well to in-distribution test\nsets, yet perform poorly on adversarially selected inputs. Most prior work on\nadversarial inputs studies oversensitivity: semantically invariant text\nperturbations that cause a model's prediction to change when it should not. In\nthis work we focus on the complementary problem: excessive prediction\nundersensitivity, where input text is meaningfully changed but the model's\nprediction does not, even though it should. We formulate a noisy adversarial\nattack which searches among semantic variations of the question for which a\nmodel erroneously predicts the same answer, and with even higher probability.\nDespite comprising unanswerable questions, both SQuAD2.0 and NewsQA models are\nvulnerable to this attack. This indicates that although accurate, models tend\nto rely on spurious patterns and do not fully consider the information\nspecified in a question. We experiment with data augmentation and adversarial\ntraining as defences, and find that both substantially decrease vulnerability\nto attacks on held out data, as well as held out attack spaces. Addressing\nundersensitivity also improves results on AddSent and AddOneSent, and models\nfurthermore generalise better when facing train/evaluation distribution\nmismatch: they are less prone to overly rely on predictive cues present only in\nthe training set, and outperform a conventional model by as much as 10.9% F1.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 19:03:36 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Welbl", "Johannes", ""], ["Minervini", "Pasquale", ""], ["Bartolo", "Max", ""], ["Stenetorp", "Pontus", ""], ["Riedel", "Sebastian", ""]]}, {"id": "2003.04865", "submitter": "Yutaro Shigeto", "authors": "Yutaro Shigeto, Yuya Yoshikawa, Jiaqing Lin, Akikazu Takeuchi", "title": "Video Caption Dataset for Describing Human Actions in Japanese", "comments": "Accepted for LREC 2020. Dataset available at\n  https://actions.stair.center/captions.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, automatic video caption generation has attracted\nconsiderable attention. This paper focuses on the generation of Japanese\ncaptions for describing human actions. While most currently available video\ncaption datasets have been constructed for English, there is no equivalent\nJapanese dataset. To address this, we constructed a large-scale Japanese video\ncaption dataset consisting of 79,822 videos and 399,233 captions. Each caption\nin our dataset describes a video in the form of \"who does what and where.\" To\ndescribe human actions, it is important to identify the details of a person,\nplace, and action. Indeed, when we describe human actions, we usually mention\nthe scene, person, and action. In our experiments, we evaluated two caption\ngeneration methods to obtain benchmark results. Further, we investigated\nwhether those generation methods could specify \"who does what and where.\"\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 17:15:48 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Shigeto", "Yutaro", ""], ["Yoshikawa", "Yuya", ""], ["Lin", "Jiaqing", ""], ["Takeuchi", "Akikazu", ""]]}, {"id": "2003.04866", "submitter": "Ivan Vuli\\'c", "authors": "Ivan Vuli\\'c, Simon Baker, Edoardo Maria Ponti, Ulla Petti, Ira\n  Leviant, Kelly Wing, Olga Majewska, Eden Bar, Matt Malone, Thierry Poibeau,\n  Roi Reichart, Anna Korhonen", "title": "Multi-SimLex: A Large-Scale Evaluation of Multilingual and Cross-Lingual\n  Lexical Semantic Similarity", "comments": "Data and guidelines available at https://multisimlex.com/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce Multi-SimLex, a large-scale lexical resource and evaluation\nbenchmark covering datasets for 12 typologically diverse languages, including\nmajor languages (e.g., Mandarin Chinese, Spanish, Russian) as well as\nless-resourced ones (e.g., Welsh, Kiswahili). Each language dataset is\nannotated for the lexical relation of semantic similarity and contains 1,888\nsemantically aligned concept pairs, providing a representative coverage of word\nclasses (nouns, verbs, adjectives, adverbs), frequency ranks, similarity\nintervals, lexical fields, and concreteness levels. Additionally, owing to the\nalignment of concepts across languages, we provide a suite of 66 cross-lingual\nsemantic similarity datasets. Due to its extensive size and language coverage,\nMulti-SimLex provides entirely novel opportunities for experimental evaluation\nand analysis. On its monolingual and cross-lingual benchmarks, we evaluate and\nanalyze a wide array of recent state-of-the-art monolingual and cross-lingual\nrepresentation models, including static and contextualized word embeddings\n(such as fastText, M-BERT and XLM), externally informed lexical\nrepresentations, as well as fully unsupervised and (weakly) supervised\ncross-lingual word embeddings. We also present a step-by-step dataset creation\nprotocol for creating consistent, Multi-Simlex-style resources for additional\nlanguages. We make these contributions -- the public release of Multi-SimLex\ndatasets, their creation protocol, strong baseline results, and in-depth\nanalyses which can be be helpful in guiding future developments in multilingual\nlexical semantics and representation learning -- available via a website which\nwill encourage community effort in further expansion of Multi-Simlex to many\nmore languages. Such a large-scale semantic resource could inspire significant\nfurther advances in NLP across languages.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 17:17:01 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Vuli\u0107", "Ivan", ""], ["Baker", "Simon", ""], ["Ponti", "Edoardo Maria", ""], ["Petti", "Ulla", ""], ["Leviant", "Ira", ""], ["Wing", "Kelly", ""], ["Majewska", "Olga", ""], ["Bar", "Eden", ""], ["Malone", "Matt", ""], ["Poibeau", "Thierry", ""], ["Reichart", "Roi", ""], ["Korhonen", "Anna", ""]]}, {"id": "2003.04887", "submitter": "Huanru Henry Mao", "authors": "Thomas Bachlechner, Bodhisattwa Prasad Majumder, Huanru Henry Mao,\n  Garrison W. Cottrell, Julian McAuley", "title": "ReZero is All You Need: Fast Convergence at Large Depth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks often suffer from vanishing or exploding gradients due to\ninefficient signal propagation, leading to long training times or convergence\ndifficulties. Various architecture designs, sophisticated residual-style\nnetworks, and initialization schemes have been shown to improve deep signal\npropagation. Recently, Pennington et al. used free probability theory to show\nthat dynamical isometry plays an integral role in efficient deep learning. We\nshow that the simplest architecture change of gating each residual connection\nusing a single zero-initialized parameter satisfies initial dynamical isometry\nand outperforms more complex approaches. Although much simpler than its\npredecessors, this gate enables training thousands of fully connected layers\nwith fast convergence and better test performance for ResNets trained on\nCIFAR-10. We apply this technique to language modeling and find that we can\neasily train 120-layer Transformers. When applied to 12 layer Transformers, it\nconverges 56% faster on enwiki8.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 17:58:01 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 00:09:04 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Bachlechner", "Thomas", ""], ["Majumder", "Bodhisattwa Prasad", ""], ["Mao", "Huanru Henry", ""], ["Cottrell", "Garrison W.", ""], ["McAuley", "Julian", ""]]}, {"id": "2003.04967", "submitter": "Shubhankar Mohapatra", "authors": "Shubhankar Mohapatra, Nauman Ahmed and Paulo Alencar", "title": "KryptoOracle: A Real-Time Cryptocurrency Price Prediction Platform Using\n  Twitter Sentiments", "comments": "7 pages, 8 figures, IEEE Big Data 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptocurrencies, such as Bitcoin, are becoming increasingly popular, having\nbeen widely used as an exchange medium in areas such as financial transaction\nand asset transfer verification. However, there has been a lack of solutions\nthat can support real-time price prediction to cope with high currency\nvolatility, handle massive heterogeneous data volumes, including social media\nsentiments, while supporting fault tolerance and persistence in real time, and\nprovide real-time adaptation of learning algorithms to cope with new price and\nsentiment data. In this paper we introduce KryptoOracle, a novel real-time and\nadaptive cryptocurrency price prediction platform based on Twitter sentiments.\nThe integrative and modular platform is based on (i) a Spark-based architecture\nwhich handles the large volume of incoming data in a persistent and fault\ntolerant way; (ii) an approach that supports sentiment analysis which can\nrespond to large amounts of natural language processing queries in real time;\nand (iii) a predictive method grounded on online learning in which a model\nadapts its weights to cope with new prices and sentiments. Besides providing an\narchitectural design, the paper also describes the KryptoOracle platform\nimplementation and experimental evaluation. Overall, the proposed platform can\nhelp accelerate decision-making, uncover new opportunities and provide more\ntimely insights based on the available and ever-larger financial data volume\nand variety.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 20:38:46 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Mohapatra", "Shubhankar", ""], ["Ahmed", "Nauman", ""], ["Alencar", "Paulo", ""]]}, {"id": "2003.04968", "submitter": "Tanvir Ahmad", "authors": "Gunjan Ansari, Chandni Saxena, Tanvir Ahmad and M.N.Doja", "title": "Aspect Term Extraction using Graph-based Semi-Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect based Sentiment Analysis is a major subarea of sentiment analysis.\nMany supervised and unsupervised approaches have been proposed in the past for\ndetecting and analyzing the sentiment of aspect terms. In this paper, a\ngraph-based semi-supervised learning approach for aspect term extraction is\nproposed. In this approach, every identified token in the review document is\nclassified as aspect or non-aspect term from a small set of labeled tokens\nusing label spreading algorithm. The k-Nearest Neighbor (kNN) for graph\nsparsification is employed in the proposed approach to make it more time and\nmemory efficient. The proposed work is further extended to determine the\npolarity of the opinion words associated with the identified aspect terms in\nreview sentence to generate visual aspect-based summary of review documents.\nThe experimental study is conducted on benchmark and crawled datasets of\nrestaurant and laptop domains with varying value of labeled instances. The\nresults depict that the proposed approach could achieve good result in terms of\nPrecision, Recall and Accuracy with limited availability of labeled data.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 13:11:02 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Ansari", "Gunjan", ""], ["Saxena", "Chandni", ""], ["Ahmad", "Tanvir", ""], ["Doja", "M. N.", ""]]}, {"id": "2003.04970", "submitter": "Oana Cocarascu", "authors": "Oana Cocarascu, Elena Cabrio, Serena Villata, Francesca Toni", "title": "A Dataset Independent Set of Baselines for Relation Prediction in\n  Argument Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Argument Mining is the research area which aims at extracting argument\ncomponents and predicting argumentative relations (i.e.,support and attack)\nfrom text. In particular, numerous approaches have been proposed in the\nliterature to predict the relations holding between the arguments, and\napplication-specific annotated resources were built for this purpose. Despite\nthe fact that these resources have been created to experiment on the same task,\nthe definition of a single relation prediction method to be successfully\napplied to a significant portion of these datasets is an open research problem\nin Argument Mining. This means that none of the methods proposed in the\nliterature can be easily ported from one resource to another. In this paper, we\naddress this problem by proposing a set of dataset independent strong neural\nbaselines which obtain homogeneous results on all the datasets proposed in the\nliterature for the argumentative relation prediction task. Thus, our baselines\ncan be employed by the Argument Mining community to compare more effectively\nhow well a method performs on the argumentative relation prediction task.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 12:38:18 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Cocarascu", "Oana", ""], ["Cabrio", "Elena", ""], ["Villata", "Serena", ""], ["Toni", "Francesca", ""]]}, {"id": "2003.04972", "submitter": "Zachary Lindner", "authors": "Zachary Lindner", "title": "A Comparative Study of Sequence Classification Models for Privacy Policy\n  Coverage Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Privacy policies are legal documents that describe how a website will\ncollect, use, and distribute a user's data. Unfortunately, such documents are\noften overly complicated and filled with legal jargon; making it difficult for\nusers to fully grasp what exactly is being collected and why. Our solution to\nthis problem is to provide users with a coverage analysis of a given website's\nprivacy policy using a wide range of classical machine learning and deep\nlearning techniques. Given a website's privacy policy, the classifier\nidentifies the associated data practice for each logical segment. These data\npractices/labels are taken directly from the OPP-115 corpus. For example, the\ndata practice \"Data Retention\" refers to how long a website stores a user's\ninformation. The coverage analysis allows users to determine how many of the\nten possible data practices are covered, along with identifying the sections\nthat correspond to the data practices of particular interest.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 21:46:22 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Lindner", "Zachary", ""]]}, {"id": "2003.04973", "submitter": "Neha Singh", "authors": "Neha Singh, Nirmalya Roy, Aryya Gangopadhyay", "title": "Localized Flood DetectionWith Minimal Labeled Social Media Data Using\n  Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media generates an enormous amount of data on a daily basis but it is\nvery challenging to effectively utilize the data without annotating or labeling\nit according to the target application. We investigate the problem of localized\nflood detection using the social sensing model (Twitter) in order to provide an\nefficient, reliable and accurate flood text classification model with minimal\nlabeled data. This study is important since it can immensely help in providing\nthe flood-related updates and notifications to the city officials for emergency\ndecision making, rescue operations, and early warnings, etc. We propose to\nperform the text classification using the inductive transfer learning method\ni.e pre-trained language model ULMFiT and fine-tune it in order to effectively\nclassify the flood-related feeds in any new location. Finally, we show that\nusing very little new labeled data in the target domain we can successfully\nbuild an efficient and high performing model for flood detection and analysis\nwith human-generated facts and observations from Twitter.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 20:17:34 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Singh", "Neha", ""], ["Roy", "Nirmalya", ""], ["Gangopadhyay", "Aryya", ""]]}, {"id": "2003.04974", "submitter": "Prakhar Thapak", "authors": "Prakhar Thapak and Prodip Hore", "title": "Transformer++", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in attention mechanisms have replaced recurrent neural\nnetworks and its variants for machine translation tasks. Transformer using\nattention mechanism solely achieved state-of-the-art results in sequence\nmodeling. Neural machine translation based on the attention mechanism is\nparallelizable and addresses the problem of handling long-range dependencies\namong words in sentences more effectively than recurrent neural networks. One\nof the key concepts in attention is to learn three matrices, query, key, and\nvalue, where global dependencies among words are learned through linearly\nprojecting word embeddings through these matrices. Multiple query, key, value\nmatrices can be learned simultaneously focusing on a different subspace of the\nembedded dimension, which is called multi-head in Transformer. We argue that\ncertain dependencies among words could be learned better through an\nintermediate context than directly modeling word-word dependencies. This could\nhappen due to the nature of certain dependencies or lack of patterns that lend\nthem difficult to be modeled globally using multi-head self-attention. In this\nwork, we propose a new way of learning dependencies through a context in\nmulti-head using convolution. This new form of multi-head attention along with\nthe traditional form achieves better results than Transformer on the WMT 2014\nEnglish-to-German and English-to-French translation tasks. We also introduce a\nframework to learn POS tagging and NER information during the training of\nencoder which further improves results achieving a new state-of-the-art of 32.1\nBLEU, better than existing best by 1.4 BLEU, on the WMT 2014 English-to-German\nand 44.6 BLEU, better than existing best by 1.1 BLEU, on the WMT 2014\nEnglish-to-French translation tasks. We call this Transformer++.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 13:00:16 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Thapak", "Prakhar", ""], ["Hore", "Prodip", ""]]}, {"id": "2003.04975", "submitter": "Zahra Shekarchi", "authors": "Zahra Shekarchi, Yang Xu", "title": "A Computational Investigation on Denominalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language has been a dynamic system and word meanings always have been changed\nover times. Every time a novel concept or sense is introduced, we need to\nassign it a word to express it. Also, some changes have happened because the\nresult of a change can be more desirable for humans, or cognitively easier to\nbe used by humans. Finding the patterns of these changes is interesting and can\nreveal some facts about human cognitive evolution. As we have enough resources\nfor studying this problem, it is a good idea to work on the problem through\ncomputational modeling, and that can make the work easier and possible to be\nstudied on large scale. In this work, we want to study the nouns which have\nbeen used as verbs after some years of their emergence as nouns and find some\ncommonalities among these nouns. In other words, we are interested in finding\nwhat potential requirements are essential for this change.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 22:28:00 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Shekarchi", "Zahra", ""], ["Xu", "Yang", ""]]}, {"id": "2003.04976", "submitter": "Gaurav Pandey", "authors": "Gaurav Pandey, Dinesh Raghu and Sachindra Joshi", "title": "Mask & Focus: Conversation Modelling by Learning Concepts", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence to sequence models attempt to capture the correlation between all\nthe words in the input and output sequences. While this is quite useful for\nmachine translation where the correlation among the words is indeed quite\nstrong, it becomes problematic for conversation modelling where the correlation\nis often at a much abstract level. In contrast, humans tend to focus on the\nessential concepts discussed in the conversation context and generate responses\naccordingly. In this paper, we attempt to mimic this response generating\nmechanism by learning the essential concepts in the context and response in an\nunsupervised manner. The proposed model, referred to as Mask \\& Focus maps the\ninput context to a sequence of concepts which are then used to generate the\nresponse concepts. Together, the context and the response concepts generate the\nfinal response. In order to learn context concepts from the training data\nautomatically, we \\emph{mask} words in the input and observe the effect of\nmasking on response generation. We train our model to learn those response\nconcepts that have high mutual information with respect to the context\nconcepts, thereby guiding the model to \\emph{focus} on the context concepts.\nMask \\& Focus achieves significant improvement over the existing baselines in\nseveral established metrics for dialogues.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 15:11:55 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Pandey", "Gaurav", ""], ["Raghu", "Dinesh", ""], ["Joshi", "Sachindra", ""]]}, {"id": "2003.04978", "submitter": "Sairamvinay Vijayaraghavan", "authors": "Sairamvinay Vijayaraghavan, Ye Wang, Zhiyuan Guo, John Voong, Wenda\n  Xu, Armand Nasseri, Jiaru Cai, Linda Li, Kevin Vuong, and Eshan Wadhwa", "title": "Fake News Detection with Different Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This is a paper for exploring various different models aiming at developing\nfake news detection models and we had used certain machine learning algorithms\nand we had used pretrained algorithms such as TFIDF and CV and W2V as features\nfor processing textual data.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 06:15:17 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Vijayaraghavan", "Sairamvinay", ""], ["Wang", "Ye", ""], ["Guo", "Zhiyuan", ""], ["Voong", "John", ""], ["Xu", "Wenda", ""], ["Nasseri", "Armand", ""], ["Cai", "Jiaru", ""], ["Li", "Linda", ""], ["Vuong", "Kevin", ""], ["Wadhwa", "Eshan", ""]]}, {"id": "2003.04980", "submitter": "Jonas Rieger", "authors": "Jonas Rieger, Lars Koppers, Carsten Jentsch, and J\\\"org Rahnenf\\\"uhrer", "title": "Improving Reliability of Latent Dirichlet Allocation by Assessing Its\n  Stability Using Clustering Techniques on Replicated Runs", "comments": "16 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For organizing large text corpora topic modeling provides useful tools. A\nwidely used method is Latent Dirichlet Allocation (LDA), a generative\nprobabilistic model which models single texts in a collection of texts as\nmixtures of latent topics. The assignments of words to topics rely on initial\nvalues such that generally the outcome of LDA is not fully reproducible. In\naddition, the reassignment via Gibbs Sampling is based on conditional\ndistributions, leading to different results in replicated runs on the same text\ndata. This fact is often neglected in everyday practice. We aim to improve the\nreliability of LDA results. Therefore, we study the stability of LDA by\ncomparing assignments from replicated runs. We propose to quantify the\nsimilarity of two generated topics by a modified Jaccard coefficient. Using\nsuch similarities, topics can be clustered. A new pruning algorithm for\nhierarchical clustering results based on the idea that two LDA runs create\npairs of similar topics is proposed. This approach leads to the new measure\nS-CLOP ({\\bf S}imilarity of multiple sets by {\\bf C}lustering with {\\bf LO}cal\n{\\bf P}runing) for quantifying the stability of LDA models. We discuss some\ncharacteristics of this measure and illustrate it with an application to real\ndata consisting of newspaper articles from \\textit{USA Today}. Our results show\nthat the measure S-CLOP is useful for assessing the stability of LDA models or\nany other topic modeling procedure that characterize its topics by word\ndistributions. Based on the newly proposed measure for LDA stability, we\npropose a method to increase the reliability and hence to improve the\nreproducibility of empirical findings based on topic modeling. This increase in\nreliability is obtained by running the LDA several times and taking as\nprototype the most representative run, that is the LDA run with highest average\nsimilarity to all other runs.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 07:10:18 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Rieger", "Jonas", ""], ["Koppers", "Lars", ""], ["Jentsch", "Carsten", ""], ["Rahnenf\u00fchrer", "J\u00f6rg", ""]]}, {"id": "2003.04981", "submitter": "Xinyi Zhou", "authors": "Xinyi Zhou, Jindi Wu, Reza Zafarani", "title": "SAFE: Similarity-Aware Multi-Modal Fake News Detection", "comments": "To be published in The 24th Pacific-Asia Conference on Knowledge\n  Discovery and Data Mining (PAKDD 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective detection of fake news has recently attracted significant\nattention. Current studies have made significant contributions to predicting\nfake news with less focus on exploiting the relationship (similarity) between\nthe textual and visual information in news articles. Attaching importance to\nsuch similarity helps identify fake news stories that, for example, attempt to\nuse irrelevant images to attract readers' attention. In this work, we propose a\n$\\mathsf{S}$imilarity-$\\mathsf{A}$ware $\\mathsf{F}$ak$\\mathsf{E}$ news\ndetection method ($\\mathsf{SAFE}$) which investigates multi-modal (textual and\nvisual) information of news articles. First, neural networks are adopted to\nseparately extract textual and visual features for news representation. We\nfurther investigate the relationship between the extracted features across\nmodalities. Such representations of news textual and visual information along\nwith their relationship are jointly learned and used to predict fake news. The\nproposed method facilitates recognizing the falsity of news articles based on\ntheir text, images, or their \"mismatches.\" We conduct extensive experiments on\nlarge-scale real-world data, which demonstrate the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 02:51:04 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Zhou", "Xinyi", ""], ["Wu", "Jindi", ""], ["Zafarani", "Reza", ""]]}, {"id": "2003.04983", "submitter": "Megan Leszczynski", "authors": "Megan Leszczynski, Avner May, Jian Zhang, Sen Wu, Christopher R.\n  Aberger, Christopher R\\'e", "title": "Understanding the Downstream Instability of Word Embeddings", "comments": "In Proceedings of the 3rd MLSys Conference, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many industrial machine learning (ML) systems require frequent retraining to\nkeep up-to-date with constantly changing data. This retraining exacerbates a\nlarge challenge facing ML systems today: model training is unstable, i.e.,\nsmall changes in training data can cause significant changes in the model's\npredictions. In this paper, we work on developing a deeper understanding of\nthis instability, with a focus on how a core building block of modern natural\nlanguage processing (NLP) pipelines---pre-trained word embeddings---affects the\ninstability of downstream NLP models. We first empirically reveal a tradeoff\nbetween stability and memory: increasing the embedding memory 2x can reduce the\ndisagreement in predictions due to small changes in training data by 5% to 37%\n(relative). To theoretically explain this tradeoff, we introduce a new measure\nof embedding instability---the eigenspace instability measure---which we prove\nbounds the disagreement in downstream predictions introduced by the change in\nword embeddings. Practically, we show that the eigenspace instability measure\ncan be a cost-effective way to choose embedding parameters to minimize\ninstability without training downstream models, outperforming other embedding\ndistance measures and performing competitively with a nearest neighbor-based\nmeasure. Finally, we demonstrate that the observed stability-memory tradeoffs\nextend to other types of embeddings as well, including knowledge graph and\ncontextual word embeddings.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 00:39:12 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Leszczynski", "Megan", ""], ["May", "Avner", ""], ["Zhang", "Jian", ""], ["Wu", "Sen", ""], ["Aberger", "Christopher R.", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "2003.04985", "submitter": "Lichao Sun", "authors": "Lichao Sun, Kazuma Hashimoto, Wenpeng Yin, Akari Asai, Jia Li, Philip\n  Yu, Caiming Xiong", "title": "Adv-BERT: BERT is not robust on misspellings! Generating nature\n  adversarial samples on BERT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing amount of literature that claims the brittleness of\ndeep neural networks in dealing with adversarial examples that are created\nmaliciously. It is unclear, however, how the models will perform in realistic\nscenarios where \\textit{natural rather than malicious} adversarial instances\noften exist. This work systematically explores the robustness of BERT, the\nstate-of-the-art Transformer-style model in NLP, in dealing with noisy data,\nparticularly mistakes in typing the keyboard, that occur inadvertently.\nIntensive experiments on sentiment analysis and question answering benchmarks\nindicate that: (i) Typos in various words of a sentence do not influence\nequally. The typos in informative words make severer damages; (ii) Mistype is\nthe most damaging factor, compared with inserting, deleting, etc.; (iii) Humans\nand machines have different focuses on recognizing adversarial attacks.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 22:07:11 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Sun", "Lichao", ""], ["Hashimoto", "Kazuma", ""], ["Yin", "Wenpeng", ""], ["Asai", "Akari", ""], ["Li", "Jia", ""], ["Yu", "Philip", ""], ["Xiong", "Caiming", ""]]}, {"id": "2003.04986", "submitter": "Vukosi Marivate", "authors": "Vukosi Marivate, Tshephisho Sefara, Vongani Chabalala, Keamogetswe\n  Makhaya, Tumisho Mokgonyane, Rethabile Mokoena, Abiodun Modupe", "title": "Investigating an approach for low resource language dataset creation,\n  curation and classification: Setswana and Sepedi", "comments": "Submitted to Resources for African Indigenous Languages (RAIL) at\n  LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The recent advances in Natural Language Processing have been a boon for\nwell-represented languages in terms of available curated data and research\nresources. One of the challenges for low-resourced languages is clear\nguidelines on the collection, curation and preparation of datasets for\ndifferent use-cases. In this work, we take on the task of creation of two\ndatasets that are focused on news headlines (i.e short text) for Setswana and\nSepedi and creation of a news topic classification task. We document our work\nand also present baselines for classification. We investigate an approach on\ndata augmentation, better suited to low resource languages, to improve the\nperformance of the classifiers\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 13:58:06 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Marivate", "Vukosi", ""], ["Sefara", "Tshephisho", ""], ["Chabalala", "Vongani", ""], ["Makhaya", "Keamogetswe", ""], ["Mokgonyane", "Tumisho", ""], ["Mokoena", "Rethabile", ""], ["Modupe", "Abiodun", ""]]}, {"id": "2003.04987", "submitter": "Shi Yu", "authors": "Shi Yu, Yuxin Chen, Hussain Zaidi", "title": "A Financial Service Chatbot based on Deep Bidirectional Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a chatbot using Deep Bidirectional Transformer models (BERT) to\nhandle client questions in financial investment customer service. The bot can\nrecognize 381 intents, and decides when to say \"I don't know\" and escalates\nirrelevant/uncertain questions to human operators. Our main novel contribution\nis the discussion about uncertainty measure for BERT, where three different\napproaches are systematically compared on real problems. We investigated two\nuncertainty metrics, information entropy and variance of dropout sampling in\nBERT, followed by mixed-integer programming to optimize decision thresholds.\nAnother novel contribution is the usage of BERT as a language model in\nautomatic spelling correction. Inputs with accidental spelling errors can\nsignificantly decrease intent classification performance. The proposed approach\ncombines probabilities from masked language model and word edit distances to\nfind the best corrections for misspelled words. The chatbot and the entire\nconversational AI system are developed using open-source tools, and deployed\nwithin our company's intranet. The proposed approach can be useful for\nindustries seeking similar in-house solutions in their specific business\ndomains. We share all our code and a sample chatbot built on a public dataset\non Github.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 18:48:55 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Yu", "Shi", ""], ["Chen", "Yuxin", ""], ["Zaidi", "Hussain", ""]]}, {"id": "2003.04988", "submitter": "Barun Patra", "authors": "Vishwas Suryanarayanan, Barun Patra, Pamela Bhattacharya, Chala Fufa,\n  Charles Lee", "title": "ScopeIt: Scoping Task Relevant Sentences in Documents", "comments": "Accepted in COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent assistants like Cortana, Siri, Alexa, and Google Assistant are\ntrained to parse information when the conversation is synchronous and short;\nhowever, for email-based conversational agents, the communication is\nasynchronous, and often contains information irrelevant to the assistant. This\nmakes it harder for the system to accurately detect intents, extract entities\nrelevant to those intents and thereby perform the desired action. We present a\nneural model for scoping relevant information for the agent from a large query.\nWe show that when used as a preprocessing step, the model improves performance\nof both intent detection and entity extraction tasks. We demonstrate the\nmodel's impact on Scheduler (Cortana is the persona of the agent, while\nScheduler is the name of the service. We use them interchangeably in the\ncontext of this paper.) - a virtual conversational meeting scheduling assistant\nthat interacts asynchronously with users through email. The model helps the\nentity extraction and intent detection tasks requisite by Scheduler achieve an\naverage gain of 35% in precision without any drop in recall. Additionally, we\ndemonstrate that the same approach can be used for component level analysis in\nlarge documents, such as signature block identification.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 02:33:10 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 09:44:46 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Suryanarayanan", "Vishwas", ""], ["Patra", "Barun", ""], ["Bhattacharya", "Pamela", ""], ["Fufa", "Chala", ""], ["Lee", "Charles", ""]]}, {"id": "2003.04991", "submitter": "Jitin Krishnan", "authors": "Jitin Krishnan, Hemant Purohit and Huzefa Rangwala", "title": "Unsupervised and Interpretable Domain Adaptation to Rapidly Filter\n  Tweets for Emergency Services", "comments": "8 pages, 4 Figures, 6 Tables, Source Code Available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  During the onset of a disaster event, filtering relevant information from the\nsocial web data is challenging due to its sparse availability and practical\nlimitations in labeling datasets of an ongoing crisis. In this paper, we\nhypothesize that unsupervised domain adaptation through multi-task learning can\nbe a useful framework to leverage data from past crisis events for training\nefficient information filtering models during the sudden onset of a new crisis.\nWe present a novel method to classify relevant tweets during an ongoing crisis\nwithout seeing any new examples, using the publicly available dataset of TREC\nincident streams. Specifically, we construct a customized multi-task\narchitecture with a multi-domain discriminator for crisis analytics: multi-task\ndomain adversarial attention network. This model consists of dedicated\nattention layers for each task to provide model interpretability; critical for\nreal-word applications. As deep networks struggle with sparse datasets, we show\nthat this can be improved by sharing a base layer for multi-task learning and\ndomain adversarial training. Evaluation of domain adaptation for crisis events\nis performed by choosing a target event as the test set and training on the\nrest. Our results show that the multi-task model outperformed its single task\ncounterpart. For the qualitative evaluation of interpretability, we show that\nthe attention layer can be used as a guide to explain the model predictions and\nempower emergency services for exploring accountability of the model, by\nshowcasing the words in a tweet that are deemed important in the classification\nprocess. Finally, we show a practical implication of our work by providing a\nuse-case for the COVID-19 pandemic.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 06:40:14 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 18:01:19 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Krishnan", "Jitin", ""], ["Purohit", "Hemant", ""], ["Rangwala", "Huzefa", ""]]}, {"id": "2003.04992", "submitter": "Hui Wan", "authors": "Hui Wan", "title": "Multi-task Learning with Multi-head Attention for Multi-choice Reading\n  Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple-choice Machine Reading Comprehension (MRC) is an important and\nchallenging Natural Language Understanding (NLU) task, in which a machine must\nchoose the answer to a question from a set of choices, with the question placed\nin context of text passages or dialog. In the last a couple of years the NLU\nfield has been revolutionized with the advent of models based on the\nTransformer architecture, which are pretrained on massive amounts of\nunsupervised data and then fine-tuned for various supervised learning NLU\ntasks. Transformer models have come to dominate a wide variety of leader-boards\nin the NLU field; in the area of MRC, the current state-of-the-art model on the\nDREAM dataset (see[Sunet al., 2019]) fine tunes Albert, a large pretrained\nTransformer-based model, and addition-ally combines it with an extra layer of\nmulti-head attention between context and question-answer[Zhuet al., 2020].The\npurpose of this note is to document a new state-of-the-art result in the DREAM\ntask, which is accomplished by, additionally, performing multi-task learning on\ntwo MRC multi-choice reading comprehension tasks (RACE and DREAM).\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 16:32:25 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Wan", "Hui", ""]]}, {"id": "2003.04993", "submitter": "Siyi Liu", "authors": "Siyi Liu (1), Ziang Leng (1), Derry Wijaya (1) ((1) Boston University)", "title": "Learning to mirror speaking styles incrementally", "comments": "4 pages, 3 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mirroring is the behavior in which one person subconsciously imitates the\ngesture, speech pattern, or attitude of another. In conversations, mirroring\noften signals the speakers enjoyment and engagement in their communication. In\nchatbots, methods have been proposed to add personas to the chatbots and to\ntrain them to speak or to shift their dialogue style to that of the personas.\nHowever, they often require a large dataset consisting of dialogues of the\ntarget personalities to train. In this work, we explore a method that can learn\nto mirror the speaking styles of a person incrementally. Our method extracts\nngrams that capture a persons speaking styles and uses the ngrams to create\npatterns for transforming sentences to the persons speaking styles. Our\nexperiments show that our method is able to capture patterns of speaking style\nthat can be used to transform regular sentences into sentences with the target\nstyle.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 02:54:32 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Liu", "Siyi", "", "Boston University"], ["Leng", "Ziang", "", "Boston University"], ["Wijaya", "Derry", "", "Boston University"]]}, {"id": "2003.04994", "submitter": "Yating Zhang", "authors": "Tianyi Wang, Yating Zhang, Xiaozhong Liu, Changlong Sun, Qiong Zhang", "title": "Masking Orchestration: Multi-task Pretraining for Multi-role Dialogue\n  Representation Learning", "comments": "8 pages, 4 figures, AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-role dialogue understanding comprises a wide range of diverse tasks\nsuch as question answering, act classification, dialogue summarization etc.\nWhile dialogue corpora are abundantly available, labeled data, for specific\nlearning tasks, can be highly scarce and expensive. In this work, we\ninvestigate dialogue context representation learning with various types\nunsupervised pretraining tasks where the training objectives are given\nnaturally according to the nature of the utterance and the structure of the\nmulti-role conversation. Meanwhile, in order to locate essential information\nfor dialogue summarization/extraction, the pretraining process enables external\nknowledge integration. The proposed fine-tuned pretraining mechanism is\ncomprehensively evaluated via three different dialogue datasets along with a\nnumber of downstream dialogue-mining tasks. Result shows that the proposed\npretraining mechanism significantly contributes to all the downstream tasks\nwithout discrimination to different encoders.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 04:36:52 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Wang", "Tianyi", ""], ["Zhang", "Yating", ""], ["Liu", "Xiaozhong", ""], ["Sun", "Changlong", ""], ["Zhang", "Qiong", ""]]}, {"id": "2003.04996", "submitter": "Fabio Massimo Zanzotto", "authors": "Fabio Massimo Zanzotto and Viviana Bono and Paola Vocca and Andrea\n  Santilli and Danilo Croce and Giorgio Gambosi and Roberto Basili", "title": "GASP! Generating Abstracts of Scientific Papers from Abstracts of Cited\n  Papers", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creativity is one of the driving forces of human kind as it allows to break\ncurrent understanding to envision new ideas, which may revolutionize entire\nfields of knowledge. Scientific research offers a challenging environment where\nto learn a model for the creative process. In fact, scientific research is a\ncreative act in the formal settings of the scientific method and this creative\nact is described in articles.\n  In this paper, we dare to introduce the novel, scientifically and\nphilosophically challenging task of Generating Abstracts of Scientific Papers\nfrom abstracts of cited papers (GASP) as a text-to-text task to investigate\nscientific creativity, To foster research in this novel, challenging task, we\nprepared a dataset by using services where that solve the problem of copyright\nand, hence, the dataset is public available with its standard split. Finally,\nwe experimented with two vanilla summarization systems to start the analysis of\nthe complexity of the GASP task.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 14:58:41 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Zanzotto", "Fabio Massimo", ""], ["Bono", "Viviana", ""], ["Vocca", "Paola", ""], ["Santilli", "Andrea", ""], ["Croce", "Danilo", ""], ["Gambosi", "Giorgio", ""], ["Basili", "Roberto", ""]]}, {"id": "2003.04998", "submitter": "Yitong Li", "authors": "Yitong Li, Dianqi Li, Sushant Prakash and Peng Wang", "title": "Toward Interpretability of Dual-Encoder Models for Dialogue Response\n  Suggestions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work shows how to improve and interpret the commonly used dual encoder\nmodel for response suggestion in dialogue. We present an attentive dual encoder\nmodel that includes an attention mechanism on top of the extracted word-level\nfeatures from two encoders, one for context and one for label respectively. To\nimprove the interpretability in the dual encoder models, we design a novel\nregularization loss to minimize the mutual information between unimportant\nwords and desired labels, in addition to the original attention method, so that\nimportant words are emphasized while unimportant words are de-emphasized. This\ncan help not only with model interpretability, but can also further improve\nmodel accuracy. We propose an approximation method that uses a neural network\nto calculate the mutual information. Furthermore, by adding a residual layer\nbetween raw word embeddings and the final encoded context feature, word-level\ninterpretability is preserved at the final prediction of the model. We compare\nthe proposed model with existing methods for the dialogue response task on two\npublic datasets (Persona and Ubuntu). The experiments demonstrate the\neffectiveness of the proposed model in terms of better Recall@1 accuracy and\nvisualized interpretability.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 21:26:06 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Li", "Yitong", ""], ["Li", "Dianqi", ""], ["Prakash", "Sushant", ""], ["Wang", "Peng", ""]]}, {"id": "2003.05002", "submitter": "Jonathan Clark", "authors": "Jonathan H. Clark, Eunsol Choi, Michael Collins, Dan Garrette, Tom\n  Kwiatkowski, Vitaly Nikolaev, and Jennimaria Palomaki", "title": "TyDi QA: A Benchmark for Information-Seeking Question Answering in\n  Typologically Diverse Languages", "comments": "To appear in Transactions of the Association for Computational\n  Linguistics (TACL) 2020. Please use this as the citation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Confidently making progress on multilingual modeling requires challenging,\ntrustworthy evaluations. We present TyDi QA---a question answering dataset\ncovering 11 typologically diverse languages with 204K question-answer pairs.\nThe languages of TyDi QA are diverse with regard to their typology---the set of\nlinguistic features each language expresses---such that we expect models\nperforming well on this set to generalize across a large number of the world's\nlanguages. We present a quantitative analysis of the data quality and\nexample-level qualitative linguistic analyses of observed language phenomena\nthat would not be found in English-only corpora. To provide a realistic\ninformation-seeking task and avoid priming effects, questions are written by\npeople who want to know the answer, but don't know the answer yet, and the data\nis collected directly in each language without the use of translation.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 21:11:53 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Clark", "Jonathan H.", ""], ["Choi", "Eunsol", ""], ["Collins", "Michael", ""], ["Garrette", "Dan", ""], ["Kwiatkowski", "Tom", ""], ["Nikolaev", "Vitaly", ""], ["Palomaki", "Jennimaria", ""]]}, {"id": "2003.05019", "submitter": "V\\'it Novotn\\'y", "authors": "V\\'it Novotn\\'y, Eniafe Festus Ayetiran, Michal \\v{S}tef\\'anik, and\n  Petr Sojka", "title": "Text classification with word embedding regularization and soft\n  similarity measure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the seminal work of Mikolov et al., word embeddings have become the\npreferred word representations for many natural language processing tasks.\nDocument similarity measures extracted from word embeddings, such as the soft\ncosine measure (SCM) and the Word Mover's Distance (WMD), were reported to\nachieve state-of-the-art performance on semantic text similarity and text\nclassification.\n  Despite the strong performance of the WMD on text classification and semantic\ntext similarity, its super-cubic average time complexity is impractical. The\nSCM has quadratic worst-case time complexity, but its performance on text\nclassification has never been compared with the WMD. Recently, two word\nembedding regularization techniques were shown to reduce storage and memory\ncosts, and to improve training speed, document processing speed, and task\nperformance on word analogy, word similarity, and semantic text similarity.\nHowever, the effect of these techniques on text classification has not yet been\nstudied.\n  In our work, we investigate the individual and joint effect of the two word\nembedding regularization techniques on the document processing speed and the\ntask performance of the SCM and the WMD on text classification. For evaluation,\nwe use the $k$NN classifier and six standard datasets: BBCSPORT, TWITTER,\nOHSUMED, REUTERS-21578, AMAZON, and 20NEWS.\n  We show 39% average $k$NN test error reduction with regularized word\nembeddings compared to non-regularized word embeddings. We describe a practical\nprocedure for deriving such regularized embeddings through Cholesky\nfactorization. We also show that the SCM with regularized word embeddings\nsignificantly outperforms the WMD on text classification and is over 10,000\ntimes faster.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 22:07:34 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Novotn\u00fd", "V\u00edt", ""], ["Ayetiran", "Eniafe Festus", ""], ["\u0160tef\u00e1nik", "Michal", ""], ["Sojka", "Petr", ""]]}, {"id": "2003.05078", "submitter": "Gunnar Sigurdsson", "authors": "Gunnar A. Sigurdsson, Jean-Baptiste Alayrac, Aida Nematzadeh, Lucas\n  Smaira, Mateusz Malinowski, Jo\\~ao Carreira, Phil Blunsom, Andrew Zisserman", "title": "Visual Grounding in Video for Unsupervised Word Translation", "comments": "CVPR 2020", "journal-ref": "CVPR 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are thousands of actively spoken languages on Earth, but a single\nvisual world. Grounding in this visual world has the potential to bridge the\ngap between all these languages. Our goal is to use visual grounding to improve\nunsupervised word mapping between languages. The key idea is to establish a\ncommon visual representation between two languages by learning embeddings from\nunpaired instructional videos narrated in the native language. Given this\nshared embedding we demonstrate that (i) we can map words between the\nlanguages, particularly the 'visual' words; (ii) that the shared embedding\nprovides a good initialization for existing unsupervised text-based word\ntranslation techniques, forming the basis for our proposed hybrid visual-text\nmapping algorithm, MUVE; and (iii) our approach achieves superior performance\nby addressing the shortcomings of text-based methods -- it is more robust,\nhandles datasets with less commonality, and is applicable to low-resource\nlanguages. We apply these methods to translate words from English to French,\nKorean, and Japanese -- all without any parallel corpora and simply by watching\nmany videos of people speaking while doing things.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 02:03:37 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 15:20:44 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Sigurdsson", "Gunnar A.", ""], ["Alayrac", "Jean-Baptiste", ""], ["Nematzadeh", "Aida", ""], ["Smaira", "Lucas", ""], ["Malinowski", "Mateusz", ""], ["Carreira", "Jo\u00e3o", ""], ["Blunsom", "Phil", ""], ["Zisserman", "Andrew", ""]]}, {"id": "2003.05146", "submitter": "Nicolas Heist", "authors": "Nicolas Heist and Heiko Paulheim", "title": "Entity Extraction from Wikipedia List Pages", "comments": "Preprint of a full paper at European Semantic Web Conference 2020\n  (ESWC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When it comes to factual knowledge about a wide range of domains, Wikipedia\nis often the prime source of information on the web. DBpedia and YAGO, as large\ncross-domain knowledge graphs, encode a subset of that knowledge by creating an\nentity for each page in Wikipedia, and connecting them through edges. It is\nwell known, however, that Wikipedia-based knowledge graphs are far from\ncomplete. Especially, as Wikipedia's policies permit pages about subjects only\nif they have a certain popularity, such graphs tend to lack information about\nless well-known entities. Information about these entities is oftentimes\navailable in the encyclopedia, but not represented as an individual page. In\nthis paper, we present a two-phased approach for the extraction of entities\nfrom Wikipedia's list pages, which have proven to serve as a valuable source of\ninformation. In the first phase, we build a large taxonomy from categories and\nlist pages with DBpedia as a backbone. With distant supervision, we extract\ntraining data for the identification of new entities in list pages that we use\nin the second phase to train a classification model. With this approach we\nextract over 700k new entities and extend DBpedia with 7.5M new type statements\nand 3.8M new facts of high precision.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 07:48:46 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Heist", "Nicolas", ""], ["Paulheim", "Heiko", ""]]}, {"id": "2003.05161", "submitter": "Laura Ruis", "authors": "Laura Ruis, Jacob Andreas, Marco Baroni, Diane Bouchacourt, Brenden M.\n  Lake", "title": "A Benchmark for Systematic Generalization in Grounded Language\n  Understanding", "comments": "accepted at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans easily interpret expressions that describe unfamiliar situations\ncomposed from familiar parts (\"greet the pink brontosaurus by the ferris\nwheel\"). Modern neural networks, by contrast, struggle to interpret novel\ncompositions. In this paper, we introduce a new benchmark, gSCAN, for\nevaluating compositional generalization in situated language understanding.\nGoing beyond a related benchmark that focused on syntactic aspects of\ngeneralization, gSCAN defines a language grounded in the states of a grid\nworld, facilitating novel evaluations of acquiring linguistically motivated\nrules. For example, agents must understand how adjectives such as 'small' are\ninterpreted relative to the current world state or how adverbs such as\n'cautiously' combine with new verbs. We test a strong multi-modal baseline\nmodel and a state-of-the-art compositional method finding that, in most cases,\nthey fail dramatically when generalization requires systematic compositional\nrules.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 08:40:15 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2020 17:02:02 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Ruis", "Laura", ""], ["Andreas", "Jacob", ""], ["Baroni", "Marco", ""], ["Bouchacourt", "Diane", ""], ["Lake", "Brenden M.", ""]]}, {"id": "2003.05162", "submitter": "Tejas Gokhale", "authors": "Zhiyuan Fang, Tejas Gokhale, Pratyay Banerjee, Chitta Baral, Yezhou\n  Yang", "title": "Video2Commonsense: Generating Commonsense Descriptions to Enrich Video\n  Captioning", "comments": "Accepted to EMNLP, Long Papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Captioning is a crucial and challenging task for video understanding. In\nvideos that involve active agents such as humans, the agent's actions can bring\nabout myriad changes in the scene. Observable changes such as movements,\nmanipulations, and transformations of the objects in the scene, are reflected\nin conventional video captioning. Unlike images, actions in videos are also\ninherently linked to social aspects such as intentions (why the action is\ntaking place), effects (what changes due to the action), and attributes that\ndescribe the agent. Thus for video understanding, such as when captioning\nvideos or when answering questions about videos, one must have an understanding\nof these commonsense aspects. We present the first work on generating\ncommonsense captions directly from videos, to describe latent aspects such as\nintentions, effects, and attributes. We present a new dataset\n\"Video-to-Commonsense (V2C)\" that contains $\\sim9k$ videos of human agents\nperforming various actions, annotated with 3 types of commonsense descriptions.\nAdditionally we explore the use of open-ended video-based commonsense question\nanswering (V2C-QA) as a way to enrich our captions. Both the generation task\nand the QA task can be used to enrich video captions.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 08:42:57 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 05:16:13 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 02:08:26 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Fang", "Zhiyuan", ""], ["Gokhale", "Tejas", ""], ["Banerjee", "Pratyay", ""], ["Baral", "Chitta", ""], ["Yang", "Yezhou", ""]]}, {"id": "2003.05171", "submitter": "Peter beim Graben", "authors": "Peter beim Graben, Markus Huber, Werner Meyer, Ronald R\\\"omer and\n  Matthias Wolff", "title": "Vector symbolic architectures for context-free grammars", "comments": "36 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background / introduction. Vector symbolic architectures (VSA) are a viable\napproach for the hyperdimensional representation of symbolic data, such as\ndocuments, syntactic structures, or semantic frames. Methods. We present a\nrigorous mathematical framework for the representation of phrase structure\ntrees and parse trees of context-free grammars (CFG) in Fock space, i.e.\ninfinite-dimensional Hilbert space as being used in quantum field theory. We\ndefine a novel normal form for CFG by means of term algebras. Using a recently\ndeveloped software toolbox, called FockBox, we construct Fock space\nrepresentations for the trees built up by a CFG left-corner (LC) parser.\nResults. We prove a universal representation theorem for CFG term algebras in\nFock space and illustrate our findings through a low-dimensional principal\ncomponent projection of the LC parser states. Conclusions. Our approach could\nleverage the development of VSA for explainable artificial intelligence (XAI)\nby means of hyperdimensional deep neural computation. It could be of\nsignificance for the improvement of cognitive user interfaces and other\napplications of VSA in machine learning.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 09:07:02 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 08:34:46 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Graben", "Peter beim", ""], ["Huber", "Markus", ""], ["Meyer", "Werner", ""], ["R\u00f6mer", "Ronald", ""], ["Wolff", "Matthias", ""]]}, {"id": "2003.05258", "submitter": "Manolis Peponakis", "authors": "Manolis Peponakis, Anna Mastora, Sarantos Kapidakis, Martin Doerr", "title": "Expressiveness and machine processability of Knowledge Organization\n  Systems (KOS): An analysis of concepts and relations", "comments": "34 pages, 2 tables, 2 figures", "journal-ref": "International Journal on Digital Libraries, 20(4), 433-452 (2019)", "doi": "10.1007/s00799-019-00269-0", "report-no": null, "categories": "cs.DL cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This study considers the expressiveness (that is the expressive power or\nexpressivity) of different types of Knowledge Organization Systems (KOS) and\ndiscusses its potential to be machine-processable in the context of the\nSemantic Web. For this purpose, the theoretical foundations of KOS are reviewed\nbased on conceptualizations introduced by the Functional Requirements for\nSubject Authority Data (FRSAD) and the Simple Knowledge Organization System\n(SKOS); natural language processing techniques are also implemented. Applying a\ncomparative analysis, the dataset comprises a thesaurus (Eurovoc), a subject\nheadings system (LCSH) and a classification scheme (DDC). These are compared\nwith an ontology (CIDOC-CRM) by focusing on how they define and handle concepts\nand relations. It was observed that LCSH and DDC focus on the formalism of\ncharacter strings (nomens) rather than on the modelling of semantics; their\ndefinition of what constitutes a concept is quite fuzzy, and they comprise a\nlarge number of complex concepts. By contrast, thesauri have a coherent\ndefinition of what constitutes a concept, and apply a systematic approach to\nthe modelling of relations. Ontologies explicitly define diverse types of\nrelations, and are by their nature machine-processable. The paper concludes\nthat the potential of both the expressiveness and machine processability of\neach KOS is extensively regulated by its structural rules. It is harder to\nrepresent subject headings and classification schemes as semantic networks with\nnodes and arcs, while thesauri are more suitable for such a representation. In\naddition, a paradigm shift is revealed which focuses on the modelling of\nrelations between concepts, rather than the concepts themselves.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 12:35:52 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Peponakis", "Manolis", ""], ["Mastora", "Anna", ""], ["Kapidakis", "Sarantos", ""], ["Doerr", "Martin", ""]]}, {"id": "2003.05259", "submitter": "Elman Mansimov", "authors": "Elman Mansimov, G\\'abor Melis, Lei Yu", "title": "Capturing document context inside sentence-level neural machine\n  translation models with self-training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) has arguably achieved human level parity\nwhen trained and evaluated at the sentence-level. Document-level neural machine\ntranslation has received less attention and lags behind its sentence-level\ncounterpart. The majority of the proposed document-level approaches investigate\nways of conditioning the model on several source or target sentences to capture\ndocument context. These approaches require training a specialized NMT model\nfrom scratch on parallel document-level corpora. We propose an approach that\ndoesn't require training a specialized model on parallel document-level corpora\nand is applied to a trained sentence-level NMT model at decoding time. We\nprocess the document from left to right multiple times and self-train the\nsentence-level model on pairs of source sentences and generated translations.\nOur approach reinforces the choices made by the model, thus making it more\nlikely that the same choices will be made in other sentences in the document.\nWe evaluate our approach on three document-level datasets: NIST\nChinese-English, WMT'19 Chinese-English and OpenSubtitles English-Russian. We\ndemonstrate that our approach has higher BLEU score and higher human preference\nthan the baseline. Qualitative analysis of our approach shows that choices made\nby model are consistent across the document.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 12:36:17 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Mansimov", "Elman", ""], ["Melis", "G\u00e1bor", ""], ["Yu", "Lei", ""]]}, {"id": "2003.05377", "submitter": "Raul Lima", "authors": "Raul de Ara\\'ujo Lima, R\\^omulo C\\'esar Costa de Sousa, Simone Diniz\n  Junqueira Barbosa, H\\'elio Cort\\^es Vieira Lopes", "title": "Brazilian Lyrics-Based Music Genre Classification Using a BLSTM Network", "comments": "7 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organize songs, albums, and artists in groups with shared similarity could be\ndone with the help of genre labels. In this paper, we present a novel approach\nfor automatic classifying musical genre in Brazilian music using only the song\nlyrics. This kind of classification remains a challenge in the field of Natural\nLanguage Processing. We construct a dataset of 138,368 Brazilian song lyrics\ndistributed in 14 genres. We apply SVM, Random Forest and a Bidirectional Long\nShort-Term Memory (BLSTM) network combined with different word embeddings\ntechniques to address this classification task. Our experiments show that the\nBLSTM method outperforms the other models with an F1-score average of $0.48$.\nSome genres like \"gospel\", \"funk-carioca\" and \"sertanejo\", which obtained 0.89,\n0.70 and 0.69 of F1-score, respectively, can be defined as the most distinct\nand easy to classify in the Brazilian musical genres context.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 05:39:21 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Lima", "Raul de Ara\u00fajo", ""], ["de Sousa", "R\u00f4mulo C\u00e9sar Costa", ""], ["Barbosa", "Simone Diniz Junqueira", ""], ["Lopes", "H\u00e9lio Cort\u00eas Vieira", ""]]}, {"id": "2003.05443", "submitter": "Muhammad Ali Ibrahim", "authors": "Faiza Memood, Muhammad Usman Ghani, Muhammad Ali Ibrahim, Rehab\n  Shehzadi, Muhammad Nabeel Asim", "title": "A Precisely Xtreme-Multi Channel Hybrid Approach For Roman Urdu\n  Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In order to accelerate the performance of various Natural Language Processing\ntasks for Roman Urdu, this paper for the very first time provides 3 neural word\nembeddings prepared using most widely used approaches namely Word2vec,\nFastText, and Glove. The integrity of generated neural word embeddings is\nevaluated using intrinsic and extrinsic evaluation approaches. Considering the\nlack of publicly available benchmark datasets, it provides a first-ever Roman\nUrdu dataset which consists of 3241 sentiments annotated against positive,\nnegative and neutral classes. To provide benchmark baseline performance over\nthe presented dataset, we adapt diverse machine learning (Support Vector\nMachine Logistic Regression, Naive Bayes), deep learning (convolutional neural\nnetwork, recurrent neural network), and hybrid approaches. Effectiveness of\ngenerated neural word embeddings is evaluated by comparing the performance of\nmachine and deep learning based methodologies using 7, and 5 distinct feature\nrepresentation approaches respectively. Finally, it proposes a novel precisely\nextreme multi-channel hybrid methodology which outperforms state-of-the-art\nadapted machine and deep learning approaches by the figure of 9%, and 4% in\nterms of F1-score. Roman Urdu Sentiment Analysis, Pretrain word embeddings for\nRoman Urdu, Word2Vec, Glove, Fast-Text\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 04:08:27 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Memood", "Faiza", ""], ["Ghani", "Muhammad Usman", ""], ["Ibrahim", "Muhammad Ali", ""], ["Shehzadi", "Rehab", ""], ["Asim", "Muhammad Nabeel", ""]]}, {"id": "2003.05473", "submitter": "Samuel Broscheit", "authors": "Samuel Broscheit", "title": "Investigating Entity Knowledge in BERT with Simple Neural End-To-End\n  Entity Linking", "comments": "Published at CoNLL 2019", "journal-ref": "Proceedings of the 23rd Conference on Computational Natural\n  Language Learning (CoNLL), 2019, 677-685", "doi": "10.18653/v1/K19-1063", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A typical architecture for end-to-end entity linking systems consists of\nthree steps: mention detection, candidate generation and entity disambiguation.\nIn this study we investigate the following questions: (a) Can all those steps\nbe learned jointly with a model for contextualized text-representations, i.e.\nBERT (Devlin et al., 2019)? (b) How much entity knowledge is already contained\nin pretrained BERT? (c) Does additional entity knowledge improve BERT's\nperformance in downstream tasks? To this end, we propose an extreme\nsimplification of the entity linking setup that works surprisingly well: simply\ncast it as a per token classification over the entire entity vocabulary (over\n700K classes in our case). We show on an entity linking benchmark that (i) this\nmodel improves the entity representations over plain BERT, (ii) that it\noutperforms entity linking architectures that optimize the tasks separately and\n(iii) that it only comes second to the current state-of-the-art that does\nmention detection and entity disambiguation jointly. Additionally, we\ninvestigate the usefulness of entity-aware token-representations in the\ntext-understanding benchmark GLUE, as well as the question answering benchmarks\nSQUAD V2 and SWAG and also the EN-DE WMT14 machine translation benchmark. To\nour surprise, we find that most of those benchmarks do not benefit from\nadditional entity knowledge, except for a task with very small training data,\nthe RTE task in GLUE, which improves by 2%.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 18:23:00 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Broscheit", "Samuel", ""]]}, {"id": "2003.05522", "submitter": "Tom\\'a\\v{s} Musil", "authors": "Tom\\'a\\v{s} Musil", "title": "Semantic Holism and Word Representations in Artificial Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks are a state-of-the-art solution for many problems\nin natural language processing. What can we learn about language and meaning\nfrom the way artificial neural networks represent it? Word representations\nobtained from the Skip-gram variant of the word2vec model exhibit interesting\nsemantic properties. This is usually explained by referring to the general\ndistributional hypothesis, which states that the meaning of the word is given\nby the contexts where it occurs. We propose a more specific approach based on\nFrege's holistic and functional approach to meaning. Taking Tugendhat's formal\nreinterpretation of Frege's work as a starting point, we demonstrate that it is\nanalogical to the process of training the Skip-gram model and offers a possible\nexplanation of its semantic properties.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 21:04:49 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Musil", "Tom\u00e1\u0161", ""]]}, {"id": "2003.05573", "submitter": "Wai Keen Vong", "authors": "Wai Keen Vong, Brenden M. Lake", "title": "Learning word-referent mappings and concepts from raw inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How do children learn correspondences between the language and the world from\nnoisy, ambiguous, naturalistic input? One hypothesis is via cross-situational\nlearning: tracking words and their possible referents across multiple\nsituations allows learners to disambiguate correct word-referent mappings (Yu &\nSmith, 2007). However, previous models of cross-situational word learning\noperate on highly simplified representations, side-stepping two important\naspects of the actual learning problem. First, how can word-referent mappings\nbe learned from raw inputs such as images? Second, how can these learned\nmappings generalize to novel instances of a known word? In this paper, we\npresent a neural network model trained from scratch via self-supervision that\ntakes in raw images and words as inputs, and show that it can learn\nword-referent mappings from fully ambiguous scenes and utterances through\ncross-situational learning. In addition, the model generalizes to novel word\ninstances, locates referents of words in a scene, and shows a preference for\nmutual exclusivity.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 02:18:19 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Vong", "Wai Keen", ""], ["Lake", "Brenden M.", ""]]}, {"id": "2003.05574", "submitter": "Magdalena Biesialska", "authors": "Katarzyna Biesialska, Magdalena Biesialska and Henryk Rybinski", "title": "Sentiment Analysis with Contextual Embeddings and Self-Attention", "comments": "Accepted at the 25th International Symposium on Methodologies for\n  Intelligent Systems (ISMIS 2020)", "journal-ref": null, "doi": "10.1007/978-3-030-59491-6_4", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In natural language the intended meaning of a word or phrase is often\nimplicit and depends on the context. In this work, we propose a simple yet\neffective method for sentiment analysis using contextual embeddings and a\nself-attention mechanism. The experimental results for three languages,\nincluding morphologically rich Polish and German, show that our model is\ncomparable to or even outperforms state-of-the-art models. In all cases the\nsuperiority of models leveraging contextual embeddings is demonstrated.\nFinally, this work is intended as a step towards introducing a universal,\nmultilingual sentiment classifier.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 02:19:51 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 23:02:42 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Biesialska", "Katarzyna", ""], ["Biesialska", "Magdalena", ""], ["Rybinski", "Henryk", ""]]}, {"id": "2003.05758", "submitter": "Ivan P Yamshchikov", "authors": "Ivan P. Yamshchikov, Cyrille Merleau Nono Saha, Igor Samenko, J\\\"urgen\n  Jost", "title": "It Means More if It Sounds Good: Yet Another Hypothesis Concerning the\n  Evolution of Polysemous Words", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL math.MG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This position paper looks into the formation of language and shows ties\nbetween structural properties of the words in the English language and their\npolysemy. Using Ollivier-Ricci curvature over a large graph of synonyms to\nestimate polysemy it shows empirically that the words that arguably are easier\nto pronounce also tend to have multiple meanings.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 12:55:50 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 11:51:44 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Yamshchikov", "Ivan P.", ""], ["Saha", "Cyrille Merleau Nono", ""], ["Samenko", "Igor", ""], ["Jost", "J\u00fcrgen", ""]]}, {"id": "2003.05809", "submitter": "Heiko Paulheim", "authors": "Jan Portisch, Michael Hladik, Heiko Paulheim", "title": "KGvec2go -- Knowledge Graph Embeddings as a Service", "comments": "to be published in the Proceedings of the International Conference on\n  Language Resources and Evaluation (LREC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present KGvec2go, a Web API for accessing and consuming\ngraph embeddings in a light-weight fashion in downstream applications.\nCurrently, we serve pre-trained embeddings for four knowledge graphs. We\nintroduce the service and its usage, and we show further that the trained\nmodels have semantic value by evaluating them on multiple semantic benchmarks.\nThe evaluation also reveals that the combination of multiple models can lead to\na better outcome than the best individual model.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 12:57:10 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Portisch", "Jan", ""], ["Hladik", "Michael", ""], ["Paulheim", "Heiko", ""]]}, {"id": "2003.05826", "submitter": "Petra Wolf", "authors": "Petra Wolf, Henning Fernau", "title": "Regular Intersection Emptiness of Graph Problems: Finding a Needle in a\n  Haystack of Graphs with the Help of Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Int_reg-problem of a combinatorial problem P asks, given a\nnondeterministic automaton M as input, whether the language L(M) accepted by M\ncontains any positive instance of the problem P. We consider the\nInt_reg-problem for a number of different graph problems and give general\ncriteria that give decision procedures for these Int_reg-problems. To achieve\nthis goal, we consider a natural graph encoding so that the language of all\ngraph encodings is regular. Then, we draw the connection between classical\npumping- and interchange-arguments from the field of formal language theory\nwith the graph operations induced on the encoded graph. Our techniques apply\namong others to the Int_reg-problem of well-known graph problems like Vertex\nCover and Independent Set, as well as to subgraph problems, graph-edit problems\nand graph-partitioning problems, including coloring problems.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 14:51:41 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Wolf", "Petra", ""], ["Fernau", "Henning", ""]]}, {"id": "2003.05895", "submitter": "Michael Filletti", "authors": "Michael Filletti", "title": "Investigating the influence Brexit had on Financial Markets, in\n  particular the GBP/EUR exchange rate", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On 23rd June 2016, 51.9% of British voters voted to leave the European Union,\ntriggering a process and events that have led to the United Kingdom leaving the\nEU, an event that has become known as 'Brexit'. In this piece of research, we\ninvestigate the effects of this entire process on the currency markets,\nspecifically the GBP/EUR exchange rate. Financial markets are known to be\nsensitive to news articles and media, and the aim of this research is to\nevaluate the magnitude of impact of relevant events, as well as whether the\nimpact was positive or negative for the GBP.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 22:05:37 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Filletti", "Michael", ""]]}, {"id": "2003.05995", "submitter": "Francisco Javier Chiyah Garcia", "authors": "Francisco J. Chiyah Garcia, Jos\\'e Lopes, Xingkun Liu, Helen Hastie", "title": "CRWIZ: A Framework for Crowdsourcing Real-Time Wizard-of-Oz Dialogues", "comments": "10 pages, 5 figures. To Appear in LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large corpora of task-based and open-domain conversational dialogues are\nhugely valuable in the field of data-driven dialogue systems. Crowdsourcing\nplatforms, such as Amazon Mechanical Turk, have been an effective method for\ncollecting such large amounts of data. However, difficulties arise when\ntask-based dialogues require expert domain knowledge or rapid access to\ndomain-relevant information, such as databases for tourism. This will become\neven more prevalent as dialogue systems become increasingly ambitious,\nexpanding into tasks with high levels of complexity that require collaboration\nand forward planning, such as in our domain of emergency response. In this\npaper, we propose CRWIZ: a framework for collecting real-time Wizard of Oz\ndialogues through crowdsourcing for collaborative, complex tasks. This\nframework uses semi-guided dialogue to avoid interactions that breach\nprocedures and processes only known to experts, while enabling the capture of a\nwide variety of interactions. The framework is available at\nhttps://github.com/JChiyah/crwiz\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 19:47:29 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Garcia", "Francisco J. Chiyah", ""], ["Lopes", "Jos\u00e9", ""], ["Liu", "Xingkun", ""], ["Hastie", "Helen", ""]]}, {"id": "2003.06044", "submitter": "Qile Zhu", "authors": "Zhigang Dai, Jinhua Fu, Qile Zhu, Hengbin Cui, Xiaolong li, Yuan Qi", "title": "Local Contextual Attention with Hierarchical Structure for Dialogue Act\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue act recognition is a fundamental task for an intelligent dialogue\nsystem. Previous work models the whole dialog to predict dialog acts, which may\nbring the noise from unrelated sentences. In this work, we design a\nhierarchical model based on self-attention to capture intra-sentence and\ninter-sentence information. We revise the attention distribution to focus on\nthe local and contextual semantic information by incorporating the relative\nposition information between utterances. Based on the found that the length of\ndialog affects the performance, we introduce a new dialog segmentation\nmechanism to analyze the effect of dialog length and context padding length\nunder online and offline settings. The experiment shows that our method\nachieves promising performance on two datasets: Switchboard Dialogue Act and\nDailyDialog with the accuracy of 80.34\\% and 85.81\\% respectively.\nVisualization of the attention weights shows that our method can learn the\ncontext dependency between utterances explicitly.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 22:26:11 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Dai", "Zhigang", ""], ["Fu", "Jinhua", ""], ["Zhu", "Qile", ""], ["Cui", "Hengbin", ""], ["li", "Xiaolong", ""], ["Qi", "Yuan", ""]]}, {"id": "2003.06050", "submitter": "Mandana Saebi", "authors": "Mandana Saebi, Steven Krieg, Chuxu Zhang, Meng Jiang, and Nitesh\n  Chawla", "title": "Heterogeneous Relational Reasoning in Knowledge Graphs with\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Path-based relational reasoning over knowledge graphs has become increasingly\npopular due to a variety of downstream applications such as question answering\nin dialogue systems, fact prediction, and recommender systems. In recent years,\nreinforcement learning (RL) has provided solutions that are more interpretable\nand explainable than other deep learning models. However, these solutions still\nface several challenges, including large action space for the RL agent and\naccurate representation of entity neighborhood structure. We address these\nproblems by introducing a type-enhanced RL agent that uses the local\nneighborhood information for efficient path-based reasoning over knowledge\ngraphs. Our solution uses graph neural network (GNN) for encoding the\nneighborhood information and utilizes entity types to prune the action space.\nExperiments on real-world dataset show that our method outperforms\nstate-of-the-art RL methods and discovers more novel paths during the training\nprocedure.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 22:39:58 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Saebi", "Mandana", ""], ["Krieg", "Steven", ""], ["Zhang", "Chuxu", ""], ["Jiang", "Meng", ""], ["Chawla", "Nitesh", ""]]}, {"id": "2003.06071", "submitter": "Yulong Gu", "authors": "Yulong Gu, Yu Guan, Paolo Missier", "title": "Towards Learning Instantiated Logical Rules from Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficiently inducing high-level interpretable regularities from knowledge\ngraphs (KGs) is an essential yet challenging task that benefits many downstream\napplications. In this work, we present GPFL, a probabilistic rule learner\noptimized to mine instantiated first-order logic rules from KGs. Instantiated\nrules contain constants extracted from KGs. Compared to abstract rules that\ncontain no constants, instantiated rules are capable of explaining and\nexpressing concepts in more details. GPFL utilizes a novel two-stage rule\ngeneration mechanism that first generalizes extracted paths into templates that\nare acyclic abstract rules until a certain degree of template saturation is\nachieved, then specializes the generated templates into instantiated rules.\nUnlike existing works that ground every mined instantiated rule for evaluation,\nGPFL shares groundings between structurally similar rules for collective\nevaluation. Moreover, we reveal the presence of overfitting rules, their impact\non the predictive performance, and the effectiveness of a simple validation\nmethod filtering out overfitting rules. Through extensive experiments on public\nbenchmark datasets, we show that GPFL 1.) significantly reduces the runtime on\nevaluating instantiated rules; 2.) discovers much more quality instantiated\nrules than existing works; 3.) improves the predictive performance of learned\nrules by removing overfitting rules via validation; 4.) is competitive on\nknowledge graph completion task compared to state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 00:32:46 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 11:11:19 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Gu", "Yulong", ""], ["Guan", "Yu", ""], ["Missier", "Paolo", ""]]}, {"id": "2003.06094", "submitter": "Xiaoyuan Yi", "authors": "Xiaoyuan Yi, Ruoyu Li, Cheng Yang, Wenhao Li, Maosong Sun", "title": "MixPoet: Diverse Poetry Generation via Learning Controllable Mixed\n  Latent Space", "comments": "8 pages, 5 figures, published in AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an essential step towards computer creativity, automatic poetry generation\nhas gained increasing attention these years. Though recent neural models make\nprominent progress in some criteria of poetry quality, generated poems still\nsuffer from the problem of poor diversity. Related literature researches show\nthat different factors, such as life experience, historical background, etc.,\nwould influence composition styles of poets, which considerably contributes to\nthe high diversity of human-authored poetry. Inspired by this, we propose\nMixPoet, a novel model that absorbs multiple factors to create various styles\nand promote diversity. Based on a semi-supervised variational autoencoder, our\nmodel disentangles the latent space into some subspaces, with each conditioned\non one influence factor by adversarial training. In this way, the model learns\na controllable latent variable to capture and mix generalized factor-related\nproperties. Different factor mixtures lead to diverse styles and hence further\ndifferentiate generated poems from each other. Experiment results on Chinese\npoetry demonstrate that MixPoet improves both diversity and quality against\nthree state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 03:31:29 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Yi", "Xiaoyuan", ""], ["Li", "Ruoyu", ""], ["Yang", "Cheng", ""], ["Li", "Wenhao", ""], ["Sun", "Maosong", ""]]}, {"id": "2003.06190", "submitter": "Noe Cecillon", "authors": "No\\'e Cecillon (LIA), Vincent Labatut (LIA), Richard Dufour (LIA),\n  Georges Linares (LIA)", "title": "WAC: A Corpus of Wikipedia Conversations for Online Abuse Detection", "comments": null, "journal-ref": "12th Language Resources and Evaluation Conference (LREC 2020),\n  p.1375-1383 , May 2020, Marseille, France", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the spread of online social networks, it is more and more difficult to\nmonitor all the user-generated content. Automating the moderation process of\nthe inappropriate exchange content on Internet has thus become a priority task.\nMethods have been proposed for this purpose, but it can be challenging to find\na suitable dataset to train and develop them. This issue is especially true for\napproaches based on information derived from the structure and the dynamic of\nthe conversation. In this work, we propose an original framework, based on the\nWikipedia Comment corpus, with comment-level abuse annotations of different\ntypes. The major contribution concerns the reconstruction of conversations, by\ncomparison to existing corpora, which focus only on isolated messages (i.e.\ntaken out of their conversational context). This large corpus of more than 380k\nannotated messages opens perspectives for online abuse detection and especially\nfor context-based approaches. We also propose, in addition to this corpus, a\ncomplete benchmarking platform to stimulate and fairly compare scientific works\naround the problem of content abuse detection, trying to avoid the recurring\nproblem of result replication. Finally, we apply two classification methods to\nour dataset to demonstrate its potential.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 10:26:45 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Cecillon", "No\u00e9", "", "LIA"], ["Labatut", "Vincent", "", "LIA"], ["Dufour", "Richard", "", "LIA"], ["Linares", "Georges", "", "LIA"]]}, {"id": "2003.06209", "submitter": "Wenxuan Zhang", "authors": "Wenxuan Zhang, Wai Lam, Yang Deng, Jing Ma", "title": "Review-guided Helpful Answer Identification in E-commerce", "comments": "Accepted by WWW2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Product-specific community question answering platforms can greatly help\naddress the concerns of potential customers. However, the user-provided answers\non such platforms often vary a lot in their qualities. Helpfulness votes from\nthe community can indicate the overall quality of the answer, but they are\noften missing. Accurately predicting the helpfulness of an answer to a given\nquestion and thus identifying helpful answers is becoming a demanding need.\nSince the helpfulness of an answer depends on multiple perspectives instead of\nonly topical relevance investigated in typical QA tasks, common answer\nselection algorithms are insufficient for tackling this task. In this paper, we\npropose the Review-guided Answer Helpfulness Prediction (RAHP) model that not\nonly considers the interactions between QA pairs but also investigates the\nopinion coherence between the answer and crowds' opinions reflected in the\nreviews, which is another important factor to identify helpful answers.\nMoreover, we tackle the task of determining opinion coherence as a language\ninference problem and explore the utilization of pre-training strategy to\ntransfer the textual inference knowledge obtained from a specifically designed\ntrained network. Extensive experiments conducted on real-world data across\nseven product categories show that our proposed model achieves superior\nperformance on the prediction task.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 11:34:29 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Zhang", "Wenxuan", ""], ["Lam", "Wai", ""], ["Deng", "Yang", ""], ["Ma", "Jing", ""]]}, {"id": "2003.06279", "submitter": "Diego Amancio", "authors": "Laura V. C. Quispe and Jorge A. V. Tohalino and Diego R. Amancio", "title": "Using word embeddings to improve the discriminability of co-occurrence\n  text networks", "comments": null, "journal-ref": "Physica A 562, 125344, 2021", "doi": "10.1016/j.physa.2020.125344", "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word co-occurrence networks have been employed to analyze texts both in the\npractical and theoretical scenarios. Despite the relative success in several\napplications, traditional co-occurrence networks fail in establishing links\nbetween similar words whenever they appear distant in the text. Here we\ninvestigate whether the use of word embeddings as a tool to create virtual\nlinks in co-occurrence networks may improve the quality of classification\nsystems. Our results revealed that the discriminability in the stylometry task\nis improved when using Glove, Word2Vec and FastText. In addition, we found that\noptimized results are obtained when stopwords are not disregarded and a simple\nglobal thresholding strategy is used to establish virtual links. Because the\nproposed approach is able to improve the representation of texts as complex\nnetworks, we believe that it could be extended to study other natural language\nprocessing tasks. Likewise, theoretical languages studies could benefit from\nthe adopted enriched representation of word co-occurrence networks.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 13:35:44 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Quispe", "Laura V. C.", ""], ["Tohalino", "Jorge A. V.", ""], ["Amancio", "Diego R.", ""]]}, {"id": "2003.06381", "submitter": "Serge Sharoff", "authors": "Yu Yuan, Serge Sharoff", "title": "Sentence Level Human Translation Quality Estimation with Attention-based\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the use of Deep Learning methods for automatic estimation\nof quality of human translations. Automatic estimation can provide useful\nfeedback for translation teaching, examination and quality control.\nConventional methods for solving this task rely on manually engineered features\nand external knowledge. This paper presents an end-to-end neural model without\nfeature engineering, incorporating a cross attention mechanism to detect which\nparts in sentence pairs are most relevant for assessing quality. Another\ncontribution concerns of prediction of fine-grained scores for measuring\ndifferent aspects of translation quality. Empirical results on a large human\nannotated dataset show that the neural model outperforms feature-based methods\nsignificantly. The dataset and the tools are available.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 16:57:55 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Yuan", "Yu", ""], ["Sharoff", "Serge", ""]]}, {"id": "2003.06389", "submitter": "Serge Sharoff", "authors": "Serge Sharoff", "title": "Know thy corpus! Robust methods for digital curation of Web corpora", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel framework for digital curation of Web corpora in\norder to provide robust estimation of their parameters, such as their\ncomposition and the lexicon. In recent years language models pre-trained on\nlarge corpora emerged as clear winners in numerous NLP tasks, but no proper\nanalysis of the corpora which led to their success has been conducted. The\npaper presents a procedure for robust frequency estimation, which helps in\nestablishing the core lexicon for a given corpus, as well as a procedure for\nestimating the corpus composition via unsupervised topic models and via\nsupervised genre classification of Web pages. The results of the digital\ncuration study applied to several Web-derived corpora demonstrate their\nconsiderable differences. First, this concerns different frequency bursts which\nimpact the core lexicon obtained from each corpus. Second, this concerns the\nkinds of texts they contain. For example, OpenWebText contains considerably\nmore topical news and political argumentation in comparison to ukWac or\nWikipedia. The tools and the results of analysis have been released.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 17:21:57 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Sharoff", "Serge", ""]]}, {"id": "2003.06499", "submitter": "Hadi Abdi Khojasteh", "authors": "Hadi Abdi Khojasteh, Ebrahim Ansari, Mahdi Bohlouli", "title": "LSCP: Enhanced Large Scale Colloquial Persian Language Understanding", "comments": "6 pages, 2 figures, 3 tables, Accepted at the 12th International\n  Conference on Language Resources and Evaluation (LREC 2020)", "journal-ref": "https://www.aclweb.org/anthology/2020.lrec-1.776/", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language recognition has been significantly advanced in recent years by means\nof modern machine learning methods such as deep learning and benchmarks with\nrich annotations. However, research is still limited in low-resource formal\nlanguages. This consists of a significant gap in describing the colloquial\nlanguage especially for low-resourced ones such as Persian. In order to target\nthis gap for low resource languages, we propose a \"Large Scale Colloquial\nPersian Dataset\" (LSCP). LSCP is hierarchically organized in a semantic\ntaxonomy that focuses on multi-task informal Persian language understanding as\na comprehensive problem. This encompasses the recognition of multiple semantic\naspects in the human-level sentences, which naturally captures from the\nreal-world sentences. We believe that further investigations and processing, as\nwell as the application of novel algorithms and methods, can strengthen\nenriching computerized understanding and processing of low resource languages.\nThe proposed corpus consists of 120M sentences resulted from 27M tweets\nannotated with parsing tree, part-of-speech tags, sentiment polarity and\ntranslation in five different languages.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 22:24:14 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Khojasteh", "Hadi Abdi", ""], ["Ansari", "Ebrahim", ""], ["Bohlouli", "Mahdi", ""]]}, {"id": "2003.06514", "submitter": "Chang Xu", "authors": "Chang Xu, Cecile Paris, Surya Nepal, Ross Sparks, Chong Long, Yafang\n  Wang", "title": "DAN: Dual-View Representation Learning for Adapting Stance Classifiers\n  to New Domains", "comments": "Accepted at ECAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the issue of having a limited number of annotations for stance\nclassification in a new domain, by adapting out-of-domain classifiers with\ndomain adaptation. Existing approaches often align different domains in a\nsingle, global feature space (or view), which may fail to fully capture the\nrichness of the languages used for expressing stances, leading to reduced\nadaptability on stance data. In this paper, we identify two major types of\nstance expressions that are linguistically distinct, and we propose a tailored\ndual-view adaptation network (DAN) to adapt these expressions across domains.\nThe proposed model first learns a separate view for domain transfer in each\nexpression channel and then selects the best adapted parts of both views for\noptimal transfer. We find that the learned view features can be more easily\naligned and more stance-discriminative in either or both views, leading to more\ntransferable overall features after combining the views. Results from extensive\nexperiments show that our method can enhance the state-of-the-art single-view\nmethods in matching stance data across different domains, and that it\nconsistently improves those methods on various adaptation tasks.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 23:56:37 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Xu", "Chang", ""], ["Paris", "Cecile", ""], ["Nepal", "Surya", ""], ["Sparks", "Ross", ""], ["Long", "Chong", ""], ["Wang", "Yafang", ""]]}, {"id": "2003.06561", "submitter": "Gengchen Mai", "authors": "Gengchen Mai, Krzysztof Janowicz, Sathya Prasad, Meilin Shi, Ling Cai,\n  Rui Zhu, Blake Regalia, Ni Lao", "title": "Semantically-Enriched Search Engine for Geoportals: A Case Study with\n  ArcGIS Online", "comments": "18 pages; Accepted to AGILE 2020 as a full paper GitHub Code\n  Repository: https://github.com/gengchenmai/arcgis-online-search-engine", "journal-ref": "AGILE 2020, Jun. 16 - 19, 2020, Chania, Crete, Greece", "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many geoportals such as ArcGIS Online are established with the goal of\nimproving geospatial data reusability and achieving intelligent knowledge\ndiscovery. However, according to previous research, most of the existing\ngeoportals adopt Lucene-based techniques to achieve their core search\nfunctionality, which has a limited ability to capture the user's search\nintentions. To better understand a user's search intention, query expansion can\nbe used to enrich the user's query by adding semantically similar terms. In the\ncontext of geoportals and geographic information retrieval, we advocate the\nidea of semantically enriching a user's query from both geospatial and thematic\nperspectives. In the geospatial aspect, we propose to enrich a query by using\nboth place partonomy and distance decay. In terms of the thematic aspect,\nconcept expansion and embedding-based document similarity are used to infer the\nimplicit information hidden in a user's query. This semantic query expansion 1\n2 G. Mai et al. framework is implemented as a semantically-enriched search\nengine using ArcGIS Online as a case study. A benchmark dataset is constructed\nto evaluate the proposed framework. Our evaluation results show that the\nproposed semantic query expansion framework is very effective in capturing a\nuser's search intention and significantly outperforms a well-established\nbaseline-Lucene's practical scoring function-with more than 3.0 increments in\nDCG@K (K=3,5,10).\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 06:16:30 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Mai", "Gengchen", ""], ["Janowicz", "Krzysztof", ""], ["Prasad", "Sathya", ""], ["Shi", "Meilin", ""], ["Cai", "Ling", ""], ["Zhu", "Rui", ""], ["Regalia", "Blake", ""], ["Lao", "Ni", ""]]}, {"id": "2003.06576", "submitter": "Long Chen", "authors": "Long Chen, Xin Yan, Jun Xiao, Hanwang Zhang, Shiliang Pu, Yueting\n  Zhuang", "title": "Counterfactual Samples Synthesizing for Robust Visual Question Answering", "comments": "Appear in CVPR 2020; Codes in https://github.com/yanxinzju/CSS-VQA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite Visual Question Answering (VQA) has realized impressive progress over\nthe last few years, today's VQA models tend to capture superficial linguistic\ncorrelations in the train set and fail to generalize to the test set with\ndifferent QA distributions. To reduce the language biases, several recent works\nintroduce an auxiliary question-only model to regularize the training of\ntargeted VQA model, and achieve dominating performance on VQA-CP. However,\nsince the complexity of design, current methods are unable to equip the\nensemble-based models with two indispensable characteristics of an ideal VQA\nmodel: 1) visual-explainable: the model should rely on the right visual regions\nwhen making decisions. 2) question-sensitive: the model should be sensitive to\nthe linguistic variations in question. To this end, we propose a model-agnostic\nCounterfactual Samples Synthesizing (CSS) training scheme. The CSS generates\nnumerous counterfactual training samples by masking critical objects in images\nor words in questions, and assigning different ground-truth answers. After\ntraining with the complementary samples (ie, the original and generated\nsamples), the VQA models are forced to focus on all critical objects and words,\nwhich significantly improves both visual-explainable and question-sensitive\nabilities. In return, the performance of these models is further boosted.\nExtensive ablations have shown the effectiveness of CSS. Particularly, by\nbuilding on top of the model LMH, we achieve a record-breaking performance of\n58.95% on VQA-CP v2, with 6.5% gains.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 08:34:31 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Chen", "Long", ""], ["Yan", "Xin", ""], ["Xiao", "Jun", ""], ["Zhang", "Hanwang", ""], ["Pu", "Shiliang", ""], ["Zhuang", "Yueting", ""]]}, {"id": "2003.06634", "submitter": "Caio Almeida", "authors": "Caio Almeida and D\\'ebora Santos", "title": "Text Similarity Using Word Embeddings to Classify Misinformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fake news is a growing problem in the last years, especially during\nelections. It's hard work to identify what is true and what is false among all\nthe user generated content that circulates every day. Technology can help with\nthat work and optimize the fact-checking process. In this work, we address the\nchallenge of finding similar content in order to be able to suggest to a\nfact-checker articles that could have been verified before and thus avoid that\nthe same information is verified more than once. This is especially important\nin collaborative approaches to fact-checking where members of large teams will\nnot know what content others have already fact-checked.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 14:02:27 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Almeida", "Caio", ""], ["Santos", "D\u00e9bora", ""]]}, {"id": "2003.06651", "submitter": "Dmitry Ustalov", "authors": "Varvara Logacheva and Denis Teslenko and Artem Shelmanov and Steffen\n  Remus and Dmitry Ustalov and Andrey Kutuzov and Ekaterina Artemova and Chris\n  Biemann and Simone Paolo Ponzetto and Alexander Panchenko", "title": "Word Sense Disambiguation for 158 Languages using Word Embeddings Only", "comments": "10 pages, 5 figures, 4 tables, accepted at LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disambiguation of word senses in context is easy for humans, but is a major\nchallenge for automatic approaches. Sophisticated supervised and\nknowledge-based models were developed to solve this task. However, (i) the\ninherent Zipfian distribution of supervised training instances for a given word\nand/or (ii) the quality of linguistic knowledge representations motivate the\ndevelopment of completely unsupervised and knowledge-free approaches to word\nsense disambiguation (WSD). They are particularly useful for under-resourced\nlanguages which do not have any resources for building either supervised and/or\nknowledge-based models. In this paper, we present a method that takes as input\na standard pre-trained word embedding model and induces a fully-fledged word\nsense inventory, which can be used for disambiguation in context. We use this\nmethod to induce a collection of sense inventories for 158 languages on the\nbasis of the original pre-trained fastText word embeddings by Grave et al.\n(2018), enabling WSD in these languages. Models and system are available\nonline.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 14:50:04 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Logacheva", "Varvara", ""], ["Teslenko", "Denis", ""], ["Shelmanov", "Artem", ""], ["Remus", "Steffen", ""], ["Ustalov", "Dmitry", ""], ["Kutuzov", "Andrey", ""], ["Artemova", "Ekaterina", ""], ["Biemann", "Chris", ""], ["Ponzetto", "Simone Paolo", ""], ["Panchenko", "Alexander", ""]]}, {"id": "2003.06658", "submitter": "Ning Shi", "authors": "Ning Shi", "title": "Synonymous Generalization in Sequence-to-Sequence Recurrent Networks", "comments": "7 pages, 1 figure, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When learning a language, people can quickly expand their understanding of\nthe unknown content by using compositional skills, such as from two words \"go\"\nand \"fast\" to a new phrase \"go fast.\" In recent work of Lake and Baroni (2017),\nmodern Sequence-to-Sequence(seq2seq) Recurrent Neural Networks (RNNs) can make\npowerful zero-shot generalizations in specifically controlled experiments.\nHowever, there is a missing regarding the property of such strong\ngeneralization and its precise requirements. This paper explores this positive\nresult in detail and defines this pattern as the synonymous generalization, an\nability to recognize an unknown sequence by decomposing the difference between\nit and a known sequence as corresponding existing synonyms. To better\ninvestigate it, I introduce a new environment called Colorful Extended Cleanup\nWorld (CECW), which consists of complex commands paired with logical\nexpressions. While demonstrating that sequential RNNs can perform synonymous\ngeneralizations on foreign commands, I conclude their prerequisites for\nsuccess. I also propose a data augmentation method, which is successfully\nverified on the Geoquery (GEO) dataset, as a novel application of synonymous\ngeneralization for real cases.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 15:27:29 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 15:59:26 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Shi", "Ning", ""]]}, {"id": "2003.06686", "submitter": "Zack Hodari", "authors": "Zack Hodari, Catherine Lai, Simon King", "title": "Perception of prosodic variation for speech synthesis using an\n  unsupervised discrete representation of F0", "comments": "Published to the 10th ISCA International Conference on Speech Prosody\n  (SP2020)", "journal-ref": null, "doi": "10.21437/SpeechProsody.2020-197", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In English, prosody adds a broad range of information to segment sequences,\nfrom information structure (e.g. contrast) to stylistic variation (e.g.\nexpression of emotion). However, when learning to control prosody in\ntext-to-speech voices, it is not clear what exactly the control is modifying.\nExisting research on discrete representation learning for prosody has\ndemonstrated high naturalness, but no analysis has been performed on what these\nrepresentations capture, or if they can generate meaningfully-distinct variants\nof an utterance. We present a phrase-level variational autoencoder with a\nmulti-modal prior, using the mode centres as \"intonation codes\". Our evaluation\nestablishes which intonation codes are perceptually distinct, finding that the\nintonation codes from our multi-modal latent model were significantly more\ndistinct than a baseline using k-means clustering. We carry out a follow-up\nqualitative study to determine what information the codes are carrying. Most\ncommonly, listeners commented on the intonation codes having a statement or\nquestion style. However, many other affect-related styles were also reported,\nincluding: emotional, uncertain, surprised, sarcastic, passive aggressive, and\nupset.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 19:17:42 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Hodari", "Zack", ""], ["Lai", "Catherine", ""], ["King", "Simon", ""]]}, {"id": "2003.06745", "submitter": "Yi Zhu", "authors": "Yi Zhu, Fengda Zhu, Zhaohuan Zhan, Bingqian Lin, Jianbin Jiao, Xiaojun\n  Chang, Xiaodan Liang", "title": "Vision-Dialog Navigation by Exploring Cross-modal Memory", "comments": "CVPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision-dialog navigation posed as a new holy-grail task in vision-language\ndisciplinary targets at learning an agent endowed with the capability of\nconstant conversation for help with natural language and navigating according\nto human responses. Besides the common challenges faced in visual language\nnavigation, vision-dialog navigation also requires to handle well with the\nlanguage intentions of a series of questions about the temporal context from\ndialogue history and co-reasoning both dialogs and visual scenes. In this\npaper, we propose the Cross-modal Memory Network (CMN) for remembering and\nunderstanding the rich information relevant to historical navigation actions.\nOur CMN consists of two memory modules, the language memory module (L-mem) and\nthe visual memory module (V-mem). Specifically, L-mem learns latent\nrelationships between the current language interaction and a dialog history by\nemploying a multi-head attention mechanism. V-mem learns to associate the\ncurrent visual views and the cross-modal memory about the previous navigation\nactions. The cross-modal memory is generated via a vision-to-language attention\nand a language-to-vision attention. Benefiting from the collaborative learning\nof the L-mem and the V-mem, our CMN is able to explore the memory about the\ndecision making of historical navigation actions which is for the current step.\nExperiments on the CVDN dataset show that our CMN outperforms the previous\nstate-of-the-art model by a significant margin on both seen and unseen\nenvironments.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 03:08:06 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Zhu", "Yi", ""], ["Zhu", "Fengda", ""], ["Zhan", "Zhaohuan", ""], ["Lin", "Bingqian", ""], ["Jiao", "Jianbin", ""], ["Chang", "Xiaojun", ""], ["Liang", "Xiaodan", ""]]}, {"id": "2003.06858", "submitter": "Nguyen Thi Thanh Thuy", "authors": "Nguyen Thi Thanh Thuy, Ngo Xuan Bach, Tu Minh Phuong", "title": "Leveraging Foreign Language Labeled Data for Aspect-Based Opinion Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-based opinion mining is the task of identifying sentiment at the\naspect level in opinionated text, which consists of two subtasks: aspect\ncategory extraction and sentiment polarity classification. While aspect\ncategory extraction aims to detect and categorize opinion targets such as\nproduct features, sentiment polarity classification assigns a sentiment label,\ni.e. positive, negative, or neutral, to each identified aspect. Supervised\nlearning methods have been shown to deliver better accuracy for this task but\nthey require labeled data, which is costly to obtain, especially for\nresource-poor languages like Vietnamese. To address this problem, we present a\nsupervised aspect-based opinion mining method that utilizes labeled data from a\nforeign language (English in this case), which is translated to Vietnamese by\nan automated translation tool (Google Translate). Because aspects and opinions\nin different languages may be expressed by different words, we propose using\nword embeddings, in addition to other features, to reduce the vocabulary\ndifference between the original and translated texts, thus improving the\neffectiveness of aspect category extraction and sentiment polarity\nclassification processes. We also introduce an annotated corpus of aspect\ncategories and sentiment polarities extracted from restaurant reviews in\nVietnamese, and conduct a series of experiments on the corpus. Experimental\nresults demonstrate the effectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 15:53:53 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Thuy", "Nguyen Thi Thanh", ""], ["Bach", "Ngo Xuan", ""], ["Phuong", "Tu Minh", ""]]}, {"id": "2003.06894", "submitter": "Natalia Tomashenko", "authors": "Natalia Tomashenko, Yuri Khokhlov, Yannick Esteve", "title": "Exploring Gaussian mixture model framework for speaker adaptation of\n  deep neural network acoustic models", "comments": "36 pages; originally was submitted to CSL in February 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the GMM-derived (GMMD) features for adaptation\nof deep neural network (DNN) acoustic models. The adaptation of the DNN trained\non GMMD features is done through the maximum a posteriori (MAP) adaptation of\nthe auxiliary GMM model used for GMMD feature extraction. We explore fusion of\nthe adapted GMMD features with conventional features, such as bottleneck and\nMFCC features, in two different neural network architectures: DNN and\ntime-delay neural network (TDNN). We analyze and compare different types of\nadaptation techniques such as i-vectors and feature-space adaptation techniques\nbased on maximum likelihood linear regression (fMLLR) with the proposed\nadaptation approach, and explore their complementarity using various types of\nfusion such as feature level, posterior level, lattice level and others in\norder to discover the best possible way of combination. Experimental results on\nthe TED-LIUM corpus show that the proposed adaptation technique can be\neffectively integrated into DNN and TDNN setups at different levels and provide\nadditional gain in recognition performance: up to 6% of relative word error\nrate reduction (WERR) over the strong feature-space adaptation techniques based\non maximum likelihood linear regression (fMLLR) speaker adapted DNN baseline,\nand up to 18% of relative WERR in comparison with a speaker independent (SI)\nDNN baseline model, trained on conventional features. For TDNN models the\nproposed approach achieves up to 26% of relative WERR in comparison with a SI\nbaseline, and up 13% in comparison with the model adapted by using i-vectors.\nThe analysis of the adapted GMMD features from various points of view\ndemonstrates their effectiveness at different levels.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 18:56:19 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Tomashenko", "Natalia", ""], ["Khokhlov", "Yuri", ""], ["Esteve", "Yannick", ""]]}, {"id": "2003.07000", "submitter": "Zhiheng Huang", "authors": "Zhiheng Huang, Peng Xu, Davis Liang, Ajay Mishra, Bing Xiang", "title": "TRANS-BLSTM: Transformer with Bidirectional LSTM for Language\n  Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bidirectional Encoder Representations from Transformers (BERT) has recently\nachieved state-of-the-art performance on a broad range of NLP tasks including\nsentence classification, machine translation, and question answering. The BERT\nmodel architecture is derived primarily from the transformer. Prior to the\ntransformer era, bidirectional Long Short-Term Memory (BLSTM) has been the\ndominant modeling architecture for neural machine translation and question\nanswering. In this paper, we investigate how these two modeling techniques can\nbe combined to create a more powerful model architecture. We propose a new\narchitecture denoted as Transformer with BLSTM (TRANS-BLSTM) which has a BLSTM\nlayer integrated to each transformer block, leading to a joint modeling\nframework for transformer and BLSTM. We show that TRANS-BLSTM models\nconsistently lead to improvements in accuracy compared to BERT baselines in\nGLUE and SQuAD 1.1 experiments. Our TRANS-BLSTM model obtains an F1 score of\n94.01% on the SQuAD 1.1 development dataset, which is comparable to the\nstate-of-the-art result.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 03:38:51 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Huang", "Zhiheng", ""], ["Xu", "Peng", ""], ["Liang", "Davis", ""], ["Mishra", "Ajay", ""], ["Xiang", "Bing", ""]]}, {"id": "2003.07008", "submitter": "Marcos Zampieri", "authors": "Matthew Shardlow, Michael Cooper, Marcos Zampieri", "title": "CompLex: A New Corpus for Lexical Complexity Prediction from Likert\n  Scale Data", "comments": "Proceedings of the 1st Workshop on Tools and Resources to Empower\n  People with REAding DIfficulties (READI). pp. 57-62", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting which words are considered hard to understand for a given target\npopulation is a vital step in many NLP applications such as text\nsimplification. This task is commonly referred to as Complex Word\nIdentification (CWI). With a few exceptions, previous studies have approached\nthe task as a binary classification task in which systems predict a complexity\nvalue (complex vs. non-complex) for a set of target words in a text. This\nchoice is motivated by the fact that all CWI datasets compiled so far have been\nannotated using a binary annotation scheme. Our paper addresses this limitation\nby presenting the first English dataset for continuous lexical complexity\nprediction. We use a 5-point Likert scale scheme to annotate complex words in\ntexts from three sources/domains: the Bible, Europarl, and biomedical texts.\nThis resulted in a corpus of 9,476 sentences each annotated by around 7\nannotators.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 03:54:22 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 02:37:40 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 16:42:55 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Shardlow", "Matthew", ""], ["Cooper", "Michael", ""], ["Zampieri", "Marcos", ""]]}, {"id": "2003.07019", "submitter": "Manikandan Ravikiran", "authors": "Manikandan Ravikiran", "title": "Key Phrase Classification in Complex Assignments", "comments": "v1 preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Complex assignments typically consist of open-ended questions with large and\ndiverse content in the context of both classroom and online graduate programs.\nWith the sheer scale of these programs comes a variety of problems in peer and\nexpert feedback, including rogue reviews. As such with the hope of identifying\nimportant contents needed for the review, in this work we present a very first\nwork on key phrase classification with a detailed empirical study on\ntraditional and most recent language modeling approaches. From this study, we\nfind that the task of classification of key phrases is ambiguous at a human\nlevel producing Cohen's kappa of 0.77 on a new data set. Both pretrained\nlanguage models and simple TFIDF SVM classifiers produce similar results with a\nformer producing average of 0.6 F1 higher than the latter. We finally derive\npractical advice from our extensive empirical and model interpretability\nresults for those interested in key phrase classification from educational\nreports in the future.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 04:25:37 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Ravikiran", "Manikandan", ""]]}, {"id": "2003.07074", "submitter": "Tavpritesh Sethi", "authors": "Rohan Pandey, Vaibhav Gautam, Ridam Pal, Harsh Bandhey, Lovedeep Singh\n  Dhingra, Himanshu Sharma, Chirag Jain, Kanav Bhagat, Arushi, Lajjaben Patel,\n  Mudit Agarwal, Samprati Agrawal, Rishabh Jalan, Akshat Wadhwa, Ayush Garg,\n  Vihaan Misra, Yashwin Agrawal, Bhavika Rana, Ponnurangam Kumaraguru,\n  Tavpritesh Sethi", "title": "A Machine Learning Application for Raising WASH Awareness in the Times\n  of COVID-19 Pandemic", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background: The COVID-19 pandemic has uncovered the potential of digital\nmisinformation in shaping the health of nations. The deluge of unverified\ninformation that spreads faster than the epidemic itself is an unprecedented\nphenomenon that has put millions of lives in danger. Mitigating this Infodemic\nrequires strong health messaging systems that are engaging, vernacular,\nscalable, effective and continuously learn the new patterns of misinformation.\n  Objective: We created WashKaro, a multi-pronged intervention for mitigating\nmisinformation through conversational AI, machine translation and natural\nlanguage processing. WashKaro provides the right information matched against\nWHO guidelines through AI, and delivers it in the right format in local\nlanguages.\n  Methods: We theorize (i) an NLP based AI engine that could continuously\nincorporate user feedback to improve relevance of information, (ii) bite sized\naudio in the local language to improve penetrance in a country with skewed\ngender literacy ratios, and (iii) conversational but interactive AI engagement\nwith users towards an increased health awareness in the community. Results: A\ntotal of 5026 people who downloaded the app during the study window, among\nthose 1545 were active users. Our study shows that 3.4 times more females\nengaged with the App in Hindi as compared to males, the relevance of\nAI-filtered news content doubled within 45 days of continuous machine learning,\nand the prudence of integrated AI chatbot Satya increased thus proving the\nusefulness of an mHealth platform to mitigate health misinformation.\n  Conclusion: We conclude that a multi-pronged machine learning application\ndelivering vernacular bite-sized audios and conversational AI is an effective\napproach to mitigate health misinformation.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 08:51:40 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 09:14:47 GMT"}, {"version": "v3", "created": "Fri, 30 Oct 2020 15:49:04 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Pandey", "Rohan", ""], ["Gautam", "Vaibhav", ""], ["Pal", "Ridam", ""], ["Bandhey", "Harsh", ""], ["Dhingra", "Lovedeep Singh", ""], ["Sharma", "Himanshu", ""], ["Jain", "Chirag", ""], ["Bhagat", "Kanav", ""], ["Arushi", "", ""], ["Patel", "Lajjaben", ""], ["Agarwal", "Mudit", ""], ["Agrawal", "Samprati", ""], ["Jalan", "Rishabh", ""], ["Wadhwa", "Akshat", ""], ["Garg", "Ayush", ""], ["Misra", "Vihaan", ""], ["Agrawal", "Yashwin", ""], ["Rana", "Bhavika", ""], ["Kumaraguru", "Ponnurangam", ""], ["Sethi", "Tavpritesh", ""]]}, {"id": "2003.07082", "submitter": "Yuhao Zhang", "authors": "Peng Qi, Yuhao Zhang, Yuhui Zhang, Jason Bolton, Christopher D.\n  Manning", "title": "Stanza: A Python Natural Language Processing Toolkit for Many Human\n  Languages", "comments": "ACL2020 System Demonstration. First two authors contribute equally.\n  Website: https://stanfordnlp.github.io/stanza", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Stanza, an open-source Python natural language processing\ntoolkit supporting 66 human languages. Compared to existing widely used\ntoolkits, Stanza features a language-agnostic fully neural pipeline for text\nanalysis, including tokenization, multi-word token expansion, lemmatization,\npart-of-speech and morphological feature tagging, dependency parsing, and named\nentity recognition. We have trained Stanza on a total of 112 datasets,\nincluding the Universal Dependencies treebanks and other multilingual corpora,\nand show that the same neural architecture generalizes well and achieves\ncompetitive performance on all languages tested. Additionally, Stanza includes\na native Python interface to the widely used Java Stanford CoreNLP software,\nwhich further extends its functionality to cover other tasks such as\ncoreference resolution and relation extraction. Source code, documentation, and\npretrained models for 66 languages are available at\nhttps://stanfordnlp.github.io/stanza.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 09:05:53 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 04:22:16 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Qi", "Peng", ""], ["Zhang", "Yuhao", ""], ["Zhang", "Yuhui", ""], ["Bolton", "Jason", ""], ["Manning", "Christopher D.", ""]]}, {"id": "2003.07278", "submitter": "Qi Liu", "authors": "Qi Liu, Matt J. Kusner, Phil Blunsom", "title": "A Survey on Contextual Embeddings", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual embeddings, such as ELMo and BERT, move beyond global word\nrepresentations like Word2Vec and achieve ground-breaking performance on a wide\nrange of natural language processing tasks. Contextual embeddings assign each\nword a representation based on its context, thereby capturing uses of words\nacross varied contexts and encoding knowledge that transfers across languages.\nIn this survey, we review existing contextual embedding models, cross-lingual\npolyglot pre-training, the application of contextual embeddings in downstream\ntasks, model compression, and model analyses.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 15:22:22 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 10:49:17 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Liu", "Qi", ""], ["Kusner", "Matt J.", ""], ["Blunsom", "Phil", ""]]}, {"id": "2003.07370", "submitter": "Vivian Lai", "authors": "Vivian Lai, Samuel Carton, Chenhao Tan", "title": "Harnessing Explanations to Bridge AI and Humans", "comments": "4 pages, CHI 2020 Fair & Responsible AI Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are increasingly integrated into societally critical\napplications such as recidivism prediction and medical diagnosis, thanks to\ntheir superior predictive power. In these applications, however, full\nautomation is often not desired due to ethical and legal concerns. The research\ncommunity has thus ventured into developing interpretable methods that explain\nmachine predictions. While these explanations are meant to assist humans in\nunderstanding machine predictions and thereby allowing humans to make better\ndecisions, this hypothesis is not supported in many recent studies. To improve\nhuman decision-making with AI assistance, we propose future directions for\nclosing the gap between the efficacy of explanations and improvement in human\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 18:00:02 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Lai", "Vivian", ""], ["Carton", "Samuel", ""], ["Tan", "Chenhao", ""]]}, {"id": "2003.07385", "submitter": "Nikhil Krishnaswamy", "authors": "Nikhil Krishnaswamy and James Pustejovsky", "title": "A Formal Analysis of Multimodal Referring Strategies Under Common Ground", "comments": "9 pages (incl refs), 7 figures, 3 tables, proceedings of LREC 2020\n  (postponed due to COVID-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an analysis of computationally generated\nmixed-modality definite referring expressions using combinations of gesture and\nlinguistic descriptions. In doing so, we expose some striking formal semantic\nproperties of the interactions between gesture and language, conditioned on the\nintroduction of content into the common ground between the (computational)\nspeaker and (human) viewer, and demonstrate how these formal features can\ncontribute to training better models to predict viewer judgment of referring\nexpressions, and potentially to the generation of more natural and informative\nreferring expressions.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 18:08:52 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Krishnaswamy", "Nikhil", ""], ["Pustejovsky", "James", ""]]}, {"id": "2003.07424", "submitter": "Lenz Furrer", "authors": "Lenz Furrer (1 and 3), Joseph Cornelius (1), Fabio Rinaldi (1, 2, and\n  3) ((1) University of Zurich, Switzerland, (2) Dalle Molle Institute for\n  Artificial Intelligence Research (IDSIA), Switzerland, (3) Swiss Institute of\n  Bioinformatics, Switzerland)", "title": "Parallel sequence tagging for concept recognition", "comments": "14 pages, 5 figures; style changed, sections reordered, minor\n  additions suggested by reviewers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Named Entity Recognition (NER) and Normalisation (NEN) are core\ncomponents of any text-mining system for biomedical texts. In a traditional\nconcept-recognition pipeline, these tasks are combined in a serial way, which\nis inherently prone to error propagation from NER to NEN. We propose a parallel\narchitecture, where both NER and NEN are modeled as a sequence-labeling task,\noperating directly on the source text. We examine different harmonisation\nstrategies for merging the predictions of the two classifiers into a single\noutput sequence. Results: We test our approach on the recent Version 4 of the\nCRAFT corpus. In all 20 annotation sets of the concept-annotation task, our\nsystem outperforms the pipeline system reported as a baseline in the CRAFT\nshared task 2019. Conclusions: Our analysis shows that the strengths of the two\nclassifiers can be combined in a fruitful way. However, prediction\nharmonisation requires individual calibration on a development set for each\nannotation set. This allows achieving a good trade-off between established\nknowledge (training set) and novel information (unseen concepts). Availability\nand Implementation: Source code freely available for download at\nhttps://github.com/OntoGene/craft-st. Supplementary data are available at arXiv\nonline.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 19:41:07 GMT"}, {"version": "v2", "created": "Sat, 8 Aug 2020 07:54:17 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Furrer", "Lenz", "", "1 and 3"], ["Cornelius", "Joseph", "", "1, 2, and\n  3"], ["Rinaldi", "Fabio", "", "1, 2, and\n  3"]]}, {"id": "2003.07428", "submitter": "Ritesh Kumar", "authors": "Shiladitya Bhattacharya, Siddharth Singh, Ritesh Kumar, Akanksha\n  Bansal, Akash Bhagat, Yogesh Dawer, Bornini Lahiri, Atul Kr. Ojha", "title": "Developing a Multilingual Annotated Corpus of Misogyny and Aggression", "comments": "Submitted for review to Second Workshop on Trolling, Aggression and\n  Cyberbullying (TRAC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss the development of a multilingual annotated corpus\nof misogyny and aggression in Indian English, Hindi, and Indian Bangla as part\nof a project on studying and automatically identifying misogyny and communalism\non social media (the ComMA Project). The dataset is collected from comments on\nYouTube videos and currently contains a total of over 20,000 comments. The\ncomments are annotated at two levels - aggression (overtly aggressive, covertly\naggressive, and non-aggressive) and misogyny (gendered and non-gendered). We\ndescribe the process of data collection, the tagset used for annotation, and\nissues and challenges faced during the process of annotation. Finally, we\ndiscuss the results of the baseline experiments conducted to develop a\nclassifier for misogyny in the three languages.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 20:19:21 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Bhattacharya", "Shiladitya", ""], ["Singh", "Siddharth", ""], ["Kumar", "Ritesh", ""], ["Bansal", "Akanksha", ""], ["Bhagat", "Akash", ""], ["Dawer", "Yogesh", ""], ["Lahiri", "Bornini", ""], ["Ojha", "Atul Kr.", ""]]}, {"id": "2003.07433", "submitter": "Mohammad Arif Ul Alam", "authors": "Mohammad Arif Ul Alam and Dhawal Kapadia", "title": "LAXARY: A Trustworthy Explainable Twitter Analysis Model for\n  Post-Traumatic Stress Disorder Assessment", "comments": "Accepted in SmartComp 2020 (SmartSys)", "journal-ref": "IEEE INTERNATIONAL CONFERENCE ON SMART COMPUTING (SMARTCOMP 2020)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Veteran mental health is a significant national problem as large number of\nveterans are returning from the recent war in Iraq and continued military\npresence in Afghanistan. While significant existing works have investigated\ntwitter posts-based Post Traumatic Stress Disorder (PTSD) assessment using\nblackbox machine learning techniques, these frameworks cannot be trusted by the\nclinicians due to the lack of clinical explainability. To obtain the trust of\nclinicians, we explore the big question, can twitter posts provide enough\ninformation to fill up clinical PTSD assessment surveys that have been\ntraditionally trusted by clinicians? To answer the above question, we propose,\nLAXARY (Linguistic Analysis-based Exaplainable Inquiry) model, a novel\nExplainable Artificial Intelligent (XAI) model to detect and represent PTSD\nassessment of twitter users using a modified Linguistic Inquiry and Word Count\n(LIWC) analysis. First, we employ clinically validated survey tools for\ncollecting clinical PTSD assessment data from real twitter users and develop a\nPTSD Linguistic Dictionary using the PTSD assessment survey results. Then, we\nuse the PTSD Linguistic Dictionary along with machine learning model to fill up\nthe survey tools towards detecting PTSD status and its intensity of\ncorresponding twitter users. Our experimental evaluation on 210 clinically\nvalidated veteran twitter users provides promising accuracies of both PTSD\nclassification and its intensity estimation. We also evaluate our developed\nPTSD Linguistic Dictionary's reliability and validity.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 20:32:24 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 08:12:42 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Alam", "Mohammad Arif Ul", ""], ["Kapadia", "Dhawal", ""]]}, {"id": "2003.07444", "submitter": "Zhuohao Chen", "authors": "Zhuohao Chen, Singla Karan, David C. Atkins, Zac E Imel, Shrikanth\n  Narayanan", "title": "A Label Proportions Estimation Technique for Adversarial Domain\n  Adaptation in Text Classification", "comments": "add a proposition and a proof of it, correct typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many text classification tasks are domain-dependent, and various domain\nadaptation approaches have been proposed to predict unlabeled data in a new\ndomain. Domain-adversarial neural networks (DANN) and their variants have been\nused widely recently and have achieved promising results for this problem.\nHowever, most of these approaches assume that the label proportions of the\nsource and target domains are similar, which rarely holds in most real-world\nscenarios. Sometimes the label shift can be large and the DANN fails to learn\ndomain-invariant features. In this study, we focus on unsupervised domain\nadaptation of text classification with label shift and introduce a domain\nadversarial network with label proportions estimation (DAN-LPE) framework. The\nDAN-LPE simultaneously trains a domain adversarial net and processes label\nproportions estimation by the confusion of the source domain and the\npredictions of the target domain. Experiments show the DAN-LPE achieves a good\nestimate of the target label distributions and reduces the label shift to\nimprove the classification performance.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 21:16:00 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 07:23:10 GMT"}, {"version": "v3", "created": "Thu, 26 Mar 2020 08:13:52 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Chen", "Zhuohao", ""], ["Karan", "Singla", ""], ["Atkins", "David C.", ""], ["Imel", "Zac E", ""], ["Narayanan", "Shrikanth", ""]]}, {"id": "2003.07456", "submitter": "Anssi Yli-Jyr\\\"a PhD", "authors": "Anssi Yli-Jyr\\\"a and Josi Purhonen and Matti Liljeqvist and Arto\n  Antturi and Pekka Nieminen and Kari M. R\\\"antil\\\"a and Valtter Luoto", "title": "HELFI: a Hebrew-Greek-Finnish Parallel Bible Corpus with Cross-Lingual\n  Morpheme Alignment", "comments": "8 pages, 3 tables, to appear in the Language Resources and Evaluation\n  Conference (LREC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Twenty-five years ago, morphologically aligned Hebrew-Finnish and\nGreek-Finnish bitexts (texts accompanied by a translation) were constructed\nmanually in order to create an analytical concordance (Luoto et al., 1997) for\na Finnish Bible translation. The creators of the bitexts recently secured the\npublisher's permission to release its fine-grained alignment, but the alignment\nwas still dependent on proprietary, third-party resources such as a copyrighted\ntext edition and proprietary morphological analyses of the source texts. In\nthis paper, we describe a nontrivial editorial process starting from the\ncreation of the original one-purpose database and ending with its\nreconstruction using only freely available text editions and annotations. This\nprocess produced an openly available dataset that contains (i) the source texts\nand their translations, (ii) the morphological analyses, (iii) the\ncross-lingual morpheme alignments.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 22:10:35 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Yli-Jyr\u00e4", "Anssi", ""], ["Purhonen", "Josi", ""], ["Liljeqvist", "Matti", ""], ["Antturi", "Arto", ""], ["Nieminen", "Pekka", ""], ["R\u00e4ntil\u00e4", "Kari M.", ""], ["Luoto", "Valtter", ""]]}, {"id": "2003.07459", "submitter": "Tharindu Ranasinghe Mr", "authors": "Zeses Pitenis, Marcos Zampieri, Tharindu Ranasinghe", "title": "Offensive Language Identification in Greek", "comments": "Accepted to LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As offensive language has become a rising issue for online communities and\nsocial media platforms, researchers have been investigating ways of coping with\nabusive content and developing systems to detect its different types:\ncyberbullying, hate speech, aggression, etc. With a few notable exceptions,\nmost research on this topic so far has dealt with English. This is mostly due\nto the availability of language resources for English. To address this\nshortcoming, this paper presents the first Greek annotated dataset for\noffensive language identification: the Offensive Greek Tweet Dataset (OGTD).\nOGTD is a manually annotated dataset containing 4,779 posts from Twitter\nannotated as offensive and not offensive. Along with a detailed description of\nthe dataset, we evaluate several computational models trained and tested on\nthis data.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 22:47:27 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 17:26:20 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Pitenis", "Zeses", ""], ["Zampieri", "Marcos", ""], ["Ranasinghe", "Tharindu", ""]]}, {"id": "2003.07482", "submitter": "Jinyu Li", "authors": "Jinyu Li, Rui Zhao, Eric Sun, Jeremy H. M. Wong, Amit Das, Zhong Meng,\n  and Yifan Gong", "title": "High-Accuracy and Low-Latency Speech Recognition with Two-Head\n  Contextual Layer Trajectory LSTM Model", "comments": "Accepted by ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the community keeps promoting end-to-end models over conventional\nhybrid models, which usually are long short-term memory (LSTM) models trained\nwith a cross entropy criterion followed by a sequence discriminative training\ncriterion, we argue that such conventional hybrid models can still be\nsignificantly improved. In this paper, we detail our recent efforts to improve\nconventional hybrid LSTM acoustic models for high-accuracy and low-latency\nautomatic speech recognition. To achieve high accuracy, we use a contextual\nlayer trajectory LSTM (cltLSTM), which decouples the temporal modeling and\ntarget classification tasks, and incorporates future context frames to get more\ninformation for accurate acoustic modeling. We further improve the training\nstrategy with sequence-level teacher-student learning. To obtain low latency,\nwe design a two-head cltLSTM, in which one head has zero latency and the other\nhead has a small latency, compared to an LSTM. When trained with Microsoft's 65\nthousand hours of anonymized training data and evaluated with test sets with\n1.8 million words, the proposed two-head cltLSTM model with the proposed\ntraining strategy yields a 28.2\\% relative WER reduction over the conventional\nLSTM acoustic model, with a similar perceived latency.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 00:52:11 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Li", "Jinyu", ""], ["Zhao", "Rui", ""], ["Sun", "Eric", ""], ["Wong", "Jeremy H. M.", ""], ["Das", "Amit", ""], ["Meng", "Zhong", ""], ["Gong", "Yifan", ""]]}, {"id": "2003.07490", "submitter": "Zheng Zhang", "authors": "Zheng Zhang, Ryuichi Takanobu, Qi Zhu, Minlie Huang, Xiaoyan Zhu", "title": "Recent Advances and Challenges in Task-oriented Dialog System", "comments": "Under review of SCIENCE CHINA Technological Science (SCTS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the significance and value in human-computer interaction and natural\nlanguage processing, task-oriented dialog systems are attracting more and more\nattention in both academic and industrial communities. In this paper, we survey\nrecent advances and challenges in task-oriented dialog systems. We also discuss\nthree critical topics for task-oriented dialog systems: (1) improving data\nefficiency to facilitate dialog modeling in low-resource settings, (2) modeling\nmulti-turn dynamics for dialog policy learning to achieve better\ntask-completion performance, and (3) integrating domain ontology knowledge into\nthe dialog model. Besides, we review the recent progresses in dialog evaluation\nand some widely-used corpora. We believe that this survey, though incomplete,\ncan shed a light on future research in task-oriented dialog systems.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 01:34:56 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 06:32:24 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 12:35:23 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Zhang", "Zheng", ""], ["Takanobu", "Ryuichi", ""], ["Zhu", "Qi", ""], ["Huang", "Minlie", ""], ["Zhu", "Xiaoyan", ""]]}, {"id": "2003.07507", "submitter": "Saptarshi Purkayastha", "authors": "A.K. Bhavani Singh, Mounika Guntu, Ananth Reddy Bhimireddy, Judy W.\n  Gichoya, Saptarshi Purkayastha", "title": "Multi-label natural language processing to identify diagnosis and\n  procedure codes from MIMIC-III inpatient notes", "comments": "This is a shortened version of the Capstone Project that was accepted\n  by the Faculty of Indiana University, in partial fulfillment of the\n  requirements for the degree of Master of Science in Health Informatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the United States, 25% or greater than 200 billion dollars of hospital\nspending accounts for administrative costs that involve services for medical\ncoding and billing. With the increasing number of patient records, manual\nassignment of the codes performed is overwhelming, time-consuming and\nerror-prone, causing billing errors. Natural language processing can automate\nthe extraction of codes/labels from unstructured clinical notes, which can aid\nhuman coders to save time, increase productivity, and verify medical coding\nerrors. Our objective is to identify appropriate diagnosis and procedure codes\nfrom clinical notes by performing multi-label classification. We used\nde-identified data of critical care patients from the MIMIC-III database and\nsubset the data to select the ten (top-10) and fifty (top-50) most common\ndiagnoses and procedures, which covers 47.45% and 74.12% of all admissions\nrespectively. We implemented state-of-the-art Bidirectional Encoder\nRepresentations from Transformers (BERT) to fine-tune the language model on 80%\nof the data and validated on the remaining 20%. The model achieved an overall\naccuracy of 87.08%, an F1 score of 85.82%, and an AUC of 91.76% for top-10\ncodes. For the top-50 codes, our model achieved an overall accuracy of 93.76%,\nan F1 score of 92.24%, and AUC of 91%. When compared to previously published\nresearch, our model outperforms in predicting codes from the clinical text. We\ndiscuss approaches to generalize the knowledge discovery process of our\nMIMIC-BERT to other clinical notes. This can help human coders to save time,\nprevent backlogs, and additional costs due to coding errors.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 02:56:27 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Singh", "A. K. Bhavani", ""], ["Guntu", "Mounika", ""], ["Bhimireddy", "Ananth Reddy", ""], ["Gichoya", "Judy W.", ""], ["Purkayastha", "Saptarshi", ""]]}, {"id": "2003.07568", "submitter": "Zhaojiang Lin", "authors": "Zhaojiang Lin, Zihan Liu, Genta Indra Winata, Samuel Cahyawijaya,\n  Andrea Madotto, Yejin Bang, Etsuko Ishii, Pascale Fung", "title": "XPersona: Evaluating Multilingual Personalized Chatbot", "comments": "Preprint, 23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalized dialogue systems are an essential step toward better\nhuman-machine interaction. Existing personalized dialogue agents rely on\nproperly designed conversational datasets, which are mostly monolingual (e.g.,\nEnglish), which greatly limits the usage of conversational agents in other\nlanguages. In this paper, we propose a multi-lingual extension of Persona-Chat,\nnamely XPersona. Our dataset includes persona conversations in six different\nlanguages other than English for building and evaluating multilingual\npersonalized agents. We experiment with both multilingual and cross-lingual\ntrained baselines, and evaluate them against monolingual and\ntranslation-pipeline models using both automatic and human evaluation.\nExperimental results show that the multilingual trained models outperform the\ntranslation-pipeline and that they are on par with the monolingual models, with\nthe advantage of having a single model across multiple languages. On the other\nhand, the state-of-the-art cross-lingual trained models achieve inferior\nperformance to the other models, showing that cross-lingual conversation\nmodeling is a challenging task. We hope that our dataset and baselines will\naccelerate research in multilingual dialogue systems.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 07:52:08 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 07:38:28 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Lin", "Zhaojiang", ""], ["Liu", "Zihan", ""], ["Winata", "Genta Indra", ""], ["Cahyawijaya", "Samuel", ""], ["Madotto", "Andrea", ""], ["Bang", "Yejin", ""], ["Ishii", "Etsuko", ""], ["Fung", "Pascale", ""]]}, {"id": "2003.07634", "submitter": "Ivan Sekulic", "authors": "Ivan Sekuli\\'c and Michael Strube", "title": "Adapting Deep Learning Methods for Mental Health Prediction on Social\n  Media", "comments": "W-NUT at EMNLP 2019", "journal-ref": "Proceedings of the 5th Workshop on Noisy User-generated Text,\n  2019, 322-327", "doi": "10.18653/v1/D19-5542", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Mental health poses a significant challenge for an individual's well-being.\nText analysis of rich resources, like social media, can contribute to deeper\nunderstanding of illnesses and provide means for their early detection. We\ntackle a challenge of detecting social media users' mental status through deep\nlearning-based models, moving away from traditional approaches to the task. In\na binary classification task on predicting if a user suffers from one of nine\ndifferent disorders, a hierarchical attention network outperforms previously\nset benchmarks for four of the disorders. Furthermore, we explore the\nlimitations of our model and analyze phrases relevant for classification by\ninspecting the model's word-level attention weights.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 10:49:03 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Sekuli\u0107", "Ivan", ""], ["Strube", "Michael", ""]]}, {"id": "2003.07683", "submitter": "Chaehan So", "authors": "Chaehan So", "title": "Who Wins the Game of Thrones? How Sentiments Improve the Prediction of\n  Candidate Choice", "comments": "To be published in IEEE conference proceedings: International\n  Conference on Artificial Intelligence in Information and Communication,\n  ICAIIC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes how candidate choice prediction improves by different\npsychological predictors. To investigate this question, it collected an\noriginal survey dataset featuring the popular TV series \"Game of Thrones\". The\nrespondents answered which character they anticipated to win in the final\nepisode of the series, and explained their choice of the final candidate in\nfree text from which sentiments were extracted. These sentiments were compared\nto feature sets derived from candidate likeability and candidate personality\nratings. In our benchmarking of 10-fold cross-validation in 100 repetitions,\nall feature sets except the likeability ratings yielded a 10-11% improvement in\naccuracy on the holdout set over the base model. Treating the class imbalance\nwith synthetic minority oversampling (SMOTE) increased holdout set performance\nby 20-34% but surprisingly not testing set performance. Taken together, our\nstudy provides a quantified estimation of the additional predictive value of\npsychological predictors. Likeability ratings were clearly outperformed by the\nfeature sets based on personality, emotional valence, and basic emotions.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 04:30:28 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["So", "Chaehan", ""]]}, {"id": "2003.07705", "submitter": "Ehsan Variani", "authors": "Ehsan Variani, David Rybach, Cyril Allauzen, Michael Riley", "title": "Hybrid Autoregressive Transducer (hat)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes and evaluates the hybrid autoregressive transducer (HAT)\nmodel, a time-synchronous encoderdecoder model that preserves the modularity of\nconventional automatic speech recognition systems. The HAT model provides a way\nto measure the quality of the internal language model that can be used to\ndecide whether inference with an external language model is beneficial or not.\nThis article also presents a finite context version of the HAT model that\naddresses the exposure bias problem and significantly simplifies the overall\ntraining and inference. We evaluate our proposed model on a large-scale voice\nsearch task. Our experiments show significant improvements in WER compared to\nthe state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 20:47:06 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Variani", "Ehsan", ""], ["Rybach", "David", ""], ["Allauzen", "Cyril", ""], ["Riley", "Michael", ""]]}, {"id": "2003.07723", "submitter": "Thomas Haider", "authors": "Thomas Haider, Steffen Eger, Evgeny Kim, Roman Klinger, Winfried\n  Menninghaus", "title": "PO-EMO: Conceptualization, Annotation, and Modeling of Aesthetic\n  Emotions in German and English Poetry", "comments": "Emotion, Aesthetic Emotions, Literature, Poetry, Annotation, Corpora,\n  Emotion Recognition, Multi-Label", "journal-ref": "International Conference on Language Resources and Evaluation\n  (LREC) 2020, Marseille", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most approaches to emotion analysis of social media, literature, news, and\nother domains focus exclusively on basic emotion categories as defined by Ekman\nor Plutchik. However, art (such as literature) enables engagement in a broader\nrange of more complex and subtle emotions. These have been shown to also\ninclude mixed emotional responses. We consider emotions in poetry as they are\nelicited in the reader, rather than what is expressed in the text or intended\nby the author. Thus, we conceptualize a set of aesthetic emotions that are\npredictive of aesthetic appreciation in the reader, and allow the annotation of\nmultiple labels per line to capture mixed emotions within their context. We\nevaluate this novel setting in an annotation experiment both with carefully\ntrained experts and via crowdsourcing. Our annotation with experts leads to an\nacceptable agreement of kappa = .70, resulting in a consistent dataset for\nfuture large scale analysis. Finally, we conduct first emotion classification\nexperiments based on BERT, showing that identifying aesthetic emotions is\nchallenging in our data, with up to .52 F1-micro on the German subset. Data and\nresources are available at https://github.com/tnhaider/poetry-emotion\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 13:54:48 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 17:28:57 GMT"}, {"version": "v3", "created": "Wed, 23 Jun 2021 15:21:25 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Haider", "Thomas", ""], ["Eger", "Steffen", ""], ["Kim", "Evgeny", ""], ["Klinger", "Roman", ""], ["Menninghaus", "Winfried", ""]]}, {"id": "2003.07743", "submitter": "Wei Hu", "authors": "Zequn Sun and Qingheng Zhang and Wei Hu and Chengming Wang and Muhao\n  Chen and Farahnaz Akrami and Chengkai Li", "title": "A Benchmarking Study of Embedding-based Entity Alignment for Knowledge\n  Graphs", "comments": "Accepted in the 46th International Conference on Very Large Data\n  Bases (VLDB 2020)", "journal-ref": null, "doi": "10.14778/3407790.3407828", "report-no": null, "categories": "cs.CL cs.AI cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity alignment seeks to find entities in different knowledge graphs (KGs)\nthat refer to the same real-world object. Recent advancement in KG embedding\nimpels the advent of embedding-based entity alignment, which encodes entities\nin a continuous embedding space and measures entity similarities based on the\nlearned embeddings. In this paper, we conduct a comprehensive experimental\nstudy of this emerging field. We survey 23 recent embedding-based entity\nalignment approaches and categorize them based on their techniques and\ncharacteristics. We also propose a new KG sampling algorithm, with which we\ngenerate a set of dedicated benchmark datasets with various heterogeneity and\ndistributions for a realistic evaluation. We develop an open-source library\nincluding 12 representative embedding-based entity alignment approaches, and\nextensively evaluate these approaches, to understand their strengths and\nlimitations. Additionally, for several directions that have not been explored\nin current approaches, we perform exploratory experiments and report our\npreliminary findings for future studies. The benchmark datasets, open-source\nlibrary and experimental results are all accessible online and will be duly\nmaintained.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 05:32:06 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 00:47:26 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Sun", "Zequn", ""], ["Zhang", "Qingheng", ""], ["Hu", "Wei", ""], ["Wang", "Chengming", ""], ["Chen", "Muhao", ""], ["Akrami", "Farahnaz", ""], ["Li", "Chengkai", ""]]}, {"id": "2003.07758", "submitter": "Vladimir Iashin", "authors": "Vladimir Iashin and Esa Rahtu", "title": "Multi-modal Dense Video Captioning", "comments": "To appear in the proceedings of CVPR Workshops 2020; Code:\n  https://github.com/v-iashin/MDVC Project Page:\n  https://v-iashin.github.io/mdvc", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG cs.SD eess.AS eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dense video captioning is a task of localizing interesting events from an\nuntrimmed video and producing textual description (captions) for each localized\nevent. Most of the previous works in dense video captioning are solely based on\nvisual information and completely ignore the audio track. However, audio, and\nspeech, in particular, are vital cues for a human observer in understanding an\nenvironment. In this paper, we present a new dense video captioning approach\nthat is able to utilize any number of modalities for event description.\nSpecifically, we show how audio and speech modalities may improve a dense video\ncaptioning model. We apply automatic speech recognition (ASR) system to obtain\na temporally aligned textual description of the speech (similar to subtitles)\nand treat it as a separate input alongside video frames and the corresponding\naudio track. We formulate the captioning task as a machine translation problem\nand utilize recently proposed Transformer architecture to convert multi-modal\ninput data into textual descriptions. We demonstrate the performance of our\nmodel on ActivityNet Captions dataset. The ablation studies indicate a\nconsiderable contribution from audio and speech components suggesting that\nthese modalities contain substantial complementary information to video frames.\nFurthermore, we provide an in-depth analysis of the ActivityNet Caption results\nby leveraging the category tags obtained from original YouTube videos. Code is\npublicly available: github.com/v-iashin/MDVC\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 15:15:17 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 18:12:10 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Iashin", "Vladimir", ""], ["Rahtu", "Esa", ""]]}, {"id": "2003.07820", "submitter": "Bhaskar Mitra", "authors": "Nick Craswell, Bhaskar Mitra, Emine Yilmaz, Daniel Campos, Ellen M.\n  Voorhees", "title": "Overview of the TREC 2019 deep learning track", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Deep Learning Track is a new track for TREC 2019, with the goal of\nstudying ad hoc ranking in a large data regime. It is the first track with\nlarge human-labeled training sets, introducing two sets corresponding to two\ntasks, each with rigorous TREC-style blind evaluation and reusable test sets.\nThe document retrieval task has a corpus of 3.2 million documents with 367\nthousand training queries, for which we generate a reusable test set of 43\nqueries. The passage retrieval task has a corpus of 8.8 million passages with\n503 thousand training queries, for which we generate a reusable test set of 43\nqueries. This year 15 groups submitted a total of 75 runs, using various\ncombinations of deep learning, transfer learning and traditional IR ranking\nmethods. Deep learning runs significantly outperformed traditional IR runs.\nPossible explanations for this result are that we introduced large training\ndata and we included deep models trained on such data in our judging pools,\nwhereas some past studies did not have such training data or pooling.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 17:12:36 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 16:56:56 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Craswell", "Nick", ""], ["Mitra", "Bhaskar", ""], ["Yilmaz", "Emine", ""], ["Campos", "Daniel", ""], ["Voorhees", "Ellen M.", ""]]}, {"id": "2003.07845", "submitter": "Amir Gholami", "authors": "Sheng Shen, Zhewei Yao, Amir Gholami, Michael W. Mahoney, Kurt Keutzer", "title": "PowerNorm: Rethinking Batch Normalization in Transformers", "comments": null, "journal-ref": "ICML 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard normalization method for neural network (NN) models used in\nNatural Language Processing (NLP) is layer normalization (LN). This is\ndifferent than batch normalization (BN), which is widely-adopted in Computer\nVision. The preferred use of LN in NLP is principally due to the empirical\nobservation that a (naive/vanilla) use of BN leads to significant performance\ndegradation for NLP tasks; however, a thorough understanding of the underlying\nreasons for this is not always evident. In this paper, we perform a systematic\nstudy of NLP transformer models to understand why BN has a poor performance, as\ncompared to LN. We find that the statistics of NLP data across the batch\ndimension exhibit large fluctuations throughout training. This results in\ninstability, if BN is naively implemented. To address this, we propose Power\nNormalization (PN), a novel normalization scheme that resolves this issue by\n(i) relaxing zero-mean normalization in BN, (ii) incorporating a running\nquadratic mean instead of per batch statistics to stabilize fluctuations, and\n(iii) using an approximate backpropagation for incorporating the running\nstatistics in the forward pass. We show theoretically, under mild assumptions,\nthat PN leads to a smaller Lipschitz constant for the loss, compared with BN.\nFurthermore, we prove that the approximate backpropagation scheme leads to\nbounded gradients. We extensively test PN for transformers on a range of NLP\ntasks, and we show that it significantly outperforms both LN and BN. In\nparticular, PN outperforms LN by 0.4/0.6 BLEU on IWSLT14/WMT14 and 5.6/3.0 PPL\non PTB/WikiText-103. We make our code publicly available at\n\\url{https://github.com/sIncerass/powernorm}.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 17:50:26 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 07:12:51 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Shen", "Sheng", ""], ["Yao", "Zhewei", ""], ["Gholami", "Amir", ""], ["Mahoney", "Michael W.", ""], ["Keutzer", "Kurt", ""]]}, {"id": "2003.07892", "submitter": "Shrey Desai", "authors": "Shrey Desai and Greg Durrett", "title": "Calibration of Pre-trained Transformers", "comments": "Accepted to EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained Transformers are now ubiquitous in natural language processing,\nbut despite their high end-task performance, little is known empirically about\nwhether they are calibrated. Specifically, do these models' posterior\nprobabilities provide an accurate empirical measure of how likely the model is\nto be correct on a given example? We focus on BERT and RoBERTa in this work,\nand analyze their calibration across three tasks: natural language inference,\nparaphrase detection, and commonsense reasoning. For each task, we consider\nin-domain as well as challenging out-of-domain settings, where models face more\nexamples they should be uncertain about. We show that: (1) when used\nout-of-the-box, pre-trained models are calibrated in-domain, and compared to\nbaselines, their calibration error out-of-domain can be as much as 3.5x lower;\n(2) temperature scaling is effective at further reducing calibration error\nin-domain, and using label smoothing to deliberately increase empirical\nuncertainty helps calibrate posteriors out-of-domain.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 18:58:44 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 21:35:54 GMT"}, {"version": "v3", "created": "Thu, 15 Oct 2020 17:04:21 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Desai", "Shrey", ""], ["Durrett", "Greg", ""]]}, {"id": "2003.07962", "submitter": "Ke Hu", "authors": "Ke Hu, Tara N. Sainath, Ruoming Pang, Rohit Prabhavalkar", "title": "Deliberation Model Based Two-Pass End-to-End Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end (E2E) models have made rapid progress in automatic speech\nrecognition (ASR) and perform competitively relative to conventional models. To\nfurther improve the quality, a two-pass model has been proposed to rescore\nstreamed hypotheses using the non-streaming Listen, Attend and Spell (LAS)\nmodel while maintaining a reasonable latency. The model attends to acoustics to\nrescore hypotheses, as opposed to a class of neural correction models that use\nonly first-pass text hypotheses. In this work, we propose to attend to both\nacoustics and first-pass hypotheses using a deliberation network. A\nbidirectional encoder is used to extract context information from first-pass\nhypotheses. The proposed deliberation model achieves 12% relative WER reduction\ncompared to LAS rescoring in Google Voice Search (VS) tasks, and 23% reduction\non a proper noun test set. Compared to a large conventional model, our best\nmodel performs 21% relatively better for VS. In terms of computational\ncomplexity, the deliberation decoder has a larger size than the LAS decoder,\nand hence requires more computations in second-pass decoding.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 22:01:12 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Hu", "Ke", ""], ["Sainath", "Tara N.", ""], ["Pang", "Ruoming", ""], ["Prabhavalkar", "Rohit", ""]]}, {"id": "2003.07996", "submitter": "Shivali Goel", "authors": "Shivali Goel (1), Homayoon Beigi (1 and 2) ((1) Department of Computer\n  Science, Columbia University, (2) Recognition Technologies, Inc., South\n  Salem, New York, United States)", "title": "Cross Lingual Cross Corpus Speech Emotion Recognition", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of existing speech emotion recognition models are trained and\nevaluated on a single corpus and a single language setting. These systems do\nnot perform as well when applied in a cross-corpus and cross-language scenario.\nThis paper presents results for speech emotion recognition for 4 languages in\nboth single corpus and cross corpus setting. Additionally, since multi-task\nlearning (MTL) with gender, naturalness and arousal as auxiliary tasks has\nshown to enhance the generalisation capabilities of the emotion models, this\npaper introduces language ID as another auxiliary task in MTL framework to\nexplore the role of spoken language on emotion recognition which has not been\nstudied yet.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 00:23:08 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Goel", "Shivali", "", "1 and 2"], ["Beigi", "Homayoon", "", "1 and 2"]]}, {"id": "2003.08001", "submitter": "Farahnaz Akrami", "authors": "Farahnaz Akrami (1), Mohammed Samiul Saeef (1), Qingheng Zhang (2),\n  Wei Hu (2), Chengkai Li (1) ((1) Department of Computer Science and\n  Engineering, University of Texas at Arlington, (2) State Key Laboratory for\n  Novel Software Technology, Nanjing University)", "title": "Realistic Re-evaluation of Knowledge Graph Completion Methods: An\n  Experimental Study", "comments": "accepted to SIGMOD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the active research area of employing embedding models for knowledge graph\ncompletion, particularly for the task of link prediction, most prior studies\nused two benchmark datasets FB15k and WN18 in evaluating such models. Most\ntriples in these and other datasets in such studies belong to reverse and\nduplicate relations which exhibit high data redundancy due to semantic\nduplication, correlation or data incompleteness. This is a case of excessive\ndata leakage---a model is trained using features that otherwise would not be\navailable when the model needs to be applied for real prediction. There are\nalso Cartesian product relations for which every triple formed by the Cartesian\nproduct of applicable subjects and objects is a true fact. Link prediction on\nthe aforementioned relations is easy and can be achieved with even better\naccuracy using straightforward rules instead of sophisticated embedding models.\nA more fundamental defect of these models is that the link prediction scenario,\ngiven such data, is non-existent in the real-world. This paper is the first\nsystematic study with the main objective of assessing the true effectiveness of\nembedding models when the unrealistic triples are removed. Our experiment\nresults show these models are much less accurate than what we used to perceive.\nTheir poor accuracy renders link prediction a task without truly effective\nautomated solution. Hence, we call for re-investigation of possible effective\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 01:18:09 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Akrami", "Farahnaz", ""], ["Saeef", "Mohammed Samiul", ""], ["Zhang", "Qingheng", ""], ["Hu", "Wei", ""], ["Li", "Chengkai", ""]]}, {"id": "2003.08004", "submitter": "Haiyang Xu", "authors": "Haiyang Xu, Yun Wang, Kun Han, Baochang Ma, Junwen Chen, Xiangang Li", "title": "Selective Attention Encoders by Syntactic Graph Convolutional Networks\n  for Document Summarization", "comments": "ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstractive text summarization is a challenging task, and one need to design\na mechanism to effectively extract salient information from the source text and\nthen generate a summary. A parsing process of the source text contains critical\nsyntactic or semantic structures, which is useful to generate more accurate\nsummary. However, modeling a parsing tree for text summarization is not trivial\ndue to its non-linear structure and it is harder to deal with a document that\nincludes multiple sentences and their parsing trees. In this paper, we propose\nto use a graph to connect the parsing trees from the sentences in a document\nand utilize the stacked graph convolutional networks (GCNs) to learn the\nsyntactic representation for a document. The selective attention mechanism is\nused to extract salient information in semantic and structural aspect and\ngenerate an abstractive summary. We evaluate our approach on the CNN/Daily Mail\ntext summarization dataset. The experimental results show that the proposed\nGCNs based selective attention approach outperforms the baselines and achieves\nthe state-of-the-art performance on the dataset.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 01:30:02 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Xu", "Haiyang", ""], ["Wang", "Yun", ""], ["Han", "Kun", ""], ["Ma", "Baochang", ""], ["Chen", "Junwen", ""], ["Li", "Xiangang", ""]]}, {"id": "2003.08132", "submitter": "Mahault Garnerin", "authors": "Mahault Garnerin, Solange Rossato, Laurent Besacier", "title": "Gender Representation in Open Source Speech Resources", "comments": "accepted to LREC2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the rise of artificial intelligence (AI) and the growing use of\ndeep-learning architectures, the question of ethics, transparency and fairness\nof AI systems has become a central concern within the research community. We\naddress transparency and fairness in spoken language systems by proposing a\nstudy about gender representation in speech resources available through the\nOpen Speech and Language Resource platform. We show that finding gender\ninformation in open source corpora is not straightforward and that gender\nbalance depends on other corpus characteristics (elicited/non elicited speech,\nlow/high resource language, speech task targeted). The paper ends with\nrecommendations about metadata and gender information for researchers in order\nto assure better transparency of the speech systems built using such corpora.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 10:23:36 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Garnerin", "Mahault", ""], ["Rossato", "Solange", ""], ["Besacier", "Laurent", ""]]}, {"id": "2003.08197", "submitter": "Paul Pu Liang", "authors": "Paul Pu Liang, Manzil Zaheer, Yuan Wang, Amr Ahmed", "title": "Anchor & Transform: Learning Sparse Embeddings for Large Vocabularies", "comments": "ICLR 2021, code can be found at\n  http://github.com/pliang279/sparse_discrete", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning continuous representations of discrete objects such as text, users,\nmovies, and URLs lies at the heart of many applications including language and\nuser modeling. When using discrete objects as input to neural networks, we\noften ignore the underlying structures (e.g., natural groupings and\nsimilarities) and embed the objects independently into individual vectors. As a\nresult, existing methods do not scale to large vocabulary sizes. In this paper,\nwe design a simple and efficient embedding algorithm that learns a small set of\nanchor embeddings and a sparse transformation matrix. We call our method Anchor\n& Transform (ANT) as the embeddings of discrete objects are a sparse linear\ncombination of the anchors, weighted according to the transformation matrix.\nANT is scalable, flexible, and end-to-end trainable. We further provide a\nstatistical interpretation of our algorithm as a Bayesian nonparametric prior\nfor embeddings that encourages sparsity and leverages natural groupings among\nobjects. By deriving an approximate inference algorithm based on Small Variance\nAsymptotics, we obtain a natural extension that automatically learns the\noptimal number of anchors instead of having to tune it as a hyperparameter. On\ntext classification, language modeling, and movie recommendation benchmarks, we\nshow that ANT is particularly suitable for large vocabulary sizes and\ndemonstrates stronger performance with fewer parameters (up to 40x compression)\nas compared to existing compression baselines.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 13:07:51 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 03:51:17 GMT"}, {"version": "v3", "created": "Thu, 15 Oct 2020 04:43:51 GMT"}, {"version": "v4", "created": "Thu, 11 Mar 2021 06:11:05 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Liang", "Paul Pu", ""], ["Zaheer", "Manzil", ""], ["Wang", "Yuan", ""], ["Ahmed", "Amr", ""]]}, {"id": "2003.08271", "submitter": "Xipeng Qiu", "authors": "Xipeng Qiu, Tianxiang Sun, Yige Xu, Yunfan Shao, Ning Dai, and\n  Xuanjing Huang", "title": "Pre-trained Models for Natural Language Processing: A Survey", "comments": "Invited Review of Science China Technological Sciences", "journal-ref": "SCIENCE CHINA Technological Sciences,2020, 63, 1872-1897", "doi": "10.1007/s11431-020-1647-3", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the emergence of pre-trained models (PTMs) has brought natural\nlanguage processing (NLP) to a new era. In this survey, we provide a\ncomprehensive review of PTMs for NLP. We first briefly introduce language\nrepresentation learning and its research progress. Then we systematically\ncategorize existing PTMs based on a taxonomy with four perspectives. Next, we\ndescribe how to adapt the knowledge of PTMs to the downstream tasks. Finally,\nwe outline some potential directions of PTMs for future research. This survey\nis purposed to be a hands-on guide for understanding, using, and developing\nPTMs for various NLP tasks.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 15:22:51 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 10:32:40 GMT"}, {"version": "v3", "created": "Fri, 24 Apr 2020 15:16:59 GMT"}, {"version": "v4", "created": "Wed, 23 Jun 2021 17:40:26 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Qiu", "Xipeng", ""], ["Sun", "Tianxiang", ""], ["Xu", "Yige", ""], ["Shao", "Yunfan", ""], ["Dai", "Ning", ""], ["Huang", "Xuanjing", ""]]}, {"id": "2003.08272", "submitter": "Ernie Chang", "authors": "Ernie Chang, David Ifeoluwa Adelani, Xiaoyu Shen, Vera Demberg", "title": "Unsupervised Pidgin Text Generation By Pivoting English Data and\n  Self-Training", "comments": "Accepted to Workshop at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  West African Pidgin English is a language that is significantly spoken in\nWest Africa, consisting of at least 75 million speakers. Nevertheless, proper\nmachine translation systems and relevant NLP datasets for pidgin English are\nvirtually absent. In this work, we develop techniques targeted at bridging the\ngap between Pidgin English and English in the context of natural language\ngeneration. %As a proof of concept, we explore the proposed techniques in the\narea of data-to-text generation. By building upon the previously released\nmonolingual Pidgin English text and parallel English data-to-text corpus, we\nhope to build a system that can automatically generate Pidgin English\ndescriptions from structured data. We first train a data-to-English text\ngeneration system, before employing techniques in unsupervised neural machine\ntranslation and self-training to establish the Pidgin-to-English cross-lingual\nalignment. The human evaluation performed on the generated Pidgin texts shows\nthat, though still far from being practically usable, the pivoting +\nself-training technique improves both Pidgin text fluency and relevance.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 15:27:35 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 06:27:33 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Chang", "Ernie", ""], ["Adelani", "David Ifeoluwa", ""], ["Shen", "Xiaoyu", ""], ["Demberg", "Vera", ""]]}, {"id": "2003.08370", "submitter": "David Adelani", "authors": "David Ifeoluwa Adelani, Michael A. Hedderich, Dawei Zhu, Esther van\n  den Berg, Dietrich Klakow", "title": "Distant Supervision and Noisy Label Learning for Low Resource Named\n  Entity Recognition: A Study on Hausa and Yor\\`ub\\'a", "comments": "Accepted to ICLR 2020 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The lack of labeled training data has limited the development of natural\nlanguage processing tools, such as named entity recognition, for many languages\nspoken in developing countries. Techniques such as distant and weak supervision\ncan be used to create labeled data in a (semi-) automatic way. Additionally, to\nalleviate some of the negative effects of the errors in automatic annotation,\nnoise-handling methods can be integrated. Pretrained word embeddings are\nanother key component of most neural named entity classifiers. With the advent\nof more complex contextual word embeddings, an interesting trade-off between\nmodel size and performance arises. While these techniques have been shown to\nwork well in high-resource settings, we want to study how they perform in\nlow-resource scenarios. In this work, we perform named entity recognition for\nHausa and Yor\\`ub\\'a, two languages that are widely spoken in several\ndeveloping countries. We evaluate different embedding approaches and show that\ndistant supervision can be successfully leveraged in a realistic low-resource\nscenario where it can more than double a classifier's performance.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 17:48:35 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 13:18:17 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Adelani", "David Ifeoluwa", ""], ["Hedderich", "Michael A.", ""], ["Zhu", "Dawei", ""], ["Berg", "Esther van den", ""], ["Klakow", "Dietrich", ""]]}, {"id": "2003.08380", "submitter": "Jimmy Lin", "authors": "Sheng-Chieh Lin, Jheng-Hong Yang, Rodrigo Nogueira, Ming-Feng Tsai,\n  Chuan-Ju Wang, Jimmy Lin", "title": "TTTTTackling WinoGrande Schemas", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We applied the T5 sequence-to-sequence model to tackle the AI2 WinoGrande\nChallenge by decomposing each example into two input text strings, each\ncontaining a hypothesis, and using the probabilities assigned to the\n\"entailment\" token as a score of the hypothesis. Our first (and only)\nsubmission to the official leaderboard yielded 0.7673 AUC on March 13, 2020,\nwhich is the best known result at this time and beats the previous state of the\nart by over five points.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 17:56:07 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Lin", "Sheng-Chieh", ""], ["Yang", "Jheng-Hong", ""], ["Nogueira", "Rodrigo", ""], ["Tsai", "Ming-Feng", ""], ["Wang", "Chuan-Ju", ""], ["Lin", "Jimmy", ""]]}, {"id": "2003.08385", "submitter": "Jannis Vamvas", "authors": "Jannis Vamvas and Rico Sennrich", "title": "X-Stance: A Multilingual Multi-Target Dataset for Stance Detection", "comments": "SwissText + KONVENS 2020. Data and code are available at\n  https://github.com/ZurichNLP/xstance", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We extract a large-scale stance detection dataset from comments written by\ncandidates of elections in Switzerland. The dataset consists of German, French\nand Italian text, allowing for a cross-lingual evaluation of stance detection.\nIt contains 67 000 comments on more than 150 political issues (targets). Unlike\nstance detection models that have specific target issues, we use the dataset to\ntrain a single model on all the issues. To make learning across targets\npossible, we prepend to each instance a natural question that represents the\ntarget (e.g. \"Do you support X?\"). Baseline results from multilingual BERT show\nthat zero-shot cross-lingual and cross-target transfer of stance detection is\nmoderately successful with this approach.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 17:58:10 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 15:05:11 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Vamvas", "Jannis", ""], ["Sennrich", "Rico", ""]]}, {"id": "2003.08437", "submitter": "Siyao Peng", "authors": "Siyao Peng, Yang Liu, Yilun Zhu, Austin Blodgett, Yushi Zhao, Nathan\n  Schneider", "title": "A Corpus of Adpositional Supersenses for Mandarin Chinese", "comments": "LREC 2020 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adpositions are frequent markers of semantic relations, but they are highly\nambiguous and vary significantly from language to language. Moreover, there is\na dearth of annotated corpora for investigating the cross-linguistic variation\nof adposition semantics, or for building multilingual disambiguation systems.\nThis paper presents a corpus in which all adpositions have been semantically\nannotated in Mandarin Chinese; to the best of our knowledge, this is the first\nChinese corpus to be broadly annotated with adposition semantics. Our approach\nadapts a framework that defined a general set of supersenses according to\nostensibly language-independent semantic criteria, though its development\nfocused primarily on English prepositions (Schneider et al., 2018). We find\nthat the supersense categories are well-suited to Chinese adpositions despite\nsyntactic differences from English. On a Mandarin translation of The Little\nPrince, we achieve high inter-annotator agreement and analyze semantic\ncorrespondences of adposition tokens in bitext.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 18:59:55 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Peng", "Siyao", ""], ["Liu", "Yang", ""], ["Zhu", "Yilun", ""], ["Blodgett", "Austin", ""], ["Zhao", "Yushi", ""], ["Schneider", "Nathan", ""]]}, {"id": "2003.08489", "submitter": "Canlin Zhang", "authors": "Canlin Zhang, Xiuwen Liu and Daniel Bis", "title": "An Analysis on the Learning Rules of the Skip-Gram Model", "comments": "Published on the 2019 International Joint Conference on Neural\n  Networks", "journal-ref": "The 2019 International Joint Conference on Neural Networks (IJCNN)", "doi": "10.1109/IJCNN.2019.8852182", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve the generalization of the representations for natural language\nprocessing tasks, words are commonly represented using vectors, where distances\namong the vectors are related to the similarity of the words. While word2vec,\nthe state-of-the-art implementation of the skip-gram model, is widely used and\nimproves the performance of many natural language processing tasks, its\nmechanism is not yet well understood.\n  In this work, we derive the learning rules for the skip-gram model and\nestablish their close relationship to competitive learning. In addition, we\nprovide the global optimal solution constraints for the skip-gram model and\nvalidate them by experimental results.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 22:17:48 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Zhang", "Canlin", ""], ["Liu", "Xiuwen", ""], ["Bis", "Daniel", ""]]}, {"id": "2003.08529", "submitter": "Yi-An Lai", "authors": "Yi-An Lai, Xuan Zhu, Yi Zhang, Mona Diab", "title": "Diversity, Density, and Homogeneity: Quantitative Characteristic Metrics\n  for Text Collections", "comments": "Accepted by LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Summarizing data samples by quantitative measures has a long history, with\ndescriptive statistics being a case in point. However, as natural language\nprocessing methods flourish, there are still insufficient characteristic\nmetrics to describe a collection of texts in terms of the words, sentences, or\nparagraphs they comprise. In this work, we propose metrics of diversity,\ndensity, and homogeneity that quantitatively measure the dispersion, sparsity,\nand uniformity of a text collection. We conduct a series of simulations to\nverify that each metric holds desired properties and resonates with human\nintuitions. Experiments on real-world datasets demonstrate that the proposed\ncharacteristic metrics are highly correlated with text classification\nperformance of a renowned model, BERT, which could inspire future applications.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 00:48:32 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Lai", "Yi-An", ""], ["Zhu", "Xuan", ""], ["Zhang", "Yi", ""], ["Diab", "Mona", ""]]}, {"id": "2003.08553", "submitter": "Anshuman Suri", "authors": "Parag Agrawal, Tulasi Menon, Aya Kamel, Michel Naim, Chaikesh\n  Chouragade, Gurvinder Singh, Rohan Kulkarni, Anshuman Suri, Sahithi Katakam,\n  Vineet Pratik, Prakul Bansal, Simerpreet Kaur, Neha Rajput, Anand Duggal,\n  Achraf Chalabi, Prashant Choudhari, Reddy Satti, Niranjan Nayak", "title": "QnAMaker: Data to Bot in 2 Minutes", "comments": "Published at The Web Conference 2020 in the demo track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Having a bot for seamless conversations is a much-desired feature that\nproducts and services today seek for their websites and mobile apps. These bots\nhelp reduce traffic received by human support significantly by handling\nfrequent and directly answerable known questions. Many such services have huge\nreference documents such as FAQ pages, which makes it hard for users to browse\nthrough this data. A conversation layer over such raw data can lower traffic to\nhuman support by a great margin. We demonstrate QnAMaker, a service that\ncreates a conversational layer over semi-structured data such as FAQ pages,\nproduct manuals, and support documents. QnAMaker is the popular choice for\nExtraction and Question-Answering as a service and is used by over 15,000 bots\nin production. It is also used by search interfaces and not just bots.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 03:32:03 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Agrawal", "Parag", ""], ["Menon", "Tulasi", ""], ["Kamel", "Aya", ""], ["Naim", "Michel", ""], ["Chouragade", "Chaikesh", ""], ["Singh", "Gurvinder", ""], ["Kulkarni", "Rohan", ""], ["Suri", "Anshuman", ""], ["Katakam", "Sahithi", ""], ["Pratik", "Vineet", ""], ["Bansal", "Prakul", ""], ["Kaur", "Simerpreet", ""], ["Rajput", "Neha", ""], ["Duggal", "Anand", ""], ["Chalabi", "Achraf", ""], ["Choudhari", "Prashant", ""], ["Satti", "Reddy", ""], ["Nayak", "Niranjan", ""]]}, {"id": "2003.08612", "submitter": "Chenguang Zhu", "authors": "Chenguang Zhu, William Hinthorn, Ruochen Xu, Qingkai Zeng, Michael\n  Zeng, Xuedong Huang, Meng Jiang", "title": "Enhancing Factual Consistency of Abstractive Summarization", "comments": "Prediction results available at: https://github.com/zcgzcgzcg1/FASum/", "journal-ref": "North American Chapter of the Association for Computational\n  Linguistics (NAACL), Mexico City, Mexico, 2021", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic abstractive summaries are found to often distort or fabricate facts\nin the article. This inconsistency between summary and original text has\nseriously impacted its applicability. We propose a fact-aware summarization\nmodel FASum to extract and integrate factual relations into the summary\ngeneration process via graph attention. We then design a factual corrector\nmodel FC to automatically correct factual errors from summaries generated by\nexisting systems. Empirical results show that the fact-aware summarization can\nproduce abstractive summaries with higher factual consistency compared with\nexisting systems, and the correction model improves the factual consistency of\ngiven summaries via modifying only a few keywords.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 07:36:10 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 04:49:16 GMT"}, {"version": "v3", "created": "Sat, 4 Apr 2020 06:30:18 GMT"}, {"version": "v4", "created": "Sat, 25 Apr 2020 19:55:10 GMT"}, {"version": "v5", "created": "Sat, 26 Sep 2020 02:55:31 GMT"}, {"version": "v6", "created": "Thu, 11 Mar 2021 06:47:00 GMT"}, {"version": "v7", "created": "Fri, 12 Mar 2021 01:41:13 GMT"}, {"version": "v8", "created": "Mon, 15 Mar 2021 00:40:15 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Zhu", "Chenguang", ""], ["Hinthorn", "William", ""], ["Xu", "Ruochen", ""], ["Zeng", "Qingkai", ""], ["Zeng", "Michael", ""], ["Huang", "Xuedong", ""], ["Jiang", "Meng", ""]]}, {"id": "2003.08717", "submitter": "Thierry Deruyttere", "authors": "Thierry Deruyttere, Guillem Collell, Marie-Francine Moens", "title": "Giving Commands to a Self-driving Car: A Multimodal Reasoner for Visual\n  Grounding", "comments": "Updated acknowledgements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a new spatial memory module and a spatial reasoner for the Visual\nGrounding (VG) task. The goal of this task is to find a certain object in an\nimage based on a given textual query. Our work focuses on integrating the\nregions of a Region Proposal Network (RPN) into a new multi-step reasoning\nmodel which we have named a Multimodal Spatial Region Reasoner (MSRR). The\nintroduced model uses the object regions from an RPN as initialization of a 2D\nspatial memory and then implements a multi-step reasoning process scoring each\nregion according to the query, hence why we call it a multimodal reasoner. We\nevaluate this new model on challenging datasets and our experiments show that\nour model that jointly reasons over the object regions of the image and words\nof the query largely improves accuracy compared to current state-of-the-art\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 12:40:41 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 08:44:40 GMT"}, {"version": "v3", "created": "Wed, 26 May 2021 12:08:13 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Deruyttere", "Thierry", ""], ["Collell", "Guillem", ""], ["Moens", "Marie-Francine", ""]]}, {"id": "2003.08769", "submitter": "Nitish Nag", "authors": "Nitish Nag, Bindu Rajanna, Ramesh Jain", "title": "Personalized Taste and Cuisine Preference Modeling via Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the exponential growth in the usage of social media to share live\nupdates about life, taking pictures has become an unavoidable phenomenon.\nIndividuals unknowingly create a unique knowledge base with these images. The\nfood images, in particular, are of interest as they contain a plethora of\ninformation. From the image metadata and using computer vision tools, we can\nextract distinct insights for each user to build a personal profile. Using the\nunderlying connection between cuisines and their inherent tastes, we attempt to\ndevelop such a profile for an individual based solely on the images of his\nfood. Our study provides insights about an individual's inclination towards\nparticular cuisines. Interpreting these insights can lead to the development of\na more precise recommendation system. Such a system would avoid the generic\napproach in favor of a personalized recommendation system.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 01:07:56 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Nag", "Nitish", ""], ["Rajanna", "Bindu", ""], ["Jain", "Ramesh", ""]]}, {"id": "2003.08808", "submitter": "Mohammad Hamed Mozaffari", "authors": "M. Hamed Mozaffari, Won-Sook Lee", "title": "Deep Learning for Automatic Tracking of Tongue Surface in Real-time\n  Ultrasound Videos, Landmarks instead of Contours", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One usage of medical ultrasound imaging is to visualize and characterize\nhuman tongue shape and motion during a real-time speech to study healthy or\nimpaired speech production. Due to the low-contrast characteristic and noisy\nnature of ultrasound images, it might require expertise for non-expert users to\nrecognize tongue gestures in applications such as visual training of a second\nlanguage. Moreover, quantitative analysis of tongue motion needs the tongue\ndorsum contour to be extracted, tracked, and visualized. Manual tongue contour\nextraction is a cumbersome, subjective, and error-prone task. Furthermore, it\nis not a feasible solution for real-time applications. The growth of deep\nlearning has been vigorously exploited in various computer vision tasks,\nincluding ultrasound tongue contour tracking. In the current methods, the\nprocess of tongue contour extraction comprises two steps of image segmentation\nand post-processing. This paper presents a new novel approach of automatic and\nreal-time tongue contour tracking using deep neural networks. In the proposed\nmethod, instead of the two-step procedure, landmarks of the tongue surface are\ntracked. This novel idea enables researchers in this filed to benefits from\navailable previously annotated databases to achieve high accuracy results. Our\nexperiment disclosed the outstanding performances of the proposed technique in\nterms of generalization, performance, and accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 00:38:13 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Mozaffari", "M. Hamed", ""], ["Lee", "Won-Sook", ""]]}, {"id": "2003.08811", "submitter": "Alessandro Antonucci", "authors": "Vani K and Simone Mellace and Alessandro Antonucci", "title": "Temporal Embeddings and Transformer Models for Narrative Text\n  Understanding", "comments": "Presented at the Third International Workshop on Narrative Extraction\n  from Texts (Text2Story 2020) held in conjunction with the 42nd European\n  Conference on Information Retrieval", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two deep learning approaches to narrative text understanding for\ncharacter relationship modelling. The temporal evolution of these relations is\ndescribed by dynamic word embeddings, that are designed to learn semantic\nchanges over time. An empirical analysis of the corresponding character\ntrajectories shows that such approaches are effective in depicting dynamic\nevolution. A supervised learning approach based on the state-of-the-art\ntransformer model BERT is used instead to detect static relations between\ncharacters. The empirical validation shows that such events (e.g., two\ncharacters belonging to the same family) might be spotted with good accuracy,\neven when using automatically annotated data. This provides a deeper\nunderstanding of narrative plots based on the identification of key facts.\nStandard clustering techniques are finally used for character de-aliasing, a\nnecessary pre-processing step for both approaches. Overall, deep learning\nmodels appear to be suitable for narrative text understanding, while also\nproviding a challenging and unexploited benchmark for general natural language\nunderstanding.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 14:23:12 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["K", "Vani", ""], ["Mellace", "Simone", ""], ["Antonucci", "Alessandro", ""]]}, {"id": "2003.08875", "submitter": "Ehsan Taher", "authors": "Ehsan Taher, Seyed Abbas Hoseini, and Mehrnoush Shamsfard", "title": "Beheshti-NER: Persian Named Entity Recognition Using BERT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity recognition is a natural language processing task to recognize\nand extract spans of text associated with named entities and classify them in\nsemantic Categories.\n  Google BERT is a deep bidirectional language model, pre-trained on large\ncorpora that can be fine-tuned to solve many NLP tasks such as question\nanswering, named entity recognition, part of speech tagging and etc. In this\npaper, we use the pre-trained deep bidirectional network, BERT, to make a model\nfor named entity recognition in Persian.\n  We also compare the results of our model with the previous state of the art\nresults achieved on Persian NER. Our evaluation metric is CONLL 2003 score in\ntwo levels of word and phrase. This model achieved second place in NSURL-2019\ntask 7 competition which associated with NER for the Persian language. our\nresults in this competition are 83.5 and 88.4 f1 CONLL score respectively in\nphrase and word level evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 15:55:21 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Taher", "Ehsan", ""], ["Hoseini", "Seyed Abbas", ""], ["Shamsfard", "Mehrnoush", ""]]}, {"id": "2003.08897", "submitter": "Longteng Guo", "authors": "Longteng Guo, Jing Liu, Xinxin Zhu, Peng Yao, Shichen Lu, and Hanqing\n  Lu", "title": "Normalized and Geometry-Aware Self-Attention Network for Image\n  Captioning", "comments": "Accepted by CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-attention (SA) network has shown profound value in image captioning. In\nthis paper, we improve SA from two aspects to promote the performance of image\ncaptioning. First, we propose Normalized Self-Attention (NSA), a\nreparameterization of SA that brings the benefits of normalization inside SA.\nWhile normalization is previously only applied outside SA, we introduce a novel\nnormalization method and demonstrate that it is both possible and beneficial to\nperform it on the hidden activations inside SA. Second, to compensate for the\nmajor limit of Transformer that it fails to model the geometry structure of the\ninput objects, we propose a class of Geometry-aware Self-Attention (GSA) that\nextends SA to explicitly and efficiently consider the relative geometry\nrelations between the objects in the image. To construct our image captioning\nmodel, we combine the two modules and apply it to the vanilla self-attention\nnetwork. We extensively evaluate our proposals on MS-COCO image captioning\ndataset and superior results are achieved when comparing to state-of-the-art\napproaches. Further experiments on three challenging tasks, i.e. video\ncaptioning, machine translation, and visual question answering, show the\ngenerality of our methods.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 16:54:16 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Guo", "Longteng", ""], ["Liu", "Jing", ""], ["Zhu", "Xinxin", ""], ["Yao", "Peng", ""], ["Lu", "Shichen", ""], ["Lu", "Hanqing", ""]]}, {"id": "2003.08925", "submitter": "Anoop Kunchukuttan", "authors": "Anoop Kunchukuttan, Pushpak Bhattacharyya", "title": "Utilizing Language Relatedness to improve Machine Translation: A Case\n  Study on Languages of the Indian Subcontinent", "comments": "This work was done in 2017-2018 as part of the first author's thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present an extensive study of statistical machine\ntranslation involving languages of the Indian subcontinent. These languages are\nrelated by genetic and contact relationships. We describe the similarities\nbetween Indic languages arising from these relationships. We explore how\nlexical and orthographic similarity among these languages can be utilized to\nimprove translation quality between Indic languages when limited parallel\ncorpora is available. We also explore how the structural correspondence between\nIndic languages can be utilized to re-use linguistic resources for English to\nIndic language translation. Our observations span 90 language pairs from 9\nIndic languages and English. To the best of our knowledge, this is the first\nlarge-scale study specifically devoted to utilizing language relatedness to\nimprove translation between related languages.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 17:43:28 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Kunchukuttan", "Anoop", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "2003.08964", "submitter": "Cristi\\'an Bravo", "authors": "Matthew Stevenson, Christophe Mues and Cristi\\'an Bravo", "title": "The value of text for small business default prediction: A deep learning\n  approach", "comments": "25 pages, 12 figures. v4 - Accepted", "journal-ref": "European Journal of Operational Research 295 (2): 758-771 (2021)", "doi": "10.1016/j.ejor.2021.03.008", "report-no": null, "categories": "cs.LG cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Compared to consumer lending, Micro, Small and Medium Enterprise (mSME)\ncredit risk modelling is particularly challenging, as, often, the same sources\nof information are not available. Therefore, it is standard policy for a loan\nofficer to provide a textual loan assessment to mitigate limited data\navailability. In turn, this statement is analysed by a credit expert alongside\nany available standard credit data. In our paper, we exploit recent advances\nfrom the field of Deep Learning and Natural Language Processing (NLP),\nincluding the BERT (Bidirectional Encoder Representations from Transformers)\nmodel, to extract information from 60 000 textual assessments provided by a\nlender. We consider the performance in terms of the AUC (Area Under the\nreceiver operating characteristic Curve) and Brier Score metrics and find that\nthe text alone is surprisingly effective for predicting default. However, when\ncombined with traditional data, it yields no additional predictive capability,\nwith performance dependent on the text's length. Our proposed deep learning\nmodel does, however, appear to be robust to the quality of the text and\ntherefore suitable for partly automating the mSME lending process. We also\ndemonstrate how the content of loan assessments influences performance, leading\nus to a series of recommendations on a new strategy for collecting future mSME\nloan assessments.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 18:15:05 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 20:03:50 GMT"}, {"version": "v3", "created": "Thu, 11 Feb 2021 21:57:54 GMT"}, {"version": "v4", "created": "Wed, 7 Jul 2021 19:19:33 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Stevenson", "Matthew", ""], ["Mues", "Christophe", ""], ["Bravo", "Cristi\u00e1n", ""]]}, {"id": "2003.09024", "submitter": "Vladimir Bataev", "authors": "Nikolay Malkovsky, Vladimir Bataev, Dmitrii Sviridkin, Natalia\n  Kizhaeva, Aleksandr Laptev, Ildar Valiev, Oleg Petrov", "title": "Techniques for Vocabulary Expansion in Hybrid Speech Recognition Systems", "comments": "Submitted to Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of out of vocabulary words (OOV) is typical for any speech\nrecognition system, hybrid systems are usually constructed to recognize a fixed\nset of words and rarely can include all the words that will be encountered\nduring exploitation of the system. One of the popular approach to cover OOVs is\nto use subword units rather then words. Such system can potentially recognize\nany previously unseen word if the word can be constructed from present subword\nunits, but also non-existing words can be recognized. The other popular\napproach is to modify HMM part of the system so that it can be easily and\neffectively expanded with custom set of words we want to add to the system. In\nthis paper we explore different existing methods of this solution on both graph\nconstruction and search method levels. We also present a novel vocabulary\nexpansion techniques which solve some common internal subroutine problems\nregarding recognition graph processing.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 21:24:45 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Malkovsky", "Nikolay", ""], ["Bataev", "Vladimir", ""], ["Sviridkin", "Dmitrii", ""], ["Kizhaeva", "Natalia", ""], ["Laptev", "Aleksandr", ""], ["Valiev", "Ildar", ""], ["Petrov", "Oleg", ""]]}, {"id": "2003.09029", "submitter": "Nasrin Taghizadeh", "authors": "Nasrin Taghizadeh, Zeinab Borhanifard, Melika GolestaniPour, Heshaam\n  Faili", "title": "NSURL-2019 Task 7: Named Entity Recognition (NER) in Farsi", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NSURL-2019 Task 7 focuses on Named Entity Recognition (NER) in Farsi. This\ntask was chosen to compare different approaches to find phrases that specify\nNamed Entities in Farsi texts, and to establish a standard testbed for future\nresearches on this task in Farsi. This paper describes the process of making\ntraining and test data, a list of participating teams (6 teams), and evaluation\nresults of their systems. The best system obtained 85.4% of F1 score based on\nphrase-level evaluation on seven classes of NEs including person, organization,\nlocation, date, time, money and percent.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 22:09:51 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Taghizadeh", "Nasrin", ""], ["Borhanifard", "Zeinab", ""], ["GolestaniPour", "Melika", ""], ["Faili", "Heshaam", ""]]}, {"id": "2003.09136", "submitter": "Anne Baillot", "authors": "David Lassner (TUB), Anne Baillot (3L.AM), Sergej Dogadov (TUB),\n  Klaus-Robert M\\\"uller (TUB), Shinichi Nakajima (TUB)", "title": "Automatic Identification of Types of Alterations in Historical\n  Manuscripts", "comments": "Accepted for publication in Digital Humanities Quarterly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alterations in historical manuscripts such as letters represent a promising\nfield of research. On the one hand, they help understand the construction of\ntext. On the other hand, topics that are being considered sensitive at the time\nof the manuscript gain coherence and contextuality when taking alterations into\naccount, especially in the case of deletions. The analysis of alterations in\nmanuscripts, though, is a traditionally very tedious work. In this paper, we\npresent a machine learning-based approach to help categorize alterations in\ndocuments. In particular, we present a new probabilistic model (Alteration\nLatent Dirichlet Allocation, alterLDA in the following) that categorizes\ncontent-related alterations. The method proposed here is developed based on\nexperiments carried out on the digital scholarly edition Berlin Intellectuals,\nfor which alterLDA achieves high performance in the recognition of alterations\non labelled data. On unlabelled data, applying alterLDA leads to interesting\nnew insights into the alteration behavior of authors, editors and other\nmanuscript contributors, as well as insights into sensitive topics in the\ncorrespondence of Berlin intellectuals around 1800. In addition to the findings\nbased on the digital scholarly edition Berlin Intellectuals, we present a\ngeneral framework for the analysis of text genesis that can be used in the\ncontext of other digital resources representing document variants. To that end,\nwe present in detail the methodological steps that are to be followed in order\nto achieve such results, giving thereby a prime example of an Machine Learning\napplication the Digital Humanities.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 08:05:27 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 08:10:13 GMT"}, {"version": "v3", "created": "Wed, 4 Nov 2020 15:36:16 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Lassner", "David", "", "TUB"], ["Baillot", "Anne", "", "3L.AM"], ["Dogadov", "Sergej", "", "TUB"], ["M\u00fcller", "Klaus-Robert", "", "TUB"], ["Nakajima", "Shinichi", "", "TUB"]]}, {"id": "2003.09166", "submitter": "Matej Martinc", "authors": "Matej Martinc, Bla\\v{z} \\v{S}krlj and Senja Pollak", "title": "TNT-KID: Transformer-based Neural Tagger for Keyword Identification", "comments": "Submitted to Natural Language Engineering journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With growing amounts of available textual data, development of algorithms\ncapable of automatic analysis, categorization and summarization of these data\nhas become a necessity. In this research we present a novel algorithm for\nkeyword identification, i.e., an extraction of one or multi-word phrases\nrepresenting key aspects of a given document, called Transformer-based Neural\nTagger for Keyword IDentification (TNT-KID). By adapting the transformer\narchitecture for a specific task at hand and leveraging language model\npretraining on a domain specific corpus, the model is capable of overcoming\ndeficiencies of both supervised and unsupervised state-of-the-art approaches to\nkeyword extraction by offering competitive and robust performance on a variety\nof different datasets while requiring only a fraction of manually labeled data\nrequired by the best performing systems. This study also offers thorough error\nanalysis with valuable insights into the inner workings of the model and an\nablation study measuring the influence of specific components of the keyword\nidentification workflow on the overall performance.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 09:55:10 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 11:45:00 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Martinc", "Matej", ""], ["\u0160krlj", "Bla\u017e", ""], ["Pollak", "Senja", ""]]}, {"id": "2003.09180", "submitter": "Yoonjae Jeong", "authors": "Yoonjae Jeong, Hoon-Young Cho", "title": "Detecting Mismatch between Text Script and Voice-over Using Utterance\n  Verification Based on Phoneme Recognition Ranking", "comments": "Accepted by ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this study is to detect the mismatch between text script and\nvoice-over. For this, we present a novel utterance verification (UV) method,\nwhich calculates the degree of correspondence between a voice-over and the\nphoneme sequence of a script. We found that the phoneme recognition\nprobabilities of exaggerated voice-overs decrease compared to ordinary\nutterances, but their rankings do not demonstrate any significant change. The\nproposed method, therefore, uses the recognition ranking of each phoneme\nsegment corresponding to a phoneme sequence for measuring the confidence of a\nvoice-over utterance for its corresponding script. The experimental results\nshow that the proposed UV method outperforms a state-of-the-art approach using\ncross modal attention used for detecting mismatch between speech and\ntranscription.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 10:35:35 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Jeong", "Yoonjae", ""], ["Cho", "Hoon-Young", ""]]}, {"id": "2003.09211", "submitter": "Himanshu Mangla", "authors": "Anmol Bhasin, Bharatram Natarajan, Gaurav Mathur and Himanshu Mangla", "title": "Parallel Intent and Slot Prediction using MLB Fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intent and Slot Identification are two important tasks in Spoken Language\nUnderstanding (SLU). For a natural language utterance, there is a high\ncorrelation between these two tasks. A lot of work has been done on each of\nthese using Recurrent-Neural-Networks (RNN), Convolution Neural Networks (CNN)\nand Attention based models. Most of the past work used two separate models for\nintent and slot prediction. Some of them also used sequence-to-sequence type\nmodels where slots are predicted after evaluating the utterance-level intent.\nIn this work, we propose a parallel Intent and Slot Prediction technique where\nseparate Bidirectional Gated Recurrent Units (GRU) are used for each task. We\nposit the usage of MLB (Multimodal Low-rank Bilinear Attention Network) fusion\nfor improvement in performance of intent and slot learning. To the best of our\nknowledge, this is the first attempt of using such a technique on text based\nproblems. Also, our proposed methods outperform the existing state-of-the-art\nresults for both intent and slot prediction on two benchmark datasets\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 11:48:16 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Bhasin", "Anmol", ""], ["Natarajan", "Bharatram", ""], ["Mathur", "Gaurav", ""], ["Mangla", "Himanshu", ""]]}, {"id": "2003.09229", "submitter": "Xuanqing Liu", "authors": "Xuanqing Liu, Hsiang-Fu Yu, Inderjit Dhillon, Cho-Jui Hsieh", "title": "Learning to Encode Position for Transformer with Continuous Dynamical\n  Model", "comments": "Code to be released in https://github.com/xuanqing94/FLOATER", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new way of learning to encode position information for\nnon-recurrent models, such as Transformer models. Unlike RNN and LSTM, which\ncontain inductive bias by loading the input tokens sequentially, non-recurrent\nmodels are less sensitive to position. The main reason is that position\ninformation among input units is not inherently encoded, i.e., the models are\npermutation equivalent; this problem justifies why all of the existing models\nare accompanied by a sinusoidal encoding/embedding layer at the input. However,\nthis solution has clear limitations: the sinusoidal encoding is not flexible\nenough as it is manually designed and does not contain any learnable\nparameters, whereas the position embedding restricts the maximum length of\ninput sequences. It is thus desirable to design a new position layer that\ncontains learnable parameters to adjust to different datasets and different\narchitectures. At the same time, we would also like the encodings to\nextrapolate in accordance with the variable length of inputs. In our proposed\nsolution, we borrow from the recent Neural ODE approach, which may be viewed as\na versatile continuous version of a ResNet. This model is capable of modeling\nmany kinds of dynamical systems. We model the evolution of encoded results\nalong position index by such a dynamical system, thereby overcoming the above\nlimitations of existing methods. We evaluate our new position layers on a\nvariety of neural machine translation and language understanding tasks, the\nexperimental results show consistent improvements over the baselines.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 00:41:41 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Liu", "Xuanqing", ""], ["Yu", "Hsiang-Fu", ""], ["Dhillon", "Inderjit", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "2003.09244", "submitter": "Hrafn Loftsson", "authors": "Anna Bj\\\"ork Nikul\\'asd\\'ottir, J\\'on Gu{\\dh}nason, Anton Karl\n  Ingason, Hrafn Loftsson, Eir\\'ikur R\\\"ognvaldsson, Einar Freyr Sigur{\\dh}sson\n  and Stein{\\th}\\'or Steingr\\'imsson", "title": "Language Technology Programme for Icelandic 2019-2023", "comments": "Accepted at LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe a new national language technology programme for\nIcelandic. The programme, which spans a period of five years, aims at making\nIcelandic usable in communication and interactions in the digital world, by\ndeveloping accessible, open-source language resources and software. The\nresearch and development work within the programme is carried out by a\nconsortium of universities, institutions, and private companies, with a strong\nemphasis on cooperation between academia and industries. Five core projects\nwill be the main content of the programme: language resources, speech\nrecognition, speech synthesis, machine translation, and spell and grammar\nchecking. We also describe other national language technology programmes and\ngive an overview over the history of language technology in Iceland.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 12:54:43 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Nikul\u00e1sd\u00f3ttir", "Anna Bj\u00f6rk", ""], ["Gu\u00f0nason", "J\u00f3n", ""], ["Ingason", "Anton Karl", ""], ["Loftsson", "Hrafn", ""], ["R\u00f6gnvaldsson", "Eir\u00edkur", ""], ["Sigur\u00f0sson", "Einar Freyr", ""], ["Steingr\u00edmsson", "Stein\u00fe\u00f3r", ""]]}, {"id": "2003.09288", "submitter": "Suyu Ge", "authors": "Suyu Ge, Fangzhao Wu, Chuhan Wu, Tao Qi, Yongfeng Huang, and Xing Xie", "title": "FedNER: Privacy-preserving Medical Named Entity Recognition with\n  Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical named entity recognition (NER) has wide applications in intelligent\nhealthcare. Sufficient labeled data is critical for training accurate medical\nNER model. However, the labeled data in a single medical platform is usually\nlimited. Although labeled datasets may exist in many different medical\nplatforms, they cannot be directly shared since medical data is highly\nprivacy-sensitive. In this paper, we propose a privacy-preserving medical NER\nmethod based on federated learning, which can leverage the labeled data in\ndifferent platforms to boost the training of medical NER model and remove the\nneed of exchanging raw data among different platforms. Since the labeled data\nin different platforms usually has some differences in entity type and\nannotation criteria, instead of constraining different platforms to share the\nsame model, we decompose the medical NER model in each platform into a shared\nmodule and a private module. The private module is used to capture the\ncharacteristics of the local data in each platform, and is updated using local\nlabeled data. The shared module is learned across different medical platform to\ncapture the shared NER knowledge. Its local gradients from different platforms\nare aggregated to update the global shared module, which is further delivered\nto each platform to update their local shared modules. Experiments on three\npublicly available datasets validate the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 14:17:16 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 06:37:06 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Ge", "Suyu", ""], ["Wu", "Fangzhao", ""], ["Wu", "Chuhan", ""], ["Qi", "Tao", ""], ["Huang", "Yongfeng", ""], ["Xie", "Xing", ""]]}, {"id": "2003.09520", "submitter": "Elisa Gugliotta", "authors": "Elisa Gugliotta, Marco Dinarelli", "title": "TArC: Incrementally and Semi-Automatically Collecting a Tunisian Arabish\n  Corpus", "comments": "Paper accepted at the Language Resources and Evaluation Conference\n  (LREC) 2020", "journal-ref": "Proceedings of the 12th Language Resources and Evaluation\n  Conference, 2020, (6279-6286)", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This article describes the constitution process of the first\nmorpho-syntactically annotated Tunisian Arabish Corpus (TArC). Arabish, also\nknown as Arabizi, is a spontaneous coding of Arabic dialects in Latin\ncharacters and arithmographs (numbers used as letters). This code-system was\ndeveloped by Arabic-speaking users of social media in order to facilitate the\nwriting in the Computer-Mediated Communication (CMC) and text messaging\ninformal frameworks. There is variety in the realization of Arabish amongst\ndialects, and each Arabish code-system is under-resourced, in the same way as\nmost of the Arabic dialects. In the last few years, the focus on Arabic\ndialects in the NLP field has considerably increased. Taking this into\nconsideration, TArC will be a useful support for different types of analyses,\ncomputational and linguistic, as well as for NLP tools training. In this\narticle we will describe preliminary work on the TArC semi-automatic\nconstruction process and some of the first analyses we developed on TArC. In\naddition, in order to provide a complete overview of the challenges faced\nduring the building process, we will present the main Tunisian dialect\ncharacteristics and their encoding in Tunisian Arabish.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 22:29:42 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 12:00:28 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Gugliotta", "Elisa", ""], ["Dinarelli", "Marco", ""]]}, {"id": "2003.09530", "submitter": "Jonathan Harris", "authors": "Jonathan J. Harris, Ching-Hua Chen, Mohammed J. Zaki", "title": "A Framework for Generating Explanations from Temporal Personal Health\n  Data", "comments": "41 pages, 24 figures. To appear in ACM Transactions on Computing for\n  Healthcare", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whereas it has become easier for individuals to track their personal health\ndata (e.g., heart rate, step count, food log), there is still a wide chasm\nbetween the collection of data and the generation of meaningful explanations to\nhelp users better understand what their data means to them. With an increased\ncomprehension of their data, users will be able to act upon the newfound\ninformation and work towards striving closer to their health goals. We aim to\nbridge the gap between data collection and explanation generation by mining the\ndata for interesting behavioral findings that may provide hints about a user's\ntendencies. Our focus is on improving the explainability of temporal personal\nhealth data via a set of informative summary templates, or \"protoforms.\" These\nprotoforms span both evaluation-based summaries that help users evaluate their\nhealth goals and pattern-based summaries that explain their implicit behaviors.\nIn addition to individual users, the protoforms we use are also designed for\npopulation-level summaries. We apply our approach to generate summaries (both\nunivariate and multivariate) from real user data and show that our system can\ngenerate interesting and useful explanations.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 23:32:08 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 00:53:00 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Harris", "Jonathan J.", ""], ["Chen", "Ching-Hua", ""], ["Zaki", "Mohammed J.", ""]]}, {"id": "2003.09586", "submitter": "Hongfei Xu", "authors": "Hongfei Xu and Josef van Genabith and Qiuhui Liu and Deyi Xiong", "title": "Probing Word Translations in the Transformer and Trading Decoder for\n  Encoder Layers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to its effectiveness and performance, the Transformer translation model\nhas attracted wide attention, most recently in terms of probing-based\napproaches. Previous work focuses on using or probing source linguistic\nfeatures in the encoder. To date, the way word translation evolves in\nTransformer layers has not yet been investigated. Naively, one might assume\nthat encoder layers capture source information while decoder layers translate.\nIn this work, we show that this is not quite the case: translation already\nhappens progressively in encoder layers and even in the input embeddings. More\nsurprisingly, we find that some of the lower decoder layers do not actually do\nthat much decoding. We show all of this in terms of a probing approach where we\nproject representations of the layer analyzed to the final trained and frozen\nclassifier level of the Transformer decoder to measure word translation\naccuracy. Our findings motivate and explain a Transformer configuration change:\nif translation already happens in the encoder layers, perhaps we can increase\nthe number of encoder layers, while decreasing the number of decoder layers,\nboosting decoding speed, without loss in translation quality? Our experiments\nshow that this is indeed the case: we can increase speed by up to a factor 2.3\nwith small gains in translation quality, while an 18-4 deep encoder\nconfiguration boosts translation quality by +1.42 BLEU (En-De) at a speed-up of\n1.4.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 06:12:14 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 00:31:13 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Xu", "Hongfei", ""], ["van Genabith", "Josef", ""], ["Liu", "Qiuhui", ""], ["Xiong", "Deyi", ""]]}, {"id": "2003.09606", "submitter": "Ekaterina Artemova", "authors": "Irina Krotova and Sergey Aksenov and Ekaterina Artemova", "title": "A Joint Approach to Compound Splitting and Idiomatic Compound Detection", "comments": "8 pages, 5 tables, 1 figure, accepted at LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Applications such as machine translation, speech recognition, and information\nretrieval require efficient handling of noun compounds as they are one of the\npossible sources for out-of-vocabulary (OOV) words. In-depth processing of noun\ncompounds requires not only splitting them into smaller components (or even\nroots) but also the identification of instances that should remain unsplitted\nas they are of idiomatic nature. We develop a two-fold deep learning-based\napproach of noun compound splitting and idiomatic compound detection for the\nGerman language that we train using a newly collected corpus of annotated\nGerman compounds. Our neural noun compound splitter operates on a sub-word\nlevel and outperforms the current state of the art by about 5%.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 09:00:52 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Krotova", "Irina", ""], ["Aksenov", "Sergey", ""], ["Artemova", "Ekaterina", ""]]}, {"id": "2003.09772", "submitter": "Mo Yu", "authors": "Shiyu Chang, Yang Zhang, Mo Yu, Tommi S. Jaakkola", "title": "Invariant Rationalization", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selective rationalization improves neural network interpretability by\nidentifying a small subset of input features -- the rationale -- that best\nexplains or supports the prediction. A typical rationalization criterion, i.e.\nmaximum mutual information (MMI), finds the rationale that maximizes the\nprediction performance based only on the rationale. However, MMI can be\nproblematic because it picks up spurious correlations between the input\nfeatures and the output. Instead, we introduce a game-theoretic invariant\nrationalization criterion where the rationales are constrained to enable the\nsame predictor to be optimal across different environments. We show both\ntheoretically and empirically that the proposed rationales can rule out\nspurious correlations, generalize better to different test scenarios, and align\nbetter with human judgments. Our data and code are available.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 00:50:27 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Chang", "Shiyu", ""], ["Zhang", "Yang", ""], ["Yu", "Mo", ""], ["Jaakkola", "Tommi S.", ""]]}, {"id": "2003.09831", "submitter": "Su Zhu", "authors": "Su Zhu, Zijian Zhao, Rao Ma, and Kai Yu", "title": "Prior Knowledge Driven Label Embedding for Slot Filling in Natural\n  Language Understanding", "comments": "11 pages, 6 figures; Accepted for IEEE/ACM TRANSACTIONS ON AUDIO,\n  SPEECH, AND LANGUAGE PROCESSING", "journal-ref": "TASLP, vol. 28, pp. 1440-1451, 2020", "doi": "10.1109/TASLP.2020.2980152", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional slot filling in natural language understanding (NLU) predicts a\none-hot vector for each word. This form of label representation lacks semantic\ncorrelation modelling, which leads to severe data sparsity problem, especially\nwhen adapting an NLU model to a new domain. To address this issue, a novel\nlabel embedding based slot filling framework is proposed in this paper. Here,\ndistributed label embedding is constructed for each slot using prior knowledge.\nThree encoding methods are investigated to incorporate different kinds of prior\nknowledge about slots: atomic concepts, slot descriptions, and slot exemplars.\nThe proposed label embeddings tend to share text patterns and reuses data with\ndifferent slot labels. This makes it useful for adaptive NLU with limited data.\nAlso, since label embedding is independent of NLU model, it is compatible with\nalmost all deep learning based slot filling models. The proposed approaches are\nevaluated on three datasets. Experiments on single domain and domain adaptation\ntasks show that label embedding achieves significant performance improvement\nover traditional one-hot label representation as well as advanced zero-shot\napproaches.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 07:27:07 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Zhu", "Su", ""], ["Zhao", "Zijian", ""], ["Ma", "Rao", ""], ["Yu", "Kai", ""]]}, {"id": "2003.09833", "submitter": "Jiwei Li", "authors": "Xiaoya Li, Yuxian Meng, Mingxin Zhou, Qinghong Han, Fei Wu and Jiwei\n  Li", "title": "SAC: Accelerating and Structuring Self-Attention via Sparse Adaptive\n  Connection", "comments": "To appear at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the self-attention mechanism has been widely used in a wide variety of\ntasks, it has the unfortunate property of a quadratic cost with respect to the\ninput length, which makes it difficult to deal with long inputs. In this paper,\nwe present a method for accelerating and structuring self-attentions: Sparse\nAdaptive Connection (SAC). In SAC, we regard the input sequence as a graph and\nattention operations are performed between linked nodes. In contrast with\nprevious self-attention models with pre-defined structures (edges), the model\nlearns to construct attention edges to improve task-specific performances. In\nthis way, the model is able to select the most salient nodes and reduce the\nquadratic complexity regardless of the sequence length. Based on SAC, we show\nthat previous variants of self-attention models are its special cases. Through\nextensive experiments on neural machine translation, language modeling, graph\nrepresentation learning and image classification, we demonstrate SAC is\ncompetitive with state-of-the-art models while significantly reducing memory\ncost.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 07:58:44 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 08:23:41 GMT"}, {"version": "v3", "created": "Tue, 29 Sep 2020 08:01:23 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Li", "Xiaoya", ""], ["Meng", "Yuxian", ""], ["Zhou", "Mingxin", ""], ["Han", "Qinghong", ""], ["Wu", "Fei", ""], ["Li", "Jiwei", ""]]}, {"id": "2003.09853", "submitter": "Federico Becattini", "authors": "Pietro Bongini, Federico Becattini, Andrew D. Bagdanov, Alberto Del\n  Bimbo", "title": "Visual Question Answering for Cultural Heritage", "comments": "accepted at FlorenceHeritech 2020", "journal-ref": null, "doi": "10.1088/1757-899X/949/1/012074", "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technology and the fruition of cultural heritage are becoming increasingly\nmore entwined, especially with the advent of smart audio guides, virtual and\naugmented reality, and interactive installations. Machine learning and computer\nvision are important components of this ongoing integration, enabling new\ninteraction modalities between user and museum. Nonetheless, the most frequent\nway of interacting with paintings and statues still remains taking pictures.\nYet images alone can only convey the aesthetics of the artwork, lacking is\ninformation which is often required to fully understand and appreciate it.\nUsually this additional knowledge comes both from the artwork itself (and\ntherefore the image depicting it) and from an external source of knowledge,\nsuch as an information sheet. While the former can be inferred by computer\nvision algorithms, the latter needs more structured data to pair visual content\nwith relevant information. Regardless of its source, this information still\nmust be be effectively transmitted to the user. A popular emerging trend in\ncomputer vision is Visual Question Answering (VQA), in which users can interact\nwith a neural network by posing questions in natural language and receiving\nanswers about the visual content. We believe that this will be the evolution of\nsmart audio guides for museum visits and simple image browsing on personal\nsmartphones. This will turn the classic audio guide into a smart personal\ninstructor with which the visitor can interact by asking for explanations\nfocused on specific interests. The advantages are twofold: on the one hand the\ncognitive burden of the visitor will decrease, limiting the flow of information\nto what the user actually wants to hear; and on the other hand it proposes the\nmost natural way of interacting with a guide, favoring engagement.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 10:26:08 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Bongini", "Pietro", ""], ["Becattini", "Federico", ""], ["Bagdanov", "Andrew D.", ""], ["Del Bimbo", "Alberto", ""]]}, {"id": "2003.09881", "submitter": "Malte Ostendorff", "authors": "Malte Ostendorff, Terry Ruas, Moritz Schubotz, Georg Rehm, Bela Gipp", "title": "Pairwise Multi-Class Document Classification for Semantic Relations\n  between Wikipedia Articles", "comments": "Accepted at ACM/IEEE Joint Conference on Digital Libraries (JCDL\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many digital libraries recommend literature to their users considering the\nsimilarity between a query document and their repository. However, they often\nfail to distinguish what is the relationship that makes two documents alike. In\nthis paper, we model the problem of finding the relationship between two\ndocuments as a pairwise document classification task. To find the semantic\nrelation between documents, we apply a series of techniques, such as GloVe,\nParagraph-Vectors, BERT, and XLNet under different configurations (e.g.,\nsequence length, vector concatenation scheme), including a Siamese architecture\nfor the Transformer-based systems. We perform our experiments on a newly\nproposed dataset of 32,168 Wikipedia article pairs and Wikidata properties that\ndefine the semantic document relations. Our results show vanilla BERT as the\nbest performing system with an F1-score of 0.93, which we manually examine to\nbetter understand its applicability to other domains. Our findings suggest that\nclassifying semantic relations between documents is a solvable task and\nmotivates the development of recommender systems based on the evaluated\ntechniques. The discussions in this paper serve as first steps in the\nexploration of documents through SPARQL-like queries such that one could find\ndocuments that are similar in one aspect but dissimilar in another.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 12:52:56 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Ostendorff", "Malte", ""], ["Ruas", "Terry", ""], ["Schubotz", "Moritz", ""], ["Rehm", "Georg", ""], ["Gipp", "Bela", ""]]}, {"id": "2003.09891", "submitter": "Thai Son Nguyen", "authors": "Thai Son Nguyen, Jan Niehues, Eunah Cho, Thanh-Le Ha, Kevin Kilgour,\n  Markus Muller, Matthias Sperber, Sebastian Stueker, Alex Waibel", "title": "Low Latency ASR for Simultaneous Speech Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User studies have shown that reducing the latency of our simultaneous lecture\ntranslation system should be the most important goal. We therefore have worked\non several techniques for reducing the latency for both components, the\nautomatic speech recognition and the speech translation module. Since the\ncommonly used commitment latency is not appropriate in our case of continuous\nstream decoding, we focused on word latency. We used it to analyze the\nperformance of our current system and to identify opportunities for\nimprovements. In order to minimize the latency we combined run-on decoding with\na technique for identifying stable partial hypotheses when stream decoding and\na protocol for dynamic output update that allows to revise the most recent\nparts of the transcription. This combination reduces the latency at word level,\nwhere the words are final and will never be updated again in the future, from\n18.1s to 1.1s without sacrificing performance in terms of word error rate.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 13:37:05 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Nguyen", "Thai Son", ""], ["Niehues", "Jan", ""], ["Cho", "Eunah", ""], ["Ha", "Thanh-Le", ""], ["Kilgour", "Kevin", ""], ["Muller", "Markus", ""], ["Sperber", "Matthias", ""], ["Stueker", "Sebastian", ""], ["Waibel", "Alex", ""]]}, {"id": "2003.09971", "submitter": "Ruotian Luo", "authors": "Ruotian Luo", "title": "A Better Variant of Self-Critical Sequence Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a simple yet better variant of Self-Critical\nSequence Training. We make a simple change in the choice of baseline function\nin REINFORCE algorithm. The new baseline can bring better performance with no\nextra cost, compared to the greedy decoding baseline.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 19:04:25 GMT"}, {"version": "v2", "created": "Sun, 10 May 2020 21:59:36 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Luo", "Ruotian", ""]]}, {"id": "2003.09986", "submitter": "Yao Qiang", "authors": "Yao Qiang, Xin Li, Dongxiao Zhu", "title": "Toward Tag-free Aspect Based Sentiment Analysis: A Multiple Attention\n  Network Approach", "comments": "to appear in the proceedings of IJCNN'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing aspect based sentiment analysis (ABSA) approaches leverage various\nneural network models to extract the aspect sentiments via learning\naspect-specific feature representations. However, these approaches heavily rely\non manual tagging of user reviews according to the predefined aspects as the\ninput, a laborious and time-consuming process. Moreover, the underlying methods\ndo not explain how and why the opposing aspect level polarities in a user\nreview lead to the overall polarity. In this paper, we tackle these two\nproblems by designing and implementing a new Multiple-Attention Network (MAN)\napproach for more powerful ABSA without the need for aspect tags using two new\ntag-free data sets crawled directly from TripAdvisor\n({https://www.tripadvisor.com}). With the Self- and Position-Aware attention\nmechanism, MAN is capable of extracting both aspect level and overall\nsentiments from the text reviews using the aspect level and overall customer\nratings, and it can also detect the vital aspect(s) leading to the overall\nsentiment polarity among different aspects via a new aspect ranking scheme. We\ncarry out extensive experiments to demonstrate the strong performance of MAN\ncompared to other state-of-the-art ABSA approaches and the explainability of\nour approach by visualizing and interpreting attention weights in case studies.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 20:18:20 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Qiang", "Yao", ""], ["Li", "Xin", ""], ["Zhu", "Dongxiao", ""]]}, {"id": "2003.09989", "submitter": "Alexander Nwala", "authors": "Alexander C. Nwala, Michele C. Weigle, Michael L. Nelson", "title": "365 Dots in 2019: Quantifying Attention of News Sources", "comments": "This is an extended version of the paper accepted at Computation +\n  Journalism Symposium 2020, which has been postponed because of COVID-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We investigate the overlap of topics of online news articles from a variety\nof sources. To do this, we provide a platform for studying the news by\nmeasuring this overlap and scoring news stories according to the degree of\nattention in near-real time. This can enable multiple studies, including\nidentifying topics that receive the most attention from news organizations and\nidentifying slow news days versus major news days. Our application, StoryGraph,\nperiodically (10-minute intervals) extracts the first five news articles from\nthe RSS feeds of 17 US news media organizations across the partisanship\nspectrum (left, center, and right). From these articles, StoryGraph extracts\nnamed entities (PEOPLE, LOCATIONS, ORGANIZATIONS, etc.) and then represents\neach news article with its set of extracted named entities. Finally, StoryGraph\ngenerates a news similarity graph where the nodes represent news articles, and\nan edge between a pair of nodes represents a high degree of similarity between\nthe nodes (similar news stories). Each news story within the news similarity\ngraph is assigned an attention score which quantifies the amount of attention\nthe topics in the news story receive collectively from the news media\norganizations. The StoryGraph service has been running since August 2017, and\nusing this method, we determined that the top news story of 2018 was the\n\"Kavanaugh hearings\" with attention score of 25.85 on September 27, 2018.\nSimilarly, the top news story for 2019 so far (2019-12-12) is \"AG William\nBarr's release of his principal conclusions of the Mueller Report,\" with an\nattention score of 22.93 on March 24, 2019.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 20:32:47 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Nwala", "Alexander C.", ""], ["Weigle", "Michele C.", ""], ["Nelson", "Michael L.", ""]]}, {"id": "2003.10022", "submitter": "Thai Son Nguyen", "authors": "Thai-Son Nguyen, Ngoc-Quan Pham, Sebastian Stueker, Alex Waibel", "title": "High Performance Sequence-to-Sequence Model for Streaming Speech\n  Recognition", "comments": "To appear in Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently sequence-to-sequence models have started to achieve state-of-the-art\nperformance on standard speech recognition tasks when processing audio data in\nbatch mode, i.e., the complete audio data is available when starting\nprocessing. However, when it comes to performing run-on recognition on an input\nstream of audio data while producing recognition results in real-time and with\nlow word-based latency, these models face several challenges. For many\ntechniques, the whole audio sequence to be decoded needs to be available at the\nstart of the processing, e.g., for the attention mechanism or the bidirectional\nLSTM (BLSTM). In this paper, we propose several techniques to mitigate these\nproblems. We introduce an additional loss function controlling the uncertainty\nof the attention mechanism, a modified beam search identifying partial, stable\nhypotheses, ways of working with BLSTM in the encoder, and the use of chunked\nBLSTM. Our experiments show that with the right combination of these\ntechniques, it is possible to perform run-on speech recognition with low\nword-based latency without sacrificing in word error rate performance.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 23:04:32 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2020 21:32:22 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Nguyen", "Thai-Son", ""], ["Pham", "Ngoc-Quan", ""], ["Stueker", "Sebastian", ""], ["Waibel", "Alex", ""]]}, {"id": "2003.10066", "submitter": "Koichiro Yoshino Ph.D.", "authors": "Koichiro Yoshino, Kohei Wakimoto, Yuta Nishimura, Satoshi Nakamura", "title": "Caption Generation of Robot Behaviors based on Unsupervised Learning of\n  Action Segments", "comments": "Will appear in IWSDS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bridging robot action sequences and their natural language captions is an\nimportant task to increase explainability of human assisting robots in their\nrecently evolving field. In this paper, we propose a system for generating\nnatural language captions that describe behaviors of human assisting robots.\nThe system describes robot actions by using robot observations; histories from\nactuator systems and cameras, toward end-to-end bridging between robot actions\nand natural language captions. Two reasons make it challenging to apply\nexisting sequence-to-sequence models to this mapping: 1) it is hard to prepare\na large-scale dataset for any kind of robots and their environment, and 2)\nthere is a gap between the number of samples obtained from robot action\nobservations and generated word sequences of captions. We introduced\nunsupervised segmentation based on K-means clustering to unify typical robot\nobservation patterns into a class. This method makes it possible for the\nnetwork to learn the relationship from a small amount of data. Moreover, we\nutilized a chunking method based on byte-pair encoding (BPE) to fill in the gap\nbetween the number of samples of robot action observations and words in a\ncaption. We also applied an attention mechanism to the segmentation task.\nExperimental results show that the proposed model based on unsupervised\nlearning can generate better descriptions than other methods. We also show that\nthe attention mechanism did not work well in our low-resource setting.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 03:44:56 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Yoshino", "Koichiro", ""], ["Wakimoto", "Kohei", ""], ["Nishimura", "Yuta", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "2003.10097", "submitter": "Michael Stewart", "authors": "Michael Stewart and Wei Liu", "title": "E2EET: From Pipeline to End-to-end Entity Typing via Transformer-Based\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Entity Typing (ET) is the process of identifying the semantic types of every\nentity within a corpus. In contrast to Named Entity Recognition, where each\ntoken in a sentence is labelled with zero or one class label, ET involves\nlabelling each entity mention with one or more class labels. Existing entity\ntyping models, which operate at the mention level, are limited by two key\nfactors: they do not make use of recently-proposed context-dependent\nembeddings, and are trained on fixed context windows. They are therefore\nsensitive to window size selection and are unable to incorporate the context of\nthe entire document. In light of these drawbacks we propose to incorporate\ncontext using transformer-based embeddings for a mention-level model, and an\nend-to-end model using a Bi-GRU to remove the dependency on window size. An\nextensive ablative study demonstrates the effectiveness of contextualised\nembeddings for mention-level models and the competitiveness of our end-to-end\nmodel for entity typing.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 06:46:28 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Stewart", "Michael", ""], ["Liu", "Wei", ""]]}, {"id": "2003.10224", "submitter": "Christos Xypolopoulos", "authors": "Christos Xypolopoulos, Antoine J.-P. Tixier, Michalis Vazirgiannis", "title": "Unsupervised Word Polysemy Quantification with Multiresolution Grids of\n  Contextual Embeddings", "comments": "Equal contribution by Christos Xypolopoulos and Antoine J.-P. Tixier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of senses of a given word, or polysemy, is a very subjective\nnotion, which varies widely across annotators and resources. We propose a novel\nmethod to estimate polysemy, based on simple geometry in the contextual\nembedding space. Our approach is fully unsupervised and purely data-driven. We\nshow through rigorous experiments that our rankings are well correlated (with\nstrong statistical significance) with 6 different rankings derived from famous\nhuman-constructed resources such as WordNet, OntoNotes, Oxford, Wikipedia etc.,\nfor 6 different standard metrics. We also visualize and analyze the correlation\nbetween the human rankings. A valuable by-product of our method is the ability\nto sample, at no extra cost, sentences containing different senses of a given\nword. Finally, the fully unsupervised nature of our method makes it applicable\nto any language.\n  Code and data are publicly available at\nhttps://github.com/ksipos/polysemy-assessment .\n  The paper was accepted as a long paper at EACL 2021.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 12:38:40 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 12:29:31 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Xypolopoulos", "Christos", ""], ["Tixier", "Antoine J. -P.", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "2003.10254", "submitter": "Guillaume Raille", "authors": "Guillaume Raille, Sandra Djambazovska, Claudiu Musat", "title": "Fast Cross-domain Data Augmentation through Neural Sentence Editing", "comments": "7 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data augmentation promises to alleviate data scarcity. This is most important\nin cases where the initial data is in short supply. This is, for existing\nmethods, also where augmenting is the most difficult, as learning the full data\ndistribution is impossible. For natural language, sentence editing offers a\nsolution - relying on small but meaningful changes to the original ones.\nLearning which changes are meaningful also requires large amounts of training\ndata. We thus aim to learn this in a source domain where data is abundant and\napply it in a different, target domain, where data is scarce - cross-domain\naugmentation.\n  We create the Edit-transformer, a Transformer-based sentence editor that is\nsignificantly faster than the state of the art and also works cross-domain. We\nargue that, due to its structure, the Edit-transformer is better suited for\ncross-domain environments than its edit-based predecessors. We show this\nperformance gap on the Yelp-Wikipedia domain pairs. Finally, we show that due\nto this cross-domain performance advantage, the Edit-transformer leads to\nmeaningful performance gains in several downstream tasks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 13:05:27 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Raille", "Guillaume", ""], ["Djambazovska", "Sandra", ""], ["Musat", "Claudiu", ""]]}, {"id": "2003.10286", "submitter": "Xuehai He", "authors": "Xuehai He, Yichen Zhang, Luntian Mou, Eric Xing, Pengtao Xie", "title": "PathVQA: 30000+ Questions for Medical Visual Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is it possible to develop an \"AI Pathologist\" to pass the board-certified\nexamination of the American Board of Pathology? To achieve this goal, the first\nstep is to create a visual question answering (VQA) dataset where the AI agent\nis presented with a pathology image together with a question and is asked to\ngive the correct answer. Our work makes the first attempt to build such a\ndataset. Different from creating general-domain VQA datasets where the images\nare widely accessible and there are many crowdsourcing workers available and\ncapable of generating question-answer pairs, developing a medical VQA dataset\nis much more challenging. First, due to privacy concerns, pathology images are\nusually not publicly available. Second, only well-trained pathologists can\nunderstand pathology images, but they barely have time to help create datasets\nfor AI research. To address these challenges, we resort to pathology textbooks\nand online digital libraries. We develop a semi-automated pipeline to extract\npathology images and captions from textbooks and generate question-answer pairs\nfrom captions using natural language processing. We collect 32,799 open-ended\nquestions from 4,998 pathology images where each question is manually checked\nto ensure correctness. To our best knowledge, this is the first dataset for\npathology VQA. Our dataset will be released publicly to promote research in\nmedical VQA.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 17:55:41 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["He", "Xuehai", ""], ["Zhang", "Yichen", ""], ["Mou", "Luntian", ""], ["Xing", "Eric", ""], ["Xie", "Pengtao", ""]]}, {"id": "2003.10296", "submitter": "Pramod Rao", "authors": "Thong Nguyen, Duy Nguyen, Pramod Rao", "title": "Adaptive Name Entity Recognition under Highly Unbalanced Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For several purposes in Natural Language Processing (NLP), such as\nInformation Extraction, Sentiment Analysis or Chatbot, Named Entity Recognition\n(NER) holds an important role as it helps to determine and categorize entities\nin text into predefined groups such as the names of persons, locations,\nquantities, organizations or percentages, etc. In this report, we present our\nexperiments on a neural architecture composed of a Conditional Random Field\n(CRF) layer stacked on top of a Bi-directional LSTM (BI-LSTM) layer for solving\nNER tasks. Besides, we also employ a fusion input of embedding vectors (Glove,\nBERT), which are pre-trained on the huge corpus to boost the generalization\ncapacity of the model. Unfortunately, due to the heavy unbalanced distribution\ncross-training data, both approaches just attained a bad performance on less\ntraining samples classes. To overcome this challenge, we introduce an add-on\nclassification model to split sentences into two different sets: Weak and\nStrong classes and then designing a couple of Bi-LSTM-CRF models properly to\noptimize performance on each set. We evaluated our models on the test set and\ndiscovered that our method can improve performance for Weak classes\nsignificantly by using a very small data set (approximately 0.45\\%) compared to\nthe rest classes.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 06:56:52 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Nguyen", "Thong", ""], ["Nguyen", "Duy", ""], ["Rao", "Pramod", ""]]}, {"id": "2003.10388", "submitter": "Xxxx Lin Lin", "authors": "Yankun Ren and Jianbin Lin and Siliang Tang and Jun Zhou and Shuang\n  Yang and Yuan Qi and Xiang Ren", "title": "Generating Natural Language Adversarial Examples on a Large Scale with\n  Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today text classification models have been widely used. However, these\nclassifiers are found to be easily fooled by adversarial examples. Fortunately,\nstandard attacking methods generate adversarial texts in a pair-wise way, that\nis, an adversarial text can only be created from a real-world text by replacing\na few words. In many applications, these texts are limited in numbers,\ntherefore their corresponding adversarial examples are often not diverse enough\nand sometimes hard to read, thus can be easily detected by humans and cannot\ncreate chaos at a large scale. In this paper, we propose an end to end solution\nto efficiently generate adversarial texts from scratch using generative models,\nwhich are not restricted to perturbing the given texts. We call it unrestricted\nadversarial text generation. Specifically, we train a conditional variational\nautoencoder (VAE) with an additional adversarial loss to guide the generation\nof adversarial examples. Moreover, to improve the validity of adversarial\ntexts, we utilize discrimators and the training framework of generative\nadversarial networks (GANs) to make adversarial texts consistent with real\ndata. Experimental results on sentiment analysis demonstrate the scalability\nand efficiency of our method. It can attack text classification models with a\nhigher success rate than existing methods, and provide acceptable quality for\nhumans in the meantime.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 03:21:35 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Ren", "Yankun", ""], ["Lin", "Jianbin", ""], ["Tang", "Siliang", ""], ["Zhou", "Jun", ""], ["Yang", "Shuang", ""], ["Qi", "Yuan", ""], ["Ren", "Xiang", ""]]}, {"id": "2003.10421", "submitter": "Eric M\\\"uller-Budack", "authors": "Eric M\\\"uller-Budack, Jonas Theiner, Sebastian Diering, Maximilian\n  Idahl, Ralph Ewerth", "title": "Multimodal Analytics for Real-world News using Measures of Cross-modal\n  Entity Consistency", "comments": "Accepted for publication in: International Conference on Multimedia\n  Retrieval (ICMR), Dublin, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The World Wide Web has become a popular source for gathering information and\nnews. Multimodal information, e.g., enriching text with photos, is typically\nused to convey the news more effectively or to attract attention. Photo content\ncan range from decorative, depict additional important information, or can even\ncontain misleading information. Therefore, automatic approaches to quantify\ncross-modal consistency of entity representation can support human assessors to\nevaluate the overall multimodal message, for instance, with regard to bias or\nsentiment. In some cases such measures could give hints to detect fake news,\nwhich is an increasingly important topic in today's society. In this paper, we\nintroduce a novel task of cross-modal consistency verification in real-world\nnews and present a multimodal approach to quantify the entity coherence between\nimage and text. Named entity linking is applied to extract persons, locations,\nand events from news texts. Several measures are suggested to calculate\ncross-modal similarity for these entities using state of the art approaches. In\ncontrast to previous work, our system automatically gathers example data from\nthe Web and is applicable to real-world news. Results on two novel datasets\nthat cover different languages, topics, and domains demonstrate the feasibility\nof our approach. Datasets and code are publicly available to foster research\ntowards this new direction.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 17:49:06 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 09:22:53 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["M\u00fcller-Budack", "Eric", ""], ["Theiner", "Jonas", ""], ["Diering", "Sebastian", ""], ["Idahl", "Maximilian", ""], ["Ewerth", "Ralph", ""]]}, {"id": "2003.10540", "submitter": "Evgeny Burnaev", "authors": "Ekaterina Artemova and Amir Bakarov and Aleksey Artemov and Evgeny\n  Burnaev and Maxim Sharaev", "title": "Data-driven models and computational tools for neurolinguistics: a\n  language technology perspective", "comments": "37 pages, 1 figure", "journal-ref": "Journal of Cognitive Science, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, our focus is the connection and influence of language\ntechnologies on the research in neurolinguistics. We present a review of brain\nimaging-based neurolinguistic studies with a focus on the natural language\nrepresentations, such as word embeddings and pre-trained language models.\nMutual enrichment of neurolinguistics and language technologies leads to\ndevelopment of brain-aware natural language representations. The importance of\nthis research area is emphasized by medical applications.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 20:41:51 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Artemova", "Ekaterina", ""], ["Bakarov", "Amir", ""], ["Artemov", "Aleksey", ""], ["Burnaev", "Evgeny", ""], ["Sharaev", "Maxim", ""]]}, {"id": "2003.10555", "submitter": "Kevin Clark", "authors": "Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning", "title": "ELECTRA: Pre-training Text Encoders as Discriminators Rather Than\n  Generators", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Masked language modeling (MLM) pre-training methods such as BERT corrupt the\ninput by replacing some tokens with [MASK] and then train a model to\nreconstruct the original tokens. While they produce good results when\ntransferred to downstream NLP tasks, they generally require large amounts of\ncompute to be effective. As an alternative, we propose a more sample-efficient\npre-training task called replaced token detection. Instead of masking the\ninput, our approach corrupts it by replacing some tokens with plausible\nalternatives sampled from a small generator network. Then, instead of training\na model that predicts the original identities of the corrupted tokens, we train\na discriminative model that predicts whether each token in the corrupted input\nwas replaced by a generator sample or not. Thorough experiments demonstrate\nthis new pre-training task is more efficient than MLM because the task is\ndefined over all input tokens rather than just the small subset that was masked\nout. As a result, the contextual representations learned by our approach\nsubstantially outperform the ones learned by BERT given the same model size,\ndata, and compute. The gains are particularly strong for small models; for\nexample, we train a model on one GPU for 4 days that outperforms GPT (trained\nusing 30x more compute) on the GLUE natural language understanding benchmark.\nOur approach also works well at scale, where it performs comparably to RoBERTa\nand XLNet while using less than 1/4 of their compute and outperforms them when\nusing the same amount of compute.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 21:17:42 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Clark", "Kevin", ""], ["Luong", "Minh-Thang", ""], ["Le", "Quoc V.", ""], ["Manning", "Christopher D.", ""]]}, {"id": "2003.10557", "submitter": "Roee Litman", "authors": "Sharon Fogel (1), Hadar Averbuch-Elor (2), Sarel Cohen, Shai Mazor (1)\n  and Roee Litman (1) ((1) Amazon Rekognition Israel, (2) Cornell University)", "title": "ScrabbleGAN: Semi-Supervised Varying Length Handwritten Text Generation", "comments": "in CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical character recognition (OCR) systems performance have improved\nsignificantly in the deep learning era. This is especially true for handwritten\ntext recognition (HTR), where each author has a unique style, unlike printed\ntext, where the variation is smaller by design. That said, deep learning based\nHTR is limited, as in every other task, by the number of training examples.\nGathering data is a challenging and costly task, and even more so, the labeling\ntask that follows, of which we focus here. One possible approach to reduce the\nburden of data annotation is semi-supervised learning. Semi supervised methods\nuse, in addition to labeled data, some unlabeled samples to improve\nperformance, compared to fully supervised ones. Consequently, such methods may\nadapt to unseen images during test time.\n  We present ScrabbleGAN, a semi-supervised approach to synthesize handwritten\ntext images that are versatile both in style and lexicon. ScrabbleGAN relies on\na novel generative model which can generate images of words with an arbitrary\nlength. We show how to operate our approach in a semi-supervised manner,\nenjoying the aforementioned benefits such as performance boost over state of\nthe art supervised HTR. Furthermore, our generator can manipulate the resulting\ntext style. This allows us to change, for instance, whether the text is\ncursive, or how thin is the pen stroke.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 21:41:19 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Fogel", "Sharon", "", "Amazon Rekognition Israel"], ["Averbuch-Elor", "Hadar", "", "Cornell University"], ["Cohen", "Sarel", "", "Amazon Rekognition Israel"], ["Mazor", "Shai", "", "Amazon Rekognition Israel"], ["Litman", "Roee", "", "Amazon Rekognition Israel"]]}, {"id": "2003.10564", "submitter": "David Adelani", "authors": "Iroro Orife, David I. Adelani, Timi Fasubaa, Victor Williamson,\n  Wuraola Fisayo Oyewusi, Olamilekan Wahab, Kola Tubosun", "title": "Improving Yor\\`ub\\'a Diacritic Restoration", "comments": "Accepted to ICLR 2020 AfricaNLP workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Yor\\`ub\\'a is a widely spoken West African language with a writing system\nrich in orthographic and tonal diacritics. They provide morphological\ninformation, are crucial for lexical disambiguation, pronunciation and are\nvital for any computational Speech or Natural Language Processing tasks.\nHowever diacritic marks are commonly excluded from electronic texts due to\nlimited device and application support as well as general education on proper\nusage. We report on recent efforts at dataset cultivation. By aggregating and\nimproving disparate texts from the web and various personal libraries, we were\nable to significantly grow our clean Yor\\`ub\\'a dataset from a majority\nBibilical text corpora with three sources to millions of tokens from over a\ndozen sources. We evaluate updated diacritic restoration models on a new,\ngeneral purpose, public-domain Yor\\`ub\\'a evaluation dataset of modern\njournalistic news text, selected to be multi-purpose and reflecting\ncontemporary usage. All pre-trained models, datasets and source-code have been\nreleased as an open-source project to advance efforts on Yor\\`ub\\'a language\ntechnology.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 22:07:15 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Orife", "Iroro", ""], ["Adelani", "David I.", ""], ["Fasubaa", "Timi", ""], ["Williamson", "Victor", ""], ["Oyewusi", "Wuraola Fisayo", ""], ["Wahab", "Olamilekan", ""], ["Tubosun", "Kola", ""]]}, {"id": "2003.10606", "submitter": "Arka Sadhu", "authors": "Arka Sadhu, Kan Chen, Ram Nevatia", "title": "Video Object Grounding using Semantic Roles in Language Description", "comments": "CVPR20 camera-ready including appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the task of Video Object Grounding (VOG), which grounds objects in\nvideos referred to in natural language descriptions. Previous methods apply\nimage grounding based algorithms to address VOG, fail to explore the object\nrelation information and suffer from limited generalization. Here, we\ninvestigate the role of object relations in VOG and propose a novel framework\nVOGNet to encode multi-modal object relations via self-attention with relative\nposition encoding. To evaluate VOGNet, we propose novel contrasting sampling\nmethods to generate more challenging grounding input samples, and construct a\nnew dataset called ActivityNet-SRL (ASRL) based on existing caption and\ngrounding datasets. Experiments on ASRL validate the need of encoding object\nrelations in VOG, and our VOGNet outperforms competitive baselines by a\nsignificant margin.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 01:31:14 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Sadhu", "Arka", ""], ["Chen", "Kan", ""], ["Nevatia", "Ram", ""]]}, {"id": "2003.10687", "submitter": "Jonathan Mallinson", "authors": "Jonathan Mallinson, Aliaksei Severyn, Eric Malmi, Guillermo Garrido", "title": "Felix: Flexible Text Editing Through Tagging and Insertion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Felix --- a flexible text-editing approach for generation,\ndesigned to derive the maximum benefit from the ideas of decoding with\nbi-directional contexts and self-supervised pre-training. In contrast to\nconventional sequence-to-sequence (seq2seq) models, Felix is efficient in\nlow-resource settings and fast at inference time, while being capable of\nmodeling flexible input-output transformations. We achieve this by decomposing\nthe text-editing task into two sub-tasks: tagging to decide on the subset of\ninput tokens and their order in the output text and insertion to in-fill the\nmissing tokens in the output not present in the input. The tagging model\nemploys a novel Pointer mechanism, while the insertion model is based on a\nMasked Language Model. Both of these models are chosen to be non-autoregressive\nto guarantee faster inference. Felix performs favourably when compared to\nrecent text-editing methods and strong seq2seq baselines when evaluated on four\nNLG tasks: Sentence Fusion, Machine Translation Automatic Post-Editing,\nSummarization, and Text Simplification.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 07:01:09 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Mallinson", "Jonathan", ""], ["Severyn", "Aliaksei", ""], ["Malmi", "Eric", ""], ["Garrido", "Guillermo", ""]]}, {"id": "2003.10704", "submitter": "Iroro Orife", "authors": "Iroro Orife", "title": "Towards Neural Machine Translation for Edoid Languages", "comments": "Accepted to ICLR 2020 AfricaNLP workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many Nigerian languages have relinquished their previous prestige and purpose\nin modern society to English and Nigerian Pidgin. For the millions of L1\nspeakers of indigenous languages, there are inequalities that manifest\nthemselves as unequal access to information, communications, health care,\nsecurity as well as attenuated participation in political and civic life. To\nminimize exclusion and promote socio-linguistic and economic empowerment, this\nwork explores the feasibility of Neural Machine Translation (NMT) for the Edoid\nlanguage family of Southern Nigeria. Using the new JW300 public dataset, we\ntrained and evaluated baseline translation models for four widely spoken\nlanguages in this group: \\`Ed\\'o, \\'Es\\'an, Urhobo and Isoko. Trained models,\ncode and datasets have been open-sourced to advance future research efforts on\nEdoid language technology.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 07:53:41 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Orife", "Iroro", ""]]}, {"id": "2003.10715", "submitter": "David Schindler", "authors": "David Schindler, Benjamin Zapilko, Frank Kr\\\"uger", "title": "Investigating Software Usage in the Social Sciences: A Knowledge Graph\n  Approach", "comments": "16 pages, 4 figures, preprint of a full paper at Extended Semantic\n  Web Conference (ESWC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge about the software used in scientific investigations is necessary\nfor different reasons, including provenance of the results, measuring software\nimpact to attribute developers, and bibliometric software citation analysis in\ngeneral. Additionally, providing information about whether and how the software\nand the source code are available allows an assessment about the state and role\nof open source software in science in general. While such analyses can be done\nmanually, large scale analyses require the application of automated methods of\ninformation extraction and linking. In this paper, we present SoftwareKG - a\nknowledge graph that contains information about software mentions from more\nthan 51,000 scientific articles from the social sciences. A silver standard\ncorpus, created by a distant and weak supervision approach, and a gold standard\ncorpus, created by manual annotation, were used to train an LSTM based neural\nnetwork to identify software mentions in scientific articles. The model\nachieves a recognition rate of .82 F-score in exact matches. As a result, we\nidentified more than 133,000 software mentions. For entity disambiguation, we\nused the public domain knowledge base DBpedia. Furthermore, we linked the\nentities of the knowledge graph to other knowledge bases such as the Microsoft\nAcademic Knowledge Graph, the Software Ontology, and Wikidata. Finally, we\nillustrate, how SoftwareKG can be used to assess the role of software in the\nsocial sciences.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 08:38:36 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Schindler", "David", ""], ["Zapilko", "Benjamin", ""], ["Kr\u00fcger", "Frank", ""]]}, {"id": "2003.10773", "submitter": "Yusen Liu", "authors": "Yusen Liu, Dayiheng Liu, Jiancheng Lv, Yongsheng Sang", "title": "Generating Chinese Poetry from Images via Concrete and Abstract\n  Information", "comments": "Accepted by the 2020 International Joint Conference on Neural\n  Networks (IJCNN 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the automatic generation of classical Chinese poetry has\nmade great progress. Besides focusing on improving the quality of the generated\npoetry, there is a new topic about generating poetry from an image. However,\nthe existing methods for this topic still have the problem of topic drift and\nsemantic inconsistency, and the image-poem pairs dataset is hard to be built\nwhen training these models. In this paper, we extract and integrate the\nConcrete and Abstract information from images to address those issues. We\nproposed an infilling-based Chinese poetry generation model which can infill\nthe Concrete keywords into each line of poems in an explicit way, and an\nabstract information embedding to integrate the Abstract information into\ngenerated poems. In addition, we use non-parallel data during training and\nconstruct separate image datasets and poem datasets to train the different\ncomponents in our framework. Both automatic and human evaluation results show\nthat our approach can generate poems which have better consistency with images\nwithout losing the quality.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 11:17:20 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Liu", "Yusen", ""], ["Liu", "Dayiheng", ""], ["Lv", "Jiancheng", ""], ["Sang", "Yongsheng", ""]]}, {"id": "2003.10816", "submitter": "Nasrin Taghizadeh", "authors": "Nasrin Taghizadeh and Heshaam Faili", "title": "Cross-Lingual Adaptation Using Universal Dependencies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a cross-lingual adaptation method based on syntactic parse trees\nobtained from the Universal Dependencies (UD), which are consistent across\nlanguages, to develop classifiers in low-resource languages. The idea of UD\nparsing is to capture similarities as well as idiosyncrasies among\ntypologically different languages. In this paper, we show that models trained\nusing UD parse trees for complex NLP tasks can characterize very different\nlanguages. We study two tasks of paraphrase identification and semantic\nrelation extraction as case studies. Based on UD parse trees, we develop\nseveral models using tree kernels and show that these models trained on the\nEnglish dataset can correctly classify data of other languages e.g. French,\nFarsi, and Arabic. The proposed approach opens up avenues for exploiting UD\nparsing in solving similar cross-lingual tasks, which is very useful for\nlanguages that no labeled data is available for them.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 13:04:06 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2020 17:09:11 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Taghizadeh", "Nasrin", ""], ["Faili", "Heshaam", ""]]}, {"id": "2003.10925", "submitter": "Zhenzhong Chen", "authors": "Nannan Li, Zhenzhong Chen", "title": "Learning Compact Reward for Image Captioning", "comments": "13 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial learning has shown its advances in generating natural and diverse\ndescriptions in image captioning. However, the learned reward of existing\nadversarial methods is vague and ill-defined due to the reward ambiguity\nproblem. In this paper, we propose a refined Adversarial Inverse Reinforcement\nLearning (rAIRL) method to handle the reward ambiguity problem by disentangling\nreward for each word in a sentence, as well as achieve stable adversarial\ntraining by refining the loss function to shift the generator towards Nash\nequilibrium. In addition, we introduce a conditional term in the loss function\nto mitigate mode collapse and to increase the diversity of the generated\ndescriptions. Our experiments on MS COCO and Flickr30K show that our method can\nlearn compact reward for image captioning.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 15:31:05 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Li", "Nannan", ""], ["Chen", "Zhenzhong", ""]]}, {"id": "2003.11080", "submitter": "Junjie Hu", "authors": "Junjie Hu, Sebastian Ruder, Aditya Siddhant, Graham Neubig, Orhan\n  Firat, Melvin Johnson", "title": "XTREME: A Massively Multilingual Multi-task Benchmark for Evaluating\n  Cross-lingual Generalization", "comments": "In Proceedings of the 37th International Conference on Machine\n  Learning (ICML). July 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much recent progress in applications of machine learning models to NLP has\nbeen driven by benchmarks that evaluate models across a wide variety of tasks.\nHowever, these broad-coverage benchmarks have been mostly limited to English,\nand despite an increasing interest in multilingual models, a benchmark that\nenables the comprehensive evaluation of such methods on a diverse range of\nlanguages and tasks is still missing. To this end, we introduce the\nCross-lingual TRansfer Evaluation of Multilingual Encoders XTREME benchmark, a\nmulti-task benchmark for evaluating the cross-lingual generalization\ncapabilities of multilingual representations across 40 languages and 9 tasks.\nWe demonstrate that while models tested on English reach human performance on\nmany tasks, there is still a sizable gap in the performance of cross-lingually\ntransferred models, particularly on syntactic and sentence retrieval tasks.\nThere is also a wide spread of results across languages. We release the\nbenchmark to encourage research on cross-lingual learning methods that transfer\nlinguistic knowledge across a diverse and representative set of languages and\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 19:09:37 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 00:21:24 GMT"}, {"version": "v3", "created": "Fri, 10 Apr 2020 16:39:28 GMT"}, {"version": "v4", "created": "Mon, 13 Jul 2020 17:05:58 GMT"}, {"version": "v5", "created": "Fri, 4 Sep 2020 17:56:31 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Hu", "Junjie", ""], ["Ruder", "Sebastian", ""], ["Siddhant", "Aditya", ""], ["Neubig", "Graham", ""], ["Firat", "Orhan", ""], ["Johnson", "Melvin", ""]]}, {"id": "2003.11082", "submitter": "Claudia Schulz", "authors": "Claudia Schulz, Damir Juric", "title": "Can Embeddings Adequately Represent Medical Terminology? New Large-Scale\n  Medical Term Similarity Datasets Have the Answer!", "comments": "Accepted at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large number of embeddings trained on medical data have emerged, but it\nremains unclear how well they represent medical terminology, in particular\nwhether the close relationship of semantically similar medical terms is encoded\nin these embeddings. To date, only small datasets for testing medical term\nsimilarity are available, not allowing to draw conclusions about the\ngeneralisability of embeddings to the enormous amount of medical terms used by\ndoctors. We present multiple automatically created large-scale medical term\nsimilarity datasets and confirm their high quality in an annotation study with\ndoctors. We evaluate state-of-the-art word and contextual embeddings on our new\ndatasets, comparing multiple vector similarity metrics and word vector\naggregation techniques. Our results show that current embeddings are limited in\ntheir ability to adequately encode medical terms. The novel datasets thus form\na challenging new benchmark for the development of medical embeddings able to\naccurately represent the whole medical terminology.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 19:18:34 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Schulz", "Claudia", ""], ["Juric", "Damir", ""]]}, {"id": "2003.11105", "submitter": "Alan Liu", "authors": "Han Liu, Shantao Liu", "title": "EQL -- an extremely easy to learn knowledge graph query language,\n  achieving highspeed and precise search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  EQL, also named as Extremely Simple Query Language, can be widely used in the\nfield of knowledge graph, precise search, strong artificial intelligence,\ndatabase, smart speaker ,patent search and other fields. EQL adopt the\nprinciple of minimalism in design and pursues simplicity and easy to learn so\nthat everyone can master it quickly. EQL language and lambda calculus are\ninterconvertible, that reveals the mathematical nature of EQL language, and\nlays a solid foundation for rigor and logical integrity of EQL language. The\nEQL language and a comprehensive knowledge graph system with the world's\ncommonsense can together form the foundation of strong AI in the future, and\nmake up for the current lack of understanding of world's commonsense by current\nAI system. EQL language can be used not only by humans, but also as a basic\nlanguage for data query and data exchange between robots.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 03:32:04 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Liu", "Han", ""], ["Liu", "Shantao", ""]]}, {"id": "2003.11117", "submitter": "Bj\\\"orn Schuller", "authors": "Bj\\\"orn W. Schuller, Dagmar M. Schuller, Kun Qian, Juan Liu, Huaiyuan\n  Zheng, Xiao Li", "title": "COVID-19 and Computer Audition: An Overview on What Speech & Sound\n  Analysis Could Contribute in the SARS-CoV-2 Corona Crisis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the time of writing, the world population is suffering from more than\n10,000 registered COVID-19 disease epidemic induced deaths since the outbreak\nof the Corona virus more than three months ago now officially known as\nSARS-CoV-2. Since, tremendous efforts have been made worldwide to counter-steer\nand control the epidemic by now labelled as pandemic. In this contribution, we\nprovide an overview on the potential for computer audition (CA), i.e., the\nusage of speech and sound analysis by artificial intelligence to help in this\nscenario. We first survey which types of related or contextually significant\nphenomena can be automatically assessed from speech or sound. These include the\nautomatic recognition and monitoring of breathing, dry and wet coughing or\nsneezing sounds, speech under cold, eating behaviour, sleepiness, or pain to\nname but a few. Then, we consider potential use-cases for exploitation. These\ninclude risk assessment and diagnosis based on symptom histograms and their\ndevelopment over time, as well as monitoring of spread, social distancing and\nits effects, treatment and recovery, and patient wellbeing. We quickly guide\nfurther through challenges that need to be faced for real-life usage. We come\nto the conclusion that CA appears ready for implementation of (pre-)diagnosis\nand monitoring tools, and more generally provides rich and significant, yet so\nfar untapped potential in the fight against COVID-19 spread.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 21:17:44 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Schuller", "Bj\u00f6rn W.", ""], ["Schuller", "Dagmar M.", ""], ["Qian", "Kun", ""], ["Liu", "Juan", ""], ["Zheng", "Huaiyuan", ""], ["Li", "Xiao", ""]]}, {"id": "2003.11173", "submitter": "Haiyang Xu", "authors": "Haiyang Xu, Yahao He, Kun Han, Junwen Chen and Xiangang Li", "title": "Learning Syntactic and Dynamic Selective Encoding for Document\n  Summarization", "comments": "IJCNN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text summarization aims to generate a headline or a short summary consisting\nof the major information of the source text. Recent studies employ the\nsequence-to-sequence framework to encode the input with a neural network and\ngenerate abstractive summary. However, most studies feed the encoder with the\nsemantic word embedding but ignore the syntactic information of the text.\nFurther, although previous studies proposed the selective gate to control the\ninformation flow from the encoder to the decoder, it is static during the\ndecoding and cannot differentiate the information based on the decoder states.\nIn this paper, we propose a novel neural architecture for document\nsummarization. Our approach has the following contributions: first, we\nincorporate syntactic information such as constituency parsing trees into the\nencoding sequence to learn both the semantic and syntactic information from the\ndocument, resulting in more accurate summary; second, we propose a dynamic gate\nnetwork to select the salient information based on the context of the decoder\nstate, which is essential to document summarization. The proposed model has\nbeen evaluated on CNN/Daily Mail summarization datasets and the experimental\nresults show that the proposed approach outperforms baseline approaches.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 01:29:38 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Xu", "Haiyang", ""], ["He", "Yahao", ""], ["Han", "Kun", ""], ["Chen", "Junwen", ""], ["Li", "Xiangang", ""]]}, {"id": "2003.11184", "submitter": "Haiyang Xu", "authors": "Haiyang Xu, Junwen Chen, Kun Han, Xiangang Li", "title": "Adversarial Multi-Binary Neural Network for Multi-class Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-class text classification is one of the key problems in machine\nlearning and natural language processing. Emerging neural networks deal with\nthe problem using a multi-output softmax layer and achieve substantial\nprogress, but they do not explicitly learn the correlation among classes. In\nthis paper, we use a multi-task framework to address multi-class\nclassification, where a multi-class classifier and multiple binary classifiers\nare trained together. Moreover, we employ adversarial training to distinguish\nthe class-specific features and the class-agnostic features. The model benefits\nfrom better feature representation. We conduct experiments on two large-scale\nmulti-class text classification tasks and demonstrate that the proposed\narchitecture outperforms baseline approaches.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 02:19:17 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Xu", "Haiyang", ""], ["Chen", "Junwen", ""], ["Han", "Kun", ""], ["Li", "Xiangang", ""]]}, {"id": "2003.11459", "submitter": "Kunwoo Park", "authors": "Kunwoo Park, Taegyun Kim, Seunghyun Yoon, Meeyoung Cha, and Kyomin\n  Jung", "title": "BaitWatcher: A lightweight web interface for the detection of\n  incongruent news headlines", "comments": "24 pages (single column), 7 figures. This research article is\n  published as a book chapter of \\textit{Fake News, Disinformation, and\n  Misinformation in Social Media-Emerging Research Challenges and\n  Opportunities}. Springer, 2020. arXiv admin note: text overlap with\n  arXiv:1811.07066", "journal-ref": null, "doi": "10.1007/978-3-030-42699-6", "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In digital environments where substantial amounts of information are shared\nonline, news headlines play essential roles in the selection and diffusion of\nnews articles. Some news articles attract audience attention by showing\nexaggerated or misleading headlines. This study addresses the \\textit{headline\nincongruity} problem, in which a news headline makes claims that are either\nunrelated or opposite to the contents of the corresponding article. We present\n\\textit{BaitWatcher}, which is a lightweight web interface that guides readers\nin estimating the likelihood of incongruence in news articles before clicking\non the headlines. BaitWatcher utilizes a hierarchical recurrent encoder that\nefficiently learns complex textual representations of a news headline and its\nassociated body text. For training the model, we construct a million scale\ndataset of news articles, which we also release for broader research use. Based\non the results of a focus group interview, we discuss the importance of\ndeveloping an interpretable AI agent for the design of a better interface for\nmitigating the effects of online misinformation.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 23:43:02 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Park", "Kunwoo", ""], ["Kim", "Taegyun", ""], ["Yoon", "Seunghyun", ""], ["Cha", "Meeyoung", ""], ["Jung", "Kyomin", ""]]}, {"id": "2003.11515", "submitter": "Amy X. Lu", "authors": "Haoran Zhang, Amy X. Lu, Mohamed Abdalla, Matthew McDermott, Marzyeh\n  Ghassemi", "title": "Hurtful Words: Quantifying Biases in Clinical Contextual Word Embeddings", "comments": "Accepted at ACM CHIL 2020 (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we examine the extent to which embeddings may encode\nmarginalized populations differently, and how this may lead to a perpetuation\nof biases and worsened performance on clinical tasks. We pretrain deep\nembedding models (BERT) on medical notes from the MIMIC-III hospital dataset,\nand quantify potential disparities using two approaches. First, we identify\ndangerous latent relationships that are captured by the contextual word\nembeddings using a fill-in-the-blank method with text from real clinical notes\nand a log probability bias score quantification. Second, we evaluate\nperformance gaps across different definitions of fairness on over 50 downstream\nclinical prediction tasks that include detection of acute and chronic\nconditions. We find that classifiers trained from BERT representations exhibit\nstatistically significant differences in performance, often favoring the\nmajority group with regards to gender, language, ethnicity, and insurance\nstatus. Finally, we explore shortcomings of using adversarial debiasing to\nobfuscate subgroup information in contextual word embeddings, and recommend\nbest practices for such deep embedding models in clinical settings.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 23:21:14 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Zhang", "Haoran", ""], ["Lu", "Amy X.", ""], ["Abdalla", "Mohamed", ""], ["McDermott", "Matthew", ""], ["Ghassemi", "Marzyeh", ""]]}, {"id": "2003.11516", "submitter": "Changyu Miao", "authors": "Changyu Miao, Zhen Cao and Yik-Cheung Tam", "title": "Keyword-Attentive Deep Semantic Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Semantic Matching is a crucial component in various natural language\nprocessing applications such as question and answering (QA), where an input\nquery is compared to each candidate question in a QA corpus in terms of\nrelevance. Measuring similarities between a query-question pair in an open\ndomain scenario can be challenging due to diverse word tokens in the\nqueryquestion pair. We propose a keyword-attentive approach to improve deep\nsemantic matching. We first leverage domain tags from a large corpus to\ngenerate a domain-enhanced keyword dictionary. Built upon BERT, we stack a\nkeyword-attentive transformer layer to highlight the importance of keywords in\nthe query-question pair. During model training, we propose a new negative\nsampling approach based on keyword coverage between the input pair. We evaluate\nour approach on a Chinese QA corpus using various metrics, including precision\nof retrieval candidates and accuracy of semantic matching. Experiments show\nthat our approach outperforms existing strong baselines. Our approach is\ngeneral and can be applied to other text matching tasks with little adaptation.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 10:18:32 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Miao", "Changyu", ""], ["Cao", "Zhen", ""], ["Tam", "Yik-Cheung", ""]]}, {"id": "2003.11517", "submitter": "Shafiuddin Rehan Ahmed", "authors": "Adam Wiemerslage and Shafiuddin Rehan Ahmed", "title": "From Algebraic Word Problem to Program: A Formalized Approach", "comments": "9 pages, 6 figures, Course project of Programming Languages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a pipeline to convert grade school level algebraic\nword problem into program of a formal languageA-IMP. Using natural language\nprocessing tools, we break the problem into sentence fragments which can then\nbe reduced to functions. The functions are categorized by the head verb of the\nsentence and its structure, as defined by (Hosseini et al., 2014). We define\nthe function signature and extract its arguments from the text using dependency\nparsing. We have a working implementation of the entire pipeline which can be\nfound on our github repository.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 20:55:01 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Wiemerslage", "Adam", ""], ["Ahmed", "Shafiuddin Rehan", ""]]}, {"id": "2003.11518", "submitter": "Yan Xiao", "authors": "Yan Xiao, Yaochu Jin, Ran Cheng, Kuangrong Hao", "title": "Hybrid Attention-Based Transformer Block Model for Distant Supervision\n  Relation Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With an exponential explosive growth of various digital text information, it\nis challenging to efficiently obtain specific knowledge from massive\nunstructured text information. As one basic task for natural language\nprocessing (NLP), relation extraction aims to extract the semantic relation\nbetween entity pairs based on the given text. To avoid manual labeling of\ndatasets, distant supervision relation extraction (DSRE) has been widely used,\naiming to utilize knowledge base to automatically annotate datasets.\nUnfortunately, this method heavily suffers from wrong labelling due to the\nunderlying strong assumptions. To address this issue, we propose a new\nframework using hybrid attention-based Transformer block with multi-instance\nlearning to perform the DSRE task. More specifically, the Transformer block is\nfirstly used as the sentence encoder to capture syntactic information of\nsentences, which mainly utilizes multi-head self-attention to extract features\nfrom word level. Then, a more concise sentence-level attention mechanism is\nadopted to constitute the bag representation, aiming to incorporate valid\ninformation of each sentence to effectively represent the bag. Experimental\nresults on the public dataset New York Times (NYT) demonstrate that the\nproposed approach can outperform the state-of-the-art algorithms on the\nevaluation dataset, which verifies the effectiveness of our model for the DSRE\ntask.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 13:05:52 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 09:04:45 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Xiao", "Yan", ""], ["Jin", "Yaochu", ""], ["Cheng", "Ran", ""], ["Hao", "Kuangrong", ""]]}, {"id": "2003.11519", "submitter": "Eduardo Mizraji", "authors": "Eduardo Mizraji", "title": "Vector logic allows counterfactual virtualization by The Square Root of\n  NOT", "comments": "This is a 12 pages preprint", "journal-ref": "Logic Journal of IGPL-Published online on July 2020", "doi": "10.1093/jigpal/jzaa026", "report-no": null, "categories": "cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we investigate the representation of counterfactual conditionals\nusing the vector logic, a matrix-vectors formalism for logical functions and\ntruth values. Inside this formalism, the counterfactuals can be transformed in\ncomplex matrices preprocessing an implication matrix with one of the square\nroots of NOT, a complex matrix. This mathematical approach puts in evidence the\nvirtual character of the counterfactuals. This happens because this\nrepresentation produces a valuation of a counterfactual that is the\nsuperposition of the two opposite truth values weighted, respectively, by two\ncomplex conjugated coefficients. This result shows that this procedure gives an\nuncertain evaluation projected on the complex domain. After this basic\nrepresentation, the judgment of the plausibility of a given counterfactual\nallows us to shift the decision towards an acceptance or a refusal. This shift\nis the result of applying for a second time one of the two square roots of NOT.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 20:56:36 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 01:23:39 GMT"}, {"version": "v3", "created": "Tue, 1 Sep 2020 21:59:24 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Mizraji", "Eduardo", ""]]}, {"id": "2003.11520", "submitter": "Radomir Popovi\\'c", "authors": "Radomir Popovi\\'c, Florian Lemmerich and Markus Strohmaier", "title": "Joint Multiclass Debiasing of Word Embeddings", "comments": "10 pages, 2 figures. To appear in the Proceedings of the 25th\n  International Symposium on Intelligent Systems (ISMIS 2020), May 2020, Graz,\n  Austria. Online appendix available at: https://git.io/JvL10", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bias in Word Embeddings has been a subject of recent interest, along with\nefforts for its reduction. Current approaches show promising progress towards\ndebiasing single bias dimensions such as gender or race. In this paper, we\npresent a joint multiclass debiasing approach that is capable of debiasing\nmultiple bias dimensions simultaneously. In that direction, we present two\napproaches, HardWEAT and SoftWEAT, that aim to reduce biases by minimizing the\nscores of the Word Embeddings Association Test (WEAT). We demonstrate the\nviability of our methods by debiasing Word Embeddings on three classes of\nbiases (religion, gender and race) in three different publicly available word\nembeddings and show that our concepts can both reduce or even completely\neliminate bias, while maintaining meaningful relationships between vectors in\nword embeddings. Our work strengthens the foundation for more unbiased neural\nrepresentations of textual data.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 22:06:37 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Popovi\u0107", "Radomir", ""], ["Lemmerich", "Florian", ""], ["Strohmaier", "Markus", ""]]}, {"id": "2003.11521", "submitter": "Xixi Zhou", "authors": "Xixi Zhou (1), Chengxi Li (1), Jiajun Bu (1), Chengwei Yao (1), Keyue\n  Shi (1), Zhi Yu (1), Zhou Yu (2) ((1) Zhejiang University, (2) University of\n  California, Davis)", "title": "Matching Text with Deep Mutual Information Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text matching is a core natural language processing research problem. How to\nretain sufficient information on both content and structure information is one\nimportant challenge. In this paper, we present a neural approach for\ngeneral-purpose text matching with deep mutual information estimation\nincorporated. Our approach, Text matching with Deep Info Max (TIM), is\nintegrated with a procedure of unsupervised learning of representations by\nmaximizing the mutual information between text matching neural network's input\nand output. We use both global and local mutual information to learn text\nrepresentations. We evaluate our text matching approach on several tasks\nincluding natural language inference, paraphrase identification, and answer\nselection. Compared to the state-of-the-art approaches, the experiments show\nthat our method integrated with mutual information estimation learns better\ntext representation and achieves better experimental results of text matching\ntasks without exploiting pretraining on external data.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 15:25:37 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Zhou", "Xixi", ""], ["Li", "Chengxi", ""], ["Bu", "Jiajun", ""], ["Yao", "Chengwei", ""], ["Shi", "Keyue", ""], ["Yu", "Zhi", ""], ["Yu", "Zhou", ""]]}, {"id": "2003.11522", "submitter": "Joseph Tassone", "authors": "Joseph Tassone, Peizhi Yan, Mackenzie Simpson, Chetan Mendhe, Vijay\n  Mago, Salimur Choudhury", "title": "Utilizing Deep Learning to Identify Drug Use on Twitter Data", "comments": "20 pages, 12 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The collection and examination of social media has become a useful mechanism\nfor studying the mental activity and behavior tendencies of users. Through the\nanalysis of collected Twitter data, models were developed for classifying\ndrug-related tweets. Using topic pertaining keywords, such as slang and methods\nof drug consumption, a set of tweets was generated. Potential candidates were\nthen preprocessed resulting in a dataset of 3,696,150 rows. The classification\npower of multiple methods was compared including support vector machines (SVM),\nXGBoost, and convolutional neural network (CNN) based classifiers. Rather than\nsimple feature or attribute analysis, a deep learning approach was implemented\nto screen and analyze the tweets' semantic meaning. The two CNN-based\nclassifiers presented the best result when compared against other\nmethodologies. The first was trained with 2,661 manually labeled samples, while\nthe other included synthetically generated tweets culminating in 12,142\nsamples. The accuracy scores were 76.35% and 82.31%, with an AUC of 0.90 and\n0.91. Additionally, association rule mining showed that commonly mentioned\ndrugs had a level of correspondence with frequently used illicit substances,\nproving the practical usefulness of the system. Lastly, the synthetically\ngenerated set provided increased scores, improving the classification\ncapability and proving the worth of this methodology.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 07:52:40 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Tassone", "Joseph", ""], ["Yan", "Peizhi", ""], ["Simpson", "Mackenzie", ""], ["Mendhe", "Chetan", ""], ["Mago", "Vijay", ""], ["Choudhury", "Salimur", ""]]}, {"id": "2003.11523", "submitter": "Alp \\\"Oktem", "authors": "Alp \\\"Oktem, Mirko Plitt, and Grace Tang", "title": "Tigrinya Neural Machine Translation with Transfer Learning for\n  Humanitarian Response", "comments": "Pre-print accepted to Africa NLP workshop organized within Eighth\n  International Conference on Learning Representations (ICLR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report our experiments in building a domain-specific Tigrinya-to-English\nneural machine translation system. We use transfer learning from other Ge'ez\nscript languages and report an improvement of 1.3 BLEU points over a classic\nneural baseline. We publish our development pipeline as an open-source library\nand also provide a demonstration application.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 10:34:25 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["\u00d6ktem", "Alp", ""], ["Plitt", "Mirko", ""], ["Tang", "Grace", ""]]}, {"id": "2003.11528", "submitter": "Jinyi Hu", "authors": "Jinyi Hu, Maosong Sun", "title": "Generating Major Types of Chinese Classical Poetry in a Uniformed\n  Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poetry generation is an interesting research topic in the field of text\ngeneration. As one of the most valuable literary and cultural heritages of\nChina, Chinese classical poetry is very familiar and loved by Chinese people\nfrom generation to generation. It has many particular characteristics in its\nlanguage structure, ranging from form, sound to meaning, thus is regarded as an\nideal testing task for text generation. In this paper, we propose a GPT-2 based\nuniformed framework for generating major types of Chinese classical poems. We\ndefine a unified format for formulating all types of training samples by\nintegrating detailed form information, then present a simple form-stressed\nweighting method in GPT-2 to strengthen the control to the form of the\ngenerated poems, with special emphasis on those forms with longer body length.\nPreliminary experimental results show this enhanced model can generate Chinese\nclassical poems of major types with high quality in both form and content,\nvalidating the effectiveness of the proposed strategy. The model has been\nincorporated into Jiuge, the most influential Chinese classical poetry\ngeneration system developed by Tsinghua University (Guo et al., 2019).\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 14:16:25 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Hu", "Jinyi", ""], ["Sun", "Maosong", ""]]}, {"id": "2003.11529", "submitter": "Iroro Orife", "authors": "Iroro Orife, Julia Kreutzer, Blessing Sibanda, Daniel Whitenack,\n  Kathleen Siminyu, Laura Martinus, Jamiil Toure Ali, Jade Abbott, Vukosi\n  Marivate, Salomon Kabongo, Musie Meressa, Espoir Murhabazi, Orevaoghene Ahia,\n  Elan van Biljon, Arshath Ramkilowan, Adewale Akinfaderin, Alp \\\"Oktem, Wole\n  Akin, Ghollah Kioko, Kevin Degila, Herman Kamper, Bonaventure Dossou, Chris\n  Emezue, Kelechi Ogueji, Abdallah Bashir", "title": "Masakhane -- Machine Translation For Africa", "comments": "Accepted for the AfricaNLP Workshop, ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Africa has over 2000 languages. Despite this, African languages account for a\nsmall portion of available resources and publications in Natural Language\nProcessing (NLP). This is due to multiple factors, including: a lack of focus\nfrom government and funding, discoverability, a lack of community, sheer\nlanguage complexity, difficulty in reproducing papers and no benchmarks to\ncompare techniques. To begin to address the identified problems, MASAKHANE, an\nopen-source, continent-wide, distributed, online research effort for machine\ntranslation for African languages, was founded. In this paper, we discuss our\nmethodology for building the community and spurring research from the African\ncontinent, as well as outline the success of the community in terms of\naddressing the identified problems affecting African NLP.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 09:01:02 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Orife", "Iroro", ""], ["Kreutzer", "Julia", ""], ["Sibanda", "Blessing", ""], ["Whitenack", "Daniel", ""], ["Siminyu", "Kathleen", ""], ["Martinus", "Laura", ""], ["Ali", "Jamiil Toure", ""], ["Abbott", "Jade", ""], ["Marivate", "Vukosi", ""], ["Kabongo", "Salomon", ""], ["Meressa", "Musie", ""], ["Murhabazi", "Espoir", ""], ["Ahia", "Orevaoghene", ""], ["van Biljon", "Elan", ""], ["Ramkilowan", "Arshath", ""], ["Akinfaderin", "Adewale", ""], ["\u00d6ktem", "Alp", ""], ["Akin", "Wole", ""], ["Kioko", "Ghollah", ""], ["Degila", "Kevin", ""], ["Kamper", "Herman", ""], ["Dossou", "Bonaventure", ""], ["Emezue", "Chris", ""], ["Ogueji", "Kelechi", ""], ["Bashir", "Abdallah", ""]]}, {"id": "2003.11530", "submitter": "Ping Li", "authors": "Haiyan Yin, Dingcheng Li, Xu Li, Ping Li", "title": "Meta-CoTGAN: A Meta Cooperative Training Paradigm for Improving\n  Adversarial Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training generative models that can generate high-quality text with\nsufficient diversity is an important open problem for Natural Language\nGeneration (NLG) community. Recently, generative adversarial models have been\napplied extensively on text generation tasks, where the adversarially trained\ngenerators alleviate the exposure bias experienced by conventional maximum\nlikelihood approaches and result in promising generation quality. However, due\nto the notorious defect of mode collapse for adversarial training, the\nadversarially trained generators face a quality-diversity trade-off, i.e., the\ngenerator models tend to sacrifice generation diversity severely for increasing\ngeneration quality. In this paper, we propose a novel approach which aims to\nimprove the performance of adversarial text generation via efficiently\ndecelerating mode collapse of the adversarial training. To this end, we\nintroduce a cooperative training paradigm, where a language model is\ncooperatively trained with the generator and we utilize the language model to\nefficiently shape the data distribution of the generator against mode collapse.\nMoreover, instead of engaging the cooperative update for the generator in a\nprincipled way, we formulate a meta learning mechanism, where the cooperative\nupdate to the generator serves as a high level meta task, with an intuition of\nensuring the parameters of the generator after the adversarial update would\nstay resistant against mode collapse. In the experiment, we demonstrate our\nproposed approach can efficiently slow down the pace of mode collapse for the\nadversarial text generators. Overall, our proposed method is able to outperform\nthe baseline approaches with significant margins in terms of both generation\nquality and diversity in the testified domains.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 04:47:52 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Yin", "Haiyan", ""], ["Li", "Dingcheng", ""], ["Li", "Xu", ""], ["Li", "Ping", ""]]}, {"id": "2003.11531", "submitter": "Izhak Shafran", "authors": "Izhak Shafran, Nan Du, Linh Tran, Amanda Perry, Lauren Keyes, Mark\n  Knichel, Ashley Domin, Lei Huang, Yuhui Chen, Gang Li, Mingqiu Wang, Laurent\n  El Shafey, Hagen Soltau, and Justin S. Paul", "title": "The Medical Scribe: Corpus Development and Model Performance Analyses", "comments": "Extended version of the paper accepted at LREC 2020", "journal-ref": "Proceedings of Language Resources and Evaluation, 2020", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing interest in creating tools to assist in clinical note\ngeneration using the audio of provider-patient encounters. Motivated by this\ngoal and with the help of providers and medical scribes, we developed an\nannotation scheme to extract relevant clinical concepts. We used this\nannotation scheme to label a corpus of about 6k clinical encounters. This was\nused to train a state-of-the-art tagging model. We report ontologies, labeling\nresults, model performances, and detailed analyses of the results. Our results\nshow that the entities related to medications can be extracted with a\nrelatively high accuracy of 0.90 F-score, followed by symptoms at 0.72 F-score,\nand conditions at 0.57 F-score. In our task, we not only identify where the\nsymptoms are mentioned but also map them to canonical forms as they appear in\nthe clinical notes. Of the different types of errors, in about 19-38% of the\ncases, we find that the model output was correct, and about 17-32% of the\nerrors do not impact the clinical note. Taken together, the models developed in\nthis work are more useful than the F-scores reflect, making it a promising\napproach for practical applications.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 03:10:25 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Shafran", "Izhak", ""], ["Du", "Nan", ""], ["Tran", "Linh", ""], ["Perry", "Amanda", ""], ["Keyes", "Lauren", ""], ["Knichel", "Mark", ""], ["Domin", "Ashley", ""], ["Huang", "Lei", ""], ["Chen", "Yuhui", ""], ["Li", "Gang", ""], ["Wang", "Mingqiu", ""], ["Shafey", "Laurent El", ""], ["Soltau", "Hagen", ""], ["Paul", "Justin S.", ""]]}, {"id": "2003.11545", "submitter": "Fernando Alonso-Fernandez", "authors": "Nicole Mariah Sharon Belvisi, Naveed Muhammad, Fernando\n  Alonso-Fernandez", "title": "Forensic Authorship Analysis of Microblogging Texts Using N-Grams and\n  Stylometric Features", "comments": "Accepted for publication at 8th International Workshop on Biometrics\n  and Forensics, IWBF 2020", "journal-ref": "Proc. 8th International Workshop on Biometrics and Forensics,\n  IWBF, Porto, Portugal, April 29-30, 2020", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, messages and text posted on the Internet are used in\ncriminal investigations. Unfortunately, the authorship of many of them remains\nunknown. In some channels, the problem of establishing authorship may be even\nharder, since the length of digital texts is limited to a certain number of\ncharacters. In this work, we aim at identifying authors of tweet messages,\nwhich are limited to 280 characters. We evaluate popular features employed\ntraditionally in authorship attribution which capture properties of the writing\nstyle at different levels. We use for our experiments a self-captured database\nof 40 users, with 120 to 200 tweets per user. Results using this small set are\npromising, with the different features providing a classification accuracy\nbetween 92% and 98.5%. These results are competitive in comparison to existing\nstudies which employ short texts such as tweets or SMS.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 19:32:11 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Belvisi", "Nicole Mariah Sharon", ""], ["Muhammad", "Naveed", ""], ["Alonso-Fernandez", "Fernando", ""]]}, {"id": "2003.11561", "submitter": "Felipe Maia Polo", "authors": "Felipe Maia Polo, Itamar Ciochetti, Emerson Bertolo", "title": "Predicting Legal Proceedings Status: Approaches Based on Sequential Text\n  Data", "comments": "Published at the 18th International Conference on Artificial\n  Intelligence and Law (ICAIL) 2021 as an extended abstract", "journal-ref": null, "doi": "10.1145/3462757.3466138", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this paper is to develop predictive models to classify\nBrazilian legal proceedings in three possible classes of status: (i) archived\nproceedings, (ii) active proceedings, and (iii) suspended proceedings. This\nproblem's resolution is intended to assist public and private institutions in\nmanaging large portfolios of legal proceedings, providing gains in scale and\nefficiency. In this paper, legal proceedings are made up of sequences of short\ntexts called \"motions.\" We combined several natural language processing (NLP)\nand machine learning techniques to solve the problem. Although working with\nPortuguese NLP, which can be challenging due to lack of resources, our\napproaches performed remarkably well in the classification task, achieving\nmaximum accuracy of .93 and top average F1 Scores of .89 (macro) and .93\n(weighted). Furthermore, we could extract and interpret the patterns learned by\none of our models besides quantifying how those patterns relate to the\nclassification task. The interpretability step is important among machine\nlearning legal applications and gives us an exciting insight into how black-box\nmodels make decisions.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 19:40:57 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 20:36:55 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2021 16:24:36 GMT"}, {"version": "v4", "created": "Wed, 23 Jun 2021 02:57:08 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Polo", "Felipe Maia", ""], ["Ciochetti", "Itamar", ""], ["Bertolo", "Emerson", ""]]}, {"id": "2003.11562", "submitter": "Abhilash Jain", "authors": "Abhilash Jain, Aku Ruohe, Stig-Arne Gr\\\"onroos, Mikko Kurimo", "title": "Finnish Language Modeling with Deep Transformer Models", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Transformers have recently taken the center stage in language modeling after\nLSTM's were considered the dominant model architecture for a long time. In this\nproject, we investigate the performance of the Transformer architectures-BERT\nand Transformer-XL for the language modeling task. We use a sub-word model\nsetting with the Finnish language and compare it to the previous State of the\nart (SOTA) LSTM model. BERT achieves a pseudo-perplexity score of 14.5, which\nis the first such measure achieved as far as we know. Transformer-XL improves\nupon the perplexity score to 73.58 which is 27\\% better than the LSTM model.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 15:12:03 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 10:02:24 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Jain", "Abhilash", ""], ["Ruohe", "Aku", ""], ["Gr\u00f6nroos", "Stig-Arne", ""], ["Kurimo", "Mikko", ""]]}, {"id": "2003.11563", "submitter": "Elena Kochkina", "authors": "Harish Tayyar Madabushi, Elena Kochkina, Michael Castelle", "title": "Cost-Sensitive BERT for Generalisable Sentence Classification with\n  Imbalanced Data", "comments": "NLP4IF 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The automatic identification of propaganda has gained significance in recent\nyears due to technological and social changes in the way news is generated and\nconsumed. That this task can be addressed effectively using BERT, a powerful\nnew architecture which can be fine-tuned for text classification tasks, is not\nsurprising. However, propaganda detection, like other tasks that deal with news\ndocuments and other forms of decontextualized social communication (e.g.\nsentiment analysis), inherently deals with data whose categories are\nsimultaneously imbalanced and dissimilar. We show that BERT, while capable of\nhandling imbalanced classes with no additional data augmentation, does not\ngeneralise well when the training and test data are sufficiently dissimilar (as\nis often the case with news sources, whose topics evolve over time). We show\nhow to address this problem by providing a statistical measure of similarity\nbetween datasets and a method of incorporating cost-weighting into BERT when\nthe training and test sets are dissimilar. We test these methods on the\nPropaganda Techniques Corpus (PTC) and achieve the second-highest score on\nsentence-level propaganda classification.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 19:10:57 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Madabushi", "Harish Tayyar", ""], ["Kochkina", "Elena", ""], ["Castelle", "Michael", ""]]}, {"id": "2003.11593", "submitter": "Hamid Jalalzai", "authors": "Hamid Jalalzai, Pierre Colombo, Chlo\\'e Clavel, Eric Gaussier,\n  Giovanna Varni, Emmanuel Vignon, Anne Sabourin", "title": "Heavy-tailed Representations, Text Polarity Classification & Data\n  Augmentation", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems (NeurIPS), Dec\n  2020", "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dominant approaches to text representation in natural language rely on\nlearning embeddings on massive corpora which have convenient properties such as\ncompositionality and distance preservation. In this paper, we develop a novel\nmethod to learn a heavy-tailed embedding with desirable regularity properties\nregarding the distributional tails, which allows to analyze the points far away\nfrom the distribution bulk using the framework of multivariate extreme value\ntheory. In particular, a classifier dedicated to the tails of the proposed\nembedding is obtained which performance outperforms the baseline. This\nclassifier exhibits a scale invariance property which we leverage by\nintroducing a novel text generation method for label preserving dataset\naugmentation. Numerical experiments on synthetic and real text data demonstrate\nthe relevance of the proposed framework and confirm that this method generates\nmeaningful sentences with controllable attribute, e.g. positive or negative\nsentiment.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 19:24:05 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 15:49:21 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Jalalzai", "Hamid", ""], ["Colombo", "Pierre", ""], ["Clavel", "Chlo\u00e9", ""], ["Gaussier", "Eric", ""], ["Varni", "Giovanna", ""], ["Vignon", "Emmanuel", ""], ["Sabourin", "Anne", ""]]}, {"id": "2003.11618", "submitter": "Jingzhou Liu", "authors": "Jingzhou Liu, Wenhu Chen, Yu Cheng, Zhe Gan, Licheng Yu, Yiming Yang,\n  Jingjing Liu", "title": "VIOLIN: A Large-Scale Dataset for Video-and-Language Inference", "comments": "Accepted to CVPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new task, Video-and-Language Inference, for joint multimodal\nunderstanding of video and text. Given a video clip with aligned subtitles as\npremise, paired with a natural language hypothesis based on the video content,\na model needs to infer whether the hypothesis is entailed or contradicted by\nthe given video clip. A new large-scale dataset, named Violin\n(VIdeO-and-Language INference), is introduced for this task, which consists of\n95,322 video-hypothesis pairs from 15,887 video clips, spanning over 582 hours\nof video. These video clips contain rich content with diverse temporal\ndynamics, event shifts, and people interactions, collected from two sources:\n(i) popular TV shows, and (ii) movie clips from YouTube channels. In order to\naddress our new multimodal inference task, a model is required to possess\nsophisticated reasoning skills, from surface-level grounding (e.g., identifying\nobjects and characters in the video) to in-depth commonsense reasoning (e.g.,\ninferring causal relations of events in the video). We present a detailed\nanalysis of the dataset and an extensive evaluation over many strong baselines,\nproviding valuable insights on the challenges of this new task.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 20:39:05 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Liu", "Jingzhou", ""], ["Chen", "Wenhu", ""], ["Cheng", "Yu", ""], ["Gan", "Zhe", ""], ["Yu", "Licheng", ""], ["Yang", "Yiming", ""], ["Liu", "Jingjing", ""]]}, {"id": "2003.11622", "submitter": "Constanza Fierro", "authors": "Constanza Fierro, Jorge P\\'erez, Javier Mora", "title": "Predicting Unplanned Readmissions with Highly Unstructured Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning techniques have been successfully applied to predict unplanned\nreadmissions of patients in medical centers. The training data for these models\nis usually based on historical medical records that contain a significant\namount of free-text from admission reports, referrals, exam notes, etc. Most of\nthe models proposed so far are tailored to English text data and assume that\nelectronic medical records follow standards common in developed countries.\nThese two characteristics make them difficult to apply in developing countries\nthat do not necessarily follow international standards for registering patient\ninformation, or that store text information in languages other than English.\n  In this paper we propose a deep learning architecture for predicting\nunplanned readmissions that consumes data that is significantly less structured\ncompared with previous models in the literature. We use it to present the first\nresults for this task in a large clinical dataset that mainly contains Spanish\ntext data. The dataset is composed of almost 10 years of records in a Chilean\nmedical center. On this dataset, our model achieves results that are comparable\nto some of the most recent results obtained in US medical centers for the same\ntask (0.76 AUROC).\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 23:21:00 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 13:23:00 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Fierro", "Constanza", ""], ["P\u00e9rez", "Jorge", ""], ["Mora", "Javier", ""]]}, {"id": "2003.11627", "submitter": "Weizhe Lin", "authors": "Xiaodong Wu, Weizhe Lin, Zhilin Wang, and Elena Rastorgueva", "title": "Author2Vec: A Framework for Generating User Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online forums and social media platforms provide noisy but valuable data\nevery day. In this paper, we propose a novel end-to-end neural network-based\nuser embedding system, Author2Vec. The model incorporates sentence\nrepresentations generated by BERT (Bidirectional Encoder Representations from\nTransformers) with a novel unsupervised pre-training objective, authorship\nclassification, to produce better user embedding that encodes useful\nuser-intrinsic properties. This user embedding system was pre-trained on post\ndata of 10k Reddit users and was analyzed and evaluated on two user\nclassification benchmarks: depression detection and personality classification,\nin which the model proved to outperform traditional count-based and\nprediction-based methods. We substantiate that Author2Vec successfully encoded\nuseful user attributes and the generated user embedding performs well in\ndownstream classification tasks without further finetuning.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 23:31:11 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Wu", "Xiaodong", ""], ["Lin", "Weizhe", ""], ["Wang", "Zhilin", ""], ["Rastorgueva", "Elena", ""]]}, {"id": "2003.11643", "submitter": "Sairamvinay Vijayaraghavan", "authors": "Sairamvinay Vijayaraghavan, Debraj Basu", "title": "Sentiment Analysis in Drug Reviews using Supervised Machine Learning\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment Analysis is an important algorithm in Natural Language Processing\nwhich is used to detect sentiment within some text. In our project, we had\nchosen to work on analyzing reviews of various drugs which have been reviewed\nin form of texts and have also been given a rating on a scale from 1-10. We had\nobtained this data set from the UCI machine learning repository which had 2\ndata sets: train and test (split as 75-25\\%). We had split the number rating\nfor the drug into three classes in general: positive (7-10), negative (1-4) or\nneutral(4-7). There are multiple reviews for the drugs that belong to a similar\ncondition and we decided to investigate how the reviews for different\nconditions use different words impact the ratings of the drugs. Our intention\nwas mainly to implement supervised machine learning classification algorithms\nthat predict the class of the rating using the textual review. We had primarily\nimplemented different embeddings such as Term Frequency Inverse Document\nFrequency (TFIDF) and the Count Vectors (CV). We had trained models on the most\npopular conditions such as \"Birth Control\", \"Depression\" and \"Pain\" within the\ndata set and obtained good results while predicting the test data sets.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 20:13:11 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Vijayaraghavan", "Sairamvinay", ""], ["Basu", "Debraj", ""]]}, {"id": "2003.11644", "submitter": "Ankit Pal", "authors": "Ankit Pal, Muru Selvakumar and Malaikannan Sankarasubbu", "title": "Multi-Label Text Classification using Attention-based Graph Neural\n  Network", "comments": null, "journal-ref": "12th International Conference on Agents and Artificial\n  Intelligence (ICAART 2020)", "doi": "10.5220/0008940304940505", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In Multi-Label Text Classification (MLTC), one sample can belong to more than\none class. It is observed that most MLTC tasks, there are dependencies or\ncorrelations among labels. Existing methods tend to ignore the relationship\namong labels. In this paper, a graph attention network-based model is proposed\nto capture the attentive dependency structure among the labels. The graph\nattention network uses a feature matrix and a correlation matrix to capture and\nexplore the crucial dependencies between the labels and generate classifiers\nfor the task. The generated classifiers are applied to sentence feature vectors\nobtained from the text feature extraction network (BiLSTM) to enable end-to-end\ntraining. Attention allows the system to assign different weights to neighbor\nnodes per label, thus allowing it to learn the dependencies among labels\nimplicitly. The results of the proposed model are validated on five real-world\nMLTC datasets. The proposed model achieves similar or better performance\ncompared to the previous state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 17:12:43 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Pal", "Ankit", ""], ["Selvakumar", "Muru", ""], ["Sankarasubbu", "Malaikannan", ""]]}, {"id": "2003.11645", "submitter": "Tosin Adewumi", "authors": "Tosin P. Adewumi, Foteini Liwicki and Marcus Liwicki", "title": "Word2Vec: Optimal Hyper-Parameters and Their Impact on NLP Downstream\n  Tasks", "comments": "8 pages, 7 figures, 6 tables; added new references based on new input\n  in the result section about CI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Word2Vec is a prominent model for natural language processing (NLP) tasks.\nSimilar inspiration is found in distributed embeddings for new state-of-the-art\n(SotA) deep neural networks. However, wrong combination of hyper-parameters can\nproduce poor quality vectors. The objective of this work is to empirically show\noptimal combination of hyper-parameters exists and evaluate various\ncombinations. We compare them with the released, pre-trained original word2vec\nmodel. Both intrinsic and extrinsic (downstream) evaluations, including named\nentity recognition (NER) and sentiment analysis (SA) were carried out. The\ndownstream tasks reveal that the best model is usually task-specific, high\nanalogy scores don't necessarily correlate positively with F1 scores and the\nsame applies to focus on data alone. Increasing vector dimension size after a\npoint leads to poor quality or performance. If ethical considerations to save\ntime, energy and the environment are made, then reasonably smaller corpora may\ndo just as well or even better in some cases. Besides, using a small corpus, we\nobtain better human-assigned WordSim scores, corresponding Spearman correlation\nand better downstream performances (with significance tests) compared to the\noriginal model, trained on 100 billion-word corpus.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 07:38:17 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 10:09:22 GMT"}, {"version": "v3", "created": "Sat, 17 Apr 2021 06:02:44 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Adewumi", "Tosin P.", ""], ["Liwicki", "Foteini", ""], ["Liwicki", "Marcus", ""]]}, {"id": "2003.11687", "submitter": "Jitin Krishnan", "authors": "Jitin Krishnan, Patrick Coronado, Hemant Purohit, and Huzefa Rangwala", "title": "Common-Knowledge Concept Recognition for SEVA", "comments": "Source code available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We build a common-knowledge concept recognition system for a Systems\nEngineer's Virtual Assistant (SEVA) which can be used for downstream tasks such\nas relation extraction, knowledge graph construction, and question-answering.\nThe problem is formulated as a token classification task similar to named\nentity extraction. With the help of a domain expert and text processing\nmethods, we construct a dataset annotated at the word-level by carefully\ndefining a labelling scheme to train a sequence model to recognize systems\nengineering concepts. We use a pre-trained language model and fine-tune it with\nthe labeled dataset of concepts. In addition, we also create some essential\ndatasets for information such as abbreviations and definitions from the systems\nengineering domain. Finally, we construct a simple knowledge graph using these\nextracted concepts along with some hyponym relations.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 00:30:36 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Krishnan", "Jitin", ""], ["Coronado", "Patrick", ""], ["Purohit", "Hemant", ""], ["Rangwala", "Huzefa", ""]]}, {"id": "2003.11922", "submitter": "Marco Baroni", "authors": "Marco Baroni", "title": "Rat big, cat eaten! Ideas for a useful deep-agent protolanguage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep-agent communities developing their own language-like communication\nprotocol are a hot (or at least warm) topic in AI. Such agents could be very\nuseful in machine-machine and human-machine interaction scenarios long before\nthey have evolved a protocol as complex as human language. Here, I propose a\nsmall set of priorities we should focus on, if we want to get as fast as\npossible to a stage where deep agents speak a useful protolanguage.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 18:41:26 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Baroni", "Marco", ""]]}, {"id": "2003.11963", "submitter": "Shaojie Jiang", "authors": "Shaojie Jiang, Thomas Wolf, Christof Monz, Maarten de Rijke", "title": "TLDR: Token Loss Dynamic Reweighting for Reducing Repetitive Utterance\n  Generation", "comments": "9 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Language Generation (NLG) models are prone to generating repetitive\nutterances. In this work, we study the repetition problem for encoder-decoder\nmodels, using both recurrent neural network (RNN) and transformer\narchitectures. To this end, we consider the chit-chat task, where the problem\nis more prominent than in other tasks that need encoder-decoder architectures.\nWe first study the influence of model architectures. By using pre-attention and\nhighway connections for RNNs, we manage to achieve lower repetition rates.\nHowever, this method does not generalize to other models such as transformers.\nWe hypothesize that the deeper reason is that in the training corpora, there\nare hard tokens that are more difficult for a generative model to learn than\nothers and, once learning has finished, hard tokens are still under-learned, so\nthat repetitive generations are more likely to happen. Based on this\nhypothesis, we propose token loss dynamic reweighting (TLDR) that applies\ndifferentiable weights to individual token losses. By using higher weights for\nhard tokens and lower weights for easy tokens, NLG models are able to learn\nindividual tokens at different paces. Experiments on chit-chat benchmark\ndatasets show that TLDR is more effective in repetition reduction for both RNN\nand transformer architectures than baselines using different weighting\nfunctions.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 15:01:37 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 09:59:25 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Jiang", "Shaojie", ""], ["Wolf", "Thomas", ""], ["Monz", "Christof", ""], ["de Rijke", "Maarten", ""]]}, {"id": "2003.12111", "submitter": "Chris C. Emezue", "authors": "Bonaventure F. P. Dossou and Chris C. Emezue", "title": "FFR V1.0: Fon-French Neural Machine Translation", "comments": "Accepted for the AfricaNLP Workshop, ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Africa has the highest linguistic diversity in the world. On account of the\nimportance of language to communication, and the importance of reliable,\npowerful and accurate machine translation models in modern inter-cultural\ncommunication, there have been (and still are) efforts to create\nstate-of-the-art translation models for the many African languages. However,\nthe low-resources, diacritical and tonal complexities of African languages are\nmajor issues facing African NLP today. The FFR is a major step towards creating\na robust translation model from Fon, a very low-resource and tonal language, to\nFrench, for research and public use. In this paper, we describe our pilot\nproject: the creation of a large growing corpora for Fon-to-French translations\nand our FFR v1.0 model, trained on this dataset. The dataset and model are made\npublicly available.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 19:01:31 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Dossou", "Bonaventure F. P.", ""], ["Emezue", "Chris C.", ""]]}, {"id": "2003.12133", "submitter": "Alina Arseniev-Koehler", "authors": "Alina Arseniev-Koehler and Jacob G. Foster", "title": "Machine learning as a model for cultural learning: Teaching an algorithm\n  what it means to be fat", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As we navigate our cultural environment, we learn cultural biases, like those\naround gender, social class, health, and body weight. It is unclear, however,\nexactly how public culture becomes private culture. In this paper, we provide a\ntheoretical account of such cultural learning. We propose that neural word\nembeddings provide a parsimonious and cognitively plausible model of the\nrepresentations learned from natural language. Using neural word embeddings, we\nextract cultural schemata about body weight from New York Times articles. We\nidentify several cultural schemata that link obesity to gender, immorality,\npoor health, and low socioeconomic class. Such schemata may be subtly but\npervasively activated in public culture; thus, language can chronically\nreproduce biases. Our findings reinforce ongoing concerns that machine learning\ncan also encode, and reproduce, harmful human biases.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 00:47:51 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 22:58:22 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Arseniev-Koehler", "Alina", ""], ["Foster", "Jacob G.", ""]]}, {"id": "2003.12139", "submitter": "Yunpeng Zhao", "authors": "Yunpeng Zhao, Mattia Prosperi, Tianchen Lyu, Yi Guo, Jiang Bian", "title": "Integrating Crowdsourcing and Active Learning for Classification of\n  Work-Life Events from Tweets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media, especially Twitter, is being increasingly used for research\nwith predictive analytics. In social media studies, natural language processing\n(NLP) techniques are used in conjunction with expert-based, manual and\nqualitative analyses. However, social media data are unstructured and must\nundergo complex manipulation for research use. The manual annotation is the\nmost resource and time-consuming process that multiple expert raters have to\nreach consensus on every item, but is essential to create gold-standard\ndatasets for training NLP-based machine learning classifiers. To reduce the\nburden of the manual annotation, yet maintaining its reliability, we devised a\ncrowdsourcing pipeline combined with active learning strategies. We\ndemonstrated its effectiveness through a case study that identifies job loss\nevents from individual tweets. We used Amazon Mechanical Turk platform to\nrecruit annotators from the Internet and designed a number of quality control\nmeasures to assure annotation accuracy. We evaluated 4 different active\nlearning strategies (i.e., least confident, entropy, vote entropy, and\nKullback-Leibler divergence). The active learning strategies aim at reducing\nthe number of tweets needed to reach a desired performance of automated\nclassification. Results show that crowdsourcing is useful to create\nhigh-quality annotations and active learning helps in reducing the number of\nrequired tweets, although there was no substantial difference among the\nstrategies tested.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 20:19:33 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 15:30:35 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Zhao", "Yunpeng", ""], ["Prosperi", "Mattia", ""], ["Lyu", "Tianchen", ""], ["Guo", "Yi", ""], ["Bian", "Jiang", ""]]}, {"id": "2003.12145", "submitter": "Navdeep Kaur", "authors": "Navdeep Kaur and Gautam Kunapuli and Sriraam Natarajan", "title": "Knowledge Graph Alignment using String Edit Distance", "comments": "Position Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a novel knowledge graph alignment technique based\nupon string edit distance that exploits the type information between entities\nand can find similarity between relations of any arity\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 22:11:39 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 00:31:35 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Kaur", "Navdeep", ""], ["Kunapuli", "Gautam", ""], ["Natarajan", "Sriraam", ""]]}, {"id": "2003.12218", "submitter": "Xuan Wang", "authors": "Xuan Wang, Xiangchen Song, Bangzheng Li, Yingjun Guan, Jiawei Han", "title": "Comprehensive Named Entity Recognition on CORD-19 with Distant or Weak\n  Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We created this CORD-NER dataset with comprehensive named entity recognition\n(NER) on the COVID-19 Open Research Dataset Challenge (CORD-19) corpus\n(2020-03-13). This CORD-NER dataset covers 75 fine-grained entity types: In\naddition to the common biomedical entity types (e.g., genes, chemicals and\ndiseases), it covers many new entity types related explicitly to the COVID-19\nstudies (e.g., coronaviruses, viral proteins, evolution, materials, substrates\nand immune responses), which may benefit research on COVID-19 related virus,\nspreading mechanisms, and potential vaccines. CORD-NER annotation is a\ncombination of four sources with different NER methods. The quality of CORD-NER\nannotation surpasses SciSpacy (over 10% higher on the F1 score based on a\nsample set of documents), a fully supervised BioNER tool. Moreover, CORD-NER\nsupports incrementally adding new documents as well as adding new entity types\nwhen needed by adding dozens of seeds as the input examples. We will constantly\nupdate CORD-NER based on the incremental updates of the CORD-19 corpus and the\nimprovement of our system.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 03:35:46 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 01:42:54 GMT"}, {"version": "v3", "created": "Wed, 8 Apr 2020 01:19:09 GMT"}, {"version": "v4", "created": "Fri, 10 Apr 2020 04:07:24 GMT"}, {"version": "v5", "created": "Wed, 15 Apr 2020 19:37:16 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Wang", "Xuan", ""], ["Song", "Xiangchen", ""], ["Li", "Bangzheng", ""], ["Guan", "Yingjun", ""], ["Han", "Jiawei", ""]]}, {"id": "2003.12298", "submitter": "Elena Voita", "authors": "Elena Voita, Ivan Titov", "title": "Information-Theoretic Probing with Minimum Description Length", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To measure how well pretrained representations encode some linguistic\nproperty, it is common to use accuracy of a probe, i.e. a classifier trained to\npredict the property from the representations. Despite widespread adoption of\nprobes, differences in their accuracy fail to adequately reflect differences in\nrepresentations. For example, they do not substantially favour pretrained\nrepresentations over randomly initialized ones. Analogously, their accuracy can\nbe similar when probing for genuine linguistic labels and probing for random\nsynthetic tasks. To see reasonable differences in accuracy with respect to\nthese random baselines, previous work had to constrain either the amount of\nprobe training data or its model size. Instead, we propose an alternative to\nthe standard probes, information-theoretic probing with minimum description\nlength (MDL). With MDL probing, training a probe to predict labels is recast as\nteaching it to effectively transmit the data. Therefore, the measure of\ninterest changes from probe accuracy to the description length of labels given\nrepresentations. In addition to probe quality, the description length evaluates\n\"the amount of effort\" needed to achieve the quality. This amount of effort\ncharacterizes either (i) size of a probing model, or (ii) the amount of data\nneeded to achieve the high quality. We consider two methods for estimating MDL\nwhich can be easily implemented on top of the standard probing pipelines:\nvariational coding and online coding. We show that these methods agree in\nresults and are more informative and stable than the standard probes.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 09:35:38 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Voita", "Elena", ""], ["Titov", "Ivan", ""]]}, {"id": "2003.12362", "submitter": "Chaz Firestone", "authors": "Michael A Lepori and Chaz Firestone", "title": "Can you hear me $\\textit{now}$? Sensitive comparisons of human and\n  machine perception", "comments": "21 pages; 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of sophisticated machine-recognition systems has brought with it a\nrise in comparisons between human and machine perception. But such comparisons\nface an asymmetry: Whereas machine perception of some stimulus can often be\nprobed through direct and explicit measures, much of human perceptual knowledge\nis latent, incomplete, or embedded in unconscious mental processes that may not\nbe available for explicit report. Here, we show how this asymmetry can cause\nsuch comparisons to underestimate the overlap in human and machine perception.\nAs a case study, we consider human perception of $\\textit{adversarial speech}$\n-- synthetic audio commands that are recognized as valid messages by automated\nspeech-recognition systems but that human listeners reportedly hear as\nmeaningless noise. In five experiments, we adapt task designs from the human\npsychophysics literature to show that even when subjects cannot freely\ntranscribe adversarial speech (the previous benchmark for human understanding),\nthey nevertheless $\\textit{can}$ discriminate adversarial speech from closely\nmatched non-speech (Experiments 1-2), finish common phrases begun in\nadversarial speech (Experiments 3-4), and solve simple math problems posed in\nadversarial speech (Experiment 5) -- even for stimuli previously described as\n\"unintelligible to human listeners\". We recommend the adoption of\n$\\textit{sensitive tests}$ of human and machine perception, and discuss the\nbroader consequences of this approach for comparing natural and artificial\nintelligence.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 16:24:08 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Lepori", "Michael A", ""], ["Firestone", "Chaz", ""]]}, {"id": "2003.12383", "submitter": "Xander Wilcke", "authors": "W.X. Wilcke (1), P. Bloem (1), V. de Boer (1), R.H. van t Veer (2),\n  F.A.H. van Harmelen (1) ((1) Department of Computer Science Vrije\n  Universiteit Amsterdam The Netherlands, (2) Geodan Amsterdam The Netherlands)", "title": "End-to-End Entity Classification on Multimodal Knowledge Graphs", "comments": "Submitted to the 17th International Conference on Principles of\n  Knowledge Representation and Reasoning (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end multimodal learning on knowledge graphs has been left largely\nunaddressed. Instead, most end-to-end models such as message passing networks\nlearn solely from the relational information encoded in graphs' structure: raw\nvalues, or literals, are either omitted completely or are stripped from their\nvalues and treated as regular nodes. In either case we lose potentially\nrelevant information which could have otherwise been exploited by our learning\nmethods. To avoid this, we must treat literals and non-literals as separate\ncases. We must also address each modality separately and accordingly: numbers,\ntexts, images, geometries, et cetera. We propose a multimodal message passing\nnetwork which not only learns end-to-end from the structure of graphs, but also\nfrom their possibly divers set of multimodal node features. Our model uses\ndedicated (neural) encoders to naturally learn embeddings for node features\nbelonging to five different types of modalities, including images and\ngeometries, which are projected into a joint representation space together with\ntheir relational information. We demonstrate our model on a node classification\ntask, and evaluate the effect that each modality has on the overall\nperformance. Our result supports our hypothesis that including information from\nmultiple modalities can help our models obtain a better overall performance.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 14:57:52 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Wilcke", "W. X.", ""], ["Bloem", "P.", ""], ["de Boer", "V.", ""], ["Veer", "R. H. van t", ""], ["van Harmelen", "F. A. H.", ""]]}, {"id": "2003.12450", "submitter": "Wuraola Oyewusi", "authors": "Wuraola Fisayo Oyewusi, Olubayo Adekanmbi and Olalekan Akinsande", "title": "Semantic Enrichment of Nigerian Pidgin English for Contextual Sentiment\n  Classification", "comments": "Accepted to ICLR 2020 AfricaNLP workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nigerian English adaptation, Pidgin, has evolved over the years through\nmulti-language code switching, code mixing and linguistic adaptation. While\nPidgin preserves many of the words in the normal English language corpus, both\nin spelling and pronunciation, the fundamental meaning of these words have\nchanged significantly. For example,'ginger' is not a plant but an expression of\nmotivation and 'tank' is not a container but an expression of gratitude. The\nimplication is that the current approach of using direct English sentiment\nanalysis of social media text from Nigeria is sub-optimal, as it will not be\nable to capture the semantic variation and contextual evolution in the\ncontemporary meaning of these words. In practice, while many words in Nigerian\nPidgin adaptation are the same as the standard English, the full English\nlanguage based sentiment analysis models are not designed to capture the full\nintent of the Nigerian pidgin when used alone or code-mixed. By augmenting\nscarce human labelled code-changed text with ample synthetic code-reformatted\ntext and meaning, we achieve significant improvements in sentiment scoring. Our\nresearch explores how to understand sentiment in an intrasentential code mixing\nand switching context where there has been significant word localization.This\nwork presents a 300 VADER lexicon compatible Nigerian Pidgin sentiment tokens\nand their scores and a 14,000 gold standard Nigerian Pidgin tweets and their\nsentiments labels.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 14:52:55 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Oyewusi", "Wuraola Fisayo", ""], ["Adekanmbi", "Olubayo", ""], ["Akinsande", "Olalekan", ""]]}, {"id": "2003.12462", "submitter": "Oleksii Sidorov", "authors": "Oleksii Sidorov, Ronghang Hu, Marcus Rohrbach, Amanpreet Singh", "title": "TextCaps: a Dataset for Image Captioning with Reading Comprehension", "comments": "To appear in ECCV 2020 (oral) Project page:\n  https://textvqa.org/textcaps", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image descriptions can help visually impaired people to quickly understand\nthe image content. While we made significant progress in automatically\ndescribing images and optical character recognition, current approaches are\nunable to include written text in their descriptions, although text is\nomnipresent in human environments and frequently critical to understand our\nsurroundings. To study how to comprehend text in the context of an image we\ncollect a novel dataset, TextCaps, with 145k captions for 28k images. Our\ndataset challenges a model to recognize text, relate it to its visual context,\nand decide what part of the text to copy or paraphrase, requiring spatial,\nsemantic, and visual reasoning between multiple text tokens and visual\nentities, such as objects. We study baselines and adapt existing approaches to\nthis new task, which we refer to as image captioning with reading\ncomprehension. Our analysis with automatic and human studies shows that our new\nTextCaps dataset provides many new technical challenges over previous datasets.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 02:38:35 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 04:08:02 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Sidorov", "Oleksii", ""], ["Hu", "Ronghang", ""], ["Rohrbach", "Marcus", ""], ["Singh", "Amanpreet", ""]]}, {"id": "2003.12660", "submitter": "Kelechi Ogueji", "authors": "Orevaoghene Ahia and Kelechi Ogueji", "title": "Towards Supervised and Unsupervised Neural Machine Translation Baselines\n  for Nigerian Pidgin", "comments": "Accepted for the AfricaNLP Workshop, ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nigerian Pidgin is arguably the most widely spoken language in Nigeria.\nVariants of this language are also spoken across West and Central Africa,\nmaking it a very important language. This work aims to establish supervised and\nunsupervised neural machine translation (NMT) baselines between English and\nNigerian Pidgin. We implement and compare NMT models with different\ntokenization methods, creating a solid foundation for future works.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 22:40:01 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Ahia", "Orevaoghene", ""], ["Ogueji", "Kelechi", ""]]}, {"id": "2003.12687", "submitter": "Naoyuki Kanda", "authors": "Naoyuki Kanda, Yashesh Gaur, Xiaofei Wang, Zhong Meng, Takuya Yoshioka", "title": "Serialized Output Training for End-to-End Overlapped Speech Recognition", "comments": "Accepted to INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes serialized output training (SOT), a novel framework for\nmulti-speaker overlapped speech recognition based on an attention-based\nencoder-decoder approach. Instead of having multiple output layers as with the\npermutation invariant training (PIT), SOT uses a model with only one output\nlayer that generates the transcriptions of multiple speakers one after another.\nThe attention and decoder modules take care of producing multiple\ntranscriptions from overlapped speech. SOT has two advantages over PIT: (1) no\nlimitation in the maximum number of speakers, and (2) an ability to model the\ndependencies among outputs for different speakers. We also propose a simple\ntrick that allows SOT to be executed in $O(S)$, where $S$ is the number of the\nspeakers in the training sample, by using the start times of the constituent\nsource utterances. Experimental results on LibriSpeech corpus show that the SOT\nmodels can transcribe overlapped speech with variable numbers of speakers\nsignificantly better than PIT-based models. We also show that the SOT models\ncan accurately count the number of speakers in the input audio.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 02:37:09 GMT"}, {"version": "v2", "created": "Sat, 8 Aug 2020 20:08:37 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Kanda", "Naoyuki", ""], ["Gaur", "Yashesh", ""], ["Wang", "Xiaofei", ""], ["Meng", "Zhong", ""], ["Yoshioka", "Takuya", ""]]}, {"id": "2003.12694", "submitter": "Yuchen Lu", "authors": "Yuchen Lu, Soumye Singhal, Florian Strub, Olivier Pietquin, Aaron\n  Courville", "title": "Countering Language Drift with Seeded Iterated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Pretraining on human corpus and then finetuning in a simulator has become a\nstandard pipeline for training a goal-oriented dialogue agent. Nevertheless, as\nsoon as the agents are finetuned to maximize task completion, they suffer from\nthe so-called language drift phenomenon: they slowly lose syntactic and\nsemantic properties of language as they only focus on solving the task. In this\npaper, we propose a generic approach to counter language drift called Seeded\niterated learning (SIL). We periodically refine a pretrained student agent by\nimitating data sampled from a newly generated teacher agent. At each time step,\nthe teacher is created by copying the student agent, before being finetuned to\nmaximize task completion. SIL does not require external syntactic constraint\nnor semantic knowledge, making it a valuable task-agnostic finetuning protocol.\nWe evaluate SIL in a toy-setting Lewis Game, and then scale it up to the\ntranslation game with natural language. In both settings, SIL helps counter\nlanguage drift as well as it improves the task completion compared to\nbaselines.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 03:45:31 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 03:24:46 GMT"}, {"version": "v3", "created": "Mon, 24 Aug 2020 19:26:54 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Lu", "Yuchen", ""], ["Singhal", "Soumye", ""], ["Strub", "Florian", ""], ["Pietquin", "Olivier", ""], ["Courville", "Aaron", ""]]}, {"id": "2003.12710", "submitter": "Yanzhang He", "authors": "Tara N. Sainath, Yanzhang He, Bo Li, Arun Narayanan, Ruoming Pang,\n  Antoine Bruguier, Shuo-yiin Chang, Wei Li, Raziel Alvarez, Zhifeng Chen,\n  Chung-Cheng Chiu, David Garcia, Alex Gruenstein, Ke Hu, Minho Jin, Anjuli\n  Kannan, Qiao Liang, Ian McGraw, Cal Peyser, Rohit Prabhavalkar, Golan Pundak,\n  David Rybach, Yuan Shangguan, Yash Sheth, Trevor Strohman, Mirko Visontai,\n  Yonghui Wu, Yu Zhang, Ding Zhao", "title": "A Streaming On-Device End-to-End Model Surpassing Server-Side\n  Conventional Model Quality and Latency", "comments": "In Proceedings of IEEE ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thus far, end-to-end (E2E) models have not been shown to outperform\nstate-of-the-art conventional models with respect to both quality, i.e., word\nerror rate (WER), and latency, i.e., the time the hypothesis is finalized after\nthe user stops speaking. In this paper, we develop a first-pass Recurrent\nNeural Network Transducer (RNN-T) model and a second-pass Listen, Attend, Spell\n(LAS) rescorer that surpasses a conventional model in both quality and latency.\nOn the quality side, we incorporate a large number of utterances across varied\ndomains to increase acoustic diversity and the vocabulary seen by the model. We\nalso train with accented English speech to make the model more robust to\ndifferent pronunciations. In addition, given the increased amount of training\ndata, we explore a varied learning rate schedule. On the latency front, we\nexplore using the end-of-sentence decision emitted by the RNN-T model to close\nthe microphone, and also introduce various optimizations to improve the speed\nof LAS rescoring. Overall, we find that RNN-T+LAS offers a better WER and\nlatency tradeoff compared to a conventional model. For example, for the same\nlatency, RNN-T+LAS obtains a 8% relative improvement in WER, while being more\nthan 400-times smaller in model size.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 05:00:33 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 21:36:25 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Sainath", "Tara N.", ""], ["He", "Yanzhang", ""], ["Li", "Bo", ""], ["Narayanan", "Arun", ""], ["Pang", "Ruoming", ""], ["Bruguier", "Antoine", ""], ["Chang", "Shuo-yiin", ""], ["Li", "Wei", ""], ["Alvarez", "Raziel", ""], ["Chen", "Zhifeng", ""], ["Chiu", "Chung-Cheng", ""], ["Garcia", "David", ""], ["Gruenstein", "Alex", ""], ["Hu", "Ke", ""], ["Jin", "Minho", ""], ["Kannan", "Anjuli", ""], ["Liang", "Qiao", ""], ["McGraw", "Ian", ""], ["Peyser", "Cal", ""], ["Prabhavalkar", "Rohit", ""], ["Pundak", "Golan", ""], ["Rybach", "David", ""], ["Shangguan", "Yuan", ""], ["Sheth", "Yash", ""], ["Strohman", "Trevor", ""], ["Visontai", "Mirko", ""], ["Wu", "Yonghui", ""], ["Zhang", "Yu", ""], ["Zhao", "Ding", ""]]}, {"id": "2003.12718", "submitter": "Gaole He", "authors": "Gaole He, Junyi Li, Wayne Xin Zhao, Peiju Liu and Ji-Rong Wen", "title": "Mining Implicit Entity Preference from User-Item Interaction Data for\n  Knowledge Graph Completion via Adversarial Learning", "comments": "11 pages, 4 figures, 6 tables. Accepted as WWW 2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of Knowledge Graph Completion (KGC) aims to automatically infer the\nmissing fact information in Knowledge Graph (KG). In this paper, we take a new\nperspective that aims to leverage rich user-item interaction data (user\ninteraction data for short) for improving the KGC task. Our work is inspired by\nthe observation that many KG entities correspond to online items in application\nsystems. However, the two kinds of data sources have very different intrinsic\ncharacteristics, and it is likely to hurt the original performance using simple\nfusion strategy. To address this challenge, we propose a novel adversarial\nlearning approach by leveraging user interaction data for the KGC task. Our\ngenerator is isolated from user interaction data, and serves to improve the\nperformance of the discriminator. The discriminator takes the learned useful\ninformation from user interaction data as input, and gradually enhances the\nevaluation capacity in order to identify the fake samples generated by the\ngenerator. To discover implicit entity preference of users, we design an\nelaborate collaborative learning algorithms based on graph neural networks,\nwhich will be jointly optimized with the discriminator. Such an approach is\neffective to alleviate the issues about data heterogeneity and semantic\ncomplexity for the KGC task. Extensive experiments on three real-world datasets\nhave demonstrated the effectiveness of our approach on the KGC task.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 05:47:33 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 07:29:19 GMT"}, {"version": "v3", "created": "Sun, 26 Apr 2020 07:07:22 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["He", "Gaole", ""], ["Li", "Junyi", ""], ["Zhao", "Wayne Xin", ""], ["Liu", "Peiju", ""], ["Wen", "Ji-Rong", ""]]}, {"id": "2003.12724", "submitter": "Zhenzhong Chen", "authors": "Yaochen Zhu, Jiayi Xie, Zhenzhong Chen", "title": "Predicting the Popularity of Micro-videos with Multimodal Variational\n  Encoder-Decoder Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an emerging type of user-generated content, micro-video drastically\nenriches people's entertainment experiences and social interactions. However,\nthe popularity pattern of an individual micro-video still remains elusive among\nthe researchers. One of the major challenges is that the potential popularity\nof a micro-video tends to fluctuate under the impact of various external\nfactors, which makes it full of uncertainties. In addition, since micro-videos\nare mainly uploaded by individuals that lack professional techniques, multiple\ntypes of noise could exist that obscure useful information. In this paper, we\npropose a multimodal variational encoder-decoder (MMVED) framework for\nmicro-video popularity prediction tasks. MMVED learns a stochastic Gaussian\nembedding of a micro-video that is informative to its popularity level while\npreserves the inherent uncertainties simultaneously. Moreover, through the\noptimization of a deep variational information bottleneck lower-bound (IBLBO),\nthe learned hidden representation is shown to be maximally expressive about the\npopularity target while maximally compressive to the noise in micro-video\nfeatures. Furthermore, the Bayesian product-of-experts principle is applied to\nthe multimodal encoder, where the decision for information keeping or\ndiscarding is made comprehensively with all available modalities. Extensive\nexperiments conducted on a public dataset and a dataset we collect from Xigua\ndemonstrate the effectiveness of the proposed MMVED framework.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 06:08:16 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Zhu", "Yaochen", ""], ["Xie", "Jiayi", ""], ["Chen", "Zhenzhong", ""]]}, {"id": "2003.12738", "submitter": "Zhaojiang Lin", "authors": "Zhaojiang Lin, Genta Indra Winata, Peng Xu, Zihan Liu, Pascale Fung", "title": "Variational Transformers for Diverse Response Generation", "comments": "open domain dialogue", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the great promise of Transformers in many sequence modeling tasks\n(e.g., machine translation), their deterministic nature hinders them from\ngeneralizing to high entropy tasks such as dialogue response generation.\nPrevious work proposes to capture the variability of dialogue responses with a\nrecurrent neural network (RNN)-based conditional variational autoencoder\n(CVAE). However, the autoregressive computation of the RNN limits the training\nefficiency. Therefore, we propose the Variational Transformer (VT), a\nvariational self-attentive feed-forward sequence model. The VT combines the\nparallelizability and global receptive field of the Transformer with the\nvariational nature of the CVAE by incorporating stochastic latent variables\ninto Transformers. We explore two types of the VT: 1) modeling the\ndiscourse-level diversity with a global latent variable; and 2) augmenting the\nTransformer decoder with a sequence of fine-grained latent variables. Then, the\nproposed models are evaluated on three conversational datasets with both\nautomatic metric and human evaluation. The experimental results show that our\nmodels improve standard Transformers and other baselines in terms of diversity,\nsemantic relevance, and human judgment.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 07:48:02 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Lin", "Zhaojiang", ""], ["Winata", "Genta Indra", ""], ["Xu", "Peng", ""], ["Liu", "Zihan", ""], ["Fung", "Pascale", ""]]}, {"id": "2003.12739", "submitter": "Deniz Yuret", "authors": "Ozan Arkan Can, \\.Ilker Kesen, Deniz Yuret", "title": "BiLingUNet: Image Segmentation by Modulating Top-Down and Bottom-Up\n  Visual Processing with Referring Expressions", "comments": "18 pages, 3 figures, submitted to ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present BiLingUNet, a state-of-the-art model for image segmentation using\nreferring expressions. BiLingUNet uses language to customize visual filters and\noutperforms approaches that concatenate a linguistic representation to the\nvisual input. We find that using language to modulate both bottom-up and\ntop-down visual processing works better than just making the top-down\nprocessing language-conditional. We argue that common 1x1 language-conditional\nfilters cannot represent relational concepts and experimentally demonstrate\nthat wider filters work better. Our model achieves state-of-the-art performance\non four referring expression datasets.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 07:54:03 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Can", "Ozan Arkan", ""], ["Kesen", "\u0130lker", ""], ["Yuret", "Deniz", ""]]}, {"id": "2003.12754", "submitter": "Hengzhu Tang", "authors": "Hengzhu Tang, Yanan Cao, Zhenyu Zhang, Jiangxia Cao, Fang Fang, Shi\n  Wang and Pengfei Yin", "title": "HIN: Hierarchical Inference Network for Document-Level Relation\n  Extraction", "comments": "Accepted by PAKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document-level RE requires reading, inferring and aggregating over multiple\nsentences. From our point of view, it is necessary for document-level RE to\ntake advantage of multi-granularity inference information: entity level,\nsentence level and document level. Thus, how to obtain and aggregate the\ninference information with different granularity is challenging for\ndocument-level RE, which has not been considered by previous work. In this\npaper, we propose a Hierarchical Inference Network (HIN) to make full use of\nthe abundant information from entity level, sentence level and document level.\nTranslation constraint and bilinear transformation are applied to target entity\npair in multiple subspaces to get entity-level inference information. Next, we\nmodel the inference between entity-level information and sentence\nrepresentation to achieve sentence-level inference information. Finally, a\nhierarchical aggregation approach is adopted to obtain the document-level\ninference information. In this way, our model can effectively aggregate\ninference information from these three different granularities. Experimental\nresults show that our method achieves state-of-the-art performance on the\nlarge-scale DocRED dataset. We also demonstrate that using BERT representations\ncan further substantially boost the performance.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 09:32:31 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Tang", "Hengzhu", ""], ["Cao", "Yanan", ""], ["Zhang", "Zhenyu", ""], ["Cao", "Jiangxia", ""], ["Fang", "Fang", ""], ["Wang", "Shi", ""], ["Yin", "Pengfei", ""]]}, {"id": "2003.12799", "submitter": "Herman Kamper", "authors": "Petri-Johan Last, Herman A. Engelbrecht, Herman Kamper", "title": "Unsupervised feature learning for speech using correspondence and\n  Siamese networks", "comments": "5 pages, 3 figures, 2 tables; accepted to the IEEE Signal Processing\n  Letters, (c) 2020 IEEE", "journal-ref": "IEEE Signal Processing Letters 27 (2020) 421-425", "doi": "10.1109/LSP.2020.2973798", "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In zero-resource settings where transcribed speech audio is unavailable,\nunsupervised feature learning is essential for downstream speech processing\ntasks. Here we compare two recent methods for frame-level acoustic feature\nlearning. For both methods, unsupervised term discovery is used to find pairs\nof word examples of the same unknown type. Dynamic programming is then used to\nalign the feature frames between each word pair, serving as weak top-down\nsupervision for the two models. For the correspondence autoencoder (CAE),\nmatching frames are presented as input-output pairs. The Triamese network uses\na contrastive loss to reduce the distance between frames of the same predicted\nword type while increasing the distance between negative examples. For the\nfirst time, these feature extractors are compared on the same discrimination\ntasks using the same weak supervision pairs. We find that, on the two datasets\nconsidered here, the CAE outperforms the Triamese network. However, we show\nthat a new hybrid correspondence-Triamese approach (CTriamese), consistently\noutperforms both the CAE and Triamese models in terms of average precision and\nABX error rates on both English and Xitsonga evaluation data.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 14:31:01 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Last", "Petri-Johan", ""], ["Engelbrecht", "Herman A.", ""], ["Kamper", "Herman", ""]]}, {"id": "2003.12900", "submitter": "Georg Rehm", "authors": "Juli\\'an Moreno-Schneider and Georg Rehm and Elena Montiel-Ponsoda and\n  V\\'ictor Rodriguez-Doncel and Artem Revenko and Sotirios Karampatakis and\n  Maria Khvalchik and Christian Sageder and Jorge Gracia and Filippo Maganza", "title": "Orchestrating NLP Services for the Legal Domain", "comments": "Proceedings of the 12th Language Resources and Evaluation Conference\n  (LREC 2020). To appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Legal technology is currently receiving a lot of attention from various\nangles. In this contribution we describe the main technical components of a\nsystem that is currently under development in the European innovation project\nLynx, which includes partners from industry and research. The key contribution\nof this paper is a workflow manager that enables the flexible orchestration of\nworkflows based on a portfolio of Natural Language Processing and Content\nCuration services as well as a Multilingual Legal Knowledge Graph that contains\nsemantic information and meaningful references to legal documents. We also\ndescribe different use cases with which we experiment and develop prototypical\nsolutions.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 22:10:48 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Moreno-Schneider", "Juli\u00e1n", ""], ["Rehm", "Georg", ""], ["Montiel-Ponsoda", "Elena", ""], ["Rodriguez-Doncel", "V\u00edctor", ""], ["Revenko", "Artem", ""], ["Karampatakis", "Sotirios", ""], ["Khvalchik", "Maria", ""], ["Sageder", "Christian", ""], ["Gracia", "Jorge", ""], ["Maganza", "Filippo", ""]]}, {"id": "2003.12932", "submitter": "Anuj Gupta", "authors": "Ankit Kumar, Piyush Makhija, Anuj Gupta", "title": "Noisy Text Data: Achilles' Heel of BERT", "comments": "7 pages, 2 tables, 1 plot", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Owing to the phenomenal success of BERT on various NLP tasks and benchmark\ndatasets, industry practitioners are actively experimenting with fine-tuning\nBERT to build NLP applications for solving industry use cases. For most\ndatasets that are used by practitioners to build industrial NLP applications,\nit is hard to guarantee absence of any noise in the data. While BERT has\nperformed exceedingly well for transferring the learnings from one use case to\nanother, it remains unclear how BERT performs when fine-tuned on noisy text. In\nthis work, we explore the sensitivity of BERT to noise in the data. We work\nwith most commonly occurring noise (spelling mistakes, typos) and show that\nthis results in significant degradation in the performance of BERT. We present\nexperimental results to show that BERT's performance on fundamental NLP tasks\nlike sentiment analysis and textual similarity drops significantly in the\npresence of (simulated) noise on benchmark datasets viz. IMDB Movie Review,\nSTS-B, SST-2. Further, we identify shortcomings in the existing BERT pipeline\nthat are responsible for this drop in performance. Our findings suggest that\npractitioners need to be vary of presence of noise in their datasets while\nfine-tuning BERT to solve industry use cases.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 02:49:11 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 05:50:31 GMT"}, {"version": "v3", "created": "Sun, 18 Oct 2020 09:22:01 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Kumar", "Ankit", ""], ["Makhija", "Piyush", ""], ["Gupta", "Anuj", ""]]}, {"id": "2003.12961", "submitter": "Dilip Singh Sisodia", "authors": "Abinash Pujahari and Dilip Singh Sisodia", "title": "Clickbait Detection using Multiple Categorization Techniques", "comments": "11 pages, 7 figures, 4 tables to be published in Journal of\n  Information Science", "journal-ref": "2019", "doi": "10.1177/0165551519871822", "report-no": null, "categories": "cs.SI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clickbaits are online articles with deliberately designed misleading titles\nfor luring more and more readers to open the intended web page. Clickbaits are\nused to tempted visitors to click on a particular link either to monetize the\nlanding page or to spread the false news for sensationalization. The presence\nof clickbaits on any news aggregator portal may lead to unpleasant experience\nto readers. Automatic detection of clickbait headlines from news headlines has\nbeen a challenging issue for the machine learning community. A lot of methods\nhave been proposed for preventing clickbait articles in recent past. However,\nthe recent techniques available in detecting clickbaits are not much robust.\nThis paper proposes a hybrid categorization technique for separating clickbait\nand non-clickbait articles by integrating different features, sentence\nstructure, and clustering. During preliminary categorization, the headlines are\nseparated using eleven features. After that, the headlines are recategorized\nusing sentence formality, syntactic similarity measures. In the last phase, the\nheadlines are again recategorized by applying clustering using word vector\nsimilarity based on t-Stochastic Neighbourhood Embedding (t-SNE) approach.\nAfter categorization of these headlines, machine learning models are applied to\nthe data set to evaluate machine learning algorithms. The obtained experimental\nresults indicate the proposed hybrid model is more robust, reliable and\nefficient than any individual categorization techniques for the real-world\ndataset we used.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 07:16:41 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Pujahari", "Abinash", ""], ["Sisodia", "Dilip Singh", ""]]}, {"id": "2003.13003", "submitter": "Chengyu Wang", "authors": "Chengyu Wang, Minghui Qiu, Jun Huang, Xiaofeng He", "title": "Meta Fine-Tuning Neural Language Models for Multi-Domain Text Mining", "comments": "accepted by emnlp 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained neural language models bring significant improvement for various\nNLP tasks, by fine-tuning the models on task-specific training sets. During\nfine-tuning, the parameters are initialized from pre-trained models directly,\nwhich ignores how the learning process of similar NLP tasks in different\ndomains is correlated and mutually reinforced. In this paper, we propose an\neffective learning procedure named Meta Fine-Tuning (MFT), served as a\nmeta-learner to solve a group of similar NLP tasks for neural language models.\nInstead of simply multi-task training over all the datasets, MFT only learns\nfrom typical instances of various domains to acquire highly transferable\nknowledge. It further encourages the language model to encode domain-invariant\nrepresentations by optimizing a series of novel domain corruption loss\nfunctions. After MFT, the model can be fine-tuned for each domain with better\nparameter initializations and higher generalization ability. We implement MFT\nupon BERT to solve several multi-domain text mining tasks. Experimental results\nconfirm the effectiveness of MFT and its usefulness for few-shot learning.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 11:27:10 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 15:00:14 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Wang", "Chengyu", ""], ["Qiu", "Minghui", ""], ["Huang", "Jun", ""], ["He", "Xiaofeng", ""]]}, {"id": "2003.13016", "submitter": "Georg Rehm", "authors": "Elena Leitner and Georg Rehm and Juli\\'an Moreno-Schneider", "title": "A Dataset of German Legal Documents for Named Entity Recognition", "comments": "Proceedings of the 12th Language Resources and Evaluation Conference\n  (LREC 2020). To appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a dataset developed for Named Entity Recognition in German\nfederal court decisions. It consists of approx. 67,000 sentences with over 2\nmillion tokens. The resource contains 54,000 manually annotated entities,\nmapped to 19 fine-grained semantic classes: person, judge, lawyer, country,\ncity, street, landscape, organization, company, institution, court, brand, law,\nordinance, European legal norm, regulation, contract, court decision, and legal\nliterature. The legal documents were, furthermore, automatically annotated with\nmore than 35,000 TimeML-based time expressions. The dataset, which is available\nunder a CC-BY 4.0 license in the CoNNL-2002 format, was developed for training\nan NER service for German legal documents in the EU project Lynx.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 13:20:43 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Leitner", "Elena", ""], ["Rehm", "Georg", ""], ["Moreno-Schneider", "Juli\u00e1n", ""]]}, {"id": "2003.13027", "submitter": "Georg Rehm", "authors": "Dmitrii Aksenov and Juli\\'an Moreno-Schneider and Peter Bourgonje and\n  Robert Schwarzenberg and Leonhard Hennig and Georg Rehm", "title": "Abstractive Text Summarization based on Language Model Conditioning and\n  Locality Modeling", "comments": "Proceedings of the 12th Language Resources and Evaluation Conference\n  (LREC 2020). To appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore to what extent knowledge about the pre-trained language model that\nis used is beneficial for the task of abstractive summarization. To this end,\nwe experiment with conditioning the encoder and decoder of a Transformer-based\nneural model on the BERT language model. In addition, we propose a new method\nof BERT-windowing, which allows chunk-wise processing of texts longer than the\nBERT window size. We also explore how locality modelling, i.e., the explicit\nrestriction of calculations to the local context, can affect the summarization\nability of the Transformer. This is done by introducing 2-dimensional\nconvolutional self-attention into the first layers of the encoder. The results\nof our models are compared to a baseline and the state-of-the-art models on the\nCNN/Daily Mail dataset. We additionally train our model on the SwissText\ndataset to demonstrate usability on German. Both models outperform the baseline\nin ROUGE scores on two datasets and show its superiority in a manual\nqualitative analysis.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 14:00:17 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Aksenov", "Dmitrii", ""], ["Moreno-Schneider", "Juli\u00e1n", ""], ["Bourgonje", "Peter", ""], ["Schwarzenberg", "Robert", ""], ["Hennig", "Leonhard", ""], ["Rehm", "Georg", ""]]}, {"id": "2003.13028", "submitter": "Itsumi Saito", "authors": "Itsumi Saito, Kyosuke Nishida, Kosuke Nishida, Junji Tomita", "title": "Abstractive Summarization with Combination of Pre-trained\n  Sequence-to-Sequence and Saliency Models", "comments": "Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained sequence-to-sequence (seq-to-seq) models have significantly\nimproved the accuracy of several language generation tasks, including\nabstractive summarization. Although the fluency of abstractive summarization\nhas been greatly improved by fine-tuning these models, it is not clear whether\nthey can also identify the important parts of the source text to be included in\nthe summary. In this study, we investigated the effectiveness of combining\nsaliency models that identify the important parts of the source text with the\npre-trained seq-to-seq models through extensive experiments. We also proposed a\nnew combination model consisting of a saliency model that extracts a token\nsequence from a source text and a seq-to-seq model that takes the sequence as\nan additional input text. Experimental results showed that most of the\ncombination models outperformed a simple fine-tuned seq-to-seq model on both\nthe CNN/DM and XSum datasets even if the seq-to-seq model is pre-trained on\nlarge-scale corpora. Moreover, for the CNN/DM dataset, the proposed combination\nmodel exceeded the previous best-performed model by 1.33 points on ROUGE-L.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 14:00:25 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Saito", "Itsumi", ""], ["Nishida", "Kyosuke", ""], ["Nishida", "Kosuke", ""], ["Tomita", "Junji", ""]]}, {"id": "2003.13032", "submitter": "Georg Rehm", "authors": "Sarah Schulz and Jurica \\v{S}eva and Samuel Rodriguez and Malte\n  Ostendorff and Georg Rehm", "title": "Named Entities in Medical Case Reports: Corpus and Experiments", "comments": "Proceedings of the 12th Language Resources and Evaluation Conference\n  (LREC 2020). To appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new corpus comprising annotations of medical entities in case\nreports, originating from PubMed Central's open access library. In the case\nreports, we annotate cases, conditions, findings, factors and negation\nmodifiers. Moreover, where applicable, we annotate relations between these\nentities. As such, this is the first corpus of this kind made available to the\nscientific community in English. It enables the initial investigation of\nautomatic information extraction from case reports through tasks like Named\nEntity Recognition, Relation Extraction and (sentence/paragraph) relevance\ndetection. Additionally, we present four strong baseline systems for the\ndetection of medical entities made available through the annotated dataset.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 14:08:43 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Schulz", "Sarah", ""], ["\u0160eva", "Jurica", ""], ["Rodriguez", "Samuel", ""], ["Ostendorff", "Malte", ""], ["Rehm", "Georg", ""]]}, {"id": "2003.13074", "submitter": "Shafie Gholizadeh", "authors": "Shafie Gholizadeh, Armin Seyeditabari and Wlodek Zadrozny", "title": "A Novel Method of Extracting Topological Features from Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, topological data analysis has been utilized for a wide range\nof problems to deal with high dimensional noisy data. While text\nrepresentations are often high dimensional and noisy, there are only a few work\non the application of topological data analysis in natural language processing.\nIn this paper, we introduce a novel algorithm to extract topological features\nfrom word embedding representation of text that can be used for text\nclassification. Working on word embeddings, topological data analysis can\ninterpret the embedding high-dimensional space and discover the relations among\ndifferent embedding dimensions. We will use persistent homology, the most\ncommonly tool from topological data analysis, for our experiment. Examining our\ntopological algorithm on long textual documents, we will show our defined\ntopological features may outperform conventional text mining features.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 16:55:23 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 21:56:57 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Gholizadeh", "Shafie", ""], ["Seyeditabari", "Armin", ""], ["Zadrozny", "Wlodek", ""]]}, {"id": "2003.13118", "submitter": "Alireza Mohammadshahi", "authors": "Alireza Mohammadshahi, James Henderson", "title": "Recursive Non-Autoregressive Graph-to-Graph Transformer for Dependency\n  Parsing with Iterative Refinement", "comments": "Accepted to Transactions of the Association for Computational\n  Linguistics (TACL) journal", "journal-ref": null, "doi": "10.1162/tacl_a_00358", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Recursive Non-autoregressive Graph-to-Graph Transformer\narchitecture (RNGTr) for the iterative refinement of arbitrary graphs through\nthe recursive application of a non-autoregressive Graph-to-Graph Transformer\nand apply it to syntactic dependency parsing. We demonstrate the power and\neffectiveness of RNGTr on several dependency corpora, using a refinement model\npre-trained with BERT. We also introduce Syntactic Transformer (SynTr), a\nnon-recursive parser similar to our refinement model. RNGTr can improve the\naccuracy of a variety of initial parsers on 13 languages from the Universal\nDependencies Treebanks, English and Chinese Penn Treebanks, and the German\nCoNLL2009 corpus, even improving over the new state-of-the-art results achieved\nby SynTr, significantly improving the state-of-the-art for all corpora tested.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 19:25:32 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 17:05:10 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Mohammadshahi", "Alireza", ""], ["Henderson", "James", ""]]}, {"id": "2003.13198", "submitter": "An Yang", "authors": "Junyang Lin, An Yang, Yichang Zhang, Jie Liu, Jingren Zhou, Hongxia\n  Yang", "title": "InterBERT: Vision-and-Language Interaction for Multi-modal Pretraining", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-modal pretraining for learning high-level multi-modal representation is\na further step towards deep learning and artificial intelligence. In this work,\nwe propose a novel model, namely InterBERT (BERT for Interaction), which is the\nfirst model of our series of multimodal pretraining methods M6\n(MultiModality-to-MultiModality Multitask Mega-transformer). The model owns\nstrong capability of modeling interaction between the information flows of\ndifferent modalities. The single-stream interaction module is capable of\neffectively processing information of multiple modalilties, and the two-stream\nmodule on top preserves the independence of each modality to avoid performance\ndowngrade in single-modal tasks. We pretrain the model with three pretraining\ntasks, including masked segment modeling (MSM), masked region modeling (MRM)\nand image-text matching (ITM); and finetune the model on a series of\nvision-and-language downstream tasks. Experimental results demonstrate that\nInterBERT outperforms a series of strong baselines, including the most recent\nmulti-modal pretraining methods, and the analysis shows that MSM and MRM are\neffective for pretraining and our method can achieve performances comparable to\nBERT in single-modal tasks. Besides, we propose a large-scale dataset for\nmulti-modal pretraining in Chinese, and we develop the Chinese InterBERT which\nis the first Chinese multi-modal pretrained model. We pretrain the Chinese\nInterBERT on our proposed dataset of 3.1M image-text pairs from the mobile\nTaobao, the largest Chinese e-commerce platform. We finetune the model for\ntext-based image retrieval, and recently we deployed the model online for\ntopic-based recommendation.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 03:13:22 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 02:14:00 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2021 16:19:34 GMT"}, {"version": "v4", "created": "Thu, 22 Apr 2021 11:20:26 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Lin", "Junyang", ""], ["Yang", "An", ""], ["Zhang", "Yichang", ""], ["Liu", "Jie", ""], ["Zhou", "Jingren", ""], ["Yang", "Hongxia", ""]]}, {"id": "2003.13205", "submitter": "Pei Zhang", "authors": "Pei Zhang, Xu Zhang, Wei Chen, Jian Yu, Yanfeng Wang, Deyi Xiong", "title": "Learning Contextualized Sentence Representations for Document-Level\n  Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document-level machine translation incorporates inter-sentential dependencies\ninto the translation of a source sentence. In this paper, we propose a new\nframework to model cross-sentence dependencies by training neural machine\ntranslation (NMT) to predict both the target translation and surrounding\nsentences of a source sentence. By enforcing the NMT model to predict source\ncontext, we want the model to learn \"contextualized\" source sentence\nrepresentations that capture document-level dependencies on the source side. We\nfurther propose two different methods to learn and integrate such\ncontextualized sentence embeddings into NMT: a joint training method that\njointly trains an NMT model with the source context prediction model and a\npre-training & fine-tuning method that pretrains the source context prediction\nmodel on a large-scale monolingual document corpus and then fine-tunes it with\nthe NMT model. Experiments on Chinese-English and English-German translation\nshow that both methods can substantially improve the translation quality over a\nstrong document-level Transformer baseline.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 03:38:01 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Zhang", "Pei", ""], ["Zhang", "Xu", ""], ["Chen", "Wei", ""], ["Yu", "Jian", ""], ["Wang", "Yanfeng", ""], ["Xiong", "Deyi", ""]]}, {"id": "2003.13230", "submitter": "Xusheng Luo", "authors": "Xusheng Luo, Luxin Liu, Yonghua Yang, Le Bo, Yuanpeng Cao, Jinhang Wu,\n  Qiang Li, Keping Yang and Kenny Q. Zhu", "title": "AliCoCo: Alibaba E-commerce Cognitive Concept Net", "comments": "15 pages. Accepted by SIGMOD 2020 Industry Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the ultimate goals of e-commerce platforms is to satisfy various\nshopping needs for their customers. Much efforts are devoted to creating\ntaxonomies or ontologies in e-commerce towards this goal. However, user needs\nin e-commerce are still not well defined, and none of the existing ontologies\nhas the enough depth and breadth for universal user needs understanding. The\nsemantic gap in-between prevents shopping experience from being more\nintelligent. In this paper, we propose to construct a large-scale e-commerce\ncognitive concept net named \"AliCoCo\", which is practiced in Alibaba, the\nlargest Chinese e-commerce platform in the world. We formally define user needs\nin e-commerce, then conceptualize them as nodes in the net. We present details\non how AliCoCo is constructed semi-automatically and its successful, ongoing\nand potential applications in e-commerce.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 05:42:03 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Luo", "Xusheng", ""], ["Liu", "Luxin", ""], ["Yang", "Yonghua", ""], ["Bo", "Le", ""], ["Cao", "Yuanpeng", ""], ["Wu", "Jinhang", ""], ["Li", "Qiang", ""], ["Yang", "Keping", ""], ["Zhu", "Kenny Q.", ""]]}, {"id": "2003.13236", "submitter": "Georg Rehm", "authors": "Penny Labropoulou and Katerina Gkirtzou and Maria Gavriilidou and\n  Miltos Deligiannis and Dimitrios Galanis and Stelios Piperidis and Georg Rehm\n  and Maria Berger and Val\\'erie Mapelli and Micka\\\"el Rigault and Victoria\n  Arranz and Khalid Choukri and Gerhard Backfried and Jos\\'e Manuel G\\'omez\n  P\\'erez and Andres Garcia Silva", "title": "Making Metadata Fit for Next Generation Language Technology Platforms:\n  The Metadata Schema of the European Language Grid", "comments": "Proceedings of the 12th Language Resources and Evaluation Conference\n  (LREC 2020). To appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current scientific and technological landscape is characterised by the\nincreasing availability of data resources and processing tools and services. In\nthis setting, metadata have emerged as a key factor facilitating management,\nsharing and usage of such digital assets. In this paper we present ELG-SHARE, a\nrich metadata schema catering for the description of Language Resources and\nTechnologies (processing and generation services and tools, models, corpora,\nterm lists, etc.), as well as related entities (e.g., organizations, projects,\nsupporting documents, etc.). The schema powers the European Language Grid\nplatform that aims to be the primary hub and marketplace for industry-relevant\nLanguage Technology in Europe. ELG-SHARE has been based on various metadata\nschemas, vocabularies, and ontologies, as well as related recommendations and\nguidelines.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 06:46:35 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Labropoulou", "Penny", ""], ["Gkirtzou", "Katerina", ""], ["Gavriilidou", "Maria", ""], ["Deligiannis", "Miltos", ""], ["Galanis", "Dimitrios", ""], ["Piperidis", "Stelios", ""], ["Rehm", "Georg", ""], ["Berger", "Maria", ""], ["Mapelli", "Val\u00e9rie", ""], ["Rigault", "Micka\u00ebl", ""], ["Arranz", "Victoria", ""], ["Choukri", "Khalid", ""], ["Backfried", "Gerhard", ""], ["P\u00e9rez", "Jos\u00e9 Manuel G\u00f3mez", ""], ["Silva", "Andres Garcia", ""]]}, {"id": "2003.13316", "submitter": "Bennett Kleinberg", "authors": "Bennett Kleinberg and Bruno Verschuere", "title": "How human judgment impairs automated deception detection performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background: Deception detection is a prevalent problem for security\npractitioners. With a need for more large-scale approaches, automated methods\nusing machine learning have gained traction. However, detection performance\nstill implies considerable error rates. Findings from other domains suggest\nthat hybrid human-machine integrations could offer a viable path in deception\ndetection tasks. Method: We collected a corpus of truthful and deceptive\nanswers about participants' autobiographical intentions (n=1640) and tested\nwhether a combination of supervised machine learning and human judgment could\nimprove deception detection accuracy. Human judges were presented with the\noutcome of the automated credibility judgment of truthful and deceptive\nstatements. They could either fully overrule it (hybrid-overrule condition) or\nadjust it within a given boundary (hybrid-adjust condition). Results: The data\nsuggest that in neither of the hybrid conditions did the human judgment add a\nmeaningful contribution. Machine learning in isolation identified truth-tellers\nand liars with an overall accuracy of 69%. Human involvement through\nhybrid-overrule decisions brought the accuracy back to the chance level. The\nhybrid-adjust condition did not deception detection performance. The\ndecision-making strategies of humans suggest that the truth bias - the tendency\nto assume the other is telling the truth - could explain the detrimental\neffect. Conclusion: The current study does not support the notion that humans\ncan meaningfully add to the deception detection performance of a machine\nlearning system.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 10:06:36 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Kleinberg", "Bennett", ""], ["Verschuere", "Bruno", ""]]}, {"id": "2003.13325", "submitter": "Marcely Zanon Boito", "authors": "Marcely Zanon Boito, Aline Villavicencio, Laurent Besacier", "title": "Investigating Language Impact in Bilingual Approaches for Computational\n  Language Documentation", "comments": "Accepted to 1st Joint SLTU and CCURL Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For endangered languages, data collection campaigns have to accommodate the\nchallenge that many of them are from oral tradition, and producing\ntranscriptions is costly. Therefore, it is fundamental to translate them into a\nwidely spoken language to ensure interpretability of the recordings. In this\npaper we investigate how the choice of translation language affects the\nposterior documentation work and potential automatic approaches which will work\non top of the produced bilingual corpus. For answering this question, we use\nthe MaSS multilingual speech corpus (Boito et al., 2020) for creating 56\nbilingual pairs that we apply to the task of low-resource unsupervised word\nsegmentation and alignment. Our results highlight that the choice of language\nfor translation influences the word segmentation performance, and that\ndifferent lexicons are learned by using different aligned translations. Lastly,\nthis paper proposes a hybrid approach for bilingual word segmentation,\ncombining boundary clues extracted from a non-parametric Bayesian model\n(Goldwater et al., 2009a) with the attentional word segmentation neural model\nfrom Godard et al. (2018). Our results suggest that incorporating these clues\ninto the neural models' input representation increases their translation and\nalignment quality, specially for challenging language pairs.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 10:30:34 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Boito", "Marcely Zanon", ""], ["Villavicencio", "Aline", ""], ["Besacier", "Laurent", ""]]}, {"id": "2003.13342", "submitter": "Fabian Galetzka", "authors": "Fabian Galetzka, Chukwuemeka U. Eneh, David Schlangen", "title": "A Corpus of Controlled Opinionated and Knowledgeable Movie Discussions\n  for Training Neural Conversation Models", "comments": "8 Pages, 8 Figures, 5 Tables. Accepted paper for LREC 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Fully data driven Chatbots for non-goal oriented dialogues are known to\nsuffer from inconsistent behaviour across their turns, stemming from a general\ndifficulty in controlling parameters like their assumed background personality\nand knowledge of facts. One reason for this is the relative lack of labeled\ndata from which personality consistency and fact usage could be learned\ntogether with dialogue behaviour. To address this, we introduce a new labeled\ndialogue dataset in the domain of movie discussions, where every dialogue is\nbased on pre-specified facts and opinions. We thoroughly validate the collected\ndialogue for adherence of the participants to their given fact and opinion\nprofile, and find that the general quality in this respect is high. This\nprocess also gives us an additional layer of annotation that is potentially\nuseful for training models. We introduce as a baseline an end-to-end trained\nself-attention decoder model trained on this data and show that it is able to\ngenerate opinionated responses that are judged to be natural and knowledgeable\nand show attentiveness.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 11:17:31 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Galetzka", "Fabian", ""], ["Eneh", "Chukwuemeka U.", ""], ["Schlangen", "David", ""]]}, {"id": "2003.13352", "submitter": "Juan Quiroz", "authors": "Juan C Quiroz, Liliana Laranjo, Catalin Tufanaru, Ahmet Baki\n  Kocaballi, Dana Rezazadegan, Shlomo Berkovsky, Enrico Coiera", "title": "Empirical Analysis of Zipf's Law, Power Law, and Lognormal Distributions\n  in Medical Discharge Reports", "comments": "Reduced word count to 3000, moved methods details to appendices", "journal-ref": "International Journal of Medical Informatics (2020), 104324", "doi": "10.1016/j.ijmedinf.2020.104324", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian modelling and statistical text analysis rely on informed probability\npriors to encourage good solutions. This paper empirically analyses whether\ntext in medical discharge reports follow Zipf's law, a commonly assumed\nstatistical property of language where word frequency follows a discrete power\nlaw distribution. We examined 20,000 medical discharge reports from the\nMIMIC-III dataset. Methods included splitting the discharge reports into\ntokens, counting token frequency, fitting power law distributions to the data,\nand testing whether alternative distributions--lognormal, exponential,\nstretched exponential, and truncated power law--provided superior fits to the\ndata. Results show that discharge reports are best fit by the truncated power\nlaw and lognormal distributions. Our findings suggest that Bayesian modelling\nand statistical text analysis of discharge report text would benefit from using\ntruncated power law and lognormal probability priors.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 11:34:53 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 02:02:06 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 01:35:40 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Quiroz", "Juan C", ""], ["Laranjo", "Liliana", ""], ["Tufanaru", "Catalin", ""], ["Kocaballi", "Ahmet Baki", ""], ["Rezazadegan", "Dana", ""], ["Berkovsky", "Shlomo", ""], ["Coiera", "Enrico", ""]]}, {"id": "2003.13414", "submitter": "Michael Filletti", "authors": "Michael Filletti and Aaron Grech", "title": "Using News Articles and Financial Data to predict the likelihood of\n  bankruptcy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade, millions of companies have filed for bankruptcy. This\nhas been caused by a plethora of reasons, namely, high interest rates, heavy\ndebts and government regulations. The effect of a company going bankrupt can be\ndevastating, hurting not only workers and shareholders, but also clients,\nsuppliers and any related external companies. One of the aims of this paper is\nto provide a framework for company bankruptcy to be predicted by making use of\nfinancial figures, provided by our external dataset, in conjunction with the\nsentiment of news articles about certain sectors. News articles are used to\nattempt to quantify the sentiment on a company and its sector from an external\nperspective, rather than simply using internal figures. This work builds on\nprevious studies carried out by multiple researchers, to bring us closer to\nlessening the impact of such events.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 17:29:41 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Filletti", "Michael", ""], ["Grech", "Aaron", ""]]}, {"id": "2003.13519", "submitter": "Bell Raj Eapen", "authors": "Bell Raj Eapen, Norm Archer and Kamran Sartipi", "title": "QRMine: A python package for triangulation in Grounded Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grounded theory (GT) is a qualitative research method for building theory\ngrounded in data. GT uses textual and numeric data and follows various stages\nof coding or tagging data for sense-making, such as open coding and selective\ncoding. Machine Learning (ML) techniques, including natural language processing\n(NLP), can assist the researchers in the coding process. Triangulation is the\nprocess of combining various types of data. ML can facilitate deriving insights\nfrom numerical data for corroborating findings from the textual interview\ntranscripts. We present an open-source python package (QRMine) that\nencapsulates various ML and NLP libraries to support coding and triangulation\nin GT. QRMine enables researchers to use these methods on their data with\nminimal effort. Researchers can install QRMine from the python package index\n(PyPI) and can contribute to its development. We believe that the concept of\ncomputational triangulation will make GT relevant in the realm of big data.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 14:45:51 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Eapen", "Bell Raj", ""], ["Archer", "Norm", ""], ["Sartipi", "Kamran", ""]]}, {"id": "2003.13551", "submitter": "Georg Rehm", "authors": "Georg Rehm and Maria Berger and Ela Elsholz and Stefanie Hegele and\n  Florian Kintzel and Katrin Marheinecke and Stelios Piperidis and Miltos\n  Deligiannis and Dimitris Galanis and Katerina Gkirtzou and Penny Labropoulou\n  and Kalina Bontcheva and David Jones and Ian Roberts and Jan Hajic and Jana\n  Hamrlov\\'a and Luk\\'a\\v{s} Ka\\v{c}ena and Khalid Choukri and Victoria Arranz\n  and Andrejs Vasi\\c{l}jevs and Orians Anvari and Andis Lagzdi\\c{n}\\v{s} and\n  J\\=ulija Me\\c{l}\\c{n}ika and Gerhard Backfried and Erin\\c{c} Dikici and\n  Miroslav Janosik and Katja Prinz and Christoph Prinz and Severin Stampler and\n  Dorothea Thomas-Aniola and Jos\\'e Manuel G\\'omez P\\'erez and Andres Garcia\n  Silva and Christian Berr\\'io and Ulrich Germann and Steve Renals and Ondrej\n  Klejch", "title": "European Language Grid: An Overview", "comments": "Proceedings of the 12th Language Resources and Evaluation Conference\n  (LREC 2020). To appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With 24 official EU and many additional languages, multilingualism in Europe\nand an inclusive Digital Single Market can only be enabled through Language\nTechnologies (LTs). European LT business is dominated by hundreds of SMEs and a\nfew large players. Many are world-class, with technologies that outperform the\nglobal players. However, European LT business is also fragmented, by nation\nstates, languages, verticals and sectors, significantly holding back its\nimpact. The European Language Grid (ELG) project addresses this fragmentation\nby establishing the ELG as the primary platform for LT in Europe. The ELG is a\nscalable cloud platform, providing, in an easy-to-integrate way, access to\nhundreds of commercial and non-commercial LTs for all European languages,\nincluding running tools and services as well as data sets and resources. Once\nfully operational, it will enable the commercial and non-commercial European LT\ncommunity to deposit and upload their technologies and data sets into the ELG,\nto deploy them through the grid, and to connect with other resources. The ELG\nwill boost the Multilingual Digital Single Market towards a thriving European\nLT community, creating new jobs and opportunities. Furthermore, the ELG project\norganises two open calls for up to 20 pilot projects. It also sets up 32\nNational Competence Centres (NCCs) and the European LT Council (LTC) for\noutreach and coordination purposes.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 15:25:34 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Rehm", "Georg", ""], ["Berger", "Maria", ""], ["Elsholz", "Ela", ""], ["Hegele", "Stefanie", ""], ["Kintzel", "Florian", ""], ["Marheinecke", "Katrin", ""], ["Piperidis", "Stelios", ""], ["Deligiannis", "Miltos", ""], ["Galanis", "Dimitris", ""], ["Gkirtzou", "Katerina", ""], ["Labropoulou", "Penny", ""], ["Bontcheva", "Kalina", ""], ["Jones", "David", ""], ["Roberts", "Ian", ""], ["Hajic", "Jan", ""], ["Hamrlov\u00e1", "Jana", ""], ["Ka\u010dena", "Luk\u00e1\u0161", ""], ["Choukri", "Khalid", ""], ["Arranz", "Victoria", ""], ["Vasi\u013cjevs", "Andrejs", ""], ["Anvari", "Orians", ""], ["Lagzdi\u0146\u0161", "Andis", ""], ["Me\u013c\u0146ika", "J\u016blija", ""], ["Backfried", "Gerhard", ""], ["Dikici", "Erin\u00e7", ""], ["Janosik", "Miroslav", ""], ["Prinz", "Katja", ""], ["Prinz", "Christoph", ""], ["Stampler", "Severin", ""], ["Thomas-Aniola", "Dorothea", ""], ["P\u00e9rez", "Jos\u00e9 Manuel G\u00f3mez", ""], ["Silva", "Andres Garcia", ""], ["Berr\u00edo", "Christian", ""], ["Germann", "Ulrich", ""], ["Renals", "Steve", ""], ["Klejch", "Ondrej", ""]]}, {"id": "2003.13600", "submitter": "Luca Celotti", "authors": "Luca Celotti, Simon Brodeur, Jean Rouat", "title": "AriEL: volume coding for sentence generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mapping sequences of discrete data to a point in a continuous space makes it\ndifficult to retrieve those sequences via random sampling. Mapping the input to\na volume would make it easier to retrieve at test time, and that's the strategy\nfollowed by the family of approaches based on Variational Autoencoder. However\nthe fact that they are at the same time optimizing for prediction and for\nsmoothness of representation, forces them to trade-off between the two. We\nimprove on the performance of some of the standard methods in deep learning to\ngenerate sentences by uniformly sampling a continuous space. We do it by\nproposing AriEL, that constructs volumes in a continuous space, without the\nneed of encouraging the creation of volumes through the loss function. We first\nbenchmark on a toy grammar, that allows to automatically evaluate the language\nlearned and generated by the models. Then, we benchmark on a real dataset of\nhuman dialogues. Our results indicate that the random access to the stored\ninformation is dramatically improved, and our method AriEL is able to generate\na wider variety of correct language by randomly sampling the latent space. VAE\nfollows in performance for the toy dataset while, AE and Transformer follow for\nthe real dataset. This partially supports to the hypothesis that encoding\ninformation into volumes instead of into points, can lead to improved retrieval\nof learned information with random sampling. This can lead to better generators\nand we also discuss potential disadvantages.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 16:30:47 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 14:06:11 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Celotti", "Luca", ""], ["Brodeur", "Simon", ""], ["Rouat", "Jean", ""]]}, {"id": "2003.13624", "submitter": "Jeffrey Dalton", "authors": "Jeffrey Dalton, Chenyan Xiong, Jamie Callan", "title": "TREC CAsT 2019: The Conversational Assistance Track Overview", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Conversational Assistance Track (CAsT) is a new track for TREC 2019 to\nfacilitate Conversational Information Seeking (CIS) research and to create a\nlarge-scale reusable test collection for conversational search systems. The\ndocument corpus is 38,426,252 passages from the TREC Complex Answer Retrieval\n(CAR) and Microsoft MAchine Reading COmprehension (MARCO) datasets. Eighty\ninformation seeking dialogues (30 train, 50 test) are an average of 9 to 10\nquestions long. Relevance assessments are provided for 30 training topics and\n20 test topics. This year 21 groups submitted a total of 65 runs using varying\nmethods for conversational query understanding and ranking. Methods include\ntraditional retrieval based methods, feature based learning-to-rank, neural\nmodels, and knowledge enhanced methods. A common theme through the runs is the\nuse of BERT-based neural reranking methods. Leading methods also employed\ndocument expansion, conversational query expansion, and generative language\nmodels for conversational query rewriting (GPT-2). The results show a gap\nbetween automatic systems and those using the manually resolved utterances,\nwith a 35% relative improvement of manual rewrites over the best automatic\nsystem.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 16:58:04 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Dalton", "Jeffrey", ""], ["Xiong", "Chenyan", ""], ["Callan", "Jamie", ""]]}, {"id": "2003.13657", "submitter": "Sayan Sinha", "authors": "Rakesh Bal, Sayan Sinha, Swastika Dutta, Rishabh Joshi, Sayan Ghosh,\n  and Ritam Dutt", "title": "Analysing the Extent of Misinformation in Cancer Related Tweets", "comments": "Proceedings of the 14th International Conference on Web and Social\n  Media (ICWSM-20)", "journal-ref": "ICWSM 2020, 14, 924-928", "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twitter has become one of the most sought after places to discuss a wide\nvariety of topics, including medically relevant issues such as cancer. This\nhelps spread awareness regarding the various causes, cures and prevention\nmethods of cancer. However, no proper analysis has been performed, which\ndiscusses the validity of such claims. In this work, we aim to tackle the\nmisinformation spread in such platforms. We collect and present a dataset\nregarding tweets which talk specifically about cancer and propose an\nattention-based deep learning model for automated detection of misinformation\nalong with its spread. We then do a comparative analysis of the linguistic\nvariation in the text corresponding to misinformation and truth. This analysis\nhelps us gather relevant insights on various social aspects related to\nmisinformed tweets.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 17:44:42 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 22:19:34 GMT"}, {"version": "v3", "created": "Thu, 2 Apr 2020 16:32:15 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Bal", "Rakesh", ""], ["Sinha", "Sayan", ""], ["Dutta", "Swastika", ""], ["Joshi", "Rishabh", ""], ["Ghosh", "Sayan", ""], ["Dutt", "Ritam", ""]]}, {"id": "2003.13721", "submitter": "Amr Mahmoud Zaki", "authors": "Amr M. Zaki, Mahmoud I. Khalil, Hazem M. Abbas", "title": "Amharic Abstractive Text Summarization", "comments": "content 3 pages, reference 2 pages, 2 figures, presented to AfricaNLP\n  workshop ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text Summarization is the task of condensing long text into just a handful of\nsentences. Many approaches have been proposed for this task, some of the very\nfirst were building statistical models (Extractive Methods) capable of\nselecting important words and copying them to the output, however these models\nlacked the ability to paraphrase sentences, as they simply select important\nwords without actually understanding their contexts nor understanding their\nmeaning, here comes the use of Deep Learning based architectures (Abstractive\nMethods), which effectively tries to understand the meaning of sentences to\nbuild meaningful summaries. In this work we discuss one of these new novel\napproaches which combines curriculum learning with Deep Learning, this model is\ncalled Scheduled Sampling. We apply this work to one of the most widely spoken\nAfrican languages which is the Amharic Language, as we try to enrich the\nAfrican NLP community with top-notch Deep Learning architectures.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 18:15:32 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Zaki", "Amr M.", ""], ["Khalil", "Mahmoud I.", ""], ["Abbas", "Hazem M.", ""]]}, {"id": "2003.13779", "submitter": "Hamada Zahera", "authors": "Hamada M. Zahera and Mohamed Ahmed Sherif, and Axel Ngonga", "title": "Semantic-based End-to-End Learning for Typhoon Intensity Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disaster prediction is one of the most critical tasks towards disaster\nsurveillance and preparedness. Existing technologies employ different machine\nlearning approaches to predict incoming disasters from historical environmental\ndata. However, for short-term disasters (e.g., earthquakes), historical data\nalone has a limited prediction capability. Therefore, additional sources of\nwarnings are required for accurate prediction. We consider social media as a\nsupplementary source of knowledge in addition to historical environmental data.\nHowever, social media posts (e.g., tweets) is very informal and contains only\nlimited content. To alleviate these limitations, we propose the combination of\nsemantically-enriched word embedding models to represent entities in tweets\nwith their semantic representations computed with the traditionalword2vec.\nMoreover, we study how the correlation between social media posts and typhoons\nmagnitudes (also called intensities)-in terms of volume and sentiments of\ntweets-. Based on these insights, we propose an end-to-end based framework that\nlearns from disaster-related tweets and environmental data to improve typhoon\nintensity prediction. This paper is an extension of our work originally\npublished in K-CAP 2019 [32]. We extended this paper by building our framework\nwith state-of-the-art deep neural models, up-dated our dataset with new\ntyphoons and their tweets to-date and benchmark our approach against recent\nbaselines in disaster prediction. Our experimental results show that our\napproach outperforms the accuracy of the state-of-the-art baselines in terms of\nF1-score with (CNN by12.1%and BiLSTM by3.1%) improvement compared with last\nexperiments\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 01:13:20 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 11:02:22 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Zahera", "Hamada M.", ""], ["Sherif", "Mohamed Ahmed", ""], ["Ngonga", "Axel", ""]]}, {"id": "2003.13785", "submitter": "Caio Corro", "authors": "Caio Corro", "title": "Span-based discontinuous constituency parsing: a family of exact\n  chart-based algorithms with time complexities from O(n^6) down to O(n^3)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a novel chart-based algorithm for span-based parsing of\ndiscontinuous constituency trees of block degree two, including ill-nested\nstructures. In particular, we show that we can build variants of our parser\nwith smaller search spaces and time complexities ranging from $\\mathcal O(n^6)$\ndown to $\\mathcal O(n^3)$. The cubic time variant covers 98\\% of constituents\nobserved in linguistic treebanks while having the same complexity as continuous\nconstituency parsers. We evaluate our approach on German and English treebanks\n(Negra, Tiger and Discontinuous PTB) and report state-of-the-art results in the\nfully supervised setting. We also experiment with pre-trained word embeddings\nand \\bert{}-based neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 19:54:20 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Corro", "Caio", ""]]}, {"id": "2003.13830", "submitter": "Necati Cihan Camgoz", "authors": "Necati Cihan Camgoz, Oscar Koller, Simon Hadfield, Richard Bowden", "title": "Sign Language Transformers: Joint End-to-end Sign Language Recognition\n  and Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work on Sign Language Translation has shown that having a mid-level\nsign gloss representation (effectively recognizing the individual signs)\nimproves the translation performance drastically. In fact, the current\nstate-of-the-art in translation requires gloss level tokenization in order to\nwork. We introduce a novel transformer based architecture that jointly learns\nContinuous Sign Language Recognition and Translation while being trainable in\nan end-to-end manner. This is achieved by using a Connectionist Temporal\nClassification (CTC) loss to bind the recognition and translation problems into\na single unified architecture. This joint approach does not require any\nground-truth timing information, simultaneously solving two co-dependant\nsequence-to-sequence learning problems and leads to significant performance\ngains.\n  We evaluate the recognition and translation performances of our approaches on\nthe challenging RWTH-PHOENIX-Weather-2014T (PHOENIX14T) dataset. We report\nstate-of-the-art sign language recognition and translation results achieved by\nour Sign Language Transformers. Our translation networks outperform both sign\nvideo to spoken language and gloss to spoken language translation models, in\nsome cases more than doubling the performance (9.58 vs. 21.80 BLEU-4 Score). We\nalso share new baseline translation results using transformer networks for\nseveral other text-to-text sign language translation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 21:35:09 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Camgoz", "Necati Cihan", ""], ["Koller", "Oscar", ""], ["Hadfield", "Simon", ""], ["Bowden", "Richard", ""]]}, {"id": "2003.13833", "submitter": "Georg Rehm", "authors": "Georg Rehm and Katrin Marheinecke and Stefanie Hegele and Stelios\n  Piperidis and Kalina Bontcheva and Jan Haji\\v{c} and Khalid Choukri and\n  Andrejs Vasi\\c{l}jevs and Gerhard Backfried and Christoph Prinz and Jos\\'e\n  Manuel G\\'omez P\\'erez and Luc Meertens and Paul Lukowicz and Josef van\n  Genabith and Andrea L\\\"osch and Philipp Slusallek and Morten Irgens and\n  Patrick Gatellier and Joachim K\\\"ohler and Laure Le Bars and Dimitra\n  Anastasiou and Albina Auksori\\=ut\\.e and N\\'uria Bel and Ant\\'onio Branco and\n  Gerhard Budin and Walter Daelemans and Koenraad De Smedt and Radovan\n  Garab\\'ik and Maria Gavriilidou and Dagmar Gromann and Svetla Koeva and Simon\n  Krek and Cvetana Krstev and Krister Lind\\'en and Bernardo Magnini and Jan\n  Odijk and Maciej Ogrodniczuk and Eir\\'ikur R\\\"ognvaldsson and Mike Rosner and\n  Bolette Sandford Pedersen and Inguna Skadi\\c{n}a and Marko Tadi\\'c and Dan\n  Tufi\\c{s} and Tam\\'as V\\'aradi and Kadri Vider and Andy Way and Fran\\c{c}ois\n  Yvon", "title": "The European Language Technology Landscape in 2020: Language-Centric and\n  Human-Centric AI for Cross-Cultural Communication in Multilingual Europe", "comments": "Proceedings of the 12th Language Resources and Evaluation Conference\n  (LREC 2020). To appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingualism is a cultural cornerstone of Europe and firmly anchored in\nthe European treaties including full language equality. However, language\nbarriers impacting business, cross-lingual and cross-cultural communication are\nstill omnipresent. Language Technologies (LTs) are a powerful means to break\ndown these barriers. While the last decade has seen various initiatives that\ncreated a multitude of approaches and technologies tailored to Europe's\nspecific needs, there is still an immense level of fragmentation. At the same\ntime, AI has become an increasingly important concept in the European\nInformation and Communication Technology area. For a few years now, AI,\nincluding many opportunities, synergies but also misconceptions, has been\novershadowing every other topic. We present an overview of the European LT\nlandscape, describing funding programmes, activities, actions and challenges in\nthe different countries with regard to LT, including the current state of play\nin industry and the LT market. We present a brief overview of the main\nLT-related activities on the EU level in the last ten years and develop\nstrategic guidance with regard to four key dimensions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 21:42:45 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Rehm", "Georg", ""], ["Marheinecke", "Katrin", ""], ["Hegele", "Stefanie", ""], ["Piperidis", "Stelios", ""], ["Bontcheva", "Kalina", ""], ["Haji\u010d", "Jan", ""], ["Choukri", "Khalid", ""], ["Vasi\u013cjevs", "Andrejs", ""], ["Backfried", "Gerhard", ""], ["Prinz", "Christoph", ""], ["P\u00e9rez", "Jos\u00e9 Manuel G\u00f3mez", ""], ["Meertens", "Luc", ""], ["Lukowicz", "Paul", ""], ["van Genabith", "Josef", ""], ["L\u00f6sch", "Andrea", ""], ["Slusallek", "Philipp", ""], ["Irgens", "Morten", ""], ["Gatellier", "Patrick", ""], ["K\u00f6hler", "Joachim", ""], ["Bars", "Laure Le", ""], ["Anastasiou", "Dimitra", ""], ["Auksori\u016bt\u0117", "Albina", ""], ["Bel", "N\u00faria", ""], ["Branco", "Ant\u00f3nio", ""], ["Budin", "Gerhard", ""], ["Daelemans", "Walter", ""], ["De Smedt", "Koenraad", ""], ["Garab\u00edk", "Radovan", ""], ["Gavriilidou", "Maria", ""], ["Gromann", "Dagmar", ""], ["Koeva", "Svetla", ""], ["Krek", "Simon", ""], ["Krstev", "Cvetana", ""], ["Lind\u00e9n", "Krister", ""], ["Magnini", "Bernardo", ""], ["Odijk", "Jan", ""], ["Ogrodniczuk", "Maciej", ""], ["R\u00f6gnvaldsson", "Eir\u00edkur", ""], ["Rosner", "Mike", ""], ["Pedersen", "Bolette Sandford", ""], ["Skadi\u0146a", "Inguna", ""], ["Tadi\u0107", "Marko", ""], ["Tufi\u015f", "Dan", ""], ["V\u00e1radi", "Tam\u00e1s", ""], ["Vider", "Kadri", ""], ["Way", "Andy", ""], ["Yvon", "Fran\u00e7ois", ""]]}, {"id": "2003.13841", "submitter": "Ashok Thillaisundaram", "authors": "Ashok Thillaisundaram", "title": "A Hierarchical Transformer for Unsupervised Parsing", "comments": "ICLR 2020: AfricaNLP Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The underlying structure of natural language is hierarchical; words combine\ninto phrases, which in turn form clauses. An awareness of this hierarchical\nstructure can aid machine learning models in performing many linguistic tasks.\nHowever, most such models just process text sequentially and there is no bias\ntowards learning hierarchical structure encoded into their architecture. In\nthis paper, we extend the recent transformer model (Vaswani et al., 2017) by\nenabling it to learn hierarchical representations. To achieve this, we adapt\nthe ordering mechanism introduced in Shen et al., 2018, to the self-attention\nmodule of the transformer architecture. We train our new model on language\nmodelling and then apply it to the task of unsupervised parsing. We achieve\nreasonable results on the freely available subset of the WSJ10 dataset with an\nF1-score of about 50%.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 22:07:22 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Thillaisundaram", "Ashok", ""]]}, {"id": "2003.13878", "submitter": "Aida Amini", "authors": "Aida Amini, Antoine Bosselut, Bhavana Dalvi Mishra, Yejin Choi,\n  Hannaneh Hajishirzi", "title": "Procedural Reading Comprehension with Attribute-Aware Context Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Procedural texts often describe processes (e.g., photosynthesis and cooking)\nthat happen over entities (e.g., light, food). In this paper, we introduce an\nalgorithm for procedural reading comprehension by translating the text into a\ngeneral formalism that represents processes as a sequence of transitions over\nentity attributes (e.g., location, temperature). Leveraging pre-trained\nlanguage models, our model obtains entity-aware and attribute-aware\nrepresentations of the text by joint prediction of entity attributes and their\ntransitions. Our model dynamically obtains contextual encodings of the\nprocedural text exploiting information that is encoded about previous and\ncurrent states to predict the transition of a certain attribute which can be\nidentified as a span of text or from a pre-defined set of classes. Moreover,\nour model achieves state of the art results on two procedural reading\ncomprehension datasets, namely ProPara and npn-cooking\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 00:06:29 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Amini", "Aida", ""], ["Bosselut", "Antoine", ""], ["Mishra", "Bhavana Dalvi", ""], ["Choi", "Yejin", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "2003.13917", "submitter": "C.-H. Huck Yang", "authors": "Chao-Han Huck Yang, Jun Qi, Pin-Yu Chen, Xiaoli Ma, Chin-Hui Lee", "title": "Characterizing Speech Adversarial Examples Using Self-Attention U-Net\n  Enhancement", "comments": "The first draft was finished in August 2019. Accepted to IEEE ICASSP\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.CR cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent studies have highlighted adversarial examples as ubiquitous threats to\nthe deep neural network (DNN) based speech recognition systems. In this work,\nwe present a U-Net based attention model, U-Net$_{At}$, to enhance adversarial\nspeech signals. Specifically, we evaluate the model performance by\ninterpretable speech recognition metrics and discuss the model performance by\nthe augmented adversarial training. Our experiments show that our proposed\nU-Net$_{At}$ improves the perceptual evaluation of speech quality (PESQ) from\n1.13 to 2.78, speech transmission index (STI) from 0.65 to 0.75, short-term\nobjective intelligibility (STOI) from 0.83 to 0.96 on the task of speech\nenhancement with adversarial speech examples. We conduct experiments on the\nautomatic speech recognition (ASR) task with adversarial audio attacks. We find\nthat (i) temporal features learned by the attention network are capable of\nenhancing the robustness of DNN based ASR models; (ii) the generalization power\nof DNN based ASR model could be enhanced by applying adversarial training with\nan additive adversarial data augmentation. The ASR metric on word-error-rates\n(WERs) shows that there is an absolute 2.22 $\\%$ decrease under gradient-based\nperturbation, and an absolute 2.03 $\\%$ decrease, under evolutionary-optimized\nperturbation, which suggests that our enhancement models with adversarial\ntraining can further secure a resilient ASR system.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 02:16:34 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Yang", "Chao-Han Huck", ""], ["Qi", "Jun", ""], ["Chen", "Pin-Yu", ""], ["Ma", "Xiaoli", ""], ["Lee", "Chin-Hui", ""]]}, {"id": "2003.13956", "submitter": "Gong Cheng", "authors": "Yawei Sun, Lingling Zhang, Gong Cheng, Yuzhong Qu", "title": "SPARQA: Skeleton-based Semantic Parsing for Complex Questions over\n  Knowledge Bases", "comments": "Accepted to AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Semantic parsing transforms a natural language question into a formal query\nover a knowledge base. Many existing methods rely on syntactic parsing like\ndependencies. However, the accuracy of producing such expressive formalisms is\nnot satisfying on long complex questions. In this paper, we propose a novel\nskeleton grammar to represent the high-level structure of a complex question.\nThis dedicated coarse-grained formalism with a BERT-based parsing algorithm\nhelps to improve the accuracy of the downstream fine-grained semantic parsing.\nBesides, to align the structure of a question with the structure of a knowledge\nbase, our multi-strategy method combines sentence-level and word-level\nsemantics. Our approach shows promising performance on several datasets.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 05:12:31 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Sun", "Yawei", ""], ["Zhang", "Lingling", ""], ["Cheng", "Gong", ""], ["Qu", "Yuzhong", ""]]}, {"id": "2003.14026", "submitter": "Toma\\v{z} Erjavec", "authors": "Toma\\v{z} Erjavec", "title": "MULTEXT-East", "comments": null, "journal-ref": "Published in: Nancy Ide, James Pustejovsky, eds. 2007. Handbook of\n  linguistic annotation. pp. 441-462. Springer", "doi": "10.1007/978-94-024-0881-2_17", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MULTEXT-East language resources, a multilingual dataset for language\nengineering research, focused on the morphosyntactic level of linguistic\ndescription. The MULTEXT-East dataset includes the EAGLES-based morphosyntactic\nspecifications, morphosyntactic lexicons, and an annotated multilingual\ncorpora. The parallel corpus, the novel \"1984\" by George Orwell, is sentence\naligned and contains hand-validated morphosyntactic descriptions and lemmas.\nThe resources are uniformly encoded in XML, using the Text Encoding Initiative\nGuidelines, TEI P5, and cover 16 languages: Bulgarian, Croatian, Czech,\nEnglish, Estonian, Hungarian, Macedonian, Persian, Polish, Resian, Romanian,\nRussian, Serbian, Slovak, Slovene, and Ukrainian. This dataset is extensively\ndocumented, and freely available for research purposes. This case study gives a\nhistory of the development of the MULTEXT-East resources, presents their\nencoding and components, discusses related work and gives some conclusions.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 08:45:52 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Erjavec", "Toma\u017e", ""]]}, {"id": "2003.14056", "submitter": "Prajit Dhar", "authors": "Prajit Dhar and Arianna Bisazza", "title": "Understanding Cross-Lingual Syntactic Transfer in Multilingual Recurrent\n  Neural Networks", "comments": "v3: Submitted to NaDaLiDa 2021. 9 pages, two columns and with 6\n  figures and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is now established that modern neural language models can be successfully\ntrained on multiple languages simultaneously without changes to the underlying\narchitecture. But what kind of knowledge is really shared among languages\nwithin these models? Does multilingual training mostly lead to an alignment of\nthe lexical representation spaces or does it also enable the sharing of purely\ngrammatical knowledge? In this paper we dissect different forms of\ncross-lingual transfer and look for its most determining factors, using a\nvariety of models and probing tasks. We find that exposing our LMs to a related\nlanguage does not always increase grammatical knowledge in the target language,\nand that optimal conditions for lexical-semantic transfer may not be optimal\nfor syntactic transfer.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 09:48:25 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 08:10:28 GMT"}, {"version": "v3", "created": "Wed, 14 Apr 2021 11:26:21 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Dhar", "Prajit", ""], ["Bisazza", "Arianna", ""]]}, {"id": "2003.14155", "submitter": "Roman Klinger", "authors": "Jan Hofmann, Enrica Troiano, Kai Sassenberg, and Roman Klinger", "title": "Appraisal Theories for Emotion Classification in Text", "comments": "Accepted at COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Automatic emotion categorization has been predominantly formulated as text\nclassification in which textual units are assigned to an emotion from a\npredefined inventory, for instance following the fundamental emotion classes\nproposed by Paul Ekman (fear, joy, anger, disgust, sadness, surprise) or Robert\nPlutchik (adding trust, anticipation). This approach ignores existing\npsychological theories to some degree, which provide explanations regarding the\nperception of events. For instance, the description that somebody discovers a\nsnake is associated with fear, based on the appraisal as being an unpleasant\nand non-controllable situation. This emotion reconstruction is even possible\nwithout having access to explicit reports of a subjective feeling (for instance\nexpressing this with the words \"I am afraid.\"). Automatic classification\napproaches therefore need to learn properties of events as latent variables\n(for instance that the uncertainty and the mental or physical effort associated\nwith the encounter of a snake leads to fear). With this paper, we propose to\nmake such interpretations of events explicit, following theories of cognitive\nappraisal of events, and show their potential for emotion classification when\nbeing encoded in classification models. Our results show that high quality\nappraisal dimension assignments in event descriptions lead to an improvement in\nthe classification of discrete emotion categories. We make our corpus of\nappraisal-annotated emotion-associated event descriptions publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 12:43:54 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 09:43:12 GMT"}, {"version": "v3", "created": "Tue, 7 Apr 2020 08:14:17 GMT"}, {"version": "v4", "created": "Thu, 28 May 2020 15:48:56 GMT"}, {"version": "v5", "created": "Mon, 12 Oct 2020 11:45:01 GMT"}, {"version": "v6", "created": "Tue, 3 Nov 2020 16:04:46 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Hofmann", "Jan", ""], ["Troiano", "Enrica", ""], ["Sassenberg", "Kai", ""], ["Klinger", "Roman", ""]]}, {"id": "2003.14282", "submitter": "Mark Anderson", "authors": "Mark Anderson, Carlos G\\'omez-Rodr\\'iguez", "title": "Inherent Dependency Displacement Bias of Transition-Based Algorithms", "comments": "To be published in proceedings of the 12th Language Resources and\n  Evaluation Conference. Earlier versions were rejected at the 57th Annual\n  Conference of the Association for Computational Linguistics and the SIGNLL\n  Conference on Computational Natural Language Learning, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide variety of transition-based algorithms are currently used for\ndependency parsers. Empirical studies have shown that performance varies across\ndifferent treebanks in such a way that one algorithm outperforms another on one\ntreebank and the reverse is true for a different treebank. There is often no\ndiscernible reason for what causes one algorithm to be more suitable for a\ncertain treebank and less so for another. In this paper we shed some light on\nthis by introducing the concept of an algorithm's inherent dependency\ndisplacement distribution. This characterises the bias of the algorithm in\nterms of dependency displacement, which quantify both distance and direction of\nsyntactic relations. We show that the similarity of an algorithm's inherent\ndistribution to a treebank's displacement distribution is clearly correlated to\nthe algorithm's parsing performance on that treebank, specifically with highly\nsignificant and substantial correlations for the predominant sentence lengths\nin Universal Dependency treebanks. We also obtain results which show a more\ndiscrete analysis of dependency displacement does not result in any meaningful\ncorrelations.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 15:11:12 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Anderson", "Mark", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "2003.14292", "submitter": "Suyu Ge", "authors": "Suyu Ge and Chuhan Wu and Fangzhao Wu and Tao Qi and Yongfeng Huang", "title": "Graph Enhanced Representation Learning for News Recommendation", "comments": null, "journal-ref": null, "doi": "10.1145/3366423.3380050", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the explosion of online news, personalized news recommendation becomes\nincreasingly important for online news platforms to help their users find\ninteresting information. Existing news recommendation methods achieve\npersonalization by building accurate news representations from news content and\nuser representations from their direct interactions with news (e.g., click),\nwhile ignoring the high-order relatedness between users and news. Here we\npropose a news recommendation method which can enhance the representation\nlearning of users and news by modeling their relatedness in a graph setting. In\nour method, users and news are both viewed as nodes in a bipartite graph\nconstructed from historical user click behaviors. For news representations, a\ntransformer architecture is first exploited to build news semantic\nrepresentations. Then we combine it with the information from neighbor news in\nthe graph via a graph attention network. For user representations, we not only\nrepresent users from their historically clicked news, but also attentively\nincorporate the representations of their neighbor users in the graph. Improved\nperformances on a large-scale real-world dataset validate the effectiveness of\nour proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 15:27:31 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Ge", "Suyu", ""], ["Wu", "Chuhan", ""], ["Wu", "Fangzhao", ""], ["Qi", "Tao", ""], ["Huang", "Yongfeng", ""]]}, {"id": "2003.14324", "submitter": "Eva Vanmassenhove", "authors": "Eva Vanmassenhove", "title": "On the Integration of LinguisticFeatures into Statistical and Neural\n  Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New machine translations (MT) technologies are emerging rapidly and with\nthem, bold claims of achieving human parity such as: (i) the results produced\napproach \"accuracy achieved by average bilingual human translators\" (Wu et al.,\n2017b) or (ii) the \"translation quality is at human parity when compared to\nprofessional human translators\" (Hassan et al., 2018) have seen the light of\nday (Laubli et al., 2018). Aside from the fact that many of these papers craft\ntheir own definition of human parity, these sensational claims are often not\nsupported by a complete analysis of all aspects involved in translation.\nEstablishing the discrepancies between the strengths of statistical approaches\nto MT and the way humans translate has been the starting point of our research.\nBy looking at MT output and linguistic theory, we were able to identify some\nremaining issues. The problems range from simple number and gender agreement\nerrors to more complex phenomena such as the correct translation of aspectual\nvalues and tenses. Our experiments confirm, along with other studies\n(Bentivogli et al., 2016), that neural MT has surpassed statistical MT in many\naspects. However, some problems remain and others have emerged. We cover a\nseries of problems related to the integration of specific linguistic features\ninto statistical and neural MT, aiming to analyse and provide a solution to\nsome of them. Our work focuses on addressing three main research questions that\nrevolve around the complex relationship between linguistics and MT in general.\nWe identify linguistic information that is lacking in order for automatic\ntranslation systems to produce more accurate translations and integrate\nadditional features into the existing pipelines. We identify overgeneralization\nor 'algorithmic bias' as a potential drawback of neural MT and link it to many\nof the remaining linguistic issues.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 16:03:38 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Vanmassenhove", "Eva", ""]]}, {"id": "2003.14386", "submitter": "Asmelash Teka Hadgu", "authors": "Asmelash Teka Hadgu, Adam Beaudoin, Abel Aregawi", "title": "Evaluating Amharic Machine Translation", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine translation (MT) systems are now able to provide very accurate\nresults for high resource language pairs. However, for many low resource\nlanguages, MT is still under active research. In this paper, we develop and\nshare a dataset to automatically evaluate the quality of MT systems for\nAmharic. We compare two commercially available MT systems that support\ntranslation of Amharic to and from English to assess the current state of MT\nfor Amharic. The BLEU score results show that the results for Amharic\ntranslation are promising but still low. We hope that this dataset will be\nuseful to the research community both in academia and industry as a benchmark\nto evaluate Amharic MT systems.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 17:30:08 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Hadgu", "Asmelash Teka", ""], ["Beaudoin", "Adam", ""], ["Aregawi", "Abel", ""]]}, {"id": "2003.14402", "submitter": "Surafel Melaku Lakew Mr.", "authors": "Surafel M. Lakew, Matteo Negri, Marco Turchi", "title": "Low Resource Neural Machine Translation: A Benchmark for Five African\n  Languages", "comments": "Accepted for AfricaNLP workshop at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advents in Neural Machine Translation (NMT) have shown improvements in\nlow-resource language (LRL) translation tasks. In this work, we benchmark NMT\nbetween English and five African LRL pairs (Swahili, Amharic, Tigrigna, Oromo,\nSomali [SATOS]). We collected the available resources on the SATOS languages to\nevaluate the current state of NMT for LRLs. Our evaluation, comparing a\nbaseline single language pair NMT model against semi-supervised learning,\ntransfer learning, and multilingual modeling, shows significant performance\nimprovements both in the En-LRL and LRL-En directions. In terms of averaged\nBLEU score, the multilingual approach shows the largest gains, up to +5 points,\nin six out of ten translation directions. To demonstrate the generalization\ncapability of each model, we also report results on multi-domain test sets. We\nrelease the standardized experimental data and the test sets for future works\naddressing the challenges of NMT in under-resourced settings, in particular for\nthe SATOS languages.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 17:50:07 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Lakew", "Surafel M.", ""], ["Negri", "Matteo", ""], ["Turchi", "Marco", ""]]}]