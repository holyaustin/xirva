[{"id": "2008.00032", "submitter": "Cristina Zuheros", "authors": "Cristina Zuheros, Eugenio Mart\\'inez-C\\'amara, Enrique Herrera-Viedma,\n  and Francisco Herrera", "title": "Sentiment Analysis based Multi-person Multi-criteria Decision Making\n  Methodology using Natural Language Processing and Deep Learning for Smarter\n  Decision Aid. Case study of restaurant choice using TripAdvisor reviews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision making models are constrained by taking the expert evaluations with\npre-defined numerical or linguistic terms. We claim that the use of sentiment\nanalysis will allow decision making models to consider expert evaluations in\nnatural language. Accordingly, we propose the Sentiment Analysis based\nMulti-person Multi-criteria Decision Making (SA-MpMcDM) methodology for smarter\ndecision aid, which builds the expert evaluations from their natural language\nreviews, and even from their numerical ratings if they are available. The\nSA-MpMcDM methodology incorporates an end-to-end multi-task deep learning model\nfor aspect based sentiment analysis, named DOC-ABSADeepL model, able to\nidentify the aspect categories mentioned in an expert review, and to distill\ntheir opinions and criteria. The individual evaluations are aggregated via the\nprocedure named criteria weighting through the attention of the experts. We\nevaluate the methodology in a case study of restaurant choice using TripAdvisor\nreviews, hence we build, manually annotate, and release the TripR-2020 dataset\nof restaurant reviews. We analyze the SA-MpMcDM methodology in different\nscenarios using and not using natural language and numerical evaluations. The\nanalysis shows that the combination of both sources of information results in a\nhigher quality preference vector.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 18:45:52 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 14:18:41 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Zuheros", "Cristina", ""], ["Mart\u00ednez-C\u00e1mara", "Eugenio", ""], ["Herrera-Viedma", "Enrique", ""], ["Herrera", "Francisco", ""]]}, {"id": "2008.00036", "submitter": "Fabrizio Falchi Prof.", "authors": "Tiziano Fagni, Fabrizio Falchi, Margherita Gambini, Antonio Martella,\n  Maurizio Tesconi", "title": "TweepFake: about Detecting Deepfake Tweets", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0251415", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advances in language modeling significantly improved the\ngenerative capabilities of deep neural models: in 2019 OpenAI released GPT-2, a\npre-trained language model that can autonomously generate coherent, non-trivial\nand human-like text samples. Since then, ever more powerful text generative\nmodels have been developed. Adversaries can exploit these tremendous generative\ncapabilities to enhance social bots that will have the ability to write\nplausible deepfake messages, hoping to contaminate public debate. To prevent\nthis, it is crucial to develop deepfake social media messages detection\nsystems. However, to the best of our knowledge no one has ever addressed the\ndetection of machine-generated texts on social networks like Twitter or\nFacebook. With the aim of helping the research in this detection field, we\ncollected the first dataset of \\real deepfake tweets, TweepFake. It is real in\nthe sense that each deepfake tweet was actually posted on Twitter. We collected\ntweets from a total of 23 bots, imitating 17 human accounts. The bots are based\non various generation techniques, i.e., Markov Chains, RNN, RNN+Markov, LSTM,\nGPT-2. We also randomly selected tweets from the humans imitated by the bots to\nhave an overall balanced dataset of 25,572 tweets (half human and half bots\ngenerated). The dataset is publicly available on Kaggle. Lastly, we evaluated\n13 deepfake text detection methods (based on various state-of-the-art\napproaches) to both demonstrate the challenges that Tweepfake poses and create\na solid baseline of detection techniques. We hope that TweepFake can offer the\nopportunity to tackle the deepfake detection on social media messages as well.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 19:01:13 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 16:40:26 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Fagni", "Tiziano", ""], ["Falchi", "Fabrizio", ""], ["Gambini", "Margherita", ""], ["Martella", "Antonio", ""], ["Tesconi", "Maurizio", ""]]}, {"id": "2008.00097", "submitter": "Karen Leung Ms", "authors": "Karen Leung, Nikos Ar\\'echiga, Marco Pavone", "title": "Back-propagation through Signal Temporal Logic Specifications: Infusing\n  Logical Structure into Gradient-Based Methods", "comments": "Published in the Workshop on Algorithmic Foundations of Robotics 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CL cs.LO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a technique, named STLCG, to compute the quantitative\nsemantics of Signal Temporal Logic (STL) formulas using computation graphs.\nSTLCG provides a platform which enables the incorporation of logical\nspecifications into robotics problems that benefit from gradient-based\nsolutions. Specifically, STL is a powerful and expressive formal language that\ncan specify spatial and temporal properties of signals generated by both\ncontinuous and hybrid systems. The quantitative semantics of STL provide a\nrobustness metric, i.e., how much a signal satisfies or violates an STL\nspecification. In this work, we devise a systematic methodology for translating\nSTL robustness formulas into computation graphs. With this representation, and\nby leveraging off-the-shelf automatic differentiation tools, we are able to\nback-propagate through STL robustness formulas and hence enable a natural and\neasy-to-use integration with many gradient-based approaches used in robotics.\nWe demonstrate, through examples stemming from various robotics applications,\nthat STLCG is versatile, computationally efficient, and capable of injecting\nhuman-domain knowledge into the problem formulation.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 22:01:39 GMT"}, {"version": "v2", "created": "Sun, 3 Jan 2021 00:04:46 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Leung", "Karen", ""], ["Ar\u00e9chiga", "Nikos", ""], ["Pavone", "Marco", ""]]}, {"id": "2008.00107", "submitter": "Hu Hu", "authors": "Hu Hu, Sabato Marco Siniscalchi, Yannan Wang, Xue Bai, Jun Du,\n  Chin-Hui Lee", "title": "An Acoustic Segment Model Based Segment Unit Selection Approach to\n  Acoustic Scene Classification with Partial Utterances", "comments": "Accepted by Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a sub-utterance unit selection framework to remove\nacoustic segments in audio recordings that carry little information for\nacoustic scene classification (ASC). Our approach is built upon a universal set\nof acoustic segment units covering the overall acoustic scene space. First,\nthose units are modeled with acoustic segment models (ASMs) used to tokenize\nacoustic scene utterances into sequences of acoustic segment units. Next,\nparalleling the idea of stop words in information retrieval, stop ASMs are\nautomatically detected. Finally, acoustic segments associated with the stop\nASMs are blocked, because of their low indexing power in retrieval of most\nacoustic scenes. In contrast to building scene models with whole utterances,\nthe ASM-removed sub-utterances, i.e., acoustic utterances without stop acoustic\nsegments, are then used as inputs to the AlexNet-L back-end for final\nclassification. On the DCASE 2018 dataset, scene classification accuracy\nincreases from 68%, with whole utterances, to 72.1%, with segment selection.\nThis represents a competitive accuracy without any data augmentation, and/or\nensemble strategy. Moreover, our approach compares favourably to AlexNet-L with\nattention.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 23:01:53 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Hu", "Hu", ""], ["Siniscalchi", "Sabato Marco", ""], ["Wang", "Yannan", ""], ["Bai", "Xue", ""], ["Du", "Jun", ""], ["Lee", "Chin-Hui", ""]]}, {"id": "2008.00110", "submitter": "Hu Hu", "authors": "Hu Hu, Sabato Marco Siniscalchi, Yannan Wang, Chin-Hui Lee", "title": "Relational Teacher Student Learning with Neural Label Embedding for\n  Device Adaptation in Acoustic Scene Classification", "comments": "Accepted by Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a domain adaptation framework to address the device\nmismatch issue in acoustic scene classification leveraging upon neural label\nembedding (NLE) and relational teacher student learning (RTSL). Taking into\naccount the structural relationships between acoustic scene classes, our\nproposed framework captures such relationships which are intrinsically\ndevice-independent. In the training stage, transferable knowledge is condensed\nin NLE from the source domain. Next in the adaptation stage, a novel RTSL\nstrategy is adopted to learn adapted target models without using paired\nsource-target data often required in conventional teacher student learning. The\nproposed framework is evaluated on the DCASE 2018 Task1b data set. Experimental\nresults based on AlexNet-L deep classification models confirm the effectiveness\nof our proposed approach for mismatch situations. NLE-alone adaptation compares\nfavourably with the conventional device adaptation and teacher student based\nadaptation techniques. NLE with RTSL further improves the classification\naccuracy.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 23:07:20 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Hu", "Hu", ""], ["Siniscalchi", "Sabato Marco", ""], ["Wang", "Yannan", ""], ["Lee", "Chin-Hui", ""]]}, {"id": "2008.00140", "submitter": "Daniel Lee", "authors": "Daniel Lee and Rakesh Verma and Avisha Das and Arjun Mukherjee", "title": "Experiments in Extractive Summarization: Integer Linear Programming,\n  Term/Sentence Scoring, and Title-driven Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit the challenging problem of unsupervised\nsingle-document summarization and study the following aspects: Integer linear\nprogramming (ILP) based algorithms, Parameterized normalization of term and\nsentence scores, and Title-driven approaches for summarization. We describe a\nnew framework, NewsSumm, that includes many existing and new approaches for\nsummarization including ILP and title-driven approaches. NewsSumm's flexibility\nallows to combine different algorithms and sentence scoring schemes seamlessly.\nOur results combining sentence scoring with ILP and normalization are in\ncontrast to previous work on this topic, showing the importance of a broader\nsearch for optimal parameters. We also show that the new title-driven reduction\nidea leads to improvement in performance for both unsupervised and supervised\napproaches considered.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 01:05:55 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Lee", "Daniel", ""], ["Verma", "Rakesh", ""], ["Das", "Avisha", ""], ["Mukherjee", "Arjun", ""]]}, {"id": "2008.00177", "submitter": "Xin Li", "authors": "Jiahuang Lin, Xin Li, Gennady Pekhimenko", "title": "Multi-node Bert-pretraining: Cost-efficient Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, large scale Transformer-based language models such as BERT, GPT-2,\nand XLNet have brought about exciting leaps in state-of-the-art results for\nmany Natural Language Processing (NLP) tasks. One of the common trends in these\nrecent models is a significant increase in model complexity, which introduces\nboth more weights and computation. Moreover, with the advent of large-scale\nunsupervised datasets, training time is further extended due to the increased\namount of data samples within a single training epoch. As a result, to train\nthese models within a reasonable time, machine learning (ML) programmers often\nrequire advanced hardware setups such as the premium GPU-enabled NVIDIA DGX\nworkstations or specialized accelerators such as Google's TPU Pods. Our work\naddresses this limitation and demonstrates that the BERT pre-trained model can\nbe trained within 2 weeks on an academic-size cluster of widely available GPUs\nthrough careful algorithmic and software optimizations. In this paper, we\npresent these optimizations on how to improve single device training\nthroughput, distribute the training workload over multiple nodes and GPUs, and\novercome the communication bottleneck introduced by the large data exchanges\nover the network. We show that we are able to perform pre-training on BERT\nwithin a reasonable time budget (12 days) in an academic setting, but with a\nmuch less expensive and less aggressive hardware resource requirement than in\npreviously demonstrated industrial settings based on NVIDIA DGX machines or\nGoogle's TPU Pods.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 05:49:20 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Lin", "Jiahuang", ""], ["Li", "Xin", ""], ["Pekhimenko", "Gennady", ""]]}, {"id": "2008.00279", "submitter": "Jie Zou", "authors": "Jie Zou, Evangelos Kanoulas, and Yiqun Liu", "title": "An Empirical Study of Clarifying Question-Based Systems", "comments": "Parts of content are published on CIKM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search and recommender systems that take the initiative to ask clarifying\nquestions to better understand users' information needs are receiving\nincreasing attention from the research community. However, to the best of our\nknowledge, there is no empirical study to quantify whether and to what extent\nusers are willing or able to answer these questions. In this work, we conduct\nan online experiment by deploying an experimental system, which interacts with\nusers by asking clarifying questions against a product repository. We collect\nboth implicit interaction behavior data and explicit feedback from users\nshowing that: (a) users are willing to answer a good number of clarifying\nquestions (11-21 on average), but not many more than that; (b) most users\nanswer questions until they reach the target product, but also a fraction of\nthem stops due to fatigue or due to receiving irrelevant questions; (c) part of\nthe users' answers (12-17%) are actually opposite to the description of the\ntarget product; while (d) most of the users (66-84%) find the question-based\nsystem helpful towards completing their tasks. Some of the findings of the\nstudy contradict current assumptions on simulated evaluations in the field,\nwhile they point towards improvements in the evaluation framework and can\ninspire future interactive search/recommender system designs.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 15:10:11 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Zou", "Jie", ""], ["Kanoulas", "Evangelos", ""], ["Liu", "Yiqun", ""]]}, {"id": "2008.00293", "submitter": "Ernest Davis", "authors": "Ernest Davis", "title": "The test set for the TransCoder system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The TransCoder system translates source code between Java, C++, and Python 3.\nThe test set that was used to evaluate its quality is missing important\nfeatures of Java, including the ability to define and use classes and the\nability to call user-defined functions other than recursively. Therefore, the\naccuracy of TransCoder over programs with those features remains unknown.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 16:28:47 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Davis", "Ernest", ""]]}, {"id": "2008.00304", "submitter": "Nabil Hossain", "authors": "Nabil Hossain, John Krumm, Michael Gamon and Henry Kautz", "title": "SemEval-2020 Task 7: Assessing Humor in Edited News Headlines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes the SemEval-2020 shared task \"Assessing Humor in Edited\nNews Headlines.\" The task's dataset contains news headlines in which short\nedits were applied to make them funny, and the funniness of these edited\nheadlines was rated using crowdsourcing. This task includes two subtasks, the\nfirst of which is to estimate the funniness of headlines on a humor scale in\nthe interval 0-3. The second subtask is to predict, for a pair of edited\nversions of the same original headline, which is the funnier version. To date,\nthis task is the most popular shared computational humor task, attracting 48\nteams for the first subtask and 31 teams for the second.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 17:34:37 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Hossain", "Nabil", ""], ["Krumm", "John", ""], ["Gamon", "Michael", ""], ["Kautz", "Henry", ""]]}, {"id": "2008.00312", "submitter": "Xinyang Zhang", "authors": "Xinyang Zhang, Zheng Zhang, Shouling Ji and Ting Wang", "title": "Trojaning Language Models for Fun and Profit", "comments": "Additional experiments and text editing; To appear in 2021 6th IEEE\n  European Symposium on Security and Privacy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the emergence of a new paradigm of building\nnatural language processing (NLP) systems: general-purpose, pre-trained\nlanguage models (LMs) are composed with simple downstream models and fine-tuned\nfor a variety of NLP tasks. This paradigm shift significantly simplifies the\nsystem development cycles. However, as many LMs are provided by untrusted third\nparties, their lack of standardization or regulation entails profound security\nimplications, which are largely unexplored.\n  To bridge this gap, this work studies the security threats posed by malicious\nLMs to NLP systems. Specifically, we present TROJAN-LM, a new class of\ntrojaning attacks in which maliciously crafted LMs trigger host NLP systems to\nmalfunction in a highly predictable manner. By empirically studying three\nstate-of-the-art LMs (BERT, GPT-2, XLNet) in a range of security-critical NLP\ntasks (toxic comment detection, question answering, text completion) as well as\nuser studies on crowdsourcing platforms, we demonstrate that TROJAN-LM\npossesses the following properties: (i) flexibility - the adversary is able to\nflexibly dene logical combinations (e.g., 'and', 'or', 'xor') of arbitrary\nwords as triggers, (ii) efficacy - the host systems misbehave as desired by the\nadversary with high probability when trigger-embedded inputs are present, (iii)\nspecificity - the trojan LMs function indistinguishably from their benign\ncounterparts on clean inputs, and (iv) fluency - the trigger-embedded inputs\nappear as fluent natural language and highly relevant to their surrounding\ncontexts. We provide analytical justification for the practicality of\nTROJAN-LM, and further discuss potential countermeasures and their challenges,\nwhich lead to several promising research directions.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 18:22:38 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 21:52:58 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Zhang", "Xinyang", ""], ["Zhang", "Zheng", ""], ["Ji", "Shouling", ""], ["Wang", "Ting", ""]]}, {"id": "2008.00343", "submitter": "Ali H\\\"urriyeto\\u{g}lu", "authors": "Ali H\\\"urriyeto\\u{g}lu", "title": "Extracting actionable information from microtexts", "comments": "Radboud Univeversity, Dissertation, 2019. Go to\n  https://hdl.handle.net/2066/204517 for the original version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microblogs such as Twitter represent a powerful source of information. Part\nof this information can be aggregated beyond the level of individual posts.\nSome of this aggregated information is referring to events that could or should\nbe acted upon in the interest of e-governance, public safety, or other levels\nof public interest. Moreover, a significant amount of this information, if\naggregated, could complement existing information networks in a non-trivial\nway. This dissertation proposes a semi-automatic method for extracting\nactionable information that serves this purpose. First, we show that predicting\ntime to event is possible for both in-domain and cross-domain scenarios.\nSecond, we suggest a method which facilitates the definition of relevance for\nan analyst's context and the use of this definition to analyze new data.\nFinally, we propose a method to integrate the machine learning based relevant\ninformation classification method with a rule-based information classification\ntechnique to classify microtexts. Fully automatizing microtext analysis has\nbeen our goal since the first day of this research project. Our efforts in this\ndirection informed us about the extent this automation can be realized. We\nmostly first developed an automated approach, then we extended and improved it\nby integrating human intervention at various steps of the automated approach.\nOur experience confirms previous work that states that a well-designed human\nintervention or contribution in design, realization, or evaluation of an\ninformation system either improves its performance or enables its realization.\nAs our studies and results directed us toward its necessity and value, we were\ninspired from previous studies in designing human involvement and customized\nour approaches to benefit from human input.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 21:22:53 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["H\u00fcrriyeto\u011flu", "Ali", ""]]}, {"id": "2008.00345", "submitter": "Ali H\\\"urriyeto\\u{g}lu", "authors": "Ali H\\\"urriyeto\\u{g}lu, Erdem Y\\\"or\\\"uk, Deniz Y\\\"uret,\n  \\c{C}a\\u{g}r{\\i} Yoltar, Burak G\\\"urel, F{\\i}rat Duru\\c{s}an, Osman Mutlu,\n  and Arda Akdemir", "title": "Overview of CLEF 2019 Lab ProtestNews: Extracting Protests from News in\n  a Cross-context Setting", "comments": "Conference and Labs of the Evaluation Forum (CLEF 2019), Overview of\n  the Protest News analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an overview of the CLEF-2019 Lab ProtestNews on Extracting\nProtests from News in the context of generalizable natural language processing.\nThe lab consists of document, sentence, and token level information\nclassification and extraction tasks that were referred as task 1, task 2, and\ntask 3 respectively in the scope of this lab. The tasks required the\nparticipants to identify protest relevant information from English local news\nat one or more aforementioned levels in a cross-context setting, which is\ncross-country in the scope of this lab. The training and development data were\ncollected from India and test data was collected from India and China. The lab\nattracted 58 teams to participate in the lab. 12 and 9 of these teams submitted\nresults and working notes respectively. We have observed neural networks yield\nthe best results and the performance drops significantly for majority of the\nsubmissions in the cross-country setting, which is China.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 21:39:54 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["H\u00fcrriyeto\u011flu", "Ali", ""], ["Y\u00f6r\u00fck", "Erdem", ""], ["Y\u00fcret", "Deniz", ""], ["Yoltar", "\u00c7a\u011fr\u0131", ""], ["G\u00fcrel", "Burak", ""], ["Duru\u015fan", "F\u0131rat", ""], ["Mutlu", "Osman", ""], ["Akdemir", "Arda", ""]]}, {"id": "2008.00351", "submitter": "Ali H\\\"urriyeto\\u{g}lu", "authors": "Ali H\\\"urriyeto\\u{g}lu, Erdem Y\\\"or\\\"uk, Deniz Y\\\"uret, Osman Mutlu,\n  \\c{C}a\\u{g}r{\\i} Yoltar, F{\\i}rat Duru\\c{s}an, Burak G\\\"urel", "title": "Cross-context News Corpus for Protest Events related Knowledge Base\n  Construction", "comments": "Presented at Automated Knowledge Base Construction (AKBC 2020)\n  conference. See: https://www.akbc.ws/2020/papers/7NZkNhLCjp", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a gold standard corpus of protest events that comprise of various\nlocal and international sources from various countries in English. The corpus\ncontains document, sentence, and token level annotations. This corpus\nfacilitates creating machine learning models that automatically classify news\narticles and extract protest event-related information, constructing knowledge\nbases which enable comparative social and political science studies. For each\nnews source, the annotation starts on random samples of news articles and\ncontinues with samples that are drawn using active learning. Each batch of\nsamples was annotated by two social and political scientists, adjudicated by an\nannotation supervisor, and was improved by identifying annotation errors\nsemi-automatically. We found that the corpus has the variety and quality to\ndevelop and benchmark text classification and event extraction systems in a\ncross-context setting, which contributes to the generalizability and robustness\nof automated text processing systems. This corpus and the reported results will\nset the currently lacking common ground in automated protest event collection\nstudies.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 22:20:48 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["H\u00fcrriyeto\u011flu", "Ali", ""], ["Y\u00f6r\u00fck", "Erdem", ""], ["Y\u00fcret", "Deniz", ""], ["Mutlu", "Osman", ""], ["Yoltar", "\u00c7a\u011fr\u0131", ""], ["Duru\u015fan", "F\u0131rat", ""], ["G\u00fcrel", "Burak", ""]]}, {"id": "2008.00364", "submitter": "Qian Li", "authors": "Qian Li, Hao Peng, Jianxin Li, Congying Xia, Renyu Yang, Lichao Sun,\n  Philip S. Yu, Lifang He", "title": "A Survey on Text Classification: From Shallow to Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text classification is the most fundamental and essential task in natural\nlanguage processing. The last decade has seen a surge of research in this area\ndue to the unprecedented success of deep learning. Numerous methods, datasets,\nand evaluation metrics have been proposed in the literature, raising the need\nfor a comprehensive and updated survey. This paper fills the gap by reviewing\nthe state of the art approaches from 1961 to 2020, focusing on models from\nshallow to deep learning. We create a taxonomy for text classification\naccording to the text involved and the models used for feature extraction and\nclassification. We then discuss each of these categories in detail, dealing\nwith both the technical developments and benchmark datasets that support tests\nof predictions. A comprehensive comparison between different techniques, as\nwell as identifying the pros and cons of various evaluation metrics are also\nprovided in this survey. Finally, we conclude by summarizing key implications,\nfuture research directions, and the challenges facing the research area.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 00:09:03 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 06:13:59 GMT"}, {"version": "v3", "created": "Sun, 11 Oct 2020 04:15:57 GMT"}, {"version": "v4", "created": "Tue, 13 Oct 2020 07:05:36 GMT"}, {"version": "v5", "created": "Mon, 26 Oct 2020 02:46:42 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Li", "Qian", ""], ["Peng", "Hao", ""], ["Li", "Jianxin", ""], ["Xia", "Congying", ""], ["Yang", "Renyu", ""], ["Sun", "Lichao", ""], ["Yu", "Philip S.", ""], ["He", "Lifang", ""]]}, {"id": "2008.00386", "submitter": "Franck Dernoncourt", "authors": "Lidan Wang, Franck Dernoncourt, Trung Bui", "title": "Bayesian Optimization for Selecting Efficient Machine Learning Models", "comments": "Published at CIKM MoST-Rec 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The performance of many machine learning models depends on their\nhyper-parameter settings. Bayesian Optimization has become a successful tool\nfor hyper-parameter optimization of machine learning algorithms, which aims to\nidentify optimal hyper-parameters during an iterative sequential process.\nHowever, most of the Bayesian Optimization algorithms are designed to select\nmodels for effectiveness only and ignore the important issue of model training\nefficiency. Given that both model effectiveness and training time are important\nfor real-world applications, models selected for effectiveness may not meet the\nstrict training time requirements necessary to deploy in a production\nenvironment. In this work, we present a unified Bayesian Optimization framework\nfor jointly optimizing models for both prediction effectiveness and training\nefficiency. We propose an objective that captures the tradeoff between these\ntwo metrics and demonstrate how we can jointly optimize them in a principled\nBayesian Optimization framework. Experiments on model selection for\nrecommendation tasks indicate models selected this way significantly improves\nmodel training efficiency while maintaining strong effectiveness as compared to\nstate-of-the-art Bayesian Optimization algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 02:56:30 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Wang", "Lidan", ""], ["Dernoncourt", "Franck", ""], ["Bui", "Trung", ""]]}, {"id": "2008.00401", "submitter": "Yuqing Tang", "authors": "Yuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav\n  Chaudhary, Jiatao Gu, Angela Fan", "title": "Multilingual Translation with Extensible Multilingual Pretraining and\n  Finetuning", "comments": "10 pages (main) + 5 pages (appendices). 9 tables and 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work demonstrates the potential of multilingual pretraining of\ncreating one model that can be used for various tasks in different languages.\nPrevious work in multilingual pretraining has demonstrated that machine\ntranslation systems can be created by finetuning on bitext. In this work, we\nshow that multilingual translation models can be created through multilingual\nfinetuning. Instead of finetuning on one direction, a pretrained model is\nfinetuned on many directions at the same time. Compared to multilingual models\ntrained from scratch, starting from pretrained models incorporates the benefits\nof large quantities of unlabeled monolingual data, which is particularly\nimportant for low resource languages where bitext is not available. We\ndemonstrate that pretrained models can be extended to incorporate additional\nlanguages without loss of performance. We double the number of languages in\nmBART to support multilingual machine translation models of 50 languages.\nFinally, we create the ML50 benchmark, covering low, mid, and high resource\nlanguages, to facilitate reproducible research by standardizing training and\nevaluation data. On ML50, we demonstrate that multilingual finetuning improves\non average 1 BLEU over the strongest baselines (being either multilingual from\nscratch or bilingual finetuning) while improving 9.3 BLEU on average over\nbilingual baselines from scratch.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 05:36:55 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Tang", "Yuqing", ""], ["Tran", "Chau", ""], ["Li", "Xian", ""], ["Chen", "Peng-Jen", ""], ["Goyal", "Naman", ""], ["Chaudhary", "Vishrav", ""], ["Gu", "Jiatao", ""], ["Fan", "Angela", ""]]}, {"id": "2008.00441", "submitter": "Sunil Sahu", "authors": "Sunil Kumar Sahu, Derek Thomas, Billy Chiu, Neha Sengupta, Mohammady\n  Mahdy", "title": "Relation Extraction with Self-determined Graph Convolutional Network", "comments": "CIKM-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation Extraction is a way of obtaining the semantic relationship between\nentities in text. The state-of-the-art methods use linguistic tools to build a\ngraph for the text in which the entities appear and then a Graph Convolutional\nNetwork (GCN) is employed to encode the pre-built graphs. Although their\nperformance is promising, the reliance on linguistic tools results in a non\nend-to-end process. In this work, we propose a novel model, the Self-determined\nGraph Convolutional Network (SGCN), which determines a weighted graph using a\nself-attention mechanism, rather using any linguistic tool. Then, the\nself-determined graph is encoded using a GCN. We test our model on the TACRED\ndataset and achieve the state-of-the-art result. Our experiments show that SGCN\noutperforms the traditional GCN, which uses dependency parsing tools to build\nthe graph.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 09:52:58 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 05:55:43 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Sahu", "Sunil Kumar", ""], ["Thomas", "Derek", ""], ["Chiu", "Billy", ""], ["Sengupta", "Neha", ""], ["Mahdy", "Mohammady", ""]]}, {"id": "2008.00461", "submitter": "Oguzhan Gencoglu", "authors": "Oguzhan Gencoglu", "title": "Large-scale, Language-agnostic Discourse Classification of Tweets During\n  COVID-19", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": "10.3390/make2040032", "report-no": null, "categories": "cs.SI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantifying the characteristics of public attention is an essential\nprerequisite for appropriate crisis management during severe events such as\npandemics. For this purpose, we propose language-agnostic tweet representations\nto perform large-scale Twitter discourse classification with machine learning.\nOur analysis on more than 26 million COVID-19 tweets shows that large-scale\nsurveillance of public discourse is feasible with computationally lightweight\nclassifiers by out-of-the-box utilization of these representations.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 11:12:56 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2020 15:03:58 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Gencoglu", "Oguzhan", ""]]}, {"id": "2008.00482", "submitter": "Ilyos Rabbimov", "authors": "Ilyos Rabbimov, Iosif Mporas, Vasiliki Simaki, Sami Kobilov", "title": "Investigating the Effect of Emoji in Opinion Classification of Uzbek\n  Movie Review Comments", "comments": "10 pages, 1 figure, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Opinion mining on social media posts has become more and more popular. Users\noften express their opinion on a topic not only with words but they also use\nimage symbols such as emoticons and emoji. In this paper, we investigate the\neffect of emoji-based features in opinion classification of Uzbek texts, and\nmore specifically movie review comments from YouTube. Several classification\nalgorithms are tested, and feature ranking is performed to evaluate the\ndiscriminative ability of the emoji-based features.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 13:50:47 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Rabbimov", "Ilyos", ""], ["Mporas", "Iosif", ""], ["Simaki", "Vasiliki", ""], ["Kobilov", "Sami", ""]]}, {"id": "2008.00544", "submitter": "Wentian Zhao", "authors": "Wentian Zhao, Seokhwan Kim, Ning Xu, Hailin Jin", "title": "Video Question Answering on Screencast Tutorials", "comments": null, "journal-ref": null, "doi": "10.24963/ijcai.2020/148", "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new video question answering task on screencast\ntutorials. We introduce a dataset including question, answer and context\ntriples from the tutorial videos for a software. Unlike other video question\nanswering works, all the answers in our dataset are grounded to the domain\nknowledge base. An one-shot recognition algorithm is designed to extract the\nvisual cues, which helps enhance the performance of video question answering.\nWe also propose several baseline neural network architectures based on various\naspects of video contexts from the dataset. The experimental results\ndemonstrate that our proposed models significantly improve the question\nanswering performances by incorporating multi-modal contexts and domain\nknowledge.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 19:27:42 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Zhao", "Wentian", ""], ["Kim", "Seokhwan", ""], ["Xu", "Ning", ""], ["Jin", "Hailin", ""]]}, {"id": "2008.00545", "submitter": "Badr M. Abdullah", "authors": "Badr M. Abdullah, Tania Avgustinova, Bernd M\\\"obius, Dietrich Klakow", "title": "Cross-Domain Adaptation of Spoken Language Identification for Related\n  Languages: The Curious Case of Slavic Languages", "comments": "To appear in INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art spoken language identification (LID) systems, which are\nbased on end-to-end deep neural networks, have shown remarkable success not\nonly in discriminating between distant languages but also between\nclosely-related languages or even different spoken varieties of the same\nlanguage. However, it is still unclear to what extent neural LID models\ngeneralize to speech samples with different acoustic conditions due to domain\nshift. In this paper, we present a set of experiments to investigate the impact\nof domain mismatch on the performance of neural LID systems for a subset of six\nSlavic languages across two domains (read speech and radio broadcast) and\nexamine two low-level signal descriptors (spectral and cepstral features) for\nthis task. Our experiments show that (1) out-of-domain speech samples severely\nhinder the performance of neural LID models, and (2) while both spectral and\ncepstral features show comparable performance within-domain, spectral features\nshow more robustness under domain mismatch. Moreover, we apply unsupervised\ndomain adaptation to minimize the discrepancy between the two domains in our\nstudy. We achieve relative accuracy improvements that range from 9% to 77%\ndepending on the diversity of acoustic conditions in the source domain.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 19:30:39 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 00:31:40 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Abdullah", "Badr M.", ""], ["Avgustinova", "Tania", ""], ["M\u00f6bius", "Bernd", ""], ["Klakow", "Dietrich", ""]]}, {"id": "2008.00563", "submitter": "Xiaoyu Yang", "authors": "Xiaoyu Yang, Stephen Obadinma, Huasha Zhao, Qiong Zhang, Stan Matwin,\n  Xiaodan Zhu", "title": "SemEval-2020 Task 5: Counterfactual Recognition", "comments": "Task description paper of SemEval-2020 Task 5: Modelling Causal\n  Reasoning in Language: Detecting Counterfactuals", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a counterfactual recognition (CR) task, the shared Task 5 of\nSemEval-2020. Counterfactuals describe potential outcomes (consequents)\nproduced by actions or circumstances that did not happen or cannot happen and\nare counter to the facts (antecedent). Counterfactual thinking is an important\ncharacteristic of the human cognitive system; it connects antecedents and\nconsequents with causal relations. Our task provides a benchmark for\ncounterfactual recognition in natural language with two subtasks. Subtask-1\naims to determine whether a given sentence is a counterfactual statement or\nnot. Subtask-2 requires the participating systems to extract the antecedent and\nconsequent in a given counterfactual statement. During the SemEval-2020\nofficial evaluation period, we received 27 submissions to Subtask-1 and 11 to\nSubtask-2. The data, baseline code, and leaderboard can be found at\nhttps://competitions.codalab.org/competitions/21691. The data and baseline code\nare also available at https://zenodo.org/record/3932442.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 20:32:19 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Yang", "Xiaoyu", ""], ["Obadinma", "Stephen", ""], ["Zhao", "Huasha", ""], ["Zhang", "Qiong", ""], ["Matwin", "Stan", ""], ["Zhu", "Xiaodan", ""]]}, {"id": "2008.00620", "submitter": "Ahmed Hussen Abdelaziz", "authors": "Ahmed Hussen Abdelaziz, Anushree Prasanna Kumar, Chloe Seivwright,\n  Gabriele Fanelli, Justin Binder, Yannis Stylianou, Sachin Kajarekar", "title": "Audiovisual Speech Synthesis using Tacotron2", "comments": "This work has been submitted to the IEEE transactions on Multimedia\n  for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audiovisual speech synthesis is the problem of synthesizing a talking face\nwhile maximizing the coherency of the acoustic and visual speech. In this\npaper, we propose and compare two audiovisual speech synthesis systems for 3D\nface models. The first system is the AVTacotron2, which is an end-to-end\ntext-to-audiovisual speech synthesizer based on the Tacotron2 architecture.\nAVTacotron2 converts a sequence of phonemes representing the sentence to\nsynthesize into a sequence of acoustic features and the corresponding\ncontrollers of a face model. The output acoustic features are used to condition\na WaveRNN to reconstruct the speech waveform, and the output facial controllers\nare used to generate the corresponding video of the talking face. The second\naudiovisual speech synthesis system is modular, where acoustic speech is\nsynthesized from text using the traditional Tacotron2. The reconstructed\nacoustic speech signal is then used to drive the facial controls of the face\nmodel using an independently trained audio-to-facial-animation neural network.\nWe further condition both the end-to-end and modular approaches on emotion\nembeddings that encode the required prosody to generate emotional audiovisual\nspeech. We analyze the performance of the two systems and compare them to the\nground truth videos using subjective evaluation tests. The end-to-end and\nmodular systems are able to synthesize close to human-like audiovisual speech\nwith mean opinion scores (MOS) of 4.1 and 3.9, respectively, compared to a MOS\nof 4.1 for the ground truth generated from professionally recorded videos.\nWhile the end-to-end system gives a better overall quality, the modular\napproach is more flexible and the quality of acoustic speech and visual speech\nsynthesis is almost independent of each other.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 02:45:06 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Abdelaziz", "Ahmed Hussen", ""], ["Kumar", "Anushree Prasanna", ""], ["Seivwright", "Chloe", ""], ["Fanelli", "Gabriele", ""], ["Binder", "Justin", ""], ["Stylianou", "Yannis", ""], ["Kajarekar", "Sachin", ""]]}, {"id": "2008.00623", "submitter": "Sachin Mehta", "authors": "Sachin Mehta, Marjan Ghazvininejad, Srinivasan Iyer, Luke Zettlemoyer,\n  Hannaneh Hajishirzi", "title": "DeLighT: Deep and Light-weight Transformer", "comments": "Accepted at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a deep and light-weight transformer, DeLighT, that delivers\nsimilar or better performance than standard transformer-based models with\nsignificantly fewer parameters. DeLighT more efficiently allocates parameters\nboth (1) within each Transformer block using the DeLighT transformation, a deep\nand light-weight transformation, and (2) across blocks using block-wise\nscaling, which allows for shallower and narrower DeLighT blocks near the input\nand wider and deeper DeLighT blocks near the output. Overall, DeLighT networks\nare 2.5 to 4 times deeper than standard transformer models and yet have fewer\nparameters and operations. Experiments on benchmark machine translation and\nlanguage modeling tasks show that DeLighT matches or improves the performance\nof baseline Transformers with 2 to 3 times fewer parameters on average. Our\nsource code is available at: \\url{https://github.com/sacmehta/delight}\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 03:08:29 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 21:30:28 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Mehta", "Sachin", ""], ["Ghazvininejad", "Marjan", ""], ["Iyer", "Srinivasan", ""], ["Zettlemoyer", "Luke", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "2008.00670", "submitter": "Yok Yen Nguwi", "authors": "Shaan Aryaman and Nguwi Yok Yen", "title": "Deep Learning based Topic Analysis on Financial Emerging Event Tweets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Financial analyses of stock markets rely heavily on quantitative approaches\nin an attempt to predict subsequent or market movements based on historical\nprices and other measurable metrics. These quantitative analyses might have\nmissed out on un-quantifiable aspects like sentiment and speculation that also\nimpact the market. Analyzing vast amounts of qualitative text data to\nunderstand public opinion on social media platform is one approach to address\nthis gap. This work carried out topic analysis on 28264 financial tweets [1]\nvia clustering to discover emerging events in the stock market. Three main\ntopics were discovered to be discussed frequently within the period. First, the\nfinancial ratio EPS is a measure that has been discussed frequently by\ninvestors. Secondly, short selling of shares were discussed heavily, it was\noften mentioned together with Morgan Stanley. Thirdly, oil and energy sectors\nwere often discussed together with policy. These tweets were semantically\nclustered by a method consisting of word2vec algorithm to obtain word\nembeddings that map words to vectors. Semantic word clusters were then formed.\nEach tweet was then vectorized using the Term Frequency-Inverse Document\nFrequency (TF-IDF) values of the words it consisted of and based on which\nclusters its words were in. Tweet vectors were then converted to compressed\nrepresentations by training a deep-autoencoder. K-means clusters were then\nformed. This method reduces dimensionality and produces dense vectors, in\ncontrast to the usual Vector Space Model. Topic modelling with Latent Dirichlet\nAllocation (LDA) and top frequent words were used to analyze clusters and\nreveal emerging events.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 06:43:11 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Aryaman", "Shaan", ""], ["Yen", "Nguwi Yok", ""]]}, {"id": "2008.00702", "submitter": "Monica Sunkara", "authors": "Monica Sunkara, Srikanth Ronanki, Dhanush Bekal, Sravan Bodapati,\n  Katrin Kirchhoff", "title": "Multimodal Semi-supervised Learning Framework for Punctuation Prediction\n  in Conversational Speech", "comments": "Accepted for Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we explore a multimodal semi-supervised learning approach for\npunctuation prediction by learning representations from large amounts of\nunlabelled audio and text data. Conventional approaches in speech processing\ntypically use forced alignment to encoder per frame acoustic features to word\nlevel features and perform multimodal fusion of the resulting acoustic and\nlexical representations. As an alternative, we explore attention based\nmultimodal fusion and compare its performance with forced alignment based\nfusion. Experiments conducted on the Fisher corpus show that our proposed\napproach achieves ~6-9% and ~3-4% absolute improvement (F1 score) over the\nbaseline BLSTM model on reference transcripts and ASR outputs respectively. We\nfurther improve the model robustness to ASR errors by performing data\naugmentation with N-best lists which achieves up to an additional ~2-6%\nimprovement on ASR outputs. We also demonstrate the effectiveness of\nsemi-supervised learning approach by performing ablation study on various sizes\nof the corpus. When trained on 1 hour of speech and text data, the proposed\nmodel achieved ~9-18% absolute improvement over baseline model.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 08:13:09 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Sunkara", "Monica", ""], ["Ronanki", "Srikanth", ""], ["Bekal", "Dhanush", ""], ["Bodapati", "Sravan", ""], ["Kirchhoff", "Katrin", ""]]}, {"id": "2008.00731", "submitter": "Okko R\\\"as\\\"anen", "authors": "Okko R\\\"as\\\"anen and Mar\\'ia Andrea Cruz Bland\\'on", "title": "Unsupervised Discovery of Recurring Speech Patterns Using Probabilistic\n  Adaptive Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised spoken term discovery (UTD) aims at finding recurring segments\nof speech from a corpus of acoustic speech data. One potential approach to this\nproblem is to use dynamic time warping (DTW) to find well-aligning patterns\nfrom the speech data. However, automatic selection of initial candidate\nsegments for the DTW-alignment and detection of \"sufficiently good\" alignments\namong those require some type of pre-defined criteria, often operationalized as\nthreshold parameters for pair-wise distance metrics between signal\nrepresentations. In the existing UTD systems, the optimal hyperparameters may\ndiffer across datasets, limiting their applicability to new corpora and truly\nlow-resource scenarios. In this paper, we propose a novel probabilistic\napproach to DTW-based UTD named as PDTW. In PDTW, distributional\ncharacteristics of the processed corpus are utilized for adaptive evaluation of\nalignment quality, thereby enabling systematic discovery of pattern pairs that\nhave similarity what would be expected by coincidence. We test PDTW on Zero\nResource Speech Challenge 2017 datasets as a part of 2020 implementation of the\nchallenge. The results show that the system performs consistently on all five\ntested languages using fixed hyperparameters, clearly outperforming the earlier\nDTW-based system in terms of coverage of the detected patterns.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 09:09:12 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["R\u00e4s\u00e4nen", "Okko", ""], ["Bland\u00f3n", "Mar\u00eda Andrea Cruz", ""]]}, {"id": "2008.00768", "submitter": "Tom\\'a\\v{s} Nekvinda", "authors": "Tom\\'a\\v{s} Nekvinda and Ond\\v{r}ej Du\\v{s}ek", "title": "One Model, Many Languages: Meta-learning for Multilingual Text-to-Speech", "comments": "Accepted to INTERSPEECH 2020; for the source files, see\n  https://github.com/Tomiinek/Multilingual_Text_to_Speech", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an approach to multilingual speech synthesis which uses the\nmeta-learning concept of contextual parameter generation and produces\nnatural-sounding multilingual speech using more languages and less training\ndata than previous approaches. Our model is based on Tacotron 2 with a fully\nconvolutional input text encoder whose weights are predicted by a separate\nparameter generator network. To boost voice cloning, the model uses an\nadversarial speaker classifier with a gradient reversal layer that removes\nspeaker-specific information from the encoder.\n  We arranged two experiments to compare our model with baselines using various\nlevels of cross-lingual parameter sharing, in order to evaluate: (1) stability\nand performance when training on low amounts of data, (2) pronunciation\naccuracy and voice quality of code-switching synthesis. For training, we used\nthe CSS10 dataset and our new small dataset based on Common Voice recordings in\nfive languages. Our model is shown to effectively share information across\nlanguages and according to a subjective evaluation test, it produces more\nnatural and accurate code-switching speech than the baselines.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 10:43:30 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Nekvinda", "Tom\u00e1\u0161", ""], ["Du\u0161ek", "Ond\u0159ej", ""]]}, {"id": "2008.00774", "submitter": "Daniel Kershaw", "authors": "Daniel Kershaw and Rob Koeling", "title": "Elsevier OA CC-By Corpus", "comments": "6 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Elsevier OA CC-BY corpus. This is the first open corpus of\nScientific Research papers which has a representative sample from across\nscientific disciplines. This corpus not only includes the full text of the\narticle, but also the metadata of the documents, along with the bibliographic\ninformation for each reference.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 10:51:10 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 17:47:41 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2020 09:39:13 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Kershaw", "Daniel", ""], ["Koeling", "Rob", ""]]}, {"id": "2008.00791", "submitter": "Shahan Ali Memon", "authors": "Shahan Ali Memon and Kathleen M. Carley", "title": "Characterizing COVID-19 Misinformation Communities Using a Novel Twitter\n  Dataset", "comments": "9 pages, In Proceedings of The 5th International Workshop on Mining\n  Actionable Insights from Social Networks (MAISoN 2020), co-located with CIKM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From conspiracy theories to fake cures and fake treatments, COVID-19 has\nbecome a hot-bed for the spread of misinformation online. It is more important\nthan ever to identify methods to debunk and correct false information online.\nIn this paper, we present a methodology and analyses to characterize the two\ncompeting COVID-19 misinformation communities online: (i) misinformed users or\nusers who are actively posting misinformation, and (ii) informed users or users\nwho are actively spreading true information, or calling out misinformation. The\ngoals of this study are two-fold: (i) collecting a diverse set of annotated\nCOVID-19 Twitter dataset that can be used by the research community to conduct\nmeaningful analysis; and (ii) characterizing the two target communities in\nterms of their network structure, linguistic patterns, and their membership in\nother communities. Our analyses show that COVID-19 misinformed communities are\ndenser, and more organized than informed communities, with a possibility of a\nhigh volume of the misinformation being part of disinformation campaigns. Our\nanalyses also suggest that a large majority of misinformed users may be\nanti-vaxxers. Finally, our sociolinguistic analyses suggest that COVID-19\ninformed users tend to use more narratives than misinformed users.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 11:44:22 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 22:34:33 GMT"}, {"version": "v3", "created": "Mon, 31 Aug 2020 14:36:01 GMT"}, {"version": "v4", "created": "Sat, 19 Sep 2020 07:11:39 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Memon", "Shahan Ali", ""], ["Carley", "Kathleen M.", ""]]}, {"id": "2008.00805", "submitter": "Emily Ohman", "authors": "Marc P\\`amies, Emily \\\"Ohman, Kaisla Kajava, J\\\"org Tiedemann", "title": "LT@Helsinki at SemEval-2020 Task 12: Multilingual or language-specific\n  BERT?", "comments": "Accepted at SemEval-2020 Task 12. Identical to camera-ready version\n  except where adjustments to fit arXiv requirements were necessary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents the different models submitted by the LT@Helsinki team\nfor the SemEval 2020 Shared Task 12. Our team participated in sub-tasks A and\nC; titled offensive language identification and offense target identification,\nrespectively. In both cases we used the so-called Bidirectional Encoder\nRepresentation from Transformer (BERT), a model pre-trained by Google and\nfine-tuned by us on the OLID and SOLID datasets. The results show that\noffensive tweet classification is one of several language-based tasks where\nBERT can achieve state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 12:03:17 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["P\u00e0mies", "Marc", ""], ["\u00d6hman", "Emily", ""], ["Kajava", "Kaisla", ""], ["Tiedemann", "J\u00f6rg", ""]]}, {"id": "2008.00842", "submitter": "Paris Carbone", "authors": "Marios Fragkoulis, Paris Carbone, Vasiliki Kalavri, Asterios\n  Katsifodimos", "title": "A Survey on the Evolution of Stream Processing Systems", "comments": "34 pages, 15 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CL cs.DB cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stream processing has been an active research field for more than 20 years,\nbut it is now witnessing its prime time due to recent successful efforts by the\nresearch community and numerous worldwide open-source communities. This survey\nprovides a comprehensive overview of fundamental aspects of stream processing\nsystems and their evolution in the functional areas of out-of-order data\nmanagement, state management, fault tolerance, high availability, load\nmanagement, elasticity, and reconfiguration. We review noteworthy past research\nfindings, outline the similarities and differences between early ('00-'10) and\nmodern ('11-'18) streaming systems, and discuss recent trends and open\nproblems.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 12:43:46 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Fragkoulis", "Marios", ""], ["Carbone", "Paris", ""], ["Kalavri", "Vasiliki", ""], ["Katsifodimos", "Asterios", ""]]}, {"id": "2008.00853", "submitter": "Tristan Miller", "authors": "Tristan Miller, Erik-L\\^an Do Dinh, Edwin Simpson and Iryna Gurevych", "title": "Predicting the Humorousness of Tweets Using Gaussian Process Preference\n  Learning", "comments": "8 pages, 1 figure. A previous version of this paper was published as\n  \"OFAI-UKP at HAHA@IberLEF2019: Predicting the Humorousness of Tweets Using\n  Gaussian Process Preference Learning\" in the Proceedings of the Iberian\n  Languages Evaluation Forum (IberLEF 2019), volume 2421 of CEUR Workshop\n  Proceedings, pages 180-190, 2019", "journal-ref": "Procesamiento del Lenguaje Natural, 64:37-44, March 2020", "doi": "10.26342/2020-64-4", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most humour processing systems to date make at best discrete, coarse-grained\ndistinctions between the comical and the conventional, yet such notions are\nbetter conceptualized as a broad spectrum. In this paper, we present a\nprobabilistic approach, a variant of Gaussian process preference learning\n(GPPL), that learns to rank and rate the humorousness of short texts by\nexploiting human preference judgments and automatically sourced linguistic\nannotations. We apply our system, which is similar to one that had previously\nshown good performance on English-language one-liners annotated with pairwise\nhumorousness annotations, to the Spanish-language data set of the\nHAHA@IberLEF2019 evaluation campaign. We report system performance for the\ncampaign's two subtasks, humour detection and funniness score prediction, and\ndiscuss some issues arising from the conversion between the numeric scores used\nin the HAHA@IberLEF2019 data and the pairwise judgment annotations required for\nour method.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 13:05:42 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 20:30:50 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Miller", "Tristan", ""], ["Dinh", "Erik-L\u00e2n Do", ""], ["Simpson", "Edwin", ""], ["Gurevych", "Iryna", ""]]}, {"id": "2008.00920", "submitter": "Jacopo Tagliabue", "authors": "Nicole Fitzgerald and Jacopo Tagliabue", "title": "On The Plurality of Graphs", "comments": "Manuscript accepted at NETREASON @ ECAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct a series of experiments designed to empirically demonstrate the\neffects of varying the structural features of a multi-agent emergent\ncommunication game framework. Specifically, we model the interactions (edges)\nbetween individual agents (nodes)as the structure of a graph generated\naccording to a series of known random graph generating algorithms. Confirming\nthe hypothesis proposed in [10], we show that the two factors of variation\ninduced in this work, namely 1) the graph-generating process and 2) the\ncentrality measure according to which edges are sampled, in fact play a\nsignificant role in determining the dynamics of language emergence within the\npopulation at hand.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 14:54:09 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Fitzgerald", "Nicole", ""], ["Tagliabue", "Jacopo", ""]]}, {"id": "2008.00956", "submitter": "Paul Tarau", "authors": "Paul Tarau and Eduardo Blanco", "title": "Interactive Text Graph Mining with a Prolog-based Dialog Engine", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP). arXiv admin note: substantial text overlap with arXiv:1909.09742", "journal-ref": "Theory and Practice of Logic Programming 21 (2021) 244-263", "doi": "10.1017/S1471068420000137", "report-no": null, "categories": "cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On top of a neural network-based dependency parser and a graph-based natural\nlanguage processing module we design a Prolog-based dialog engine that explores\ninteractively a ranked fact database extracted from a text document.\n  We reorganize dependency graphs to focus on the most relevant content\nelements of a sentence and integrate sentence identifiers as graph nodes.\n  Additionally, after ranking the graph we take advantage of the implicit\nsemantic information that dependency links and WordNet bring in the form of\nsubject-verb-object, is-a and part-of relations.\n  Working on the Prolog facts and their inferred consequences, the dialog\nengine specializes the text graph with respect to a query and reveals\ninteractively the document's most relevant content elements.\n  The open-source code of the integrated system is available at\nhttps://github.com/ptarau/DeepRank .\n  Under consideration in Theory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 03:29:49 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Tarau", "Paul", ""], ["Blanco", "Eduardo", ""]]}, {"id": "2008.01297", "submitter": "Abhinava Sikdar", "authors": "Abhinava Sikdar, Niladri Chatterjee", "title": "An improved Bayesian TRIE based model for SMS text normalization", "comments": "7 pages, 8 figures, under review at Pattern Recognition Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalization of SMS text, commonly known as texting language, is being\npursued for more than a decade. A probabilistic approach based on the Trie data\nstructure was proposed in literature which was found to be better performing\nthan HMM based approaches proposed earlier in predicting the correct\nalternative for an out-of-lexicon word. However, success of the Trie based\napproach depends largely on how correctly the underlying probabilities of word\noccurrences are estimated. In this work we propose a structural modification to\nthe existing Trie-based model along with a novel training algorithm and\nprobability generation scheme. We prove two theorems on statistical properties\nof the proposed Trie and use them to claim that is an unbiased and consistent\nestimator of the occurrence probabilities of the words. We further fuse our\nmodel into the paradigm of noisy channel based error correction and provide a\nheuristic to go beyond a Damerau Levenshtein distance of one. We also run\nsimulations to support our claims and show superiority of the proposed scheme\nover previous works.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 03:01:23 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 17:19:31 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Sikdar", "Abhinava", ""], ["Chatterjee", "Niladri", ""]]}, {"id": "2008.01300", "submitter": "Chengyu Wang", "authors": "Mengli Cheng, Chengyu Wang, Xu Hu, Jun Huang, Xiaobo Wang", "title": "Weakly Supervised Construction of ASR Systems with Massive Video Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building Automatic Speech Recognition (ASR) systems from scratch is\nsignificantly challenging, mostly due to the time-consuming and\nfinancially-expensive process of annotating a large amount of audio data with\ntranscripts. Although several unsupervised pre-training models have been\nproposed, applying such models directly might still be sub-optimal if more\nlabeled, training data could be obtained without a large cost. In this paper,\nwe present a weakly supervised framework for constructing ASR systems with\nmassive video data. As videos often contain human-speech audios aligned with\nsubtitles, we consider videos as an important knowledge source, and propose an\neffective approach to extract high-quality audios aligned with transcripts from\nvideos based on Optical Character Recognition (OCR). The underlying ASR model\ncan be fine-tuned to fit any domain-specific target training datasets after\nweakly supervised pre-training. Extensive experiments show that our framework\ncan easily produce state-of-the-art results on six public datasets for Mandarin\nspeech recognition.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 03:11:32 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 07:22:35 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Cheng", "Mengli", ""], ["Wang", "Chengyu", ""], ["Hu", "Xu", ""], ["Huang", "Jun", ""], ["Wang", "Xiaobo", ""]]}, {"id": "2008.01354", "submitter": "Chan Young Park", "authors": "Hwijeen Ahn and Jimin Sun and Chan Young Park and Jungyun Seo", "title": "NLPDove at SemEval-2020 Task 12: Improving Offensive Language Detection\n  with Cross-lingual Transfer", "comments": "To be published in SemEval-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes our approach to the task of identifying offensive\nlanguages in a multilingual setting. We investigate two data augmentation\nstrategies: using additional semi-supervised labels with different thresholds\nand cross-lingual transfer with data selection. Leveraging the semi-supervised\ndataset resulted in performance improvements compared to the baseline trained\nsolely with the manually-annotated dataset. We propose a new metric,\nTranslation Embedding Distance, to measure the transferability of instances for\ncross-lingual data selection. We also introduce various preprocessing steps\ntailored for social media text along with methods to fine-tune the pre-trained\nmultilingual BERT (mBERT) for offensive language identification. Our\nmultilingual systems achieved competitive results in Greek, Danish, and Turkish\nat OffensEval 2020.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 06:20:50 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Ahn", "Hwijeen", ""], ["Sun", "Jimin", ""], ["Park", "Chan Young", ""], ["Seo", "Jungyun", ""]]}, {"id": "2008.01377", "submitter": "Stefan Heid", "authors": "Stefan Heid, Marcel Wever, Eyke H\\\"ullermeier", "title": "Reliable Part-of-Speech Tagging of Historical Corpora through Set-Valued\n  Prediction", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Syntactic annotation of corpora in the form of part-of-speech (POS) tags is a\nkey requirement for both linguistic research and subsequent automated natural\nlanguage processing (NLP) tasks. This problem is commonly tackled using machine\nlearning methods, i.e., by training a POS tagger on a sufficiently large corpus\nof labeled data. While the problem of POS tagging can essentially be considered\nas solved for modern languages, historical corpora turn out to be much more\ndifficult, especially due to the lack of native speakers and sparsity of\ntraining data. Moreover, most texts have no sentences as we know them today,\nnor a common orthography. These irregularities render the task of automated POS\ntagging more difficult and error-prone. Under these circumstances, instead of\nforcing the POS tagger to predict and commit to a single tag, it should be\nenabled to express its uncertainty. In this paper, we consider POS tagging\nwithin the framework of set-valued prediction, which allows the POS tagger to\nexpress its uncertainty via predicting a set of candidate POS tags instead of\nguessing a single one. The goal is to guarantee a high confidence that the\ncorrect POS tag is included while keeping the number of candidates small. In\nour experimental study, we find that extending state-of-the-art POS taggers to\nset-valued prediction yields more precise and robust taggings, especially for\nunknown words, i.e., words not occurring in the training data.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 07:21:36 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 12:59:57 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Heid", "Stefan", ""], ["Wever", "Marcel", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "2008.01391", "submitter": "Bharathi Raja Chakravarthi", "authors": "Bharathi Raja Chakravarthi, Priya Rani, Mihael Arcan and John P.\n  McCrae", "title": "A Survey of Orthographic Information in Machine Translation", "comments": "18 pages", "journal-ref": "SN Computer Science (2021) 2:330", "doi": "10.1007/s42979-021-00723-4", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine translation is one of the applications of natural language processing\nwhich has been explored in different languages. Recently researchers started\npaying attention towards machine translation for resource-poor languages and\nclosely related languages. A widespread and underlying problem for these\nmachine translation systems is the variation in orthographic conventions which\ncauses many issues to traditional approaches. Two languages written in two\ndifferent orthographies are not easily comparable, but orthographic information\ncan also be used to improve the machine translation system. This article offers\na survey of research regarding orthography's influence on machine translation\nof under-resourced languages. It introduces under-resourced languages in terms\nof machine translation and how orthographic information can be utilised to\nimprove machine translation. We describe previous work in this area, discussing\nwhat underlying assumptions were made, and showing how orthographic knowledge\nimproves the performance of machine translation of under-resourced languages.\nWe discuss different types of machine translation and demonstrate a recent\ntrend that seeks to link orthographic information with well-established machine\ntranslation methods. Considerable attention is given to current efforts of\ncognates information at different levels of machine translation and the lessons\nthat can be drawn from this. Additionally, multilingual neural machine\ntranslation of closely related languages is given a particular focus in this\nsurvey. This article ends with a discussion of the way forward in machine\ntranslation with orthographic information, focusing on multilingual settings\nand bilingual lexicon induction.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 07:59:02 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Chakravarthi", "Bharathi Raja", ""], ["Rani", "Priya", ""], ["Arcan", "Mihael", ""], ["McCrae", "John P.", ""]]}, {"id": "2008.01441", "submitter": "Robert Ridley", "authors": "Robert Ridley, Liang He, Xinyu Dai, Shujian Huang, Jiajun Chen", "title": "Prompt Agnostic Essay Scorer: A Domain Generalization Approach to\n  Cross-prompt Automated Essay Scoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-prompt automated essay scoring (AES) requires the system to use non\ntarget-prompt essays to award scores to a target-prompt essay. Since obtaining\na large quantity of pre-graded essays to a particular prompt is often difficult\nand unrealistic, the task of cross-prompt AES is vital for the development of\nreal-world AES systems, yet it remains an under-explored area of research.\nModels designed for prompt-specific AES rely heavily on prompt-specific\nknowledge and perform poorly in the cross-prompt setting, whereas current\napproaches to cross-prompt AES either require a certain quantity of labelled\ntarget-prompt essays or require a large quantity of unlabelled target-prompt\nessays to perform transfer learning in a multi-step manner. To address these\nissues, we introduce Prompt Agnostic Essay Scorer (PAES) for cross-prompt AES.\nOur method requires no access to labelled or unlabelled target-prompt data\nduring training and is a single-stage approach. PAES is easy to apply in\npractice and achieves state-of-the-art performance on the Automated Student\nAssessment Prize (ASAP) dataset.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 10:17:38 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Ridley", "Robert", ""], ["He", "Liang", ""], ["Dai", "Xinyu", ""], ["Huang", "Shujian", ""], ["Chen", "Jiajun", ""]]}, {"id": "2008.01466", "submitter": "Chen Xing", "authors": "Qiyu Wu, Chen Xing, Yatao Li, Guolin Ke, Di He, Tie-Yan Liu", "title": "Taking Notes on the Fly Helps BERT Pre-training", "comments": "Qiyu Wu and Chen Xing contribute equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to make unsupervised language pre-training more efficient and less\nresource-intensive is an important research direction in NLP. In this paper, we\nfocus on improving the efficiency of language pre-training methods through\nproviding better data utilization. It is well-known that in language data\ncorpus, words follow a heavy-tail distribution. A large proportion of words\nappear only very few times and the embeddings of rare words are usually poorly\noptimized. We argue that such embeddings carry inadequate semantic signals,\nwhich could make the data utilization inefficient and slow down the\npre-training of the entire model. To mitigate this problem, we propose Taking\nNotes on the Fly (TNF), which takes notes for rare words on the fly during\npre-training to help the model understand them when they occur next time.\nSpecifically, TNF maintains a note dictionary and saves a rare word's\ncontextual information in it as notes when the rare word occurs in a sentence.\nWhen the same rare word occurs again during training, the note information\nsaved beforehand can be employed to enhance the semantics of the current\nsentence. By doing so, TNF provides better data utilization since\ncross-sentence information is employed to cover the inadequate semantics caused\nby rare words in the sentences. We implement TNF on both BERT and ELECTRA to\ncheck its efficiency and effectiveness. Experimental results show that TNF's\ntraining time is $60\\%$ less than its backbone pre-training models when\nreaching the same performance. When trained with the same number of iterations,\nTNF outperforms its backbone methods on most of downstream tasks and the\naverage GLUE score. Source code is attached in the supplementary material.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 11:25:09 GMT"}, {"version": "v2", "created": "Sun, 14 Mar 2021 15:37:11 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Wu", "Qiyu", ""], ["Xing", "Chen", ""], ["Li", "Yatao", ""], ["Ke", "Guolin", ""], ["He", "Di", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2008.01474", "submitter": "Mengzuo Huang", "authors": "Mengzuo Huang, Feng Li, Wuhe Zou and Weidong Zhang", "title": "SARG: A Novel Semi Autoregressive Generator for Multi-turn Incomplete\n  Utterance Restoration", "comments": "Accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue systems in open domain have achieved great success due to the easily\nobtained single-turn corpus and the development of deep learning, but the\nmulti-turn scenario is still a challenge because of the frequent coreference\nand information omission. In this paper, we investigate the incomplete\nutterance restoration which has brought general improvement over multi-turn\ndialogue systems in recent studies. Meanwhile, jointly inspired by the\nautoregression for text generation and the sequence labeling for text editing,\nwe propose a novel semi autoregressive generator (SARG) with the high\nefficiency and flexibility. Moreover, experiments on two benchmarks show that\nour proposed model significantly outperforms the state-of-the-art models in\nterms of quality and inference speed.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 11:52:20 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 08:31:34 GMT"}, {"version": "v3", "created": "Mon, 21 Dec 2020 03:10:17 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Huang", "Mengzuo", ""], ["Li", "Feng", ""], ["Zou", "Wuhe", ""], ["Zhang", "Weidong", ""]]}, {"id": "2008.01504", "submitter": "Arseniy Gorin", "authors": "Arseniy Gorin, Daniil Kulko, Steven Grima, Alex Glasman", "title": "\"This is Houston. Say again, please\". The Behavox system for the\n  Apollo-11 Fearless Steps Challenge (phase II)", "comments": "Accepted to Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe the speech activity detection (SAD), speaker diarization (SD),\nand automatic speech recognition (ASR) experiments conducted by the Behavox\nteam for the Interspeech 2020 Fearless Steps Challenge (FSC-2). A relatively\nsmall amount of labeled data, a large variety of speakers and channel\ndistortions, specific lexicon and speaking style resulted in high error rates\non the systems which involved this data. In addition to approximately 36 hours\nof annotated NASA mission recordings, the organizers provided a much larger but\nunlabeled 19k hour Apollo-11 corpus that we also explore for semi-supervised\ntraining of ASR acoustic and language models, observing more than 17% relative\nword error rate improvement compared to training on the FSC-2 data only. We\nalso compare several SAD and SD systems to approach the most difficult tracks\nof the challenge (track 1 for diarization and ASR), where long 30-minute audio\nrecordings are provided for evaluation without segmentation or speaker\ninformation. For all systems, we report substantial performance improvements\ncompared to the FSC-2 baseline systems, and achieved a first-place ranking for\nSD and ASR and fourth-place for SAD in the challenge.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 13:18:28 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Gorin", "Arseniy", ""], ["Kulko", "Daniil", ""], ["Grima", "Steven", ""], ["Glasman", "Alex", ""]]}, {"id": "2008.01515", "submitter": "Arthur Reys", "authors": "Arthur D. Reys, Danilo Silva, Daniel Severo, Saulo Pedro, Marcia M. de\n  Souza e S\\'a, Guilherme A. C. Salgado", "title": "Predicting Multiple ICD-10 Codes from Brazilian-Portuguese Clinical\n  Notes", "comments": "Accepted at BRACIS 2020", "journal-ref": null, "doi": "10.1007/978-3-030-61377-8_39", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ICD coding from electronic clinical records is a manual, time-consuming and\nexpensive process. Code assignment is, however, an important task for billing\npurposes and database organization. While many works have studied the problem\nof automated ICD coding from free text using machine learning techniques, most\nuse records in the English language, especially from the MIMIC-III public\ndataset. This work presents results for a dataset with Brazilian Portuguese\nclinical notes. We develop and optimize a Logistic Regression model, a\nConvolutional Neural Network (CNN), a Gated Recurrent Unit Neural Network and a\nCNN with Attention (CNN-Att) for prediction of diagnosis ICD codes. We also\nreport our results for the MIMIC-III dataset, which outperform previous work\namong models of the same families, as well as the state of the art. Compared to\nMIMIC-III, the Brazilian Portuguese dataset contains far fewer words per\ndocument, when only discharge summaries are used. We experiment concatenating\nadditional documents available in this dataset, achieving a great boost in\nperformance. The CNN-Att model achieves the best results on both datasets, with\nmicro-averaged F1 score of 0.537 on MIMIC-III and 0.485 on our dataset with\nadditional documents.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 22:12:26 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Reys", "Arthur D.", ""], ["Silva", "Danilo", ""], ["Severo", "Daniel", ""], ["Pedro", "Saulo", ""], ["S\u00e1", "Marcia M. de Souza e", ""], ["Salgado", "Guilherme A. C.", ""]]}, {"id": "2008.01523", "submitter": "Haiyue Song", "authors": "Akiko Aizawa, Frederic Bergeron, Junjie Chen, Fei Cheng, Katsuhiko\n  Hayashi, Kentaro Inui, Hiroyoshi Ito, Daisuke Kawahara, Masaru Kitsuregawa,\n  Hirokazu Kiyomaru, Masaki Kobayashi, Takashi Kodama, Sadao Kurohashi,\n  Qianying Liu, Masaki Matsubara, Yusuke Miyao, Atsuyuki Morishima, Yugo\n  Murawaki, Kazumasa Omura, Haiyue Song, Eiichiro Sumita, Shinji Suzuki, Ribeka\n  Tanaka, Yu Tanaka, Masashi Toyoda, Nobuhiro Ueda, Honai Ueoka, Masao Utiyama,\n  Ying Zhong", "title": "A System for Worldwide COVID-19 Information Aggregation", "comments": "Accepted to EMNLP 2020 Workshop NLP-COVID", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The global pandemic of COVID-19 has made the public pay close attention to\nrelated news, covering various domains, such as sanitation, treatment, and\neffects on education. Meanwhile, the COVID-19 condition is very different among\nthe countries (e.g., policies and development of the epidemic), and thus\ncitizens would be interested in news in foreign countries. We build a system\nfor worldwide COVID-19 information aggregation containing reliable articles\nfrom 10 regions in 7 languages sorted by topics. Our reliable COVID-19 related\nwebsite dataset collected through crowdsourcing ensures the quality of the\narticles. A neural machine translation module translates articles in other\nlanguages into Japanese and English. A BERT-based topic-classifier trained on\nour article-topic pair dataset helps users find their interested information\nefficiently by putting articles into different categories.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 01:33:54 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 05:36:36 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Aizawa", "Akiko", ""], ["Bergeron", "Frederic", ""], ["Chen", "Junjie", ""], ["Cheng", "Fei", ""], ["Hayashi", "Katsuhiko", ""], ["Inui", "Kentaro", ""], ["Ito", "Hiroyoshi", ""], ["Kawahara", "Daisuke", ""], ["Kitsuregawa", "Masaru", ""], ["Kiyomaru", "Hirokazu", ""], ["Kobayashi", "Masaki", ""], ["Kodama", "Takashi", ""], ["Kurohashi", "Sadao", ""], ["Liu", "Qianying", ""], ["Matsubara", "Masaki", ""], ["Miyao", "Yusuke", ""], ["Morishima", "Atsuyuki", ""], ["Murawaki", "Yugo", ""], ["Omura", "Kazumasa", ""], ["Song", "Haiyue", ""], ["Sumita", "Eiichiro", ""], ["Suzuki", "Shinji", ""], ["Tanaka", "Ribeka", ""], ["Tanaka", "Yu", ""], ["Toyoda", "Masashi", ""], ["Ueda", "Nobuhiro", ""], ["Ueoka", "Honai", ""], ["Utiyama", "Masao", ""], ["Zhong", "Ying", ""]]}, {"id": "2008.01526", "submitter": "Samarth Rawal", "authors": "Samarth Rawal", "title": "Multi-Perspective Semantic Information Retrieval in the Biomedical\n  Domain", "comments": "Masters thesis, Arizona State Univ (May, 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information Retrieval (IR) is the task of obtaining pieces of data (such as\ndocuments) that are relevant to a particular query or need from a large\nrepository of information. IR is a valuable component of several downstream\nNatural Language Processing (NLP) tasks. Practically, IR is at the heart of\nmany widely-used technologies like search engines. While probabilistic ranking\nfunctions like the Okapi BM25 function have been utilized in IR systems since\nthe 1970's, modern neural approaches pose certain advantages compared to their\nclassical counterparts. In particular, the release of BERT (Bidirectional\nEncoder Representations from Transformers) has had a significant impact in the\nNLP community by demonstrating how the use of a Masked Language Model trained\non a large corpus of data can improve a variety of downstream NLP tasks,\nincluding sentence classification and passage re-ranking. IR Systems are also\nimportant in the biomedical and clinical domains. Given the increasing amount\nof scientific literature across biomedical domain, the ability find answers to\nspecific clinical queries from a repository of millions of articles is a matter\nof practical value to medical professionals. Moreover, there are\ndomain-specific challenges present, including handling clinical jargon and\nevaluating the similarity or relatedness of various medical symptoms when\ndetermining the relevance between a query and a sentence. This work presents\ncontributions to several aspects of the Biomedical Semantic Information\nRetrieval domain. First, it introduces Multi-Perspective Sentence Relevance, a\nnovel methodology of utilizing BERT-based models for contextual IR. The system\nis evaluated using the BioASQ Biomedical IR Challenge. Finally, practical\ncontributions in the form of a live IR system for medics and a proposed\nchallenge on the Living Systematic Review clinical task are provided.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 21:05:44 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Rawal", "Samarth", ""]]}, {"id": "2008.01532", "submitter": "Qi Liu", "authors": "Qi Liu, Lijuan Wang, Qiang Huo", "title": "A Study on Effects of Implicit and Explicit Language Model Information\n  for DBLSTM-CTC Based Handwriting Recognition", "comments": "Accepted by ICDAR-2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Bidirectional Long Short-Term Memory (D-BLSTM) with a Connectionist\nTemporal Classification (CTC) output layer has been established as one of the\nstate-of-the-art solutions for handwriting recognition. It is well known that\nthe DBLSTM trained by using a CTC objective function will learn both local\ncharacter image dependency for character modeling and long-range contextual\ndependency for implicit language modeling. In this paper, we study the effects\nof implicit and explicit language model information for DBLSTM-CTC based\nhandwriting recognition by comparing the performance of using or without using\nan explicit language model in decoding. It is observed that even using one\nmillion lines of training sentences to train the DBLSTM, using an explicit\nlanguage model is still helpful. To deal with such a large-scale training\nproblem, a GPU-based training tool has been developed for CTC training of\nDBLSTM by using a mini-batch based epochwise Back Propagation Through Time\n(BPTT) algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 08:23:37 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Liu", "Qi", ""], ["Wang", "Lijuan", ""], ["Huo", "Qiang", ""]]}, {"id": "2008.01533", "submitter": "Fernando Alonso-Fernandez", "authors": "Fernando Alonso-Fernandez, Nicole Mariah Sharon Belvisi, Kevin\n  Hernandez-Diaz, Naveed Muhammad, Josef Bigun", "title": "Writer Identification Using Microblogging Texts for Social Media\n  Forensics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Establishing authorship of online texts is fundamental to combat cybercrimes.\nUnfortunately, text length is limited on some platforms, making the challenge\nharder. We aim at identifying the authorship of Twitter messages limited to 140\ncharacters. We evaluate popular stylometric features, widely used in literary\nanalysis, and specific Twitter features like URLs, hashtags, replies or quotes.\nWe use two databases with 93 and 3957 authors, respectively. We test varying\nsized author sets and varying amounts of training/test texts per author.\nPerformance is further improved by feature combination via automatic selection.\nWith a large number of training Tweets (>500), a good accuracy (Rank-5>80%) is\nachievable with only a few dozens of test Tweets, even with several thousands\nof authors. With smaller sample sizes (10-20 training Tweets), the search space\ncan be diminished by 9-15% while keeping a high chance that the correct author\nis retrieved among the candidates. In such cases, automatic attribution can\nprovide significant time savings to experts in suspect search. For\ncompleteness, we report verification results. With few training/test Tweets,\nthe EER is above 20-25%, which is reduced to < 15% if hundreds of training\nTweets are available. We also quantify the computational complexity and time\npermanence of the employed features.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 00:23:18 GMT"}, {"version": "v2", "created": "Sat, 6 Mar 2021 02:42:18 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Alonso-Fernandez", "Fernando", ""], ["Belvisi", "Nicole Mariah Sharon", ""], ["Hernandez-Diaz", "Kevin", ""], ["Muhammad", "Naveed", ""], ["Bigun", "Josef", ""]]}, {"id": "2008.01535", "submitter": "Kwadwo Osei Bonsu", "authors": "Kwadwo Osei Bonsu", "title": "Weighted Accuracy Algorithmic Approach In Counteracting Fake News And\n  Disinformation", "comments": null, "journal-ref": null, "doi": "10.2478/ers-2021-0007", "report-no": null, "categories": "cs.CL cs.SI econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the world is becoming more dependent on the internet for information\nexchange, some overzealous journalists, hackers, bloggers, individuals and\norganizations tend to abuse the gift of free information environment by\npolluting it with fake news, disinformation and pretentious content for their\nown agenda. Hence, there is the need to address the issue of fake news and\ndisinformation with utmost seriousness. This paper proposes a methodology for\nfake news detection and reporting through a constraint mechanism that utilizes\nthe combined weighted accuracies of four machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 08:56:51 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 01:53:01 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Bonsu", "Kwadwo Osei", ""]]}, {"id": "2008.01543", "submitter": "Joppe Wouts", "authors": "Joppe Valentijn Wouts", "title": "Text-based classification of interviews for mental health -- juxtaposing\n  the state of the art", "comments": "33 pages, 7 figures, belabBERT is available on\n  http://github.com/Joppewouts/belabBERT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, the state of the art for classification of psychiatric illness is\nbased on audio-based classification. This thesis aims to design and evaluate a\nstate of the art text classification network on this challenge. The hypothesis\nis that a well designed text-based approach poses a strong competition against\nthe state-of-the-art audio based approaches. Dutch natural language models are\nbeing limited by the scarcity of pre-trained monolingual NLP models, as a\nresult Dutch natural language models have a low capture of long range semantic\ndependencies over sentences. For this issue, this thesis presents belabBERT, a\nnew Dutch language model extending the RoBERTa[15] architecture. belabBERT is\ntrained on a large Dutch corpus (+32GB) of web crawled texts. After this thesis\nevaluates the strength of text-based classification, a brief exploration is\ndone, extending the framework to a hybrid text- and audio-based classification.\nThe goal of this hybrid framework is to show the principle of hybridisation\nwith a very basic audio-classification network. The overall goal is to create\nthe foundations for a hybrid psychiatric illness classification, by proving\nthat the new text-based classification is already a strong stand-alone\nsolution.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 16:19:30 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Wouts", "Joppe Valentijn", ""]]}, {"id": "2008.01544", "submitter": "Manoel Verissimo Dos Santos Neto Mvst", "authors": "Manoel Ver\\'issimo dos Santos Neto, Ayrton Denner da Silva Amaral,\n  N\\'adia F\\'elix Felipe da Silva, Anderson da Silva Soares", "title": "Deep Learning Brasil -- NLP at SemEval-2020 Task 9: Overview of\n  Sentiment Analysis of Code-Mixed Tweets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe a methodology to predict sentiment in code-mixed\ntweets (hindi-english). Our team called verissimo.manoel in CodaLab developed\nan approach based on an ensemble of four models (MultiFiT, BERT, ALBERT, and\nXLNET). The final classification algorithm was an ensemble of some predictions\nof all softmax values from these four models. This architecture was used and\nevaluated in the context of the SemEval 2020 challenge (task 9), and our system\ngot 72.7% on the F1 score.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 16:42:41 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Neto", "Manoel Ver\u00edssimo dos Santos", ""], ["Amaral", "Ayrton Denner da Silva", ""], ["da Silva", "N\u00e1dia F\u00e9lix Felipe", ""], ["Soares", "Anderson da Silva", ""]]}, {"id": "2008.01545", "submitter": "Koustava Goswami", "authors": "Koustava Goswami, Priya Rani, Bharathi Raja Chakravarthi, Theodorus\n  Fransen, and John P. McCrae", "title": "ULD@NUIG at SemEval-2020 Task 9: Generative Morphemes with an Attention\n  Model for Sentiment Analysis in Code-Mixed Text", "comments": "To be published in 14th International Workshop on Semantic Evaluation\n  SemEval-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code mixing is a common phenomena in multilingual societies where people\nswitch from one language to another for various reasons. Recent advances in\npublic communication over different social media sites have led to an increase\nin the frequency of code-mixed usage in written language. In this paper, we\npresent the Generative Morphemes with Attention (GenMA) Model sentiment\nanalysis system contributed to SemEval 2020 Task 9 SentiMix. The system aims to\npredict the sentiments of the given English-Hindi code-mixed tweets without\nusing word-level language tags instead inferring this automatically using a\nmorphological model. The system is based on a novel deep neural network (DNN)\narchitecture, which has outperformed the baseline F1-score on the test data-set\nas well as the validation data-set. Our results can be found under the user\nname \"koustava\" on the \"Sentimix Hindi English\" page\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 23:58:54 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Goswami", "Koustava", ""], ["Rani", "Priya", ""], ["Chakravarthi", "Bharathi Raja", ""], ["Fransen", "Theodorus", ""], ["McCrae", "John P.", ""]]}, {"id": "2008.01546", "submitter": "Tarik A. Rashid", "authors": "Hozan K. Hamarashid, Soran A. Saeed and Tarik A. Rashid", "title": "Next word prediction based on the N-gram model for Kurdish Sorani and\n  Kurmanji", "comments": "37 pages", "journal-ref": "Neural Computing and Applications, NCAA-D-19-02773R1, 2020", "doi": "10.1007/s00521-020-05245-3", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Next word prediction is an input technology that simplifies the process of\ntyping by suggesting the next word to a user to select, as typing in a\nconversation consumes time. A few previous studies have focused on the Kurdish\nlanguage, including the use of next word prediction. However, the lack of a\nKurdish text corpus presents a challenge. Moreover, the lack of a sufficient\nnumber of N-grams for the Kurdish language, for instance, five grams, is the\nreason for the rare use of next Kurdish word prediction. Furthermore, the\nimproper display of several Kurdish letters in the Rstudio software is another\nproblem. This paper provides a Kurdish corpus, creates five, and presents a\nunique research work on next word prediction for Kurdish Sorani and Kurmanji.\nThe N-gram model has been used for next word prediction to reduce the amount of\ntime while typing in the Kurdish language. In addition, little work has been\nconducted on next Kurdish word prediction; thus, the N-gram model is utilized\nto suggest text accurately. To do so, R programming and RStudio are used to\nbuild the application. The model is 96.3% accurate.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 20:45:13 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Hamarashid", "Hozan K.", ""], ["Saeed", "Soran A.", ""], ["Rashid", "Tarik A.", ""]]}, {"id": "2008.01547", "submitter": "Shuai Zhang", "authors": "Shuai Zhang, Peng Zhang, Xindian Ma, Junqiu Wei, Ningning Wang, Qun\n  Liu", "title": "TensorCoder: Dimension-Wise Attention via Tensor Representation for\n  Natural Language Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer has been widely-used in many Natural Language Processing (NLP)\ntasks and the scaled dot-product attention between tokens is a core module of\nTransformer. This attention is a token-wise design and its complexity is\nquadratic to the length of sequence, limiting its application potential for\nlong sequence tasks. In this paper, we propose a dimension-wise attention\nmechanism based on which a novel language modeling approach (namely\nTensorCoder) can be developed. The dimension-wise attention can reduce the\nattention complexity from the original $O(N^2d)$ to $O(Nd^2)$, where $N$ is the\nlength of the sequence and $d$ is the dimensionality of head. We verify\nTensorCoder on two tasks including masked language modeling and neural machine\ntranslation. Compared with the original Transformer, TensorCoder not only\ngreatly reduces the calculation of the original model but also obtains improved\nperformance on masked language modeling task (in PTB dataset) and comparable\nperformance on machine translation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 13:42:02 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 11:25:49 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Zhang", "Shuai", ""], ["Zhang", "Peng", ""], ["Ma", "Xindian", ""], ["Wei", "Junqiu", ""], ["Wang", "Ningning", ""], ["Liu", "Qun", ""]]}, {"id": "2008.01548", "submitter": "Catherine Yeo", "authors": "Catherine Yeo and Alyssa Chen", "title": "Defining and Evaluating Fair Natural Language Generation", "comments": "7 pages, 2 figures, to be published in Proceedings of the The Fourth\n  Widening Natural Language Processing Workshop at ACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our work focuses on the biases that emerge in the natural language generation\n(NLG) task of sentence completion. In this paper, we introduce a framework of\nfairness for NLG followed by an evaluation of gender biases in two\nstate-of-the-art language models. Our analysis provides a theoretical\nformulation for biases in NLG and empirical evidence that existing language\ngeneration models embed gender bias.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 04:11:10 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Yeo", "Catherine", ""], ["Chen", "Alyssa", ""]]}, {"id": "2008.01551", "submitter": "Jekaterina Novikova Dr.", "authors": "Aparna Balagopalan, Benjamin Eyre, Frank Rudzicz, Jekaterina Novikova", "title": "To BERT or Not To BERT: Comparing Speech and Language-based Approaches\n  for Alzheimer's Disease Detection", "comments": "accepted to INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research related to automatically detecting Alzheimer's disease (AD) is\nimportant, given the high prevalence of AD and the high cost of traditional\nmethods. Since AD significantly affects the content and acoustics of\nspontaneous speech, natural language processing and machine learning provide\npromising techniques for reliably detecting AD. We compare and contrast the\nperformance of two such approaches for AD detection on the recent ADReSS\nchallenge dataset: 1) using domain knowledge-based hand-crafted features that\ncapture linguistic and acoustic phenomena, and 2) fine-tuning Bidirectional\nEncoder Representations from Transformer (BERT)-based sequence classification\nmodels. We also compare multiple feature-based regression models for a\nneuropsychological score task in the challenge. We observe that fine-tuned BERT\nmodels, given the relative importance of linguistics in cognitive impairment\ndetection, outperform feature-based approaches on the AD detection task.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 04:50:47 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Balagopalan", "Aparna", ""], ["Eyre", "Benjamin", ""], ["Rudzicz", "Frank", ""], ["Novikova", "Jekaterina", ""]]}, {"id": "2008.01555", "submitter": "Ali H\\\"urriyeto\\u{g}lu", "authors": "Ali H\\\"urriyeto\\u{g}lu", "title": "Tense, aspect and mood based event extraction for situation analysis and\n  crisis management", "comments": "Middle East Technical University, Master Thesis, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays event extraction systems mainly deal with a relatively small amount\nof information about temporal and modal qualifications of situations, primarily\nprocessing assertive sentences in the past tense. However, systems with a wider\ncoverage of tense, aspect and mood can provide better analyses and can be used\nin a wider range of text analysis applications. This thesis develops such a\nsystem for Turkish language. This is accomplished by extending Open Source\nInformation Mining and Analysis (OPTIMA) research group's event extraction\nsoftware, by implementing appropriate extensions in the semantic representation\nformat, by adding a partial grammar which improves the TAM (Tense, Aspect and\nMood) marker, adverb analysis and matching functions of ExPRESS, and by\nconstructing an appropriate lexicon in the standard of CORLEONE. These\nextensions are based on iv the theory of anchoring relations (Tem\\\"urc\\\"u,\n2007, 2011) which is a crosslinguistically applicable semantic framework for\nanalyzing tense, aspect and mood related categories. The result is a system\nwhich can, in addition to extracting basic event structures, classify sentences\ngiven in news reports according to their temporal, modal and\nvolitional/illocutionary values. Although the focus is on news reports of\nnatural disasters, disease outbreaks and man-made disasters in Turkish\nlanguage, the approach can be adapted to other languages, domains and genres.\nThis event extraction and classification system, with further developments, can\nprovide a basis for automated browsing systems for preventing environmental and\nhumanitarian risk.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 19:22:51 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["H\u00fcrriyeto\u011flu", "Ali", ""]]}, {"id": "2008.01564", "submitter": "Bruce Lee", "authors": "Bruce W. Lee, Jason Hyung-Jong Lee", "title": "LXPER Index: a curriculum-specific text readability assessment model for\n  EFL students in Korea", "comments": "8 pages, 2 figures, 7 tables", "journal-ref": "International Journal of Advanced Computer Science and\n  Applications, 11(8), 2020", "doi": "10.14569/IJACSA.2020.0110801", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Automatic readability assessment is one of the most important applications of\nNatural Language Processing (NLP) in education. Since automatic readability\nassessment allows the fast selection of appropriate reading material for\nreaders at all levels of proficiency, it can be particularly useful for the\nEnglish education of English as Foreign Language (EFL) students around the\nworld. Most readability assessment models are developed for the native readers\nof English and have low accuracy for texts in the non-native English Language\nTraining (ELT) curriculum. We introduce LXPER Index, which is a readability\nassessment model for non-native EFL readers in the ELT curriculum of Korea. Our\nexperiments show that our new model, trained with CoKEC-text (Text Corpus of\nthe Korean ELT Curriculum), significantly improves the accuracy of automatic\nreadability assessment for texts in the Korean ELT curriculum.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 11:55:03 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Lee", "Bruce W.", ""], ["Lee", "Jason Hyung-Jong", ""]]}, {"id": "2008.01572", "submitter": "Abhishek Dubey", "authors": "Abhishek K Dubey and Alina Peluso and Jacob Hinkle and Devanshu\n  Agarawal and Zilong Tan", "title": "Model Reduction of Shallow CNN Model for Reliable Deployment of\n  Information Extraction from Medical Reports", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shallow Convolution Neural Network (CNN) is a time-tested tool for the\ninformation extraction from cancer pathology reports. Shallow CNN performs\ncompetitively on this task to other deep learning models including BERT, which\nholds the state-of-the-art for many NLP tasks. The main insight behind this\neccentric phenomenon is that the information extraction from cancer pathology\nreports require only a small number of domain-specific text segments to perform\nthe task, thus making the most of the texts and contexts excessive for the\ntask. Shallow CNN model is well-suited to identify these key short text\nsegments from the labeled training set; however, the identified text segments\nremain obscure to humans. In this study, we fill this gap by developing a model\nreduction tool to make a reliable connection between CNN filters and relevant\ntext segments by discarding the spurious connections. We reduce the complexity\nof shallow CNN representation by approximating it with a linear transformation\nof n-gram presence representation with a non-negativity and sparsity prior on\nthe transformation weights to obtain an interpretable model. Our approach\nbridge the gap between the conventionally perceived trade-off boundary between\naccuracy on the one side and explainability on the other by model reduction.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 16:41:08 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Dubey", "Abhishek K", ""], ["Peluso", "Alina", ""], ["Hinkle", "Jacob", ""], ["Agarawal", "Devanshu", ""], ["Tan", "Zilong", ""]]}, {"id": "2008.01663", "submitter": "Inaam Ilahi", "authors": "Inaam Ilahi, Hafiz Muhammad Abdullah Zia, Muhammad Ahtazaz Ahsan, Rauf\n  Tabassam, Armaghan Ahmed", "title": "Efficient Urdu Caption Generation using Attention based LSTM", "comments": "This a project report of Deep Learning subject taught at Information\n  Technology University, Lahore, Pakistan by Dr. Mohsen Ali", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advancements in deep learning have created many opportunities to solve\nreal-world problems that remained unsolved for more than a decade. Automatic\ncaption generation is a major research field, and the research community has\ndone a lot of work on it in most common languages like English. Urdu is the\nnational language of Pakistan and also much spoken and understood in the\nsub-continent region of Pakistan-India, and yet no work has been done for Urdu\nlanguage caption generation. Our research aims to fill this gap by developing\nan attention-based deep learning model using techniques of sequence modeling\nspecialized for the Urdu language. We have prepared a dataset in the Urdu\nlanguage by translating a subset of the \"Flickr8k\" dataset containing 700 'man'\nimages. We evaluate our proposed technique on this dataset and show that it can\nachieve a BLEU score of 0.83 in the Urdu language. We improve on the previous\nstate-of-the-art by using better CNN architectures and optimization techniques.\nFurthermore, we provide a discussion on how the generated captions can be made\ncorrect grammar-wise.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 17:22:33 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 09:32:28 GMT"}, {"version": "v3", "created": "Tue, 4 May 2021 11:01:09 GMT"}, {"version": "v4", "created": "Sat, 19 Jun 2021 15:31:55 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Ilahi", "Inaam", ""], ["Zia", "Hafiz Muhammad Abdullah", ""], ["Ahsan", "Muhammad Ahtazaz", ""], ["Tabassam", "Rauf", ""], ["Ahmed", "Armaghan", ""]]}, {"id": "2008.01739", "submitter": "Wasi Ahmad", "authors": "Wasi Uddin Ahmad and Xiao Bai and Soomin Lee and Kai-Wei Chang", "title": "Select, Extract and Generate: Neural Keyphrase Generation with\n  Layer-wise Coverage Attention", "comments": "ACL 2021 (camera ready)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language processing techniques have demonstrated promising results in\nkeyphrase generation. However, one of the major challenges in \\emph{neural}\nkeyphrase generation is processing long documents using deep neural networks.\nGenerally, documents are truncated before given as inputs to neural networks.\nConsequently, the models may miss essential points conveyed in the target\ndocument. To overcome this limitation, we propose \\emph{SEG-Net}, a neural\nkeyphrase generation model that is composed of two major components, (1) a\nselector that selects the salient sentences in a document and (2) an\nextractor-generator that jointly extracts and generates keyphrases from the\nselected sentences. SEG-Net uses Transformer, a self-attentive architecture, as\nthe basic building block with a novel \\emph{layer-wise} coverage attention to\nsummarize most of the points discussed in the document. The experimental\nresults on seven keyphrase generation benchmarks from scientific and web\ndocuments demonstrate that SEG-Net outperforms the state-of-the-art neural\ngenerative methods by a large margin.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 18:00:07 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 20:50:29 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Ahmad", "Wasi Uddin", ""], ["Bai", "Xiao", ""], ["Lee", "Soomin", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "2008.01766", "submitter": "Brenden Lake", "authors": "Brenden M. Lake and Gregory L. Murphy", "title": "Word meaning in minds and machines", "comments": "In press at Psychological Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machines have achieved a broad and growing set of linguistic competencies,\nthanks to recent progress in Natural Language Processing (NLP). Psychologists\nhave shown increasing interest in such models, comparing their output to\npsychological judgments such as similarity, association, priming, and\ncomprehension, raising the question of whether the models could serve as\npsychological theories. In this article, we compare how humans and machines\nrepresent the meaning of words. We argue that contemporary NLP systems are\nfairly successful models of human word similarity, but they fall short in many\nother respects. Current models are too strongly linked to the text-based\npatterns in large corpora, and too weakly linked to the desires, goals, and\nbeliefs that people express through words. Word meanings must also be grounded\nin perception and action and be capable of flexible combinations in ways that\ncurrent systems are not. We discuss more promising approaches to grounding NLP\nsystems and argue that they will be more successful with a more human-like,\nconceptual basis for word meaning.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 18:45:49 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 20:53:24 GMT"}, {"version": "v3", "created": "Sat, 17 Apr 2021 21:05:02 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Lake", "Brenden M.", ""], ["Murphy", "Gregory L.", ""]]}, {"id": "2008.01809", "submitter": "Haoran Zhang", "authors": "Haoran Zhang and Diane Litman", "title": "Automated Topical Component Extraction Using Neural Network Attention\n  Scores from Source-based Essay Scoring", "comments": "Published in the ACL 2020", "journal-ref": "The 58th Annual Meeting of the Association for Computational\n  Linguistics, pp. 8569-8584. 2020", "doi": "10.18653/v1/2020.acl-main.759", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While automated essay scoring (AES) can reliably grade essays at scale,\nautomated writing evaluation (AWE) additionally provides formative feedback to\nguide essay revision. However, a neural AES typically does not provide useful\nfeature representations for supporting AWE. This paper presents a method for\nlinking AWE and neural AES, by extracting Topical Components (TCs) representing\nevidence from a source text using the intermediate output of attention layers.\nWe evaluate performance using a feature-based AES requiring TCs. Results show\nthat performance is comparable whether using automatically or manually\nconstructed TCs for 1) representing essays as rubric-based features, 2) grading\nessays.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 20:13:51 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Zhang", "Haoran", ""], ["Litman", "Diane", ""]]}, {"id": "2008.01832", "submitter": "Qi Liu", "authors": "Qi Liu, Yanmin Qian, Kai Yu", "title": "Future Vector Enhanced LSTM Language Model for LVCSR", "comments": "Accepted by ASRU-2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language models (LM) play an important role in large vocabulary continuous\nspeech recognition (LVCSR). However, traditional language models only predict\nnext single word with given history, while the consecutive predictions on a\nsequence of words are usually demanded and useful in LVCSR. The mismatch\nbetween the single word prediction modeling in trained and the long term\nsequence prediction in read demands may lead to the performance degradation. In\nthis paper, a novel enhanced long short-term memory (LSTM) LM using the future\nvector is proposed. In addition to the given history, the rest of the sequence\nwill be also embedded by future vectors. This future vector can be incorporated\nwith the LSTM LM, so it has the ability to model much longer term sequence\nlevel information. Experiments show that, the proposed new LSTM LM gets a\nbetter result on BLEU scores for long term sequence prediction. For the speech\nrecognition rescoring, although the proposed LSTM LM obtains very slight gains,\nthe new model seems obtain the great complementary with the conventional LSTM\nLM. Rescoring using both the new and conventional LSTM LMs can achieve a very\nlarge improvement on the word error rate.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 08:38:56 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Liu", "Qi", ""], ["Qian", "Yanmin", ""], ["Yu", "Kai", ""]]}, {"id": "2008.01937", "submitter": "Chun-Nan Hsu", "authors": "Chun-Nan Hsu, Chia-Hui Chang, Thamolwan Poopradubsil, Amanda Lo, Karen\n  A. William, Ko-Wei Lin, Anita Bandrowski, Ibrahim Burak Ozyurt, Jeffrey S.\n  Grethe, and Maryann E. Martone", "title": "Antibody Watch: Text Mining Antibody Specificity from the Literature", "comments": "16 pages, 1 figures", "journal-ref": "PLOS Computational Biology, 2021", "doi": "10.1371/journal.pcbi.1008967", "report-no": null, "categories": "cs.CL q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Antibodies are widely used reagents to test for expression of proteins and\nother antigens. However, they might not always reliably produce results when\nthey do not specifically bind to the target proteins that their providers\ndesigned them for, leading to unreliable research results. While many proposals\nhave been developed to deal with the problem of antibody specificity, it is\nstill challenging to cover the millions of antibodies that are available to\nresearchers. In this study, we investigate the feasibility of automatically\ngenerating alerts to users of problematic antibodies by extracting statements\nabout antibody specificity reported in the literature. The extracted alerts can\nbe used to construct an \"Antibody Watch\" knowledge base containing supporting\nstatements of problematic antibodies. We developed a deep neural network system\nand tested its performance with a corpus of more than two thousand articles\nthat reported uses of antibodies. We divided the problem into two tasks. Given\nan input article, the first task is to identify snippets about antibody\nspecificity and classify if the snippets report that any antibody exhibits\nnon-specificity, and thus is problematic. The second task is to link each of\nthese snippets to one or more antibodies mentioned in the snippet. The\nexperimental evaluation shows that our system can accurately perform both\nclassification and linking tasks with weighted F-scores over 0.925 and 0.923,\nrespectively, and 0.914 overall when combined to complete the joint task. We\nleveraged Research Resource Identifiers (RRID) to precisely identify antibodies\nlinked to the extracted specificity snippets. The result shows that it is\nfeasible to construct a reliable knowledge base about problematic antibodies by\ntext mining.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 05:14:11 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 00:40:18 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Hsu", "Chun-Nan", ""], ["Chang", "Chia-Hui", ""], ["Poopradubsil", "Thamolwan", ""], ["Lo", "Amanda", ""], ["William", "Karen A.", ""], ["Lin", "Ko-Wei", ""], ["Bandrowski", "Anita", ""], ["Ozyurt", "Ibrahim Burak", ""], ["Grethe", "Jeffrey S.", ""], ["Martone", "Maryann E.", ""]]}, {"id": "2008.01940", "submitter": "Matiss Rikters", "authors": "Mat\\=iss Rikters, Ryokan Ri, Tong Li, Toshiaki Nakazawa", "title": "Designing the Business Conversation Corpus", "comments": null, "journal-ref": "Published in proceedings of the 6th Workshop on Asian Translation,\n  2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the progress of machine translation of written text has come far in the\npast several years thanks to the increasing availability of parallel corpora\nand corpora-based training technologies, automatic translation of spoken text\nand dialogues remains challenging even for modern systems. In this paper, we\naim to boost the machine translation quality of conversational texts by\nintroducing a newly constructed Japanese-English business conversation parallel\ncorpus. A detailed analysis of the corpus is provided along with challenging\nexamples for automatic translation. We also experiment with adding the corpus\nin a machine translation training scenario and show how the resulting system\nbenefits from its use.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 05:19:44 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Rikters", "Mat\u012bss", ""], ["Ri", "Ryokan", ""], ["Li", "Tong", ""], ["Nakazawa", "Toshiaki", ""]]}, {"id": "2008.01946", "submitter": "Ali Basirat", "authors": "Hartger Veeman and Ali Basirat", "title": "An exploration of the encoding of grammatical gender in word embeddings", "comments": "Accepted at the 4th Swedish Symposium on Deep Learning (SSDL-2020)\n  and the 8th Swedish Language Technology Conference (SLTC-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vector representation of words, known as word embeddings, has opened a\nnew research approach in linguistic studies. These representations can capture\ndifferent types of information about words. The grammatical gender of nouns is\na typical classification of nouns based on their formal and semantic\nproperties. The study of grammatical gender based on word embeddings can give\ninsight into discussions on how grammatical genders are determined. In this\nstudy, we compare different sets of word embeddings according to the accuracy\nof a neural classifier determining the grammatical gender of nouns. It is found\nthat there is an overlap in how grammatical gender is encoded in Swedish,\nDanish, and Dutch embeddings. Our experimental results on the contextualized\nembeddings pointed out that adding more contextual information to embeddings is\ndetrimental to the classifier's performance. We also observed that removing\nmorpho-syntactic features such as articles from the training corpora of\nembeddings decreases the classification performance dramatically, indicating a\nlarge portion of the information is encoded in the relationship between nouns\nand articles.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 06:01:46 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 13:11:41 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Veeman", "Hartger", ""], ["Basirat", "Ali", ""]]}, {"id": "2008.01972", "submitter": "Jason Fries", "authors": "Jason A. Fries, Ethan Steinberg, Saelig Khattar, Scott L. Fleming,\n  Jose Posada, Alison Callahan, Nigam H. Shah", "title": "Ontology-driven weak supervision for clinical entity classification in\n  electronic health records", "comments": null, "journal-ref": "Nature Communications 12.1 (2021): 1-11", "doi": "10.1038/s41467-021-22328-4", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the electronic health record, using clinical notes to identify entities\nsuch as disorders and their temporality (e.g. the order of an event relative to\na time index) can inform many important analyses. However, creating training\ndata for clinical entity tasks is time consuming and sharing labeled data is\nchallenging due to privacy concerns. The information needs of the COVID-19\npandemic highlight the need for agile methods of training machine learning\nmodels for clinical notes. We present Trove, a framework for weakly supervised\nentity classification using medical ontologies and expert-generated rules. Our\napproach, unlike hand-labeled notes, is easy to share and modify, while\noffering performance comparable to learning from manually labeled training\ndata. In this work, we validate our framework on six benchmark tasks and\ndemonstrate Trove's ability to analyze the records of patients visiting the\nemergency department at Stanford Health Care for COVID-19 presenting symptoms\nand risk factors.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 07:42:09 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 04:11:52 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Fries", "Jason A.", ""], ["Steinberg", "Ethan", ""], ["Khattar", "Saelig", ""], ["Fleming", "Scott L.", ""], ["Posada", "Jose", ""], ["Callahan", "Alison", ""], ["Shah", "Nigam H.", ""]]}, {"id": "2008.01994", "submitter": "Philip John Gorinski", "authors": "Yusheng Tian, Philip John Gorinski", "title": "Improving End-to-End Speech-to-Intent Classification with Reptile", "comments": "4 pages + 1 page references, 4 figures, 3 tables, 1 algorithm,\n  accepted for presentation at InterSpeech2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end spoken language understanding (SLU) systems have many advantages\nover conventional pipeline systems, but collecting in-domain speech data to\ntrain an end-to-end system is costly and time consuming. One question arises\nfrom this: how to train an end-to-end SLU with limited amounts of data? Many\nresearchers have explored approaches that make use of other related data\nresources, typically by pre-training parts of the model on high-resource speech\nrecognition. In this paper, we suggest improving the generalization performance\nof SLU models with a non-standard learning algorithm, Reptile. Though Reptile\nwas originally proposed for model-agnostic meta learning, we argue that it can\nalso be used to directly learn a target task and result in better\ngeneralization than conventional gradient descent. In this work, we employ\nReptile to the task of end-to-end spoken intent classification. Experiments on\nfour datasets of different languages and domains show improvement of intent\nprediction accuracy, both when Reptile is used alone and used in addition to\npre-training.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 08:32:15 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Tian", "Yusheng", ""], ["Gorinski", "Philip John", ""]]}, {"id": "2008.02047", "submitter": "Alexander Mehler", "authors": "Alexander Mehler and Wahed Hemati and Pascal Welke and Maxim Konca and\n  Tolga Uslu", "title": "Multiple Texts as a Limiting Factor in Online Learning: Quantifying\n  (Dis-)similarities of Knowledge Networks across Languages", "comments": "40 pages, 13 figures, 5 tables", "journal-ref": null, "doi": "10.3389/feduc.2020.562670", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We test the hypothesis that the extent to which one obtains information on a\ngiven topic through Wikipedia depends on the language in which it is consulted.\nControlling the size factor, we investigate this hypothesis for a number of 25\nsubject areas. Since Wikipedia is a central part of the web-based information\nlandscape, this indicates a language-related, linguistic bias. The article\ntherefore deals with the question of whether Wikipedia exhibits this kind of\nlinguistic relativity or not. From the perspective of educational science, the\narticle develops a computational model of the information landscape from which\nmultiple texts are drawn as typical input of web-based reading. For this\npurpose, it develops a hybrid model of intra- and intertextual similarity of\ndifferent parts of the information landscape and tests this model on the\nexample of 35 languages and corresponding Wikipedias. In this way the article\nbuilds a bridge between reading research, educational science, Wikipedia\nresearch and computational linguistics.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 11:11:55 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Mehler", "Alexander", ""], ["Hemati", "Wahed", ""], ["Welke", "Pascal", ""], ["Konca", "Maxim", ""], ["Uslu", "Tolga", ""]]}, {"id": "2008.02096", "submitter": "Alexander Mehler", "authors": "Andy L\\\"ucking and Sebastian Br\\\"uckner and Giuseppe Abrami and Tolga\n  Uslu and Alexander Mehler", "title": "Computational linguistic assessment of textbook and online learning\n  media by means of threshold concepts in business education", "comments": "35 pages, 6 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Threshold concepts are key terms in domain-based knowledge acquisition. They\nare regarded as building blocks of the conceptual development of domain\nknowledge within particular learners. From a linguistic perspective, however,\nthreshold concepts are instances of specialized vocabularies, exhibiting\nparticular linguistic features. Threshold concepts are typically used in\nspecialized texts such as textbooks -- that is, within a formal learning\nenvironment. However, they also occur in informal learning environments like\nnewspapers. In this article, a first approach is taken to combine both lines\ninto an overarching research program - that is, to provide a computational\nlinguistic assessment of different resources, including in particular online\nresources, by means of threshold concepts. To this end, the distributive\nprofiles of 63 threshold concepts from business education (which have been\ncollected from threshold concept research) has been investigated in three kinds\nof (German) resources, namely textbooks, newspapers, and Wikipedia. Wikipedia\nis (one of) the largest and most widely used online resources. We looked at the\nthreshold concepts' frequency distribution, their compound distribution, and\ntheir network structure within the three kind of resources. The two main\nfindings can be summarized as follows: Firstly, the three kinds of resources\ncan indeed be distinguished in terms of their threshold concepts' profiles.\nSecondly, Wikipedia definitely appears to be a formal learning resource.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 12:56:16 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["L\u00fccking", "Andy", ""], ["Br\u00fcckner", "Sebastian", ""], ["Abrami", "Giuseppe", ""], ["Uslu", "Tolga", ""], ["Mehler", "Alexander", ""]]}, {"id": "2008.02213", "submitter": "Tianyu Cui", "authors": "Tianyu Cui, Gang Xiong, Gaopeng Gou, Junzheng Shi and Wei Xia", "title": "6VecLM: Language Modeling in Vector Space for IPv6 Target Generation", "comments": "The paper has been accepted at the European Conference on Machine\n  Learning and Principles and Practice of Knowledge Discovery in Databases\n  (ECMLPKDD 2020) (https://ecmlpkdd2020.net/programme/accepted/#ADSTab)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast IPv6 scanning is challenging in the field of network measurement as it\nrequires exploring the whole IPv6 address space but limited by current\ncomputational power. Researchers propose to obtain possible active target\ncandidate sets to probe by algorithmically analyzing the active seed sets.\nHowever, IPv6 addresses lack semantic information and contain numerous\naddressing schemes, leading to the difficulty of designing effective\nalgorithms. In this paper, we introduce our approach 6VecLM to explore\nachieving such target generation algorithms. The architecture can map addresses\ninto a vector space to interpret semantic relationships and uses a Transformer\nnetwork to build IPv6 language models for predicting address sequence.\nExperiments indicate that our approach can perform semantic classification on\naddress space. By adding a new generation approach, our model possesses a\ncontrollable word innovation capability compared to conventional language\nmodels. The work outperformed the state-of-the-art target generation algorithms\non two active address datasets by reaching more quality candidate sets.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 16:26:50 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Cui", "Tianyu", ""], ["Xiong", "Gang", ""], ["Gou", "Gaopeng", ""], ["Shi", "Junzheng", ""], ["Xia", "Wei", ""]]}, {"id": "2008.02217", "submitter": "Hubert Ramsauer", "authors": "Hubert Ramsauer, Bernhard Sch\\\"afl, Johannes Lehner, Philipp Seidl,\n  Michael Widrich, Thomas Adler, Lukas Gruber, Markus Holzleitner, Milena\n  Pavlovi\\'c, Geir Kjetil Sandve, Victor Greiff, David Kreil, Michael Kopp,\n  G\\\"unter Klambauer, Johannes Brandstetter, Sepp Hochreiter", "title": "Hopfield Networks is All You Need", "comments": "10 pages (+ appendix); 12 figures; Blog:\n  https://ml-jku.github.io/hopfield-layers/; GitHub:\n  https://github.com/ml-jku/hopfield-layers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a modern Hopfield network with continuous states and a\ncorresponding update rule. The new Hopfield network can store exponentially\n(with the dimension of the associative space) many patterns, retrieves the\npattern with one update, and has exponentially small retrieval errors. It has\nthree types of energy minima (fixed points of the update): (1) global fixed\npoint averaging over all patterns, (2) metastable states averaging over a\nsubset of patterns, and (3) fixed points which store a single pattern. The new\nupdate rule is equivalent to the attention mechanism used in transformers. This\nequivalence enables a characterization of the heads of transformer models.\nThese heads perform in the first layers preferably global averaging and in\nhigher layers partial averaging via metastable states. The new modern Hopfield\nnetwork can be integrated into deep learning architectures as layers to allow\nthe storage of and access to raw input data, intermediate results, or learned\nprototypes. These Hopfield layers enable new ways of deep learning, beyond\nfully-connected, convolutional, or recurrent networks, and provide pooling,\nmemory, association, and attention mechanisms. We demonstrate the broad\napplicability of the Hopfield layers across various domains. Hopfield layers\nimproved state-of-the-art on three out of four considered multiple instance\nlearning problems as well as on immune repertoire classification with several\nhundreds of thousands of instances. On the UCI benchmark collections of small\nclassification tasks, where deep learning methods typically struggle, Hopfield\nlayers yielded a new state-of-the-art when compared to different machine\nlearning methods. Finally, Hopfield layers achieved state-of-the-art on two\ndrug design datasets. The implementation is available at:\nhttps://github.com/ml-jku/hopfield-layers\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 17:52:37 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 14:16:15 GMT"}, {"version": "v3", "created": "Wed, 28 Apr 2021 07:24:49 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Ramsauer", "Hubert", ""], ["Sch\u00e4fl", "Bernhard", ""], ["Lehner", "Johannes", ""], ["Seidl", "Philipp", ""], ["Widrich", "Michael", ""], ["Adler", "Thomas", ""], ["Gruber", "Lukas", ""], ["Holzleitner", "Markus", ""], ["Pavlovi\u0107", "Milena", ""], ["Sandve", "Geir Kjetil", ""], ["Greiff", "Victor", ""], ["Kreil", "David", ""], ["Kopp", "Michael", ""], ["Klambauer", "G\u00fcnter", ""], ["Brandstetter", "Johannes", ""], ["Hochreiter", "Sepp", ""]]}, {"id": "2008.02239", "submitter": "Aleksander Mendoza-Drosik", "authors": "Aleksander Mendoza-Drosik", "title": "Glushkov's construction for functional subsequential transducers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Glushkov's construction has many interesting properties and they become even\nmore evident when applied to transducers. This article strives to show the wast\nrange of possible extensions and optimisations for this algorithm. Special\nflavour of regular expressions is introduced, which can be efficiently\nconverted to $\\epsilon$-free functional subsequential weighted finite state\ntransducers. Produced automata are very compact, as they contain only one state\nfor each symbol (from input alphabet) of original expression and only one\ntransition for each range of symbols, no matter how large. Such compactified\nranges of transitions allow for efficient binary search lookup during automaton\nevaluation. All the methods and algorithms presented here were used to\nimplement open-source compiler of regular expressions for multitape\ntransducers.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 17:09:58 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 16:09:54 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2020 17:42:10 GMT"}, {"version": "v4", "created": "Tue, 22 Sep 2020 13:36:57 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Mendoza-Drosik", "Aleksander", ""]]}, {"id": "2008.02250", "submitter": "Ryan Gallagher", "authors": "Ryan J. Gallagher, Morgan R. Frank, Lewis Mitchell, Aaron J. Schwartz,\n  Andrew J. Reagan, Christopher M. Danforth, Peter Sheridan Dodds", "title": "Generalized Word Shift Graphs: A Method for Visualizing and Explaining\n  Pairwise Comparisons Between Texts", "comments": "20 pages, 7 figures, 2 tables", "journal-ref": "EPJ Data Science, 10(4), 2021", "doi": "10.1140/epjds/s13688-021-00260-3", "report-no": null, "categories": "cs.CL cs.CY cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common task in computational text analyses is to quantify how two corpora\ndiffer according to a measurement like word frequency, sentiment, or\ninformation content. However, collapsing the texts' rich stories into a single\nnumber is often conceptually perilous, and it is difficult to confidently\ninterpret interesting or unexpected textual patterns without looming concerns\nabout data artifacts or measurement validity. To better capture fine-grained\ndifferences between texts, we introduce generalized word shift graphs,\nvisualizations which yield a meaningful and interpretable summary of how\nindividual words contribute to the variation between two texts for any measure\nthat can be formulated as a weighted average. We show that this framework\nnaturally encompasses many of the most commonly used approaches for comparing\ntexts, including relative frequencies, dictionary scores, and entropy-based\nmeasures like the Kullback-Leibler and Jensen-Shannon divergences. Through\nseveral case studies, we demonstrate how generalized word shift graphs can be\nflexibly applied across domains for diagnostic investigation, hypothesis\ngeneration, and substantive interpretation. By providing a detailed lens into\ntextual shifts between corpora, generalized word shift graphs help\ncomputational social scientists, digital humanists, and other text analysis\npractitioners fashion more robust scientific narratives.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 17:27:11 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Gallagher", "Ryan J.", ""], ["Frank", "Morgan R.", ""], ["Mitchell", "Lewis", ""], ["Schwartz", "Aaron J.", ""], ["Reagan", "Andrew J.", ""], ["Danforth", "Christopher M.", ""], ["Dodds", "Peter Sheridan", ""]]}, {"id": "2008.02270", "submitter": "Marco Gaido", "authors": "Marco Gaido, Mattia Antonino Di Gangi, Matteo Negri, Mauro Cettolo,\n  Marco Turchi", "title": "Contextualized Translation of Automatically Segmented Speech", "comments": "Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Direct speech-to-text translation (ST) models are usually trained on corpora\nsegmented at sentence level, but at inference time they are commonly fed with\naudio split by a voice activity detector (VAD). Since VAD segmentation is not\nsyntax-informed, the resulting segments do not necessarily correspond to\nwell-formed sentences uttered by the speaker but, most likely, to fragments of\none or more sentences. This segmentation mismatch degrades considerably the\nquality of ST models' output. So far, researchers have focused on improving\naudio segmentation towards producing sentence-like splits. In this paper,\ninstead, we address the issue in the model, making it more robust to a\ndifferent, potentially sub-optimal segmentation. To this aim, we train our\nmodels on randomly segmented data and compare two approaches: fine-tuning and\nadding the previous segment as context. We show that our context-aware solution\nis more robust to VAD-segmented input, outperforming a strong base model and\nthe fine-tuning on different VAD segmentations of an English-German test set by\nup to 4.25 BLEU points.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 17:52:25 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Gaido", "Marco", ""], ["Di Gangi", "Mattia Antonino", ""], ["Negri", "Matteo", ""], ["Cettolo", "Mauro", ""], ["Turchi", "Marco", ""]]}, {"id": "2008.02275", "submitter": "Dan Hendrycks", "authors": "Dan Hendrycks and Collin Burns and Steven Basart and Andrew Critch and\n  Jerry Li and Dawn Song and Jacob Steinhardt", "title": "Aligning AI With Shared Human Values", "comments": "ICLR 2021; the ETHICS dataset is available at\n  https://github.com/hendrycks/ethics/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to assess a language model's knowledge of basic concepts of\nmorality. We introduce the ETHICS dataset, a new benchmark that spans concepts\nin justice, well-being, duties, virtues, and commonsense morality. Models\npredict widespread moral judgments about diverse text scenarios. This requires\nconnecting physical and social world knowledge to value judgements, a\ncapability that may enable us to steer chatbot outputs or eventually regularize\nopen-ended reinforcement learning agents. With the ETHICS dataset, we find that\ncurrent language models have a promising but incomplete ability to predict\nbasic human ethical judgements. Our work shows that progress can be made on\nmachine ethics today, and it provides a steppingstone toward AI that is aligned\nwith human values.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 17:59:16 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 06:02:59 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2021 18:57:47 GMT"}, {"version": "v4", "created": "Thu, 4 Mar 2021 21:47:22 GMT"}, {"version": "v5", "created": "Sat, 24 Jul 2021 04:40:33 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Hendrycks", "Dan", ""], ["Burns", "Collin", ""], ["Basart", "Steven", ""], ["Critch", "Andrew", ""], ["Li", "Jerry", ""], ["Song", "Dawn", ""], ["Steinhardt", "Jacob", ""]]}, {"id": "2008.02347", "submitter": "Subhadip Maji", "authors": "Subhadip Maji, Anudeep Srivatsav Appe, Raghav Bali, Veera Raghavendra\n  Chikka, Arijit Ghosh Chowdhury and Vamsi M Bhandaru", "title": "An Interpretable Deep Learning System for Automatically Scoring Request\n  for Proposals", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Managed Care system within Medicaid (US Healthcare) uses Request For\nProposals (RFP) to award contracts for various healthcare and related services.\nRFP responses are very detailed documents (hundreds of pages) submitted by\ncompeting organisations to win contracts. Subject matter expertise and domain\nknowledge play an important role in preparing RFP responses along with analysis\nof historical submissions. Automated analysis of these responses through\nNatural Language Processing (NLP) systems can reduce time and effort needed to\nexplore historical responses, and assisting in writing better responses. Our\nwork draws parallels between scoring RFPs and essay scoring models, while\nhighlighting new challenges and the need for interpretability. Typical scoring\nmodels focus on word level impacts to grade essays and other short write-ups.\nWe propose a novel Bi-LSTM based regression model, and provide deeper insight\ninto phrases which latently impact scoring of responses. We contend the merits\nof our proposed methodology using extensive quantitative experiments. We also\nqualitatively asses the impact of important phrases using human evaluators.\nFinally, we introduce a novel problem statement that can be used to further\nimprove the state of the art in NLP based automatic scoring systems.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 20:21:35 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Maji", "Subhadip", ""], ["Appe", "Anudeep Srivatsav", ""], ["Bali", "Raghav", ""], ["Chikka", "Veera Raghavendra", ""], ["Chowdhury", "Arijit Ghosh", ""], ["Bhandaru", "Vamsi M", ""]]}, {"id": "2008.02385", "submitter": "Ruizhe Huang", "authors": "Ruizhe Huang, Ke Li, Ashish Arora, Dan Povey and Sanjeev Khudanpur", "title": "Efficient MDI Adaptation for n-gram Language Models", "comments": "To appear in INTERSPEECH 2020. Appendix A of this full version will\n  be filled soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an efficient algorithm for n-gram language model\nadaptation under the minimum discrimination information (MDI) principle, where\nan out-of-domain language model is adapted to satisfy the constraints of\nmarginal probabilities of the in-domain data. The challenge for MDI language\nmodel adaptation is its computational complexity. By taking advantage of the\nbackoff structure of n-gram model and the idea of hierarchical training method,\noriginally proposed for maximum entropy (ME) language models, we show that MDI\nadaptation can be computed in linear-time complexity to the inputs in each\niteration. The complexity remains the same as ME models, although MDI is more\ngeneral than ME. This makes MDI adaptation practical for large corpus and\nvocabulary. Experimental results confirm the scalability of our algorithm on\nvery large datasets, while MDI adaptation gets slightly worse perplexity but\nbetter word error rate results compared to simple linear interpolation.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 22:21:03 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Huang", "Ruizhe", ""], ["Li", "Ke", ""], ["Arora", "Ashish", ""], ["Povey", "Dan", ""], ["Khudanpur", "Sanjeev", ""]]}, {"id": "2008.02460", "submitter": "Xiaowei Liu", "authors": "Weiwei Guo, Xiaowei Liu, Sida Wang, Huiji Gao, Ananth Sankar, Zimeng\n  Yang, Qi Guo, Liang Zhang, Bo Long, Bee-Chung Chen and Deepak Agarwal", "title": "DeText: A Deep Text Ranking Framework with BERT", "comments": "Ranking, Deep Language Models, Natural Language Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ranking is the most important component in a search system. Mostsearch\nsystems deal with large amounts of natural language data,hence an effective\nranking system requires a deep understandingof text semantics. Recently, deep\nlearning based natural languageprocessing (deep NLP) models have generated\npromising results onranking systems. BERT is one of the most successful models\nthatlearn contextual embedding, which has been applied to capturecomplex\nquery-document relations for search ranking. However,this is generally done by\nexhaustively interacting each query wordwith each document word, which is\ninefficient for online servingin search product systems. In this paper, we\ninvestigate how tobuild an efficient BERT-based ranking model for industry use\ncases.The solution is further extended to a general ranking framework,DeText,\nthat is open sourced and can be applied to various rankingproductions. Offline\nand online experiments of DeText on threereal-world search systems present\nsignificant improvement overstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 05:12:11 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Guo", "Weiwei", ""], ["Liu", "Xiaowei", ""], ["Wang", "Sida", ""], ["Gao", "Huiji", ""], ["Sankar", "Ananth", ""], ["Yang", "Zimeng", ""], ["Guo", "Qi", ""], ["Zhang", "Liang", ""], ["Long", "Bo", ""], ["Chen", "Bee-Chung", ""], ["Agarwal", "Deepak", ""]]}, {"id": "2008.02496", "submitter": "Zihang Jiang", "authors": "Zihang Jiang, Weihao Yu, Daquan Zhou, Yunpeng Chen, Jiashi Feng,\n  Shuicheng Yan", "title": "ConvBERT: Improving BERT with Span-based Dynamic Convolution", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language models like BERT and its variants have recently achieved\nimpressive performance in various natural language understanding tasks.\nHowever, BERT heavily relies on the global self-attention block and thus\nsuffers large memory footprint and computation cost. Although all its attention\nheads query on the whole input sequence for generating the attention map from a\nglobal perspective, we observe some heads only need to learn local\ndependencies, which means the existence of computation redundancy. We therefore\npropose a novel span-based dynamic convolution to replace these self-attention\nheads to directly model local dependencies. The novel convolution heads,\ntogether with the rest self-attention heads, form a new mixed attention block\nthat is more efficient at both global and local context learning. We equip BERT\nwith this mixed attention design and build a ConvBERT model. Experiments have\nshown that ConvBERT significantly outperforms BERT and its variants in various\ndownstream tasks, with lower training cost and fewer model parameters.\nRemarkably, ConvBERTbase model achieves 86.4 GLUE score, 0.7 higher than\nELECTRAbase, while using less than 1/4 training cost. Code and pre-trained\nmodels will be released.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 07:43:19 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 07:54:36 GMT"}, {"version": "v3", "created": "Tue, 2 Feb 2021 11:11:28 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Jiang", "Zihang", ""], ["Yu", "Weihao", ""], ["Zhou", "Daquan", ""], ["Chen", "Yunpeng", ""], ["Feng", "Jiashi", ""], ["Yan", "Shuicheng", ""]]}, {"id": "2008.02516", "submitter": "Jinglin Liu", "authors": "Jinglin Liu, Yi Ren, Zhou Zhao, Chen Zhang, Baoxing Huai, Nicholas\n  Jing Yuan", "title": "FastLR: Non-Autoregressive Lipreading Model with Integrate-and-Fire", "comments": "Accepted by ACM MM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.CV cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lipreading is an impressive technique and there has been a definite\nimprovement of accuracy in recent years. However, existing methods for\nlipreading mainly build on autoregressive (AR) model, which generate target\ntokens one by one and suffer from high inference latency. To breakthrough this\nconstraint, we propose FastLR, a non-autoregressive (NAR) lipreading model\nwhich generates all target tokens simultaneously. NAR lipreading is a\nchallenging task that has many difficulties: 1) the discrepancy of sequence\nlengths between source and target makes it difficult to estimate the length of\nthe output sequence; 2) the conditionally independent behavior of NAR\ngeneration lacks the correlation across time which leads to a poor\napproximation of target distribution; 3) the feature representation ability of\nencoder can be weak due to lack of effective alignment mechanism; and 4) the\nremoval of AR language model exacerbates the inherent ambiguity problem of\nlipreading. Thus, in this paper, we introduce three methods to reduce the gap\nbetween FastLR and AR model: 1) to address challenges 1 and 2, we leverage\nintegrate-and-fire (I\\&F) module to model the correspondence between source\nvideo frames and output text sequence. 2) To tackle challenge 3, we add an\nauxiliary connectionist temporal classification (CTC) decoder to the top of the\nencoder and optimize it with extra CTC loss. We also add an auxiliary\nautoregressive decoder to help the feature extraction of encoder. 3) To\novercome challenge 4, we propose a novel Noisy Parallel Decoding (NPD) for I\\&F\nand bring Byte-Pair Encoding (BPE) into lipreading. Our experiments exhibit\nthat FastLR achieves the speedup up to 10.97$\\times$ comparing with\nstate-of-the-art lipreading model with slight WER absolute increase of 1.5\\%\nand 5.5\\% on GRID and LRS2 lipreading datasets respectively, which demonstrates\nthe effectiveness of our proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 08:28:56 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 12:17:54 GMT"}, {"version": "v3", "created": "Mon, 18 Jan 2021 05:04:54 GMT"}, {"version": "v4", "created": "Mon, 15 Mar 2021 07:23:19 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Liu", "Jinglin", ""], ["Ren", "Yi", ""], ["Zhao", "Zhou", ""], ["Zhang", "Chen", ""], ["Huai", "Baoxing", ""], ["Yuan", "Nicholas Jing", ""]]}, {"id": "2008.02603", "submitter": "Quynh Ngoc Thi Do", "authors": "Judith Gaspers, Quynh Do, Fabian Triefenbach", "title": "Data balancing for boosting performance of low-frequency classes in\n  Spoken Language Understanding", "comments": "accepted at InterSpeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the fact that data imbalance is becoming more and more common in\nreal-world Spoken Language Understanding (SLU) applications, it has not been\nstudied extensively in the literature. To the best of our knowledge, this paper\npresents the first systematic study on handling data imbalance for SLU. In\nparticular, we discuss the application of existing data balancing techniques\nfor SLU and propose a multi-task SLU model for intent classification and slot\nfilling. Aiming to avoid over-fitting, in our model methods for data balancing\nare leveraged indirectly via an auxiliary task which makes use of a\nclass-balanced batch generator and (possibly) synthetic data. Our results on a\nreal-world dataset indicate that i) our proposed model can boost performance on\nlow frequency intents significantly while avoiding a potential performance\ndecrease on the head intents, ii) synthetic data are beneficial for\nbootstrapping new intents when realistic data are not available, but iii) once\na certain amount of realistic data becomes available, using synthetic data in\nthe auxiliary task only yields better performance than adding them to the\nprimary task training data, and iv) in a joint training scenario, balancing the\nintent distribution individually improves not only intent classification but\nalso slot filling performance.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 12:23:11 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Gaspers", "Judith", ""], ["Do", "Quynh", ""], ["Triefenbach", "Fabian", ""]]}, {"id": "2008.02637", "submitter": "Patrick Lewis", "authors": "Patrick Lewis, Pontus Stenetorp, Sebastian Riedel", "title": "Question and Answer Test-Train Overlap in Open-Domain Question Answering\n  Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ideally Open-Domain Question Answering models should exhibit a number of\ncompetencies, ranging from simply memorizing questions seen at training time,\nto answering novel question formulations with answers seen during training, to\ngeneralizing to completely novel questions with novel answers. However, single\naggregated test set scores do not show the full picture of what capabilities\nmodels truly have. In this work, we perform a detailed study of the test sets\nof three popular open-domain benchmark datasets with respect to these\ncompetencies. We find that 60-70% of test-time answers are also present\nsomewhere in the training sets. We also find that 30% of test-set questions\nhave a near-duplicate paraphrase in their corresponding training sets. Using\nthese findings, we evaluate a variety of popular open-domain models to obtain\ngreater insight into what extent they can actually generalize, and what drives\ntheir overall performance. We find that all models perform dramatically worse\non questions that cannot be memorized from training sets, with a mean absolute\nperformance difference of 63% between repeated and non-repeated data. Finally\nwe show that simple nearest-neighbor models out-perform a BART closed-book QA\nmodel, further highlighting the role that training set memorization plays in\nthese benchmarks\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 13:17:43 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Lewis", "Patrick", ""], ["Stenetorp", "Pontus", ""], ["Riedel", "Sebastian", ""]]}, {"id": "2008.02687", "submitter": "Bereket Abera Yilma Mr.", "authors": "Bereket Abera Yilma, Najib Aghenda, Marcelo Romero, Yannick Naudet and\n  Herve Panetto", "title": "Personalised Visual Art Recommendation by Learning Latent Semantic\n  Representations", "comments": "Accepted at SMAP2020", "journal-ref": "SMAP 2020 15th International Workshop on Semantic and Social Media\n  Adaptation & Personalization", "doi": "10.1109/SMAP49528.2020.9248448", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In Recommender systems, data representation techniques play a great role as\nthey have the power to entangle, hide and reveal explanatory factors embedded\nwithin datasets. Hence, they influence the quality of recommendations.\nSpecifically, in Visual Art (VA) recommendations the complexity of the concepts\nembodied within paintings, makes the task of capturing semantics by machines\nfar from trivial. In VA recommendation, prominent works commonly use manually\ncurated metadata to drive recommendations. Recent works in this domain aim at\nleveraging visual features extracted using Deep Neural Networks (DNN). However,\nsuch data representation approaches are resource demanding and do not have a\ndirect interpretation, hindering user acceptance. To address these limitations,\nwe introduce an approach for Personalised Recommendation of Visual arts based\non learning latent semantic representation of paintings. Specifically, we\ntrained a Latent Dirichlet Allocation (LDA) model on textual descriptions of\npaintings. Our LDA model manages to successfully uncover non-obvious semantic\nrelationships between paintings whilst being able to offer explainable\nrecommendations. Experimental evaluations demonstrate that our method tends to\nperform better than exploiting visual features extracted using pre-trained Deep\nNeural Networks.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 14:50:10 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Yilma", "Bereket Abera", ""], ["Aghenda", "Najib", ""], ["Romero", "Marcelo", ""], ["Naudet", "Yannick", ""], ["Panetto", "Herve", ""]]}, {"id": "2008.02742", "submitter": "Yen-Ling Kuo", "authors": "Yen-Ling Kuo, Boris Katz, Andrei Barbu", "title": "Compositional Networks Enable Systematic Generalization for Grounded\n  Language Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are remarkably flexible when understanding new sentences that include\ncombinations of concepts they have never encountered before. Recent work has\nshown that while deep networks can mimic some human language abilities when\npresented with novel sentences, systematic variation uncovers the limitations\nin the language-understanding abilities of networks. We demonstrate that these\nlimitations can be overcome by addressing the generalization challenges in a\nrecently-released dataset, gSCAN, which explicitly measures how well an agent\nis able to interpret novel ideas grounded in vision, e.g., novel pairings of\nadjectives and nouns. The key principle we employ is compositionality: that the\ncompositional structure of networks should reflect the compositional structure\nof the problem domain they address, while allowing other parameters and\nproperties to be learned end-to-end with weak supervision. We build a\ngeneral-purpose mechanism that enables robots to generalize their language\nunderstanding to compositional domains. Crucially, our network has the same\nstate-of-the-art performance as prior work while at the same time generalizing\nits knowledge when prior work does not. Our network also provides a level of\ninterpretability that enables users to inspect what each part of networks\nlearns. Robust language understanding without dramatic failures and without\ncorner cases is critical to building safe and fair robots; we demonstrate the\nsignificant role that compositionality can play in achieving that goal.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 16:17:35 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 01:02:32 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Kuo", "Yen-Ling", ""], ["Katz", "Boris", ""], ["Barbu", "Andrei", ""]]}, {"id": "2008.02754", "submitter": "Xavier Ferrer Aran", "authors": "Xavier Ferrer, Tom van Nuenen, Jose M. Such, Natalia Criado", "title": "Discovering and Categorising Language Biases in Reddit", "comments": "Author's copy of the paper accepted at the International AAAI\n  Conference on Web and Social Media (ICWSM 2021)", "journal-ref": "International AAAI Conference on Web and Social Media (ICWSM 2021)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a data-driven approach using word embeddings to discover and\ncategorise language biases on the discussion platform Reddit. As spaces for\nisolated user communities, platforms such as Reddit are increasingly connected\nto issues of racism, sexism and other forms of discrimination. Hence, there is\na need to monitor the language of these groups. One of the most promising AI\napproaches to trace linguistic biases in large textual datasets involves word\nembeddings, which transform text into high-dimensional dense vectors and\ncapture semantic relations between words. Yet, previous studies require\npredefined sets of potential biases to study, e.g., whether gender is more or\nless associated with particular types of jobs. This makes these approaches\nunfit to deal with smaller and community-centric datasets such as those on\nReddit, which contain smaller vocabularies and slang, as well as biases that\nmay be particular to that community. This paper proposes a data-driven approach\nto automatically discover language biases encoded in the vocabulary of online\ndiscourse communities on Reddit. In our approach, protected attributes are\nconnected to evaluative words found in the data, which are then categorised\nthrough a semantic analysis system. We verify the effectiveness of our method\nby comparing the biases we discover in the Google News dataset with those found\nin previous literature. We then successfully discover gender bias, religion\nbias, and ethnic bias in different Reddit communities. We conclude by\ndiscussing potential application scenarios and limitations of this data-driven\nbias discovery method.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 16:42:10 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 18:38:21 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Ferrer", "Xavier", ""], ["van Nuenen", "Tom", ""], ["Such", "Jose M.", ""], ["Criado", "Natalia", ""]]}, {"id": "2008.02837", "submitter": "Preslav Nakov", "authors": "Anton Chernyavskiy, Dmitry Ilvovsky, Preslav Nakov", "title": "aschern at SemEval-2020 Task 11: It Takes Three to Tango: RoBERTa, CRF,\n  and Transfer Learning", "comments": "propaganda, persuasion, disinformation, fake news", "journal-ref": "SemEval-2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe our system for SemEval-2020 Task 11 on Detection of Propaganda\nTechniques in News Articles. We developed ensemble models using RoBERTa-based\nneural architectures, additional CRF layers, transfer learning between the two\nsubtasks, and advanced post-processing to handle the multi-label nature of the\ntask, the consistency between nested spans, repetitions, and labels from\nsimilar spans in training. We achieved sizable improvements over baseline\nfine-tuned RoBERTa models, and the official evaluation ranked our system 3rd\n(almost tied with the 2nd) out of 36 teams on the span identification subtask\nwith an F1 score of 0.491, and 2nd (almost tied with the 1st) out of 31 teams\non the technique classification subtask with an F1 score of 0.62.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 18:45:25 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Chernyavskiy", "Anton", ""], ["Ilvovsky", "Dmitry", ""], ["Nakov", "Preslav", ""]]}, {"id": "2008.02858", "submitter": "Samridhi Choudhary", "authors": "Joseph P. McKenna, Samridhi Choudhary, Michael Saxon, Grant P.\n  Strimel, Athanasios Mouchtaris", "title": "Semantic Complexity in End-to-End Spoken Language Understanding", "comments": "Accepted at Interspeech, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end spoken language understanding (SLU) models are a class of model\narchitectures that predict semantics directly from speech. Because of their\ninput and output types, we refer to them as speech-to-interpretation (STI)\nmodels. Previous works have successfully applied STI models to targeted use\ncases, such as recognizing home automation commands, however no study has yet\naddressed how these models generalize to broader use cases. In this work, we\nanalyze the relationship between the performance of STI models and the\ndifficulty of the use case to which they are applied. We introduce empirical\nmeasures of dataset semantic complexity to quantify the difficulty of the SLU\ntasks. We show that near-perfect performance metrics for STI models reported in\nthe literature were obtained with datasets that have low semantic complexity\nvalues. We perform experiments where we vary the semantic complexity of a\nlarge, proprietary dataset and show that STI model performance correlates with\nour semantic complexity measures, such that performance increases as complexity\nvalues decrease. Our results show that it is important to contextualize an STI\nmodel's performance with the complexity values of its training dataset to\nreveal the scope of its applicability.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 20:18:53 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["McKenna", "Joseph P.", ""], ["Choudhary", "Samridhi", ""], ["Saxon", "Michael", ""], ["Strimel", "Grant P.", ""], ["Mouchtaris", "Athanasios", ""]]}, {"id": "2008.02878", "submitter": "Vassilina Nikoulina", "authors": "Alexandre B\\'erard, Zae Myung Kim, Vassilina Nikoulina, Eunjeong L.\n  Park, Matthias Gall\\'e", "title": "A Multilingual Neural Machine Translation Model for Biomedical Data", "comments": "https://github.com/naver/covid19-nmt", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We release a multilingual neural machine translation model, which can be used\nto translate text in the biomedical domain. The model can translate from 5\nlanguages (French, German, Italian, Korean and Spanish) into English. It is\ntrained with large amounts of generic and biomedical data, using domain tags.\nOur benchmarks show that it performs near state-of-the-art both on news\n(generic domain) and biomedical test sets, and that it outperforms the existing\npublicly released models. We believe that this release will help the\nlarge-scale multilingual analysis of the digital content of the COVID-19 crisis\nand of its effects on society, economy, and healthcare policies.\n  We also release a test set of biomedical text for Korean-English. It consists\nof 758 sentences from official guidelines and recent papers, all about\nCOVID-19.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 21:26:43 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["B\u00e9rard", "Alexandre", ""], ["Kim", "Zae Myung", ""], ["Nikoulina", "Vassilina", ""], ["Park", "Eunjeong L.", ""], ["Gall\u00e9", "Matthias", ""]]}, {"id": "2008.02879", "submitter": "Sida Wang", "authors": "Sida Wang, Weiwei Guo, Huiji Gao, Bo Long", "title": "Efficient Neural Query Auto Completion", "comments": "Accepted at CIKM 2020", "journal-ref": null, "doi": "10.1145/3340531.3412701", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Query Auto Completion (QAC), as the starting point of information retrieval\ntasks, is critical to user experience. Generally it has two steps: generating\ncompleted query candidates according to query prefixes, and ranking them based\non extracted features. Three major challenges are observed for a query auto\ncompletion system: (1) QAC has a strict online latency requirement. For each\nkeystroke, results must be returned within tens of milliseconds, which poses a\nsignificant challenge in designing sophisticated language models for it. (2)\nFor unseen queries, generated candidates are of poor quality as contextual\ninformation is not fully utilized. (3) Traditional QAC systems heavily rely on\nhandcrafted features such as the query candidate frequency in search logs,\nlacking sufficient semantic understanding of the candidate.\n  In this paper, we propose an efficient neural QAC system with effective\ncontext modeling to overcome these challenges. On the candidate generation\nside, this system uses as much information as possible in unseen prefixes to\ngenerate relevant candidates, increasing the recall by a large margin. On the\ncandidate ranking side, an unnormalized language model is proposed, which\neffectively captures deep semantics of queries. This approach presents better\nranking performance over state-of-the-art neural ranking methods and reduces\n$\\sim$95\\% latency compared to neural language modeling methods. The empirical\nresults on public datasets show that our model achieves a good balance between\naccuracy and efficiency. This system is served in LinkedIn job search with\nsignificant product impact observed.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 21:28:36 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Wang", "Sida", ""], ["Guo", "Weiwei", ""], ["Gao", "Huiji", ""], ["Long", "Bo", ""]]}, {"id": "2008.02885", "submitter": "Jake Williams", "authors": "Jake Ryland Williams, Diana Solano-Oropeza, and Jacob R. Hunsberger", "title": "A general solution to the preferential selection model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a general analytic solution to Herbert Simon's 1955 model for\ntime-evolving novelty functions. This has far-reaching consequences: Simon's is\na pre-cursor model for Barabasi's 1999 preferential attachment model for\ngrowing social networks, and our general abstraction of it more considers\nattachment to be a form of link selection. We show that any system which can be\nmodeled as instances of types---i.e., occurrence data (frequencies)---can be\ngeneratively modeled (and simulated) from a distributional perspective with an\nexceptionally high-degree of accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 21:51:00 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Williams", "Jake Ryland", ""], ["Solano-Oropeza", "Diana", ""], ["Hunsberger", "Jacob R.", ""]]}, {"id": "2008.02888", "submitter": "Yevgen Matusevych", "authors": "Yevgen Matusevych, Thomas Schatz, Herman Kamper, Naomi H. Feldman,\n  Sharon Goldwater", "title": "Evaluating computational models of infant phonetic learning across\n  languages", "comments": "7 pages, 1 figure", "journal-ref": "2020. In S. Denison, M. Mack, Y. Xu, and B. Armstrong (Eds.),\n  Proceedings of the 42nd Annual Conference of the Cognitive Science Society\n  (pp. 571-577). Austin, TX: Cognitive Science Society", "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the first year of life, infants' speech perception becomes attuned to the\nsounds of their native language. Many accounts of this early phonetic learning\nexist, but computational models predicting the attunement patterns observed in\ninfants from the speech input they hear have been lacking. A recent study\npresented the first such model, drawing on algorithms proposed for unsupervised\nlearning from naturalistic speech, and tested it on a single phone contrast.\nHere we study five such algorithms, selected for their potential cognitive\nrelevance. We simulate phonetic learning with each algorithm and perform tests\non three phone contrasts from different languages, comparing the results to\ninfants' discrimination patterns. The five models display varying degrees of\nagreement with empirical observations, showing that our approach can help\ndecide between candidate mechanisms for early phonetic learning, and providing\ninsight into which aspects of the models are critical for capturing infants'\nperceptual development.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 22:07:45 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Matusevych", "Yevgen", ""], ["Schatz", "Thomas", ""], ["Kamper", "Herman", ""], ["Feldman", "Naomi H.", ""], ["Goldwater", "Sharon", ""]]}, {"id": "2008.02954", "submitter": "Wenjun Qiu", "authors": "Wenjun Qiu and David Lie", "title": "Deep Active Learning with Crowdsourcing Data for Privacy Policy\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy policies are statements that notify users of the services' data\npractices. However, few users are willing to read through policy texts due to\nthe length and complexity. While automated tools based on machine learning\nexist for privacy policy analysis, to achieve high classification accuracy,\nclassifiers need to be trained on a large labeled dataset. Most existing policy\ncorpora are labeled by skilled human annotators, requiring significant amount\nof labor hours and effort. In this paper, we leverage active learning and\ncrowdsourcing techniques to develop an automated classification tool named\nCalpric (Crowdsourcing Active Learning PRIvacy Policy Classifier), which is\nable to perform annotation equivalent to those done by skilled human annotators\nwith high accuracy while minimizing the labeling cost. Specifically, active\nlearning allows classifiers to proactively select the most informative segments\nto be labeled. On average, our model is able to achieve the same F1 score using\nonly 62% of the original labeling effort. Calpric's use of active learning also\naddresses naturally occurring class imbalance in unlabeled privacy policy\ndatasets as there are many more statements stating the collection of private\ninformation than stating the absence of collection. By selecting samples from\nthe minority class for labeling, Calpric automatically creates a more balanced\ntraining set.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 02:13:31 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Qiu", "Wenjun", ""], ["Lie", "David", ""]]}, {"id": "2008.02964", "submitter": "Tian Lan", "authors": "Tian Lan, Xian-Ling Mao, Wei Wei, Heyan Huang", "title": "Which Kind Is Better in Open-domain Multi-turn Dialog,Hierarchical or\n  Non-hierarchical Models? An Empirical Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, open-domain generative dialog systems have attracted considerable\nattention in academia and industry. Despite the success of single-turn dialog\ngeneration, multi-turn dialog generation is still a big challenge. So far,\nthere are two kinds of models for open-domain multi-turn dialog generation:\nhierarchical and non-hierarchical models. Recently, some works have shown that\nthe hierarchical models are better than non-hierarchical models under their\nexperimental settings; meanwhile, some works also demonstrate the opposite\nconclusion. Due to the lack of adequate comparisons, it's not clear which kind\nof models are better in open-domain multi-turn dialog generation. Thus, in this\npaper, we will measure systematically nearly all representative hierarchical\nand non-hierarchical models over the same experimental settings to check which\nkind is better. Through extensive experiments, we have the following three\nimportant conclusions: (1) Nearly all hierarchical models are worse than\nnon-hierarchical models in open-domain multi-turn dialog generation, except for\nthe HRAN model. Through further analysis, the excellent performance of HRAN\nmainly depends on its word-level attention mechanism; (2) The performance of\nother hierarchical models will also obtain a great improvement if integrating\nthe word-level attention mechanism into these models. The modified hierarchical\nmodels even significantly outperform the non-hierarchical models; (3) The\nreason why the word-level attention mechanism is so powerful for hierarchical\nmodels is because it can leverage context information more effectively,\nespecially the fine-grained information. Besides, we have implemented all of\nthe models and already released the codes.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 02:54:55 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Lan", "Tian", ""], ["Mao", "Xian-Ling", ""], ["Wei", "Wei", ""], ["Huang", "Heyan", ""]]}, {"id": "2008.02976", "submitter": "Shankar Kumar", "authors": "Jared Lichtarge and Chris Alberti and Shankar Kumar", "title": "Data Weighted Training Strategies for Grammatical Error Correction", "comments": "Accepted to TACL (Transactions of the Association for Computational\n  Linguistics)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in the task of Grammatical Error Correction (GEC) has been\ndriven by addressing data sparsity, both through new methods for generating\nlarge and noisy pretraining data and through the publication of small and\nhigher-quality finetuning data in the BEA-2019 shared task. Building upon\nrecent work in Neural Machine Translation (NMT), we make use of both kinds of\ndata by deriving example-level scores on our large pretraining data based on a\nsmaller, higher-quality dataset. In this work, we perform an empirical study to\ndiscover how to best incorporate delta-log-perplexity, a type of example\nscoring, into a training schedule for GEC. In doing so, we perform experiments\nthat shed light on the function and applicability of delta-log-perplexity.\nModels trained on scored data achieve state-of-the-art results on common GEC\ntest sets.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 03:30:14 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 13:58:58 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Lichtarge", "Jared", ""], ["Alberti", "Chris", ""], ["Kumar", "Shankar", ""]]}, {"id": "2008.03020", "submitter": "Zeinab Rajabi", "authors": "Zeinab Rajabi, MohammadReza Valavi, Maryam Hourali", "title": "A Context-based Disambiguation Model for Sentiment Concepts Using a\n  Bag-of-concepts Approach", "comments": "This is a pre-print of an article published in Cogn Comput(2020)", "journal-ref": null, "doi": "10.1007/s12559-020-09729-1", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread dissemination of user-generated content on different\nsocial networks, and online consumer systems such as Amazon, the quantity of\nopinionated information available on the Internet has been increased. One of\nthe main tasks of the sentiment analysis is to detect polarity within a text.\nThe existing polarity detection methods mainly focus on keywords and their\nnaive frequency counts; however, they less regard the meanings and implicit\ndimensions of the natural concepts. Although background knowledge plays a\ncritical role in determining the polarity of concepts, it has been disregarded\nin polarity detection methods. This study presents a context-based model to\nsolve ambiguous polarity concepts using commonsense knowledge. First, a model\nis presented to generate a source of ambiguous sentiment concepts based on\nSenticNet by computing the probability distribution. Then the model uses a\nbag-of-concepts approach to remove ambiguities and semantic augmentation with\nthe ConceptNet handling to overcome lost knowledge. ConceptNet is a large-scale\nsemantic network with a large number of commonsense concepts. In this paper,\nthe point mutual information (PMI) measure is used to select the contextual\nconcepts having strong relationships with ambiguous concepts. The polarity of\nthe ambiguous concepts is precisely detected using positive/negative contextual\nconcepts and the relationship of the concepts in the semantic knowledge base.\nThe text representation scheme is semantically enriched using Numberbatch,\nwhich is a word embedding model based on the concepts from the ConceptNet\nsemantic network. The proposed model is evaluated by applying a corpus of\nproduct reviews, called Semeval. The experimental results revealed an accuracy\nrate of 82.07%, representing the effectiveness of the proposed model.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 07:16:40 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Rajabi", "Zeinab", ""], ["Valavi", "MohammadReza", ""], ["Hourali", "Maryam", ""]]}, {"id": "2008.03029", "submitter": "Yusong Wu", "authors": "Yusong Wu, Shengchen Li, Chengzhu Yu, Heng Lu, Chao Weng, Liqiang\n  Zhang, Dong Yu", "title": "Peking Opera Synthesis via Duration Informed Attention Network", "comments": "Accepted by INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peking Opera has been the most dominant form of Chinese performing art since\naround 200 years ago. A Peking Opera singer usually exhibits a very strong\npersonal style via introducing improvisation and expressiveness on stage which\nleads the actual rhythm and pitch contour to deviate significantly from the\noriginal music score. This inconsistency poses a great challenge in Peking\nOpera singing voice synthesis from a music score. In this work, we propose to\ndeal with this issue and synthesize expressive Peking Opera singing from the\nmusic score based on the Duration Informed Attention Network (DurIAN)\nframework. To tackle the rhythm mismatch, Lagrange multiplier is used to find\nthe optimal output phoneme duration sequence with the constraint of the given\nnote duration from music score. As for the pitch contour mismatch, instead of\ndirectly inferring from music score, we adopt a pseudo music score generated\nfrom the real singing and feed it as input during training. The experiments\ndemonstrate that with the proposed system we can synthesize Peking Opera\nsinging voice with high-quality timbre, pitch and expressiveness.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 08:04:41 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Wu", "Yusong", ""], ["Li", "Shengchen", ""], ["Yu", "Chengzhu", ""], ["Lu", "Heng", ""], ["Weng", "Chao", ""], ["Zhang", "Liqiang", ""], ["Yu", "Dong", ""]]}, {"id": "2008.03082", "submitter": "Jing Gu", "authors": "Jing Gu, Qingyang Wu, Zhou Yu", "title": "Perception Score, A Learned Metric for Open-ended Text Generation\n  Evaluation", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic evaluation for open-ended natural language generation tasks remains\na challenge. Existing metrics such as BLEU show a low correlation with human\njudgment. We propose a novel and powerful learning-based evaluation metric:\nPerception Score. The method measures the overall quality of the generation and\nscores holistically instead of only focusing on one evaluation criteria, such\nas word overlapping. Moreover, it also shows the amount of uncertainty about\nits evaluation result. By connecting the uncertainty, Perception Score gives a\nmore accurate evaluation for the generation system. Perception Score provides\nstate-of-the-art results on two conditional generation tasks and two\nunconditional generation tasks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 10:48:40 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 23:25:52 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Gu", "Jing", ""], ["Wu", "Qingyang", ""], ["Yu", "Zhou", ""]]}, {"id": "2008.03088", "submitter": "Wen-Chin Huang", "authors": "Wen-Chin Huang, Tomoki Hayashi, Yi-Chiao Wu, Hirokazu Kameoka, Tomoki\n  Toda", "title": "Pretraining Techniques for Sequence-to-Sequence Voice Conversion", "comments": "Preprint. Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence (seq2seq) voice conversion (VC) models are attractive\nowing to their ability to convert prosody. Nonetheless, without sufficient\ndata, seq2seq VC models can suffer from unstable training and mispronunciation\nproblems in the converted speech, thus far from practical. To tackle these\nshortcomings, we propose to transfer knowledge from other speech processing\ntasks where large-scale corpora are easily available, typically text-to-speech\n(TTS) and automatic speech recognition (ASR). We argue that VC models\ninitialized with such pretrained ASR or TTS model parameters can generate\neffective hidden representations for high-fidelity, highly intelligible\nconverted speech. We apply such techniques to recurrent neural network\n(RNN)-based and Transformer based models, and through systematical experiments,\nwe demonstrate the effectiveness of the pretraining scheme and the superiority\nof Transformer based models over RNN-based models in terms of intelligibility,\nnaturalness, and similarity.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 11:02:07 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Huang", "Wen-Chin", ""], ["Hayashi", "Tomoki", ""], ["Wu", "Yi-Chiao", ""], ["Kameoka", "Hirokazu", ""], ["Toda", "Tomoki", ""]]}, {"id": "2008.03101", "submitter": "David Adelani", "authors": "David Ifeoluwa Adelani, Ali Davody, Thomas Kleinbauer, and Dietrich\n  Klakow", "title": "Privacy Guarantees for De-identifying Text Transformations", "comments": "Proceedings of INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine Learning approaches to Natural Language Processing tasks benefit from\na comprehensive collection of real-life user data. At the same time, there is a\nclear need for protecting the privacy of the users whose data is collected and\nprocessed. For text collections, such as, e.g., transcripts of voice\ninteractions or patient records, replacing sensitive parts with benign\nalternatives can provide de-identification. However, how much privacy is\nactually guaranteed by such text transformations, and are the resulting texts\nstill useful for machine learning? In this paper, we derive formal privacy\nguarantees for general text transformation-based de-identification methods on\nthe basis of Differential Privacy. We also measure the effect that different\nways of masking private information in dialog transcripts have on a subsequent\nmachine learning task. To this end, we formulate different masking strategies\nand compare their privacy-utility trade-offs. In particular, we compare a\nsimple redact approach with more sophisticated word-by-word replacement using\ndeep learning models on multiple natural language understanding tasks like\nnamed entity recognition, intent detection, and dialog act classification. We\nfind that only word-by-word replacement is robust against performance drops in\nvarious tasks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 12:06:42 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Adelani", "David Ifeoluwa", ""], ["Davody", "Ali", ""], ["Kleinbauer", "Thomas", ""], ["Klakow", "Dietrich", ""]]}, {"id": "2008.03130", "submitter": "Caglar Demir", "authors": "Caglar Demir and Axel-Cyrille Ngonga Ngomo", "title": "Convolutional Complex Knowledge Graph Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of learning continuous vector\nrepresentations of knowledge graphs for predicting missing links. We present a\nnew approach called ConEx, which infers missing links by leveraging the\ncomposition of a 2D convolution with a Hermitian inner product of\ncomplex-valued embedding vectors. We evaluate ConEx against state-of-the-art\napproaches on the WN18RR, FB15K-237, KINSHIP and UMLS benchmark datasets. Our\nexperimental results show that ConEx achieves a performance superior to that of\nstate-of-the-art approaches such as RotatE, QuatE and TuckER on the link\nprediction task on all datasets while requiring at least 8 times fewer\nparameters. We ensure the reproducibility of our results by providing an\nopen-source implementation which includes the training, evaluation scripts\nalong with pre-trained models at https://github.com/conex-kge/ConEx.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 12:49:01 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 11:57:04 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 12:25:01 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Demir", "Caglar", ""], ["Ngomo", "Axel-Cyrille Ngonga", ""]]}, {"id": "2008.03156", "submitter": "Armen Aghajanyan", "authors": "Armen Aghajanyan, Akshat Shrivastava, Anchit Gupta, Naman Goyal, Luke\n  Zettlemoyer, Sonal Gupta", "title": "Better Fine-Tuning by Reducing Representational Collapse", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although widely adopted, existing approaches for fine-tuning pre-trained\nlanguage models have been shown to be unstable across hyper-parameter settings,\nmotivating recent work on trust region methods. In this paper, we present a\nsimplified and efficient method rooted in trust region theory that replaces\npreviously used adversarial objectives with parametric noise (sampling from\neither a normal or uniform distribution), thereby discouraging representation\nchange during fine-tuning when possible without hurting performance. We also\nintroduce a new analysis to motivate the use of trust region methods more\ngenerally, by studying representational collapse; the degradation of\ngeneralizable representations from pre-trained models as they are fine-tuned\nfor a specific end task. Extensive experiments show that our fine-tuning method\nmatches or exceeds the performance of previous trust region methods on a range\nof understanding and generation tasks (including DailyMail/CNN, Gigaword,\nReddit TIFU, and the GLUE benchmark), while also being much faster. We also\nshow that it is less prone to representation collapse; the pre-trained models\nmaintain more generalizable representations every time they are fine-tuned.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 02:13:16 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Aghajanyan", "Armen", ""], ["Shrivastava", "Akshat", ""], ["Gupta", "Anchit", ""], ["Goyal", "Naman", ""], ["Zettlemoyer", "Luke", ""], ["Gupta", "Sonal", ""]]}, {"id": "2008.03164", "submitter": "Jens Kaiser", "authors": "Jens Kaiser, Dominik Schlechtweg, Sean Papay, Sabine Schulte im Walde", "title": "IMS at SemEval-2020 Task 1: How low can you go? Dimensionality in\n  Lexical Semantic Change Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present the results of our system for SemEval-2020 Task 1 that exploits a\ncommonly used lexical semantic change detection model based on Skip-Gram with\nNegative Sampling. Our system focuses on Vector Initialization (VI) alignment,\ncompares VI to the currently top-ranking models for Subtask 2 and demonstrates\nthat these can be outperformed if we optimize VI dimensionality. We demonstrate\nthat differences in performance can largely be attributed to model-specific\nsources of noise, and we reveal a strong relationship between dimensionality\nand frequency-induced noise in VI alignment. Our results suggest that lexical\nsemantic change models integrating vector space alignment should pay more\nattention to the role of the dimensionality parameter.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 13:16:28 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Kaiser", "Jens", ""], ["Schlechtweg", "Dominik", ""], ["Papay", "Sean", ""], ["Walde", "Sabine Schulte im", ""]]}, {"id": "2008.03183", "submitter": "G\\'abor Gosztolya", "authors": "G\\'abor Gosztolya and L\\'aszl\\'o T\\'oth", "title": "Applying Speech Tempo-Derived Features, BoAW and Fisher Vectors to\n  Detect Elderly Emotion and Speech in Surgical Masks", "comments": "rejected from Interspeech, ComParE Challenge (Mask & Elderly Emotion\n  Sub-Challenges)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 2020 INTERSPEECH Computational Paralinguistics Challenge (ComParE)\nconsists of three Sub-Challenges, where the tasks are to identify the level of\narousal and valence of elderly speakers, determine whether the actual speaker\nwearing a surgical mask, and estimate the actual breathing of the speaker. In\nour contribution to the Challenge, we focus on the Elderly Emotion and the Mask\nsub-challenges. Besides utilizing standard or close-to-standard features such\nas ComParE functionals, Bag-of-Audio-Words and Fisher vectors, we exploit that\nemotion is related to the velocity of speech (i.e. speech rate). To utilize\nthis, we perform phone-level recognition using an ASR system, and extract\nfeatures from the output such as articulation tempo, speech tempo, and various\nattributes measuring the amount of pauses. We also hypothesize that wearing a\nsurgical mask makes the speaker feel uneasy, leading to a slower speech rate\nand more hesitations; hence, we experiment with the same features in the Mask\nsub-challenge as well. Although this theory was not justified by the\nexperimental results on the Mask Sub-Challenge, in the Elderly Emotion\nSub-Challenge we got significantly improved arousal and valence values with\nthis feature type both on the development set and in cross-validation.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 13:42:25 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Gosztolya", "G\u00e1bor", ""], ["T\u00f3th", "L\u00e1szl\u00f3", ""]]}, {"id": "2008.03232", "submitter": "Fouzi Harrag", "authors": "Fouzi Harrag, Abdullah Al-Nasser, Abdullah Al-Musnad, Rayan Al-Shaya", "title": "Quran Intelligent Ontology Construction Approach Using Association Rules\n  Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontology can be seen as a formal representation of knowledge. They have been\ninvestigated in many artificial intelligence studies including semantic web,\nsoftware engineering, and information retrieval. The aim of ontology is to\ndevelop knowledge representations that can be shared and reused. This research\nproject is concerned with the use of association rules to extract the Quran\nontology. The manual acquisition of ontologies from Quran verses can be very\ncostly; therefore, we need an intelligent system for Quran ontology\nconstruction using patternbased schemes and associations rules to discover\nQuran concepts and semantics relations from Quran verses. Our system is based\non the combination of statistics and linguistics methods to extract concepts\nand conceptual relations from Quran. In particular, a linguistic pattern-based\napproach is exploited to extract specific concepts from the Quran, while the\nconceptual relations are found based on association rules technique. The Quran\nontology will offer a new and powerful representation of Quran knowledge, and\nthe association rules will help to represent the relations between all classes\nof connected concepts in the Quran ontology.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 15:48:58 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 01:30:31 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Harrag", "Fouzi", ""], ["Al-Nasser", "Abdullah", ""], ["Al-Musnad", "Abdullah", ""], ["Al-Shaya", "Rayan", ""]]}, {"id": "2008.03274", "submitter": "Amirreza Shirani", "authors": "Amirreza Shirani, Franck Dernoncourt, Nedim Lipka, Paul Asente, Jose\n  Echevarria and Thamar Solorio", "title": "SemEval-2020 Task 10: Emphasis Selection for Written Text in Visual\n  Media", "comments": "Accepted at Proceedings of 14th International Workshop on Semantic\n  Evaluation (SemEval-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present the main findings and compare the results of\nSemEval-2020 Task 10, Emphasis Selection for Written Text in Visual Media. The\ngoal of this shared task is to design automatic methods for emphasis selection,\ni.e. choosing candidates for emphasis in textual content to enable automated\ndesign assistance in authoring. The main focus is on short text instances for\nsocial media, with a variety of examples, from social media posts to\ninspirational quotes. Participants were asked to model emphasis using plain\ntext with no additional context from the user or other design considerations.\nSemEval-2020 Emphasis Selection shared task attracted 197 participants in the\nearly phase and a total of 31 teams made submissions to this task. The\nhighest-ranked submission achieved 0.823 Matchm score. The analysis of systems\nsubmitted to the task indicates that BERT and RoBERTa were the most common\nchoice of pre-trained models used, and part of speech tag (POS) was the most\nuseful feature. Full results can be found on the task's website.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 17:24:53 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Shirani", "Amirreza", ""], ["Dernoncourt", "Franck", ""], ["Lipka", "Nedim", ""], ["Asente", "Paul", ""], ["Echevarria", "Jose", ""], ["Solorio", "Thamar", ""]]}, {"id": "2008.03277", "submitter": "Christopher Wang", "authors": "Christopher Wang, Candace Ross, Yen-Ling Kuo, Boris Katz, Andrei Barbu", "title": "Learning a natural-language to LTL executable semantic parser for\n  grounded robotics", "comments": "10 pages, 2 figures, Accepted in Conference on Robot Learning (CoRL)\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Children acquire their native language with apparent ease by observing how\nlanguage is used in context and attempting to use it themselves. They do so\nwithout laborious annotations, negative examples, or even direct corrections.\nWe take a step toward robots that can do the same by training a grounded\nsemantic parser, which discovers latent linguistic representations that can be\nused for the execution of natural-language commands. In particular, we focus on\nthe difficult domain of commands with a temporal aspect, whose semantics we\ncapture with Linear Temporal Logic, LTL. Our parser is trained with pairs of\nsentences and executions as well as an executor. At training time, the parser\nhypothesizes a meaning representation for the input as a formula in LTL. Three\ncompeting pressures allow the parser to discover meaning from language. First,\nany hypothesized meaning for a sentence must be permissive enough to reflect\nall the annotated execution trajectories. Second, the executor -- a pretrained\nend-to-end LTL planner -- must find that the observe trajectories are likely\nexecutions of the meaning. Finally, a generator, which reconstructs the\noriginal input, encourages the model to find representations that conserve\nknowledge about the command. Together these ensure that the meaning is neither\ntoo general nor too specific. Our model generalizes well, being able to parse\nand execute both machine-generated and human-generated commands, with\nnear-equal accuracy, despite the fact that the human-generated sentences are\nmuch more varied and complex with an open lexicon. The approach presented here\nis not specific to LTL: it can be applied to any domain where sentence meanings\ncan be hypothesized and an executor can verify these meanings, thus opening the\ndoor to many applications for robotic agents.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 17:28:32 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 23:43:28 GMT"}, {"version": "v3", "created": "Wed, 17 Mar 2021 03:53:20 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Wang", "Christopher", ""], ["Ross", "Candace", ""], ["Kuo", "Yen-Ling", ""], ["Katz", "Boris", ""], ["Barbu", "Andrei", ""]]}, {"id": "2008.03340", "submitter": "Xiruo Ding", "authors": "Xiruo Ding, Trevor Cohen", "title": "Retrofitting Vector Representations of Adverse Event Reporting Data to\n  Structured Knowledge to Improve Pharmacovigilance Signal Detection", "comments": "To be published in the Proceedings of AMIA 2020 Annual Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adverse drug events (ADE) are prevalent and costly. Clinical trials are\nconstrained in their ability to identify potential ADEs, motivating the\ndevelopment of spontaneous reporting systems for post-market surveillance.\nStatistical methods provide a convenient way to detect signals from these\nreports but have limitations in leveraging relationships between drugs and ADEs\ngiven their discrete count-based nature. A previously proposed method, aer2vec,\ngenerates distributed vector representations of ADE report entities that\ncapture patterns of similarity but cannot utilize lexical knowledge. We address\nthis limitation by retrofitting aer2vec drug embeddings to knowledge from\nRxNorm and developing a novel retrofitting variant using vector rescaling to\npreserve magnitude. When evaluated in the context of a pharmacovigilance signal\ndetection task, aer2vec with retrofitting consistently outperforms\ndisproportionality metrics when trained on minimally preprocessed data.\nRetrofitting with rescaling results in further improvements in the larger and\nmore challenging of two pharmacovigilance reference sets used for evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 19:11:51 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Ding", "Xiruo", ""], ["Cohen", "Trevor", ""]]}, {"id": "2008.03359", "submitter": "Homayoon Beigi", "authors": "Lin Ai and Shih-Ying Jeng and Homayoon Beigi", "title": "A New Approach to Accent Recognition and Conversion for Mandarin Chinese", "comments": "11 pages, 7 figures, and 10 tables", "journal-ref": null, "doi": null, "report-no": "RTI-20200218-01", "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two new approaches to accent classification and conversion are presented and\nexplored, respectively. The first topic is Chinese accent\nclassification/recognition. The second topic is the use of encoder-decoder\nmodels for end-to-end Chinese accent conversion, where the classifier in the\nfirst topic is used for the training of the accent converter encoder-decoder\nmodel. Experiments using different features and model are performed for accent\nrecognition. These features include MFCCs and spectrograms. The classifier\nmodels were TDNN and 1D-CNN. On the MAGICDATA dataset with 5 classes of\naccents, the TDNN classifier trained on MFCC features achieved a test accuracy\nof 54% and a test F1 score of 0.54 while the 1D-CNN classifier trained on\nspectrograms achieve a test accuracy of 62% and a test F1 score of 0.62. A\nprototype of an end-to-end accent converter model is also presented. The\nconverter model comprises of an encoder and a decoder. The encoder model\nconverts an accented input into an accent-neutral form. The decoder model\nconverts an accent-neutral form to an accented form with the specified accent\nassigned by the input accent label. The converter prototype preserves the tone\nand foregoes the details in the output audio. An encoder-decoder structure\ndemonstrates the potential of being an effective accent converter. A proposal\nfor future improvements is also presented to address the issue of lost details\nin the decoder output.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 20:06:33 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Ai", "Lin", ""], ["Jeng", "Shih-Ying", ""], ["Beigi", "Homayoon", ""]]}, {"id": "2008.03391", "submitter": "Pengjie Ren", "authors": "Phillip Lippe, Pengjie Ren, Hinda Haned, Bart Voorn, and Maarten de\n  Rijke", "title": "Diversifying Task-oriented Dialogue Response Generation with Prototype\n  Guided Paraphrasing", "comments": "under review at TASLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing methods for Dialogue Response Generation (DRG) in Task-oriented\nDialogue Systems (TDSs) can be grouped into two categories: template-based and\ncorpus-based. The former prepare a collection of response templates in advance\nand fill the slots with system actions to produce system responses at runtime.\nThe latter generate system responses token by token by taking system actions\ninto account. While template-based DRG provides high precision and highly\npredictable responses, they usually lack in terms of generating diverse and\nnatural responses when compared to (neural) corpus-based approaches.\nConversely, while corpus-based DRG methods are able to generate natural\nresponses, we cannot guarantee their precision or predictability. Moreover, the\ndiversity of responses produced by today's corpus-based DRG methods is still\nlimited. We propose to combine the merits of template-based and corpus-based\nDRGs by introducing a prototype-based, paraphrasing neural network, called\nP2-Net, which aims to enhance quality of the responses in terms of both\nprecision and diversity. Instead of generating a response from scratch, P2-Net\ngenerates system responses by paraphrasing template-based responses. To\nguarantee the precision of responses, P2-Net learns to separate a response into\nits semantics, context influence, and paraphrasing noise, and to keep the\nsemantics unchanged during paraphrasing. To introduce diversity, P2-Net\nrandomly samples previous conversational utterances as prototypes, from which\nthe model can then extract speaking style information. We conduct extensive\nexperiments on the MultiWOZ dataset with both automatic and human evaluations.\nThe results show that P2-Net achieves a significant improvement in diversity\nwhile preserving the semantics of responses.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 22:25:36 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Lippe", "Phillip", ""], ["Ren", "Pengjie", ""], ["Haned", "Hinda", ""], ["Voorn", "Bart", ""], ["de Rijke", "Maarten", ""]]}, {"id": "2008.03403", "submitter": "Ahmed Ali", "authors": "Ahmed Ali and Steve Renals", "title": "Word Error Rate Estimation Without ASR Output: e-WER2", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring the performance of automatic speech recognition (ASR) systems\nrequires manually transcribed data in order to compute the word error rate\n(WER), which is often time-consuming and expensive. In this paper, we continue\nour effort in estimating WER using acoustic, lexical and phonotactic features.\nOur novel approach to estimate the WER uses a multistream end-to-end\narchitecture. We report results for systems using internal speech decoder\nfeatures (glass-box), systems without speech decoder features (black-box), and\nfor systems without having access to the ASR system (no-box). The no-box system\nlearns joint acoustic-lexical representation from phoneme recognition results\nalong with MFCC acoustic features to estimate WER. Considering WER per\nsentence, our no-box system achieves 0.56 Pearson correlation with the\nreference evaluation and 0.24 root mean square error (RMSE) across 1,400\nsentences. The estimated overall WER by e-WER2 is 30.9% for a three hours test\nset, while the WER computed using the reference transcriptions was 28.5%.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 00:19:09 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Ali", "Ahmed", ""], ["Renals", "Steve", ""]]}, {"id": "2008.03408", "submitter": "Bo Wang", "authors": "Bo Wang, Yue Wu, Niall Taylor, Terry Lyons, Maria Liakata, Alejo J\n  Nevado-Holgado, Kate E A Saunders", "title": "Learning to Detect Bipolar Disorder and Borderline Personality Disorder\n  with Language and Speech in Non-Clinical Interviews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bipolar disorder (BD) and borderline personality disorder (BPD) are both\nchronic psychiatric disorders. However, their overlapping symptoms and common\ncomorbidity make it challenging for the clinicians to distinguish the two\nconditions on the basis of a clinical interview. In this work, we first present\na new multi-modal dataset containing interviews involving individuals with BD\nor BPD being interviewed about a non-clinical topic . We investigate the\nautomatic detection of the two conditions, and demonstrate a good linear\nclassifier that can be learnt using a down-selected set of features from the\ndifferent aspects of the interviews and a novel approach of summarising these\nfeatures. Finally, we find that different sets of features characterise BD and\nBPD, thus providing insights into the difference between the automatic\nscreening of the two conditions.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 00:48:59 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 04:23:15 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wang", "Bo", ""], ["Wu", "Yue", ""], ["Taylor", "Niall", ""], ["Lyons", "Terry", ""], ["Liakata", "Maria", ""], ["Nevado-Holgado", "Alejo J", ""], ["Saunders", "Kate E A", ""]]}, {"id": "2008.03415", "submitter": "Shubhanshu Mishra", "authors": "Shubhanshu Mishra, Sijun He, Luca Belli", "title": "Assessing Demographic Bias in Named Entity Recognition", "comments": "Presented at the AKBC Workshop on Bias in Automatic Knowledge Graph\n  Construction, 2020 (arXiv:2007.11659)", "journal-ref": null, "doi": null, "report-no": "REPORT-NO:KGBias/2020/02", "categories": "cs.CL cs.CY cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Named Entity Recognition (NER) is often the first step towards automated\nKnowledge Base (KB) generation from raw text. In this work, we assess the bias\nin various Named Entity Recognition (NER) systems for English across different\ndemographic groups with synthetically generated corpora. Our analysis reveals\nthat models perform better at identifying names from specific demographic\ngroups across two datasets. We also identify that debiased embeddings do not\nhelp in resolving this issue. Finally, we observe that character-based\ncontextualized word representation models such as ELMo results in the least\nbias across demographics. Our work can shed light on potential biases in\nautomated KB generation due to systematic exclusion of named entities belonging\nto certain demographics.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 02:01:25 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Mishra", "Shubhanshu", ""], ["He", "Sijun", ""], ["Belli", "Luca", ""]]}, {"id": "2008.03417", "submitter": "Xiaohui Song", "authors": "Song Xiaohui and Hu Songlin", "title": "Point or Generate Dialogue State Tracker", "comments": "rejected in emnlp-ijcnlp 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue state tracking is a key part of a task-oriented dialogue system,\nwhich estimates the user's goal at each turn of the dialogue. In this paper, we\npropose the Point-Or-Generate Dialogue State Tracker (POGD). POGD solves the\ndialogue state tracking task in two perspectives: 1) point out explicitly\nexpressed slot values from the user's utterance, and 2) generate implicitly\nexpressed ones based on slot-specific contexts. It also shares parameters\nacross all slots, which achieves knowledge sharing and gains scalability to\nlarge-scale across-domain dialogues. Moreover, the training process of its\nsubmodules is formulated as a multi-task learning procedure to further promote\nits capability of generalization. Experiments show that POGD not only obtains\nstate-of-the-art results on both WoZ 2.0 and MultiWoZ 2.0 datasets but also has\ngood generalization on unseen values and new slots.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 02:15:25 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Xiaohui", "Song", ""], ["Songlin", "Hu", ""]]}, {"id": "2008.03425", "submitter": "Leda Sar{\\i}", "authors": "Leda Sar{\\i} and Mark Hasegawa-Johnson", "title": "Deep F-measure Maximization for End-to-End Speech Understanding", "comments": "Interspeech 2020 submission (Accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken language understanding (SLU) datasets, like many other machine\nlearning datasets, usually suffer from the label imbalance problem. Label\nimbalance usually causes the learned model to replicate similar biases at the\noutput which raises the issue of unfairness to the minority classes in the\ndataset. In this work, we approach the fairness problem by maximizing the\nF-measure instead of accuracy in neural network model training. We propose a\ndifferentiable approximation to the F-measure and train the network with this\nobjective using standard backpropagation. We perform experiments on two\nstandard fairness datasets, Adult, and Communities and Crime, and also on\nspeech-to-intent detection on the ATIS dataset and speech-to-image concept\nclassification on the Speech-COCO dataset. In all four of these tasks,\nF-measure maximization results in improved micro-F1 scores, with absolute\nimprovements of up to 8% absolute, as compared to models trained with the\ncross-entropy loss function. In the two multi-class SLU tasks, the proposed\napproach significantly improves class coverage, i.e., the number of classes\nwith positive recall.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 03:02:27 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Sar\u0131", "Leda", ""], ["Hasegawa-Johnson", "Mark", ""]]}, {"id": "2008.03687", "submitter": "Jin Xu", "authors": "Jin Xu, Xu Tan, Yi Ren, Tao Qin, Jian Li, Sheng Zhao, Tie-Yan Liu", "title": "LRSpeech: Extremely Low-Resource Speech Synthesis and Recognition", "comments": null, "journal-ref": "KDD 2020", "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech synthesis (text to speech, TTS) and recognition (automatic speech\nrecognition, ASR) are important speech tasks, and require a large amount of\ntext and speech pairs for model training. However, there are more than 6,000\nlanguages in the world and most languages are lack of speech training data,\nwhich poses significant challenges when building TTS and ASR systems for\nextremely low-resource languages. In this paper, we develop LRSpeech, a TTS and\nASR system under the extremely low-resource setting, which can support rare\nlanguages with low data cost. LRSpeech consists of three key techniques: 1)\npre-training on rich-resource languages and fine-tuning on low-resource\nlanguages; 2) dual transformation between TTS and ASR to iteratively boost the\naccuracy of each other; 3) knowledge distillation to customize the TTS model on\na high-quality target-speaker voice and improve the ASR model on multiple\nvoices. We conduct experiments on an experimental language (English) and a\ntruly low-resource language (Lithuanian) to verify the effectiveness of\nLRSpeech. Experimental results show that LRSpeech 1) achieves high quality for\nTTS in terms of both intelligibility (more than 98% intelligibility rate) and\nnaturalness (above 3.5 mean opinion score (MOS)) of the synthesized speech,\nwhich satisfy the requirements for industrial deployment, 2) achieves promising\nrecognition accuracy for ASR, and 3) last but not least, uses extremely\nlow-resource training data. We also conduct comprehensive analyses on LRSpeech\nwith different amounts of data resources, and provide valuable insights and\nguidances for industrial deployment. We are currently deploying LRSpeech into a\ncommercialized cloud speech service to support TTS on more rare languages.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 08:16:33 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Xu", "Jin", ""], ["Tan", "Xu", ""], ["Ren", "Yi", ""], ["Qin", "Tao", ""], ["Li", "Jian", ""], ["Zhao", "Sheng", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2008.03709", "submitter": "Xiaosen Wang", "authors": "Xiaosen Wang, Yichen Yang, Yihe Deng, Kun He", "title": "Adversarial Training with Fast Gradient Projection Method against\n  Synonym Substitution based Text Attacks", "comments": "Accepted by AAAI 2021, code is available at\n  https://github.com/JHL-HUST/FGPM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is the most empirically successful approach in improving\nthe robustness of deep neural networks for image classification.For text\nclassification, however, existing synonym substitution based adversarial\nattacks are effective but not efficient to be incorporated into practical text\nadversarial training. Gradient-based attacks, which are very efficient for\nimages, are hard to be implemented for synonym substitution based text attacks\ndue to the lexical, grammatical and semantic constraints and the discrete text\ninput space. Thereby, we propose a fast text adversarial attack method called\nFast Gradient Projection Method (FGPM) based on synonym substitution, which is\nabout 20 times faster than existing text attack methods and could achieve\nsimilar attack performance. We then incorporate FGPM with adversarial training\nand propose a text defense method called Adversarial Training with FGPM\nenhanced by Logit pairing (ATFL). Experiments show that ATFL could\nsignificantly improve the model robustness and block the transferability of\nadversarial examples.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 11:02:06 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 14:59:24 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 06:51:01 GMT"}, {"version": "v4", "created": "Wed, 16 Dec 2020 03:01:25 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Wang", "Xiaosen", ""], ["Yang", "Yichen", ""], ["Deng", "Yihe", ""], ["He", "Kun", ""]]}, {"id": "2008.03717", "submitter": "Antonios Minas Krasakis", "authors": "Antonios Minas Krasakis, Mohammad Aliannejadi, Nikos Voskarides,\n  Evangelos Kanoulas", "title": "Analysing the Effect of Clarifying Questions on Document Ranking in\n  Conversational Search", "comments": "Proceedings of the 2020 ACM SIGIR International Conference on the\n  Theory of Information Retrieval (ICTIR '20), September 14-17, 2020", "journal-ref": null, "doi": "10.1145/3409256.3409817", "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research on conversational search highlights the importance of\nmixed-initiative in conversations. To enable mixed-initiative, the system\nshould be able to ask clarifying questions to the user. However, the ability of\nthe underlying ranking models (which support conversational search) to account\nfor these clarifying questions and answers has not been analysed when ranking\ndocuments, at large. To this end, we analyse the performance of a lexical\nranking model on a conversational search dataset with clarifying questions. We\ninvestigate, both quantitatively and qualitatively, how different aspects of\nclarifying questions and user answers affect the quality of ranking. We argue\nthat there needs to be some fine-grained treatment of the entire conversational\nround of clarification, based on the explicit feedback which is present in such\nmixed-initiative settings. Informed by our findings, we introduce a simple\nheuristic-based lexical baseline, that significantly outperforms the existing\nnaive baselines. Our work aims to enhance our understanding of the challenges\npresent in this particular task and inform the design of more appropriate\nconversational ranking models.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 12:55:16 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 10:21:13 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Krasakis", "Antonios Minas", ""], ["Aliannejadi", "Mohammad", ""], ["Voskarides", "Nikos", ""], ["Kanoulas", "Evangelos", ""]]}, {"id": "2008.03736", "submitter": "Yu Zhang", "authors": "Yu Zhang, Houquan Zhou, Zhenghua Li", "title": "Fast and Accurate Neural CRF Constituency Parsing", "comments": "IJCAI 2020", "journal-ref": null, "doi": "10.24963/ijcai.2020/560", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating probability distribution is one of the core issues in the NLP\nfield. However, in both deep learning (DL) and pre-DL eras, unlike the vast\napplications of linear-chain CRF in sequence labeling tasks, very few works\nhave applied tree-structure CRF to constituency parsing, mainly due to the\ncomplexity and inefficiency of the inside-outside algorithm. This work presents\na fast and accurate neural CRF constituency parser. The key idea is to batchify\nthe inside algorithm for loss computation by direct large tensor operations on\nGPU, and meanwhile avoid the outside algorithm for gradient computation via\nefficient back-propagation. We also propose a simple two-stage\nbracketing-then-labeling parsing approach to improve efficiency further. To\nimprove the parsing performance, inspired by recent progress in dependency\nparsing, we introduce a new scoring architecture based on boundary\nrepresentation and biaffine attention, and a beneficial dropout strategy.\nExperiments on PTB, CTB5.1, and CTB7 show that our two-stage CRF parser\nachieves new state-of-the-art performance on both settings of w/o and w/ BERT,\nand can parse over 1,000 sentences per second. We release our code at\nhttps://github.com/yzhangcs/crfpar.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 14:38:48 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Zhang", "Yu", ""], ["Zhou", "Houquan", ""], ["Li", "Zhenghua", ""]]}, {"id": "2008.03802", "submitter": "Jan Vainer", "authors": "Jan Vainer, Ond\\v{r}ej Du\\v{s}ek", "title": "SpeedySpeech: Efficient Neural Speech Synthesis", "comments": "5 pages, 3 figures, Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While recent neural sequence-to-sequence models have greatly improved the\nquality of speech synthesis, there has not been a system capable of fast\ntraining, fast inference and high-quality audio synthesis at the same time. We\npropose a student-teacher network capable of high-quality faster-than-real-time\nspectrogram synthesis, with low requirements on computational resources and\nfast training time. We show that self-attention layers are not necessary for\ngeneration of high quality audio. We utilize simple convolutional blocks with\nresidual connections in both student and teacher networks and use only a single\nattention layer in the teacher model. Coupled with a MelGAN vocoder, our\nmodel's voice quality was rated significantly higher than Tacotron 2. Our model\ncan be efficiently trained on a single GPU and can run in real time even on a\nCPU. We provide both our source code and audio samples in our GitHub\nrepository.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 20:00:57 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Vainer", "Jan", ""], ["Du\u0161ek", "Ond\u0159ej", ""]]}, {"id": "2008.03822", "submitter": "Hayato Futami", "authors": "Hayato Futami, Hirofumi Inaguma, Sei Ueno, Masato Mimura, Shinsuke\n  Sakai and Tatsuya Kawahara", "title": "Distilling the Knowledge of BERT for Sequence-to-Sequence ASR", "comments": "Accepted in INTERSPEECH2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based sequence-to-sequence (seq2seq) models have achieved promising\nresults in automatic speech recognition (ASR). However, as these models decode\nin a left-to-right way, they do not have access to context on the right. We\nleverage both left and right context by applying BERT as an external language\nmodel to seq2seq ASR through knowledge distillation. In our proposed method,\nBERT generates soft labels to guide the training of seq2seq ASR. Furthermore,\nwe leverage context beyond the current utterance as input to BERT. Experimental\nevaluations show that our method significantly improves the ASR performance\nfrom the seq2seq baseline on the Corpus of Spontaneous Japanese (CSJ).\nKnowledge distillation from BERT outperforms that from a transformer LM that\nonly looks at left context. We also show the effectiveness of leveraging\ncontext beyond the current utterance. Our method outperforms other LM\napplication approaches such as n-best rescoring and shallow fusion, while it\ndoes not require extra inference cost.\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 21:48:02 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Futami", "Hayato", ""], ["Inaguma", "Hirofumi", ""], ["Ueno", "Sei", ""], ["Mimura", "Masato", ""], ["Sakai", "Shinsuke", ""], ["Kawahara", "Tatsuya", ""]]}, {"id": "2008.03843", "submitter": "Ahmed Ramzy", "authors": "Ahmed Ramzy and Ahmed Elazab", "title": "Question Identification in Arabic Language Using Emotional Based\n  Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growth of content on social media networks, enterprises and services\nproviders have become interested in identifying the questions of their\ncustomers. Tracking these questions become very challenging with the growth of\ntext that grows directly proportional to the increase of Arabic users thus\nmaking it very difficult to be tracked manually. By automatic identifying the\nquestions seeking answers on the social media networks and defining their\ncategory, we can automatically answer them by finding an existing answer or\neven routing them to those responsible for answering those questions in the\ncustomer service. This will result in saving the time and the effort and\nenhancing the customer feedback and improving the business. In this paper, we\nhave implemented a binary classifier to classify Arabic text to either question\nseeking answer or not. We have added emotional based features to the state of\nthe art features. Experimental evaluation has done and showed that these\nemotional features have improved the accuracy of the classifier.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 00:18:32 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Ramzy", "Ahmed", ""], ["Elazab", "Ahmed", ""]]}, {"id": "2008.03923", "submitter": "Prakhar Swarup", "authors": "Prakhar Swarup, Debmalya Chakrabarty, Ashtosh Sapru, Hitesh Tulsiani,\n  Harish Arsikere, Sri Garimella", "title": "Knowledge Distillation and Data Selection for Semi-Supervised Learning\n  in CTC Acoustic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning (SSL) is an active area of research which aims to\nutilize unlabelled data in order to improve the accuracy of speech recognition\nsystems. The current study proposes a methodology for integration of two key\nideas: 1) SSL using connectionist temporal classification (CTC) objective and\nteacher-student based learning 2) Designing effective data-selection mechanisms\nfor leveraging unlabelled data to boost performance of student models. Our aim\nis to establish the importance of good criteria in selecting samples from a\nlarge pool of unlabelled data based on attributes like confidence measure,\nspeaker and content variability. The question we try to answer is: Is it\npossible to design a data selection mechanism which reduces dependence on a\nlarge set of randomly selected unlabelled samples without compromising on Word\nError Rate (WER)? We perform empirical investigations of different data\nselection methods to answer this question and quantify the effect of different\nsampling strategies. On a semi-supervised ASR setting with 40000 hours of\ncarefully selected unlabelled data, our CTC-SSL approach gives 17% relative WER\nimprovement over a baseline CTC system trained with labelled data. It also\nachieves on-par performance with CTC-SSL system trained on order of magnitude\nlarger unlabeled data based on random sampling.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 07:00:08 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Swarup", "Prakhar", ""], ["Chakrabarty", "Debmalya", ""], ["Sapru", "Ashtosh", ""], ["Tulsiani", "Hitesh", ""], ["Arsikere", "Harish", ""], ["Garimella", "Sri", ""]]}, {"id": "2008.03945", "submitter": "Leyang Cui", "authors": "Leyang Cui, Sijie Cheng, Yu Wu, Yue Zhang", "title": "On Commonsense Cues in BERT for Solving Commonsense Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BERT has been used for solving commonsense tasks such as CommonsenseQA. While\nprior research has found that BERT does contain commonsense information to some\nextent, there has been work showing that pre-trained models can rely on\nspurious associations (e.g., data bias) rather than key cues in solving\nsentiment classification and other problems. We quantitatively investigate the\npresence of structural commonsense cues in BERT when solving commonsense tasks,\nand the importance of such cues for the model prediction. Using two different\nmeasures, we find that BERT does use relevant knowledge for solving the task,\nand the presence of commonsense knowledge is positively correlated to the model\naccuracy.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 08:12:34 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 11:24:36 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 07:07:25 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Cui", "Leyang", ""], ["Cheng", "Sijie", ""], ["Wu", "Yu", ""], ["Zhang", "Yue", ""]]}, {"id": "2008.03946", "submitter": "Yida Wang", "authors": "Yida Wang, Pei Ke, Yinhe Zheng, Kaili Huang, Yong Jiang, Xiaoyan Zhu,\n  and Minlie Huang", "title": "A Large-Scale Chinese Short-Text Conversation Dataset", "comments": "Accepted to NLPCC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advancements of neural dialogue generation models show promising results\non modeling short-text conversations. However, training such models usually\nneeds a large-scale high-quality dialogue corpus, which is hard to access. In\nthis paper, we present a large-scale cleaned Chinese conversation dataset,\nLCCC, which contains a base version (6.8million dialogues) and a large version\n(12.0 million dialogues). The quality of our dataset is ensured by a rigorous\ndata cleaning pipeline, which is built based on a set of rules and a classifier\nthat is trained on manually annotated 110K dialogue pairs. We also release\npre-training dialogue models which are trained on LCCC-base and LCCC-large\nrespectively. The cleaned dataset and the pre-training models will facilitate\nthe research of short-text conversation modeling. All the models and datasets\nare available at https://github.com/thu-coai/CDial-GPT.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 08:12:49 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Wang", "Yida", ""], ["Ke", "Pei", ""], ["Zheng", "Yinhe", ""], ["Huang", "Kaili", ""], ["Jiang", "Yong", ""], ["Zhu", "Xiaoyan", ""], ["Huang", "Minlie", ""]]}, {"id": "2008.03964", "submitter": "Swaroop Mishra", "authors": "Swaroop Mishra, Anjana Arunkumar, Bhavdeep Sachdeva, Chris Bryan and\n  Chitta Baral", "title": "DQI: A Guide to Benchmark Evaluation", "comments": "ICML UDL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A `state of the art' model A surpasses humans in a benchmark B, but fails on\nsimilar benchmarks C, D, and E. What does B have that the other benchmarks do\nnot? Recent research provides the answer: spurious bias. However, developing A\nto solve benchmarks B through E does not guarantee that it will solve future\nbenchmarks. To progress towards a model that `truly learns' an underlying task,\nwe need to quantify the differences between successive benchmarks, as opposed\nto existing binary and black-box approaches. We propose a novel approach to\nsolve this underexplored task of quantifying benchmark quality by debuting a\ndata quality metric: DQI.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 08:38:55 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Mishra", "Swaroop", ""], ["Arunkumar", "Anjana", ""], ["Sachdeva", "Bhavdeep", ""], ["Bryan", "Chris", ""], ["Baral", "Chitta", ""]]}, {"id": "2008.03979", "submitter": "Sangah Lee", "authors": "Sangah Lee, Hansol Jang, Yunmee Baik, Suzi Park, Hyopil Shin", "title": "KR-BERT: A Small-Scale Korean-Specific Language Model", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the appearance of BERT, recent works including XLNet and RoBERTa\nutilize sentence embedding models pre-trained by large corpora and a large\nnumber of parameters. Because such models have large hardware and a huge amount\nof data, they take a long time to pre-train. Therefore it is important to\nattempt to make smaller models that perform comparatively. In this paper, we\ntrained a Korean-specific model KR-BERT, utilizing a smaller vocabulary and\ndataset. Since Korean is one of the morphologically rich languages with poor\nresources using non-Latin alphabets, it is also important to capture\nlanguage-specific linguistic phenomena that the Multilingual BERT model missed.\nWe tested several tokenizers including our BidirectionalWordPiece Tokenizer and\nadjusted the minimal span of tokens for tokenization ranging from sub-character\nlevel to character-level to construct a better vocabulary for our model. With\nthose adjustments, our KR-BERT model performed comparably and even better than\nother existing pre-trained models using a corpus about 1/10 of the size.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 09:26:00 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 06:21:50 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Lee", "Sangah", ""], ["Jang", "Hansol", ""], ["Baik", "Yunmee", ""], ["Park", "Suzi", ""], ["Shin", "Hyopil", ""]]}, {"id": "2008.03992", "submitter": "Junchen Lu", "authors": "Junchen Lu, Kun Zhou, Berrak Sisman, Haizhou Li", "title": "VAW-GAN for Singing Voice Conversion with Non-parallel Training Data", "comments": "Accepted to APSIPA ASC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Singing voice conversion aims to convert singer's voice from source to target\nwithout changing singing content. Parallel training data is typically required\nfor the training of singing voice conversion system, that is however not\npractical in real-life applications. Recent encoder-decoder structures, such as\nvariational autoencoding Wasserstein generative adversarial network (VAW-GAN),\nprovide an effective way to learn a mapping through non-parallel training data.\nIn this paper, we propose a singing voice conversion framework that is based on\nVAW-GAN. We train an encoder to disentangle singer identity and singing prosody\n(F0 contour) from phonetic content. By conditioning on singer identity and F0,\nthe decoder generates output spectral features with unseen target singer\nidentity, and improves the F0 rendering. Experimental results show that the\nproposed framework achieves better performance than the baseline frameworks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 09:44:10 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 04:50:27 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 10:58:10 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Lu", "Junchen", ""], ["Zhou", "Kun", ""], ["Sisman", "Berrak", ""], ["Li", "Haizhou", ""]]}, {"id": "2008.04057", "submitter": "Matthew Ciolino", "authors": "David Noever, Matt Ciolino and Josh Kalin", "title": "The Chess Transformer: Mastering Play using Generative Language Models", "comments": "7 Pages, 6 Figures, AAAI Format, AAAI 21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.GT cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work demonstrates that natural language transformers can support more\ngeneric strategic modeling, particularly for text-archived games. In addition\nto learning natural language skills, the abstract transformer architecture can\ngenerate meaningful moves on a chessboard. With further fine-tuning, the\ntransformer learns complex gameplay by training on 2.8 million chess games in\nPortable Game Notation. After 30,000 training steps, OpenAI's Generative\nPre-trained Transformer (GPT-2) optimizes weights for 774 million parameters.\nThis fine-tuned Chess Transformer generates plausible strategies and displays\ngame formations identifiable as classic openings, such as English or the Slav\nExchange. Finally, in live play, the novel model demonstrates a\nhuman-to-transformer interface that correctly filters illegal moves and\nprovides a novel method to challenge the transformer's chess strategies. We\nanticipate future work will build on this transformer's promise, particularly\nin other strategy games where features can capture the underlying complex rule\nsyntax from simple but expressive player annotations.\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 18:04:36 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 13:38:42 GMT"}, {"version": "v3", "created": "Wed, 12 Aug 2020 20:05:54 GMT"}, {"version": "v4", "created": "Fri, 21 Aug 2020 17:31:29 GMT"}, {"version": "v5", "created": "Fri, 18 Sep 2020 17:12:52 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Noever", "David", ""], ["Ciolino", "Matt", ""], ["Kalin", "Josh", ""]]}, {"id": "2008.04162", "submitter": "Philip Feldman", "authors": "Philip Feldman and Antonio Bucchiarone", "title": "Navigating Human Language Models with Synthetic Agents", "comments": "8 pages, 6 figures, 2 tables, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern natural language models such as the GPT-2/GPT-3 contain tremendous\namounts of information about human belief in a consistently testable form. If\nthese models could be shown to accurately reflect the underlying beliefs of the\nhuman beings that produced the data used to train these models, then such\nmodels become a powerful sociological tool in ways that are distinct from\ntraditional methods, such as interviews and surveys. In this study, We train a\nversion of the GPT-2 on a corpora of historical chess games, and then \"launch\"\nclusters of synthetic agents into the model, using text strings to create\ncontext and orientation. We compare the trajectories contained in the text\ngenerated by the agents/model and compare that to the known ground truth of the\nchess board, move legality, and historical patterns of play. We find that the\npercentages of moves by piece using the model are substantially similar from\nhuman patterns. We further find that the model creates an accurate latent\nrepresentation of the chessboard, and that it is possible to plot trajectories\nof legal moves across the board using this knowledge.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 14:39:53 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 15:09:36 GMT"}, {"version": "v3", "created": "Thu, 13 Aug 2020 13:42:00 GMT"}, {"version": "v4", "created": "Fri, 14 Aug 2020 11:12:43 GMT"}, {"version": "v5", "created": "Mon, 24 Aug 2020 19:18:21 GMT"}, {"version": "v6", "created": "Mon, 28 Sep 2020 15:40:41 GMT"}, {"version": "v7", "created": "Tue, 29 Sep 2020 09:57:33 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Feldman", "Philip", ""], ["Bucchiarone", "Antonio", ""]]}, {"id": "2008.04200", "submitter": "Marco De Nadai", "authors": "Yahui Liu, Marco De Nadai, Deng Cai, Huayang Li, Xavier\n  Alameda-Pineda, Nicu Sebe and Bruno Lepri", "title": "Describe What to Change: A Text-guided Unsupervised Image-to-Image\n  Translation Approach", "comments": "Submitted to ACM MM '20, October 12-16, 2020, Seattle, WA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manipulating visual attributes of images through human-written text is a very\nchallenging task. On the one hand, models have to learn the manipulation\nwithout the ground truth of the desired output. On the other hand, models have\nto deal with the inherent ambiguity of natural language. Previous research\nusually requires either the user to describe all the characteristics of the\ndesired image or to use richly-annotated image captioning datasets. In this\nwork, we propose a novel unsupervised approach, based on image-to-image\ntranslation, that alters the attributes of a given image through a command-like\nsentence such as \"change the hair color to black\". Contrarily to\nstate-of-the-art approaches, our model does not require a human-annotated\ndataset nor a textual description of all the attributes of the desired image,\nbut only those that have to be modified. Our proposed model disentangles the\nimage content from the visual attributes, and it learns to modify the latter\nusing the textual description, before generating a new image from the content\nand the modified attribute representation. Because text might be inherently\nambiguous (blond hair may refer to different shadows of blond, e.g. golden,\nicy, sandy), our method generates multiple stochastic versions of the same\ntranslation. Experiments show that the proposed model achieves promising\nperformances on two large-scale public datasets: CelebA and CUB. We believe our\napproach will pave the way to new avenues of research combining textual and\nspeech commands with visual attributes.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 15:40:05 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Liu", "Yahui", ""], ["De Nadai", "Marco", ""], ["Cai", "Deng", ""], ["Li", "Huayang", ""], ["Alameda-Pineda", "Xavier", ""], ["Sebe", "Nicu", ""], ["Lepri", "Bruno", ""]]}, {"id": "2008.04203", "submitter": "Gunnar Mein", "authors": "Gunnar Mein, Kevin Hartman, Andrew Morris", "title": "FireBERT: Hardening BERT-based classifiers against adversarial attack", "comments": "8 pages, 10 figures, code available at:\n  https://github.com/FireBERT-author/FireBERT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present FireBERT, a set of three proof-of-concept NLP classifiers hardened\nagainst TextFooler-style word-perturbation by producing diverse alternatives to\noriginal samples. In one approach, we co-tune BERT against the training data\nand synthetic adversarial samples. In a second approach, we generate the\nsynthetic samples at evaluation time through substitution of words and\nperturbation of embedding vectors. The diversified evaluation results are then\ncombined by voting. A third approach replaces evaluation-time word substitution\nwith perturbation of embedding vectors. We evaluate FireBERT for MNLI and IMDB\nMovie Review datasets, in the original and on adversarial examples generated by\nTextFooler. We also test whether TextFooler is less successful in creating new\nadversarial samples when manipulating FireBERT, compared to working on\nunhardened classifiers. We show that it is possible to improve the accuracy of\nBERT-based models in the face of adversarial attacks without significantly\nreducing the accuracy for regular benchmark samples. We present co-tuning with\na synthetic data generator as a highly effective method to protect against 95%\nof pre-manufactured adversarial samples while maintaining 98% of original\nbenchmark performance. We also demonstrate evaluation-time perturbation as a\npromising direction for further research, restoring accuracy up to 75% of\nbenchmark performance for pre-made adversarials, and up to 65% (from a baseline\nof 75% orig. / 12% attack) under active attack by TextFooler.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 15:43:28 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Mein", "Gunnar", ""], ["Hartman", "Kevin", ""], ["Morris", "Andrew", ""]]}, {"id": "2008.04276", "submitter": "David Skillicorn", "authors": "B. Simons, D.B. Skillicorn", "title": "A Bootstrapped Model to Detect Abuse and Intent in White Supremacist\n  Corpora", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligence analysts face a difficult problem: distinguishing extremist\nrhetoric from potential extremist violence. Many are content to express abuse\nagainst some target group, but only a few indicate a willingness to engage in\nviolence. We address this problem by building a predictive model for intent,\nbootstrapping from a seed set of intent words, and language templates\nexpressing intent. We design both an n-gram and attention-based deep learner\nfor intent and use them as colearners to improve both the basis for prediction\nand the predictions themselves. They converge to stable predictions in a few\nrounds. We merge predictions of intent with predictions of abusive language to\ndetect posts that indicate a desire for violent action. We validate the\npredictions by comparing them to crowd-sourced labelling. The methodology can\nbe applied to other linguistic properties for which a plausible starting point\ncan be defined.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 17:17:21 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Simons", "B.", ""], ["Skillicorn", "D. B.", ""]]}, {"id": "2008.04277", "submitter": "Parth Patwa", "authors": "Parth Patwa and Gustavo Aguilar and Sudipta Kar and Suraj Pandey and\n  Srinivas PYKL and Bj\\\"orn Gamb\\\"ack and Tanmoy Chakraborty and Thamar Solorio\n  and Amitava Das", "title": "SemEval-2020 Task 9: Overview of Sentiment Analysis of Code-Mixed Tweets", "comments": "Accepted at SemEval-2020, COLING", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present the results of the SemEval-2020 Task 9 on Sentiment\nAnalysis of Code-Mixed Tweets (SentiMix 2020). We also release and describe our\nHinglish (Hindi-English) and Spanglish (Spanish-English) corpora annotated with\nword-level language identification and sentence-level sentiment labels. These\ncorpora are comprised of 20K and 19K examples, respectively. The sentiment\nlabels are - Positive, Negative, and Neutral. SentiMix attracted 89 submissions\nin total including 61 teams that participated in the Hinglish contest and 28\nsubmitted systems to the Spanglish competition. The best performance achieved\nwas 75.0% F1 score for Hinglish and 80.6% F1 for Spanglish. We observe that\nBERT-like models and ensemble methods are the most common and successful\napproaches among the participants.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 17:17:52 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Patwa", "Parth", ""], ["Aguilar", "Gustavo", ""], ["Kar", "Sudipta", ""], ["Pandey", "Suraj", ""], ["PYKL", "Srinivas", ""], ["Gamb\u00e4ck", "Bj\u00f6rn", ""], ["Chakraborty", "Tanmoy", ""], ["Solorio", "Thamar", ""], ["Das", "Amitava", ""]]}, {"id": "2008.04374", "submitter": "Preslav Nakov", "authors": "Preslav Nakov", "title": "Can We Spot the \"Fake News\" Before It Was Even Written?", "comments": "Fake News, Disinformation, Media Bias, Propaganda, Infodemic,\n  COVID-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the recent proliferation of disinformation online, there has been also\ngrowing research interest in automatically debunking rumors, false claims, and\n\"fake news.\" A number of fact-checking initiatives have been launched so far,\nboth manual and automatic, but the whole enterprise remains in a state of\ncrisis: by the time a claim is finally fact-checked, it could have reached\nmillions of users, and the harm caused could hardly be undone. An arguably more\npromising direction is to focus on fact-checking entire news outlets, which can\nbe done in advance. Then, we could fact-check the news before it was even\nwritten: by checking how trustworthy the outlets that published it is. We\ndescribe how we do this in the Tanbih news aggregator, which makes readers\naware of what they are reading. In particular, we develop media profiles that\nshow the general factuality of reporting, the degree of propagandistic content,\nhyper-partisanship, leading political ideology, general frame of reporting, and\nstance with respect to various claims and topics.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2020 19:21:06 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Nakov", "Preslav", ""]]}, {"id": "2008.04481", "submitter": "Xi Chen", "authors": "Xi Chen and Songyang Zhang and Dandan Song and Peng Ouyang and Shouyi\n  Yin", "title": "Transformer with Bidirectional Decoder for Speech Recognition", "comments": "Accepted by InterSpeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attention-based models have made tremendous progress on end-to-end automatic\nspeech recognition(ASR) recently. However, the conventional transformer-based\napproaches usually generate the sequence results token by token from left to\nright, leaving the right-to-left contexts unexploited. In this work, we\nintroduce a bidirectional speech transformer to utilize the different\ndirectional contexts simultaneously. Specifically, the outputs of our proposed\ntransformer include a left-to-right target, and a right-to-left target. In\ninference stage, we use the introduced bidirectional beam search method, which\ncan not only generate left-to-right candidates but also generate right-to-left\ncandidates, and determine the best hypothesis by the score.\n  To demonstrate our proposed speech transformer with a bidirectional\ndecoder(STBD), we conduct extensive experiments on the AISHELL-1 dataset. The\nresults of experiments show that STBD achieves a 3.6\\% relative CER\nreduction(CERR) over the unidirectional speech transformer baseline. Besides,\nthe strongest model in this paper called STBD-Big can achieve 6.64\\% CER on the\ntest set, without language model rescoring and any extra data augmentation\nstrategies.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 02:12:42 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Chen", "Xi", ""], ["Zhang", "Songyang", ""], ["Song", "Dandan", ""], ["Ouyang", "Peng", ""], ["Yin", "Shouyi", ""]]}, {"id": "2008.04504", "submitter": "Li Jiacheng", "authors": "Jiacheng Li, Siliang Tang, Juncheng Li, Jun Xiao, Fei Wu, Shiliang Pu,\n  Yueting Zhuang", "title": "Topic Adaptation and Prototype Encoding for Few-Shot Visual Storytelling", "comments": "ACM Multimedia 2020", "journal-ref": null, "doi": "10.1145/3394171.3413886", "report-no": null, "categories": "cs.CL cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Storytelling~(VIST) is a task to tell a narrative story about a\ncertain topic according to the given photo stream. The existing studies focus\non designing complex models, which rely on a huge amount of human-annotated\ndata. However, the annotation of VIST is extremely costly and many topics\ncannot be covered in the training dataset due to the long-tail topic\ndistribution. In this paper, we focus on enhancing the generalization ability\nof the VIST model by considering the few-shot setting. Inspired by the way\nhumans tell a story, we propose a topic adaptive storyteller to model the\nability of inter-topic generalization. In practice, we apply the gradient-based\nmeta-learning algorithm on multi-modal seq2seq models to endow the model the\nability to adapt quickly from topic to topic. Besides, We further propose a\nprototype encoding structure to model the ability of intra-topic derivation.\nSpecifically, we encode and restore the few training story text to serve as a\nreference to guide the generation at inference time. Experimental results show\nthat topic adaptation and prototype encoding structure mutually bring benefit\nto the few-shot model on BLEU and METEOR metric. The further case study shows\nthat the stories generated after few-shot adaptation are more relative and\nexpressive.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 03:55:11 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Li", "Jiacheng", ""], ["Tang", "Siliang", ""], ["Li", "Juncheng", ""], ["Xiao", "Jun", ""], ["Wu", "Fei", ""], ["Pu", "Shiliang", ""], ["Zhuang", "Yueting", ""]]}, {"id": "2008.04510", "submitter": "Han Zhao", "authors": "Han Zhao, Junjie Hu, Andrej Risteski", "title": "On Learning Language-Invariant Representations for Universal Machine\n  Translation", "comments": "Appeared in ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of universal machine translation is to learn to translate between\nany pair of languages, given a corpus of paired translated documents for\n\\emph{a small subset} of all pairs of languages. Despite impressive empirical\nresults and an increasing interest in massively multilingual models,\ntheoretical analysis on translation errors made by such universal machine\ntranslation models is only nascent. In this paper, we formally prove certain\nimpossibilities of this endeavour in general, as well as prove positive results\nin the presence of additional (but natural) structure of data.\n  For the former, we derive a lower bound on the translation error in the\nmany-to-many translation setting, which shows that any algorithm aiming to\nlearn shared sentence representations among multiple language pairs has to make\na large translation error on at least one of the translation tasks, if no\nassumption on the structure of the languages is made. For the latter, we show\nthat if the paired documents in the corpus follow a natural\n\\emph{encoder-decoder} generative process, we can expect a natural notion of\n``generalization'': a linear number of language pairs, rather than quadratic,\nsuffices to learn a good representation. Our theory also explains what kinds of\nconnection graphs between pairs of languages are better suited: ones with\nlonger paths result in worse sample complexity in terms of the total number of\ndocuments per language pair needed. We believe our theoretical insights and\nimplications contribute to the future algorithmic design of universal machine\ntranslation.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 04:45:33 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Zhao", "Han", ""], ["Hu", "Junjie", ""], ["Risteski", "Andrej", ""]]}, {"id": "2008.04527", "submitter": "Shreyas Ramoji", "authors": "Shreyas Ramoji, Prashant Krishnan, Sriram Ganapathy", "title": "Neural PLDA Modeling for End-to-End Speaker Verification", "comments": "Accepted in Interspeech 2020. GitHub Implementation Repos:\n  https://github.com/iiscleap/E2E-NPLDA and\n  https://github.com/iiscleap/NeuralPlda", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning models have made significant advances in supervised\nclassification problems, the application of these models for out-of-set\nverification tasks like speaker recognition has been limited to deriving\nfeature embeddings. The state-of-the-art x-vector PLDA based speaker\nverification systems use a generative model based on probabilistic linear\ndiscriminant analysis (PLDA) for computing the verification score. Recently, we\nhad proposed a neural network approach for backend modeling in speaker\nverification called the neural PLDA (NPLDA) where the likelihood ratio score of\nthe generative PLDA model is posed as a discriminative similarity function and\nthe learnable parameters of the score function are optimized using a\nverification cost. In this paper, we extend this work to achieve joint\noptimization of the embedding neural network (x-vector network) with the NPLDA\nnetwork in an end-to-end (E2E) fashion. This proposed end-to-end model is\noptimized directly from the acoustic features with a verification cost function\nand during testing, the model directly outputs the likelihood ratio score. With\nvarious experiments using the NIST speaker recognition evaluation (SRE) 2018\nand 2019 datasets, we show that the proposed E2E model improves significantly\nover the x-vector PLDA baseline speaker verification system.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 05:54:54 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Ramoji", "Shreyas", ""], ["Krishnan", "Prashant", ""], ["Ganapathy", "Sriram", ""]]}, {"id": "2008.04545", "submitter": "Zusheng Zhang", "authors": "Jiachun Feng, Zusheng Zhang, Cheng Ding, Yanghui Rao and Haoran Xie", "title": "Context Reinforced Neural Topic Modeling over Short Texts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one of the prevalent topic mining tools, neural topic modeling has\nattracted a lot of interests for the advantages of high efficiency in training\nand strong generalisation abilities. However, due to the lack of context in\neach short text, the existing neural topic models may suffer from feature\nsparsity on such documents. To alleviate this issue, we propose a Context\nReinforced Neural Topic Model (CRNTM), whose characteristics can be summarized\nas follows. Firstly, by assuming that each short text covers only a few salient\ntopics, CRNTM infers the topic for each word in a narrow range. Secondly, our\nmodel exploits pre-trained word embeddings by treating topics as multivariate\nGaussian distributions or Gaussian mixture distributions in the embedding\nspace. Extensive experiments on two benchmark datasets validate the\neffectiveness of the proposed model on both topic discovery and text\nclassification.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 06:41:53 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Feng", "Jiachun", ""], ["Zhang", "Zusheng", ""], ["Ding", "Cheng", ""], ["Rao", "Yanghui", ""], ["Xie", "Haoran", ""]]}, {"id": "2008.04546", "submitter": "Naoyuki Kanda", "authors": "Naoyuki Kanda, Xuankai Chang, Yashesh Gaur, Xiaofei Wang, Zhong Meng,\n  Zhuo Chen, Takuya Yoshioka", "title": "Investigation of End-To-End Speaker-Attributed ASR for Continuous\n  Multi-Talker Recordings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, an end-to-end (E2E) speaker-attributed automatic speech recognition\n(SA-ASR) model was proposed as a joint model of speaker counting, speech\nrecognition and speaker identification for monaural overlapped speech. It\nshowed promising results for simulated speech mixtures consisting of various\nnumbers of speakers. However, the model required prior knowledge of speaker\nprofiles to perform speaker identification, which significantly limited the\napplication of the model. In this paper, we extend the prior work by addressing\nthe case where no speaker profile is available. Specifically, we perform\nspeaker counting and clustering by using the internal speaker representations\nof the E2E SA-ASR model to diarize the utterances of the speakers whose\nprofiles are missing from the speaker inventory. We also propose a simple\nmodification to the reference labels of the E2E SA-ASR training which helps\nhandle continuous multi-talker recordings well. We conduct a comprehensive\ninvestigation of the original E2E SA-ASR and the proposed method on the\nmonaural LibriCSS dataset. Compared to the original E2E SA-ASR with relevant\nspeaker profiles, the proposed method achieves a close performance without any\nprior speaker knowledge. We also show that the source-target attention in the\nE2E SA-ASR model provides information about the start and end times of the\nhypotheses.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 06:41:55 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Kanda", "Naoyuki", ""], ["Chang", "Xuankai", ""], ["Gaur", "Yashesh", ""], ["Wang", "Xiaofei", ""], ["Meng", "Zhong", ""], ["Chen", "Zhuo", ""], ["Yoshioka", "Takuya", ""]]}, {"id": "2008.04548", "submitter": "Haonan Lu", "authors": "Haonan Lu, Hailin Hu", "title": "DensE: An Enhanced Non-Abelian Group Representation for Knowledge Graph\n  Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capturing the composition patterns of relations is a vital task in knowledge\ngraph completion. It also serves as a fundamental step towards multi-hop\nreasoning over learned knowledge. Previously, rotation-based translational\nmethods, e.g., RotatE, have been developed to model composite relations using\nthe product of a series of complex-valued diagonal matrices. However, RotatE\nmakes several oversimplified assumptions on the composition patterns, forcing\nthe relations to be commutative, independent from entities and fixed in scale.\nTo tackle this problem, we have developed a novel knowledge graph embedding\nmethod, named DensE, to provide sufficient modeling capacity for complex\ncomposition patterns. In particular, our method decomposes each relation into\nan SO(3) group-based rotation operator and a scaling operator in the three\ndimensional (3-D) Euclidean space. The advantages of our method are twofold:\n(1) For composite relations, the corresponding diagonal relation matrices can\nbe non-commutative and related with entity embeddings; (2) It extends the\nconcept of RotatE to a more expressive setting with lower model complexity and\npreserves the direct geometrical interpretations, which reveals how relations\nwith distinct patterns (i.e., symmetry/anti-symmetry, inversion and\ncomposition) are modeled. Experimental results on multiple benchmark knowledge\ngraphs show that DensE outperforms the current state-of-the-art models for\nmissing link prediction, especially on composite relations.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 06:45:50 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Lu", "Haonan", ""], ["Hu", "Hailin", ""]]}, {"id": "2008.04550", "submitter": "Miriam Exel", "authors": "Bianka Buschbeck and Miriam Exel", "title": "A Parallel Evaluation Data Set of Software Documentation with Document\n  Structure Annotation", "comments": "Accepted for publication at WAT 2020; update to camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper accompanies the software documentation data set for machine\ntranslation, a parallel evaluation data set of data originating from the SAP\nHelp Portal, that we released to the machine translation community for research\npurposes. It offers the possibility to tune and evaluate machine translation\nsystems in the domain of corporate software documentation and contributes to\nthe availability of a wider range of evaluation scenarios. The data set\ncomprises of the language pairs English to Hindi, Indonesian, Malay and Thai,\nand thus also increases the test coverage for the many low-resource language\npairs. Unlike most evaluation data sets that consist of plain parallel text,\nthe segments in this data set come with additional metadata that describes\nstructural information of the document context. We provide insights into the\norigin and creation, the particularities and characteristics of the data set as\nwell as machine translation results.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 06:50:23 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 14:15:36 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Buschbeck", "Bianka", ""], ["Exel", "Miriam", ""]]}, {"id": "2008.04562", "submitter": "Zongyang Du", "authors": "Zongyang Du, Kun Zhou, Berrak Sisman, Haizhou Li", "title": "Spectrum and Prosody Conversion for Cross-lingual Voice Conversion with\n  CycleGAN", "comments": "Accepted to APSIPA ASC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual voice conversion aims to change source speaker's voice to sound\nlike that of target speaker, when source and target speakers speak different\nlanguages. It relies on non-parallel training data from two different\nlanguages, hence, is more challenging than mono-lingual voice conversion.\nPrevious studies on cross-lingual voice conversion mainly focus on spectral\nconversion with a linear transformation for F0 transfer. However, as an\nimportant prosodic factor, F0 is inherently hierarchical, thus it is\ninsufficient to just use a linear method for conversion. We propose the use of\ncontinuous wavelet transform (CWT) decomposition for F0 modeling. CWT provides\na way to decompose a signal into different temporal scales that explain prosody\nin different time resolutions. We also propose to train two CycleGAN pipelines\nfor spectrum and prosody mapping respectively. In this way, we eliminate the\nneed for parallel data of any two languages and any alignment techniques.\nExperimental results show that our proposed Spectrum-Prosody-CycleGAN framework\noutperforms the Spectrum-CycleGAN baseline in subjective evaluation. To our\nbest knowledge, this is the first study of prosody in cross-lingual voice\nconversion.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 07:29:55 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 04:53:16 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 16:34:35 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Du", "Zongyang", ""], ["Zhou", "Kun", ""], ["Sisman", "Berrak", ""], ["Li", "Haizhou", ""]]}, {"id": "2008.04636", "submitter": "Anna Glazkova", "authors": "Anna Glazkova", "title": "A Comparison of Synthetic Oversampling Methods for Multi-class Text\n  Classification", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The authors compared oversampling methods for the problem of multi-class\ntopic classification. The SMOTE algorithm underlies one of the most popular\noversampling methods. It consists in choosing two examples of a minority class\nand generating a new example based on them. In the paper, the authors compared\nthe basic SMOTE method with its two modifications (Borderline SMOTE and ADASYN)\nand random oversampling technique on the example of one of text classification\ntasks. The paper discusses the k-nearest neighbor algorithm, the support vector\nmachine algorithm and three types of neural networks (feedforward network, long\nshort-term memory (LSTM) and bidirectional LSTM). The authors combine these\nmachine learning algorithms with different text representations and compared\nsynthetic oversampling methods. In most cases, the use of oversampling\ntechniques can significantly improve the quality of classification. The authors\nconclude that for this task, the quality of the KNN and SVM algorithms is more\ninfluenced by class imbalance than neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 11:41:53 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Glazkova", "Anna", ""]]}, {"id": "2008.04637", "submitter": "Amit Moryossef", "authors": "Amit Moryossef, Ioannis Tsochantaridis, Roee Aharoni, Sarah Ebling,\n  and Srini Narayanan", "title": "Real-Time Sign Language Detection using Human Pose Estimation", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a lightweight real-time sign language detection model, as we\nidentify the need for such a case in videoconferencing. We extract optical flow\nfeatures based on human pose estimation and, using a linear classifier, show\nthese features are meaningful with an accuracy of 80%, evaluated on the DGS\nCorpus. Using a recurrent model directly on the input, we see improvements of\nup to 91% accuracy, while still working under 4ms. We describe a demo\napplication to sign language detection in the browser in order to demonstrate\nits usage possibility in videoconferencing applications.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 11:42:03 GMT"}, {"version": "v2", "created": "Sun, 13 Sep 2020 11:40:20 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Moryossef", "Amit", ""], ["Tsochantaridis", "Ioannis", ""], ["Aharoni", "Roee", ""], ["Ebling", "Sarah", ""], ["Narayanan", "Srini", ""]]}, {"id": "2008.04702", "submitter": "Lixing Zhu", "authors": "Lixing Zhu, Yulan He and Deyu Zhou", "title": "A Neural Generative Model for Joint Learning Topics and Topic-Specific\n  Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel generative model to explore both local and global context\nfor joint learning topics and topic-specific word embeddings. In particular, we\nassume that global latent topics are shared across documents, a word is\ngenerated by a hidden semantic vector encoding its contextual semantic meaning,\nand its context words are generated conditional on both the hidden semantic\nvector and global latent topics. Topics are trained jointly with the word\nembeddings. The trained model maps words to topic-dependent embeddings, which\nnaturally addresses the issue of word polysemy. Experimental results show that\nthe proposed model outperforms the word-level embedding methods in both word\nsimilarity evaluation and word sense disambiguation. Furthermore, the model\nalso extracts more coherent topics compared with existing neural topic models\nor other models for joint learning of topics and word embeddings. Finally, the\nmodel can be easily integrated with existing deep contextualized word embedding\nlearning methods to further improve the performance of downstream tasks such as\nsentiment classification.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 13:54:11 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Zhu", "Lixing", ""], ["He", "Yulan", ""], ["Zhou", "Deyu", ""]]}, {"id": "2008.04759", "submitter": "Qin Lyu", "authors": "Qin Lyu, Kaushik Chakrabarti, Shobhit Hathi, Souvik Kundu, Jianwen\n  Zhang, Zheng Chen", "title": "Hybrid Ranking Network for Text-to-SQL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study how to leverage pre-trained language models in\nText-to-SQL. We argue that previous approaches under utilize the base language\nmodels by concatenating all columns together with the NL question and feeding\nthem into the base language model in the encoding stage. We propose a neat\napproach called Hybrid Ranking Network (HydraNet) which breaks down the problem\ninto column-wise ranking and decoding and finally assembles the column-wise\noutputs into a SQL query by straightforward rules. In this approach, the\nencoder is given a NL question and one individual column, which perfectly\naligns with the original tasks BERT/RoBERTa is trained on, and hence we avoid\nany ad-hoc pooling or additional encoding layers which are necessary in prior\napproaches. Experiments on the WikiSQL dataset show that the proposed approach\nis very effective, achieving the top place on the leaderboard.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 15:01:52 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Lyu", "Qin", ""], ["Chakrabarti", "Kaushik", ""], ["Hathi", "Shobhit", ""], ["Kundu", "Souvik", ""], ["Zhang", "Jianwen", ""], ["Chen", "Zheng", ""]]}, {"id": "2008.04820", "submitter": "Sopan Khosla", "authors": "Sopan Khosla, Rishabh Joshi, Ritam Dutt, Alan W Black, Yulia Tsvetkov", "title": "LTIatCMU at SemEval-2020 Task 11: Incorporating Multi-Level Features for\n  Multi-Granular Propaganda Span Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we describe our submission for the task of Propaganda Span\nIdentification in news articles. We introduce a BERT-BiLSTM based span-level\npropaganda classification model that identifies which token spans within the\nsentence are indicative of propaganda. The \"multi-granular\" model incorporates\nlinguistic knowledge at various levels of text granularity, including word,\nsentence and document level syntactic, semantic and pragmatic affect features,\nwhich significantly improve model performance, compared to its\nlanguage-agnostic variant. To facilitate better representation learning, we\nalso collect a corpus of 10k news articles, and use it for fine-tuning the\nmodel. The final model is a majority-voting ensemble which learns different\npropaganda class boundaries by leveraging different subsets of incorporated\nknowledge and attains $4^{th}$ position on the test leaderboard. Our final\nmodel and code is released at https://github.com/sopu/PropagandaSemEval2020.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 16:14:47 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 15:14:18 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Khosla", "Sopan", ""], ["Joshi", "Rishabh", ""], ["Dutt", "Ritam", ""], ["Black", "Alan W", ""], ["Tsvetkov", "Yulia", ""]]}, {"id": "2008.04860", "submitter": "Jerin Philip", "authors": "Jerin Philip, Shashank Siripragada, Vinay P. Namboodiri, C.V. Jawahar", "title": "Revisiting Low Resource Status of Indian Languages in Machine\n  Translation", "comments": "10 pages, few figures, Preprint under review", "journal-ref": "8th ACM IKDD CODS and 26th COMAD (CODS COMAD 2021), January 2--4,\n  2021, Bangalore, India", "doi": "10.1145/3430984.3431026", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Indian language machine translation performance is hampered due to the lack\nof large scale multi-lingual sentence aligned corpora and robust benchmarks.\nThrough this paper, we provide and analyse an automated framework to obtain\nsuch a corpus for Indian language neural machine translation (NMT) systems. Our\npipeline consists of a baseline NMT system, a retrieval module, and an\nalignment module that is used to work with publicly available websites such as\npress releases by the government. The main contribution towards this effort is\nto obtain an incremental method that uses the above pipeline to iteratively\nimprove the size of the corpus as well as improve each of the components of our\nsystem. Through our work, we also evaluate the design choices such as the\nchoice of pivoting language and the effect of iterative incremental increase in\ncorpus size. Our work in addition to providing an automated framework also\nresults in generating a relatively larger corpus as compared to existing\ncorpora that are available for Indian languages. This corpus helps us obtain\nsubstantially improved results on the publicly available WAT evaluation\nbenchmark and other standard evaluation benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 17:05:13 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 09:29:26 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Philip", "Jerin", ""], ["Siripragada", "Shashank", ""], ["Namboodiri", "Vinay P.", ""], ["Jawahar", "C. V.", ""]]}, {"id": "2008.04885", "submitter": "Michael Denkowski", "authors": "Tobias Domhan, Michael Denkowski, David Vilar, Xing Niu, Felix Hieber,\n  Kenneth Heafield", "title": "The Sockeye 2 Neural Machine Translation Toolkit at AMTA 2020", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Sockeye 2, a modernized and streamlined version of the Sockeye\nneural machine translation (NMT) toolkit. New features include a simplified\ncode base through the use of MXNet's Gluon API, a focus on state of the art\nmodel architectures, distributed mixed precision training, and efficient CPU\ndecoding with 8-bit quantization. These improvements result in faster training\nand inference, higher automatic metric scores, and a shorter path from research\nto production.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 17:42:26 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Domhan", "Tobias", ""], ["Denkowski", "Michael", ""], ["Vilar", "David", ""], ["Niu", "Xing", ""], ["Hieber", "Felix", ""], ["Heafield", "Kenneth", ""]]}, {"id": "2008.04935", "submitter": "Brian Thompson", "authors": "Brian Thompson and Matt Post", "title": "Paraphrase Generation as Zero-Shot Multilingual Translation:\n  Disentangling Semantic Similarity from Lexical and Syntactic Diversity", "comments": "WMT2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that a multilingual neural machine translation (NMT)\nmodel can be used to judge how well a sentence paraphrases another sentence in\nthe same language (Thompson and Post, 2020); however, attempting to generate\nparaphrases from such a model using standard beam search produces trivial\ncopies or near copies. We introduce a simple paraphrase generation algorithm\nwhich discourages the production of n-grams that are present in the input. Our\napproach enables paraphrase generation in many languages from a single\nmultilingual NMT model. Furthermore, the amount of lexical diversity between\nthe input and output can be controlled at generation time. We conduct a human\nevaluation to compare our method to a paraphraser trained on the large English\nsynthetic paraphrase database ParaBank 2 (Hu et al., 2019c) and find that our\nmethod produces paraphrases that better preserve meaning and are more\ngramatical, for the same level of lexical diversity. Additional smaller human\nassessments demonstrate our approach also works in two non-English languages.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 18:05:34 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 02:54:13 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Thompson", "Brian", ""], ["Post", "Matt", ""]]}, {"id": "2008.05011", "submitter": "Munir Georges", "authors": "Munir Georges, Jonathan Huang, Tobias Bocklet", "title": "Compact Speaker Embedding: lrx-vector", "comments": "Accepted to INTERSPEECH 2020", "journal-ref": "Proc. Interspeech 2020", "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) have recently been widely used in speaker\nrecognition systems, achieving state-of-the-art performance on various\nbenchmarks. The x-vector architecture is especially popular in this research\ncommunity, due to its excellent performance and manageable computational\ncomplexity. In this paper, we present the lrx-vector system, which is the\nlow-rank factorized version of the x-vector embedding network. The primary\nobjective of this topology is to further reduce the memory requirement of the\nspeaker recognition system. We discuss the deployment of knowledge distillation\nfor training the lrx-vector system and compare against low-rank factorization\nwith SVD. On the VOiCES 2019 far-field corpus we were able to reduce the\nweights by 28% compared to the full-rank x-vector system while keeping the\nrecognition rate constant (1.83% EER).\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 21:32:16 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Georges", "Munir", ""], ["Huang", "Jonathan", ""], ["Bocklet", "Tobias", ""]]}, {"id": "2008.05049", "submitter": "Dianbo Sui", "authors": "Dianbo Sui, Yubo Chen, Kang Liu and Jun Zhao", "title": "Distantly Supervised Relation Extraction in Federated Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates distantly supervised relation extraction in federated\nsettings. Previous studies focus on distant supervision under the assumption of\ncentralized training, which requires collecting texts from different platforms\nand storing them on one machine. However, centralized training is challenged by\ntwo issues, namely, data barriers and privacy protection, which make it almost\nimpossible or cost-prohibitive to centralize data from multiple platforms.\nTherefore, it is worthy to investigate distant supervision in the federated\nlearning paradigm, which decouples the model training from the need for direct\naccess to the raw data. Overcoming label noise of distant supervision, however,\nbecomes more difficult in federated settings, since the sentences containing\nthe same entity pair may scatter around different platforms. In this paper, we\npropose a federated denoising framework to suppress label noise in federated\nsettings. The core of this framework is a multiple instance learning based\ndenoising method that is able to select reliable instances via cross-platform\ncollaboration. Various experimental results on New York Times dataset and miRNA\ngene regulation relation dataset demonstrate the effectiveness of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 00:58:39 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Sui", "Dianbo", ""], ["Chen", "Yubo", ""], ["Liu", "Kang", ""], ["Zhao", "Jun", ""]]}, {"id": "2008.05055", "submitter": "Prachya Boonkwan", "authors": "Prachya Boonkwan and Vorapon Luantangsrisuk and Sitthaa Phaholphinyo\n  and Kanyanat Kriengket and Dhanon Leenoi and Charun Phrombut and Monthika\n  Boriboon and Krit Kosawat and Thepchai Supnithi", "title": "The Annotation Guideline of LST20 Corpus", "comments": "28 pages, 3 tables, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This report presents the annotation guideline for LST20, a large-scale corpus\nwith multiple layers of linguistic annotation for Thai language processing. Our\nguideline consists of five layers of linguistic annotation: word segmentation,\nPOS tagging, named entities, clause boundaries, and sentence boundaries. The\ndataset complies to the CoNLL-2003-style format for ease of use. LST20 Corpus\noffers five layers of linguistic annotation as aforementioned. At a large\nscale, it consists of 3,164,864 words, 288,020 named entities, 248,962 clauses,\nand 74,180 sentences, while it is annotated with 16 distinct POS tags. All\n3,745 documents are also annotated with 15 news genres. Regarding its sheer\nsize, this dataset is considered large enough for developing joint neural\nmodels for NLP. With the existence of this publicly available corpus, Thai has\nbecome a linguistically rich language for the first time.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 01:16:45 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Boonkwan", "Prachya", ""], ["Luantangsrisuk", "Vorapon", ""], ["Phaholphinyo", "Sitthaa", ""], ["Kriengket", "Kanyanat", ""], ["Leenoi", "Dhanon", ""], ["Phrombut", "Charun", ""], ["Boriboon", "Monthika", ""], ["Kosawat", "Krit", ""], ["Supnithi", "Thepchai", ""]]}, {"id": "2008.05086", "submitter": "Vikas Joshi", "authors": "Vikas Joshi, Rui Zhao, Rupesh R. Mehta, Kshitiz Kumar, Jinyu Li", "title": "Transfer Learning Approaches for Streaming End-to-End Speech Recognition\n  System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning (TL) is widely used in conventional hybrid automatic speech\nrecognition (ASR) system, to transfer the knowledge from source to target\nlanguage. TL can be applied to end-to-end (E2E) ASR system such as recurrent\nneural network transducer (RNN-T) models, by initializing the encoder and/or\nprediction network of the target language with the pre-trained models from\nsource language. In the hybrid ASR system, transfer learning is typically done\nby initializing the target language acoustic model (AM) with source language\nAM. Several transfer learning strategies exist in the case of the RNN-T\nframework, depending upon the choice of the initialization model for encoder\nand prediction networks. This paper presents a comparative study of four\ndifferent TL methods for RNN-T framework. We show 17% relative word error rate\nreduction with different TL methods over randomly initialized RNN-T model. We\nalso study the impact of TL with varying amount of training data ranging from\n50 hours to 1000 hours and show the efficacy of TL for languages with small\namount of training data.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 03:25:05 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 14:27:06 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Joshi", "Vikas", ""], ["Zhao", "Rui", ""], ["Mehta", "Rupesh R.", ""], ["Kumar", "Kshitiz", ""], ["Li", "Jinyu", ""]]}, {"id": "2008.05122", "submitter": "Ian Tenney", "authors": "Ian Tenney, James Wexler, Jasmijn Bastings, Tolga Bolukbasi, Andy\n  Coenen, Sebastian Gehrmann, Ellen Jiang, Mahima Pushkarna, Carey Radebaugh,\n  Emily Reif, Ann Yuan", "title": "The Language Interpretability Tool: Extensible, Interactive\n  Visualizations and Analysis for NLP Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Language Interpretability Tool (LIT), an open-source platform\nfor visualization and understanding of NLP models. We focus on core questions\nabout model behavior: Why did my model make this prediction? When does it\nperform poorly? What happens under a controlled change in the input? LIT\nintegrates local explanations, aggregate analysis, and counterfactual\ngeneration into a streamlined, browser-based interface to enable rapid\nexploration and error analysis. We include case studies for a diverse set of\nworkflows, including exploring counterfactuals for sentiment analysis,\nmeasuring gender bias in coreference systems, and exploring local behavior in\ntext generation. LIT supports a wide range of models--including classification,\nseq2seq, and structured prediction--and is highly extensible through a\ndeclarative, framework-agnostic API. LIT is under active development, with code\nand full documentation available at https://github.com/pair-code/lit.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 06:07:44 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Tenney", "Ian", ""], ["Wexler", "James", ""], ["Bastings", "Jasmijn", ""], ["Bolukbasi", "Tolga", ""], ["Coenen", "Andy", ""], ["Gehrmann", "Sebastian", ""], ["Jiang", "Ellen", ""], ["Pushkarna", "Mahima", ""], ["Radebaugh", "Carey", ""], ["Reif", "Emily", ""], ["Yuan", "Ann", ""]]}, {"id": "2008.05179", "submitter": "Yunlong Liang", "authors": "Yunlong Liang, Fandong Meng, Jinchao Zhang, Yufeng Chen, Jinan Xu, and\n  Jie Zhou", "title": "Modeling Inter-Aspect Dependencies with a Non-temporal Mechanism for\n  Aspect-Based Sentiment Analysis", "comments": "rejected in emnlp-ijcnlp 2019 as a short paper(3/3/3)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For multiple aspects scenario of aspect-based sentiment analysis (ABSA),\nexisting approaches typically ignore inter-aspect relations or rely on temporal\ndependencies to process aspect-aware representations of all aspects in a\nsentence. Although multiple aspects of a sentence appear in a non-adjacent\nsequential order, they are not in a strict temporal relationship as natural\nlanguage sequence, thus the aspect-aware sentence representations should not be\ntreated as temporal dependency processing. In this paper, we propose a novel\nnon-temporal mechanism to enhance the ABSA task through modeling inter-aspect\ndependencies. Furthermore, we focus on the well-known class imbalance issue on\nthe ABSA task and address it by down-weighting the loss assigned to\nwell-classified instances. Experiments on two distinct domains of SemEval 2014\ntask 4 demonstrate the effectiveness of our proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 08:50:09 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Liang", "Yunlong", ""], ["Meng", "Fandong", ""], ["Zhang", "Jinchao", ""], ["Chen", "Yufeng", ""], ["Xu", "Jinan", ""], ["Zhou", "Jie", ""]]}, {"id": "2008.05190", "submitter": "Isaiah Onando Mulang' Mr.", "authors": "Isaiah Onando Mulang', Kuldeep Singh, Chaitali Prabhu, Abhishek\n  Nadgeri, Johannes Hoffart, Jens Lehmann", "title": "Evaluating the Impact of Knowledge Graph Context on Entity\n  Disambiguation Models", "comments": "to appear in proceedings of CIKM 2020", "journal-ref": "CIKM 2020", "doi": "10.1145/3340531.3412159", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pretrained Transformer models have emerged as state-of-the-art approaches\nthat learn contextual information from text to improve the performance of\nseveral NLP tasks. These models, albeit powerful, still require specialized\nknowledge in specific scenarios. In this paper, we argue that context derived\nfrom a knowledge graph (in our case: Wikidata) provides enough signals to\ninform pretrained transformer models and improve their performance for named\nentity disambiguation (NED) on Wikidata KG. We further hypothesize that our\nproposed KG context can be standardized for Wikipedia, and we evaluate the\nimpact of KG context on state-of-the-art NED model for the Wikipedia knowledge\nbase. Our empirical results validate that the proposed KG context can be\ngeneralized (for Wikipedia), and providing KG context in transformer\narchitectures considerably outperforms the existing baselines, including the\nvanilla transformer models.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 09:12:22 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 08:44:29 GMT"}, {"version": "v3", "created": "Sun, 30 Aug 2020 08:58:56 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Mulang'", "Isaiah Onando", ""], ["Singh", "Kuldeep", ""], ["Prabhu", "Chaitali", ""], ["Nadgeri", "Abhishek", ""], ["Hoffart", "Johannes", ""], ["Lehmann", "Jens", ""]]}, {"id": "2008.05201", "submitter": "Qihao Zhu", "authors": "Qihao Zhu, Zeyu Sun, Xiran Liang, Yingfei Xiong, Lu Zhang", "title": "OCoR: An Overlapping-Aware Code Retriever", "comments": null, "journal-ref": "ASE 2020: 35th IEEE/ACM International Conference on Automated\n  Software Engineering Proceedings", "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code retrieval helps developers reuse the code snippet in the open-source\nprojects. Given a natural language description, code retrieval aims to search\nfor the most relevant code among a set of code. Existing state-of-the-art\napproaches apply neural networks to code retrieval. However, these approaches\nstill fail to capture an important feature: overlaps. The overlaps between\ndifferent names used by different people indicate that two different names may\nbe potentially related (e.g., \"message\" and \"msg\"), and the overlaps between\nidentifiers in code and words in natural language descriptions indicate that\nthe code snippet and the description may potentially be related. To address\nthese problems, we propose a novel neural architecture named OCoR, where we\nintroduce two specifically-designed components to capture overlaps: the first\nembeds identifiers by character to capture the overlaps between identifiers,\nand the second introduces a novel overlap matrix to represent the degrees of\noverlaps between each natural language word and each identifier.\n  The evaluation was conducted on two established datasets. The experimental\nresults show that OCoR significantly outperforms the existing state-of-the-art\napproaches and achieves 13.1% to 22.3% improvements. Moreover, we also\nconducted several in-depth experiments to help understand the performance of\ndifferent components in OCoR.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 09:43:35 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 12:05:03 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Zhu", "Qihao", ""], ["Sun", "Zeyu", ""], ["Liang", "Xiran", ""], ["Xiong", "Yingfei", ""], ["Zhang", "Lu", ""]]}, {"id": "2008.05221", "submitter": "Manish Gupta", "authors": "Manish Gupta, Puneet Agrawal", "title": "Compression of Deep Learning Models for Text: A Survey", "comments": "Accepted at TKDD for publication. 53 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the fields of natural language processing (NLP) and\ninformation retrieval (IR) have made tremendous progress thanksto deep learning\nmodels like Recurrent Neural Networks (RNNs), Gated Recurrent Units (GRUs) and\nLong Short-Term Memory (LSTMs)networks, and Transformer [120] based models like\nBidirectional Encoder Representations from Transformers (BERT) [24],\nGenerativePre-training Transformer (GPT-2) [94], Multi-task Deep Neural Network\n(MT-DNN) [73], Extra-Long Network (XLNet) [134], Text-to-text transfer\ntransformer (T5) [95], T-NLG [98] and GShard [63]. But these models are\nhumongous in size. On the other hand,real world applications demand small model\nsize, low response times and low computational power wattage. In this survey,\nwediscuss six different types of methods (Pruning, Quantization, Knowledge\nDistillation, Parameter Sharing, Tensor Decomposition, andSub-quadratic\nTransformer based methods) for compression of such models to enable their\ndeployment in real industry NLP projects.Given the critical need of building\napplications with efficient and small models, and the large amount of recently\npublished work inthis area, we believe that this survey organizes the plethora\nof work done by the 'deep learning for NLP' community in the past fewyears and\npresents it as a coherent story.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 10:42:14 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 10:41:02 GMT"}, {"version": "v3", "created": "Sun, 11 Apr 2021 12:25:10 GMT"}, {"version": "v4", "created": "Sun, 13 Jun 2021 17:47:28 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Gupta", "Manish", ""], ["Agrawal", "Puneet", ""]]}, {"id": "2008.05282", "submitter": "Zhenyu Liu", "authors": "Zhenyu Liu, Chaohong Lu, Haiwei Huang, Shengfei Lyu, Zhenchao Tao", "title": "Text Classification based on Multi-granularity Attention Hybrid Neural\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network-based approaches have become the driven forces for Natural\nLanguage Processing (NLP) tasks. Conventionally, there are two mainstream\nneural architectures for NLP tasks: the recurrent neural network (RNN) and the\nconvolution neural network (ConvNet). RNNs are good at modeling long-term\ndependencies over input texts, but preclude parallel computation. ConvNets do\nnot have memory capability and it has to model sequential data as un-ordered\nfeatures. Therefore, ConvNets fail to learn sequential dependencies over the\ninput texts, but it is able to carry out high-efficient parallel computation.\nAs each neural architecture, such as RNN and ConvNets, has its own pro and con,\nintegration of different architectures is assumed to be able to enrich the\nsemantic representation of texts, thus enhance the performance of NLP tasks.\nHowever, few investigation explores the reconciliation of these seemingly\nincompatible architectures. To address this issue, we propose a hybrid\narchitecture based on a novel hierarchical multi-granularity attention\nmechanism, named Multi-granularity Attention-based Hybrid Neural Network\n(MahNN). The attention mechanism is to assign different weights to different\nparts of the input sequence to increase the computation efficiency and\nperformance of neural models. In MahNN, two types of attentions are introduced:\nthe syntactical attention and the semantical attention. The syntactical\nattention computes the importance of the syntactic elements (such as words or\nsentence) at the lower symbolic level and the semantical attention is used to\ncompute the importance of the embedded space dimension corresponding to the\nupper latent semantics. We adopt the text classification as an exemplifying way\nto illustrate the ability of MahNN to understand texts.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 13:02:48 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Liu", "Zhenyu", ""], ["Lu", "Chaohong", ""], ["Huang", "Haiwei", ""], ["Lyu", "Shengfei", ""], ["Tao", "Zhenchao", ""]]}, {"id": "2008.05284", "submitter": "Rui Liu", "authors": "Rui Liu, Berrak Sisman, Feilong Bao, Guanglai Gao and Haizhou Li", "title": "Modeling Prosodic Phrasing with Multi-Task Learning in Tacotron-based\n  TTS", "comments": "To appear in IEEE Signal Processing Letters (SPL)", "journal-ref": null, "doi": "10.1109/LSP.2020.3016564", "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tacotron-based end-to-end speech synthesis has shown remarkable voice\nquality. However, the rendering of prosody in the synthesized speech remains to\nbe improved, especially for long sentences, where prosodic phrasing errors can\noccur frequently. In this paper, we extend the Tacotron-based speech synthesis\nframework to explicitly model the prosodic phrase breaks. We propose a\nmulti-task learning scheme for Tacotron training, that optimizes the system to\npredict both Mel spectrum and phrase breaks. To our best knowledge, this is the\nfirst implementation of multi-task learning for Tacotron based TTS with a\nprosodic phrasing model. Experiments show that our proposed training scheme\nconsistently improves the voice quality for both Chinese and Mongolian systems.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 07:57:29 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Liu", "Rui", ""], ["Sisman", "Berrak", ""], ["Bao", "Feilong", ""], ["Gao", "Guanglai", ""], ["Li", "Haizhou", ""]]}, {"id": "2008.05333", "submitter": "Liang Chen", "authors": "Liang Chen", "title": "Variance-reduced Language Pretraining via a Mask Proposal Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised learning, a.k.a., pretraining, is important in natural\nlanguage processing. Most of the pretraining methods first randomly mask some\npositions in a sentence and then train a model to recover the tokens at the\nmasked positions. In such a way, the model can be trained without human\nlabeling, and the massive data can be used with billion parameters. Therefore,\nthe optimization efficiency becomes critical. In this paper, we tackle the\nproblem from the view of gradient variance reduction. In particular, we first\npropose a principled gradient variance decomposition theorem, which shows that\nthe variance of the stochastic gradient of the language pretraining can be\nnaturally decomposed into two terms: the variance that arises from the sample\nof data in a batch, and the variance that arises from the sampling of the mask.\nThe second term is the key difference between selfsupervised learning and\nsupervised learning, which makes the pretraining slower. In order to reduce the\nvariance of the second part, we leverage the importance sampling strategy,\nwhich aims at sampling the masks according to a proposal distribution instead\nof the uniform distribution. It can be shown that if the proposal distribution\nis proportional to the gradient norm, the variance of the sampling is reduced.\nTo improve efficiency, we introduced a MAsk Proposal Network (MAPNet), which\napproximates the optimal mask proposal distribution and is trained end-to-end\nalong with the model. According to the experimental result, our model converges\nmuch faster and achieves higher performance than the baseline BERT model.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 14:12:32 GMT"}, {"version": "v2", "created": "Sun, 16 Aug 2020 15:40:33 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Chen", "Liang", ""]]}, {"id": "2008.05348", "submitter": "Pinzhen Chen", "authors": "Pinzhen Chen, Kenneth Heafield", "title": "Approaching Neural Chinese Word Segmentation as a Low-Resource Machine\n  Translation Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised Chinese word segmentation has entered the deep learning era which\nreduces the hassle of feature engineering. Recently, some researchers attempted\nto treat it as character-level translation which further simplified model\ndesigning and building, but there is still a performance gap between the\ntranslation-based approach and other methods. In this work, we apply the best\npractices from low-resource neural machine translation to Chinese word\nsegmentation. We build encoder-decoder models with attention, and examine a\nseries of techniques including regularization, data augmentation, objective\nweighting, transfer learning and ensembling. Our method is generic for word\nsegmentation, without the need for feature engineering or model implementation.\nIn the closed test with constrained data, our method ties with the state of the\nart on the MSR dataset and is comparable to other methods on the PKU dataset.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 14:40:51 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 16:08:56 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Chen", "Pinzhen", ""], ["Heafield", "Kenneth", ""]]}, {"id": "2008.05363", "submitter": "Sebastian Hofst\\\"atter", "authors": "Sebastian Hofst\\\"atter, Markus Zlabinger, Mete Sertkan, Michael\n  Schr\\\"oder, Allan Hanbury", "title": "Fine-Grained Relevance Annotations for Multi-Task Document Ranking and\n  Question Answering", "comments": "Accepted at CIKM 2020 (Resource Track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many existing retrieval and question answering datasets. However,\nmost of them either focus on ranked list evaluation or single-candidate\nquestion answering. This divide makes it challenging to properly evaluate\napproaches concerned with ranking documents and providing snippets or answers\nfor a given query. In this work, we present FiRA: a novel dataset of\nFine-Grained Relevance Annotations. We extend the ranked retrieval annotations\nof the Deep Learning track of TREC 2019 with passage and word level graded\nrelevance annotations for all relevant documents. We use our newly created data\nto study the distribution of relevance in long documents, as well as the\nattention of annotators to specific positions of the text. As an example, we\nevaluate the recently introduced TKL document ranking model. We find that\nalthough TKL exhibits state-of-the-art retrieval results for long documents, it\nmisses many relevant passages.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 14:59:50 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Hofst\u00e4tter", "Sebastian", ""], ["Zlabinger", "Markus", ""], ["Sertkan", "Mete", ""], ["Schr\u00f6der", "Michael", ""], ["Hanbury", "Allan", ""]]}, {"id": "2008.05449", "submitter": "Sonia Laudanna", "authors": "Gerardo Canfora, Andrea Di Sorbo, Sonia Laudanna, Anna Vacca, Corrado\n  A. Visaggio", "title": "Profiling Gas Leaks in Solidity Smart Contracts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, more and more applications are developed for running on a\ndistributed ledger technology, namely dApps. The business logic of dApps is\nusually implemented within smart contracts developed through Solidity, a\nprogramming language for writing smart contracts on different blockchain\nplatforms, including the popular Ethereum. In Ethereum, the smart contracts run\non the machines of miners and the gas corresponds to the execution fee\ncompensating such computing resources. However, the deployment and execution\ncosts of a smart contract depend on the implementation choices done by\ndevelopers. Unappropriated design choices could lead to higher gas consumption\nthan necessary. In this paper, we (i) identify a set of 19 Solidity code smells\naffecting the deployment and transaction costs of a smart contract, and (ii)\nassess the relevance of such smells through a survey involving 34 participants.\nOn top of these smells, we propose GasMet, a suite of metrics for statically\nevaluating the code quality of a smart contract from the gas consumption\nperspective. An experiment involving 2,186 smart contracts demonstrates that\nthe proposed metrics have direct associations with deployment costs. The\nmetrics in our suite can be used for more easily identifying source code\nsegments that need optimizations.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 17:26:55 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 10:24:04 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Canfora", "Gerardo", ""], ["Di Sorbo", "Andrea", ""], ["Laudanna", "Sonia", ""], ["Vacca", "Anna", ""], ["Visaggio", "Corrado A.", ""]]}, {"id": "2008.05514", "submitter": "Roger Hsiao", "authors": "Roger Hsiao, Dogan Can, Tim Ng, Ruchir Travadi and Arnab Ghoshal", "title": "Online Automatic Speech Recognition with Listen, Attend and Spell Model", "comments": "5 pages, 4 figures, this version is submitted to IEEE Signal\n  Processing Letters", "journal-ref": null, "doi": "10.1109/LSP.2020.3031480", "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Listen, Attend and Spell (LAS) model and other attention-based automatic\nspeech recognition (ASR) models have known limitations when operated in a fully\nonline mode. In this paper, we analyze the online operation of LAS models to\ndemonstrate that these limitations stem from the handling of silence regions\nand the reliability of online attention mechanism at the edge of input buffers.\nWe propose a novel and simple technique that can achieve fully online\nrecognition while meeting accuracy and latency targets. For the Mandarin\ndictation task, our proposed approach can achieve a character error rate in\nonline operation that is within 4% relative to an offline LAS model. The\nproposed online LAS model operates at 12% lower latency relative to a\nconventional neural network hidden Markov model hybrid of comparable accuracy.\nWe have validated the proposed method through a production scale deployment,\nwhich, to the best of our knowledge, is the first such deployment of a fully\nonline LAS model.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 18:18:54 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 18:40:28 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Hsiao", "Roger", ""], ["Can", "Dogan", ""], ["Ng", "Tim", ""], ["Travadi", "Ruchir", ""], ["Ghoshal", "Arnab", ""]]}, {"id": "2008.05536", "submitter": "Rahul Singh", "authors": "Rahul Singh, Tarun Joshi, Vijayan N. Nair, and Agus Sudjianto", "title": "Model Robustness with Text Classification: Semantic-preserving\n  adversarial attacks", "comments": "12 Pages, 3 Figures, 10 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose algorithms to create adversarial attacks to assess model\nrobustness in text classification problems. They can be used to create white\nbox attacks and black box attacks while at the same time preserving the\nsemantics and syntax of the original text. The attacks cause significant number\nof flips in white-box setting and same rule based can be used in black-box\nsetting. In a black-box setting, the attacks created are able to reverse\ndecisions of transformer based architectures.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 19:17:46 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 01:05:09 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Singh", "Rahul", ""], ["Joshi", "Tarun", ""], ["Nair", "Vijayan N.", ""], ["Sudjianto", "Agus", ""]]}, {"id": "2008.05640", "submitter": "Liang Pang", "authors": "Changying Hao, Liang Pang, Yanyan Lan, Fei Sun, Jiafeng Guo, Xueqi\n  Cheng", "title": "Ranking Enhanced Dialogue Generation", "comments": "Accepted at CIKM 2020", "journal-ref": null, "doi": "10.1145/3340531.3411918", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  How to effectively utilize the dialogue history is a crucial problem in\nmulti-turn dialogue generation. Previous works usually employ various neural\nnetwork architectures (e.g., recurrent neural networks, attention mechanisms,\nand hierarchical structures) to model the history. However, a recent empirical\nstudy by Sankar et al. has shown that these architectures lack the ability of\nunderstanding and modeling the dynamics of the dialogue history. For example,\nthe widely used architectures are insensitive to perturbations of the dialogue\nhistory, such as words shuffling, utterances missing, and utterances\nreordering. To tackle this problem, we propose a Ranking Enhanced Dialogue\ngeneration framework in this paper. Despite the traditional representation\nencoder and response generation modules, an additional ranking module is\nintroduced to model the ranking relation between the former utterance and\nconsecutive utterances. Specifically, the former utterance and consecutive\nutterances are treated as query and corresponding documents, and both local and\nglobal ranking losses are designed in the learning process. In this way, the\ndynamics in the dialogue history can be explicitly captured. To evaluate our\nproposed models, we conduct extensive experiments on three public datasets,\ni.e., bAbI, PersonaChat, and JDC. Experimental results show that our models\nproduce better responses in terms of both quantitative measures and human\njudgments, as compared with the state-of-the-art dialogue generation models.\nFurthermore, we give some detailed experimental analysis to show where and how\nthe improvements come from.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 01:49:56 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Hao", "Changying", ""], ["Pang", "Liang", ""], ["Lan", "Yanyan", ""], ["Sun", "Fei", ""], ["Guo", "Jiafeng", ""], ["Cheng", "Xueqi", ""]]}, {"id": "2008.05656", "submitter": "Jianzong Wang", "authors": "Zhen Zeng, Jianzong Wang, Ning Cheng, Jing Xiao", "title": "Prosody Learning Mechanism for Speech Synthesis System Without Text\n  Length Limit", "comments": "will be presented in INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent neural speech synthesis systems have gradually focused on the control\nof prosody to improve the quality of synthesized speech, but they rarely\nconsider the variability of prosody and the correlation between prosody and\nsemantics together. In this paper, a prosody learning mechanism is proposed to\nmodel the prosody of speech based on TTS system, where the prosody information\nof speech is extracted from the melspectrum by a prosody learner and combined\nwith the phoneme sequence to reconstruct the mel-spectrum. Meanwhile, the\nsematic features of text from the pre-trained language model is introduced to\nimprove the prosody prediction results. In addition, a novel self-attention\nstructure, named as local attention, is proposed to lift this restriction of\ninput text length, where the relative position information of the sequence is\nmodeled by the relative position matrices so that the position encodings is no\nlonger needed. Experiments on English and Mandarin show that speech with more\nsatisfactory prosody has obtained in our model. Especially in Mandarin\nsynthesis, our proposed model outperforms baseline model with a MOS gap of\n0.08, and the overall naturalness of the synthesized speech has been\nsignificantly improved.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 02:54:50 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Zeng", "Zhen", ""], ["Wang", "Jianzong", ""], ["Cheng", "Ning", ""], ["Xiao", "Jing", ""]]}, {"id": "2008.05658", "submitter": "Yiru Wang", "authors": "Yiru Wang, Shen Huang, Gongfu Li, Qiang Deng, Dongliang Liao, Pengda\n  Si, Yujiu Yang, Jin Xu", "title": "Cognitive Representation Learning of Self-Media Online Article Quality", "comments": "Accepted at the Proceedings of the 28th ACM International Conference\n  on Multimedia", "journal-ref": null, "doi": "10.1145/3394171.3413747", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automatic quality assessment of self-media online articles is an urgent\nand new issue, which is of great value to the online recommendation and search.\nDifferent from traditional and well-formed articles, self-media online articles\nare mainly created by users, which have the appearance characteristics of\ndifferent text levels and multi-modal hybrid editing, along with the potential\ncharacteristics of diverse content, different styles, large semantic spans and\ngood interactive experience requirements. To solve these challenges, we\nestablish a joint model CoQAN in combination with the layout organization,\nwriting characteristics and text semantics, designing different representation\nlearning subnetworks, especially for the feature learning process and\ninteractive reading habits on mobile terminals. It is more consistent with the\ncognitive style of expressing an expert's evaluation of articles. We have also\nconstructed a large scale real-world assessment dataset. Extensive experimental\nresults show that the proposed framework significantly outperforms\nstate-of-the-art methods, and effectively learns and integrates different\nfactors of the online article quality assessment.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 02:59:52 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Wang", "Yiru", ""], ["Huang", "Shen", ""], ["Li", "Gongfu", ""], ["Deng", "Qiang", ""], ["Liao", "Dongliang", ""], ["Si", "Pengda", ""], ["Yang", "Yujiu", ""], ["Xu", "Jin", ""]]}, {"id": "2008.05666", "submitter": "Qingkai Min", "authors": "Qingkai Min, Libo Qin, Zhiyang Teng, Xiao Liu, Yue Zhang", "title": "Dialogue State Induction Using Neural Latent Variable Models", "comments": "IJCAI 2020", "journal-ref": null, "doi": "10.24963/ijcai.2020/532", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue state modules are a useful component in a task-oriented dialogue\nsystem. Traditional methods find dialogue states by manually labeling training\ncorpora, upon which neural models are trained. However, the labeling process\ncan be costly, slow, error-prone, and more importantly, cannot cover the vast\nrange of domains in real-world dialogues for customer service. We propose the\ntask of dialogue state induction, building two neural latent variable models\nthat mine dialogue states automatically from unlabeled customer service\ndialogue records. Results show that the models can effectively find meaningful\nslots. In addition, equipped with induced dialogue states, a state-of-the-art\ndialogue system gives better performance compared with not using a dialogue\nstate module.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 03:14:25 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Min", "Qingkai", ""], ["Qin", "Libo", ""], ["Teng", "Zhiyang", ""], ["Liu", "Xiao", ""], ["Zhang", "Yue", ""]]}, {"id": "2008.05671", "submitter": "Jianzong Wang", "authors": "Xueli Jia, Jianzong Wang, Zhiyong Zhang, Ning Cheng, Jing Xiao", "title": "Large-scale Transfer Learning for Low-resource Spoken Language\n  Understanding", "comments": "will be presented in INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end Spoken Language Understanding (SLU) models are made increasingly\nlarge and complex to achieve the state-ofthe-art accuracy. However, the\nincreased complexity of a model can also introduce high risk of over-fitting,\nwhich is a major challenge in SLU tasks due to the limitation of available\ndata. In this paper, we propose an attention-based SLU model together with\nthree encoder enhancement strategies to overcome data sparsity challenge. The\nfirst strategy focuses on the transferlearning approach to improve feature\nextraction capability of the encoder. It is implemented by pre-training the\nencoder component with a quantity of Automatic Speech Recognition annotated\ndata relying on the standard Transformer architecture and then fine-tuning the\nSLU model with a small amount of target labelled data. The second strategy\nadopts multitask learning strategy, the SLU model integrates the speech\nrecognition model by sharing the same underlying encoder, such that improving\nrobustness and generalization ability. The third strategy, learning from\nComponent Fusion (CF) idea, involves a Bidirectional Encoder Representation\nfrom Transformer (BERT) model and aims to boost the capability of the decoder\nwith an auxiliary network. It hence reduces the risk of over-fitting and\naugments the ability of the underlying encoder, indirectly. Experiments on the\nFluentAI dataset show that cross-language transfer learning and multi-task\nstrategies have been improved by up to 4:52% and 3:89% respectively, compared\nto the baseline.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 03:43:05 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Jia", "Xueli", ""], ["Wang", "Jianzong", ""], ["Zhang", "Zhiyong", ""], ["Cheng", "Ning", ""], ["Xiao", "Jing", ""]]}, {"id": "2008.05701", "submitter": "Damiano Spina", "authors": "Kevin Roitero, Michael Soprano, Beatrice Portelli, Damiano Spina,\n  Vincenzo Della Mea, Giuseppe Serra, Stefano Mizzaro and Gianluca Demartini", "title": "The COVID-19 Infodemic: Can the Crowd Judge Recent Misinformation\n  Objectively?", "comments": "10 pages; Preprint of the full paper accepted at CIKM 2020", "journal-ref": null, "doi": "10.1145/3340531.3412048", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Misinformation is an ever increasing problem that is difficult to solve for\nthe research community and has a negative impact on the society at large. Very\nrecently, the problem has been addressed with a crowdsourcing-based approach to\nscale up labeling efforts: to assess the truthfulness of a statement, instead\nof relying on a few experts, a crowd of (non-expert) judges is exploited. We\nfollow the same approach to study whether crowdsourcing is an effective and\nreliable method to assess statements truthfulness during a pandemic. We\nspecifically target statements related to the COVID-19 health emergency, that\nis still ongoing at the time of the study and has arguably caused an increase\nof the amount of misinformation that is spreading online (a phenomenon for\nwhich the term \"infodemic\" has been used). By doing so, we are able to address\n(mis)information that is both related to a sensitive and personal issue like\nhealth and very recent as compared to when the judgment is done: two issues\nthat have not been analyzed in related work. In our experiment, crowd workers\nare asked to assess the truthfulness of statements, as well as to provide\nevidence for the assessments as a URL and a text justification. Besides showing\nthat the crowd is able to accurately judge the truthfulness of the statements,\nwe also report results on many different aspects, including: agreement among\nworkers, the effect of different aggregation functions, of scales\ntransformations, and of workers background / bias. We also analyze workers\nbehavior, in terms of queries submitted, URLs found / selected, text\njustifications, and other behavioral data like clicks and mouse actions\ncollected by means of an ad hoc logger.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 05:53:24 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Roitero", "Kevin", ""], ["Soprano", "Michael", ""], ["Portelli", "Beatrice", ""], ["Spina", "Damiano", ""], ["Della Mea", "Vincenzo", ""], ["Serra", "Giuseppe", ""], ["Mizzaro", "Stefano", ""], ["Demartini", "Gianluca", ""]]}, {"id": "2008.05713", "submitter": "Ella Rabinovich", "authors": "Jai Aggarwal, Ella Rabinovich, Suzanne Stevenson", "title": "Exploration of Gender Differences in COVID-19 Discourse on Reddit", "comments": "Proceedings of the 1st Workshop on NLP for COVID-19 (ACL 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decades of research on differences in the language of men and women have\nestablished postulates about preferences in lexical, topical, and emotional\nexpression between the two genders, along with their sociological\nunderpinnings. Using a novel dataset of male and female linguistic productions\ncollected from the Reddit discussion platform, we further confirm existing\nassumptions about gender-linked affective distinctions, and demonstrate that\nthese distinctions are amplified in social media postings involving\nemotionally-charged discourse related to COVID-19. Our analysis also confirms\nconsiderable differences in topical preferences between male and female authors\nin spontaneous pandemic-related discussions.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 06:29:24 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Aggarwal", "Jai", ""], ["Rabinovich", "Ella", ""], ["Stevenson", "Suzanne", ""]]}, {"id": "2008.05750", "submitter": "Wenyong Huang", "authors": "Wenyong Huang, Wenchao Hu, Yu Ting Yeung, Xiao Chen", "title": "Conv-Transformer Transducer: Low Latency, Low Frame Rate, Streamable\n  End-to-End Speech Recognition", "comments": "Accepted by INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer has achieved competitive performance against state-of-the-art\nend-to-end models in automatic speech recognition (ASR), and requires\nsignificantly less training time than RNN-based models. The original\nTransformer, with encoder-decoder architecture, is only suitable for offline\nASR. It relies on an attention mechanism to learn alignments, and encodes input\naudio bidirectionally. The high computation cost of Transformer decoding also\nlimits its use in production streaming systems. To make Transformer suitable\nfor streaming ASR, we explore Transducer framework as a streamable way to learn\nalignments. For audio encoding, we apply unidirectional Transformer with\ninterleaved convolution layers. The interleaved convolution layers are used for\nmodeling future context which is important to performance. To reduce\ncomputation cost, we gradually downsample acoustic input, also with the\ninterleaved convolution layers. Moreover, we limit the length of history\ncontext in self-attention to maintain constant computation cost for each\ndecoding step. We show that this architecture, named Conv-Transformer\nTransducer, achieves competitive performance on LibriSpeech dataset (3.6\\% WER\non test-clean) without external language models. The performance is comparable\nto previously published streamable Transformer Transducer and strong hybrid\nstreaming ASR systems, and is achieved with smaller look-ahead window (140~ms),\nfewer parameters and lower frame rate.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 08:20:02 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Huang", "Wenyong", ""], ["Hu", "Wenchao", ""], ["Yeung", "Yu Ting", ""], ["Chen", "Xiao", ""]]}, {"id": "2008.05759", "submitter": "Tadej \\v{S}kvorc", "authors": "Tadej \\v{S}kvorc, Polona Gantar, Marko Robnik-\\v{S}ikonja", "title": "MICE: Mining Idioms with Contextual Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Idiomatic expressions can be problematic for natural language processing\napplications as their meaning cannot be inferred from their constituting words.\nA lack of successful methodological approaches and sufficiently large datasets\nprevents the development of machine learning approaches for detecting idioms,\nespecially for expressions that do not occur in the training set. We present an\napproach, called MICE, that uses contextual embeddings for that purpose. We\npresent a new dataset of multi-word expressions with literal and idiomatic\nmeanings and use it to train a classifier based on two state-of-the-art\ncontextual word embeddings: ELMo and BERT. We show that deep neural networks\nusing both embeddings perform much better than existing approaches, and are\ncapable of detecting idiomatic word use, even for expressions that were not\npresent in the training set. We demonstrate cross-lingual transfer of developed\nmodels and analyze the size of the required dataset.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 08:56:40 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["\u0160kvorc", "Tadej", ""], ["Gantar", "Polona", ""], ["Robnik-\u0160ikonja", "Marko", ""]]}, {"id": "2008.05760", "submitter": "Albert Gatt", "authors": "Carlos Mena, Albert Gatt, Andrea DeMarco, Claudia Borg, Lonneke van\n  der Plas, Amanda Muscat, Ian Padovani", "title": "MASRI-HEADSET: A Maltese Corpus for Speech Recognition", "comments": "8 pages, 2 figures, 4 tables, 1 appendix. Appears in Proceedings of\n  the 12th edition of the Language Resources and Evaluation Conference\n  (LREC'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Maltese, the national language of Malta, is spoken by approximately 500,000\npeople. Speech processing for Maltese is still in its early stages of\ndevelopment. In this paper, we present the first spoken Maltese corpus designed\npurposely for Automatic Speech Recognition (ASR). The MASRI-HEADSET corpus was\ndeveloped by the MASRI project at the University of Malta. It consists of 8\nhours of speech paired with text, recorded by using short text snippets in a\nlaboratory environment. The speakers were recruited from different geographical\nlocations all over the Maltese islands, and were roughly evenly distributed by\ngender. This paper also presents some initial results achieved in baseline\nexperiments for Maltese ASR using Sphinx and Kaldi. The MASRI-HEADSET Corpus is\npublicly available for research/academic purposes.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 08:57:16 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Mena", "Carlos", ""], ["Gatt", "Albert", ""], ["DeMarco", "Andrea", ""], ["Borg", "Claudia", ""], ["van der Plas", "Lonneke", ""], ["Muscat", "Amanda", ""], ["Padovani", "Ian", ""]]}, {"id": "2008.05773", "submitter": "Yu Wu", "authors": "Sanyuan Chen, Yu Wu, Zhuo Chen, Jian Wu, Jinyu Li, Takuya Yoshioka,\n  Chengyi Wang, Shujie Liu, Ming Zhou", "title": "Continuous Speech Separation with Conformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous speech separation plays a vital role in complicated speech related\ntasks such as conversation transcription. The separation model extracts a\nsingle speaker signal from a mixed speech. In this paper, we use transformer\nand conformer in lieu of recurrent neural networks in the separation system, as\nwe believe capturing global information with the self-attention based method is\ncrucial for the speech separation. Evaluating on the LibriCSS dataset, the\nconformer separation model achieves state of the art results, with a relative\n23.5% word error rate (WER) reduction from bi-directional LSTM (BLSTM) in the\nutterance-wise evaluation and a 15.4% WER reduction in the continuous\nevaluation.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 09:36:05 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 12:38:51 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Chen", "Sanyuan", ""], ["Wu", "Yu", ""], ["Chen", "Zhuo", ""], ["Wu", "Jian", ""], ["Li", "Jinyu", ""], ["Yoshioka", "Takuya", ""], ["Wang", "Chengyi", ""], ["Liu", "Shujie", ""], ["Zhou", "Ming", ""]]}, {"id": "2008.05828", "submitter": "Madhura Pande", "authors": "Madhura Pande, Aakriti Budhraja, Preksha Nema, Pratyush Kumar, Mitesh\n  M. Khapra", "title": "On the Importance of Local Information in Transformer Based Models", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The self-attention module is a key component of Transformer-based models,\nwherein each token pays attention to every other token. Recent studies have\nshown that these heads exhibit syntactic, semantic, or local behaviour. Some\nstudies have also identified promise in restricting this attention to be local,\ni.e., a token attending to other tokens only in a small neighbourhood around\nit. However, no conclusive evidence exists that such local attention alone is\nsufficient to achieve high accuracy on multiple NLP tasks. In this work, we\nsystematically analyse the role of locality information in learnt models and\ncontrast it with the role of syntactic information. More specifically, we first\ndo a sensitivity analysis and show that, at every layer, the representation of\na token is much more sensitive to tokens in a small neighborhood around it than\nto tokens which are syntactically related to it. We then define an attention\nbias metric to determine whether a head pays more attention to local tokens or\nto syntactically related tokens. We show that a larger fraction of heads have a\nlocality bias as compared to a syntactic bias. Having established the\nimportance of local attention heads, we train and evaluate models where varying\nfractions of the attention heads are constrained to be local. Such models would\nbe more efficient as they would have fewer computations in the attention layer.\nWe evaluate these models on 4 GLUE datasets (QQP, SST-2, MRPC, QNLI) and 2 MT\ndatasets (En-De, En-Ru) and clearly demonstrate that such constrained models\nhave comparable performance to the unconstrained models. Through this\nsystematic evaluation we establish that attention in Transformer-based models\ncan be constrained to be local without affecting performance.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 11:32:47 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Pande", "Madhura", ""], ["Budhraja", "Aakriti", ""], ["Nema", "Preksha", ""], ["Kumar", "Pratyush", ""], ["Khapra", "Mitesh M.", ""]]}, {"id": "2008.05925", "submitter": "Cunxiang Wang", "authors": "Cunxiang Wang, Jinhang Wu, Luxin Liu and Yue Zhang", "title": "Commonsense Knowledge Graph Reasoning by Selection or Generation? Why?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense knowledge graph reasoning(CKGR) is the task of predicting a\nmissing entity given one existing and the relation in a commonsense knowledge\ngraph (CKG). Existing methods can be classified into two categories generation\nmethod and selection method. Each method has its own advantage. We\ntheoretically and empirically compare the two methods, finding the selection\nmethod is more suitable than the generation method in CKGR. Given the\nobservation, we further combine the structure of neural Text Encoder and\nKnowledge Graph Embedding models to solve the selection method's two problems,\nachieving competitive results. We provide a basic framework and baseline model\nfor subsequent CKGR tasks by selection methods.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 14:13:30 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Wang", "Cunxiang", ""], ["Wu", "Jinhang", ""], ["Liu", "Luxin", ""], ["Zhang", "Yue", ""]]}, {"id": "2008.05972", "submitter": "Pramod Vadiraja", "authors": "Pramod Vadiraja and Muhammad Ali Chattha", "title": "A Survey on Knowledge integration techniques with Artificial Neural\n  Networks for seq-2-seq/time series models", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, with the advent of massive computational power and the\navailability of huge amounts of data, Deep neural networks have enabled the\nexploration of uncharted areas in several domains. But at times, they\nunder-perform due to insufficient data, poor data quality, data that might not\nbe covering the domain broadly, etc. Knowledge-based systems leverage expert\nknowledge for making decisions and suitably take actions. Such systems retain\ninterpretability in the decision-making process. This paper focuses on\nexploring techniques to integrate expert knowledge to the Deep Neural Networks\nfor sequence-to-sequence and time series models to improve their performance\nand interpretability.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 15:40:38 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Vadiraja", "Pramod", ""], ["Chattha", "Muhammad Ali", ""]]}, {"id": "2008.06079", "submitter": "Francielle Alves Vargas", "authors": "Francielle Alves Vargas and Thiago Alexandre Salgueiro Pardo", "title": "Studying Dishonest Intentions in Brazilian Portuguese Texts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Previous work in the social sciences, psychology and linguistics has show\nthat liars have some control over the content of their stories, however their\nunderlying state of mind may \"leak out\" through the way that they tell them. To\nthe best of our knowledge, no previous systematic effort exists in order to\ndescribe and model deception language for Brazilian Portuguese. To fill this\nimportant gap, we carry out an initial empirical linguistic study on false\nstatements in Brazilian news. We methodically analyze linguistic features using\na deceptive news corpus, which includes both fake and true news. The results\nshow that they present substantial lexical, syntactic and semantic variations,\nas well as punctuation and emotion distinctions.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 18:44:52 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 21:31:47 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Vargas", "Francielle Alves", ""], ["Pardo", "Thiago Alexandre Salgueiro", ""]]}, {"id": "2008.06146", "submitter": "Hyeonmook Park", "authors": "Hyeonmook Park, Jungbae Park, Sang Wan Lee", "title": "End-to-End Trainable Self-Attentive Shallow Network for Text-Independent\n  Speaker Verification", "comments": "5 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized end-to-end (GE2E) model is widely used in speaker verification\n(SV) fields due to its expandability and generality regardless of specific\nlanguages. However, the long-short term memory (LSTM) based on GE2E has two\nlimitations: First, the embedding of GE2E suffers from vanishing gradient,\nwhich leads to performance degradation for very long input sequences. Secondly,\nutterances are not represented as a properly fixed dimensional vector. In this\npaper, to overcome issues mentioned above, we propose a novel framework for SV,\nend-to-end trainable self-attentive shallow network (SASN), incorporating a\ntime-delay neural network (TDNN) and a self-attentive pooling mechanism based\non the self-attentive x-vector system during an utterance embedding phase. We\ndemonstrate that the proposed model is highly efficient, and provides more\naccurate speaker verification than GE2E. For VCTK dataset, with just less than\nhalf the size of GE2E, the proposed model showed significant performance\nimprovement over GE2E of about 63%, 67%, and 85% in EER (Equal error rate), DCF\n(Detection cost function), and AUC (Area under the curve), respectively.\nNotably, when the input length becomes longer, the DCF score improvement of the\nproposed model is about 17 times greater than that of GE2E.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 00:46:50 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Park", "Hyeonmook", ""], ["Park", "Jungbae", ""], ["Lee", "Sang Wan", ""]]}, {"id": "2008.06173", "submitter": "Milind Rao", "authors": "Milind Rao, Anirudh Raju, Pranav Dheram, Bach Bui, Ariya Rastrow", "title": "Speech To Semantics: Improve ASR and NLU Jointly via All-Neural\n  Interfaces", "comments": "Proceedings of INTERSPEECH", "journal-ref": "Proc. Interspeech 2020, 876-880 (2020)", "doi": "10.21437/Interspeech.2020-2976", "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of spoken language understanding (SLU) of extracting\nnatural language intents and associated slot arguments or named entities from\nspeech that is primarily directed at voice assistants. Such a system subsumes\nboth automatic speech recognition (ASR) as well as natural language\nunderstanding (NLU). An end-to-end joint SLU model can be built to a required\nspecification opening up the opportunity to deploy on hardware constrained\nscenarios like devices enabling voice assistants to work offline, in a privacy\npreserving manner, whilst also reducing server costs.\n  We first present models that extract utterance intent directly from speech\nwithout intermediate text output. We then present a compositional model, which\ngenerates the transcript using the Listen Attend Spell ASR system and then\nextracts interpretation using a neural NLU model. Finally, we contrast these\nmethods to a jointly trained end-to-end joint SLU model, consisting of ASR and\nNLU subsystems which are connected by a neural network based interface instead\nof text, that produces transcripts as well as NLU interpretation. We show that\nthe jointly trained model shows improvements to ASR incorporating semantic\ninformation from NLU and also improves NLU by exposing it to ASR confusion\nencoded in the hidden layer.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 02:43:57 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Rao", "Milind", ""], ["Raju", "Anirudh", ""], ["Dheram", "Pranav", ""], ["Bui", "Bach", ""], ["Rastrow", "Ariya", ""]]}, {"id": "2008.06176", "submitter": "Ye Bi", "authors": "Ye Bi, Shuo Wang, Zhongrui Fan", "title": "A Hybrid BERT and LightGBM based Model for Predicting Emotion GIF\n  Categories on Twitter", "comments": "4 pages, ACL 2020 EmotionGIF Challenge Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The animated Graphical Interchange Format (GIF) images have been widely used\non social media as an intuitive way of expression emotion. Given their\nexpressiveness, GIFs offer a more nuanced and precise way to convey emotions.\nIn this paper, we present our solution for the EmotionGIF 2020 challenge, the\nshared task of SocialNLP 2020. To recommend GIF categories for unlabeled\ntweets, we regarded this problem as a kind of matching tasks and proposed a\nlearning to rank framework based on Bidirectional Encoder Representations from\nTransformer (BERT) and LightGBM. Our team won the 4th place with a Mean Average\nPrecision @ 6 (MAP@6) score of 0.5394 on the round 1 leaderboard.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 03:23:09 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Bi", "Ye", ""], ["Wang", "Shuo", ""], ["Fan", "Zhongrui", ""]]}, {"id": "2008.06208", "submitter": "Taewoo Lee", "authors": "Taewoo Lee, Min-Joong Lee, Tae Gyoon Kang, Seokyeoung Jung, Minseok\n  Kwon, Yeona Hong, Jungin Lee, Kyoung-Gu Woo, Ho-Gyeong Kim, Jiseung Jeong,\n  Jihyun Lee, Hosik Lee, Young Sang Choi", "title": "Adaptable Multi-Domain Language Model for Transformer ASR", "comments": "This paper is accepted for presentation at IEEE International\n  Conference on Acoustics, Speech and Signal Processing (IEEE ICASSP), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an adapter based multi-domain Transformer based language model\n(LM) for Transformer ASR. The model consists of a big size common LM and small\nsize adapters. The model can perform multi-domain adaptation with only the\nsmall size adapters and its related layers. The proposed model can reuse the\nfull fine-tuned LM which is fine-tuned using all layers of an original model.\nThe proposed LM can be expanded to new domains by adding about 2% of parameters\nfor a first domain and 13% parameters for after second domain. The proposed\nmodel is also effective in reducing the model maintenance cost because it is\npossible to omit the costly and time-consuming common LM pre-training process.\nUsing proposed adapter based approach, we observed that a general LM with\nadapter can outperform a dedicated music domain LM in terms of word error rate\n(WER).\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 06:33:26 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 03:17:30 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Lee", "Taewoo", ""], ["Lee", "Min-Joong", ""], ["Kang", "Tae Gyoon", ""], ["Jung", "Seokyeoung", ""], ["Kwon", "Minseok", ""], ["Hong", "Yeona", ""], ["Lee", "Jungin", ""], ["Woo", "Kyoung-Gu", ""], ["Kim", "Ho-Gyeong", ""], ["Jeong", "Jiseung", ""], ["Lee", "Jihyun", ""], ["Lee", "Hosik", ""], ["Choi", "Young Sang", ""]]}, {"id": "2008.06222", "submitter": "Albert Gatt", "authors": "Stavros Assimakopoulos, Rebecca Vella Muskat, Lonneke van der Plas,\n  Albert Gatt", "title": "Annotating for Hate Speech: The MaNeCo Corpus and Some Input from\n  Critical Discourse Analysis", "comments": "10 pages, 1 table. Appears in Proceedings of the 12th edition of the\n  Language Resources and Evaluation Conference (LREC'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a novel scheme for the annotation of hate speech in\ncorpora of Web 2.0 commentary. The proposed scheme is motivated by the critical\nanalysis of posts made in reaction to news reports on the Mediterranean\nmigration crisis and LGBTIQ+ matters in Malta, which was conducted under the\nauspices of the EU-funded C.O.N.T.A.C.T. project. Based on the realization that\nhate speech is not a clear-cut category to begin with, appears to belong to a\ncontinuum of discriminatory discourse and is often realized through the use of\nindirect linguistic means, it is argued that annotation schemes for its\ndetection should refrain from directly including the label 'hate speech,' as\ndifferent annotators might have different thresholds as to what constitutes\nhate speech and what not. In view of this, we suggest a multi-layer annotation\nscheme, which is pilot-tested against a binary +/- hate speech classification\nand appears to yield higher inter-annotator agreement. Motivating the\npostulation of our scheme, we then present the MaNeCo corpus on which it will\neventually be used; a substantial corpus of on-line newspaper comments spanning\n10 years.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 07:39:21 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Assimakopoulos", "Stavros", ""], ["Muskat", "Rebecca Vella", ""], ["van der Plas", "Lonneke", ""], ["Gatt", "Albert", ""]]}, {"id": "2008.06239", "submitter": "Andrea Madotto Mr", "authors": "Andrea Madotto, Zihan Liu, Zhaojiang Lin, Pascale Fung", "title": "Language Models as Few-Shot Learner for Task-Oriented Dialogue Systems", "comments": "Blog (https://andreamad8.github.io/few-shot-gpt/), Medium\n  (https://medium.com/@madottoandrea/language-model-as-few-shot-learner-for-task-oriented-dialogue-systems-db4765796744)\n  and Code (https://github.com/andreamad8/TASK-ORIENTED-LM-FEWSHOT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-oriented dialogue systems use four connected modules, namely, Natural\nLanguage Understanding (NLU), a Dialogue State Tracking (DST), Dialogue Policy\n(DP) and Natural Language Generation (NLG). A research challenge is to learn\neach module with the least amount of samples (i.e., few-shots) given the high\ncost related to the data collection. The most common and effective technique to\nsolve this problem is transfer learning, where large language models, either\npre-trained on text or task-specific data, are fine-tuned on the few samples.\nThese methods require fine-tuning steps and a set of parameters for each task.\nDifferently, language models, such as GPT-2 (Radford et al., 2019) and GPT-3\n(Brown et al., 2020), allow few-shot learning by priming the model with few\nexamples. In this paper, we evaluate the priming few-shot ability of language\nmodels in the NLU, DST, DP and NLG tasks. Importantly, we highlight the current\nlimitations of this approach, and we discuss the possible implication for\nfuture work.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 08:23:21 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 10:56:47 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Madotto", "Andrea", ""], ["Liu", "Zihan", ""], ["Lin", "Zhaojiang", ""], ["Fung", "Pascale", ""]]}, {"id": "2008.06258", "submitter": "Herman Kamper", "authors": "Leanne Nortje, Herman Kamper", "title": "Unsupervised vs. transfer learning for multimodal one-shot matching of\n  speech and images", "comments": "Accepted at Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of multimodal one-shot speech-image matching. An agent\nis shown a picture along with a spoken word describing the object in the\npicture, e.g. cookie, broccoli and ice-cream. After observing one paired\nspeech-image example per class, it is shown a new set of unseen pictures, and\nasked to pick the \"ice-cream\". Previous work attempted to tackle this problem\nusing transfer learning: supervised models are trained on labelled background\ndata not containing any of the one-shot classes. Here we compare transfer\nlearning to unsupervised models trained on unlabelled in-domain data. On a\ndataset of paired isolated spoken and visual digits, we specifically compare\nunsupervised autoencoder-like models to supervised classifier and Siamese\nneural networks. In both unimodal and multimodal few-shot matching experiments,\nwe find that transfer learning outperforms unsupervised training. We also\npresent experiments towards combining the two methodologies, but find that\ntransfer learning still performs best (despite idealised experiments showing\nthe benefits of unsupervised learning).\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 09:13:37 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Nortje", "Leanne", ""], ["Kamper", "Herman", ""]]}, {"id": "2008.06268", "submitter": "Muddassar Sindhu", "authors": "Muddassar A. Sindhu", "title": "An Efficient Model Inference Algorithm for Learning-based Testing of\n  Reactive Systems", "comments": "29 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning-based testing (LBT) is an emerging methodology to automate iterative\nblack-box requirements testing of software systems. The methodology involves\ncombining model inference with model checking techniques. However, a variety of\noptimisations on model inference are necessary in order to achieve scalable\ntesting for large systems. In this paper we describe the IKL learning algorithm\nwhich is an active incremental learning algorithm for deterministic Kripke\nstructures. We formally prove the correctness of IKL. We discuss the\noptimisations it incorporates to achieve scalability of testing. We also\nevaluate a black box heuristic for test termination based on convergence of IKL\nlearning.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 09:48:58 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Sindhu", "Muddassar A.", ""]]}, {"id": "2008.06274", "submitter": "Shantanu Chandra", "authors": "Shantanu Chandra, Pushkar Mishra, Helen Yannakoudakis, Madhav\n  Nimishakavi, Marzieh Saeidi, Ekaterina Shutova", "title": "Graph-based Modeling of Online Communities for Fake News Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years, there has been a substantial effort towards\nautomated detection of fake news on social media platforms. Existing research\nhas modeled the structure, style, content, and patterns in dissemination of\nonline posts, as well as the demographic traits of users who interact with\nthem. However, no attention has been directed towards modeling the properties\nof online communities that interact with the posts. In this work, we propose a\nnovel social context-aware fake news detection framework, SAFER, based on graph\nneural networks (GNNs). The proposed framework aggregates information with\nrespect to: 1) the nature of the content disseminated, 2) content-sharing\nbehavior of users, and 3) the social network of those users. We furthermore\nperform a systematic comparison of several GNN models for this task and\nintroduce novel methods based on relational and hyperbolic GNNs, which have not\nbeen previously used for user or community modeling within NLP. We empirically\ndemonstrate that our framework yields significant improvements over existing\ntext-based techniques and achieves state-of-the-art results on fake news\ndatasets from two different domains.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 10:01:34 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 14:02:47 GMT"}, {"version": "v3", "created": "Mon, 14 Sep 2020 16:04:41 GMT"}, {"version": "v4", "created": "Mon, 23 Nov 2020 15:07:48 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Chandra", "Shantanu", ""], ["Mishra", "Pushkar", ""], ["Yannakoudakis", "Helen", ""], ["Nimishakavi", "Madhav", ""], ["Saeidi", "Marzieh", ""], ["Shutova", "Ekaterina", ""]]}, {"id": "2008.06351", "submitter": "Richard Moot", "authors": "Richard Moot", "title": "Partial Orders, Residuation, and First-Order Linear Logic", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We will investigate proof-theoretic and linguistic aspects of first-order\nlinear logic. We will show that adding partial order constraints in such a way\nthat each sequent defines a unique linear order on the antecedent formulas of a\nsequent allows us to define many useful logical operators. In addition, the\npartial order constraints improve the efficiency of proof search.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 13:06:21 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Moot", "Richard", ""]]}, {"id": "2008.06408", "submitter": "Juan Manuel Perez", "authors": "Juan Manuel P\\'erez, Aym\\'e Arango, Franco Luque", "title": "ANDES at SemEval-2020 Task 12: A jointly-trained BERT multilingual model\n  for offensive language detection", "comments": "Github repo: https://github.com/finiteautomata/offenseval2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our participation in SemEval-2020 Task 12: Multilingual\nOffensive Language Detection. We jointly-trained a single model by fine-tuning\nMultilingual BERT to tackle the task across all the proposed languages:\nEnglish, Danish, Turkish, Greek and Arabic. Our single model had competitive\nresults, with a performance close to top-performing systems in spite of sharing\nthe same parameters across all languages. Zero-shot and few-shot experiments\nwere also conducted to analyze the transference performance among these\nlanguages. We make our code public for further research\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 16:07:00 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["P\u00e9rez", "Juan Manuel", ""], ["Arango", "Aym\u00e9", ""], ["Luque", "Franco", ""]]}, {"id": "2008.06452", "submitter": "Fei Cheng", "authors": "Fei Cheng and Yusuke Miyao", "title": "Predicting Event Time by Classifying Sub-Level Temporal Relations\n  Induced from a Unified Representation of Time Anchors", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Extracting event time from news articles is a challenging but attractive\ntask. In contrast to the most existing pair-wised temporal link annotation,\nReimers et al.(2016) proposed to annotate the time anchor (a.k.a. the exact\ntime) of each event. Their work represents time anchors with discrete\nrepresentations of Single-Day/Multi-Day and Certain/Uncertain. This increases\nthe complexity of modeling the temporal relations between two time anchors,\nwhich cannot be categorized into the relations of Allen's interval algebra\n(Allen, 1990).\n  In this paper, we propose an effective method to decompose such complex\ntemporal relations into sub-level relations by introducing a unified quadruple\nrepresentation for both Single-Day/Multi-Day and Certain/Uncertain time\nanchors. The temporal relation classifiers are trained in a multi-label\nclassification manner. The system structure of our approach is much simpler\nthan the existing decision tree model (Reimers et al., 2018), which is composed\nby a dozen of node classifiers. Another contribution of this work is to\nconstruct a larger event time corpus (256 news documents) with a reasonable\nInter-Annotator Agreement (IAA), for the purpose of overcoming the data\nshortage of the existing event time corpus (36 news documents). The empirical\nresults show our approach outperforms the state-of-the-art decision tree model\nand the increase of data size obtained a significant improvement of\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 16:30:07 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Cheng", "Fei", ""], ["Miyao", "Yusuke", ""]]}, {"id": "2008.06460", "submitter": "Marzieh Mozafari", "authors": "Marzieh Mozafari, Reza Farahbakhsh, Noel Crespi", "title": "Hate Speech Detection and Racial Bias Mitigation in Social Media based\n  on BERT model", "comments": "This paper has been accepted in the PLOS ONE journal in August 2020", "journal-ref": null, "doi": "10.1371/journal.pone.0237861", "report-no": null, "categories": "cs.SI cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disparate biases associated with datasets and trained classifiers in hateful\nand abusive content identification tasks have raised many concerns recently.\nAlthough the problem of biased datasets on abusive language detection has been\naddressed more frequently, biases arising from trained classifiers have not yet\nbeen a matter of concern. Here, we first introduce a transfer learning approach\nfor hate speech detection based on an existing pre-trained language model\ncalled BERT and evaluate the proposed model on two publicly available datasets\nannotated for racism, sexism, hate or offensive content on Twitter. Next, we\nintroduce a bias alleviation mechanism in hate speech detection task to\nmitigate the effect of bias in training set during the fine-tuning of our\npre-trained BERT-based model. Toward that end, we use an existing\nregularization method to reweight input samples, thereby decreasing the effects\nof high correlated training set' s n-grams with class labels, and then\nfine-tune our pre-trained BERT-based model with the new re-weighted samples. To\nevaluate our bias alleviation mechanism, we employ a cross-domain approach in\nwhich we use the trained classifiers on the aforementioned datasets to predict\nthe labels of two new datasets from Twitter, AAE-aligned and White-aligned\ngroups, which indicate tweets written in African-American English (AAE) and\nStandard American English (SAE) respectively. The results show the existence of\nsystematic racial bias in trained classifiers as they tend to assign tweets\nwritten in AAE from AAE-aligned group to negative classes such as racism,\nsexism, hate, and offensive more often than tweets written in SAE from\nWhite-aligned. However, the racial bias in our classifiers reduces\nsignificantly after our bias alleviation mechanism is incorporated. This work\ncould institute the first step towards debiasing hate speech and abusive\nlanguage detection systems.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 16:47:25 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 10:06:40 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Mozafari", "Marzieh", ""], ["Farahbakhsh", "Reza", ""], ["Crespi", "Noel", ""]]}, {"id": "2008.06580", "submitter": "Pawel Swietojanski", "authors": "Peter Bell, Joachim Fainberg, Ondrej Klejch, Jinyu Li, Steve Renals,\n  Pawel Swietojanski", "title": "Adaptation Algorithms for Neural Network-Based Speech Recognition: An\n  Overview", "comments": "Total of 31 pages, 27 figures. Associated repository:\n  https://github.com/pswietojanski/ojsp_adaptation_review_2020", "journal-ref": "IEEE Open Journal of Signal Processing, vol. 2, pp. 33-66, 2021", "doi": "10.1109/OJSP.2020.3045349", "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a structured overview of adaptation algorithms for neural\nnetwork-based speech recognition, considering both hybrid hidden Markov model /\nneural network systems and end-to-end neural network systems, with a focus on\nspeaker adaptation, domain adaptation, and accent adaptation. The overview\ncharacterizes adaptation algorithms as based on embeddings, model parameter\nadaptation, or data augmentation. We present a meta-analysis of the performance\nof speech recognition adaptation algorithms, based on relative error rate\nreductions as reported in the literature.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 21:50:03 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 19:41:45 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Bell", "Peter", ""], ["Fainberg", "Joachim", ""], ["Klejch", "Ondrej", ""], ["Li", "Jinyu", ""], ["Renals", "Steve", ""], ["Swietojanski", "Pawel", ""]]}, {"id": "2008.06606", "submitter": "Mihir Khambete", "authors": "Mihir P. Khambete, William Su, Juan Garcia, Marcus A. Badgeley", "title": "Quantification of BERT Diagnosis Generalizability Across Medical\n  Specialties Using Semantic Dataset Distance", "comments": "20 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models in healthcare may fail to generalize on data from unseen\ncorpora. Additionally, no quantitative metric exists to tell how existing\nmodels will perform on new data. Previous studies demonstrated that NLP models\nof medical notes generalize variably between institutions, but ignored other\nlevels of healthcare organization. We measured SciBERT diagnosis sentiment\nclassifier generalizability between medical specialties using EHR sentences\nfrom MIMIC-III. Models trained on one specialty performed better on internal\ntest sets than mixed or external test sets (mean AUCs 0.92, 0.87, and 0.83,\nrespectively; p = 0.016). When models are trained on more specialties, they\nhave better test performances (p < 1e-4). Model performance on new corpora is\ndirectly correlated to the similarity between train and test sentence content\n(p < 1e-4). Future studies should assess additional axes of generalization to\nensure deep learning models fulfil their intended purpose across institutions,\nspecialties, and practices.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 23:44:11 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 04:51:57 GMT"}, {"version": "v3", "created": "Fri, 19 Feb 2021 06:58:18 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Khambete", "Mihir P.", ""], ["Su", "William", ""], ["Garcia", "Juan", ""], ["Badgeley", "Marcus A.", ""]]}, {"id": "2008.06682", "submitter": "Rivindu Weerasekera", "authors": "Shamane Siriwardhana, Andrew Reis, Rivindu Weerasekera, Suranga\n  Nanayakkara", "title": "Jointly Fine-Tuning \"BERT-like\" Self Supervised Models to Improve\n  Multimodal Speech Emotion Recognition", "comments": "Accepted to INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal emotion recognition from speech is an important area in affective\ncomputing. Fusing multiple data modalities and learning representations with\nlimited amounts of labeled data is a challenging task. In this paper, we\nexplore the use of modality-specific \"BERT-like\" pretrained Self Supervised\nLearning (SSL) architectures to represent both speech and text modalities for\nthe task of multimodal speech emotion recognition. By conducting experiments on\nthree publicly available datasets (IEMOCAP, CMU-MOSEI, and CMU-MOSI), we show\nthat jointly fine-tuning \"BERT-like\" SSL architectures achieve state-of-the-art\n(SOTA) results. We also evaluate two methods of fusing speech and text\nmodalities and show that a simple fusion mechanism can outperform more complex\nones when using SSL models that have similar architectural properties to BERT.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 08:54:48 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Siriwardhana", "Shamane", ""], ["Reis", "Andrew", ""], ["Weerasekera", "Rivindu", ""], ["Nanayakkara", "Suranga", ""]]}, {"id": "2008.06695", "submitter": "Han Liu", "authors": "Han Liu, Caixia Yuan, and Xiaojie Wang", "title": "Label-Wise Document Pre-Training for Multi-Label Text Classification", "comments": "Accepted to NLPCC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge of multi-label text classification (MLTC) is to\nstimulatingly exploit possible label differences and label correlations. In\nthis paper, we tackle this challenge by developing Label-Wise Pre-Training\n(LW-PT) method to get a document representation with label-aware information.\nThe basic idea is that, a multi-label document can be represented as a\ncombination of multiple label-wise representations, and that, correlated labels\nalways cooccur in the same or similar documents. LW-PT implements this idea by\nconstructing label-wise document classification tasks and trains label-wise\ndocument encoders. Finally, the pre-trained label-wise encoder is fine-tuned\nwith the downstream MLTC task. Extensive experimental results validate that the\nproposed method has significant advantages over the previous state-of-the-art\nmodels and is able to discover reasonable label relationship. The code is\nreleased to facilitate other researchers.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 10:34:27 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Liu", "Han", ""], ["Yuan", "Caixia", ""], ["Wang", "Xiaojie", ""]]}, {"id": "2008.06759", "submitter": "Xiaowei Liu", "authors": "Xiaowei Liu, Weiwei Guo, Huiji Gao, Bo Long", "title": "Deep Search Query Intent Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding a user's query intent behind a search is critical for modern\nsearch engine success. Accurate query intent prediction allows the search\nengine to better serve the user's need by rendering results from more relevant\ncategories. This paper aims to provide a comprehensive learning framework for\nmodeling query intent under different stages of a search. We focus on the\ndesign for 1) predicting users' intents as they type in queries on-the-fly in\ntypeahead search using character-level models; and 2) accurate word-level\nintent prediction models for complete queries. Various deep learning components\nfor query text understanding are experimented. Offline evaluation and online\nA/B test experiments show that the proposed methods are effective in\nunderstanding query intent and efficient to scale for online search systems.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 18:19:56 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 04:59:27 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Liu", "Xiaowei", ""], ["Guo", "Weiwei", ""], ["Gao", "Huiji", ""], ["Long", "Bo", ""]]}, {"id": "2008.06788", "submitter": "Goran Glava\\v{s}", "authors": "Goran Glava\\v{s} and Ivan Vuli\\'c", "title": "Is Supervised Syntactic Parsing Beneficial for Language Understanding?\n  An Empirical Investigation", "comments": "EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Traditional NLP has long held (supervised) syntactic parsing necessary for\nsuccessful higher-level semantic language understanding (LU). The recent advent\nof end-to-end neural models, self-supervised via language modeling (LM), and\ntheir success on a wide range of LU tasks, however, questions this belief. In\nthis work, we empirically investigate the usefulness of supervised parsing for\nsemantic LU in the context of LM-pretrained transformer networks. Relying on\nthe established fine-tuning paradigm, we first couple a pretrained transformer\nwith a biaffine parsing head, aiming to infuse explicit syntactic knowledge\nfrom Universal Dependencies treebanks into the transformer. We then fine-tune\nthe model for LU tasks and measure the effect of the intermediate parsing\ntraining (IPT) on downstream LU task performance. Results from both monolingual\nEnglish and zero-shot language transfer experiments (with intermediate\ntarget-language parsing) show that explicit formalized syntax, injected into\ntransformers through IPT, has very limited and inconsistent effect on\ndownstream LU performance. Our results, coupled with our analysis of\ntransformers' representation spaces before and after intermediate parsing, make\na significant step towards providing answers to an essential question: how\n(un)availing is supervised parsing for high-level semantic natural language\nunderstanding in the era of large neural models?\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 21:03:36 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 12:05:00 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Glava\u0161", "Goran", ""], ["Vuli\u0107", "Ivan", ""]]}, {"id": "2008.06854", "submitter": "Koteswar Rao Jerripothula", "authors": "Akansha Gautam, Koteswar Rao Jerripothula", "title": "SGG: Spinbot, Grammarly and GloVe based Fake News Detection", "comments": "9 pages, 7 figures, Accepted by IEEE International Conference on\n  Multimedia Big Data (BigMM), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, news consumption using online news portals has increased\nexponentially due to several reasons, such as low cost and easy accessibility.\nHowever, such online platforms inadvertently also become the cause of spreading\nfalse information across the web. They are being misused quite frequently as a\nmedium to disseminate misinformation and hoaxes. Such malpractices call for a\nrobust automatic fake news detection system that can keep us at bay from such\nmisinformation and hoaxes. We propose a robust yet simple fake news detection\nsystem, leveraging the tools for paraphrasing, grammar-checking, and\nword-embedding. In this paper, we try to the potential of these tools in\njointly unearthing the authenticity of a news article. Notably, we leverage\nSpinbot (for paraphrasing), Grammarly (for grammar-checking), and GloVe (for\nword-embedding) tools for this purpose. Using these tools, we were able to\nextract novel features that could yield state-of-the-art results on the Fake\nNews AMT dataset and comparable results on Celebrity datasets when combined\nwith some of the essential features. More importantly, the proposed method is\nfound to be more robust empirically than the existing ones, as revealed in our\ncross-domain analysis and multi-domain analysis.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 08:06:52 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Gautam", "Akansha", ""], ["Jerripothula", "Koteswar Rao", ""]]}, {"id": "2008.06860", "submitter": "Sachin Saxena", "authors": "Sachin Saxena", "title": "TextDecepter: Hard Label Black Box Attack on Text Classifiers", "comments": "10 pages, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has been proven to be susceptible to carefully crafted\nsamples, known as adversarial examples. The generation of these adversarial\nexamples helps to make the models more robust and gives us an insight into the\nunderlying decision-making of these models. Over the years, researchers have\nsuccessfully attacked image classifiers in both, white and black-box settings.\nHowever, these methods are not directly applicable to texts as text data is\ndiscrete. In recent years, research on crafting adversarial examples against\ntextual applications has been on the rise. In this paper, we present a novel\napproach for hard-label black-box attacks against Natural Language Processing\n(NLP) classifiers, where no model information is disclosed, and an attacker can\nonly query the model to get a final decision of the classifier, without\nconfidence scores of the classes involved. Such an attack scenario applies to\nreal-world black-box models being used for security-sensitive applications such\nas sentiment analysis and toxic content detection.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 08:57:01 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 00:06:56 GMT"}, {"version": "v3", "created": "Fri, 27 Nov 2020 02:27:55 GMT"}, {"version": "v4", "created": "Sat, 19 Dec 2020 23:01:13 GMT"}, {"version": "v5", "created": "Tue, 22 Dec 2020 03:21:17 GMT"}, {"version": "v6", "created": "Mon, 28 Dec 2020 00:23:08 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Saxena", "Sachin", ""]]}, {"id": "2008.06865", "submitter": "Tafseer Ahmed", "authors": "Tafseer Ahmed, Muhammad Suffian Nizami, Muhammad Yaseen Khan", "title": "Discovering Lexical Similarity Through Articulatory Feature-based\n  Phonetic Edit Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexical Similarity (LS) between two languages uncovers many interesting\nlinguistic insights such as genetic relationship, mutual intelligibility, and\nthe usage of one's vocabulary into other. There are various methods through\nwhich LS is evaluated. In the same regard, this paper presents a method of\nPhonetic Edit Distance (PED) that uses a soft comparison of letters using the\narticulatory features associated with them. The system converts the words into\nthe corresponding International Phonetic Alphabet (IPA), followed by the\nconversion of IPA into its set of articulatory features. Later, the lists of\nthe set of articulatory features are compared using the proposed method. As an\nexample, PED gives edit distance of German word vater and Persian word pidar as\n0.82; and similarly, Hebrew word shalom and Arabic word salaam as 0.93, whereas\nfor a juxtapose comparison, their IPA based edit distances are 4 and 2\nrespectively. Experiments are performed with six languages (Arabic, Hindi,\nMarathi, Persian, Sanskrit, and Urdu). In this regard, we extracted part of\nspeech wise word-lists from the Universal Dependency corpora and evaluated the\nLS for every pair of language. Thus, with the proposed approach, we find the\ngenetic affinity, similarity, and borrowing/loan-words despite having script\ndifferences and sound variation phenomena among these languages.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 09:28:37 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Ahmed", "Tafseer", ""], ["Nizami", "Muhammad Suffian", ""], ["Khan", "Muhammad Yaseen", ""]]}, {"id": "2008.06867", "submitter": "Hyun-Wook Yoon", "authors": "Hyun-Wook Yoon, Sang-Hoon Lee, Hyeong-Rae Noh, Seong-Whan Lee", "title": "Audio Dequantization for High Fidelity Audio Generation in Flow-based\n  Neural Vocoder", "comments": "Accepted in INTERSPEECH2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent works, a flow-based neural vocoder has shown significant\nimprovement in real-time speech generation task. The sequence of invertible\nflow operations allows the model to convert samples from simple distribution to\naudio samples. However, training a continuous density model on discrete audio\ndata can degrade model performance due to the topological difference between\nlatent and actual distribution. To resolve this problem, we propose audio\ndequantization methods in flow-based neural vocoder for high fidelity audio\ngeneration. Data dequantization is a well-known method in image generation but\nhas not yet been studied in the audio domain. For this reason, we implement\nvarious audio dequantization methods in flow-based neural vocoder and\ninvestigate the effect on the generated audio. We conduct various objective\nperformance assessments and subjective evaluation to show that audio\ndequantization can improve audio generation quality. From our experiments,\nusing audio dequantization produces waveform audio with better harmonic\nstructure and fewer digital artifacts.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 09:37:18 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Yoon", "Hyun-Wook", ""], ["Lee", "Sang-Hoon", ""], ["Noh", "Hyeong-Rae", ""], ["Lee", "Seong-Whan", ""]]}, {"id": "2008.06877", "submitter": "Meysam Asgari-Chenaghlu", "authors": "Meysam Asgari-Chenaghlu, Mohammad-Reza Feizi-Derakhshi, Leili\n  farzinvash, Mohammad-Ali Balafar, Cina Motamed", "title": "TopicBERT: A Transformer transfer learning based memory-graph approach\n  for multimodal streaming social media topic detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real time nature of social networks with bursty short messages and their\nrespective large data scale spread among vast variety of topics are research\ninterest of many researchers. These properties of social networks which are\nknown as 5'Vs of big data has led to many unique and enlightenment algorithms\nand techniques applied to large social networking datasets and data streams.\nMany of these researches are based on detection and tracking of hot topics and\ntrending social media events that help revealing many unanswered questions.\nThese algorithms and in some cases software products mostly rely on the nature\nof the language itself. Although, other techniques such as unsupervised data\nmining methods are language independent but many requirements for a\ncomprehensive solution are not met. Many research issues such as noisy\nsentences that adverse grammar and new online user invented words are\nchallenging maintenance of a good social network topic detection and tracking\nmethodology; The semantic relationship between words and in most cases,\nsynonyms are also ignored by many of these researches. In this research, we use\nTransformers combined with an incremental community detection algorithm.\nTransformer in one hand, provides the semantic relation between words in\ndifferent contexts. On the other hand, the proposed graph mining technique\nenhances the resulting topics with aid of simple structural rules. Named entity\nrecognition from multimodal data, image and text, labels the named entities\nwith entity type and the extracted topics are tuned using them. All operations\nof proposed system has been applied with big social data perspective under\nNoSQL technologies. In order to present a working and systematic solution, we\ncombined MongoDB with Neo4j as two major database systems of our work. The\nproposed system shows higher precision and recall compared to other methods in\nthree different datasets.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 10:39:50 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Asgari-Chenaghlu", "Meysam", ""], ["Feizi-Derakhshi", "Mohammad-Reza", ""], ["farzinvash", "Leili", ""], ["Balafar", "Mohammad-Ali", ""], ["Motamed", "Cina", ""]]}, {"id": "2008.06884", "submitter": "Shengyu Zhang", "authors": "Shengyu Zhang, Tan Jiang, Tan Wang, Kun Kuang, Zhou Zhao, Jianke Zhu,\n  Jin Yu, Hongxia Yang, Fei Wu", "title": "DeVLBert: Learning Deconfounded Visio-Linguistic Representations", "comments": "10 pages, 4 figures, to appear in ACM MM 2020 proceedings", "journal-ref": null, "doi": "10.1145/3394171.3413518", "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose to investigate the problem of out-of-domain\nvisio-linguistic pretraining, where the pretraining data distribution differs\nfrom that of downstream data on which the pretrained model will be fine-tuned.\nExisting methods for this problem are purely likelihood-based, leading to the\nspurious correlations and hurt the generalization ability when transferred to\nout-of-domain downstream tasks. By spurious correlation, we mean that the\nconditional probability of one token (object or word) given another one can be\nhigh (due to the dataset biases) without robust (causal) relationships between\nthem. To mitigate such dataset biases, we propose a Deconfounded\nVisio-Linguistic Bert framework, abbreviated as DeVLBert, to perform\nintervention-based learning. We borrow the idea of the backdoor adjustment from\nthe research field of causality and propose several neural-network based\narchitectures for Bert-style out-of-domain pretraining. The quantitative\nresults on three downstream tasks, Image Retrieval (IR), Zero-shot IR, and\nVisual Question Answering, show the effectiveness of DeVLBert by boosting\ngeneralization ability.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 11:09:22 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 12:00:56 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Zhang", "Shengyu", ""], ["Jiang", "Tan", ""], ["Wang", "Tan", ""], ["Kuang", "Kun", ""], ["Zhao", "Zhou", ""], ["Zhu", "Jianke", ""], ["Yu", "Jin", ""], ["Yang", "Hongxia", ""], ["Wu", "Fei", ""]]}, {"id": "2008.06914", "submitter": "Libo Qin", "authors": "Libo Qin, Wanxiang Che, Yangming Li, Minheng Ni, Ting Liu", "title": "DCR-Net: A Deep Co-Interactive Relation Network for Joint Dialog Act\n  Recognition and Sentiment Classification", "comments": "Accepted by AAAI2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In dialog system, dialog act recognition and sentiment classification are two\ncorrelative tasks to capture speakers intentions, where dialog act and\nsentiment can indicate the explicit and the implicit intentions separately.\nMost of the existing systems either treat them as separate tasks or just\njointly model the two tasks by sharing parameters in an implicit way without\nexplicitly modeling mutual interaction and relation. To address this problem,\nwe propose a Deep Co-Interactive Relation Network (DCR-Net) to explicitly\nconsider the cross-impact and model the interaction between the two tasks by\nintroducing a co-interactive relation layer. In addition, the proposed relation\nlayer can be stacked to gradually capture mutual knowledge with multiple steps\nof interaction. Especially, we thoroughly study different relation layers and\ntheir effects. Experimental results on two public datasets (Mastodon and\nDailydialog) show that our model outperforms the state-of-the-art joint model\nby 4.3% and 3.4% in terms of F1 score on dialog act recognition task, 5.7% and\n12.4% on sentiment classification respectively. Comprehensive analysis\nempirically verifies the effectiveness of explicitly modeling the relation\nbetween the two tasks and the multi-steps interaction mechanism. Finally, we\nemploy the Bidirectional Encoder Representation from Transformer (BERT) in our\nframework, which can further boost our performance in both tasks.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 14:13:32 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Qin", "Libo", ""], ["Che", "Wanxiang", ""], ["Li", "Yangming", ""], ["Ni", "Minheng", ""], ["Liu", "Ting", ""]]}, {"id": "2008.06974", "submitter": "Mona Jalal", "authors": "Alyssa Smith, David Assefa Tofu, Mona Jalal, Edward Edberg Halim,\n  Yimeng Sun, Vidya Akavoor, Margrit Betke, Prakash Ishwar, Lei Guo, Derry\n  Wijaya", "title": "OpenFraming: We brought the ML; you bring the data. Interact with your\n  data and discover its frames", "comments": "8 pages, 8 figures, EMNLP 2020 demonstration papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When journalists cover a news story, they can cover the story from multiple\nangles or perspectives. A news article written about COVID-19 for example,\nmight focus on personal preventative actions such as mask-wearing, while\nanother might focus on COVID-19's impact on the economy. These perspectives are\ncalled \"frames,\" which when used may influence public perception and opinion of\nthe issue. We introduce a Web-based system for analyzing and classifying frames\nin text documents. Our goal is to make effective tools for automatic frame\ndiscovery and labeling based on topic modeling and deep learning widely\naccessible to researchers from a diverse array of disciplines. To this end, we\nprovide both state-of-the-art pre-trained frame classification models on\nvarious issues as well as a user-friendly pipeline for training novel\nclassification models on user-provided corpora. Researchers can submit their\ndocuments and obtain frames of the documents. The degree of user involvement is\nflexible: they can run models that have been pre-trained on select issues;\nsubmit labeled documents and train a new model for frame classification; or\nsubmit unlabeled documents and obtain potential frames of the documents. The\ncode making up our system is also open-sourced and well-documented, making the\nsystem transparent and expandable. The system is available on-line at\nhttp://www.openframing.org and via our GitHub page\nhttps://github.com/davidatbu/openFraming .\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 18:59:30 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Smith", "Alyssa", ""], ["Tofu", "David Assefa", ""], ["Jalal", "Mona", ""], ["Halim", "Edward Edberg", ""], ["Sun", "Yimeng", ""], ["Akavoor", "Vidya", ""], ["Betke", "Margrit", ""], ["Ishwar", "Prakash", ""], ["Guo", "Lei", ""], ["Wijaya", "Derry", ""]]}, {"id": "2008.06995", "submitter": "Yaqing Wang", "authors": "Yaqing Wang, Fenglong Ma, Jing Gao", "title": "Efficient Knowledge Graph Validation via Cross-Graph Representation\n  Learning", "comments": "CIKM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in information extraction have motivated the automatic\nconstruction of huge Knowledge Graphs (KGs) by mining from large-scale text\ncorpus. However, noisy facts are unavoidably introduced into KGs that could be\ncaused by automatic extraction. To validate the correctness of facts (i.e.,\ntriplets) inside a KG, one possible approach is to map the triplets into vector\nrepresentations by capturing the semantic meanings of facts. Although many\nrepresentation learning approaches have been developed for knowledge graphs,\nthese methods are not effective for validation. They usually assume that facts\nare correct, and thus may overfit noisy facts and fail to detect such facts.\nTowards effective KG validation, we propose to leverage an external\nhuman-curated KG as auxiliary information source to help detect the errors in a\ntarget KG. The external KG is built upon human-curated knowledge repositories\nand tends to have high precision. On the other hand, although the target KG\nbuilt by information extraction from texts has low precision, it can cover new\nor domain-specific facts that are not in any human-curated repositories. To\ntackle this challenging task, we propose a cross-graph representation learning\nframework, i.e., CrossVal, which can leverage an external KG to validate the\nfacts in the target KG efficiently. This is achieved by embedding triplets\nbased on their semantic meanings, drawing cross-KG negative samples and\nestimating a confidence score for each triplet based on its degree of\ncorrectness. We evaluate the proposed framework on datasets across different\ndomains. Experimental results show that the proposed framework achieves the\nbest performance compared with the state-of-the-art methods on large-scale KGs.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 20:51:17 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wang", "Yaqing", ""], ["Ma", "Fenglong", ""], ["Gao", "Jing", ""]]}, {"id": "2008.06996", "submitter": "Dmitry Krotov", "authors": "Dmitry Krotov, John Hopfield", "title": "Large Associative Memory Problem in Neurobiology and Machine Learning", "comments": "Accepted for publication at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dense Associative Memories or modern Hopfield networks permit storage and\nreliable retrieval of an exponentially large (in the dimension of feature\nspace) number of memories. At the same time, their naive implementation is\nnon-biological, since it seemingly requires the existence of many-body synaptic\njunctions between the neurons. We show that these models are effective\ndescriptions of a more microscopic (written in terms of biological degrees of\nfreedom) theory that has additional (hidden) neurons and only requires two-body\ninteractions between them. For this reason our proposed microscopic theory is a\nvalid model of large associative memory with a degree of biological\nplausibility. The dynamics of our network and its reduced dimensional\nequivalent both minimize energy (Lyapunov) functions. When certain dynamical\nvariables (hidden neurons) are integrated out from our microscopic theory, one\ncan recover many of the models that were previously discussed in the\nliterature, e.g. the model presented in \"Hopfield Networks is All You Need\"\npaper. We also provide an alternative derivation of the energy function and the\nupdate rule proposed in the aforementioned paper and clarify the relationships\nbetween various models of this class.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 21:03:52 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 20:06:50 GMT"}, {"version": "v3", "created": "Tue, 27 Apr 2021 22:20:05 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Krotov", "Dmitry", ""], ["Hopfield", "John", ""]]}, {"id": "2008.07027", "submitter": "Davis Yoshida", "authors": "Davis Yoshida, Allyson Ettinger, Kevin Gimpel", "title": "Adding Recurrence to Pretrained Transformers for Improved Efficiency and\n  Context Size", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning a pretrained transformer for a downstream task has become a\nstandard method in NLP in the last few years. While the results from these\nmodels are impressive, applying them can be extremely computationally\nexpensive, as is pretraining new models with the latest architectures. We\npresent a novel method for applying pretrained transformer language models\nwhich lowers their memory requirement both at training and inference time. An\nadditional benefit is that our method removes the fixed context size constraint\nthat most transformer models have, allowing for more flexible use. When applied\nto the GPT-2 language model, we find that our method attains better perplexity\nthan an unmodified GPT-2 model on the PG-19 and WikiText-103 corpora, for a\ngiven amount of computation or memory.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 23:19:30 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Yoshida", "Davis", ""], ["Ettinger", "Allyson", ""], ["Gimpel", "Kevin", ""]]}, {"id": "2008.07118", "submitter": "Ziyu Wang", "authors": "Ziyu Wang, Yiyi Zhang, Yixiao Zhang, Junyan Jiang, Ruihan Yang, Junbo\n  Zhao (Jake), Gus Xia", "title": "PIANOTREE VAE: Structured Representation Learning for Polyphonic Music", "comments": null, "journal-ref": "In Proceedings of 21st International Conference on Music\n  Information Retrieval (ISMIR), Montreal, Canada (virtual conference), 2020", "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dominant approach for music representation learning involves the deep\nunsupervised model family variational autoencoder (VAE). However, most, if not\nall, viable attempts on this problem have largely been limited to monophonic\nmusic. Normally composed of richer modality and more complex musical\nstructures, the polyphonic counterpart has yet to be addressed in the context\nof music representation learning. In this work, we propose the PianoTree VAE, a\nnovel tree-structure extension upon VAE aiming to fit the polyphonic music\nlearning. The experiments prove the validity of the PianoTree VAE via\n(i)-semantically meaningful latent code for polyphonic segments; (ii)-more\nsatisfiable reconstruction aside of decent geometry learned in the latent\nspace; (iii)-this model's benefits to the variety of the downstream music\ngeneration.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 06:48:59 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wang", "Ziyu", "", "Jake"], ["Zhang", "Yiyi", "", "Jake"], ["Zhang", "Yixiao", "", "Jake"], ["Jiang", "Junyan", "", "Jake"], ["Yang", "Ruihan", "", "Jake"], ["Zhao", "Junbo", "", "Jake"], ["Xia", "Gus", ""]]}, {"id": "2008.07122", "submitter": "Ziyu Wang", "authors": "Ziyu Wang, Dingsu Wang, Yixiao Zhang, Gus Xia", "title": "Learning Interpretable Representation for Controllable Polyphonic Music\n  Generation", "comments": null, "journal-ref": "In Proceedings of 21st International Conference on Music\n  Information Retrieval (ISMIR), Montreal, Canada, 2020", "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep generative models have become the leading methods for algorithmic\ncomposition, it remains a challenging problem to control the generation process\nbecause the latent variables of most deep-learning models lack good\ninterpretability. Inspired by the content-style disentanglement idea, we design\na novel architecture, under the VAE framework, that effectively learns two\ninterpretable latent factors of polyphonic music: chord and texture. The\ncurrent model focuses on learning 8-beat long piano composition segments. We\nshow that such chord-texture disentanglement provides a controllable generation\npathway leading to a wide spectrum of applications, including compositional\nstyle transfer, texture variation, and accompaniment arrangement. Both\nobjective and subjective evaluations show that our method achieves a successful\ndisentanglement and high quality controlled music generation.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 07:11:16 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wang", "Ziyu", ""], ["Wang", "Dingsu", ""], ["Zhang", "Yixiao", ""], ["Xia", "Gus", ""]]}, {"id": "2008.07138", "submitter": "Richard Moot", "authors": "Davide Catta (TEXTE), Richard Moot (TEXTE, LIRMM, CNRS), Christian\n  Retor\\'e (LaBRI)", "title": "Logical Semantics, Dialogical Argumentation, and Textual Entailment", "comments": "Natural Language Processing in Artificial Intelligence, In press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter, we introduce a new dialogical system for first order\nclassical logic which is close to natural language argumentation, and we prove\nits completeness with respect to usual classical validity. We combine our\ndialogical system with the Grail syntactic and semantic parser developed by the\nsecond author in order to address automated textual entailment, that is, we use\nit for deciding whether or not a sentence is a consequence of a short text.\nThis work-which connects natural language semantics and argumentation with\ndialogical logic-can be viewed as a step towards an inferentialist view of\nnatural language semantics.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 08:04:11 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Catta", "Davide", "", "TEXTE"], ["Moot", "Richard", "", "TEXTE, LIRMM, CNRS"], ["Retor\u00e9", "Christian", "", "LaBRI"]]}, {"id": "2008.07189", "submitter": "Maria Biryukov", "authors": "Maria Biryukov", "title": "Comparison of Syntactic Parsers on Biomedical Texts", "comments": "Most of this work was done in 2018 when the author was primarily\n  affiliated with LCSB, Bioinformatic Core", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syntactic parsing is an important step in the automated text analysis which\naims at information extraction. Quality of the syntactic parsing determines to\na large extent the recall and precision of the text mining results. In this\npaper we evaluate the performance of several popular syntactic parsers in\napplication to the biomedical text mining.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 10:07:23 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Biryukov", "Maria", ""]]}, {"id": "2008.07259", "submitter": "Josef Jon", "authors": "Josef Jon, Martin Faj\\v{c}\\'ik, Martin Do\\v{c}ekal, Pavel Smr\\v{z}", "title": "BUT-FIT at SemEval-2020 Task 4: Multilingual commonsense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes work of the BUT-FIT's team at SemEval 2020 Task 4 -\nCommonsense Validation and Explanation. We participated in all three subtasks.\nIn subtasks A and B, our submissions are based on pretrained language\nrepresentation models (namely ALBERT) and data augmentation. We experimented\nwith solving the task for another language, Czech, by means of multilingual\nmodels and machine translated dataset, or translated model inputs. We show that\nwith a strong machine translation system, our system can be used in another\nlanguage with a small accuracy loss. In subtask C, our submission, which is\nbased on pretrained sequence-to-sequence model (BART), ranked 1st in BLEU score\nranking, however, we show that the correlation between BLEU and human\nevaluation, in which our submission ended up 4th, is low. We analyse the\nmetrics used in the evaluation and we propose an additional score based on\nmodel from subtask B, which correlates well with our manual ranking, as well as\nreranking method based on the same principle. We performed an error and dataset\nanalysis for all subtasks and we present our findings.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 12:45:39 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 09:15:32 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Jon", "Josef", ""], ["Faj\u010d\u00edk", "Martin", ""], ["Do\u010dekal", "Martin", ""], ["Smr\u017e", "Pavel", ""]]}, {"id": "2008.07267", "submitter": "Christopher Schr\\\"oder", "authors": "Christopher Schr\\\"oder and Andreas Niekler", "title": "A Survey of Active Learning for Text Classification using Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Natural language processing (NLP) and neural networks (NNs) have both\nundergone significant changes in recent years. For active learning (AL)\npurposes, NNs are, however, less commonly used -- despite their current\npopularity. By using the superior text classification performance of NNs for\nAL, we can either increase a model's performance using the same amount of data\nor reduce the data and therefore the required annotation efforts while keeping\nthe same performance. We review AL for text classification using deep neural\nnetworks (DNNs) and elaborate on two main causes which used to hinder the\nadoption: (a) the inability of NNs to provide reliable uncertainty estimates,\non which the most commonly used query strategies rely, and (b) the challenge of\ntraining DNNs on small data. To investigate the former, we construct a taxonomy\nof query strategies, which distinguishes between data-based, model-based, and\nprediction-based instance selection, and investigate the prevalence of these\nclasses in recent research. Moreover, we review recent NN-based advances in NLP\nlike word embeddings or language models in the context of (D)NNs, survey the\ncurrent state-of-the-art at the intersection of AL, text classification, and\nDNNs and relate recent advances in NLP to AL. Finally, we analyze recent work\nin AL for text classification, connect the respective query strategies to the\ntaxonomy, and outline commonalities and shortcomings. As a result, we highlight\ngaps in current research and present open research questions.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 12:53:20 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Schr\u00f6der", "Christopher", ""], ["Niekler", "Andreas", ""]]}, {"id": "2008.07291", "submitter": "Michael Sejr Schlichtkrull", "authors": "Michael Sejr Schlichtkrull, Weiwei Cheng", "title": "Evaluating for Diversity in Question Generation over Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating diverse and relevant questions over text is a task with widespread\napplications. We argue that commonly-used evaluation metrics such as BLEU and\nMETEOR are not suitable for this task due to the inherent diversity of\nreference questions, and propose a scheme for extending conventional metrics to\nreflect diversity. We furthermore propose a variational encoder-decoder model\nfor this task. We show through automatic and human evaluation that our\nvariational model improves diversity without loss of quality, and demonstrate\nhow our evaluation scheme reflects this improvement.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 13:16:12 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Schlichtkrull", "Michael Sejr", ""], ["Cheng", "Weiwei", ""]]}, {"id": "2008.07302", "submitter": "Chris C. Emezue", "authors": "Chris C. Emezue and Bonaventure F.P. Dossou", "title": "Lanfrica: A Participatory Approach to Documenting Machine Translation\n  Research on African Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the years, there have been campaigns to include the African languages in\nthe growing research on machine translation (MT) in particular, and natural\nlanguage processing (NLP) in general. Africa has the highest language\ndiversity, with 1500-2000 documented languages and many more undocumented or\nextinct languages(Lewis, 2009; Bendor-Samuel, 2017). This makes it hard to keep\ntrack of the MT research, models and dataset that have been developed for some\nof them. As the internet and social media make up the daily lives of more than\nhalf of the world(Lin, 2020), as well as over 40% of Africans(Campbell, 2019),\nonline platforms can be useful in creating accessibility to researches,\nbenchmarks and datasets in these African languages, thereby improving\nreproducibility and sharing of existing research and their results. In this\npaper, we introduce Lanfrica, a novel, on-going framework that employs a\nparticipatory approach to documenting researches, projects, benchmarks and\ndataset on African languages.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 18:14:04 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Emezue", "Chris C.", ""], ["Dossou", "Bonaventure F. P.", ""]]}, {"id": "2008.07347", "submitter": "Leon Weber", "authors": "Leon Weber, Mario S\\\"anger, Jannes M\\\"unchmeyer, Maryam Habibi, Ulf\n  Leser, Alan Akbik", "title": "HunFlair: An Easy-to-Use Tool for State-of-the-Art Biomedical Named\n  Entity Recognition", "comments": "- Corrected author list - Updated project link", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Summary: Named Entity Recognition (NER) is an important step in biomedical\ninformation extraction pipelines. Tools for NER should be easy to use, cover\nmultiple entity types, highly accurate, and robust towards variations in text\ngenre and style. To this end, we propose HunFlair, an NER tagger covering\nmultiple entity types integrated into the widely used NLP framework Flair.\nHunFlair outperforms other state-of-the-art standalone NER tools with an\naverage gain of 7.26 pp over the next best tool, can be installed with a single\ncommand and is applied with only four lines of code. Availability: HunFlair is\nfreely available through the Flair framework under an MIT license:\nhttps://github.com/flairNLP/flair and is compatible with all major operating\nsystems. Contact:{weberple,saengema,alan.akbik}@informatik.hu-berlin.de\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 14:16:15 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 09:02:27 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Weber", "Leon", ""], ["S\u00e4nger", "Mario", ""], ["M\u00fcnchmeyer", "Jannes", ""], ["Habibi", "Maryam", ""], ["Leser", "Ulf", ""], ["Akbik", "Alan", ""]]}, {"id": "2008.07466", "submitter": "Su Wang", "authors": "Su Wang, Greg Durrett, Katrin Erk", "title": "Narrative Interpolation for Generating and Understanding Stories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for controlled narrative/story generation where we are\nable to guide the model to produce coherent narratives with user-specified\ntarget endings by interpolation: for example, we are told that Jim went hiking\nand at the end Jim needed to be rescued, and we want the model to incrementally\ngenerate steps along the way. The core of our method is an interpolation model\nbased on GPT-2 which conditions on a previous sentence and a next sentence in a\nnarrative and fills in the gap. Additionally, a reranker helps control for\ncoherence of the generated text. With human evaluation, we show that\nending-guided generation results in narratives which are coherent, faithful to\nthe given ending guide, and require less manual effort on the part of the human\nguide writer than past approaches.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 16:45:50 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wang", "Su", ""], ["Durrett", "Greg", ""], ["Erk", "Katrin", ""]]}, {"id": "2008.07467", "submitter": "Shaunak Mishra", "authors": "Shaunak Mishra, Manisha Verma, Yichao Zhou, Kapil Thadani, Wei Wang", "title": "Learning to Create Better Ads: Generation and Ranking Approaches for Ad\n  Creative Refinement", "comments": "9 pages, accepted for publication in CIKM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the online advertising industry, the process of designing an ad creative\n(i.e., ad text and image) requires manual labor. Typically, each advertiser\nlaunches multiple creatives via online A/B tests to infer effective creatives\nfor the target audience, that are then refined further in an iterative fashion.\nDue to the manual nature of this process, it is time-consuming to learn,\nrefine, and deploy the modified creatives. Since major ad platforms typically\nrun A/B tests for multiple advertisers in parallel, we explore the possibility\nof collaboratively learning ad creative refinement via A/B tests of multiple\nadvertisers. In particular, given an input ad creative, we study approaches to\nrefine the given ad text and image by: (i) generating new ad text, (ii)\nrecommending keyphrases for new ad text, and (iii) recommending image tags\n(objects in image) to select new ad image. Based on A/B tests conducted by\nmultiple advertisers, we form pairwise examples of inferior and superior ad\ncreatives, and use such pairs to train models for the above tasks. For\ngenerating new ad text, we demonstrate the efficacy of an encoder-decoder\narchitecture with copy mechanism, which allows some words from the (inferior)\ninput text to be copied to the output while incorporating new words associated\nwith higher click-through-rate. For the keyphrase and image tag recommendation\ntask, we demonstrate the efficacy of a deep relevance matching model, as well\nas the relative robustness of ranking approaches compared to ad text generation\nin cold-start scenarios with unseen advertisers. We also share broadly\napplicable insights from our experiments using data from the Yahoo Gemini ad\nplatform.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 16:46:28 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 00:16:11 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Mishra", "Shaunak", ""], ["Verma", "Manisha", ""], ["Zhou", "Yichao", ""], ["Thadani", "Kapil", ""], ["Wang", "Wei", ""]]}, {"id": "2008.07481", "submitter": "Aniruddha Uttam Tammewar", "authors": "Aniruddha Tammewar, Alessandra Cervone, Giuseppe Riccardi", "title": "Emotion Carrier Recognition from Personal Narratives", "comments": "To be published at INTERSPEECH 2021, Brno, Czechia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personal Narratives (PN) - recollections of facts, events, and thoughts from\none's own experience - are often used in everyday conversations. So far, PNs\nhave mainly been explored for tasks such as valence prediction or emotion\nclassification (e.g. happy, sad). However, these tasks might overlook more\nfine-grained information that could prove to be relevant for understanding PNs.\nIn this work, we propose a novel task for Narrative Understanding: Emotion\nCarrier Recognition (ECR). Emotion carriers, the text fragments that carry the\nemotions of the narrator (e.g. loss of a grandpa, high school reunion), provide\na fine-grained description of the emotion state. We explore the task of ECR in\na corpus of PNs manually annotated with emotion carriers and investigate\ndifferent machine learning models for the task. We propose evaluation\nstrategies for ECR including metrics that can be appropriate for different\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 17:16:08 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 15:24:53 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Tammewar", "Aniruddha", ""], ["Cervone", "Alessandra", ""], ["Riccardi", "Giuseppe", ""]]}, {"id": "2008.07520", "submitter": "Anastassia Loukina", "authors": "Anastassia Loukina, Keelan Evanini, Matthew Mulholland, Ian Blood, and\n  Klaus Zechner", "title": "Do face masks introduce bias in speech technologies? The case of\n  automated scoring of speaking proficiency", "comments": null, "journal-ref": "Proceedings of Interspeech 2020, 1942-1946", "doi": "10.21437/Interspeech.2020-1264", "report-no": null, "categories": "eess.AS cs.CL cs.HC cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic has led to a dramatic increase in the use of face masks\nworldwide. Face coverings can affect both acoustic properties of the signal as\nwell as speech patterns and have unintended effects if the person wearing the\nmask attempts to use speech processing technologies. In this paper we explore\nthe impact of wearing face masks on the automated assessment of English\nlanguage proficiency. We use a dataset from a large-scale speaking test for\nwhich test-takers were required to wear face masks during the test\nadministration, and we compare it to a matched control sample of test-takers\nwho took the same test before the mask requirements were put in place. We find\nthat the two samples differ across a range of acoustic measures and also show a\nsmall but significant difference in speech patterns. However, these differences\ndo not lead to differences in human or automated scores of English language\nproficiency. Several measures of bias showed no differences in scores between\nthe two groups.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 17:58:29 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 16:10:15 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Loukina", "Anastassia", ""], ["Evanini", "Keelan", ""], ["Mulholland", "Matthew", ""], ["Blood", "Ian", ""], ["Zechner", "Klaus", ""]]}, {"id": "2008.07559", "submitter": "Kaustubh Dhole", "authors": "Kaustubh D. Dhole", "title": "Resolving Intent Ambiguities by Retrieving Discriminative Clarifying\n  Questions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task oriented Dialogue Systems generally employ intent detection systems in\norder to map user queries to a set of pre-defined intents. However, user\nqueries appearing in natural language can be easily ambiguous and hence such a\ndirect mapping might not be straightforward harming intent detection and\neventually the overall performance of a dialogue system. Moreover, acquiring\ndomain-specific clarification questions is costly. In order to disambiguate\nqueries which are ambiguous between two intents, we propose a novel method of\ngenerating discriminative questions using a simple rule based system which can\ntake advantage of any question generation system without requiring annotated\ndata of clarification questions. Our approach aims at discrimination between\ntwo intents but can be easily extended to clarification over multiple intents.\nSeeking clarification from the user to classify user intents not only helps\nunderstand the user intent effectively, but also reduces the roboticity of the\nconversation and makes the interaction considerably natural.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 18:11:13 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Dhole", "Kaustubh D.", ""]]}, {"id": "2008.07605", "submitter": "Yue Zhou", "authors": "Yue Zhou, Kerstin Voigt", "title": "Stock Index Prediction with Multi-task Learning and Word Polarity Over\n  Time", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment-based stock prediction systems aim to explore sentiment or event\nsignals from online corpora and attempt to relate the signals to stock price\nvariations. Both the feature-based and neural-networks-based approaches have\ndelivered promising results. However, the frequently minor fluctuations of the\nstock prices restrict learning the sentiment of text from price patterns, and\nlearning market sentiment from text can be biased if the text is irrelevant to\nthe underlying market. In addition, when using discrete word features, the\npolarity of a certain term can change over time according to different events.\nTo address these issues, we propose a two-stage system that consists of a\nsentiment extractor to extract the opinion on the market trend and a summarizer\nthat predicts the direction of the index movement of following week given the\nopinions of the news over the current week. We adopt BERT with multitask\nlearning which additionally predicts the worthiness of the news and propose a\nmetric called Polarity-Over-Time to extract the word polarity among different\nevent periods. A Weekly-Monday prediction framework and a new dataset, the\n10-year Reuters financial news dataset, are also proposed.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 20:22:56 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Zhou", "Yue", ""], ["Voigt", "Kerstin", ""]]}, {"id": "2008.07643", "submitter": "Fajrian Yunus", "authors": "Fajrian Yunus, Chlo\\'e Clavel, Catherine Pelachaud", "title": "Sequence-to-Sequence Predictive Model: From Prosody To Communicative\n  Gestures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.CV cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communicative gestures and speech acoustic are tightly linked. Our objective\nis to predict the timing of gestures according to the acoustic. That is, we\nwant to predict when a certain gesture occurs. We develop a model based on a\nrecurrent neural network with attention mechanism. The model is trained on a\ncorpus of natural dyadic interaction where the speech acoustic and the gesture\nphases and types have been annotated. The input of the model is a sequence of\nspeech acoustic and the output is a sequence of gesture classes. The classes we\nare using for the model output is based on a combination of gesture phases and\ngesture types. We use a sequence comparison technique to evaluate the model\nperformance. We find that the model can predict better certain gesture classes\nthan others. We also perform ablation studies which reveal that fundamental\nfrequency is a relevant feature for gesture prediction task. In another\nsub-experiment, we find that including eyebrow movements as acting as beat\ngesture improves the performance. Besides, we also find that a model trained on\nthe data of one given speaker also works for the other speaker of the same\nconversation. We also perform a subjective experiment to measure how\nrespondents judge the naturalness, the time consistency, and the semantic\nconsistency of the generated gesture timing of a virtual agent. Our respondents\nrate the output of our model favorably.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 21:55:22 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 21:03:40 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Yunus", "Fajrian", ""], ["Clavel", "Chlo\u00e9", ""], ["Pelachaud", "Catherine", ""]]}, {"id": "2008.07683", "submitter": "Karthik Gopalakrishnan", "authors": "Karthik Gopalakrishnan, Behnam Hedayatnia, Longshaokan Wang, Yang Liu,\n  Dilek Hakkani-Tur", "title": "Are Neural Open-Domain Dialog Systems Robust to Speech Recognition\n  Errors in the Dialog History? An Empirical Study", "comments": "Accepted at INTERSPEECH 2020. For dataset, see\n  https://github.com/alexa/Topical-Chat/tree/master/TopicalChatASR/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large end-to-end neural open-domain chatbots are becoming increasingly\npopular. However, research on building such chatbots has typically assumed that\nthe user input is written in nature and it is not clear whether these chatbots\nwould seamlessly integrate with automatic speech recognition (ASR) models to\nserve the speech modality. We aim to bring attention to this important question\nby empirically studying the effects of various types of synthetic and actual\nASR hypotheses in the dialog history on TransferTransfo, a state-of-the-art\nGenerative Pre-trained Transformer (GPT) based neural open-domain dialog system\nfrom the NeurIPS ConvAI2 challenge. We observe that TransferTransfo trained on\nwritten data is very sensitive to such hypotheses introduced to the dialog\nhistory during inference time. As a baseline mitigation strategy, we introduce\nsynthetic ASR hypotheses to the dialog history during training and observe\nmarginal improvements, demonstrating the need for further research into\ntechniques to make end-to-end open-domain chatbots fully speech-robust. To the\nbest of our knowledge, this is the first study to evaluate the effects of\nsynthetic and actual ASR hypotheses on a state-of-the-art neural open-domain\ndialog system and we hope it promotes speech-robustness as an evaluation\ncriterion in open-domain dialog.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 00:36:57 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Gopalakrishnan", "Karthik", ""], ["Hedayatnia", "Behnam", ""], ["Wang", "Longshaokan", ""], ["Liu", "Yang", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "2008.07703", "submitter": "Yi Ren", "authors": "Yi Ren, Jinzheng He, Xu Tan, Tao Qin, Zhou Zhao, Tie-Yan Liu", "title": "PopMAG: Pop Music Accompaniment Generation", "comments": "Accepted by ACM-MM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.IR cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In pop music, accompaniments are usually played by multiple instruments\n(tracks) such as drum, bass, string and guitar, and can make a song more\nexpressive and contagious by arranging together with its melody. Previous works\nusually generate multiple tracks separately and the music notes from different\ntracks not explicitly depend on each other, which hurts the harmony modeling.\nTo improve harmony, in this paper, we propose a novel MUlti-track MIDI\nrepresentation (MuMIDI), which enables simultaneous multi-track generation in a\nsingle sequence and explicitly models the dependency of the notes from\ndifferent tracks. While this greatly improves harmony, unfortunately, it\nenlarges the sequence length and brings the new challenge of long-term music\nmodeling. We further introduce two new techniques to address this challenge: 1)\nWe model multiple note attributes (e.g., pitch, duration, velocity) of a\nmusical note in one step instead of multiple steps, which can shorten the\nlength of a MuMIDI sequence. 2) We introduce extra long-context as memory to\ncapture long-term dependency in music. We call our system for pop music\naccompaniment generation as PopMAG. We evaluate PopMAG on multiple datasets\n(LMD, FreeMidi and CPMD, a private dataset of Chinese pop songs) with both\nsubjective and objective metrics. The results demonstrate the effectiveness of\nPopMAG for multi-track harmony modeling and long-term context modeling.\nSpecifically, PopMAG wins 42\\%/38\\%/40\\% votes when comparing with ground truth\nmusical pieces on LMD, FreeMidi and CPMD datasets respectively and largely\noutperforms other state-of-the-art music accompaniment generation models and\nmulti-track MIDI representations in terms of subjective and objective metrics.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 02:28:36 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Ren", "Yi", ""], ["He", "Jinzheng", ""], ["Tan", "Xu", ""], ["Qin", "Tao", ""], ["Zhao", "Zhou", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2008.07720", "submitter": "Hung Pham Thuc", "authors": "Pham Thuc Hung, Kenji Yamanishi", "title": "Word2vec Skip-gram Dimensionality Selection via Sequential Normalized\n  Maximum Likelihood", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a novel information criteria-based approach to\nselect the dimensionality of the word2vec Skip-gram (SG). From the perspective\nof the probability theory, SG is considered as an implicit probability\ndistribution estimation under the assumption that there exists a true\ncontextual distribution among words. Therefore, we apply information criteria\nwith the aim of selecting the best dimensionality so that the corresponding\nmodel can be as close as possible to the true distribution. We examine the\nfollowing information criteria for the dimensionality selection problem: the\nAkaike Information Criterion, Bayesian Information Criterion, and Sequential\nNormalized Maximum Likelihood (SNML) criterion. SNML is the total codelength\nrequired for the sequential encoding of a data sequence on the basis of the\nminimum description length. The proposed approach is applied to both the\noriginal SG model and the SG Negative Sampling model to clarify the idea of\nusing information criteria. Additionally, as the original SNML suffers from\ncomputational disadvantages, we introduce novel heuristics for its efficient\ncomputation. Moreover, we empirically demonstrate that SNML outperforms both\nBIC and AIC. In comparison with other evaluation methods for word embedding,\nthe dimensionality selected by SNML is significantly closer to the optimal\ndimensionality obtained by word analogy or word similarity tasks.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 03:24:21 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 04:55:56 GMT"}, {"version": "v3", "created": "Tue, 25 Aug 2020 01:08:24 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Hung", "Pham Thuc", ""], ["Yamanishi", "Kenji", ""]]}, {"id": "2008.07723", "submitter": "Huang Hu", "authors": "Xiaoyu Kou, Bingfeng Luo, Huang Hu and Yan Zhang", "title": "NASE: Learning Knowledge Graph Embedding for Link Prediction via Neural\n  Architecture Search", "comments": "Accepted by CIKM 2020, short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction is the task of predicting missing connections between\nentities in the knowledge graph (KG). While various forms of models are\nproposed for the link prediction task, most of them are designed based on a few\nknown relation patterns in several well-known datasets. Due to the diversity\nand complexity nature of the real-world KGs, it is inherently difficult to\ndesign a model that fits all datasets well. To address this issue, previous\nwork has tried to use Automated Machine Learning (AutoML) to search for the\nbest model for a given dataset. However, their search space is limited only to\nbilinear model families. In this paper, we propose a novel Neural Architecture\nSearch (NAS) framework for the link prediction task. First, the embeddings of\nthe input triplet are refined by the Representation Search Module. Then, the\nprediction score is searched within the Score Function Search Module. This\nframework entails a more general search space, which enables us to take\nadvantage of several mainstream model families, and thus it can potentially\nachieve better performance. We relax the search space to be continuous so that\nthe architecture can be optimized efficiently using gradient-based search\nstrategies. Experimental results on several benchmark datasets demonstrate the\neffectiveness of our method compared with several state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 03:34:09 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Kou", "Xiaoyu", ""], ["Luo", "Bingfeng", ""], ["Hu", "Huang", ""], ["Zhang", "Yan", ""]]}, {"id": "2008.07772", "submitter": "Xiaodong Liu", "authors": "Xiaodong Liu, Kevin Duh, Liyuan Liu and Jianfeng Gao", "title": "Very Deep Transformers for Neural Machine Translation", "comments": "6 pages, 3 figures and 4 tables. V2 includes the back-translation\n  results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the application of very deep Transformer models for Neural Machine\nTranslation (NMT). Using a simple yet effective initialization technique that\nstabilizes training, we show that it is feasible to build standard\nTransformer-based models with up to 60 encoder layers and 12 decoder layers.\nThese deep models outperform their baseline 6-layer counterparts by as much as\n2.5 BLEU, and achieve new state-of-the-art benchmark results on WMT14\nEnglish-French (43.8 BLEU and 46.4 BLEU with back-translation) and WMT14\nEnglish-German (30.1 BLEU).The code and trained models will be publicly\navailable at: https://github.com/namisan/exdeep-nmt.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 07:14:54 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 22:56:32 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Liu", "Xiaodong", ""], ["Duh", "Kevin", ""], ["Liu", "Liyuan", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2008.07880", "submitter": "Karin Verspoor", "authors": "Karin Verspoor, Simon \\v{S}uster, Yulia Otmakhova, Shevon Mendis,\n  Zenan Zhai, Biaoyan Fang, Jey Han Lau, Timothy Baldwin, Antonio Jimeno Yepes,\n  David Martinez", "title": "COVID-SEE: Scientific Evidence Explorer for COVID-19 Related Research", "comments": "COVID-SEE is available at http://covid-see.com", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present COVID-SEE, a system for medical literature discovery based on the\nconcept of information exploration, which builds on several distinct text\nanalysis and natural language processing methods to structure and organise\ninformation in publications, and augments search by providing a visual overview\nsupporting exploration of a collection to identify key articles of interest. We\ndeveloped this system over COVID-19 literature to help medical professionals\nand researchers explore the literature evidence, and improve findability of\nrelevant information. COVID-SEE is available at http://covid-see.com.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 12:14:36 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Verspoor", "Karin", ""], ["\u0160uster", "Simon", ""], ["Otmakhova", "Yulia", ""], ["Mendis", "Shevon", ""], ["Zhai", "Zenan", ""], ["Fang", "Biaoyan", ""], ["Lau", "Jey Han", ""], ["Baldwin", "Timothy", ""], ["Yepes", "Antonio Jimeno", ""], ["Martinez", "David", ""]]}, {"id": "2008.07905", "submitter": "Lihua Qian", "authors": "Lihua Qian, Hao Zhou, Yu Bao, Mingxuan Wang, Lin Qiu, Weinan Zhang,\n  Yong Yu, Lei Li", "title": "Glancing Transformer for Non-Autoregressive Neural Machine Translation", "comments": "9 pages, 7 figures, ACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on non-autoregressive neural machine translation (NAT) aims at\nimproving the efficiency by parallel decoding without sacrificing the quality.\nHowever, existing NAT methods are either inferior to Transformer or require\nmultiple decoding passes, leading to reduced speedup. We propose the Glancing\nLanguage Model (GLM), a method to learn word interdependency for single-pass\nparallel generation models. With GLM, we develop Glancing Transformer (GLAT)\nfor machine translation. With only single-pass parallel decoding, GLAT is able\nto generate high-quality translation with 8-15 times speedup. Experiments on\nmultiple WMT language directions show that GLAT outperforms all previous single\npass non-autoregressive methods, and is nearly comparable to Transformer,\nreducing the gap to 0.25-0.9 BLEU points.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 13:04:03 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 09:42:52 GMT"}, {"version": "v3", "created": "Thu, 13 May 2021 14:41:40 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Qian", "Lihua", ""], ["Zhou", "Hao", ""], ["Bao", "Yu", ""], ["Wang", "Mingxuan", ""], ["Qiu", "Lin", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""], ["Li", "Lei", ""]]}, {"id": "2008.07939", "submitter": "Van-Hoang Nguyen", "authors": "Van-Hoang Nguyen and Kazunari Sugiyama and Preslav Nakov and Min-Yen\n  Kan", "title": "FANG: Leveraging Social Context for Fake News Detection Using Graph\n  Representation", "comments": "To appear in CIKM 2020", "journal-ref": null, "doi": "10.1145/3340531.3412046", "report-no": null, "categories": "cs.SI cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Factual News Graph (FANG), a novel graphical social context\nrepresentation and learning framework for fake news detection. Unlike previous\ncontextual models that have targeted performance, our focus is on\nrepresentation learning. Compared to transductive models, FANG is scalable in\ntraining as it does not have to maintain all nodes, and it is efficient at\ninference time, without the need to re-process the entire graph. Our\nexperimental results show that FANG is better at capturing the social context\ninto a high fidelity representation, compared to recent graphical and\nnon-graphical models. In particular, FANG yields significant improvements for\nthe task of fake news detection, and it is robust in the case of limited\ntraining data. We further demonstrate that the representations learned by FANG\ngeneralize to related tasks, such as predicting the factuality of reporting of\na news medium.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 14:05:16 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 11:45:23 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Nguyen", "Van-Hoang", ""], ["Sugiyama", "Kazunari", ""], ["Nakov", "Preslav", ""], ["Kan", "Min-Yen", ""]]}, {"id": "2008.07962", "submitter": "Xin Mao", "authors": "Xin Mao, Wenting Wang, Huimin Xu, Yuanbin Wu, Man Lan", "title": "Relational Reflection Entity Alignment", "comments": "10 pages, Accepted by CIKM2020", "journal-ref": null, "doi": "10.1145/3340531.3412001", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity alignment aims to identify equivalent entity pairs from different\nKnowledge Graphs (KGs), which is essential in integrating multi-source KGs.\nRecently, with the introduction of GNNs into entity alignment, the\narchitectures of recent models have become more and more complicated. We even\nfind two counter-intuitive phenomena within these methods: (1) The standard\nlinear transformation in GNNs is not working well. (2) Many advanced KG\nembedding models designed for link prediction task perform poorly in entity\nalignment. In this paper, we abstract existing entity alignment methods into a\nunified framework, Shape-Builder & Alignment, which not only successfully\nexplains the above phenomena but also derives two key criteria for an ideal\ntransformation operation. Furthermore, we propose a novel GNNs-based method,\nRelational Reflection Entity Alignment (RREA). RREA leverages Relational\nReflection Transformation to obtain relation specific embeddings for each\nentity in a more efficient way. The experimental results on real-world datasets\nshow that our model significantly outperforms the state-of-the-art methods,\nexceeding by 5.8%-10.9% on Hits@1.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 14:49:31 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Mao", "Xin", ""], ["Wang", "Wenting", ""], ["Xu", "Huimin", ""], ["Wu", "Yuanbin", ""], ["Lan", "Man", ""]]}, {"id": "2008.08076", "submitter": "Jason  Weston", "authors": "Kurt Shuster, Jack Urbanek, Emily Dinan, Arthur Szlam, Jason Weston", "title": "Deploying Lifelong Open-Domain Dialogue Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of NLP research has focused on crowdsourced static datasets and the\nsupervised learning paradigm of training once and then evaluating test\nperformance. As argued in de Vries et al. (2020), crowdsourced data has the\nissues of lack of naturalness and relevance to real-world use cases, while the\nstatic dataset paradigm does not allow for a model to learn from its\nexperiences of using language (Silver et al., 2013). In contrast, one might\nhope for machine learning systems that become more useful as they interact with\npeople. In this work, we build and deploy a role-playing game, whereby human\nplayers converse with learning agents situated in an open-domain fantasy world.\nWe show that by training models on the conversations they have with humans in\nthe game the models progressively improve, as measured by automatic metrics and\nonline engagement scores. This learning is shown to be more efficient than\ncrowdsourced data when applied to conversations with real users, as well as\nbeing far cheaper to collect.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 17:57:26 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 16:03:27 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Shuster", "Kurt", ""], ["Urbanek", "Jack", ""], ["Dinan", "Emily", ""], ["Szlam", "Arthur", ""], ["Weston", "Jason", ""]]}, {"id": "2008.08113", "submitter": "Rishika Agarwal", "authors": "Rishika Agarwal, Xiaochuan Niu, Pranay Dighe, Srikanth Vishnubhotla,\n  Sameer Badaskar, Devang Naik", "title": "Complementary Language Model and Parallel Bi-LRNN for False Trigger\n  Mitigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  False triggers in voice assistants are unintended invocations of the\nassistant, which not only degrade the user experience but may also compromise\nprivacy. False trigger mitigation (FTM) is a process to detect the false\ntrigger events and respond appropriately to the user. In this paper, we propose\na novel solution to the FTM problem by introducing a parallel ASR decoding\nprocess with a special language model trained from \"out-of-domain\" data\nsources. Such language model is complementary to the existing language model\noptimized for the assistant task. A bidirectional lattice RNN (Bi-LRNN)\nclassifier trained from the lattices generated by the complementary language\nmodel shows a $38.34\\%$ relative reduction of the false trigger (FT) rate at\nthe fixed rate of $0.4\\%$ false suppression (FS) of correct invocations,\ncompared to the current Bi-LRNN model. In addition, we propose to train a\nparallel Bi-LRNN model based on the decoding lattices from both language\nmodels, and examine various ways of implementation. The resulting model leads\nto further reduction in the false trigger rate by $10.8\\%$.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 18:21:33 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Agarwal", "Rishika", ""], ["Niu", "Xiaochuan", ""], ["Dighe", "Pranay", ""], ["Vishnubhotla", "Srikanth", ""], ["Badaskar", "Sameer", ""], ["Naik", "Devang", ""]]}, {"id": "2008.08225", "submitter": "Victor Martinez Palacios", "authors": "Victor R Martinez and Krishna Somandepalli and Karan Singla and Anil\n  Ramanakrishna and Yalda T. Uhls and Shrikanth Narayanan", "title": "Victim or Perpetrator? Analysis of Violent Characters Portrayals from\n  Movie Scripts", "comments": "In 2nd workshop on Media Analytics for Societal Trends: Closing the\n  loop with impact and affect in human-media interactions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Violent content in the media can influence viewers' perception of the\nsociety. For example, frequent depictions of certain demographics as victims or\nperpetrators of violence can shape stereotyped attitudes. We propose that\ncomputational methods can aid in the large-scale analysis of violence in\nmovies. The method we develop characterizes aspects of violent content solely\nfrom the language used in the scripts. Thus, our method is applicable to a\nmovie in the earlier stages of content creation even before it is produced.\nThis is complementary to previous works which rely on audio or video post\nproduction. In this work, we identify stereotypes in character roles (i.e.,\nvictim, perpetrator and narrator) based on the demographics of the actor casted\nfor that role. Our results highlight two significant differences in the\nfrequency of portrayals as well as the demographics of the interaction between\nvictims and perpetrators : (1) female characters appear more often as victims,\nand (2) perpetrators are more likely to be White if the victim is Black or\nLatino. To date, we are the first to show that language used in movie scripts\nis a strong indicator of violent content, and that there are systematic\nportrayals of certain demographics as victims and perpetrators in a large\ndataset. This offers novel computational tools to assist in creating awareness\nof representations in storytelling\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 02:18:53 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 19:00:34 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Martinez", "Victor R", ""], ["Somandepalli", "Krishna", ""], ["Singla", "Karan", ""], ["Ramanakrishna", "Anil", ""], ["Uhls", "Yalda T.", ""], ["Narayanan", "Shrikanth", ""]]}, {"id": "2008.08247", "submitter": "Kun Zhou", "authors": "Kun Zhou, Wayne Xin Zhao, Hui Wang, Sirui Wang, Fuzheng Zhang,\n  Zhongyuan Wang and Ji-Rong Wen", "title": "Leveraging Historical Interaction Data for Improving Conversational\n  Recommender System", "comments": "Accepted as CIKM short paper", "journal-ref": null, "doi": "10.1145/3340531.3412098", "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, conversational recommender system (CRS) has become an emerging and\npractical research topic. Most of the existing CRS methods focus on learning\neffective preference representations for users from conversation data alone.\nWhile, we take a new perspective to leverage historical interaction data for\nimproving CRS. For this purpose, we propose a novel pre-training approach to\nintegrating both item-based preference sequence (from historical interaction\ndata) and attribute-based preference sequence (from conversation data) via\npre-training methods. We carefully design two pre-training tasks to enhance\ninformation fusion between item- and attribute-based preference. To improve the\nlearning performance, we further develop an effective negative sample generator\nwhich can produce high-quality negative samples. Experiment results on two\nreal-world datasets have demonstrated the effectiveness of our approach for\nimproving CRS.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 03:43:50 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Zhou", "Kun", ""], ["Zhao", "Wayne Xin", ""], ["Wang", "Hui", ""], ["Wang", "Sirui", ""], ["Zhang", "Fuzheng", ""], ["Wang", "Zhongyuan", ""], ["Wen", "Ji-Rong", ""]]}, {"id": "2008.08315", "submitter": "Mittul Singh", "authors": "Katri Leino, Juho Leinonen, Mittul Singh, Sami Virpioja, Mikko Kurimo", "title": "FinChat: Corpus and evaluation setup for Finnish chat conversations on\n  everyday topics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating open-domain chatbots requires large amounts of conversational data\nand related benchmark tasks to evaluate them. Standardized evaluation tasks are\ncrucial for creating automatic evaluation metrics for model development;\notherwise, comparing the models would require resource-expensive human\nevaluation. While chatbot challenges have recently managed to provide a\nplethora of such resources for English, resources in other languages are not\nyet available. In this work, we provide a starting point for Finnish\nopen-domain chatbot research. We describe our collection efforts to create the\nFinnish chat conversation corpus FinChat, which is made available publicly.\nFinChat includes unscripted conversations on seven topics from people of\ndifferent ages. Using this corpus, we also construct a retrieval-based\nevaluation task for Finnish chatbot development. We observe that off-the-shelf\nchatbot models trained on conversational corpora do not perform better than\nchance at choosing the right answer based on automatic metrics, while humans\ncan do the same task almost perfectly. Similarly, in a human evaluation,\nresponses to questions from the evaluation set generated by the chatbots are\npredominantly marked as incoherent. Thus, FinChat provides a challenging\nevaluation set, meant to encourage chatbot development in Finnish.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 07:58:16 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Leino", "Katri", ""], ["Leinonen", "Juho", ""], ["Singh", "Mittul", ""], ["Virpioja", "Sami", ""], ["Kurimo", "Mikko", ""]]}, {"id": "2008.08428", "submitter": "Shuo Zhang", "authors": "Shuo Zhang and Krisztian Balog and Jamie Callan", "title": "Generating Categories for Sets of Entities", "comments": "Proceedings of the 29th ACM International Conference on Information\n  and Knowledge Management (CIKM '20)", "journal-ref": null, "doi": "10.1145/3340531.3412019", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Category systems are central components of knowledge bases, as they provide a\nhierarchical grouping of semantically related concepts and entities. They are a\nunique and valuable resource that is utilized in a broad range of information\naccess tasks. To aid knowledge editors in the manual process of expanding a\ncategory system, this paper presents a method of generating categories for sets\nof entities. First, we employ neural abstractive summarization models to\ngenerate candidate categories. Next, the location within the hierarchy is\nidentified for each candidate. Finally, structure-, content-, and\nhierarchy-based features are used to rank candidates to identify by the most\npromising ones (measured in terms of specificity, hierarchy, and importance).\nWe develop a test collection based on Wikipedia categories and demonstrate the\neffectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 13:31:07 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Zhang", "Shuo", ""], ["Balog", "Krisztian", ""], ["Callan", "Jamie", ""]]}, {"id": "2008.08439", "submitter": "Lucas Pessutto", "authors": "Lucas R. C. Pessutto, Tiago de Melo, Viviane P. Moreira, Altigran da\n  Silva", "title": "BabelEnconding at SemEval-2020 Task 3: Contextual Similarity as a\n  Combination of Multilingualism and Language Models", "comments": "Accepted to SemEval 2020 (http://alt.qcri.org/semeval2020/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes the system submitted by our team (BabelEnconding) to\nSemEval-2020 Task 3: Predicting the Graded Effect of Context in Word\nSimilarity. We propose an approach that relies on translation and multilingual\nlanguage models in order to compute the contextual similarity between pairs of\nwords. Our hypothesis is that evidence from additional languages can leverage\nthe correlation with the human generated scores. BabelEnconding was applied to\nboth subtasks and ranked among the top-3 in six out of eight task/language\ncombinations and was the highest scoring system three times.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 13:46:37 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Pessutto", "Lucas R. C.", ""], ["de Melo", "Tiago", ""], ["Moreira", "Viviane P.", ""], ["da Silva", "Altigran", ""]]}, {"id": "2008.08547", "submitter": "Harish Tayyar Madabushi PhD", "authors": "Wah Meng Lim and Harish Tayyar Madabushi", "title": "UoB at SemEval-2020 Task 12: Boosting BERT with Corpus Level Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pre-trained language model word representation, such as BERT, have been\nextremely successful in several Natural Language Processing tasks significantly\nimproving on the state-of-the-art. This can largely be attributed to their\nability to better capture semantic information contained within a sentence.\nSeveral tasks, however, can benefit from information available at a corpus\nlevel, such as Term Frequency-Inverse Document Frequency (TF-IDF). In this work\nwe test the effectiveness of integrating this information with BERT on the task\nof identifying abuse on social media and show that integrating this information\nwith BERT does indeed significantly improve performance. We participate in\nSub-Task A (abuse detection) wherein we achieve a score within two points of\nthe top performing team and in Sub-Task B (target detection) wherein we are\nranked 4 of the 44 participating teams.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 16:47:15 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Lim", "Wah Meng", ""], ["Madabushi", "Harish Tayyar", ""]]}, {"id": "2008.08567", "submitter": "Wei Li", "authors": "Wei Li and Brian Mak", "title": "Transformer based Multilingual document Embedding model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the current state-of-the-art multilingual document embedding model\nLASER is based on the bidirectional LSTM neural machine translation model. This\npaper presents a transformer-based sentence/document embedding model, T-LASER,\nwhich makes three significant improvements. Firstly, the BiLSTM layers is\nreplaced by the attention-based transformer layers, which is more capable of\nlearning sequential patterns in longer texts. Secondly, due to the absence of\nrecurrence, T-LASER enables faster parallel computations in the encoder to\ngenerate the text embedding. Thirdly, we augment the NMT translation loss\nfunction with an additional novel distance constraint loss. This distance\nconstraint loss would further bring the embeddings of parallel sentences close\ntogether in the vector space; we call the T-LASER model trained with distance\nconstraint, cT-LASER. Our cT-LASER model significantly outperforms both\nBiLSTM-based LASER and the simpler transformer-based T-LASER.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 17:51:30 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 16:37:29 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Li", "Wei", ""], ["Mak", "Brian", ""]]}, {"id": "2008.08612", "submitter": "Punardeep Sikka", "authors": "Punardeep Sikka and Vijay Mago", "title": "A Survey on Text Simplification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text Simplification (TS) aims to reduce the linguistic complexity of content\nto make it easier to understand. Research in TS has been of keen interest,\nespecially as approaches to TS have shifted from manual, hand-crafted rules to\nautomated simplification. This survey seeks to provide a comprehensive overview\nof TS, including a brief description of earlier approaches used, discussion of\nvarious aspects of simplification (lexical, semantic and syntactic), and latest\ntechniques being utilized in the field. We note that the research in the field\nhas clearly shifted towards utilizing deep learning techniques to perform TS,\nwith a specific focus on developing solutions to combat the lack of data\navailable for simplification. We also include a discussion of datasets and\nevaluations metrics commonly used, along with discussion of related fields\nwithin Natural Language Processing (NLP), like semantic similarity.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 18:12:33 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 22:54:07 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Sikka", "Punardeep", ""], ["Mago", "Vijay", ""]]}, {"id": "2008.08727", "submitter": "Aparna Elangovan", "authors": "Aparna Elangovan, Melissa Davis and Karin Verspoor", "title": "Assigning function to protein-protein interactions: a weakly supervised\n  BioBERT based approach using PubMed abstracts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Protein-protein interactions (PPI) are critical to the function\nof proteins in both normal and diseased cells, and many critical protein\nfunctions are mediated by interactions.Knowledge of the nature of these\ninteractions is important for the construction of networks to analyse\nbiological data. However, only a small percentage of PPIs captured in protein\ninteraction databases have annotations of function available, e.g. only 4% of\nPPI are functionally annotated in the IntAct database. Here, we aim to label\nthe function type of PPIs by extracting relationships described in PubMed\nabstracts.\n  Method: We create a weakly supervised dataset from the IntAct PPI database\ncontaining interacting protein pairs with annotated function and associated\nabstracts from the PubMed database. We apply a state-of-the-art deep learning\ntechnique for biomedical natural language processing tasks, BioBERT, to build a\nmodel - dubbed PPI-BioBERT - for identifying the function of PPIs. In order to\nextract high quality PPI functions at large scale, we use an ensemble of\nPPI-BioBERT models to improve uncertainty estimation and apply an interaction\ntype-specific threshold to counteract the effects of variations in the number\nof training samples per interaction type.\n  Results: We scan 18 million PubMed abstracts to automatically identify 3253\nnew typed PPIs, including phosphorylation and acetylation interactions, with an\noverall precision of 46% (87% for acetylation) based on a human-reviewed\nsample. This work demonstrates that analysis of biomedical abstracts for PPI\nfunction extraction is a feasible approach to substantially increasing the\nnumber of interactions annotated with function captured in online databases.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 01:42:28 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 09:57:29 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Elangovan", "Aparna", ""], ["Davis", "Melissa", ""], ["Verspoor", "Karin", ""]]}, {"id": "2008.08769", "submitter": "Alexandre Lopes", "authors": "Alexandre Lopes, Rodrigo Nogueira, Roberto Lotufo, Helio Pedrini", "title": "Lite Training Strategies for Portuguese-English and English-Portuguese\n  Translation", "comments": "for code and weights, visit\n  https://github.com/unicamp-dl/Lite-T5-Translation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Despite the widespread adoption of deep learning for machine translation, it\nis still expensive to develop high-quality translation models. In this work, we\ninvestigate the use of pre-trained models, such as T5 for Portuguese-English\nand English-Portuguese translation tasks using low-cost hardware. We explore\nthe use of Portuguese and English pre-trained language models and propose an\nadaptation of the English tokenizer to represent Portuguese characters, such as\ndiaeresis, acute and grave accents. We compare our models to the Google\nTranslate API and MarianMT on a subset of the ParaCrawl dataset, as well as to\nthe winning submission to the WMT19 Biomedical Translation Shared Task. We also\ndescribe our submission to the WMT20 Biomedical Translation Shared Task. Our\nresults show that our models have a competitive performance to state-of-the-art\nmodels while being trained on modest hardware (a single 8GB gaming GPU for nine\ndays). Our data, models and code are available at\nhttps://github.com/unicamp-dl/Lite-T5-Translation.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 04:31:03 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Lopes", "Alexandre", ""], ["Nogueira", "Rodrigo", ""], ["Lotufo", "Roberto", ""], ["Pedrini", "Helio", ""]]}, {"id": "2008.08810", "submitter": "Son T. Luu", "authors": "Son T. Luu, Kiet Van Nguyen, Anh Gia-Tuan Nguyen and Ngan Luu-Thuy\n  Nguyen", "title": "An Experimental Study of Deep Neural Network Models for Vietnamese\n  Multiple-Choice Reading Comprehension", "comments": "Published in the 2020 IEEE Eighth International Conference on\n  Communications and Electronics (ICCE)", "journal-ref": null, "doi": "10.1109/ICCE48956.2021.9352127", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine reading comprehension (MRC) is a challenging task in natural language\nprocessing that makes computers understanding natural language texts and answer\nquestions based on those texts. There are many techniques for solving this\nproblems, and word representation is a very important technique that impact\nmost to the accuracy of machine reading comprehension problem in the popular\nlanguages like English and Chinese. However, few studies on MRC have been\nconducted in low-resource languages such as Vietnamese. In this paper, we\nconduct several experiments on neural network-based model to understand the\nimpact of word representation to the Vietnamese multiple-choice machine reading\ncomprehension. Our experiments include using the Co-match model on six\ndifferent Vietnamese word embeddings and the BERT model for multiple-choice\nreading comprehension. On the ViMMRC corpus, the accuracy of BERT model is\n61.28% on test set.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 07:29:14 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 15:10:12 GMT"}, {"version": "v3", "created": "Fri, 6 Nov 2020 12:36:21 GMT"}, {"version": "v4", "created": "Thu, 18 Feb 2021 08:55:59 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Luu", "Son T.", ""], ["Van Nguyen", "Kiet", ""], ["Nguyen", "Anh Gia-Tuan", ""], ["Nguyen", "Ngan Luu-Thuy", ""]]}, {"id": "2008.08854", "submitter": "Liesbeth Allein", "authors": "Liesbeth Allein and Marie-Francine Moens", "title": "Checkworthiness in Automatic Claim Detection Models: Definitions and\n  Analysis of Datasets", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-61841-4_1", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public, professional and academic interest in automated fact-checking has\ndrastically increased over the past decade, with many aiming to automate one of\nthe first steps in a fact-check procedure: the selection of so-called\ncheckworthy claims. However, there is little agreement on the definition and\ncharacteristics of checkworthiness among fact-checkers, which is consequently\nreflected in the datasets used for training and testing checkworthy claim\ndetection models. After elaborate analysis of checkworthy claim selection\nprocedures in fact-check organisations and analysis of state-of-the-art claim\ndetection datasets, checkworthiness is defined as the concept of having a\nspatiotemporal and context-dependent worth and need to have the correctness of\nthe objectivity it conveys verified. This is irrespective of the claim's\nperceived veracity judgement by an individual based on prior knowledge and\nbeliefs. Concerning the characteristics of current datasets, it is argued that\nthe data is not only highly imbalanced and noisy, but also too limited in scope\nand language. Furthermore, we believe that the subjective concept of\ncheckworthiness might not be a suitable filter for claim detection.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 09:30:05 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Allein", "Liesbeth", ""], ["Moens", "Marie-Francine", ""]]}, {"id": "2008.08896", "submitter": "Juri Opitz", "authors": "Juri Opitz and Anette Frank", "title": "Towards a Decomposable Metric for Explainable Evaluation of Text\n  Generation from AMR", "comments": "EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems that generate natural language text from abstract meaning\nrepresentations such as AMR are typically evaluated using automatic surface\nmatching metrics that compare the generated texts to reference texts from which\nthe input meaning representations were constructed. We show that besides\nwell-known issues from which such metrics suffer, an additional problem arises\nwhen applying these metrics for AMR-to-text evaluation, since an abstract\nmeaning representation allows for numerous surface realizations. In this work\nwe aim to alleviate these issues by proposing $\\mathcal{M}\\mathcal{F}_\\beta$, a\ndecomposable metric that builds on two pillars. The first is the principle of\nmeaning preservation $\\mathcal{M}$: it measures to what extent a given AMR can\nbe reconstructed from the generated sentence using SOTA AMR parsers and\napplying (fine-grained) AMR evaluation metrics to measure the distance between\nthe original and the reconstructed AMR. The second pillar builds on a principle\nof (grammatical) form $\\mathcal{F}$ that measures the linguistic quality of the\ngenerated text, which we implement using SOTA language models. In two extensive\npilot studies we show that fulfillment of both principles offers benefits for\nAMR-to-text evaluation, including explainability of scores. Since\n$\\mathcal{M}\\mathcal{F}_\\beta$ does not necessarily rely on gold AMRs, it may\nextend to other text generation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 11:25:26 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 10:46:19 GMT"}, {"version": "v3", "created": "Tue, 26 Jan 2021 08:55:07 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Opitz", "Juri", ""], ["Frank", "Anette", ""]]}, {"id": "2008.08901", "submitter": "Tianchi Liu", "authors": "Tianchi Liu, Rohan Kumar Das, Maulik Madhavi, Shengmei Shen, Haizhou\n  Li", "title": "Speaker-Utterance Dual Attention for Speaker and Utterance Verification", "comments": "Accepted by Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a novel technique that exploits the interaction\nbetween speaker traits and linguistic content to improve both speaker\nverification and utterance verification performance. We implement an idea of\nspeaker-utterance dual attention (SUDA) in a unified neural network. The dual\nattention refers to an attention mechanism for the two tasks of speaker and\nutterance verification. The proposed SUDA features an attention mask mechanism\nto learn the interaction between the speaker and utterance information streams.\nThis helps to focus only on the required information for respective task by\nmasking the irrelevant counterparts. The studies conducted on RSR2015 corpus\nconfirm that the proposed SUDA outperforms the framework without attention mask\nas well as several competitive systems for both speaker and utterance\nverification.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 11:37:57 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Liu", "Tianchi", ""], ["Das", "Rohan Kumar", ""], ["Madhavi", "Maulik", ""], ["Shen", "Shengmei", ""], ["Li", "Haizhou", ""]]}, {"id": "2008.08937", "submitter": "Christopher Frantz", "authors": "Christopher K. Frantz and Saba N. Siddiki", "title": "Institutional Grammar 2.0 Codebook", "comments": "120 pages, 16 figures, 14 tables", "journal-ref": null, "doi": "10.1111/padm.12719", "report-no": "IG-001", "categories": "cs.MA cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Grammar of Institutions, or Institutional Grammar, is an established\napproach to encode policy information in terms of institutional statements\nbased on a set of pre-defined syntactic components. This codebook provides\ncoding guidelines for a revised version of the Institutional Grammar, the\nInstitutional Grammar 2.0 (IG 2.0). IG 2.0 is a specification that aims at\nfacilitating the encoding of policy to meet varying analytical objectives. To\nthis end, it revises the grammar with respect to comprehensiveness,\nflexibility, and specificity by offering multiple levels of expressiveness (IG\nCore, IG Extended, IG Logico). In addition to the encoding of regulative\nstatements, it further introduces the encoding of constitutive institutional\nstatements, as well as statements that exhibit both constitutive and regulative\ncharacteristics. Introducing those aspects, the codebook initially covers\nfundamental concepts of IG 2.0, before providing an overview of pre-coding\nsteps relevant for document preparation. Detailed coding guidelines are\nprovided for both regulative and constitutive statements across all levels of\nexpressiveness, along with the encoding guidelines for statements of mixed form\n-- hybrid and polymorphic institutional statements. The document further\nprovides an overview of taxonomies used in the encoding process and referred to\nthroughout the codebook. The codebook concludes with a summary and discussion\nof relevant considerations to facilitate the coding process. An initial\nReader's Guide helps the reader tailor the content to her interest.\n  Note that this codebook specifically focuses on operational aspects of IG 2.0\nin the context of policy coding. Links to additional resources such as the\nunderlying scientific literature (that offers a comprehensive treatment of the\nunderlying theoretical concepts) are referred to in the concluding section of\nthe codebook.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 12:38:55 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 21:15:52 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 13:12:00 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Frantz", "Christopher K.", ""], ["Siddiki", "Saba N.", ""]]}, {"id": "2008.08995", "submitter": "Seunghak Yu", "authors": "Seunghak Yu, Tianxing He, James Glass", "title": "AutoKG: Constructing Virtual Knowledge Graphs from Unstructured\n  Documents for Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs (KGs) have the advantage of providing fine-grained detail\nfor question-answering systems. Unfortunately, building a reliable KG is\ntime-consuming and expensive as it requires human intervention. To overcome\nthis issue, we propose a novel framework to automatically construct a KG from\nunstructured documents that does not require external alignment. We first\nextract surface-form knowledge tuples from unstructured documents and encode\nthem with contextual information. Entities with similar context semantics are\nthen linked through internal alignment to form a graph structure. This allows\nus to extract the desired information from multiple documents by traversing the\ngenerated KG without a manual process. We examine its performance in retrieval\nbased QA systems by reformulating the WikiMovies and MetaQA datasets into a\ntuple-level retrieval task. The experimental results show that our method\noutperforms traditional retrieval methods by a large margin.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 14:30:33 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 20:45:02 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Yu", "Seunghak", ""], ["He", "Tianxing", ""], ["Glass", "James", ""]]}, {"id": "2008.09035", "submitter": "Rajdeep Mukherjee", "authors": "Rajdeep Mukherjee, Sriyash Poddar, Atharva Naik, Soham Dasgupta", "title": "How Have We Reacted To The COVID-19 Pandemic? Analyzing Changing Indian\n  Emotions Through The Lens of Twitter", "comments": "4 pages, submitted to CODS-COMAD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since its outbreak, the ongoing COVID-19 pandemic has caused unprecedented\nlosses to human lives and economies around the world. As of 18th July 2020, the\nWorld Health Organization (WHO) has reported more than 13 million confirmed\ncases including close to 600,000 deaths across 216 countries and territories.\nDespite several government measures, India has gradually moved up the ranks to\nbecome the third worst-hit nation by the pandemic after the US and Brazil, thus\ncausing widespread anxiety and fear among her citizens. As majority of the\nworld's population continues to remain confined to their homes, more and more\npeople have started relying on social media platforms such as Twitter for\nexpressing their feelings and attitudes towards various aspects of the\npandemic. With rising concerns of mental well-being, it becomes imperative to\nanalyze the dynamics of public affect in order to anticipate any potential\nthreats and take precautionary measures. Since affective states of human mind\nare more nuanced than meager binary sentiments, here we propose a deep\nlearning-based system to identify people's emotions from their tweets. We\nachieve competitive results on two benchmark datasets for multi-label emotion\nclassification. We then use our system to analyze the evolution of emotional\nresponses among Indians as the pandemic continues to spread its wings. We also\nstudy the development of salient factors contributing towards the changes in\nattitudes over time. Finally, we discuss directions to further improve our work\nand hope that our analysis can aid in better public health monitoring.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 15:39:05 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Mukherjee", "Rajdeep", ""], ["Poddar", "Sriyash", ""], ["Naik", "Atharva", ""], ["Dasgupta", "Soham", ""]]}, {"id": "2008.09036", "submitter": "Benjamin Heinzerling", "authors": "Benjamin Heinzerling and Kentaro Inui", "title": "Language Models as Knowledge Bases: On Entity Representations, Storage\n  Capacity, and Paraphrased Queries", "comments": "EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretrained language models have been suggested as a possible alternative or\ncomplement to structured knowledge bases. However, this emerging LM-as-KB\nparadigm has so far only been considered in a very limited setting, which only\nallows handling 21k entities whose single-token name is found in common LM\nvocabularies. Furthermore, the main benefit of this paradigm, namely querying\nthe KB using a variety of natural language paraphrases, is underexplored so\nfar. Here, we formulate two basic requirements for treating LMs as KBs: (i) the\nability to store a large number facts involving a large number of entities and\n(ii) the ability to query stored facts. We explore three entity representations\nthat allow LMs to represent millions of entities and present a detailed case\nstudy on paraphrased querying of world knowledge in LMs, thereby providing a\nproof-of-concept that language models can indeed serve as knowledge bases.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 15:39:36 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 18:06:11 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Heinzerling", "Benjamin", ""], ["Inui", "Kentaro", ""]]}, {"id": "2008.09049", "submitter": "Nishant Subramani", "authors": "Nishant Subramani and Nivedita Suresh", "title": "Discovering Useful Sentence Representations from Large Pretrained\n  Language Models", "comments": "13 pages, 11 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the extensive success of pretrained language models as encoders for\nbuilding NLP systems, they haven't seen prominence as decoders for sequence\ngeneration tasks. We explore the question of whether these models can be\nadapted to be used as universal decoders. To be considered \"universal,\" a\ndecoder must have an implicit representation for any target sentence $s$, such\nthat it can recover that sentence exactly when conditioned on its\nrepresentation. For large transformer-based language models trained on vast\namounts of English text, we investigate whether such representations can be\neasily discovered using standard optimization methods. We present and compare\nthree representation injection techniques for transformer-based models and\nthree accompanying methods which map sentences to and from this representation\nspace. Experiments show that not only do representations exist for sentences\nfrom a variety of genres. More importantly, without needing complex\noptimization algorithms, our methods recover these sentences almost perfectly\nwithout fine-tuning the underlying language model at all.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 16:03:51 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Subramani", "Nishant", ""], ["Suresh", "Nivedita", ""]]}, {"id": "2008.09075", "submitter": "Prakhar Gupta", "authors": "Prakhar Gupta, Jeffrey P. Bigham, Yulia Tsvetkov and Amy Pavel", "title": "Controlling Dialogue Generation with Semantic Exemplars", "comments": "Accepted at NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue systems pretrained with large language models generate locally\ncoherent responses, but lack the fine-grained control over responses necessary\nto achieve specific goals. A promising method to control response generation is\nexemplar-based generation, in which models edit exemplar responses that are\nretrieved from training data, or hand-written to strategically address\ndiscourse-level goals, to fit new dialogue contexts. But, current\nexemplar-based approaches often excessively copy words from the exemplar\nresponses, leading to incoherent replies. We present an Exemplar-based Dialogue\nGeneration model, EDGE, that uses the semantic frames present in exemplar\nresponses to guide generation. We show that controlling dialogue generation\nbased on the semantic frames of exemplars, rather than words in the exemplar\nitself, improves the coherence of generated responses, while preserving\nsemantic meaning and conversation goals present in exemplar responses.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 17:02:37 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 17:30:46 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Gupta", "Prakhar", ""], ["Bigham", "Jeffrey P.", ""], ["Tsvetkov", "Yulia", ""], ["Pavel", "Amy", ""]]}, {"id": "2008.09084", "submitter": "Devendra Singh Sachan", "authors": "Devendra Singh Sachan and Yuhao Zhang and Peng Qi and William Hamilton", "title": "Do Syntax Trees Help Pre-trained Transformers Extract Information?", "comments": "EACL 2021. Code available at:\n  https://github.com/DevSinghSachan/syntax-augmented-bert", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much recent work suggests that incorporating syntax information from\ndependency trees can improve task-specific transformer models. However, the\neffect of incorporating dependency tree information into pre-trained\ntransformer models (e.g., BERT) remains unclear, especially given recent\nstudies highlighting how these models implicitly encode syntax. In this work,\nwe systematically study the utility of incorporating dependency trees into\npre-trained transformers on three representative information extraction tasks:\nsemantic role labeling (SRL), named entity recognition, and relation\nextraction.\n  We propose and investigate two distinct strategies for incorporating\ndependency structure: a late fusion approach, which applies a graph neural\nnetwork on the output of a transformer, and a joint fusion approach, which\ninfuses syntax structure into the transformer attention layers. These\nstrategies are representative of prior work, but we introduce additional model\ndesign elements that are necessary for obtaining improved performance. Our\nempirical analysis demonstrates that these syntax-infused transformers obtain\nstate-of-the-art results on SRL and relation extraction tasks. However, our\nanalysis also reveals a critical shortcoming of these models: we find that\ntheir performance gains are highly contingent on the availability of\nhuman-annotated dependency parses, which raises important questions regarding\nthe viability of syntax-augmented transformers in real-world applications.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 17:17:38 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 03:42:49 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Sachan", "Devendra Singh", ""], ["Zhang", "Yuhao", ""], ["Qi", "Peng", ""], ["Hamilton", "William", ""]]}, {"id": "2008.09094", "submitter": "Nicholas Lourie", "authors": "Nicholas Lourie, Ronan Le Bras, Yejin Choi", "title": "Scruples: A Corpus of Community Ethical Judgments on 32,000 Real-Life\n  Anecdotes", "comments": "18 pages, 14 tables, 18 figures. Accepted to AAAI 2021. For\n  associated code and data, see https://github.com/allenai/scruples", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As AI systems become an increasing part of people's everyday lives, it\nbecomes ever more important that they understand people's ethical norms.\nMotivated by descriptive ethics, a field of study that focuses on people's\ndescriptive judgments rather than theoretical prescriptions on morality, we\ninvestigate a novel, data-driven approach to machine ethics.\n  We introduce Scruples, the first large-scale dataset with 625,000 ethical\njudgments over 32,000 real-life anecdotes. Each anecdote recounts a complex\nethical situation, often posing moral dilemmas, paired with a distribution of\njudgments contributed by the community members. Our dataset presents a major\nchallenge to state-of-the-art neural language models, leaving significant room\nfor improvement. However, when presented with simplified moral situations, the\nresults are considerably more promising, suggesting that neural models can\neffectively learn simpler ethical building blocks.\n  A key take-away of our empirical analysis is that norms are not always\nclean-cut; many situations are naturally divisive. We present a new method to\nestimate the best possible performance on such tasks with inherently diverse\nlabel distributions, and explore likelihood functions that separate intrinsic\nfrom model uncertainty.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 17:34:15 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 11:04:10 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Lourie", "Nicholas", ""], ["Bras", "Ronan Le", ""], ["Choi", "Yejin", ""]]}, {"id": "2008.09105", "submitter": "Mingkui Tan", "authors": "Deng Huang, Peihao Chen, Runhao Zeng, Qing Du, Mingkui Tan, Chuang Gan", "title": "Location-aware Graph Convolutional Networks for Video Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We addressed the challenging task of video question answering, which requires\nmachines to answer questions about videos in a natural language form. Previous\nstate-of-the-art methods attempt to apply spatio-temporal attention mechanism\non video frame features without explicitly modeling the location and relations\namong object interaction occurred in videos. However, the relations between\nobject interaction and their location information are very critical for both\naction recognition and question reasoning. In this work, we propose to\nrepresent the contents in the video as a location-aware graph by incorporating\nthe location information of an object into the graph construction. Here, each\nnode is associated with an object represented by its appearance and location\nfeatures. Based on the constructed graph, we propose to use graph convolution\nto infer both the category and temporal locations of an action. As the graph is\nbuilt on objects, our method is able to focus on the foreground action contents\nfor better video question answering. Lastly, we leverage an attention mechanism\nto combine the output of graph convolution and encoded question features for\nfinal answer reasoning. Extensive experiments demonstrate the effectiveness of\nthe proposed methods. Specifically, our method significantly outperforms\nstate-of-the-art methods on TGIF-QA, Youtube2Text-QA, and MSVD-QA datasets.\nCode and pre-trained models are publicly available at:\nhttps://github.com/SunDoge/L-GCN\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2020 02:12:56 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Huang", "Deng", ""], ["Chen", "Peihao", ""], ["Zeng", "Runhao", ""], ["Du", "Qing", ""], ["Tan", "Mingkui", ""], ["Gan", "Chuang", ""]]}, {"id": "2008.09112", "submitter": "Wei Zhao", "authors": "Wei Zhao, Steffen Eger, Johannes Bjerva, Isabelle Augenstein", "title": "Inducing Language-Agnostic Multilingual Representations", "comments": "*SEM2021 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual representations have the potential to make NLP techniques\navailable to the vast majority of languages in the world. However, they\ncurrently require large pretraining corpora or access to typologically similar\nlanguages. In this work, we address these obstacles by removing language\nidentity signals from multilingual embeddings. We examine three approaches for\nthis: (i) re-aligning the vector spaces of target languages (all together) to a\npivot source language; (ii) removing language-specific means and variances,\nwhich yields better discriminativeness of embeddings as a by-product; and (iii)\nincreasing input similarity across languages by removing morphological\ncontractions and sentence reordering. We evaluate on XNLI and reference-free MT\nacross 19 typologically diverse languages. Our findings expose the limitations\nof these approaches -- unlike vector normalization, vector space re-alignment\nand text normalization do not achieve consistent gains across encoders and\nlanguages. Due to the approaches' additive effects, their combination decreases\nthe cross-lingual transfer gap by 8.9 points (m-BERT) and 18.2 points (XLM-R)\non average across all tasks and languages, however. Our code and models are\npublicly available.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 17:58:56 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 11:44:24 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Zhao", "Wei", ""], ["Eger", "Steffen", ""], ["Bjerva", "Johannes", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "2008.09144", "submitter": "Diedre Carmo", "authors": "Diedre Carmo, Marcos Piau, Israel Campiotti, Rodrigo Nogueira, Roberto\n  Lotufo", "title": "PTT5: Pretraining and validating the T5 model on Brazilian Portuguese\n  data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In natural language processing (NLP), there is a need for more resources in\nPortuguese, since much of the data used in the state-of-the-art research is in\nother languages. In this paper, we pretrain a T5 model on the BrWac corpus, an\nextensive collection of web pages in Portuguese, and evaluate its performance\nagainst other Portuguese pretrained models and multilingual models on three\ndifferent tasks. We show that our Portuguese pretrained models have\nsignificantly better performance over the original T5 models. Moreover, we\ndemonstrate the positive impact of using a Portuguese vocabulary. Our code and\nmodels are available at https://github.com/unicamp-dl/PTT5.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 18:10:13 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 18:37:54 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Carmo", "Diedre", ""], ["Piau", "Marcos", ""], ["Campiotti", "Israel", ""], ["Nogueira", "Rodrigo", ""], ["Lotufo", "Roberto", ""]]}, {"id": "2008.09150", "submitter": "Iacer Calixto", "authors": "Houda Alberts, Teresa Huang, Yash Deshpande, Yibo Liu, Kyunghyun Cho,\n  Clara Vania, Iacer Calixto", "title": "VisualSem: a high-quality knowledge graph for vision and language", "comments": "11 pages, 5 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue that the next frontier in natural language understanding (NLU) and\ngeneration (NLG) will include models that can efficiently access external\nstructured knowledge repositories. In order to support the development of such\nmodels, we release the VisualSem knowledge graph (KG) which includes nodes with\nmultilingual glosses and multiple illustrative images and visually relevant\nrelations. We also release a neural multi-modal retrieval model that can use\nimages or sentences as inputs and retrieves entities in the KG. This\nmulti-modal retrieval model can be integrated into any (neural network) model\npipeline and we encourage the research community to use VisualSem for data\naugmentation and/or as a source of grounding, among other possible uses.\nVisualSem as well as the multi-modal retrieval model are publicly available and\ncan be downloaded in: https://github.com/iacercalixto/visualsem.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 18:20:29 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Alberts", "Houda", ""], ["Huang", "Teresa", ""], ["Deshpande", "Yash", ""], ["Liu", "Yibo", ""], ["Cho", "Kyunghyun", ""], ["Vania", "Clara", ""], ["Calixto", "Iacer", ""]]}, {"id": "2008.09151", "submitter": "Liangming Pan", "authors": "Liangming Pan, Jingjing Chen, Jianlong Wu, Shaoteng Liu, Chong-Wah\n  Ngo, Min-Yen Kan, Yu-Gang Jiang, Tat-Seng Chua", "title": "Multi-modal Cooking Workflow Construction for Food Recipes", "comments": "This manuscript has been accepted at ACM MM 2020", "journal-ref": null, "doi": "10.1145/3394171.3413765", "report-no": null, "categories": "cs.CL cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding food recipe requires anticipating the implicit causal effects\nof cooking actions, such that the recipe can be converted into a graph\ndescribing the temporal workflow of the recipe. This is a non-trivial task that\ninvolves common-sense reasoning. However, existing efforts rely on hand-crafted\nfeatures to extract the workflow graph from recipes due to the lack of\nlarge-scale labeled datasets. Moreover, they fail to utilize the cooking\nimages, which constitute an important part of food recipes. In this paper, we\nbuild MM-ReS, the first large-scale dataset for cooking workflow construction,\nconsisting of 9,850 recipes with human-labeled workflow graphs. Cooking steps\nare multi-modal, featuring both text instructions and cooking images. We then\npropose a neural encoder-decoder model that utilizes both visual and textual\ninformation to construct the cooking workflow, which achieved over 20%\nperformance gain over existing hand-crafted baselines.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 18:31:25 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Pan", "Liangming", ""], ["Chen", "Jingjing", ""], ["Wu", "Jianlong", ""], ["Liu", "Shaoteng", ""], ["Ngo", "Chong-Wah", ""], ["Kan", "Min-Yen", ""], ["Jiang", "Yu-Gang", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "2008.09152", "submitter": "Iacer Calixto", "authors": "Houda Alberts and Iacer Calixto", "title": "ImagiFilter: A resource to enable the semi-automatic mining of images at\n  scale", "comments": "10 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datasets (semi-)automatically collected from the web can easily scale to\nmillions of entries, but a dataset's usefulness is directly related to how\nclean and high-quality its examples are. In this paper, we describe and\npublicly release an image dataset along with pretrained models designed to\n(semi-)automatically filter out undesirable images from very large image\ncollections, possibly obtained from the web. Our dataset focusses on\nphotographic and/or natural images, a very common use-case in computer vision\nresearch. We provide annotations for coarse prediction, i.e. photographic vs.\nnon-photographic, and smaller fine-grained prediction tasks where we further\nbreak down the non-photographic class into five classes: maps, drawings,\ngraphs, icons, and sketches. Results on held out validation data show that a\nmodel architecture with reduced memory footprint achieves over 96% accuracy on\ncoarse-prediction. Our best model achieves 88% accuracy on the hardest\nfine-grained classification task available. Dataset and pretrained models are\navailable at: https://github.com/houda96/imagi-filter.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 18:31:52 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Alberts", "Houda", ""], ["Calixto", "Iacer", ""]]}, {"id": "2008.09207", "submitter": "Huili Chen", "authors": "Huili Chen and Yue Zhang and Felix Weninger and Rosalind Picard and\n  Cynthia Breazeal and Hae Won Park", "title": "Dyadic Speech-based Affect Recognition using DAMI-P2C Parent-child\n  Multimodal Interaction Dataset", "comments": "Accepted by the 2020 International Conference on Multimodal\n  Interaction (ICMI'20)", "journal-ref": null, "doi": "10.1145/3382507.3418842", "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speech-based affect recognition of individuals in dyadic\nconversation is a challenging task, in part because of its heavy reliance on\nmanual pre-processing. Traditional approaches frequently require hand-crafted\nspeech features and segmentation of speaker turns. In this work, we design\nend-to-end deep learning methods to recognize each person's affective\nexpression in an audio stream with two speakers, automatically discovering\nfeatures and time regions relevant to the target speaker's affect. We integrate\na local attention mechanism into the end-to-end architecture and compare the\nperformance of three attention implementations -- one mean pooling and two\nweighted pooling methods. Our results show that the proposed weighted-pooling\nattention solutions are able to learn to focus on the regions containing target\nspeaker's affective information and successfully extract the individual's\nvalence and arousal intensity. Here we introduce and use a \"dyadic affect in\nmultimodal interaction - parent to child\" (DAMI-P2C) dataset collected in a\nstudy of 34 families, where a parent and a child (3-7 years old) engage in\nreading storybooks together. In contrast to existing public datasets for affect\nrecognition, each instance for both speakers in the DAMI-P2C dataset is\nannotated for the perceived affect by three labelers. To encourage more\nresearch on the challenging task of multi-speaker affect sensing, we make the\nannotated DAMI-P2C dataset publicly available, including acoustic features of\nthe dyads' raw audios, affect annotations, and a diverse set of developmental,\nsocial, and demographic profiles of each dyad.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 20:53:23 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Chen", "Huili", ""], ["Zhang", "Yue", ""], ["Weninger", "Felix", ""], ["Picard", "Rosalind", ""], ["Breazeal", "Cynthia", ""], ["Park", "Hae Won", ""]]}, {"id": "2008.09236", "submitter": "Sayali Kulkarni", "authors": "Sayali Kulkarni, Shailee Jain, Mohammad Javad Hosseini, Jason\n  Baldridge, Eugene Ie, Li Zhang", "title": "Spatial Language Representation with Multi-Level Geocoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a multi-level geocoding model (MLG) that learns to associate texts\nto geographic locations. The Earth's surface is represented using space-filling\ncurves that decompose the sphere into a hierarchy of similarly sized,\nnon-overlapping cells. MLG balances generalization and accuracy by combining\nlosses across multiple levels and predicting cells at each level\nsimultaneously. Without using any dataset-specific tuning, we show that MLG\nobtains state-of-the-art results for toponym resolution on three English\ndatasets. Furthermore, it obtains large gains without any knowledge base\nmetadata, demonstrating that it can effectively learn the connection between\ntext spans and coordinates - and thus can be extended to toponymns not present\nin knowledge bases.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 00:05:08 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Kulkarni", "Sayali", ""], ["Jain", "Shailee", ""], ["Hosseini", "Mohammad Javad", ""], ["Baldridge", "Jason", ""], ["Ie", "Eugene", ""], ["Zhang", "Li", ""]]}, {"id": "2008.09237", "submitter": "Zuohui Fu", "authors": "Zuohui Fu, Yikun Xian, Yaxin Zhu, Yongfeng Zhang, Gerard de Melo", "title": "COOKIE: A Dataset for Conversational Recommendation over Knowledge\n  Graphs in E-commerce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a new dataset for conversational recommendation over\nknowledge graphs in e-commerce platforms called COOKIE. The dataset is\nconstructed from an Amazon review corpus by integrating both user-agent\ndialogue and custom knowledge graphs for recommendation. Specifically, we first\nconstruct a unified knowledge graph and extract key entities between\nuser--product pairs, which serve as the skeleton of a conversation. Then we\nsimulate conversations mirroring the human coarse-to-fine process of choosing\npreferred items. The proposed baselines and experiments demonstrate that our\ndataset is able to provide innovative opportunities for conversational\nrecommendation.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 00:11:31 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Fu", "Zuohui", ""], ["Xian", "Yikun", ""], ["Zhu", "Yaxin", ""], ["Zhang", "Yongfeng", ""], ["de Melo", "Gerard", ""]]}, {"id": "2008.09249", "submitter": "Xinya Du", "authors": "Xinya Du, Alexander M. Rush, Claire Cardie", "title": "GRIT: Generative Role-filler Transformers for Document-level Event\n  Entity Extraction", "comments": "To appear in EACL 2021; Code is available at\n  https://github.com/xinyadu/grit_doc_event_entity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the classic problem of document-level role-filler entity\nextraction (REE) for template filling. We argue that sentence-level approaches\nare ill-suited to the task and introduce a generative transformer-based\nencoder-decoder framework (GRIT) that is designed to model context at the\ndocument level: it can make extraction decisions across sentence boundaries; is\nimplicitly aware of noun phrase coreference structure, and has the capacity to\nrespect cross-role dependencies in the template structure. We evaluate our\napproach on the MUC-4 dataset, and show that our model performs substantially\nbetter than prior work. We also show that our modeling choices contribute to\nmodel performance, e.g., by implicitly capturing linguistic knowledge such as\nrecognizing coreferent entity mentions.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 01:07:36 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 19:51:07 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Du", "Xinya", ""], ["Rush", "Alexander M.", ""], ["Cardie", "Claire", ""]]}, {"id": "2008.09266", "submitter": "Aakanksha Naik", "authors": "Aakanksha Naik, Jill Lehman, Carolyn Rose", "title": "Adapting Event Extractors to Medical Data: Bridging the Covariate Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We tackle the task of adapting event extractors to new domains without\nlabeled data, by aligning the marginal distributions of source and target\ndomains. As a testbed, we create two new event extraction datasets using\nEnglish texts from two medical domains: (i) clinical notes, and (ii)\ndoctor-patient conversations. We test the efficacy of three marginal alignment\ntechniques: (i) adversarial domain adaptation (ADA), (ii) domain adaptive\nfine-tuning (DAFT), and (iii) a novel instance weighting technique based on\nlanguage model likelihood scores (LIW). LIW and DAFT improve over a no-transfer\nBERT baseline on both domains, but ADA only improves on clinical notes. Deeper\nanalysis of performance under different types of shifts (e.g., lexical shift,\nsemantic shift) reveals interesting variations among models. Our\nbest-performing models reach F1 scores of 70.0 and 72.9 on notes and\nconversations respectively, using no labeled data from target domains.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 02:12:32 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Naik", "Aakanksha", ""], ["Lehman", "Jill", ""], ["Rose", "Carolyn", ""]]}, {"id": "2008.09290", "submitter": "Mohan Zhang", "authors": "Mohan Zhang, Luchen Tan, Zhengkai Tu, Zihang Fu, Kun Xiong, Ming Li,\n  Jimmy Lin", "title": "Don't Change Me! User-Controllable Selective Paraphrase Generation", "comments": "To appear in EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paraphrase generation task, source sentences often contain phrases\nthat should not be altered. Which phrases, however, can be context dependent\nand can vary by application. Our solution to this challenge is to provide the\nuser with explicit tags that can be placed around any arbitrary segment of text\nto mean \"don't change me!\" when generating a paraphrase; the model learns to\nexplicitly copy these phrases to the output. The contribution of this work is a\nnovel data generation technique using distant supervision that allows us to\nstart with a pretrained sequence-to-sequence model and fine-tune a paraphrase\ngenerator that exhibits this behavior, allowing user-controllable paraphrase\ngeneration. Additionally, we modify the loss during fine-tuning to explicitly\nencourage diversity in model output. Our technique is language agnostic, and we\nreport experiments in English and Chinese.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 03:31:50 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 20:09:21 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Zhang", "Mohan", ""], ["Tan", "Luchen", ""], ["Tu", "Zhengkai", ""], ["Fu", "Zihang", ""], ["Xiong", "Kun", ""], ["Li", "Ming", ""], ["Lin", "Jimmy", ""]]}, {"id": "2008.09333", "submitter": "Zishan Ahmad", "authors": "Zishan Ahmad, Mukuntha N S, Asif Ekbal, Pushpak Bhattacharyya", "title": "Tweet to News Conversion: An Investigation into Unsupervised\n  Controllable Text Generation", "comments": "Accepted in IJCNN-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text generator systems have become extremely popular with the advent of\nrecent deep learning models such as encoder-decoder. Controlling the\ninformation and style of the generated output without supervision is an\nimportant and challenging Natural Language Processing (NLP) task. In this\npaper, we define the task of constructing a coherent paragraph from a set of\ndisaster domain tweets, without any parallel data. We tackle the problem by\nbuilding two systems in pipeline. The first system focuses on unsupervised\nstyle transfer and converts the individual tweets into news sentences. The\nsecond system stitches together the outputs from the first system to form a\ncoherent news paragraph. We also propose a novel training mechanism, by\nsplitting the sentences into propositions and training the second system to\nmerge the sentences. We create a validation and test set consisting of\ntweet-sets and their equivalent news paragraphs to perform empirical\nevaluation. In a completely unsupervised setting, our model was able to achieve\na BLEU score of 19.32, while successfully transferring styles and joining\ntweets to form a meaningful news paragraph.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 06:56:57 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Ahmad", "Zishan", ""], ["S", "Mukuntha N", ""], ["Ekbal", "Asif", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "2008.09335", "submitter": "Abhinav Arora", "authors": "Haoran Li, Abhinav Arora, Shuohui Chen, Anchit Gupta, Sonal Gupta,\n  Yashar Mehdad", "title": "MTOP: A Comprehensive Multilingual Task-Oriented Semantic Parsing\n  Benchmark", "comments": "13 pages, 2 figures, Accepted at EACL 2021", "journal-ref": "EACL 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scaling semantic parsing models for task-oriented dialog systems to new\nlanguages is often expensive and time-consuming due to the lack of available\ndatasets. Available datasets suffer from several shortcomings: a) they contain\nfew languages b) they contain small amounts of labeled examples per language c)\nthey are based on the simple intent and slot detection paradigm for\nnon-compositional queries. In this paper, we present a new multilingual\ndataset, called MTOP, comprising of 100k annotated utterances in 6 languages\nacross 11 domains. We use this dataset and other publicly available datasets to\nconduct a comprehensive benchmarking study on using various state-of-the-art\nmultilingual pre-trained models for task-oriented semantic parsing. We achieve\nan average improvement of +6.3 points on Slot F1 for the two existing\nmultilingual datasets, over best results reported in their experiments.\nFurthermore, we demonstrate strong zero-shot performance using pre-trained\nmodels combined with automatic translation and alignment, and a proposed\ndistant supervision method to reduce the noise in slot label projection.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 07:02:11 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 03:36:21 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Li", "Haoran", ""], ["Arora", "Abhinav", ""], ["Chen", "Shuohui", ""], ["Gupta", "Anchit", ""], ["Gupta", "Sonal", ""], ["Mehdad", "Yashar", ""]]}, {"id": "2008.09371", "submitter": "Neeraj Varshney", "authors": "Neeraj Varshney, Swaroop Mishra, Chitta Baral", "title": "It's better to say \"I can't answer\" than answering incorrectly: Towards\n  Safety critical NLP systems", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to make AI systems more reliable and their adoption in safety\ncritical applications possible, it is essential to impart the capability to\nabstain from answering when their prediction is likely to be incorrect and seek\nhuman intervention. Recently proposed \"selective answering\" techniques model\ncalibration as a binary classification task. We argue that, not all incorrectly\nanswered questions are incorrect to the same extent and the same is true for\ncorrectly answered questions. Hence, treating all correct predictions equally\nand all incorrect predictions equally constraints calibration. In this work, we\npropose a methodology that incorporates the degree of correctness, shifting\naway from classification labels as it directly tries to predict the probability\nof model's prediction being correct. We show the efficacy of the proposed\nmethod on existing Natural Language Inference (NLI) datasets by training on\nSNLI and evaluating on MNLI mismatched and matched datasets. Our approach\nimproves area under the curve (AUC) of risk-coverage plot by 10.22\\% and 8.06\\%\nover maxProb with respect to the maximum possible improvement on MNLI\nmismatched and matched set respectively. In order to evaluate our method on Out\nof Distribution (OOD) datasets, we propose a novel setup involving questions\nwith a variety of reasoning skills. Our setup includes a test set for each of\nthe five reasoning skills: numerical, logical, qualitative, abductive and\ncommonsense. We select confidence threshold for each of the approaches where\nthe in-domain accuracy (SNLI) is 99\\%. Our results show that, the proposed\nmethod outperforms existing approaches by abstaining on 2.6\\% more OOD\nquestions at respective confidence thresholds.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 08:46:36 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Varshney", "Neeraj", ""], ["Mishra", "Swaroop", ""], ["Baral", "Chitta", ""]]}, {"id": "2008.09378", "submitter": "Zihan Liu", "authors": "Peng Xu, Zihan Liu, Genta Indra Winata, Zhaojiang Lin, Pascale Fung", "title": "EmoGraph: Capturing Emotion Correlations using Graph Networks", "comments": "The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most emotion recognition methods tackle the emotion understanding task by\nconsidering individual emotion independently while ignoring their fuzziness\nnature and the interconnections among them. In this paper, we explore how\nemotion correlations can be captured and help different classification tasks.\nWe propose EmoGraph that captures the dependencies among different emotions\nthrough graph networks. These graphs are constructed by leveraging the\nco-occurrence statistics among different emotion categories. Empirical results\non two multi-label classification datasets demonstrate that EmoGraph\noutperforms strong baselines, especially for macro-F1. An additional experiment\nillustrates the captured emotion correlations can also benefit a single-label\nclassification task.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 08:59:29 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Xu", "Peng", ""], ["Liu", "Zihan", ""], ["Winata", "Genta Indra", ""], ["Lin", "Zhaojiang", ""], ["Fung", "Pascale", ""]]}, {"id": "2008.09394", "submitter": "Ziqian Zeng", "authors": "Ziqian Zeng, Wenxuan Zhou, Xin Liu, Zizheng Lin, Yangqin Song, Michael\n  David Kuo, and Wan Hang Keith Chiu", "title": "A Variational Approach to Unsupervised Sentiment Analysis", "comments": "arXiv admin note: substantial text overlap with arXiv:1904.05055", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a variational approach to unsupervised sentiment\nanalysis. Instead of using ground truth provided by domain experts, we use\ntarget-opinion word pairs as a supervision signal. For example, in a document\nsnippet \"the room is big,\" (room, big) is a target-opinion word pair. These\nword pairs can be extracted by using dependency parsers and simple rules. Our\nobjective function is to predict an opinion word given a target word while our\nultimate goal is to learn a sentiment classifier. By introducing a latent\nvariable, i.e., the sentiment polarity, to the objective function, we can\ninject the sentiment classifier to the objective function via the evidence\nlower bound. We can learn a sentiment classifier by optimizing the lower bound.\nWe also impose sophisticated constraints on opinion words as regularization\nwhich encourages that if two documents have similar (dissimilar) opinion words,\nthe sentiment classifiers should produce similar (different) probability\ndistribution. We apply our method to sentiment analysis on customer reviews and\nclinical narratives. The experiment results show our method can outperform\nunsupervised baselines in sentiment analysis task on both domains, and our\nmethod obtains comparable results to the supervised method with hundreds of\nlabels per aspect in customer reviews domain, and obtains comparable results to\nsupervised methods in clinical narratives domain.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 09:52:35 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Zeng", "Ziqian", ""], ["Zhou", "Wenxuan", ""], ["Liu", "Xin", ""], ["Lin", "Zizheng", ""], ["Song", "Yangqin", ""], ["Kuo", "Michael David", ""], ["Chiu", "Wan Hang Keith", ""]]}, {"id": "2008.09396", "submitter": "Uri Shaham", "authors": "Uri Shaham and Omer Levy", "title": "Neural Machine Translation without Embeddings", "comments": "NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many NLP models operate over sequences of subword tokens produced by\nhand-crafted tokenization rules and heuristic subword induction algorithms. A\nsimple universal alternative is to represent every computerized text as a\nsequence of bytes via UTF-8, obviating the need for an embedding layer since\nthere are fewer token types (256) than dimensions. Surprisingly, replacing the\nubiquitous embedding layer with one-hot representations of each byte does not\nhurt performance; experiments on byte-to-byte machine translation from English\nto 10 different languages show a consistent improvement in BLEU, rivaling\ncharacter-level and even standard subword-level models. A deeper investigation\nreveals that the combination of embeddingless models with decoder-input dropout\namounts to token dropout, which benefits byte-to-byte models in particular.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 09:54:11 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 13:33:25 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Shaham", "Uri", ""], ["Levy", "Omer", ""]]}, {"id": "2008.09470", "submitter": "Dimo Angelov", "authors": "Dimo Angelov", "title": "Top2Vec: Distributed Representations of Topics", "comments": "Implementation available at https://github.com/ddangelov/Top2Vec", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic modeling is used for discovering latent semantic structure, usually\nreferred to as topics, in a large collection of documents. The most widely used\nmethods are Latent Dirichlet Allocation and Probabilistic Latent Semantic\nAnalysis. Despite their popularity they have several weaknesses. In order to\nachieve optimal results they often require the number of topics to be known,\ncustom stop-word lists, stemming, and lemmatization. Additionally these methods\nrely on bag-of-words representation of documents which ignore the ordering and\nsemantics of words. Distributed representations of documents and words have\ngained popularity due to their ability to capture semantics of words and\ndocuments. We present $\\texttt{top2vec}$, which leverages joint document and\nword semantic embedding to find $\\textit{topic vectors}$. This model does not\nrequire stop-word lists, stemming or lemmatization, and it automatically finds\nthe number of topics. The resulting topic vectors are jointly embedded with the\ndocument and word vectors with distance between them representing semantic\nsimilarity. Our experiments demonstrate that $\\texttt{top2vec}$ finds topics\nwhich are significantly more informative and representative of the corpus\ntrained on than probabilistic generative models.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 20:58:27 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Angelov", "Dimo", ""]]}, {"id": "2008.09483", "submitter": "Kevin El Haddad", "authors": "No\\'e Tits, Kevin El Haddad, Thierry Dutoit", "title": "Laughter Synthesis: Combining Seq2seq modeling with Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the growing interest for expressive speech synthesis, synthesis of\nnonverbal expressions is an under-explored area. In this paper we propose an\naudio laughter synthesis system based on a sequence-to-sequence TTS synthesis\nsystem. We leverage transfer learning by training a deep learning model to\nlearn to generate both speech and laughs from annotations. We evaluate our\nmodel with a listening test, comparing its performance to an HMM-based laughter\nsynthesis one and assess that it reaches higher perceived naturalness. Our\nsolution is a first step towards a TTS system that would be able to synthesize\nspeech with a control on amusement level with laughter integration.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 09:37:28 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Tits", "No\u00e9", ""], ["Haddad", "Kevin El", ""], ["Dutoit", "Thierry", ""]]}, {"id": "2008.09513", "submitter": "Eirini Papagiannopoulou", "authors": "Eirini Papagiannopoulou, Grigorios Tsoumakas and Apostolos N.\n  Papadopoulos", "title": "Keywords lie far from the mean of all words in local vector space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyword extraction is an important document process that aims at finding a\nsmall set of terms that concisely describe a document's topics. The most\npopular state-of-the-art unsupervised approaches belong to the family of the\ngraph-based methods that build a graph-of-words and use various centrality\nmeasures to score the nodes (candidate keywords). In this work, we follow a\ndifferent path to detect the keywords from a text document by modeling the main\ndistribution of the document's words using local word vector representations.\nThen, we rank the candidates based on their position in the text and the\ndistance between the corresponding local vectors and the main distribution's\ncenter. We confirm the high performance of our approach compared to strong\nbaselines and state-of-the-art unsupervised keyword extraction methods, through\nan extended experimental study, investigating the properties of the local\nrepresentations.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 14:42:33 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Papagiannopoulou", "Eirini", ""], ["Tsoumakas", "Grigorios", ""], ["Papadopoulos", "Apostolos N.", ""]]}, {"id": "2008.09558", "submitter": "Artem Polyvyanyy", "authors": "Artem Polyvyanyy, Hanan Alkhammash, Claudio Di Ciccio, Luciano\n  Garc\\'ia-Ba\\~nuelos, Anna Kalenkova, Sander J. J. Leemans, Jan Mendling,\n  Alistair Moffat, Matthias Weidlich", "title": "Entropia: A Family of Entropy-Based Conformance Checking Measures for\n  Process Mining", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.FL cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a command-line tool, called Entropia, that implements a\nfamily of conformance checking measures for process mining founded on the\nnotion of entropy from information theory. The measures allow quantifying\nclassical non-deterministic and stochastic precision and recall quality\ncriteria for process models automatically discovered from traces executed by\nIT-systems and recorded in their event logs. A process model has \"good\"\nprecision with respect to the log it was discovered from if it does not encode\nmany traces that are not part of the log, and has \"good\" recall if it encodes\nmost of the traces from the log. By definition, the measures possess useful\nproperties and can often be computed quickly.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 15:54:47 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 03:26:57 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Polyvyanyy", "Artem", ""], ["Alkhammash", "Hanan", ""], ["Di Ciccio", "Claudio", ""], ["Garc\u00eda-Ba\u00f1uelos", "Luciano", ""], ["Kalenkova", "Anna", ""], ["Leemans", "Sander J. J.", ""], ["Mendling", "Jan", ""], ["Moffat", "Alistair", ""], ["Weidlich", "Matthias", ""]]}, {"id": "2008.09606", "submitter": "Raphael Tang", "authors": "Raphael Tang, Jaejun Lee, Afsaneh Razi, Julia Cambre, Ian Bicking,\n  Jofish Kaye, Jimmy Lin", "title": "Howl: A Deployed, Open-Source Wake Word Detection System", "comments": "The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We describe Howl, an open-source wake word detection toolkit with native\nsupport for open speech datasets, like Mozilla Common Voice and Google Speech\nCommands. We report benchmark results on Speech Commands and our own freely\navailable wake word detection dataset, built from MCV. We operationalize our\nsystem for Firefox Voice, a plugin enabling speech interactivity for the\nFirefox web browser. Howl represents, to the best of our knowledge, the first\nfully productionized yet open-source wake word detection toolkit with a web\nbrowser deployment target. Our codebase is at\nhttps://github.com/castorini/howl.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 17:59:01 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Tang", "Raphael", ""], ["Lee", "Jaejun", ""], ["Razi", "Afsaneh", ""], ["Cambre", "Julia", ""], ["Bicking", "Ian", ""], ["Kaye", "Jofish", ""], ["Lin", "Jimmy", ""]]}, {"id": "2008.09659", "submitter": "Jaebok Kim", "authors": "Marcel de Korte, Jaebok Kim, Esther Klabbers", "title": "Efficient neural speech synthesis for low-resource languages through\n  multilingual modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in neural TTS have led to models that can produce\nhigh-quality synthetic speech. However, these models typically require large\namounts of training data, which can make it costly to produce a new voice with\nthe desired quality. Although multi-speaker modeling can reduce the data\nrequirements necessary for a new voice, this approach is usually not viable for\nmany low-resource languages for which abundant multi-speaker data is not\navailable. In this paper, we therefore investigated to what extent multilingual\nmulti-speaker modeling can be an alternative to monolingual multi-speaker\nmodeling, and explored how data from foreign languages may best be combined\nwith low-resource language data. We found that multilingual modeling can\nincrease the naturalness of low-resource language speech, showed that\nmultilingual models can produce speech with a naturalness comparable to\nmonolingual multi-speaker models, and saw that the target language naturalness\nwas affected by the strategy used to add foreign language data.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2020 14:05:28 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["de Korte", "Marcel", ""], ["Kim", "Jaebok", ""], ["Klabbers", "Esther", ""]]}, {"id": "2008.09676", "submitter": "Alexandra Savelieva", "authors": "Alexandra Savelieva, Bryan Au-Yeung, and Vasanth Ramani", "title": "Abstractive Summarization of Spoken and Written Instructions with BERT", "comments": "Accepted for KDD Converse 2020\n  (https://conversekdd20.github.io/accepted-papers.html)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Summarization of speech is a difficult problem due to the spontaneity of the\nflow, disfluencies, and other issues that are not usually encountered in\nwritten texts. Our work presents the first application of the BERTSum model to\nconversational language. We generate abstractive summaries of narrated\ninstructional videos across a wide variety of topics, from gardening and\ncooking to software configuration and sports. In order to enrich the\nvocabulary, we use transfer learning and pretrain the model on a few large\ncross-domain datasets in both written and spoken English. We also do\npreprocessing of transcripts to restore sentence segmentation and punctuation\nin the output of an ASR system. The results are evaluated with ROUGE and\nContent-F1 scoring for the How2 and WikiHow datasets. We engage human judges to\nscore a set of summaries randomly selected from a dataset curated from\nHowTo100M and YouTube. Based on blind evaluation, we achieve a level of textual\nfluency and utility close to that of summaries written by human content\ncreators. The model beats current SOTA when applied to WikiHow articles that\nvary widely in style and topic, while showing no performance regression on the\ncanonical CNN/DailyMail dataset. Due to the high generalizability of the model\nacross different styles and domains, it has great potential to improve\naccessibility and discoverability of internet content. We envision this\nintegrated as a feature in intelligent virtual assistants, enabling them to\nsummarize both written and spoken instructional content upon request.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 20:59:34 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 14:36:29 GMT"}, {"version": "v3", "created": "Wed, 26 Aug 2020 20:46:23 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Savelieva", "Alexandra", ""], ["Au-Yeung", "Bryan", ""], ["Ramani", "Vasanth", ""]]}, {"id": "2008.09689", "submitter": "Yue Shang", "authors": "Yunjiang Jiang, Yue Shang, Hongwei Shen, Wen-Yun Yang and Yun Xiao", "title": "Fine-tune BERT for E-commerce Non-Default Search Ranking", "comments": "4 pages, SIGIR 2019 eCommerce Data Challenge report paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of non-default ranking on e-commerce platforms, such as based on\nascending item price or descending historical sales volume, often suffers from\nacute relevance problems, since the irrelevant items are much easier to be\nexposed at the top of the ranking results. In this work, we propose a two-stage\nranking scheme, which first recalls wide range of candidate items through\nrefined query/title keyword matching, and then classifies the recalled items\nusing BERT-Large fine-tuned on human label data. We also implemented parallel\nprediction on multiple GPU hosts and a C++ tokenization custom op of\nTensorflow. In this data challenge, our model won the 1st place in the\nsupervised phase (based on overall F1 score) and 2nd place in the final phase\n(based on average per query F1 score).\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 21:48:00 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Jiang", "Yunjiang", ""], ["Shang", "Yue", ""], ["Shen", "Hongwei", ""], ["Yang", "Wen-Yun", ""], ["Xiao", "Yun", ""]]}, {"id": "2008.09703", "submitter": "Michael Kranzlein", "authors": "Michael Kranzlein, Shabnam Behzad, Nazli Goharian", "title": "Team DoNotDistribute at SemEval-2020 Task 11: Features, Finetuning, and\n  Data Augmentation in Neural Models for Propaganda Detection in News Articles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents our systems for SemEval 2020 Shared Task 11: Detection of\nPropaganda Techniques in News Articles. We participate in both the span\nidentification and technique classification subtasks and report on experiments\nusing different BERT-based models along with handcrafted features. Our models\nperform well above the baselines for both tasks, and we contribute ablation\nstudies and discussion of our results to dissect the effectiveness of different\nfeatures and techniques with the goal of aiding future studies in propaganda\ndetection.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 22:35:57 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Kranzlein", "Michael", ""], ["Behzad", "Shabnam", ""], ["Goharian", "Nazli", ""]]}, {"id": "2008.09706", "submitter": "Pengjie Ren", "authors": "Yangjun Zhang, Pengjie Ren, Maarten de Rijke", "title": "Detecting and Classifying Malevolent Dialogue Responses: Taxonomy, Data\n  and Methodology", "comments": "under review at JASIST", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational interfaces are increasingly popular as a way of connecting\npeople to information. Corpus-based conversational interfaces are able to\ngenerate more diverse and natural responses than template-based or\nretrieval-based agents. With their increased generative capacity of corpusbased\nconversational agents comes the need to classify and filter out malevolent\nresponses that are inappropriate in terms of content and dialogue acts.\nPrevious studies on the topic of recognizing and classifying inappropriate\ncontent are mostly focused on a certain category of malevolence or on single\nsentences instead of an entire dialogue. In this paper, we define the task of\nMalevolent Dialogue Response Detection and Classification (MDRDC). We make\nthree contributions to advance research on this task. First, we present a\nHierarchical Malevolent Dialogue Taxonomy (HMDT). Second, we create a labelled\nmulti-turn dialogue dataset and formulate the MDRDC task as a hierarchical\nclassification task over this taxonomy. Third, we apply stateof-the-art text\nclassification methods to the MDRDC task and report on extensive experiments\naimed at assessing the performance of these approaches.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 22:43:27 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Zhang", "Yangjun", ""], ["Ren", "Pengjie", ""], ["de Rijke", "Maarten", ""]]}, {"id": "2008.09740", "submitter": "Chenxiao Wang", "authors": "Gang Zhao, Teng Zhang, Chenxiao Wang, Ping Lv, Ji Wu", "title": "Applications of BERT Based Sequence Tagging Models on Chinese Medical\n  Text Attributes Extraction", "comments": "in Chinese language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We convert the Chinese medical text attributes extraction task into a\nsequence tagging or machine reading comprehension task. Based on BERT\npre-trained models, we have not only tried the widely used LSTM-CRF sequence\ntagging model, but also other sequence models, such as CNN, UCNN, WaveNet,\nSelfAttention, etc, which reaches similar performance as LSTM+CRF. This sheds a\nlight on the traditional sequence tagging models. Since the aspect of emphasis\nfor different sequence tagging models varies substantially, ensembling these\nmodels adds diversity to the final system. By doing so, our system achieves\ngood performance on the task of Chinese medical text attributes extraction\n(subtask 2 of CCKS 2019 task 1).\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 03:02:57 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Zhao", "Gang", ""], ["Zhang", "Teng", ""], ["Wang", "Chenxiao", ""], ["Lv", "Ping", ""], ["Wu", "Ji", ""]]}, {"id": "2008.09820", "submitter": "Nirant K", "authors": "Meghana Bhange and Nirant Kasliwal", "title": "HinglishNLP: Fine-tuned Language Models for Hinglish Sentiment Detection", "comments": "SemEval 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis for code-mixed social media text continues to be an\nunder-explored area. This work adds two common approaches: fine-tuning large\ntransformer models and sample efficient methods like ULMFiT. Prior work\ndemonstrates the efficacy of classical ML methods for polarity detection.\nFine-tuned general-purpose language representation models, such as those of the\nBERT family are benchmarked along with classical machine learning and ensemble\nmethods. We show that NB-SVM beats RoBERTa by 6.2% (relative) F1. The best\nperforming model is a majority-vote ensemble which achieves an F1 of 0.707. The\nleaderboard submission was made under the codalab username nirantk, with F1 of\n0.689.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 12:01:44 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Bhange", "Meghana", ""], ["Kasliwal", "Nirant", ""]]}, {"id": "2008.09859", "submitter": "Sam Tureski", "authors": "Verena Blaschke, Maxim Korniyenko, Sam Tureski", "title": "CyberWallE at SemEval-2020 Task 11: An Analysis of Feature Engineering\n  for Ensemble Models for Propaganda Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes our participation in the SemEval-2020 task Detection of\nPropaganda Techniques in News Articles. We participate in both subtasks: Span\nIdentification (SI) and Technique Classification (TC). We use a bi-LSTM\narchitecture in the SI subtask and train a complex ensemble model for the TC\nsubtask. Our architectures are built using embeddings from BERT in combination\nwith additional lexical features and extensive label post-processing. Our\nsystems achieve a rank of 8 out of 35 teams in the SI subtask (F1-score:\n43.86%) and 8 out of 31 teams in the TC subtask (F1-score: 57.37%).\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 15:51:16 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Blaschke", "Verena", ""], ["Korniyenko", "Maxim", ""], ["Tureski", "Sam", ""]]}, {"id": "2008.09869", "submitter": "Nadezhda Ganzherli", "authors": "Elena Mikhalkova, Nadezhda Ganzherli, Anna Glazkova, Yuliya Bidulya", "title": "UTMN at SemEval-2020 Task 11: A Kitchen Solution to Automatic Propaganda\n  Detection", "comments": "5 pages -- the article proper; 2 pages -- references; 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The article describes a fast solution to propaganda detection at SemEval-2020\nTask 11, based onfeature adjustment. We use per-token vectorization of features\nand a simple Logistic Regressionclassifier to quickly test different hypotheses\nabout our data. We come up with what seems to usthe best solution, however, we\nare unable to align it with the result of the metric suggested by theorganizers\nof the task. We test how our system handles class and feature imbalance by\nvarying thenumber of samples of two classes (Propaganda and None) in the\ntraining set, the size of a contextwindow in which a token is vectorized and\ncombination of vectorization means. The result of oursystem at SemEval2020 Task\n11 is F-score=0.37.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 16:31:01 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Mikhalkova", "Elena", ""], ["Ganzherli", "Nadezhda", ""], ["Glazkova", "Anna", ""], ["Bidulya", "Yuliya", ""]]}, {"id": "2008.09894", "submitter": "Anastasios Bairaktaris", "authors": "Anastasios Bairaktaris, Symeon Symeonidis, Avi Arampatzis", "title": "DUTH at SemEval-2020 Task 11: BERT with Entity Mapping for Propaganda\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This report describes the methods employed by the Democritus University of\nThrace (DUTH) team for participating in SemEval-2020 Task 11: Detection of\nPropaganda Techniques in News Articles. Our team dealt with Subtask 2:\nTechnique Classification. We used shallow Natural Language Processing (NLP)\npreprocessing techniques to reduce the noise in the dataset, feature selection\nmethods, and common supervised machine learning algorithms. Our final model is\nbased on using the BERT system with entity mapping. To improve our model's\naccuracy, we mapped certain words into five distinct categories by employing\nword-classes and entity recognition.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 18:18:02 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 10:20:22 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Bairaktaris", "Anastasios", ""], ["Symeonidis", "Symeon", ""], ["Arampatzis", "Avi", ""]]}, {"id": "2008.09943", "submitter": "Chen Yiwei", "authors": "Yiwei Chen, Yu Pan, Daoyi Dong", "title": "Quantum Language Model with Entanglement Embedding for Question\n  Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum Language Models (QLMs) in which words are modelled as quantum\nsuperposition of sememes have demonstrated a high level of model transparency\nand good post-hoc interpretability. Nevertheless, in the current literature\nword sequences are basically modelled as a classical mixture of word states,\nwhich cannot fully exploit the potential of a quantum probabilistic\ndescription. A full quantum model is yet to be developed to explicitly capture\nthe non-classical correlations within the word sequences. We propose a neural\nnetwork model with a novel Entanglement Embedding (EE) module, whose function\nis to transform the word sequences into entangled pure states of many-body\nquantum systems. Strong quantum entanglement, which is the central concept of\nquantum information and an indication of parallelized correlations among the\nwords, is observed within the word sequences. Numerical experiments show that\nthe proposed QLM with EE (QLM-EE) achieves superior performance compared with\nthe classical deep neural network models and other QLMs on Question Answering\n(QA) datasets. In addition, the post-hoc interpretability of the model can be\nimproved by quantizing the degree of entanglement among the words.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 02:34:26 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Chen", "Yiwei", ""], ["Pan", "Yu", ""], ["Dong", "Daoyi", ""]]}, {"id": "2008.09961", "submitter": "Shadi Shahsavari", "authors": "Timothy R. Tangherlini, Shadi Shahsavari, Behnam Shahbazi, Ehsan\n  Ebrahimzadeh, Vwani Roychowdhury", "title": "An automated pipeline for the discovery of conspiracy and conspiracy\n  theory narrative frameworks: Bridgegate, Pizzagate and storytelling on the\n  web", "comments": "conspiracy theory, narrative structure", "journal-ref": null, "doi": "10.1371/journal.pone.0233879", "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although a great deal of attention has been paid to how conspiracy theories\ncirculate on social media and their factual counterpart conspiracies, there has\nbeen little computational work done on describing their narrative structures.\nWe present an automated pipeline for the discovery and description of the\ngenerative narrative frameworks of conspiracy theories on social media, and\nactual conspiracies reported in the news media. We base this work on two\nseparate repositories of posts and news articles describing the well-known\nconspiracy theory Pizzagate from 2016, and the New Jersey conspiracy Bridgegate\nfrom 2013. We formulate a graphical generative machine learning model where\nnodes represent actors/actants, and multi-edges and self-loops among nodes\ncapture context-specific relationships. Posts and news items are viewed as\nsamples of subgraphs of the hidden narrative network. The problem of\nreconstructing the underlying structure is posed as a latent model estimation\nproblem. We automatically extract and aggregate the actants and their\nrelationships from the posts and articles. We capture context specific actants\nand interactant relationships by developing a system of supernodes and\nsubnodes. We use these to construct a network, which constitutes the underlying\nnarrative framework. We show how the Pizzagate framework relies on the\nconspiracy theorists' interpretation of \"hidden knowledge\" to link otherwise\nunlinked domains of human interaction, and hypothesize that this multi-domain\nfocus is an important feature of conspiracy theories. While Pizzagate relies on\nthe alignment of multiple domains, Bridgegate remains firmly rooted in the\nsingle domain of New Jersey politics. We hypothesize that the narrative\nframework of a conspiracy theory might stabilize quickly in contrast to the\nnarrative framework of an actual one, which may develop more slowly as\nrevelations come to light.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 05:14:38 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Tangherlini", "Timothy R.", ""], ["Shahsavari", "Shadi", ""], ["Shahbazi", "Behnam", ""], ["Ebrahimzadeh", "Ehsan", ""], ["Roychowdhury", "Vwani", ""]]}, {"id": "2008.09976", "submitter": "Cuiyun Gao", "authors": "Cuiyun Gao, Jichuan Zeng, Zhiyuan Wen, David Lo, Xin Xia, Irwin King,\n  Michael R. Lyu", "title": "Emerging App Issue Identification via Online Joint Sentiment-Topic\n  Tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millions of mobile apps are available in app stores, such as Apple's App\nStore and Google Play. For a mobile app, it would be increasingly challenging\nto stand out from the enormous competitors and become prevalent among users.\nGood user experience and well-designed functionalities are the keys to a\nsuccessful app. To achieve this, popular apps usually schedule their updates\nfrequently. If we can capture the critical app issues faced by users in a\ntimely and accurate manner, developers can make timely updates, and good user\nexperience can be ensured. There exist prior studies on analyzing reviews for\ndetecting emerging app issues. These studies are usually based on topic\nmodeling or clustering techniques. However, the short-length characteristics\nand sentiment of user reviews have not been considered. In this paper, we\npropose a novel emerging issue detection approach named MERIT to take into\nconsideration the two aforementioned characteristics. Specifically, we propose\nan Adaptive Online Biterm Sentiment-Topic (AOBST) model for jointly modeling\ntopics and corresponding sentiments that takes into consideration app versions.\nBased on the AOBST model, we infer the topics negatively reflected in user\nreviews for one app version, and automatically interpret the meaning of the\ntopics with most relevant phrases and sentences. Experiments on popular apps\nfrom Google Play and Apple's App Store demonstrate the effectiveness of MERIT\nin identifying emerging app issues, improving the state-of-the-art method by\n22.3% in terms of F1-score. In terms of efficiency, MERIT can return results\nwithin acceptable time.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 06:34:05 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Gao", "Cuiyun", ""], ["Zeng", "Jichuan", ""], ["Wen", "Zhiyuan", ""], ["Lo", "David", ""], ["Xia", "Xin", ""], ["King", "Irwin", ""], ["Lyu", "Michael R.", ""]]}, {"id": "2008.10022", "submitter": "Oladapo Oyebode", "authors": "Oladapo Oyebode, Chinenye Ndulue, Dinesh Mulchandani, Banuchitra\n  Suruliraj, Ashfaq Adib, Fidelia Anulika Orji, Evangelos Milios, Stan Matwin,\n  and Rita Orji", "title": "COVID-19 Pandemic: Identifying Key Issues using Social Media and Natural\n  Language Processing", "comments": "12 pages, 7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic has affected people's lives in many ways. Social media\ndata can reveal public perceptions and experience with respect to the pandemic,\nand also reveal factors that hamper or support efforts to curb global spread of\nthe disease. In this paper, we analyzed COVID-19-related comments collected\nfrom six social media platforms using Natural Language Processing (NLP)\ntechniques. We identified relevant opinionated keyphrases and their respective\nsentiment polarity (negative or positive) from over 1 million randomly selected\ncomments, and then categorized them into broader themes using thematic\nanalysis. Our results uncover 34 negative themes out of which 17 are economic,\nsocio-political, educational, and political issues. 20 positive themes were\nalso identified. We discuss the negative issues and suggest interventions to\ntackle them based on the positive themes and research evidence.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 12:05:12 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Oyebode", "Oladapo", ""], ["Ndulue", "Chinenye", ""], ["Mulchandani", "Dinesh", ""], ["Suruliraj", "Banuchitra", ""], ["Adib", "Ashfaq", ""], ["Orji", "Fidelia Anulika", ""], ["Milios", "Evangelos", ""], ["Matwin", "Stan", ""], ["Orji", "Rita", ""]]}, {"id": "2008.10031", "submitter": "Ali Shariq Imran", "authors": "Ali Shariq Imran, Sher Mohammad Doudpota, Zenun Kastrati, Rakhi Bhatra", "title": "Cross-Cultural Polarity and Emotion Detection Using Sentiment Analysis\n  and Deep Learning -- a Case Study on COVID-19", "comments": "19 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How different cultures react and respond given a crisis is predominant in a\nsociety's norms and political will to combat the situation. Often the decisions\nmade are necessitated by events, social pressure, or the need of the hour,\nwhich may not represent the will of the nation. While some are pleased with it,\nothers might show resentment. Coronavirus (COVID-19) brought a mix of similar\nemotions from the nations towards the decisions taken by their respective\ngovernments. Social media was bombarded with posts containing both positive and\nnegative sentiments on the COVID-19, pandemic, lockdown, hashtags past couple\nof months. Despite geographically close, many neighboring countries reacted\ndifferently to one another. For instance, Denmark and Sweden, which share many\nsimilarities, stood poles apart on the decision taken by their respective\ngovernments. Yet, their nation's support was mostly unanimous, unlike the South\nAsian neighboring countries where people showed a lot of anxiety and\nresentment. This study tends to detect and analyze sentiment polarity and\nemotions demonstrated during the initial phase of the pandemic and the lockdown\nperiod employing natural language processing (NLP) and deep learning techniques\non Twitter posts. Deep long short-term memory (LSTM) models used for estimating\nthe sentiment polarity and emotions from extracted tweets have been trained to\nachieve state-of-the-art accuracy on the sentiment140 dataset. The use of\nemoticons showed a unique and novel way of validating the supervised deep\nlearning models on tweets extracted from Twitter.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 12:43:26 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Imran", "Ali Shariq", ""], ["Doudpota", "Sher Mohammad", ""], ["Kastrati", "Zenun", ""], ["Bhatra", "Rakhi", ""]]}, {"id": "2008.10077", "submitter": "Qing Sun", "authors": "Qing Sun and James Cross", "title": "Learn to Talk via Proactive Knowledge Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Transfer has been applied in solving a wide variety of problems.\nFor example, knowledge can be transferred between tasks (e.g., learning to\nhandle novel situations by leveraging prior knowledge) or between agents (e.g.,\nlearning from others without direct experience). Without loss of generality, we\nrelate knowledge transfer to KL-divergence minimization, i.e., matching the\n(belief) distributions of learners and teachers. The equivalence gives us a new\nperspective in understanding variants of the KL-divergence by looking at how\nlearners structure their interaction with teachers in order to acquire\nknowledge. In this paper, we provide an in-depth analysis of KL-divergence\nminimization in Forward and Backward orders, which shows that learners are\nreinforced via on-policy learning in Backward. In contrast, learners are\nsupervised in Forward. Moreover, our analysis is gradient-based, so it can be\ngeneralized to arbitrary tasks and help to decide which order to minimize given\nthe property of the task. By replacing Forward with Backward in Knowledge\nDistillation, we observed +0.7-1.1 BLEU gains on the WMT'17 De-En and IWSLT'15\nTh-En machine translation tasks.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 17:46:04 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Sun", "Qing", ""], ["Cross", "James", ""]]}, {"id": "2008.10105", "submitter": "Benedikt Boenninghoff", "authors": "Benedikt Boenninghoff and Julian Rupp and Robert M. Nickel and\n  Dorothea Kolossa", "title": "Deep Bayes Factor Scoring for Authorship Verification", "comments": "CLEF 2020 Labs and Workshops, Notebook Papers, September 2020.\n  CEUR-WS.org", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The PAN 2020 authorship verification (AV) challenge focuses on a\ncross-topic/closed-set AV task over a collection of fanfiction texts.\nFanfiction is a fan-written extension of a storyline in which a so-called\nfandom topic describes the principal subject of the document. The data provided\nin the PAN 2020 AV task is quite challenging because authors of texts across\nmultiple/different fandom topics are included. In this work, we present a\nhierarchical fusion of two well-known approaches into a single end-to-end\nlearning procedure: A deep metric learning framework at the bottom aims to\nlearn a pseudo-metric that maps a document of variable length onto a\nfixed-sized feature vector. At the top, we incorporate a probabilistic layer to\nperform Bayes factor scoring in the learned metric space. We also provide text\npreprocessing strategies to deal with the cross-topic issue.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 21:00:33 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Boenninghoff", "Benedikt", ""], ["Rupp", "Julian", ""], ["Nickel", "Robert M.", ""], ["Kolossa", "Dorothea", ""]]}, {"id": "2008.10129", "submitter": "Mahmoud Al-Ayyoub", "authors": "Abdalraheem Alsmadi, Shadi AlZu'bi, Mahmoud Al-Ayyoub, Yaser Jararweh", "title": "Predicting Helpfulness of Online Reviews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  E-commerce dominates a large part of the world's economy with many websites\ndedicated to online selling products. The vast majority of e-commerce websites\nprovide their customers with the ability to express their opinions about the\nproducts/services they purchase. These feedback in the form of reviews\nrepresent a rich source of information about the users' experiences and level\nof satisfaction, which is of great benefit to both the producer and the\nconsumer. However, not all of these reviews are helpful/useful. The traditional\nway of determining the helpfulness of a review is through the feedback from\nhuman users. However, such a method does not necessarily cover all reviews.\nMoreover, it has many issues like bias, high cost, etc. Thus, there is a need\nto automate this process. This paper presents a set of machine learning (ML)\nmodels to predict the helpfulness online reviews. Mainly, three approaches are\nused: a supervised learning approach (using ML as well as deep learning (DL)\nmodels), a semi-supervised approach (that combines DL models with word\nembeddings), and pre-trained word embedding models that uses transfer learning\n(TL). The latter two approaches are among the unique aspects of this paper as\nthey follow the recent trend of utilizing unlabeled text. The results show that\nthe proposed DL approaches have superiority over the traditional existing ones.\nMoreover, the semi-supervised has a remarkable performance compared with the\nother ones.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 23:19:17 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Alsmadi", "Abdalraheem", ""], ["AlZu'bi", "Shadi", ""], ["Al-Ayyoub", "Mahmoud", ""], ["Jararweh", "Yaser", ""]]}, {"id": "2008.10163", "submitter": "Jinfen Li", "authors": "Jinfen Li, Lu Xiao", "title": "syrapropa at SemEval-2020 Task 11: BERT-based Models Design For\n  Propagandistic Technique and Span Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes the BERT-based models proposed for two subtasks in\nSemEval-2020 Task 11: Detection of Propaganda Techniques in News Articles. We\nfirst build the model for Span Identification (SI) based on SpanBERT, and\nfacilitate the detection by a deeper model and a sentence-level representation.\nWe then develop a hybrid model for the Technique Classification (TC). The\nhybrid model is composed of three submodels including two BERT models with\ndifferent training methods, and a feature-based Logistic Regression model. We\nendeavor to deal with imbalanced dataset by adjusting cost function. We are in\nthe seventh place in SI subtask (0.4711 of F1-measure), and in the third place\nin TC subtask (0.6783 of F1-measure) on the development set.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 02:15:29 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Li", "Jinfen", ""], ["Xiao", "Lu", ""]]}, {"id": "2008.10166", "submitter": "Jiaxu Dao", "authors": "Jiaxu Dao, Jin Wang, Xuejie Zhang", "title": "YNU-HPCC at SemEval-2020 Task 11: LSTM Network for Detection of\n  Propaganda Techniques in News Articles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper summarizes our studies on propaganda detection techniques for news\narticles in the SemEval-2020 task 11. This task is divided into the SI and TC\nsubtasks. We implemented the GloVe word representation, the BERT pretraining\nmodel, and the LSTM model architecture to accomplish this task. Our approach\nachieved good results for both the SI and TC subtasks. The macro-F1-score for\nthe SI subtask is 0.406, and the micro-F1-score for the TC subtask is 0.505.\nOur method significantly outperforms the officially released baseline method,\nand the SI and TC subtasks rank 17th and 22nd, respectively, for the test set.\nThis paper also compares the performances of different deep learning model\narchitectures, such as the Bi-LSTM, LSTM, BERT, and XGBoost models, on the\ndetection of news promotion techniques. The code of this paper is availabled\nat: https://github.com/daojiaxu/semeval_11.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 02:42:12 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 11:03:18 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Dao", "Jiaxu", ""], ["Wang", "Jin", ""], ["Zhang", "Xuejie", ""]]}, {"id": "2008.10284", "submitter": "Hao Fei", "authors": "Hao Fei and Meishan Zhang and Fei Li and Donghong Ji", "title": "Cross-lingual Semantic Role Labeling with Model Transfer", "comments": "Accepted at TASLP", "journal-ref": "TASLP, 2020", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior studies show that cross-lingual semantic role labeling (SRL) can be\nachieved by model transfer under the help of universal features. In this paper,\nwe fill the gap of cross-lingual SRL by proposing an end-to-end SRL model that\nincorporates a variety of universal features and transfer methods. We study\nboth the bilingual transfer and multi-source transfer, under gold or\nmachine-generated syntactic inputs, pre-trained high-order abstract features,\nand contextualized multilingual word representations. Experimental results on\nthe Universal Proposition Bank corpus indicate that performances of the\ncross-lingual SRL can vary by leveraging different cross-lingual features. In\naddition, whether the features are gold-standard also has an impact on\nperformances. Precisely, we find that gold syntax features are much more\ncrucial for cross-lingual SRL, compared with the automatically-generated ones.\nMoreover, universal dependency structure features are able to give the best\nhelp, and both pre-trained high-order features and contextualized word\nrepresentations can further bring significant improvements.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 09:37:45 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Fei", "Hao", ""], ["Zhang", "Meishan", ""], ["Li", "Fei", ""], ["Ji", "Donghong", ""]]}, {"id": "2008.10327", "submitter": "Chengyu Wang", "authors": "Taolin Zhang, Chengyu Wang, Minghui Qiu, Bite Yang, Xiaofeng He, Jun\n  Huang", "title": "Knowledge-Empowered Representation Learning for Chinese Medical Reading\n  Comprehension: Task, Model and Resources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Reading Comprehension (MRC) aims to extract answers to questions\ngiven a passage. It has been widely studied recently, especially in open\ndomains. However, few efforts have been made on closed-domain MRC, mainly due\nto the lack of large-scale training data. In this paper, we introduce a\nmulti-target MRC task for the medical domain, whose goal is to predict answers\nto medical questions and the corresponding support sentences from medical\ninformation sources simultaneously, in order to ensure the high reliability of\nmedical knowledge serving. A high-quality dataset is manually constructed for\nthe purpose, named Multi-task Chinese Medical MRC dataset (CMedMRC), with\ndetailed analysis conducted. We further propose the Chinese medical BERT model\nfor the task (CMedBERT), which fuses medical knowledge into pre-trained\nlanguage models by the dynamic fusion mechanism of heterogeneous features and\nthe multi-task learning strategy. Experiments show that CMedBERT consistently\noutperforms strong baselines by fusing context-aware and knowledge-aware token\nrepresentations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 11:23:28 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Zhang", "Taolin", ""], ["Wang", "Chengyu", ""], ["Qiu", "Minghui", ""], ["Yang", "Bite", ""], ["He", "Xiaofeng", ""], ["Huang", "Jun", ""]]}, {"id": "2008.10392", "submitter": "Ond\\v{r}ej M\\v{e}kota", "authors": "Ond\\v{r}ej M\\v{e}kota, Memduh G\\\"ok{\\i}rmak, Petr Laitoch", "title": "End to End Dialogue Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue systems attempt to facilitate conversations between humans and\ncomputers, for purposes as diverse as small talk to booking a vacation. We are\nhere inspired by the performance of the recurrent neural network-based model\nSequicity, which when conducting a dialogue uses a sequence-to-sequence\narchitecture to first produce a textual representation of what is going on in\nthe dialogue, and in a further step use this along with database findings to\nproduce a reply to the user. We here propose a dialogue system based on the\nTransformer architecture instead of Sequicity's RNN-based architecture, that\nworks similarly in an end-to-end, sequence-to-sequence fashion.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 12:43:08 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["M\u011bkota", "Ond\u0159ej", ""], ["G\u00f6k\u0131rmak", "Memduh", ""], ["Laitoch", "Petr", ""]]}, {"id": "2008.10427", "submitter": "Prasanna Parthasarathi", "authors": "Prasanna Parthasarathi and Joelle Pineau and Sarath Chandar", "title": "How To Evaluate Your Dialogue System: Probe Tasks as an Alternative for\n  Token-level Evaluation Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though generative dialogue modeling is widely seen as a language modeling\ntask, the task demands an agent to have a complex natural language\nunderstanding of its input text to carry a meaningful interaction with an user.\nThe automatic metrics used evaluate the quality of the generated text as a\nproxy to the holistic interaction of the agent. Such metrics were earlier shown\nto not correlate with the human judgement. In this work, we observe that human\nevaluation of dialogue agents can be inconclusive due to the lack of sufficient\ninformation for appropriate evaluation. The automatic metrics are deterministic\nyet shallow and human evaluation can be relevant yet inconclusive. To bridge\nthis gap in evaluation, we propose designing a set of probing tasks to evaluate\ndialogue models. The hand-crafted tasks are aimed at quantitatively evaluating\na generative dialogue model's understanding beyond the token-level evaluation\non the generated text. The probing tasks are deterministic like automatic\nmetrics and requires human judgement in their designing; benefiting from the\nbest of both worlds. With experiments on probe tasks we observe that, unlike\nRNN based architectures, transformer model may not be learning to comprehend\nthe input text despite its generated text having higher overlap with the target\ntext.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 13:28:35 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Parthasarathi", "Prasanna", ""], ["Pineau", "Joelle", ""], ["Chandar", "Sarath", ""]]}, {"id": "2008.10492", "submitter": "Brent Biseda", "authors": "Brent Biseda, Gaurav Desai, Haifeng Lin, and Anish Philip", "title": "Prediction of ICD Codes with Clinical BERT Embeddings and Text\n  Augmentation with Label Balancing using MIMIC-III", "comments": "5 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper achieves state of the art results for the ICD code prediction task\nusing the MIMIC-III dataset. This was achieved through the use of Clinical BERT\n(Alsentzer et al., 2019). embeddings and text augmentation and label balancing\nto improve F1 scores for both ICD Chapter as well as ICD disease codes. We\nattribute the improved performance mainly to the use of novel text augmentation\nto shuffle the order of sentences during training. In comparison to the Top-32\nICD code prediction (Keyang Xu, et. al.) with an F1 score of 0.76, we achieve a\nfinal F1 score of 0.75 but on a total of the top 50 ICD codes.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 14:53:21 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Biseda", "Brent", ""], ["Desai", "Gaurav", ""], ["Lin", "Haifeng", ""], ["Philip", "Anish", ""]]}, {"id": "2008.10522", "submitter": "Peter beim Graben", "authors": "Peter Klimczak, G\\\"unther Wirsching and Peter beim Graben", "title": "Machine Semiotics", "comments": "37 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their satisfactory speech recognition capabilities, current speech\nassistive devices still lack suitable automatic semantic analysis capabilities\nas well as useful representation of pragmatic world knowledge. Instead, current\ntechnologies require users to learn keywords necessary to effectively operate\nand work with a machine. Such a machine-centered approach can be frustrating\nfor users. However, recognizing a basic difference between the semiotics of\nhumans and machines presents a possibility to overcome this shortcoming: For\nthe machine, the meaning of a (human) utterance is defined by its own scope of\nactions. Machines, thus, do not need to understand the meanings of individual\nwords, nor the meaning of phrasal and sentence semantics that combine\nindividual word meanings with additional implicit world knowledge. For speech\nassistive devices, the learning of machine specific meanings of human\nutterances by trial and error should be sufficient. Using the trivial example\nof a cognitive heating device, we show that -- based on dynamic semantics --\nthis process can be formalized as the learning of utterance-meaning pairs\n(UMP). This is followed by a detailed semiotic contextualization of the\npreviously generated signs.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 15:49:54 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Klimczak", "Peter", ""], ["Wirsching", "G\u00fcnther", ""], ["Graben", "Peter beim", ""]]}, {"id": "2008.10570", "submitter": "Morteza Ziyadi", "authors": "Morteza Ziyadi, Yuting Sun, Abhishek Goswami, Jade Huang, and Weizhu\n  Chen", "title": "Example-Based Named Entity Recognition", "comments": "15 pages, 6 figures, 5 tables with appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to named entity recognition (NER) in the presence\nof scarce data that we call example-based NER. Our train-free few-shot learning\napproach takes inspiration from question-answering to identify entity spans in\na new and unseen domain. In comparison with the current state-of-the-art, the\nproposed method performs significantly better, especially when using a low\nnumber of support examples.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 17:18:24 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Ziyadi", "Morteza", ""], ["Sun", "Yuting", ""], ["Goswami", "Abhishek", ""], ["Huang", "Jade", ""], ["Chen", "Weizhu", ""]]}, {"id": "2008.10648", "submitter": "Chujie Zheng", "authors": "Chujie Zheng, Harry Jiannan Wang, Kunpeng Zhang, Ling Fan", "title": "A Baseline Analysis for Podcast Abstractive Summarization", "comments": "Accepted for PodRecs: The Workshop on Podcast Recommendations\n  (online), 25th September 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Podcast summary, an important factor affecting end-users' listening\ndecisions, has often been considered a critical feature in podcast\nrecommendation systems, as well as many downstream applications. Existing\nabstractive summarization approaches are mainly built on fine-tuned models on\nprofessionally edited texts such as CNN and DailyMail news. Different from\nnews, podcasts are often longer, more colloquial and conversational, and\nnoisier with contents on commercials and sponsorship, which makes automatic\npodcast summarization extremely challenging. This paper presents a baseline\nanalysis of podcast summarization using the Spotify Podcast Dataset provided by\nTREC 2020. It aims to help researchers understand current state-of-the-art\npre-trained models and hence build a foundation for creating better models.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 18:38:42 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 01:32:36 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Zheng", "Chujie", ""], ["Wang", "Harry Jiannan", ""], ["Zhang", "Kunpeng", ""], ["Fan", "Ling", ""]]}, {"id": "2008.10762", "submitter": "Jing Yi Xie", "authors": "Jing Yi Xie, Graeme Hirst, Yang Xu", "title": "Contextualized moral inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing moral awareness in intelligent systems has shifted from a topic of\nphilosophical inquiry to a critical and practical issue in artificial\nintelligence over the past decades. However, automated inference of everyday\nmoral situations remains an under-explored problem. We present a text-based\napproach that predicts people's intuitive judgment of moral vignettes. Our\nmethodology builds on recent work in contextualized language models and textual\ninference of moral sentiment. We show that a contextualized representation\noffers a substantial advantage over alternative representations based on word\nembeddings and emotion sentiment in inferring human moral judgment, evaluated\nand reflected in three independent datasets from moral psychology. We discuss\nthe promise and limitations of our approach toward automated textual moral\nreasoning.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 00:34:28 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Xie", "Jing Yi", ""], ["Hirst", "Graeme", ""], ["Xu", "Yang", ""]]}, {"id": "2008.10813", "submitter": "Ningyu Zhang", "authors": "Ningyu Zhang, Qianghuai Jia, Kangping Yin, Liang Dong, Feng Gao,\n  Nengwei Hua", "title": "Conceptualized Representation Learning for Chinese Biomedical Text\n  Mining", "comments": "WSDM2020 Health Day", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biomedical text mining is becoming increasingly important as the number of\nbiomedical documents and web data rapidly grows. Recently, word representation\nmodels such as BERT has gained popularity among researchers. However, it is\ndifficult to estimate their performance on datasets containing biomedical texts\nas the word distributions of general and biomedical corpora are quite\ndifferent. Moreover, the medical domain has long-tail concepts and\nterminologies that are difficult to be learned via language models. For the\nChinese biomedical text, it is more difficult due to its complex structure and\nthe variety of phrase combinations. In this paper, we investigate how the\nrecently introduced pre-trained language model BERT can be adapted for Chinese\nbiomedical corpora and propose a novel conceptualized representation learning\napproach. We also release a new Chinese Biomedical Language Understanding\nEvaluation benchmark (\\textbf{ChineseBLUE}). We examine the effectiveness of\nChinese pre-trained models: BERT, BERT-wwm, RoBERTa, and our approach.\nExperimental results on the benchmark show that our approach could bring\nsignificant gain. We release the pre-trained model on GitHub:\nhttps://github.com/alibaba-research/ChineseBLUE.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 04:41:35 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Zhang", "Ningyu", ""], ["Jia", "Qianghuai", ""], ["Yin", "Kangping", ""], ["Dong", "Liang", ""], ["Gao", "Feng", ""], ["Hua", "Nengwei", ""]]}, {"id": "2008.10820", "submitter": "Danny Suarez Vargas", "authors": "Danny Suarez Vargas, Lucas R. C. Pessutto, and Viviane Pereira Moreira", "title": "Simple Unsupervised Similarity-Based Aspect Extraction", "comments": "12 pages, 3 figures, paper to be published in 20th International\n  Conference on Computational Linguistics and Intelligent Text Processing\n  (CICLing 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of sentiment analysis, there has been growing interest in\nperforming a finer granularity analysis focusing on the specific aspects of the\nentities being evaluated. This is the goal of Aspect-Based Sentiment Analysis\n(ABSA) which basically involves two tasks: aspect extraction and polarity\ndetection. The first task is responsible for discovering the aspects mentioned\nin the review text and the second task assigns a sentiment orientation\n(positive, negative, or neutral) to that aspect. Currently, the\nstate-of-the-art in ABSA consists of the application of deep learning methods\nsuch as recurrent, convolutional and attention neural networks. The limitation\nof these techniques is that they require a lot of training data and are\ncomputationally expensive. In this paper, we propose a simple approach called\nSUAEx for aspect extraction. SUAEx is unsupervised and relies solely on the\nsimilarity of word embeddings. Experimental results on datasets from three\ndifferent domains have shown that SUAEx achieves results that can outperform\nthe state-of-the-art attention-based approach at a fraction of the time.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 04:58:07 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Vargas", "Danny Suarez", ""], ["Pessutto", "Lucas R. C.", ""], ["Moreira", "Viviane Pereira", ""]]}, {"id": "2008.10835", "submitter": "Chenhan Zhang", "authors": "Chenhan Zhang", "title": "Complicating the Social Networks for Better Storytelling: An Empirical\n  Study of Chinese Historical Text and Novel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital humanities is an important subject because it enables developments in\nhistory, literature, and films. In this paper, we perform an empirical study of\na Chinese historical text, Records of the Three Kingdoms (\\textit{Records}),\nand a historical novel of the same story, Romance of the Three Kingdoms\n(\\textit{Romance}). We employ natural language processing techniques to extract\ncharacters and their relationships. Then, we characterize the social networks\nand sentiments of the main characters in the historical text and the historical\nnovel. We find that the social network in \\textit{Romance} is more complex and\ndynamic than that of \\textit{Records}, and the influence of the main characters\ndiffers. These findings shed light on the different styles of storytelling in\nthe two literary genres and how the historical novel complicates the social\nnetworks of characters to enrich the literariness of the story.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 06:03:14 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Zhang", "Chenhan", ""]]}, {"id": "2008.10856", "submitter": "Maryam Habibi", "authors": "Maryam Habibi, Johannes Starlinger, Ulf Leser", "title": "TabSim: A Siamese Neural Network for Accurate Estimation of Table\n  Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tables are a popular and efficient means of presenting structured\ninformation. They are used extensively in various kinds of documents including\nweb pages. Tables display information as a two-dimensional matrix, the\nsemantics of which is conveyed by a mixture of structure (rows, columns),\nheaders, caption, and content. Recent research has started to consider tables\nas first class objects, not just as an addendum to texts, yielding interesting\nresults for problems like table matching, table completion, or value\nimputation. All of these problems inherently rely on an accurate measure for\nthe semantic similarity of two tables. We present TabSim, a novel method to\ncompute table similarity scores using deep neural networks. Conceptually,\nTabSim represents a table as a learned concatenation of embeddings of its\ncaption, its content, and its structure. Given two tables in this\nrepresentation, a Siamese neural network is trained to compute a score\ncorrelating with the tables' semantic similarity. To train and evaluate our\nmethod, we created a gold standard corpus consisting of 1500 table pairs\nextracted from biomedical articles and manually scored regarding their degree\nof similarity, and adopted two other corpora originally developed for a\ndifferent yet similar task. Our evaluation shows that TabSim outperforms other\ntable similarity measures on average by app. 7% pp F1-score in a binary\nsimilarity classification setting and by app. 1.5% pp in a ranking scenario.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 07:32:09 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Habibi", "Maryam", ""], ["Starlinger", "Johannes", ""], ["Leser", "Ulf", ""]]}, {"id": "2008.10873", "submitter": "Saja Khaled Tawalbeh", "authors": "Saja Tawalbeh and Mohammad AL-Smadi", "title": "Is this sentence valid? An Arabic Dataset for Commonsense Validation", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The commonsense understanding and validation remains a challenging task in\nthe field of natural language understanding. Therefore, several research papers\nhave been published that studied the capability of proposed systems to evaluate\nthe models ability to validate commonsense in text. In this paper, we present a\nbenchmark Arabic dataset for commonsense understanding and validation as well\nas a baseline research and models trained using the same dataset. To the best\nof our knowledge, this dataset is considered as the first in the field of\nArabic text commonsense validation. The dataset is distributed under the\nCreative Commons BY-SA 4.0 license and can be found on GitHub.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 08:15:55 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Tawalbeh", "Saja", ""], ["AL-Smadi", "Mohammad", ""]]}, {"id": "2008.10875", "submitter": "Ginevra Carbone", "authors": "Ginevra Carbone, Gabriele Sarti", "title": "ETC-NLG: End-to-end Topic-Conditioned Natural Language Generation", "comments": null, "journal-ref": "Italian Journal of Computational Linguistics (IJCoL 2021)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Plug-and-play language models (PPLMs) enable topic-conditioned natural\nlanguage generation by pairing large pre-trained generators with attribute\nmodels used to steer the predicted token distribution towards the selected\ntopic. Despite their computational efficiency, PPLMs require large amounts of\nlabeled texts to effectively balance generation fluency and proper\nconditioning, making them unsuitable for low-resource settings. We present\nETC-NLG, an approach leveraging topic modeling annotations to enable\nfully-unsupervised End-to-end Topic-Conditioned Natural Language Generation\nover emergent topics in unlabeled document collections. We first test the\neffectiveness of our approach in a low-resource setting for Italian, evaluating\nthe conditioning for both topic models and gold annotations. We then perform a\ncomparative evaluation of ETC-NLG for Italian and English using a parallel\ncorpus. Finally, we propose an automatic approach to estimate the effectiveness\nof conditioning on the generated utterances.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 08:22:38 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 08:29:42 GMT"}, {"version": "v3", "created": "Tue, 22 Jun 2021 08:45:23 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Carbone", "Ginevra", ""], ["Sarti", "Gabriele", ""]]}, {"id": "2008.10889", "submitter": "Ruqing Zhang", "authors": "Ruqing Zhang, Jiafeng Guo, Yixing Fan, Yanyan Lan, and Xueqi Cheng", "title": "Query Understanding via Intent Description Generation", "comments": "Accepted as Long Research Paper in CIKM2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Query understanding is a fundamental problem in information retrieval (IR),\nwhich has attracted continuous attention through the past decades. Many\ndifferent tasks have been proposed for understanding users' search queries,\ne.g., query classification or query clustering. However, it is not that precise\nto understand a search query at the intent class/cluster level due to the loss\nof many detailed information. As we may find in many benchmark datasets, e.g.,\nTREC and SemEval, queries are often associated with a detailed description\nprovided by human annotators which clearly describes its intent to help\nevaluate the relevance of the documents. If a system could automatically\ngenerate a detailed and precise intent description for a search query, like\nhuman annotators, that would indicate much better query understanding has been\nachieved. In this paper, therefore, we propose a novel\nQuery-to-Intent-Description (Q2ID) task for query understanding. Unlike those\nexisting ranking tasks which leverage the query and its description to compute\nthe relevance of documents, Q2ID is a reverse task which aims to generate a\nnatural language intent description based on both relevant and irrelevant\ndocuments of a given query. To address this new task, we propose a novel\nContrastive Generation model, namely CtrsGen for short, to generate the intent\ndescription by contrasting the relevant documents with the irrelevant documents\ngiven a query. We demonstrate the effectiveness of our model by comparing with\nseveral state-of-the-art generation models on the Q2ID task. We discuss the\npotential usage of such Q2ID technique through an example application.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 08:56:40 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Zhang", "Ruqing", ""], ["Guo", "Jiafeng", ""], ["Fan", "Yixing", ""], ["Lan", "Yanyan", ""], ["Cheng", "Xueqi", ""]]}, {"id": "2008.10906", "submitter": "Mahdi Mohseni", "authors": "Mahdi Mohseni, Volker Gast, Christoph Redies", "title": "Comparative Computational Analysis of Global Structure in Canonical,\n  Non-Canonical and Non-Literary Texts", "comments": "30 pages + 7 pages supplementary material, 5 figures", "journal-ref": "https://www.frontiersin.org/articles/10.3389/fpsyg.2021.599063/full?&utm_source=Email_to_authors_&utm_medium=Email&utm_content=T1_11.5e1_author&utm_campaign=Email_publication&field=&journalName=Frontiers_in_Psychology&id=599063", "doi": "10.3389/fpsyg.2021.599063", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study investigates global properties of literary and non-literary texts.\nWithin the literary texts, a distinction is made between canonical and\nnon-canonical works. The central hypothesis of the study is that the three text\ntypes (non-literary, literary/canonical and literary/non-canonical) exhibit\nsystematic differences with respect to structural design features as correlates\nof aesthetic responses in readers. To investigate these differences, we\ncompiled a corpus containing texts of the three categories of interest, the\nJena Textual Aesthetics Corpus. Two aspects of global structure are\ninvestigated, variability and self-similar (fractal) patterns, which reflect\nlong-range correlations along texts. We use four types of basic observations,\n(i) the frequency of POS-tags per sentence, (ii) sentence length, (iii) lexical\ndiversity in chunks of text, and (iv) the distribution of topic probabilities\nin chunks of texts. These basic observations are grouped into two more general\ncategories, (a) the low-level properties (i) and (ii), which are observed at\nthe level of the sentence (reflecting linguistic decoding), and (b) the\nhigh-level properties (iii) and (iv), which are observed at the textual level\n(reflecting comprehension). The basic observations are transformed into time\nseries, and these time series are subject to multifractal detrended fluctuation\nanalysis (MFDFA). Our results show that low-level properties of texts are\nbetter discriminators than high-level properties, for the three text types\nunder analysis. Canonical literary texts differ from non-canonical ones\nprimarily in terms of variability. Fractality seems to be a universal feature\nof text, more pronounced in non-literary than in literary texts. Beyond the\nspecific results of the study, we intend to open up new perspectives on the\nexperimental study of textual aesthetics.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 09:37:06 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Mohseni", "Mahdi", ""], ["Gast", "Volker", ""], ["Redies", "Christoph", ""]]}, {"id": "2008.10984", "submitter": "Martin Radfar", "authors": "Martin Radfar, Athanasios Mouchtaris, and Siegfried Kunzmann", "title": "End-to-End Neural Transformer Based Spoken Language Understanding", "comments": "Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken language understanding (SLU) refers to the process of inferring the\nsemantic information from audio signals. While the neural transformers\nconsistently deliver the best performance among the state-of-the-art neural\narchitectures in field of natural language processing (NLP), their merits in a\nclosely related field, i.e., spoken language understanding (SLU) have not beed\ninvestigated. In this paper, we introduce an end-to-end neural\ntransformer-based SLU model that can predict the variable-length domain,\nintent, and slots vectors embedded in an audio signal with no intermediate\ntoken prediction architecture. This new architecture leverages the\nself-attention mechanism by which the audio signal is transformed to various\nsub-subspaces allowing to extract the semantic context implied by an utterance.\nOur end-to-end transformer SLU predicts the domains, intents and slots in the\nFluent Speech Commands dataset with accuracy equal to 98.1 \\%, 99.6 \\%, and\n99.6 \\%, respectively and outperforms the SLU models that leverage a\ncombination of recurrent and convolutional neural networks by 1.4 \\% while the\nsize of our model is 25\\% smaller than that of these architectures.\nAdditionally, due to independent sub-space projections in the self-attention\nlayer, the model is highly parallelizable which makes it a good candidate for\non-device SLU.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 22:58:20 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Radfar", "Martin", ""], ["Mouchtaris", "Athanasios", ""], ["Kunzmann", "Siegfried", ""]]}, {"id": "2008.11015", "submitter": "Mengyu Zhou", "authors": "Mengyu Zhou, Qingtao Li, Xinyi He, Yuejiang Li, Yibo Liu, Wei Ji, Shi\n  Han, Yining Chen, Daxin Jiang, Dongmei Zhang", "title": "Table2Charts: Recommending Charts by Learning Shared Table\n  Representations", "comments": "9 + 2(appendix) pages, accepted by KDD'21 conference", "journal-ref": null, "doi": "10.1145/3447548.3467279", "report-no": null, "categories": "cs.DB cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is common for people to create different types of charts to explore a\nmulti-dimensional dataset (table). However, to recommend commonly composed\ncharts in real world, one should take the challenges of efficiency, imbalanced\ndata and table context into consideration. In this paper, we propose\nTable2Charts framework which learns common patterns from a large corpus of\n(table, charts) pairs. Based on deep Q-learning with copying mechanism and\nheuristic searching, Table2Charts does table-to-sequence generation, where each\nsequence follows a chart template. On a large spreadsheet corpus with 165k\ntables and 266k charts, we show that Table2Charts could learn a shared\nrepresentation of table fields so that recommendation tasks on different chart\ntypes could mutually enhance each other. Table2Charts outperforms other chart\nrecommendation systems in both multi-type task (with doubled recall numbers\nR@3=0.61 and R@1=0.43) and human evaluations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2020 15:06:26 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 18:21:42 GMT"}, {"version": "v3", "created": "Sun, 6 Jun 2021 14:08:32 GMT"}, {"version": "v4", "created": "Mon, 28 Jun 2021 11:57:20 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Zhou", "Mengyu", ""], ["Li", "Qingtao", ""], ["He", "Xinyi", ""], ["Li", "Yuejiang", ""], ["Liu", "Yibo", ""], ["Ji", "Wei", ""], ["Han", "Shi", ""], ["Chen", "Yining", ""], ["Jiang", "Daxin", ""], ["Zhang", "Dongmei", ""]]}, {"id": "2008.11045", "submitter": "No\\'e Tits", "authors": "No\\'e Tits, Kevin El Haddad and Thierry Dutoit", "title": "ICE-Talk: an Interface for a Controllable Expressive Talking Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ICE-Talk is an open source web-based GUI that allows the use of a TTS system\nwith controllable parameters via a text field and a clickable 2D plot. It\nenables the study of latent spaces for controllable TTS. Moreover it is\nimplemented as a module that can be used as part of a Human-Agent interaction.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 14:17:10 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Tits", "No\u00e9", ""], ["Haddad", "Kevin El", ""], ["Dutoit", "Thierry", ""]]}, {"id": "2008.11053", "submitter": "Martin Docekal", "authors": "Martin Docekal, Martin Fajcik, Josef Jon, Pavel Smrz", "title": "JokeMeter at SemEval-2020 Task 7: Convolutional humor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes our system that was designed for Humor evaluation within\nthe SemEval-2020 Task 7. The system is based on convolutional neural network\narchitecture. We investigate the system on the official dataset, and we provide\nmore insight to model itself to see how the learned inner features look.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 14:27:58 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Docekal", "Martin", ""], ["Fajcik", "Martin", ""], ["Jon", "Josef", ""], ["Smrz", "Pavel", ""]]}, {"id": "2008.11081", "submitter": "Amanuel Alambo", "authors": "Amanuel Alambo, Ryan Andrew, Sid Gollarahalli, Jacqueline Vaughn,\n  Tanvi Banerjee, Krishnaprasad Thirunarayan, Daniel Abrams, Nirmish Shah", "title": "Measuring Pain in Sickle Cell Disease using Clinical Text", "comments": "The 42nd Annual International Conference of the IEEE Engineering in\n  Medicine and Biology Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sickle Cell Disease (SCD) is a hereditary disorder of red blood cells in\nhumans. Complications such as pain, stroke, and organ failure occur in SCD as\nmalformed, sickled red blood cells passing through small blood vessels get\ntrapped. Particularly, acute pain is known to be the primary symptom of SCD.\nThe insidious and subjective nature of SCD pain leads to challenges in pain\nassessment among Medical Practitioners (MPs). Thus, accurate identification of\nmarkers of pain in patients with SCD is crucial for pain management.\nClassifying clinical notes of patients with SCD based on their pain level\nenables MPs to give appropriate treatment. We propose a binary classification\nmodel to predict pain relevance of clinical notes and a multiclass\nclassification model to predict pain level. While our four binary machine\nlearning (ML) classifiers are comparable in their performance, Decision Trees\nhad the best performance for the multiclass classification task achieving 0.70\nin F-measure. Our results show the potential clinical text analysis and machine\nlearning offer to pain management in sickle cell patients.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2020 23:39:57 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Alambo", "Amanuel", ""], ["Andrew", "Ryan", ""], ["Gollarahalli", "Sid", ""], ["Vaughn", "Jacqueline", ""], ["Banerjee", "Tanvi", ""], ["Thirunarayan", "Krishnaprasad", ""], ["Abrams", "Daniel", ""], ["Shah", "Nirmish", ""]]}, {"id": "2008.11183", "submitter": "Vladimir Vargas-Calder\\'on", "authors": "Vladimir Vargas-Calder\\'on and Juan S. Fl\\'orez and Leonel F. Ardila\n  and Nicolas Parra-A. and Jorge E. Camargo and Nelson Vargas", "title": "Learning from students' perception on professors through opinion mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Students' perception of classes measured through their opinions on teaching\nsurveys allows to identify deficiencies and problems, both in the environment\nand in the learning methodologies. The purpose of this paper is to study,\nthrough sentiment analysis using natural language processing (NLP) and machine\nlearning (ML) techniques, those opinions in order to identify topics that are\nrelevant for students, as well as predicting the associated sentiment via\npolarity analysis. As a result, it is implemented, trained and tested two\nalgorithms to predict the associated sentiment as well as the relevant topics\nof such opinions. The combination of both approaches then becomes useful to\nidentify specific properties of the students' opinions associated with each\nsentiment label (positive, negative or neutral opinions) and topic.\nFurthermore, we explore the possibility that students' perception surveys are\ncarried out without closed questions, relying on the information that students\ncan provide through open questions where they express their opinions about\ntheir classes.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 17:36:45 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Vargas-Calder\u00f3n", "Vladimir", ""], ["Fl\u00f3rez", "Juan S.", ""], ["Ardila", "Leonel F.", ""], ["Parra-A.", "Nicolas", ""], ["Camargo", "Jorge E.", ""], ["Vargas", "Nelson", ""]]}, {"id": "2008.11228", "submitter": "Anna Kruspe", "authors": "Anna Kruspe", "title": "A simple method for domain adaptation of sentence embeddings", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.22173.26085", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained sentence embeddings have been shown to be very useful for a\nvariety of NLP tasks. Due to the fact that training such embeddings requires a\nlarge amount of data, they are commonly trained on a variety of text data. An\nadaptation to specific domains could improve results in many cases, but such a\nfinetuning is usually problem-dependent and poses the risk of over-adapting to\nthe data used for adaptation. In this paper, we present a simple universal\nmethod for finetuning Google's Universal Sentence Encoder (USE) using a Siamese\narchitecture. We demonstrate how to use this approach for a variety of data\nsets and present results on different data sets representing similar problems.\nThe approach is also compared to traditional finetuning on these data sets. As\na further advantage, the approach can be used for combining data sets with\ndifferent annotations. We also present an embedding finetuned on all data sets\nin parallel.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 18:31:08 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Kruspe", "Anna", ""]]}, {"id": "2008.11257", "submitter": "Alberto Poncelas", "authors": "Alberto Poncelas, Pintu Lohar, Andy Way, James Hadley", "title": "The Impact of Indirect Machine Translation on Sentiment Classification", "comments": null, "journal-ref": "Proceedings of Association for Machine Translation in the\n  Americas, AMTA (2020)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment classification has been crucial for many natural language\nprocessing (NLP) applications, such as the analysis of movie reviews, tweets,\nor customer feedback. A sufficiently large amount of data is required to build\na robust sentiment classification system. However, such resources are not\nalways available for all domains or for all languages.\n  In this work, we propose employing a machine translation (MT) system to\ntranslate customer feedback into another language to investigate in which cases\ntranslated sentences can have a positive or negative impact on an automatic\nsentiment classifier. Furthermore, as performing a direct translation is not\nalways possible, we explore the performance of automatic classifiers on\nsentences that have been translated using a pivot MT system.\n  We conduct several experiments using the above approaches to analyse the\nperformance of our proposed sentiment classification system and discuss the\nadvantages and drawbacks of classifying translated sentences.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 20:30:21 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Poncelas", "Alberto", ""], ["Lohar", "Pintu", ""], ["Way", "Andy", ""], ["Hadley", "James", ""]]}, {"id": "2008.11290", "submitter": "Athar Sefid", "authors": "Athar Sefid, Clyde Lee Giles, Prasenjit Mitra", "title": "Extractive Summarizer for Scholarly Articles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an extractive method that will summarize long scientific papers.\nOur model uses presentation slides provided by the authors of the papers as the\ngold summary standard to label the sentences. The sentences are ranked based on\ntheir novelty and their importance as estimated by deep neural networks. Our\nwindow-based extractive labeling of sentences results in the improvement of at\nleast 4 ROUGE1-Recall points.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 22:08:34 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Sefid", "Athar", ""], ["Giles", "Clyde Lee", ""], ["Mitra", "Prasenjit", ""]]}, {"id": "2008.11293", "submitter": "Byron Wallace", "authors": "Byron C. Wallace, Sayantan Saha, Frank Soboczenski, Iain J. Marshall", "title": "Generating (Factual?) Narrative Summaries of RCTs: Experiments with\n  Neural Multi-Document Summarization", "comments": "11 pages, 2 figures. Accepted for presentation at the 2021 AMIA\n  Informatics Summit", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of automatically generating a narrative biomedical\nevidence summary from multiple trial reports. We evaluate modern neural models\nfor abstractive summarization of relevant article abstracts from systematic\nreviews previously conducted by members of the Cochrane collaboration, using\nthe authors conclusions section of the review abstract as our target. We enlist\nmedical professionals to evaluate generated summaries, and we find that modern\nsummarization systems yield consistently fluent and relevant synopses, but that\nthey are not always factual. We propose new approaches that capitalize on\ndomain-specific models to inform summarization, e.g., by explicitly demarcating\nsnippets of inputs that convey key findings, and emphasizing the reports of\nlarge and high-quality trials. We find that these strategies modestly improve\nthe factual accuracy of generated summaries. Finally, we propose a new method\nfor automatically evaluating the factuality of generated narrative evidence\nsyntheses using models that infer the directionality of reported findings.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 22:22:50 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 16:50:27 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Wallace", "Byron C.", ""], ["Saha", "Sayantan", ""], ["Soboczenski", "Frank", ""], ["Marshall", "Iain J.", ""]]}, {"id": "2008.11295", "submitter": "Alexander Shvets", "authors": "Alexander Shvets and Leo Wanner", "title": "Concept Extraction Using Pointer-Generator Networks", "comments": "Contribution to the Proceedings of the 22nd International Conference\n  on Knowledge Engineering and Knowledge Management (EKAW 2020). A link to the\n  final authenticated publication will be added once it is available online.\n  Keywords: Open-domain discourse texts, Concept extraction, Pointer-generator\n  neural network, Distant supervision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Concept extraction is crucial for a number of downstream applications.\nHowever, surprisingly enough, straightforward single token/nominal\nchunk-concept alignment or dictionary lookup techniques such as DBpedia\nSpotlight still prevail. We propose a generic open-domain OOV-oriented\nextractive model that is based on distant supervision of a pointer-generator\nnetwork leveraging bidirectional LSTMs and a copy mechanism. The model has been\ntrained on a large annotated corpus compiled specifically for this task from\n250K Wikipedia pages, and tested on regular pages, where the pointers to other\npages are considered as ground truth concepts. The outcome of the experiments\nshows that our model significantly outperforms standard techniques and, when\nused on top of DBpedia Spotlight, further improves its performance. The\nexperiments furthermore show that the model can be readily ported to other\ndatasets on which it equally achieves a state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 22:28:14 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Shvets", "Alexander", ""], ["Wanner", "Leo", ""]]}, {"id": "2008.11398", "submitter": "Gaurav Singh", "authors": "Gaurav Singh", "title": "Decision Tree J48 at SemEval-2020 Task 9: Sentiment Analysis for\n  Code-Mixed Social Media Text (Hinglish)", "comments": "5 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the design of the system used for providing a solution\nfor the problem given at SemEval-2020 Task 9 where sentiment analysis of\ncode-mixed language Hindi and English needed to be performed. This system uses\nWeka as a tool for providing the classifier for the classification of tweets\nand python is used for loading the data from the files provided and cleaning\nit. Only part of the training data was provided to the system for classifying\nthe tweets in the test data set on which evaluation of the system was done. The\nsystem performance was assessed using the official competition evaluation\nmetric F1-score. Classifier was trained on two sets of training data which\nresulted in F1 scores of 0.4972 and 0.5316.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 06:30:43 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Singh", "Gaurav", ""]]}, {"id": "2008.11488", "submitter": "WanHong Huang", "authors": "Wanhong Huang", "title": "Machine learning approach of Japanese composition scoring and writing\n  aided system's design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic scoring system is extremely complex for any language. Because\nnatural language itself is a complex model. When we evaluate articles generated\nby natural language, we need to view the articles from many dimensions such as\nword features, grammatical features, semantic features, text structure and so\non. Even human beings sometimes can't accurately grade a composition because\ndifferent people have different opinions about the same article. But a\ncomposition scoring system can greatly assist language learners. It can make\nlanguage leaner improve themselves in the process of output something. Though\nit is still difficult for machines to directly evaluate a composition at the\nsemantic and pragmatic levels, especially for Japanese, Chinese and other\nlanguage in high context cultures, we can make machine evaluate a passage in\nword and grammar levels, which can as an assistance of composition rater or\nlanguage learner. Especially for foreign language learners, lexical and\nsyntactic content are usually what they are more concerned about. In our\nexperiments, we did the follows works: 1) We use word segmentation tools and\ndictionaries to achieve word segmentation of an article, and extract word\nfeatures, as well as generate a words' complexity feature of an article. And\nBow technique are used to extract the theme features. 2) We designed a\nTuring-complete automata model and create 300+ automatons for the grammars that\nappear in the JLPT examination. And extract grammars features by using these\nautomatons. 3) We propose a statistical approach for scoring a specify theme of\ncomposition, the final score will depend on all the writings that submitted to\nthe system. 4) We design an grammar hint function for language leaner, so that\nthey can know currently what grammars they can use.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 11:01:13 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Huang", "Wanhong", ""]]}, {"id": "2008.11567", "submitter": "Jieming Zhu", "authors": "Kelong Mao, Xi Xiao, Jieming Zhu, Biao Lu, Ruiming Tang, Xiuqiang He", "title": "Item Tagging for Information Retrieval: A Tripartite Graph Neural\n  Network based Approach", "comments": "Accepted by SIGIR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tagging has been recognized as a successful practice to boost relevance\nmatching for information retrieval (IR), especially when items lack rich\ntextual descriptions. A lot of research has been done for either multi-label\ntext categorization or image annotation. However, there is a lack of published\nwork that targets at item tagging specifically for IR. Directly applying a\ntraditional multi-label classification model for item tagging is sub-optimal,\ndue to the ignorance of unique characteristics in IR. In this work, we propose\nto formulate item tagging as a link prediction problem between item nodes and\ntag nodes. To enrich the representation of items, we leverage the query logs\navailable in IR tasks, and construct a query-item-tag tripartite graph. This\nformulation results in a TagGNN model that utilizes heterogeneous graph neural\nnetworks with multiple types of nodes and edges. Different from previous\nresearch, we also optimize both full tag prediction and partial tag completion\ncases in a unified framework via a primary-dual loss mechanism. Experimental\nresults on both open and industrial datasets show that our TagGNN approach\noutperforms the state-of-the-art multi-label classification approaches.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 13:58:19 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Mao", "Kelong", ""], ["Xiao", "Xi", ""], ["Zhu", "Jieming", ""], ["Lu", "Biao", ""], ["Tang", "Ruiming", ""], ["He", "Xiuqiang", ""]]}, {"id": "2008.11573", "submitter": "Selim F{\\i}rat Y{\\i}lmaz", "authors": "Selim F. Yilmaz, E. Batuhan Kaynak, Aykut Ko\\c{c}, Hamdi\n  Dibeklio\\u{g}lu and Suleyman S. Kozat", "title": "Multi-Label Sentiment Analysis on 100 Languages with Dynamic Weighting\n  for Label Imbalance", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate cross-lingual sentiment analysis, which has attracted\nsignificant attention due to its applications in various areas including market\nresearch, politics and social sciences. In particular, we introduce a sentiment\nanalysis framework in multi-label setting as it obeys Plutchik wheel of\nemotions. We introduce a novel dynamic weighting method that balances the\ncontribution from each class during training, unlike previous static weighting\nmethods that assign non-changing weights based on their class frequency.\nMoreover, we adapt the focal loss that favors harder instances from\nsingle-label object recognition literature to our multi-label setting.\nFurthermore, we derive a method to choose optimal class-specific thresholds\nthat maximize the macro-f1 score in linear time complexity. Through an\nextensive set of experiments, we show that our method obtains the\nstate-of-the-art performance in 7 of 9 metrics in 3 different languages using a\nsingle model compared to the common baselines and the best-performing methods\nin the SemEval competition. We publicly share our code for our model, which can\nperform sentiment analysis in 100 languages, to facilitate further research.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 14:16:02 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Yilmaz", "Selim F.", ""], ["Kaynak", "E. Batuhan", ""], ["Ko\u00e7", "Aykut", ""], ["Dibeklio\u011flu", "Hamdi", ""], ["Kozat", "Suleyman S.", ""]]}, {"id": "2008.11584", "submitter": "Vladimir Ivanov", "authors": "Dmitry Grigorev, Vladimir Ivanov", "title": "Inno at SemEval-2020 Task 11: Leveraging Pure Transformer for\n  Multi-Class Propaganda Detection", "comments": "7 pages, SEMEVAL TASK 11, COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper presents the solution of team \"Inno\" to a SEMEVAL 2020 task 11\n\"Detection of propaganda techniques in news articles\". The goal of the second\nsubtask is to classify textual segments that correspond to one of the 18 given\npropaganda techniques in news articles dataset. We tested a pure\nTransformer-based model with an optimized learning scheme on the ability to\ndistinguish propaganda techniques between each other. Our model showed 0.6 and\n0.58 overall F1 score on validation set and test set accordingly and non-zero\nF1 score on each class on both sets.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 14:42:14 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 09:01:38 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Grigorev", "Dmitry", ""], ["Ivanov", "Vladimir", ""]]}, {"id": "2008.11608", "submitter": "Daniel Loureiro", "authors": "Daniel Loureiro, Kiamehr Rezaee, Mohammad Taher Pilehvar, Jose\n  Camacho-Collados", "title": "Analysis and Evaluation of Language Models for Word Sense Disambiguation", "comments": "55 pages, accepted to Computational Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer-based language models have taken many fields in NLP by storm.\nBERT and its derivatives dominate most of the existing evaluation benchmarks,\nincluding those for Word Sense Disambiguation (WSD), thanks to their ability in\ncapturing context-sensitive semantic nuances. However, there is still little\nknowledge about their capabilities and potential limitations in encoding and\nrecovering word senses. In this article, we provide an in-depth quantitative\nand qualitative analysis of the celebrated BERT model with respect to lexical\nambiguity. One of the main conclusions of our analysis is that BERT can\naccurately capture high-level sense distinctions, even when a limited number of\nexamples is available for each word sense. Our analysis also reveals that in\nsome cases language models come close to solving coarse-grained noun\ndisambiguation under ideal conditions in terms of availability of training data\nand computing resources. However, this scenario rarely occurs in real-world\nsettings and, hence, many practical challenges remain even in the\ncoarse-grained setting. We also perform an in-depth comparison of the two main\nlanguage model based WSD strategies, i.e., fine-tuning and feature extraction,\nfinding that the latter approach is more robust with respect to sense bias and\nit can better exploit limited available training data. In fact, the simple\nfeature extraction strategy of averaging contextualized embeddings proves\nrobust even using only three training sentences per word sense, with minimal\nimprovements obtained by increasing the size of this training data.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 15:07:07 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 11:46:01 GMT"}, {"version": "v3", "created": "Wed, 17 Mar 2021 19:16:39 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Loureiro", "Daniel", ""], ["Rezaee", "Kiamehr", ""], ["Pilehvar", "Mohammad Taher", ""], ["Camacho-Collados", "Jose", ""]]}, {"id": "2008.11649", "submitter": "Masataro Asai", "authors": "Masataro Asai, Zilu Tang", "title": "Discrete Word Embedding for Logical Natural Language Understanding", "comments": "equal contribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an unsupervised neural model for learning a discrete embedding of\nwords. Unlike existing discrete embeddings, our binary embedding supports\nvector arithmetic operations similar to continuous embeddings. Our embedding\nrepresents each word as a set of propositional statements describing a\ntransition rule in classical/STRIPS planning formalism. This makes the\nembedding directly compatible with symbolic, state of the art classical\nplanning solvers.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 16:15:18 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 14:37:59 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Asai", "Masataro", ""], ["Tang", "Zilu", ""]]}, {"id": "2008.11708", "submitter": "Yiding Wang", "authors": "Yiding Wang, Zhenyi Wang, Chenghao Li, Yilin Zhang, Haizhou Wang", "title": "A Multitask Deep Learning Approach for User Depression Detection on Sina\n  Weibo", "comments": "23 pages, 32 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, due to the mental burden of depression, the number of people\nwho endanger their lives has been increasing rapidly. The online social network\n(OSN) provides researchers with another perspective for detecting individuals\nsuffering from depression. However, existing studies of depression detection\nbased on machine learning still leave relatively low classification\nperformance, suggesting that there is significant improvement potential for\nimprovement in their feature engineering. In this paper, we manually build a\nlarge dataset on Sina Weibo (a leading OSN with the largest number of active\nusers in the Chinese community), namely Weibo User Depression Detection Dataset\n(WU3D). It includes more than 20,000 normal users and more than 10,000\ndepressed users, both of which are manually labeled and rechecked by\nprofessionals. By analyzing the user's text, social behavior, and posted\npictures, ten statistical features are concluded and proposed. In the meantime,\ntext-based word features are extracted using the popular pretrained model\nXLNet. Moreover, a novel deep neural network classification model, i.e.\nFusionNet (FN), is proposed and simultaneously trained with the above-extracted\nfeatures, which are seen as multiple classification tasks. The experimental\nresults show that FusionNet achieves the highest F1-Score of 0.9772 on the test\ndataset. Compared to existing studies, our proposed method has better\nclassification performance and robustness for unbalanced training samples. Our\nwork also provides a new way to detect depression on other OSN platforms.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 17:53:17 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Wang", "Yiding", ""], ["Wang", "Zhenyi", ""], ["Li", "Chenghao", ""], ["Zhang", "Yilin", ""], ["Wang", "Haizhou", ""]]}, {"id": "2008.11785", "submitter": "Guy Marshall", "authors": "Guy Clarke Marshall, Caroline Jay and Andr\\'e Freitas", "title": "Understanding scholarly Natural Language Processing system diagrams\n  through application of the Richards-Engelhardt framework", "comments": "16 pages, 5 figures, pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We utilise Richards-Engelhardt framework as a tool for understanding Natural\nLanguage Processing systems diagrams. Through four examples from scholarly\nproceedings, we find that the application of the framework to this ecological\nand complex domain is effective for reflecting on these diagrams. We argue for\nvocabulary to describe multiple-codings, semiotic variability, and\ninconsistency or misuse of visual encoding principles in diagrams. Further, for\napplication to scholarly Natural Language Processing systems, and perhaps\nsystems diagrams more broadly, we propose the addition of \"Grouping by Object\"\nas a new visual encoding principle, and \"Emphasising\" as a new visual encoding\ntype.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 20:06:30 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Marshall", "Guy Clarke", ""], ["Jay", "Caroline", ""], ["Freitas", "Andr\u00e9", ""]]}, {"id": "2008.11825", "submitter": "Wei Zhao", "authors": "Wei Zhao, Tarun Joshi, Vijayan N. Nair, and Agus Sudjianto", "title": "SHAP values for Explaining CNN-based Text Classification Models", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are increasingly used in natural language processing\n(NLP) models. However, the need to interpret and explain the results from\ncomplex algorithms are limiting their widespread adoption in regulated\nindustries such as banking. There has been recent work on interpretability of\nmachine learning algorithms with structured data. But there are only limited\ntechniques for NLP applications where the problem is more challenging due to\nthe size of the vocabulary, high-dimensional nature, and the need to consider\ntextual coherence and language structure. This paper develops a methodology to\ncompute SHAP values for local explainability of CNN-based text classification\nmodels. The approach is also extended to compute global scores to assess the\nimportance of features. The results are illustrated on sentiment analysis of\nAmazon Electronic Review data.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 21:28:41 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 01:27:41 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Zhao", "Wei", ""], ["Joshi", "Tarun", ""], ["Nair", "Vijayan N.", ""], ["Sudjianto", "Agus", ""]]}, {"id": "2008.11841", "submitter": "Paul Egr\\'e", "authors": "Paul Egr\\'e, Benjamin Spector, Ad\\`ele Mortier, Steven Verheyen", "title": "On the Optimality of Vagueness: \"Around\", \"Between\", and the Gricean\n  Maxims", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Why is our language vague? We argue that in contexts in which a cooperative\nspeaker is not perfectly informed about the world, the use of vague expressions\ncan offer an optimal tradeoff between truthfulness (Gricean Quality) and\ninformativeness (Gricean Quantity). Focusing on expressions of approximation\nsuch as \"around\", which are semantically vague, we show that they allow the\nspeaker to convey indirect probabilistic information, in a way that gives the\nlistener a more accurate representation of the information available to the\nspeaker than any more precise expression would (intervals of the form\n\"between\"). We give a probabilistic treatment of the interpretation of\n\"around\", and offer a model for the interpretation and use of\n\"around\"-statements within the Rational Speech Act (RSA) framework. Our model\ndiffers in substantive ways from the Lexical Uncertainty model often used\nwithin the RSA framework for vague predicates.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 21:57:25 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 21:46:45 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Egr\u00e9", "Paul", ""], ["Spector", "Benjamin", ""], ["Mortier", "Ad\u00e8le", ""], ["Verheyen", "Steven", ""]]}, {"id": "2008.11869", "submitter": "Xinsong Zhang", "authors": "Xinsong Zhang, Pengshuai Li, and Hang Li", "title": "AMBERT: A Pre-trained Language Model with Multi-Grained Tokenization", "comments": "To be appeared in Findings of ACL2021. In this version, we develop a\n  simplified method to improve the efficiency of AMBERT in inference, which\n  still performs better than BERT with the same computational cost as BERT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language models such as BERT have exhibited remarkable\nperformances in many tasks in natural language understanding (NLU). The tokens\nin the models are usually fine-grained in the sense that for languages like\nEnglish they are words or sub-words and for languages like Chinese they are\ncharacters. In English, for example, there are multi-word expressions which\nform natural lexical units and thus the use of coarse-grained tokenization also\nappears to be reasonable. In fact, both fine-grained and coarse-grained\ntokenizations have advantages and disadvantages for learning of pre-trained\nlanguage models. In this paper, we propose a novel pre-trained language model,\nreferred to as AMBERT (A Multi-grained BERT), on the basis of both fine-grained\nand coarse-grained tokenizations. For English, AMBERT takes both the sequence\nof words (fine-grained tokens) and the sequence of phrases (coarse-grained\ntokens) as input after tokenization, employs one encoder for processing the\nsequence of words and the other encoder for processing the sequence of the\nphrases, utilizes shared parameters between the two encoders, and finally\ncreates a sequence of contextualized representations of the words and a\nsequence of contextualized representations of the phrases. Experiments have\nbeen conducted on benchmark datasets for Chinese and English, including CLUE,\nGLUE, SQuAD and RACE. The results show that AMBERT can outperform BERT in all\ncases, particularly the improvements are significant for Chinese. We also\ndevelop a method to improve the efficiency of AMBERT in inference, which still\nperforms better than BERT with the same computational cost as BERT.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 00:23:48 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 05:29:27 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 06:53:33 GMT"}, {"version": "v4", "created": "Thu, 27 May 2021 10:39:47 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Zhang", "Xinsong", ""], ["Li", "Pengshuai", ""], ["Li", "Hang", ""]]}, {"id": "2008.11897", "submitter": "Fahimeh Rezazadegan", "authors": "Dana Rezazadegan, Shlomo Berkovsky, Juan C. Quiroz, A. Baki Kocaballi,\n  Ying Wang, Liliana Laranjo, Enrico Coiera", "title": "Automatic Speech Summarisation: A Scoping Review", "comments": "21 Pages, excluding Supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech summarisation techniques take human speech as input and then output an\nabridged version as text or speech. Speech summarisation has applications in\nmany domains from information technology to health care, for example improving\nspeech archives or reducing clinical documentation burden. This scoping review\nmaps the speech summarisation literature, with no restrictions on time frame,\nlanguage summarised, research method, or paper type. We reviewed a total of 110\npapers out of a set of 153 found through a literature search and extracted\nspeech features used, methods, scope, and training corpora. Most studies employ\none of four speech summarisation architectures: (1) Sentence extraction and\ncompaction; (2) Feature extraction and classification or rank-based sentence\nselection; (3) Sentence compression and compression summarisation; and (4)\nLanguage modelling. We also discuss the strengths and weaknesses of these\ndifferent methods and speech features. Overall, supervised methods (e.g. Hidden\nMarkov support vector machines, Ranking support vector machines, Conditional\nrandom fields) performed better than unsupervised methods. As supervised\nmethods require manually annotated training data which can be costly, there was\nmore interest in unsupervised methods. Recent research into unsupervised\nmethods focusses on extending language modelling, for example by combining\nUni-gram modelling with deep neural networks. Protocol registration: The\nprotocol for this scoping review is registered at https://osf.io.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 03:15:40 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Rezazadegan", "Dana", ""], ["Berkovsky", "Shlomo", ""], ["Quiroz", "Juan C.", ""], ["Kocaballi", "A. Baki", ""], ["Wang", "Ying", ""], ["Laranjo", "Liliana", ""], ["Coiera", "Enrico", ""]]}, {"id": "2008.11940", "submitter": "Takeshi Onishi", "authors": "Takeshi Onishi", "title": "Relation/Entity-Centric Reading Comprehension", "comments": "Ph.D. Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing a machine that understands human language is one of the most\nelusive and long-standing challenges in artificial intelligence. This thesis\naddresses this challenge through studies of reading comprehension with a focus\non understanding entities and their relationships. More specifically, we focus\non question answering tasks designed to measure reading comprehension. We focus\non entities and relations because they are typically used to represent the\nsemantics of natural language.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 06:42:18 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Onishi", "Takeshi", ""]]}, {"id": "2008.11970", "submitter": "Qiang Han", "authors": "Qiang Han", "title": "Improvement of a dedicated model for open domain persona-aware dialogue\n  generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper analyzes some speed and performance improvement methods of\nTransformer architecture in recent years, mainly its application in dedicated\nmodel training. The dedicated model studied here refers to the open domain\npersona-aware dialogue generation model, and the dataset is multi turn short\ndialogue, The total length of a single input sequence is no more than 105\ntokens. Therefore, many improvements in the architecture and attention\nmechanism of transformer architecture for long sequence processing are not\ndiscussed in this paper. The source code of the experiments has been open\nsourced: https://github.com/ghosthamlet/persona\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 07:53:47 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Han", "Qiang", ""]]}, {"id": "2008.11972", "submitter": "Yang Deng", "authors": "Yang Deng, Wenxuan Zhang, Wai Lam", "title": "Opinion-aware Answer Generation for Review-driven Question Answering in\n  E-Commerce", "comments": "Accepted by CIKM 2020 (Full Paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Product-related question answering (QA) is an important but challenging task\nin E-Commerce. It leads to a great demand on automatic review-driven QA, which\naims at providing instant responses towards user-posted questions based on\ndiverse product reviews. Nevertheless, the rich information about personal\nopinions in product reviews, which is essential to answer those\nproduct-specific questions, is underutilized in current generation-based\nreview-driven QA studies. There are two main challenges when exploiting the\nopinion information from the reviews to facilitate the opinion-aware answer\ngeneration: (i) jointly modeling opinionated and interrelated information\nbetween the question and reviews to capture important information for answer\ngeneration, (ii) aggregating diverse opinion information to uncover the common\nopinion towards the given question. In this paper, we tackle opinion-aware\nanswer generation by jointly learning answer generation and opinion mining\ntasks with a unified model. Two kinds of opinion fusion strategies, namely,\nstatic and dynamic fusion, are proposed to distill and aggregate important\nopinion information learned from the opinion mining task into the answer\ngeneration process. Then a multi-view pointer-generator network is employed to\ngenerate opinion-aware answers for a given product-related question.\nExperimental results show that our method achieves superior performance in\nreal-world E-Commerce QA datasets, and effectively generate opinionated and\ninformative answers.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 07:54:45 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 05:29:47 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Deng", "Yang", ""], ["Zhang", "Wenxuan", ""], ["Lam", "Wai", ""]]}, {"id": "2008.11986", "submitter": "Diego Molla Aliod", "authors": "Diego Molla, Christopher Jones, and Vincent Nguyen", "title": "Query Focused Multi-document Summarisation of Biomedical Texts", "comments": "14 pages, 7 tables, 3 figures. Accepted at BioASQ workshop, CLEF 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the participation of Macquarie University and the\nAustralian National University for Task B Phase B of the 2020 BioASQ Challenge\n(BioASQ8b). Our overall framework implements Query focused multi-document\nextractive summarisation by applying either a classification or a regression\nlayer to the candidate sentence embeddings and to the comparison between the\nquestion and sentence embeddings. We experiment with variants using BERT and\nBioBERT, Siamese architectures, and reinforcement learning. We observe the best\nresults when BERT is used to obtain the word embeddings, followed by an LSTM\nlayer to obtain sentence embeddings. Variants using Siamese architectures or\nBioBERT did not improve the results.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 08:31:13 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Molla", "Diego", ""], ["Jones", "Christopher", ""], ["Nguyen", "Vincent", ""]]}, {"id": "2008.12009", "submitter": "Ananya B Sai", "authors": "Ananya B. Sai, Akash Kumar Mohankumar, Mitesh M. Khapra", "title": "A Survey of Evaluation Metrics Used for NLG Systems", "comments": "A condensed version of this paper is submitted to ACM CSUR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of Deep Learning has created a surge in interest in a wide a\nrange of Natural Language Generation (NLG) tasks. Deep Learning has not only\npushed the state of the art in several existing NLG tasks but has also\nfacilitated researchers to explore various newer NLG tasks such as image\ncaptioning. Such rapid progress in NLG has necessitated the development of\naccurate automatic evaluation metrics that would allow us to track the progress\nin the field of NLG. However, unlike classification tasks, automatically\nevaluating NLG systems in itself is a huge challenge. Several works have shown\nthat early heuristic-based metrics such as BLEU, ROUGE are inadequate for\ncapturing the nuances in the different NLG tasks. The expanding number of NLG\nmodels and the shortcomings of the current metrics has led to a rapid surge in\nthe number of evaluation metrics proposed since 2014. Moreover, various\nevaluation metrics have shifted from using pre-determined heuristic-based\nformulae to trained transformer models. This rapid change in a relatively short\ntime has led to the need for a survey of the existing NLG metrics to help\nexisting and new researchers to quickly come up to speed with the developments\nthat have happened in NLG evaluation in the last few years. Through this\nsurvey, we first wish to highlight the challenges and difficulties in\nautomatically evaluating NLG systems. Then, we provide a coherent taxonomy of\nthe evaluation metrics to organize the existing metrics and to better\nunderstand the developments in the field. We also describe the different\nmetrics in detail and highlight their key contributions. Later, we discuss the\nmain shortcomings identified in the existing metrics and describe the\nmethodology used to evaluate evaluation metrics. Finally, we discuss our\nsuggestions and recommendations on the next steps forward to improve the\nautomatic evaluation metrics.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 09:25:05 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 17:38:22 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Sai", "Ananya B.", ""], ["Mohankumar", "Akash Kumar", ""], ["Khapra", "Mitesh M.", ""]]}, {"id": "2008.12014", "submitter": "Ilias Chalkidis", "authors": "John Koutsikakis, Ilias Chalkidis, Prodromos Malakasiotis and Ion\n  Androutsopoulos", "title": "GREEK-BERT: The Greeks visiting Sesame Street", "comments": "8 pages, 1 figure, 11th Hellenic Conference on Artificial\n  Intelligence (SETN 2020)", "journal-ref": null, "doi": "10.1145/3411408.3411440", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer-based language models, such as BERT and its variants, have\nachieved state-of-the-art performance in several downstream natural language\nprocessing (NLP) tasks on generic benchmark datasets (e.g., GLUE, SQUAD, RACE).\nHowever, these models have mostly been applied to the resource-rich English\nlanguage. In this paper, we present GREEK-BERT, a monolingual BERT-based\nlanguage model for modern Greek. We evaluate its performance in three NLP\ntasks, i.e., part-of-speech tagging, named entity recognition, and natural\nlanguage inference, obtaining state-of-the-art performance. Interestingly, in\ntwo of the benchmarks GREEK-BERT outperforms two multilingual Transformer-based\nmodels (M-BERT, XLM-R), as well as shallower neural baselines operating on\npre-trained word embeddings, by a large margin (5%-10%). Most importantly, we\nmake both GREEK-BERT and our training code publicly available, along with code\nillustrating how GREEK-BERT can be fine-tuned for downstream NLP tasks. We\nexpect these resources to boost NLP research and applications for modern Greek.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 09:36:14 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 08:41:35 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Koutsikakis", "John", ""], ["Chalkidis", "Ilias", ""], ["Malakasiotis", "Prodromos", ""], ["Androutsopoulos", "Ion", ""]]}, {"id": "2008.12169", "submitter": "Tommi Jauhiainen", "authors": "Tommi Jauhiainen, Heidi Jauhiainen, Niko Partanen and Krister Lind\\'en", "title": "Uralic Language Identification (ULI) 2020 shared task dataset and the\n  Wanca 2017 corpus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article introduces the Wanca 2017 corpus of texts crawled from the\ninternet from which the sentences in rare Uralic languages for the use of the\nUralic Language Identification (ULI) 2020 shared task were collected. We\ndescribe the ULI dataset and how it was constructed using the Wanca 2017 corpus\nand texts in different languages from the Leipzig corpora collection. We also\nprovide baseline language identification experiments conducted using the ULI\n2020 dataset.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 14:57:01 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Jauhiainen", "Tommi", ""], ["Jauhiainen", "Heidi", ""], ["Partanen", "Niko", ""], ["Lind\u00e9n", "Krister", ""]]}, {"id": "2008.12281", "submitter": "Minh Nguyen", "authors": "Minh Nguyen, Gia H. Ngo, Nancy F. Chen", "title": "Domain-shift Conditioning using Adaptable Filtering via Hierarchical\n  Embeddings for Robust Chinese Spell Check", "comments": "Accepted at IEEE/ACM TASLP. Code is available at\n  https://github.com/mnhng/HeadFilt", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spell check is a useful application which processes noisy human-generated\ntext. Spell check for Chinese poses unresolved problems due to the large number\nof characters, the sparse distribution of errors, and the dearth of resources\nwith sufficient coverage of heterogeneous and shifting error domains. For\nChinese spell check, filtering using confusion sets narrows the search space\nand makes finding corrections easier. However, most, if not all, confusion sets\nused to date are fixed and thus do not include new, shifting error domains. We\npropose a scalable adaptable filter that exploits hierarchical character\nembeddings to (1) obviate the need to handcraft confusion sets, and (2) resolve\nsparsity problems related to infrequent errors. Our approach compares favorably\nwith competitive baselines and obtains SOTA results on the 2014 and 2015\nChinese Spelling Check Bake-off datasets.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 17:34:40 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 17:31:56 GMT"}, {"version": "v3", "created": "Sat, 22 May 2021 04:22:39 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Nguyen", "Minh", ""], ["Ngo", "Gia H.", ""], ["Chen", "Nancy F.", ""]]}, {"id": "2008.12283", "submitter": "Kevin Huang", "authors": "Kevin Huang, Guangtao Wang, Tengyu Ma and Jing Huang", "title": "Entity and Evidence Guided Relation Extraction for DocRED", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document-level relation extraction is a challenging task which requires\nreasoning over multiple sentences in order to predict relations in a document.\nIn this paper, we pro-pose a joint training frameworkE2GRE(Entity and Evidence\nGuided Relation Extraction)for this task. First, we introduce entity-guided\nsequences as inputs to a pre-trained language model (e.g. BERT, RoBERTa). These\nentity-guided sequences help a pre-trained language model (LM) to focus on\nareas of the document related to the entity. Secondly, we guide the fine-tuning\nof the pre-trained language model by using its internal attention probabilities\nas additional features for evidence prediction.Our new approach encourages the\npre-trained language model to focus on the entities and supporting/evidence\nsentences. We evaluate our E2GRE approach on DocRED, a recently released\nlarge-scale dataset for relation extraction. Our approach is able to achieve\nstate-of-the-art results on the public leaderboard across all metrics, showing\nthat our E2GRE is both effective and synergistic on relation extraction and\nevidence prediction.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 17:41:23 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Huang", "Kevin", ""], ["Wang", "Guangtao", ""], ["Ma", "Tengyu", ""], ["Huang", "Jing", ""]]}, {"id": "2008.12348", "submitter": "Abigail See", "authors": "Ashwin Paranjape, Abigail See, Kathleen Kenealy, Haojun Li, Amelia\n  Hardy, Peng Qi, Kaushik Ram Sadagopan, Nguyet Minh Phu, Dilara Soylu,\n  Christopher D. Manning", "title": "Neural Generation Meets Real People: Towards Emotionally Engaging\n  Mixed-Initiative Conversations", "comments": "Published in 3rd Proceedings of Alexa Prize (Alexa Prize 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Chirpy Cardinal, an open-domain dialogue agent, as a research\nplatform for the 2019 Alexa Prize competition. Building an open-domain\nsocialbot that talks to real people is challenging - such a system must meet\nmultiple user expectations such as broad world knowledge, conversational style,\nand emotional connection. Our socialbot engages users on their terms -\nprioritizing their interests, feelings and autonomy. As a result, our socialbot\nprovides a responsive, personalized user experience, capable of talking\nknowledgeably about a wide variety of topics, as well as chatting\nempathetically about ordinary life. Neural generation plays a key role in\nachieving these goals, providing the backbone for our conversational and\nemotional tone. At the end of the competition, Chirpy Cardinal progressed to\nthe finals with an average rating of 3.6/5.0, a median conversation duration of\n2 minutes 16 seconds, and a 90th percentile duration of over 12 minutes.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 19:37:27 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 17:14:26 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Paranjape", "Ashwin", ""], ["See", "Abigail", ""], ["Kenealy", "Kathleen", ""], ["Li", "Haojun", ""], ["Hardy", "Amelia", ""], ["Qi", "Peng", ""], ["Sadagopan", "Kaushik Ram", ""], ["Phu", "Nguyet Minh", ""], ["Soylu", "Dilara", ""], ["Manning", "Christopher D.", ""]]}, {"id": "2008.12353", "submitter": "Connor Heaton", "authors": "Connor T. Heaton, Prasenjit Mitra", "title": "Repurposing TREC-COVID Annotations to Answer the Key Questions of\n  CORD-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The novel coronavirus disease 2019 (COVID-19) began in Wuhan, China in late\n2019 and to date has infected over 14M people worldwide, resulting in over\n750,000 deaths. On March 10, 2020 the World Health Organization (WHO) declared\nthe outbreak a global pandemic. Many academics and researchers, not restricted\nto the medical domain, began publishing papers describing new discoveries.\nHowever, with the large influx of publications, it was hard for these\nindividuals to sift through the large amount of data and make sense of the\nfindings. The White House and a group of industry research labs, lead by the\nAllen Institute for AI, aggregated over 200,000 journal articles related to a\nvariety of coronaviruses and tasked the community with answering key questions\nrelated to the corpus, releasing the dataset as CORD-19. The information\nretrieval (IR) community repurposed the journal articles within CORD-19 to more\nclosely resemble a classic TREC-style competition, dubbed TREC-COVID, with\nhuman annotators providing relevancy judgements at the end of each round of\ncompetition. Seeing the related endeavors, we set out to repurpose the\nrelevancy annotations for TREC-COVID tasks to identify journal articles in\nCORD-19 which are relevant to the key questions posed by CORD-19. A BioBERT\nmodel trained on this repurposed dataset prescribes relevancy annotations for\nCORD-19 tasks that have an overall agreement of 0.4430 with majority human\nannotations in terms of Cohen's kappa. We present the methodology used to\nconstruct the new dataset and describe the decision process used throughout.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 19:51:07 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Heaton", "Connor T.", ""], ["Mitra", "Prasenjit", ""]]}, {"id": "2008.12360", "submitter": "Connor Heaton", "authors": "Connor T. Heaton, David M. Schwartz", "title": "Language Models as Emotional Classifiers for Textual Conversations", "comments": null, "journal-ref": null, "doi": "10.1145/3394171.3413755", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotions play a critical role in our everyday lives by altering how we\nperceive, process and respond to our environment. Affective computing aims to\ninstill in computers the ability to detect and act on the emotions of human\nactors. A core aspect of any affective computing system is the classification\nof a user's emotion. In this study we present a novel methodology for\nclassifying emotion in a conversation. At the backbone of our proposed\nmethodology is a pre-trained Language Model (LM), which is supplemented by a\nGraph Convolutional Network (GCN) that propagates information over the\npredicate-argument structure identified in an utterance. We apply our proposed\nmethodology on the IEMOCAP and Friends data sets, achieving state-of-the-art\nperformance on the former and a higher accuracy on certain emotional labels on\nthe latter. Furthermore, we examine the role context plays in our methodology\nby altering how much of the preceding conversation the model has access to when\nmaking a classification.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 20:04:30 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Heaton", "Connor T.", ""], ["Schwartz", "David M.", ""]]}, {"id": "2008.12448", "submitter": "Md Abul Bashar", "authors": "Md Abul Bashar, Richi Nayak", "title": "QutNocturnal@HASOC'19: CNN for Hate Speech and Offensive Content\n  Identification in Hindi Language", "comments": null, "journal-ref": "CEUR Workshop Proceedings. Working Notes of FIRE 2019 - Forum for\n  Information Retrieval Evaluation. Vol. 2517. Sun SITE Central Europe,\n  Germany, pp. 237-245", "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe our top-team solution to Task 1 for Hindi in the HASOC contest\norganised by FIRE 2019. The task is to identify hate speech and offensive\nlanguage in Hindi. More specifically, it is a binary classification problem\nwhere a system is required to classify tweets into two classes: (a) \\emph{Hate\nand Offensive (HOF)} and (b) \\emph{Not Hate or Offensive (NOT)}. In contrast to\nthe popular idea of pretraining word vectors (a.k.a. word embedding) with a\nlarge corpus from a general domain such as Wikipedia, we used a relatively\nsmall collection of relevant tweets (i.e. random and sarcasm tweets in Hindi\nand Hinglish) for pretraining. We trained a Convolutional Neural Network (CNN)\non top of the pretrained word vectors. This approach allowed us to be ranked\nfirst for this task out of all teams. Our approach could easily be adapted to\nother applications where the goal is to predict class of a text when the\nprovided context is limited.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 02:44:17 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Bashar", "Md Abul", ""], ["Nayak", "Richi", ""]]}, {"id": "2008.12452", "submitter": "Md Abul Bashar", "authors": "Md Abul Bashar, Richi Nayak, Nicolas Suzor, Bridget Weir", "title": "Misogynistic Tweet Detection: Modelling CNN with Small Datasets", "comments": null, "journal-ref": "Australasian Conference on Data Mining. Springer. 3--16, 2018", "doi": "10.1007/978-981-13-6661-1_1", "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online abuse directed towards women on the social media platform Twitter has\nattracted considerable attention in recent years. An automated method to\neffectively identify misogynistic abuse could improve our understanding of the\npatterns, driving factors, and effectiveness of responses associated with\nabusive tweets over a sustained time period. However, training a neural network\n(NN) model with a small set of labelled data to detect misogynistic tweets is\ndifficult. This is partly due to the complex nature of tweets which contain\nmisogynistic content, and the vast number of parameters needed to be learned in\na NN model. We have conducted a series of experiments to investigate how to\ntrain a NN model to detect misogynistic tweets effectively. In particular, we\nhave customised and regularised a Convolutional Neural Network (CNN)\narchitecture and shown that the word vectors pre-trained on a task-specific\ndomain can be used to train a CNN model effectively when a small set of\nlabelled data is available. A CNN model trained in this way yields an improved\naccuracy over the state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 02:59:22 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Bashar", "Md Abul", ""], ["Nayak", "Richi", ""], ["Suzor", "Nicolas", ""], ["Weir", "Bridget", ""]]}, {"id": "2008.12520", "submitter": "Noa Garcia", "authors": "Noa Garcia, Chentao Ye, Zihua Liu, Qingtao Hu, Mayu Otani, Chenhui\n  Chu, Yuta Nakashima, Teruko Mitamura", "title": "A Dataset and Baselines for Visual Question Answering on Art", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering questions related to art pieces (paintings) is a difficult task, as\nit implies the understanding of not only the visual information that is shown\nin the picture, but also the contextual knowledge that is acquired through the\nstudy of the history of art. In this work, we introduce our first attempt\ntowards building a new dataset, coined AQUA (Art QUestion Answering). The\nquestion-answer (QA) pairs are automatically generated using state-of-the-art\nquestion generation methods based on paintings and comments provided in an\nexisting art understanding dataset. The QA pairs are cleansed by crowdsourcing\nworkers with respect to their grammatical correctness, answerability, and\nanswers' correctness. Our dataset inherently consists of visual\n(painting-based) and knowledge (comment-based) questions. We also present a\ntwo-branch model as baseline, where the visual and knowledge questions are\nhandled independently. We extensively compare our baseline model against the\nstate-of-the-art models for question answering, and we provide a comprehensive\nstudy about the challenges and potential future directions for visual question\nanswering on art.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 07:33:30 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Garcia", "Noa", ""], ["Ye", "Chentao", ""], ["Liu", "Zihua", ""], ["Hu", "Qingtao", ""], ["Otani", "Mayu", ""], ["Chu", "Chenhui", ""], ["Nakashima", "Yuta", ""], ["Mitamura", "Teruko", ""]]}, {"id": "2008.12548", "submitter": "Yangming Zhou", "authors": "Tingting Cai, Yangming Zhou, Hong Zheng", "title": "Cost-Quality Adaptive Active Learning for Chinese Clinical Named Entity\n  Recognition", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical Named Entity Recognition (CNER) aims to automatically identity\nclinical terminologies in Electronic Health Records (EHRs), which is a\nfundamental and crucial step for clinical research. To train a high-performance\nmodel for CNER, it usually requires a large number of EHRs with high-quality\nlabels. However, labeling EHRs, especially Chinese EHRs, is time-consuming and\nexpensive. One effective solution to this is active learning, where a model\nasks labelers to annotate data which the model is uncertain of. Conventional\nactive learning assumes a single labeler that always replies noiseless answers\nto queried labels. However, in real settings, multiple labelers provide diverse\nquality of annotation with varied costs and labelers with low overall\nannotation quality can still assign correct labels for some specific instances.\nIn this paper, we propose a Cost-Quality Adaptive Active Learning (CQAAL)\napproach for CNER in Chinese EHRs, which maintains a balance between the\nannotation quality, labeling costs, and the informativeness of selected\ninstances. Specifically, CQAAL selects cost-effective instance-labeler pairs to\nachieve better annotation quality with lower costs in an adaptive manner.\nComputational results on the CCKS-2017 Task 2 benchmark dataset demonstrate the\nsuperiority and effectiveness of the proposed CQAAL.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 09:27:43 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Cai", "Tingting", ""], ["Zhou", "Yangming", ""], ["Zheng", "Hong", ""]]}, {"id": "2008.12552", "submitter": "Yashank Singh", "authors": "Yashank Singh, Niladri Chatterjee", "title": "Temporal Random Indexing of Context Vectors Applied to Event Detection", "comments": "8 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore new representations for encoding language data. The\ngeneral method of one-hot encoding grows linearly with the size of the word\ncorpus in space-complexity. We address this by using Random Indexing(RI) of\ncontext vectors with non-zero entries. We propose a novel RI representation\nwhere we exploit the effect imposing a probability distribution on the number\nof randomized entries which leads to a class of RI representations. We also\npropose an algorithm that is log linear in the size of word corpus to track the\nsemantic relationship of the query word to other words for suggesting the\nevents that are relevant to the word in question. Finally we run simulations on\nthe novel RI representations using the proposed algorithms for tweets relevant\nto the word \"iPhone\" and present results. The RI representation is shown to be\nfaster and space efficient as compared to BoW embeddings.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 09:37:39 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 13:51:27 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Singh", "Yashank", ""], ["Chatterjee", "Niladri", ""]]}, {"id": "2008.12579", "submitter": "Andrea Madotto Mr", "authors": "Andrea Madotto, Zhaojiang Lin, Yejin Bang, Pascale Fung", "title": "The Adapter-Bot: All-In-One Controllable Conversational Model", "comments": "Andrea Madotto and Zhaojiang Lin contributed equally to this work.\n  Video demo: https://www.youtube.com/watch?v=Jz8KWE_gKH0&feature=youtu.be", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considerable progress has been made towards conversational models that\ngenerate coherent and fluent responses by training large language models on\nlarge dialogue datasets. These models have little or no control of the\ngenerated responses and miss two important features: continuous dialogue skills\nintegration and seamlessly leveraging diverse knowledge sources. In this paper,\nwe propose the Adapter-Bot, a dialogue model that uses a fixed backbone\nconversational model such as DialGPT (Zhang et al., 2019) and triggers\non-demand dialogue skills (e.g., emphatic response, weather information, movie\nrecommendation) via different adapters (Houlsby et al., 2019). Each adapter can\nbe trained independently, thus allowing a continual integration of skills\nwithout retraining the entire model. Depending on the skills, the model is able\nto process multiple knowledge types, such as text, tables, and graphs, in a\nseamless manner. The dialogue skills can be triggered automatically via a\ndialogue manager, or manually, thus allowing high-level control of the\ngenerated responses. At the current stage, we have implemented 12 response\nstyles (e.g., positive, negative etc.), 8 goal-oriented skills (e.g. weather\ninformation, movie recommendation, etc.), and personalized and emphatic\nresponses. We evaluate our model using automatic evaluation by comparing it\nwith existing state-of-the-art conversational models, and we have released an\ninteractive system at adapter.bot.ust.hk.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 10:59:31 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 02:44:30 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Madotto", "Andrea", ""], ["Lin", "Zhaojiang", ""], ["Bang", "Yejin", ""], ["Fung", "Pascale", ""]]}, {"id": "2008.12704", "submitter": "Siliang Tang", "authors": "Siliang Tang, Qi Zhang, Tianpeng Zheng, Mengdi Zhou, Zhan Chen, Lixing\n  Shen, Xiang Ren, Yueting Zhuang, Shiliang Pu and Fei Wu", "title": "Two Step Joint Model for Drug Drug Interaction Extraction", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When patients need to take medicine, particularly taking more than one kind\nof drug simultaneously, they should be alarmed that there possibly exists\ndrug-drug interaction. Interaction between drugs may have a negative impact on\npatients or even cause death. Generally, drugs that conflict with a specific\ndrug (or label drug) are usually described in its drug label or package insert.\nSince more and more new drug products come into the market, it is difficult to\ncollect such information by manual. We take part in the Drug-Drug Interaction\n(DDI) Extraction from Drug Labels challenge of Text Analysis Conference (TAC)\n2018, choosing task1 and task2 to automatically extract DDI related mentions\nand DDI relations respectively. Instead of regarding task1 as named entity\nrecognition (NER) task and regarding task2 as relation extraction (RE) task\nthen solving it in a pipeline, we propose a two step joint model to detect DDI\nand it's related mentions jointly. A sequence tagging system (CNN-GRU\nencoder-decoder) finds precipitants first and search its fine-grained Trigger\nand determine the DDI for each precipitant in the second step. Moreover, a rule\nbased model is built to determine the sub-type for pharmacokinetic interation.\nOur system achieved best result in both task1 and task2. F-measure reaches 0.46\nin task1 and 0.40 in task2.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 15:30:08 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Tang", "Siliang", ""], ["Zhang", "Qi", ""], ["Zheng", "Tianpeng", ""], ["Zhou", "Mengdi", ""], ["Chen", "Zhan", ""], ["Shen", "Lixing", ""], ["Ren", "Xiang", ""], ["Zhuang", "Yueting", ""], ["Pu", "Shiliang", ""], ["Wu", "Fei", ""]]}, {"id": "2008.12742", "submitter": "Jose Manuel Gomez-Perez", "authors": "Ronald Denaux and Jose Manuel Gomez-Perez", "title": "Linked Credibility Reviews for Explainable Misinformation Detection", "comments": "Accepted to the 19th International Semantic Web Conference (ISWC\n  2020) https://iswc2020.semanticweb.org", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, misinformation on the Web has become increasingly rampant.\nThe research community has responded by proposing systems and challenges, which\nare beginning to be useful for (various subtasks of) detecting misinformation.\nHowever, most proposed systems are based on deep learning techniques which are\nfine-tuned to specific domains, are difficult to interpret and produce results\nwhich are not machine readable. This limits their applicability and adoption as\nthey can only be used by a select expert audience in very specific settings. In\nthis paper we propose an architecture based on a core concept of Credibility\nReviews (CRs) that can be used to build networks of distributed bots that\ncollaborate for misinformation detection. The CRs serve as building blocks to\ncompose graphs of (i) web content, (ii) existing credibility signals\n--fact-checked claims and reputation reviews of websites--, and (iii)\nautomatically computed reviews. We implement this architecture on top of\nlightweight extensions to Schema.org and services providing generic NLP tasks\nfor semantic similarity and stance detection. Evaluations on existing datasets\nof social-media posts, fake news and political speeches demonstrates several\nadvantages over existing systems: extensibility, domain-independence,\ncomposability, explainability and transparency via provenance. Furthermore, we\nobtain competitive results without requiring finetuning and establish a new\nstate of the art on the Clef'18 CheckThat! Factuality task.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 16:55:43 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Denaux", "Ronald", ""], ["Gomez-Perez", "Jose Manuel", ""]]}, {"id": "2008.12804", "submitter": "Martin Faj\\v{c}\\'ik", "authors": "Martin Fajcik, Josef Jon, Pavel Smrz", "title": "Rethinking the Objectives of Extractive Question Answering", "comments": "final preprint version (added manual analysis, code & results,\n  experiments with MLP similarity, complexity analysis, conditional objective)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work demonstrates that, contrary to a common belief, using the objective\nwith independence assumption for modelling the span probability $P(a_s,a_e) =\nP(a_s)P(a_e)$ of span starting at position $a_s$ and ending at position $a_e$\nhas adverse effects. Therefore we propose multiple approaches to modelling\njoint probability $P(a_s,a_e)$ directly. Among those, we propose a compound\nobjective, composed from the joint probability while still keeping the\nobjective with independence assumption as an auxiliary objective. We find that\nthe compound objective is consistently superior or equal to other assumptions\nin exact match. Additionally, we identified common errors caused by the\nassumption of independence and manually checked the counterpart predictions,\ndemonstrating the impact of the compound objective on the real examples. Our\nfindings are supported via experiments with three extractive QA models (BIDAF,\nBERT, ALBERT) over six datasets and our code, individual results and manual\nanalysis are available online.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 18:22:19 GMT"}, {"version": "v2", "created": "Thu, 31 Dec 2020 15:04:42 GMT"}, {"version": "v3", "created": "Mon, 19 Jul 2021 13:24:01 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Fajcik", "Martin", ""], ["Jon", "Josef", ""], ["Smrz", "Pavel", ""]]}, {"id": "2008.12813", "submitter": "Sanxing Chen", "authors": "Sanxing Chen, Xiaodong Liu, Jianfeng Gao, Jian Jiao, Ruofei Zhang and\n  Yangfeng Ji", "title": "HittER: Hierarchical Transformers for Knowledge Graph Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines the challenging problem of learning representations of\nentities and relations in a complex multi-relational knowledge graph. We\npropose HittER, a Hierarchical Transformer model to jointly learn\nEntity-relation composition and Relational contextualization based on a source\nentity's neighborhood. Our proposed model consists of two different Transformer\nblocks: the bottom block extracts features of each entity-relation pair in the\nlocal neighborhood of the source entity and the top block aggregates the\nrelational information from the outputs of the bottom block. We further design\na masked entity prediction task to balance information from the relational\ncontext and the source entity itself. Evaluated on the task of link prediction,\nour approach achieves new state-of-the-art results on two standard benchmark\ndatasets FB15K-237 and WN18RR.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 18:58:15 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Chen", "Sanxing", ""], ["Liu", "Xiaodong", ""], ["Gao", "Jianfeng", ""], ["Jiao", "Jian", ""], ["Zhang", "Ruofei", ""], ["Ji", "Yangfeng", ""]]}, {"id": "2008.12842", "submitter": "Rahul Ragesh", "authors": "Rahul Ragesh, Sundararajan Sellamanickam, Arun Iyer, Ram Bairi, Vijay\n  Lingam", "title": "HeteGCN: Heterogeneous Graph Convolutional Networks for Text\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning efficient and inductive graph\nconvolutional networks for text classification with a large number of examples\nand features. Existing state-of-the-art graph embedding based methods such as\npredictive text embedding (PTE) and TextGCN have shortcomings in terms of\npredictive performance, scalability and inductive capability. To address these\nlimitations, we propose a heterogeneous graph convolutional network (HeteGCN)\nmodeling approach that unites the best aspects of PTE and TextGCN together. The\nmain idea is to learn feature embeddings and derive document embeddings using a\nHeteGCN architecture with different graphs used across layers. We simplify\nTextGCN by dissecting into several HeteGCN models which (a) helps to study the\nusefulness of individual models and (b) offers flexibility in fusing learned\nembeddings from different models. In effect, the number of model parameters is\nreduced significantly, enabling faster training and improving performance in\nsmall labeled training set scenario. Our detailed experimental studies\ndemonstrate the efficacy of the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 12:24:35 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Ragesh", "Rahul", ""], ["Sellamanickam", "Sundararajan", ""], ["Iyer", "Arun", ""], ["Bairi", "Ram", ""], ["Lingam", "Vijay", ""]]}, {"id": "2008.12854", "submitter": "Anh Nguyen Tuan", "authors": "Anh Tuan Nguyen", "title": "TATL at W-NUT 2020 Task 2: A Transformer-based Baseline System for\n  Identification of Informative COVID-19 English Tweets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the COVID-19 outbreak continues to spread throughout the world, more and\nmore information about the pandemic has been shared publicly on social media.\nFor example, there are a huge number of COVID-19 English Tweets daily on\nTwitter. However, the majority of those Tweets are uninformative, and hence it\nis important to be able to automatically select only the informative ones for\ndownstream applications. In this short paper, we present our participation in\nthe W-NUT 2020 Shared Task 2: Identification of Informative COVID-19 English\nTweets. Inspired by the recent advances in pretrained Transformer language\nmodels, we propose a simple yet effective baseline for the task. Despite its\nsimplicity, our proposed approach shows very competitive results in the\nleaderboard as we ranked 8 over 56 teams participated in total.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 21:27:42 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Nguyen", "Anh Tuan", ""]]}, {"id": "2008.12875", "submitter": "Raul Arrabales", "authors": "Ra\\'ul Arrabales", "title": "Perla: A Conversational Agent for Depression Screening in Digital\n  Ecosystems. Design, Implementation and Validation", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most depression assessment tools are based on self-report questionnaires,\nsuch as the Patient Health Questionnaire (PHQ-9). These psychometric\ninstruments can be easily adapted to an online setting by means of electronic\nforms. However, this approach lacks the interacting and engaging features of\nmodern digital environments. With the aim of making depression screening more\navailable, attractive and effective, we developed Perla, a conversational agent\nable to perform an interview based on the PHQ-9. We also conducted a validation\nstudy in which we compared the results obtained by the traditional self-report\nquestionnaire with Perla's automated interview. Analyzing the results from this\nstudy we draw two significant conclusions: firstly, Perla is much preferred by\nInternet users, achieving more than 2.5 times more reach than a traditional\nform-based questionnaire; secondly, her psychometric properties (Cronbach's\nalpha of 0.81, sensitivity of 96% and specificity of 90%) are excellent and\ncomparable to the traditional well-established depression screening\nquestionnaires.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 23:09:04 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 10:00:45 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Arrabales", "Ra\u00fal", ""]]}, {"id": "2008.12878", "submitter": "Hai Wang", "authors": "Hai Wang", "title": "Knowledge Efficient Deep Learning for Natural Language Processing", "comments": "Ph.D thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has become the workhorse for a wide range of natural language\nprocessing applications. But much of the success of deep learning relies on\nannotated examples. Annotation is time-consuming and expensive to produce at\nscale. Here we are interested in methods for reducing the required quantity of\nannotated data -- by making the learning methods more knowledge efficient so as\nto make them more applicable in low annotation (low resource) settings. There\nare various classical approaches to making the models more knowledge efficient\nsuch as multi-task learning, transfer learning, weakly supervised and\nunsupervised learning etc. This thesis focuses on adapting such classical\nmethods to modern deep learning models and algorithms.\n  This thesis describes four works aimed at making machine learning models more\nknowledge efficient. First, we propose a knowledge rich deep learning model\n(KRDL) as a unifying learning framework for incorporating prior knowledge into\ndeep models. In particular, we apply KRDL built on Markov logic networks to\ndenoise weak supervision. Second, we apply a KRDL model to assist the machine\nreading models to find the correct evidence sentences that can support their\ndecision. Third, we investigate the knowledge transfer techniques in\nmultilingual setting, where we proposed a method that can improve pre-trained\nmultilingual BERT based on the bilingual dictionary. Fourth, we present an\nepisodic memory network for language modelling, in which we encode the large\nexternal knowledge for the pre-trained GPT.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 23:32:33 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Wang", "Hai", ""]]}, {"id": "2008.12914", "submitter": "Mittul Singh", "authors": "Hemant Kathania, Mittul Singh, Tam\\'as Gr\\'osz, Mikko Kurimo", "title": "Data augmentation using prosody and false starts to recognize non-native\n  children's speech", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes AaltoASR's speech recognition system for the INTERSPEECH\n2020 shared task on Automatic Speech Recognition (ASR) for non-native\nchildren's speech. The task is to recognize non-native speech from children of\nvarious age groups given a limited amount of speech. Moreover, the speech being\nspontaneous has false starts transcribed as partial words, which in the test\ntranscriptions leads to unseen partial words. To cope with these two\nchallenges, we investigate a data augmentation-based approach. Firstly, we\napply the prosody-based data augmentation to supplement the audio data.\nSecondly, we simulate false starts by introducing partial-word noise in the\nlanguage modeling corpora creating new words. Acoustic models trained on\nprosody-based augmented data outperform the models using the baseline recipe or\nthe SpecAugment-based augmentation. The partial-word noise also helps to\nimprove the baseline language model. Our ASR system, a combination of these\nschemes, is placed third in the evaluation period and achieves the word error\nrate of 18.71%. Post-evaluation period, we observe that increasing the amounts\nof prosody-based augmented data leads to better performance. Furthermore,\nremoving low-confidence-score words from hypotheses can lead to further gains.\nThese two improvements lower the ASR error rate to 17.99%.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 05:32:32 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Kathania", "Hemant", ""], ["Singh", "Mittul", ""], ["Gr\u00f3sz", "Tam\u00e1s", ""], ["Kurimo", "Mikko", ""]]}, {"id": "2008.12918", "submitter": "Can Xu", "authors": "Linxiao Li, Can Xu, Wei Wu, Yufan Zhao, Xueliang Zhao, Chongyang Tao", "title": "Zero-Resource Knowledge-Grounded Dialogue Generation", "comments": "Accepted by NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural conversation models have shown great potentials towards\ngenerating informative and engaging responses via introducing external\nknowledge, learning such a model often requires knowledge-grounded dialogues\nthat are difficult to obtain. To overcome the data challenge and reduce the\ncost of building a knowledge-grounded dialogue system, we explore the problem\nunder a zero-resource setting by assuming no context-knowledge-response triples\nare needed for training. To this end, we propose representing the knowledge\nthat bridges a context and a response and the way that the knowledge is\nexpressed as latent variables, and devise a variational approach that can\neffectively estimate a generation model from a dialogue corpus and a knowledge\ncorpus that are independent with each other. Evaluation results on three\nbenchmarks of knowledge-grounded dialogue generation indicate that our model\ncan achieve comparable performance with state-of-the-art methods that rely on\nknowledge-grounded dialogues for training, and exhibits a good generalization\nability over different topics and different datasets.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 05:48:32 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 17:13:10 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Li", "Linxiao", ""], ["Xu", "Can", ""], ["Wu", "Wei", ""], ["Zhao", "Yufan", ""], ["Zhao", "Xueliang", ""], ["Tao", "Chongyang", ""]]}, {"id": "2008.12988", "submitter": "Ran Zmigrod", "authors": "Ran Zmigrod, Tim Vieira, Ryan Cotterell", "title": "Efficient Computation of Expectations under Spanning Tree Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a general framework for inference in spanning tree models. We propose\nunified algorithms for the important cases of first-order expectations and\nsecond-order expectations in edge-factored, non-projective spanning-tree\nmodels. Our algorithms exploit a fundamental connection between gradients and\nexpectations, which allows us to derive efficient algorithms. These algorithms\nare easy to implement with or without automatic differentiation software. We\nmotivate the development of our framework with several \\emph{cautionary tales}\nof previous research, which has developed numerous inefficient algorithms for\ncomputing expectations and their gradients. We demonstrate how our framework\nefficiently computes several quantities with known algorithms, including the\nexpected attachment score, entropy, and generalized expectation criteria. As a\nbonus, we give algorithms for quantities that are missing in the literature,\nincluding the KL divergence. In all cases, our approach matches the efficiency\nof existing algorithms and, in several cases, reduces the runtime complexity by\na factor of the sentence length. We validate the implementation of our\nframework through runtime experiments. We find our algorithms are up to 15 and\n9 times faster than previous algorithms for computing the Shannon entropy and\nthe gradient of the generalized expectation objective, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 14:58:26 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 22:13:01 GMT"}, {"version": "v3", "created": "Wed, 18 Nov 2020 14:52:00 GMT"}, {"version": "v4", "created": "Thu, 25 Mar 2021 10:12:34 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Zmigrod", "Ran", ""], ["Vieira", "Tim", ""], ["Cotterell", "Ryan", ""]]}, {"id": "2008.13012", "submitter": "Gangeshwar Krishnamurthy", "authors": "Gangeshwar Krishnamurthy, Raj Kumar Gupta, Yinping Yang", "title": "SocCogCom at SemEval-2020 Task 11: Characterizing and Detecting\n  Propaganda using Sentence-Level Emotional Salience Features", "comments": "Accepted at SemEval 2020 for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes a system developed for detecting propaganda techniques\nfrom news articles. We focus on examining how emotional salience features\nextracted from a news segment can help to characterize and predict the presence\nof propaganda techniques. Correlation analyses surfaced interesting patterns\nthat, for instance, the \"loaded language\" and \"slogan\" techniques are\nnegatively associated with valence and joy intensity but are positively\nassociated with anger, fear and sadness intensity. In contrast, \"flag waving\"\nand \"appeal to fear-prejudice\" have the exact opposite pattern. Through\npredictive experiments, results further indicate that whereas BERT-only\nfeatures obtained F1-score of 0.548, emotion intensity features and BERT hybrid\nfeatures were able to obtain F1-score of 0.570, when a simple feedforward\nnetwork was used as the classifier in both settings. On gold test data, our\nsystem obtained micro-averaged F1-score of 0.558 on overall detection efficacy\nover fourteen propaganda techniques. It performed relatively well in detecting\n\"loaded language\" (F1 = 0.772), \"name calling and labeling\" (F1 = 0.673),\n\"doubt\" (F1 = 0.604) and \"flag waving\" (F1 = 0.543).\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2020 16:55:29 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Krishnamurthy", "Gangeshwar", ""], ["Gupta", "Raj Kumar", ""], ["Yang", "Yinping", ""]]}, {"id": "2008.13093", "submitter": "Wei Li", "authors": "Wei Li, James Qin, Chung-Cheng Chiu, Ruoming Pang, Yanzhang He", "title": "Parallel Rescoring with Transformer for Streaming On-Device Speech\n  Recognition", "comments": "Proceedings of Interspeech, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances of end-to-end models have outperformed conventional models\nthrough employing a two-pass model. The two-pass model provides better\nspeed-quality trade-offs for on-device speech recognition, where a 1st-pass\nmodel generates hypotheses in a streaming fashion, and a 2nd-pass model\nre-scores the hypotheses with full audio sequence context. The 2nd-pass model\nplays a key role in the quality improvement of the end-to-end model to surpass\nthe conventional model. One main challenge of the two-pass model is the\ncomputation latency introduced by the 2nd-pass model. Specifically, the\noriginal design of the two-pass model uses LSTMs for the 2nd-pass model, which\nare subject to long latency as they are constrained by the recurrent nature and\nhave to run inference sequentially. In this work we explore replacing the LSTM\nlayers in the 2nd-pass rescorer with Transformer layers, which can process the\nentire hypothesis sequences in parallel and can therefore utilize the on-device\ncomputation resources more efficiently. Compared with an LSTM-based baseline,\nour proposed Transformer rescorer achieves more than 50% latency reduction with\nquality improvement.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 05:17:31 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 06:04:36 GMT"}, {"version": "v3", "created": "Wed, 2 Sep 2020 23:05:17 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Li", "Wei", ""], ["Qin", "James", ""], ["Chiu", "Chung-Cheng", ""], ["Pang", "Ruoming", ""], ["He", "Yanzhang", ""]]}, {"id": "2008.13121", "submitter": "Tom Tabak", "authors": "Tom Tabak and Matthew Purver", "title": "Temporal Mental Health Dynamics on Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a set of experiments for building a temporal mental health\ndynamics system. We utilise a pre-existing methodology for distant-supervision\nof mental health data mining from social media platforms and deploy the system\nduring the global COVID-19 pandemic as a case study. Despite the challenging\nnature of the task, we produce encouraging results, both explicit to the global\npandemic and implicit to a global phenomenon, Christmas Depression, supported\nby the literature. We propose a methodology for providing insight into temporal\nmental health dynamics to be utilised for strategic decision-making.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 09:05:11 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 16:50:41 GMT"}, {"version": "v3", "created": "Wed, 2 Sep 2020 12:31:13 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Tabak", "Tom", ""], ["Purver", "Matthew", ""]]}, {"id": "2008.13160", "submitter": "Rabab Alkhalifa", "authors": "Rabab Alkhalifa, Theodore Yoong, Elena Kochkina, Arkaitz Zubiaga and\n  Maria Liakata", "title": "QMUL-SDS at CheckThat! 2020: Determining COVID-19 Tweet Check-Worthiness\n  Using an Enhanced CT-BERT with Numeric Expressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes the participation of the QMUL-SDS team for Task 1 of the\nCLEF 2020 CheckThat! shared task. The purpose of this task is to determine the\ncheck-worthiness of tweets about COVID-19 to identify and prioritise tweets\nthat need fact-checking. The overarching aim is to further support ongoing\nefforts to protect the public from fake news and help people find reliable\ninformation. We describe and analyse the results of our submissions. We show\nthat a CNN using COVID-Twitter-BERT (CT-BERT) enhanced with numeric expressions\ncan effectively boost performance from baseline results. We also show results\nof training data augmentation with rumours on other topics. Our best system\nranked fourth in the task with encouraging outcomes showing potential for\nimproved results in the future.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 13:03:53 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Alkhalifa", "Rabab", ""], ["Yoong", "Theodore", ""], ["Kochkina", "Elena", ""], ["Zubiaga", "Arkaitz", ""], ["Liakata", "Maria", ""]]}, {"id": "2008.13173", "submitter": "Somnath Banerjee", "authors": "Somnath Banerjee, Sahar Ghannay, Sophie Rosset, Anne Vilnat and Paolo\n  Rosso", "title": "LIMSI_UPV at SemEval-2020 Task 9: Recurrent Convolutional Neural Network\n  for Code-mixed Sentiment Analysis", "comments": "To be published in the Proceedings of the 14th International Workshop\n  on Semantic Evaluation (SemEval-2020), Barcelona, Spain, Sep. Association for\n  Computational Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes the participation of LIMSI UPV team in SemEval-2020 Task\n9: Sentiment Analysis for Code-Mixed Social Media Text. The proposed approach\ncompeted in SentiMix Hindi-English subtask, that addresses the problem of\npredicting the sentiment of a given Hindi-English code-mixed tweet. We propose\nRecurrent Convolutional Neural Network that combines both the recurrent neural\nnetwork and the convolutional network to better capture the semantics of the\ntext, for code-mixed sentiment analysis. The proposed system obtained 0.69\n(best run) in terms of F1 score on the given test data and achieved the 9th\nplace (Codalab username: somban) in the SentiMix Hindi-English subtask.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 13:52:24 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Banerjee", "Somnath", ""], ["Ghannay", "Sahar", ""], ["Rosset", "Sophie", ""], ["Vilnat", "Anne", ""], ["Rosso", "Paolo", ""]]}, {"id": "2008.13298", "submitter": "Nirmit Desai", "authors": "Shalisha Witherspoon, Dean Steuer, Graham Bent, Nirmit Desai", "title": "SEEC: Semantic Vector Federation across Edge Computing Environments", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic vector embedding techniques have proven useful in learning semantic\nrepresentations of data across multiple domains. A key application enabled by\nsuch techniques is the ability to measure semantic similarity between given\ndata samples and find data most similar to a given sample. State-of-the-art\nembedding approaches assume all data is available on a single site. However, in\nmany business settings, data is distributed across multiple edge locations and\ncannot be aggregated due to a variety of constraints. Hence, the applicability\nof state-of-the-art embedding approaches is limited to freely shared datasets,\nleaving out applications with sensitive or mission-critical data. This paper\naddresses this gap by proposing novel unsupervised algorithms called\n\\emph{SEEC} for learning and applying semantic vector embedding in a variety of\ndistributed settings. Specifically, for scenarios where multiple edge locations\ncan engage in joint learning, we adapt the recently proposed federated learning\ntechniques for semantic vector embedding. Where joint learning is not possible,\nwe propose novel semantic vector translation algorithms to enable semantic\nquery across multiple edge locations, each with its own semantic vector-space.\nExperimental results on natural language as well as graph datasets show that\nthis may be a promising new direction.\n", "versions": [{"version": "v1", "created": "Sun, 30 Aug 2020 23:51:41 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Witherspoon", "Shalisha", ""], ["Steuer", "Dean", ""], ["Bent", "Graham", ""], ["Desai", "Nirmit", ""]]}, {"id": "2008.13339", "submitter": "Xukun Luo", "authors": "Xukun Luo, Weijie Liu, Meng Ma and Ping Wang", "title": "BiTT: Bidirectional Tree Tagging for Joint Extraction of Overlapping\n  Entities and Relations", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint extraction refers to extracting triples, composed of entities and\nrelations, simultaneously from the text with a single model. However, most\nexisting methods fail to extract all triples accurately and efficiently from\nsentences with overlapping issue, i.e., the same entity is included in multiple\ntriples. In this paper, we propose a novel scheme called Bidirectional Tree\nTagging (BiTT) to label overlapping triples in text. In BiTT, the triples with\nthe same relation category in a sentence are especially represented as two\nbinary trees, each of which is converted into a word-level tags sequence to\nlabel each word. Based on BiTT scheme, we develop an end-to-end extraction\nframework to predict the BiTT tags and further extract triples efficiently. We\nadopt the Bi-LSTM and the BERT as the encoder in our framework respectively,\nand obtain promising results in public English as well as Chinese datasets.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 03:28:18 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 09:06:00 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Luo", "Xukun", ""], ["Liu", "Weijie", ""], ["Ma", "Meng", ""], ["Wang", "Ping", ""]]}, {"id": "2008.13347", "submitter": "Ashiqur KhudaBukhsh Ashiqur Rahman KhudaBukhsh", "authors": "Ashiqur R. KhudaBukhsh, Shriphani Palakodety, Tom M. Mitchell", "title": "Discovering Bilingual Lexicons in Polyglot Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilingual lexicons and phrase tables are critical resources for modern\nMachine Translation systems. Although recent results show that without any seed\nlexicon or parallel data, highly accurate bilingual lexicons can be learned\nusing unsupervised methods, such methods rely on the existence of large, clean\nmonolingual corpora. In this work, we utilize a single Skip-gram model trained\non a multilingual corpus yielding polyglot word embeddings, and present a novel\nfinding that a surprisingly simple constrained nearest-neighbor sampling\ntechnique in this embedding space can retrieve bilingual lexicons, even in\nharsh social media data sets predominantly written in English and Romanized\nHindi and often exhibiting code switching. Our method does not require\nmonolingual corpora, seed lexicons, or any other such resources. Additionally,\nacross three European language pairs, we observe that polyglot word embeddings\nindeed learn a rich semantic representation of words and substantial bilingual\nlexicons can be retrieved using our constrained nearest neighbor sampling. We\ninvestigate potential reasons and downstream applications in settings spanning\nboth clean texts and noisy social media data sets, and in both resource-rich\nand under-resourced language pairs.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 03:57:50 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["KhudaBukhsh", "Ashiqur R.", ""], ["Palakodety", "Shriphani", ""], ["Mitchell", "Tom M.", ""]]}, {"id": "2008.13533", "submitter": "Dara Bahri", "authors": "Dara Bahri, Yi Tay, Che Zheng, Donald Metzler, Cliff Brunk, Andrew\n  Tomkins", "title": "Generative Models are Unsupervised Predictors of Page Quality: A\n  Colossal-Scale Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large generative language models such as GPT-2 are well-known for their\nability to generate text as well as their utility in supervised downstream\ntasks via fine-tuning. Our work is twofold: firstly we demonstrate via human\nevaluation that classifiers trained to discriminate between human and\nmachine-generated text emerge as unsupervised predictors of \"page quality\",\nable to detect low quality content without any training. This enables fast\nbootstrapping of quality indicators in a low-resource setting. Secondly,\ncurious to understand the prevalence and nature of low quality pages in the\nwild, we conduct extensive qualitative and quantitative analysis over 500\nmillion web articles, making this the largest-scale study ever conducted on the\ntopic.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2020 07:13:24 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Bahri", "Dara", ""], ["Tay", "Yi", ""], ["Zheng", "Che", ""], ["Metzler", "Donald", ""], ["Brunk", "Cliff", ""], ["Tomkins", "Andrew", ""]]}, {"id": "2008.13537", "submitter": "He Zhao", "authors": "He Zhao, Dinh Phung, Viet Huynh, Trung Le, Wray Buntine", "title": "Neural Topic Model via Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recently, Neural Topic Models (NTMs) inspired by variational autoencoders\nhave obtained increasingly research interest due to their promising results on\ntext analysis. However, it is usually hard for existing NTMs to achieve good\ndocument representation and coherent/diverse topics at the same time. Moreover,\nthey often degrade their performance severely on short documents. The\nrequirement of reparameterisation could also comprise their training quality\nand model flexibility. To address these shortcomings, we present a new neural\ntopic model via the theory of optimal transport (OT). Specifically, we propose\nto learn the topic distribution of a document by directly minimising its OT\ndistance to the document's word distributions. Importantly, the cost matrix of\nthe OT distance models the weights between topics and words, which is\nconstructed by the distances between topics and words in an embedding space.\nOur proposed model can be trained efficiently with a differentiable loss.\nExtensive experiments show that our framework significantly outperforms the\nstate-of-the-art NTMs on discovering more coherent and diverse topics and\nderiving better document representations for both regular and short texts.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 06:37:09 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 01:49:09 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Zhao", "He", ""], ["Phung", "Dinh", ""], ["Huynh", "Viet", ""], ["Le", "Trung", ""], ["Buntine", "Wray", ""]]}, {"id": "2008.13544", "submitter": "Hamada Zahera", "authors": "Hamada M. Zahera, Rricha Jalota, Mohamed A. Sherif, Axel N. Ngomo", "title": "I-AID: Identifying Actionable Information from Disaster-related Tweets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Social media plays a significant role in disaster management by providing\nvaluable data about affected people, donations and help requests. Recent\nstudies highlight the need to filter information on social media into\nfine-grained content labels. However, identifying useful information from\nmassive amounts of social media posts during a crisis is a challenging task. In\nthis paper, we propose I-AID, a multimodel approach to automatically categorize\ntweets into multi-label information types and filter critical information from\nthe enormous volume of social media data. I-AID incorporates three main\ncomponents: i) a BERT-based encoder to capture the semantics of a tweet and\nrepresent as a low-dimensional vector, ii) a graph attention network (GAT) to\napprehend correlations between tweets' words/entities and the corresponding\ninformation types, and iii) a Relation Network as a learnable distance metric\nto compute the similarity between tweets and their corresponding information\ntypes in a supervised way. We conducted several experiments on two real\npublicly-available datasets. Our results indicate that I-AID outperforms\nstate-of-the-art approaches in terms of weighted average F1 score by +6% and\n+4% on the TREC-IS dataset and COVID-19 Tweets, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 19:07:50 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 02:32:43 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Zahera", "Hamada M.", ""], ["Jalota", "Rricha", ""], ["Sherif", "Mohamed A.", ""], ["Ngomo", "Axel N.", ""]]}, {"id": "2008.13546", "submitter": "Xavier Amatriain", "authors": "Clara H. McCreery, Namit Katariya, Anitha Kannan, Manish Chablani,\n  Xavier Amatriain", "title": "Effective Transfer Learning for Identifying Similar Questions: Matching\n  User Questions to COVID-19 FAQs", "comments": "arXiv admin note: substantial text overlap with arXiv:1910.04192", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People increasingly search online for answers to their medical questions but\nthe rate at which medical questions are asked online significantly exceeds the\ncapacity of qualified people to answer them. This leaves many questions\nunanswered or inadequately answered. Many of these questions are not unique,\nand reliable identification of similar questions would enable more efficient\nand effective question answering schema. COVID-19 has only exacerbated this\nproblem. Almost every government agency and healthcare organization has tried\nto meet the informational need of users by building online FAQs, but there is\nno way for people to ask their question and know if it is answered on one of\nthese pages. While many research efforts have focused on the problem of general\nquestion similarity, these approaches do not generalize well to domains that\nrequire expert knowledge to determine semantic similarity, such as the medical\ndomain. In this paper, we show how a double fine-tuning approach of pretraining\na neural network on medical question-answer pairs followed by fine-tuning on\nmedical question-question pairs is a particularly useful intermediate task for\nthe ultimate goal of determining medical question similarity. While other\npretraining tasks yield an accuracy below 78.7% on this task, our model\nachieves an accuracy of 82.6% with the same number of training examples, an\naccuracy of 80.0% with a much smaller training set, and an accuracy of 84.5%\nwhen the full corpus of medical question-answer data is used. We also describe\na currently live system that uses the trained model to match user questions to\nCOVID-related FAQs.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2020 18:20:04 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["McCreery", "Clara H.", ""], ["Katariya", "Namit", ""], ["Kannan", "Anitha", ""], ["Chablani", "Manish", ""], ["Amatriain", "Xavier", ""]]}, {"id": "2008.13549", "submitter": "Laksh Advani", "authors": "Laksh Advani and Clement Lu and Suraj Maharjan", "title": "C1 at SemEval-2020 Task 9: SentiMix: Sentiment Analysis for Code-Mixed\n  Social Media Text using Feature Engineering", "comments": "SemEval-2020 Task 9", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In today's interconnected and multilingual world, code-mixing of languages on\nsocial media is a common occurrence. While many Natural Language Processing\n(NLP) tasks like sentiment analysis are mature and well designed for\nmonolingual text, techniques to apply these tasks to code-mixed text still\nwarrant exploration. This paper describes our feature engineering approach to\nsentiment analysis in code-mixed social media text for SemEval-2020 Task 9:\nSentiMix. We tackle this problem by leveraging a set of hand-engineered\nlexical, sentiment, and metadata features to design a classifier that can\ndisambiguate between \"positive\", \"negative\" and \"neutral\" sentiment. With this\nmodel, we are able to obtain a weighted F1 score of 0.65 for the \"Hinglish\"\ntask and 0.63 for the \"Spanglish\" tasks\n", "versions": [{"version": "v1", "created": "Sun, 9 Aug 2020 00:46:26 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Advani", "Laksh", ""], ["Lu", "Clement", ""], ["Maharjan", "Suraj", ""]]}, {"id": "2008.13597", "submitter": "Somnath Banerjee", "authors": "Somnath Banerjee, Sudip Kumar Naskar, Paolo Rosso and Sivaji\n  Bandyopadhyay", "title": "Classifier Combination Approach for Question Classification for Bengali\n  Question Answering System", "comments": "16 pages, to be published in Sadhana", "journal-ref": "Sadhana, Springer, 2019", "doi": "10.1007/s12046-019-1224-8", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question classification (QC) is a prime constituent of automated question\nanswering system. The work presented here demonstrates that the combination of\nmultiple models achieve better classification performance than those obtained\nwith existing individual models for the question classification task in\nBengali. We have exploited state-of-the-art multiple model combination\ntechniques, i.e., ensemble, stacking and voting, to increase QC accuracy.\nLexical, syntactic and semantic features of Bengali questions are used for four\nwell-known classifiers, namely Na\\\"{\\i}ve Bayes, kernel Na\\\"{\\i}ve Bayes, Rule\nInduction, and Decision Tree, which serve as our base learners. Single-layer\nquestion-class taxonomy with 8 coarse-grained classes is extended to two-layer\ntaxonomy by adding 69 fine-grained classes. We carried out the experiments both\non single-layer and two-layer taxonomies. Experimental results confirmed that\nclassifier combination approaches outperform single classifier classification\napproaches by 4.02% for coarse-grained question classes. Overall, the stacking\napproach produces the best results for fine-grained classification and achieves\n87.79% of accuracy. The approach presented here could be used in other\nIndo-Aryan or Indic languages to develop a question answering system.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 13:39:04 GMT"}, {"version": "v2", "created": "Sun, 6 Sep 2020 14:47:12 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Banerjee", "Somnath", ""], ["Naskar", "Sudip Kumar", ""], ["Rosso", "Paolo", ""], ["Bandyopadhyay", "Sivaji", ""]]}, {"id": "2008.13609", "submitter": "Sourav Das", "authors": "Sourav Das and Anup Kumar Kolya", "title": "Detecting Generic Music Features with Single Layer Feedforward Network\n  using Unsupervised Hebbian Computation", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the ever-increasing number of digital music and vast music track\nfeatures through popular online music streaming software and apps, feature\nrecognition using the neural network is being used for experimentation to\nproduce a wide range of results across a variety of experiments recently.\nThrough this work, the authors extract information on such features from a\npopular open-source music corpus and explored new recognition techniques, by\napplying unsupervised Hebbian learning techniques on their single-layer neural\nnetwork using the same dataset. The authors show the detailed empirical\nfindings to simulate how such an algorithm can help a single layer feedforward\nnetwork in training for music feature learning as patterns. The unsupervised\ntraining algorithm enhances their proposed neural network to achieve an\naccuracy of 90.36% for successful music feature detection. For comparative\nanalysis against similar tasks, authors put their results with the likes of\nseveral previous benchmark works. They further discuss the limitations and\nthorough error analysis of their work. The authors hope to discover and gather\nnew information about this particular classification technique and its\nperformance, and further understand future potential directions and prospects\nthat could improve the art of computational music feature recognition.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 13:57:31 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Das", "Sourav", ""], ["Kolya", "Anup Kumar", ""]]}, {"id": "2008.13694", "submitter": "Sasha Spala", "authors": "Sasha Spala, Nicholas A Miller, Franck Dernoncourt, Carl Dockhorn", "title": "SemEval-2020 Task 6: Definition extraction from free text with the DEFT\n  corpus", "comments": "To be published in Proceedings of the 14th International Workshop on\n  Semantic Evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Research on definition extraction has been conducted for well over a decade,\nlargely with significant constraints on the type of definitions considered. In\nthis work, we present DeftEval, a SemEval shared task in which participants\nmust extract definitions from free text using a term-definition pair corpus\nthat reflects the complex reality of definitions in natural language.\nDefinitions and glosses in free text often appear without explicit indicators,\nacross sentences boundaries, or in an otherwise complex linguistic manner.\nDeftEval involved 3 distinct subtasks: 1)Sentence classification, 2) sequence\nlabeling, and 3) relation extraction.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 15:55:24 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Spala", "Sasha", ""], ["Miller", "Nicholas A", ""], ["Dernoncourt", "Franck", ""], ["Dockhorn", "Carl", ""]]}]