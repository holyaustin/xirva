[{"id": "1810.00278", "submitter": "Pawe{\\l} Budzianowski", "authors": "Pawe{\\l} Budzianowski, Tsung-Hsien Wen, Bo-Hsiang Tseng, I\\~nigo\n  Casanueva, Stefan Ultes, Osman Ramadan, Milica Ga\\v{s}i\\'c", "title": "MultiWOZ -- A Large-Scale Multi-Domain Wizard-of-Oz Dataset for\n  Task-Oriented Dialogue Modelling", "comments": "Accepted for publication at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even though machine learning has become the major scene in dialogue research\ncommunity, the real breakthrough has been blocked by the scale of data\navailable. To address this fundamental obstacle, we introduce the Multi-Domain\nWizard-of-Oz dataset (MultiWOZ), a fully-labeled collection of human-human\nwritten conversations spanning over multiple domains and topics. At a size of\n$10$k dialogues, it is at least one order of magnitude larger than all previous\nannotated task-oriented corpora. The contribution of this work apart from the\nopen-sourced dataset labelled with dialogue belief states and dialogue actions\nis two-fold: firstly, a detailed description of the data collection procedure\nalong with a summary of data structure and analysis is provided. The proposed\ndata-collection pipeline is entirely based on crowd-sourcing without the need\nof hiring professional annotators; secondly, a set of benchmark results of\nbelief tracking, dialogue act and response generation is reported, which shows\nthe usability of the data and sets a baseline for future studies.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 23:44:39 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 12:45:07 GMT"}, {"version": "v3", "created": "Mon, 20 Apr 2020 15:02:43 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Budzianowski", "Pawe\u0142", ""], ["Wen", "Tsung-Hsien", ""], ["Tseng", "Bo-Hsiang", ""], ["Casanueva", "I\u00f1igo", ""], ["Ultes", "Stefan", ""], ["Ramadan", "Osman", ""], ["Ga\u0161i\u0107", "Milica", ""]]}, {"id": "1810.00324", "submitter": "Walid Saba", "authors": "Walid S. Saba", "title": "On the Winograd Schema: Situating Language Understanding in the\n  Data-Information-Knowledge Continuum", "comments": "6 pages, 1 figure", "journal-ref": "Proceedings of the 32nd International FLAIRS Conference, 2019", "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Winograd Schema (WS) challenge, proposed as an al-ternative to the Turing\nTest, has become the new standard for evaluating progress in natural language\nunderstanding (NLU). In this paper we will not however be concerned with how\nthis challenge might be addressed. Instead, our aim here is threefold: (i) we\nwill first formally 'situate' the WS challenge in the\ndata-information-knowledge continuum, suggesting where in that continuum a good\nWS resides; (ii) we will show that a WS is just special case of a more general\nphenomenon in language understanding, namely the missing text phenomenon\n(henceforth, MTP) - in particular, we will argue that what we usually call\nthinking in the process of language understanding involves discovering a\nsignificant amount of 'missing text' - text that is not explicitly stated, but\nis often implicitly assumed as shared background knowledge; and (iii) we\nconclude by a brief discussion on why MTP is inconsistent with the data-driven\nand machine learning approach to language understanding.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 06:25:31 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 16:28:32 GMT"}, {"version": "v3", "created": "Tue, 12 Feb 2019 18:03:51 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Saba", "Walid S.", ""]]}, {"id": "1810.00333", "submitter": "Albert Gatt", "authors": "Albert Gatt and Nicol\\'as Mar\\'in and Gustavo Rivas-Gervilla and\n  Daniel S\\'anchez", "title": "Specificity measures and reference", "comments": "Accepted for publication in: Proceedings of the 11th International\n  Conference on Natural Language Generation. Tilburg, The Netherlands:\n  Association for Computational Linguistics 11 pages, 5 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study empirically the validity of measures of referential\nsuccess for referring expressions involving gradual properties. More\nspecifically, we study the ability of several measures of referential success\nto predict the success of a user in choosing the right object, given a\nreferring expression. Experimental results indicate that certain fuzzy measures\nof success are able to predict human accuracy in reference resolution. Such\nmeasures are therefore suitable for the estimation of the success or otherwise\nof a referring expression produced by a generation algorithm, especially in\ncase the properties in a domain cannot be assumed to have crisp denotations.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 07:49:22 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Gatt", "Albert", ""], ["Mar\u00edn", "Nicol\u00e1s", ""], ["Rivas-Gervilla", "Gustavo", ""], ["S\u00e1nchez", "Daniel", ""]]}, {"id": "1810.00341", "submitter": "Shaohan Huang", "authors": "Shaohan Huang, Yu Wu, Furu Wei, Ming Zhou", "title": "Text Morphing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel natural language generation task, termed\nas text morphing, which targets at generating the intermediate sentences that\nare fluency and smooth with the two input sentences. We propose the Morphing\nNetworks consisting of the editing vector generation networks and the sentence\nediting networks which are trained jointly. Specifically, the editing vectors\nare generated with a recurrent neural networks model from the lexical gap\nbetween the source sentence and the target sentence. Then the sentence editing\nnetworks iteratively generate new sentences with the current editing vector and\nthe sentence generated in the previous step. We conduct experiments with 10\nmillion text morphing sequences which are extracted from the Yelp review\ndataset. Experiment results show that the proposed method outperforms baselines\non the text morphing task. We also discuss directions and opportunities for\nfuture research of text morphing.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 09:04:54 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Huang", "Shaohan", ""], ["Wu", "Yu", ""], ["Wei", "Furu", ""], ["Zhou", "Ming", ""]]}, {"id": "1810.00347", "submitter": "Xiaoxiao Yin", "authors": "Xiaoxiao Yin, Daqi Zheng, Zhengdong Lu, Ruifang Liu", "title": "Neural Entity Reasoner for Global Consistency in NER", "comments": "8 pages, 3 figures, submitted to AAAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Neural Entity Reasoner (NE-Reasoner), a framework to introduce\nglobal consistency of recognized entities into Neural Reasoner over Named\nEntity Recognition (NER) task. Given an input sentence, the NE-Reasoner layer\ncan infer over multiple entities to increase the global consistency of output\nlabels, which then be transfered into entities for the input of next layer.\nNE-Reasoner inherits and develops some features from Neural Reasoner 1) a\nsymbolic memory, allowing it to exchange entities between layers. 2) the\nspecific interaction-pooling mechanism, allowing it to connect each local word\nto multiple global entities, and 3) the deep architecture, allowing it to\nbootstrap the recognized entity set from coarse to fine. Like human beings,\nNE-Reasoner is able to accommodate ambiguous words and Name Entities that\nrarely or never met before. Despite the symbolic information the model\nintroduced, NE-Reasoner can still be trained effectively in an end-to-end\nmanner via parameter sharing strategy. NE-Reasoner can outperform conventional\nNER models in most cases on both English and Chinese NER datasets. For example,\nit achieves state-of-art on CoNLL-2003 English NER dataset.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 09:28:57 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Yin", "Xiaoxiao", ""], ["Zheng", "Daqi", ""], ["Lu", "Zhengdong", ""], ["Liu", "Ruifang", ""]]}, {"id": "1810.00367", "submitter": "Reuben Cohn-Gordon", "authors": "Reuben Cohn-Gordon, Noah D. Goodman, Christopher Potts", "title": "An Incremental Iterated Response Model of Pragmatics", "comments": "Camera-Ready Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent Iterated Response (IR) models of pragmatics conceptualize language use\nas a recursive process in which agents reason about each other to increase\ncommunicative efficiency. These models are generally defined over complete\nutterances. However, there is substantial evidence that pragmatic reasoning\ntakes place incrementally during production and comprehension. We address this\nwith an incremental IR model. We compare the incremental and global versions\nusing computational simulations, and we assess the incremental model against\nexisting experimental data and in the TUNA corpus for referring expression\ngeneration, showing that the model can capture phenomena out of reach of global\nversions.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 12:52:03 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 18:41:30 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Cohn-Gordon", "Reuben", ""], ["Goodman", "Noah D.", ""], ["Potts", "Christopher", ""]]}, {"id": "1810.00428", "submitter": "Saeed Najafi", "authors": "Saeed Najafi, Colin Cherry, Grzegorz Kondrak", "title": "Efficient Sequence Labeling with Actor-Critic Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural approaches to sequence labeling often use a Conditional Random Field\n(CRF) to model their output dependencies, while Recurrent Neural Networks (RNN)\nare used for the same purpose in other tasks. We set out to establish RNNs as\nan attractive alternative to CRFs for sequence labeling. To do so, we address\none of the RNN's most prominent shortcomings, the fact that it is not exposed\nto its own errors with the maximum-likelihood training. We frame the prediction\nof the output sequence as a sequential decision-making process, where we train\nthe network with an adjusted actor-critic algorithm (AC-RNN). We\ncomprehensively compare this strategy with maximum-likelihood training for both\nRNNs and CRFs on three structured-output tasks. The proposed AC-RNN efficiently\nmatches the performance of the CRF on NER and CCG tagging, and outperforms it\non Machine Transliteration. We also show that our training strategy is\nsignificantly better than other techniques for addressing RNN's exposure bias,\nsuch as Scheduled Sampling, and Self-Critical policy training.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 17:31:52 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Najafi", "Saeed", ""], ["Cherry", "Colin", ""], ["Kondrak", "Grzegorz", ""]]}, {"id": "1810.00438", "submitter": "Ziyi Yang", "authors": "Ziyi Yang, Chenguang Zhu, Weizhu Chen", "title": "Parameter-free Sentence Embedding via Orthogonal Basis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple and robust non-parameterized approach for building\nsentence representations. Inspired by the Gram-Schmidt Process in geometric\ntheory, we build an orthogonal basis of the subspace spanned by a word and its\nsurrounding context in a sentence. We model the semantic meaning of a word in a\nsentence based on two aspects. One is its relatedness to the word vector\nsubspace already spanned by its contextual words. The other is the word's novel\nsemantic meaning which shall be introduced as a new basis vector perpendicular\nto this existing subspace. Following this motivation, we develop an innovative\nmethod based on orthogonal basis to combine pre-trained word embeddings into\nsentence representations. This approach requires zero parameters, along with\nefficient inference performance. We evaluate our approach on 11 downstream NLP\ntasks. Our model shows superior performance compared with non-parameterized\nalternatives and it is competitive to other approaches relying on either large\namounts of labelled data or prolonged training time.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 18:26:30 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 05:01:36 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Yang", "Ziyi", ""], ["Zhu", "Chenguang", ""], ["Chen", "Weizhu", ""]]}, {"id": "1810.00472", "submitter": "Raquel Fern\\'andez", "authors": "Yujie Xing and Raquel Fern\\'andez", "title": "Automatic Evaluation of Neural Personality-based Chatbots", "comments": "To appear in the Proceedings of the 11th International Conference on\n  Natural Language Generation (INLG-2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Stylistic variation is critical to render the utterances generated by\nconversational agents natural and engaging. In this paper, we focus on\nsequence-to-sequence models for open-domain dialogue response generation and\npropose a new method to evaluate the extent to which such models are able to\ngenerate responses that reflect different personality traits.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 21:53:47 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Xing", "Yujie", ""], ["Fern\u00e1ndez", "Raquel", ""]]}, {"id": "1810.00494", "submitter": "Jinhyuk Lee", "authors": "Jinhyuk Lee, Seongjun Yun, Hyunjae Kim, Miyoung Ko, Jaewoo Kang", "title": "Ranking Paragraphs for Improving Answer Recall in Open-Domain Question\n  Answering", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, open-domain question answering (QA) has been combined with machine\ncomprehension models to find answers in a large knowledge source. As\nopen-domain QA requires retrieving relevant documents from text corpora to\nanswer questions, its performance largely depends on the performance of\ndocument retrievers. However, since traditional information retrieval systems\nare not effective in obtaining documents with a high probability of containing\nanswers, they lower the performance of QA systems. Simply extracting more\ndocuments increases the number of irrelevant documents, which also degrades the\nperformance of QA systems. In this paper, we introduce Paragraph Ranker which\nranks paragraphs of retrieved documents for a higher answer recall with less\nnoise. We show that ranking paragraphs and aggregating answers using Paragraph\nRanker improves performance of open-domain QA pipeline on the four open-domain\nQA datasets by 7.8% on average.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 00:51:25 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Lee", "Jinhyuk", ""], ["Yun", "Seongjun", ""], ["Kim", "Hyunjae", ""], ["Ko", "Miyoung", ""], ["Kang", "Jaewoo", ""]]}, {"id": "1810.00521", "submitter": "Walid Saba", "authors": "Walid S. Saba", "title": "A Simple Machine Learning Method for Commonsense Reasoning? A Short\n  Commentary on Trinh & Le (2018)", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a short Commentary on Trinh & Le (2018) (\"A Simple Method for\nCommonsense Reasoning\") that outlines three serious flaws in the cited paper\nand discusses why data-driven approaches cannot be considered as serious models\nfor the commonsense reasoning needed in natural language understanding in\ngeneral, and in reference resolution, in particular.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 03:58:00 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Saba", "Walid S.", ""]]}, {"id": "1810.00593", "submitter": "Andreas St\\\"ockl", "authors": "Andreas St\\\"ockl", "title": "Detecting Satire in the News with Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We built models with Logistic Regression and linear Support Vector Machines\non a large dataset consisting of regular news articles and news from satirical\nwebsites, and showed that such linear classifiers on a corpus with about 60,000\narticles can perform with a precision of 98.7% and a recall of 95.2% on a\nrandom test set of the news. On the other hand, when testing the classifier on\n\"publication sources\" which are completely unknown during training, only an\naccuracy of 88.2% and an F1-score of 76.3% are achieved. As another result, we\nshowed that the same algorithm can distinguish between news written by the news\nagency itself and paid articles from customers. Here the results had an\naccuracy of 99%.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 09:26:43 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["St\u00f6ckl", "Andreas", ""]]}, {"id": "1810.00647", "submitter": "I\\~naki San Vicente Roncal", "authors": "I\\~naki San Vicente, Xabier Saralegi, Rodrigo Agerri", "title": "Real Time Monitoring of Social Media and Digital Press", "comments": "Preprint submission, 35 pages (22 + references and Appendices)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Talaia is a platform for monitoring social media and digital press. A\nconfigurable crawler gathers content with respect to user defined domains or\ntopics. Crawled data is processed by means of the EliXa Sentiment Analysis\nsystem. A Django powered interface provides data visualization for a user-based\nanalysis of the data. This paper presents the architecture of the system and\ndescribes in detail its different components. To prove the validity of the\napproach, two real use cases are accounted for: one in the cultural domain and\none in the political domain. Evaluation for the sentiment analysis task in both\nscenarios is also provided, showing the capacity for domain adaptation.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 16:00:20 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 16:56:26 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Vicente", "I\u00f1aki San", ""], ["Saralegi", "Xabier", ""], ["Agerri", "Rodrigo", ""]]}, {"id": "1810.00660", "submitter": "Sina Ahmadi", "authors": "Sina Ahmadi", "title": "Attention-based Encoder-Decoder Networks for Spelling and Grammatical\n  Error Correction", "comments": "75 pages, 20 figures, submitted as a Master's thesis at the\n  University of Paris Descartes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic spelling and grammatical correction systems are one of the most\nwidely used tools within natural language applications. In this thesis, we\nassume the task of error correction as a type of monolingual machine\ntranslation where the source sentence is potentially erroneous and the target\nsentence should be the corrected form of the input. Our main focus in this\nproject is building neural network models for the task of error correction. In\nparticular, we investigate sequence-to-sequence and attention-based models\nwhich have recently shown a higher performance than the state-of-the-art of\nmany language processing problems. We demonstrate that neural machine\ntranslation models can be successfully applied to the task of error correction.\n  While the experiments of this research are performed on an Arabic corpus, our\nmethods in this thesis can be easily applied to any language.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 23:47:42 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Ahmadi", "Sina", ""]]}, {"id": "1810.00662", "submitter": "Sreeram Ganji Mr.", "authors": "Ganji Sreeram, Kunal Dhawan and Rohit Sinha", "title": "Hindi-English Code-Switching Speech Corpus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code-switching refers to the usage of two languages within a sentence or\ndiscourse. It is a global phenomenon among multilingual communities and has\nemerged as an independent area of research. With the increasing demand for the\ncode-switching automatic speech recognition (ASR) systems, the development of a\ncode-switching speech corpus has become highly desirable. However, for training\nsuch systems, very limited code-switched resources are available as yet. In\nthis work, we present our first efforts in building a code-switching ASR system\nin the Indian context. For that purpose, we have created a Hindi-English\ncode-switching speech database. The database not only contains the speech\nutterances with code-switching properties but also covers the session and the\nspeaker variations like pronunciation, accent, age, gender, etc. This database\ncan be applied in several speech signal processing applications, such as\ncode-switching ASR, language identification, language modeling, speech\nsynthesis etc. This paper mainly presents an analysis of the statistics of the\ncollected code-switching speech corpus. Later, the performance results for the\nASR task have been reported for the created database.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 03:39:47 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Sreeram", "Ganji", ""], ["Dhawan", "Kunal", ""], ["Sinha", "Rohit", ""]]}, {"id": "1810.00663", "submitter": "Xiaoxue Zang", "authors": "Xiaoxue Zang, Ashwini Pokle, Marynel V\\'azquez, Kevin Chen, Juan\n  Carlos Niebles, Alvaro Soto and Silvio Savarese", "title": "Translating Navigation Instructions in Natural Language to a High-Level\n  Plan for Behavioral Robot Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an end-to-end deep learning model for translating free-form\nnatural language instructions to a high-level plan for behavioral robot\nnavigation. We use attention models to connect information from both the user\ninstructions and a topological representation of the environment. We evaluate\nour model's performance on a new dataset containing 10,050 pairs of navigation\ninstructions. Our model significantly outperforms baseline approaches.\nFurthermore, our results suggest that it is possible to leverage the\nenvironment map as a relevant knowledge base to facilitate the translation of\nfree-form navigational instruction.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 06:09:20 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Zang", "Xiaoxue", ""], ["Pokle", "Ashwini", ""], ["V\u00e1zquez", "Marynel", ""], ["Chen", "Kevin", ""], ["Niebles", "Juan Carlos", ""], ["Soto", "Alvaro", ""], ["Savarese", "Silvio", ""]]}, {"id": "1810.00664", "submitter": "Omid Shahmirzadi", "authors": "Omid Shahmirzadi, Adam Lugowski and Kenneth Younge", "title": "Text Similarity in Vector Space Models: A Comparative Study", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic measurement of semantic text similarity is an important task in\nnatural language processing. In this paper, we evaluate the performance of\ndifferent vector space models to perform this task. We address the real-world\nproblem of modeling patent-to-patent similarity and compare TFIDF (and related\nextensions), topic models (e.g., latent semantic indexing), and neural models\n(e.g., paragraph vectors). Contrary to expectations, the added computational\ncost of text embedding methods is justified only when: 1) the target text is\ncondensed; and 2) the similarity comparison is trivial. Otherwise, TFIDF\nperforms surprisingly well in other cases: in particular for longer and more\ntechnical texts or for making finer-grained distinctions between nearest\nneighbors. Unexpectedly, extensions to the TFIDF method, such as adding noun\nphrases or calculating term weights incrementally, were not helpful in our\ncontext.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 10:54:52 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Shahmirzadi", "Omid", ""], ["Lugowski", "Adam", ""], ["Younge", "Kenneth", ""]]}, {"id": "1810.00668", "submitter": "Sudhanshu Kasewa", "authors": "Sudhanshu Kasewa and Pontus Stenetorp and Sebastian Riedel", "title": "Wronging a Right: Generating Better Errors to Improve Grammatical Error\n  Detection", "comments": "Accepted as a short paper at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grammatical error correction, like other machine learning tasks, greatly\nbenefits from large quantities of high quality training data, which is\ntypically expensive to produce. While writing a program to automatically\ngenerate realistic grammatical errors would be difficult, one could learn the\ndistribution of naturallyoccurring errors and attempt to introduce them into\nother datasets. Initial work on inducing errors in this way using statistical\nmachine translation has shown promise; we investigate cheaply constructing\nsynthetic samples, given a small corpus of human-annotated data, using an\noff-the-rack attentive sequence-to-sequence model and a straight-forward\npost-processing procedure. Our approach yields error-filled artificial data\nthat helps a vanilla bi-directional LSTM to outperform the previous state of\nthe art at grammatical error detection, and a previously introduced model to\ngain further improvements of over 5% $F_{0.5}$ score. When attempting to\ndetermine if a given sentence is synthetic, a human annotator at best achieves\n39.39 $F_1$ score, indicating that our model generates mostly human-like\ninstances.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 14:25:40 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Kasewa", "Sudhanshu", ""], ["Stenetorp", "Pontus", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1810.00670", "submitter": "Shahab Jalalvand", "authors": "Shahab Jalalvand, Andrej Ljolje and Srinivas Bangalore", "title": "Automatic Data Expansion for Customer-care Spoken Language Understanding", "comments": "10 pages, 4 figures, 5 tabels", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken language understanding (SLU) systems are widely used in handling of\ncustomer-care calls.A traditional SLU system consists of an acoustic model (AM)\nand a language model (LM) that areused to decode the utterance and a natural\nlanguage understanding (NLU) model that predicts theintent. While AM can be\nshared across different domains, LM and NLU models need to be\ntrainedspecifically for every new task. However, preparing enough data to train\nthese models is prohibitivelyexpensive. In this paper, we introduce an\nefficient method to expand the limited in-domain data. Theprocess starts with\ntraining a preliminary NLU model based on logistic regression on the\nin-domaindata. Since the features are based onn= 1,2-grams, we can detect the\nmost informative n-gramsfor each intent class. Using these n-grams, we find the\nsamples in the out-of-domain corpus that1) contain the desired n-gram and/or 2)\nhave similar intent label. The ones which meet the firstconstraint are used to\ntrain a new LM model and the ones that meet both constraints are used to train\nanew NLU model. Our results on two divergent experimental setups show that the\nproposed approachreduces by 30% the absolute classification error rate (CER)\ncomparing to the preliminary modelsand it significantly outperforms the\ntraditional data expansion algorithms such as the ones based onsemi-supervised\nlearning, TF-IDF and embedding vectors.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 18:49:29 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Jalalvand", "Shahab", ""], ["Ljolje", "Andrej", ""], ["Bangalore", "Srinivas", ""]]}, {"id": "1810.00671", "submitter": "Hui Su", "authors": "Hui Su, Xiaoyu Shen, Wenjie Li and Dietrich Klakow", "title": "NEXUS Network: Connecting the Preceding and the Following in Dialogue\n  Generation", "comments": "Accepted by EMNLP2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-Sequence (seq2seq) models have become overwhelmingly popular in\nbuilding end-to-end trainable dialogue systems. Though highly efficient in\nlearning the backbone of human-computer communications, they suffer from the\nproblem of strongly favoring short generic responses. In this paper, we argue\nthat a good response should smoothly connect both the preceding dialogue\nhistory and the following conversations. We strengthen this connection through\nmutual information maximization. To sidestep the non-differentiability of\ndiscrete natural language tokens, we introduce an auxiliary continuous code\nspace and map such code space to a learnable prior distribution for generation\npurpose. Experiments on two dialogue datasets validate the effectiveness of our\nmodel, where the generated responses are closely related to the dialogue\ncontext and lead to more interactive conversations.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 10:09:44 GMT"}, {"version": "v2", "created": "Sun, 7 Oct 2018 16:13:02 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Su", "Hui", ""], ["Shen", "Xiaoyu", ""], ["Li", "Wenjie", ""], ["Klakow", "Dietrich", ""]]}, {"id": "1810.00679", "submitter": "Rasool Fakoor", "authors": "Rasool Fakoor, Amanjit Kainth, Siamak Shakeri, Christopher Winestock,\n  Abdel-rahman Mohamed, Ruhi Sarikaya", "title": "Direct optimization of F-measure for retrieval-based personal question\n  answering", "comments": "accepted at SLT2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in spoken language technologies and the introduction of many\ncustomer facing products, have given rise to a wide customer reliance on smart\npersonal assistants for many of their daily tasks. In this paper, we present a\nsystem to reduce users' cognitive load by extending personal assistants with\nlong-term personal memory where users can store and retrieve by voice,\narbitrary pieces of information. The problem is framed as a neural retrieval\nbased question answering system where answers are selected from previously\nstored user memories. We propose to directly optimize the end-to-end retrieval\nperformance, measured by the F1-score, using reinforcement learning, leading to\nbetter performance on our experimental test set(s).\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 00:51:24 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Fakoor", "Rasool", ""], ["Kainth", "Amanjit", ""], ["Shakeri", "Siamak", ""], ["Winestock", "Christopher", ""], ["Mohamed", "Abdel-rahman", ""], ["Sarikaya", "Ruhi", ""]]}, {"id": "1810.00681", "submitter": "Xueying Bai", "authors": "Wasi Uddin Ahmad, Xueying Bai, Nanyun Peng, Kai-Wei Chang", "title": "Learning Robust, Transferable Sentence Representations for Text\n  Classification", "comments": "arXiv admin note: substantial text overlap with arXiv:1804.07911", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite deep recurrent neural networks (RNNs) demonstrate strong performance\nin text classification, training RNN models are often expensive and requires an\nextensive collection of annotated data which may not be available. To overcome\nthe data limitation issue, existing approaches leverage either pre-trained word\nembedding or sentence representation to lift the burden of training RNNs from\nscratch. In this paper, we show that jointly learning sentence representations\nfrom multiple text classification tasks and combining them with pre-trained\nword-level and sentence level encoders result in robust sentence\nrepresentations that are useful for transfer learning. Extensive experiments\nand analyses using a wide range of transfer and linguistic tasks endorse the\neffectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 05:40:20 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Ahmad", "Wasi Uddin", ""], ["Bai", "Xueying", ""], ["Peng", "Nanyun", ""], ["Chang", "Kai-Wei", ""]]}, {"id": "1810.00782", "submitter": "Filip Ilievski", "authors": "Filip Ilievski, Eduard Hovy, Qizhe Xie, Piek Vossen", "title": "The Profiling Machine: Active Generalization over Knowledge", "comments": "AAAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human mind is a powerful multifunctional knowledge storage and management\nsystem that performs generalization, type inference, anomaly detection,\nstereotyping, and other tasks. A dynamic KR system that appropriately profiles\nover sparse inputs to provide complete expectations for unknown facets can help\nwith all these tasks. In this paper, we introduce the task of profiling,\ninspired by theories and findings in social psychology about the potential of\nprofiles for reasoning and information processing. We describe two generic\nstate-of-the-art neural architectures that can be easily instantiated as\nprofiling machines to generate expectations and applied to any kind of\nknowledge to fill gaps. We evaluate these methods against Wikidata and crowd\nexpectations, and compare the results to gain insight in the nature of\nknowledge captured by various profiling methods. We make all code and data\navailable to facilitate future research.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 16:03:49 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Ilievski", "Filip", ""], ["Hovy", "Eduard", ""], ["Xie", "Qizhe", ""], ["Vossen", "Piek", ""]]}, {"id": "1810.00924", "submitter": "Matthieu Riou", "authors": "Matthieu Riou, Bassam Jabaian, St\\'ephane Huet and Fabrice Lef\\`evre", "title": "Joint On-line Learning of a Zero-shot Spoken Semantic Parser and a\n  Reinforcement Learning Dialogue Manager", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite many recent advances for the design of dialogue systems, a true\nbottleneck remains the acquisition of data required to train its components.\nUnlike many other language processing applications, dialogue systems require\ninteractions with users, therefore it is complex to develop them with\npre-recorded data. Building on previous works, on-line learning is pursued here\nas a most convenient way to address the issue. Data collection, annotation and\nuse in learning algorithms are performed in a single process. The main\ndifficulties are then: to bootstrap an initial basic system, and to control the\nlevel of additional cost on the user side. Considering that well-performing\nsolutions can be used directly off the shelf for speech recognition and\nsynthesis, the study is focused on learning the spoken language understanding\nand dialogue management modules only. Several variants of joint learning are\ninvestigated and tested with user trials to confirm that the overall on-line\nlearning can be obtained after only a few hundred training dialogues and can\noverstep an expert-based system.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 19:15:57 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Riou", "Matthieu", ""], ["Jabaian", "Bassam", ""], ["Huet", "St\u00e9phane", ""], ["Lef\u00e8vre", "Fabrice", ""]]}, {"id": "1810.00956", "submitter": "Zach Wood-Doughty", "authors": "Zach Wood-Doughty, Ilya Shpitser, and Mark Dredze", "title": "Challenges of Using Text Classifiers for Causal Inference", "comments": "To appear at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal understanding is essential for many kinds of decision-making, but\ncausal inference from observational data has typically only been applied to\nstructured, low-dimensional datasets. While text classifiers produce\nlow-dimensional outputs, their use in causal inference has not previously been\nstudied. To facilitate causal analyses based on language data, we consider the\nrole that text classifiers can play in causal inference through established\nmodeling mechanisms from the causality literature on missing data and\nmeasurement error. We demonstrate how to conduct causal analyses using text\nclassifiers on simulated and Yelp data, and discuss the opportunities and\nchallenges of future work that uses text data in causal inference.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 20:08:40 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Wood-Doughty", "Zach", ""], ["Shpitser", "Ilya", ""], ["Dredze", "Mark", ""]]}, {"id": "1810.00967", "submitter": "Li Yao", "authors": "Nithya Attaluri, Ahmed Nasir, Carolynne Powe, Harold Racz, Ben\n  Covington, Li Yao, Jordan Prosky, Eric Poblenz, Tobi Olatunji, Kevin Lyman", "title": "Efficient and Accurate Abnormality Mining from Radiology Reports with\n  Customized False Positive Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining datasets labeled to facilitate model development is a challenge for\nmost machine learning tasks. The difficulty is heightened for medical imaging,\nwhere data itself is limited in accessibility and labeling requires costly time\nand effort by trained medical specialists. Medical imaging studies, however,\nare often accompanied by a medical report produced by a radiologist,\nidentifying important features on the corresponding scan for other physicians\nnot specifically trained in radiology. We propose a methodology for\napproximating image-level labels for radiology studies from associated reports\nusing a general purpose language processing tool for medical concept extraction\nand sentiment analysis, and simple manually crafted heuristics for false\npositive reduction. Using this approach, we label more than 175,000 Head CT\nstudies for the presence of 33 features indicative of 11 clinically relevant\nconditions. For 27 of the 30 keywords that yielded positive results (3 had no\noccurrences), the lower bound of the confidence intervals created to estimate\nthe percentage of accurately labeled reports was above 85%, with the average\nbeing above 95%. Though noisier then manual labeling, these results suggest\nthis method to be a viable means of labeling medical images at scale.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 20:40:15 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Attaluri", "Nithya", ""], ["Nasir", "Ahmed", ""], ["Powe", "Carolynne", ""], ["Racz", "Harold", ""], ["Covington", "Ben", ""], ["Yao", "Li", ""], ["Prosky", "Jordan", ""], ["Poblenz", "Eric", ""], ["Olatunji", "Tobi", ""], ["Lyman", "Kevin", ""]]}, {"id": "1810.00968", "submitter": "Aysenur Bilgin", "authors": "Aysenur Bilgin (1), Laura Hollink (1), Jacco van Ossenbruggen (1),\n  Erik Tjong Kim Sang (2), Kim Smeenk (3), Frank Harbers (3), Marcel Broersma\n  (3) ((1) CWI, (2) Netherlands eScience Center, (3) University of Groningen)", "title": "Utilizing a Transparency-driven Environment toward Trusted Automatic\n  Genre Classification: A Case Study in Journalism History", "comments": "11 pages, 8 figures, IEEE eScience Conference 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing abundance of unlabeled data in real-world tasks, researchers\nhave to rely on the predictions given by black-boxed computational models.\nHowever, it is an often neglected fact that these models may be scoring high on\naccuracy for the wrong reasons. In this paper, we present a practical impact\nanalysis of enabling model transparency by various presentation forms. For this\npurpose, we developed an environment that empowers non-computer scientists to\nbecome practicing data scientists in their own research field. We demonstrate\nthe gradually increasing understanding of journalism historians through a\nreal-world use case study on automatic genre classification of newspaper\narticles. This study is a first step towards trusted usage of machine learning\npipelines in a responsible way.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 20:40:59 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Bilgin", "Aysenur", "", "CWI"], ["Hollink", "Laura", "", "CWI"], ["van Ossenbruggen", "Jacco", "", "CWI"], ["Sang", "Erik Tjong Kim", "", "Netherlands eScience Center"], ["Smeenk", "Kim", "", "University of Groningen"], ["Harbers", "Frank", "", "University of Groningen"], ["Broersma", "Marcel", "", "University of Groningen"]]}, {"id": "1810.01064", "submitter": "Shuai Tang", "authors": "Shuai Tang, Virginia R. de Sa", "title": "Improving Sentence Representations with Consensus Maximisation", "comments": "arXiv admin note: substantial text overlap with arXiv:1805.07443", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consensus maximisation learning can provide self-supervision when different\nviews are available of the same data. The distributional hypothesis provides\nanother form of useful self-supervision from adjacent sentences which are\nplentiful in large unlabelled corpora. Motivated by the observation that\ndifferent learning architectures tend to emphasise different aspects of\nsentence meaning, we present a new self-supervised learning framework for\nlearning sentence representations which minimises the disagreement between two\nviews of the same sentence where one view encodes the sentence with a recurrent\nneural network (RNN), and the other view encodes the same sentence with a\nsimple linear model. After learning, the individual views (networks) result in\nhigher quality sentence representations than their single-view learnt\ncounterparts (learnt using only the distributional hypothesis) as judged by\nperformance on standard downstream tasks. An ensemble of both views provides\neven better generalisation on both supervised and unsupervised downstream\ntasks. Also, importantly the ensemble of views trained with consensus\nmaximisation between the two different architectures performs better on\ndownstream tasks than an analogous ensemble made from the single-view trained\ncounterparts.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 04:51:33 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 01:12:24 GMT"}, {"version": "v3", "created": "Fri, 3 May 2019 18:02:53 GMT"}, {"version": "v4", "created": "Tue, 7 May 2019 01:02:40 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Tang", "Shuai", ""], ["de Sa", "Virginia R.", ""]]}, {"id": "1810.01114", "submitter": "Marlo H\\\"aring", "authors": "Marlo H\\\"aring, Wiebke Loosen, Walid Maalej", "title": "Who is Addressed in this Comment? Automatically Classifying\n  Meta-Comments in News Comments", "comments": "Accepted for publication to the 21st ACM Conference on\n  Computer-Supported Cooperative Work and Social Computing (CSCW18)", "journal-ref": null, "doi": "10.1145/3274336", "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User comments have become an essential part of online journalism. However,\nnewsrooms are often overwhelmed by the vast number of diverse comments, for\nwhich a manual analysis is barely feasible. Identifying meta-comments that\naddress or mention newsrooms, individual journalists, or moderators and that\nmay call for reactions is particularly critical. In this paper, we present an\nautomated approach to identify and classify meta-comments. We compare comment\nclassification based on manually extracted features with an end-to-end learning\napproach. We develop, optimize, and evaluate multiple classifiers on a comment\ndataset of the large German online newsroom SPIEGEL Online and the 'One Million\nPosts' corpus of DER STANDARD, an Austrian newspaper. Both optimized\nclassification approaches achieved encouraging $F_{0.5}$ values between 76% and\n91%. We report on the most significant classification features with the results\nof a qualitative analysis and discuss how our work contributes to making\nparticipation in online journalism more constructive.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 08:32:08 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["H\u00e4ring", "Marlo", ""], ["Loosen", "Wiebke", ""], ["Maalej", "Walid", ""]]}, {"id": "1810.01165", "submitter": "Tao Li", "authors": "Tao Li, Xudong Liu, Shihan Su", "title": "Semi-supervised Text Regression with Conditional Generative Adversarial\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1109/BigData.2018.8622140", "report-no": null, "categories": "cs.CL cs.AI q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enormous online textual information provides intriguing opportunities for\nunderstandings of social and economic semantics. In this paper, we propose a\nnovel text regression model based on a conditional generative adversarial\nnetwork (GAN), with an attempt to associate textual data and social outcomes in\na semi-supervised manner. Besides promising potential of predicting\ncapabilities, our superiorities are twofold: (i) the model works with\nunbalanced datasets of limited labelled data, which align with real-world\nscenarios; and (ii) predictions are obtained by an end-to-end framework,\nwithout explicitly selecting high-level representations. Finally we point out\nrelated datasets for experiments and future research directions.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 10:35:13 GMT"}, {"version": "v2", "created": "Sun, 11 Nov 2018 05:37:37 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Li", "Tao", ""], ["Liu", "Xudong", ""], ["Su", "Shihan", ""]]}, {"id": "1810.01170", "submitter": "Ond\\v{r}ej Du\\v{s}ek", "authors": "Ond\\v{r}ej Du\\v{s}ek, Jekaterina Novikova and Verena Rieser", "title": "Findings of the E2E NLG Challenge", "comments": "Accepted to INLG 2018", "journal-ref": "Proceedings of the 11th International Conference on Natural\n  Language Generation, pages 322-328, Tilburg, The Netherlands, November 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper summarises the experimental setup and results of the first shared\ntask on end-to-end (E2E) natural language generation (NLG) in spoken dialogue\nsystems. Recent end-to-end generation systems are promising since they reduce\nthe need for data annotation. However, they are currently limited to small,\ndelexicalised datasets. The E2E NLG shared task aims to assess whether these\nnovel approaches can generate better-quality output by learning from a dataset\ncontaining higher lexical richness, syntactic complexity and diverse discourse\nphenomena. We compare 62 systems submitted by 17 institutions, covering a wide\nrange of approaches, including machine learning architectures -- with the\nmajority implementing sequence-to-sequence models (seq2seq) -- as well as\nsystems based on grammatical rules and templates.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 11:06:35 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Du\u0161ek", "Ond\u0159ej", ""], ["Novikova", "Jekaterina", ""], ["Rieser", "Verena", ""]]}, {"id": "1810.01371", "submitter": "Rui Zhao", "authors": "Rui Zhao, Volker Tresp", "title": "Efficient Dialog Policy Learning via Positive Memory Retention", "comments": "Published in IEEE Spoken Language Technology (SLT 2018), Athens,\n  Greece", "journal-ref": null, "doi": "10.1109/SLT.2018.8639617", "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the training of recurrent neural networks as\ngoal-oriented dialog agents using reinforcement learning. Training such agents\nwith policy gradients typically requires a large amount of samples. However,\nthe collection of the required data in form of conversations between chat-bots\nand human agents is time-consuming and expensive. To mitigate this problem, we\ndescribe an efficient policy gradient method using positive memory retention,\nwhich significantly increases the sample-efficiency. We show that our method is\n10 times more sample-efficient than policy gradients in extensive experiments\non a new synthetic number guessing game. Moreover, in a real-word visual object\ndiscovery game, the proposed method is twice as sample-efficient as policy\ngradients and shows state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:01:28 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 10:26:56 GMT"}, {"version": "v3", "created": "Sun, 24 May 2020 08:08:15 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Zhao", "Rui", ""], ["Tresp", "Volker", ""]]}, {"id": "1810.01375", "submitter": "Ali Emami Mr.", "authors": "Ali Emami, Noelia De La Cruz, Adam Trischler, Kaheer Suleman, Jackie\n  Chi Kit Cheung", "title": "A Knowledge Hunting Framework for Common Sense Reasoning", "comments": "10 pages, accepted at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an automatic system that achieves state-of-the-art results on\nthe Winograd Schema Challenge (WSC), a common sense reasoning task that\nrequires diverse, complex forms of inference and knowledge. Our method uses a\nknowledge hunting module to gather text from the web, which serves as evidence\nfor candidate problem resolutions. Given an input problem, our system generates\nrelevant queries to send to a search engine, then extracts and classifies\nknowledge from the returned results and weighs them to make a resolution. Our\napproach improves F1 performance on the full WSC by 0.21 over the previous best\nand represents the first system to exceed 0.5 F1. We further demonstrate that\nthe approach is competitive on the Choice of Plausible Alternatives (COPA)\ntask, which suggests that it is generally applicable.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:12:44 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Emami", "Ali", ""], ["De La Cruz", "Noelia", ""], ["Trischler", "Adam", ""], ["Suleman", "Kaheer", ""], ["Cheung", "Jackie Chi Kit", ""]]}, {"id": "1810.01395", "submitter": "Jonathan Le Roux", "authors": "Jonathan Le Roux, Gordon Wichern, Shinji Watanabe, Andy Sarroff, John\n  R. Hershey", "title": "Phasebook and Friends: Leveraging Discrete Representations for Source\n  Separation", "comments": null, "journal-ref": null, "doi": "10.1109/JSTSP.2019.2904183", "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning based speech enhancement and source separation systems have\nrecently reached unprecedented levels of quality, to the point that performance\nis reaching a new ceiling. Most systems rely on estimating the magnitude of a\ntarget source by estimating a real-valued mask to be applied to a\ntime-frequency representation of the mixture signal. A limiting factor in such\napproaches is a lack of phase estimation: the phase of the mixture is most\noften used when reconstructing the estimated time-domain signal. Here, we\npropose \"magbook\", \"phasebook\", and \"combook\", three new types of layers based\non discrete representations that can be used to estimate complex time-frequency\nmasks. Magbook layers extend classical sigmoidal units and a recently\nintroduced convex softmax activation for mask-based magnitude estimation.\nPhasebook layers use a similar structure to give an estimate of the phase mask\nwithout suffering from phase wrapping issues. Combook layers are an alternative\nto the magbook-phasebook combination that directly estimate complex masks. We\npresent various training and inference schemes involving these representations,\nand explain in particular how to include them in an end-to-end learning\nframework. We also present an oracle study to assess upper bounds on\nperformance for various types of masks using discrete phase representations. We\nevaluate the proposed methods on the wsj0-2mix dataset, a well-studied corpus\nfor single-channel speaker-independent speaker separation, matching the\nperformance of state-of-the-art mask-based approaches without requiring\nadditional phase reconstruction steps.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:36:23 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 16:26:58 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Roux", "Jonathan Le", ""], ["Wichern", "Gordon", ""], ["Watanabe", "Shinji", ""], ["Sarroff", "Andy", ""], ["Hershey", "John R.", ""]]}, {"id": "1810.01398", "submitter": "Sara Sabour", "authors": "Sara Sabour, William Chan, Mohammad Norouzi", "title": "Optimal Completion Distillation for Sequence Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Optimal Completion Distillation (OCD), a training procedure for\noptimizing sequence to sequence models based on edit distance. OCD is\nefficient, has no hyper-parameters of its own, and does not require pretraining\nor joint optimization with conditional log-likelihood. Given a partial sequence\ngenerated by the model, we first identify the set of optimal suffixes that\nminimize the total edit distance, using an efficient dynamic programming\nalgorithm. Then, for each position of the generated sequence, we use a target\ndistribution that puts equal probability on the first token of all the optimal\nsuffixes. OCD achieves the state-of-the-art performance on end-to-end speech\nrecognition, on both Wall Street Journal and Librispeech datasets, achieving\n$9.3\\%$ WER and $4.5\\%$ WER respectively.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 17:44:44 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 21:30:20 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Sabour", "Sara", ""], ["Chan", "William", ""], ["Norouzi", "Mohammad", ""]]}, {"id": "1810.01480", "submitter": "Julia Kreutzer", "authors": "Julia Kreutzer, Artem Sokolov", "title": "Learning to Segment Inputs for NMT Favors Character-Level Processing", "comments": "Technical report for IWSLT 2018 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most modern neural machine translation (NMT) systems rely on presegmented\ninputs. Segmentation granularity importantly determines the input and output\nsequence lengths, hence the modeling depth, and source and target vocabularies,\nwhich in turn determine model size, computational costs of softmax\nnormalization, and handling of out-of-vocabulary words. However, the current\npractice is to use static, heuristic-based segmentations that are fixed before\nNMT training. This begs the question whether the chosen segmentation is optimal\nfor the translation task. To overcome suboptimal segmentation choices, we\npresent an algorithm for dynamic segmentation based on the Adaptative\nComputation Time algorithm (Graves 2016), that is trainable end-to-end and\ndriven by the NMT objective. In an evaluation on four translation tasks we\nfound that, given the freedom to navigate between different segmentation\nlevels, the model prefers to operate on (almost) character level, providing\nsupport for purely character-level NMT models from a novel angle.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 19:52:38 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2018 10:21:05 GMT"}, {"version": "v3", "created": "Mon, 5 Nov 2018 09:14:21 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Kreutzer", "Julia", ""], ["Sokolov", "Artem", ""]]}, {"id": "1810.01570", "submitter": "Kaung Khin", "authors": "Kaung Khin, Philipp Burckhardt, Rema Padman", "title": "A Deep Learning Architecture for De-identification of Patient Notes:\n  Implementation and Evaluation", "comments": "Submitted to the 28th Workshop on Information Technologies and\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  De-identification is the process of removing 18 protected health information\n(PHI) from clinical notes in order for the text to be considered not\nindividually identifiable. Recent advances in natural language processing (NLP)\nhas allowed for the use of deep learning techniques for the task of\nde-identification. In this paper, we present a deep learning architecture that\nbuilds on the latest NLP advances by incorporating deep contextualized word\nembeddings and variational drop out Bi-LSTMs. We test this architecture on two\ngold standard datasets and show that the architecture achieves state-of-the-art\nperformance on both data sets while also converging faster than other systems\nwithout the use of dictionaries or other knowledge sources.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 02:53:04 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Khin", "Kaung", ""], ["Burckhardt", "Philipp", ""], ["Padman", "Rema", ""]]}, {"id": "1810.01656", "submitter": "Phuong Le-Hong", "authors": "Phuong Le-Hong and Anh-Cuong Le", "title": "A Comparative Study of Neural Network Models for Sentence Classification", "comments": "To appear in the 5th NAFOSTED Conference on Information and Computer\n  Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an extensive comparative study of four neural network\nmodels, including feed-forward networks, convolutional networks, recurrent\nnetworks and long short-term memory networks, on two sentence classification\ndatasets of English and Vietnamese text. We show that on the English dataset,\nthe convolutional network models without any feature engineering outperform\nsome competitive sentence classifiers with rich hand-crafted linguistic\nfeatures. We demonstrate that the GloVe word embeddings are consistently better\nthan both Skip-gram word embeddings and word count vectors. We also show the\nsuperiority of convolutional neural network models on a Vietnamese newspaper\nsentence dataset over strong baseline models. Our experimental results suggest\nsome good practices for applying neural network models in sentence\nclassification.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 09:36:20 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Le-Hong", "Phuong", ""], ["Le", "Anh-Cuong", ""]]}, {"id": "1810.01808", "submitter": "Bailin Wang", "authors": "Bailin Wang, Wei Lu, Yu Wang and Hongxia Jin", "title": "A Neural Transition-based Model for Nested Mention Recognition", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is common that entity mentions can contain other mentions recursively.\nThis paper introduces a scalable transition-based method to model the nested\nstructure of mentions. We first map a sentence with nested mentions to a\ndesignated forest where each mention corresponds to a constituent of the\nforest. Our shift-reduce based system then learns to construct the forest\nstructure in a bottom-up manner through an action sequence whose maximal length\nis guaranteed to be three times of the sentence length. Based on Stack-LSTM\nwhich is employed to efficiently and effectively represent the states of the\nsystem in a continuous space, our system is further incorporated with a\ncharacter-based component to capture letter-level patterns. Our model achieves\nthe state-of-the-art results on ACE datasets, showing its effectiveness in\ndetecting nested mentions.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 15:53:37 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Wang", "Bailin", ""], ["Lu", "Wei", ""], ["Wang", "Yu", ""], ["Jin", "Hongxia", ""]]}, {"id": "1810.01817", "submitter": "Bailin Wang", "authors": "Bailin Wang, Wei Lu", "title": "Neural Segmental Hypergraphs for Overlapping Mention Recognition", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we propose a novel segmental hypergraph representation to model\noverlapping entity mentions that are prevalent in many practical datasets. We\nshow that our model built on top of such a new representation is able to\ncapture features and interactions that cannot be captured by previous models\nwhile maintaining a low time complexity for inference. We also present a\ntheoretical analysis to formally assess how our representation is better than\nalternative representations reported in the literature in terms of\nrepresentational power. Coupled with neural networks for feature learning, our\nmodel achieves the state-of-the-art performance in three benchmark datasets\nannotated with overlapping mentions.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 16:13:26 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Wang", "Bailin", ""], ["Lu", "Wei", ""]]}, {"id": "1810.01869", "submitter": "David Noever", "authors": "David Noever", "title": "Machine Learning Suites for Online Toxicity Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To identify and classify toxic online commentary, the modern tools of data\nscience transform raw text into key features from which either thresholding or\nlearning algorithms can make predictions for monitoring offensive\nconversations. We systematically evaluate 62 classifiers representing 19 major\nalgorithmic families against features extracted from the Jigsaw dataset of\nWikipedia comments. We compare the classifiers based on statistically\nsignificant differences in accuracy and relative execution time. Among these\nclassifiers for identifying toxic comments, tree-based algorithms provide the\nmost transparently explainable rules and rank-order the predictive contribution\nof each feature. Among 28 features of syntax, sentiment, emotion and outlier\nword dictionaries, a simple bad word list proves most predictive of offensive\ncommentary.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 13:22:44 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Noever", "David", ""]]}, {"id": "1810.01912", "submitter": "Menuka Warushavithana", "authors": "Viraj Gamage, Menuka Warushavithana, Nisansa de Silva, Amal Shehan\n  Perera, Gathika Ratnayaka and Thejan Rupasinghe", "title": "Fast Approach to Build an Automatic Sentiment Annotator for Legal Domain\n  using Transfer Learning", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes a novel way of identifying the sentiment of the phrases\nused in the legal domain. The added complexity of the language used in law, and\nthe inability of the existing systems to accurately predict the sentiments of\nwords in law are the main motivations behind this study. This is a transfer\nlearning approach, which can be used for other domain adaptation tasks as well.\nThe proposed methodology achieves an improvement of over 6\\% compared to the\nsource model's accuracy in the legal domain.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 18:45:40 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Gamage", "Viraj", ""], ["Warushavithana", "Menuka", ""], ["de Silva", "Nisansa", ""], ["Perera", "Amal Shehan", ""], ["Ratnayaka", "Gathika", ""], ["Rupasinghe", "Thejan", ""]]}, {"id": "1810.02047", "submitter": "Sergey Slavnov A", "authors": "Sergey Slavnov", "title": "Classical linear logic, cobordisms and categorical semantics of\n  categorial grammars", "comments": "A precursor of this work was posted and shortly removed under the\n  title \"\"Commutative linear logic as a multiple context-free grammar\". This\n  contained a wrong proof and a wrong claim. Linear logic grammars in general\n  are not multiple context-free and are at least as expressive as ACG", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a categorial grammar based on classical multiplicative linear\nlogic.\n  This can be seen as an extension of abstract categorial grammars (ACG) and is\nat least as expressive. However, constituents of {\\it linear logic grammars\n(LLG)} are not abstract ${\\lambda}$-terms, but simply tuples of words with\nlabeled endpoints, we call them {\\it multiwords}. At least, this gives a\nconcrete and intuitive representation of ACG.\n  A key observation is that the class of multiwords has a fundamental algebraic\nstructure. Namely, multiwords can be organized in a category, very similar to\nthe category of topological cobordisms. This category is symmetric monoidal\nclosed and compact closed and thus is a model of linear $\\lambda$-calculus and\nclassical linear logic. We think that this category is interesting on its own\nright. In particular, it might provide categorical representation for other\nformalisms.\n  On the other hand, many models of language semantics are based on commutative\nlogic or, more generally, on symmetric monoidal closed categories. But the\ncategory of {\\it word cobordisms} is a category of language elements, which is\nitself symmetric monoidal closed and independent of any grammar. Thus, it might\nprove useful in understanding language semantics as well.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 04:02:11 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 16:51:16 GMT"}, {"version": "v3", "created": "Sat, 3 Nov 2018 08:26:26 GMT"}, {"version": "v4", "created": "Sun, 16 Dec 2018 17:52:41 GMT"}, {"version": "v5", "created": "Sun, 20 Jan 2019 19:31:35 GMT"}, {"version": "v6", "created": "Sat, 9 Feb 2019 18:20:54 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Slavnov", "Sergey", ""]]}, {"id": "1810.02100", "submitter": "Juntao Yu", "authors": "Juntao Yu", "title": "Semi-Supervised Methods for Out-of-Domain Dependency Parsing", "comments": "PhD Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dependency parsing is one of the important natural language processing tasks\nthat assigns syntactic trees to texts. Due to the wider availability of\ndependency corpora and improved parsing and machine learning techniques,\nparsing accuracies of supervised learning-based systems have been significantly\nimproved. However, due to the nature of supervised learning, those parsing\nsystems highly rely on the manually annotated training corpora. They work\nreasonably good on the in-domain data but the performance drops significantly\nwhen tested on out-of-domain texts. To bridge the performance gap between\nin-domain and out-of-domain, this thesis investigates three semi-supervised\ntechniques for out-of-domain dependency parsing, namely co-training,\nself-training and dependency language models. Our approaches use easily\nobtainable unlabelled data to improve out-of-domain parsing accuracies without\nthe need of expensive corpora annotation. The evaluations on several English\ndomains and multi-lingual data show quite good improvements on parsing\naccuracy. Overall this work conducted a survey of semi-supervised methods for\nout-of-domain dependency parsing, where I extended and compared a number of\nimportant semi-supervised methods in a unified framework. The comparison\nbetween those techniques shows that self-training works equally well as\nco-training on out-of-domain parsing, while dependency language models can\nimprove both in- and out-of-domain accuracies.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 08:41:50 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Yu", "Juntao", ""]]}, {"id": "1810.02114", "submitter": "Yukun Yan", "authors": "Yukun Yan, Daqi Zheng, Zhengdong Lu, Sen Song", "title": "Zooming Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural information is important in natural language understanding.\nAlthough some current neural net-based models have a limited ability to take\nlocal syntactic information, they fail to use high-level and large-scale\nstructures of documents. This information is valuable for text understanding\nsince it contains the author's strategy to express information, in building an\neffective representation and forming appropriate output modes. We propose a\nneural net-based model, Zooming Network, capable of representing and leveraging\ntext structure of long document and developing its own analyzing rhythm to\nextract critical information. Generally, ZN consists of an encoding neural net\nthat can build a hierarchical representation of a document, and an interpreting\nneural model that can read the information at multi-levels and issuing labeling\nactions through a policy-net. Our model is trained with a hybrid paradigm of\nsupervised learning (distinguishing right and wrong decision) and reinforcement\nlearning (determining the goodness among multiple right paths). We applied the\nproposed model to long text sequence labeling tasks, with performance exceeding\nbaseline model (biLSTM-crf) by 10 F1-measure.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 09:20:32 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Yan", "Yukun", ""], ["Zheng", "Daqi", ""], ["Lu", "Zhengdong", ""], ["Song", "Sen", ""]]}, {"id": "1810.02156", "submitter": "Federico Fancellu", "authors": "Federico Fancellu, Adam Lopez, Bonnie Webber", "title": "Neural Networks for Cross-lingual Negation Scope Detection", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Negation scope has been annotated in several English and Chinese corpora, and\nhighly accurate models for this task in these languages have been learned from\nthese annotations. Unfortunately, annotations are not available in other\nlanguages. Could a model that detects negation scope be applied to a language\nthat it hasn't been trained on? We develop neural models that learn from\ncross-lingual word embeddings or universal dependencies in English, and test\nthem on Chinese, showing that they work surprisingly well. We find that\nmodelling syntax is helpful even in monolingual settings and that cross-lingual\nword embeddings help relatively little, and we analyse cases that are still\ndifficult for this task.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 11:51:47 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Fancellu", "Federico", ""], ["Lopez", "Adam", ""], ["Webber", "Bonnie", ""]]}, {"id": "1810.02229", "submitter": "Tommaso Caselli", "authors": "Tommaso Caselli", "title": "Italian Event Detection Goes Deep Learning", "comments": "to appear at CLiC-it 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper reports on a set of experiments with different word embeddings to\ninitialize a state-of-the-art Bi-LSTM-CRF network for event detection and\nclassification in Italian, following the EVENTI evaluation exercise. The net-\nwork obtains a new state-of-the-art result by improving the F1 score for\ndetection of 1.3 points, and of 6.5 points for classification, by using a\nsingle step approach. The results also provide further evidence that embeddings\nhave a major impact on the performance of such architectures.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 14:09:20 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Caselli", "Tommaso", ""]]}, {"id": "1810.02245", "submitter": "Hiroki Ouchi", "authors": "Hiroki Ouchi, Hiroyuki Shindo, Yuji Matsumoto", "title": "A Span Selection Model for Semantic Role Labeling", "comments": "Accepted by EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a simple and accurate span-based model for semantic role labeling\n(SRL). Our model directly takes into account all possible argument spans and\nscores them for each label. At decoding time, we greedily select higher scoring\nlabeled spans. One advantage of our model is to allow us to design and use\nspan-level features, that are difficult to use in token-based BIO tagging\napproaches. Experimental results demonstrate that our ensemble model achieves\nthe state-of-the-art results, 87.4 F1 and 87.0 F1 on the CoNLL-2005 and 2012\ndatasets, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 14:34:02 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Ouchi", "Hiroki", ""], ["Shindo", "Hiroyuki", ""], ["Matsumoto", "Yuji", ""]]}, {"id": "1810.02268", "submitter": "Mathias M\\\"uller", "authors": "Mathias M\\\"uller, Annette Rios, Elena Voita, Rico Sennrich", "title": "A Large-Scale Test Set for the Evaluation of Context-Aware Pronoun\n  Translation in Neural Machine Translation", "comments": "Accepted at WMT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The translation of pronouns presents a special challenge to machine\ntranslation to this day, since it often requires context outside the current\nsentence. Recent work on models that have access to information across sentence\nboundaries has seen only moderate improvements in terms of automatic evaluation\nmetrics such as BLEU. However, metrics that quantify the overall translation\nquality are ill-equipped to measure gains from additional context. We argue\nthat a different kind of evaluation is needed to assess how well models\ntranslate inter-sentential phenomena such as pronouns. This paper therefore\npresents a test suite of contrastive translations focused specifically on the\ntranslation of pronouns. Furthermore, we perform experiments with several\ncontext-aware models. We show that, while gains in BLEU are moderate for those\nsystems, they outperform baselines by a large margin in terms of accuracy on\nour contrastive test set. Our experiments also show the effectiveness of\nparameter tying for multi-encoder architectures.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 15:06:27 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 13:50:31 GMT"}, {"version": "v3", "created": "Wed, 6 Mar 2019 10:53:42 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["M\u00fcller", "Mathias", ""], ["Rios", "Annette", ""], ["Voita", "Elena", ""], ["Sennrich", "Rico", ""]]}, {"id": "1810.02338", "submitter": "Kexin Yi", "authors": "Kexin Yi, Jiajun Wu, Chuang Gan, Antonio Torralba, Pushmeet Kohli,\n  Joshua B. Tenenbaum", "title": "Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language\n  Understanding", "comments": "NeurIPS 2018 (spotlight). The first two authors contributed equally\n  to this work. Project page: http://nsvqa.csail.mit.edu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We marry two powerful ideas: deep representation learning for visual\nrecognition and language understanding, and symbolic program execution for\nreasoning. Our neural-symbolic visual question answering (NS-VQA) system first\nrecovers a structural scene representation from the image and a program trace\nfrom the question. It then executes the program on the scene representation to\nobtain an answer. Incorporating symbolic structure as prior knowledge offers\nthree unique advantages. First, executing programs on a symbolic space is more\nrobust to long program traces; our model can solve complex reasoning tasks\nbetter, achieving an accuracy of 99.8% on the CLEVR dataset. Second, the model\nis more data- and memory-efficient: it performs well after learning on a small\nnumber of training data; it can also encode an image into a compact\nrepresentation, requiring less storage than existing methods for offline\nquestion answering. Third, symbolic program execution offers full transparency\nto the reasoning process; we are thus able to interpret and diagnose each\nexecution step.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 17:38:50 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 23:07:12 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Yi", "Kexin", ""], ["Wu", "Jiajun", ""], ["Gan", "Chuang", ""], ["Torralba", "Antonio", ""], ["Kohli", "Pushmeet", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1810.02358", "submitter": "Hyeonwoo Noh", "authors": "Hyeonwoo Noh, Taehoon Kim, Jonghwan Mun, Bohyung Han", "title": "Transfer Learning via Unsupervised Task Discovery for Visual Question\n  Answering", "comments": "CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how to leverage off-the-shelf visual and linguistic data to cope\nwith out-of-vocabulary answers in visual question answering task. Existing\nlarge-scale visual datasets with annotations such as image class labels,\nbounding boxes and region descriptions are good sources for learning rich and\ndiverse visual concepts. However, it is not straightforward how the visual\nconcepts can be captured and transferred to visual question answering models\ndue to missing link between question dependent answering models and visual data\nwithout question. We tackle this problem in two steps: 1) learning a task\nconditional visual classifier, which is capable of solving diverse\nquestion-specific visual recognition tasks, based on unsupervised task\ndiscovery and 2) transferring the task conditional visual classifier to visual\nquestion answering models. Specifically, we employ linguistic knowledge sources\nsuch as structured lexical database (e.g. WordNet) and visual descriptions for\nunsupervised task discovery, and transfer a learned task conditional visual\nclassifier as an answering unit in a visual question answering model. We\nempirically show that the proposed algorithm generalizes to out-of-vocabulary\nanswers successfully using the knowledge transferred from the visual dataset.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 19:48:38 GMT"}, {"version": "v2", "created": "Sun, 7 Apr 2019 11:50:11 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Noh", "Hyeonwoo", ""], ["Kim", "Taehoon", ""], ["Mun", "Jonghwan", ""], ["Han", "Bohyung", ""]]}, {"id": "1810.02508", "submitter": "Soujanya Poria", "authors": "Soujanya Poria, Devamanyu Hazarika, Navonil Majumder, Gautam Naik,\n  Erik Cambria and Rada Mihalcea", "title": "MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in\n  Conversations", "comments": "https://affective-meld.github.io", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Emotion recognition in conversations is a challenging task that has recently\ngained popularity due to its potential applications. Until now, however, a\nlarge-scale multimodal multi-party emotional conversational database containing\nmore than two speakers per dialogue was missing. Thus, we propose the\nMultimodal EmotionLines Dataset (MELD), an extension and enhancement of\nEmotionLines. MELD contains about 13,000 utterances from 1,433 dialogues from\nthe TV-series Friends. Each utterance is annotated with emotion and sentiment\nlabels, and encompasses audio, visual and textual modalities. We propose\nseveral strong multimodal baselines and show the importance of contextual and\nmultimodal information for emotion recognition in conversations. The full\ndataset is available for use at http:// affective-meld.github.io.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 03:50:24 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 10:27:57 GMT"}, {"version": "v3", "created": "Thu, 18 Oct 2018 04:35:49 GMT"}, {"version": "v4", "created": "Tue, 23 Oct 2018 09:51:03 GMT"}, {"version": "v5", "created": "Thu, 16 May 2019 16:16:17 GMT"}, {"version": "v6", "created": "Tue, 4 Jun 2019 12:33:49 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Poria", "Soujanya", ""], ["Hazarika", "Devamanyu", ""], ["Majumder", "Navonil", ""], ["Naik", "Gautam", ""], ["Cambria", "Erik", ""], ["Mihalcea", "Rada", ""]]}, {"id": "1810.02614", "submitter": "Nikolaos Pappas", "authors": "Xiao Pu, Nikolaos Pappas, James Henderson, Andrei Popescu-Belis", "title": "Integrating Weakly Supervised Word Sense Disambiguation into Neural\n  Machine Translation", "comments": "To appear in TACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates that word sense disambiguation (WSD) can improve\nneural machine translation (NMT) by widening the source context considered when\nmodeling the senses of potentially ambiguous words. We first introduce three\nadaptive clustering algorithms for WSD, based on k-means, Chinese restaurant\nprocesses, and random walks, which are then applied to large word contexts\nrepresented in a low-rank space and evaluated on SemEval shared-task data. We\nthen learn word vectors jointly with sense vectors defined by our best WSD\nmethod, within a state-of-the-art NMT system. We show that the concatenation of\nthese vectors, and the use of a sense selection mechanism based on the weighted\naverage of sense vectors, outperforms several baselines including sense-aware\nones. This is demonstrated by translation on five language pairs. The\nimprovements are above one BLEU point over strong NMT baselines, +4% accuracy\nover all ambiguous nouns and verbs, or +20% when scored manually over several\nchallenging words.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 11:20:39 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Pu", "Xiao", ""], ["Pappas", "Nikolaos", ""], ["Henderson", "James", ""], ["Popescu-Belis", "Andrei", ""]]}, {"id": "1810.02720", "submitter": "Pengcheng Yin", "authors": "Pengcheng Yin, Graham Neubig", "title": "TRANX: A Transition-based Neural Abstract Syntax Parser for Semantic\n  Parsing and Code Generation", "comments": "EMNLP 2018 (Demo Track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present TRANX, a transition-based neural semantic parser that maps natural\nlanguage (NL) utterances into formal meaning representations (MRs). TRANX uses\na transition system based on the abstract syntax description language for the\ntarget MR, which gives it two major advantages: (1) it is highly accurate,\nusing information from the syntax of the target MR to constrain the output\nspace and model the information flow, and (2) it is highly generalizable, and\ncan easily be applied to new types of MR by just writing a new abstract syntax\ndescription corresponding to the allowable structures in the MR. Experiments on\nfour different semantic parsing and code generation tasks show that our system\nis generalizable, extensible, and effective, registering strong results\ncompared to existing neural semantic parsers.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 14:35:01 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Yin", "Pengcheng", ""], ["Neubig", "Graham", ""]]}, {"id": "1810.02741", "submitter": "Peihui Chen", "authors": "Peihui Chen", "title": "From direct tagging to Tagging with sentences compression", "comments": "9 pages, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In essence, the two tagging methods (direct tagging and tagging with\nsentences compression) are to tag the information we need by using regular\nexpression which basing on the inherent language patterns of the natural\nlanguage. Though it has many advantages in extracting regular data, Direct\ntagging is not applicable to some situations. if the data we need extract is\nnot regular and its surrounding words are regular is relatively regular, then\nwe can use information compression to cut the information we do not need before\nwe tagging the data we need. In this way we can increase the precision of the\ndata while not undermine the recall of the data.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 15:11:32 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Chen", "Peihui", ""]]}, {"id": "1810.02802", "submitter": "Ni Lao", "authors": "Gengchen Mai, Krzysztof Janowicz, Cheng He, Sumang Liu, Ni Lao", "title": "POIReviewQA: A Semantically Enriched POI Retrieval and Question\n  Answering Dataset", "comments": null, "journal-ref": "12th Workshop on Geographic Information Retrieval (GIR 2018)", "doi": "10.1145/3281354.3281359", "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many services that perform information retrieval for Points of Interest (POI)\nutilize a Lucene-based setup with spatial filtering. While this type of system\nis easy to implement it does not make use of semantics but relies on direct\nword matches between a query and reviews leading to a loss in both precision\nand recall. To study the challenging task of semantically enriching POIs from\nunstructured data in order to support open-domain search and question answering\n(QA), we introduce a new dataset POIReviewQA. It consists of 20k questions\n(e.g.\"is this restaurant dog friendly?\") for 1022 Yelp business types. For each\nquestion we sampled 10 reviews, and annotated each sentence in the reviews\nwhether it answers the question and what the corresponding answer is. To test a\nsystem's ability to understand the text we adopt an information retrieval\nevaluation by ranking all the review sentences for a question based on the\nlikelihood that they answer this question. We build a Lucene-based baseline\nmodel, which achieves 77.0% AUC and 48.8% MAP. A sentence embedding-based model\nachieves 79.2% AUC and 41.8% MAP, indicating that the dataset presents a\nchallenging problem for future research by the GIR community. The result\ntechnology can help exploit the thematic content of web documents and social\nmedia for characterisation of locations.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 17:37:37 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Mai", "Gengchen", ""], ["Janowicz", "Krzysztof", ""], ["He", "Cheng", ""], ["Liu", "Sumang", ""], ["Lao", "Ni", ""]]}, {"id": "1810.02851", "submitter": "Yaushian Wang", "authors": "Yau-Shian Wang and Hung-Yi Lee", "title": "Learning to Encode Text as Human-Readable Summaries using Generative\n  Adversarial Networks", "comments": "Accepted by EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auto-encoders compress input data into a latent-space representation and\nreconstruct the original data from the representation. This latent\nrepresentation is not easily interpreted by humans. In this paper, we propose\ntraining an auto-encoder that encodes input text into human-readable sentences,\nand unpaired abstractive summarization is thereby achieved. The auto-encoder is\ncomposed of a generator and a reconstructor. The generator encodes the input\ntext into a shorter word sequence, and the reconstructor recovers the generator\ninput from the generator output. To make the generator output human-readable, a\ndiscriminator restricts the output of the generator to resemble human-written\nsentences. By taking the generator output as the summary of the input text,\nabstractive summarization is achieved without document-summary pairs as\ntraining data. Promising results are shown on both English and Chinese corpora.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 18:58:35 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Wang", "Yau-Shian", ""], ["Lee", "Hung-Yi", ""]]}, {"id": "1810.02889", "submitter": "Anirban Laha", "authors": "Anirban Laha and Parag Jain and Abhijit Mishra and Karthik\n  Sankaranarayanan", "title": "Scalable Micro-planned Generation of Discourse from Structured Data", "comments": "Accepted for Computational Linguistics journal on 17 Sep 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for generating natural language description from\nstructured data such as tables; the problem comes under the category of\ndata-to-text natural language generation (NLG). Modern data-to-text NLG systems\ntypically employ end-to-end statistical and neural architectures that learn\nfrom a limited amount of task-specific labeled data, and therefore, exhibit\nlimited scalability, domain-adaptability, and interpretability. Unlike these\nsystems, ours is a modular, pipeline-based approach, and does not require\ntask-specific parallel data. It rather relies on monolingual corpora and basic\noff-the-shelf NLP tools. This makes our system more scalable and easily\nadaptable to newer domains.\n  Our system employs a 3-staged pipeline that: (i) converts entries in the\nstructured data to canonical form, (ii) generates simple sentences for each\natomic entry in the canonicalized representation, and (iii) combines the\nsentences to produce a coherent, fluent and adequate paragraph description\nthrough sentence compounding and co-reference replacement modules. Experiments\non a benchmark mixed-domain dataset curated for paragraph description from\ntables reveals the superiority of our system over existing data-to-text\napproaches. We also demonstrate the robustness of our system in accepting other\npopular datasets covering diverse data types such as Knowledge Graphs and\nKey-Value maps.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 21:07:11 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 14:00:08 GMT"}, {"version": "v3", "created": "Fri, 4 Oct 2019 21:34:15 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Laha", "Anirban", ""], ["Jain", "Parag", ""], ["Mishra", "Abhijit", ""], ["Sankaranarayanan", "Karthik", ""]]}, {"id": "1810.02891", "submitter": "Luong Hoang", "authors": "Luong Hoang, Sam Wiseman, Alexander M. Rush", "title": "Entity Tracking Improves Cloze-style Reading Comprehension", "comments": "EMNLP 2018 (Short Paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reading comprehension tasks test the ability of models to process long-term\ncontext and remember salient information. Recent work has shown that relatively\nsimple neural methods such as the Attention Sum-Reader can perform well on\nthese tasks; however, these systems still significantly trail human\nperformance. Analysis suggests that many of the remaining hard instances are\nrelated to the inability to track entity-references throughout documents. This\nwork focuses on these hard entity tracking cases with two extensions: (1)\nadditional entity features, and (2) training with a multi-task tracking\nobjective. We show that these simple modifications improve performance both\nindependently and in combination, and we outperform the previous state of the\nart on the LAMBADA dataset, particularly on difficult entity examples.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 21:20:25 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Hoang", "Luong", ""], ["Wiseman", "Sam", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1810.02938", "submitter": "Yi Tay", "authors": "Yi Tay, Luu Anh Tuan, Siu Cheung Hui", "title": "Co-Stack Residual Affinity Networks with Multi-level Attention\n  Refinement for Matching Text Sequences", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a matching function between two text sequences is a long standing\nproblem in NLP research. This task enables many potential applications such as\nquestion answering and paraphrase identification. This paper proposes Co-Stack\nResidual Affinity Networks (CSRAN), a new and universal neural architecture for\nthis problem. CSRAN is a deep architecture, involving stacked (multi-layered)\nrecurrent encoders. Stacked/Deep architectures are traditionally difficult to\ntrain, due to the inherent weaknesses such as difficulty with feature\npropagation and vanishing gradients. CSRAN incorporates two novel components to\ntake advantage of the stacked architecture. Firstly, it introduces a new\nbidirectional alignment mechanism that learns affinity weights by fusing\nsequence pairs across stacked hierarchies. Secondly, it leverages a multi-level\nattention refinement component between stacked recurrent layers. The key\nintuition is that, by leveraging information across all network hierarchies, we\ncan not only improve gradient flow but also improve overall performance. We\nconduct extensive experiments on six well-studied text sequence matching\ndatasets, achieving state-of-the-art performance on all.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 05:25:24 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Tay", "Yi", ""], ["Tuan", "Luu Anh", ""], ["Hui", "Siu Cheung", ""]]}, {"id": "1810.02980", "submitter": "Ivandr\\'e Paraboni", "authors": "Wesley Ramos dos Santos and Ivandre Paraboni", "title": "Personality facets recognition from text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fundamental Big Five personality traits (e.g., Extraversion) and their facets\n(e.g., Activity) are known to correlate with a broad range of linguistic\nfeatures and, accordingly, the recognition of personality traits from text is a\nwell-known Natural Language Processing task. Labelling text data with facets\ninformation, however, may require the use of lengthy personality inventories,\nand perhaps for that reason existing computational models of this kind are\nusually limited to the recognition of the fundamental traits. Based on these\nobservations, this paper investigates the issue of personality facets\nrecognition from text labelled only with information available from a shorter\npersonality inventory. In doing so, we provide a low-cost model for the\nrecognition of certain personality facets, and present reference results for\nfurther studies in this field.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 11:09:54 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 11:29:53 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Santos", "Wesley Ramos dos", ""], ["Paraboni", "Ivandre", ""]]}, {"id": "1810.03002", "submitter": "Eric Sancho Adamson", "authors": "Bj{\\o}rn Jespersen, Ana de Almeida Borges, Jorge del Castillo Tierz,\n  Juan Jos\\'e Conejero Rodr\\'iguez, Eric Sancho Adamson, Aleix Sol\\'e\n  S\\'anchez, Nika Pona, Joost J. Joosten", "title": "When logic lays down the law", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse so-called computable laws, i.e., laws that can be enforced by\nautomatic procedures. These laws should be logically perfect and unambiguous,\nbut sometimes they are not. We use a regulation on road transport to illustrate\nthis issue, and show what some fragments of this regulation would look like if\nrewritten in the image of logic. We further propose desiderata to be fulfilled\nby computable laws, and provide a critical platform from which to assess\nexisting laws and a guideline for composing future ones.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 13:25:54 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Jespersen", "Bj\u00f8rn", ""], ["Borges", "Ana de Almeida", ""], ["Tierz", "Jorge del Castillo", ""], ["Rodr\u00edguez", "Juan Jos\u00e9 Conejero", ""], ["Adamson", "Eric Sancho", ""], ["S\u00e1nchez", "Aleix Sol\u00e9", ""], ["Pona", "Nika", ""], ["Joosten", "Joost J.", ""]]}, {"id": "1810.03031", "submitter": "Erion \\c{C}ano", "authors": "Erion \\c{C}ano", "title": "Text-based Sentiment Analysis and Music Emotion Recognition", "comments": "Ph.D. Thesis", "journal-ref": null, "doi": "10.6092/polito/porto/2709436", "report-no": null, "categories": "cs.CL cs.HC cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Sentiment polarity of tweets, blog posts or product reviews has become highly\nattractive and is utilized in recommender systems, market predictions, business\nintelligence and more. Deep learning techniques are becoming top performers on\nanalyzing such texts. There are however several problems that need to be solved\nfor efficient use of deep neural networks on text mining and text polarity\nanalysis. First, deep neural networks need to be fed with data sets that are\nbig in size as well as properly labeled. Second, there are various\nuncertainties regarding the use of word embedding vectors: should they be\ngenerated from the same data set that is used to train the model or it is\nbetter to source them from big and popular collections? Third, to simplify\nmodel creation it is convenient to have generic neural network architectures\nthat are effective and can adapt to various texts, encapsulating much of design\ncomplexity. This thesis addresses the above problems to provide methodological\nand practical insights for utilizing neural networks on sentiment analysis of\ntexts and achieving state of the art results. Regarding the first problem, the\neffectiveness of various crowdsourcing alternatives is explored and two\nmedium-sized and emotion-labeled song data sets are created utilizing social\ntags. To address the second problem, a series of experiments with large text\ncollections of various contents and domains were conducted, trying word\nembeddings of various parameters. Regarding the third problem, a series of\nexperiments involving convolution and max-pooling neural layers were conducted.\nCombining convolutions of words, bigrams, and trigrams with regional\nmax-pooling layers in a couple of stacks produced the best results. The derived\narchitecture achieves competitive performance on sentiment polarity analysis of\nmovie, business and product reviews.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 17:42:19 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["\u00c7ano", "Erion", ""]]}, {"id": "1810.03067", "submitter": "Keith Harrigian", "authors": "Keith Harrigian", "title": "Geocoding Without Geotags: A Text-based Approach for reddit", "comments": "Accepted to the EMNLP Workshop on Noisy User-generated Text (W-NUT).\n  Brussels, Belgium. November 1, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we introduce the first geolocation inference approach for\nreddit, a social media platform where user pseudonymity has thus far made\nsupervised demographic inference difficult to implement and validate. In\nparticular, we design a text-based heuristic schema to generate ground truth\nlocation labels for reddit users in the absence of explicitly geotagged data.\nAfter evaluating the accuracy of our labeling procedure, we train and test\nseveral geolocation inference models across our reddit data set and three\nbenchmark Twitter geolocation data sets. Ultimately, we show that geolocation\nmodels trained and applied on the same domain substantially outperform models\nattempting to transfer training data across domains, even more so on reddit\nwhere platform-specific interest-group metadata can be used to improve\ninferences.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 01:46:27 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Harrigian", "Keith", ""]]}, {"id": "1810.03148", "submitter": "Karin Sim Smith", "authors": "Karin Sim Smith and Lucia Specia", "title": "Assessing Crosslingual Discourse Relations in Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an attempt to improve overall translation quality, there has been an\nincreasing focus on integrating more linguistic elements into Machine\nTranslation (MT). While significant progress has been achieved, especially\nrecently with neural models, automatically evaluating the output of such\nsystems is still an open problem. Current practice in MT evaluation relies on a\nsingle reference translation, even though there are many ways of translating a\nparticular text, and it tends to disregard higher level information such as\ndiscourse. We propose a novel approach that assesses the translated output\nbased on the source text rather than the reference translation, and measures\nthe extent to which the semantics of the discourse elements (discourse\nrelations, in particular) in the source text are preserved in the MT output.\nThe challenge is to detect the discourse relations in the source text and\ndetermine whether these relations are correctly transferred crosslingually to\nthe target language -- without a reference translation. This methodology could\nbe used independently for discourse-level evaluation, or as a component in\nother metrics, at a time where substantial amounts of MT are online and would\nbenefit from evaluation where the source text serves as a benchmark.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 14:14:27 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Smith", "Karin Sim", ""], ["Specia", "Lucia", ""]]}, {"id": "1810.03167", "submitter": "Zhiqing Sun", "authors": "Zhiqing Sun and Zhi-Hong Deng", "title": "Unsupervised Neural Word Segmentation for Chinese via Segmental Language\n  Modeling", "comments": "To appear in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous traditional approaches to unsupervised Chinese word segmentation\n(CWS) can be roughly classified into discriminative and generative models. The\nformer uses the carefully designed goodness measures for candidate\nsegmentation, while the latter focuses on finding the optimal segmentation of\nthe highest generative probability. However, while there exists a trivial way\nto extend the discriminative models into neural version by using neural\nlanguage models, those of generative ones are non-trivial. In this paper, we\npropose the segmental language models (SLMs) for CWS. Our approach explicitly\nfocuses on the segmental nature of Chinese, as well as preserves several\nproperties of language models. In SLMs, a context encoder encodes the previous\ncontext and a segment decoder generates each segment incrementally. As far as\nwe know, we are the first to propose a neural model for unsupervised CWS and\nachieve competitive performance to the state-of-the-art statistical models on\nfour different datasets from SIGHAN 2005 bakeoff.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 15:55:58 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Sun", "Zhiqing", ""], ["Deng", "Zhi-Hong", ""]]}, {"id": "1810.03184", "submitter": "Gia Ngo", "authors": "Gia H. Ngo, Minh Nguyen, Nancy F. Chen", "title": "Phonology-Augmented Statistical Framework for Machine Transliteration\n  using Limited Linguistic Resources", "comments": "Accepted by IEEE Transactions on Audio, Speech and Language\n  Processing. Copyright 2018 IEEE", "journal-ref": "IEEE/ACM Transactions on Audio, Speech and Language Processing.\n  27(2019) 199-211", "doi": "10.1109/TASLP.2018.2875269", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transliteration converts words in a source language (e.g., English) into\nwords in a target language (e.g., Vietnamese). This conversion considers the\nphonological structure of the target language, as the transliterated output\nneeds to be pronounceable in the target language. For example, a word in\nVietnamese that begins with a consonant cluster is phonologically invalid and\nthus would be an incorrect output of a transliteration system. Most statistical\ntransliteration approaches, albeit being widely adopted, do not explicitly\nmodel the target language's phonology, which often results in invalid outputs.\nThe problem is compounded by the limited linguistic resources available when\nconverting foreign words to transliterated words in the target language. In\nthis work, we present a phonology-augmented statistical framework suitable for\ntransliteration, especially when only limited linguistic resources are\navailable. We propose the concept of pseudo-syllables as structures\nrepresenting how segments of a foreign word are organized according to the\nsyllables of the target language's phonology. We performed transliteration\nexperiments on Vietnamese and Cantonese. We show that the proposed framework\noutperforms the statistical baseline by up to 44.68% relative, when there are\nlimited training examples (587 entries).\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 17:32:11 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Ngo", "Gia H.", ""], ["Nguyen", "Minh", ""], ["Chen", "Nancy F.", ""]]}, {"id": "1810.03274", "submitter": "Yu Gong", "authors": "Yunlun Yang, Yu Gong, Xi Chen", "title": "Query Tracking for E-commerce Conversational Search: A Machine\n  Comprehension Perspective", "comments": "CIKM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of dialog techniques, conversational search has\nattracted more and more attention as it enables users to interact with the\nsearch engine in a natural and efficient manner. However, comparing with the\nnatural language understanding in traditional task-oriented dialog which\nfocuses on slot filling and tracking, the query understanding in E-commerce\nconversational search is quite different and more challenging due to more\ndiverse user expressions and complex intentions. In this work, we define the\nreal-world problem of query tracking in E-commerce conversational search, in\nwhich the goal is to update the internal query after each round of interaction.\nWe also propose a self attention based neural network to handle the task in a\nmachine comprehension perspective. Further more we build a novel E-commerce\nquery tracking dataset from an operational E-commerce Search Engine, and\nexperimental results on this dataset suggest that our proposed model\noutperforms several baseline methods by a substantial gain for Exact Match\naccuracy and F1 score, showing the potential of machine comprehension like\nmodel for this task.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 05:27:44 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Yang", "Yunlun", ""], ["Gong", "Yu", ""], ["Chen", "Xi", ""]]}, {"id": "1810.03352", "submitter": "Igor Shalyminov", "authors": "Igor Shalyminov, Arash Eshghi, and Oliver Lemon", "title": "Multi-Task Learning for Domain-General Spoken Disfluency Detection in\n  Dialogue Systems", "comments": "9 pages, 1 figure, 7 tables. Accepted as a full paper for SemDial\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spontaneous spoken dialogue is often disfluent, containing pauses,\nhesitations, self-corrections and false starts. Processing such phenomena is\nessential in understanding a speaker's intended meaning and controlling the\nflow of the conversation. Furthermore, this processing needs to be word-by-word\nincremental to allow further downstream processing to begin as early as\npossible in order to handle real spontaneous human conversational behaviour.\n  In addition, from a developer's point of view, it is highly desirable to be\nable to develop systems which can be trained from `clean' examples while also\nable to generalise to the very diverse disfluent variations on the same data --\nthereby enhancing both data-efficiency and robustness. In this paper, we\npresent a multi-task LSTM-based model for incremental detection of disfluency\nstructure, which can be hooked up to any component for incremental\ninterpretation (e.g. an incremental semantic parser), or else simply used to\n`clean up' the current utterance as it is being produced.\n  We train the system on the Switchboard Dialogue Acts (SWDA) corpus and\npresent its accuracy on this dataset. Our model outperforms prior neural\nnetwork-based incremental approaches by about 10 percentage points on SWDA\nwhile employing a simpler architecture. To test the model's generalisation\npotential, we evaluate the same model on the bAbI+ dataset, without any\nadditional training. bAbI+ is a dataset of synthesised goal-oriented dialogues\nwhere we control the distribution of disfluencies and their types. This shows\nthat our approach has good generalisation potential, and sheds more light on\nwhich types of disfluency might be amenable to domain-general processing.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 09:57:44 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Shalyminov", "Igor", ""], ["Eshghi", "Arash", ""], ["Lemon", "Oliver", ""]]}, {"id": "1810.03430", "submitter": "Mohd Zeeshan Ansari", "authors": "Mohd Zeeshan Ansari, Tanvir Ahmad and Md Arshad Ali", "title": "Cross Script Hindi English NER Corpus from Wikipedia", "comments": "International Conference on Intelligent Data Communication\n  Technologies and Internet of Things (ICICI-2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The text generated on social media platforms is essentially a mixed lingual\ntext. The mixing of language in any form produces considerable amount of\ndifficulty in language processing systems. Moreover, the advancements in\nlanguage processing research depends upon the availability of standard corpora.\nThe development of mixed lingual Indian Named Entity Recognition (NER) systems\nare facing obstacles due to unavailability of the standard evaluation corpora.\nSuch corpora may be of mixed lingual nature in which text is written using\nmultiple languages predominantly using a single script only. The motivation of\nour work is to emphasize the automatic generation such kind of corpora in order\nto encourage mixed lingual Indian NER. The paper presents the preparation of a\nCross Script Hindi-English Corpora from Wikipedia category pages. The corpora\nis successfully annotated using standard CoNLL-2003 categories of PER, LOC,\nORG, and MISC. Its evaluation is carried out on a variety of machine learning\nalgorithms and favorable results are achieved.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 13:25:05 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Ansari", "Mohd Zeeshan", ""], ["Ahmad", "Tanvir", ""], ["Ali", "Md Arshad", ""]]}, {"id": "1810.03444", "submitter": "Xuan Phi Nguyen", "authors": "Phi Xuan Nguyen, Shafiq Joty", "title": "Phrase-Based Attentions", "comments": "Under review as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most state-of-the-art neural machine translation systems, despite being\ndifferent in architectural skeletons (e.g. recurrence, convolutional), share an\nindispensable feature: the Attention. However, most existing attention methods\nare token-based and ignore the importance of phrasal alignments, the key\ningredient for the success of phrase-based statistical machine translation. In\nthis paper, we propose novel phrase-based attention methods to model n-grams of\ntokens as attention entities. We incorporate our phrase-based attentions into\nthe recently proposed Transformer network, and demonstrate that our approach\nyields improvements of 1.3 BLEU for English-to-German and 0.5 BLEU for\nGerman-to-English translation tasks on WMT newstest2014 using WMT'16 training\ndata.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 16:28:40 GMT"}], "update_date": "2019-08-17", "authors_parsed": [["Nguyen", "Phi Xuan", ""], ["Joty", "Shafiq", ""]]}, {"id": "1810.03445", "submitter": "Zhu Gao", "authors": "Zhu Gao, Yanhui Jiang, Junhui Gao", "title": "Building a language evolution tree based on word vector combination\n  model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we try to explore the evolution of language through case\ncalculations. First, we chose the novels of eleven British writers from 1400 to\n2005 and found the corresponding works; Then, we use the natural language\nprocessing tool to construct the corresponding eleven corpora, and calculate\nthe respective word vectors of 100 high-frequency words in eleven corpora;\nNext, for each corpus, we concatenate the 100 word vectors from beginning to\nend into one; Finally, we use the similarity comparison and hierarchical\nclustering method to generate the relationship tree between the combined eleven\nword vectors. This tree represents the relationship between eleven corpora. We\nfound that in the tree generated by clustering, the distance between the corpus\nand the year corresponding to the corpus are basically the same. This means\nthat we have discovered a specific language evolution tree. To verify the\nstability and versatility of this method, we add three other themes: Dickens's\neight works, the 19th century poets' works, and art criticism of recent 60\nyears. For these four themes, we tested different parameters such as the time\nspan of the corpus, the time interval between the corpora, the dimension of the\nword vector, and the number of high-frequency public words. The results show\nthat this is fairly stable and versatile.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 14:25:36 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Gao", "Zhu", ""], ["Jiang", "Yanhui", ""], ["Gao", "Junhui", ""]]}, {"id": "1810.03449", "submitter": "Shaobo Liu", "authors": "Shaobo Liu and Rui Cheng and Xiaoming Yu and Xueqi Cheng", "title": "Exploiting Contextual Information via Dynamic Memory Network for Event\n  Detection", "comments": "Accepted as short paper by EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of event detection involves identifying and categorizing event\ntriggers. Contextual information has been shown effective on the task. However,\nexisting methods which utilize contextual information only process the context\nonce. We argue that the context can be better exploited by processing the\ncontext multiple times, allowing the model to perform complex reasoning and to\ngenerate better context representation, thus improving the overall performance.\nMeanwhile, dynamic memory network (DMN) has demonstrated promising capability\nin capturing contextual information and has been applied successfully to\nvarious tasks. In light of the multi-hop mechanism of the DMN to model the\ncontext, we propose the trigger detection dynamic memory network (TD-DMN) to\ntackle the event detection problem. We performed a five-fold cross-validation\non the ACE-2005 dataset and experimental results show that the multi-hop\nmechanism does improve the performance and the proposed model achieves best\n$F_1$ score compared to the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 08:43:11 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Liu", "Shaobo", ""], ["Cheng", "Rui", ""], ["Yu", "Xiaoming", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1810.03450", "submitter": "Stanislav Peshterliev", "authors": "Stanislav Peshterliev, John Kearney, Abhyuday Jagannatha, Imre Kiss,\n  Spyros Matsoukas", "title": "Active Learning for New Domains in Natural Language Understanding", "comments": "NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore active learning (AL) for improving the accuracy of new domains in\na natural language understanding (NLU) system. We propose an algorithm called\nMajority-CRF that uses an ensemble of classification models to guide the\nselection of relevant utterances, as well as a sequence labeling model to help\nprioritize informative examples. Experiments with three domains show that\nMajority-CRF achieves 6.6%-9% relative error rate reduction compared to random\nsampling with the same annotation budget, and statistically significant\nimprovements compared to other AL approaches. Additionally, case studies with\nhuman-in-the-loop AL on six new domains show 4.6%-9% improvement on an existing\nNLU system.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 12:50:56 GMT"}, {"version": "v2", "created": "Sat, 30 Mar 2019 16:04:09 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Peshterliev", "Stanislav", ""], ["Kearney", "John", ""], ["Jagannatha", "Abhyuday", ""], ["Kiss", "Imre", ""], ["Matsoukas", "Spyros", ""]]}, {"id": "1810.03459", "submitter": "Murali Karthick Baskar", "authors": "Jaejin Cho, Murali Karthick Baskar, Ruizhi Li, Matthew Wiesner, Sri\n  Harish Mallidi, Nelson Yalta, Martin Karafiat, Shinji Watanabe, Takaaki Hori", "title": "Multilingual sequence-to-sequence speech recognition: architecture,\n  transfer learning, and language modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sequence-to-sequence (seq2seq) approach for low-resource ASR is a relatively\nnew direction in speech research. The approach benefits by performing model\ntraining without using lexicon and alignments. However, this poses a new\nproblem of requiring more data compared to conventional DNN-HMM systems. In\nthis work, we attempt to use data from 10 BABEL languages to build a\nmulti-lingual seq2seq model as a prior model, and then port them towards 4\nother BABEL languages using transfer learning approach. We also explore\ndifferent architectures for improving the prior multilingual seq2seq model. The\npaper also discusses the effect of integrating a recurrent neural network\nlanguage model (RNNLM) with a seq2seq model during decoding. Experimental\nresults show that the transfer learning approach from the multilingual model\nshows substantial gains over monolingual models across all 4 BABEL languages.\nIncorporating an RNNLM also brings significant improvements in terms of %WER,\nand achieves recognition performance comparable to the models trained with\ntwice more training data.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 08:53:42 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Cho", "Jaejin", ""], ["Baskar", "Murali Karthick", ""], ["Li", "Ruizhi", ""], ["Wiesner", "Matthew", ""], ["Mallidi", "Sri Harish", ""], ["Yalta", "Nelson", ""], ["Karafiat", "Martin", ""], ["Watanabe", "Shinji", ""], ["Hori", "Takaaki", ""]]}, {"id": "1810.03479", "submitter": "Xu Han", "authors": "Xu Han, Hongsu Wang, Sanqian Zhang, Qunchao Fu, Jun S. Liu", "title": "Sentence Segmentation for Classical Chinese Based on LSTM with Radical\n  Embedding", "comments": "The Journal of China Universities of Posts and Telecommunications,\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a low than character feature embedding called\nradical embedding, and apply it on LSTM model for sentence segmentation of pre\nmodern Chinese texts. The datasets includes over 150 classical Chinese books\nfrom 3 different dynasties and contains different literary styles. LSTM CRF\nmodel is a state of art method for the sequence labeling problem. Our new model\nadds a component of radical embedding, which leads to improved performances.\nExperimental results based on the aforementioned Chinese books demonstrates a\nbetter accuracy than earlier methods on sentence segmentation, especial in Tang\nEpitaph texts.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 14:49:42 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Han", "Xu", ""], ["Wang", "Hongsu", ""], ["Zhang", "Sanqian", ""], ["Fu", "Qunchao", ""], ["Liu", "Jun S.", ""]]}, {"id": "1810.03480", "submitter": "Arnaud Mignan", "authors": "Arnaud Mignan", "title": "Text Classification of the Precursory Accelerating Seismicity Corpus:\n  Inference on some Theoretical Trends in Earthquake Predictability Research\n  from 1988 to 2018", "comments": "21 pages, 3 figures, 7 tables", "journal-ref": "Journal of Seismology, 2019", "doi": "10.1007/s10950-019-09833-2", "report-no": null, "categories": "cs.CL physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text analytics based on supervised machine learning classifiers has shown\ngreat promise in a multitude of domains, but has yet to be applied to\nSeismology. We test various standard models (Naive Bayes, k-Nearest Neighbors,\nSupport Vector Machines, and Random Forests) on a seismological corpus of 100\narticles related to the topic of precursory accelerating seismicity, spanning\nfrom 1988 to 2010. This corpus was labelled in Mignan (2011) with the precursor\nwhether explained by critical processes (i.e., cascade triggering) or by other\nprocesses (such as signature of main fault loading). We investigate rather the\nclassification process can be automatized to help analyze larger corpora in\norder to better understand trends in earthquake predictability research. We\nfind that the Naive Bayes model performs best, in agreement with the machine\nlearning literature for the case of small datasets, with cross-validation\naccuracies of 86% for binary classification. For a refined multiclass\nclassification ('non-critical process' < 'agnostic' < 'critical process\nassumed' < 'critical process demonstrated'), we obtain up to 78% accuracy.\nPrediction on a dozen of articles published since 2011 shows however a weak\ngeneralization with a F1-score of 60%, only slightly better than a random\nclassifier, which can be explained by a change of authorship and use of\ndifferent terminologies. Yet, the model shows F1-scores greater than 80% for\nthe two multiclass extremes ('non-critical process' versus 'critical process\ndemonstrated') while it falls to random classifier results (around 25%) for\npapers labelled 'agnostic' or 'critical process assumed'. Those results are\nencouraging in view of the small size of the corpus and of the high degree of\nabstraction of the labelling. Domain knowledge engineering remains essential\nbut can be made transparent by an investigation of Naive Bayes keyword\nposterior probabilities.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 16:15:14 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Mignan", "Arnaud", ""]]}, {"id": "1810.03541", "submitter": "Yijia Liu", "authors": "Yijia Liu, Wanxiang Che, Bo Zheng, Bing Qin, Ting Liu", "title": "An AMR Aligner Tuned by Transition-based Parser", "comments": "EMNLP2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new rich resource enhanced AMR aligner which\nproduces multiple alignments and a new transition system for AMR parsing along\nwith its oracle parser. Our aligner is further tuned by our oracle parser via\npicking the alignment that leads to the highest-scored achievable AMR graph.\nExperimental results show that our aligner outperforms the rule-based aligner\nin previous work by achieving higher alignment F1 score and consistently\nimproving two open-sourced AMR parsers. Based on our aligner and transition\nsystem, we develop a transition-based AMR parser that parses a sentence into\nits AMR graph directly. An ensemble of our parsers with only words and POS tags\nas input leads to 68.4 Smatch F1 score.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 16:00:50 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Liu", "Yijia", ""], ["Che", "Wanxiang", ""], ["Zheng", "Bo", ""], ["Qin", "Bing", ""], ["Liu", "Ting", ""]]}, {"id": "1810.03552", "submitter": "Xilun Chen", "authors": "Xilun Chen, Ahmed Hassan Awadallah, Hany Hassan, Wei Wang, Claire\n  Cardie", "title": "Multi-Source Cross-Lingual Model Transfer: Learning What to Share", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern NLP applications have enjoyed a great boost utilizing neural networks\nmodels. Such deep neural models, however, are not applicable to most human\nlanguages due to the lack of annotated training data for various NLP tasks.\nCross-lingual transfer learning (CLTL) is a viable method for building NLP\nmodels for a low-resource target language by leveraging labeled data from other\n(source) languages. In this work, we focus on the multilingual transfer setting\nwhere training data in multiple source languages is leveraged to further boost\ntarget language performance.\n  Unlike most existing methods that rely only on language-invariant features\nfor CLTL, our approach coherently utilizes both language-invariant and\nlanguage-specific features at instance level. Our model leverages adversarial\nnetworks to learn language-invariant features, and mixture-of-experts models to\ndynamically exploit the similarity between the target language and each\nindividual source language. This enables our model to learn effectively what to\nshare between various languages in the multilingual setup. Moreover, when\ncoupled with unsupervised multilingual embeddings, our model can operate in a\nzero-resource setting where neither target language training data nor\ncross-lingual resources are available. Our model achieves significant\nperformance gains over prior art, as shown in an extensive set of experiments\nover multiple text classification and sequence tagging tasks including a\nlarge-scale industry dataset.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 16:11:01 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 17:06:49 GMT"}, {"version": "v3", "created": "Wed, 5 Jun 2019 04:04:07 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Chen", "Xilun", ""], ["Awadallah", "Ahmed Hassan", ""], ["Hassan", "Hany", ""], ["Wang", "Wei", ""], ["Cardie", "Claire", ""]]}, {"id": "1810.03581", "submitter": "Jiacheng Zhang", "authors": "Jiacheng Zhang, Huanbo Luan, Maosong Sun, FeiFei Zhai, Jingfang Xu,\n  Min Zhang and Yang Liu", "title": "Improving the Transformer Translation Model with Document-Level Context", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the Transformer translation model (Vaswani et al., 2017) has\nachieved state-of-the-art performance in a variety of translation tasks, how to\nuse document-level context to deal with discourse phenomena problematic for\nTransformer still remains a challenge. In this work, we extend the Transformer\nmodel with a new context encoder to represent document-level context, which is\nthen incorporated into the original encoder and decoder. As large-scale\ndocument-level parallel corpora are usually not available, we introduce a\ntwo-step training method to take full advantage of abundant sentence-level\nparallel corpora and limited document-level parallel corpora. Experiments on\nthe NIST Chinese-English datasets and the IWSLT French-English datasets show\nthat our approach improves over Transformer significantly.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 17:09:10 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Zhang", "Jiacheng", ""], ["Luan", "Huanbo", ""], ["Sun", "Maosong", ""], ["Zhai", "FeiFei", ""], ["Xu", "Jingfang", ""], ["Zhang", "Min", ""], ["Liu", "Yang", ""]]}, {"id": "1810.03595", "submitter": "Shunsuke Kitada", "authors": "Shunsuke Kitada, Ryunosuke Kotani, Hitoshi Iyatomi", "title": "End-to-End Text Classification via Image-based Embedding using\n  Character-level Networks", "comments": "To appear in IEEE Applied Imagery Pattern Recognition (AIPR) 2018\n  workshop", "journal-ref": null, "doi": "10.1109/AIPR.2018.8707407", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For analysing and/or understanding languages having no word boundaries based\non morphological analysis such as Japanese, Chinese, and Thai, it is desirable\nto perform appropriate word segmentation before word embeddings. But it is\ninherently difficult in these languages. In recent years, various language\nmodels based on deep learning have made remarkable progress, and some of these\nmethodologies utilizing character-level features have successfully avoided such\na difficult problem. However, when a model is fed character-level features of\nthe above languages, it often causes overfitting due to a large number of\ncharacter types. In this paper, we propose a CE-CLCNN, character-level\nconvolutional neural networks using a character encoder to tackle these\nproblems. The proposed CE-CLCNN is an end-to-end learning model and has an\nimage-based character encoder, i.e. the CE-CLCNN handles each character in the\ntarget document as an image. Through various experiments, we found and\nconfirmed that our CE-CLCNN captured closely embedded features for visually and\nsemantically similar characters and achieves state-of-the-art results on\nseveral open document classification tasks. In this paper we report the\nperformance of our CE-CLCNN with the Wikipedia title estimation task and\nanalyse the internal behaviour.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 17:44:34 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 12:14:04 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Kitada", "Shunsuke", ""], ["Kotani", "Ryunosuke", ""], ["Iyatomi", "Hitoshi", ""]]}, {"id": "1810.03655", "submitter": "Takuya Yoshioka", "authors": "Takuya Yoshioka, Hakan Erdogan, Zhuo Chen, Xiong Xiao, Fil Alleva", "title": "Recognizing Overlapped Speech in Meetings: A Multichannel Separation\n  Approach Using Neural Networks", "comments": null, "journal-ref": "Proc. Interspeech 2018, 3038-3042", "doi": "10.21437/Interspeech.2018-2284", "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this work is to develop a meeting transcription system that can\nrecognize speech even when utterances of different speakers are overlapped.\nWhile speech overlaps have been regarded as a major obstacle in accurately\ntranscribing meetings, a traditional beamformer with a single output has been\nexclusively used because previously proposed speech separation techniques have\ncritical constraints for application to real meetings. This paper proposes a\nnew signal processing module, called an unmixing transducer, and describes its\nimplementation using a windowed BLSTM. The unmixing transducer has a fixed\nnumber, say J, of output channels, where J may be different from the number of\nmeeting attendees, and transforms an input multi-channel acoustic signal into J\ntime-synchronous audio streams. Each utterance in the meeting is separated and\nemitted from one of the output channels. Then, each output signal can be simply\nfed to a speech recognition back-end for segmentation and transcription. Our\nmeeting transcription system using the unmixing transducer outperforms a system\nbased on a state-of-the-art neural mask-based beamformer by 10.8%. Significant\nimprovements are observed in overlapped segments. To the best of our knowledge,\nthis is the first report that applies overlapped speech recognition to\nunconstrained real meeting audio.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 18:50:54 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Yoshioka", "Takuya", ""], ["Erdogan", "Hakan", ""], ["Chen", "Zhuo", ""], ["Xiao", "Xiong", ""], ["Alleva", "Fil", ""]]}, {"id": "1810.03660", "submitter": "Jacopo Staiano", "authors": "Oscar Araque, Lorenzo Gatti, Jacopo Staiano, Marco Guerini", "title": "DepecheMood++: a Bilingual Emotion Lexicon Built Through Simple Yet\n  Powerful Techniques", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several lexica for sentiment analysis have been developed and made available\nin the NLP community. While most of these come with word polarity annotations\n(e.g. positive/negative), attempts at building lexica for finer-grained emotion\nanalysis (e.g. happiness, sadness) have recently attracted significant\nattention. Such lexica are often exploited as a building block in the process\nof developing learning models for which emotion recognition is needed, and/or\nused as baselines to which compare the performance of the models. In this work,\nwe contribute two new resources to the community: a) an extension of an\nexisting and widely used emotion lexicon for English; and b) a novel version of\nthe lexicon targeting Italian. Furthermore, we show how simple techniques can\nbe used, both in supervised and unsupervised experimental settings, to boost\nperformances on datasets and tasks of varying degree of domain-specificity.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 19:05:23 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Araque", "Oscar", ""], ["Gatti", "Lorenzo", ""], ["Staiano", "Jacopo", ""], ["Guerini", "Marco", ""]]}, {"id": "1810.03717", "submitter": "Judy Hanwen Shen", "authors": "Judy Hanwen Shen, Matthias Hofer, Bjarke Felbo, Roger Levy", "title": "Comparing Models of Associative Meaning: An Empirical Investigation of\n  Reference in Simple Language Games", "comments": "Conference on Computational Natural Language Learning (CoNLL) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simple reference games are of central theoretical and empirical importance in\nthe study of situated language use. Although language provides rich,\ncompositional truth-conditional semantics to facilitate reference, speakers and\nlisteners may sometimes lack the overall lexical and cognitive resources to\nguarantee successful reference through these means alone. However, language\nalso has rich associational structures that can serve as a further resource for\nachieving successful reference. Here we investigate this use of associational\ninformation in a setting where only associational information is available: a\nsimplified version of the popular game Codenames. Using optimal experiment\ndesign techniques, we compare a range of models varying in the type of\nassociative information deployed and in level of pragmatic sophistication\nagainst human behavior. In this setting, we find that listeners' behavior\nreflects direct bigram collocational associations more strongly than\nword-embedding or semantic knowledge graph-based associations and that there is\nlittle evidence for pragmatically sophisticated behavior by either speakers or\nlisteners of the type that might be predicted by recursive-reasoning models\nsuch as the Rational Speech Acts theory. These results shed light on the nature\nof the lexical resources that speakers and listeners can bring to bear in\nachieving reference through associative meaning alone.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 21:51:44 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Shen", "Judy Hanwen", ""], ["Hofer", "Matthias", ""], ["Felbo", "Bjarke", ""], ["Levy", "Roger", ""]]}, {"id": "1810.03875", "submitter": "Aliaksandr Huminski", "authors": "Aliaksandr Huminski, Hao Zhang, Gangeshwar Krishnamurthy", "title": "Towards Verifying Semantic Roles Co-occurrence", "comments": "5 pages, 1 figure, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic role theory considers roles as a small universal set of unanalyzed\nentities. It means that formally there are no restrictions on role\ncombinations. We argue that the semantic roles co-occur in verb\nrepresentations. It means that there are hidden restrictions on role\ncombinations. To demonstrate that a practical and evidence-based approach has\nbeen built on in-depth analysis of the largest verb database VerbNet. The\nconsequences of this approach are considered.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 09:28:27 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Huminski", "Aliaksandr", ""], ["Zhang", "Hao", ""], ["Krishnamurthy", "Gangeshwar", ""]]}, {"id": "1810.03879", "submitter": "Aliaksandr Huminski", "authors": "Aliaksandr Huminski, Hao Zhang", "title": "Event Representation through Semantic Roles: Evaluation of Coverage", "comments": "5 pages, 1 table, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic role theory is a widely used approach for event representation. Yet,\nthere are multiple indications that semantic role paradigm is necessary but not\nsufficient to cover all elements of event structure. We conducted an analysis\nof semantic role representation for events to provide an empirical evidence of\ninsufficiency. The consequence of that is a hybrid role-scalar approach. The\nresults are considered as preliminary in investigation of semantic roles\ncoverage for event representation.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 09:37:31 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Huminski", "Aliaksandr", ""], ["Zhang", "Hao", ""]]}, {"id": "1810.03947", "submitter": "Pankaj Gupta", "authors": "Pankaj Gupta and Yatin Chaudhary and Florian Buettner and Hinrich\n  Sch\\\"utze", "title": "textTOvec: Deep Contextualized Neural Autoregressive Topic Models of\n  Language with Distributed Compositional Prior", "comments": "Published in #ICLR2019 International Conference on Learning\n  Representations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address two challenges of probabilistic topic modelling in order to better\nestimate the probability of a word in a given context, i.e., P(word|context):\n(1) No Language Structure in Context: Probabilistic topic models ignore word\norder by summarizing a given context as a \"bag-of-word\" and consequently the\nsemantics of words in the context is lost. The LSTM-LM learns a vector-space\nrepresentation of each word by accounting for word order in local collocation\npatterns and models complex characteristics of language (e.g., syntax and\nsemantics), while the TM simultaneously learns a latent representation from the\nentire document and discovers the underlying thematic structure. We unite two\ncomplementary paradigms of learning the meaning of word occurrences by\ncombining a TM (e.g., DocNADE) and a LM in a unified probabilistic framework,\nnamed as ctx-DocNADE. (2) Limited Context and/or Smaller training corpus of\ndocuments: In settings with a small number of word occurrences (i.e., lack of\ncontext) in short text or data sparsity in a corpus of few documents, the\napplication of TMs is challenging. We address this challenge by incorporating\nexternal knowledge into neural autoregressive topic models via a language\nmodelling approach: we use word embeddings as input of a LSTM-LM with the aim\nto improve the word-topic mapping on a smaller and/or short-text corpus. The\nproposed DocNADE extension is named as ctx-DocNADEe.\n  We present novel neural autoregressive topic model variants coupled with\nneural LMs and embeddings priors that consistently outperform state-of-the-art\ngenerative TMs in terms of generalization (perplexity), interpretability (topic\ncoherence) and applicability (retrieval and classification) over 6 long-text\nand 8 short-text datasets from diverse domains.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 13:04:25 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 11:29:00 GMT"}, {"version": "v3", "created": "Sun, 25 Nov 2018 11:40:26 GMT"}, {"version": "v4", "created": "Sat, 23 Feb 2019 14:14:05 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Gupta", "Pankaj", ""], ["Chaudhary", "Yatin", ""], ["Buettner", "Florian", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1810.03975", "submitter": "Parnia Bahar", "authors": "Parnia Bahar, Christopher Brix and Hermann Ney", "title": "Towards Two-Dimensional Sequence to Sequence Model in Neural Machine\n  Translation", "comments": "7 pages, EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates an alternative model for neural machine translation\n(NMT) and proposes a novel architecture, where we employ a multi-dimensional\nlong short-term memory (MDLSTM) for translation modeling. In the\nstate-of-the-art methods, source and target sentences are treated as\none-dimensional sequences over time, while we view translation as a\ntwo-dimensional (2D) mapping using an MDLSTM layer to define the correspondence\nbetween source and target words. We extend beyond the current sequence to\nsequence backbone NMT models to a 2D structure in which the source and target\nsentences are aligned with each other in a 2D grid. Our proposed topology shows\nconsistent improvements over attention-based sequence to sequence model on two\nWMT 2017 tasks, German$\\leftrightarrow$English.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 13:42:58 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Bahar", "Parnia", ""], ["Brix", "Christopher", ""], ["Ney", "Hermann", ""]]}, {"id": "1810.03996", "submitter": "Sina Ahmadi", "authors": "Sina Ahmadi", "title": "Learning Noun Cases Using Sequential Neural Networks", "comments": "3 pages research proposal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Morphological declension, which aims to inflect nouns to indicate number,\ncase and gender, is an important task in natural language processing (NLP).\nThis research proposal seeks to address the degree to which Recurrent Neural\nNetworks (RNNs) are efficient in learning to decline noun cases. Given the\nchallenge of data sparsity in processing morphologically rich languages and\nalso, the flexibility of sentence structures in such languages, we believe that\nmodeling morphological dependencies can improve the performance of neural\nnetwork models. It is suggested to carry out various experiments to understand\nthe interpretable features that may lead to a better generalization of the\nlearned models on cross-lingual tasks.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 14:01:41 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Ahmadi", "Sina", ""]]}, {"id": "1810.04000", "submitter": "Lin Li", "authors": "Zhaohui Chao, Lin Li", "title": "The combination of context information to enhance simple question\n  answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of knowledge base,question answering based on\nknowledge base has been a hot research issue. In this paper, we focus on\nanswering singlerelation factoid questions based on knowledge base. We build a\nquestion answering system and study the effect of context information on fact\nselection, such as entity's notable type,outdegree. Experimental results show\nthat context information can improve the result of simple question answering.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 14:02:56 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Chao", "Zhaohui", ""], ["Li", "Lin", ""]]}, {"id": "1810.04142", "submitter": "Yuan Zhang", "authors": "Yuan Zhang, Jason Riesa, Daniel Gillick, Anton Bakalov, Jason\n  Baldridge, David Weiss", "title": "A Fast, Compact, Accurate Model for Language Identification of Codemixed\n  Text", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address fine-grained multilingual language identification: providing a\nlanguage code for every token in a sentence, including codemixed text\ncontaining multiple languages. Such text is prevalent online, in documents,\nsocial media, and message boards. We show that a feed-forward network with a\nsimple globally constrained decoder can accurately and rapidly label both\ncodemixed and monolingual text in 100 languages and 100 language pairs. This\nmodel outperforms previously published multilingual approaches in terms of both\naccuracy and speed, yielding an 800x speed-up and a 19.5% averaged absolute\ngain on three codemixed datasets. It furthermore outperforms several benchmark\nsystems on monolingual language identification.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 17:21:41 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Zhang", "Yuan", ""], ["Riesa", "Jason", ""], ["Gillick", "Daniel", ""], ["Bakalov", "Anton", ""], ["Baldridge", "Jason", ""], ["Weiss", "David", ""]]}, {"id": "1810.04216", "submitter": "Lamana Mulaffer", "authors": "Arun Pandian, Lamana Mulaffer, Kemal Oflazer, Amna AlZeyara", "title": "Event Coreference Resolution Using Neural Network Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a neural network classifier approach to detecting both\nwithin- and cross- document event coreference effectively using only event\nmention based features. Our approach does not (yet) rely on any event argument\nfeatures such as semantic roles or spatiotemporal arguments. Experimental\nresults on the ECB+ dataset show that our approach produces F1 scores that\nsignificantly outperform the state-of-the-art methods for both within-document\nand cross-document event coreference resolution when we use B3 and CEAFe\nevaluation measures, but gets worse F1 score with the MUC measure. However,\nwhen we use the CoNLL measure, which is the average of these three scores, our\napproach has slightly better F1 for within- document event coreference\nresolution but is significantly better for cross-document event coreference\nresolution.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 19:00:52 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Pandian", "Arun", ""], ["Mulaffer", "Lamana", ""], ["Oflazer", "Kemal", ""], ["AlZeyara", "Amna", ""]]}, {"id": "1810.04297", "submitter": "Xusen Yin", "authors": "Xusen Yin and Nada Aldarrab and Be\\'ata Megyesi and Kevin Knight", "title": "Decipherment of Historical Manuscript Images", "comments": "International Conference on Document Analysis and Recognition 2019\n  Long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  European libraries and archives are filled with enciphered manuscripts from\nthe early modern period. These include military and diplomatic correspondence,\nrecords of secret societies, private letters, and so on. Although they are\nenciphered with classical cryptographic algorithms, their contents are\nunavailable to working historians. We therefore attack the problem of\nautomatically converting cipher manuscript images into plaintext. We develop\nunsupervised models for character segmentation, character-image clustering, and\ndecipherment of cluster sequences. We experiment with both pipelined and joint\nmodels, and we give empirical results for multiple ciphers.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 23:21:18 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 04:38:41 GMT"}, {"version": "v3", "created": "Sun, 2 Jun 2019 21:58:50 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Yin", "Xusen", ""], ["Aldarrab", "Nada", ""], ["Megyesi", "Be\u00e1ta", ""], ["Knight", "Kevin", ""]]}, {"id": "1810.04428", "submitter": "Jipeng Qiang", "authors": "Jipeng Qiang", "title": "Improving Neural Text Simplification Model with Simplified Corpora", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text simplification (TS) can be viewed as monolingual translation task,\ntranslating between text variations within a single language. Recent neural TS\nmodels draw on insights from neural machine translation to learn lexical\nsimplification and content reduction using encoder-decoder model. But different\nfrom neural machine translation, we cannot obtain enough ordinary and\nsimplified sentence pairs for TS, which are expensive and time-consuming to\nbuild. Target-side simplified sentences plays an important role in boosting\nfluency for statistical TS, and we investigate the use of simplified sentences\nto train, with no changes to the network architecture. We propose to pair\nsimple training sentence with a synthetic ordinary sentence via\nback-translation, and treating this synthetic data as additional training data.\nWe train encoder-decoder model using synthetic sentence pairs and original\nsentence pairs, which can obtain substantial improvements on the available\nWikiLarge data and WikiSmall data compared with the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 09:14:06 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Qiang", "Jipeng", ""]]}, {"id": "1810.04440", "submitter": "Diptesh Kanojia", "authors": "Jayashree Gajjam, Diptesh Kanojia, Malhar Kulkarni", "title": "New Vistas to study Bhartrhari: Cognitive NLP", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Sanskrit grammatical tradition which has commenced with Panini's\nAstadhyayi mostly as a Padasastra has culminated as a Vakyasastra, at the hands\nof Bhartrhari. The grammarian-philosopher Bhartrhari and his authoritative work\n'Vakyapadiya' have been a matter of study for modern scholars, at least for\nmore than 50 years, since Ashok Aklujkar submitted his Ph.D. dissertation at\nHarvard University. The notions of a sentence and a word as a meaningful\nlinguistic unit in the language have been a subject matter for the discussion\nin many works that followed later on. While some scholars have applied\nphilological techniques to critically establish the text of the works of\nBhartrhari, some others have devoted themselves to exploring philosophical\ninsights from them. Some others have studied his works from the point of view\nof modern linguistics, and psychology. Few others have tried to justify the\nviews by logical discussions.\n  In this paper, we present a fresh view to study Bhartrhari, and his works,\nespecially the 'Vakyapadiya'. This view is from the field of Natural Language\nProcessing (NLP), more specifically, what is called as Cognitive NLP. We have\nstudied the definitions of a sentence given by Bhartrhari at the beginning of\nthe second chapter of 'Vakyapadiya'. We have researched one of these\ndefinitions by conducting an experiment and following the methodology of\nsilent-reading of Sanskrit paragraphs. We collect the Gaze-behavior data of\nparticipants and analyze it to understand the underlying comprehension\nprocedure in the human mind and present our results. We evaluate the\nstatistical significance of our results using T-test, and discuss the caveats\nof our work. We also present some general remarks on this experiment and\nusefulness of this method for gaining more insights in the work of Bhartrhari.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 10:00:17 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Gajjam", "Jayashree", ""], ["Kanojia", "Diptesh", ""], ["Kulkarni", "Malhar", ""]]}, {"id": "1810.04528", "submitter": "Vinicius Woloszyn", "authors": "Brenda Salenave Santana, Vinicius Woloszyn, Leandro Krug Wives", "title": "Is there Gender bias and stereotype in Portuguese Word Embeddings?", "comments": null, "journal-ref": "The 13th edition of the International Conference on the\n  Computational Processing of Portuguese (PROPOR 2018)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we propose an analysis of the presence of gender bias\nassociated with professions in Portuguese word embeddings. The objective of\nthis work is to study gender implications related to stereotyped professions\nfor women and men in the context of the Portuguese language.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 13:42:16 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Santana", "Brenda Salenave", ""], ["Woloszyn", "Vinicius", ""], ["Wives", "Leandro Krug", ""]]}, {"id": "1810.04631", "submitter": "Won Ik Cho", "authors": "Won Ik Cho, Young Ki Moon, Woo Hyun Kang, Nam Soo Kim", "title": "Extracting Arguments from Korean Question and Command: An Annotated\n  Corpus for Structured Paraphrasing", "comments": "5 pages and 2 tables, Annotation guideline for Seoul Korean sentences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intention identification is a core issue in dialog management. However, due\nto the non-canonicality of the spoken language, it is difficult to extract the\ncontent automatically from the conversation-style utterances. This is much more\nchallenging for languages like Korean and Japanese since the agglutination\nbetween morphemes make it difficult for the machines to parse the sentence and\nunderstand the intention. To suggest a guideline for this problem, and to merge\nthe issue flexibly with the neural paraphrasing systems introduced recently, we\npropose a structured annotation scheme for Korean question/commands and the\nresulting corpus which are widely applicable to the field of argument mining.\nThe scheme and dataset are expected to help machines understand the intention\nof natural language and grasp the core meaning of conversation-style\ninstructions.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 16:46:41 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2019 04:49:28 GMT"}, {"version": "v3", "created": "Tue, 9 Jul 2019 05:26:15 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Cho", "Won Ik", ""], ["Moon", "Young Ki", ""], ["Kang", "Woo Hyun", ""], ["Kim", "Nam Soo", ""]]}, {"id": "1810.04635", "submitter": "Seunghyun Yoon", "authors": "Seunghyun Yoon, Seokhyun Byun, Kyomin Jung", "title": "Multimodal Speech Emotion Recognition Using Audio and Text", "comments": "7 pages, Accepted as a conference paper at IEEE SLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech emotion recognition is a challenging task, and extensive reliance has\nbeen placed on models that use audio features in building well-performing\nclassifiers. In this paper, we propose a novel deep dual recurrent encoder\nmodel that utilizes text data and audio signals simultaneously to obtain a\nbetter understanding of speech data. As emotional dialogue is composed of sound\nand spoken content, our model encodes the information from audio and text\nsequences using dual recurrent neural networks (RNNs) and then combines the\ninformation from these sources to predict the emotion class. This architecture\nanalyzes speech data from the signal level to the language level, and it thus\nutilizes the information within the data more comprehensively than models that\nfocus on audio features. Extensive experiments are conducted to investigate the\nefficacy and properties of the proposed model. Our proposed model outperforms\nprevious state-of-the-art methods in assigning data to one of four emotion\ncategories (i.e., angry, happy, sad and neutral) when the model is applied to\nthe IEMOCAP dataset, as reflected by accuracies ranging from 68.8% to 71.8%.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 16:51:58 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Yoon", "Seunghyun", ""], ["Byun", "Seokhyun", ""], ["Jung", "Kyomin", ""]]}, {"id": "1810.04700", "submitter": "Sebastian Gehrmann", "authors": "Sebastian Gehrmann, Falcon Z. Dai, Henry Elder, Alexander M. Rush", "title": "End-to-End Content and Plan Selection for Data-to-Text Generation", "comments": "INLG 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to generate fluent natural language from structured data with neural\nnetworks has become an common approach for NLG. This problem can be challenging\nwhen the form of the structured data varies between examples. This paper\npresents a survey of several extensions to sequence-to-sequence models to\naccount for the latent content selection process, particularly variants of copy\nattention and coverage decoding. We further propose a training method based on\ndiverse ensembling to encourage models to learn distinct sentence templates\nduring training. An empirical evaluation of these techniques shows an increase\nin the quality of generated text across five automated metrics, as well as\nhuman evaluation.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 18:36:04 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Gehrmann", "Sebastian", ""], ["Dai", "Falcon Z.", ""], ["Elder", "Henry", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1810.04755", "submitter": "Maria Leonor Pacheco", "authors": "Samuel Jero, Maria Leonor Pacheco, Dan Goldwasser and Cristina\n  Nita-Rotaru", "title": "Leveraging Textual Specifications for Grammar-based Fuzzing of Network\n  Protocols", "comments": null, "journal-ref": "The Thirty-First AAAI Conference on Innovative Applications of\n  Artificial Intelligence, IAAI 2019", "doi": "10.1609/aaai.v33i01.33019478", "report-no": null, "categories": "cs.CR cs.CL cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grammar-based fuzzing is a technique used to find software vulnerabilities by\ninjecting well-formed inputs generated following rules that encode application\nsemantics. Most grammar-based fuzzers for network protocols rely on human\nexperts to manually specify these rules. In this work we study automated\nlearning of protocol rules from textual specifications (i.e. RFCs). We evaluate\nthe automatically extracted protocol rules by applying them to a\nstate-of-the-art fuzzer for transport protocols and show that it leads to a\nsmaller number of test cases while finding the same attacks as the system that\nuses manually specified rules.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 21:42:29 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Jero", "Samuel", ""], ["Pacheco", "Maria Leonor", ""], ["Goldwasser", "Dan", ""], ["Nita-Rotaru", "Cristina", ""]]}, {"id": "1810.04805", "submitter": "Ming-Wei Chang", "authors": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova", "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language\n  Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new language representation model called BERT, which stands\nfor Bidirectional Encoder Representations from Transformers. Unlike recent\nlanguage representation models, BERT is designed to pre-train deep\nbidirectional representations from unlabeled text by jointly conditioning on\nboth left and right context in all layers. As a result, the pre-trained BERT\nmodel can be fine-tuned with just one additional output layer to create\nstate-of-the-art models for a wide range of tasks, such as question answering\nand language inference, without substantial task-specific architecture\nmodifications.\n  BERT is conceptually simple and empirically powerful. It obtains new\nstate-of-the-art results on eleven natural language processing tasks, including\npushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI\naccuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering\nTest F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1\n(5.1 point absolute improvement).\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 00:50:01 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 20:37:26 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Devlin", "Jacob", ""], ["Chang", "Ming-Wei", ""], ["Lee", "Kenton", ""], ["Toutanova", "Kristina", ""]]}, {"id": "1810.04839", "submitter": "Diptesh Kanojia", "authors": "Sandeep Mathias, Diptesh Kanojia, Kevin Patel, Samarth Agarwal,\n  Abhijit Mishra, Pushpak Bhattacharyya", "title": "Eyes are the Windows to the Soul: Predicting the Rating of Text Quality\n  Using Gaze Behaviour", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting a reader's rating of text quality is a challenging task that\ninvolves estimating different subjective aspects of the text, like structure,\nclarity, etc. Such subjective aspects are better handled using cognitive\ninformation. One such source of cognitive information is gaze behaviour. In\nthis paper, we show that gaze behaviour does indeed help in effectively\npredicting the rating of text quality. To do this, we first model text quality\nas a function of three properties - organization, coherence and cohesion. Then,\nwe demonstrate how capturing gaze behaviour helps in predicting each of these\nproperties, and hence the overall quality, by reporting improvements obtained\nby adding gaze features to traditional textual features for score prediction.\nWe also hypothesize that if a reader has fully understood the text, the\ncorresponding gaze behaviour would give a better indication of the assigned\nrating, as opposed to partial understanding. Our experiments validate this\nhypothesis by showing greater agreement between the given rating and the\npredicted rating when the reader has a full understanding of the text.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 04:34:31 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Mathias", "Sandeep", ""], ["Kanojia", "Diptesh", ""], ["Patel", "Kevin", ""], ["Agarwal", "Samarth", ""], ["Mishra", "Abhijit", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1810.04864", "submitter": "Glorianna Jagfeld", "authors": "Glorianna Jagfeld, Sabrina Jenne, Ngoc Thang Vu", "title": "Sequence-to-Sequence Models for Data-to-Text Natural Language\n  Generation: Word- vs. Character-based Processing and Output Diversity", "comments": "INLG 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a comparison of word-based and character-based\nsequence-to-sequence models for data-to-text natural language generation, which\ngenerate natural language descriptions for structured inputs. On the datasets\nof two recent generation challenges, our models achieve comparable or better\nautomatic evaluation results than the best challenge submissions. Subsequent\ndetailed statistical and human analyses shed light on the differences between\nthe two input representations and the diversity of the generated texts. In a\ncontrolled experiment with synthetic training data generated from templates, we\ndemonstrate the ability of neural models to learn novel combinations of the\ntemplates and thereby generalize beyond the linguistic structures they were\ntrained on.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 06:43:28 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Jagfeld", "Glorianna", ""], ["Jenne", "Sabrina", ""], ["Vu", "Ngoc Thang", ""]]}, {"id": "1810.04882", "submitter": "Kawin Ethayarajh", "authors": "Kawin Ethayarajh, David Duvenaud, Graeme Hirst", "title": "Towards Understanding Linear Word Analogies", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A surprising property of word vectors is that word analogies can often be\nsolved with vector arithmetic. However, it is unclear why arithmetic operators\ncorrespond to non-linear embedding models such as skip-gram with negative\nsampling (SGNS). We provide a formal explanation of this phenomenon without\nmaking the strong assumptions that past theories have made about the vector\nspace and word distribution. Our theory has several implications. Past work has\nconjectured that linear substructures exist in vector spaces because relations\ncan be represented as ratios; we prove that this holds for SGNS. We provide\nnovel justification for the addition of SGNS word vectors by showing that it\nautomatically down-weights the more frequent word, as weighting schemes do ad\nhoc. Lastly, we offer an information theoretic interpretation of Euclidean\ndistance in vector spaces, justifying its use in capturing word dissimilarity.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 08:08:40 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 02:35:38 GMT"}, {"version": "v3", "created": "Sat, 27 Oct 2018 14:36:59 GMT"}, {"version": "v4", "created": "Thu, 8 Nov 2018 03:45:30 GMT"}, {"version": "v5", "created": "Mon, 24 Dec 2018 01:27:39 GMT"}, {"version": "v6", "created": "Tue, 4 Jun 2019 17:09:44 GMT"}, {"version": "v7", "created": "Mon, 12 Aug 2019 04:04:15 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Ethayarajh", "Kawin", ""], ["Duvenaud", "David", ""], ["Hirst", "Graeme", ""]]}, {"id": "1810.05022", "submitter": "Elior Sulem", "authors": "Elior Sulem, Omri Abend, Ari Rappoport", "title": "Semantic Structural Evaluation for Text Simplification", "comments": null, "journal-ref": "Proc. of NAACL 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current measures for evaluating text simplification systems focus on\nevaluating lexical text aspects, neglecting its structural aspects. In this\npaper we propose the first measure to address structural aspects of text\nsimplification, called SAMSA. It leverages recent advances in semantic parsing\nto assess simplification quality by decomposing the input based on its semantic\nstructure and comparing it to the output. SAMSA provides a reference-less\nautomatic evaluation procedure, avoiding the problems that reference-based\nmethods face due to the vast space of valid simplifications for a given\nsentence. Our human evaluation experiments show both SAMSA's substantial\ncorrelation with human judgments, as well as the deficiency of existing\nreference-based measures in evaluating structural simplification.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 13:54:50 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Sulem", "Elior", ""], ["Abend", "Omri", ""], ["Rappoport", "Ari", ""]]}, {"id": "1810.05102", "submitter": "Pankaj Gupta", "authors": "Pankaj Gupta and Subburam Rajaram and Hinrich Sch\\\"utze and Bernt\n  Andrassy and Thomas Runkler", "title": "Neural Relation Extraction Within and Across Sentence Boundaries", "comments": "AAAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Past work in relation extraction mostly focuses on binary relation between\nentity pairs within single sentence. Recently, the NLP community has gained\ninterest in relation extraction in entity pairs spanning multiple sentences. In\nthis paper, we propose a novel architecture for this task: inter-sentential\ndependency-based neural networks (iDepNN). iDepNN models the shortest and\naugmented dependency paths via recurrent and recursive neural networks to\nextract relationships within (intra-) and across (inter-) sentence boundaries.\nCompared to SVM and neural network baselines, iDepNN is more robust to false\npositives in relationships spanning sentences.\n  We evaluate our models on four datasets from newswire (MUC6) and medical\n(BioNLP shared task) domains that achieve state-of-the-art performance and show\na better balance in precision and recall for inter-sentential relationships. We\nperform better than 11 teams participating in the BioNLP shared task 2016 and\nachieve a gain of 5.2% (0.587 vs 0.558) in F1 over the winning team. We also\nrelease the crosssentence annotations for MUC6.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 16:07:20 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 16:56:53 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Gupta", "Pankaj", ""], ["Rajaram", "Subburam", ""], ["Sch\u00fctze", "Hinrich", ""], ["Andrassy", "Bernt", ""], ["Runkler", "Thomas", ""]]}, {"id": "1810.05104", "submitter": "Elior Sulem", "authors": "Elior Sulem, Omri Abend, Ari Rappoport", "title": "Simple and Effective Text Simplification Using Semantic and Neural\n  Methods", "comments": null, "journal-ref": "Proc. of ACL 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence splitting is a major simplification operator. Here we present a\nsimple and efficient splitting algorithm based on an automatic semantic parser.\nAfter splitting, the text is amenable for further fine-tuned simplification\noperations. In particular, we show that neural Machine Translation can be\neffectively used in this situation. Previous application of Machine Translation\nfor simplification suffers from a considerable disadvantage in that they are\nover-conservative, often failing to modify the source in any way. Splitting\nbased on semantic parsing, as proposed here, alleviates this issue. Extensive\nautomatic and human evaluation shows that the proposed method compares\nfavorably to the state-of-the-art in combined lexical and structural\nsimplification.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 16:14:24 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Sulem", "Elior", ""], ["Abend", "Omri", ""], ["Rappoport", "Ari", ""]]}, {"id": "1810.05201", "submitter": "Kellie Webster", "authors": "Kellie Webster and Marta Recasens and Vera Axelrod and Jason Baldridge", "title": "Mind the GAP: A Balanced Corpus of Gendered Ambiguous Pronouns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coreference resolution is an important task for natural language\nunderstanding, and the resolution of ambiguous pronouns a longstanding\nchallenge. Nonetheless, existing corpora do not capture ambiguous pronouns in\nsufficient volume or diversity to accurately indicate the practical utility of\nmodels. Furthermore, we find gender bias in existing corpora and systems\nfavoring masculine entities. To address this, we present and release GAP, a\ngender-balanced labeled corpus of 8,908 ambiguous pronoun-name pairs sampled to\nprovide diverse coverage of challenges posed by real-world text. We explore a\nrange of baselines which demonstrate the complexity of the challenge, the best\nachieving just 66.9% F1. We show that syntactic structure and continuous neural\nmodels provide promising, complementary cues for approaching the challenge.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 18:52:42 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Webster", "Kellie", ""], ["Recasens", "Marta", ""], ["Axelrod", "Vera", ""], ["Baldridge", "Jason", ""]]}, {"id": "1810.05237", "submitter": "Tao Yu", "authors": "Tao Yu, Michihiro Yasunaga, Kai Yang, Rui Zhang, Dongxu Wang, Zifan\n  Li, Dragomir Radev", "title": "SyntaxSQLNet: Syntax Tree Networks for Complex and\n  Cross-DomainText-to-SQL Task", "comments": "EMNLP 2018, Long Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing studies in text-to-SQL tasks do not require generating complex\nSQL queries with multiple clauses or sub-queries, and generalizing to new,\nunseen databases. In this paper we propose SyntaxSQLNet, a syntax tree network\nto address the complex and cross-domain text-to-SQL generation task.\nSyntaxSQLNet employs a SQL specific syntax tree-based decoder with SQL\ngeneration path history and table-aware column attention encoders. We evaluate\nSyntaxSQLNet on the Spider text-to-SQL task, which contains databases with\nmultiple tables and complex SQL queries with multiple SQL clauses and nested\nqueries. We use a database split setting where databases in the test set are\nunseen during training. Experimental results show that SyntaxSQLNet can handle\na significantly greater number of complex SQL examples than prior work,\noutperforming the previous state-of-the-art model by 7.3% in exact matching\naccuracy. We also show that SyntaxSQLNet can further improve the performance by\nan additional 7.5% using a cross-domain augmentation method, resulting in a\n14.8% improvement in total. To our knowledge, we are the first to study this\ncomplex and cross-domain text-to-SQL task.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 20:24:13 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 20:33:55 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Yu", "Tao", ""], ["Yasunaga", "Michihiro", ""], ["Yang", "Kai", ""], ["Zhang", "Rui", ""], ["Wang", "Dongxu", ""], ["Li", "Zifan", ""], ["Radev", "Dragomir", ""]]}, {"id": "1810.05241", "submitter": "Eric Yuan", "authors": "Xingdi Yuan, Tong Wang, Rui Meng, Khushboo Thaker, Peter Brusilovsky,\n  Daqing He, Adam Trischler", "title": "One Size Does Not Fit All: Generating and Evaluating Variable Number of\n  Keyphrases", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different texts shall by nature correspond to different number of keyphrases.\nThis desideratum is largely missing from existing neural keyphrase generation\nmodels. In this study, we address this problem from both modeling and\nevaluation perspectives.\n  We first propose a recurrent generative model that generates multiple\nkeyphrases as delimiter-separated sequences. Generation diversity is further\nenhanced with two novel techniques by manipulating decoder hidden states. In\ncontrast to previous approaches, our model is capable of generating diverse\nkeyphrases and controlling number of outputs.\n  We further propose two evaluation metrics tailored towards the\nvariable-number generation. We also introduce a new dataset StackEx that\nexpands beyond the only existing genre (i.e., academic writing) in keyphrase\ngeneration tasks. With both previous and new evaluation metrics, our model\noutperforms strong baselines on all datasets.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 20:40:15 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 13:57:57 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 05:43:27 GMT"}, {"version": "v4", "created": "Tue, 12 May 2020 16:44:21 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Yuan", "Xingdi", ""], ["Wang", "Tong", ""], ["Meng", "Rui", ""], ["Thaker", "Khushboo", ""], ["Brusilovsky", "Peter", ""], ["He", "Daqing", ""], ["Trischler", "Adam", ""]]}, {"id": "1810.05320", "submitter": "Shengjie Sun", "authors": "Shengjie Sun, Dong Yang, Hongchun Zhang, Yanxu Chen, Chao Wei, Xiaonan\n  Meng, Yi Hu", "title": "Important Attribute Identification in Knowledge Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The knowledge graph(KG) composed of entities with their descriptions and\nattributes, and relationship between entities, is finding more and more\napplication scenarios in various natural language processing tasks. In a\ntypical knowledge graph like Wikidata, entities usually have a large number of\nattributes, but it is difficult to know which ones are important. The\nimportance of attributes can be a valuable piece of information in various\napplications spanning from information retrieval to natural language\ngeneration. In this paper, we propose a general method of using external user\ngenerated text data to evaluate the relative importance of an entity's\nattributes. To be more specific, we use the word/sub-word embedding techniques\nto match the external textual data back to entities' attribute name and values\nand rank the attributes by their matching cohesiveness. To our best knowledge,\nthis is the first work of applying vector based semantic matching to important\nattribute identification, and our method outperforms the previous traditional\nmethods. We also apply the outcome of the detected important attributes to a\nlanguage generation task; compared with previous generated text, the new method\ngenerates much more customized and informative messages.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 02:19:42 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Sun", "Shengjie", ""], ["Yang", "Dong", ""], ["Zhang", "Hongchun", ""], ["Chen", "Yanxu", ""], ["Wei", "Chao", ""], ["Meng", "Xiaonan", ""], ["Hu", "Yi", ""]]}, {"id": "1810.05334", "submitter": "Kemal Kurniawan", "authors": "Kemal Kurniawan and Samuel Louvan", "title": "IndoSum: A New Benchmark Dataset for Indonesian Text Summarization", "comments": "Accepted in IALP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic text summarization is generally considered as a challenging task in\nthe NLP community. One of the challenges is the publicly available and large\ndataset that is relatively rare and difficult to construct. The problem is even\nworse for low-resource languages such as Indonesian. In this paper, we present\nIndoSum, a new benchmark dataset for Indonesian text summarization. The dataset\nconsists of news articles and manually constructed summaries. Notably, the\ndataset is almost 200x larger than the previous Indonesian summarization\ndataset of the same domain. We evaluated various extractive summarization\napproaches and obtained encouraging results which demonstrate the usefulness of\nthe dataset and provide baselines for future research. The code and the dataset\nare available online under permissive licenses.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 03:07:21 GMT"}, {"version": "v2", "created": "Fri, 23 Nov 2018 07:00:23 GMT"}, {"version": "v3", "created": "Thu, 21 Feb 2019 04:37:55 GMT"}, {"version": "v4", "created": "Tue, 26 Feb 2019 06:27:40 GMT"}, {"version": "v5", "created": "Wed, 20 Mar 2019 02:45:00 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Kurniawan", "Kemal", ""], ["Louvan", "Samuel", ""]]}, {"id": "1810.05436", "submitter": "Hosein Azarbonyad", "authors": "Hosein Azarbonyad, Mostafa Dehghani, Tom Kenter, Maarten Marx, Jaap\n  Kamps, and Maarten de Rijke", "title": "HiTR: Hierarchical Topic Model Re-estimation for Measuring Topical\n  Diversity of Documents", "comments": "IEEE Transactions on Knowledge and Data Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A high degree of topical diversity is often considered to be an important\ncharacteristic of interesting text documents. A recent proposal for measuring\ntopical diversity identifies three distributions for assessing the diversity of\ndocuments: distributions of words within documents, words within topics, and\ntopics within documents. Topic models play a central role in this approach and,\nhence, their quality is crucial to the efficacy of measuring topical diversity.\nThe quality of topic models is affected by two causes: generality and impurity\nof topics. General topics only include common information of a background\ncorpus and are assigned to most of the documents. Impure topics contain words\nthat are not related to the topic. Impurity lowers the interpretability of\ntopic models. Impure topics are likely to get assigned to documents\nerroneously. We propose a hierarchical re-estimation process aimed at removing\ngenerality and impurity. Our approach has three re-estimation components: (1)\ndocument re-estimation, which removes general words from the documents; (2)\ntopic re-estimation, which re-estimates the distribution over words of each\ntopic; and (3) topic assignment re-estimation, which re-estimates for each\ndocument its distributions over topics. For measuring topical diversity of text\ndocuments, our HiTR approach improves over the state-of-the-art measured on\nPubMed dataset.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 10:02:23 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Azarbonyad", "Hosein", ""], ["Dehghani", "Mostafa", ""], ["Kenter", "Tom", ""], ["Marx", "Maarten", ""], ["Kamps", "Jaap", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1810.05474", "submitter": "Marc Tanti", "authors": "Marc Tanti and Albert Gatt and Adrian Muscat", "title": "Pre-gen metrics: Predicting caption quality metrics without generating\n  captions", "comments": "13 pages, 6 figures This publication will appear in the Proceedings\n  of the First Workshop on Shortcomings in Vision and Language (2018). DOI to\n  be inserted later", "journal-ref": null, "doi": "10.1007/978-3-030-11018-5_11", "report-no": null, "categories": "cs.NE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image caption generation systems are typically evaluated against reference\noutputs. We show that it is possible to predict output quality without\ngenerating the captions, based on the probability assigned by the neural model\nto the reference captions. Such pre-gen metrics are strongly correlated to\nstandard evaluation metrics.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 12:19:56 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Tanti", "Marc", ""], ["Gatt", "Albert", ""], ["Muscat", "Adrian", ""]]}, {"id": "1810.05475", "submitter": "Marc Tanti", "authors": "Marc Tanti and Albert Gatt and Kenneth P. Camilleri", "title": "Quantifying the amount of visual information used by neural caption\n  generators", "comments": "10 pages, 4 figures This publication will appear in the Proceedings\n  of the First Workshop on Shortcomings in Vision and Language (2018). DOI to\n  be inserted later", "journal-ref": null, "doi": "10.1007/978-3-030-11018-5_11", "report-no": null, "categories": "cs.NE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the sensitivity of neural image caption generators to\ntheir visual input. A sensitivity analysis and omission analysis based on image\nfoils is reported, showing that the extent to which image captioning\narchitectures retain and are sensitive to visual information varies depending\non the type of word being generated and the position in the caption as a whole.\nWe motivate this work in the context of broader goals in the field to achieve\nmore explainability in AI.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 12:23:08 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Tanti", "Marc", ""], ["Gatt", "Albert", ""], ["Camilleri", "Kenneth P.", ""]]}, {"id": "1810.05512", "submitter": "David Leroy", "authors": "David Leroy, Alice Coucke, Thibaut Lavril, Thibault Gisselbrecht and\n  Joseph Dureau", "title": "Federated Learning for Keyword Spotting", "comments": "Accepted for publication to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a practical approach based on federated learning to solve\nout-of-domain issues with continuously running embedded speech-based models\nsuch as wake word detectors. We conduct an extensive empirical study of the\nfederated averaging algorithm for the \"Hey Snips\" wake word based on a\ncrowdsourced dataset that mimics a federation of wake word users. We\nempirically demonstrate that using an adaptive averaging strategy inspired from\nAdam in place of standard weighted model averaging highly reduces the number of\ncommunication rounds required to reach our target performance. The associated\nupstream communication costs per user are estimated at 8 MB, which is a\nreasonable in the context of smart home voice assistants. Additionally, the\ndataset used for these experiments is being open sourced with the aim of\nfostering further transparent research in the application of federated learning\nto speech data.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 09:41:15 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 10:07:18 GMT"}, {"version": "v3", "created": "Tue, 18 Dec 2018 09:31:52 GMT"}, {"version": "v4", "created": "Mon, 18 Feb 2019 18:41:00 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Leroy", "David", ""], ["Coucke", "Alice", ""], ["Lavril", "Thibaut", ""], ["Gisselbrecht", "Thibault", ""], ["Dureau", "Joseph", ""]]}, {"id": "1810.05682", "submitter": "Rajarshi Das", "authors": "Rajarshi Das, Tsendsuren Munkhdalai, Xingdi Yuan, Adam Trischler,\n  Andrew McCallum", "title": "Building Dynamic Knowledge Graphs from Text using Machine Reading\n  Comprehension", "comments": "ICLR 2019 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a neural machine-reading model that constructs dynamic knowledge\ngraphs from procedural text. It builds these graphs recurrently for each step\nof the described procedure, and uses them to track the evolving states of\nparticipant entities. We harness and extend a recently proposed machine reading\ncomprehension (MRC) model to query for entity states, since these states are\ngenerally communicated in spans of text and MRC models perform well in\nextracting entity-centric spans. The explicit, structured, and evolving\nknowledge graph representations that our model constructs can be used in\ndownstream question answering tasks to improve machine comprehension of text,\nas we demonstrate empirically. On two comprehension tasks from the recently\nproposed PROPARA dataset (Dalvi et al., 2018), our model achieves\nstate-of-the-art results. We further show that our model is competitive on the\nRECIPES dataset (Kiddon et al., 2015), suggesting it may be generally\napplicable. We present some evidence that the model's knowledge graphs help it\nto impose commonsense constraints on its predictions.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 19:01:32 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Das", "Rajarshi", ""], ["Munkhdalai", "Tsendsuren", ""], ["Yuan", "Xingdi", ""], ["Trischler", "Adam", ""], ["McCallum", "Andrew", ""]]}, {"id": "1810.05739", "submitter": "Peter J Liu", "authors": "Eric Chu and Peter J. Liu", "title": "MeanSum: A Neural Model for Unsupervised Multi-document Abstractive\n  Summarization", "comments": "Accepted to ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Abstractive summarization has been studied using neural sequence transduction\nmethods with datasets of large, paired document-summary examples. However, such\ndatasets are rare and the models trained from them do not generalize to other\ndomains. Recently, some progress has been made in learning sequence-to-sequence\nmappings with only unpaired examples. In our work, we consider the setting\nwhere there are only documents (product or business reviews) with no summaries\nprovided, and propose an end-to-end, neural model architecture to perform\nunsupervised abstractive summarization. Our proposed model consists of an\nauto-encoder where the mean of the representations of the input reviews decodes\nto a reasonable summary-review while not relying on any review-specific\nfeatures. We consider variants of the proposed architecture and perform an\nablation study to show the importance of specific components. We show through\nautomated metrics and human evaluation that the generated summaries are highly\nabstractive, fluent, relevant, and representative of the average sentiment of\nthe input reviews. Finally, we collect a reference evaluation dataset and show\nthat our model outperforms a strong extractive baseline.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 21:24:33 GMT"}, {"version": "v2", "created": "Sat, 26 Jan 2019 01:56:53 GMT"}, {"version": "v3", "created": "Tue, 29 Jan 2019 19:15:00 GMT"}, {"version": "v4", "created": "Wed, 22 May 2019 22:22:55 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Chu", "Eric", ""], ["Liu", "Peter J.", ""]]}, {"id": "1810.05754", "submitter": "Mounica Maddela", "authors": "Mounica Maddela, Wei Xu", "title": "A Word-Complexity Lexicon and A Neural Readability Ranking Model for\n  Lexical Simplification", "comments": "12 pages; EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Current lexical simplification approaches rely heavily on heuristics and\ncorpus level features that do not always align with human judgment. We create a\nhuman-rated word-complexity lexicon of 15,000 English words and propose a novel\nneural readability ranking model with a Gaussian-based feature vectorization\nlayer that utilizes these human ratings to measure the complexity of any given\nword or phrase. Our model performs better than the state-of-the-art systems for\ndifferent lexical simplification tasks and evaluation datasets. Additionally,\nwe also produce SimplePPDB++, a lexical resource of over 10 million simplifying\nparaphrase rules, by applying our model to the Paraphrase Database (PPDB).\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 23:05:01 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Maddela", "Mounica", ""], ["Xu", "Wei", ""]]}, {"id": "1810.05788", "submitter": "Shun Kiyono", "authors": "Shun Kiyono, Jun Suzuki, Kentaro Inui", "title": "Mixture of Expert/Imitator Networks: Scalable Semi-supervised Learning\n  Framework", "comments": "Accepted by AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current success of deep neural networks (DNNs) in an increasingly broad\nrange of tasks involving artificial intelligence strongly depends on the\nquality and quantity of labeled training data. In general, the scarcity of\nlabeled data, which is often observed in many natural language processing\ntasks, is one of the most important issues to be addressed. Semi-supervised\nlearning (SSL) is a promising approach to overcoming this issue by\nincorporating a large amount of unlabeled data. In this paper, we propose a\nnovel scalable method of SSL for text classification tasks. The unique property\nof our method, Mixture of Expert/Imitator Networks, is that imitator networks\nlearn to \"imitate\" the estimated label distribution of the expert network over\nthe unlabeled data, which potentially contributes a set of features for the\nclassification. Our experiments demonstrate that the proposed method\nconsistently improves the performance of several types of baseline DNNs. We\nalso demonstrate that our method has the more data, better performance property\nwith promising scalability to the amount of unlabeled data.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 02:39:39 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 02:30:02 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Kiyono", "Shun", ""], ["Suzuki", "Jun", ""], ["Inui", "Kentaro", ""]]}, {"id": "1810.05867", "submitter": "Shduong Hao", "authors": "Shudong Hao and Michael J. Paul", "title": "An Empirical Study on Crosslingual Transfer in Probabilistic Topic\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic topic modeling is a popular choice as the first step of\ncrosslingual tasks to enable knowledge transfer and extract multilingual\nfeatures. While many multilingual topic models have been developed, their\nassumptions on the training corpus are quite varied, and it is not clear how\nwell the models can be applied under various training conditions. In this\npaper, we systematically study the knowledge transfer mechanisms behind\ndifferent multilingual topic models, and through a broad set of experiments\nwith four models on ten languages, we provide empirical insights that can\ninform the selection and future development of multilingual topic models.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 14:35:08 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 14:44:37 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Hao", "Shudong", ""], ["Paul", "Michael J.", ""]]}, {"id": "1810.05983", "submitter": "Yaliang Li", "authors": "Yaliang Li, Liuyi Yao, Nan Du, Jing Gao, Qi Li, Chuishi Meng, Chenwei\n  Zhang, Wei Fan", "title": "Finding Similar Medical Questions from Question Answering Websites", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past few years have witnessed the flourishing of crowdsourced medical\nquestion answering (Q&A) websites. Patients who have medical information\ndemands tend to post questions about their health conditions on these\ncrowdsourced Q&A websites and get answers from other users. However, we observe\nthat a large portion of new medical questions cannot be answered in time or\nreceive only few answers from these websites. On the other hand, we notice that\nsolved questions have great potential to solve this challenge. Motivated by\nthese, we propose an end-to-end system that can automatically find similar\nquestions for unsolved medical questions. By learning the vector presentation\nof unsolved questions and their candidate similar questions, the proposed\nsystem outputs similar questions according to the similarity between vector\nrepresentations. Through the vector representation, the similar questions are\nfound at the question level, and the diversity of medical questions expression\nissue can be addressed. Further, we handle two more important issues, i.e.,\ntraining data generation issue and efficiency issue, associated with the LSTM\ntraining procedure and the retrieval of candidate similar questions. The\neffectiveness of the proposed system is validated on a large-scale real-world\ndataset collected from a crowdsourced maternal-infant Q&A website.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 06:34:18 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Li", "Yaliang", ""], ["Yao", "Liuyi", ""], ["Du", "Nan", ""], ["Gao", "Jing", ""], ["Li", "Qi", ""], ["Meng", "Chuishi", ""], ["Zhang", "Chenwei", ""], ["Fan", "Wei", ""]]}, {"id": "1810.05995", "submitter": "Elior Sulem", "authors": "Elior Sulem, Omri Abend, Ari Rappoport", "title": "BLEU is Not Suitable for the Evaluation of Text Simplification", "comments": "Accepted to EMNLP 2018 (Short papers)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BLEU is widely considered to be an informative metric for text-to-text\ngeneration, including Text Simplification (TS). TS includes both lexical and\nstructural aspects. In this paper we show that BLEU is not suitable for the\nevaluation of sentence splitting, the major structural simplification\noperation. We manually compiled a sentence splitting gold standard corpus\ncontaining multiple structural paraphrases, and performed a correlation\nanalysis with human judgments. We find low or no correlation between BLEU and\nthe grammaticality and meaning preservation parameters where sentence splitting\nis involved. Moreover, BLEU often negatively correlates with simplicity,\nessentially penalizing simpler sentences.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 08:32:35 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Sulem", "Elior", ""], ["Abend", "Omri", ""], ["Rappoport", "Ari", ""]]}, {"id": "1810.06033", "submitter": "Xutan Peng", "authors": "Chen Li, Xutan Peng, Shanghang Zhang, Hao Peng, Philip S. Yu, Min He,\n  Linfeng Du, Lihong Wang", "title": "Modeling relation paths for knowledge base completion via joint\n  adversarial training", "comments": "Accepted by Knowledge-Based Systems", "journal-ref": null, "doi": "10.1016/j.knosys.2020.105865", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Base Completion (KBC), which aims at determining the missing\nrelations between entity pairs, has received increasing attention in recent\nyears. Most existing KBC methods focus on either embedding the Knowledge Base\n(KB) into a specific semantic space or leveraging the joint probability of\nRandom Walks (RWs) on multi-hop paths. Only a few unified models take both\nsemantic and path-related features into consideration with adequacy. In this\npaper, we propose a novel method to explore the intrinsic relationship between\nthe single relation (i.e. 1-hop path) and multi-hop paths between paired\nentities. We use Hierarchical Attention Networks (HANs) to select important\nrelations in multi-hop paths and encode them into low-dimensional vectors. By\ntreating relations and multi-hop paths as two different input sources, we use a\nfeature extractor, which is shared by two downstream components (i.e. relation\nclassifier and source discriminator), to capture shared/similar information\nbetween them. By joint adversarial training, we encourage our model to extract\nfeatures from the multi-hop paths which are representative for relation\ncompletion. We apply the trained model (except for the source discriminator) to\nseveral large-scale KBs for relation completion. Experimental results show that\nour method outperforms existing path information-based approaches. Since each\nsub-module of our model can be well interpreted, our model can be applied to a\nlarge number of relation learning tasks.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 13:26:34 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 08:55:36 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Li", "Chen", ""], ["Peng", "Xutan", ""], ["Zhang", "Shanghang", ""], ["Peng", "Hao", ""], ["Yu", "Philip S.", ""], ["He", "Min", ""], ["Du", "Linfeng", ""], ["Wang", "Lihong", ""]]}, {"id": "1810.06065", "submitter": "Lisa Fan", "authors": "Lisa Fan, Dong Yu, Lu Wang", "title": "Robust Neural Abstractive Summarization Systems and Evaluation against\n  Adversarial Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence (seq2seq) neural models have been actively investigated\nfor abstractive summarization. Nevertheless, existing neural abstractive\nsystems frequently generate factually incorrect summaries and are vulnerable to\nadversarial information, suggesting a crucial lack of semantic understanding.\nIn this paper, we propose a novel semantic-aware neural abstractive\nsummarization model that learns to generate high quality summaries through\nsemantic interpretation over salient content. A novel evaluation scheme with\nadversarial samples is introduced to measure how well a model identifies\noff-topic information, where our model yields significantly better performance\nthan the popular pointer-generator summarizer. Human evaluation also confirms\nthat our system summaries are uniformly more informative and faithful as well\nas less redundant than the seq2seq model.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2018 17:08:54 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Fan", "Lisa", ""], ["Yu", "Dong", ""], ["Wang", "Lu", ""]]}, {"id": "1810.06195", "submitter": "Longyue Wang", "authors": "Longyue Wang, Zhaopeng Tu, Andy Way, Qun Liu", "title": "Learning to Jointly Translate and Predict Dropped Pronouns with a Shared\n  Reconstruction Mechanism", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pronouns are frequently omitted in pro-drop languages, such as Chinese,\ngenerally leading to significant challenges with respect to the production of\ncomplete translations. Recently, Wang et al. (2018) proposed a novel\nreconstruction-based approach to alleviating dropped pronoun (DP) translation\nproblems for neural machine translation models. In this work, we improve the\noriginal model from two perspectives. First, we employ a shared reconstructor\nto better exploit encoder and decoder representations. Second, we jointly learn\nto translate and predict DPs in an end-to-end manner, to avoid the errors\npropagated from an external DP prediction model. Experimental results show that\nour approach significantly improves both translation performance and DP\nprediction accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 06:30:04 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Wang", "Longyue", ""], ["Tu", "Zhaopeng", ""], ["Way", "Andy", ""], ["Liu", "Qun", ""]]}, {"id": "1810.06233", "submitter": "Jean-Benoit Delbrouck", "authors": "Jean-Benoit Delbrouck and St\\'ephane Dupont", "title": "UMONS Submission for WMT18 Multimodal Translation Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the UMONS solution for the Multimodal Machine\nTranslation Task presented at the third conference on machine translation\n(WMT18). We explore a novel architecture, called deepGRU, based on recent\nfindings in the related task of Neural Image Captioning (NIC). The models\npresented in the following sections lead to the best METEOR translation score\nfor both constrained (English, image) -> German and (English, image) -> French\nsub-tasks.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 09:05:21 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Delbrouck", "Jean-Benoit", ""], ["Dupont", "St\u00e9phane", ""]]}, {"id": "1810.06245", "submitter": "Jean-Benoit Delbrouck", "authors": "Jean-Benoit Delbrouck, St\\'ephane Dupont", "title": "Bringing back simplicity and lightliness into neural image captioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Image Captioning (NIC) or neural caption generation has attracted a\nlot of attention over the last few years. Describing an image with a natural\nlanguage has been an emerging challenge in both fields of computer vision and\nlanguage processing. Therefore a lot of research has focused on driving this\ntask forward with new creative ideas. So far, the goal has been to maximize\nscores on automated metric and to do so, one has to come up with a plurality of\nnew modules and techniques. Once these add up, the models become complex and\nresource-hungry. In this paper, we take a small step backwards in order to\nstudy an architecture with interesting trade-off between performance and\ncomputational complexity. To do so, we tackle every component of a neural\ncaptioning model and propose one or more solution that lightens the model\noverall. Our ideas are inspired by two related tasks: Multimodal and Monomodal\nNeural Machine Translation.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 09:42:55 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Delbrouck", "Jean-Benoit", ""], ["Dupont", "St\u00e9phane", ""]]}, {"id": "1810.06306", "submitter": "Dat Quoc Nguyen", "authors": "Dat Quoc Nguyen, Richard Billingsley, Lan Du, Mark Johnson", "title": "Improving Topic Models with Latent Feature Word Representations", "comments": "The published version is available at:\n  https://transacl.org/ojs/index.php/tacl/article/view/582 ; The source code is\n  available at: https://github.com/datquocnguyen/LFTM", "journal-ref": "Transactions of the Association for Computational Linguistics,\n  vol. 3, pp. 299-313, 2015", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Probabilistic topic models are widely used to discover latent topics in\ndocument collections, while latent feature vector representations of words have\nbeen used to obtain high performance in many NLP tasks. In this paper, we\nextend two different Dirichlet multinomial topic models by incorporating latent\nfeature vector representations of words trained on very large corpora to\nimprove the word-topic mapping learnt on a smaller corpus. Experimental results\nshow that by using information from the external corpora, our new models\nproduce significant improvements on topic coherence, document clustering and\ndocument classification tasks, especially on datasets with few or short\ndocuments.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 12:34:05 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Nguyen", "Dat Quoc", ""], ["Billingsley", "Richard", ""], ["Du", "Lan", ""], ["Johnson", "Mark", ""]]}, {"id": "1810.06351", "submitter": "Marta R. Costa-juss\\`a", "authors": "Carlos Escolano, Marta R. Costa-juss\\`a and Jos\\'e A. R. Fonollosa", "title": "(Self-Attentive) Autoencoder-based Universal Language Representation for\n  Machine Translation", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Universal language representation is the holy grail in machine translation\n(MT). Thanks to the new neural MT approach, it seems that there are good\nperspectives towards this goal. In this paper, we propose a new architecture\nbased on combining variational autoencoders with encoder-decoders and\nintroducing an interlingual loss as an additional training objective. By adding\nand forcing this interlingual loss, we are able to train multiple encoders and\ndecoders for each language, sharing a common universal representation. Since\nthe final objective of this universal representation is producing close results\nfor similar input sentences (in any language), we propose to evaluate it by\nencoding the same sentence in two different languages, decoding both latent\nrepresentations into the same language and comparing both outputs. Preliminary\nresults on the WMT 2017 Turkish/English task shows that the proposed\narchitecture is capable of learning a universal language representation and\nsimultaneously training both translation directions with state-of-the-art\nresults.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 13:52:35 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Escolano", "Carlos", ""], ["Costa-juss\u00e0", "Marta R.", ""], ["Fonollosa", "Jos\u00e9 A. R.", ""]]}, {"id": "1810.06368", "submitter": "Bill Yuchen Lin", "authors": "Bill Yuchen Lin, Wei Lu", "title": "Neural Adaptation Layers for Cross-domain Named Entity Recognition", "comments": "11 pages, accepted as a long paper in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research efforts have shown that neural architectures can be effective\nin conventional information extraction tasks such as named entity recognition,\nyielding state-of-the-art results on standard newswire datasets. However,\ndespite significant resources required for training such models, the\nperformance of a model trained on one domain typically degrades dramatically\nwhen applied to a different domain, yet extracting entities from new emerging\ndomains such as social media can be of significant interest. In this paper, we\nempirically investigate effective methods for conveniently adapting an\nexisting, well-trained neural NER model for a new domain. Unlike existing\napproaches, we propose lightweight yet effective methods for performing domain\nadaptation for neural models. Specifically, we introduce adaptation layers on\ntop of existing neural architectures, where no re-training using the source\ndomain data is required. We conduct extensive empirical studies and show that\nour approach significantly outperforms state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 14:24:36 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Lin", "Bill Yuchen", ""], ["Lu", "Wei", ""]]}, {"id": "1810.06526", "submitter": "Youzhi Tian", "authors": "Youzhi Tian, Zhiting Hu, Zhou Yu", "title": "Structured Content Preservation for Unsupervised Text Style Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text style transfer aims to modify the style of a sentence while keeping its\ncontent unchanged. Recent style transfer systems often fail to faithfully\npreserve the content after changing the style. This paper proposes a structured\ncontent preserving model that leverages linguistic information in the\nstructured fine-grained supervisions to better preserve the style-independent\ncontent during style transfer. In particular, we achieve the goal by devising\nrich model objectives based on both the sentence's lexical information and a\nlanguage model that conditions on content. The resulting model therefore is\nencouraged to retain the semantic meaning of the target sentences. We perform\nextensive experiments that compare our model to other existing approaches in\nthe tasks of sentiment and political slant transfer. Our model achieves\nsignificant improvement in terms of both content preservation and style\ntransfer in automatic and human evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 17:19:18 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 21:55:10 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Tian", "Youzhi", ""], ["Hu", "Zhiting", ""], ["Yu", "Zhou", ""]]}, {"id": "1810.06546", "submitter": "Octavian-Eugen Ganea", "authors": "Alexandru Tifrea, Gary B\\'ecigneul, Octavian-Eugen Ganea", "title": "Poincar\\'e GloVe: Hyperbolic Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Words are not created equal. In fact, they form an aristocratic graph with a\nlatent hierarchical structure that the next generation of unsupervised learned\nword embeddings should reveal. In this paper, justified by the notion of\ndelta-hyperbolicity or tree-likeliness of a space, we propose to embed words in\na Cartesian product of hyperbolic spaces which we theoretically connect to the\nGaussian word embeddings and their Fisher geometry. This connection allows us\nto introduce a novel principled hypernymy score for word embeddings. Moreover,\nwe adapt the well-known Glove algorithm to learn unsupervised word embeddings\nin this type of Riemannian manifolds. We further explain how to solve the\nanalogy task using the Riemannian parallel transport that generalizes vector\narithmetics to this new type of geometry. Empirically, based on extensive\nexperiments, we prove that our embeddings, trained unsupervised, are the first\nto simultaneously outperform strong and popular baselines on the tasks of\nsimilarity, analogy and hypernymy detection. In particular, for word hypernymy,\nwe obtain new state-of-the-art on fully unsupervised WBLESS classification\naccuracy.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 17:54:36 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2018 15:46:17 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Tifrea", "Alexandru", ""], ["B\u00e9cigneul", "Gary", ""], ["Ganea", "Octavian-Eugen", ""]]}, {"id": "1810.06619", "submitter": "Ahmed Abdelali", "authors": "Ahmed Abdelali, Mohammed Attia, Younes Samih, Kareem Darwish and Hamdy\n  Mubarak", "title": "Diacritization of Maghrebi Arabic Sub-Dialects", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Diacritization process attempt to restore the short vowels in Arabic written\ntext; which typically are omitted. This process is essential for applications\nsuch as Text-to-Speech (TTS). While diacritization of Modern Standard Arabic\n(MSA) still holds the lion share, research on dialectal Arabic (DA)\ndiacritization is very limited. In this paper, we present our contribution and\nresults on the automatic diacritization of two sub-dialects of Maghrebi Arabic,\nnamely Tunisian and Moroccan, using a character-level deep neural network\narchitecture that stacks two bi-LSTM layers over a CRF output layer. The model\nachieves word error rate of 2.7% and 3.6% for Moroccan and Tunisian\nrespectively and is capable of implicitly identifying the sub-dialect of the\ninput.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 19:08:03 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 18:50:58 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 23:02:46 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Abdelali", "Ahmed", ""], ["Attia", "Mohammed", ""], ["Samih", "Younes", ""], ["Darwish", "Kareem", ""], ["Mubarak", "Hamdy", ""]]}, {"id": "1810.06635", "submitter": "Anoop Toffy", "authors": "Maharajan Chellapriyadharshini, Anoop Toffy, Srinivasa Raghavan K. M.,\n  V Ramasubramanian", "title": "Semi-supervised and Active-learning Scenarios: Efficient Acoustic Model\n  Refinement for a Low Resource Indian Language", "comments": null, "journal-ref": "Proc. Interspeech 2018", "doi": "10.21437/Interspeech.2018-2486", "report-no": null, "categories": "cs.CL cs.CV cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the problem of efficient acoustic-model refinement (continuous\nretraining) using semi-supervised and active learning for a low resource Indian\nlanguage, wherein the low resource constraints are having i) a small labeled\ncorpus from which to train a baseline `seed' acoustic model and ii) a large\ntraining corpus without orthographic labeling or from which to perform a data\nselection for manual labeling at low costs. The proposed semi-supervised\nlearning decodes the unlabeled large training corpus using the seed model and\nthrough various protocols, selects the decoded utterances with high reliability\nusing confidence levels (that correlate to the WER of the decoded utterances)\nand iterative bootstrapping. The proposed active learning protocol uses\nconfidence level based metric to select the decoded utterances from the large\nunlabeled corpus for further labeling. The semi-supervised learning protocols\ncan offer a WER reduction, from a poorly trained seed model, by as much as 50%\nof the best WER-reduction realizable from the seed model's WER, if the large\ncorpus were labeled and used for acoustic-model training. The active learning\nprotocols allow that only 60% of the entire training corpus be manually\nlabeled, to reach the same performance as the entire data.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 07:23:42 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Chellapriyadharshini", "Maharajan", ""], ["Toffy", "Anoop", ""], ["M.", "Srinivasa Raghavan K.", ""], ["Ramasubramanian", "V", ""]]}, {"id": "1810.06638", "submitter": "Xipeng Qiu", "authors": "Fu Sun, Linyang Li, Xipeng Qiu, Yang Liu", "title": "U-Net: Machine Reading Comprehension with Unanswerable Questions", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine reading comprehension with unanswerable questions is a new\nchallenging task for natural language processing. A key subtask is to reliably\npredict whether the question is unanswerable. In this paper, we propose a\nunified model, called U-Net, with three important components: answer pointer,\nno-answer pointer, and answer verifier. We introduce a universal node and thus\nprocess the question and its context passage as a single contiguous sequence of\ntokens. The universal node encodes the fused information from both the question\nand passage, and plays an important role to predict whether the question is\nanswerable and also greatly improves the conciseness of the U-Net. Different\nfrom the state-of-art pipeline models, U-Net can be learned in an end-to-end\nfashion. The experimental results on the SQuAD 2.0 dataset show that U-Net can\neffectively predict the unanswerability of questions and achieves an F1 score\nof 71.7 on SQuAD 2.0.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 12:48:34 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Sun", "Fu", ""], ["Li", "Linyang", ""], ["Qiu", "Xipeng", ""], ["Liu", "Yang", ""]]}, {"id": "1810.06639", "submitter": "Hamid Mohammadi", "authors": "Hamid Mohammadi, Seyed Hossein Khasteh", "title": "A Machine Learning Approach to Persian Text Readability Assessment Using\n  a Crowdsourced Dataset", "comments": "15 pages, 4 figures, 4 tables, 7 equations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An automated approach to text readability assessment is essential to a\nlanguage and can be a powerful tool for improving the understandability of\ntexts written and published in that language. However, the Persian language,\nwhich is spoken by over 110 million speakers, lacks such a system. Unlike other\nlanguages such as English, French, and Chinese, very limited research studies\nhave been carried out to build an accurate and reliable text readability\nassessment system for the Persian language. In the present research, the first\nPersian dataset for text readability assessment was gathered and the first\nmodel for Persian text readability assessment using machine learning was\nintroduced. The experiments showed that this model was accurate and could\nassess the readability of Persian texts with a high degree of confidence. The\nresults of this study can be used in a number of applications such as medical\nand educational text readability evaluation and have the potential to be the\ncornerstone of future studies in Persian text readability assessment.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 19:07:59 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 21:31:08 GMT"}, {"version": "v3", "created": "Fri, 30 Aug 2019 20:43:15 GMT"}, {"version": "v4", "created": "Tue, 21 Apr 2020 23:03:57 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Mohammadi", "Hamid", ""], ["Khasteh", "Seyed Hossein", ""]]}, {"id": "1810.06640", "submitter": "David Donahue", "authors": "David Donahue, Anna Rumshisky", "title": "Adversarial Text Generation Without Reinforcement Learning", "comments": "Four pages without references. ACL latex style. Four figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have experienced a recent surge in\npopularity, performing competitively in a variety of tasks, especially in\ncomputer vision. However, GAN training has shown limited success in natural\nlanguage processing. This is largely because sequences of text are discrete,\nand thus gradients cannot propagate from the discriminator to the generator.\nRecent solutions use reinforcement learning to propagate approximate gradients\nto the generator, but this is inefficient to train. We propose to utilize an\nautoencoder to learn a low-dimensional representation of sentences. A GAN is\nthen trained to generate its own vectors in this space, which decode to\nrealistic utterances. We report both random and interpolated samples from the\ngenerator. Visualization of sentence vectors indicate our model correctly\nlearns the latent space of the autoencoder. Both human ratings and BLEU scores\nshow that our model generates realistic text against competitive baselines.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 22:50:38 GMT"}, {"version": "v2", "created": "Tue, 1 Jan 2019 23:38:54 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Donahue", "David", ""], ["Rumshisky", "Anna", ""]]}, {"id": "1810.06644", "submitter": "Lin Li", "authors": "Lin Li, Yueqing Sun", "title": "An Instance Transfer based Approach Using Enhanced Recurrent Neural\n  Network for Domain Named Entity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, neural networks have shown promising results for named entity\nrecognition (NER), which needs a number of labeled data to for model training.\nWhen meeting a new domain (target domain) for NER, there is no or a few labeled\ndata, which makes domain NER much more difficult. As NER has been researched\nfor a long time, some similar domain already has well labelled data (source\ndomain). Therefore, in this paper, we focus on domain NER by studying how to\nutilize the labelled data from such similar source domain for the new target\ndomain. We design a kernel function based instance transfer strategy by getting\nsimilar labelled sentences from a source domain. Moreover, we propose an\nenhanced recurrent neural network (ERNN) by adding an additional layer that\ncombines the source domain labelled data into traditional RNN structure.\nComprehensive experiments are conducted on two datasets. The comparison results\namong HMM, CRF and RNN show that RNN performs bette than others. When there is\nno labelled data in domain target, compared to directly using the source domain\nlabelled data without selecting transferred instances, our enhanced RNN\napproach gets improvement from 0.8052 to 0.9328 in terms of F1 measure.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 06:55:04 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Li", "Lin", ""], ["Sun", "Yueqing", ""]]}, {"id": "1810.06645", "submitter": "Lin Li", "authors": "Yunpei Zheng, Lin Li, Luo Zhong, Jianwei Zhang, Jinhang Liu", "title": "Using Sentiment Representation Learning to Enhance Gender Classification\n  for User Profiling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User profiling means exploiting the technology of machine learning to predict\nattributes of users, such as demographic attributes, hobby attributes,\npreference attributes, etc. It's a powerful data support of precision\nmarketing. Existing methods mainly study network behavior, personal\npreferences, post texts to build user profile. Through our data analysis of\nmicro-blog, we find that females show more positive and have richer emotions\nthan males in online social platform. This difference is very conducive to the\ndistinction between genders. Therefore, we argue that sentiment context is\nimportant as well for user profiling.This paper focuses on exploiting microblog\nuser posts to predict one of the demographic labels: gender. We propose a\nSentiment Representation Learning based Multi-Layer Perceptron(SRL-MLP) model\nto classify gender. First we build a sentiment polarity classifier in advance\nby training Long Short-Term Memory(LSTM) model on e-commerce review corpus.\nNext we transfer sentiment representation to a basic MLP network. Last we\nconduct experiments on gender classification by sentiment representation.\nExperimental results show that our approach can improve gender classification\naccuracy by 5.53\\%, from 84.20\\% to 89.73\\%.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 07:01:20 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Zheng", "Yunpei", ""], ["Li", "Lin", ""], ["Zhong", "Luo", ""], ["Zhang", "Jianwei", ""], ["Liu", "Jinhang", ""]]}, {"id": "1810.06665", "submitter": "Ahmed Elnaggar", "authors": "Ahmed Elnaggar, Bernhard Waltl, Ingo Glaser, J\\\"org Landthaler, Elena\n  Scepankova and Florian Matthes", "title": "Stop Illegal Comments: A Multi-Task Deep Learning Approach", "comments": "10 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods are often difficult to apply in the legal domain due to\nthe large amount of labeled data required by deep learning methods. A recent\nnew trend in the deep learning community is the application of multi-task\nmodels that enable single deep neural networks to perform more than one task at\nthe same time, for example classification and translation tasks. These powerful\nnovel models are capable of transferring knowledge among different tasks or\ntraining sets and therefore could open up the legal domain for many deep\nlearning applications. In this paper, we investigate the transfer learning\ncapabilities of such a multi-task model on a classification task on the\npublicly available Kaggle toxic comment dataset for classifying illegal\ncomments and we can report promising results.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 20:22:44 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Elnaggar", "Ahmed", ""], ["Waltl", "Bernhard", ""], ["Glaser", "Ingo", ""], ["Landthaler", "J\u00f6rg", ""], ["Scepankova", "Elena", ""], ["Matthes", "Florian", ""]]}, {"id": "1810.06667", "submitter": "Yaser Keneshloo", "authors": "Yaser Keneshloo, Naren Ramakrishnan, Chandan K. Reddy", "title": "Deep Transfer Reinforcement Learning for Text Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are data hungry models and thus face difficulties when\nattempting to train on small text datasets. Transfer learning is a potential\nsolution but their effectiveness in the text domain is not as explored as in\nareas such as image analysis. In this paper, we study the problem of transfer\nlearning for text summarization and discuss why existing state-of-the-art\nmodels fail to generalize well on other (unseen) datasets. We propose a\nreinforcement learning framework based on a self-critic policy gradient\napproach which achieves good generalization and state-of-the-art results on a\nvariety of datasets. Through an extensive set of experiments, we also show the\nability of our proposed framework to fine-tune the text summarization model\nusing only a few training samples. To the best of our knowledge, this is the\nfirst work that studies transfer learning in text summarization and provides a\ngeneric solution that works well on unseen data.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 20:26:44 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 20:14:33 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Keneshloo", "Yaser", ""], ["Ramakrishnan", "Naren", ""], ["Reddy", "Chandan K.", ""]]}, {"id": "1810.06673", "submitter": "Ahmed Elnaggar", "authors": "Ahmed Elnaggar, Robin Otto and Florian Matthes", "title": "Named-Entity Linking Using Deep Learning For Legal Documents: A Transfer\n  Learning Approach", "comments": "10 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the legal domain it is important to differentiate between words in\ngeneral, and afterwards to link the occurrences of the same entities. The topic\nto solve these challenges is called Named-Entity Linking (NEL). Current\nsupervised neural networks designed for NEL use publicly available datasets for\ntraining and testing. However, this paper focuses especially on the aspect of\napplying transfer learning approach using networks trained for NEL to legal\ndocuments. Experiments show consistent improvement in the legal datasets that\nwere created from the European Union law in the scope of this research. Using\ntransfer learning approach, we reached F1-score of 98.90\\% and 98.01\\% on the\nlegal small and large test dataset.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 20:38:00 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Elnaggar", "Ahmed", ""], ["Otto", "Robin", ""], ["Matthes", "Florian", ""]]}, {"id": "1810.06682", "submitter": "Shaojie Bai", "authors": "Shaojie Bai, J. Zico Kolter, Vladlen Koltun", "title": "Trellis Networks for Sequence Modeling", "comments": "Published at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present trellis networks, a new architecture for sequence modeling. On the\none hand, a trellis network is a temporal convolutional network with special\nstructure, characterized by weight tying across depth and direct injection of\nthe input into deep layers. On the other hand, we show that truncated recurrent\nnetworks are equivalent to trellis networks with special sparsity structure in\ntheir weight matrices. Thus trellis networks with general weight matrices\ngeneralize truncated recurrent networks. We leverage these connections to\ndesign high-performing trellis networks that absorb structural and algorithmic\nelements from both recurrent and convolutional models. Experiments demonstrate\nthat trellis networks outperform the current state of the art methods on a\nvariety of challenging benchmarks, including word-level language modeling and\ncharacter-level language modeling tasks, and stress tests designed to evaluate\nlong-term memory retention. The code is available at\nhttps://github.com/locuslab/trellisnet .\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 20:50:05 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 21:37:42 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Bai", "Shaojie", ""], ["Kolter", "J. Zico", ""], ["Koltun", "Vladlen", ""]]}, {"id": "1810.06683", "submitter": "Hsin-Yuan Huang", "authors": "Hsin-Yuan Huang, Eunsol Choi, Wen-tau Yih", "title": "FlowQA: Grasping Flow in History for Conversational Machine\n  Comprehension", "comments": "15 pages, Published at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational machine comprehension requires the understanding of the\nconversation history, such as previous question/answer pairs, the document\ncontext, and the current question. To enable traditional, single-turn models to\nencode the history comprehensively, we introduce Flow, a mechanism that can\nincorporate intermediate representations generated during the process of\nanswering previous questions, through an alternating parallel processing\nstructure. Compared to approaches that concatenate previous questions/answers\nas input, Flow integrates the latent semantics of the conversation history more\ndeeply. Our model, FlowQA, shows superior performance on two recently proposed\nconversational challenges (+7.2% F1 on CoQA and +4.0% on QuAC). The\neffectiveness of Flow also shows in other tasks. By reducing sequential\ninstruction understanding to conversational machine comprehension, FlowQA\noutperforms the best models on all three domains in SCONE, with +1.8% to +4.4%\nimprovement in accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 20:46:49 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2018 23:38:44 GMT"}, {"version": "v3", "created": "Tue, 16 Apr 2019 03:17:47 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Huang", "Hsin-Yuan", ""], ["Choi", "Eunsol", ""], ["Yih", "Wen-tau", ""]]}, {"id": "1810.06694", "submitter": "Stamatis Outsios", "authors": "Stamatis Outsios, Konstantinos Skianis, Polykarpos Meladianos,\n  Christos Xypolopoulos, Michalis Vazirgiannis", "title": "Word Embeddings from Large-Scale Greek Web Content", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are undoubtedly very useful components in many NLP tasks. In\nthis paper, we present word embeddings and other linguistic resources trained\non the largest to date digital Greek language corpus. We also present a live\nweb tool for testing the Greek word embeddings, by offering \"analogy\",\n\"similarity score\" and \"most similar words\" functions. Through our explorer,\none could interact with the Greek word vectors.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 17:19:07 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2018 10:04:33 GMT"}, {"version": "v3", "created": "Fri, 26 Oct 2018 14:32:21 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Outsios", "Stamatis", ""], ["Skianis", "Konstantinos", ""], ["Meladianos", "Polykarpos", ""], ["Xypolopoulos", "Christos", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "1810.06695", "submitter": "Giancarlo Salton", "authors": "Giancarlo D. Salton and Robert J. Ross and John D. Kelleher", "title": "Exploring the Use of Attention within an Neural Machine Translation\n  Decoder States to Translate Idioms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Idioms pose problems to almost all Machine Translation systems. This type of\nlanguage is very frequent in day-to-day language use and cannot be simply\nignored. The recent interest in memory augmented models in the field of\nLanguage Modelling has aided the systems to achieve good results by bridging\nlong-distance dependencies. In this paper we explore the use of such techniques\ninto a Neural Machine Translation system to help in translation of idiomatic\nlanguage.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 09:57:32 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Salton", "Giancarlo D.", ""], ["Ross", "Robert J.", ""], ["Kelleher", "John D.", ""]]}, {"id": "1810.06729", "submitter": "Mingbo Ma", "authors": "Hairong Liu, Mingbo Ma, Liang Huang, Hao Xiong and Zhongjun He", "title": "Robust Neural Machine Translation with Joint Textual and Phonetic\n  Embedding", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) is notoriously sensitive to noises, but\nnoises are almost inevitable in practice. One special kind of noise is the\nhomophone noise, where words are replaced by other words with similar\npronunciations. We propose to improve the robustness of NMT to homophone noises\nby 1) jointly embedding both textual and phonetic information of source\nsentences, and 2) augmenting the training dataset with homophone noises.\nInterestingly, to achieve better translation quality and more robustness, we\nfound that most (though not all) weights should be put on the phonetic rather\nthan textual information. Experiments show that our method not only\nsignificantly improves the robustness of NMT to homophone noises, but also\nsurprisingly improves the translation quality on some clean test sets.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 22:23:28 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 22:27:11 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Liu", "Hairong", ""], ["Ma", "Mingbo", ""], ["Huang", "Liang", ""], ["Xiong", "Hao", ""], ["He", "Zhongjun", ""]]}, {"id": "1810.06743", "submitter": "Arya McCarthy", "authors": "Arya D. McCarthy, Miikka Silfverberg, Ryan Cotterell, Mans Hulden,\n  David Yarowsky", "title": "Marrying Universal Dependencies and Universal Morphology", "comments": "UDW18", "journal-ref": "Proceedings of the Second Workshop on Universal Dependencies\n  (2018) 91-101", "doi": "10.18653/v1/W18-6011", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Universal Dependencies (UD) and Universal Morphology (UniMorph) projects\neach present schemata for annotating the morphosyntactic details of language.\nEach project also provides corpora of annotated text in many languages - UD at\nthe token level and UniMorph at the type level. As each corpus is built by\ndifferent annotators, language-specific decisions hinder the goal of universal\nschemata. With compatibility of tags, each project's annotations could be used\nto validate the other's. Additionally, the availability of both type- and\ntoken-level resources would be a boon to tasks such as parsing and homograph\ndisambiguation. To ease this interoperability, we present a deterministic\nmapping from Universal Dependencies v2 features into the UniMorph schema. We\nvalidate our approach by lookup in the UniMorph corpora and find a\nmacro-average of 64.13% recall. We also note incompatibilities due to paucity\nof data on either side. Finally, we present a critical evaluation of the\nfoundations, strengths, and weaknesses of the two annotation projects.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 23:00:13 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["McCarthy", "Arya D.", ""], ["Silfverberg", "Miikka", ""], ["Cotterell", "Ryan", ""], ["Hulden", "Mans", ""], ["Yarowsky", "David", ""]]}, {"id": "1810.06745", "submitter": "Michael Bossetta", "authors": "Anamaria Dutceac Segesten, Michael Bossetta", "title": "Can Euroscepticism Contribute to a European Public Sphere? The\n  Europeanization of Media Discourses about Euroscepticism across Six Countries", "comments": "29 pages, 2 figures, 4 tables, 2 appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study compares the media discourses about Euroscepticism in 2014 across\nsix countries (United Kingdom, Ireland, France, Spain, Sweden, and Denmark). We\nassess the extent to which the mass media's reporting of Euroscepticism\nindicates the Europeanization of public spheres. Using a mixed-methods approach\ncombining LDA topic modeling and qualitative coding, we find that approximately\n70 per cent of print articles mentioning \"Euroscepticism\" or \"Eurosceptic\" are\nframed in a non-domestic (i.e. European) context. In five of the six cases\nstudied, articles exhibiting a European context are strikingly similar in\ncontent, with the British case as the exception. However, coverage of British\nEuroscepticism drives Europeanization in other Member States. Bivariate\nlogistic regressions further reveal three macro-level structural variables that\nsignificantly correlate with a Europeanized media discourse: newspaper type\n(tabloid or broadsheet), presence of a strong Eurosceptic party, and\nrelationship to the EU budget (net contributor or receiver of EU funds).\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 23:06:03 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Segesten", "Anamaria Dutceac", ""], ["Bossetta", "Michael", ""]]}, {"id": "1810.06765", "submitter": "Vithya Yogarajan", "authors": "Vithya Yogarajan, Michael Mayo and Bernhard Pfahringer", "title": "A survey of automatic de-identification of longitudinal clinical\n  narratives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Use of medical data, also known as electronic health records, in research\nhelps develop and advance medical science. However, protecting patient\nconfidentiality and identity while using medical data for analysis is crucial.\nMedical data can be in the form of tabular structures (i.e. tables), free-form\nnarratives, and images. This study focuses on medical data in the free form\nlongitudinal text. De-identification of electronic health records provides the\nopportunity to use such data for research without it affecting patient privacy,\nand avoids the need for individual patient consent. In recent years there is\nincreasing interest in developing an accurate, robust and adaptable automatic\nde-identification system for electronic health records. This is mainly due to\nthe dilemma between the availability of an abundance of health data, and the\ninability to use such data in research due to legal and ethical restrictions.\nDe-identification tracks in competitions such as the 2014 i2b2 UTHealth and the\n2016 CEGS N-GRID shared tasks have provided a great platform to advance this\narea. The primary reasons for this include the open source nature of the\ndataset and the fact that raw psychiatric data were used for 2016 competitions.\nThis study focuses on noticeable trend changes in the techniques used in the\ndevelopment of automatic de-identification for longitudinal clinical\nnarratives. More specifically, the shift from using conditional random fields\n(CRF) based systems only or rules (regular expressions, dictionary or\ncombinations) based systems only, to hybrid models (combining CRF and rules),\nand more recently to deep learning based systems. We review the literature and\nresults that arose from the 2014 and the 2016 competitions and discuss the\noutcomes of these systems. We also provide a list of research questions that\nemerged from this survey.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 00:26:39 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Yogarajan", "Vithya", ""], ["Mayo", "Michael", ""], ["Pfahringer", "Bernhard", ""]]}, {"id": "1810.06818", "submitter": "Xiaoshi Zhong", "authors": "Xiaoshi Zhong and Erik Cambria and Jagath C. Rajapakse", "title": "Named Entity Analysis and Extraction with Uncommon Words", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most previous research treats named entity extraction and classification as\nan end-to-end task. We argue that the two sub-tasks should be addressed\nseparately. Entity extraction lies at the level of syntactic analysis while\nentity classification lies at the level of semantic analysis. According to Noam\nChomsky's \"Syntactic Structures,\" pp. 93-94 (Chomsky 1957), syntax is not\nappealed to semantics and semantics does not affect syntax. We analyze two\nbenchmark datasets for the characteristics of named entities, finding that\nuncommon words can distinguish named entities from common text; where uncommon\nwords are the words that hardly appear in common text and they are mainly the\nproper nouns. Experiments validate that lexical and syntactic features achieve\nstate-of-the-art performance on entity extraction and that semantic features do\nnot further improve the extraction performance, in both of our model and the\nstate-of-the-art baselines. With Chomsky's view, we also explain the failure of\njoint syntactic and semantic parsings in other works.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 05:40:03 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 11:57:12 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Zhong", "Xiaoshi", ""], ["Cambria", "Erik", ""], ["Rajapakse", "Jagath C.", ""]]}, {"id": "1810.06826", "submitter": "Yuta Nishimura", "authors": "Yuta Nishimura, Katsuhito Sudoh, Graham Neubig, Satoshi Nakamura", "title": "Multi-Source Neural Machine Translation with Data Augmentation", "comments": "15th International Workshop on Spoken Language Translation 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-source translation systems translate from multiple languages to a\nsingle target language. By using information from these multiple sources, these\nsystems achieve large gains in accuracy. To train these systems, it is\nnecessary to have corpora with parallel text in multiple sources and the target\nlanguage. However, these corpora are rarely complete in practice due to the\ndifficulty of providing human translations in all of the relevant languages. In\nthis paper, we propose a data augmentation approach to fill such incomplete\nparts using multi-source neural machine translation (NMT). In our experiments,\nresults varied over different language combinations but significant gains were\nobserved when using a source language similar to the target language.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 06:00:37 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 12:30:26 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Nishimura", "Yuta", ""], ["Sudoh", "Katsuhito", ""], ["Neubig", "Graham", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "1810.06898", "submitter": "Bardia Panahbehagh Ph.D.", "authors": "Mehdi Hosseini Moghadam and Bardia Panahbehagh", "title": "Creating a New Persian Poet Based on Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we describe an application of Machine Learning (ML) and\nLinguistic Modeling to generate persian poems. In fact we teach machine by\nreading and learning persian poems to generate fake poems in the same style of\nthe original poems. As two well known poets we used Hafez (1310-1390) and Saadi\n(1210-1292) poems. First we feed the machine with Hafez poems to generate fake\npoems with the same style and then we feed the machine with the both Hafez and\nSaadi poems to generate a new style poems which is combination of these two\npoets styles with emotional (Hafez) and rational (Saadi) elements. This idea of\ncombination of different styles with ML opens new gates for extending the\ntreasure of past literature of different cultures. Results show with enough\nmemory, processing power and time it is possible to generate reasonable good\npoems.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 09:37:24 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Moghadam", "Mehdi Hosseini", ""], ["Panahbehagh", "Bardia", ""]]}, {"id": "1810.06908", "submitter": "Alexander Tkachenko", "authors": "Alexander Tkachenko and Kairit Sirts", "title": "Neural Morphological Tagging for Estonian", "comments": null, "journal-ref": "Proceedings of the Eighth International Conference Baltic HLT 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop neural morphological tagging and disambiguation models for\nEstonian. First, we experiment with two neural architectures for morphological\ntagging - a standard multiclass classifier which treats each morphological tag\nas a single unit, and a sequence model which handles the morphological tags as\nsequences of morphological category values. Secondly, we complement these\nmodels with the analyses generated by a rule-based Estonian morphological\nanalyser (MA) VABAMORF , thus performing a soft morphological disambiguation.\nWe compare two ways of supplementing a neural morphological tagger with the MA\noutputs: firstly, by adding the combined analyses embeddings to the word\nrepresentation input to the neural tagging model, and secondly, by adopting an\nattention mechanism to focus on the most relevant analyses generated by the MA.\nExperiments on three Estonian datasets show that our neural architectures\nconsistently outperform the non-neural baselines, including HMM-disambiguated\nVABAMORF, while augmenting models with MA outputs results in a further\nperformance boost for both models.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 10:00:06 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Tkachenko", "Alexander", ""], ["Sirts", "Kairit", ""]]}, {"id": "1810.07030", "submitter": "Xuanda Chen", "authors": "Xuanda Chen, Ziyu Xiong, Jian Hu", "title": "The Trajectory of Voice Onset Time with Vocal Aging", "comments": "conference", "journal-ref": "Interspeech 2018", "doi": "10.21437/Interspeech.2018-60", "report-no": null, "categories": "cs.SD cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vocal aging, a universal process of human aging, can largely affect one's\nlanguage use, possibly including some subtle acoustic features of one's\nutterances like Voice Onset Time. To figure out the time effects, Queen\nElizabeth's Christmas speeches are documented and analyzed in the long-term\ntrend. We build statistical models of time dependence in Voice Onset Time,\ncontrolling a wide range of other fixed factors, to present annual variations\nand the simulated trajectory. It is revealed that the variation range of Voice\nOnset Time has been narrowing over fifty years with a slight reduction in the\nmean value, which, possibly, is an effect of diminishing exertion, resulting\nfrom subdued muscle contraction, transcending other non-linguistic factors in\nforming Voice Onset Time patterns over a long time.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 08:30:27 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Chen", "Xuanda", ""], ["Xiong", "Ziyu", ""], ["Hu", "Jian", ""]]}, {"id": "1810.07091", "submitter": "Ahmad Taie", "authors": "Ahmad Taie and Raphael Rubino and Josef van Genabith", "title": "INFODENS: An Open-source Framework for Learning Text Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of representation learning methods enabled large performance gains\non various language tasks, alleviating the need for manual feature engineering.\nWhile engineered representations are usually based on some linguistic\nunderstanding and are therefore more interpretable, learned representations are\nharder to interpret. Empirically studying the complementarity of both\napproaches can provide more linguistic insights that would help reach a better\ncompromise between interpretability and performance. We present INFODENS, a\nframework for studying learned and engineered representations of text in the\ncontext of text classification tasks. It is designed to simplify the tasks of\nfeature engineering as well as provide the groundwork for extracting learned\nfeatures and combining both approaches. INFODENS is flexible, extensible, with\na short learning curve, and is easy to integrate with many of the available and\nwidely used natural language processing tools.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 15:44:53 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Taie", "Ahmad", ""], ["Rubino", "Raphael", ""], ["van Genabith", "Josef", ""]]}, {"id": "1810.07125", "submitter": "Sabrina Mielke", "authors": "Ryan Cotterell and Christo Kirov and John Sylak-Glassman and\n  G\\'eraldine Walther and Ekaterina Vylomova and Arya D. McCarthy and Katharina\n  Kann and Sabrina J. Mielke and Garrett Nicolai and Miikka Silfverberg and\n  David Yarowsky and Jason Eisner and Mans Hulden", "title": "The CoNLL--SIGMORPHON 2018 Shared Task: Universal Morphological\n  Reinflection", "comments": "CoNLL 2018. arXiv admin note: text overlap with arXiv:1706.09031", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CoNLL--SIGMORPHON 2018 shared task on supervised learning of\nmorphological generation featured data sets from 103 typologically diverse\nlanguages. Apart from extending the number of languages involved in earlier\nsupervised tasks of generating inflected forms, this year the shared task also\nfeatured a new second task which asked participants to inflect words in\nsentential context, similar to a cloze task. This second task featured seven\nlanguages. Task 1 received 27 submissions and task 2 received 6 submissions.\nBoth tasks featured a low, medium, and high data condition. Nearly all\nsubmissions featured a neural component and built on highly-ranked systems from\nthe earlier 2017 shared task. In the inflection task (task 1), 41 of the 52\nlanguages present in last year's inflection task showed improvement by the best\nsystems in the low-resource setting. The cloze task (task 2) proved to be\ndifficult, and few submissions managed to consistently improve upon both a\nsimple neural baseline system and a lemma-repeating baseline.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 16:39:49 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 17:44:36 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2020 18:33:54 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Cotterell", "Ryan", ""], ["Kirov", "Christo", ""], ["Sylak-Glassman", "John", ""], ["Walther", "G\u00e9raldine", ""], ["Vylomova", "Ekaterina", ""], ["McCarthy", "Arya D.", ""], ["Kann", "Katharina", ""], ["Mielke", "Sabrina J.", ""], ["Nicolai", "Garrett", ""], ["Silfverberg", "Miikka", ""], ["Yarowsky", "David", ""], ["Eisner", "Jason", ""], ["Hulden", "Mans", ""]]}, {"id": "1810.07150", "submitter": "Kumar Shridhar", "authors": "Kumar Shridhar, Ayushman Dash, Amit Sahu, Gustav Grund Pihlgren, Pedro\n  Alonso, Vinaychandran Pondenkandath, Gyorgy Kovacs, Foteini Simistira, Marcus\n  Liwicki", "title": "Subword Semantic Hashing for Intent Classification on Small Datasets", "comments": "Accepted at IJCNN 2019 (Oral Presentation)", "journal-ref": null, "doi": "10.1109/IJCNN.2019.8852420", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we introduce the use of Semantic Hashing as embedding for the\ntask of Intent Classification and achieve state-of-the-art performance on three\nfrequently used benchmarks. Intent Classification on a small dataset is a\nchallenging task for data-hungry state-of-the-art Deep Learning based systems.\nSemantic Hashing is an attempt to overcome such a challenge and learn robust\ntext classification. Current word embedding based are dependent on\nvocabularies. One of the major drawbacks of such methods is out-of-vocabulary\nterms, especially when having small training datasets and using a wider\nvocabulary. This is the case in Intent Classification for chatbots, where\ntypically small datasets are extracted from internet communication. Two\nproblems arise by the use of internet communication. First, such datasets miss\na lot of terms in the vocabulary to use word embeddings efficiently. Second,\nusers frequently make spelling errors. Typically, the models for intent\nclassification are not trained with spelling errors and it is difficult to\nthink about ways in which users will make mistakes. Models depending on a word\nvocabulary will always face such issues. An ideal classifier should handle\nspelling errors inherently. With Semantic Hashing, we overcome these challenges\nand achieve state-of-the-art results on three datasets: AskUbuntu, Chatbot, and\nWeb Application. Our benchmarks are available online:\nhttps://github.com/kumar-shridhar/Know-Your-Intent\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 17:25:22 GMT"}, {"version": "v2", "created": "Sun, 16 Dec 2018 14:59:49 GMT"}, {"version": "v3", "created": "Sat, 14 Sep 2019 15:42:30 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Shridhar", "Kumar", ""], ["Dash", "Ayushman", ""], ["Sahu", "Amit", ""], ["Pihlgren", "Gustav Grund", ""], ["Alonso", "Pedro", ""], ["Pondenkandath", "Vinaychandran", ""], ["Kovacs", "Gyorgy", ""], ["Simistira", "Foteini", ""], ["Liwicki", "Marcus", ""]]}, {"id": "1810.07156", "submitter": "Soumil Mandal", "authors": "Soumil Mandal, Sankalp Sanand", "title": "Strategies for Language Identification in Code-Mixed Low Resource\n  Languages", "comments": "International Conference on Natural Language Processing (ICON 18) -\n  Student Paper Competition, Patiala, India", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, substantial work has been done on language tagging of\ncode-mixed data, but most of them use large amounts of data to build their\nmodels. In this article, we present three strategies to build a word level\nlanguage tagger for code-mixed data using very low resources. Each of them\nsecured an accuracy higher than our baseline model, and the best performing\nsystem got an accuracy around 91%. Combining all, the ensemble system achieved\nan accuracy of around 92.6%.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 17:35:31 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 20:59:09 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Mandal", "Soumil", ""], ["Sanand", "Sankalp", ""]]}, {"id": "1810.07217", "submitter": "Wei-Ning Hsu", "authors": "Wei-Ning Hsu, Yu Zhang, Ron J. Weiss, Heiga Zen, Yonghui Wu, Yuxuan\n  Wang, Yuan Cao, Ye Jia, Zhifeng Chen, Jonathan Shen, Patrick Nguyen, Ruoming\n  Pang", "title": "Hierarchical Generative Modeling for Controllable Speech Synthesis", "comments": "27 pages, accepted to ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a neural sequence-to-sequence text-to-speech (TTS) model\nwhich can control latent attributes in the generated speech that are rarely\nannotated in the training data, such as speaking style, accent, background\nnoise, and recording conditions. The model is formulated as a conditional\ngenerative model based on the variational autoencoder (VAE) framework, with two\nlevels of hierarchical latent variables. The first level is a categorical\nvariable, which represents attribute groups (e.g. clean/noisy) and provides\ninterpretability. The second level, conditioned on the first, is a multivariate\nGaussian variable, which characterizes specific attribute configurations (e.g.\nnoise level, speaking rate) and enables disentangled fine-grained control over\nthese attributes. This amounts to using a Gaussian mixture model (GMM) for the\nlatent distribution. Extensive evaluation demonstrates its ability to control\nthe aforementioned attributes. In particular, we train a high-quality\ncontrollable TTS model on real found data, which is capable of inferring\nspeaker and style attributes from a noisy utterance and use it to synthesize\nclean speech with controllable speaking style.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 18:20:02 GMT"}, {"version": "v2", "created": "Thu, 27 Dec 2018 06:50:41 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Hsu", "Wei-Ning", ""], ["Zhang", "Yu", ""], ["Weiss", "Ron J.", ""], ["Zen", "Heiga", ""], ["Wu", "Yonghui", ""], ["Wang", "Yuxuan", ""], ["Cao", "Yuan", ""], ["Jia", "Ye", ""], ["Chen", "Zhifeng", ""], ["Shen", "Jonathan", ""], ["Nguyen", "Patrick", ""], ["Pang", "Ruoming", ""]]}, {"id": "1810.07320", "submitter": "Adly Templeton", "authors": "Adly Templeton, Jugal Kalita", "title": "Exploring Sentence Vector Spaces through Automatic Summarization", "comments": "Accepted for publication in ICMLA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given vector representations for individual words, it is necessary to compute\nvector representations of sentences for many applications in a compositional\nmanner, often using artificial neural networks.\n  Relatively little work has explored the internal structure and properties of\nsuch sentence vectors. In this paper, we explore the properties of sentence\nvectors in the context of automatic summarization. In particular, we show that\ncosine similarity between sentence vectors and document vectors is strongly\ncorrelated with sentence importance and that vector semantics can identify and\ncorrect gaps between the sentences chosen so far and the document. In addition,\nwe identify specific dimensions which are linked to effective summaries. To our\nknowledge, this is the first time specific dimensions of sentence embeddings\nhave been connected to sentence properties. We also compare the features of\ndifferent methods of sentence embeddings. Many of these insights have\napplications in uses of sentence embeddings far beyond summarization.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 23:57:37 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Templeton", "Adly", ""], ["Kalita", "Jugal", ""]]}, {"id": "1810.07366", "submitter": "Yiming Cui", "authors": "Yiming Cui, Ting Liu, Wanxiang Che, Li Xiao, Zhipeng Chen, Wentao Ma,\n  Shijin Wang, Guoping Hu", "title": "A Span-Extraction Dataset for Chinese Machine Reading Comprehension", "comments": "6 pages, accepted as a conference paper at EMNLP-IJCNLP 2019 (short\n  paper)", "journal-ref": "EMNLP 2019 5886-5891", "doi": "10.18653/v1/D19-1600", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Reading Comprehension (MRC) has become enormously popular recently\nand has attracted a lot of attention. However, the existing reading\ncomprehension datasets are mostly in English. In this paper, we introduce a\nSpan-Extraction dataset for Chinese machine reading comprehension to add\nlanguage diversities in this area. The dataset is composed by near 20,000 real\nquestions annotated on Wikipedia paragraphs by human experts. We also annotated\na challenge set which contains the questions that need comprehensive\nunderstanding and multi-sentence inference throughout the context. We present\nseveral baseline systems as well as anonymous submissions for demonstrating the\ndifficulties in this dataset. With the release of the dataset, we hosted the\nSecond Evaluation Workshop on Chinese Machine Reading Comprehension (CMRC\n2018). We hope the release of the dataset could further accelerate the Chinese\nmachine reading comprehension research. Resources are available:\nhttps://github.com/ymcui/cmrc2018\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 03:02:26 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 05:25:53 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Cui", "Yiming", ""], ["Liu", "Ting", ""], ["Che", "Wanxiang", ""], ["Xiao", "Li", ""], ["Chen", "Zhipeng", ""], ["Ma", "Wentao", ""], ["Wang", "Shijin", ""], ["Hu", "Guoping", ""]]}, {"id": "1810.07382", "submitter": "Kamran Kowsari", "authors": "Mojtaba Heidarysafa, Kamran Kowsari, Laura E. Barnes and Donald E.\n  Brown", "title": "Analysis of Railway Accidents' Narratives Using Deep Learning", "comments": "accepted in IEEE International Conference on Machine Learning and\n  Applications (IEEE ICMLA)", "journal-ref": null, "doi": "10.1109/ICMLA.2018.00235", "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic understanding of domain specific texts in order to extract useful\nrelationships for later use is a non-trivial task. One such relationship would\nbe between railroad accidents' causes and their correspondent descriptions in\nreports. From 2001 to 2016 rail accidents in the U.S. cost more than $4.6B.\nRailroads involved in accidents are required to submit an accident report to\nthe Federal Railroad Administration (FRA). These reports contain a variety of\nfixed field entries including primary cause of the accidents (a coded variable\nwith 389 values) as well as a narrative field which is a short text description\nof the accident. Although these narratives provide more information than a\nfixed field entry, the terminologies used in these reports are not easy to\nunderstand by a non-expert reader. Therefore, providing an assisting method to\nfill in the primary cause from such domain specific texts(narratives) would\nhelp to label the accidents with more accuracy. Another important question for\ntransportation safety is whether the reported accident cause is consistent with\nnarrative description. To address these questions, we applied deep learning\nmethods together with powerful word embeddings such as Word2Vec and GloVe to\nclassify accident cause values for the primary cause field using the text in\nthe narratives. The results show that such approaches can both accurately\nclassify accident causes based on report narratives and find important\ninconsistencies in accident reporting.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 04:30:02 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2018 22:08:21 GMT"}, {"version": "v3", "created": "Wed, 20 May 2020 16:16:48 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Heidarysafa", "Mojtaba", ""], ["Kowsari", "Kamran", ""], ["Barnes", "Laura E.", ""], ["Brown", "Donald E.", ""]]}, {"id": "1810.07391", "submitter": "Xuanli He", "authors": "Xuanli He, Gholamreza Haffari, Mohammad Norouzi", "title": "Sequence to Sequence Mixture Model for Diverse Machine Translation", "comments": "11 pages, 5 figures, accepted to CoNLL2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence to sequence (SEQ2SEQ) models often lack diversity in their generated\ntranslations. This can be attributed to the limitation of SEQ2SEQ models in\ncapturing lexical and syntactic variations in a parallel corpus resulting from\ndifferent styles, genres, topics, or ambiguity of the translation process. In\nthis paper, we develop a novel sequence to sequence mixture (S2SMIX) model that\nimproves both translation diversity and quality by adopting a committee of\nspecialized translation models rather than a single translation model. Each\nmixture component selects its own training dataset via optimization of the\nmarginal loglikelihood, which leads to a soft clustering of the parallel\ncorpus. Experiments on four language pairs demonstrate the superiority of our\nmixture model compared to a SEQ2SEQ baseline with standard or diversity-boosted\nbeam search. Our mixture model uses negligible additional parameters and incurs\nno extra computation cost during decoding.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 05:42:49 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["He", "Xuanli", ""], ["Haffari", "Gholamreza", ""], ["Norouzi", "Mohammad", ""]]}, {"id": "1810.07455", "submitter": "Xuanli He", "authors": "Xuanli He, Quan Hung Tran, William Havard, Laurent Besacier, Ingrid\n  Zukerman, Gholamreza Haffari", "title": "Exploring Textual and Speech information in Dialogue Act Classification\n  with Speaker Domain Adaptation", "comments": "5 pages, 2 figurs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of the recent success of Dialogue Act (DA) classification, the\nmajority of prior works focus on text-based classification with oracle\ntranscriptions, i.e. human transcriptions, instead of Automatic Speech\nRecognition (ASR)'s transcriptions. In spoken dialog systems, however, the\nagent would only have access to noisy ASR transcriptions, which may further\nsuffer performance degradation due to domain shift. In this paper, we explore\nthe effectiveness of using both acoustic and textual signals, either oracle or\nASR transcriptions, and investigate speaker domain adaptation for DA\nclassification. Our multimodal model proves to be superior to the unimodal\nmodels, particularly when the oracle transcriptions are not available. We also\npropose an effective method for speaker domain adaptation, which achieves\ncompetitive results.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 09:53:03 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["He", "Xuanli", ""], ["Tran", "Quan Hung", ""], ["Havard", "William", ""], ["Besacier", "Laurent", ""], ["Zukerman", "Ingrid", ""], ["Haffari", "Gholamreza", ""]]}, {"id": "1810.07513", "submitter": "Ahmed Elnaggar", "authors": "Ahmed Elnaggar, Christoph Gebendorfer, Ingo Glaser and Florian Matthes", "title": "Multi-Task Deep Learning for Legal Document Translation, Summarization\n  and Multi-Label Classification", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The digitalization of the legal domain has been ongoing for a couple of\nyears. In that process, the application of different machine learning (ML)\ntechniques is crucial. Tasks such as the classification of legal documents or\ncontract clauses as well as the translation of those are highly relevant. On\nthe other side, digitized documents are barely accessible in this field,\nparticularly in Germany. Today, deep learning (DL) is one of the hot topics\nwith many publications and various applications. Sometimes it provides results\noutperforming the human level. Hence this technique may be feasible for the\nlegal domain as well. However, DL requires thousands of samples to provide\ndecent results. A potential solution to this problem is multi-task DL to enable\ntransfer learning. This approach may be able to overcome the data scarcity\nproblem in the legal domain, specifically for the German language. We applied\nthe state of the art multi-task model on three tasks: translation,\nsummarization, and multi-label classification. The experiments were conducted\non legal document corpora utilizing several task combinations as well as\nvarious model parameters. The goal was to find the optimal configuration for\nthe tasks at hand within the legal domain. The multi-task DL approach\noutperformed the state of the art results in all three tasks. This opens a new\ndirection to integrate DL technology more efficiently in the legal domain.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 08:54:50 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Elnaggar", "Ahmed", ""], ["Gebendorfer", "Christoph", ""], ["Glaser", "Ingo", ""], ["Matthes", "Florian", ""]]}, {"id": "1810.07595", "submitter": "Gongbo Tang", "authors": "Gongbo Tang and Rico Sennrich and Joakim Nivre", "title": "An Analysis of Attention Mechanisms: The Case of Word Sense\n  Disambiguation in Neural Machine Translation", "comments": "10 pages, accepted by WMT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that the encoder-decoder attention mechanisms in neural\nmachine translation (NMT) are different from the word alignment in statistical\nmachine translation. In this paper, we focus on analyzing encoder-decoder\nattention mechanisms, in the case of word sense disambiguation (WSD) in NMT\nmodels. We hypothesize that attention mechanisms pay more attention to context\ntokens when translating ambiguous words. We explore the attention distribution\npatterns when translating ambiguous nouns. Counter-intuitively, we find that\nattention mechanisms are likely to distribute more attention to the ambiguous\nnoun itself rather than context tokens, in comparison to other nouns. We\nconclude that attention mechanism is not the main mechanism used by NMT models\nto incorporate contextual information for WSD. The experimental results suggest\nthat NMT models learn to encode contextual information necessary for WSD in the\nencoder hidden states. For the attention mechanism in Transformer models, we\nreveal that the first few layers gradually learn to \"align\" source and target\ntokens and the last few layers learn to extract features from the related but\nunaligned context tokens.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 14:58:54 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Tang", "Gongbo", ""], ["Sennrich", "Rico", ""], ["Nivre", "Joakim", ""]]}, {"id": "1810.07652", "submitter": "Mattia Antonino Di Gangi", "authors": "Mattia Antonino Di Gangi, Roberto Dess\\`i, Roldano Cattoni, Matteo\n  Negri, Marco Turchi", "title": "Fine-tuning on Clean Data for End-to-End Speech Translation: FBK @ IWSLT\n  2018", "comments": "6 pages, 2 figures, system description at the 15th International\n  Workshop on Spoken Language Translation (IWSLT) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes FBK's submission to the end-to-end English-German speech\ntranslation task at IWSLT 2018. Our system relies on a state-of-the-art model\nbased on LSTMs and CNNs, where the CNNs are used to reduce the temporal\ndimension of the audio input, which is in general much higher than machine\ntranslation input. Our model was trained only on the audio-to-text parallel\ndata released for the task, and fine-tuned on cleaned subsets of the original\ntraining corpus. The addition of weight normalization and label smoothing\nimproved the baseline system by 1.0 BLEU point on our validation set. The final\nsubmission also featured checkpoint averaging within a training run and\nensemble decoding of models trained during multiple runs. On test data, our\nbest single model obtained a BLEU score of 9.7, while the ensemble obtained a\nBLEU score of 10.24.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 09:54:37 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Di Gangi", "Mattia Antonino", ""], ["Dess\u00ec", "Roberto", ""], ["Cattoni", "Roldano", ""], ["Negri", "Matteo", ""], ["Turchi", "Marco", ""]]}, {"id": "1810.07653", "submitter": "Baohua Sun", "authors": "Baohua Sun, Lin Yang, Patrick Dong, Wenhan Zhang, Jason Dong, Charles\n  Young", "title": "Super Characters: A Conversion from Sentiment Classification to Image\n  Classification", "comments": "7 pages, 1 figure, 5 tables. Accepted by EMNLP2018 workshop WASSA2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method named Super Characters for sentiment classification. This\nmethod converts the sentiment classification problem into image classification\nproblem by projecting texts into images and then applying CNN models for\nclassification. Text features are extracted automatically from the generated\nSuper Characters images, hence there is no need of any explicit step of\nembedding the words or characters into numerical vector representations.\nExperimental results on large social media corpus show that the Super\nCharacters method consistently outperforms other methods for sentiment\nclassification and topic classification tasks on ten large social media\ndatasets of millions of contents in four different languages, including\nChinese, Japanese, Korean and English.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 22:49:48 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Sun", "Baohua", ""], ["Yang", "Lin", ""], ["Dong", "Patrick", ""], ["Zhang", "Wenhan", ""], ["Dong", "Jason", ""], ["Young", "Charles", ""]]}, {"id": "1810.07767", "submitter": "Suryanto Nugroho", "authors": "Suryanto Nugroho, Prihandoko", "title": "Architecture of Text Mining Application in Analyzing Public Sentiments\n  of West Java Governor Election using Naive Bayes Classification", "comments": "5 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The selection of West Java governor is one event that seizes the attention of\nthe public is no exception to social media users. Public opinion on a\nprospective regional leader can help predict electability and tendency of\nvoters. Data that can be used by the opinion mining process can be obtained\nfrom Twitter. Because the data is very varied form and very unstructured, it\nmust be managed and uninformed using data pre-processing techniques into\nsemi-structured data. This semi-structured information is followed by a\nclassification stage to categorize the opinion into negative or positive\nopinions. The research methodology uses a literature study where the research\nwill examine previous research on a similar topic. The purpose of this study is\nto find the right architecture to develop it into the application of twitter\nopinion mining to know public sentiments toward the election of the governor of\nwest java. The result of this research is that Twitter opinion mining is part\nof text mining where opinions in Twitter if they want to be classified, must go\nthrough the preprocessing text stage first. The preprocessing step required\nfrom twitter data is cleansing, case folding, POS Tagging and stemming. The\nresulting text mining architecture is an architecture that can be used for text\nmining research with different topics.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 07:14:10 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Nugroho", "Suryanto", ""], ["Prihandoko", "", ""]]}, {"id": "1810.07781", "submitter": "Federica Calanca", "authors": "Federica Calanca, Luiza Sayfullina, Lara Minkus, Claudia Wagner, Eric\n  Malmi", "title": "Responsible team players wanted: an analysis of soft skill requirements\n  in job advertisements", "comments": "16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the past decades the importance of soft skills for labour market\noutcomes has grown substantially. This carries implications for labour market\ninequality, since previous research shows that soft skills are not valued\nequally across race and gender. This work explores the role of soft skills in\njob advertisements by drawing on methods from computational science as well as\non theoretical and empirical insights from economics, sociology and psychology.\nWe present a semi-automatic approach based on crowdsourcing and text mining for\nextracting a list of soft skills. We find that soft skills are a crucial\ncomponent of job ads, especially of low-paid jobs and jobs in female-dominated\nprofessions. Our work shows that soft skills can serve as partial predictors of\nthe gender composition in job categories and that not all soft skills receive\nequal wage returns at the labour market. Especially \"female\" skills are\nfrequently associated with wage penalties. Our results expand the growing\nliterature on the association of soft skills on wage inequality and highlight\ntheir importance for occupational gender segregation at labour markets.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 10:28:45 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 18:28:18 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Calanca", "Federica", ""], ["Sayfullina", "Luiza", ""], ["Minkus", "Lara", ""], ["Wagner", "Claudia", ""], ["Malmi", "Eric", ""]]}, {"id": "1810.07931", "submitter": "Sai Surya", "authors": "Sai Surya, Abhijit Mishra, Anirban Laha, Parag Jain, Karthik\n  Sankaranarayanan", "title": "Unsupervised Neural Text Simplification", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a first attempt towards unsupervised neural text\nsimplification that relies only on unlabeled text corpora. The core framework\nis composed of a shared encoder and a pair of attentional-decoders and gains\nknowledge of simplification through discrimination based-losses and denoising.\nThe framework is trained using unlabeled text collected from en-Wikipedia dump.\nOur analysis (both quantitative and qualitative involving human evaluators) on\na public test data shows that the proposed model can perform\ntext-simplification at both lexical and syntactic levels, competitive to\nexisting supervised methods. Addition of a few labelled pairs also improves the\nperformance further.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 07:43:12 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2018 14:28:43 GMT"}, {"version": "v3", "created": "Wed, 2 Jan 2019 03:36:48 GMT"}, {"version": "v4", "created": "Thu, 10 Jan 2019 11:43:46 GMT"}, {"version": "v5", "created": "Tue, 4 Jun 2019 13:33:50 GMT"}, {"version": "v6", "created": "Wed, 21 Aug 2019 08:45:12 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Surya", "Sai", ""], ["Mishra", "Abhijit", ""], ["Laha", "Anirban", ""], ["Jain", "Parag", ""], ["Sankaranarayanan", "Karthik", ""]]}, {"id": "1810.07942", "submitter": "Sonal Gupta", "authors": "Sonal Gupta, Rushin Shah, Mrinal Mohit, Anuj Kumar, Mike Lewis", "title": "Semantic Parsing for Task Oriented Dialog using Hierarchical\n  Representations", "comments": "Conference on Empirical Methods in Natural Language Processing\n  (EMNLP) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task oriented dialog systems typically first parse user utterances to\nsemantic frames comprised of intents and slots. Previous work on task oriented\nintent and slot-filling work has been restricted to one intent per query and\none slot label per token, and thus cannot model complex compositional requests.\nAlternative semantic parsing systems have represented queries as logical forms,\nbut these are challenging to annotate and parse. We propose a hierarchical\nannotation scheme for semantic parsing that allows the representation of\ncompositional queries, and can be efficiently and accurately parsed by standard\nconstituency parsing models. We release a dataset of 44k annotated queries\n(fb.me/semanticparsingdialog), and show that parsing models outperform\nsequence-to-sequence approaches on this dataset.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 08:22:49 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Gupta", "Sonal", ""], ["Shah", "Rushin", ""], ["Mohit", "Mrinal", ""], ["Kumar", "Anuj", ""], ["Lewis", "Mike", ""]]}, {"id": "1810.07949", "submitter": "Sebastian Martschat", "authors": "Sebastian Martschat, Katja Markert", "title": "A Temporally Sensitive Submodularity Framework for Timeline\n  Summarization", "comments": "To appear at CoNLL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timeline summarization (TLS) creates an overview of long-running events via\ndated daily summaries for the most important dates. TLS differs from standard\nmulti-document summarization (MDS) in the importance of date selection,\ninterdependencies between summaries of different dates and by having very short\nsummaries compared to the number of corpus documents. However, we show that MDS\noptimization models using submodular functions can be adapted to yield\nwell-performing TLS models by designing objective functions and constraints\nthat model the temporal dimension inherent in TLS. Importantly, these\nadaptations retain the elegance and advantages of the original MDS models\n(clear separation of features and inference, performance guarantees and\nscalability, little need for supervision) that current TLS-specific models\nlack. An open-source implementation of the framework and all models described\nin this paper is available online.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 08:46:40 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Martschat", "Sebastian", ""], ["Markert", "Katja", ""]]}, {"id": "1810.08076", "submitter": "Leonid Berov", "authors": "Leonid Berov, Kai Standvoss", "title": "Discourse Embellishment Using a Deep Encoder-Decoder Network", "comments": "Accepted at CC-NLG 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest a new NLG task in the context of the discourse generation pipeline\nof computational storytelling systems. This task, textual embellishment, is\ndefined by taking a text as input and generating a semantically equivalent\noutput with increased lexical and syntactic complexity. Ideally, this would\nallow the authors of computational storytellers to implement just lightweight\nNLG systems and use a domain-independent embellishment module to translate its\noutput into more literary text. We present promising first results on this task\nusing LSTM Encoder-Decoder networks trained on the WikiLarge dataset.\nFurthermore, we introduce \"Compiled Computer Tales\", a corpus of\ncomputationally generated stories, that can be used to test the capabilities of\nembellishment algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 14:29:50 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Berov", "Leonid", ""], ["Standvoss", "Kai", ""]]}, {"id": "1810.08113", "submitter": "Reinald Kim Amplayo", "authors": "Minseok Cho, Reinald Kim Amplayo, Seung-won Hwang, Jonghyuck Park", "title": "Adversarial TableQA: Attention Supervision for Question Answering on\n  Tables", "comments": "ACML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of answering a question given a text passage has shown great\ndevelopments on model performance thanks to community efforts in building\nuseful datasets. Recently, there have been doubts whether such rapid progress\nhas been based on truly understanding language. The same question has not been\nasked in the table question answering (TableQA) task, where we are tasked to\nanswer a query given a table. We show that existing efforts, of using \"answers\"\nfor both evaluation and supervision for TableQA, show deteriorating\nperformances in adversarial settings of perturbations that do not affect the\nanswer. This insight naturally motivates to develop new models that understand\nquestion and table more precisely. For this goal, we propose Neural Operator\n(NeOp), a multi-layer sequential network with attention supervision to answer\nthe query given a table. NeOp uses multiple Selective Recurrent Units (SelRUs)\nto further help the interpretability of the answers of the model. Experiments\nshow that the use of operand information to train the model significantly\nimproves the performance and interpretability of TableQA models. NeOp\noutperforms all the previous models by a big margin.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 15:35:07 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 13:01:24 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Cho", "Minseok", ""], ["Amplayo", "Reinald Kim", ""], ["Hwang", "Seung-won", ""], ["Park", "Jonghyuck", ""]]}, {"id": "1810.08135", "submitter": "Rahul Goel", "authors": "Chandra Khatri, Rahul Goel, Behnam Hedayatnia, Angeliki Metanillou,\n  Anushree Venkatesh, Raefer Gabriel, Arindam Mandal", "title": "Contextual Topic Modeling For Dialog Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate prediction of conversation topics can be a valuable signal for\ncreating coherent and engaging dialog systems. In this work, we focus on\ncontext-aware topic classification methods for identifying topics in free-form\nhuman-chatbot dialogs. We extend previous work on neural topic classification\nand unsupervised topic keyword detection by incorporating conversational\ncontext and dialog act features. On annotated data, we show that incorporating\ncontext and dialog acts leads to relative gains in topic classification\naccuracy by 35% and on unsupervised keyword detection recall by 11% for\nconversational interactions where topics frequently span multiple utterances.\nWe show that topical metrics such as topical depth is highly correlated with\ndialog evaluation metrics such as coherence and engagement implying that\nconversational topic models can predict user satisfaction. Our work for\ndetecting conversation topics and keywords can be used to guide chatbots\ntowards coherent dialog.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 16:19:16 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 01:00:20 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Khatri", "Chandra", ""], ["Goel", "Rahul", ""], ["Hedayatnia", "Behnam", ""], ["Metanillou", "Angeliki", ""], ["Venkatesh", "Anushree", ""], ["Gabriel", "Raefer", ""], ["Mandal", "Arindam", ""]]}, {"id": "1810.08237", "submitter": "Nikola Nikolov", "authors": "Nikola I. Nikolov, Richard H.R. Hahnloser", "title": "Large-scale Hierarchical Alignment for Data-driven Text Rewriting", "comments": "RANLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple unsupervised method for extracting pseudo-parallel\nmonolingual sentence pairs from comparable corpora representative of two\ndifferent text styles, such as news articles and scientific papers. Our\napproach does not require a seed parallel corpus, but instead relies solely on\nhierarchical search over pre-trained embeddings of documents and sentences. We\ndemonstrate the effectiveness of our method through automatic and extrinsic\nevaluation on text simplification from the normal to the Simple Wikipedia. We\nshow that pseudo-parallel sentences extracted with our method not only\nsupplement existing parallel data, but can even lead to competitive performance\non their own.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 18:51:43 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 07:25:09 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Nikolov", "Nikola I.", ""], ["Hahnloser", "Richard H. R.", ""]]}, {"id": "1810.08272", "submitter": "Dzmitry Bahdanau", "authors": "Maxime Chevalier-Boisvert, Dzmitry Bahdanau, Salem Lahlou, Lucas\n  Willems, Chitwan Saharia, Thien Huu Nguyen, Yoshua Bengio", "title": "BabyAI: A Platform to Study the Sample Efficiency of Grounded Language\n  Learning", "comments": "Accepted at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Allowing humans to interactively train artificial agents to understand\nlanguage instructions is desirable for both practical and scientific reasons,\nbut given the poor data efficiency of the current learning methods, this goal\nmay require substantial research efforts. Here, we introduce the BabyAI\nresearch platform to support investigations towards including humans in the\nloop for grounded language learning. The BabyAI platform comprises an\nextensible suite of 19 levels of increasing difficulty. The levels gradually\nlead the agent towards acquiring a combinatorially rich synthetic language\nwhich is a proper subset of English. The platform also provides a heuristic\nexpert agent for the purpose of simulating a human teacher. We report baseline\nresults and estimate the amount of human involvement that would be required to\ntrain a neural network-based agent on some of the BabyAI levels. We put forward\nstrong evidence that current deep learning methods are not yet sufficiently\nsample efficient when it comes to learning a language with compositional\nproperties.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 20:48:08 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 20:53:11 GMT"}, {"version": "v3", "created": "Wed, 11 Dec 2019 18:12:35 GMT"}, {"version": "v4", "created": "Thu, 19 Dec 2019 15:44:33 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Chevalier-Boisvert", "Maxime", ""], ["Bahdanau", "Dzmitry", ""], ["Lahlou", "Salem", ""], ["Willems", "Lucas", ""], ["Saharia", "Chitwan", ""], ["Nguyen", "Thien Huu", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1810.08307", "submitter": "Tomoki Matsuno", "authors": "Tomoki Matsuno, Katsuhiko Hayashi, Takahiro Ishihara, Hitoshi Manabe,\n  Yuji Matsumoto", "title": "Reduction of Parameter Redundancy in Biaffine Classifiers with Symmetric\n  and Circulant Weight Matrices", "comments": "Accepted to PACLIC 32", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, the biaffine classifier has been attracting attention as a method\nto introduce an attention mechanism into the modeling of binary relations. For\ninstance, in the field of dependency parsing, the Deep Biaffine Parser by Dozat\nand Manning has achieved state-of-the-art performance as a graph-based\ndependency parser on the English Penn Treebank and CoNLL 2017 shared task. On\nthe other hand, it is reported that parameter redundancy in the weight matrix\nin biaffine classifiers, which has O(n^2) parameters, results in overfitting (n\nis the number of dimensions). In this paper, we attempted to reduce the\nparameter redundancy by assuming either symmetry or circularity of weight\nmatrices. In our experiments on the CoNLL 2017 shared task dataset, our model\nachieved better or comparable accuracy on most of the treebanks with more than\n16% parameter reduction.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 23:40:47 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Matsuno", "Tomoki", ""], ["Hayashi", "Katsuhiko", ""], ["Ishihara", "Takahiro", ""], ["Manabe", "Hitoshi", ""], ["Matsumoto", "Yuji", ""]]}, {"id": "1810.08392", "submitter": "Mat\\=iss Rikters", "authors": "Mat\\=iss Rikters", "title": "Impact of Corpora Quality on Neural Machine Translation", "comments": null, "journal-ref": "Published in the proceedings of the 8th International Baltic Human\n  Language Technologies Conference (Baltic HLT 2018), held in Tartu, Estonia,\n  on 27-29 September 2018", "doi": "10.3233/978-1-61499-912-6-126", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large parallel corpora that are automatically obtained from the web,\ndocuments or elsewhere often exhibit many corrupted parts that are bound to\nnegatively affect the quality of the systems and models that learn from these\ncorpora. This paper describes frequent problems found in data and such data\naffects neural machine translation systems, as well as how to identify and deal\nwith them. The solutions are summarised in a set of scripts that remove\nproblematic sentences from input corpora.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 08:28:07 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Rikters", "Mat\u012bss", ""]]}, {"id": "1810.08398", "submitter": "Mingbo Ma", "authors": "Mingbo Ma, Liang Huang, Hao Xiong, Renjie Zheng, Kaibo Liu, Baigong\n  Zheng, Chuanqiang Zhang, Zhongjun He, Hairong Liu, Xing Li, Hua Wu and\n  Haifeng Wang", "title": "STACL: Simultaneous Translation with Implicit Anticipation and\n  Controllable Latency using Prefix-to-Prefix Framework", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneous translation, which translates sentences before they are\nfinished, is useful in many scenarios but is notoriously difficult due to\nword-order differences. While the conventional seq-to-seq framework is only\nsuitable for full-sentence translation, we propose a novel prefix-to-prefix\nframework for simultaneous translation that implicitly learns to anticipate in\na single translation model. Within this framework, we present a very simple yet\nsurprisingly effective wait-k policy trained to generate the target sentence\nconcurrently with the source sentence, but always k words behind. Experiments\nshow our strategy achieves low latency and reasonable quality (compared to\nfull-sentence translation) on 4 directions: zh<->en and de<->en.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 08:37:40 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 04:13:16 GMT"}, {"version": "v3", "created": "Sat, 3 Nov 2018 01:39:39 GMT"}, {"version": "v4", "created": "Thu, 13 Jun 2019 17:36:54 GMT"}, {"version": "v5", "created": "Mon, 24 Jun 2019 21:35:07 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Ma", "Mingbo", ""], ["Huang", "Liang", ""], ["Xiong", "Hao", ""], ["Zheng", "Renjie", ""], ["Liu", "Kaibo", ""], ["Zheng", "Baigong", ""], ["Zhang", "Chuanqiang", ""], ["He", "Zhongjun", ""], ["Liu", "Hairong", ""], ["Li", "Xing", ""], ["Wu", "Hua", ""], ["Wang", "Haifeng", ""]]}, {"id": "1810.08436", "submitter": "Aldrian Obaja Muis", "authors": "Zhanming Jie, Aldrian Obaja Muis, Wei Lu", "title": "Efficient Dependency-Guided Named Entity Recognition", "comments": "8+1 pages, 9 pages supplementary. Published in The 31st AAAI\n  Conference on Artificial Intelligence (AAAI 2017). This version fixes the\n  errors in two equations. arXiv admin note: text overlap with arXiv:1711.07010\n  by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity recognition (NER), which focuses on the extraction of\nsemantically meaningful named entities and their semantic classes from text,\nserves as an indispensable component for several down-stream natural language\nprocessing (NLP) tasks such as relation extraction and event extraction.\nDependency trees, on the other hand, also convey crucial semantic-level\ninformation. It has been shown previously that such information can be used to\nimprove the performance of NER (Sasano and Kurohashi 2008, Ling and Weld 2012).\nIn this work, we investigate on how to better utilize the structured\ninformation conveyed by dependency trees to improve the performance of NER.\nSpecifically, unlike existing approaches which only exploit dependency\ninformation for designing local features, we show that certain global\nstructured information of the dependency trees can be exploited when building\nNER models where such information can provide guided learning and inference.\nThrough extensive experiments, we show that our proposed novel\ndependency-guided NER model performs competitively with models based on\nconventional semi-Markov conditional random fields, while requiring\nsignificantly less running time.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 10:47:12 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 05:35:13 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Jie", "Zhanming", ""], ["Muis", "Aldrian Obaja", ""], ["Lu", "Wei", ""]]}, {"id": "1810.08567", "submitter": "Aldrian Obaja Muis", "authors": "Aldrian Obaja Muis, Wei Lu", "title": "Weak Semi-Markov CRFs for NP Chunking in Informal Text", "comments": "5+1 pages, published in NAACL 2016", "journal-ref": "Aldrian Obaja Muis and Wei Lu. 2016. Weak Semi-Markov CRFs for\n  Noun Phrase Chunking in Informal Text. In Proceedings of HLT-NAACL 2016,\n  pages 714-719", "doi": "10.18653/v1/N16-1085", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces a new annotated corpus based on an existing informal\ntext corpus: the NUS SMS Corpus (Chen and Kan, 2013). The new corpus includes\n76,490 noun phrases from 26,500 SMS messages, annotated by university students.\nWe then explored several graphical models, including a novel variant of the\nsemi-Markov conditional random fields (semi-CRF) for the task of noun phrase\nchunking. We demonstrated through empirical evaluations on the new dataset that\nthe new variant yielded similar accuracy but ran in significantly lower running\ntime compared to the conventional semi-CRF.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 16:09:35 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Muis", "Aldrian Obaja", ""], ["Lu", "Wei", ""]]}, {"id": "1810.08577", "submitter": "Adam Hornsby", "authors": "Adam N. Hornsby, Thomas Evans, Peter Riefer, Rosie Prior and Bradley\n  C. Love", "title": "Conceptual Organization is Revealed by Consumer Activity Patterns", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": "10.1007/s42113-019-00064-9", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Meaning may arise from an element's role or interactions within a larger\nsystem. For example, hitting nails is more central to people's concept of a\nhammer than its particular material composition or other intrinsic features.\nLikewise, the importance of a web page may result from its links with other\npages rather than solely from its content. One example of meaning arising from\nextrinsic relationships are approaches that extract the meaning of word\nconcepts from co-occurrence patterns in large, text corpora. The success of\nthese methods suggest that human activity patterns may reveal conceptual\norganization. However, texts do not directly reflect human activity, but\ninstead serve a communicative function and are usually highly curated or edited\nto suit an audience. Here, we apply methods devised for text to a data source\nthat directly reflects thousands of individuals' activity patterns, namely\nsupermarket purchases. Using product co-occurrence data from nearly 1.3m\nshopping baskets, we trained a topic model to learn 25 high-level concepts (or\n\"topics\"). These topics were found to be comprehensible and coherent by both\nretail experts and consumers. Topics ranged from specific (e.g., ingredients\nfor a stir-fry) to general (e.g., cooking from scratch). Topics tended to be\ngoal-directed and situational, consistent with the notion that human conceptual\nknowledge is tailored to support action. Individual differences in the topics\nsampled predicted basic demographic characteristics. These results suggest that\nhuman activity patterns reveal conceptual organization and may give rise to it.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 16:41:27 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Hornsby", "Adam N.", ""], ["Evans", "Thomas", ""], ["Riefer", "Peter", ""], ["Prior", "Rosie", ""], ["Love", "Bradley C.", ""]]}, {"id": "1810.08579", "submitter": "Aldrian Obaja Muis", "authors": "Aldrian Obaja Muis, Wei Lu", "title": "Learning to Recognize Discontiguous Entities", "comments": "9+1 pages + 8 pages supplementary, published in EMNLP 2016. v2: fix\n  references. v3: include missing supplementary, update with code repository", "journal-ref": "In Proc. of EMNLP, pages 75-84, Stroudsburg, PA, USA. Association\n  for Computational Linguistics (2016)", "doi": "10.18653/v1/D16-1008", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper focuses on the study of recognizing discontiguous entities.\nMotivated by a previous work, we propose to use a novel hypergraph\nrepresentation to jointly encode discontiguous entities of unbounded length,\nwhich can overlap with one another. To compare with existing approaches, we\nfirst formally introduce the notion of model ambiguity, which defines the\ndifficulty level of interpreting the outputs of a model, and then formally\nanalyze the theoretical advantages of our model over previous existing\napproaches based on linear-chain CRFs. Our empirical results also show that our\nmodel is able to achieve significantly better results when evaluated on\nstandard data with many discontiguous entities.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 16:48:25 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 14:26:54 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 13:09:57 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Muis", "Aldrian Obaja", ""], ["Lu", "Wei", ""]]}, {"id": "1810.08603", "submitter": "Michael Gasser", "authors": "Michael Gasser", "title": "Mainumby: un Ayudante para la Traducci\\'on Castellano-Guaran\\'i", "comments": "in Spanish, Ponencia presentada en el Tercer Seminario Internacional\n  sobre Traducci\\'on, Terminolog\\'ia y Lenguas Minorizadas, Asunci\\'on,\n  Paraguay, 19-21 julio, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A wide range of applications play an important role in the daily work of the\nmodern human translator. However, the computational tools designed to aid in\nthe process of translation only benefit translation from or to a small minority\nof the 7,000 languages of the world, those that we may call \"privileged\nlanguages\". As for those translators who work with the remaining languages, the\nmarginalized languages in the digital world, they cannot benefit from the tools\nthat are speeding up the production of translation in the privileged languages.\nWe may ask whether it is possible to bridge the gap between what is available\nfor these languages and for the marginalized ones. This paper proposes a\nframework for computer-assisted translation into marginalized languages and its\nimplementation in a web application for Spanish-Guarani translation. The\nproposed system is based on a new theory for phrase-level translation in\ncontexts where adequate bilingual corpora are not available: Translation by\nGeneralized Segments (referred to as Minimal Dependency Translation in previous\nwork).\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 17:55:46 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Gasser", "Michael", ""]]}, {"id": "1810.08606", "submitter": "Amit Gajbhiye", "authors": "Amit Gajbhiye, Sardar Jaf, Noura Al Moubayed, A. Stephen McGough,\n  Steven Bradley", "title": "An Exploration of Dropout with RNNs for Natural Language Inference", "comments": "Accepted in International Conference on Artificial Neural Networks,\n  2018", "journal-ref": null, "doi": "10.1007/978-3-030-01424-7_16", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Dropout is a crucial regularization technique for the Recurrent Neural\nNetwork (RNN) models of Natural Language Inference (NLI). However, dropout has\nnot been evaluated for the effectiveness at different layers and dropout rates\nin NLI models. In this paper, we propose a novel RNN model for NLI and\nempirically evaluate the effect of applying dropout at different layers in the\nmodel. We also investigate the impact of varying dropout rates at these layers.\nOur empirical evaluation on a large (Stanford Natural Language Inference\n(SNLI)) and a small (SciTail) dataset suggest that dropout at each feed-forward\nconnection severely affects the model accuracy at increasing dropout rates. We\nalso show that regularizing the embedding layer is efficient for SNLI whereas\nregularizing the recurrent layer improves the accuracy for SciTail. Our model\nachieved an accuracy 86.14% on the SNLI dataset and 77.05% on SciTail.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 17:48:21 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Gajbhiye", "Amit", ""], ["Jaf", "Sardar", ""], ["Moubayed", "Noura Al", ""], ["McGough", "A. Stephen", ""], ["Bradley", "Steven", ""]]}, {"id": "1810.08641", "submitter": "Elizabeth Salesky", "authors": "Elizabeth Salesky, Andrew Runge, Alex Coda, Jan Niehues, and Graham\n  Neubig", "title": "Optimizing Segmentation Granularity for Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neural machine translation (NMT), it is has become standard to translate\nusing subword units to allow for an open vocabulary and improve accuracy on\ninfrequent words. Byte-pair encoding (BPE) and its variants are the predominant\napproach to generating these subwords, as they are unsupervised, resource-free,\nand empirically effective. However, the granularity of these subword units is a\nhyperparameter to be tuned for each language and task, using methods such as\ngrid search. Tuning may be done inexhaustively or skipped entirely due to\nresource constraints, leading to sub-optimal performance. In this paper, we\npropose a method to automatically tune this parameter using only one training\npass. We incrementally introduce new vocabulary online based on the held-out\nvalidation loss, beginning with smaller, general subwords and adding larger,\nmore specific units over the course of training. Our method matches the results\nfound with grid search, optimizing segmentation granularity without any\nadditional training time. We also show benefits in training efficiency and\nperformance improvements for rare words due to the way embeddings for larger\nunits are incrementally constructed by combining those from smaller units.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 18:47:02 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Salesky", "Elizabeth", ""], ["Runge", "Andrew", ""], ["Coda", "Alex", ""], ["Niehues", "Jan", ""], ["Neubig", "Graham", ""]]}, {"id": "1810.08677", "submitter": "Matthew Turner", "authors": "Matthew A. Turner", "title": "A neural network to classify metaphorical violence on cable news", "comments": "6 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  I present here an experimental system for identifying and annotating metaphor\nin corpora. It is designed to plug in to Metacorps, an experimental web app for\nannotating metaphor. As Metacorps users annotate metaphors, the system will use\nuser annotations as training data. When the system is confident, it will\nsuggest an identification and an annotation. Once approved by the user, this\nbecomes more training data. This naturally allows for transfer learning, where\nthe system can, with some known degree of reliability, classify one class of\nmetaphor after only being trained on another class of metaphor. For example, in\nour metaphorical violence project, metaphors may be classified by the network\nthey were observed on, the grammatical subject or object of the violence\nmetaphor, or the violent word used (hit, attack, beat, etc.).\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 20:22:53 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Turner", "Matthew A.", ""]]}, {"id": "1810.08680", "submitter": "Benjamin Penchas", "authors": "Tobin Bell and Benjamin Penchas", "title": "Lightweight Convolutional Approaches to Reading Comprehension on SQuAD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current state-of-the-art reading comprehension models rely heavily on\nrecurrent neural networks. We explored an entirely different approach to\nquestion answering: a convolutional model. By their nature, these convolutional\nmodels are fast to train and capture local dependencies well, though they can\nstruggle with longer-range dependencies and thus require augmentation to\nachieve comparable performance to RNN-based models. We conducted over two dozen\ncontrolled experiments with convolutional models and various\nkernel/attention/regularization schemes to determine the precise performance\ngains of each strategy, while maintaining a focus on speed. We ultimately\nensembled three models: crossconv (0.5398 dev F1), attnconv (0.5665), and\nmaybeconv (0.5285). The ensembled model was able to achieve a 0.6238 F1 score\nusing the official SQuAD evaluation script. Our individual convolutional model\ncrossconv was able to exceed the performance of the RNN-plus-attention baseline\nby 25% while training 6 times faster.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 20:32:36 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Bell", "Tobin", ""], ["Penchas", "Benjamin", ""]]}, {"id": "1810.08699", "submitter": "Tsolak Ghukasyan", "authors": "Tsolak Ghukasyan, Garnik Davtyan, Karen Avetisyan, Ivan Andrianov", "title": "pioNER: Datasets and Baselines for Armenian Named Entity Recognition", "comments": "Accepted paper at Ivannikov ISP RAS Open Conference 2018.\n  \\c{opyright} 2018 IEEE", "journal-ref": null, "doi": "10.1109/ISPRAS.2018.00015.", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we tackle the problem of Armenian named entity recognition,\nproviding silver- and gold-standard datasets as well as establishing baseline\nresults on popular models. We present a 163000-token named entity corpus\nautomatically generated and annotated from Wikipedia, and another 53400-token\ncorpus of news sentences with manual annotation of people, organization and\nlocation named entities. The corpora were used to train and evaluate several\npopular named entity recognition models. Alongside the datasets, we release\n50-, 100-, 200-, 300-dimensional GloVe word embeddings trained on a collection\nof Armenian texts from Wikipedia, news, blogs, and encyclopedia.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 22:01:48 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Ghukasyan", "Tsolak", ""], ["Davtyan", "Garnik", ""], ["Avetisyan", "Karen", ""], ["Andrianov", "Ivan", ""]]}, {"id": "1810.08717", "submitter": "Eric Chu", "authors": "Eric Chu, Prashanth Vijayaraghavan, Deb Roy", "title": "Learning Personas from Dialogue with Attentive Memory Networks", "comments": "Accepted EMNLP Long Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ability to infer persona from dialogue can have applications in areas\nranging from computational narrative analysis to personalized dialogue\ngeneration. We introduce neural models to learn persona embeddings in a\nsupervised character trope classification task. The models encode dialogue\nsnippets from IMDB into representations that can capture the various categories\nof film characters. The best-performing models use a multi-level attention\nmechanism over a set of utterances. We also utilize prior knowledge in the form\nof textual descriptions of the different tropes. We apply the learned\nembeddings to find similar characters across different movies, and cluster\nmovies according to the distribution of the embeddings. The use of short\nconversational text as input, and the ability to learn from prior knowledge\nusing memory, suggests these methods could be applied to other domains.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 23:53:25 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Chu", "Eric", ""], ["Vijayaraghavan", "Prashanth", ""], ["Roy", "Deb", ""]]}, {"id": "1810.08732", "submitter": "Eda Okur", "authors": "Eda Okur and Hakan Demir and Arzucan \\\"Ozg\\\"ur", "title": "Named Entity Recognition on Twitter for Turkish using Semi-supervised\n  Learning with Word Embeddings", "comments": "Proceedings of the Tenth International Conference on Language\n  Resources and Evaluation (LREC 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, due to the increasing popularity of social media, the necessity for\nextracting information from informal text types, such as microblog texts, has\ngained significant attention. In this study, we focused on the Named Entity\nRecognition (NER) problem on informal text types for Turkish. We utilized a\nsemi-supervised learning approach based on neural networks. We applied a fast\nunsupervised method for learning continuous representations of words in vector\nspace. We made use of these obtained word embeddings, together with language\nindependent features that are engineered to work better on informal text types,\nfor generating a Turkish NER system on microblog texts. We evaluated our\nTurkish NER system on Twitter messages and achieved better F-score performances\nthan the published results of previously proposed NER systems on Turkish\ntweets. Since we did not employ any language dependent features, we believe\nthat our method can be easily adapted to microblog texts in other\nmorphologically rich languages.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 02:00:35 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Okur", "Eda", ""], ["Demir", "Hakan", ""], ["\u00d6zg\u00fcr", "Arzucan", ""]]}, {"id": "1810.08740", "submitter": "Feng Ji", "authors": "Xin Tang, Shanbo Cheng, Loc Do, Zhiyu Min, Feng Ji, Heng Yu, Ji Zhang,\n  Haiqin Chen", "title": "Improving Multilingual Semantic Textual Similarity with Shared Sentence\n  Encoder for Low-resource Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Measuring the semantic similarity between two sentences (or Semantic Textual\nSimilarity - STS) is fundamental in many NLP applications. Despite the\nremarkable results in supervised settings with adequate labeling, little\nattention has been paid to this task in low-resource languages with\ninsufficient labeling. Existing approaches mostly leverage machine translation\ntechniques to translate sentences into rich-resource language. These approaches\neither beget language biases, or be impractical in industrial applications\nwhere spoken language scenario is more often and rigorous efficiency is\nrequired. In this work, we propose a multilingual framework to tackle the STS\ntask in a low-resource language e.g. Spanish, Arabic , Indonesian and Thai, by\nutilizing the rich annotation data in a rich resource language, e.g. English.\nOur approach is extended from a basic monolingual STS framework to a shared\nmultilingual encoder pretrained with translation task to incorporate\nrich-resource language data. By exploiting the nature of a shared multilingual\nencoder, one sentence can have multiple representations for different target\ntranslation language, which are used in an ensemble model to improve similarity\nevaluation. We demonstrate the superiority of our method over other state of\nthe art approaches on SemEval STS task by its significant improvement on non-MT\nmethod, as well as an online industrial product where MT method fails to beat\nbaseline while our approach still has consistently improvements.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 03:00:53 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 13:53:56 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Tang", "Xin", ""], ["Cheng", "Shanbo", ""], ["Do", "Loc", ""], ["Min", "Zhiyu", ""], ["Ji", "Feng", ""], ["Yu", "Heng", ""], ["Zhang", "Ji", ""], ["Chen", "Haiqin", ""]]}, {"id": "1810.08782", "submitter": "Abhishek", "authors": "Abhishek Abhishek and Amar Prakash Azad and Balaji Ganesan and Ashish\n  Anand and Amit Awekar", "title": "Collective Learning From Diverse Datasets for Entity Typing in the Wild", "comments": "Accepted at EYRE'19 Workshop, CIKM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity typing (ET) is the problem of assigning labels to given entity\nmentions in a sentence. Existing works for ET require knowledge about the\ndomain and target label set for a given test instance. ET in the absence of\nsuch knowledge is a novel problem that we address as ET in the wild. We\nhypothesize that the solution to this problem is to build supervised models\nthat generalize better on the ET task as a whole, rather than a specific\ndataset. In this direction, we propose a Collective Learning Framework (CLF),\nwhich enables learning from diverse datasets in a unified way. The CLF first\ncreates a unified hierarchical label set (UHLS) and a label mapping by\naggregating label information from all available datasets. Then it builds a\nsingle neural network classifier using UHLS, label mapping, and a partial loss\nfunction. The single classifier predicts the finest possible label across all\navailable domains even though these labels may not be present in any\ndomain-specific dataset. We also propose a set of evaluation schemes and\nmetrics to evaluate the performance of models in this novel problem. Extensive\nexperimentation on seven diverse real-world datasets demonstrates the efficacy\nof our CLF.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 09:59:31 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 08:20:25 GMT"}, {"version": "v3", "created": "Mon, 16 Sep 2019 15:59:10 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Abhishek", "Abhishek", ""], ["Azad", "Amar Prakash", ""], ["Ganesan", "Balaji", ""], ["Anand", "Ashish", ""], ["Awekar", "Amit", ""]]}, {"id": "1810.08802", "submitter": "Mehdi Drissi", "authors": "Mehdi Drissi, Olivia Watkins, Jugal Kalita", "title": "Hierarchical Text Generation using an Outline", "comments": "8 pages, Accepted to International Conference on Natural Language\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many challenges in natural language processing require generating text,\nincluding language translation, dialogue generation, and speech recognition.\nFor all of these problems, text generation becomes more difficult as the text\nbecomes longer. Current language models often struggle to keep track of\ncoherence for long pieces of text. Here, we attempt to have the model construct\nand use an outline of the text it generates to keep it focused. We find that\nthe usage of an outline improves perplexity. We do not find that using the\noutline improves human evaluation over a simpler baseline, revealing a\ndiscrepancy in perplexity and human perception. Similarly, hierarchical\ngeneration is not found to improve human evaluation scores.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 13:27:04 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Drissi", "Mehdi", ""], ["Watkins", "Olivia", ""], ["Kalita", "Jugal", ""]]}, {"id": "1810.08815", "submitter": "Alexander Tkachenko", "authors": "Alexander Tkachenko and Kairit Sirts", "title": "Modeling Composite Labels for Neural Morphological Tagging", "comments": "Proceedings of the 22nd Conference on Computational Natural Language\n  Learning, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural morphological tagging has been regarded as an extension to POS tagging\ntask, treating each morphological tag as a monolithic label and ignoring its\ninternal structure. We propose to view morphological tags as composite labels\nand explicitly model their internal structure in a neural sequence tagger. For\nthis, we explore three different neural architectures and compare their\nperformance with both CRF and simple neural multiclass baselines. We evaluate\nour models on 49 languages and show that the neural architecture that models\nthe morphological labels as sequences of morphological category values performs\nsignificantly better than both baselines establishing state-of-the-art results\nin morphological tagging for most languages.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 15:00:23 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Tkachenko", "Alexander", ""], ["Sirts", "Kairit", ""]]}, {"id": "1810.08838", "submitter": "Jacob Krantz", "authors": "Jacob Krantz, Jugal Kalita", "title": "Abstractive Summarization Using Attentive Neural Techniques", "comments": "Accepted for oral presentation at the 15th International Conference\n  on Natural Language Processing (ICON 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a world of proliferating data, the ability to rapidly summarize text is\ngrowing in importance. Automatic summarization of text can be thought of as a\nsequence to sequence problem. Another area of natural language processing that\nsolves a sequence to sequence problem is machine translation, which is rapidly\nevolving due to the development of attention-based encoder-decoder networks.\nThis work applies these modern techniques to abstractive summarization. We\nperform analysis on various attention mechanisms for summarization with the\ngoal of developing an approach and architecture aimed at improving the state of\nthe art. In particular, we modify and optimize a translation model with\nself-attention for generating abstractive sentence summaries. The effectiveness\nof this base model along with attention variants is compared and analyzed in\nthe context of standardized evaluation sets and test metrics. However, we show\nthat these metrics are limited in their ability to effectively score\nabstractive summaries, and propose a new approach based on the intuition that\nan abstractive model requires an abstractive evaluation.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 18:24:48 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Krantz", "Jacob", ""], ["Kalita", "Jugal", ""]]}, {"id": "1810.08854", "submitter": "Mandar Joshi", "authors": "Mandar Joshi, Eunsol Choi, Omer Levy, Daniel S. Weld, Luke Zettlemoyer", "title": "pair2vec: Compositional Word-Pair Embeddings for Cross-Sentence\n  Inference", "comments": "NAACL camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning about implied relationships (e.g., paraphrastic, common sense,\nencyclopedic) between pairs of words is crucial for many cross-sentence\ninference problems. This paper proposes new methods for learning and using\nembeddings of word pairs that implicitly represent background knowledge about\nsuch relationships. Our pairwise embeddings are computed as a compositional\nfunction on word representations, which is learned by maximizing the pointwise\nmutual information (PMI) with the contexts in which the two words co-occur. We\nadd these representations to the cross-sentence attention layer of existing\ninference models (e.g. BiDAF for QA, ESIM for NLI), instead of extending or\nreplacing existing word embeddings. Experiments show a gain of 2.7% on the\nrecently released SQuAD2.0 and 1.3% on MultiNLI. Our representations also aid\nin better generalization with gains of around 6-7% on adversarial SQuAD\ndatasets, and 8.8% on the adversarial entailment test set by Glockner et al.\n(2018).\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 21:37:08 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 18:31:24 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Joshi", "Mandar", ""], ["Choi", "Eunsol", ""], ["Levy", "Omer", ""], ["Weld", "Daniel S.", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1810.08951", "submitter": "Ta-Chung Chi", "authors": "Ta-Chung Chi, Ching-Yen Shih, Yun-Nung Chen", "title": "BCWS: Bilingual Contextual Word Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the first dataset for evaluating English-Chinese\nBilingual Contextual Word Similarity, namely BCWS\n(https://github.com/MiuLab/BCWS). The dataset consists of 2,091 English-Chinese\nword pairs with the corresponding sentential contexts and their similarity\nscores annotated by the human. Our annotated dataset has higher consistency\ncompared to other similar datasets. We establish several baselines for the\nbilingual embedding task to benchmark the experiments. Modeling cross-lingual\nsense representations as provided in this dataset has the potential of moving\nartificial intelligence from monolingual understanding towards multilingual\nunderstanding.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 13:57:17 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Chi", "Ta-Chung", ""], ["Shih", "Ching-Yen", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1810.08994", "submitter": "David Vilares", "authors": "Carlos G\\'omez-Rodr\\'iguez and David Vilares", "title": "Constituent Parsing as Sequence Labeling", "comments": "EMNLP 2018 (Long Papers). Revised version with improved results after\n  fixing evaluation bug", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method to reduce constituent parsing to sequence labeling. For\neach word w_t, it generates a label that encodes: (1) the number of ancestors\nin the tree that the words w_t and w_{t+1} have in common, and (2) the\nnonterminal symbol at the lowest common ancestor. We first prove that the\nproposed encoding function is injective for any tree without unary branches. In\npractice, the approach is made extensible to all constituency trees by\ncollapsing unary branches. We then use the PTB and CTB treebanks as testbeds\nand propose a set of fast baselines. We achieve 90.7% F-score on the PTB test\nset, outperforming the Vinyals et al. (2015) sequence-to-sequence parser. In\naddition, sacrificing some accuracy, our approach achieves the fastest\nconstituent parsing speeds reported to date on PTB by a wide margin.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 17:59:52 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 10:28:24 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["G\u00f3mez-Rodr\u00edguez", "Carlos", ""], ["Vilares", "David", ""]]}, {"id": "1810.08997", "submitter": "David Vilares", "authors": "David Vilares and Carlos G\\'omez-Rodr\\'iguez", "title": "Transition-based Parsing with Lighter Feed-Forward Networks", "comments": "UD Workshop (co-located with EMNLP 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore whether it is possible to build lighter parsers, that are\nstatistically equivalent to their corresponding standard version, for a wide\nset of languages showing different structures and morphologies. As testbed, we\nuse the Universal Dependencies and transition-based dependency parsers trained\non feed-forward networks. For these, most existing research assumes de facto\nstandard embedded features and relies on pre-computation tricks to obtain\nspeed-ups. We explore how these features and their size can be reduced and\nwhether this translates into speed-ups with a negligible impact on accuracy.\nThe experiments show that grand-daughter features can be removed for the\nmajority of treebanks without a significant (negative or positive) LAS\ndifference. They also show how the size of the embeddings can be notably\nreduced.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 18:17:37 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Vilares", "David", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "1810.09073", "submitter": "Aldrian Obaja Muis", "authors": "Aldrian Obaja Muis, Wei Lu", "title": "Labeling Gaps Between Words: Recognizing Overlapping Mentions with\n  Mention Separators", "comments": "9+2 pages, 6 pages supplementary. Published in EMNLP 2017", "journal-ref": null, "doi": "10.18653/v1/D17-1276", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a new model that is capable of recognizing\noverlapping mentions. We introduce a novel notion of mention separators that\ncan be effectively used to capture how mentions overlap with one another. On\ntop of a novel multigraph representation that we introduce, we show that\nefficient and exact inference can still be performed. We present some\ntheoretical analysis on the differences between our model and a recently\nproposed model for recognizing overlapping mentions, and discuss the possible\nimplications of the differences. Through extensive empirical analysis on\nstandard datasets, we demonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 03:38:23 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Muis", "Aldrian Obaja", ""], ["Lu", "Wei", ""]]}, {"id": "1810.09154", "submitter": "Ruizhe Li", "authors": "Ruizhe Li, Chenghua Lin, Matthew Collinson, Xiao Li, Guanyi Chen", "title": "A Dual-Attention Hierarchical Recurrent Neural Network for Dialogue Act\n  Classification", "comments": "Accepted by CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognising dialogue acts (DA) is important for many natural language\nprocessing tasks such as dialogue generation and intention recognition. In this\npaper, we propose a dual-attention hierarchical recurrent neural network for DA\nclassification. Our model is partially inspired by the observation that\nconversational utterances are normally associated with both a DA and a topic,\nwhere the former captures the social act and the latter describes the subject\nmatter. However, such a dependency between DAs and topics has not been utilised\nby most existing systems for DA classification. With a novel dual task-specific\nattention mechanism, our model is able, for utterances, to capture information\nabout both DAs and topics, as well as information about the interactions\nbetween them. Experimental results show that by modelling topic as an auxiliary\ntask, our model can significantly improve DA classification, yielding better or\ncomparable performance to the state-of-the-art method on three public datasets.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 09:45:52 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2019 22:58:09 GMT"}, {"version": "v3", "created": "Thu, 10 Oct 2019 15:21:26 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Li", "Ruizhe", ""], ["Lin", "Chenghua", ""], ["Collinson", "Matthew", ""], ["Li", "Xiao", ""], ["Chen", "Guanyi", ""]]}, {"id": "1810.09164", "submitter": "Alberto Cetoli", "authors": "Alberto Cetoli, Mohammad Akbari, Stefano Bragaglia, Andrew D.\n  O'Harney, Marc Sloan", "title": "Named Entity Disambiguation using Deep Learning on Graphs", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-15719-7_10", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle \\ac{NED} by comparing entities in short sentences with \\wikidata{}\ngraphs. Creating a context vector from graphs through deep learning is a\nchallenging problem that has never been applied to \\ac{NED}. Our main\ncontribution is to present an experimental study of recent neural techniques,\nas well as a discussion about which graph features are most important for the\ndisambiguation task. In addition, a new dataset (\\wikidatadisamb{}) is created\nto allow a clean and scalable evaluation of \\ac{NED} with \\wikidata{} entries,\nand to be used as a reference in future research. In the end our results show\nthat a \\ac{Bi-LSTM} encoding of the graph triplets performs best, improving\nupon the baseline models and scoring an \\rm{F1} value of $91.6\\%$ on the\n\\wikidatadisamb{} test set\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 10:16:07 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Cetoli", "Alberto", ""], ["Akbari", "Mohammad", ""], ["Bragaglia", "Stefano", ""], ["O'Harney", "Andrew D.", ""], ["Sloan", "Marc", ""]]}, {"id": "1810.09302", "submitter": "Qingyu Chen", "authors": "Qingyu Chen, Yifan Peng, and Zhiyong Lu", "title": "BioSentVec: creating sentence embeddings for biomedical texts", "comments": "5 pages, 3 tables and 2 figures accepted by The Seventh IEEE\n  International Conference on Healthcare Informatics (ICHI 2019)", "journal-ref": null, "doi": "10.1109/ICHI.2019.8904728", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence embeddings have become an essential part of today's natural language\nprocessing (NLP) systems, especially together advanced deep learning methods.\nAlthough pre-trained sentence encoders are available in the general domain,\nnone exists for biomedical texts to date. In this work, we introduce\nBioSentVec: the first open set of sentence embeddings trained with over 30\nmillion documents from both scholarly articles in PubMed and clinical notes in\nthe MIMIC-III Clinical Database. We evaluate BioSentVec embeddings in two\nsentence pair similarity tasks in different text genres. Our benchmarking\nresults demonstrate that the BioSentVec embeddings can better capture sentence\nsemantics compared to the other competitive alternatives and achieve\nstate-of-the-art performance in both tasks. We expect BioSentVec to facilitate\nthe research and development in biomedical text mining and to complement the\nexisting resources in biomedical word embeddings. BioSentVec is publicly\navailable at https://github.com/ncbi-nlp/BioSentVec\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 14:10:01 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 15:04:19 GMT"}, {"version": "v3", "created": "Wed, 15 May 2019 04:41:06 GMT"}, {"version": "v4", "created": "Tue, 18 Jun 2019 13:46:32 GMT"}, {"version": "v5", "created": "Wed, 19 Jun 2019 00:33:32 GMT"}, {"version": "v6", "created": "Fri, 24 Jan 2020 21:48:13 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Chen", "Qingyu", ""], ["Peng", "Yifan", ""], ["Lu", "Zhiyong", ""]]}, {"id": "1810.09305", "submitter": "Mahnaz Koupaee", "authors": "Mahnaz Koupaee, William Yang Wang", "title": "WikiHow: A Large Scale Text Summarization Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence models have recently gained the state of the art\nperformance in summarization. However, not too many large-scale high-quality\ndatasets are available and almost all the available ones are mainly news\narticles with specific writing style. Moreover, abstractive human-style systems\ninvolving description of the content at a deeper level require data with higher\nlevels of abstraction. In this paper, we present WikiHow, a dataset of more\nthan 230,000 article and summary pairs extracted and constructed from an online\nknowledge base written by different human authors. The articles span a wide\nrange of topics and therefore represent high diversity styles. We evaluate the\nperformance of the existing methods on WikiHow to present its challenges and\nset some baselines to further improve it.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 05:29:41 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Koupaee", "Mahnaz", ""], ["Wang", "William Yang", ""]]}, {"id": "1810.09309", "submitter": "Jiali Yao", "authors": "Jiali Yao, Raphael Shu, Xinjian Li, Katsutoshi Ohtsuki, Hideki\n  Nakayama", "title": "Real-time Neural-based Input Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The input method is an essential service on every mobile and desktop devices\nthat provides text suggestions. It converts sequential keyboard inputs to the\ncharacters in its target language, which is indispensable for Japanese and\nChinese users. Due to critical resource constraints and limited network\nbandwidth of the target devices, applying neural models to input method is not\nwell explored. In this work, we apply a LSTM-based language model to input\nmethod and evaluate its performance for both prediction and conversion tasks\nwith Japanese BCCWJ corpus. We articulate the bottleneck to be the slow softmax\ncomputation during conversion. To solve the issue, we propose incremental\nsoftmax approximation approach, which computes softmax with a selected subset\nvocabulary and fix the stale probabilities when the vocabulary is updated in\nfuture steps. We refer to this method as incremental selective softmax. The\nresults show a two order speedup for the softmax computation when converting\nJapanese input sequences with a large vocabulary, reaching real-time speed on\ncommodity CPU. We also exploit the model compressing potential to achieve a 92%\nmodel size reduction without losing accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 12:57:37 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Yao", "Jiali", ""], ["Shu", "Raphael", ""], ["Li", "Xinjian", ""], ["Ohtsuki", "Katsutoshi", ""], ["Nakayama", "Hideki", ""]]}, {"id": "1810.09311", "submitter": "Alejandro Moreo Fern\\'andez", "authors": "Alejandro Moreo, Andrea Esuli, Fabrizio Sebastiani", "title": "Revisiting Distributional Correspondence Indexing: A Python\n  Reimplementation and New Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces PyDCI, a new implementation of Distributional\nCorrespondence Indexing (DCI) written in Python. DCI is a transfer learning\nmethod for cross-domain and cross-lingual text classification for which we had\nprovided an implementation (here called JaDCI) built on top of JaTeCS, a Java\nframework for text classification. PyDCI is a stand-alone version of DCI that\nexploits scikit-learn and the SciPy stack. We here report on new experiments\nthat we have carried out in order to test PyDCI, and in which we use as\nbaselines new high-performing methods that have appeared after DCI was\noriginally proposed. These experiments show that, thanks to a few subtle ways\nin which we have improved DCI, PyDCI outperforms both JaDCI and the\nabove-mentioned high-performing methods, and delivers the best known results on\nthe two popular benchmarks on which we had tested DCI, i.e.,\nMultiDomainSentiment (a.k.a. MDS -- for cross-domain adaptation) and\nWebis-CLS-10 (for cross-lingual adaptation). PyDCI, together with the code\nallowing to replicate our experiments, is available at\nhttps://github.com/AlexMoreo/pydci .\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 07:27:24 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Moreo", "Alejandro", ""], ["Esuli", "Andrea", ""], ["Sebastiani", "Fabrizio", ""]]}, {"id": "1810.09312", "submitter": "Mahnaz Koupaee", "authors": "Mahnaz Koupaee, William Yang Wang", "title": "Analyzing and Interpreting Convolutional Neural Networks in NLP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks have been successfully applied to various NLP\ntasks. However, it is not obvious whether they model different linguistic\npatterns such as negation, intensification, and clause compositionality to help\nthe decision-making process. In this paper, we apply visualization techniques\nto observe how the model can capture different linguistic features and how\nthese features can affect the performance of the model. Later on, we try to\nidentify the model errors and their sources. We believe that interpreting CNNs\nis the first step to understand the underlying semantic features which can\nraise awareness to further improve the performance and explainability of CNN\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 05:18:04 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Koupaee", "Mahnaz", ""], ["Wang", "William Yang", ""]]}, {"id": "1810.09377", "submitter": "Efsun Kayi", "authors": "Efsun Sarioglu Kayi, Mona Diab, Luca Pauselli, Michael Compton, and\n  Glen Coppersmith", "title": "Predictive Linguistic Features of Schizophrenia", "comments": null, "journal-ref": "Proceedings of the 6th Joint Conference on Lexical and\n  Computational Semantics (*SEM 2017), Association for Computational\n  Linguistics, 2017, pp. 241-250", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Schizophrenia is one of the most disabling and difficult to treat of all\nhuman medical/health conditions, ranking in the top ten causes of disability\nworldwide. It has been a puzzle in part due to difficulty in identifying its\nbasic, fundamental components. Several studies have shown that some\nmanifestations of schizophrenia (e.g., the negative symptoms that include\nblunting of speech prosody, as well as the disorganization symptoms that lead\nto disordered language) can be understood from the perspective of linguistics.\nHowever, schizophrenia research has not kept pace with technologies in\ncomputational linguistics, especially in semantics and pragmatics. As such, we\nexamine the writings of schizophrenia patients analyzing their syntax,\nsemantics and pragmatics. In addition, we analyze tweets of (self pro-claimed)\nschizophrenia patients who publicly discuss their diagnoses. For writing\nsamples dataset, syntactic features are found to be the most successful in\nclassification whereas for the less structured Twitter dataset, a combination\nof features performed the best.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 15:48:52 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Kayi", "Efsun Sarioglu", ""], ["Diab", "Mona", ""], ["Pauselli", "Luca", ""], ["Compton", "Michael", ""], ["Coppersmith", "Glen", ""]]}, {"id": "1810.09379", "submitter": "Alexandre Rademaker", "authors": "Alessandra Cid and Alexandre Rademaker and Bruno Cuconato and Valeria\n  de Paiva", "title": "Linguistic Legal Concept Extraction in Portuguese", "comments": "This work was accepted for publication in the JURIX 2018\n  (http://jurix2018.ai.rug.nl) in a short 5-pages version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work investigates legal concepts and their expression in Portuguese,\nconcentrating on the \"Order of Attorneys of Brazil\" Bar exam. Using a corpus\nformed by a collection of multiple-choice questions, three norms related to the\nEthics part of the OAB exam, language resources (Princeton WordNet and\nOpenWordNet-PT) and tools (AntConc and Freeling), we began to investigate the\nconcepts and words missing from our repertory of concepts and words in\nPortuguese, the knowledge base OpenWordNet-PT. We add these concepts and words\nto OpenWordNet-PT and hence obtain a representation of these texts that is\n\"contained\" in the lexical knowledge base.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 15:58:57 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Cid", "Alessandra", ""], ["Rademaker", "Alexandre", ""], ["Cuconato", "Bruno", ""], ["de Paiva", "Valeria", ""]]}, {"id": "1810.09431", "submitter": "Christopher Shulby", "authors": "Christopher Dane Shulby, Leonardo Pombal, Vitor Jord\\~ao, Guilherme\n  Ziolle, Bruno Martho, Ant\\^onio Postal, Thiago Prochnow", "title": "Proactive Security: Embedded AI Solution for Violent and Abusive Speech\n  Recognition", "comments": "6 Pages, Bracis 2018 Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Violence is an epidemic in Brazil and a problem on the rise world-wide.\nMobile devices provide communication technologies which can be used to monitor\nand alert about violent situations. However, current solutions, like panic\nbuttons or safe words, might increase the loss of life in violent situations.\nWe propose an embedded artificial intelligence solution, using natural language\nand speech processing technology, to silently alert someone who can help in\nthis situation. The corpus used contains 400 positive phrases and 800 negative\nphrases, totaling 1,200 sentences which are classified using two well-known\nextraction methods for natural language processing tasks: bag-of-words and word\nembeddings and classified with a support vector machine. We describe the\nproof-of-concept product in development with promising results, indicating a\npath towards a commercial product. More importantly we show that model\nimprovements via word embeddings and data augmentation techniques provide an\nintrinsically robust model. The final embedded solution also has a small\nfootprint of less than 10 MB.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 17:56:08 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Shulby", "Christopher Dane", ""], ["Pombal", "Leonardo", ""], ["Jord\u00e3o", "Vitor", ""], ["Ziolle", "Guilherme", ""], ["Martho", "Bruno", ""], ["Postal", "Ant\u00f4nio", ""], ["Prochnow", "Thiago", ""]]}, {"id": "1810.09506", "submitter": "Ari Klein", "authors": "Ari Z. Klein, Abeed Sarker, Davy Weissenbacher, Graciela\n  Gonzalez-Hernandez", "title": "Automatically Detecting Self-Reported Birth Defect Outcomes on Twitter\n  for Large-scale Epidemiological Research", "comments": null, "journal-ref": "npj Digital Medicine. 2019;2:96", "doi": "10.1038/s41746-019-0170-5", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent work, we identified and studied a small cohort of Twitter users\nwhose pregnancies with birth defect outcomes could be observed via their\npublicly available tweets. Exploiting social media's large-scale potential to\ncomplement the limited methods for studying birth defects, the leading cause of\ninfant mortality, depends on the further development of automatic methods. The\nprimary objective of this study was to take the first step towards scaling the\nuse of social media for observing pregnancies with birth defect outcomes,\nnamely, developing methods for automatically detecting tweets by users\nreporting their birth defect outcomes. We annotated and pre-processed\napproximately 23,000 tweets that mention birth defects in order to train and\nevaluate supervised machine learning algorithms, including feature-engineered\nand deep learning-based classifiers. We also experimented with various\nunder-sampling and over-sampling approaches to address the class imbalance. A\nSupport Vector Machine (SVM) classifier trained on the original, imbalanced\ndata set, with n-grams, word clusters, and structural features, achieved the\nbest baseline performance for the positive classes: an F1-score of 0.65 for the\n\"defect\" class and 0.51 for the \"possible defect\" class. Our contributions\ninclude (i) natural language processing (NLP) and supervised machine learning\nmethods for automatically detecting tweets by users reporting their birth\ndefect outcomes, (ii) a comparison of feature-engineered and deep\nlearning-based classifiers trained on imbalanced, under-sampled, and\nover-sampled data, and (iii) an error analysis that could inform classification\nimprovements using our publicly available corpus. Future work will focus on\nautomating user-level analyses for cohort inclusion.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 19:00:46 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Klein", "Ari Z.", ""], ["Sarker", "Abeed", ""], ["Weissenbacher", "Davy", ""], ["Gonzalez-Hernandez", "Graciela", ""]]}, {"id": "1810.09536", "submitter": "Yikang Shen", "authors": "Yikang Shen, Shawn Tan, Alessandro Sordoni and Aaron Courville", "title": "Ordered Neurons: Integrating Tree Structures into Recurrent Neural\n  Networks", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language is hierarchically structured: smaller units (e.g., phrases)\nare nested within larger units (e.g., clauses). When a larger constituent ends,\nall of the smaller constituents that are nested within it must also be closed.\nWhile the standard LSTM architecture allows different neurons to track\ninformation at different time scales, it does not have an explicit bias towards\nmodeling a hierarchy of constituents. This paper proposes to add such an\ninductive bias by ordering the neurons; a vector of master input and forget\ngates ensures that when a given neuron is updated, all the neurons that follow\nit in the ordering are also updated. Our novel recurrent architecture, ordered\nneurons LSTM (ON-LSTM), achieves good performance on four different tasks:\nlanguage modeling, unsupervised parsing, targeted syntactic evaluation, and\nlogical inference.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 20:37:46 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 18:11:47 GMT"}, {"version": "v3", "created": "Mon, 26 Nov 2018 20:38:05 GMT"}, {"version": "v4", "created": "Wed, 24 Apr 2019 15:38:54 GMT"}, {"version": "v5", "created": "Tue, 30 Apr 2019 14:57:34 GMT"}, {"version": "v6", "created": "Wed, 8 May 2019 15:06:14 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Shen", "Yikang", ""], ["Tan", "Shawn", ""], ["Sordoni", "Alessandro", ""], ["Courville", "Aaron", ""]]}, {"id": "1810.09580", "submitter": "Alvaro Henrique Chaim Correia", "authors": "Alvaro Henrique Chaim Correia, Jorge Luiz Moreira Silva, Thiago de\n  Castro Martins, Fabio Gagliardi Cozman", "title": "A Fully Attention-Based Information Retriever", "comments": "Accepted for presentation at the International Joint Conference on\n  Neural Networks (IJCNN) 2018", "journal-ref": "A. H. C. Correia, J. L. M. Silva, T. d. C. Martins and F. G.\n  Cozman, \"A Fully Attention-Based Information Retriever,\" 2018 International\n  Joint Conference on Neural Networks (IJCNN), Rio de Janeiro, Brazil, 2018,\n  pp. 2799-2806", "doi": "10.1109/IJCNN.2018.8489656", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks are now the state-of-the-art in natural language\nprocessing because they can build rich contextual representations and process\ntexts of arbitrary length. However, recent developments on attention mechanisms\nhave equipped feedforward networks with similar capabilities, hence enabling\nfaster computations due to the increase in the number of operations that can be\nparallelized. We explore this new type of architecture in the domain of\nquestion-answering and propose a novel approach that we call Fully Attention\nBased Information Retriever (FABIR). We show that FABIR achieves competitive\nresults in the Stanford Question Answering Dataset (SQuAD) while having fewer\nparameters and being faster at both learning and inference than rival methods.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 22:10:46 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Correia", "Alvaro Henrique Chaim", ""], ["Silva", "Jorge Luiz Moreira", ""], ["Martins", "Thiago de Castro", ""], ["Cozman", "Fabio Gagliardi", ""]]}, {"id": "1810.09587", "submitter": "Liliang Ren", "authors": "Liliang Ren, Kaige Xie, Lu Chen and Kai Yu", "title": "Towards Universal Dialogue State Tracking", "comments": "EMNLP 2018 Oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue state tracking is the core part of a spoken dialogue system. It\nestimates the beliefs of possible user's goals at every dialogue turn. However,\nfor most current approaches, it's difficult to scale to large dialogue domains.\nThey have one or more of following limitations: (a) Some models don't work in\nthe situation where slot values in ontology changes dynamically; (b) The number\nof model parameters is proportional to the number of slots; (c) Some models\nextract features based on hand-crafted lexicons. To tackle these challenges, we\npropose StateNet, a universal dialogue state tracker. It is independent of the\nnumber of values, shares parameters across all slots, and uses pre-trained word\nvectors instead of explicit semantic dictionaries. Our experiments on two\ndatasets show that our approach not only overcomes the limitations, but also\nsignificantly outperforms the performance of state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 22:47:48 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Ren", "Liliang", ""], ["Xie", "Kaige", ""], ["Chen", "Lu", ""], ["Yu", "Kai", ""]]}, {"id": "1810.09593", "submitter": "Edward Choi", "authors": "Edward Choi, Cao Xiao, Walter F. Stewart, Jimeng Sun", "title": "MiME: Multilevel Medical Embedding of Electronic Health Records for\n  Predictive Healthcare", "comments": "Accepted at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models exhibit state-of-the-art performance for many predictive\nhealthcare tasks using electronic health records (EHR) data, but these models\ntypically require training data volume that exceeds the capacity of most\nhealthcare systems. External resources such as medical ontologies are used to\nbridge the data volume constraint, but this approach is often not directly\napplicable or useful because of inconsistencies with terminology. To solve the\ndata insufficiency challenge, we leverage the inherent multilevel structure of\nEHR data and, in particular, the encoded relationships among medical codes. We\npropose Multilevel Medical Embedding (MiME) which learns the multilevel\nembedding of EHR data while jointly performing auxiliary prediction tasks that\nrely on this inherent EHR structure without the need for external labels. We\nconducted two prediction tasks, heart failure prediction and sequential disease\nprediction, where MiME outperformed baseline methods in diverse evaluation\nsettings. In particular, MiME consistently outperformed all baselines when\npredicting heart failure on datasets of different volumes, especially\ndemonstrating the greatest performance improvement (15% relative gain in PR-AUC\nover the best baseline) on the smallest dataset, demonstrating its ability to\neffectively model the multilevel structure of EHR data.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 23:19:43 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Choi", "Edward", ""], ["Xiao", "Cao", ""], ["Stewart", "Walter F.", ""], ["Sun", "Jimeng", ""]]}, {"id": "1810.09597", "submitter": "Setu Shah", "authors": "Setu Shah and Xiao Luo", "title": "Biomedical Document Clustering and Visualization based on the Concepts\n  of Diseases", "comments": "KDD 2017's Data Driven Discovery Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document clustering is a text mining technique used to provide better\ndocument search and browsing in digital libraries or online corpora. A lot of\nresearch has been done on biomedical document clustering that is based on using\nexisting ontology. But, associations and co-occurrences of the medical concepts\nare not well represented by using ontology. In this research, a vector\nrepresentation of concepts of diseases and similarity measurement between\nconcepts are proposed. They identify the closest concepts of diseases in the\ncontext of a corpus. Each document is represented by using the vector space\nmodel. A weight scheme is proposed to consider both local content and\nassociations between concepts. A Self-Organizing Map is used as document\nclustering algorithm. The vector projection and visualization features of SOM\nenable visualization and analysis of the clusters distributions and\nrelationships on the two dimensional space. The experimental results show that\nthe proposed document clustering framework generates meaningful clusters and\nfacilitate visualization of the clusters based on the concepts of diseases.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 23:37:31 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Shah", "Setu", ""], ["Luo", "Xiao", ""]]}, {"id": "1810.09609", "submitter": "Linfeng Song", "authors": "Linfeng Song, Yue Zhang and Daniel Gildea", "title": "Neural Transition-based Syntactic Linearization", "comments": "INLG 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of linearization is to find a grammatical order given a set of\nwords. Traditional models use statistical methods. Syntactic linearization\nsystems, which generate a sentence along with its syntactic tree, have shown\nstate-of-the-art performance. Recent work shows that a multi-layer LSTM\nlanguage model outperforms competitive statistical syntactic linearization\nsystems without using syntax. In this paper, we study neural syntactic\nlinearization, building a transition-based syntactic linearizer leveraging a\nfeed-forward neural network, observing significantly better results compared to\nLSTM language models on this task.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 00:47:24 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Song", "Linfeng", ""], ["Zhang", "Yue", ""], ["Gildea", "Daniel", ""]]}, {"id": "1810.09630", "submitter": "Bo Dai", "authors": "Bo Dai, Sanja Fidler, Dahua Lin", "title": "A Neural Compositional Paradigm for Image Captioning", "comments": "32nd Conference on Neural Information Processing Systems (NIPS 2018),\n  Montr\\'eal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mainstream captioning models often follow a sequential structure to generate\ncaptions, leading to issues such as introduction of irrelevant semantics, lack\nof diversity in the generated captions, and inadequate generalization\nperformance. In this paper, we present an alternative paradigm for image\ncaptioning, which factorizes the captioning procedure into two stages: (1)\nextracting an explicit semantic representation from the given image; and (2)\nconstructing the caption based on a recursive compositional procedure in a\nbottom-up manner. Compared to conventional ones, our paradigm better preserves\nthe semantic content through an explicit factorization of semantics and syntax.\nBy using the compositional generation procedure, caption construction follows a\nrecursive structure, which naturally fits the properties of human language.\nMoreover, the proposed compositional procedure requires less data to train,\ngeneralizes better, and yields more diverse captions.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 02:16:12 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Dai", "Bo", ""], ["Fidler", "Sanja", ""], ["Lin", "Dahua", ""]]}, {"id": "1810.09699", "submitter": "Emre Yilmaz", "authors": "Emre Y{\\i}lmaz, Mitchell McLaren, Henk van den Heuvel, David A. van\n  Leeuwen", "title": "Semi-supervised acoustic model training for speech with code-switching", "comments": "To appear in Speech Communication -\n  https://doi.org/10.1016/j.specom.2018.10.006", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the FAME! project, we aim to develop an automatic speech recognition (ASR)\nsystem for Frisian-Dutch code-switching (CS) speech extracted from the archives\nof a local broadcaster with the ultimate goal of building a spoken document\nretrieval system. Unlike Dutch, Frisian is a low-resourced language with a very\nlimited amount of manually annotated speech data. In this paper, we describe\nseveral automatic annotation approaches to enable using of a large amount of\nraw bilingual broadcast data for acoustic model training in a semi-supervised\nsetting. Previously, it has been shown that the best-performing ASR system is\nobtained by two-stage multilingual deep neural network (DNN) training using 11\nhours of manually annotated CS speech (reference) data together with speech\ndata from other high-resourced languages. We compare the quality of\ntranscriptions provided by this bilingual ASR system with several other\napproaches that use a language recognition system for assigning language labels\nto raw speech segments at the front-end and using monolingual ASR resources for\ntranscription. We further investigate automatic annotation of the speakers\nappearing in the raw broadcast data by first labeling with (pseudo) speaker\ntags using a speaker diarization system and then linking to the known speakers\nappearing in the reference data using a speaker recognition system. These\nspeaker labels are essential for speaker-adaptive training in the proposed\nsetting. We train acoustic models using the manually and automatically\nannotated data and run recognition experiments on the development and test data\nof the FAME! speech corpus to quantify the quality of the automatic\nannotations. The ASR and CS detection results demonstrate the potential of\nusing automatic language and speaker tagging in semi-supervised bilingual\nacoustic model training.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 07:33:06 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Y\u0131lmaz", "Emre", ""], ["McLaren", "Mitchell", ""], ["Heuvel", "Henk van den", ""], ["van Leeuwen", "David A.", ""]]}, {"id": "1810.09774", "submitter": "Aarne Talman", "authors": "Aarne Talman, Stergios Chatzikyriakidis", "title": "Testing the Generalization Power of Neural Network Models Across NLI\n  Benchmarks", "comments": "Accepted to the 2019 ACL Workshop BackboxNLP: Analyzing and\n  interpreting neural networks for NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network models have been very successful in natural language\ninference, with the best models reaching 90% accuracy in some benchmarks.\nHowever, the success of these models turns out to be largely benchmark\nspecific. We show that models trained on a natural language inference dataset\ndrawn from one benchmark fail to perform well in others, even if the notion of\ninference assumed in these benchmarks is the same or similar. We train six high\nperforming neural network models on different datasets and show that each one\nof these has problems of generalizing when we replace the original test set\nwith a test set taken from another corpus designed for the same task. In light\nof these results, we argue that most of the current neural network models are\nnot able to generalize well in the task of natural language inference. We find\nthat using large pre-trained language models helps with transfer learning when\nthe datasets are similar enough. Our results also highlight that the current\nNLI datasets do not cover the different nuances of inference extensively\nenough.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 11:06:55 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 13:51:14 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 18:08:32 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Talman", "Aarne", ""], ["Chatzikyriakidis", "Stergios", ""]]}, {"id": "1810.09807", "submitter": "Hong Chen", "authors": "Hong Chen, Zhenhua Fan, Hao Lu, Alan L. Yuille and Shu Rong", "title": "PreCo: A Large-scale Dataset in Preschool Vocabulary for Coreference\n  Resolution", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce PreCo, a large-scale English dataset for coreference resolution.\nThe dataset is designed to embody the core challenges in coreference, such as\nentity representation, by alleviating the challenge of low overlap between\ntraining and test sets and enabling separated analysis of mention detection and\nmention clustering. To strengthen the training-test overlap, we collect a large\ncorpus of about 38K documents and 12.4M words which are mostly from the\nvocabulary of English-speaking preschoolers. Experiments show that with higher\ntraining-test overlap, error analysis on PreCo is more efficient than the one\non OntoNotes, a popular existing dataset. Furthermore, we annotate singleton\nmentions making it possible for the first time to quantify the influence that a\nmention detector makes on coreference resolution performance. The dataset is\nfreely available at https://preschool-lab.github.io/PreCo/.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 12:09:37 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Chen", "Hong", ""], ["Fan", "Zhenhua", ""], ["Lu", "Hao", ""], ["Yuille", "Alan L.", ""], ["Rong", "Shu", ""]]}, {"id": "1810.09947", "submitter": "Agata Savary", "authors": "Agata Savary (1), Simon Petitjean (2), Timm Lichte (3), Laura\n  Kallmeyer (2), Jakub Waszczuk (2) ((1) University of Tours, France (2)\n  Heinrich-Heine-Universit\\\"at D\\\"usseldorf, Germany, (3) University of\n  T\\\"ubingen, Germany)", "title": "Object-oriented lexical encoding of multiword expressions: Short and\n  sweet", "comments": "13 pages, 5 figures, 5 code listings, 1 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multiword expressions (MWEs) exhibit both regular and idiosyncratic\nproperties. Their idiosyncrasy requires lexical encoding in parallel with their\ncomponent words. Their (at times intricate) regularity, on the other hand,\ncalls for means of flexible factorization to avoid redundant descriptions of\nshared properties. However, so far, non-redundant general-purpose lexical\nencoding of MWEs has not received a satisfactory solution. We offer a proof of\nconcept that this challenge might be effectively addressed within eXtensible\nMetaGrammar (XMG), an object-oriented metagrammar framework. We first make an\nexisting metagrammatical resource, the FrenchTAG grammar, MWE-aware. We then\nevaluate the factorization gain during incremental implementation with XMG on a\ndataset extracted from an MWE-annotated reference corpus.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 16:27:07 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Savary", "Agata", ""], ["Petitjean", "Simon", ""], ["Lichte", "Timm", ""], ["Kallmeyer", "Laura", ""], ["Waszczuk", "Jakub", ""]]}, {"id": "1810.09988", "submitter": "Pengfei Liu", "authors": "Pengfei Liu, Xuanjing Huang", "title": "Meta-Learning Multi-task Communication", "comments": "A related blog can be found on the author's homepage", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe a general framework: Parameters Read-Write\nNetworks (PRaWNs) to systematically analyze current neural models for\nmulti-task learning, in which we find that existing models expect to\ndisentangle features into different spaces while features learned in practice\nare still entangled in shared space, leaving potential hazards for other\ntraining or unseen tasks.\n  We propose to alleviate this problem by incorporating an inductive bias into\nthe process of multi-task learning, that each task can keep informed of not\nonly the knowledge stored in other tasks but the way how other tasks maintain\ntheir knowledge.\n  In practice, we achieve above inductive bias by allowing different tasks to\ncommunicate by passing both hidden variables and gradients explicitly.\n  Experimentally, we evaluate proposed methods on three groups of tasks and two\ntypes of settings (\\textsc{in-task} and \\textsc{out-of-task}). Quantitative and\nqualitative results show their effectiveness.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 17:42:17 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Liu", "Pengfei", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1810.09995", "submitter": "Laura Perez-Beltrachini", "authors": "Diego Marcheggiani and Laura Perez-Beltrachini", "title": "Deep Graph Convolutional Encoders for Structured Data to Text Generation", "comments": "INLG 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most previous work on neural text generation from graph-structured data\nrelies on standard sequence-to-sequence methods. These approaches linearise the\ninput graph to be fed to a recurrent neural network. In this paper, we propose\nan alternative encoder based on graph convolutional networks that directly\nexploits the input structure. We report results on two graph-to-sequence\ndatasets that empirically show the benefits of explicitly encoding the input\ngraph structure.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 17:56:23 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Marcheggiani", "Diego", ""], ["Perez-Beltrachini", "Laura", ""]]}, {"id": "1810.10045", "submitter": "Mostofa Patwary", "authors": "Mostofa Patwary, Milind Chabbi, Heewoo Jun, Jiaji Huang, Gregory\n  Diamos, and Kenneth Church", "title": "Language Modeling at Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how Zipf's Law can be used to scale up language modeling (LM) to take\nadvantage of more training data and more GPUs. LM plays a key role in many\nimportant natural language applications such as speech recognition and machine\ntranslation. Scaling up LM is important since it is widely accepted by the\ncommunity that there is no data like more data. Eventually, we would like to\ntrain on terabytes (TBs) of text (trillions of words). Modern training methods\nare far from this goal, because of various bottlenecks, especially memory\n(within GPUs) and communication (across GPUs). This paper shows how Zipf's Law\ncan address these bottlenecks by grouping parameters for common words and\ncharacter sequences, because $U \\ll N$, where $U$ is the number of unique words\n(types) and $N$ is the size of the training set (tokens). For a local batch\nsize $K$ with $G$ GPUs and a $D$-dimension embedding matrix, we reduce the\noriginal per-GPU memory and communication asymptotic complexity from\n$\\Theta(GKD)$ to $\\Theta(GK + UD)$. Empirically, we find $U \\propto\n(GK)^{0.64}$ on four publicly available large datasets. When we scale up the\nnumber of GPUs to 64, a factor of 8, training time speeds up by factors up to\n6.7$\\times$ (for character LMs) and 6.3$\\times$ (for word LMs) with negligible\nloss of accuracy. Our weak scaling on 192 GPUs on the Tieba dataset shows a\n35\\% improvement in LM prediction accuracy by training on 93 GB of data\n(2.5$\\times$ larger than publicly available SOTA dataset), but taking only\n1.25$\\times$ increase in training time, compared to 3 GB of the same dataset\nrunning on 6 GPUs.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 18:44:55 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Patwary", "Mostofa", ""], ["Chabbi", "Milind", ""], ["Jun", "Heewoo", ""], ["Huang", "Jiaji", ""], ["Diamos", "Gregory", ""], ["Church", "Kenneth", ""]]}, {"id": "1810.10126", "submitter": "Yang Li", "authors": "Yang Li, Lukasz Kaiser, Samy Bengio, Si Si", "title": "Area Attention", "comments": "@InProceedings{pmlr-v97-li19e, title = {Area Attention}, author =\n  {Li, Yang and Kaiser, Lukasz and Bengio, Samy and Si, Si}, booktitle =\n  {Proceedings of the 36th International Conference on Machine Learning}, pages\n  = {3846--3855}, year = {2019}, volume = {97}, series = {Proceedings of\n  Machine Learning Research}, publisher = {PMLR} }", "journal-ref": "ICML 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing attention mechanisms are trained to attend to individual items in a\ncollection (the memory) with a predefined, fixed granularity, e.g., a word\ntoken or an image grid. We propose area attention: a way to attend to areas in\nthe memory, where each area contains a group of items that are structurally\nadjacent, e.g., spatially for a 2D memory such as images, or temporally for a\n1D memory such as natural language sentences. Importantly, the shape and the\nsize of an area are dynamically determined via learning, which enables a model\nto attend to information with varying granularity. Area attention can easily\nwork with existing model architectures such as multi-head attention for\nsimultaneously attending to multiple areas in the memory. We evaluate area\nattention on two tasks: neural machine translation (both character and\ntoken-level) and image captioning, and improve upon strong (state-of-the-art)\nbaselines in all the cases. These improvements are obtainable with a basic form\nof area attention that is parameter free.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 23:14:27 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 22:01:08 GMT"}, {"version": "v3", "created": "Tue, 27 Nov 2018 01:31:26 GMT"}, {"version": "v4", "created": "Tue, 5 Feb 2019 19:58:57 GMT"}, {"version": "v5", "created": "Thu, 23 May 2019 23:34:46 GMT"}, {"version": "v6", "created": "Wed, 5 Jun 2019 22:07:12 GMT"}, {"version": "v7", "created": "Thu, 7 May 2020 21:55:04 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Li", "Yang", ""], ["Kaiser", "Lukasz", ""], ["Bengio", "Samy", ""], ["Si", "Si", ""]]}, {"id": "1810.10136", "submitter": "Tadas Temcinas", "authors": "Tadas Tem\\v{c}inas", "title": "Local Homology of Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topological data analysis (TDA) has been widely used to make progress on a\nnumber of problems. However, it seems that TDA application in natural language\nprocessing (NLP) is at its infancy. In this paper we try to bridge the gap by\narguing why TDA tools are a natural choice when it comes to analysing word\nembedding data. We describe a parallelisable unsupervised learning algorithm\nbased on local homology of datapoints and show some experimental results on\nword embedding data. We see that local homology of datapoints in word embedding\ndata contains some information that can potentially be used to solve the word\nsense disambiguation problem.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 00:24:03 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Tem\u010dinas", "Tadas", ""]]}, {"id": "1810.10147", "submitter": "Hao Zhu", "authors": "Xu Han, Hao Zhu, Pengfei Yu, Ziyun Wang, Yuan Yao, Zhiyuan Liu,\n  Maosong Sun", "title": "FewRel: A Large-Scale Supervised Few-Shot Relation Classification\n  Dataset with State-of-the-Art Evaluation", "comments": "EMNLP 2018. The first four authors contribute equally. The order is\n  determined by dice rolling. Visit our website http://zhuhao.me/fewrel", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a Few-Shot Relation Classification Dataset (FewRel), consisting of\n70, 000 sentences on 100 relations derived from Wikipedia and annotated by\ncrowdworkers. The relation of each sentence is first recognized by distant\nsupervision methods, and then filtered by crowdworkers. We adapt the most\nrecent state-of-the-art few-shot learning methods for relation classification\nand conduct a thorough evaluation of these methods. Empirical results show that\neven the most competitive few-shot learning models struggle on this task,\nespecially as compared with humans. We also show that a range of different\nreasoning skills are needed to solve our task. These results indicate that\nfew-shot relation classification remains an open problem and still requires\nfurther research. Our detailed analysis points multiple directions for future\nresearch. All details and resources about the dataset and baselines are\nreleased on http://zhuhao.me/fewrel.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 01:18:08 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 21:41:46 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Han", "Xu", ""], ["Zhu", "Hao", ""], ["Yu", "Pengfei", ""], ["Wang", "Ziyun", ""], ["Yao", "Yuan", ""], ["Liu", "Zhiyuan", ""], ["Sun", "Maosong", ""]]}, {"id": "1810.10165", "submitter": "Nevan Wichers", "authors": "Nevan Wichers, Dilek Hakkani-Tur, Jindong Chen", "title": "Resolving Referring Expressions in Images With Labeled Elements", "comments": "Accepted into IEEE SLT Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Images may have elements containing text and a bounding box associated with\nthem, for example, text identified via optical character recognition on a\ncomputer screen image, or a natural image with labeled objects. We present an\nend-to-end trainable architecture to incorporate the information from these\nelements and the image to segment/identify the part of the image a natural\nlanguage expression is referring to. We calculate an embedding for each element\nand then project it onto the corresponding location (i.e., the associated\nbounding box) of the image feature map. We show that this architecture gives an\nimprovement in resolving referring expressions, over only using the image, and\nother methods that incorporate the element information. We demonstrate\nexperimental results on the referring expression datasets based on COCO, and on\na webpage image referring expression dataset that we developed.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 03:22:08 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 22:17:21 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Wichers", "Nevan", ""], ["Hakkani-Tur", "Dilek", ""], ["Chen", "Jindong", ""]]}, {"id": "1810.10181", "submitter": "Zhaopeng Tu", "authors": "Zi-Yi Dou, Zhaopeng Tu, Xing Wang, Shuming Shi, Tong Zhang", "title": "Exploiting Deep Representations for Neural Machine Translation", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced neural machine translation (NMT) models generally implement encoder\nand decoder as multiple layers, which allows systems to model complex functions\nand capture complicated linguistic structures. However, only the top layers of\nencoder and decoder are leveraged in the subsequent process, which misses the\nopportunity to exploit the useful information embedded in other layers. In this\nwork, we propose to simultaneously expose all of these signals with layer\naggregation and multi-layer attention mechanisms. In addition, we introduce an\nauxiliary regularization term to encourage different layers to capture diverse\ninformation. Experimental results on widely-used WMT14 English-German and WMT17\nChinese-English translation data demonstrate the effectiveness and universality\nof the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 04:08:22 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Dou", "Zi-Yi", ""], ["Tu", "Zhaopeng", ""], ["Wang", "Xing", ""], ["Shi", "Shuming", ""], ["Zhang", "Tong", ""]]}, {"id": "1810.10182", "submitter": "Zhaopeng Tu", "authors": "Baosong Yang, Zhaopeng Tu, Derek F. Wong, Fandong Meng, Lidia S. Chao,\n  Tong Zhang", "title": "Modeling Localness for Self-Attention Networks", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-attention networks have proven to be of profound value for its strength\nof capturing global dependencies. In this work, we propose to model localness\nfor self-attention networks, which enhances the ability of capturing useful\nlocal context. We cast localness modeling as a learnable Gaussian bias, which\nindicates the central and scope of the local region to be paid more attention.\nThe bias is then incorporated into the original attention distribution to form\na revised distribution. To maintain the strength of capturing long distance\ndependencies and enhance the ability of capturing short-range dependencies, we\nonly apply localness modeling to lower layers of self-attention networks.\nQuantitative and qualitative analyses on Chinese-English and English-German\ntranslation tasks demonstrate the effectiveness and universality of the\nproposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 04:08:25 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Yang", "Baosong", ""], ["Tu", "Zhaopeng", ""], ["Wong", "Derek F.", ""], ["Meng", "Fandong", ""], ["Chao", "Lidia S.", ""], ["Zhang", "Tong", ""]]}, {"id": "1810.10183", "submitter": "Zhaopeng Tu", "authors": "Jian Li, Zhaopeng Tu, Baosong Yang, Michael R. Lyu, Tong Zhang", "title": "Multi-Head Attention with Disagreement Regularization", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-head attention is appealing for the ability to jointly attend to\ninformation from different representation subspaces at different positions. In\nthis work, we introduce a disagreement regularization to explicitly encourage\nthe diversity among multiple attention heads. Specifically, we propose three\ntypes of disagreement regularization, which respectively encourage the\nsubspace, the attended positions, and the output representation associated with\neach attention head to be different from other heads. Experimental results on\nwidely-used WMT14 English-German and WMT17 Chinese-English translation tasks\ndemonstrate the effectiveness and universality of the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 04:08:27 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Li", "Jian", ""], ["Tu", "Zhaopeng", ""], ["Yang", "Baosong", ""], ["Lyu", "Michael R.", ""], ["Zhang", "Tong", ""]]}, {"id": "1810.10222", "submitter": "Marcin Kardas", "authors": "Piotr Czapla, Jeremy Howard, Marcin Kardas", "title": "Universal Language Model Fine-Tuning with Subword Tokenization for\n  Polish", "comments": "PolEval 2018 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Universal Language Model for Fine-tuning [arXiv:1801.06146] (ULMFiT) is one\nof the first NLP methods for efficient inductive transfer learning.\nUnsupervised pretraining results in improvements on many NLP tasks for English.\nIn this paper, we describe a new method that uses subword tokenization to adapt\nULMFiT to languages with high inflection. Our approach results in a new\nstate-of-the-art for the Polish language, taking first place in Task 3 of\nPolEval'18. After further training, our final model outperformed the second\nbest model by 35%. We have open-sourced our pretrained models and code.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 07:34:45 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Czapla", "Piotr", ""], ["Howard", "Jeremy", ""], ["Kardas", "Marcin", ""]]}, {"id": "1810.10254", "submitter": "Genta Indra Winata", "authors": "Genta Indra Winata, Andrea Madotto, Chien-Sheng Wu, Pascale Fung", "title": "Learn to Code-Switch: Data Augmentation using Copy Mechanism on Language\n  Modeling", "comments": "Submitted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building large-scale datasets for training code-switching language models is\nchallenging and very expensive. To alleviate this problem using parallel corpus\nhas been a major workaround. However, existing solutions use linguistic\nconstraints which may not capture the real data distribution. In this work, we\npropose a novel method for learning how to generate code-switching sentences\nfrom parallel corpora. Our model uses a Seq2Seq model in combination with\npointer networks to align and choose words from the monolingual sentences and\nform a grammatical code-switching sentence. In our experiment, we show that by\ntraining a language model using the augmented sentences we improve the\nperplexity score by 10% compared to the LSTM baseline.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 09:02:17 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 10:29:45 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Winata", "Genta Indra", ""], ["Madotto", "Andrea", ""], ["Wu", "Chien-Sheng", ""], ["Fung", "Pascale", ""]]}, {"id": "1810.10297", "submitter": "Gijs Wijnholds", "authors": "Gijs Jasper Wijnholds", "title": "A Proof-Theoretic Approach to Scope Ambiguity in Compositional Vector\n  Space Models", "comments": "This is a preprint of a paper to appear in: Journal of Language\n  Modelling, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the extent to which compositional vector space models can be\nused to account for scope ambiguity in quantified sentences (of the form \"Every\nman loves some woman\"). Such sentences containing two quantifiers introduce two\nreadings, a direct scope reading and an inverse scope reading. This ambiguity\nhas been treated in a vector space model using bialgebras by (Hedges and\nSadrzadeh, 2016) and (Sadrzadeh, 2016), though without an explanation of the\nmechanism by which the ambiguity arises. We combine a polarised focussed\nsequent calculus for the non-associative Lambek calculus NL, as described in\n(Moortgat and Moot, 2011), with the vector based approach to quantifier scope\nambiguity. In particular, we establish a procedure for obtaining a vector space\nmodel for quantifier scope ambiguity in a derivational way.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 11:20:02 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 10:37:03 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Wijnholds", "Gijs Jasper", ""]]}, {"id": "1810.10317", "submitter": "Zaixiang Zheng", "authors": "Zaixiang Zheng, Shujian Huang, Zewei Sun, Rongxiang Weng, Xin-Yu Dai,\n  Jiajun Chen", "title": "Learning to Discriminate Noises for Incorporating External Information\n  in Neural Machine Translation", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous studies show that incorporating external information could improve\nthe translation quality of Neural Machine Translation (NMT) systems. However,\nthere are inevitably noises in the external information, severely reducing the\nbenefit that the existing methods could receive from the incorporation. To\ntackle the problem, this study pays special attention to the discrimination of\nthe noises during the incorporation. We argue that there exist two kinds of\nnoise in this external information, i.e. global noise and local noise, which\naffect the translations for the whole sentence and for some specific words,\nrespectively. Accordingly, we propose a general framework that learns to\njointly discriminate both the global and local noises, so that the external\ninformation could be better leveraged. Our model is trained on the dataset\nderived from the original parallel corpus without any external labeled data or\nannotation. Experimental results in various real-world scenarios, language\npairs, and neural architectures indicate that discriminating noises contributes\nto significant improvements in translation quality by being able to better\nincorporate the external information, even in very noisy conditions.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 12:16:55 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 05:43:38 GMT"}, {"version": "v3", "created": "Mon, 19 Nov 2018 08:11:14 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Zheng", "Zaixiang", ""], ["Huang", "Shujian", ""], ["Sun", "Zewei", ""], ["Weng", "Rongxiang", ""], ["Dai", "Xin-Yu", ""], ["Chen", "Jiajun", ""]]}, {"id": "1810.10320", "submitter": "Umut Sulubacak", "authors": "Umut Sulubacak, J\\\"org Tiedemann, Aku Rouhe, Stig-Arne Gr\\\"onroos,\n  Mikko Kurimo", "title": "The MeMAD Submission to the IWSLT 2018 Speech Translation Task", "comments": "Submitted to IWSLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the MeMAD project entry to the IWSLT Speech Translation\nShared Task, addressing the translation of English audio into German text.\nBetween the pipeline and end-to-end model tracks, we participated only in the\nformer, with three contrastive systems. We tried also the latter, but were not\nable to finish our end-to-end model in time.\n  All of our systems start by transcribing the audio into text through an\nautomatic speech recognition (ASR) model trained on the TED-LIUM English Speech\nRecognition Corpus (TED-LIUM). Afterwards, we feed the transcripts into\nEnglish-German text-based neural machine translation (NMT) models. Our systems\nemploy three different translation models trained on separate training sets\ncompiled from the English-German part of the TED Speech Translation Corpus\n(TED-Trans) and the OpenSubtitles2018 section of the OPUS collection.\n  In this paper, we also describe the experiments leading up to our final\nsystems. Our experiments indicate that using OpenSubtitles2018 in training\nsignificantly improves translation performance. We also experimented with\nvarious pre- and postprocessing routines for the NMT module, but we did not\nhave much success with these.\n  Our best-scoring system attains a BLEU score of 16.45 on the test set for\nthis year's task.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 12:18:44 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Sulubacak", "Umut", ""], ["Tiedemann", "J\u00f6rg", ""], ["Rouhe", "Aku", ""], ["Gr\u00f6nroos", "Stig-Arne", ""], ["Kurimo", "Mikko", ""]]}, {"id": "1810.10401", "submitter": "Anastasios Vafeiadis", "authors": "Erinc Merdivan, Anastasios Vafeiadis, Dimitrios Kalatzis, Sten Hanke,\n  Johannes Kropf, Konstantinos Votis, Dimitrios Giakoumis, Dimitrios Tzovaras,\n  Liming Chen, Raouf Hamzaoui, Matthieu Geist", "title": "Image-based Natural Language Understanding Using 2D Convolutional Neural\n  Networks", "comments": "Natural Language Processing (NLP), Sentiment Analysis, Dialogue\n  Modeling", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach to natural language understanding in which we\nconsider the input text as an image and apply 2D Convolutional Neural Networks\nto learn the local and global semantics of the sentences from the variations\nofthe visual patterns of words. Our approach demonstrates that it is possible\nto get semantically meaningful features from images with text without using\noptical character recognition and sequential processing pipelines, techniques\nthat traditional Natural Language Understanding algorithms require. To validate\nour approach, we present results for two applications: text classification and\ndialog modeling. Using a 2D Convolutional Neural Network, we were able to\noutperform the state-of-art accuracy results of non-Latin alphabet-based text\nclassification and achieved promising results for eight text classification\ndatasets. Furthermore, our approach outperformed the memory networks when using\nout of vocabulary entities fromtask 4 of the bAbI dialog dataset.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 13:46:58 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 10:46:24 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Merdivan", "Erinc", ""], ["Vafeiadis", "Anastasios", ""], ["Kalatzis", "Dimitrios", ""], ["Hanke", "Sten", ""], ["Kropf", "Johannes", ""], ["Votis", "Konstantinos", ""], ["Giakoumis", "Dimitrios", ""], ["Tzovaras", "Dimitrios", ""], ["Chen", "Liming", ""], ["Hamzaoui", "Raouf", ""], ["Geist", "Matthieu", ""]]}, {"id": "1810.10419", "submitter": "Archit Sakhadeo", "authors": "Archit Sakhadeo and Nisheeth Srivastava", "title": "Effective extractive summarization using frequency-filtered entity\n  relationship graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word frequency-based methods for extractive summarization are easy to\nimplement and yield reasonable results across languages. However, they have\nsignificant limitations - they ignore the role of context, they offer uneven\ncoverage of topics in a document, and sometimes are disjointed and hard to\nread. We use a simple premise from linguistic typology - that English sentences\nare complete descriptors of potential interactions between entities, usually in\nthe order subject-verb-object - to address a subset of these difficulties. We\nhave developed a hybrid model of extractive summarization that combines\nword-frequency based keyword identification with information from automatically\ngenerated entity relationship graphs to select sentences for summaries.\nComparative evaluation with word-frequency and topic word-based methods shows\nthat the proposed method is competitive by conventional ROUGE standards, and\nyields moderately more informative summaries on average, as assessed by a large\npanel (N=94) of human raters.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 14:30:39 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Sakhadeo", "Archit", ""], ["Srivastava", "Nisheeth", ""]]}, {"id": "1810.10437", "submitter": "Weidi Xu", "authors": "Xingyi Cheng, Weidi Xu, Taifeng Wang and Wei Chu", "title": "Variational Semi-supervised Aspect-term Sentiment Analysis via\n  Transformer", "comments": "Accepted by CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-term sentiment analysis (ATSA) is a longstanding challenge in natural\nlanguage understanding. It requires fine-grained semantical reasoning about a\ntarget entity appeared in the text. As manual annotation over the aspects is\nlaborious and time-consuming, the amount of labeled data is limited for\nsupervised learning. This paper proposes a semi-supervised method for the ATSA\nproblem by using the Variational Autoencoder based on Transformer (VAET), which\nmodels the latent distribution via variational inference. By disentangling the\nlatent representation into the aspect-specific sentiment and the lexical\ncontext, our method induces the underlying sentiment prediction for the\nunlabeled data, which then benefits the ATSA classifier. Our method is\nclassifier agnostic, i.e., the classifier is an independent module and various\nadvanced supervised models can be integrated. Experimental results are obtained\non the SemEval 2014 task 4 and show that our method is effective with four\nclassical classifiers. The proposed method outperforms two general\nsemisupervised methods and achieves state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 15:07:19 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 03:53:49 GMT"}, {"version": "v3", "created": "Thu, 5 Sep 2019 06:02:03 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Cheng", "Xingyi", ""], ["Xu", "Weidi", ""], ["Wang", "Taifeng", ""], ["Chu", "Wei", ""]]}, {"id": "1810.10499", "submitter": "Yadollah Yaghoobzadeh", "authors": "Yadollah Yaghoobzadeh and Hinrich Sch\\\"utze", "title": "Multi-Multi-View Learning: Multilingual and Multi-Representation Entity\n  Typing", "comments": "7 pages, Accepted at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge bases (KBs) are paramount in NLP. We employ multiview learning for\nincreasing accuracy and coverage of entity type information in KBs. We rely on\ntwo metaviews: language and representation. For language, we consider\nhigh-resource and low-resource languages from Wikipedia. For representation, we\nconsider representations based on the context distribution of the entity (i.e.,\non its embedding), on the entity's name (i.e., on its surface form) and on its\ndescription in Wikipedia. The two metaviews language and representation can be\nfreely combined: each pair of language and representation (e.g., German\nembedding, English description, Spanish name) is a distinct view. Our\nexperiments on entity typing with fine-grained classes demonstrate the\neffectiveness of multiview learning. We release MVET, a large multiview - and,\nin particular, multilingual - entity typing dataset we created. Mono- and\nmultilingual fine-grained entity typing systems can be evaluated on this\ndataset.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 17:08:36 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Yaghoobzadeh", "Yadollah", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1810.10566", "submitter": "Henghui Zhu", "authors": "Henghui Zhu, Ioannis Ch. Paschalidis, Amir Tahmasebi", "title": "Clinical Concept Extraction with Contextual Word Embedding", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic extraction of clinical concepts is an essential step for turning\nthe unstructured data within a clinical note into structured and actionable\ninformation. In this work, we propose a clinical concept extraction model for\nautomatic annotation of clinical problems, treatments, and tests in clinical\nnotes utilizing domain-specific contextual word embedding. A contextual word\nembedding model is first trained on a corpus with a mixture of clinical reports\nand relevant Wikipedia pages in the clinical domain. Next, a bidirectional\nLSTM-CRF model is trained for clinical concept extraction using the contextual\nword embedding model. We tested our proposed model on the I2B2 2010 challenge\ndataset. Our proposed model achieved the best performance among reported\nbaseline models and outperformed the state-of-the-art models by 3.4% in terms\nof F1-score.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 18:18:19 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 15:55:38 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Zhu", "Henghui", ""], ["Paschalidis", "Ioannis Ch.", ""], ["Tahmasebi", "Amir", ""]]}, {"id": "1810.10639", "submitter": "Elvys Linhares Pontes", "authors": "Elvys Linhares Pontes and St\\'ephane Huet and Juan-Manuel\n  Torres-Moreno", "title": "A Multilingual Study of Compressive Cross-Language Text Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-Language Text Summarization (CLTS) generates summaries in a language\ndifferent from the language of the source documents. Recent methods use\ninformation from both languages to generate summaries with the most informative\nsentences. However, these methods have performance that can vary according to\nlanguages, which can reduce the quality of summaries. In this paper, we propose\na compressive framework to generate cross-language summaries. In order to\nanalyze performance and especially stability, we tested our system and\nextractive baselines on a dataset available in four languages (English, French,\nPortuguese, and Spanish) to generate English and French summaries. An automatic\nevaluation showed that our method outperformed extractive state-of-art CLTS\nmethods with better and more stable ROUGE scores for all languages.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 21:58:48 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Pontes", "Elvys Linhares", ""], ["Huet", "St\u00e9phane", ""], ["Torres-Moreno", "Juan-Manuel", ""]]}, {"id": "1810.10641", "submitter": "Elvys Linhares Pontes", "authors": "Elvys Linhares Pontes and St\\'ephane Huet and Andr\\'ea Carneiro\n  Linhares and Juan-Manuel Torres-Moreno", "title": "Predicting the Semantic Textual Similarity with Siamese CNN and LSTM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic Textual Similarity (STS) is the basis of many applications in\nNatural Language Processing (NLP). Our system combines convolution and\nrecurrent neural networks to measure the semantic similarity of sentences. It\nuses a convolution network to take account of the local context of words and an\nLSTM to consider the global context of sentences. This combination of networks\nhelps to preserve the relevant information of sentences and improves the\ncalculation of the similarity between sentences. Our model has achieved good\nresults and is competitive with the best state-of-the-art systems.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 22:08:26 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Pontes", "Elvys Linhares", ""], ["Huet", "St\u00e9phane", ""], ["Linhares", "Andr\u00e9a Carneiro", ""], ["Torres-Moreno", "Juan-Manuel", ""]]}, {"id": "1810.10647", "submitter": "Revanth Reddy Gangi Reddy", "authors": "Revanth Reddy, Danish Contractor, Dinesh Raghu, Sachindra Joshi", "title": "Multi-level Memory for Task Oriented Dialogs", "comments": "Accepted as full paper at NAACL 2019", "journal-ref": null, "doi": "10.18653/v1/N19-1375", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent end-to-end task oriented dialog systems use memory architectures to\nincorporate external knowledge in their dialogs. Current work makes simplifying\nassumptions about the structure of the knowledge base, such as the use of\ntriples to represent knowledge, and combines dialog utterances (context) as\nwell as knowledge base (KB) results as part of the same memory. This causes an\nexplosion in the memory size, and makes the reasoning over memory harder. In\naddition, such a memory design forces hierarchical properties of the data to be\nfit into a triple structure of memory. This requires the memory reader to infer\nrelationships across otherwise connected attributes. In this paper we relax the\nstrong assumptions made by existing architectures and separate memories used\nfor modeling dialog context and KB results. Instead of using triples to store\nKB results, we introduce a novel multi-level memory architecture consisting of\ncells for each query and their corresponding results. The multi-level memory\nfirst addresses queries, followed by results and finally each key-value pair\nwithin a result. We conduct detailed experiments on three publicly available\ntask oriented dialog data sets and we find that our method conclusively\noutperforms current state-of-the-art models. We report a 15-25% increase in\nboth entity F1 and BLEU scores.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 22:49:32 GMT"}, {"version": "v2", "created": "Sun, 12 May 2019 02:05:05 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Reddy", "Revanth", ""], ["Contractor", "Danish", ""], ["Raghu", "Dinesh", ""], ["Joshi", "Sachindra", ""]]}, {"id": "1810.10665", "submitter": "Jason  Weston", "authors": "Kurt Shuster, Samuel Humeau, Hexiang Hu, Antoine Bordes, Jason Weston", "title": "Engaging Image Captioning Via Personality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard image captioning tasks such as COCO and Flickr30k are factual,\nneutral in tone and (to a human) state the obvious (e.g., \"a man playing a\nguitar\"). While such tasks are useful to verify that a machine understands the\ncontent of an image, they are not engaging to humans as captions. With this in\nmind we define a new task, Personality-Captions, where the goal is to be as\nengaging to humans as possible by incorporating controllable style and\npersonality traits. We collect and release a large dataset of 201,858 of such\ncaptions conditioned over 215 possible traits. We build models that combine\nexisting work from (i) sentence representations (Mazare et al., 2018) with\nTransformers trained on 1.7 billion dialogue examples; and (ii) image\nrepresentations (Mahajan et al., 2018) with ResNets trained on 3.5 billion\nsocial media images. We obtain state-of-the-art performance on Flickr30k and\nCOCO, and strong performance on our new task. Finally, online evaluations\nvalidate that our task and models are engaging to humans, with our best model\nclose to human performance.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 00:46:16 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 16:53:33 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Shuster", "Kurt", ""], ["Humeau", "Samuel", ""], ["Hu", "Hexiang", ""], ["Bordes", "Antoine", ""], ["Weston", "Jason", ""]]}, {"id": "1810.10752", "submitter": "Yilin Niu", "authors": "Yilin Niu, Chao Qiao, Hang Li and Minlie Huang", "title": "Word Embedding based Edit Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text similarity calculation is a fundamental problem in natural language\nprocessing and related fields. In recent years, deep neural networks have been\ndeveloped to perform the task and high performances have been achieved. The\nneural networks are usually trained with labeled data in supervised learning,\nand creation of labeled data is usually very costly. In this short paper, we\naddress unsupervised learning for text similarity calculation. We propose a new\nmethod called Word Embedding based Edit Distance (WED), which incorporates word\nembedding into edit distance. Experiments on three benchmark datasets show WED\noutperforms state-of-the-art unsupervised methods including edit distance,\nTF-IDF based cosine, word embedding based cosine, Jaccard index, etc.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 07:50:17 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Niu", "Yilin", ""], ["Qiao", "Chao", ""], ["Li", "Hang", ""], ["Huang", "Minlie", ""]]}, {"id": "1810.10797", "submitter": "Ingrid Falk", "authors": "Ingrid Falk and Delphine Bernhard and Christophe G\\'erard", "title": "The Logoscope: a Semi-Automatic Tool for Detecting and Documenting\n  French New Words", "comments": "Project report, 28 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we present the design and implementation of the Logoscope,\nthe first tool especially developed to detect new words of the French language,\nto document them and allow a public access through a web interface.\n  This semi-automatic tool collects new words daily by browsing the online\nversions of French well known newspapers such as Le Monde, Le Figaro, L'Equipe,\nLib\\'eration, La Croix, Les \\'Echos. In contrast to other existing tools\nessentially dedicated to dictionary development, the Logoscope attempts to give\na more complete account of the context in which the new words occur. In\naddition to the commonly given morpho-syntactic information it also provides\ninformation about the textual and discursive contexts of the word creation; in\nparticular, it automatically determines the (journalistic) topics of the text\ncontaining the new word.\n  In this article we first give a general overview of the developed tool. We\nthen describe the approach taken, we discuss the linguistic background which\nguided our design decisions and present the computational methods we used to\nimplement it.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 09:16:52 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Falk", "Ingrid", ""], ["Bernhard", "Delphine", ""], ["G\u00e9rard", "Christophe", ""]]}, {"id": "1810.10802", "submitter": "Lei Yu", "authors": "Lei Yu", "title": "Tackling Sequence to Sequence Mapping Problems with Neural Networks", "comments": "PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Natural Language Processing (NLP), it is important to detect the\nrelationship between two sequences or to generate a sequence of tokens given\nanother observed sequence. We call the type of problems on modelling sequence\npairs as sequence to sequence (seq2seq) mapping problems. A lot of research has\nbeen devoted to finding ways of tackling these problems, with traditional\napproaches relying on a combination of hand-crafted features, alignment models,\nsegmentation heuristics, and external linguistic resources. Although great\nprogress has been made, these traditional approaches suffer from various\ndrawbacks, such as complicated pipeline, laborious feature engineering, and the\ndifficulty for domain adaptation. Recently, neural networks emerged as a\npromising solution to many problems in NLP, speech recognition, and computer\nvision. Neural models are powerful because they can be trained end to end,\ngeneralise well to unseen examples, and the same framework can be easily\nadapted to a new domain.\n  The aim of this thesis is to advance the state-of-the-art in seq2seq mapping\nproblems with neural networks. We explore solutions from three major aspects:\ninvestigating neural models for representing sequences, modelling interactions\nbetween sequences, and using unpaired data to boost the performance of neural\nmodels. For each aspect, we propose novel models and evaluate their efficacy on\nvarious tasks of seq2seq mapping.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 09:24:13 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Yu", "Lei", ""]]}, {"id": "1810.10882", "submitter": "Daniel Fern\\'andez-Gonz\\'alez", "authors": "Daniel Fern\\'andez-Gonz\\'alez and Carlos G\\'omez-Rodr\\'iguez", "title": "Dynamic Oracles for Top-Down and In-Order Shift-Reduce Constituent\n  Parsing", "comments": "Proceedings of EMNLP 2018. 11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce novel dynamic oracles for training two of the most accurate\nknown shift-reduce algorithms for constituent parsing: the top-down and\nin-order transition-based parsers. In both cases, the dynamic oracles manage to\nnotably increase their accuracy, in comparison to that obtained by performing\nclassic static training. In addition, by improving the performance of the\nstate-of-the-art in-order shift-reduce parser, we achieve the best accuracy to\ndate (92.0 F1) obtained by a fully-supervised single-model greedy shift-reduce\nconstituent parser on the WSJ benchmark.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 13:58:20 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Fern\u00e1ndez-Gonz\u00e1lez", "Daniel", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "1810.10927", "submitter": "Ekaterina Lobacheva Ms", "authors": "Nadezhda Chirkova, Ekaterina Lobacheva, Dmitry Vetrov", "title": "Bayesian Compression for Natural Language Processing", "comments": "Published in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In natural language processing, a lot of the tasks are successfully solved\nwith recurrent neural networks, but such models have a huge number of\nparameters. The majority of these parameters are often concentrated in the\nembedding layer, which size grows proportionally to the vocabulary length. We\npropose a Bayesian sparsification technique for RNNs which allows compressing\nthe RNN dozens or hundreds of times without time-consuming hyperparameters\ntuning. We also generalize the model for vocabulary sparsification to filter\nout unnecessary words and compress the RNN even further. We show that the\nchoice of the kept words is interpretable. Code is available on github:\nhttps://github.com/tipt0p/SparseBayesianRNN\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 15:27:23 GMT"}, {"version": "v2", "created": "Wed, 12 Dec 2018 17:18:13 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Chirkova", "Nadezhda", ""], ["Lobacheva", "Ekaterina", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1810.10942", "submitter": "Nicolas Pr\\\"ollochs", "authors": "Bernhard Lutz, Nicolas Pr\\\"ollochs, Dirk Neumann", "title": "Understanding the Role of Two-Sided Argumentation in Online Consumer\n  Reviews: A Language-Based Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper examines the effect of two-sided argumentation on the perceived\nhelpfulness of online consumer reviews. In contrast to previous works, our\nanalysis thereby sheds light on the reception of reviews from a language-based\nperspective. For this purpose, we propose an intriguing text analysis approach\nbased on distributed text representations and multi-instance learning to\noperationalize the two-sidedness of argumentation in review texts. A subsequent\nempirical analysis using a large corpus of Amazon reviews suggests that\ntwo-sided argumentation in reviews significantly increases their helpfulness.\nWe find this effect to be stronger for positive reviews than for negative\nreviews, whereas a higher degree of emotional language weakens the effect. Our\nfindings have immediate implications for retailer platforms, which can utilize\nour results to optimize their customer feedback system and to present more\nuseful product reviews.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 15:57:45 GMT"}, {"version": "v2", "created": "Mon, 24 Dec 2018 23:21:24 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Lutz", "Bernhard", ""], ["Pr\u00f6llochs", "Nicolas", ""], ["Neumann", "Dirk", ""]]}, {"id": "1810.10949", "submitter": "Sven Buechel", "authors": "Sven Buechel, Jo\\~ao Sedoc, H. Andrew Schwartz, and Lyle Ungar", "title": "Learning Emotion from 100 Observations: Unexpected Robustness of Deep\n  Learning under Strong Data Limitations", "comments": "Published at PEOPLES 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major downsides of Deep Learning is its supposed need for vast\namounts of training data. As such, these techniques appear ill-suited for NLP\nareas where annotated data is limited, such as less-resourced languages or\nemotion analysis, with its many nuanced and hard-to-acquire annotation formats.\nWe conduct a questionnaire study indicating that indeed the vast majority of\nresearchers in emotion analysis deems neural models inferior to traditional\nmachine learning when training data is limited. In stark contrast to those\nsurvey results, we provide empirical evidence for English, Polish, and\nPortuguese that commonly used neural architectures can be trained on\nsurprisingly few observations, outperforming $n$-gram based ridge regression on\nonly 100 data points. Our analysis suggests that high-quality, pre-trained word\nembeddings are a main factor for achieving those results.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 16:08:18 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 12:38:17 GMT"}, {"version": "v3", "created": "Mon, 7 Dec 2020 18:25:03 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Buechel", "Sven", ""], ["Sedoc", "Jo\u00e3o", ""], ["Schwartz", "H. Andrew", ""], ["Ungar", "Lyle", ""]]}, {"id": "1810.11067", "submitter": "Christopher Malon", "authors": "Juho Kim and Christopher Malon and Asim Kadav", "title": "Teaching Syntax by Adversarial Distraction", "comments": "To appear at the EMNLP 2018 First Workshop on Fact Extraction and\n  Verification (FEVER)", "journal-ref": "Juho Kim, Christopher Malon, and Asim Kadav. 2018. \"Teaching\n  Syntax by Adversarial Distraction.\" Proceedings of the EMNLP First Workshop\n  on Fact Extraction and Verification", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing entailment datasets mainly pose problems which can be answered\nwithout attention to grammar or word order. Learning syntax requires comparing\nexamples where different grammar and word order change the desired\nclassification. We introduce several datasets based on synthetic\ntransformations of natural entailment examples in SNLI or FEVER, to teach\naspects of grammar and word order. We show that without retraining, popular\nentailment models are unaware that these syntactic differences change meaning.\nWith retraining, some but not all popular entailment models can learn to\ncompare the syntax properly.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 18:54:49 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Kim", "Juho", ""], ["Malon", "Christopher", ""], ["Kadav", "Asim", ""]]}, {"id": "1810.11101", "submitter": "Sabrina Mielke", "authors": "Christo Kirov, Ryan Cotterell, John Sylak-Glassman, G\\'eraldine\n  Walther, Ekaterina Vylomova, Patrick Xia, Manaal Faruqui, Sabrina J. Mielke,\n  Arya D. McCarthy, Sandra K\\\"ubler, David Yarowsky, Jason Eisner, Mans Hulden", "title": "UniMorph 2.0: Universal Morphology", "comments": "LREC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Universal Morphology UniMorph project is a collaborative effort to\nimprove how NLP handles complex morphology across the world's languages. The\nproject releases annotated morphological data using a universal tagset, the\nUniMorph schema. Each inflected form is associated with a lemma, which\ntypically carries its underlying lexical meaning, and a bundle of morphological\nfeatures from our schema. Additional supporting data and tools are also\nreleased on a per-language basis when available. UniMorph is based at the\nCenter for Language and Speech Processing (CLSP) at Johns Hopkins University in\nBaltimore, Maryland and is sponsored by the DARPA LORELEI program. This paper\ndetails advances made to the collection, annotation, and dissemination of\nproject resources since the initial UniMorph release described at LREC 2016.\nlexical resources} }\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 20:42:40 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 18:35:19 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Kirov", "Christo", ""], ["Cotterell", "Ryan", ""], ["Sylak-Glassman", "John", ""], ["Walther", "G\u00e9raldine", ""], ["Vylomova", "Ekaterina", ""], ["Xia", "Patrick", ""], ["Faruqui", "Manaal", ""], ["Mielke", "Sabrina J.", ""], ["McCarthy", "Arya D.", ""], ["K\u00fcbler", "Sandra", ""], ["Yarowsky", "David", ""], ["Eisner", "Jason", ""], ["Hulden", "Mans", ""]]}, {"id": "1810.11118", "submitter": "Jonathan K Kummerfeld", "authors": "Jonathan K. Kummerfeld, Sai R. Gouravajhala, Joseph Peper, Vignesh\n  Athreya, Chulaka Gunasekara, Jatin Ganhotra, Siva Sankalp Patel, Lazaros\n  Polymenakos, Walter S. Lasecki", "title": "A Large-Scale Corpus for Conversation Disentanglement", "comments": "To appear at ACL", "journal-ref": "ACL (2019) 3846-3856", "doi": "10.18653/v1/P19-1374", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disentangling conversations mixed together in a single stream of messages is\na difficult task, made harder by the lack of large manually annotated datasets.\nWe created a new dataset of 77,563 messages manually annotated with\nreply-structure graphs that both disentangle conversations and define internal\nconversation structure. Our dataset is 16 times larger than all previously\nreleased datasets combined, the first to include adjudication of annotation\ndisagreements, and the first to include context. We use our data to re-examine\nprior work, in particular, finding that 80% of conversations in a widely used\ndialogue corpus are either missing messages or contain extra messages. Our\nmanually-annotated data presents an opportunity to develop robust data-driven\nmethods for conversation disentanglement, which will help advance dialogue\nresearch.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 21:44:14 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 18:14:53 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Kummerfeld", "Jonathan K.", ""], ["Gouravajhala", "Sai R.", ""], ["Peper", "Joseph", ""], ["Athreya", "Vignesh", ""], ["Gunasekara", "Chulaka", ""], ["Ganhotra", "Jatin", ""], ["Patel", "Siva Sankalp", ""], ["Polymenakos", "Lazaros", ""], ["Lasecki", "Walter S.", ""]]}, {"id": "1810.11181", "submitter": "Abhishek Das", "authors": "Abhishek Das, Georgia Gkioxari, Stefan Lee, Devi Parikh, Dhruv Batra", "title": "Neural Modular Control for Embodied Question Answering", "comments": "10 pages, 3 figures, 2 tables. Published at CoRL 2018. Webpage:\n  https://embodiedqa.org/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a modular approach for learning policies for navigation over long\nplanning horizons from language input. Our hierarchical policy operates at\nmultiple timescales, where the higher-level master policy proposes subgoals to\nbe executed by specialized sub-policies. Our choice of subgoals is\ncompositional and semantic, i.e. they can be sequentially combined in arbitrary\norderings, and assume human-interpretable descriptions (e.g. 'exit room', 'find\nkitchen', 'find refrigerator', etc.).\n  We use imitation learning to warm-start policies at each level of the\nhierarchy, dramatically increasing sample efficiency, followed by reinforcement\nlearning. Independent reinforcement learning at each level of hierarchy enables\nsub-policies to adapt to consequences of their actions and recover from errors.\nSubsequent joint hierarchical training enables the master policy to adapt to\nthe sub-policies.\n  On the challenging EQA (Das et al., 2018) benchmark in House3D (Wu et al.,\n2018), requiring navigating diverse realistic indoor environments, our approach\noutperforms prior work by a significant margin, both in terms of navigation and\nquestion answering.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 03:58:26 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 23:41:47 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Das", "Abhishek", ""], ["Gkioxari", "Georgia", ""], ["Lee", "Stefan", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""]]}, {"id": "1810.11190", "submitter": "Ajay Patel", "authors": "Ajay Patel, Alexander Sands, Chris Callison-Burch, and Marianna\n  Apidianaki", "title": "Magnitude: A Fast, Efficient Universal Vector Embedding Utility Package", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector space embedding models like word2vec, GloVe, fastText, and ELMo are\nextremely popular representations in natural language processing (NLP)\napplications. We present Magnitude, a fast, lightweight tool for utilizing and\nprocessing embeddings. Magnitude is an open source Python package with a\ncompact vector storage file format that allows for efficient manipulation of\nhuge numbers of embeddings. Magnitude performs common operations up to 60 to\n6,000 times faster than Gensim. Magnitude introduces several novel features for\nimproved robustness like out-of-vocabulary lookups.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 05:04:07 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Patel", "Ajay", ""], ["Sands", "Alexander", ""], ["Callison-Burch", "Chris", ""], ["Apidianaki", "Marianna", ""]]}, {"id": "1810.11193", "submitter": "Sanqiang Zhao", "authors": "Sanqiang Zhao, Rui Meng, Daqing He, Saptono Andi, Parmanto Bambang", "title": "Integrating Transformer and Paraphrase Rules for Sentence Simplification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence simplification aims to reduce the complexity of a sentence while\nretaining its original meaning. Current models for sentence simplification\nadopted ideas from ma- chine translation studies and implicitly learned\nsimplification mapping rules from normal- simple sentence pairs. In this paper,\nwe explore a novel model based on a multi-layer and multi-head attention\narchitecture and we pro- pose two innovative approaches to integrate the Simple\nPPDB (A Paraphrase Database for Simplification), an external paraphrase\nknowledge base for simplification that covers a wide range of real-world\nsimplification rules. The experiments show that the integration provides two\nmajor benefits: (1) the integrated model outperforms multiple state- of-the-art\nbaseline models for sentence simplification in the literature (2) through\nanalysis of the rule utilization, the model seeks to select more accurate\nsimplification rules. The code and models used in the paper are available at\nhttps://github.com/ Sanqiang/text_simplification.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 05:44:01 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Zhao", "Sanqiang", ""], ["Meng", "Rui", ""], ["He", "Daqing", ""], ["Andi", "Saptono", ""], ["Bambang", "Parmanto", ""]]}, {"id": "1810.11351", "submitter": "Mehrnoosh Sadrzadeh", "authors": "Mehrnoosh Sadrzadeh, Reinhard Muskens", "title": "Static and Dynamic Vector Semantics for Lambda Calculus Models of\n  Natural Language", "comments": "To appear in Journal of Language Modelling. Short versions presented\n  in DSALT 2016, SaLMoM 2016, LACL 2016. A version presented in AC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector models of language are based on the contextual aspects of language,\nthe distributions of words and how they co-occur in text. Truth conditional\nmodels focus on the logical aspects of language, compositional properties of\nwords and how they compose to form sentences. In the truth conditional\napproach, the denotation of a sentence determines its truth conditions, which\ncan be taken to be a truth value, a set of possible worlds, a context change\npotential, or similar. In the vector models, the degree of co-occurrence of\nwords in context determines how similar the meanings of words are. In this\npaper, we put these two models together and develop a vector semantics for\nlanguage based on the simply typed lambda calculus models of natural language.\nWe provide two types of vector semantics: a static one that uses techniques\nfamiliar from the truth conditional tradition and a dynamic one based on a form\nof dynamic interpretation inspired by Heim's context change potentials. We show\nhow the dynamic model can be applied to entailment between a corpus and a\nsentence and we provide examples.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 14:41:37 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Sadrzadeh", "Mehrnoosh", ""], ["Muskens", "Reinhard", ""]]}, {"id": "1810.11367", "submitter": "Eytan Adar", "authors": "Xin Rong, Joshua Luckson, Eytan Adar", "title": "LAMVI-2: A Visual Tool for Comparing and Tuning Word Embedding Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tuning machine learning models, particularly deep learning architectures, is\na complex process. Automated hyperparameter tuning algorithms often depend on\nspecific optimization metrics. However, in many situations, a developer trades\none metric against another: accuracy versus overfitting, precision versus\nrecall, smaller models and accuracy, etc. With deep learning, not only are the\nmodel's representations opaque, the model's behavior when parameters \"knobs\"\nare changed may also be unpredictable. Thus, picking the \"best\" model often\nrequires time-consuming model comparison. In this work, we introduce LAMVI-2, a\nvisual analytics system to support a developer in comparing hyperparameter\nsettings and outcomes. By focusing on word-embedding models (\"deep learning for\ntext\") we integrate views to compare both high-level statistics as well as\ninternal model behaviors (e.g., comparing word 'distances'). We demonstrate how\ndevelopers can work with LAMVI-2 to more quickly and accurately narrow down an\nappropriate and effective application-specific model.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 20:05:42 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Rong", "Xin", ""], ["Luckson", "Joshua", ""], ["Adar", "Eytan", ""]]}, {"id": "1810.11414", "submitter": "Durmus Sahin", "authors": "Durmus Ozkan Sahin, Oguz Emre Kural, Erdal Kilic, Armagan Karabina", "title": "A Text Classification Application: Poet Detection from Poetry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread use of the internet, the size of the text data increases\nday by day. Poems can be given as an example of the growing text. In this\nstudy, we aim to classify poetry according to poet. Firstly, data set\nconsisting of three different poetry of poets written in English have been\nconstructed. Then, text categorization techniques are implemented on it.\nChi-Square technique are used for feature selection. In addition, five\ndifferent classification algorithms are tried. These algorithms are Sequential\nminimal optimization, Naive Bayes, C4.5 decision tree, Random Forest and\nk-nearest neighbors. Although each classifier showed very different results,\nover the 70% classification success rate was taken by sequential minimal\noptimization technique.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2018 17:44:57 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Sahin", "Durmus Ozkan", ""], ["Kural", "Oguz Emre", ""], ["Kilic", "Erdal", ""], ["Karabina", "Armagan", ""]]}, {"id": "1810.11438", "submitter": "Bowen Shi", "authors": "Bowen Shi, Aurora Martinez Del Rio, Jonathan Keane, Jonathan Michaux,\n  Diane Brentari, Greg Shakhnarovich, Karen Livescu", "title": "American Sign Language fingerspelling recognition in the wild", "comments": "accepted in SLT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of American Sign Language fingerspelling recognition\nin the wild, using videos collected from websites. We introduce the largest\ndata set available so far for the problem of fingerspelling recognition, and\nthe first using naturally occurring video data. Using this data set, we present\nthe first attempt to recognize fingerspelling sequences in this challenging\nsetting. Unlike prior work, our video data is extremely challenging due to low\nframe rates and visual variability. To tackle the visual challenges, we train a\nspecial-purpose signing hand detector using a small subset of our data. Given\nthe hand detector output, a sequence model decodes the hypothesized\nfingerspelled letter sequence. For the sequence model, we explore\nattention-based recurrent encoder-decoders and CTC-based approaches. As the\nfirst attempt at fingerspelling recognition in the wild, this work is intended\nto serve as a baseline for future work on sign language recognition in\nrealistic conditions. We find that, as expected, letter error rates are much\nhigher than in previous work on more controlled data, and we analyze the\nsources of error and effects of model variants.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 17:43:44 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 05:14:07 GMT"}, {"version": "v3", "created": "Sun, 17 Feb 2019 22:45:52 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Shi", "Bowen", ""], ["Del Rio", "Aurora Martinez", ""], ["Keane", "Jonathan", ""], ["Michaux", "Jonathan", ""], ["Brentari", "Diane", ""], ["Shakhnarovich", "Greg", ""], ["Livescu", "Karen", ""]]}, {"id": "1810.11476", "submitter": "Oshin Agarwal", "authors": "Oshin Agarwal, Sanjay Subramanian, Ani Nenkova, Dan Roth", "title": "Named Person Coreference in English News", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People are often entities of interest in tasks such as search and information\nextraction. In these tasks, the goal is to find as much information as possible\nabout people specified by their name. However in text, some of the references\nto people are by pronouns (she, his) or generic descriptions (the professor,\nthe German chancellor). It is therefore important that coreference resolution\nsystems are able to link these different types of mentions to the correct\nperson name. Here, we evaluate two state of the art coreference resolution\nsystems on the subtask of Named Person Coreference, in which we are interested\nin identifying a person mentioned by name, along with all other mentions of the\nperson, by pronoun or generic noun phrase. Our analysis reveals that standard\ncoreference metrics do not reflect adequately the requirements in this task:\nthey do not penalize systems for not identifying any mentions by name and they\nreward systems even if systems find correctly mentions to the same entity but\nfail to link these to a proper name (she--the student---no name). We introduce\nnew metrics for evaluating named person coreference that address these\ndiscrepancies. We present a simple rule-based named entity recognition driven\nsystem, which outperforms the current state-of-the-art systems on these\ntask-specific metrics and performs on par with them on traditional coreference\nevaluations. Finally, we present similar evaluation for coreference resolution\nof other named entities and show that the rule-based approach is effective only\nfor person named coreference, not other named entity types.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 18:10:03 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 15:55:12 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Agarwal", "Oshin", ""], ["Subramanian", "Sanjay", ""], ["Nenkova", "Ani", ""], ["Roth", "Dan", ""]]}, {"id": "1810.11481", "submitter": "Marten Van Schijndel", "authors": "Marten van Schijndel and Tal Linzen", "title": "Can Entropy Explain Successor Surprisal Effects in Reading?", "comments": "Accepted for presentation at SCiL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human reading behavior is sensitive to surprisal: more predictable words tend\nto be read faster. Unexpectedly, this applies not only to the surprisal of the\nword that is currently being read, but also to the surprisal of upcoming\n(successor) words that have not been fixated yet. This finding has been\ninterpreted as evidence that readers can extract lexical information\nparafoveally. Calling this interpretation into question, Angele et al. (2015)\nshowed that successor effects appear even in contexts in which those successor\nwords are not yet visible. They hypothesized that successor surprisal predicts\nreading time because it approximates the reader's uncertainty about upcoming\nwords. We test this hypothesis on a reading time corpus using an LSTM language\nmodel, and find that successor surprisal and entropy are independent predictors\nof reading time. This independence suggests that entropy alone is unlikely to\nbe the full explanation for successor surprisal effects.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 18:19:29 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["van Schijndel", "Marten", ""], ["Linzen", "Tal", ""]]}, {"id": "1810.11497", "submitter": "Sanchit Agarwal", "authors": "Sanchit Agarwal, Rahul Goel, Tagyoung Chung, Abhishek Sethi, Arindam\n  Mandal, Spyros Matsoukas", "title": "Parsing Coordination for Spoken Language Understanding", "comments": "The paper was published in SLT 2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical spoken language understanding systems provide narrow semantic parses\nusing a domain-specific ontology. The parses contain intents and slots that are\ndirectly consumed by downstream domain applications. In this work we discuss\nexpanding such systems to handle compound entities and intents by introducing a\ndomain-agnostic shallow parser that handles linguistic coordination. We show\nthat our model for parsing coordination learns domain-independent and\nslot-independent features and is able to segment conjunct boundaries of many\ndifferent phrasal categories. We also show that using adversarial training can\nbe effective for improving generalization across different slot types for\ncoordination parsing.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 18:44:52 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Agarwal", "Sanchit", ""], ["Goel", "Rahul", ""], ["Chung", "Tagyoung", ""], ["Sethi", "Abhishek", ""], ["Mandal", "Arindam", ""], ["Matsoukas", "Spyros", ""]]}, {"id": "1810.11612", "submitter": "Genta Indra Winata", "authors": "Genta Indra Winata, Masayu Leylia Khodra", "title": "Handling Imbalanced Dataset in Multi-label Text Categorization using\n  Bagging and Adaptive Boosting", "comments": "Accepted in the 2015 International Conference on Electrical\n  Engineering and Informatics (ICEEI), Best Student Paper Award", "journal-ref": null, "doi": "10.1109/ICEEI.2015.7352552", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imbalanced dataset is occurred due to uneven distribution of data available\nin the real world such as disposition of complaints on government offices in\nBandung. Consequently, multi-label text categorization algorithms may not\nproduce the best performance because classifiers tend to be weighed down by the\nmajority of the data and ignore the minority. In this paper, Bagging and\nAdaptive Boosting algorithms are employed to handle the issue and improve the\nperformance of text categorization. The result is evaluated with four\nevaluation metrics such as hamming loss, subset accuracy, example-based\naccuracy and micro-averaged f-measure. Bagging ML-LP with SMO weak classifier\nis the best performer in terms of subset accuracy and example-based accuracy.\nBagging ML-BR with SMO weak classifier has the best micro-averaged f-measure\namong all. In other hand, AdaBoost MH with J48 weak classifier has the lowest\nhamming loss value. Thus, both algorithms have high potential in boosting the\nperformance of text categorization, but only for certain weak classifiers.\nHowever, bagging has more potential than adaptive boosting in increasing the\naccuracy of minority labels.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 07:27:18 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 17:00:25 GMT"}, {"version": "v3", "created": "Tue, 11 Jun 2019 04:18:26 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Winata", "Genta Indra", ""], ["Khodra", "Masayu Leylia", ""]]}, {"id": "1810.11663", "submitter": "Tsubasa Tagami", "authors": "Tsubasa Tagami, Hiroki Ouchi, Hiroki Asano, Kazuaki Hanawa, Kaori\n  Uchiyama, Kaito Suzuki, Kentaro Inui, Atsushi Komiya, Atsuo Fujimura,\n  Hitofumi Yanai, Ryo Yamashita, Akinori Machino", "title": "Suspicious News Detection Using Micro Blog Text", "comments": "10 pages; PACLIC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new task, suspicious news detection using micro blog text. This\ntask aims to support human experts to detect suspicious news articles to be\nverified, which is costly but a crucial step before verifying the truthfulness\nof the articles. Specifically, in this task, given a set of posts on SNS\nreferring to a news article, the goal is to judge whether the article is to be\nverified or not. For this task, we create a publicly available dataset in\nJapanese and provide benchmark results by using several basic machine learning\ntechniques. Experimental results show that our models can reduce the cost of\nmanual fact-checking process.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 15:24:15 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Tagami", "Tsubasa", ""], ["Ouchi", "Hiroki", ""], ["Asano", "Hiroki", ""], ["Hanawa", "Kazuaki", ""], ["Uchiyama", "Kaori", ""], ["Suzuki", "Kaito", ""], ["Inui", "Kentaro", ""], ["Komiya", "Atsushi", ""], ["Fujimura", "Atsuo", ""], ["Yanai", "Hitofumi", ""], ["Yamashita", "Ryo", ""], ["Machino", "Akinori", ""]]}, {"id": "1810.11735", "submitter": "Shikib Mehri", "authors": "Shikib Mehri, Leonid Sigal", "title": "Middle-Out Decoding", "comments": "Published as a conference paper at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite being virtually ubiquitous, sequence-to-sequence models are\nchallenged by their lack of diversity and inability to be externally\ncontrolled. In this paper, we speculate that a fundamental shortcoming of\nsequence generation models is that the decoding is done strictly from\nleft-to-right, meaning that outputs values generated earlier have a profound\neffect on those generated later. To address this issue, we propose a novel\nmiddle-out decoder architecture that begins from an initial middle-word and\nsimultaneously expands the sequence in both directions. To facilitate\ninformation flow and maintain consistent decoding, we introduce a dual\nself-attention mechanism that allows us to model complex dependencies between\nthe outputs. We illustrate the performance of our model on the task of video\ncaptioning, as well as a synthetic sequence de-noising task. Our middle-out\ndecoder achieves significant improvements on de-noising and competitive\nperformance in the task of video captioning, while quantifiably improving the\ncaption diversity. Furthermore, we perform a qualitative analysis that\ndemonstrates our ability to effectively control the generation process of our\ndecoder.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 00:19:26 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Mehri", "Shikib", ""], ["Sigal", "Leonid", ""]]}, {"id": "1810.11804", "submitter": "Frank F\\\"orster", "authors": "Frank F\\\"orster, Joe Saunders, Hagen Lehmann, Chrystopher L. Nehaniv", "title": "Robots Learning to Say `No': Prohibition and Rejective Mechanisms in\n  Acquisition of Linguistic Negation", "comments": "Submitted journal article. 21 pages main paper plus 28 pages\n  supplementary information / appendix. 8 figures in main paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  `No' belongs to the first ten words used by children and embodies the first\nactive form of linguistic negation. Despite its early occurrence the details of\nits acquisition process remain largely unknown. The circumstance that `no'\ncannot be construed as a label for perceptible objects or events puts it\noutside of the scope of most modern accounts of language acquisition. Moreover,\nmost symbol grounding architectures will struggle to ground the word due to its\nnon-referential character. In an experimental study involving the child-like\nhumanoid robot iCub that was designed to illuminate the acquisition process of\nnegation words, the robot is deployed in several rounds of speech-wise\nunconstrained interaction with na\\\"ive participants acting as its language\nteachers. The results corroborate the hypothesis that affect or volition plays\na pivotal role in the socially distributed acquisition process. Negation words\nare prosodically salient within prohibitive utterances and negative intent\ninterpretations such that they can be easily isolated from the teacher's speech\nsignal. These words subsequently may be grounded in negative affective states.\nHowever, observations of the nature of prohibitive acts and the temporal\nrelationships between its linguistic and extra-linguistic components raise\nserious questions over the suitability of Hebbian-type algorithms for language\ngrounding.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 12:17:27 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["F\u00f6rster", "Frank", ""], ["Saunders", "Joe", ""], ["Lehmann", "Hagen", ""], ["Nehaniv", "Chrystopher L.", ""]]}, {"id": "1810.11878", "submitter": "Richard Yuanzhe Pang", "authors": "Richard Yuanzhe Pang, Kevin Gimpel", "title": "Unsupervised Evaluation Metrics and Learning Criteria for Non-Parallel\n  Textual Transfer", "comments": "EMNLP 2019 Workshop on Neural Generation and Translation (WNGT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of automatically generating textual paraphrases with\nmodified attributes or properties, focusing on the setting without parallel\ndata (Hu et al., 2017; Shen et al., 2017). This setting poses challenges for\nevaluation. We show that the metric of post-transfer classification accuracy is\ninsufficient on its own, and propose additional metrics based on semantic\npreservation and fluency as well as a way to combine them into a single overall\nscore. We contribute new loss functions and training strategies to address the\ndifferent metrics. Semantic preservation is addressed by adding a cyclic\nconsistency loss and a loss based on paraphrase pairs, while fluency is\nimproved by integrating losses based on style-specific language models. We\nexperiment with a Yelp sentiment dataset and a new literature dataset that we\npropose, using multiple models that extend prior work (Shen et al., 2017). We\ndemonstrate that our metrics correlate well with human judgments, at both the\nsentence-level and system-level. Automatic and manual evaluation also show\nlarge improvements over the baseline method of Shen et al. (2017). We hope that\nour proposed metrics can speed up system development for new textual transfer\ntasks while also encouraging the community to address our three complementary\naspects of transfer quality.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 20:40:16 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 16:03:11 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Pang", "Richard Yuanzhe", ""], ["Gimpel", "Kevin", ""]]}, {"id": "1810.11895", "submitter": "Hila Gonen", "authors": "Hila Gonen and Yoav Goldberg", "title": "Language Modeling for Code-Switching: Evaluation, Integration of\n  Monolingual Data, and Discriminative Training", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We focus on the problem of language modeling for code-switched language, in\nthe context of automatic speech recognition (ASR). Language modeling for\ncode-switched language is challenging for (at least) three reasons: (1) lack of\navailable large-scale code-switched data for training; (2) lack of a replicable\nevaluation setup that is ASR directed yet isolates language modeling\nperformance from the other intricacies of the ASR system; and (3) the reliance\non generative modeling. We tackle these three issues: we propose an\nASR-motivated evaluation setup which is decoupled from an ASR system and the\nchoice of vocabulary, and provide an evaluation dataset for English-Spanish\ncode-switching. This setup lends itself to a discriminative training approach,\nwhich we demonstrate to work better than generative language modeling. Finally,\nwe explore a variety of training protocols and verify the effectiveness of\ntraining with large amounts of monolingual data followed by fine-tuning with\nsmall amounts of code-switched data, for both the generative and discriminative\ncases.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 22:15:32 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 11:38:52 GMT"}, {"version": "v3", "created": "Sun, 10 Nov 2019 07:11:04 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Gonen", "Hila", ""], ["Goldberg", "Yoav", ""]]}, {"id": "1810.11906", "submitter": "Mark Hamilton", "authors": "Mark Hamilton", "title": "Semi-Supervised Translation with MMD Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work aims to improve semi-supervised learning in a neural network\narchitecture by introducing a hybrid supervised and unsupervised cost function.\nThe unsupervised component is trained using a differentiable estimator of the\nMaximum Mean Discrepancy (MMD) distance between the network output and the\ntarget dataset. We introduce the notion of an $n$-channel network and several\nmethods to improve performance of these nets based on supervised\npre-initialization, and multi-scale kernels. This work investigates the\neffectiveness of these methods on language translation where very few quality\ntranslations are known \\textit{a priori}. We also present a thorough\ninvestigation of the hyper-parameter space of this method on both synthetic\ndata.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 23:40:54 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Hamilton", "Mark", ""]]}, {"id": "1810.11945", "submitter": "Shinji Takaki", "authors": "Shinji Takaki, Toru Nakashika, Xin Wang, Junichi Yamagishi", "title": "STFT spectral loss for training a neural speech waveform model", "comments": "Submitted to the 2019 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a new loss using short-time Fourier transform (STFT)\nspectra for the aim of training a high-performance neural speech waveform model\nthat predicts raw continuous speech waveform samples directly. Not only\namplitude spectra but also phase spectra obtained from generated speech\nwaveforms are used to calculate the proposed loss. We also mathematically show\nthat training of the waveform model on the basis of the proposed loss can be\ninterpreted as maximum likelihood training that assumes the amplitude and phase\nspectra of generated speech waveforms following Gaussian and von Mises\ndistributions, respectively. Furthermore, this paper presents a simple network\narchitecture as the speech waveform model, which is composed of uni-directional\nlong short-term memories (LSTMs) and an auto-regressive structure. Experimental\nresults showed that the proposed neural model synthesized high-quality speech\nwaveforms.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 04:05:35 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 05:35:57 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Takaki", "Shinji", ""], ["Nakashika", "Toru", ""], ["Wang", "Xin", ""], ["Yamagishi", "Junichi", ""]]}, {"id": "1810.11954", "submitter": "Shubham Agarwal", "authors": "Shubham Agarwal, Ondrej Dusek, Ioannis Konstas and Verena Rieser", "title": "A Knowledge-Grounded Multimodal Search-Based Conversational Agent", "comments": null, "journal-ref": "Proceedings of the 2018 EMNLP Workshop SCAI: The 2nd International\n  Workshop on Search-Oriented Conversational AI, pages 59-66, Brussels,\n  Belgium, October 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal search-based dialogue is a challenging new task: It extends\nvisually grounded question answering systems into multi-turn conversations with\naccess to an external database. We address this new challenge by learning a\nneural response generation system from the recently released Multimodal\nDialogue (MMD) dataset (Saha et al., 2017). We introduce a knowledge-grounded\nmultimodal conversational model where an encoded knowledge base (KB)\nrepresentation is appended to the decoder input. Our model substantially\noutperforms strong baselines in terms of text-based similarity measures (over 9\nBLEU points, 3 of which are solely due to the use of additional information\nfrom the KB.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 16:58:54 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Agarwal", "Shubham", ""], ["Dusek", "Ondrej", ""], ["Konstas", "Ioannis", ""], ["Rieser", "Verena", ""]]}, {"id": "1810.11955", "submitter": "Shubham Agarwal", "authors": "Shubham Agarwal, Ondrej Dusek, Ioannis Konstas and Verena Rieser", "title": "Improving Context Modelling in Multimodal Dialogue Generation", "comments": null, "journal-ref": "Proceedings of the 11th International Conference on Natural\n  Language Generation, pages 129-134, Tilburg, The Netherlands, 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate the task of textual response generation in a\nmultimodal task-oriented dialogue system. Our work is based on the recently\nreleased Multimodal Dialogue (MMD) dataset (Saha et al., 2017) in the fashion\ndomain. We introduce a multimodal extension to the Hierarchical Recurrent\nEncoder-Decoder (HRED) model and show that this extension outperforms strong\nbaselines in terms of text-based similarity metrics. We also showcase the\nshortcomings of current vision and language models by performing an error\nanalysis on our system's output.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 17:07:42 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Agarwal", "Shubham", ""], ["Dusek", "Ondrej", ""], ["Konstas", "Ioannis", ""], ["Rieser", "Verena", ""]]}, {"id": "1810.11960", "submitter": "Yusuke Yasuda", "authors": "Yusuke Yasuda, Xin Wang, Shinji Takaki, Junichi Yamagishi", "title": "Investigation of enhanced Tacotron text-to-speech synthesis systems with\n  self-attention for pitch accent language", "comments": "to be appeared at ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  End-to-end speech synthesis is a promising approach that directly converts\nraw text to speech. Although it was shown that Tacotron2 outperforms classical\npipeline systems with regards to naturalness in English, its applicability to\nother languages is still unknown. Japanese could be one of the most difficult\nlanguages for which to achieve end-to-end speech synthesis, largely due to its\ncharacter diversity and pitch accents. Therefore, state-of-the-art systems are\nstill based on a traditional pipeline framework that requires a separate text\nanalyzer and duration model. Towards end-to-end Japanese speech synthesis, we\nextend Tacotron to systems with self-attention to capture long-term\ndependencies related to pitch accents and compare their audio quality with\nclassical pipeline systems under various conditions to show their pros and\ncons. In a large-scale listening test, we investigated the impacts of the\npresence of accentual-type labels, the use of force or predicted alignments,\nand acoustic features used as local condition parameters of the Wavenet\nvocoder. Our results reveal that although the proposed systems still do not\nmatch the quality of a top-line pipeline system for Japanese, we show important\nstepping stones towards end-to-end Japanese speech synthesis.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 05:25:21 GMT"}, {"version": "v2", "created": "Thu, 14 Feb 2019 09:27:41 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Yasuda", "Yusuke", ""], ["Wang", "Xin", ""], ["Takaki", "Shinji", ""], ["Yamagishi", "Junichi", ""]]}, {"id": "1810.11975", "submitter": "Anirban Laha", "authors": "Anirban Laha, Saneem A. Chemmengath, Priyanka Agrawal, Mitesh M.\n  Khapra, Karthik Sankaranarayanan, Harish G. Ramaswamy", "title": "On Controllable Sparse Alternatives to Softmax", "comments": "To appear in NIPS 2018, Total 16 pages including appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Converting an n-dimensional vector to a probability distribution over n\nobjects is a commonly used component in many machine learning tasks like\nmulticlass classification, multilabel classification, attention mechanisms etc.\nFor this, several probability mapping functions have been proposed and employed\nin literature such as softmax, sum-normalization, spherical softmax, and\nsparsemax, but there is very little understanding in terms how they relate with\neach other. Further, none of the above formulations offer an explicit control\nover the degree of sparsity. To address this, we develop a unified framework\nthat encompasses all these formulations as special cases. This framework\nensures simple closed-form solutions and existence of sub-gradients suitable\nfor learning via backpropagation. Within this framework, we propose two novel\nsparse formulations, sparsegen-lin and sparsehourglass, that seek to provide a\ncontrol over the degree of desired sparsity. We further develop novel convex\nloss functions that help induce the behavior of aforementioned formulations in\nthe multilabel classification setting, showing improved performance. We also\ndemonstrate empirically that the proposed formulations, when used to compute\nattention weights, achieve better or comparable performance on standard seq2seq\ntasks like neural machine translation and abstractive summarization.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 06:46:37 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 19:02:13 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Laha", "Anirban", ""], ["Chemmengath", "Saneem A.", ""], ["Agrawal", "Priyanka", ""], ["Khapra", "Mitesh M.", ""], ["Sankaranarayanan", "Karthik", ""], ["Ramaswamy", "Harish G.", ""]]}, {"id": "1810.12001", "submitter": "Xinpei Zhou", "authors": "Xinpei Zhou, Jiwei Li, Xi Zhou", "title": "Cascaded CNN-resBiLSTM-CTC: An End-to-End Acoustic Model For Speech\n  Recognition", "comments": "5 pages, 1 figure, 4 tables. Submitted to 2019 ICASSP (International\n  Conference on Acoustics, Speech, and Signal Processing)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speech recognition (ASR) tasks are resolved by end-to-end deep\nlearning models, which benefits us by less preparation of raw data, and easier\ntransformation between languages. We propose a novel end-to-end deep learning\nmodel architecture namely cascaded CNN-resBiLSTM-CTC. In the proposed model, we\nadd residual blocks in BiLSTM layers to extract sophisticated phoneme and\nsemantic information together, and apply cascaded structure to pay more\nattention mining information of hard negative samples. By applying both simple\nFast Fourier Transform (FFT) technique and n-gram language model (LM) rescoring\nmethod, we manage to achieve word error rate (WER) of 3.41% on LibriSpeech test\nclean corpora. Furthermore, we propose a new batch-varied method to speed up\nthe training process in length-varied tasks, which result in 25% less training\ntime.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 08:52:31 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 11:13:35 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Zhou", "Xinpei", ""], ["Li", "Jiwei", ""], ["Zhou", "Xi", ""]]}, {"id": "1810.12051", "submitter": "Bajibabu Bollepalli Mr", "authors": "Bajibabu Bollepalli and Lauri Juvela and Paavo Alku", "title": "Speaking style adaptation in Text-To-Speech synthesis using\n  Sequence-to-sequence models with attention", "comments": "5 pages, 5 figures. Submitted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, there are increasing interests in text-to-speech (TTS) synthesis\nto use sequence-to-sequence models with attention. These models are end-to-end\nmeaning that they learn both co-articulation and duration properties directly\nfrom text and speech. Since these models are entirely data-driven, they need\nlarge amounts of data to generate synthetic speech with good quality. However,\nin challenging speaking styles, such as Lombard speech, it is difficult to\nrecord sufficiently large speech corpora. Therefore, in this study we propose a\ntransfer learning method to adapt a sequence-to-sequence based TTS system of\nnormal speaking style to Lombard style. Moreover, we experiment with a WaveNet\nvocoder in synthesis of Lombard speech. We conducted subjective evaluations to\nassess the performance of the adapted TTS systems. The subjective evaluation\nresults indicated that an adaptation system with the WaveNet vocoder clearly\noutperformed the conventional deep neural network based TTS system in synthesis\nof Lombard speech.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 10:53:31 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Bollepalli", "Bajibabu", ""], ["Juvela", "Lauri", ""], ["Alku", "Paavo", ""]]}, {"id": "1810.12085", "submitter": "Emily Alsentzer", "authors": "Emily Alsentzer and Anne Kim", "title": "Extractive Summarization of EHR Discharge Notes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patient summarization is essential for clinicians to provide coordinated care\nand practice effective communication. Automated summarization has the potential\nto save time, standardize notes, aid clinical decision making, and reduce\nmedical errors. Here we provide an upper bound on extractive summarization of\ndischarge notes and develop an LSTM model to sequentially label topics of\nhistory of present illness notes. We achieve an F1 score of 0.876, which\nindicates that this model can be employed to create a dataset for evaluation of\nextractive summarization methods.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 16:36:27 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Alsentzer", "Emily", ""], ["Kim", "Anne", ""]]}, {"id": "1810.12091", "submitter": "Shelan Jeawak", "authors": "Shelan S. Jeawak, Christopher B. Jones, and Steven Schockaert", "title": "Embedding Geographic Locations for Modelling the Natural Environment\n  using Flickr Tags and Structured Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-data from photo-sharing websites such as Flickr can be used to obtain\nrich bag-of-words descriptions of geographic locations, which have proven\nvaluable, among others, for modelling and predicting ecological features. One\nimportant insight from previous work is that the descriptions obtained from\nFlickr tend to be complementary to the structured information that is available\nfrom traditional scientific resources. To better integrate these two diverse\nsources of information, in this paper we consider a method for learning vector\nspace embeddings of geographic locations. We show experimentally that this\nmethod improves on existing approaches, especially in cases where structured\ninformation is available.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 12:22:34 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Jeawak", "Shelan S.", ""], ["Jones", "Christopher B.", ""], ["Schockaert", "Steven", ""]]}, {"id": "1810.12097", "submitter": "Ankush Chatterjee", "authors": "Sonam Damani, Nitya Raviprakash, Umang Gupta, Ankush Chatterjee,\n  Meghana Joshi, Khyatti Gupta, Kedhar Nath Narahari, Puneet Agrawal, Manoj\n  Kumar Chinnakotla, Sneha Magapu, Abhishek Mathur", "title": "Ruuh: A Deep Learning Based Conversational Social Agent", "comments": "2 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue systems and conversational agents are becoming increasingly popular\nin the modern society but building an agent capable of holding intelligent\nconversation with its users is a challenging problem for artificial\nintelligence. In this demo, we demonstrate a deep learning based conversational\nsocial agent called \"Ruuh\" (facebook.com/Ruuh) designed by a team at Microsoft\nIndia to converse on a wide range of topics. Ruuh needs to think beyond the\nutilitarian notion of merely generating \"relevant\" responses and meet a wider\nrange of user social needs, like expressing happiness when user's favorite team\nwins, sharing a cute comment on showing the pictures of the user's pet and so\non. The agent also needs to detect and respond to abusive language, sensitive\ntopics and trolling behavior of the users. Many of these problems pose\nsignificant research challenges which will be demonstrated in our demo. Our\nagent has interacted with over 2 million real world users till date which has\ngenerated over 150 million user conversations.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 14:26:13 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Damani", "Sonam", ""], ["Raviprakash", "Nitya", ""], ["Gupta", "Umang", ""], ["Chatterjee", "Ankush", ""], ["Joshi", "Meghana", ""], ["Gupta", "Khyatti", ""], ["Narahari", "Kedhar Nath", ""], ["Agrawal", "Puneet", ""], ["Chinnakotla", "Manoj Kumar", ""], ["Magapu", "Sneha", ""], ["Mathur", "Abhishek", ""]]}, {"id": "1810.12118", "submitter": "Jiamou Liu", "authors": "Helen Jiahe Zhao and Jiamou Liu", "title": "Finding Answers from the Word of God: Domain Adaptation for Neural\n  Networks in Biblical Question Answering", "comments": "The paper has been accepted at IJCNN 2018", "journal-ref": null, "doi": "10.1109/IJCNN.2018.8489756", "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering (QA) has significantly benefitted from deep learning\ntechniques in recent years. However, domain-specific QA remains a challenge due\nto the significant amount of data required to train a neural network. This\npaper studies the answer sentence selection task in the Bible domain and answer\nquestions by selecting relevant verses from the Bible. For this purpose, we\ncreate a new dataset BibleQA based on bible trivia questions and propose three\nneural network models for our task. We pre-train our models on a large-scale QA\ndataset, SQuAD, and investigate the effect of transferring weights on model\naccuracy. Furthermore, we also measure the model accuracies with different\nanswer context lengths and different Bible translations. We affirm that\ntransfer learning has a noticeable improvement in the model accuracy. We\nachieve relatively good results with shorter context lengths, whereas longer\ncontext lengths decreased model accuracy. We also find that using a more modern\nBible translation in the dataset has a positive effect on the task.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 12:34:21 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Zhao", "Helen Jiahe", ""], ["Liu", "Jiamou", ""]]}, {"id": "1810.12196", "submitter": "Quentin Grail", "authors": "Quentin Grail, Julien Perez", "title": "ReviewQA: a relational aspect-based opinion reading dataset", "comments": "Accepted at Conf\\'erence sur l'apprentissage automatique (CAp 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reading models for question-answering have demonstrated promising\nperformance over the last couple of years. However current systems tend to\nlearn how to cleverly extract a span of the source document, based on its\nsimilarity with the question, instead of seeking for the appropriate answer.\nIndeed, a reading machine should be able to detect relevant passages in a\ndocument regarding a question, but more importantly, it should be able to\nreason over the important pieces of the document in order to produce an answer\nwhen it is required. To motivate this purpose, we present ReviewQA, a\nquestion-answering dataset based on hotel reviews. The questions of this\ndataset are linked to a set of relational understanding competencies that we\nexpect a model to master. Indeed, each question comes with an associated type\nthat characterizes the required competency. With this framework, it is possible\nto benchmark the main families of models and to get an overview of what are the\nstrengths and the weaknesses of a given model on the set of tasks evaluated in\nthis dataset. Our corpus contains more than 500.000 questions in natural\nlanguage over 100.000 hotel reviews. Our setup is projective, the answer of a\nquestion does not need to be extracted from a document, like in most of the\nrecent datasets, but selected among a set of candidates that contains all the\npossible answers to the questions of the dataset. Finally, we present several\nbaselines over this dataset.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 15:35:18 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Grail", "Quentin", ""], ["Perez", "Julien", ""]]}, {"id": "1810.12264", "submitter": "Zhaojiang Lin", "authors": "Zhaojiang Lin, Genta Indra Winata, Pascale Fung", "title": "Learning Comment Generation by Leveraging User-Generated Data", "comments": "Accepted by ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing models on open-domain comment generation are difficult to train, and\nthey produce repetitive and uninteresting responses. The problem is due to\nmultiple and contradictory responses from a single article, and by the rigidity\nof retrieval methods. To solve this problem, we propose a combined approach to\nretrieval and generation methods. We propose an attentive scorer to retrieve\ninformative and relevant comments by leveraging user-generated data. Then, we\nuse such comments, together with the article, as input for a\nsequence-to-sequence model with copy mechanism. We show the robustness of our\nmodel and how it can alleviate the aforementioned issue by using a large scale\ncomment generation dataset. The result shows that the proposed generative model\nsignificantly outperforms strong baseline such as Seq2Seq with attention and\nInformation Retrieval models by around 27 and 30 BLEU-1 points respectively.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 17:23:33 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 06:43:54 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Lin", "Zhaojiang", ""], ["Winata", "Genta Indra", ""], ["Fung", "Pascale", ""]]}, {"id": "1810.12266", "submitter": "Adam Lopez", "authors": "Ieva Vasiljeva, Sorcha Gilroy, Adam Lopez", "title": "The problem with probabilistic DAG automata for semantic graphs", "comments": "To appear in NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic representations in the form of directed acyclic graphs (DAGs) have\nbeen introduced in recent years, and to model them, we need probabilistic\nmodels of DAGs. One model that has attracted some attention is the DAG\nautomaton, but it has not been studied as a probabilistic model. We show that\nsome DAG automata cannot be made into useful probabilistic models by the nearly\nuniversal strategy of assigning weights to transitions. The problem affects\nsingle-rooted, multi-rooted, and unbounded-degree variants of DAG automata, and\nappears to be pervasive. It does not affect planar variants, but these are\nproblematic for other reasons.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 17:24:57 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2019 14:41:39 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Vasiljeva", "Ieva", ""], ["Gilroy", "Sorcha", ""], ["Lopez", "Adam", ""]]}, {"id": "1810.12343", "submitter": "Chris Kedzie", "authors": "Chris Kedzie, Kathleen McKeown, and Hal Daume III", "title": "Content Selection in Deep Learning Models of Summarization", "comments": "Revised to correct for error in AMI oracle results. Originally\n  published at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We carry out experiments with deep learning models of summarization across\nthe domains of news, personal stories, meetings, and medical articles in order\nto understand how content selection is performed. We find that many\nsophisticated features of state of the art extractive summarizers do not\nimprove performance over simpler models. These results suggest that it is\neasier to create a summarizer for a new domain than previous work suggests and\nbring into question the benefit of deep learning models for summarization for\nthose domains that do have massive datasets (i.e., news). At the same time,\nthey suggest important questions for new research in summarization; namely, new\nforms of sentence representations or external knowledge sources are needed that\nare better suited to the summarization task.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 18:42:46 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 22:14:21 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Kedzie", "Chris", ""], ["McKeown", "Kathleen", ""], ["Daume", "Hal", "III"]]}, {"id": "1810.12349", "submitter": "James Gibson", "authors": "James Gibson, David C. Atkins, Torrey Creed, Zac Imel, Panayiotis\n  Georgiou, and Shrikanth Narayanan", "title": "Multi-label Multi-task Deep Learning for Behavioral Coding", "comments": null, "journal-ref": null, "doi": "10.1109/TAFFC.2019.2952113", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a methodology for estimating human behaviors in psychotherapy\nsessions using mutli-label and multi-task learning paradigms. We discuss the\nproblem of behavioral coding in which data of human interactions is the\nannotated with labels to describe relevant human behaviors of interest. We\ndescribe two related, yet distinct, corpora consisting of therapist client\ninteractions in psychotherapy sessions. We experimentally compare the proposed\nlearning approaches for estimating behaviors of interest in these datasets.\nSpecifically, we compare single and multiple label learning approaches, single\nand multiple task learning approaches, and evaluate the performance of these\napproaches when incorporating turn context. We demonstrate the prediction\nperformance gains which can be achieved by using the proposed paradigms and\ndiscuss the insights these models provide into these complex interactions.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 18:57:30 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 23:25:33 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Gibson", "James", ""], ["Atkins", "David C.", ""], ["Creed", "Torrey", ""], ["Imel", "Zac", ""], ["Georgiou", "Panayiotis", ""], ["Narayanan", "Shrikanth", ""]]}, {"id": "1810.12366", "submitter": "Arjun Chandrasekaran", "authors": "Arjun Chandrasekaran, Viraj Prabhu, Deshraj Yadav, Prithvijit\n  Chattopadhyay, Devi Parikh", "title": "Do Explanations make VQA Models more Predictable to a Human?", "comments": "EMNLP 2018. 16 pages, 11 figures. Content overlaps with \"It Takes Two\n  to Tango: Towards Theory of AI's Mind\" (arXiv:1704.00717)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A rich line of research attempts to make deep neural networks more\ntransparent by generating human-interpretable 'explanations' of their decision\nprocess, especially for interactive tasks like Visual Question Answering (VQA).\nIn this work, we analyze if existing explanations indeed make a VQA model --\nits responses as well as failures -- more predictable to a human. Surprisingly,\nwe find that they do not. On the other hand, we find that human-in-the-loop\napproaches that treat the model as a black-box do.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 19:14:26 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Chandrasekaran", "Arjun", ""], ["Prabhu", "Viraj", ""], ["Yadav", "Deshraj", ""], ["Chattopadhyay", "Prithvijit", ""], ["Parikh", "Devi", ""]]}, {"id": "1810.12368", "submitter": "Milan Gritta", "authors": "Milan Gritta, Mohammad Taher Pilehvar, Nigel Collier", "title": "A Pragmatic Guide to Geoparsing Evaluation", "comments": "Accepted at Language Resources and Evaluation (Springer Journal)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirical methods in geoparsing have thus far lacked a standard evaluation\nframework describing the task, metrics and data used to compare\nstate-of-the-art systems. Evaluation is further made inconsistent, even\nunrepresentative of real-world usage by the lack of distinction between the\ndifferent types of toponyms, which necessitates new guidelines, a consolidation\nof metrics and a detailed toponym taxonomy with implications for Named Entity\nRecognition (NER) and beyond. To address these deficiencies, our manuscript\nintroduces a new framework in three parts. Part 1) Task Definition: clarified\nvia corpus linguistic analysis proposing a fine-grained Pragmatic Taxonomy of\nToponyms. Part 2) Metrics: discussed and reviewed for a rigorous evaluation\nincluding recommendations for NER/Geoparsing practitioners. Part 3) Evaluation\nData: shared via a new dataset called GeoWebNews to provide test/train examples\nand enable immediate use of our contributions. In addition to fine-grained\nGeotagging and Toponym Resolution (Geocoding), this dataset is also suitable\nfor prototyping and evaluating machine learning NLP models.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 19:22:12 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 11:34:57 GMT"}, {"version": "v3", "created": "Mon, 5 Nov 2018 11:19:34 GMT"}, {"version": "v4", "created": "Tue, 25 Jun 2019 12:01:08 GMT"}, {"version": "v5", "created": "Sun, 15 Sep 2019 15:47:48 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Gritta", "Milan", ""], ["Pilehvar", "Mohammad Taher", ""], ["Collier", "Nigel", ""]]}, {"id": "1810.12387", "submitter": "Hao Zhu", "authors": "Yihong Gu, Jun Yan, Hao Zhu, Zhiyuan Liu, Ruobing Xie, Maosong Sun,\n  Fen Lin, Leyu Lin", "title": "Language Modeling with Sparse Product of Sememe Experts", "comments": "EMNLP 2018. The first three authors contribute equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Most language modeling methods rely on large-scale data to statistically\nlearn the sequential patterns of words. In this paper, we argue that words are\natomic language units but not necessarily atomic semantic units. Inspired by\nHowNet, we use sememes, the minimum semantic units in human languages, to\nrepresent the implicit semantics behind words for language modeling, named\nSememe-Driven Language Model (SDLM). More specifically, to predict the next\nword, SDLM first estimates the sememe distribution gave textual context.\nAfterward, it regards each sememe as a distinct semantic expert, and these\nexperts jointly identify the most probable senses and the corresponding word.\nIn this way, SDLM enables language models to work beyond word-level\nmanipulation to fine-grained sememe-level semantics and offers us more powerful\ntools to fine-tune language models and improve the interpretability as well as\nthe robustness of language models. Experiments on language modeling and the\ndownstream application of headline gener- ation demonstrate the significant\neffect of SDLM. Source code and data used in the experiments can be accessed at\nhttps:// github.com/thunlp/SDLM-pytorch.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 20:13:05 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Gu", "Yihong", ""], ["Yan", "Jun", ""], ["Zhu", "Hao", ""], ["Liu", "Zhiyuan", ""], ["Xie", "Ruobing", ""], ["Sun", "Maosong", ""], ["Lin", "Fen", ""], ["Lin", "Leyu", ""]]}, {"id": "1810.12406", "submitter": "Patrick Chen", "authors": "Patrick H. Chen, Si Si, Sanjiv Kumar, Yang Li, Cho-Jui Hsieh", "title": "Learning to Screen for Fast Softmax Inference on Large Vocabulary Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural language models have been widely used in various NLP tasks, including\nmachine translation, next word prediction and conversational agents. However,\nit is challenging to deploy these models on mobile devices due to their slow\nprediction speed, where the bottleneck is to compute top candidates in the\nsoftmax layer. In this paper, we introduce a novel softmax layer approximation\nalgorithm by exploiting the clustering structure of context vectors. Our\nalgorithm uses a light-weight screening model to predict a much smaller set of\ncandidate words based on the given context, and then conducts an exact softmax\nonly within that subset. Training such a procedure end-to-end is challenging as\ntraditional clustering methods are discrete and non-differentiable, and thus\nunable to be used with back-propagation in the training process. Using the\nGumbel softmax, we are able to train the screening model end-to-end on the\ntraining set to exploit data distribution. The algorithm achieves an order of\nmagnitude faster inference than the original softmax layer for predicting\ntop-$k$ words in various tasks such as beam search in machine translation or\nnext words prediction. For example, for machine translation task on German to\nEnglish dataset with around 25K vocabulary, we can achieve 20.4 times speed up\nwith 98.9\\% precision@1 and 99.3\\% precision@5 with the original softmax layer\nprediction, while state-of-the-art ~\\citep{MSRprediction} only achieves 6.7x\nspeedup with 98.7\\% precision@1 and 98.1\\% precision@5 for the same task.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 20:59:56 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Chen", "Patrick H.", ""], ["Si", "Si", ""], ["Kumar", "Sanjiv", ""], ["Li", "Yang", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1810.12427", "submitter": "Julian Medina", "authors": "Julian Richard Medina, Jugal Kalita", "title": "Parallel Attention Mechanisms in Neural Machine Translation", "comments": "ICMLA 2018, 6 pages", "journal-ref": "17th IEEE International Conference on Machine Learning and\n  Applications 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent papers in neural machine translation have proposed the strict use of\nattention mechanisms over previous standards such as recurrent and\nconvolutional neural networks (RNNs and CNNs). We propose that by running\ntraditionally stacked encoding branches from encoder-decoder attention- focused\narchitectures in parallel, that even more sequential operations can be removed\nfrom the model and thereby decrease training time. In particular, we modify the\nrecently published attention-based architecture called Transformer by Google,\nby replacing sequential attention modules with parallel ones, reducing the\namount of training time and substantially improving BLEU scores at the same\ntime. Experiments over the English to German and English to French translation\ntasks show that our model establishes a new state of the art.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 21:58:13 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Medina", "Julian Richard", ""], ["Kalita", "Jugal", ""]]}, {"id": "1810.12443", "submitter": "Yingwei Xin", "authors": "Yingwei Xin, Ethan Hart, Vibhuti Mahajan, Jean-David Ruvini", "title": "Learning Better Internal Structure of Words for Sequence Labeling", "comments": "EMNLP 2018 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Character-based neural models have recently proven very useful for many NLP\ntasks. However, there is a gap of sophistication between methods for learning\nrepresentations of sentences and words. While most character models for\nlearning representations of sentences are deep and complex, models for learning\nrepresentations of words are shallow and simple. Also, in spite of considerable\nresearch on learning character embeddings, it is still not clear which kind of\narchitecture is the best for capturing character-to-word representations. To\naddress these questions, we first investigate the gaps between methods for\nlearning word and sentence representations. We conduct detailed experiments and\ncomparisons of different state-of-the-art convolutional models, and also\ninvestigate the advantages and disadvantages of their constituents.\nFurthermore, we propose IntNet, a funnel-shaped wide convolutional neural\narchitecture with no down-sampling for learning representations of the internal\nstructure of words by composing their characters from limited, supervised\ntraining corpora. We evaluate our proposed model on six sequence labeling\ndatasets, including named entity recognition, part-of-speech tagging, and\nsyntactic chunking. Our in-depth analysis shows that IntNet significantly\noutperforms other character embedding models and obtains new state-of-the-art\nperformance without relying on any external knowledge or resources.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 22:39:49 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Xin", "Yingwei", ""], ["Hart", "Ethan", ""], ["Mahajan", "Vibhuti", ""], ["Ruvini", "Jean-David", ""]]}, {"id": "1810.12546", "submitter": "Biao Zhang", "authors": "Biao Zhang, Deyi Xiong, Jinsong Su, Qian Lin, Huiji Zhang", "title": "Simplifying Neural Machine Translation with Addition-Subtraction\n  Twin-Gated Recurrent Networks", "comments": "EMNLP 2018, long paper, source code released", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an additionsubtraction twin-gated recurrent network\n(ATR) to simplify neural machine translation. The recurrent units of ATR are\nheavily simplified to have the smallest number of weight matrices among units\nof all existing gated RNNs. With the simple addition and subtraction operation,\nwe introduce a twin-gated mechanism to build input and forget gates which are\nhighly correlated. Despite this simplification, the essential non-linearities\nand capability of modeling long-distance dependencies are preserved.\nAdditionally, the proposed ATR is more transparent than LSTM/GRU due to the\nsimplification. Forward self-attention can be easily established in ATR, which\nmakes the proposed network interpretable. Experiments on WMT14 translation\ntasks demonstrate that ATR-based neural machine translation can yield\ncompetitive performance on English- German and English-French language pairs in\nterms of both translation quality and speed. Further experiments on NIST\nChinese-English translation, natural language inference and Chinese word\nsegmentation verify the generality and applicability of ATR on different\nnatural language processing tasks.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 06:55:23 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Zhang", "Biao", ""], ["Xiong", "Deyi", ""], ["Su", "Jinsong", ""], ["Lin", "Qian", ""], ["Zhang", "Huiji", ""]]}, {"id": "1810.12557", "submitter": "Viet-Trung Tran", "authors": "Hong-Hai Phan-Vu, Viet-Trung Tran, Van-Nam Nguyen, Hoang-Vu Dang,\n  Phan-Thuan Do", "title": "Machine Translation between Vietnamese and English: an Empirical Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine translation is shifting to an end-to-end approach based on deep\nneural networks. The state of the art achieves impressive results for popular\nlanguage pairs such as English - French or English - Chinese. However for\nEnglish - Vietnamese the shortage of parallel corpora and expensive\nhyper-parameter search present practical challenges to neural-based approaches.\nThis paper highlights our efforts on improving English-Vietnamese translations\nin two directions: (1) Building the largest open Vietnamese - English corpus to\ndate, and (2) Extensive experiments with the latest neural models to achieve\nthe highest BLEU scores. Our experiments provide practical examples of\neffectively employing different neural machine translation models with\nlow-resource language pairs.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 07:33:52 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Phan-Vu", "Hong-Hai", ""], ["Tran", "Viet-Trung", ""], ["Nguyen", "Van-Nam", ""], ["Dang", "Hoang-Vu", ""], ["Do", "Phan-Thuan", ""]]}, {"id": "1810.12566", "submitter": "Yi-Chen Chen", "authors": "Yi-Chen Chen, Chia-Hao Shen, Sung-Feng Huang, Hung-yi Lee, Lin-shan\n  Lee", "title": "Almost-unsupervised Speech Recognition with Close-to-zero Resource Based\n  on Phonetic Structures Learned from Very Small Unpaired Speech and Text Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Producing a large amount of annotated speech data for training ASR systems\nremains difficult for more than 95% of languages all over the world which are\nlow-resourced. However, we note human babies start to learn the language by the\nsounds of a small number of exemplar words without hearing a large amount of\ndata. We initiate some preliminary work in this direction in this paper. Audio\nWord2Vec is used to obtain embeddings of spoken words which carry phonetic\ninformation extracted from the signals. An autoencoder is used to generate\nembeddings of text words based on the articulatory features for the phoneme\nsequences. Both sets of embeddings for spoken and text words describe similar\nphonetic structures among words in their respective latent spaces. A mapping\nrelation from the audio embeddings to text embeddings actually gives the\nword-level ASR. This can be learned by aligning a small number of spoken words\nand the corresponding text words in the embedding spaces. In the initial\nexperiments only 200 annotated spoken words and one hour of speech data without\nannotation gave a word accuracy of 27.5%, which is low but a good starting\npoint.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 08:11:45 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Chen", "Yi-Chen", ""], ["Shen", "Chia-Hao", ""], ["Huang", "Sung-Feng", ""], ["Lee", "Hung-yi", ""], ["Lee", "Lin-shan", ""]]}, {"id": "1810.12579", "submitter": "Rik van Noord", "authors": "Rik van Noord, Lasha Abzianidze, Antonio Toral, Johan Bos", "title": "Exploring Neural Methods for Parsing Discourse Representation Structures", "comments": "to appear in TACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural methods have had several recent successes in semantic parsing, though\nthey have yet to face the challenge of producing meaning representations based\non formal semantics. We present a sequence-to-sequence neural semantic parser\nthat is able to produce Discourse Representation Structures (DRSs) for English\nsentences with high accuracy, outperforming traditional DRS parsers. To\nfacilitate the learning of the output, we represent DRSs as a sequence of flat\nclauses and introduce a method to verify that produced DRSs are well-formed and\ninterpretable. We compare models using characters and words as input and see\n(somewhat surprisingly) that the former performs better than the latter. We\nshow that eliminating variable names from the output using De Bruijn-indices\nincreases parser performance. Adding silver training data boosts performance\neven further.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 08:42:52 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["van Noord", "Rik", ""], ["Abzianidze", "Lasha", ""], ["Toral", "Antonio", ""], ["Bos", "Johan", ""]]}, {"id": "1810.12594", "submitter": "Jie Yang", "authors": "Jie Yang, Yue Zhang, Shuailong Liang", "title": "Subword Encoding in Lattice LSTM for Chinese Word Segmentation", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a lattice LSTM network for Chinese word segmentation (CWS) to\nutilize words or subwords. It integrates the character sequence features with\nall subsequences information matched from a lexicon. The matched subsequences\nserve as information shortcut tunnels which link their start and end characters\ndirectly. Gated units are used to control the contribution of multiple input\nlinks. Through formula derivation and comparison, we show that the lattice LSTM\nis an extension of the standard LSTM with the ability to take multiple inputs.\nPrevious lattice LSTM model takes word embeddings as the lexicon input, we\nprove that subword encoding can give the comparable performance and has the\nbenefit of not relying on any external segmentor. The contribution of lattice\nLSTM comes from both lexicon and pretrained embeddings information, we find\nthat the lexicon information contributes more than the pretrained embeddings\ninformation through controlled experiments. Our experiments show that the\nlattice structure with subword encoding gives competitive or better results\nwith previous state-of-the-art methods on four segmentation benchmarks.\nDetailed analyses are conducted to compare the performance of word encoding and\nsubword encoding in lattice LSTM. We also investigate the performance of\nlattice LSTM structure under different circumstances and when this model works\nor fails.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 09:14:37 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Yang", "Jie", ""], ["Zhang", "Yue", ""], ["Liang", "Shuailong", ""]]}, {"id": "1810.12620", "submitter": "Genta Indra Winata", "authors": "Genta Indra Winata, Andrea Madotto, Chien-Sheng Wu, Pascale Fung", "title": "Towards End-to-end Automatic Code-Switching Speech Recognition", "comments": "Submitted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech recognition in mixed language has difficulties to adapt end-to-end\nframework due to the lack of data and overlapping phone sets, for example in\nwords such as \"one\" in English and \"w\\`an\" in Chinese. We propose a CTC-based\nend-to-end automatic speech recognition model for intra-sentential\nEnglish-Mandarin code-switching. The model is trained by joint training on\nmonolingual datasets, and fine-tuning with the mixed-language corpus. During\nthe decoding process, we apply a beam search and combine CTC predictions and\nlanguage model score. The proposed method is effective in leveraging\nmonolingual corpus and detecting language transitions and it improves the CER\nby 5%.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 10:11:35 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Winata", "Genta Indra", ""], ["Madotto", "Andrea", ""], ["Wu", "Chien-Sheng", ""], ["Fung", "Pascale", ""]]}, {"id": "1810.12646", "submitter": "Uwe Reichel", "authors": "Uwe D. Reichel and Katalin M\\'ady and Jennifer Cole", "title": "Prosodic entrainment in dialog acts", "comments": "This manuscript is under revision. Please contact the authors for\n  information about updates", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examined prosodic entrainment in spoken dialogs separately for several\ndialog acts in cooperative and competitive games. Entrainment was measured for\nintonation features derived from a superpositional intonation stylization as\nwell as for rhythm features. The found differences can be related to the\ncooperative or competitive nature of the game, as well as to dialog act\nproperties as its intrinsic authority, supportiveness and distributional\ncharacteristics. In cooperative games dialog acts with a high authority given\nby knowledge and with a high frequency showed the most entrainment. The results\nare discussed amongst others with respect to the degree of active entrainment\ncontrol in cooperative behavior.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 10:53:42 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Reichel", "Uwe D.", ""], ["M\u00e1dy", "Katalin", ""], ["Cole", "Jennifer", ""]]}, {"id": "1810.12686", "submitter": "Vered Shwartz", "authors": "Guy Tevet, Gavriel Habib, Vered Shwartz, Jonathan Berant", "title": "Evaluating Text GANs as Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are a promising approach for text\ngeneration that, unlike traditional language models (LM), does not suffer from\nthe problem of ``exposure bias''. However, A major hurdle for understanding the\npotential of GANs for text generation is the lack of a clear evaluation metric.\nIn this work, we propose to approximate the distribution of text generated by a\nGAN, which permits evaluating them with traditional probability-based LM\nmetrics. We apply our approximation procedure on several GAN-based models and\nshow that they currently perform substantially worse than state-of-the-art LMs.\nOur evaluation procedure promotes better understanding of the relation between\nGANs and LMs, and can accelerate progress in GAN-based text generation.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 11:58:16 GMT"}, {"version": "v2", "created": "Sun, 24 Mar 2019 08:14:51 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Tevet", "Guy", ""], ["Habib", "Gavriel", ""], ["Shwartz", "Vered", ""], ["Berant", "Jonathan", ""]]}, {"id": "1810.12698", "submitter": "Vaidheeswaran Archana", "authors": "Muru Selvakumar, Suriyadeepan Ramamoorthy, Vaidheeswaran Archana,\n  Malaikannan Sankarasubbu", "title": "Compositional Attention Networks for Interpretability in Natural\n  Language Question Answering", "comments": "8 pages,10 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MAC Net is a compositional attention network designed for Visual Question\nAnswering. We propose a modified MAC net architecture for Natural Language\nQuestion Answering. Question Answering typically requires Language\nUnderstanding and multi-step Reasoning. MAC net's unique architecture - the\nseparation between memory and control, facilitates data-driven iterative\nreasoning. This makes it an ideal candidate for solving tasks that involve\nlogical reasoning. Our experiments with 20 bAbI tasks demonstrate the value of\nMAC net as a data-efficient and interpretable architecture for Natural Language\nQuestion Answering. The transparent nature of MAC net provides a highly\ngranular view of the reasoning steps taken by the network in answering a query.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 12:23:35 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Selvakumar", "Muru", ""], ["Ramamoorthy", "Suriyadeepan", ""], ["Archana", "Vaidheeswaran", ""], ["Sankarasubbu", "Malaikannan", ""]]}, {"id": "1810.12703", "submitter": "Benjamin Marie", "authors": "Benjamin Marie and Atsushi Fujita", "title": "Unsupervised Neural Machine Translation Initialized by Unsupervised\n  Statistical Machine Translation", "comments": "preliminary work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work achieved remarkable results in training neural machine\ntranslation (NMT) systems in a fully unsupervised way, with new and dedicated\narchitectures that rely on monolingual corpora only. In this work, we propose\nto define unsupervised NMT (UNMT) as NMT trained with the supervision of\nsynthetic bilingual data. Our approach straightforwardly enables the use of\nstate-of-the-art architectures proposed for supervised NMT by replacing\nhuman-made bilingual data with synthetic bilingual data for training. We\npropose to initialize the training of UNMT with synthetic bilingual data\ngenerated by unsupervised statistical machine translation (USMT). The UNMT\nsystem is then incrementally improved using back-translation. Our preliminary\nexperiments show that our approach achieves a new state-of-the-art for\nunsupervised machine translation on the WMT16 German--English news translation\ntask, for both translation directions.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 12:33:03 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Marie", "Benjamin", ""], ["Fujita", "Atsushi", ""]]}, {"id": "1810.12730", "submitter": "Fuming Fang", "authors": "Fuming Fang, Xin Wang, Junichi Yamagishi, Isao Echizen", "title": "Audiovisual speaker conversion: jointly and simultaneously transforming\n  facial expression and acoustic characteristics", "comments": "Submitted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An audiovisual speaker conversion method is presented for simultaneously\ntransforming the facial expressions and voice of a source speaker into those of\na target speaker. Transforming the facial and acoustic features together makes\nit possible for the converted voice and facial expressions to be highly\ncorrelated and for the generated target speaker to appear and sound natural. It\nuses three neural networks: a conversion network that fuses and transforms the\nfacial and acoustic features, a waveform generation network that produces the\nwaveform from both the converted facial and acoustic features, and an image\nreconstruction network that outputs an RGB facial image also based on both the\nconverted features. The results of experiments using an emotional audiovisual\ndatabase showed that the proposed method achieved significantly higher\nnaturalness compared with one that separately transformed acoustic and facial\nfeatures.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 15:20:32 GMT"}, {"version": "v2", "created": "Sat, 1 Dec 2018 15:36:52 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Fang", "Fuming", ""], ["Wang", "Xin", ""], ["Yamagishi", "Junichi", ""], ["Echizen", "Isao", ""]]}, {"id": "1810.12735", "submitter": "Alice Coucke", "authors": "Alaa Saade, Alice Coucke, Alexandre Caulier, Joseph Dureau, Adrien\n  Ball, Th\\'eodore Bluche, David Leroy, Cl\\'ement Doumouro, Thibault\n  Gisselbrecht, Francesco Caltagirone, Thibaut Lavril, Ma\\\"el Primet", "title": "Spoken Language Understanding on the Edge", "comments": "arXiv admin note: text overlap with arXiv:1805.10190", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of performing Spoken Language Understanding (SLU) on\nsmall devices typical of IoT applications. Our contributions are twofold.\nFirst, we outline the design of an embedded, private-by-design SLU system and\nshow that it has performance on par with cloud-based commercial solutions.\nSecond, we release the datasets used in our experiments in the interest of\nreproducibility and in the hope that they can prove useful to the SLU\ncommunity.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 13:49:37 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 15:03:22 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Saade", "Alaa", ""], ["Coucke", "Alice", ""], ["Caulier", "Alexandre", ""], ["Dureau", "Joseph", ""], ["Ball", "Adrien", ""], ["Bluche", "Th\u00e9odore", ""], ["Leroy", "David", ""], ["Doumouro", "Cl\u00e9ment", ""], ["Gisselbrecht", "Thibault", ""], ["Caltagirone", "Francesco", ""], ["Lavril", "Thibaut", ""], ["Primet", "Ma\u00ebl", ""]]}, {"id": "1810.12752", "submitter": "Guoqiang Zhong", "authors": "Guoqiang Zhong, Xin Lin, Kang Chen, Qingyang Li, and Kaizhu Huang", "title": "Long Short-Term Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention is an important cognition process of humans, which helps humans\nconcentrate on critical information during their perception and learning.\nHowever, although many machine learning models can remember information of\ndata, they have no the attention mechanism. For example, the long short-term\nmemory (LSTM) network is able to remember sequential information, but it cannot\npay special attention to part of the sequences. In this paper, we present a\nnovel model called long short-term attention (LSTA), which seamlessly\nintegrates the attention mechanism into the inner cell of LSTM. More than\nprocessing long short term dependencies, LSTA can focus on important\ninformation of the sequences with the attention mechanism. Extensive\nexperiments demonstrate that LSTA outperforms LSTM and related models on the\nsequence learning tasks.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 14:08:30 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 02:44:15 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Zhong", "Guoqiang", ""], ["Lin", "Xin", ""], ["Chen", "Kang", ""], ["Li", "Qingyang", ""], ["Huang", "Kaizhu", ""]]}, {"id": "1810.12754", "submitter": "Guoqiang Zhong", "authors": "Guoqiang Zhong, Guohua Yue and Xiao Ling", "title": "Recurrent Attention Unit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Network (RNN) has been successfully applied in many sequence\nlearning problems. Such as handwriting recognition, image description, natural\nlanguage processing and video motion analysis. After years of development,\nresearchers have improved the internal structure of the RNN and introduced many\nvariants. Among others, Gated Recurrent Unit (GRU) is one of the most widely\nused RNN model. However, GRU lacks the capability of adaptively paying\nattention to certain regions or locations, so that it may cause information\nredundancy or loss during leaning. In this paper, we propose a RNN model,\ncalled Recurrent Attention Unit (RAU), which seamlessly integrates the\nattention mechanism into the interior of GRU by adding an attention gate. The\nattention gate can enhance GRU's ability to remember long-term memory and help\nmemory cells quickly discard unimportant content. RAU is capable of extracting\ninformation from the sequential data by adaptively selecting a sequence of\nregions or locations and pay more attention to the selected regions during\nlearning. Extensive experiments on image classification, sentiment\nclassification and language modeling show that RAU consistently outperforms GRU\nand other baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 14:09:19 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Zhong", "Guoqiang", ""], ["Yue", "Guohua", ""], ["Ling", "Xiao", ""]]}, {"id": "1810.12780", "submitter": "Di Jin", "authors": "Di Jin, Peter Szolovits", "title": "Advancing PICO Element Detection in Biomedical Text via Deep Neural\n  Networks", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In evidence-based medicine (EBM), defining a clinical question in terms of\nthe specific patient problem aids the physicians to efficiently identify\nappropriate resources and search for the best available evidence for medical\ntreatment. In order to formulate a well-defined, focused clinical question, a\nframework called PICO is widely used, which identifies the sentences in a given\nmedical text that belong to the four components typically reported in clinical\ntrials: Participants/Problem (P), Intervention (I), Comparison (C) and Outcome\n(O). In this work, we propose a novel deep learning model for recognizing PICO\nelements in biomedical abstracts. Based on the previous state-of-the-art\nbidirectional long-short term memory (biLSTM) plus conditional random field\n(CRF) architecture, we add another layer of biLSTM upon the sentence\nrepresentation vectors so that the contextual information from surrounding\nsentences can be gathered to help infer the interpretation of the current one.\nIn addition, we propose two methods to further generalize and improve the\nmodel: adversarial training and unsupervised pre-training over large corpora.\nWe tested our proposed approach over two benchmark datasets. One is the\nPubMed-PICO dataset, where our best results outperform the previous best by\n5.5%, 7.9%, and 5.8% for P, I, and O elements in terms of F1 score,\nrespectively. And for the other dataset named NICTA-PIBOSO, the improvements\nfor P/I/O elements are 2.4%, 13.6%, and 1.0% in F1 score, respectively.\nOverall, our proposed deep learning model can obtain unprecedented PICO element\ndetection accuracy while avoiding the need for any manual feature selection.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 14:44:24 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 02:38:02 GMT"}, {"version": "v3", "created": "Sat, 5 Oct 2019 17:26:41 GMT"}, {"version": "v4", "created": "Sun, 10 Nov 2019 07:57:16 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Jin", "Di", ""], ["Szolovits", "Peter", ""]]}, {"id": "1810.12836", "submitter": "Daniel Cer", "authors": "Muthuraman Chidambaram, Yinfei Yang, Daniel Cer, Steve Yuan, Yun-Hsuan\n  Sung, Brian Strope, Ray Kurzweil", "title": "Learning Cross-Lingual Sentence Representations via a Multi-task\n  Dual-Encoder Model", "comments": "Accepted at the 4th Workshop on Representation Learning for NLP\n  (RepL4NLP-2019)", "journal-ref": "In Proceedings of the 4th Workshop on Representation Learning for\n  NLP (RepL4NLP-2019)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant roadblock in multilingual neural language modeling is the lack\nof labeled non-English data. One potential method for overcoming this issue is\nlearning cross-lingual text representations that can be used to transfer the\nperformance from training on English tasks to non-English tasks, despite little\nto no task-specific non-English data. In this paper, we explore a natural setup\nfor learning cross-lingual sentence representations: the dual-encoder. We\nprovide a comprehensive evaluation of our cross-lingual representations on a\nnumber of monolingual, cross-lingual, and zero-shot/few-shot learning tasks,\nand also give an analysis of different learned cross-lingual embedding spaces.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 16:18:05 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 05:26:48 GMT"}, {"version": "v3", "created": "Fri, 21 Dec 2018 07:10:42 GMT"}, {"version": "v4", "created": "Thu, 1 Aug 2019 17:52:13 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Chidambaram", "Muthuraman", ""], ["Yang", "Yinfei", ""], ["Cer", "Daniel", ""], ["Yuan", "Steve", ""], ["Sung", "Yun-Hsuan", ""], ["Strope", "Brian", ""], ["Kurzweil", "Ray", ""]]}, {"id": "1810.12859", "submitter": "Jaejun Lee", "authors": "Jaejun Lee, Raphael Tang, Jimmy Lin", "title": "JavaScript Convolutional Neural Networks for Keyword Spotting in the\n  Browser: An Experimental Analysis", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Used for simple commands recognition on devices from smart routers to mobile\nphones, keyword spotting systems are everywhere. Ubiquitous as well are web\napplications, which have grown in popularity and complexity over the last\ndecade with significant improvements in usability under cross-platform\nconditions. However, despite their obvious advantage in natural language\ninteraction, voice-enabled web applications are still far and few between. In\nthis work, we attempt to bridge this gap by bringing keyword spotting\ncapabilities directly into the browser. To our knowledge, we are the first to\ndemonstrate a fully-functional implementation of convolutional neural networks\nin pure JavaScript that runs in any standards-compliant browser. We also apply\nnetwork slimming, a model compression technique, to explore the\naccuracy-efficiency tradeoffs, reporting latency measurements on a range of\ndevices and software. Overall, our robust, cross-device implementation for\nkeyword spotting realizes a new paradigm for serving neural network\napplications, and one of our slim models reduces latency by 66% with a minimal\ndecrease in accuracy of 4% from 94% to 90%.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 16:58:36 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Lee", "Jaejun", ""], ["Tang", "Raphael", ""], ["Lin", "Jimmy", ""]]}, {"id": "1810.12885", "submitter": "Sheng Zhang", "authors": "Sheng Zhang, Xiaodong Liu, Jingjing Liu, Jianfeng Gao, Kevin Duh and\n  Benjamin Van Durme", "title": "ReCoRD: Bridging the Gap between Human and Machine Commonsense Reading\n  Comprehension", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a large-scale dataset, ReCoRD, for machine reading comprehension\nrequiring commonsense reasoning. Experiments on this dataset demonstrate that\nthe performance of state-of-the-art MRC systems fall far behind human\nperformance. ReCoRD represents a challenge for future research to bridge the\ngap between human and machine commonsense reading comprehension. ReCoRD is\navailable at http://nlp.jhu.edu/record.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 17:32:16 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Zhang", "Sheng", ""], ["Liu", "Xiaodong", ""], ["Liu", "Jingjing", ""], ["Gao", "Jianfeng", ""], ["Duh", "Kevin", ""], ["Van Durme", "Benjamin", ""]]}, {"id": "1810.12897", "submitter": "Sumit Bhatia", "authors": "Sumit Bhatia and Deepak P", "title": "Topic-Specific Sentiment Analysis Can Help Identify Political Ideology", "comments": "Presented at EMNLP Workshop on Computational Approaches to\n  Subjectivity, Sentiment & Social Media Analysis, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ideological leanings of an individual can often be gauged by the sentiment\none expresses about different issues. We propose a simple framework that\nrepresents a political ideology as a distribution of sentiment polarities\ntowards a set of topics. This representation can then be used to detect\nideological leanings of documents (speeches, news articles, etc.) based on the\nsentiments expressed towards different topics. Experiments performed using a\nwidely used dataset show the promise of our proposed approach that achieves\ncomparable performance to other methods despite being much simpler and more\ninterpretable.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 17:49:46 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Bhatia", "Sumit", ""], ["P", "Deepak", ""]]}, {"id": "1810.12936", "submitter": "Kai Hui", "authors": "Canjia Li, Yingfei Sun, Ben He, Le Wang, Kai Hui, Andrew Yates, Le\n  Sun, Jungang Xu", "title": "NPRF: A Neural Pseudo Relevance Feedback Framework for Ad-hoc\n  Information Retrieval", "comments": "Full paper in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pseudo-relevance feedback (PRF) is commonly used to boost the performance of\ntraditional information retrieval (IR) models by using top-ranked documents to\nidentify and weight new query terms, thereby reducing the effect of\nquery-document vocabulary mismatches. While neural retrieval models have\nrecently demonstrated strong results for ad-hoc retrieval, combining them with\nPRF is not straightforward due to incompatibilities between existing PRF\napproaches and neural architectures. To bridge this gap, we propose an\nend-to-end neural PRF framework that can be used with existing neural IR models\nby embedding different neural models as building blocks. Extensive experiments\non two standard test collections confirm the effectiveness of the proposed NPRF\nframework in improving the performance of two state-of-the-art neural IR\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 18:03:12 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Li", "Canjia", ""], ["Sun", "Yingfei", ""], ["He", "Ben", ""], ["Wang", "Le", ""], ["Hui", "Kai", ""], ["Yates", "Andrew", ""], ["Sun", "Le", ""], ["Xu", "Jungang", ""]]}, {"id": "1810.12956", "submitter": "Iz Beltagy", "authors": "Iz Beltagy, Kyle Lo, Waleed Ammar", "title": "Combining Distant and Direct Supervision for Neural Relation Extraction", "comments": null, "journal-ref": "2019 Annual Conference of the North American Chapter of the\n  Association for Computational Linguistics (NAACL 2019)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In relation extraction with distant supervision, noisy labels make it\ndifficult to train quality models. Previous neural models addressed this\nproblem using an attention mechanism that attends to sentences that are likely\nto express the relations. We improve such models by combining the distant\nsupervision data with an additional directly-supervised data, which we use as\nsupervision for the attention weights. We find that joint training on both\ntypes of supervision leads to a better model because it improves the model's\nability to identify noisy sentences. In addition, we find that sigmoidal\nattention weights with max pooling achieves better performance over the\ncommonly used weighted average attention in this setup. Our proposed method\nachieves a new state-of-the-art result on the widely used FB-NYT dataset.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 18:31:16 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2019 22:07:38 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Beltagy", "Iz", ""], ["Lo", "Kyle", ""], ["Ammar", "Waleed", ""]]}, {"id": "1810.13024", "submitter": "Qiujia Li", "authors": "Qiujia Li, Preben Ness, Anton Ragni and Mark Gales", "title": "Bi-Directional Lattice Recurrent Neural Networks for Confidence\n  Estimation", "comments": "Accepted by ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard approach to mitigate errors made by an automatic speech\nrecognition system is to use confidence scores associated with each predicted\nword. In the simplest case, these scores are word posterior probabilities\nwhilst more complex schemes utilise bi-directional recurrent neural network\n(BiRNN) models. A number of upstream and downstream applications, however, rely\non confidence scores assigned not only to 1-best hypotheses but to all words\nfound in confusion networks or lattices. These include but are not limited to\nspeaker adaptation, semi-supervised training and information retrieval.\nAlthough word posteriors could be used in those applications as confidence\nscores, they are known to have reliability issues. To make improved confidence\nscores more generally available, this paper shows how BiRNNs can be extended\nfrom 1-best sequences to confusion network and lattice structures. Experiments\nare conducted using one of the Cambridge University submissions to the IARPA\nOpenKWS 2016 competition. The results show that confusion network and\nlattice-based BiRNNs can provide a significant improvement in confidence\nestimation.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 22:39:02 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 17:04:05 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Li", "Qiujia", ""], ["Ness", "Preben", ""], ["Ragni", "Anton", ""], ["Gales", "Mark", ""]]}, {"id": "1810.13025", "submitter": "Qiujia Li", "authors": "Anton Ragni, Qiujia Li, Mark Gales and Yu Wang", "title": "Confidence Estimation and Deletion Prediction Using Bidirectional\n  Recurrent Neural Networks", "comments": "Accepted as a conference paper at 2018 IEEE Workshop on Spoken\n  Language Technology (SLT 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard approach to assess reliability of automatic speech\ntranscriptions is through the use of confidence scores. If accurate, these\nscores provide a flexible mechanism to flag transcription errors for upstream\nand downstream applications. One challenging type of errors that recognisers\nmake are deletions. These errors are not accounted for by the standard\nconfidence estimation schemes and are hard to rectify in the upstream and\ndownstream processing. High deletion rates are prominent in limited resource\nand highly mismatched training/testing conditions studied under IARPA Babel and\nMaterial programs. This paper looks at the use of bidirectional recurrent\nneural networks to yield confidence estimates in predicted as well as deleted\nwords. Several simple schemes are examined for combination. To assess\nusefulness of this approach, the combined confidence score is examined for\nuntranscribed data selection that favours transcriptions with lower deletion\nerrors. Experiments are conducted using IARPA Babel/Material program languages.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 22:39:54 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Ragni", "Anton", ""], ["Li", "Qiujia", ""], ["Gales", "Mark", ""], ["Wang", "Yu", ""]]}, {"id": "1810.13033", "submitter": "Christopher Potts", "authors": "Atticus Geiger, Ignacio Cases, Lauri Karttunen, and Christopher Potts", "title": "Stress-Testing Neural Models of Natural Language Inference with\n  Multiply-Quantified Sentences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Standard evaluations of deep learning models for semantics using naturalistic\ncorpora are limited in what they can tell us about the fidelity of the learned\nrepresentations, because the corpora rarely come with good measures of semantic\ncomplexity. To overcome this limitation, we present a method for generating\ndata sets of multiply-quantified natural language inference (NLI) examples in\nwhich semantic complexity can be precisely characterized, and we use this\nmethod to show that a variety of common architectures for NLI inevitably fail\nto encode crucial information; only a model with forced lexical alignments\navoids this damaging information loss.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 23:31:50 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Geiger", "Atticus", ""], ["Cases", "Ignacio", ""], ["Karttunen", "Lauri", ""], ["Potts", "Christopher", ""]]}, {"id": "1810.13048", "submitter": "Junichi Yamagishi", "authors": "Cheng-I Lai, Alberto Abad, Korin Richmond, Junichi Yamagishi, Najim\n  Dehak, Simon King", "title": "Attentive Filtering Networks for Audio Replay Attack Detection", "comments": "Submitted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An attacker may use a variety of techniques to fool an automatic speaker\nverification system into accepting them as a genuine user. Anti-spoofing\nmethods meanwhile aim to make the system robust against such attacks. The\nASVspoof 2017 Challenge focused specifically on replay attacks, with the\nintention of measuring the limits of replay attack detection as well as\ndeveloping countermeasures against them. In this work, we propose our replay\nattacks detection system - Attentive Filtering Network, which is composed of an\nattention-based filtering mechanism that enhances feature representations in\nboth the frequency and time domains, and a ResNet-based classifier. We show\nthat the network enables us to visualize the automatically acquired feature\nrepresentations that are helpful for spoofing detection. Attentive Filtering\nNetwork attains an evaluation EER of 8.99$\\%$ on the ASVspoof 2017 Version 2.0\ndataset. With system fusion, our best system further obtains a 30$\\%$ relative\nimprovement over the ASVspoof 2017 enhanced baseline system.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 00:23:16 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Lai", "Cheng-I", ""], ["Abad", "Alberto", ""], ["Richmond", "Korin", ""], ["Yamagishi", "Junichi", ""], ["Dehak", "Najim", ""], ["King", "Simon", ""]]}, {"id": "1810.13083", "submitter": "Yujie Qian", "authors": "Yujie Qian, Enrico Santus, Zhijing Jin, Jiang Guo, Regina Barzilay", "title": "GraphIE: A Graph-Based Framework for Information Extraction", "comments": "NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most modern Information Extraction (IE) systems are implemented as sequential\ntaggers and only model local dependencies. Non-local and non-sequential context\nis, however, a valuable source of information to improve predictions. In this\npaper, we introduce GraphIE, a framework that operates over a graph\nrepresenting a broad set of dependencies between textual units (i.e. words or\nsentences). The algorithm propagates information between connected nodes\nthrough graph convolutions, generating a richer representation that can be\nexploited to improve word-level predictions. Evaluation on three different\ntasks --- namely textual, social media and visual information extraction ---\nshows that GraphIE consistently outperforms the state-of-the-art sequence\ntagging model by a significant margin.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 02:52:21 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 22:10:33 GMT"}, {"version": "v3", "created": "Fri, 5 Apr 2019 14:46:09 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Qian", "Yujie", ""], ["Santus", "Enrico", ""], ["Jin", "Zhijing", ""], ["Guo", "Jiang", ""], ["Barzilay", "Regina", ""]]}, {"id": "1810.13088", "submitter": "Yan Yin", "authors": "Yan Yin, Ramon Prieto, Bin Wang, Jianwei Zhou, Yiwei Gu, Yang Liu, Hui\n  Lin", "title": "Attention-based sequence-to-sequence model for speech recognition:\n  development of state-of-the-art system on LibriSpeech and its application to\n  non-native English", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has shown that attention-based sequence-to-sequence models\nsuch as Listen, Attend, and Spell (LAS) yield comparable results to\nstate-of-the-art ASR systems on various tasks. In this paper, we describe the\ndevelopment of such a system and demonstrate its performance on two tasks:\nfirst we achieve a new state-of-the-art word error rate of 3.43% on the test\nclean subset of LibriSpeech English data; second on non-native English speech,\nincluding both read speech and spontaneous speech, we obtain very competitive\nresults compared to a conventional system built with the most updated Kaldi\nrecipe.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 03:10:37 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 19:08:34 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Yin", "Yan", ""], ["Prieto", "Ramon", ""], ["Wang", "Bin", ""], ["Zhou", "Jianwei", ""], ["Gu", "Yiwei", ""], ["Liu", "Yang", ""], ["Lin", "Hui", ""]]}, {"id": "1810.13091", "submitter": "Wei Zou", "authors": "Ne Luo, Dongwei Jiang, Shuaijiang Zhao, Caixia Gong, Wei Zou, Xiangang\n  Li", "title": "Towards End-to-End Code-Switching Speech Recognition", "comments": "5 pages, submitted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code-switching speech recognition has attracted an increasing interest\nrecently, but the need for expert linguistic knowledge has always been a big\nissue. End-to-end automatic speech recognition (ASR) simplifies the building of\nASR systems considerably by predicting graphemes or characters directly from\nacoustic input. In the mean time, the need of expert linguistic knowledge is\nalso eliminated, which makes it an attractive choice for code-switching ASR.\nThis paper presents a hybrid CTC-Attention based end-to-end Mandarin-English\ncode-switching (CS) speech recognition system and studies the effect of hybrid\nCTC-Attention based models, different modeling units, the inclusion of language\nidentification and different decoding strategies on the task of code-switching\nASR. On the SEAME corpus, our system achieves a mixed error rate (MER) of\n34.24%.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 03:44:21 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 09:47:20 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Luo", "Ne", ""], ["Jiang", "Dongwei", ""], ["Zhao", "Shuaijiang", ""], ["Gong", "Caixia", ""], ["Zou", "Wei", ""], ["Li", "Xiangang", ""]]}, {"id": "1810.13097", "submitter": "Kim Anh Nguyen", "authors": "Kim Anh Nguyen and Ngan Dong and Cam-Tu Nguyen", "title": "Attentive Neural Network for Named Entity Recognition in Vietnamese", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an attentive neural network for the task of named entity\nrecognition in Vietnamese. The proposed attentive neural model makes use of\ncharacter-based language models and word embeddings to encode words as vector\nrepresentations. A neural network architecture of encoder, attention, and\ndecoder layers is then utilized to encode knowledge of input sentences and to\nlabel entity tags. The experimental results show that the proposed attentive\nneural network achieves the state-of-the-art results on the benchmark named\nentity recognition datasets in Vietnamese in comparison to both hand-crafted\nfeatures based models and neural models.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 04:05:05 GMT"}, {"version": "v2", "created": "Sun, 9 Jun 2019 11:40:02 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Nguyen", "Kim Anh", ""], ["Dong", "Ngan", ""], ["Nguyen", "Cam-Tu", ""]]}, {"id": "1810.13107", "submitter": "Andros Tjandra", "authors": "Andros Tjandra, Sakriani Sakti, Satoshi Nakamura", "title": "End-to-End Feedback Loss in Speech Chain Framework via Straight-Through\n  Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The speech chain mechanism integrates automatic speech recognition (ASR) and\ntext-to-speech synthesis (TTS) modules into a single cycle during training. In\nour previous work, we applied a speech chain mechanism as a semi-supervised\nlearning. It provides the ability for ASR and TTS to assist each other when\nthey receive unpaired data and let them infer the missing pair and optimize the\nmodel with reconstruction loss. If we only have speech without transcription,\nASR generates the most likely transcription from the speech data, and then TTS\nuses the generated transcription to reconstruct the original speech features.\nHowever, in previous papers, we just limited our back-propagation to the\nclosest module, which is the TTS part. One reason is that back-propagating the\nerror through the ASR is challenging due to the output of the ASR are discrete\ntokens, creating non-differentiability between the TTS and ASR. In this paper,\nwe address this problem and describe how to thoroughly train a speech chain\nend-to-end for reconstruction loss using a straight-through estimator (ST).\nExperimental results revealed that, with sampling from ST-Gumbel-Softmax, we\nwere able to update ASR parameters and improve the ASR performances by 11\\%\nrelative CER reduction compared to the baseline.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 05:05:37 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Tjandra", "Andros", ""], ["Sakti", "Sakriani", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "1810.13113", "submitter": "Won Ik Cho", "authors": "Won Ik Cho, Sung Jun Cheon, Woo Hyun Kang, Ji Won Kim, Nam Soo Kim", "title": "Giving Space to Your Message: Assistive Word Segmentation for the\n  Electronic Typing of Digital Minorities", "comments": "DIS 2021 Camera-ready", "journal-ref": null, "doi": "10.1145/3461778.3462078", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For readability and disambiguation of the written text, appropriate word\nsegmentation is recommended for documentation, and it also holds for the\ndigitized texts. If the language is agglutinative while far from scriptio\ncontinua, for instance in the Korean language, the problem becomes more\nsignificant. However, some device users these days find it challenging to\ncommunicate via key stroking, not only for handicap but also for being\nunskilled. In this study, we propose a real-time assistive technology that\nutilizes an automatic word segmentation, designed for digital minorities who\nare not familiar with electronic typing. We propose a data-driven system\ntrained upon a spoken Korean language corpus with various non-canonical\nexpressions and dialects, guaranteeing the comprehension of contextual\ninformation. Through quantitative and qualitative comparison with other text\nprocessing toolkits, we show the reliability of the proposed system and its fit\nwith colloquial and non-normalized texts, which fulfills the aim of supportive\ntechnology.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 05:21:17 GMT"}, {"version": "v2", "created": "Tue, 7 May 2019 11:04:42 GMT"}, {"version": "v3", "created": "Tue, 4 May 2021 06:17:31 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Cho", "Won Ik", ""], ["Cheon", "Sung Jun", ""], ["Kang", "Woo Hyun", ""], ["Kim", "Ji Won", ""], ["Kim", "Nam Soo", ""]]}, {"id": "1810.13181", "submitter": "Yiqing Hua", "authors": "Yiqing Hua, Cristian Danescu-Niculescu-Mizil, Dario Taraborelli,\n  Nithum Thain, Jeffery Sorensen, Lucas Dixon", "title": "WikiConv: A Corpus of the Complete Conversational History of a Large\n  Online Collaborative Community", "comments": null, "journal-ref": "Proceedings of the 2018 Conference on Empirical Methods in Natural\n  Language Processing", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We present a corpus that encompasses the complete history of conversations\nbetween contributors to Wikipedia, one of the largest online collaborative\ncommunities. By recording the intermediate states of conversations---including\nnot only comments and replies, but also their modifications, deletions and\nrestorations---this data offers an unprecedented view of online conversation.\nThis level of detail supports new research questions pertaining to the process\n(and challenges) of large-scale online collaboration. We illustrate the corpus'\npotential with two case studies that highlight new perspectives on earlier\nwork. First, we explore how a person's conversational behavior depends on how\nthey relate to the discussion's venue. Second, we show that community\nmoderation of toxic behavior happens at a higher rate than previously\nestimated. Finally the reconstruction framework is designed to be language\nagnostic, and we show that it can extract high quality conversational data in\nboth Chinese and English.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 09:46:11 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Hua", "Yiqing", ""], ["Danescu-Niculescu-Mizil", "Cristian", ""], ["Taraborelli", "Dario", ""], ["Thain", "Nithum", ""], ["Sorensen", "Jeffery", ""], ["Dixon", "Lucas", ""]]}, {"id": "1810.13223", "submitter": "Ankur Padia", "authors": "Ankur Padia, Francis Ferraro, and Tim Finin", "title": "SURFACE: Semantically Rich Fact Validation with Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Judging the veracity of a sentence making one or more claims is an important\nand challenging problem with many dimensions. The recent FEVER task asked\nparticipants to classify input sentences as either SUPPORTED, REFUTED or\nNotEnoughInfo using Wikipedia as a source of true facts. SURFACE does this task\nand explains its decision through a selection of sentences from the trusted\nsource. Our multi-task neural approach uses semantic lexical frames from\nFrameNet to jointly (i) find relevant evidential sentences in the trusted\nsource and (ii) use them to classify the input sentence's veracity. An\nevaluation of our efficient three-parameter model on the FEVER dataset showed\nan improvement of 90% over the state-of-the-art baseline on retrieving relevant\nsentences and a 70% relative improvement in classification.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 11:38:40 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Padia", "Ankur", ""], ["Ferraro", "Francis", ""], ["Finin", "Tim", ""]]}, {"id": "1810.13320", "submitter": "Longyue Wang", "authors": "Baosong Yang, Longyue Wang, Derek F. Wong, Lidia S. Chao, Zhaopeng Tu", "title": "Convolutional Self-Attention Network", "comments": "The least version of this paper has been uploaded to another link:\n  arXiv:1904.03107", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-attention network (SAN) has recently attracted increasing interest due\nto its fully parallelized computation and flexibility in modeling dependencies.\nIt can be further enhanced with multi-headed attention mechanism by allowing\nthe model to jointly attend to information from different representation\nsubspaces at different positions (Vaswani et al., 2017). In this work, we\npropose a novel convolutional self-attention network (CSAN), which offers SAN\nthe abilities to 1) capture neighboring dependencies, and 2) model the\ninteraction between multiple attention heads. Experimental results on WMT14\nEnglish-to-German translation task demonstrate that the proposed approach\noutperforms both the strong Transformer baseline and other existing works on\nenhancing the locality of SAN. Comparing with previous work, our model does not\nintroduce any new parameters.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 14:58:30 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2019 09:15:30 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Yang", "Baosong", ""], ["Wang", "Longyue", ""], ["Wong", "Derek F.", ""], ["Chao", "Lidia S.", ""], ["Tu", "Zhaopeng", ""]]}, {"id": "1810.13327", "submitter": "Sebastian Schuster", "authors": "Sebastian Schuster, Sonal Gupta, Rushin Shah, Mike Lewis", "title": "Cross-Lingual Transfer Learning for Multilingual Task Oriented Dialog", "comments": "11 pages, to be presented at NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the first steps in the utterance interpretation pipeline of many\ntask-oriented conversational AI systems is to identify user intents and the\ncorresponding slots. Since data collection for machine learning models for this\ntask is time-consuming, it is desirable to make use of existing data in a\nhigh-resource language to train models in low-resource languages. However,\ndevelopment of such models has largely been hindered by the lack of\nmultilingual training data. In this paper, we present a new data set of 57k\nannotated utterances in English (43k), Spanish (8.6k) and Thai (5k) across the\ndomains weather, alarm, and reminder. We use this data set to evaluate three\ndifferent cross-lingual transfer methods: (1) translating the training data,\n(2) using cross-lingual pre-trained embeddings, and (3) a novel method of using\na multilingual machine translation encoder as contextual word representations.\nWe find that given several hundred training examples in the the target\nlanguage, the latter two methods outperform translating the training data.\nFurther, in very low-resource settings, multilingual contextual word\nrepresentations give better results than using cross-lingual static embeddings.\nWe also compare the cross-lingual methods to using monolingual resources in the\nform of contextual ELMo representations and find that given just small amounts\nof target language data, this method outperforms all cross-lingual methods,\nwhich highlights the need for more sophisticated cross-lingual methods.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 15:15:00 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 21:33:00 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Schuster", "Sebastian", ""], ["Gupta", "Sonal", ""], ["Shah", "Rushin", ""], ["Lewis", "Mike", ""]]}, {"id": "1810.13391", "submitter": "Su Wang", "authors": "Su Wang and Eric Holgate and Greg Durrett and Katrin Erk", "title": "Picking Apart Story Salads", "comments": "Accepted at EMNLP 2018 (long paper)", "journal-ref": "Empirical Methods in Natural Language Processing 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During natural disasters and conflicts, information about what happened is\noften confusing, messy, and distributed across many sources. We would like to\nbe able to automatically identify relevant information and assemble it into\ncoherent narratives of what happened. To make this task accessible to neural\nmodels, we introduce Story Salads, mixtures of multiple documents that can be\ngenerated at scale. By exploiting the Wikipedia hierarchy, we can generate\nsalads that exhibit challenging inference problems. Story salads give rise to a\nnovel, challenging clustering task, where the objective is to group sentences\nfrom the same narratives. We demonstrate that simple bag-of-words similarity\nclustering falls short on this task and that it is necessary to take into\naccount global context and coherence.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 16:38:55 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Wang", "Su", ""], ["Holgate", "Eric", ""], ["Durrett", "Greg", ""], ["Erk", "Katrin", ""]]}, {"id": "1810.13407", "submitter": "Hao Tang", "authors": "Hao Tang and James Glass", "title": "On The Inductive Bias of Words in Acoustics-to-Word Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustics-to-word models are end-to-end speech recognizers that use words as\ntargets without relying on pronunciation dictionaries or graphemes. These\nmodels are notoriously difficult to train due to the lack of linguistic\nknowledge. It is also unclear how the amount of training data impacts the\noptimization and generalization of such models. In this work, we study the\noptimization and generalization of acoustics-to-word models under different\namounts of training data. In addition, we study three types of inductive bias,\nleveraging a pronunciation dictionary, word boundary annotations, and\nconstraints on word durations. We find that constraining word durations leads\nto the most improvement. Finally, we analyze the word embedding space learned\nby the model, and find that the space has a structure dominated by the\npronunciation of words. This suggests that the contexts of words, instead of\ntheir phonetic structure, should be the future focus of inductive bias in\nacoustics-to-word models.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 17:07:14 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 20:51:27 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Tang", "Hao", ""], ["Glass", "James", ""]]}, {"id": "1810.13409", "submitter": "Ofir Press", "authors": "Ofir Press, Noah A. Smith", "title": "You May Not Need Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In NMT, how far can we get without attention and without separate encoding\nand decoding? To answer that question, we introduce a recurrent neural\ntranslation model that does not use attention and does not have a separate\nencoder and decoder. Our eager translation model is low-latency, writing target\ntokens as soon as it reads the first source token, and uses constant memory\nduring decoding. It performs on par with the standard attention-based model of\nBahdanau et al. (2014), and better on long sentences.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 17:09:37 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Press", "Ofir", ""], ["Smith", "Noah A.", ""]]}, {"id": "1810.13414", "submitter": "Gerasimos Lampouras", "authors": "Gerasimos Lampouras and Ion Androutsopoulos", "title": "Extracting Linguistic Resources from the Web for Concept-to-Text\n  Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many concept-to-text generation systems require domain-specific linguistic\nresources to produce high quality texts, but manually constructing these\nresources can be tedious and costly. Focusing on NaturalOWL, a publicly\navailable state of the art natural language generator for OWL ontologies, we\npropose methods to extract from the Web sentence plans and natural language\nnames, two of the most important types of domain-specific linguistic resources\nused by the generator. Experiments show that texts generated using linguistic\nresources extracted by our methods in a semi-automatic manner, with minimal\nhuman involvement, are perceived as being almost as good as texts generated\nusing manually authored linguistic resources, and much better than texts\nproduced by using linguistic resources extracted from the relation and entity\nidentifiers of the ontology.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 17:23:05 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Lampouras", "Gerasimos", ""], ["Androutsopoulos", "Ion", ""]]}, {"id": "1810.13441", "submitter": "Kai Sun", "authors": "Kai Sun, Dian Yu, Dong Yu, Claire Cardie", "title": "Improving Machine Reading Comprehension with General Reading Strategies", "comments": "To appear in NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reading strategies have been shown to improve comprehension levels,\nespecially for readers lacking adequate prior knowledge. Just as the process of\nknowledge accumulation is time-consuming for human readers, it is\nresource-demanding to impart rich general domain knowledge into a deep language\nmodel via pre-training. Inspired by reading strategies identified in cognitive\nscience, and given limited computational resources -- just a pre-trained model\nand a fixed number of training instances -- we propose three general strategies\naimed to improve non-extractive machine reading comprehension (MRC): (i) BACK\nAND FORTH READING that considers both the original and reverse order of an\ninput sequence, (ii) HIGHLIGHTING, which adds a trainable embedding to the text\nembedding of tokens that are relevant to the question and candidate answers,\nand (iii) SELF-ASSESSMENT that generates practice questions and candidate\nanswers directly from the text in an unsupervised manner.\n  By fine-tuning a pre-trained language model (Radford et al., 2018) with our\nproposed strategies on the largest general domain multiple-choice MRC dataset\nRACE, we obtain a 5.8% absolute increase in accuracy over the previous best\nresult achieved by the same pre-trained model fine-tuned on RACE without the\nuse of strategies. We further fine-tune the resulting model on a target MRC\ntask, leading to an absolute improvement of 6.2% in average accuracy over\nprevious state-of-the-art approaches on six representative non-extractive MRC\ndatasets from different domains (i.e., ARC, OpenBookQA, MCTest, SemEval-2018\nTask 11, ROCStories, and MultiRC). These results demonstrate the effectiveness\nof our proposed strategies and the versatility and general applicability of our\nfine-tuned models that incorporate these strategies. Core code is available at\nhttps://github.com/nlpdata/strategy/.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 17:54:37 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 22:06:59 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Sun", "Kai", ""], ["Yu", "Dian", ""], ["Yu", "Dong", ""], ["Cardie", "Claire", ""]]}]