[{"id": "2009.00091", "submitter": "Jon Saad-Falcon", "authors": "Jon Saad-Falcon, Omar Shaikh, Zijie J. Wang, Austin P. Wright, Sasha\n  Richardson, and Duen Horng Chau", "title": "Mapping Researchers with PeopleMap", "comments": "2020 IEEE Visualization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering research expertise at universities can be a difficult task.\nDirectories routinely become outdated, and few help in visually summarizing\nresearchers' work or supporting the exploration of shared interests among\nresearchers. This results in lost opportunities for both internal and external\nentities to discover new connections, nurture research collaboration, and\nexplore the diversity of research. To address this problem, at Georgia Tech, we\nhave been developing PeopleMap, an open-source interactive web-based tool that\nuses natural language processing (NLP) to create visual maps for researchers\nbased on their research interests and publications. Requiring only the\nresearchers' Google Scholar profiles as input, PeopleMap generates and\nvisualizes embeddings for the researchers, significantly reducing the need for\nmanual curation of publication information. To encourage and facilitate easy\nadoption and extension of PeopleMap, we have open-sourced it under the\npermissive MIT license at https://github.com/poloclub/people-map. PeopleMap has\nreceived positive feedback and enthusiasm for expanding its adoption across\nGeorgia Tech.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 20:46:27 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Saad-Falcon", "Jon", ""], ["Shaikh", "Omar", ""], ["Wang", "Zijie J.", ""], ["Wright", "Austin P.", ""], ["Richardson", "Sasha", ""], ["Chau", "Duen Horng", ""]]}, {"id": "2009.00106", "submitter": "Debayan Banerjee", "authors": "Debayan Banerjee, Debanjan Chaudhuri, Mohnish Dubey, Jens Lehmann", "title": "PNEL: Pointer Network based End-To-End Entity Linking over Knowledge\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question Answering systems are generally modelled as a pipeline consisting of\na sequence of steps. In such a pipeline, Entity Linking (EL) is often the first\nstep. Several EL models first perform span detection and then entity\ndisambiguation. In such models errors from the span detection phase cascade to\nlater steps and result in a drop of overall accuracy. Moreover, lack of gold\nentity spans in training data is a limiting factor for span detector training.\nHence the movement towards end-to-end EL models began where no separate span\ndetection step is involved. In this work we present a novel approach to\nend-to-end EL by applying the popular Pointer Network model, which achieves\ncompetitive performance. We demonstrate this in our evaluation over three\ndatasets on the Wikidata Knowledge Graph.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2020 21:15:28 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Banerjee", "Debayan", ""], ["Chaudhuri", "Debanjan", ""], ["Dubey", "Mohnish", ""], ["Lehmann", "Jens", ""]]}, {"id": "2009.00234", "submitter": "Ukachi Osisiogu", "authors": "Ukachi Osisiogu", "title": "Semantic Sentiment Analysis Based on Probabilistic Graphical Models and\n  Recurrent Neural Network", "comments": "74 pages, Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment Analysis is the task of classifying documents based on the\nsentiments expressed in textual form, this can be achieved by using lexical and\nsemantic methods. The purpose of this study is to investigate the use of\nsemantics to perform sentiment analysis based on probabilistic graphical models\nand recurrent neural networks. In the empirical evaluation, the classification\nperformance of the graphical models was compared with some traditional machine\nlearning classifiers and a recurrent neural network. The datasets used for the\nexperiments were IMDB movie reviews, Amazon Consumer Product reviews, and\nTwitter Review datasets. After this empirical study, we conclude that the\ninclusion of semantics for sentiment analysis tasks can greatly improve the\nperformance of a classifier, as the semantic feature extraction methods reduce\nuncertainties in classification resulting in more accurate predictions.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2020 11:59:00 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Osisiogu", "Ukachi", ""]]}, {"id": "2009.00331", "submitter": "Fatima N. AL-Aswadi", "authors": "Fatima N. AL-Aswadi, Huah Yong Chan, and Keng Hoon Gan", "title": "Extracting Semantic Concepts and Relations from Scientific Publications\n  by Using Deep Learning", "comments": "Proposal", "journal-ref": null, "doi": "10.1007/978-3-030-70713-2_35", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the large volume of unstructured data that increases constantly on the\nweb, the motivation of representing the knowledge in this data in the\nmachine-understandable form is increased. Ontology is one of the major\ncornerstones of representing the information in a more meaningful way on the\nsemantic Web. The current ontology repositories are quite limited either for\ntheir scope or for currentness. In addition, the current ontology extraction\nsystems have many shortcomings and drawbacks, such as using a small dataset,\ndepending on a large amount predefined patterns to extract semantic relations,\nand extracting a very few types of relations. The aim of this paper is to\nintroduce a proposal of automatically extracting semantic concepts and\nrelations from scientific publications. This paper suggests new types of\nsemantic relations and points out of using deep learning (DL) models for\nsemantic relation extraction.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 10:19:18 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 14:27:49 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["AL-Aswadi", "Fatima N.", ""], ["Chan", "Huah Yong", ""], ["Gan", "Keng Hoon", ""]]}, {"id": "2009.00429", "submitter": "Jean-Marc Luck", "authors": "Anita Mehta, Jean-Marc Luck", "title": "Hearings and mishearings: decrypting the spoken word", "comments": "21 pages, 4 figures, 3 tables. To appear in Advances in Complex\n  Systems", "journal-ref": "Adv. Complex Systems 23, 2050008 (2020)", "doi": "10.1142/S0219525920500083", "report-no": null, "categories": "cs.CL cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a model of the speech perception of individual words in the\npresence of mishearings. This phenomenological approach is based on concepts\nused in linguistics, and provides a formalism that is universal across\nlanguages. We put forward an efficient two-parameter form for the word length\ndistribution, and introduce a simple representation of mishearings, which we\nuse in our subsequent modelling of word recognition. In a context-free\nscenario, word recognition often occurs via anticipation when, part-way into a\nword, we can correctly guess its full form. We give a quantitative estimate of\nthis anticipation threshold when no mishearings occur, in terms of model\nparameters. As might be expected, the whole anticipation effect disappears when\nthere are sufficiently many mishearings. Our global approach to the problem of\nspeech perception is in the spirit of an optimisation problem. We show for\ninstance that speech perception is easy when the word length is less than a\nthreshold, to be identified with a static transition, and hard otherwise. We\nextend this to the dynamics of word recognition, proposing an intuitive\napproach highlighting the distinction between individual, isolated mishearings\nand clusters of contiguous mishearings. At least in some parameter range, a\ndynamical transition is manifest well before the static transition is reached,\nas is the case for many other examples of complex systems.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 13:58:51 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Mehta", "Anita", ""], ["Luck", "Jean-Marc", ""]]}, {"id": "2009.00590", "submitter": "Ori Ernst", "authors": "Ori Ernst, Ori Shapira, Ramakanth Pasunuru, Michael Lepioshkin, Jacob\n  Goldberger, Mohit Bansal, Ido Dagan", "title": "SuperPAL: Supervised Proposition ALignment for Multi-Document\n  Summarization and Derivative Sub-Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-document summarization (MDS) is a challenging task, often decomposed to\nsubtasks of salience and redundancy detection, followed by generation. While\nalignment of spans between reference summaries and source documents has been\nleveraged for training component tasks, the underlying alignment step was never\nindependently addressed or evaluated. We advocate developing high quality\nsource-reference alignment algorithms, that can be applied to recent\nlarge-scale datasets to obtain useful \"silver\", i.e. approximate, training\ndata. As a first step, we present an annotation methodology by which we create\ngold standard development and test sets for summary-source alignment, and\nsuggest its utility for tuning and evaluating effective alignment algorithms,\nas well as for properly evaluating MDS subtasks. Second, we introduce a new\nlarge-scale alignment dataset for training, with which an automatic alignment\nmodel was trained. This aligner achieves higher coherency with the reference\nsummary than previous aligners used for summarization, and gets significantly\nhigher ROUGE results when replacing a simpler aligner in a competitive\nsummarization model. Finally, we release three additional datasets (for\nsalience, clustering and generation), naturally derived from our alignment\ndatasets. Furthermore, these datasets can be derived from any summarization\ndataset automatically after extracting alignments with our trained aligner.\nHence, they can be utilized for training summarization sub-tasks.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 17:27:12 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Ernst", "Ori", ""], ["Shapira", "Ori", ""], ["Pasunuru", "Ramakanth", ""], ["Lepioshkin", "Michael", ""], ["Goldberger", "Jacob", ""], ["Bansal", "Mohit", ""], ["Dagan", "Ido", ""]]}, {"id": "2009.00596", "submitter": "Salvatore Giorgi", "authors": "Salvatore Giorgi, Sharath Chandra Guntuku, Muhammad Rahman, McKenzie\n  Himelein-Wachowiak, Amy Kwarteng, Brenda Curtis", "title": "Twitter Corpus of the #BlackLivesMatter Movement And Counter Protests:\n  2013 to 2020", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Black Lives Matter (BLM) is a grassroots movement protesting violence towards\nBlack individuals and communities with a focus on police brutality. The\nmovement has gained significant media and political attention following the\nkillings of Ahmaud Arbery, Breonna Taylor, and George Floyd and the shooting of\nJacob Blake in 2020. Due to its decentralized nature, the #BlackLivesMatter\nsocial media hashtag has come to both represent the movement and been used as a\ncall to action. Similar hashtags have appeared to counter the BLM movement,\nsuch as #AllLivesMatter and #BlueLivesMatter. We introduce a data set of 41.8\nmillion tweets from 10 million users which contain one of the following\nkeywords: BlackLivesMatter, AllLivesMatter and BlueLivesMatter. This data set\ncontains all currently available tweets from the beginning of the BLM movement\nin 2013 to June 2020. We summarize the data set and show temporal trends in use\nof both the BlackLivesMatter keyword and keywords associated with counter\nmovements. In the past, similarly themed, though much smaller in scope, BLM\ndata sets have been used for studying discourse in protest and counter protest\nmovements, predicting retweets, examining the role of social media in protest\nmovements and exploring narrative agency. This paper open-sources a large-scale\ndata set to facilitate research in the areas of computational social science,\ncommunications, political science, natural language processing, and machine\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 17:37:39 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 16:20:16 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Giorgi", "Salvatore", ""], ["Guntuku", "Sharath Chandra", ""], ["Rahman", "Muhammad", ""], ["Himelein-Wachowiak", "McKenzie", ""], ["Kwarteng", "Amy", ""], ["Curtis", "Brenda", ""]]}, {"id": "2009.00611", "submitter": "Krutarth Patel", "authors": "Krutarth Patel, Cornelia Caragea, Mark Phillips, Nathaniel Fox", "title": "Identifying Documents In-Scope of a Collection from Web Archives", "comments": "10 pages", "journal-ref": "In Proceedings of the ACM/IEEE Joint Conference on Digital\n  Libraries in 2020 (JCDL 2020)", "doi": "10.1145/3383583.3398540", "report-no": null, "categories": "cs.IR cs.CL cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web archive data usually contains high-quality documents that are very useful\nfor creating specialized collections of documents, e.g., scientific digital\nlibraries and repositories of technical reports. In doing so, there is a\nsubstantial need for automatic approaches that can distinguish the documents of\ninterest for a collection out of the huge number of documents collected by web\narchiving institutions. In this paper, we explore different learning models and\nfeature representations to determine the best performing ones for identifying\nthe documents of interest from the web archived data. Specifically, we study\nboth machine learning and deep learning models and \"bag of words\" (BoW)\nfeatures extracted from the entire document or from specific portions of the\ndocument, as well as structural features that capture the structure of\ndocuments. We focus our evaluation on three datasets that we created from three\ndifferent Web archives. Our experimental results show that the BoW classifiers\nthat focus only on specific portions of the documents (rather than the full\ntext) outperform all compared methods on all three datasets.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 16:22:23 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Patel", "Krutarth", ""], ["Caragea", "Cornelia", ""], ["Phillips", "Mark", ""], ["Fox", "Nathaniel", ""]]}, {"id": "2009.00672", "submitter": "Ilia Rushkin", "authors": "Ilia Rushkin", "title": "Document Similarity from Vector Space Densities", "comments": "12 pages, 3 figures", "journal-ref": "In: Arai K., Kapoor S., Bhatia R. (eds) Intelligent Systems and\n  Applications. IntelliSys 2020. Advances in Intelligent Systems and Computing,\n  vol 1251. Springer, Cham", "doi": "10.1007/978-3-030-55187-2_14", "report-no": null, "categories": "cs.CL cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a computationally light method for estimating similarities between\ntext documents, which we call the density similarity (DS) method. The method is\nbased on a word embedding in a high-dimensional Euclidean space and on kernel\nregression, and takes into account semantic relations among words. We find that\nthe accuracy of this method is virtually the same as that of a state-of-the-art\nmethod, while the gain in speed is very substantial. Additionally, we introduce\ngeneralized versions of the top-k accuracy metric and of the Jaccard metric of\nagreement between similarity models.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 19:28:51 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Rushkin", "Ilia", ""]]}, {"id": "2009.00694", "submitter": "Wilson Lau", "authors": "Wilson Lau, Laura Aaltonen, Martin Gunn, Meliha Yetisgen", "title": "Automatic Assignment of Radiology Examination Protocols Using\n  Pre-trained Language Models with Knowledge Distillation", "comments": "accepted at American Medical Informatics Association symposium 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selecting radiology examination protocol is a repetitive, and time-consuming\nprocess. In this paper, we present a deep learning approach to automatically\nassign protocols to computer tomography examinations, by pre-training a\ndomain-specific BERT model ($BERT_{rad}$). To handle the high data imbalance\nacross exam protocols, we used a knowledge distillation approach that\nup-sampled the minority classes through data augmentation. We compared\nclassification performance of the described approach with the statistical\nn-gram models using Support Vector Machine (SVM), Gradient Boosting Machine\n(GBM), and Random Forest (RF) classifiers, as well as the Google's\n$BERT_{base}$ model. SVM, GBM and RF achieved macro-averaged F1 scores of 0.45,\n0.45, and 0.6 while $BERT_{base}$ and $BERT_{rad}$ achieved 0.61 and 0.63.\nKnowledge distillation improved overall performance on the minority classes,\nachieving a F1 score of 0.66.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 20:57:41 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 18:05:03 GMT"}, {"version": "v3", "created": "Tue, 6 Jul 2021 20:24:08 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Lau", "Wilson", ""], ["Aaltonen", "Laura", ""], ["Gunn", "Martin", ""], ["Yetisgen", "Meliha", ""]]}, {"id": "2009.00751", "submitter": "Tushar Khot", "authors": "Tushar Khot and Daniel Khashabi and Kyle Richardson and Peter Clark\n  and Ashish Sabharwal", "title": "Text Modular Networks: Learning to Decompose Tasks in the Language of\n  Existing Models", "comments": "Accepted to NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general framework called Text Modular Networks(TMNs) for\nbuilding interpretable systems that learn to solve complex tasks by decomposing\nthem into simpler ones solvable by existing models. To ensure solvability of\nsimpler tasks, TMNs learn the textual input-output behavior (i.e., language) of\nexisting models through their datasets. This differs from prior\ndecomposition-based approaches which, besides being designed specifically for\neach complex task, produce decompositions independent of existing sub-models.\nSpecifically, we focus on Question Answering (QA) and show how to train a\nnext-question generator to sequentially produce sub-questions targeting\nappropriate sub-models, without additional human annotation. These\nsub-questions and answers provide a faithful natural language explanation of\nthe model's reasoning. We use this framework to build ModularQA, a system that\ncan answer multi-hop reasoning questions by decomposing them into sub-questions\nanswerable by a neural factoid single-span QA model and a symbolic calculator.\nOur experiments show that ModularQA is more versatile than existing explainable\nsystems for DROP and HotpotQA datasets, is more robust than state-of-the-art\nblackbox (uninterpretable) systems, and generates more understandable and\ntrustworthy explanations compared to prior work.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 23:45:42 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 21:58:08 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Khot", "Tushar", ""], ["Khashabi", "Daniel", ""], ["Richardson", "Kyle", ""], ["Clark", "Peter", ""], ["Sabharwal", "Ashish", ""]]}, {"id": "2009.00829", "submitter": "Prithviraj Ammanabrolu", "authors": "Prithviraj Ammanabrolu, Wesley Cheung, William Broniec, Mark O. Riedl", "title": "Automated Storytelling via Causal, Commonsense Plot Ordering", "comments": "AAAI-21 Camera Ready Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated story plot generation is the task of generating a coherent sequence\nof plot events. Causal relations between plot events are believed to increase\nthe perception of story and plot coherence. In this work, we introduce the\nconcept of soft causal relations as causal relations inferred from commonsense\nreasoning. We demonstrate C2PO, an approach to narrative generation that\noperationalizes this concept through Causal, Commonsense Plot Ordering. Using\nhuman-participant protocols, we evaluate our system against baseline systems\nwith different commonsense reasoning reasoning and inductive biases to\ndetermine the role of soft causal relations in perceived story quality. Through\nthese studies we also probe the interplay of how changes in commonsense norms\nacross storytelling genres affect perceptions of story quality.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 05:37:03 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 18:39:22 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Ammanabrolu", "Prithviraj", ""], ["Cheung", "Wesley", ""], ["Broniec", "William", ""], ["Riedl", "Mark O.", ""]]}, {"id": "2009.00901", "submitter": "Shuai Zhang", "authors": "Shuai Zhang, Lijie Wang, Ke Sun, Xinyan Xiao", "title": "A Practical Chinese Dependency Parser Based on A Large-scale Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dependency parsing is a longstanding natural language processing task, with\nits outputs crucial to various downstream tasks. Recently, neural network based\n(NN-based) dependency parsing has achieved significant progress and obtained\nthe state-of-the-art results. As we all know, NN-based approaches require\nmassive amounts of labeled training data, which is very expensive because it\nrequires human annotation by experts. Thus few industrial-oriented dependency\nparser tools are publicly available. In this report, we present Baidu\nDependency Parser (DDParser), a new Chinese dependency parser trained on a\nlarge-scale manually labeled dataset called Baidu Chinese Treebank (DuCTB).\nDuCTB consists of about one million annotated sentences from multiple sources\nincluding search logs, Chinese newswire, various forum discourses, and\nconversation programs. DDParser is extended on the graph-based biaffine parser\nto accommodate to the characteristics of Chinese dataset. We conduct\nexperiments on two test sets: the standard test set with the same distribution\nas the training set and the random test set sampled from other sources, and the\nlabeled attachment scores (LAS) of them are 92.9% and 86.9% respectively.\nDDParser achieves the state-of-the-art results, and is released at\nhttps://github.com/baidu/DDParser.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 08:41:46 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 02:42:29 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Zhang", "Shuai", ""], ["Wang", "Lijie", ""], ["Sun", "Ke", ""], ["Xiao", "Xinyan", ""]]}, {"id": "2009.00914", "submitter": "Manish Pandey", "authors": "Sina J. Semnani, Manish Pandey", "title": "Revisiting the Open-Domain Question Answering Pipeline", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-domain question answering (QA) is the tasl of identifying answers to\nnatural questions from a large corpus of documents. The typical open-domain QA\nsystem starts with information retrieval to select a subset of documents from\nthe corpus, which are then processed by a machine reader to select the answer\nspans. This paper describes Mindstone, an open-domain QA system that consists\nof a new multi-stage pipeline that employs a traditional BM25-based information\nretriever, RM3-based neural relevance feedback, neural ranker, and a machine\nreading comprehension stage. This paper establishes a new baseline for\nend-to-end performance on question answering for Wikipedia/SQuAD dataset\n(EM=58.1, F1=65.8), with substantial gains over the previous state of the art\n(Yang et al., 2019b). We also show how the new pipeline enables the use of\nlow-resolution labels, and can be easily tuned to meet various timing\nrequirements.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 09:34:14 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Semnani", "Sina J.", ""], ["Pandey", "Manish", ""]]}, {"id": "2009.01003", "submitter": "Jun Qi", "authors": "Jun Qi, Xu Liu, Javier Tejedor", "title": "Variational Inference-Based Dropout in Recurrent Neural Networks for\n  Slot Filling in Spoken Language Understanding", "comments": "conference paper, 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes to generalize the variational recurrent neural network\n(RNN) with variational inference (VI)-based dropout regularization employed for\nthe long short-term memory (LSTM) cells to more advanced RNN architectures like\ngated recurrent unit (GRU) and bi-directional LSTM/GRU. The new variational\nRNNs are employed for slot filling, which is an intriguing but challenging task\nin spoken language understanding. The experiments on the ATIS dataset suggest\nthat the variational RNNs with the VI-based dropout regularization can\nsignificantly improve the naive dropout regularization RNNs-based baseline\nsystems in terms of F-measure. Particularly, the variational RNN with\nbi-directional LSTM/GRU obtains the best F-measure score.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 22:05:54 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Qi", "Jun", ""], ["Liu", "Xu", ""], ["Tejedor", "Javier", ""]]}, {"id": "2009.01004", "submitter": "Omar Mossad", "authors": "Omar Mossad, Amgad Ahmed, Anandharaju Raju, Hari Karthikeyan, and\n  Zayed Ahmed", "title": "FAT ALBERT: Finding Answers in Large Texts using Semantic Similarity\n  Attention Layer based on BERT", "comments": "source code available: https://github.com/omossad/fat-albert", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine based text comprehension has always been a significant research field\nin natural language processing. Once a full understanding of the text context\nand semantics is achieved, a deep learning model can be trained to solve a\nlarge subset of tasks, e.g. text summarization, classification and question\nanswering. In this paper we focus on the question answering problem,\nspecifically the multiple choice type of questions. We develop a model based on\nBERT, a state-of-the-art transformer network. Moreover, we alleviate the\nability of BERT to support large text corpus by extracting the highest\ninfluence sentences through a semantic similarity model. Evaluations of our\nproposed model demonstrate that it outperforms the leading models in the\nMovieQA challenge and we are currently ranked first in the leader board with\ntest accuracy of 87.79%. Finally, we discuss the model shortcomings and suggest\npossible improvements to overcome these limitations.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2020 08:04:21 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Mossad", "Omar", ""], ["Ahmed", "Amgad", ""], ["Raju", "Anandharaju", ""], ["Karthikeyan", "Hari", ""], ["Ahmed", "Zayed", ""]]}, {"id": "2009.01008", "submitter": "Guangzhi Sun", "authors": "G. Sun, C. Zhang and P. C. Woodland", "title": "Cross-Utterance Language Models with Acoustic Error Sampling", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effective exploitation of richer contextual information in language\nmodels (LMs) is a long-standing research problem for automatic speech\nrecognition (ASR). A cross-utterance LM (CULM) is proposed in this paper, which\naugments the input to a standard long short-term memory (LSTM) LM with a\ncontext vector derived from past and future utterances using an extraction\nnetwork. The extraction network uses another LSTM to encode surrounding\nutterances into vectors which are integrated into a context vector using either\na projection of LSTM final hidden states, or a multi-head self-attentive layer.\nIn addition, an acoustic error sampling technique is proposed to reduce the\nmismatch between training and test-time. This is achieved by considering\npossible ASR errors into the model training procedure, and can therefore\nimprove the word error rate (WER). Experiments performed on both AMI and\nSwitchboard datasets show that CULMs outperform the LSTM LM baseline WER. In\nparticular, the CULM with a self-attentive layer-based extraction network and\nacoustic error sampling achieves 0.6% absolute WER reduction on AMI, 0.3% WER\nreduction on the Switchboard part and 0.9% WER reduction on the Callhome part\nof Eval2000 test set over the respective baselines.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 17:40:11 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Sun", "G.", ""], ["Zhang", "C.", ""], ["Woodland", "P. C.", ""]]}, {"id": "2009.01026", "submitter": "Hammond Pearce", "authors": "Hammond Pearce, Benjamin Tan, Ramesh Karri", "title": "DAVE: Deriving Automatically Verilog from English", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": "10.1145/3380446.3430634", "report-no": null, "categories": "cs.SE cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While specifications for digital systems are provided in natural language,\nengineers undertake significant efforts to translate them into the programming\nlanguages understood by compilers for digital systems. Automating this process\nallows designers to work with the language in which they are most comfortable\n--the original natural language -- and focus instead on other downstream design\nchallenges. We explore the use of state-of-the-art machine learning (ML) to\nautomatically derive Verilog snippets from English via fine-tuning GPT-2, a\nnatural language ML system. We describe our approach for producing a suitable\ndataset of novice-level digital design tasks and provide a detailed exploration\nof GPT-2, finding encouraging translation performance across our task sets\n(94.8% correct), with the ability to handle both simple and abstract design\ntasks.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2020 15:25:03 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Pearce", "Hammond", ""], ["Tan", "Benjamin", ""], ["Karri", "Ramesh", ""]]}, {"id": "2009.01040", "submitter": "Reza Khan Mohammadi", "authors": "Reza Khanmohammadi and Seyed Abolghasem Mirroshandel", "title": "PGST: a Polyglot Gender Style Transfer method", "comments": "It is submitted to the Natural Language Engineering Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in Text Style Transfer have led this field to be more\nhighlighted than ever. The task of transferring an input's style to another is\naccompanied by plenty of challenges (e.g., fluency and content preservation)\nthat need to be taken care of. In this research, we introduce PGST, a novel\npolyglot text style transfer approach in the gender domain, composed of\ndifferent constitutive elements. In contrast to prior studies, it is feasible\nto apply a style transfer method in multiple languages by fulfilling our\nmethod's predefined elements. We have proceeded with a pre-trained word\nembedding for token replacement purposes, a character-based token classifier\nfor gender exchange purposes, and a beam search algorithm for extracting the\nmost fluent combination. Since different approaches are introduced in our\nresearch, we determine a trade-off value for evaluating different models'\nsuccess in faking our gender identification model with transferred text. To\ndemonstrate our method's multilingual applicability, we applied our method on\nboth English and Persian corpora and ended up defeating our proposed gender\nidentification model by 45.6% and 39.2%, respectively. While this research's\nfocus is not limited to a specific language, our obtained evaluation results\nare highly competitive in an analogy among English state of the art methods.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 13:15:11 GMT"}, {"version": "v2", "created": "Sat, 26 Jun 2021 02:39:13 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Khanmohammadi", "Reza", ""], ["Mirroshandel", "Seyed Abolghasem", ""]]}, {"id": "2009.01041", "submitter": "Jiuniu Wang", "authors": "Jiuniu Wang, Wenjia Xu, Xingyu Fu, Guangluan Xu, Yirong Wu", "title": "ASTRAL: Adversarial Trained LSTM-CNN for Named Entity Recognition", "comments": null, "journal-ref": "Knowledge-Based Systems, Volume 197, 7 June 2020, 105842", "doi": "10.1016/j.knosys.2020.105842", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named Entity Recognition (NER) is a challenging task that extracts named\nentities from unstructured text data, including news, articles, social\ncomments, etc. The NER system has been studied for decades. Recently, the\ndevelopment of Deep Neural Networks and the progress of pre-trained word\nembedding have become a driving force for NER. Under such circumstances, how to\nmake full use of the information extracted by word embedding requires more\nin-depth research. In this paper, we propose an Adversarial Trained LSTM-CNN\n(ASTRAL) system to improve the current NER method from both the model structure\nand the training process. In order to make use of the spatial information\nbetween adjacent words, Gated-CNN is introduced to fuse the information of\nadjacent words. Besides, a specific Adversarial training method is proposed to\ndeal with the overfitting problem in NER. We add perturbation to variables in\nthe network during the training process, making the variables more diverse,\nimproving the generalization and robustness of the model. Our model is\nevaluated on three benchmarks, CoNLL-03, OntoNotes 5.0, and WNUT-17, achieving\nstate-of-the-art results. Ablation study and case study also show that our\nsystem can converge faster and is less prone to overfitting.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 13:15:25 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Wang", "Jiuniu", ""], ["Xu", "Wenjia", ""], ["Fu", "Xingyu", ""], ["Xu", "Guangluan", ""], ["Wu", "Yirong", ""]]}, {"id": "2009.01046", "submitter": "Marc-Andr\\'e Larochelle", "authors": "Khoury Richard and Larochelle Marc-Andr\\'e", "title": "Generalisation of Cyberbullying Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyberbullying is a problem in today's ubiquitous online communities.\nFiltering it out of online conversations has proven a challenge, and efforts\nhave led to the creation of many different datasets, all offered as resources\nto train classifiers. Through these datasets, we will explore the variety of\ndefinitions of cyberbullying behaviors and the impact of these differences on\nthe portability of one classifier to another community. By analyzing the\nsimilarities between datasets, we also gain insight on the generalization power\nof the classifiers trained from them. A study of ensemble models combining\nthese classifiers will help us understand how they interact with each other.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 14:57:17 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Richard", "Khoury", ""], ["Marc-Andr\u00e9", "Larochelle", ""]]}, {"id": "2009.01047", "submitter": "Vahid Behzadan", "authors": "Bibek Upadhayay and Vahid Behzadan", "title": "Sentimental LIAR: Extended Corpus and Deep Learning Models for Fake\n  Claim Classification", "comments": "Accepted for publication in the proceedings of IEEE ISI '20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rampant integration of social media in our every day lives and culture\nhas given rise to fast and easier access to the flow of information than ever\nin human history. However, the inherently unsupervised nature of social media\nplatforms has also made it easier to spread false information and fake news.\nFurthermore, the high volume and velocity of information flow in such platforms\nmake manual supervision and control of information propagation infeasible. This\npaper aims to address this issue by proposing a novel deep learning approach\nfor automated detection of false short-text claims on social media. We first\nintroduce Sentimental LIAR, which extends the LIAR dataset of short claims by\nadding features based on sentiment and emotion analysis of claims. Furthermore,\nwe propose a novel deep learning architecture based on the BERT-Base language\nmodel for classification of claims as genuine or fake. Our results demonstrate\nthat the proposed architecture trained on Sentimental LIAR can achieve an\naccuracy of 70%, which is an improvement of ~30% over previously reported\nresults for the LIAR benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 02:48:11 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 04:57:21 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Upadhayay", "Bibek", ""], ["Behzadan", "Vahid", ""]]}, {"id": "2009.01048", "submitter": "Thai Le", "authors": "Thai Le, Suhang Wang, Dongwon Lee", "title": "MALCOM: Generating Malicious Comments to Attack Neural Fake News\n  Detection Models", "comments": "Accepted at the 20th IEEE International Conference on Data Mining\n  (ICDM 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the proliferation of so-called \"fake news\" has caused much\ndisruptions in society and weakened the news ecosystem. Therefore, to mitigate\nsuch problems, researchers have developed state-of-the-art models to\nauto-detect fake news on social media using sophisticated data science and\nmachine learning techniques. In this work, then, we ask \"what if adversaries\nattempt to attack such detection models?\" and investigate related issues by (i)\nproposing a novel threat model against fake news detectors, in which\nadversaries can post malicious comments toward news articles to mislead fake\nnews detectors, and (ii) developing MALCOM, an end-to-end adversarial comment\ngeneration framework to achieve such an attack. Through a comprehensive\nevaluation, we demonstrate that about 94% and 93.5% of the time on average\nMALCOM can successfully mislead five of the latest neural detection models to\nalways output targeted real and fake news labels. Furthermore, MALCOM can also\nfool black box fake news detectors to always output real news labels 90% of the\ntime on average. We also compare our attack model with four baselines across\ntwo real-world datasets, not only on attack performance but also on generated\nquality, coherency, transferability, and robustness.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 01:26:01 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 10:15:06 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Le", "Thai", ""], ["Wang", "Suhang", ""], ["Lee", "Dongwon", ""]]}, {"id": "2009.01126", "submitter": "Isabelle van der Vegt", "authors": "Isabelle van der Vegt, Bennett Kleinberg, Paul Gill", "title": "Too good to be true? Predicting author profiles from abusive language", "comments": "Pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of online threats and abuse could potentially be mitigated with a\ncomputational approach, where sources of abuse are better understood or\nidentified through author profiling. However, abusive language constitutes a\nspecific domain of language for which it has not yet been tested whether\ndifferences emerge based on a text author's personality, age, or gender. This\nstudy examines statistical relationships between author demographics and\nabusive vs normal language, and performs prediction experiments for\npersonality, age, and gender. Although some statistical relationships were\nestablished between author characteristics and language use, these patterns did\nnot translate to high prediction performance. Personality traits were predicted\nwithin 15% of their actual value, age was predicted with an error margin of 10\nyears, and gender was classified correctly in 70% of the cases. These results\nare poor when compared to previous research on author profiling, therefore we\nurge caution in applying this within the context of abusive language and threat\nassessment.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 15:05:43 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 13:23:58 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["van der Vegt", "Isabelle", ""], ["Kleinberg", "Bennett", ""], ["Gill", "Paul", ""]]}, {"id": "2009.01134", "submitter": "David Alfter", "authors": "David Alfter", "title": "An exploratory study of L1-specific non-words", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we explore L1-specific non-words, i.e. non-words in a target\nlanguage (in this case Swedish) that are re-ranked by a different-language\nlanguage model. We surmise that speakers of a certain L1 will react different\nto L1-specific non-words than to general non-words. We present the results from\ntwo small case studies exploring whether re-ranking non-words with different\nlanguage models leads to a perceived difference in `Swedishness' (pilot study\n1) and whether German and English native speakers have longer reaction times in\na lexical decision task when presented with their respective L1-specific\nnon-words (pilot study 2). Tentative results seem to indicate that L1-specific\nnon-words are processed second-slowest, after purely Swedish-looking non-words.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 15:18:55 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Alfter", "David", ""]]}, {"id": "2009.01188", "submitter": "Toktam Amanzadeh Oghaz", "authors": "Ece \\c{C}i\\u{g}dem Mutlu, Toktam A. Oghaz, Jasser Jasser, Ege\n  T\\\"ut\\\"unc\\\"uler, Amirarsalan Rajabi, Aida Tayebi, Ozlem Ozmen, Ivan Garibay", "title": "A Stance Data Set on Polarized Conversations on Twitter about the\n  Efficacy of Hydroxychloroquine as a Treatment for COVID-19", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the time of this study, the SARS-CoV-2 virus that caused the COVID-19\npandemic has spread significantly across the world. Considering the uncertainty\nabout policies, health risks, financial difficulties, etc. the online media,\nspecially the Twitter platform, is experiencing a high volume of activity\nrelated to this pandemic. Among the hot topics, the polarized debates about\nunconfirmed medicines for the treatment and prevention of the disease have\nattracted significant attention from online media users. In this work, we\npresent a stance data set, COVID-CQ, of user-generated content on Twitter in\nthe context of COVID-19. We investigated more than 14 thousand tweets and\nmanually annotated the opinions of the tweet initiators regarding the use of\n\"chloroquine\" and \"hydroxychloroquine\" for the treatment or prevention of\nCOVID-19. To the best of our knowledge, COVID-CQ is the first data set of\nTwitter users' stances in the context of the COVID-19 pandemic, and the largest\nTwitter data set on users' stances towards a claim, in any domain. We have made\nthis data set available to the research community via GitHub. We expect this\ndata set to be useful for many research purposes, including stance detection,\nevolution and dynamics of opinions regarding this outbreak, and changes in\nopinions in response to the exogenous shocks such as policy decisions and\nevents.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2020 21:58:58 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 18:37:17 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Mutlu", "Ece \u00c7i\u011fdem", ""], ["Oghaz", "Toktam A.", ""], ["Jasser", "Jasser", ""], ["T\u00fct\u00fcnc\u00fcler", "Ege", ""], ["Rajabi", "Amirarsalan", ""], ["Tayebi", "Aida", ""], ["Ozmen", "Ozlem", ""], ["Garibay", "Ivan", ""]]}, {"id": "2009.01195", "submitter": "Avishek Garain", "authors": "Avishek Garain", "title": "Garain at SemEval-2020 Task 12: Sequence based Deep Learning for\n  Categorizing Offensive Language in Social Media", "comments": "Preprint for SemEval-2020 Task 12 System description paper, 8 pages,\n  3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  SemEval-2020 Task 12 was OffenseEval: Multilingual Offensive Language\nIdentification in Social Media (Zampieri et al., 2020). The task was subdivided\ninto multiple languages and datasets were provided for each one. The task was\nfurther divided into three sub-tasks: offensive language identification,\nautomatic categorization of offense types, and offense target identification. I\nhave participated in the task-C, that is, offense target identification. For\npreparing the proposed system, I have made use of Deep Learning networks like\nLSTMs and frameworks like Keras which combine the bag of words model with\nautomatically generated sequence based features and manually extracted features\nfrom the given dataset. My system on training on 25% of the whole dataset\nachieves macro averaged f1 score of 47.763%.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 17:09:29 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Garain", "Avishek", ""]]}, {"id": "2009.01303", "submitter": "Sasi Kiran Gaddipati", "authors": "Sasi Kiran Gaddipati, Deebul Nair, Paul G. Pl\\\"oger", "title": "Comparative Evaluation of Pretrained Transfer Learning Models on\n  Automatic Short Answer Grading", "comments": "7 pages, 3 figures, 3 tables. \"for associated work, refer\n  https://github.com/gsasikiran/Evaluation-of-transfer-learning-models-on-automatic-short-answer-grading\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic Short Answer Grading (ASAG) is the process of grading the student\nanswers by computational approaches given a question and the desired answer.\nPrevious works implemented the methods of concept mapping, facet mapping, and\nsome used the conventional word embeddings for extracting semantic features.\nThey extracted multiple features manually to train on the corresponding\ndatasets. We use pretrained embeddings of the transfer learning models, ELMo,\nBERT, GPT, and GPT-2 to assess their efficiency on this task. We train with a\nsingle feature, cosine similarity, extracted from the embeddings of these\nmodels. We compare the RMSE scores and correlation measurements of the four\nmodels with previous works on Mohler dataset. Our work demonstrates that ELMo\noutperformed the other three models. We also, briefly describe the four\ntransfer learning models and conclude with the possible causes of poor results\nof transfer learning models.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 19:07:34 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Gaddipati", "Sasi Kiran", ""], ["Nair", "Deebul", ""], ["Pl\u00f6ger", "Paul G.", ""]]}, {"id": "2009.01312", "submitter": "Yichu Zhou", "authors": "Yichu Zhou, Omri Koshorek, Vivek Srikumar and Jonathan Berant", "title": "A Simple Global Neural Discourse Parser", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discourse parsing is largely dominated by greedy parsers with\nmanually-designed features, while global parsing is rare due to its\ncomputational expense. In this paper, we propose a simple chart-based neural\ndiscourse parser that does not require any manually-crafted features and is\nbased on learned span representations only. To overcome the computational\nchallenge, we propose an independence assumption between the label assigned to\na node in the tree and the splitting point that separates its children, which\nresults in tractable decoding. We empirically demonstrate that our model\nachieves the best performance among global parsers, and comparable performance\nto state-of-art greedy parsers, using only learned span representations.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 19:28:40 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 15:33:34 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Zhou", "Yichu", ""], ["Koshorek", "Omri", ""], ["Srikumar", "Vivek", ""], ["Berant", "Jonathan", ""]]}, {"id": "2009.01317", "submitter": "Zhiqiang Ma", "authors": "Zhiqiang Ma, Grace Bang, Chong Wang, Xiaomo Liu", "title": "Towards Earnings Call and Stock Price Movement", "comments": "Accepted by KDD 2020 MLF workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.CE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Earnings calls are hosted by management of public companies to discuss the\ncompany's financial performance with analysts and investors. Information\ndisclosed during an earnings call is an essential source of data for analysts\nand investors to make investment decisions. Thus, we leverage earnings call\ntranscripts to predict future stock price dynamics. We propose to model the\nlanguage in transcripts using a deep learning framework, where an attention\nmechanism is applied to encode the text data into vectors for the\ndiscriminative network classifier to predict stock price movements. Our\nempirical experiments show that the proposed model is superior to the\ntraditional machine learning baselines and earnings call information can boost\nthe stock price prediction performance.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 20:38:14 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Ma", "Zhiqiang", ""], ["Bang", "Grace", ""], ["Wang", "Chong", ""], ["Liu", "Xiaomo", ""]]}, {"id": "2009.01325", "submitter": "Ryan Lowe T.", "authors": "Nisan Stiennon, Long Ouyang, Jeff Wu, Daniel M. Ziegler, Ryan Lowe,\n  Chelsea Voss, Alec Radford, Dario Amodei, Paul Christiano", "title": "Learning to summarize from human feedback", "comments": "NeurIPS 2020 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As language models become more powerful, training and evaluation are\nincreasingly bottlenecked by the data and metrics used for a particular task.\nFor example, summarization models are often trained to predict human reference\nsummaries and evaluated using ROUGE, but both of these metrics are rough\nproxies for what we really care about---summary quality. In this work, we show\nthat it is possible to significantly improve summary quality by training a\nmodel to optimize for human preferences. We collect a large, high-quality\ndataset of human comparisons between summaries, train a model to predict the\nhuman-preferred summary, and use that model as a reward function to fine-tune a\nsummarization policy using reinforcement learning. We apply our method to a\nversion of the TL;DR dataset of Reddit posts and find that our models\nsignificantly outperform both human reference summaries and much larger models\nfine-tuned with supervised learning alone. Our models also transfer to CNN/DM\nnews articles, producing summaries nearly as good as the human reference\nwithout any news-specific fine-tuning. We conduct extensive analyses to\nunderstand our human feedback dataset and fine-tuned models We establish that\nour reward model generalizes to new datasets, and that optimizing our reward\nmodel results in better summaries than optimizing ROUGE according to humans. We\nhope the evidence from our paper motivates machine learning researchers to pay\ncloser attention to how their training loss affects the model behavior they\nactually want.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 19:54:41 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 22:19:53 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Stiennon", "Nisan", ""], ["Ouyang", "Long", ""], ["Wu", "Jeff", ""], ["Ziegler", "Daniel M.", ""], ["Lowe", "Ryan", ""], ["Voss", "Chelsea", ""], ["Radford", "Alec", ""], ["Amodei", "Dario", ""], ["Christiano", "Paul", ""]]}, {"id": "2009.01444", "submitter": "\\c{C}a\\u{g}atay Demiralp", "authors": "Sara Evensen and Chang Ge and Dongjin Choi and \\c{C}a\\u{g}atay\n  Demiralp", "title": "Data Programming by Demonstration: A Framework for Interactively\n  Learning Labeling Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.DB cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data programming is a programmatic weak supervision approach to efficiently\ncurate large-scale labeled training data. Writing data programs (labeling\nfunctions) requires, however, both programming literacy and domain expertise.\nMany subject matter experts have neither programming proficiency nor time to\neffectively write data programs. Furthermore, regardless of one's expertise in\ncoding or machine learning, transferring domain expertise into labeling\nfunctions by enumerating rules and thresholds is not only time consuming but\nalso inherently difficult. Here we propose a new framework, data programming by\ndemonstration (DPBD), to generate labeling rules using interactive\ndemonstrations of users. DPBD aims to relieve the burden of writing labeling\nfunctions from users, enabling them to focus on higher-level semantics such as\nidentifying relevant signals for labeling tasks. We operationalize our\nframework with Ruler, an interactive system that synthesizes labeling rules for\ndocument classification by using span-level annotations of users on document\nexamples. We compare Ruler with conventional data programming through a user\nstudy conducted with 10 data scientists creating labeling functions for\nsentiment and spam classification tasks. We find that Ruler is easier to use\nand learn and offers higher overall satisfaction, while providing\ndiscriminative model performances comparable to ones achieved by conventional\ndata programming.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 04:25:08 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 01:44:22 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2020 22:44:04 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Evensen", "Sara", ""], ["Ge", "Chang", ""], ["Choi", "Dongjin", ""], ["Demiralp", "\u00c7a\u011fatay", ""]]}, {"id": "2009.01449", "submitter": "Long Chen", "authors": "Long Chen, Wenbo Ma, Jun Xiao, Hanwang Zhang, Shih-Fu Chang", "title": "Ref-NMS: Breaking Proposal Bottlenecks in Two-Stage Referring Expression\n  Grounding", "comments": "Camera ready version at AAAI 2021, Codes are available at:\n  https://github.com/ChopinSharp/ref-nms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prevailing framework for solving referring expression grounding is based\non a two-stage process: 1) detecting proposals with an object detector and 2)\ngrounding the referent to one of the proposals. Existing two-stage solutions\nmostly focus on the grounding step, which aims to align the expressions with\nthe proposals. In this paper, we argue that these methods overlook an obvious\nmismatch between the roles of proposals in the two stages: they generate\nproposals solely based on the detection confidence (i.e., expression-agnostic),\nhoping that the proposals contain all right instances in the expression (i.e.,\nexpression-aware). Due to this mismatch, current two-stage methods suffer from\na severe performance drop between detected and ground-truth proposals. To this\nend, we propose Ref-NMS, which is the first method to yield expression-aware\nproposals at the first stage. Ref-NMS regards all nouns in the expression as\ncritical objects, and introduces a lightweight module to predict a score for\naligning each box with a critical object. These scores can guide the NMS\noperation to filter out the boxes irrelevant to the expression, increasing the\nrecall of critical objects, resulting in a significantly improved grounding\nperformance. Since Ref- NMS is agnostic to the grounding step, it can be easily\nintegrated into any state-of-the-art two-stage method. Extensive ablation\nstudies on several backbones, benchmarks, and tasks consistently demonstrate\nthe superiority of Ref-NMS. Codes are available at:\nhttps://github.com/ChopinSharp/ref-nms.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 05:04:12 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 08:19:22 GMT"}, {"version": "v3", "created": "Wed, 10 Mar 2021 01:25:59 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Chen", "Long", ""], ["Ma", "Wenbo", ""], ["Xiao", "Jun", ""], ["Zhang", "Hanwang", ""], ["Chang", "Shih-Fu", ""]]}, {"id": "2009.01460", "submitter": "Michal Shmueli-Scheuer", "authors": "Guy Lev, Michal Shmueli-Scheuer, Achiya Jerbi, David Konopnicki", "title": "orgFAQ: A New Dataset and Analysis on Organizational FAQs and User\n  Questions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frequently Asked Questions (FAQ) webpages are created by organizations for\ntheir users. FAQs are used in several scenarios, e.g., to answer user\nquestions. On the other hand, the content of FAQs is affected by user questions\nby definition. In order to promote research in this field, several FAQ datasets\nexist. However, we claim that being collected from community websites, they do\nnot correctly represent challenges associated with FAQs in an organizational\ncontext. Thus, we release orgFAQ, a new dataset composed of $6988$ user\nquestions and $1579$ corresponding FAQs that were extracted from organizations'\nFAQ webpages in the Jobs domain. In this paper, we provide an analysis of the\nproperties of such FAQs, and demonstrate the usefulness of our new dataset by\nutilizing it in a relevant task from the Jobs domain. We also show the value of\nthe orgFAQ dataset in a task of a different domain - the COVID-19 pandemic.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 05:51:27 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Lev", "Guy", ""], ["Shmueli-Scheuer", "Michal", ""], ["Jerbi", "Achiya", ""], ["Konopnicki", "David", ""]]}, {"id": "2009.01560", "submitter": "Cong Sun", "authors": "Cong Sun, Zhihao Yang, Lei Wang, Yin Zhang, Hongfei Lin, Jian Wang", "title": "Biomedical named entity recognition using BERT in the machine reading\n  comprehension framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognition of biomedical entities from literature is a challenging research\nfocus, which is the foundation for extracting a large amount of biomedical\nknowledge existing in unstructured texts into structured formats. Using the\nsequence labeling framework to implement biomedical named entity recognition\n(BioNER) is currently a conventional method. This method, however, often cannot\ntake full advantage of the semantic information in the dataset, and the\nperformance is not always satisfactory. In this work, instead of treating the\nBioNER task as a sequence labeling problem, we formulate it as a machine\nreading comprehension (MRC) problem. This formulation can introduce more prior\nknowledge utilizing well-designed queries, and no longer need decoding\nprocesses such as conditional random fields (CRF). We conduct experiments on\nsix BioNER datasets, and the experimental results demonstrate the effectiveness\nof our method. Our method achieves state-of-the-art (SOTA) performance on the\nBC4CHEMD, BC5CDR-Chem, BC5CDR-Disease, NCBI-Disease, BC2GM and JNLPBA datasets,\nachieving F1-scores of 92.92%, 94.19%, 87.83%, 90.04%, 85.48% and 78.93%,\nrespectively.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 10:10:20 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 07:48:41 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Sun", "Cong", ""], ["Yang", "Zhihao", ""], ["Wang", "Lei", ""], ["Zhang", "Yin", ""], ["Lin", "Hongfei", ""], ["Wang", "Jian", ""]]}, {"id": "2009.01630", "submitter": "Jiuniu Wang", "authors": "Jiuniu Wang, Wenjia Xu, Xingyu Fu, Yang Wei, Li Jin, Ziyan Chen,\n  Guangluan Xu, Yirong Wu", "title": "SRQA: Synthetic Reader for Factoid Question Answering", "comments": "arXiv admin note: text overlap with arXiv:1809.00676", "journal-ref": "Knowledge-Based Systems, Volume 193, 6 April 2020, 105415", "doi": "10.1016/j.knosys.2019.105415", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The question answering system can answer questions from various fields and\nforms with deep neural networks, but it still lacks effective ways when facing\nmultiple evidences. We introduce a new model called SRQA, which means Synthetic\nReader for Factoid Question Answering. This model enhances the question\nanswering system in the multi-document scenario from three aspects: model\nstructure, optimization goal, and training method, corresponding to Multilayer\nAttention (MA), Cross Evidence (CE), and Adversarial Training (AT)\nrespectively. First, we propose a multilayer attention network to obtain a\nbetter representation of the evidences. The multilayer attention mechanism\nconducts interaction between the question and the passage within each layer,\nmaking the token representation of evidences in each layer takes the\nrequirement of the question into account. Second, we design a cross evidence\nstrategy to choose the answer span within more evidences. We improve the\noptimization goal, considering all the answers' locations in multiple evidences\nas training targets, which leads the model to reason among multiple evidences.\nThird, adversarial training is employed to high-level variables besides the\nword embedding in our model. A new normalization method is also proposed for\nadversarial perturbations so that we can jointly add perturbations to several\ntarget variables. As an effective regularization method, adversarial training\nenhances the model's ability to process noisy data. Combining these three\nstrategies, we enhance the contextual representation and locating ability of\nour model, which could synthetically extract the answer span from several\nevidences. We perform SRQA on the WebQA dataset, and experiments show that our\nmodel outperforms the state-of-the-art models (the best fuzzy score of our\nmodel is up to 78.56%, with an improvement of about 2%).\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 13:16:24 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Wang", "Jiuniu", ""], ["Xu", "Wenjia", ""], ["Fu", "Xingyu", ""], ["Wei", "Yang", ""], ["Jin", "Li", ""], ["Chen", "Ziyan", ""], ["Xu", "Guangluan", ""], ["Wu", "Yirong", ""]]}, {"id": "2009.01712", "submitter": "James Barry", "authors": "James Barry, Joachim Wagner, Jennifer Foster", "title": "The ADAPT Enhanced Dependency Parser at the IWPT 2020 Shared Task", "comments": "Submitted to the 2020 IWPT shared task on parsing Enhanced Universal\n  Dependencies", "journal-ref": "Proceedings of the 16th International Conference on Parsing\n  Technologies and the IWPT 2020 Shared Task (2020) 227-235", "doi": "10.18653/v1/2020.iwpt-1.24", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the ADAPT system for the 2020 IWPT Shared Task on parsing\nenhanced Universal Dependencies in 17 languages. We implement a pipeline\napproach using UDPipe and UDPipe-future to provide initial levels of\nannotation. The enhanced dependency graph is either produced by a graph-based\nsemantic dependency parser or is built from the basic tree using a small set of\nheuristics. Our results show that, for the majority of languages, a semantic\ndependency parser can be successfully applied to the task of parsing enhanced\ndependencies.\n  Unfortunately, we did not ensure a connected graph as part of our pipeline\napproach and our competition submission relied on a last-minute fix to pass the\nvalidation script which harmed our official evaluation scores significantly.\nOur submission ranked eighth in the official evaluation with a macro-averaged\ncoarse ELAS F1 of 67.23 and a treebank average of 67.49. We later implemented\nour own graph-connecting fix which resulted in a score of 79.53 (language\naverage) or 79.76 (treebank average), which would have placed fourth in the\ncompetition evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 14:43:04 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Barry", "James", ""], ["Wagner", "Joachim", ""], ["Foster", "Jennifer", ""]]}, {"id": "2009.01719", "submitter": "Felix Hill Mr", "authors": "Felix Hill, Olivier Tieleman, Tamara von Glehn, Nathaniel Wong, Hamza\n  Merzic, Stephen Clark", "title": "Grounded Language Learning Fast and Slow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that large text-based neural language models, trained\nwith conventional supervised learning objectives, acquire a surprising\npropensity for few- and one-shot learning. Here, we show that an embodied agent\nsituated in a simulated 3D world, and endowed with a novel dual-coding external\nmemory, can exhibit similar one-shot word learning when trained with\nconventional reinforcement learning algorithms. After a single introduction to\na novel object via continuous visual perception and a language prompt (\"This is\na dax\"), the agent can re-identify the object and manipulate it as instructed\n(\"Put the dax on the bed\"). In doing so, it seamlessly integrates short-term,\nwithin-episode knowledge of the appropriate referent for the word \"dax\" with\nlong-term lexical and motor knowledge acquired across episodes (i.e. \"bed\" and\n\"putting\"). We find that, under certain training conditions and with a\nparticular memory writing mechanism, the agent's one-shot word-object binding\ngeneralizes to novel exemplars within the same ShapeNet category, and is\neffective in settings with unfamiliar numbers of objects. We further show how\ndual-coding memory can be exploited as a signal for intrinsic motivation,\nstimulating the agent to seek names for objects that may be useful for later\nexecuting instructions. Together, the results demonstrate that deep neural\nnetworks can exploit meta-learning, episodic memory and an explicitly\nmulti-modal environment to account for 'fast-mapping', a fundamental pillar of\nhuman cognitive development and a potentially transformative capacity for\nagents that interact with human users.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 14:52:03 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 13:25:12 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2020 10:56:08 GMT"}, {"version": "v4", "created": "Wed, 14 Oct 2020 14:38:58 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Hill", "Felix", ""], ["Tieleman", "Olivier", ""], ["von Glehn", "Tamara", ""], ["Wong", "Nathaniel", ""], ["Merzic", "Hamza", ""], ["Clark", "Stephen", ""]]}, {"id": "2009.01776", "submitter": "Jiawei Chen", "authors": "Jiawei Chen, Xu Tan, Jian Luan, Tao Qin, Tie-Yan Liu", "title": "HiFiSinger: Towards High-Fidelity Neural Singing Voice Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-fidelity singing voices usually require higher sampling rate (e.g.,\n48kHz) to convey expression and emotion. However, higher sampling rate causes\nthe wider frequency band and longer waveform sequences and throws challenges\nfor singing voice synthesis (SVS) in both frequency and time domains.\nConventional SVS systems that adopt small sampling rate cannot well address the\nabove challenges. In this paper, we develop HiFiSinger, an SVS system towards\nhigh-fidelity singing voice. HiFiSinger consists of a FastSpeech based acoustic\nmodel and a Parallel WaveGAN based vocoder to ensure fast training and\ninference and also high voice quality. To tackle the difficulty of singing\nmodeling caused by high sampling rate (wider frequency band and longer\nwaveform), we introduce multi-scale adversarial training in both the acoustic\nmodel and vocoder to improve singing modeling. Specifically, 1) To handle the\nlarger range of frequencies caused by higher sampling rate, we propose a novel\nsub-frequency GAN (SF-GAN) on mel-spectrogram generation, which splits the full\n80-dimensional mel-frequency into multiple sub-bands and models each sub-band\nwith a separate discriminator. 2) To model longer waveform sequences caused by\nhigher sampling rate, we propose a multi-length GAN (ML-GAN) for waveform\ngeneration to model different lengths of waveform sequences with separate\ndiscriminators. 3) We also introduce several additional designs and findings in\nHiFiSinger that are crucial for high-fidelity voices, such as adding F0 (pitch)\nand V/UV (voiced/unvoiced flag) as acoustic features, choosing an appropriate\nwindow/hop size for mel-spectrogram, and increasing the receptive field in\nvocoder for long vowel modeling. Experiment results show that HiFiSinger\nsynthesizes high-fidelity singing voices with much higher quality: 0.32/0.44\nMOS gain over 48kHz/24kHz baseline and 0.83 MOS gain over previous SVS systems.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 16:31:02 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Chen", "Jiawei", ""], ["Tan", "Xu", ""], ["Luan", "Jian", ""], ["Qin", "Tao", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2009.01803", "submitter": "Tsendsuren Munkhdalai", "authors": "Tsendsuren Munkhdalai", "title": "Sparse Meta Networks for Sequential Adaptation and its Application to\n  Adaptive Language Modelling", "comments": "9 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a deep neural network requires a large amount of single-task data\nand involves a long time-consuming optimization phase. This is not scalable to\ncomplex, realistic environments with new unexpected changes. Humans can perform\nfast incremental learning on the fly and memory systems in the brain play a\ncritical role. We introduce Sparse Meta Networks -- a meta-learning approach to\nlearn online sequential adaptation algorithms for deep neural networks, by\nusing deep neural networks. We augment a deep neural network with a\nlayer-specific fast-weight memory. The fast-weights are generated sparsely at\neach time step and accumulated incrementally through time providing a useful\ninductive bias for online continual adaptation. We demonstrate strong\nperformance on a variety of sequential adaptation scenarios, from a simple\nonline reinforcement learning to a large scale adaptive language modelling.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 17:06:52 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Munkhdalai", "Tsendsuren", ""]]}, {"id": "2009.01822", "submitter": "Amirhossein Hajavi", "authors": "Amirhossein Hajavi, Ali Etemad", "title": "Knowing What to Listen to: Early Attention for Deep Speech\n  Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep learning techniques have considerably improved speech processing in\nrecent years. Speech representations extracted by deep learning models are\nbeing used in a wide range of tasks such as speech recognition, speaker\nrecognition, and speech emotion recognition. Attention models play an important\nrole in improving deep learning models. However current attention mechanisms\nare unable to attend to fine-grained information items. In this paper we\npropose the novel Fine-grained Early Frequency Attention (FEFA) for speech\nsignals. This model is capable of focusing on information items as small as\nfrequency bins. We evaluate the proposed model on two popular tasks of speaker\nrecognition and speech emotion recognition. Two widely used public datasets,\nVoxCeleb and IEMOCAP, are used for our experiments. The model is implemented on\ntop of several prominent deep models as backbone networks to evaluate its\nimpact on performance compared to the original networks and other related work.\nOur experiments show that by adding FEFA to different CNN architectures,\nperformance is consistently improved by substantial margins, even setting a new\nstate-of-the-art for the speaker recognition task. We also tested our model\nagainst different levels of added noise showing improvements in robustness and\nless sensitivity compared to the backbone networks.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 17:40:27 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Hajavi", "Amirhossein", ""], ["Etemad", "Ali", ""]]}, {"id": "2009.01826", "submitter": "Mario Graff", "authors": "Mario Graff and Daniela Moctezuma and Sabino Miranda-Jim\\'enez and\n  Eric S. Tellez", "title": "A Python Library for Exploratory Data Analysis on Twitter Data based on\n  Tokens and Aggregated Origin-Destination Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twitter is perhaps the social media more amenable for research. It requires\nonly a few steps to obtain information, and there are plenty of libraries that\ncan help in this regard. Nonetheless, knowing whether a particular event is\nexpressed on Twitter is a challenging task that requires a considerable\ncollection of tweets. This proposal aims to facilitate, to a researcher\ninterested, the process of mining events on Twitter. The events could be\nrelated to natural disasters, health issues, and people's mobility, among other\nstudies that can be pursued with the library proposed. Different applications\nare presented in this contribution to illustrate the library's capabilities: an\nexploratory analysis of the topics discovered in tweets, a study on similarity\namong dialects of the Spanish language, and a mobility report on different\ncountries. In summary, the Python library presented is applied to different\ndomains and retrieves a plethora of information processed from Twitter (since\nDecember 2015) in terms of words, bi-grams of words, and their frequencies by\nday for Arabic, English, Spanish, and Russian languages. The mobility\ninformation is related to the number of travels among locations for more than\n200 countries or territories; our library also provides access to this\ninformation.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 17:44:44 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 19:43:39 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Graff", "Mario", ""], ["Moctezuma", "Daniela", ""], ["Miranda-Jim\u00e9nez", "Sabino", ""], ["Tellez", "Eric S.", ""]]}, {"id": "2009.01938", "submitter": "Samarth Rawal", "authors": "Samarth Rawal and Chitta Baral", "title": "Multi-Perspective Semantic Information Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information Retrieval (IR) is the task of obtaining pieces of data (such as\ndocuments or snippets of text) that are relevant to a particular query or need\nfrom a large repository of information. While a combination of traditional\nkeyword- and modern BERT-based approaches have been shown to be effective in\nrecent work, there are often nuances in identifying what information is\n\"relevant\" to a particular query, which can be difficult to properly capture\nusing these systems. This work introduces the concept of a Multi-Perspective IR\nsystem, a novel methodology that combines multiple deep learning and\ntraditional IR models to better predict the relevance of a query-sentence pair,\nalong with a standardized framework for tuning this system. This work is\nevaluated on the BioASQ Biomedical IR + QA challenges.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 21:56:38 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Rawal", "Samarth", ""], ["Baral", "Chitta", ""]]}, {"id": "2009.01959", "submitter": "Marcelo De Rezende Martins", "authors": "Marcelo de Rezende Martins and Marco A. Gerosa", "title": "CoNCRA: A Convolutional Neural Network Code Retrieval Approach", "comments": null, "journal-ref": null, "doi": "10.1145/3422392.3422462", "report-no": null, "categories": "cs.LG cs.CL cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software developers routinely search for code using general-purpose search\nengines. However, these search engines cannot find code semantically unless it\nhas an accompanying description. We propose a technique for semantic code\nsearch: A Convolutional Neural Network approach to code retrieval (CoNCRA). Our\ntechnique aims to find the code snippet that most closely matches the\ndeveloper's intent, expressed in natural language. We evaluated our approach's\nefficacy on a dataset composed of questions and code snippets collected from\nStack Overflow. Our preliminary results showed that our technique, which\nprioritizes local interactions (words nearby), improved the state-of-the-art\n(SOTA) by 5% on average, retrieving the most relevant code snippets in the top\n3 (three) positions by almost 80% of the time. Therefore, our technique is\npromising and can improve the efficacy of semantic code retrieval.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 23:38:52 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Martins", "Marcelo de Rezende", ""], ["Gerosa", "Marco A.", ""]]}, {"id": "2009.01987", "submitter": "Mohammad Fasha", "authors": "Mohammad Fasha, Bassam Hammo, Nadim Obeid, Jabir Widian", "title": "A Hybrid Deep Learning Model for Arabic Text Recognition", "comments": "11 pages", "journal-ref": "International Journal of Advanced Computer Science and\n  Applications, Vol. 11, No. 8, 2020", "doi": "10.14569/issn.2156-5570", "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arabic text recognition is a challenging task because of the cursive nature\nof Arabic writing system, its joint writing scheme, the large number of\nligatures and many other challenges. Deep Learning DL models achieved\nsignificant progress in numerous domains including computer vision and sequence\nmodelling. This paper presents a model that can recognize Arabic text that was\nprinted using multiple font types including fonts that mimic Arabic handwritten\nscripts. The proposed model employs a hybrid DL network that can recognize\nArabic printed text without the need for character segmentation. The model was\ntested on a custom dataset comprised of over two million word samples that were\ngenerated using 18 different Arabic font types. The objective of the testing\nprocess was to assess the model capability in recognizing a diverse set of\nArabic fonts representing a varied cursive styles. The model achieved good\nresults in recognizing characters and words and it also achieved promising\nresults in recognizing characters when it was tested on unseen data. The\nprepared model, the custom datasets and the toolkit for generating similar\ndatasets are made publicly available, these tools can be used to prepare models\nfor recognizing other font types as well as to further extend and enhance the\nperformance of the proposed model.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 02:49:17 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Fasha", "Mohammad", ""], ["Hammo", "Bassam", ""], ["Obeid", "Nadim", ""], ["Widian", "Jabir", ""]]}, {"id": "2009.01989", "submitter": "Minghui Qiu", "authors": "Cen Chen, Bingzhe Wu, Minghui Qiu, Li Wang, Jun Zhou", "title": "A Comprehensive Analysis of Information Leakage in Deep Transfer\n  Learning", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Transfer learning is widely used for transferring knowledge from a source\ndomain to the target domain where the labeled data is scarce. Recently, deep\ntransfer learning has achieved remarkable progress in various applications.\nHowever, the source and target datasets usually belong to two different\norganizations in many real-world scenarios, potential privacy issues in deep\ntransfer learning are posed. In this study, to thoroughly analyze the potential\nprivacy leakage in deep transfer learning, we first divide previous methods\ninto three categories. Based on that, we demonstrate specific threats that lead\nto unintentional privacy leakage in each category. Additionally, we also\nprovide some solutions to prevent these threats. To the best of our knowledge,\nour study is the first to provide a thorough analysis of the information\nleakage issues in deep transfer learning methods and provide potential\nsolutions to the issue. Extensive experiments on two public datasets and an\nindustry dataset are conducted to show the privacy leakage under different deep\ntransfer learning settings and defense solution effectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 02:53:20 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Chen", "Cen", ""], ["Wu", "Bingzhe", ""], ["Qiu", "Minghui", ""], ["Wang", "Li", ""], ["Zhou", "Jun", ""]]}, {"id": "2009.02016", "submitter": "Huan Lin", "authors": "Huan Lin and Fandong Meng and Jinsong Su and Yongjing Yin and\n  Zhengyuan Yang and Yubin Ge and Jie Zhou and Jiebo Luo", "title": "Dynamic Context-guided Capsule Network for Multimodal Machine\n  Translation", "comments": null, "journal-ref": null, "doi": "10.1145/3394171.3413715", "report-no": null, "categories": "cs.CL cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal machine translation (MMT), which mainly focuses on enhancing\ntext-only translation with visual features, has attracted considerable\nattention from both computer vision and natural language processing\ncommunities. Most current MMT models resort to attention mechanism, global\ncontext modeling or multimodal joint representation learning to utilize visual\nfeatures. However, the attention mechanism lacks sufficient semantic\ninteractions between modalities while the other two provide fixed visual\ncontext, which is unsuitable for modeling the observed variability when\ngenerating translation. To address the above issues, in this paper, we propose\na novel Dynamic Context-guided Capsule Network (DCCN) for MMT. Specifically, at\neach timestep of decoding, we first employ the conventional source-target\nattention to produce a timestep-specific source-side context vector. Next, DCCN\ntakes this vector as input and uses it to guide the iterative extraction of\nrelated visual features via a context-guided dynamic routing mechanism.\nParticularly, we represent the input image with global and regional visual\nfeatures, we introduce two parallel DCCNs to model multimodal context vectors\nwith visual features at different granularities. Finally, we obtain two\nmultimodal context vectors, which are fused and incorporated into the decoder\nfor the prediction of the target word. Experimental results on the Multi30K\ndataset of English-to-German and English-to-French translation demonstrate the\nsuperiority of DCCN. Our code is available on\nhttps://github.com/DeepLearnXMU/MM-DCCN.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 06:18:24 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Lin", "Huan", ""], ["Meng", "Fandong", ""], ["Su", "Jinsong", ""], ["Yin", "Yongjing", ""], ["Yang", "Zhengyuan", ""], ["Ge", "Yubin", ""], ["Zhou", "Jie", ""], ["Luo", "Jiebo", ""]]}, {"id": "2009.02035", "submitter": "Brooke Stephenson", "authors": "Brooke Stephenson, Laurent Besacier, Laurent Girin, Thomas Hueber", "title": "What the Future Brings: Investigating the Impact of Lookahead for\n  Incremental Neural TTS", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In incremental text to speech synthesis (iTTS), the synthesizer produces an\naudio output before it has access to the entire input sentence. In this paper,\nwe study the behavior of a neural sequence-to-sequence TTS system when used in\nan incremental mode, i.e. when generating speech output for token n, the system\nhas access to n + k tokens from the text sequence. We first analyze the impact\nof this incremental policy on the evolution of the encoder representations of\ntoken n for different values of k (the lookahead parameter). The results show\nthat, on average, tokens travel 88% of the way to their full context\nrepresentation with a one-word lookahead and 94% after 2 words. We then\ninvestigate which text features are the most influential on the evolution\ntowards the final representation using a random forest analysis. The results\nshow that the most salient factors are related to token length. We finally\nevaluate the effects of lookahead k at the decoder level, using a MUSHRA\nlistening test. This test shows results that contrast with the above high\nfigures: speech synthesis quality obtained with 2 word-lookahead is\nsignificantly lower than the one obtained with the full sentence.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 07:30:57 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Stephenson", "Brooke", ""], ["Besacier", "Laurent", ""], ["Girin", "Laurent", ""], ["Hueber", "Thomas", ""]]}, {"id": "2009.02043", "submitter": "Fredrik Olsson", "authors": "Fredrik Olsson, Magnus Sahlgren", "title": "Data Readiness for Natural Language Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document concerns data readiness in the context of machine learning and\nNatural Language Processing. It describes how an organization may proceed to\nidentify, make available, validate, and prepare data to facilitate automated\nanalysis methods. The contents of the document is based on the practical\nchallenges and frequently asked questions we have encountered in our work as an\napplied research institute with helping organizations and companies, both in\nthe public and private sectors, to use data in their business processes.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 07:53:43 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 12:03:58 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Olsson", "Fredrik", ""], ["Sahlgren", "Magnus", ""]]}, {"id": "2009.02070", "submitter": "Wei Zhu", "authors": "Wei Zhu, Xiaoling Wang, Xipeng Qiu, Yuan Ni, Guotong Xie", "title": "AutoTrans: Automating Transformer Design via Reinforced Architecture\n  Search", "comments": "will add new technical contents", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though the transformer architectures have shown dominance in many natural\nlanguage understanding tasks, there are still unsolved issues for the training\nof transformer models, especially the need for a principled way of warm-up\nwhich has shown importance for stable training of a transformer, as well as\nwhether the task at hand prefer to scale the attention product or not. In this\npaper, we empirically explore automating the design choices in the transformer\nmodel, i.e., how to set layer-norm, whether to scale, number of layers, number\nof heads, activation function, etc, so that one can obtain a transformer\narchitecture that better suits the tasks at hand. RL is employed to navigate\nalong search space, and special parameter sharing strategies are designed to\naccelerate the search. It is shown that sampling a proportion of training data\nper epoch during search help to improve the search quality. Experiments on the\nCoNLL03, Multi-30k, IWSLT14 and WMT-14 shows that the searched transformer\nmodel can outperform the standard transformers. In particular, we show that our\nlearned model can be trained more robustly with large learning rates without\nwarm-up.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 08:46:22 GMT"}, {"version": "v2", "created": "Sun, 30 May 2021 12:45:31 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Zhu", "Wei", ""], ["Wang", "Xiaoling", ""], ["Qiu", "Xipeng", ""], ["Ni", "Yuan", ""], ["Xie", "Guotong", ""]]}, {"id": "2009.02073", "submitter": "Eleni Metheniti", "authors": "Eleni Metheniti, Guenter Neumann, Josef van Genabith", "title": "Linguistically inspired morphological inflection with a sequence to\n  sequence model", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inflection is an essential part of every human language's morphology, yet\nlittle effort has been made to unify linguistic theory and computational\nmethods in recent years. Methods of string manipulation are used to infer\ninflectional changes; our research question is whether a neural network would\nbe capable of learning inflectional morphemes for inflection production in a\nsimilar way to a human in early stages of language acquisition. We are using an\ninflectional corpus (Metheniti and Neumann, 2020) and a single layer seq2seq\nmodel to test this hypothesis, in which the inflectional affixes are learned\nand predicted as a block and the word stem is modelled as a character sequence\nto account for infixation. Our character-morpheme-based model creates\ninflection by predicting the stem character-to-character and the inflectional\naffixes as character blocks. We conducted three experiments on creating an\ninflected form of a word given the lemma and a set of input and target\nfeatures, comparing our architecture to a mainstream character-based model with\nthe same hyperparameters, training and test sets. Overall for 17 languages, we\nnoticed small improvements on inflecting known lemmas (+0.68%) but steadily\nbetter performance of our model in predicting inflected forms of unknown words\n(+3.7%) and small improvements on predicting in a low-resource scenario\n(+1.09%)\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 08:58:42 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Metheniti", "Eleni", ""], ["Neumann", "Guenter", ""], ["van Genabith", "Josef", ""]]}, {"id": "2009.02113", "submitter": "Thomas Kober", "authors": "Vincent D. Warmerdam, Thomas Kober, Rachael Tatman", "title": "Going Beyond T-SNE: Exposing \\texttt{whatlies} in Text Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce whatlies, an open source toolkit for visually inspecting word\nand sentence embeddings. The project offers a unified and extensible API with\ncurrent support for a range of popular embedding backends including spaCy,\ntfhub, huggingface transformers, gensim, fastText and BytePair embeddings. The\npackage combines a domain specific language for vector arithmetic with\nvisualisation tools that make exploring word embeddings more intuitive and\nconcise. It offers support for many popular dimensionality reduction techniques\nas well as many interactive visualisations that can either be statically\nexported or shared via Jupyter notebooks. The project documentation is\navailable from https://rasahq.github.io/whatlies/.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 11:17:46 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Warmerdam", "Vincent D.", ""], ["Kober", "Thomas", ""], ["Tatman", "Rachael", ""]]}, {"id": "2009.02252", "submitter": "Fabio Petroni", "authors": "Fabio Petroni, Aleksandra Piktus, Angela Fan, Patrick Lewis, Majid\n  Yazdani, Nicola De Cao, James Thorne, Yacine Jernite, Vladimir Karpukhin,\n  Jean Maillard, Vassilis Plachouras, Tim Rockt\\\"aschel, Sebastian Riedel", "title": "KILT: a Benchmark for Knowledge Intensive Language Tasks", "comments": "accepted at NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Challenging problems such as open-domain question answering, fact checking,\nslot filling and entity linking require access to large, external knowledge\nsources. While some models do well on individual tasks, developing general\nmodels is difficult as each task might require computationally expensive\nindexing of custom knowledge sources, in addition to dedicated infrastructure.\nTo catalyze research on models that condition on specific information in large\ntextual resources, we present a benchmark for knowledge-intensive language\ntasks (KILT). All tasks in KILT are grounded in the same snapshot of Wikipedia,\nreducing engineering turnaround through the re-use of components, as well as\naccelerating research into task-agnostic memory architectures. We test both\ntask-specific and general baselines, evaluating downstream performance in\naddition to the ability of the models to provide provenance. We find that a\nshared dense vector index coupled with a seq2seq model is a strong baseline,\noutperforming more tailor-made approaches for fact checking, open-domain\nquestion answering and dialogue, and yielding competitive results on entity\nlinking and slot filling, by generating disambiguated text. KILT data and code\nare available at https://github.com/facebookresearch/KILT.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 15:32:19 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 08:59:41 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 09:27:43 GMT"}, {"version": "v4", "created": "Thu, 27 May 2021 15:20:59 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Petroni", "Fabio", ""], ["Piktus", "Aleksandra", ""], ["Fan", "Angela", ""], ["Lewis", "Patrick", ""], ["Yazdani", "Majid", ""], ["De Cao", "Nicola", ""], ["Thorne", "James", ""], ["Jernite", "Yacine", ""], ["Karpukhin", "Vladimir", ""], ["Maillard", "Jean", ""], ["Plachouras", "Vassilis", ""], ["Rockt\u00e4schel", "Tim", ""], ["Riedel", "Sebastian", ""]]}, {"id": "2009.02358", "submitter": "Mina Naghshnejad", "authors": "Mina Naghshnejad, Tarun Joshi, and Vijayan N. Nair", "title": "Recent Trends in the Use of Deep Learning Models for Grammar Error\n  Handling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grammar error handling (GEH) is an important topic in natural language\nprocessing (NLP). GEH includes both grammar error detection and grammar error\ncorrection. Recent advances in computation systems have promoted the use of\ndeep learning (DL) models for NLP problems such as GEH. In this survey we focus\non two main DL approaches for GEH: neural machine translation models and editor\nmodels. We describe the three main stages of the pipeline for these models:\ndata preparation, training, and inference. Additionally, we discuss different\ntechniques to improve the performance of these models at each stage of the\npipeline. We compare the performance of different models and conclude with\nproposed future directions.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 18:50:13 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Naghshnejad", "Mina", ""], ["Joshi", "Tarun", ""], ["Nair", "Vijayan N.", ""]]}, {"id": "2009.02406", "submitter": "Xinli Yu T", "authors": "Xinli Yu, Mohsen Malmir, Cynthia He, Yue Liu, Rex Wu", "title": "Video Moment Retrieval via Natural Language Queries", "comments": "needs internal approval", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel method for video moment retrieval (VMR)\nthat achieves state of the arts (SOTA) performance on R@1 metrics and\nsurpassing the SOTA on the high IoU metric (R@1, IoU=0.7).\n  First, we propose to use a multi-head self-attention mechanism, and further a\ncross-attention scheme to capture video/query interaction and long-range query\ndependencies from video context. The attention-based methods can develop\nframe-to-query interaction and query-to-frame interaction at arbitrary\npositions and the multi-head setting ensures the sufficient understanding of\ncomplicated dependencies. Our model has a simple architecture, which enables\nfaster training and inference while maintaining .\n  Second, We also propose to use multiple task training objective consists of\nmoment segmentation task, start/end distribution prediction and start/end\nlocation regression task. We have verified that start/end prediction are noisy\ndue to annotator disagreement and joint training with moment segmentation task\ncan provide richer information since frames inside the target clip are also\nutilized as positive training examples.\n  Third, we propose to use an early fusion approach, which achieves better\nperformance at the cost of inference time. However, the inference time will not\nbe a problem for our model since our model has a simple architecture which\nenables efficient training and inference.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 22:06:34 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 14:49:04 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Yu", "Xinli", ""], ["Malmir", "Mohsen", ""], ["He", "Cynthia", ""], ["Liu", "Yue", ""], ["Wu", "Rex", ""]]}, {"id": "2009.02431", "submitter": "Paul Rodrigues", "authors": "Evan Williams, Paul Rodrigues, Valerie Novak", "title": "Accenture at CheckThat! 2020: If you say so: Post-hoc fact-checking of\n  claims using transformer-based models", "comments": "To Appear As: Evan Williams, Paul Rodrigues, Valerie Novak. Accenture\n  at CheckThat! 2020: If you say so: Post-hoc fact-checking of claims using\n  transformer-based models. In: Cappellato et al. Working Notes of CLEF\n  2020-Conference and Labs of the Evaluation Forum. Thessaloniki, Greece. 22-25\n  September 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the strategies used by the Accenture Team for the CLEF2020\nCheckThat! Lab, Task 1, on English and Arabic. This shared task evaluated\nwhether a claim in social media text should be professionally fact checked. To\na journalist, a statement presented as fact, which would be of interest to a\nlarge audience, requires professional fact-checking before dissemination. We\nutilized BERT and RoBERTa models to identify claims in social media text a\nprofessional fact-checker should review, and rank these in priority order for\nthe fact-checker. For the English challenge, we fine-tuned a RoBERTa model and\nadded an extra mean pooling layer and a dropout layer to enhance\ngeneralizability to unseen text. For the Arabic task, we fine-tuned\nArabic-language BERT models and demonstrate the use of back-translation to\namplify the minority class and balance the dataset. The work presented here was\nscored 1st place in the English track, and 1st, 2nd, 3rd, and 4th place in the\nArabic track.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 01:44:11 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Williams", "Evan", ""], ["Rodrigues", "Paul", ""], ["Novak", "Valerie", ""]]}, {"id": "2009.02459", "submitter": "Hongwei Zhou", "authors": "Hongwei (Henry) Zhou, Oskar Elek, Pranav Anand, Angus G. Forbes", "title": "Bio-inspired Structure Identification in Language Embeddings", "comments": "7 pages, 8 figures, 2 tables, Visualisation for the Digital\n  Humanities 2020. Comments: Fixed white spaces in abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are a popular way to improve downstream performances in\ncontemporary language modeling. However, the underlying geometric structure of\nthe embedding space is not well understood. We present a series of explorations\nusing bio-inspired methodology to traverse and visualize word embeddings,\ndemonstrating evidence of discernible structure. Moreover, our model also\nproduces word similarity rankings that are plausible yet very different from\ncommon similarity metrics, mainly cosine similarity and Euclidean distance. We\nshow that our bio-inspired model can be used to investigate how different word\nembedding techniques result in different semantic outputs, which can emphasize\nor obscure particular interpretations in textual data.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 04:44:15 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 23:59:06 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Hongwei", "", "", "Henry"], ["Zhou", "", ""], ["Elek", "Oskar", ""], ["Anand", "Pranav", ""], ["Forbes", "Angus G.", ""]]}, {"id": "2009.02461", "submitter": "Himel Dev", "authors": "Himel Dev and Hossein Hamooni", "title": "Profiling US Restaurants from Billions of Payment Card Transactions", "comments": "The 7th IEEE International Conference on Data Science and Advanced\n  Analytics (DSAA), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A payment card (such as debit or credit) is one of the most convenient\npayment methods for purchasing goods and services. Hundreds of millions of card\ntransactions take place across the globe every day, generating a massive volume\nof transaction data. The data render a holistic view of cardholder-merchant\ninteractions, containing insights that can benefit various applications, such\nas payment fraud detection and merchant recommendation. However, utilizing\nthese insights often requires additional information about merchants missing\nfrom the data owner's (i.e., payment company's) perspective. For example,\npayment companies do not know the exact type of product a merchant serves.\nCollecting merchant attributes from external sources for commercial purposes\ncan be expensive. Motivated by this limitation, we aim to infer latent merchant\nattributes from transaction data. As proof of concept, we concentrate on\nrestaurants and infer the cuisine types of restaurants from transactions. To\nthis end, we present a framework for inferring the cuisine types of restaurants\nfrom transaction data. Our proposed framework consists of three steps. In the\nfirst step, we generate cuisine labels for a limited number of restaurants via\nweak supervision. In the second step, we extract a wide variety of statistical\nfeatures and neural embeddings from the restaurant transactions. In the third\nstep, we use deep neural networks (DNNs) to infer the remaining restaurants'\ncuisine types. The proposed framework achieved a 76.2% accuracy in classifying\nthe US restaurants. To the best of our knowledge, this is the first framework\nto infer the cuisine types of restaurants by analyzing transaction data as the\nonly source.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 04:50:27 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Dev", "Himel", ""], ["Hamooni", "Hossein", ""]]}, {"id": "2009.02554", "submitter": "Matthew Berger", "authors": "Matthew Berger", "title": "Visually Analyzing Contextualized Embeddings", "comments": "IEEE Vis 2020, Observable notebook demo at\n  https://observablehq.com/@mattberger/visually-analyzing-contextualized-embeddings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a method for visually analyzing contextualized\nembeddings produced by deep neural network-based language models. Our approach\nis inspired by linguistic probes for natural language processing, where tasks\nare designed to probe language models for linguistic structure, such as\nparts-of-speech and named entities. These approaches are largely confirmatory,\nhowever, only enabling a user to test for information known a priori. In this\nwork, we eschew supervised probing tasks, and advocate for unsupervised probes,\ncoupled with visual exploration techniques, to assess what is learned by\nlanguage models. Specifically, we cluster contextualized embeddings produced\nfrom a large text corpus, and introduce a visualization design based on this\nclustering and textual structure - cluster co-occurrences, cluster spans, and\ncluster-word membership - to help elicit the functionality of, and relationship\nbetween, individual clusters. User feedback highlights the benefits of our\ndesign in discovering different types of linguistic structures.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 15:40:51 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Berger", "Matthew", ""]]}, {"id": "2009.02619", "submitter": "Debanjan Mahata", "authors": "Sarthak Anand, Pradyumna Gupta, Hemant Yadav, Debanjan Mahata, Rakesh\n  Gosangi, Haimin Zhang, Rajiv Ratn Shah", "title": "MIDAS at SemEval-2020 Task 10: Emphasis Selection using Label\n  Distribution Learning and Contextual Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents our submission to the SemEval 2020 - Task 10 on emphasis\nselection in written text. We approach this emphasis selection problem as a\nsequence labeling task where we represent the underlying text with various\ncontextual embedding models. We also employ label distribution learning to\naccount for annotator disagreements. We experiment with the choice of model\narchitectures, trainability of layers, and different contextual embeddings. Our\nbest performing architecture is an ensemble of different models, which achieved\nan overall matching score of 0.783, placing us 15th out of 31 participating\nteams. Lastly, we analyze the results in terms of parts of speech tags,\nsentence lengths, and word ordering.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 00:15:33 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Anand", "Sarthak", ""], ["Gupta", "Pradyumna", ""], ["Yadav", "Hemant", ""], ["Mahata", "Debanjan", ""], ["Gosangi", "Rakesh", ""], ["Zhang", "Haimin", ""], ["Shah", "Rajiv Ratn", ""]]}, {"id": "2009.02645", "submitter": "Liu Pai", "authors": "Pai Liu", "title": "QiaoNing at SemEval-2020 Task 4: Commonsense Validation and Explanation\n  system based on ensemble of language model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present language model system submitted to SemEval-2020\nTask 4 competition: \"Commonsense Validation and Explanation\". We participate in\ntwo subtasks for subtask A: validation and subtask B: Explanation. We\nimplemented with transfer learning using pretrained language models (BERT,\nXLNet, RoBERTa, and ALBERT) and fine-tune them on this task. Then we compared\ntheir characteristics in this task to help future researchers understand and\nuse these models more properly. The ensembled model better solves this problem,\nmaking the model's accuracy reached 95.9% on subtask A, which just worse than\nhuman's by only 3% accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 05:12:50 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Liu", "Pai", ""]]}, {"id": "2009.02649", "submitter": "Arjun Choudhry", "authors": "Arjun Choudhry, Mandar Sharma, Pramod Chundury, Thomas Kapler, Derek\n  W.S. Gray, Naren Ramakrishnan and Niklas Elmqvist", "title": "Once Upon A Time In Visualization: Understanding the Use of Textual\n  Narratives for Causality", "comments": "9 pages + 2 references, 8 figures, 2 tables, IEEE VIS 2020 VAST Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causality visualization can help people understand temporal chains of events,\nsuch as messages sent in a distributed system, cause and effect in a historical\nconflict, or the interplay between political actors over time. However, as the\nscale and complexity of these event sequences grows, even these visualizations\ncan become overwhelming to use. In this paper, we propose the use of textual\nnarratives as a data-driven storytelling method to augment causality\nvisualization. We first propose a design space for how textual narratives can\nbe used to describe causal data. We then present results from a crowdsourced\nuser study where participants were asked to recover causality information from\ntwo causality visualizations--causal graphs and Hasse diagrams--with and\nwithout an associated textual narrative. Finally, we describe CAUSEWORKS, a\ncausality visualization system for understanding how specific interventions\ninfluence a causal model. The system incorporates an automatic textual\nnarrative mechanism based on our design space. We validate CAUSEWORKS through\ninterviews with experts who used the system for understanding complex events.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 05:46:24 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Choudhry", "Arjun", ""], ["Sharma", "Mandar", ""], ["Chundury", "Pramod", ""], ["Kapler", "Thomas", ""], ["Gray", "Derek W. S.", ""], ["Ramakrishnan", "Naren", ""], ["Elmqvist", "Niklas", ""]]}, {"id": "2009.02671", "submitter": "Tin Huynh Van", "authors": "Tin Van Huynh, Luan Thanh Nguyen and Son T. Luu", "title": "BANANA at WNUT-2020 Task 2: Identifying COVID-19 Information on Twitter\n  by Combining Deep Learning and Transfer Learning Models", "comments": "Submitted to 2020 The 6th Workshop on Noisy User-generated Text\n  (W-NUT)", "journal-ref": null, "doi": "10.18653/v1/2020.wnut-1.50", "report-no": null, "categories": "cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The outbreak COVID-19 virus caused a significant impact on the health of\npeople all over the world. Therefore, it is essential to have a piece of\nconstant and accurate information about the disease with everyone. This paper\ndescribes our prediction system for WNUT-2020 Task 2: Identification of\nInformative COVID-19 English Tweets. The dataset for this task contains size\n10,000 tweets in English labeled by humans. The ensemble model from our three\ntransformer and deep learning models is used for the final prediction. The\nexperimental result indicates that we have achieved F1 for the INFORMATIVE\nlabel on our systems at 88.81% on the test set.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 08:24:55 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 06:21:07 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Van Huynh", "Tin", ""], ["Nguyen", "Luan Thanh", ""], ["Luu", "Son T.", ""]]}, {"id": "2009.02685", "submitter": "Mika H\\\"am\\\"al\\\"ainen", "authors": "Mika H\\\"am\\\"al\\\"ainen, Niko Partanen, Khalid Alnajjar, Jack Rueter and\n  Thierry Poibeau", "title": "Automatic Dialect Adaptation in Finnish and its Effect on Perceived\n  Creativity", "comments": "In proceedings of the Eleventh International Conference on\n  Computational Creativity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a novel approach for adapting text written in standard Finnish to\ndifferent dialects. We experiment with character level NMT models both by using\na multi-dialectal and transfer learning approaches. The models are tested with\nover 20 different dialects. The results seem to favor transfer learning,\nalthough not strongly over the multi-dialectal approach. We study the influence\ndialectal adaptation has on perceived creativity of computer generated poetry.\nOur results suggest that the more the dialect deviates from the standard\nFinnish, the lower scores people tend to give on an existing evaluation metric.\nHowever, on a word association test, people associate creativity and\noriginality more with dialect and fluency more with standard Finnish.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 09:28:44 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["H\u00e4m\u00e4l\u00e4inen", "Mika", ""], ["Partanen", "Niko", ""], ["Alnajjar", "Khalid", ""], ["Rueter", "Jack", ""], ["Poibeau", "Thierry", ""]]}, {"id": "2009.02696", "submitter": "Giovanni Da San Martino", "authors": "G. Da San Martino, A. Barr\\'on-Cede\\~no, H. Wachsmuth, R. Petrov, P.\n  Nakov", "title": "SemEval-2020 Task 11: Detection of Propaganda Techniques in News\n  Articles", "comments": "37 pages, to be published in Proceedings of the 14th International\n  Workshop on Semantic Evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the results and the main findings of SemEval-2020 Task 11 on\nDetection of Propaganda Techniques in News Articles. The task featured two\nsubtasks. Subtask SI is about Span Identification: given a plain-text document,\nspot the specific text fragments containing propaganda. Subtask TC is about\nTechnique Classification: given a specific text fragment, in the context of a\nfull document, determine the propaganda technique it uses, choosing from an\ninventory of 14 possible propaganda techniques. The task attracted a large\nnumber of participants: 250 teams signed up to participate and 44 made a\nsubmission on the test set. In this paper, we present the task, analyze the\nresults, and discuss the system submissions and the methods they used. For both\nsubtasks, the best systems used pre-trained Transformers and ensembles.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 10:05:43 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Martino", "G. Da San", ""], ["Barr\u00f3n-Cede\u00f1o", "A.", ""], ["Wachsmuth", "H.", ""], ["Petrov", "R.", ""], ["Nakov", "P.", ""]]}, {"id": "2009.02725", "submitter": "Songxiang Liu", "authors": "Songxiang Liu, Yuewen Cao, Disong Wang, Xixin Wu, Xunying Liu, Helen\n  Meng", "title": "Any-to-Many Voice Conversion with Location-Relative Sequence-to-Sequence\n  Modeling", "comments": "Accepted by IEEE/ACM Transactions on Audio, Speech and Language\n  Processing", "journal-ref": null, "doi": "10.1109/TASLP.2021.3076867", "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an any-to-many location-relative, sequence-to-sequence\n(seq2seq), non-parallel voice conversion approach, which utilizes text\nsupervision during training. In this approach, we combine a bottle-neck feature\nextractor (BNE) with a seq2seq synthesis module. During the training stage, an\nencoder-decoder-based hybrid connectionist-temporal-classification-attention\n(CTC-attention) phoneme recognizer is trained, whose encoder has a bottle-neck\nlayer. A BNE is obtained from the phoneme recognizer and is utilized to extract\nspeaker-independent, dense and rich spoken content representations from\nspectral features. Then a multi-speaker location-relative attention based\nseq2seq synthesis model is trained to reconstruct spectral features from the\nbottle-neck features, conditioning on speaker representations for speaker\nidentity control in the generated speech. To mitigate the difficulties of using\nseq2seq models to align long sequences, we down-sample the input spectral\nfeature along the temporal dimension and equip the synthesis model with a\ndiscretized mixture of logistic (MoL) attention mechanism. Since the phoneme\nrecognizer is trained with large speech recognition data corpus, the proposed\napproach can conduct any-to-many voice conversion. Objective and subjective\nevaluations show that the proposed any-to-many approach has superior voice\nconversion performance in terms of both naturalness and speaker similarity.\nAblation studies are conducted to confirm the effectiveness of feature\nselection and model design strategies in the proposed approach. The proposed VC\napproach can readily be extended to support any-to-any VC (also known as\none/few-shot VC), and achieve high performance according to objective and\nsubjective evaluations.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 13:01:06 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 09:06:28 GMT"}, {"version": "v3", "created": "Sun, 23 May 2021 09:14:05 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Liu", "Songxiang", ""], ["Cao", "Yuewen", ""], ["Wang", "Disong", ""], ["Wu", "Xixin", ""], ["Liu", "Xunying", ""], ["Meng", "Helen", ""]]}, {"id": "2009.02743", "submitter": "Teodor Cotet", "authors": "Stefan Ruseti, Teodor-Mihai Cotet and Mihai Dascalu", "title": "Romanian Diacritics Restoration Using Recurrent Neural Networks", "comments": "2 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diacritics restoration is a mandatory step for adequately processing Romanian\ntexts, and not a trivial one, as you generally need context in order to\nproperly restore a character. Most previous methods which were experimented for\nRomanian restoration of diacritics do not use neural networks. Among those that\ndo, there are no solutions specifically optimized for this particular language\n(i.e., they were generally designed to work on many different languages).\nTherefore we propose a novel neural architecture based on recurrent neural\nnetworks that can attend information at different levels of abstractions in\norder to restore diacritics.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 14:20:35 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Ruseti", "Stefan", ""], ["Cotet", "Teodor-Mihai", ""], ["Dascalu", "Mihai", ""]]}, {"id": "2009.02779", "submitter": "Dumitru-Clementin Cercel", "authors": "George-Alexandru Vlad, George-Eduard Zaharia, Dumitru-Clementin\n  Cercel, Costin-Gabriel Chiru, Stefan Trausan-Matu", "title": "UPB at SemEval-2020 Task 8: Joint Textual and Visual Modeling in a\n  Multi-Task Learning Architecture for Memotion Analysis", "comments": "Accepted at SemEval-2020, 7 pages, 1 figure, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users from the online environment can create different ways of expressing\ntheir thoughts, opinions, or conception of amusement. Internet memes were\ncreated specifically for these situations. Their main purpose is to transmit\nideas by using combinations of images and texts such that they will create a\ncertain state for the receptor, depending on the message the meme has to send.\nThese posts can be related to various situations or events, thus adding a funny\nside to any circumstance our world is situated in. In this paper, we describe\nthe system developed by our team for SemEval-2020 Task 8: Memotion Analysis.\nMore specifically, we introduce a novel system to analyze these posts, a\nmultimodal multi-task learning architecture that combines ALBERT for text\nencoding with VGG-16 for image representation. In this manner, we show that the\ninformation behind them can be properly revealed. Our approach achieves good\nperformance on each of the three subtasks of the current competition, ranking\n11th for Subtask A (0.3453 macro F1-score), 1st for Subtask B (0.5183 macro\nF1-score), and 3rd for Subtask C (0.3171 macro F1-score) while exceeding the\nofficial baseline results by high margins.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 17:17:41 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 17:46:34 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Vlad", "George-Alexandru", ""], ["Zaharia", "George-Eduard", ""], ["Cercel", "Dumitru-Clementin", ""], ["Chiru", "Costin-Gabriel", ""], ["Trausan-Matu", "Stefan", ""]]}, {"id": "2009.02780", "submitter": "Dumitru-Clementin Cercel", "authors": "George-Eduard Zaharia, George-Alexandru Vlad, Dumitru-Clementin\n  Cercel, Traian Rebedea, Costin-Gabriel Chiru", "title": "UPB at SemEval-2020 Task 9: Identifying Sentiment in Code-Mixed Social\n  Media Texts using Transformers and Multi-Task Learning", "comments": "Accepted at SemEval-2020, 9 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis is a process widely used in opinion mining campaigns\nconducted today. This phenomenon presents applications in a variety of fields,\nespecially in collecting information related to the attitude or satisfaction of\nusers concerning a particular subject. However, the task of managing such a\nprocess becomes noticeably more difficult when it is applied in cultures that\ntend to combine two languages in order to express ideas and thoughts. By\ninterleaving words from two languages, the user can express with ease, but at\nthe cost of making the text far less intelligible for those who are not\nfamiliar with this technique, but also for standard opinion mining algorithms.\nIn this paper, we describe the systems developed by our team for SemEval-2020\nTask 9 that aims to cover two well-known code-mixed languages: Hindi-English\nand Spanish-English.\n  We intend to solve this issue by introducing a solution that takes advantage\nof several neural network approaches, as well as pre-trained word embeddings.\nOur approach (multlingual BERT) achieves promising performance on the\nHindi-English task, with an average F1-score of 0.6850, registered on the\ncompetition leaderboard, ranking our team 16th out of 62 participants. For the\nSpanish-English task, we obtained an average F1-score of 0.7064 ranking our\nteam 17th out of 29 participants by using another multilingual\nTransformer-based model, XLM-RoBERTa.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 17:19:18 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Zaharia", "George-Eduard", ""], ["Vlad", "George-Alexandru", ""], ["Cercel", "Dumitru-Clementin", ""], ["Rebedea", "Traian", ""], ["Chiru", "Costin-Gabriel", ""]]}, {"id": "2009.02795", "submitter": "Shuning Jin", "authors": "Shuning Jin, Yue Yin, XianE Tang, Ted Pedersen", "title": "Duluth at SemEval-2020 Task 7: Using Surprise as a Key to Unlock\n  Humorous Headlines", "comments": "To appear in the Proceedings of the 14th International Workshop on\n  Semantic Evaluation (SemEval 2020), December 12-13, 2020, Barcelona", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We use pretrained transformer-based language models in SemEval-2020 Task 7:\nAssessing the Funniness of Edited News Headlines. Inspired by the incongruity\ntheory of humor, we use a contrastive approach to capture the surprise in the\nedited headlines. In the official evaluation, our system gets 0.531 RMSE in\nSubtask 1, 11th among 49 submissions. In Subtask 2, our system gets 0.632\naccuracy, 9th among 32 submissions.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 18:34:54 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Jin", "Shuning", ""], ["Yin", "Yue", ""], ["Tang", "XianE", ""], ["Pedersen", "Ted", ""]]}, {"id": "2009.02835", "submitter": "Denghui Zhang", "authors": "Denghui Zhang, Zixuan Yuan, Yanchi Liu, Zuohui Fu, Fuzhen Zhuang,\n  Pengyang Wang, Haifeng Chen, Hui Xiong", "title": "E-BERT: A Phrase and Product Knowledge Enhanced Language Model for\n  E-commerce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language models such as BERT have achieved great success in a\nbroad range of natural language processing tasks. However, BERT cannot well\nsupport E-commerce related tasks due to the lack of two levels of domain\nknowledge, i.e., phrase-level and product-level. On one hand, many E-commerce\ntasks require an accurate understanding of domain phrases, whereas such\nfine-grained phrase-level knowledge is not explicitly modeled by BERT's\ntraining objective. On the other hand, product-level knowledge like product\nassociations can enhance the language modeling of E-commerce, but they are not\nfactual knowledge thus using them indiscriminately may introduce noise. To\ntackle the problem, we propose a unified pre-training framework, namely,\nE-BERT. Specifically, to preserve phrase-level knowledge, we introduce Adaptive\nHybrid Masking, which allows the model to adaptively switch from learning\npreliminary word knowledge to learning complex phrases, based on the fitting\nprogress of two modes. To utilize product-level knowledge, we introduce\nNeighbor Product Reconstruction, which trains E-BERT to predict a product's\nassociated neighbors with a denoising cross attention layer. Our investigation\nreveals promising results in four downstream tasks, i.e., review-based question\nanswering, aspect extraction, aspect sentiment classification, and product\nclassification.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 00:15:36 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 23:00:16 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Zhang", "Denghui", ""], ["Yuan", "Zixuan", ""], ["Liu", "Yanchi", ""], ["Fu", "Zuohui", ""], ["Zhuang", "Fuzhen", ""], ["Wang", "Pengyang", ""], ["Chen", "Haifeng", ""], ["Xiong", "Hui", ""]]}, {"id": "2009.02902", "submitter": "Zilong Wang", "authors": "Zilong Wang, Zhaohong Wan, and Xiaojun Wan", "title": "TransModality: An End2End Fusion Method with Transformer for Multimodal\n  Sentiment Analysis", "comments": "Proceedings of The Web Conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal sentiment analysis is an important research area that predicts\nspeaker's sentiment tendency through features extracted from textual, visual\nand acoustic modalities. The central challenge is the fusion method of the\nmultimodal information. A variety of fusion methods have been proposed, but few\nof them adopt end-to-end translation models to mine the subtle correlation\nbetween modalities. Enlightened by recent success of Transformer in the area of\nmachine translation, we propose a new fusion method, TransModality, to address\nthe task of multimodal sentiment analysis. We assume that translation between\nmodalities contributes to a better joint representation of speaker's utterance.\nWith Transformer, the learned features embody the information both from the\nsource modality and the target modality. We validate our model on multiple\nmultimodal datasets: CMU-MOSI, MELD, IEMOCAP. The experiments show that our\nproposed method achieves the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 06:11:56 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 04:44:54 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Wang", "Zilong", ""], ["Wan", "Zhaohong", ""], ["Wan", "Xiaojun", ""]]}, {"id": "2009.02931", "submitter": "Preslav Nakov", "authors": "Alex Nikolov, Giovanni Da San Martino, Ivan Koychev, and Preslav Nakov", "title": "Team Alex at CLEF CheckThat! 2020: Identifying Check-Worthy Tweets With\n  Transformer Models", "comments": "Check-worthiness; Fact-Checking; Veracity", "journal-ref": "CLEF-2020", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While misinformation and disinformation have been thriving in social media\nfor years, with the emergence of the COVID-19 pandemic, the political and the\nhealth misinformation merged, thus elevating the problem to a whole new level\nand giving rise to the first global infodemic. The fight against this infodemic\nhas many aspects, with fact-checking and debunking false and misleading claims\nbeing among the most important ones. Unfortunately, manual fact-checking is\ntime-consuming and automatic fact-checking is resource-intense, which means\nthat we need to pre-filter the input social media posts and to throw out those\nthat do not appear to be check-worthy. With this in mind, here we propose a\nmodel for detecting check-worthy tweets about COVID-19, which combines deep\ncontextualized text representations with modeling the social context of the\ntweet. We further describe a number of additional experiments and comparisons,\nwhich we believe should be useful for future research as they provide some\nindication about what techniques are effective for the task. Our official\nsubmission to the English version of CLEF-2020 CheckThat! Task 1, system\nTeam_Alex, was ranked second with a MAP score of 0.8034, which is almost tied\nwith the wining system, lagging behind by just 0.003 MAP points absolute.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 08:03:21 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Nikolov", "Alex", ""], ["Martino", "Giovanni Da San", ""], ["Koychev", "Ivan", ""], ["Nakov", "Preslav", ""]]}, {"id": "2009.02935", "submitter": "Khiem Tran", "authors": "Khiem Vinh Tran, Hao Phu Phan, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen", "title": "UIT-HSE at WNUT-2020 Task 2: Exploiting CT-BERT for Identifying COVID-19\n  Information on the Twitter Social Network", "comments": "Accepted by 2020 The 6th Workshop on Noisy User-generated Text\n  (W-NUT) - EMNLP 2020", "journal-ref": "https://www.aclweb.org/anthology/2020.wnut-1.53/", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recently, COVID-19 has affected a variety of real-life aspects of the world\nand led to dreadful consequences. More and more tweets about COVID-19 has been\nshared publicly on Twitter. However, the plurality of those Tweets are\nuninformative, which is challenging to build automatic systems to detect the\ninformative ones for useful AI applications. In this paper, we present our\nresults at the W-NUT 2020 Shared Task 2: Identification of Informative COVID-19\nEnglish Tweets. In particular, we propose our simple but effective approach\nusing the transformer-based models based on COVID-Twitter-BERT (CT-BERT) with\ndifferent fine-tuning techniques. As a result, we achieve the F1-Score of\n90.94\\% with the third place on the leaderboard of this task which attracted 56\nsubmitted teams in total.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 08:20:31 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 10:23:58 GMT"}, {"version": "v3", "created": "Fri, 13 Nov 2020 08:48:28 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Tran", "Khiem Vinh", ""], ["Phan", "Hao Phu", ""], ["Van Nguyen", "Kiet", ""], ["Nguyen", "Ngan Luu-Thuy", ""]]}, {"id": "2009.02963", "submitter": "Armand Boschin", "authors": "Armand Boschin", "title": "TorchKGE: Knowledge Graph Embedding in Python and PyTorch", "comments": "Paper presented at KDD-IWKG 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TorchKGE is a Python module for knowledge graph (KG) embedding relying solely\non PyTorch. This package provides researchers and engineers with a clean and\nefficient API to design and test new models. It features a KG data structure,\nsimple model interfaces and modules for negative sampling and model evaluation.\nIts main strength is a very fast evaluation module for the link prediction\ntask, a central application of KG embedding. Various KG embedding models are\nalso already implemented. Special attention has been paid to code efficiency\nand simplicity, documentation and API consistency. It is distributed using PyPI\nunder BSD license. Source code and pointers to documentation and deployment can\nbe found at https://github.com/torchkge-team/torchkge.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 09:21:34 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Boschin", "Armand", ""]]}, {"id": "2009.02985", "submitter": "Doron Tiferet", "authors": "Alexander Rabinovich and Doron Tiferet", "title": "Ambiguity Hierarchy of Regular Infinite Tree Languages", "comments": "Revised according to the reviewers comments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An automaton is unambiguous if for every input it has at most one accepting\ncomputation. An automaton is k-ambiguous (for k>0) if for every input it has at\nmost k accepting computations. An automaton is boundedly ambiguous if there is\nk, such that for every input it has at most k accepting computations. An\nautomaton is finitely (respectively, countably) ambiguous if for every input it\nhas at most finitely (respectively, countably) many accepting computations.\n  The degree of ambiguity of a regular language is defined in a natural way. A\nlanguage is k-ambiguous (respectively, boundedly, finitely, countably\nambiguous) if it is accepted by a k-ambiguous (respectively, boundedly,\nfinitely, countably ambiguous) automaton. Over finite words, every regular\nlanguage is accepted by a deterministic automaton. Over finite trees, every\nregular language is accepted by an unambiguous automaton. Over $\\omega$-words\nevery regular language is accepted by an unambiguous B\\\"uchi automaton and by a\ndeterministic parity automaton. Over infinite trees, Carayol et al. showed that\nthere are ambiguous languages.\n  We show that over infinite trees there is a hierarchy of degrees of\nambiguity: For every k>1 there are k-ambiguous languages which are not k-1\nambiguous; and there are finitely (respectively countably, uncountably)\nambiguous languages which are not boundedly (respectively finitely, countably)\nambiguous.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 10:08:24 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 12:55:20 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Rabinovich", "Alexander", ""], ["Tiferet", "Doron", ""]]}, {"id": "2009.03015", "submitter": "Sahar Abdelnabi", "authors": "Sahar Abdelnabi and Mario Fritz", "title": "Adversarial Watermarking Transformer: Towards Tracing Text Provenance\n  with Data Hiding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in natural language generation have introduced powerful\nlanguage models with high-quality output text. However, this raises concerns\nabout the potential misuse of such models for malicious purposes. In this\npaper, we study natural language watermarking as a defense to help better mark\nand trace the provenance of text. We introduce the Adversarial Watermarking\nTransformer (AWT) with a jointly trained encoder-decoder and adversarial\ntraining that, given an input text and a binary message, generates an output\ntext that is unobtrusively encoded with the given message. We further study\ndifferent training and inference strategies to achieve minimal changes to the\nsemantics and correctness of the input text.\n  AWT is the first end-to-end model to hide data in text by automatically\nlearning -- without ground truth -- word substitutions along with their\nlocations in order to encode the message. We empirically show that our model is\neffective in largely preserving text utility and decoding the watermark while\nhiding its presence against adversaries. Additionally, we demonstrate that our\nmethod is robust against a range of attacks.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 11:01:24 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 12:21:27 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Abdelnabi", "Sahar", ""], ["Fritz", "Mario", ""]]}, {"id": "2009.03068", "submitter": "Chetan Nichkawde", "authors": "Kuldeep Singh, Puneet Singla, Ketan Sarode, Anurag Chandrakar, Chetan\n  Nichkawde", "title": "Uncovering the Corona Virus Map Using Deep Entities and Relationship\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extract entities and relationships related to COVID-19 from a corpus of\narticles related to Corona virus by employing a novel entities and relationship\nmodel. The entity recognition and relationship discovery models are trained\nwith a multi-task learning objective on a large annotated corpus. We employ a\nconcept masking paradigm to prevent the evolution of neural networks\nfunctioning as an associative memory and induce right inductive bias guiding\nthe network to make inference using only the context. We uncover several import\nsubnetworks, highlight important terms and concepts and elucidate several\ntreatment modalities employed in related ailments in the past.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 12:48:36 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Singh", "Kuldeep", ""], ["Singla", "Puneet", ""], ["Sarode", "Ketan", ""], ["Chandrakar", "Anurag", ""], ["Nichkawde", "Chetan", ""]]}, {"id": "2009.03092", "submitter": "Soohwan Kim", "authors": "Soohwan Kim, Seyoung Bae, Cheolhwang Won", "title": "KoSpeech: Open-Source Toolkit for End-to-End Korean Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present KoSpeech, an open-source software, which is modular and extensible\nend-to-end Korean automatic speech recognition (ASR) toolkit based on the deep\nlearning library PyTorch. Several automatic speech recognition open-source\ntoolkits have been released, but all of them deal with non-Korean languages,\nsuch as English (e.g. ESPnet, Espresso). Although AI Hub opened 1,000 hours of\nKorean speech corpus known as KsponSpeech, there is no established\npreprocessing method and baseline model to compare model performances.\nTherefore, we propose preprocessing methods for KsponSpeech corpus and a\nbaseline model for benchmarks. Our baseline model is based on Listen, Attend\nand Spell (LAS) architecture and ables to customize various training\nhyperparameters conveniently. By KoSpeech, we hope this could be a guideline\nfor those who research Korean speech recognition. Our baseline model achieved\n10.31% character error rate (CER) at KsponSpeech corpus only with the acoustic\nmodel. Our source code is available here.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 13:25:36 GMT"}, {"version": "v2", "created": "Sat, 26 Sep 2020 17:25:34 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Kim", "Soohwan", ""], ["Bae", "Seyoung", ""], ["Won", "Cheolhwang", ""]]}, {"id": "2009.03095", "submitter": "Su Zhu", "authors": "Chen Liu, Su Zhu, Lu Chen and Kai Yu", "title": "Robust Spoken Language Understanding with RL-based Value Error Recovery", "comments": "Accepted to NLPCC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken Language Understanding (SLU) aims to extract structured semantic\nrepresentations (e.g., slot-value pairs) from speech recognized texts, which\nsuffers from errors of Automatic Speech Recognition (ASR). To alleviate the\nproblem caused by ASR-errors, previous works may apply input adaptations to the\nspeech recognized texts, or correct ASR errors in predicted values by searching\nthe most similar candidates in pronunciation. However, these two methods are\napplied separately and independently. In this work, we propose a new robust SLU\nframework to guide the SLU input adaptation with a rule-based value error\nrecovery module. The framework consists of a slot tagging model and a\nrule-based value error recovery module. We pursue on an adapted slot tagging\nmodel which can extract potential slot-value pairs mentioned in ASR hypotheses\nand is suitable for the existing value error recovery module. After the value\nerror recovery, we can achieve a supervision signal (reward) by comparing\nrefined slot-value pairs with annotations. Since operations of the value error\nrecovery are non-differentiable, we exploit policy gradient based Reinforcement\nLearning (RL) to optimize the SLU model. Extensive experiments on the public\nCATSLU dataset show the effectiveness of our proposed approach, which can\nimprove the robustness of SLU and outperform the baselines by significant\nmargins.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 13:32:07 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Liu", "Chen", ""], ["Zhu", "Su", ""], ["Chen", "Lu", ""], ["Yu", "Kai", ""]]}, {"id": "2009.03116", "submitter": "Magnus Sahlgren", "authors": "Tim Isbister and Magnus Sahlgren", "title": "Why Not Simply Translate? A First Swedish Evaluation Benchmark for\n  Semantic Similarity", "comments": "SLTC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the first Swedish evaluation benchmark for textual\nsemantic similarity. The benchmark is compiled by simply running the English\nSTS-B dataset through the Google machine translation API. This paper discusses\npotential problems with using such a simple approach to compile a Swedish\nevaluation benchmark, including translation errors, vocabulary variation, and\nproductive compounding. Despite some obvious problems with the resulting\ndataset, we use the benchmark to compare the majority of the currently existing\nSwedish text representations, demonstrating that native models outperform\nmultilingual ones, and that simple bag of words performs remarkably well.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 14:07:12 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 10:04:27 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Isbister", "Tim", ""], ["Sahlgren", "Magnus", ""]]}, {"id": "2009.03191", "submitter": "Ali H\\\"urriyeto\\u{g}lu", "authors": "Ali H\\\"urriyeto\\u{g}lu and Ali Safaya and Nelleke Oostdijk and Osman\n  Mutlu and Erdem Y\\\"or\\\"uk", "title": "COVCOR20 at WNUT-2020 Task 2: An Attempt to Combine Deep Learning and\n  Expert rules", "comments": "Shared task report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the scope of WNUT-2020 Task 2, we developed various text classification\nsystems, using deep learning models and one using linguistically informed\nrules. While both of the deep learning systems outperformed the system using\nthe linguistically informed rules, we found that through the integration of\n(the output of) the three systems a better performance could be achieved than\nthe standalone performance of each approach in a cross-validation setting.\nHowever, on the test data the performance of the integration was slightly lower\nthan our best performing deep learning model. These results hardly indicate any\nprogress in line of integrating machine learning and expert rules driven\nsystems. We expect that the release of the annotation manuals and gold labels\nof the test data after this workshop will shed light on these perplexing\nresults.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 15:54:23 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["H\u00fcrriyeto\u011flu", "Ali", ""], ["Safaya", "Ali", ""], ["Oostdijk", "Nelleke", ""], ["Mutlu", "Osman", ""], ["Y\u00f6r\u00fck", "Erdem", ""]]}, {"id": "2009.03300", "submitter": "Dan Hendrycks", "authors": "Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika,\n  Dawn Song, Jacob Steinhardt", "title": "Measuring Massive Multitask Language Understanding", "comments": "ICLR 2021; the test and code is available at\n  https://github.com/hendrycks/test", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new test to measure a text model's multitask accuracy. The test\ncovers 57 tasks including elementary mathematics, US history, computer science,\nlaw, and more. To attain high accuracy on this test, models must possess\nextensive world knowledge and problem solving ability. We find that while most\nrecent models have near random-chance accuracy, the very largest GPT-3 model\nimproves over random chance by almost 20 percentage points on average. However,\non every one of the 57 tasks, the best models still need substantial\nimprovements before they can reach expert-level accuracy. Models also have\nlopsided performance and frequently do not know when they are wrong. Worse,\nthey still have near-random accuracy on some socially important subjects such\nas morality and law. By comprehensively evaluating the breadth and depth of a\nmodel's academic and professional understanding, our test can be used to\nanalyze models across many tasks and to identify important shortcomings.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 17:59:25 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 05:06:57 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2021 18:57:11 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Hendrycks", "Dan", ""], ["Burns", "Collin", ""], ["Basart", "Steven", ""], ["Zou", "Andy", ""], ["Mazeika", "Mantas", ""], ["Song", "Dawn", ""], ["Steinhardt", "Jacob", ""]]}, {"id": "2009.03393", "submitter": "Stanislas Polu", "authors": "Stanislas Polu, Ilya Sutskever", "title": "Generative Language Modeling for Automated Theorem Proving", "comments": "15+5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the application of transformer-based language models to automated\ntheorem proving. This work is motivated by the possibility that a major\nlimitation of automated theorem provers compared to humans -- the generation of\noriginal mathematical terms -- might be addressable via generation from\nlanguage models. We present an automated prover and proof assistant, GPT-f, for\nthe Metamath formalization language, and analyze its performance. GPT-f found\nnew short proofs that were accepted into the main Metamath library, which is to\nour knowledge, the first time a deep-learning based system has contributed\nproofs that were adopted by a formal mathematics community.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 19:50:10 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Polu", "Stanislas", ""], ["Sutskever", "Ilya", ""]]}, {"id": "2009.03397", "submitter": "Jason Angel", "authors": "Jason Angel, Segun Taofeek Aroyehun, Antonio Tamayo and Alexander\n  Gelbukh", "title": "NLP-CIC at SemEval-2020 Task 9: Analysing sentiment in code-switching\n  language using a simple deep-learning classifier", "comments": "Accepted at SemEval-2020, COLING", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Code-switching is a phenomenon in which two or more languages are used in the\nsame message. Nowadays, it is quite common to find messages with languages\nmixed in social media. This phenomenon presents a challenge for sentiment\nanalysis. In this paper, we use a standard convolutional neural network model\nto predict the sentiment of tweets in a blend of Spanish and English languages.\nOur simple approach achieved a F1-score of 0.71 on test set on the competition.\nWe analyze our best model capabilities and perform error analysis to expose\nimportant difficulties for classifying sentiment in a code-switching setting.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 19:57:09 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Angel", "Jason", ""], ["Aroyehun", "Segun Taofeek", ""], ["Tamayo", "Antonio", ""], ["Gelbukh", "Alexander", ""]]}, {"id": "2009.03432", "submitter": "Gizem Sogancioglu", "authors": "Gizem So\\u{g}anc{\\i}o\\u{g}lu, Oxana Verkholyak, Heysem Kaya, Dmitrii\n  Fedotov, Tobias Cad\\`ee, Albert Ali Salah, Alexey Karpov", "title": "Is Everything Fine, Grandma? Acoustic and Linguistic Modeling for Robust\n  Elderly Speech Emotion Recognition", "comments": "5 pages, 1 figure, Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Acoustic and linguistic analysis for elderly emotion recognition is an\nunder-studied and challenging research direction, but essential for the\ncreation of digital assistants for the elderly, as well as unobtrusive\ntelemonitoring of elderly in their residences for mental healthcare purposes.\nThis paper presents our contribution to the INTERSPEECH 2020 Computational\nParalinguistics Challenge (ComParE) - Elderly Emotion Sub-Challenge, which is\ncomprised of two ternary classification tasks for arousal and valence\nrecognition. We propose a bi-modal framework, where these tasks are modeled\nusing state-of-the-art acoustic and linguistic features, respectively. In this\nstudy, we demonstrate that exploiting task-specific dictionaries and resources\ncan boost the performance of linguistic models, when the amount of labeled data\nis small. Observing a high mismatch between development and test set\nperformances of various models, we also propose alternative training and\ndecision fusion strategies to better estimate and improve the generalization\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 21:19:16 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["So\u011fanc\u0131o\u011flu", "Gizem", ""], ["Verkholyak", "Oxana", ""], ["Kaya", "Heysem", ""], ["Fedotov", "Dmitrii", ""], ["Cad\u00e8e", "Tobias", ""], ["Salah", "Albert Ali", ""], ["Karpov", "Alexey", ""]]}, {"id": "2009.03457", "submitter": "Jianfeng Gao", "authors": "Jianfeng Gao, Baolin Peng, Chunyuan Li, Jinchao Li, Shahin Shayandeh,\n  Lars Liden, Heung-Yeung Shum", "title": "Robust Conversational AI with Grounded Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a hybrid approach based on a Grounded Text Generation\n(GTG) model to building robust task bots at scale. GTG is a hybrid model which\nuses a large-scale Transformer neural network as its backbone, combined with\nsymbol-manipulation modules for knowledge base inference and prior knowledge\nencoding, to generate responses grounded in dialog belief state and real-world\nknowledge for task completion. GTG is pre-trained on large amounts of raw text\nand human conversational data, and can be fine-tuned to complete a wide range\nof tasks.\n  The hybrid approach and its variants are being developed simultaneously by\nmultiple research teams. The primary results reported on task-oriented dialog\nbenchmarks are very promising, demonstrating the big potential of this\napproach. This article provides an overview of this progress and discusses\nrelated methods and technologies that can be incorporated for building robust\nconversational AI systems.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 23:49:28 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Gao", "Jianfeng", ""], ["Peng", "Baolin", ""], ["Li", "Chunyuan", ""], ["Li", "Jinchao", ""], ["Shayandeh", "Shahin", ""], ["Liden", "Lars", ""], ["Shum", "Heung-Yeung", ""]]}, {"id": "2009.03520", "submitter": "\\c{C}a\\u{g}atay Demiralp", "authors": "Sajjadur Rahman and Peter Griggs and \\c{C}a\\u{g}atay Demiralp", "title": "Leam: An Interactive System for In-situ Visual Text Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increase in scale and availability of digital text generated on the\nweb, enterprises such as online retailers and aggregators often use text\nanalytics to mine and analyze the data to improve their services and products\nalike. Text data analysis is an iterative, non-linear process with diverse\nworkflows spanning multiple stages, from data cleaning to visualization.\nExisting text analytics systems usually accommodate a subset of these stages\nand often fail to address challenges related to data heterogeneity, provenance,\nworkflow reusability and reproducibility, and compatibility with established\npractices. Based on a set of design considerations we derive from these\nchallenges, we propose Leam, a system that treats the text analysis process as\na single continuum by combining advantages of computational notebooks,\nspreadsheets, and visualization tools. Leam features an interactive user\ninterface for running text analysis workflows, a new data model for managing\nmultiple atomic and composite data types, and an expressive algebra that\ncaptures diverse sets of operations representing various stages of text\nanalysis and enables coordination among different components of the system,\nincluding data, code, and visualizations. We report our current progress in\nLeam development while demonstrating its usefulness with usage examples.\nFinally, we outline a number of enhancements to Leam and identify several\nresearch directions for developing an interactive visual text analysis system.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 05:18:29 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Rahman", "Sajjadur", ""], ["Griggs", "Peter", ""], ["Demiralp", "\u00c7a\u011fatay", ""]]}, {"id": "2009.03673", "submitter": "Shikun Feng", "authors": "Jiaxiang Liu, Xuyi Chen, Shikun Feng, Shuohuan Wang, Xuan Ouyang, Yu\n  Sun, Zhengjie Huang, Weiyue Su", "title": "kk2018 at SemEval-2020 Task 9: Adversarial Training for Code-Mixing\n  Sentiment Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code switching is a linguistic phenomenon that may occur within a\nmultilingual setting where speakers share more than one language. With the\nincreasing communication between groups with different languages, this\nphenomenon is more and more popular. However, there are little research and\ndata in this area, especially in code-mixing sentiment classification. In this\nwork, the domain transfer learning from state-of-the-art uni-language model\nERNIE is tested on the code-mixing dataset, and surprisingly, a strong baseline\nis achieved. Furthermore, the adversarial training with a multi-lingual model\nis used to achieve 1st place of SemEval-2020 Task 9 Hindi-English sentiment\nclassification competition.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 12:20:04 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 02:20:46 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Liu", "Jiaxiang", ""], ["Chen", "Xuyi", ""], ["Feng", "Shikun", ""], ["Wang", "Shuohuan", ""], ["Ouyang", "Xuan", ""], ["Sun", "Yu", ""], ["Huang", "Zhengjie", ""], ["Su", "Weiyue", ""]]}, {"id": "2009.03695", "submitter": "Samuel Louvan", "authors": "Samuel Louvan, Bernardo Magnini", "title": "Simple is Better! Lightweight Data Augmentation for Low Resource Slot\n  Filling and Intent Classification", "comments": "Accepted at PACLIC 2020 - The 34th Pacific Asia Conference on\n  Language, Information and Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural-based models have achieved outstanding performance on slot filling and\nintent classification, when fairly large in-domain training data are available.\nHowever, as new domains are frequently added, creating sizeable data is\nexpensive. We show that lightweight augmentation, a set of augmentation methods\ninvolving word span and sentence level operations, alleviates data scarcity\nproblems. Our experiments on limited data settings show that lightweight\naugmentation yields significant performance improvement on slot filling on the\nATIS and SNIPS datasets, and achieves competitive performance with respect to\nmore complex, state-of-the-art, augmentation approaches. Furthermore,\nlightweight augmentation is also beneficial when combined with pre-trained\nLM-based models, as it improves BERT-based joint intent and slot filling\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 12:39:47 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Louvan", "Samuel", ""], ["Magnini", "Bernardo", ""]]}, {"id": "2009.03706", "submitter": "Shikun Feng", "authors": "Zhengjie Huang, Shikun Feng, Weiyue Su, Xuyi Chen, Shuohuan Wang,\n  Jiaxiang Liu, Xuan Ouyang, Yu Sun", "title": "ERNIE at SemEval-2020 Task 10: Learning Word Emphasis Selection by\n  Pre-trained Language Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the system designed by ERNIE Team which achieved the\nfirst place in SemEval-2020 Task 10: Emphasis Selection For Written Text in\nVisual Media. Given a sentence, we are asked to find out the most important\nwords as the suggestion for automated design. We leverage the unsupervised\npre-training model and finetune these models on our task. After our\ninvestigation, we found that the following models achieved an excellent\nperformance in this task: ERNIE 2.0, XLM-ROBERTA, ROBERTA and ALBERT. We\ncombine a pointwise regression loss and a pairwise ranking loss which is more\nclose to the final M atchm metric to finetune our models. And we also find that\nadditional feature engineering and data augmentation can help improve the\nperformance. Our best model achieves the highest score of 0.823 and ranks first\nfor all kinds of metrics\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 12:51:22 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Huang", "Zhengjie", ""], ["Feng", "Shikun", ""], ["Su", "Weiyue", ""], ["Chen", "Xuyi", ""], ["Wang", "Shuohuan", ""], ["Liu", "Jiaxiang", ""], ["Ouyang", "Xuan", ""], ["Sun", "Yu", ""]]}, {"id": "2009.03849", "submitter": "Kushal Chawla", "authors": "Abhilasha Sancheti, Kushal Chawla, Gaurav Verma", "title": "LynyrdSkynyrd at WNUT-2020 Task 2: Semi-Supervised Learning for\n  Identification of Informative COVID-19 English Tweets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe our system for WNUT-2020 shared task on the identification of\ninformative COVID-19 English tweets. Our system is an ensemble of various\nmachine learning methods, leveraging both traditional feature-based classifiers\nas well as recent advances in pre-trained language models that help in\ncapturing the syntactic, semantic, and contextual features from the tweets. We\nfurther employ pseudo-labelling to incorporate the unlabelled Twitter data\nreleased on the pandemic. Our best performing model achieves an F1-score of\n0.9179 on the provided validation set and 0.8805 on the blind test-set.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 16:29:25 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Sancheti", "Abhilasha", ""], ["Chawla", "Kushal", ""], ["Verma", "Gaurav", ""]]}, {"id": "2009.03897", "submitter": "Justine Zhang", "authors": "Justine Zhang, Sendhil Mullainathan, Cristian Danescu-Niculescu-Mizil", "title": "Quantifying the Causal Effects of Conversational Tendencies", "comments": "24 pages, 6 figures. In Proceedings of CSCW, 2020", "journal-ref": null, "doi": "10.1145/3415202", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding what leads to effective conversations can aid the design of\nbetter computer-mediated communication platforms. In particular, prior\nobservational work has sought to identify behaviors of individuals that\ncorrelate to their conversational efficiency. However, translating such\ncorrelations to causal interpretations is a necessary step in using them in a\nprescriptive fashion to guide better designs and policies.\n  In this work, we formally describe the problem of drawing causal links\nbetween conversational behaviors and outcomes. We focus on the task of\ndetermining a particular type of policy for a text-based crisis counseling\nplatform: how best to allocate counselors based on their behavioral tendencies\nexhibited in their past conversations. We apply arguments derived from causal\ninference to underline key challenges that arise in conversational settings\nwhere randomized trials are hard to implement. Finally, we show how to\ncircumvent these inference challenges in our particular domain, and illustrate\nthe potential benefits of an allocation policy informed by the resulting\nprescriptive information.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 18:00:00 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Zhang", "Justine", ""], ["Mullainathan", "Sendhil", ""], ["Danescu-Niculescu-Mizil", "Cristian", ""]]}, {"id": "2009.03947", "submitter": "Shervin Minaee", "authors": "Meysam Asgari-Chenaghlu, Narjes Nikzad-Khasmakhi, Shervin Minaee", "title": "Covid-Transformer: Detecting COVID-19 Trending Topics on Twitter Using\n  Universal Sentence Encoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The novel corona-virus disease (also known as COVID-19) has led to a\npandemic, impacting more than 200 countries across the globe. With its global\nimpact, COVID-19 has become a major concern of people almost everywhere, and\ntherefore there are a large number of tweets coming out from every corner of\nthe world, about COVID-19 related topics. In this work, we try to analyze the\ntweets and detect the trending topics and major concerns of people on Twitter,\nwhich can enable us to better understand the situation, and devise better\nplanning. More specifically we propose a model based on the universal sentence\nencoder to detect the main topics of Tweets in recent months. We used universal\nsentence encoder in order to derive the semantic representation and the\nsimilarity of tweets. We then used the sentence similarity and their\nembeddings, and feed them to K-means clustering algorithm to group similar\ntweets (in semantic sense). After that, the cluster summary is obtained using a\ntext summarization algorithm based on deep learning, which can uncover the\nunderlying topics of each cluster. Through experimental results, we show that\nour model can detect very informative topics, by processing a large number of\ntweets on sentence level (which can preserve the overall meaning of the\ntweets). Since this framework has no restriction on specific data distribution,\nit can be used to detect trending topics from any other social media and any\nother context rather than COVID-19. Experimental results show superiority of\nour proposed approach to other baselines, including TF-IDF, and latent\nDirichlet allocation (LDA).\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 19:00:38 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 19:36:33 GMT"}, {"version": "v3", "created": "Sat, 19 Sep 2020 21:10:57 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Asgari-Chenaghlu", "Meysam", ""], ["Nikzad-Khasmakhi", "Narjes", ""], ["Minaee", "Shervin", ""]]}, {"id": "2009.03954", "submitter": "Yiding Hao", "authors": "Yiding Hao, Simon Mendelsohn, Rachel Sterneck, Randi Martinez, Robert\n  Frank", "title": "Probabilistic Predictions of People Perusing: Evaluating Metrics of\n  Language Model Performance for Psycholinguistic Modeling", "comments": "To appear in the proceedings of the Cognitive Modeling and\n  Computational Linguistics workshop (CMCL) at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By positing a relationship between naturalistic reading times and\ninformation-theoretic surprisal, surprisal theory (Hale, 2001; Levy, 2008)\nprovides a natural interface between language models and psycholinguistic\nmodels. This paper re-evaluates a claim due to Goodkind and Bicknell (2018)\nthat a language model's ability to model reading times is a linear function of\nits perplexity. By extending Goodkind and Bicknell's analysis to modern neural\narchitectures, we show that the proposed relation does not always hold for Long\nShort-Term Memory networks, Transformers, and pre-trained models. We introduce\nan alternate measure of language modeling performance called predictability\nnorm correlation based on Cloze probabilities measured from human subjects. Our\nnew metric yields a more robust relationship between language model quality and\npsycholinguistic modeling performance that allows for comparison between models\nwith different training configurations.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 19:12:06 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Hao", "Yiding", ""], ["Mendelsohn", "Simon", ""], ["Sterneck", "Rachel", ""], ["Martinez", "Randi", ""], ["Frank", "Robert", ""]]}, {"id": "2009.03996", "submitter": "Michael S. Fiske", "authors": "Michael Stephen Fiske", "title": "Combining Determinism and Indeterminism", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CC cs.CL math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is to construct mathematical operations that combine indeterminism\nmeasured from quantum randomness with computational determinism so that\nnon-mechanistic behavior is preserved in the computation. Formally, some\nresults about operations applied to computably enumerable (c.e.) and bi-immune\nsets are proven here, where the objective is for the operations to preserve\nbi-immunity. While developing rearrangement operations on the natural numbers,\nwe discovered that the bi-immune rearrangements generate an uncountable\nsubgroup of the infinite symmetric group (Sym$(\\mathbb{N})$) on the natural\nnumbers $\\mathbb{N}$.\n  This new uncountable subgroup is called the bi-immune symmetric group. We\nshow that the bi-immune symmetric group contains the finitary symmetric group\non the natural numbers, and consequently is highly transitive. Furthermore, the\nbi-immune symmetric group is dense in Sym$(\\mathbb{N})$ with respect to the\npointwise convergence topology. The complete structure of the bi-immune\nsymmetric group and its subgroups generated by one or more bi-immune\nrearrangements is unknown.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 01:30:00 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 20:49:50 GMT"}, {"version": "v3", "created": "Mon, 21 Sep 2020 20:00:10 GMT"}, {"version": "v4", "created": "Thu, 19 Nov 2020 18:22:48 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Fiske", "Michael Stephen", ""]]}, {"id": "2009.04007", "submitter": "Devendra Singh Sachan", "authors": "Devendra Singh Sachan and Manzil Zaheer and Ruslan Salakhutdinov", "title": "Revisiting LSTM Networks for Semi-Supervised Text Classification via\n  Mixed Objective Function", "comments": "Published at AAAI 2019", "journal-ref": null, "doi": "10.1609/aaai.v33i01.33016940", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study bidirectional LSTM network for the task of text\nclassification using both supervised and semi-supervised approaches. Several\nprior works have suggested that either complex pretraining schemes using\nunsupervised methods such as language modeling (Dai and Le 2015; Miyato, Dai,\nand Goodfellow 2016) or complicated models (Johnson and Zhang 2017) are\nnecessary to achieve a high classification accuracy. However, we develop a\ntraining strategy that allows even a simple BiLSTM model, when trained with\ncross-entropy loss, to achieve competitive results compared with more complex\napproaches. Furthermore, in addition to cross-entropy loss, by using a\ncombination of entropy minimization, adversarial, and virtual adversarial\nlosses for both labeled and unlabeled data, we report state-of-the-art results\nfor text classification task on several benchmark datasets. In particular, on\nthe ACL-IMDB sentiment analysis and AG-News topic classification datasets, our\nmethod outperforms current approaches by a substantial margin. We also show the\ngenerality of the mixed objective function by improving the performance on\nrelation extraction task.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 21:55:22 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Sachan", "Devendra Singh", ""], ["Zaheer", "Manzil", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "2009.04008", "submitter": "Laura Biester", "authors": "Laura Biester, Katie Matton, Janarthanan Rajendran, Emily Mower\n  Provost, Rada Mihalcea", "title": "Quantifying the Effects of COVID-19 on Mental Health Support Forums", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic, like many of the disease outbreaks that have preceded\nit, is likely to have a profound effect on mental health. Understanding its\nimpact can inform strategies for mitigating negative consequences. In this\nwork, we seek to better understand the effects of COVID-19 on mental health by\nexamining discussions within mental health support communities on Reddit.\nFirst, we quantify the rate at which COVID-19 is discussed in each community,\nor subreddit, in order to understand levels of preoccupation with the pandemic.\nNext, we examine the volume of activity in order to determine whether the\nquantity of people seeking online mental health support has risen. Finally, we\nanalyze how COVID-19 has influenced language use and topics of discussion\nwithin each subreddit.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 21:59:08 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Biester", "Laura", ""], ["Matton", "Katie", ""], ["Rajendran", "Janarthanan", ""], ["Provost", "Emily Mower", ""], ["Mihalcea", "Rada", ""]]}, {"id": "2009.04016", "submitter": "George Zerveas", "authors": "George Zerveas, Ruochen Zhang, Leila Kim, Carsten Eickhoff", "title": "Brown University at TREC Deep Learning 2019", "comments": null, "journal-ref": "Proceedings of the Twenty-Eighth Text REtrieval Conference, TREC\n  2019, Gaithersburg, Maryland, USA, November 13-15, 2019. NIST Special\n  Publication 1250, National Institute of Standards and Technology (NIST) 2019", "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes Brown University's submission to the TREC 2019 Deep\nLearning track. We followed a 2-phase method for producing a ranking of\npassages for a given input query: In the the first phase, the user's query is\nexpanded by appending 3 queries generated by a transformer model which was\ntrained to rephrase an input query into semantically similar queries. The\nexpanded query can exhibit greater similarity in surface form and vocabulary\noverlap with the passages of interest and can therefore serve as enriched input\nto any downstream information retrieval method. In the second phase, we use a\nBERT-based model pre-trained for language modeling but fine-tuned for query -\ndocument relevance prediction to compute relevance scores for a set of 1000\ncandidate passages per query and subsequently obtain a ranking of passages by\nsorting them based on the predicted relevance scores. According to the results\npublished in the official Overview of the TREC Deep Learning Track 2019, our\nteam ranked 3rd in the passage retrieval task (including full ranking and\nre-ranking), and 2nd when considering only re-ranking submissions.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 22:54:03 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Zerveas", "George", ""], ["Zhang", "Ruochen", ""], ["Kim", "Leila", ""], ["Eickhoff", "Carsten", ""]]}, {"id": "2009.04070", "submitter": "Junghyun (Tony) Koo", "authors": "Junghyun Koo, Jie Hwan Lee, Jaewoo Pyo, Yujin Jo, Kyogu Lee", "title": "Exploiting Multi-Modal Features From Pre-trained Networks for\n  Alzheimer's Dementia Recognition", "comments": "In the Proceedings of INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collecting and accessing a large amount of medical data is very\ntime-consuming and laborious, not only because it is difficult to find specific\npatients but also because it is required to resolve the confidentiality of a\npatient's medical records. On the other hand, there are deep learning models,\ntrained on easily collectible, large scale datasets such as Youtube or\nWikipedia, offering useful representations. It could therefore be very\nadvantageous to utilize the features from these pre-trained networks for\nhandling a small amount of data at hand. In this work, we exploit various\nmulti-modal features extracted from pre-trained networks to recognize\nAlzheimer's Dementia using a neural network, with a small dataset provided by\nthe ADReSS Challenge at INTERSPEECH 2020. The challenge regards to discern\npatients suspicious of Alzheimer's Dementia by providing acoustic and textual\ndata. With the multi-modal features, we modify a Convolutional Recurrent Neural\nNetwork based structure to perform classification and regression tasks\nsimultaneously and is capable of computing conversations with variable lengths.\nOur test results surpass baseline's accuracy by 18.75%, and our validation\nresult for the regression task shows the possibility of classifying 4 classes\nof cognitive impairment with an accuracy of 78.70%.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 02:08:47 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 03:15:18 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Koo", "Junghyun", ""], ["Lee", "Jie Hwan", ""], ["Pyo", "Jaewoo", ""], ["Jo", "Yujin", ""], ["Lee", "Kyogu", ""]]}, {"id": "2009.04087", "submitter": "Laura Domin\\'e", "authors": "Christopher Liu, Laura Domin\\'e, Kevin Chavez, Richard Socher", "title": "Central Yup'ik and Machine Translation of Low-Resource Polysynthetic\n  Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine translation tools do not yet exist for the Yup'ik language, a\npolysynthetic language spoken by around 8,000 people who live primarily in\nSouthwest Alaska. We compiled a parallel text corpus for Yup'ik and English and\ndeveloped a morphological parser for Yup'ik based on grammar rules. We trained\na seq2seq neural machine translation model with attention to translate Yup'ik\ninput into English. We then compared the influence of different tokenization\nmethods, namely rule-based, unsupervised (byte pair encoding), and unsupervised\nmorphological (Morfessor) parsing, on BLEU score accuracy for Yup'ik to English\ntranslation. We find that using tokenized input increases the translation\naccuracy compared to that of unparsed input. Although overall Morfessor did\nbest with a vocabulary size of 30k, our first experiments show that BPE\nperformed best with a reduced vocabulary size.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 03:11:43 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Liu", "Christopher", ""], ["Domin\u00e9", "Laura", ""], ["Chavez", "Kevin", ""], ["Socher", "Richard", ""]]}, {"id": "2009.04095", "submitter": "Abhijeet Kumar", "authors": "Mayank Chhipa, Hrushikesh Mahesh Vazurkar, Abhijeet Kumar, Mridul\n  Mishra", "title": "Comparative Study of Language Models on Cross-Domain Data with Model\n  Agnostic Explainability", "comments": "6 pages Source code at https://github.com/fidelity/classitransformers\n  PyPi https://pypi.org/project/classitransformers/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent influx of bidirectional contextualized transformer language\nmodels in the NLP, it becomes a necessity to have a systematic comparative\nstudy of these models on variety of datasets. Also, the performance of these\nlanguage models has not been explored on non-GLUE datasets. The study presented\nin paper compares the state-of-the-art language models - BERT, ELECTRA and its\nderivatives which include RoBERTa, ALBERT and DistilBERT. We conducted\nexperiments by finetuning these models for cross domain and disparate data and\npenned an in-depth analysis of model's performances. Moreover, an\nexplainability of language models coherent with pretraining is presented which\nverifies the context capturing capabilities of these models through a model\nagnostic approach. The experimental results establish new state-of-the-art for\nYelp 2013 rating classification task and Financial Phrasebank sentiment\ndetection task with 69% accuracy and 88.2% accuracy respectively. Finally, the\nstudy conferred here can greatly assist industry researchers in choosing the\nlanguage model effectively in terms of performance or compute efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 04:31:44 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Chhipa", "Mayank", ""], ["Vazurkar", "Hrushikesh Mahesh", ""], ["Kumar", "Abhijeet", ""], ["Mishra", "Mridul", ""]]}, {"id": "2009.04202", "submitter": "Ankur Sinha PhD", "authors": "Ankur Sinha and Tanmay Khandait", "title": "Impact of News on the Commodity Market: Dataset and Results", "comments": "13 Pages, 2 Figures, 3 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last few years, machine learning based methods have been applied to\nextract information from news flow in the financial domain. However, this\ninformation has mostly been in the form of the financial sentiments contained\nin the news headlines, primarily for the stock prices. In our current work, we\npropose that various other dimensions of information can be extracted from news\nheadlines, which will be of interest to investors, policy-makers and other\npractitioners. We propose a framework that extracts information such as past\nmovements and expected directionality in prices, asset comparison and other\ngeneral information that the news is referring to. We apply this framework to\nthe commodity \"Gold\" and train the machine learning models using a dataset of\n11,412 human-annotated news headlines (released with this study), collected\nfrom the period 2000-2019. We experiment to validate the causal effect of news\nflow on gold prices and observe that the information produced from our\nframework significantly impacts the future gold price.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 10:38:48 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Sinha", "Ankur", ""], ["Khandait", "Tanmay", ""]]}, {"id": "2009.04413", "submitter": "Ziqiao Wang", "authors": "Ziqiao Wang, Yongyi Mao, Hongyu Guo, Richong Zhang", "title": "On SkipGram Word Embedding Models with Negative Sampling: Unified\n  Framework and Impact of Noise Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SkipGram word embedding models with negative sampling, or SGN in short, is an\nelegant family of word embedding models. In this paper, we formulate a\nframework for word embedding, referred to as Word-Context Classification (WCC),\nthat generalizes SGN to a wide family of models. The framework, utilizing some\n\"noise examples\", is justified through a theoretical analysis. The impact of\nnoise distribution on the learning of the WCC embedding models is studied\nexperimentally, suggesting that the best noise distribution is in fact the data\ndistribution, in terms of both the embedding performance and the speed of\nconvergence during training. Along our way, we discover several novel embedding\nmodels that outperform the existing WCC models.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 02:11:51 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Wang", "Ziqiao", ""], ["Mao", "Yongyi", ""], ["Guo", "Hongyu", ""], ["Zhang", "Richong", ""]]}, {"id": "2009.04485", "submitter": "Edward A. Fox", "authors": "Saurabh Chakravarty and Satvik Chekuri and Maanav Mehrotra and Edward\n  A. Fox", "title": "Aspect Classification for Legal Depositions", "comments": "19 pages, 3 figures, 11 tables, detailed version of shorter paper\n  being submitted to a conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attorneys and others have a strong interest in having a digital library with\nsuitable services (e.g., summarizing, searching, and browsing) to help them\nwork with large corpora of legal depositions. Their needs often involve\nunderstanding the semantics of such documents. That depends in part on the role\nof the deponent, e.g., plaintiff, defendant, law enforcement personnel, expert,\netc. In the case of tort litigation associated with property and casualty\ninsurance claims, such as relating to an injury, it is important to know not\nonly about liability, but also about events, accidents, physical conditions,\nand treatments.\n  We hypothesize that a legal deposition consists of various aspects that are\ndiscussed as part of the deponent testimony. Accordingly, we developed an\nontology of aspects in a legal deposition for accident and injury cases. Using\nthat, we have developed a classifier that can identify portions of text for\neach of the aspects of interest. Doing so was complicated by the peculiarities\nof this genre, e.g., that deposition transcripts generally consist of data in\nthe form of question-answer (QA) pairs. Accordingly, our automated system\nstarts with pre-processing, and then transforms the QA pairs into a canonical\nform made up of declarative sentences. Classifying the declarative sentences\nthat are generated, according to the aspect, can then help with downstream\ntasks such as summarization, segmentation, question-answering, and information\nretrieval.\n  Our methods have achieved a classification F1 score of 0.83. Having the\naspects classified with a good accuracy will help in choosing QA pairs that can\nbe used as candidate summary sentences, and to generate an informative summary\nfor legal professionals or insurance claim agents. Our methodology could be\nextended to legal depositions of other kinds, and to aid services like\nsearching.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 18:00:15 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Chakravarty", "Saurabh", ""], ["Chekuri", "Satvik", ""], ["Mehrotra", "Maanav", ""], ["Fox", "Edward A.", ""]]}, {"id": "2009.04530", "submitter": "Thomas Winters", "authors": "Thomas Winters, Luc De Raedt", "title": "Discovering Textual Structures: Generative Grammar Induction using\n  Template Trees", "comments": "Published in the Proceedings of the 11th International Conference on\n  Computational Creativity, p177-180", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language generation provides designers with methods for automatically\ngenerating text, e.g. for creating summaries, chatbots and game content. In\npractise, text generators are often either learned and hard to interpret, or\ncreated by hand using techniques such as grammars and templates. In this paper,\nwe introduce a novel grammar induction algorithm for learning interpretable\ngrammars for generative purposes, called Gitta. We also introduce the novel\nnotion of template trees to discover latent templates in corpora to derive\nthese generative grammars. By using existing human-created grammars, we found\nthat the algorithm can reasonably approximate these grammars using only a few\nexamples. These results indicate that Gitta could be used to automatically\nlearn interpretable and easily modifiable grammars, and thus provide a stepping\nstone for human-machine co-creation of generative models.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 19:31:04 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Winters", "Thomas", ""], ["De Raedt", "Luc", ""]]}, {"id": "2009.04534", "submitter": "Swetha Mandava", "authors": "Swetha Mandava, Szymon Migacz, Alex Fit Florea", "title": "Pay Attention when Required", "comments": "9 pages, 5 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer-based models consist of interleaved feed-forward blocks - that\ncapture content meaning, and relatively more expensive self-attention blocks -\nthat capture context meaning. In this paper, we explored trade-offs and\nordering of the blocks to improve upon the current Transformer architecture and\nproposed PAR Transformer. It needs 35% lower compute time than Transformer-XL\nachieved by replacing ~63% of the self-attention blocks with feed-forward\nblocks, and retains the perplexity on WikiText-103 language modelling\nbenchmark. We further validated our results on text8 and enwiki8 datasets, as\nwell as on the BERT model.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 19:39:15 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 07:41:58 GMT"}, {"version": "v3", "created": "Mon, 17 May 2021 04:03:34 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Mandava", "Swetha", ""], ["Migacz", "Szymon", ""], ["Florea", "Alex Fit", ""]]}, {"id": "2009.04591", "submitter": "Peng Liu", "authors": "Ying Chen, Peng Liu, Chung Piaw Teo", "title": "Regularised Text Logistic Regression: Key Word Detection and Sentiment\n  Classification for Online Reviews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online customer reviews have become important for managers and executives in\nthe hospitality and catering industry who wish to obtain a comprehensive\nunderstanding of their customers' demands and expectations. We propose a\nRegularized Text Logistic (RTL) regression model to perform text analytics and\nsentiment classification on unstructured text data, which automatically\nidentifies a set of statistically significant and operationally insightful word\nfeatures, and achieves satisfactory predictive classification accuracy. We\napply the RTL model to two online review datasets, Restaurant and Hotel, from\nTripAdvisor. Our results demonstrate satisfactory classification performance\ncompared with alternative classifiers with a highest true positive rate of\n94.9%. Moreover, RTL identifies a small set of word features, corresponding to\n3% for Restaurant and 20% for Hotel, which boosts working efficiency by\nallowing managers to drill down into a much smaller set of important customer\nreviews. We also develop the consistency, sparsity and oracle property of the\nestimator.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 22:37:53 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Chen", "Ying", ""], ["Liu", "Peng", ""], ["Teo", "Chung Piaw", ""]]}, {"id": "2009.04617", "submitter": "Sarah Finch", "authors": "Sarah E. Finch, James D. Finch, Ali Ahmadvand, Ingyu (Jason) Choi,\n  Xiangjue Dong, Ruixiang Qi, Harshita Sahijwani, Sergey Volokhin, Zihan Wang,\n  Zihao Wang, Jinho D. Choi", "title": "Emora: An Inquisitive Social Chatbot Who Cares For You", "comments": "Published in 3rd Proceedings of Alexa Prize (Alexa Prize 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by studies on the overwhelming presence of experience-sharing in\nhuman-human conversations, Emora, the social chatbot developed by Emory\nUniversity, aims to bring such experience-focused interaction to the current\nfield of conversational AI. The traditional approach of information-sharing\ntopic handlers is balanced with a focus on opinion-oriented exchanges that\nEmora delivers, and new conversational abilities are developed that support\ndialogues that consist of a collaborative understanding and learning process of\nthe partner's life experiences. We present a curated dialogue system that\nleverages highly expressive natural language templates, powerful intent\nclassification, and ontology resources to provide an engaging and interesting\nconversational experience to every user.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 00:42:59 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Finch", "Sarah E.", "", "Jason"], ["Finch", "James D.", "", "Jason"], ["Ahmadvand", "Ali", "", "Jason"], ["Ingyu", "", "", "Jason"], ["Choi", "", ""], ["Dong", "Xiangjue", ""], ["Qi", "Ruixiang", ""], ["Sahijwani", "Harshita", ""], ["Volokhin", "Sergey", ""], ["Wang", "Zihan", ""], ["Wang", "Zihao", ""], ["Choi", "Jinho D.", ""]]}, {"id": "2009.04639", "submitter": "Lu Liu", "authors": "Lu Liu, Zhenqiao Song and Xiaoqing Zheng", "title": "Improving Coreference Resolution by Leveraging Entity-Centric Features\n  with Graph Neural Networks and Second-order Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major challenges in coreference resolution is how to make use of\nentity-level features defined over clusters of mentions rather than mention\npairs. However, coreferent mentions usually spread far apart in an entire text,\nwhich makes it extremely difficult to incorporate entity-level features. We\npropose a graph neural network-based coreference resolution method that can\ncapture the entity-centric information by encouraging the sharing of features\nacross all mentions that probably refer to the same real-world entity. Mentions\nare linked to each other via the edges modeling how likely two linked mentions\npoint to the same entity. Modeling by such graphs, the features between\nmentions can be shared by message passing operations in an entity-centric\nmanner. A global inference algorithm up to second-order features is also\npresented to optimally cluster mentions into consistent groups. Experimental\nresults show our graph neural network-based method combing with the\nsecond-order decoding algorithm (named GNNCR) achieved close to\nstate-of-the-art performance on the English CoNLL-2012 Shared Task dataset.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 02:22:21 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Liu", "Lu", ""], ["Song", "Zhenqiao", ""], ["Zheng", "Xiaoqing", ""]]}, {"id": "2009.04656", "submitter": "Yian Li", "authors": "Yian Li, Hai Zhao", "title": "Learning Universal Representations from Word to Sentence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the well-developed cut-edge representation learning for language,\nmost language representation models usually focus on specific level of\nlinguistic unit, which cause great inconvenience when being confronted with\nhandling multiple layers of linguistic objects in a unified way. Thus this work\nintroduces and explores the universal representation learning, i.e., embeddings\nof different levels of linguistic unit in a uniform vector space through a\ntask-independent evaluation. We present our approach of constructing analogy\ndatasets in terms of words, phrases and sentences and experiment with multiple\nrepresentation models to examine geometric properties of the learned vector\nspace. Then we empirically verify that well pre-trained Transformer models\nincorporated with appropriate training settings may effectively yield universal\nrepresentation. Especially, our implementation of fine-tuning ALBERT on NLI and\nPPDB datasets achieves the highest accuracy on analogy tasks in different\nlanguage levels. Further experiments on the insurance FAQ task show\neffectiveness of universal representation models in real-world applications.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 03:53:18 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Li", "Yian", ""], ["Zhao", "Hai", ""]]}, {"id": "2009.04703", "submitter": "Taesun Whang", "authors": "Taesun Whang, Dongyub Lee, Dongsuk Oh, Chanhee Lee, Kijong Han,\n  Dong-hun Lee, Saebyeok Lee", "title": "Do Response Selection Models Really Know What's Next? Utterance\n  Manipulation Strategies for Multi-turn Response Selection", "comments": "Accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the task of selecting the optimal response given a\nuser and system utterance history in retrieval-based multi-turn dialog systems.\nRecently, pre-trained language models (e.g., BERT, RoBERTa, and ELECTRA) showed\nsignificant improvements in various natural language processing tasks. This and\nsimilar response selection tasks can also be solved using such language models\nby formulating the tasks as dialog--response binary classification tasks.\nAlthough existing works using this approach successfully obtained\nstate-of-the-art results, we observe that language models trained in this\nmanner tend to make predictions based on the relatedness of history and\ncandidates, ignoring the sequential nature of multi-turn dialog systems. This\nsuggests that the response selection task alone is insufficient for learning\ntemporal dependencies between utterances. To this end, we propose utterance\nmanipulation strategies (UMS) to address this problem. Specifically, UMS\nconsist of several strategies (i.e., insertion, deletion, and search), which\naid the response selection model towards maintaining dialog coherence. Further,\nUMS are self-supervised methods that do not require additional annotation and\nthus can be easily incorporated into existing approaches. Extensive evaluation\nacross multiple languages and models shows that UMS are highly effective in\nteaching dialog consistency, which leads to models pushing the state-of-the-art\nwith significant margins on multiple public benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 07:39:05 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 11:28:20 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Whang", "Taesun", ""], ["Lee", "Dongyub", ""], ["Oh", "Dongsuk", ""], ["Lee", "Chanhee", ""], ["Han", "Kijong", ""], ["Lee", "Dong-hun", ""], ["Lee", "Saebyeok", ""]]}, {"id": "2009.04707", "submitter": "Mattia Antonino Di Gangi", "authors": "Mattia Antonino Di Gangi and Marco Gaido and Matteo Negri and Marco\n  Turchi", "title": "On Target Segmentation for Direct Speech Translation", "comments": "14 pages single column, 4 figures, accepted for presentation at the\n  AMTA2020 research track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies on direct speech translation show continuous improvements by\nmeans of data augmentation techniques and bigger deep learning models. While\nthese methods are helping to close the gap between this new approach and the\nmore traditional cascaded one, there are many incongruities among different\nstudies that make it difficult to assess the state of the art. Surprisingly,\none point of discussion is the segmentation of the target text. Character-level\nsegmentation has been initially proposed to obtain an open vocabulary, but it\nresults on long sequences and long training time. Then, subword-level\nsegmentation became the state of the art in neural machine translation as it\nproduces shorter sequences that reduce the training time, while being superior\nto word-level models. As such, recent works on speech translation started using\ntarget subwords despite the initial use of characters and some recent claims of\nbetter results at the character level. In this work, we perform an extensive\ncomparison of the two methods on three benchmarks covering 8 language\ndirections and multilingual training. Subword-level segmentation compares\nfavorably in all settings, outperforming its character-level counterpart in a\nrange of 1 to 3 BLEU points.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 07:47:01 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Di Gangi", "Mattia Antonino", ""], ["Gaido", "Marco", ""], ["Negri", "Matteo", ""], ["Turchi", "Marco", ""]]}, {"id": "2009.04732", "submitter": "Trieu Hai Nguyen", "authors": "Trieu Hai Nguyen", "title": "Analyze the Effects of Weighting Functions on Cost Function in the Glove\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When dealing with the large vocabulary size and corpus size, the run-time for\ntraining Glove model is long, it can even be up to several dozen hours for\ndata, which is approximately 500MB in size. As a result, finding and selecting\nthe optimal parameters for the weighting function create many difficulties for\nweak hardware. Of course, to get the best results, we need to test benchmarks\nmany times. In order to solve this problem, we derive a weighting function,\nwhich can save time for choosing parameters and making benchmarks. It also\nallows one to obtain nearly similar accuracy at the same given time without\nconcern for experimentation.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 08:55:25 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Nguyen", "Trieu Hai", ""]]}, {"id": "2009.04765", "submitter": "Damian Pascual", "authors": "Nicolas Affolter, Beni Egressy, Damian Pascual, Roger Wattenhofer", "title": "Brain2Word: Decoding Brain Activity for Language Generation", "comments": "Preprint. Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain decoding, understood as the process of mapping brain activities to the\nstimuli that generated them, has been an active research area in the last\nyears. In the case of language stimuli, recent studies have shown that it is\npossible to decode fMRI scans into an embedding of the word a subject is\nreading. However, such word embeddings are designed for natural language\nprocessing tasks rather than for brain decoding. Therefore, they limit our\nability to recover the precise stimulus. In this work, we propose to directly\nclassify an fMRI scan, mapping it to the corresponding word within a fixed\nvocabulary. Unlike existing work, we evaluate on scans from previously unseen\nsubjects. We argue that this is a more realistic setup and we present a model\nthat can decode fMRI data from unseen subjects. Our model achieves 5.22% Top-1\nand 13.59% Top-5 accuracy in this challenging task, significantly outperforming\nall the considered competitive baselines. Furthermore, we use the decoded words\nto guide language generation with the GPT-2 model. This way, we advance the\nquest for a system that translates brain activities into coherent text.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 10:47:36 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 08:05:08 GMT"}, {"version": "v3", "created": "Wed, 11 Nov 2020 08:07:08 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Affolter", "Nicolas", ""], ["Egressy", "Beni", ""], ["Pascual", "Damian", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "2009.04798", "submitter": "Isabelle van der Vegt", "authors": "Isabelle van der Vegt, Maximilian Mozes, Bennett Kleinberg, Paul Gill", "title": "The Grievance Dictionary: Understanding Threatening Language Use", "comments": "pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the Grievance Dictionary, a psycholinguistic dictionary\nwhich can be used to automatically understand language use in the context of\ngrievance-fuelled violence threat assessment. We describe the development the\ndictionary, which was informed by suggestions from experienced threat\nassessment practitioners. These suggestions and subsequent human and\ncomputational word list generation resulted in a dictionary of 20,502 words\nannotated by 2,318 participants. The dictionary was validated by applying it to\ntexts written by violent and non-violent individuals, showing strong evidence\nfor a difference between populations in several dictionary categories. Further\nclassification tasks showed promising performance, but future improvements are\nstill needed. Finally, we provide instructions and suggestions for the use of\nthe Grievance Dictionary by security professionals and (violence) researchers.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 12:06:48 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["van der Vegt", "Isabelle", ""], ["Mozes", "Maximilian", ""], ["Kleinberg", "Bennett", ""], ["Gill", "Paul", ""]]}, {"id": "2009.04891", "submitter": "Nithin Holla", "authors": "Nithin Holla, Pushkar Mishra, Helen Yannakoudakis, Ekaterina Shutova", "title": "Meta-Learning with Sparse Experience Replay for Lifelong Language\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lifelong learning requires models that can continuously learn from sequential\nstreams of data without suffering catastrophic forgetting due to shifts in data\ndistributions. Deep learning models have thrived in the non-sequential learning\nparadigm; however, when used to learn a sequence of tasks, they fail to retain\npast knowledge and learn incrementally. We propose a novel approach to lifelong\nlearning of language tasks based on meta-learning with sparse experience replay\nthat directly optimizes to prevent forgetting. We show that under the realistic\nsetting of performing a single pass on a stream of tasks and without any task\nidentifiers, our method obtains state-of-the-art results on lifelong text\nclassification and relation extraction. We analyze the effectiveness of our\napproach and further demonstrate its low computational and space complexity.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 14:36:38 GMT"}, {"version": "v2", "created": "Sun, 25 Jul 2021 16:07:02 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Holla", "Nithin", ""], ["Mishra", "Pushkar", ""], ["Yannakoudakis", "Helen", ""], ["Shutova", "Ekaterina", ""]]}, {"id": "2009.04953", "submitter": "Saumya Banthia", "authors": "Saumya Banthia, Anantha Sharma", "title": "Classification of descriptions and summary using multiple passes of\n  statistical and natural language toolkits", "comments": "9 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This document describes a possible approach that can be used to check the\nrelevance of a summary / definition of an entity with respect to its name. This\nclassifier focuses on the relevancy of an entity's name to its summary /\ndefinition, in other words, it is a name relevance check. The percentage score\nobtained from this approach can be used either on its own or used to supplement\nscores obtained from other metrics to arrive upon a final classification; at\nthe end of the document, potential improvements have also been outlined. The\ndataset that this document focuses on achieving an objective score is a list of\npackage names and their respective summaries (sourced from pypi.org).\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 15:49:24 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Banthia", "Saumya", ""], ["Sharma", "Anantha", ""]]}, {"id": "2009.04965", "submitter": "Meng-Jiun Chiou", "authors": "Meng-Jiun Chiou, Roger Zimmermann, Jiashi Feng", "title": "Visual Relationship Detection with Visual-Linguistic Knowledge from\n  Multimodal Representations", "comments": "Published in IEEE Access", "journal-ref": "IEEE Access, 2021", "doi": "10.1109/ACCESS.2021.3069041", "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual relationship detection aims to reason over relationships among salient\nobjects in images, which has drawn increasing attention over the past few\nyears. Inspired by human reasoning mechanisms, it is believed that external\nvisual commonsense knowledge is beneficial for reasoning visual relationships\nof objects in images, which is however rarely considered in existing methods.\nIn this paper, we propose a novel approach named Relational Visual-Linguistic\nBidirectional Encoder Representations from Transformers (RVL-BERT), which\nperforms relational reasoning with both visual and language commonsense\nknowledge learned via self-supervised pre-training with multimodal\nrepresentations. RVL-BERT also uses an effective spatial module and a novel\nmask attention module to explicitly capture spatial information among the\nobjects. Moreover, our model decouples object detection from visual\nrelationship recognition by taking in object names directly, enabling it to be\nused on top of any object detection system. We show through quantitative and\nqualitative experiments that, with the transferred knowledge and novel modules,\nRVL-BERT achieves competitive results on two challenging visual relationship\ndetection datasets. The source code is available at\nhttps://github.com/coldmanck/RVL-BERT.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 16:15:09 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 14:01:49 GMT"}, {"version": "v3", "created": "Mon, 5 Apr 2021 07:48:10 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Chiou", "Meng-Jiun", ""], ["Zimmermann", "Roger", ""], ["Feng", "Jiashi", ""]]}, {"id": "2009.04968", "submitter": "Dimas Munoz", "authors": "Dimas Munoz Montesinos", "title": "Modern Methods for Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Synthetic text generation is challenging and has limited success. Recently, a\nnew architecture, called Transformers, allow machine learning models to\nunderstand better sequential data, such as translation or summarization. BERT\nand GPT-2, using Transformers in their cores, have shown a great performance in\ntasks such as text classification, translation and NLI tasks. In this article,\nwe analyse both algorithms and compare their output quality in text generation\ntasks.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 16:17:10 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Montesinos", "Dimas Munoz", ""]]}, {"id": "2009.04975", "submitter": "Andrea Fronzetti Colladon PhD", "authors": "A. Fronzetti Colladon, S. Grassi, F. Ravazzolo, F. Violante", "title": "Forecasting financial markets with semantic network analysis in the\n  COVID-19 crisis", "comments": "15 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.CL cs.SI econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper uses a new textual data index for predicting stock market data.\nThe index is applied to a large set of news to evaluate the importance of one\nor more general economic related keywords appearing in the text. The index\nassesses the importance of the economic related keywords, based on their\nfrequency of use and semantic network position. We apply it to the Italian\npress and construct indices to predict Italian stock and bond market returns\nand volatilities in a recent sample period, including the COVID-19 crisis. The\nevidence shows that the index captures the different phases of financial time\nseries well. Moreover, results indicate strong evidence of predictability for\nbond market data, both returns and volatilities, short and long maturities, and\nstock market volatility.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 15:40:56 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 18:55:57 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Colladon", "A. Fronzetti", ""], ["Grassi", "S.", ""], ["Ravazzolo", "F.", ""], ["Violante", "F.", ""]]}, {"id": "2009.04984", "submitter": "Junlong Li", "authors": "Junlong Li, Zhuosheng Zhang, Hai Zhao, Xi Zhou, Xiang Zhou", "title": "Task-specific Objectives of Pre-trained Language Models for Dialogue\n  Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained Language Models (PrLMs) have been widely used as backbones in\nlots of Natural Language Processing (NLP) tasks. The common process of\nutilizing PrLMs is first pre-training on large-scale general corpora with\ntask-independent LM training objectives, then fine-tuning on task datasets with\ntask-specific training objectives. Pre-training in a task-independent way\nenables the models to learn language representations, which is universal to\nsome extent, but fails to capture crucial task-specific features in the\nmeantime. This will lead to an incompatibility between pre-training and\nfine-tuning. To address this issue, we introduce task-specific pre-training on\nin-domain task-related corpora with task-specific objectives. This procedure is\nplaced between the original two stages to enhance the model understanding\ncapacity of specific tasks. In this work, we focus on Dialogue-related Natural\nLanguage Processing (DrNLP) tasks and design a Dialogue-Adaptive Pre-training\nObjective (DAPO) based on some important qualities for assessing dialogues\nwhich are usually ignored by general LM pre-training objectives. PrLMs with\nDAPO on a large in-domain dialogue corpus are then fine-tuned for downstream\nDrNLP tasks. Experimental results show that models with DAPO surpass those with\ngeneral LM pre-training objectives and other strong baselines on downstream\nDrNLP tasks.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 16:46:46 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Li", "Junlong", ""], ["Zhang", "Zhuosheng", ""], ["Zhao", "Hai", ""], ["Zhou", "Xi", ""], ["Zhou", "Xiang", ""]]}, {"id": "2009.05019", "submitter": "Aparna Khare", "authors": "Aparna Khare, Srinivas Parthasarathy, Shiva Sundaram", "title": "Multi-modal embeddings using multi-task learning for emotion recognition", "comments": "To appear in Interspeech,2020", "journal-ref": null, "doi": "10.21437/Interspeech.2020-1827", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General embeddings like word2vec, GloVe and ELMo have shown a lot of success\nin natural language tasks. The embeddings are typically extracted from models\nthat are built on general tasks such as skip-gram models and natural language\ngeneration. In this paper, we extend the work from natural language\nunderstanding to multi-modal architectures that use audio, visual and textual\ninformation for machine learning tasks. The embeddings in our network are\nextracted using the encoder of a transformer model trained using multi-task\ntraining. We use person identification and automatic speech recognition as the\ntasks in our embedding generation framework. We tune and evaluate the\nembeddings on the downstream task of emotion recognition and demonstrate that\non the CMU-MOSEI dataset, the embeddings can be used to improve over previous\nstate of the art results.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 17:33:16 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Khare", "Aparna", ""], ["Parthasarathy", "Srinivas", ""], ["Sundaram", "Shiva", ""]]}, {"id": "2009.05021", "submitter": "Soujanya Poria", "authors": "Rishabh Bhardwaj, Navonil Majumder, Soujanya Poria", "title": "Investigating Gender Bias in BERT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Contextual language models (CLMs) have pushed the NLP benchmarks to a new\nheight. It has become a new norm to utilize CLM provided word embeddings in\ndownstream tasks such as text classification. However, unless addressed, CLMs\nare prone to learn intrinsic gender-bias in the dataset. As a result,\npredictions of downstream NLP models can vary noticeably by varying gender\nwords, such as replacing \"he\" to \"she\", or even gender-neutral words. In this\npaper, we focus our analysis on a popular CLM, i.e., BERT. We analyse the\ngender-bias it induces in five downstream tasks related to emotion and\nsentiment intensity prediction. For each task, we train a simple regressor\nutilizing BERT's word embeddings. We then evaluate the gender-bias in\nregressors using an equity evaluation corpus. Ideally and from the specific\ndesign, the models should discard gender informative features from the input.\nHowever, the results show a significant dependence of the system's predictions\non gender-particular words and phrases. We claim that such biases can be\nreduced by removing genderspecific features from word embedding. Hence, for\neach layer in BERT, we identify directions that primarily encode gender\ninformation. The space formed by such directions is referred to as the gender\nsubspace in the semantic space of word embeddings. We propose an algorithm that\nfinds fine-grained gender directions, i.e., one primary direction for each BERT\nlayer. This obviates the need of realizing gender subspace in multiple\ndimensions and prevents other crucial information from being omitted.\nExperiments show that removing embedding components in such directions achieves\ngreat success in reducing BERT-induced bias in the downstream tasks.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 17:38:32 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Bhardwaj", "Rishabh", ""], ["Majumder", "Navonil", ""], ["Poria", "Soujanya", ""]]}, {"id": "2009.05032", "submitter": "Timo Homburg", "authors": "Timo Homburg, Steffen Staab, Daniel Janke", "title": "GeoSPARQL+: Syntax, Semantics and System for Integrated Querying of\n  Graph, Raster and Vector Data -- Technical Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an approach to semantically represent and query raster data in a\nSemantic Web graph. We extend the GeoSPARQL vocabulary and query language to\nsupport raster data as a new type of geospatial data. We define new filter\nfunctions and illustrate our approach using several use cases on real-world\ndata sets. Finally, we describe a prototypical implementation and validate the\nfeasibility of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 17:53:19 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Homburg", "Timo", ""], ["Staab", "Steffen", ""], ["Janke", "Daniel", ""]]}, {"id": "2009.05092", "submitter": "Soujanya Poria", "authors": "Hui Chen, Pengfei Hong, Wei Han, Navonil Majumder, Soujanya Poria", "title": "Dialogue Relation Extraction with Document-level Heterogeneous Graph\n  Attention Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Dialogue relation extraction (DRE) aims to detect the relation between two\nentities mentioned in a multi-party dialogue. It plays an important role in\nconstructing knowledge graphs from conversational data increasingly abundant on\nthe internet and facilitating intelligent dialogue system development. The\nprior methods of DRE do not meaningfully leverage speaker information-they just\nprepend the utterances with the respective speaker names. Thus, they fail to\nmodel the crucial inter-speaker relations that may give additional context to\nrelevant argument entities through pronouns and triggers. We, however, present\na graph attention network-based method for DRE where a graph, that contains\nmeaningfully connected speaker, entity, entity-type, and utterance nodes, is\nconstructed. This graph is fed to a graph attention network for context\npropagation among relevant nodes, which effectively captures the dialogue\ncontext. We empirically show that this graph-based approach quite effectively\ncaptures the relations between different entity pairs in a dialogue as it\noutperforms the state-of-the-art approaches by a significant margin on the\nbenchmark dataset DialogRE. Our code is released at:\nhttps://github.com/declare-lab/dialog-HGAT\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 18:51:48 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 08:20:29 GMT"}, {"version": "v3", "created": "Sun, 20 Jun 2021 05:06:34 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Chen", "Hui", ""], ["Hong", "Pengfei", ""], ["Han", "Wei", ""], ["Majumder", "Navonil", ""], ["Poria", "Soujanya", ""]]}, {"id": "2009.05121", "submitter": "Sarvesh Soni", "authors": "Sarvesh Soni and Kirk Roberts", "title": "Patient Cohort Retrieval using Transformer Language Models", "comments": "Accepted at the AMIA Annual Symposium 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply deep learning-based language models to the task of patient cohort\nretrieval (CR) with the aim to assess their efficacy. The task of CR requires\nthe extraction of relevant documents from the electronic health records (EHRs)\non the basis of a given query. Given the recent advancements in the field of\ndocument retrieval, we map the task of CR to a document retrieval task and\napply various deep neural models implemented for the general domain tasks. In\nthis paper, we propose a framework for retrieving patient cohorts using neural\nlanguage models without the need of explicit feature engineering and domain\nexpertise. We find that a majority of our models outperform the BM25 baseline\nmethod on various evaluation metrics.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 19:40:41 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Soni", "Sarvesh", ""], ["Roberts", "Kirk", ""]]}, {"id": "2009.05128", "submitter": "Surabhi Datta", "authors": "Surabhi Datta, Jordan Godfrey-Stovall, Kirk Roberts", "title": "RadLex Normalization in Radiology Reports", "comments": "Accepted at the AMIA Annual Symposium 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radiology reports have been widely used for extraction of various clinically\nsignificant information about patients' imaging studies. However, limited\nresearch has focused on standardizing the entities to a common\nradiology-specific vocabulary. Further, no study to date has attempted to\nleverage RadLex for standardization. In this paper, we aim to normalize a\ndiverse set of radiological entities to RadLex terms. We manually construct a\nnormalization corpus by annotating entities from three types of reports. This\ncontains 1706 entity mentions. We propose two deep learning-based NLP methods\nbased on a pre-trained language model (BERT) for automatic normalization.\nFirst, we employ BM25 to retrieve candidate concepts for the BERT-based models\n(re-ranker and span detector) to predict the normalized concept. The results\nare promising, with the best accuracy (78.44%) obtained by the span detector.\nAdditionally, we discuss the challenges involved in corpus construction and\npropose new RadLex terms.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 19:59:08 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Datta", "Surabhi", ""], ["Godfrey-Stovall", "Jordan", ""], ["Roberts", "Kirk", ""]]}, {"id": "2009.05160", "submitter": "Amir Atapour Abarghouei", "authors": "Amir Atapour-Abarghouei, Stephen Bonner, Andrew Stephen McGough", "title": "Rank over Class: The Untapped Potential of Ranking in Natural Language\n  Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text classification has long been a staple in natural language processing\nwith applications spanning across sentiment analysis, online content tagging,\nrecommender systems and spam detection. However, text classification, by\nnature, suffers from a variety of issues stemming from dataset imbalance, text\nambiguity, subjectivity and the lack of linguistic context in the data. In this\npaper, we explore the use of text ranking, commonly used in information\nretrieval, to carry out challenging classification-based tasks. We propose a\nnovel end-to-end ranking approach consisting of a Transformer network\nresponsible for producing representations for a pair of text sequences, which\nare in turn passed into a context aggregating network outputting ranking scores\nused to determine an ordering to the sequences based on some notion of\nrelevance. We perform numerous experiments on publicly-available datasets and\ninvestigate the possibility of applying our ranking approach to certain\nproblems often addressed using classification. In an experiment on a\nheavily-skewed sentiment analysis dataset, converting ranking results to\nclassification labels yields an approximately 22% improvement over\nstate-of-the-art text classification, demonstrating the efficacy of text\nranking over text classification in certain scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 22:18:57 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2020 11:34:35 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Atapour-Abarghouei", "Amir", ""], ["Bonner", "Stephen", ""], ["McGough", "Andrew Stephen", ""]]}, {"id": "2009.05166", "submitter": "Yuwei Fang", "authors": "Yuwei Fang, Shuohang Wang, Zhe Gan, Siqi Sun, Jingjing Liu", "title": "FILTER: An Enhanced Fusion Method for Cross-lingual Language\n  Understanding", "comments": "Accepted to AAAI 2021; Top-1 Performance on XTREME\n  (https://sites.research.google/xtreme, September 8, 2020) and XGLUE\n  (https://microsoft.github.io/XGLUE, September 14, 2020) benchmark", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale cross-lingual language models (LM), such as mBERT, Unicoder and\nXLM, have achieved great success in cross-lingual representation learning.\nHowever, when applied to zero-shot cross-lingual transfer tasks, most existing\nmethods use only single-language input for LM finetuning, without leveraging\nthe intrinsic cross-lingual alignment between different languages that proves\nessential for multilingual tasks. In this paper, we propose FILTER, an enhanced\nfusion method that takes cross-lingual data as input for XLM finetuning.\nSpecifically, FILTER first encodes text input in the source language and its\ntranslation in the target language independently in the shallow layers, then\nperforms cross-language fusion to extract multilingual knowledge in the\nintermediate layers, and finally performs further language-specific encoding.\nDuring inference, the model makes predictions based on the text input in the\ntarget language and its translation in the source language. For simple tasks\nsuch as classification, translated text in the target language shares the same\nlabel as the source language. However, this shared label becomes less accurate\nor even unavailable for more complex tasks such as question answering, NER and\nPOS tagging. To tackle this issue, we further propose an additional\nKL-divergence self-teaching loss for model training, based on auto-generated\nsoft pseudo-labels for translated text in the target language. Extensive\nexperiments demonstrate that FILTER achieves new state of the art on two\nchallenging multilingual multi-task benchmarks, XTREME and XGLUE.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 22:42:15 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 23:11:36 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2020 07:11:22 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Fang", "Yuwei", ""], ["Wang", "Shuohang", ""], ["Gan", "Zhe", ""], ["Sun", "Siqi", ""], ["Liu", "Jingjing", ""]]}, {"id": "2009.05167", "submitter": "Yuwei Fang", "authors": "Yuwei Fang, Shuohang Wang, Zhe Gan, Siqi Sun, Jingjing Liu", "title": "Accelerating Real-Time Question Answering via Question Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing approaches to real-time question answering (RTQA) rely on learning\nthe representations of only key phrases in the documents, then matching them\nwith the question representation to derive answer. However, such approach is\nbottlenecked by the encoding time of real-time questions, thus suffering from\ndetectable latency in deployment for large-volume traffic. To accelerate RTQA\nfor practical use, we present Ocean-Q (an Ocean of Questions), a novel approach\nthat leverages question generation (QG) for RTQA. Ocean-Q introduces a QG model\nto generate a large pool of question-answer (QA) pairs offline, then in real\ntime matches an input question with the candidate QA pool to predict the answer\nwithout question encoding. To further improve QG quality, we propose a new data\naugmentation method and leverage multi-task learning and diverse beam search to\nboost RTQA performance. Experiments on SQuAD(-open) and HotpotQA benchmarks\ndemonstrate that Ocean-Q is able to accelerate the fastest state-of-the-art\nRTQA system by 4X times, with only a 3+% accuracy drop.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 22:44:29 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Fang", "Yuwei", ""], ["Wang", "Shuohang", ""], ["Gan", "Zhe", ""], ["Sun", "Siqi", ""], ["Liu", "Jingjing", ""]]}, {"id": "2009.05169", "submitter": "Micha{\\l} Pietruszka", "authors": "Micha{\\l} Pietruszka, {\\L}ukasz Borchmann, {\\L}ukasz Garncarek", "title": "Sparsifying Transformer Models with Trainable Representation Pooling", "comments": "Provided formal overview. Reevaluated with Google Research script", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method to sparsify attention in the Transformer model by\nlearning to select the most-informative token representations during the\ntraining process, thus focusing on task-specific parts of the input. A\nreduction of quadratic time and memory complexity to sublinear was achieved due\nto a robust trainable top-k operator. For example, our experiments on a\nchallenging summarization task of long documents show that our method is over 3\ntimes faster and up to 16 times more memory efficient while significantly\noutperforming both dense and state-of-the-art sparse transformer models. The\nmethod can be effortlessly applied to many models used in NLP and CV,\nsimultaneously with other improvements.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 22:49:39 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 16:49:01 GMT"}, {"version": "v3", "created": "Thu, 4 Feb 2021 22:34:47 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Pietruszka", "Micha\u0142", ""], ["Borchmann", "\u0141ukasz", ""], ["Garncarek", "\u0141ukasz", ""]]}, {"id": "2009.05175", "submitter": "Khyathi Raghavi Chandu", "authors": "Khyathi Raghavi Chandu, Piyush Sharma, Soravit Changpinyo, Ashish\n  Thapliyal, Radu Soricut", "title": "Denoising Large-Scale Image Captioning from Alt-text Data using Content\n  Selection Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training large-scale image captioning (IC) models demands access to a rich\nand diverse set of training examples, gathered from the wild, often from noisy\nalt-text data. However, recent modeling approaches to IC often fall short in\nterms of performance in this case, because they assume a clean annotated\ndataset (as opposed to the noisier alt-text--based annotations), and employ an\nend-to-end generation approach, which often lacks both controllability and\ninterpretability. We address these problems by breaking down the task into two\nsimpler, more controllable tasks -- skeleton prediction and skeleton-based\ncaption generation. Specifically, we show that selecting content words as\nskeletons} helps in generating improved and denoised captions when leveraging\nrich yet noisy alt-text--based uncurated datasets. We also show that the\npredicted English skeletons can be further cross-lingually leveraged to\ngenerate non-English captions, and present experimental results covering\ncaption generation in French, Italian, German, Spanish and Hindi. We also show\nthat skeleton-based prediction allows for better control of certain caption\nproperties, such as length, content, and gender expression, providing a handle\nto perform human-in-the-loop semi-automatic corrections.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 23:31:38 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 23:11:48 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Chandu", "Khyathi Raghavi", ""], ["Sharma", "Piyush", ""], ["Changpinyo", "Soravit", ""], ["Thapliyal", "Ashish", ""], ["Soricut", "Radu", ""]]}, {"id": "2009.05289", "submitter": "Andrei Paraschiv", "authors": "Andrei Paraschiv, Dumitru-Clementin Cercel, Mihai Dascalu", "title": "UPB at SemEval-2020 Task 11: Propaganda Detection with Domain-Specific\n  Trained BERT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Manipulative and misleading news have become a commodity for some online news\noutlets and these news have gained a significant impact on the global mindset\nof people. Propaganda is a frequently employed manipulation method having as\ngoal to influence readers by spreading ideas meant to distort or manipulate\ntheir opinions. This paper describes our participation in the SemEval-2020,\nTask 11: Detection of Propaganda Techniques in News Articles competition. Our\napproach considers specializing a pre-trained BERT model on propagandistic and\nhyperpartisan news articles, enabling it to create more adequate\nrepresentations for the two subtasks, namely propaganda Span Identification\n(SI) and propaganda Technique Classification (TC). Our proposed system achieved\na F1-score of 46.060% in subtask SI, ranking 5th in the leaderboard from 36\nteams and a micro-averaged F1 score of 54.302% for subtask TC, ranking 19th\nfrom 32 teams.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 08:44:14 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Paraschiv", "Andrei", ""], ["Cercel", "Dumitru-Clementin", ""], ["Dascalu", "Mihai", ""]]}, {"id": "2009.05387", "submitter": "Genta Indra Winata", "authors": "Bryan Wilie, Karissa Vincentio, Genta Indra Winata, Samuel\n  Cahyawijaya, Xiaohong Li, Zhi Yuan Lim, Sidik Soleman, Rahmad Mahendra,\n  Pascale Fung, Syafri Bahar, Ayu Purwarianti", "title": "IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural\n  Language Understanding", "comments": "This paper will be presented in AACL-IJCNLP 2020 (with new results\n  and acknowledgment)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Indonesian is known to be the fourth most frequently used language\nover the internet, the research progress on this language in the natural\nlanguage processing (NLP) is slow-moving due to a lack of available resources.\nIn response, we introduce the first-ever vast resource for the training,\nevaluating, and benchmarking on Indonesian natural language understanding\n(IndoNLU) tasks. IndoNLU includes twelve tasks, ranging from single sentence\nclassification to pair-sentences sequence labeling with different levels of\ncomplexity. The datasets for the tasks lie in different domains and styles to\nensure task diversity. We also provide a set of Indonesian pre-trained models\n(IndoBERT) trained from a large and clean Indonesian dataset Indo4B collected\nfrom publicly available sources such as social media texts, blogs, news, and\nwebsites. We release baseline models for all twelve tasks, as well as the\nframework for benchmark evaluation, and thus it enables everyone to benchmark\ntheir system performances.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 12:21:41 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 13:13:40 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 13:11:59 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Wilie", "Bryan", ""], ["Vincentio", "Karissa", ""], ["Winata", "Genta Indra", ""], ["Cahyawijaya", "Samuel", ""], ["Li", "Xiaohong", ""], ["Lim", "Zhi Yuan", ""], ["Soleman", "Sidik", ""], ["Mahendra", "Rahmad", ""], ["Fung", "Pascale", ""], ["Bahar", "Syafri", ""], ["Purwarianti", "Ayu", ""]]}, {"id": "2009.05426", "submitter": "Vivi Nastase", "authors": "Vivi Nastase and Stan Szpakowicz", "title": "Semantic Relations and Deep Learning", "comments": "86 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The second edition of \"Semantic Relations Between Nominals\" by Vivi Nastase,\nStan Szpakowicz, Preslav Nakov and Diarmuid \\'O S\\'eaghdha has been published\nin April 2021 by Morgan & Claypool\n(www.morganclaypoolpublishers.com/catalog_Orig/product_info.php?products_id=1627).\nA new Chapter 5 of the book, by Vivi Nastase and Stan Szpakowicz, discusses\nrelation classification/extraction in the deep-learning paradigm which arose\nafter the first edition appeared. This is Chapter 5, made public by the kind\npermission of Morgan & Claypool.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 13:21:28 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 04:58:40 GMT"}, {"version": "v3", "created": "Tue, 2 Feb 2021 21:33:07 GMT"}, {"version": "v4", "created": "Thu, 15 Apr 2021 13:45:06 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Nastase", "Vivi", ""], ["Szpakowicz", "Stan", ""]]}, {"id": "2009.05451", "submitter": "Aysu Can", "authors": "Aysu Ezen-Can", "title": "A Comparison of LSTM and BERT for Small Corpus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in the NLP field showed that transfer learning helps with\nachieving state-of-the-art results for new tasks by tuning pre-trained models\ninstead of starting from scratch. Transformers have made a significant\nimprovement in creating new state-of-the-art results for many NLP tasks\nincluding but not limited to text classification, text generation, and sequence\nlabeling. Most of these success stories were based on large datasets. In this\npaper we focus on a real-life scenario that scientists in academia and industry\nface frequently: given a small dataset, can we use a large pre-trained model\nlike BERT and get better results than simple models? To answer this question,\nwe use a small dataset for intent classification collected for building\nchatbots and compare the performance of a simple bidirectional LSTM model with\na pre-trained BERT model. Our experimental results show that bidirectional LSTM\nmodels can achieve significantly higher results than a BERT model for a small\ndataset and these simple models get trained in much less time than tuning the\npre-trained counterparts. We conclude that the performance of a model is\ndependent on the task and the data, and therefore before making a model choice,\nthese factors should be taken into consideration instead of directly choosing\nthe most popular model.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 14:01:14 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Ezen-Can", "Aysu", ""]]}, {"id": "2009.05456", "submitter": "Yasser Otiefy", "authors": "Yasser Otiefy (WideBot), Ahmed Abdelmalek (WideBot), Islam El Hosary\n  (WideBot)", "title": "WOLI at SemEval-2020 Task 12: Arabic Offensive Language Identification\n  on Different Twitter Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Communicating through social platforms has become one of the principal means\nof personal communications and interactions. Unfortunately, healthy\ncommunication is often interfered by offensive language that can have damaging\neffects on the users. A key to fight offensive language on social media is the\nexistence of an automatic offensive language detection system. This paper\npresents the results and the main findings of SemEval-2020, Task 12 OffensEval\nSub-task A Zampieri et al. (2020), on Identifying and categorising Offensive\nLanguage in Social Media. The task was based on the Arabic OffensEval dataset\nMubarak et al. (2020). In this paper, we describe the system submitted by\nWideBot AI Lab for the shared task which ranked 10th out of 52 participants\nwith Macro-F1 86.9% on the golden dataset under CodaLab username\n\"yasserotiefy\". We experimented with various models and the best model is a\nlinear SVM in which we use a combination of both character and word n-grams. We\nalso introduced a neural network approach that enhanced the predictive ability\nof our system that includes CNN, highway network, Bi-LSTM, and attention\nlayers.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 14:10:03 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Otiefy", "Yasser", "", "WideBot"], ["Abdelmalek", "Ahmed", "", "WideBot"], ["Hosary", "Islam El", "", "WideBot"]]}, {"id": "2009.05460", "submitter": "Toms Bergmanis", "authors": "Toms Bergmanis, Art\\=urs Stafanovi\\v{c}s, M\\=arcis Pinnis", "title": "Robust Neural Machine Translation: Modeling Orthographic and\n  Interpunctual Variation", "comments": "Accepted in BALTIC HLT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neural machine translation systems typically are trained on curated corpora\nand break when faced with non-standard orthography or punctuation. Resilience\nto spelling mistakes and typos, however, is crucial as machine translation\nsystems are used to translate texts of informal origins, such as chat\nconversations, social media posts and web pages. We propose a simple generative\nnoise model to generate adversarial examples of ten different types. We use\nthese to augment machine translation systems' training data and show that, when\ntested on noisy data, systems trained using adversarial examples perform almost\nas well as when translating clean data, while baseline systems' performance\ndrops by 2-3 BLEU points. To measure the robustness and noise invariance of\nmachine translation systems' outputs, we use the average translation edit rate\nbetween the translation of the original sentence and its noised variants. Using\nthis measure, we show that systems trained on adversarial examples on average\nyield 50% consistency improvements when compared to baselines trained on clean\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 14:12:54 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 11:16:38 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Bergmanis", "Toms", ""], ["Stafanovi\u010ds", "Art\u016brs", ""], ["Pinnis", "M\u0101rcis", ""]]}, {"id": "2009.05493", "submitter": "Adriana Stan PhD", "authors": "Adriana Stan", "title": "RECOApy: Data recording, pre-processing and phonetic transcription for\n  end-to-end speech-based applications", "comments": "Accepted for publication at Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning enables the development of efficient end-to-end speech\nprocessing applications while bypassing the need for expert linguistic and\nsignal processing features. Yet, recent studies show that good quality speech\nresources and phonetic transcription of the training data can enhance the\nresults of these applications. In this paper, the RECOApy tool is introduced.\nRECOApy streamlines the steps of data recording and pre-processing required in\nend-to-end speech-based applications. The tool implements an easy-to-use\ninterface for prompted speech recording, spectrogram and waveform analysis,\nutterance-level normalisation and silence trimming, as well grapheme-to-phoneme\nconversion of the prompts in eight languages: Czech, English, French, German,\nItalian, Polish, Romanian and Spanish.\n  The grapheme-to-phoneme (G2P) converters are deep neural network (DNN) based\narchitectures trained on lexicons extracted from the Wiktionary online\ncollaborative resource. With the different degree of orthographic transparency,\nas well as the varying amount of phonetic entries across the languages, the\nDNN's hyperparameters are optimised with an evolution strategy. The phoneme and\nword error rates of the resulting G2P converters are presented and discussed.\nThe tool, the processed phonetic lexicons and trained G2P models are made\nfreely available.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 15:26:55 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 09:07:33 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Stan", "Adriana", ""]]}, {"id": "2009.05552", "submitter": "Qi Huang", "authors": "Tong Gao, Qi Huang, Raymond J. Mooney", "title": "Systematic Generalization on gSCAN with Language Conditioned Embedding", "comments": "Accepted by AACL-IJCNLP 2020. Huang and Gao share co-first\n  authorship, authors contribute equally and are listed in alphabetical order", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systematic Generalization refers to a learning algorithm's ability to\nextrapolate learned behavior to unseen situations that are distinct but\nsemantically similar to its training data. As shown in recent work,\nstate-of-the-art deep learning models fail dramatically even on tasks for which\nthey are designed when the test set is systematically different from the\ntraining data. We hypothesize that explicitly modeling the relations between\nobjects in their contexts while learning their representations will help\nachieve systematic generalization. Therefore, we propose a novel method that\nlearns objects' contextualized embeddings with dynamic message passing\nconditioned on the input natural language and end-to-end trainable with other\ndownstream deep learning modules. To our knowledge, this model is the first one\nthat significantly outperforms the provided baseline and reaches\nstate-of-the-art performance on grounded-SCAN (gSCAN), a grounded natural\nlanguage navigation dataset designed to require systematic generalization in\nits test splits.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 17:35:05 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 20:59:57 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Gao", "Tong", ""], ["Huang", "Qi", ""], ["Mooney", "Raymond J.", ""]]}, {"id": "2009.05560", "submitter": "Ancil Crayton", "authors": "Ancil Crayton, Jo\\~ao Fonseca, Kanav Mehra, Michelle Ng, Jared Ross,\n  Marcelo Sandoval-Casta\\~neda, Rachel von Gnechten", "title": "Narratives and Needs: Analyzing Experiences of Cyclone Amphan Using\n  Twitter Discourse", "comments": "6 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People often turn to social media to comment upon and share information about\nmajor global events. Accordingly, social media is receiving increasing\nattention as a rich data source for understanding people's social, political\nand economic experiences of extreme weather events. In this paper, we\ncontribute two novel methodologies that leverage Twitter discourse to\ncharacterize narratives and identify unmet needs in response to Cyclone Amphan,\nwhich affected 18 million people in May 2020.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 17:49:05 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Crayton", "Ancil", ""], ["Fonseca", "Jo\u00e3o", ""], ["Mehra", "Kanav", ""], ["Ng", "Michelle", ""], ["Ross", "Jared", ""], ["Sandoval-Casta\u00f1eda", "Marcelo", ""], ["von Gnechten", "Rachel", ""]]}, {"id": "2009.05603", "submitter": "Dumitru-Clementin Cercel", "authors": "Andrei-Marius Avram, Dumitru-Clementin Cercel, Costin-Gabriel Chiru", "title": "UPB at SemEval-2020 Task 6: Pretrained Language Models for Definition\n  Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work presents our contribution in the context of the 6th task of\nSemEval-2020: Extracting Definitions from Free Text in Textbooks (DeftEval).\nThis competition consists of three subtasks with different levels of\ngranularity: (1) classification of sentences as definitional or\nnon-definitional,(2) labeling of definitional sentences, and (3) relation\nclassification. We use various pretrained language models (i.e., BERT, XLNet,\nRoBERTa, SciBERT, and ALBERT) to solve each of the three subtasks of the\ncompetition. Specifically, for each language model variant, we experiment by\nboth freezing its weights and fine-tuning them. We also explore a multi-task\narchitecture that was trained to jointly predict the outputs for the second and\nthe third subtasks. Our best performing model evaluated on the DeftEval dataset\nobtains the 32nd place for the first subtask and the 37th place for the second\nsubtask. The code is available for further research at:\nhttps://github.com/avramandrei/DeftEval.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 18:36:22 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 19:33:05 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Avram", "Andrei-Marius", ""], ["Cercel", "Dumitru-Clementin", ""], ["Chiru", "Costin-Gabriel", ""]]}, {"id": "2009.05617", "submitter": "Michele Tufano", "authors": "Michele Tufano, Dawn Drain, Alexey Svyatkovskiy, Shao Kun Deng, Neel\n  Sundaresan", "title": "Unit Test Case Generation with Transformers and Focal Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated unit test case generation tools facilitate test-driven development\nand support developers by suggesting tests intended to identify flaws in their\ncode. Existing approaches are usually guided by the test coverage criteria,\ngenerating synthetic test cases that are often difficult for developers to read\nor understand. In this paper we propose AthenaTest, an approach that aims to\ngenerate unit test cases by learning from real-world focal methods and\ndeveloper-written testcases. We formulate unit test case generation as a\nsequence-to-sequence learning task, adopting a two-step training procedure\nconsisting of denoising pretraining on a large unsupervised Java corpus, and\nsupervised finetuning for a downstream translation task of generating unit\ntests. We investigate the impact of natural language and source code\npretraining, as well as the focal context information surrounding the focal\nmethod. Both techniques provide improvements in terms of validation loss, with\npretraining yielding 25% relative improvement and focal context providing\nadditional 11.1% improvement. We also introduce Methods2Test, the largest\npublicly available supervised parallel corpus of unit test case methods and\ncorresponding focal methods in Java, which comprises 780K test cases mined from\n91K open-source repositories from GitHub. We evaluate AthenaTest on five\ndefects4j projects, generating 25K passing test cases covering 43.7% of the\nfocal methods with only 30 attempts. We execute the test cases, collect test\ncoverage information, and compare them with test cases generated by EvoSuite\nand GPT-3, finding that our approach outperforms GPT-3 and has comparable\ncoverage w.r.t. EvoSuite. Finally, we survey professional developers on their\npreference in terms of readability, understandability, and testing\neffectiveness of the generated tests, showing overwhelmingly preference towards\nAthenaTest.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 18:57:36 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 23:11:01 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Tufano", "Michele", ""], ["Drain", "Dawn", ""], ["Svyatkovskiy", "Alexey", ""], ["Deng", "Shao Kun", ""], ["Sundaresan", "Neel", ""]]}, {"id": "2009.05639", "submitter": "Klim Zaporojets", "authors": "Klim Zaporojets, Giannis Bekoulis, Johannes Deleu, Thomas Demeester,\n  Chris Develder", "title": "Solving Arithmetic Word Problems by Scoring Equations with Recursive\n  Neural Networks", "comments": null, "journal-ref": "Expert Systems with Applications, 174 (2021) 114704", "doi": "10.1016/j.eswa.2021.114704", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving arithmetic word problems is a cornerstone task in assessing language\nunderstanding and reasoning capabilities in NLP systems. Recent works use\nautomatic extraction and ranking of candidate solution equations providing the\nanswer to arithmetic word problems. In this work, we explore novel approaches\nto score such candidate solution equations using tree-structured recursive\nneural network (Tree-RNN) configurations. The advantage of this Tree-RNN\napproach over using more established sequential representations, is that it can\nnaturally capture the structure of the equations. Our proposed method consists\nof transforming the mathematical expression of the equation into an expression\ntree. Further, we encode this tree into a Tree-RNN by using different Tree-LSTM\narchitectures. Experimental results show that our proposed method (i) improves\noverall performance with more than 3% accuracy points compared to previous\nstate-of-the-art, and with over 15% points on a subset of problems that require\nmore complex reasoning, and (ii) outperforms sequential LSTMs by 4% accuracy\npoints on such more complex problems.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 19:48:42 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 12:49:35 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Zaporojets", "Klim", ""], ["Bekoulis", "Giannis", ""], ["Deleu", "Johannes", ""], ["Demeester", "Thomas", ""], ["Develder", "Chris", ""]]}, {"id": "2009.05664", "submitter": "Anurag Acharya", "authors": "Anurag Acharya, Kartik Talamadupula and Mark A Finlayson", "title": "Towards an Atlas of Cultural Commonsense for Machine Reasoning", "comments": "9 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing commonsense reasoning datasets for AI and NLP tasks fail to address\nan important aspect of human life: cultural differences. We introduce an\napproach that extends prior work on crowdsourcing commonsense knowledge by\nincorporating differences in knowledge that are attributable to cultural or\nnational groups. We demonstrate the technique by collecting commonsense\nknowledge that surrounds six fairly universal rituals -- birth, coming-of-age,\nmarriage, funerals, new year, and birthdays -- across two national groups: the\nUnited States and India. Our study expands the different types of relationships\nidentified by existing work in the field of commonsense reasoning for\ncommonplace events, and uses these new types to gather information that\ndistinguish the identity of the groups providing the knowledge. It also moves\nus a step closer towards building a machine that doesn't assume a rigid\nframework of universal (and likely Western-biased) commonsense knowledge, but\nrather has the ability to reason in a contextually and culturally sensitive\nway. Our hope is that cultural knowledge of this sort will lead to more\nhuman-like performance in NLP tasks such as question answering (QA) and text\nunderstanding and generation.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 21:24:33 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 06:31:44 GMT"}, {"version": "v3", "created": "Fri, 18 Dec 2020 23:26:25 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Acharya", "Anurag", ""], ["Talamadupula", "Kartik", ""], ["Finlayson", "Mark A", ""]]}, {"id": "2009.05675", "submitter": "Ayu Purwarianti", "authors": "Turfa Auliarachman (1), Ayu Purwarianti (1) ((1) Institut Teknologi\n  Bandung)", "title": "Coreference Resolution System for Indonesian Text with Mention Pair\n  Method and Singleton Exclusion using Convolutional Neural Network", "comments": null, "journal-ref": "2019 International Conference of Advanced Informatics: Concepts,\n  Theory and Applications (ICAICTA)", "doi": "10.1109/ICAICTA.2019.8904261", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network has shown promising performance on coreference resolution\nsystems that uses mention pair method. With deep neural network, it can learn\nhidden and deep relations between two mentions. However, there is no work on\ncoreference resolution for Indonesian text that uses this learning technique.\nThe state-of-the-art system for Indonesian text only states the use of lexical\nand syntactic features can improve the existing coreference resolution system.\nIn this paper, we propose a new coreference resolution system for Indonesian\ntext with mention pair method that uses deep neural network to learn the\nrelations of the two mentions. In addition to lexical and syntactic features,\nin order to learn the representation of the mentions words and context, we use\nword embeddings and feed them to Convolutional Neural Network (CNN).\nFurthermore, we do singleton exclusion using singleton classifier component to\nprevent singleton mentions entering any entity clusters at the end. Achieving\n67.37% without singleton exclusion, 63.27% with trained singleton classifier,\nand 75.95% with gold singleton classifier on CoNLL average F1 score, our\nproposed system outperforms the state-of-the-art system.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 22:21:19 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Auliarachman", "Turfa", ""], ["Purwarianti", "Ayu", ""]]}, {"id": "2009.05687", "submitter": "Ayu Purwarianti", "authors": "Devin Hoesen (1), Ayu Purwarianti (2) ((1) Prosa.ai, (2) Institut\n  Teknologi Bandung)", "title": "Investigating Bi-LSTM and CRF with POS Tag Embedding for Indonesian\n  Named Entity Tagger", "comments": null, "journal-ref": "2018 International Conference on Asian Language Processing (IALP)", "doi": "10.1109/IALP.2018.8629158", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researches on Indonesian named entity (NE) tagger have been conducted since\nyears ago. However, most did not use deep learning and instead employed\ntraditional machine learning algorithms such as association rule, support\nvector machine, random forest, na\\\"ive bayes, etc. In those researches, word\nlists as gazetteers or clue words were provided to enhance the accuracy. Here,\nwe attempt to employ deep learning in our Indonesian NE tagger. We use long\nshort-term memory (LSTM) as the topology since it is the state-of-the-art of NE\ntagger. By using LSTM, we do not need a word list in order to enhance the\naccuracy. Basically, there are two main things that we investigate. The first\nis the output layer of the network: Softmax vs conditional random field (CRF).\nThe second is the usage of part of speech (POS) tag embedding input layer.\nUsing 8400 sentences as the training data and 97 sentences as the evaluation\ndata, we find that using POS tag embedding as additional input improves the\nperformance of our Indonesian NE tagger. As for the comparison between Softmax\nand CRF, we find that both architectures have a weakness in classifying an NE\ntag.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 23:54:31 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Hoesen", "Devin", ""], ["Purwarianti", "Ayu", ""]]}, {"id": "2009.05698", "submitter": "Ayu Purwarianti", "authors": "Ramos Janoah Hasudungan (1), Ayu Purwarianti (1) ((1) Institut\n  Teknologi Bandung)", "title": "Relation Detection for Indonesian Language using Deep Neural Network --\n  Support Vector Machine", "comments": "2018 International Conference on Asian Language Processing (IALP)", "journal-ref": null, "doi": "10.1109/IALP.2018.8629248", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation Detection is a task to determine whether two entities are related or\nnot. In this paper, we employ neural network to do relation detection between\ntwo named entities for Indonesian Language. We used feature such as word\nembedding, position embedding, POS-Tag embedding, and character embedding. For\nthe model, we divide the model into two parts: Front-part classifier\n(Convolutional layer or LSTM layer) and Back-part classifier (Dense layer or\nSVM). We did grid search method of neural network hyper parameter and SVM. We\nused 6000 Indonesian sentences for training process and 1,125 for testing. The\nbest result is 0.8083 on F1-Score using Convolutional Layer as front-part and\nSVM as back-part.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 01:45:08 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Hasudungan", "Ramos Janoah", ""], ["Purwarianti", "Ayu", ""]]}, {"id": "2009.05713", "submitter": "Ayu Purwarianti", "authors": "Ilham Firdausi Putra (1), Ayu Purwarianti (1 and 2) ((1) Institut\n  Teknologi Bandung, (2) U-CoE AI-VLB)", "title": "Improving Indonesian Text Classification Using Multilingual Language\n  Model", "comments": null, "journal-ref": "2020 International Conference on Advanced Informatics: Concept,\n  Theory and Application (ICAICTA)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared to English, the amount of labeled data for Indonesian text\nclassification tasks is very small. Recently developed multilingual language\nmodels have shown its ability to create multilingual representations\neffectively. This paper investigates the effect of combining English and\nIndonesian data on building Indonesian text classification (e.g., sentiment\nanalysis and hate speech) using multilingual language models. Using the\nfeature-based approach, we observe its performance on various data sizes and\ntotal added English data. The experiment showed that the addition of English\ndata, especially if the amount of Indonesian data is small, improves\nperformance. Using the fine-tuning approach, we further showed its\neffectiveness in utilizing the English language to build Indonesian text\nclassification models.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 03:16:25 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Putra", "Ilham Firdausi", "", "1 and 2"], ["Purwarianti", "Ayu", "", "1 and 2"]]}, {"id": "2009.05720", "submitter": "Ayu Purwarianti", "authors": "Ayu Purwarianti (1), Ida Ayu Putu Ari Crisdayanti (1) ((1) Institut\n  Teknologi Bandung)", "title": "Improving Bi-LSTM Performance for Indonesian Sentiment Analysis Using\n  Paragraph Vector", "comments": null, "journal-ref": "2019 International Conference of Advanced Informatics: Concepts,\n  Theory and Applications (ICAICTA)", "doi": "10.1109/ICAICTA.2019.8904199", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bidirectional Long Short-Term Memory Network (Bi-LSTM) has shown promising\nperformance in sentiment classification task. It processes inputs as sequence\nof information. Due to this behavior, sentiment predictions by Bi-LSTM were\ninfluenced by words sequence and the first or last phrases of the texts tend to\nhave stronger features than other phrases. Meanwhile, in the problem scope of\nIndonesian sentiment analysis, phrases that express the sentiment of a document\nmight not appear in the first or last part of the document that can lead to\nincorrect sentiment classification. To this end, we propose the using of an\nexisting document representation method called paragraph vector as additional\ninput features for Bi-LSTM. This vector provides information context of the\ndocument for each sequence processing. The paragraph vector is simply\nconcatenated to each word vector of the document. This representation also\nhelps to differentiate ambiguous Indonesian words. Bi-LSTM and paragraph vector\nwere previously used as separate methods. Combining the two methods has shown a\nsignificant performance improvement of Indonesian sentiment analysis model.\nSeveral case studies on testing data showed that the proposed method can handle\nthe sentiment phrases position problem encountered by Bi-LSTM.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 03:43:30 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Purwarianti", "Ayu", ""], ["Crisdayanti", "Ida Ayu Putu Ari", ""]]}, {"id": "2009.05737", "submitter": "Zuchao Li", "authors": "Zuchao Li, Hai Zhao, Shexia He, Jiaxun Cai", "title": "Syntax Role for Neural Semantic Role Labeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic role labeling (SRL) is dedicated to recognizing the semantic\npredicate-argument structure of a sentence. Previous studies in terms of\ntraditional models have shown syntactic information can make remarkable\ncontributions to SRL performance; however, the necessity of syntactic\ninformation was challenged by a few recent neural SRL studies that demonstrate\nimpressive performance without syntactic backbones and suggest that syntax\ninformation becomes much less important for neural semantic role labeling,\nespecially when paired with recent deep neural network and large-scale\npre-trained language models. Despite this notion, the neural SRL field still\nlacks a systematic and full investigation on the relevance of syntactic\ninformation in SRL, for both dependency and both monolingual and multilingual\nsettings. This paper intends to quantify the importance of syntactic\ninformation for neural SRL in the deep learning framework. We introduce three\ntypical SRL frameworks (baselines), sequence-based, tree-based, and\ngraph-based, which are accompanied by two categories of exploiting syntactic\ninformation: syntax pruning-based and syntax feature-based. Experiments are\nconducted on the CoNLL-2005, 2009, and 2012 benchmarks for all languages\navailable, and results show that neural SRL models can still benefit from\nsyntactic information under certain conditions. Furthermore, we show the\nquantitative significance of syntax to neural SRL models together with a\nthorough empirical survey using existing models.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 07:01:12 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Li", "Zuchao", ""], ["Zhao", "Hai", ""], ["He", "Shexia", ""], ["Cai", "Jiaxun", ""]]}, {"id": "2009.05781", "submitter": "Li Zhang", "authors": "Li Zhang, Qing Lyu, Chris Callison-Burch", "title": "Intent Detection with WikiHow", "comments": "In AACL-IJCNLP 2020", "journal-ref": "Proceedings of the 1st Conference of the Asia-Pacific Chapter of\n  the Association for Computational Linguistics and the 10th International\n  Joint Conference on Natural Language Processing (2020) 328-333", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern task-oriented dialog systems need to reliably understand users'\nintents. Intent detection is most challenging when moving to new domains or new\nlanguages, since there is little annotated data. To address this challenge, we\npresent a suite of pretrained intent detection models. Our models are able to\npredict a broad range of intended goals from many actions because they are\ntrained on wikiHow, a comprehensive instructional website. Our models achieve\nstate-of-the-art results on the Snips dataset, the Schema-Guided Dialogue\ndataset, and all 3 languages of the Facebook multilingual dialog datasets. Our\nmodels also demonstrate strong zero- and few-shot performance, reaching over\n75% accuracy using only 100 training examples in all datasets.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 12:53:47 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 15:46:03 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Zhang", "Li", ""], ["Lyu", "Qing", ""], ["Callison-Burch", "Chris", ""]]}, {"id": "2009.05782", "submitter": "Yandrapati Prakash Babu", "authors": "Yandrapati Prakash Babu and Rajagopal Eswari", "title": "CIA_NITT at WNUT-2020 Task 2: Classification of COVID-19 Tweets Using\n  Pre-trained Language Models", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents our models for WNUT 2020 shared task2. The shared task2\ninvolves identification of COVID-19 related informative tweets. We treat this\nas binary text classification problem and experiment with pre-trained language\nmodels. Our first model which is based on CT-BERT achieves F1-score of 88.7%\nand second model which is an ensemble of CT-BERT, RoBERTa and SVM achieves\nF1-score of 88.52%.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 12:59:54 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Babu", "Yandrapati Prakash", ""], ["Eswari", "Rajagopal", ""]]}, {"id": "2009.05817", "submitter": "Zeyu Zhu", "authors": "Huimin Chen, Zeyu Zhu, Fanchao Qi, Yining Ye, Zhiyuan Liu, Maosong\n  Sun, Jianbin Jin", "title": "Country Image in COVID-19 Pandemic: A Case Study of China", "comments": null, "journal-ref": null, "doi": "10.1109/TBDATA.2020.3023459", "report-no": null, "categories": "cs.CY cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Country image has a profound influence on international relations and\neconomic development. In the worldwide outbreak of COVID-19, countries and\ntheir people display different reactions, resulting in diverse perceived images\namong foreign public. Therefore, in this study, we take China as a specific and\ntypical case and investigate its image with aspect-based sentiment analysis on\na large-scale Twitter dataset. To our knowledge, this is the first study to\nexplore country image in such a fine-grained way. To perform the analysis, we\nfirst build a manually-labeled Twitter dataset with aspect-level sentiment\nannotations. Afterward, we conduct the aspect-based sentiment analysis with\nBERT to explore the image of China. We discover an overall sentiment change\nfrom non-negative to negative in the general public, and explain it with the\nincreasing mentions of negative ideology-related aspects and decreasing\nmentions of non-negative fact-based aspects. Further investigations into\ndifferent groups of Twitter users, including U.S. Congress members, English\nmedia, and social bots, reveal different patterns in their attitudes toward\nChina. This study provides a deeper understanding of the changing image of\nChina in COVID-19 pandemic. Our research also demonstrates how aspect-based\nsentiment analysis can be applied in social science researches to deliver\nvaluable insights.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 15:54:51 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Chen", "Huimin", ""], ["Zhu", "Zeyu", ""], ["Qi", "Fanchao", ""], ["Ye", "Yining", ""], ["Liu", "Zhiyuan", ""], ["Sun", "Maosong", ""], ["Jin", "Jianbin", ""]]}, {"id": "2009.05831", "submitter": "Kai Sun", "authors": "Kai Sun, Dian Yu, Jianshu Chen, Dong Yu, Claire Cardie", "title": "Improving Machine Reading Comprehension with Contextualized Commonsense\n  Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aim to extract commonsense knowledge to improve machine\nreading comprehension. We propose to represent relations implicitly by\nsituating structured knowledge in a context instead of relying on a pre-defined\nset of relations, and we call it contextualized knowledge. Each piece of\ncontextualized knowledge consists of a pair of interrelated verbal and\nnonverbal messages extracted from a script and the scene in which they occur as\ncontext to implicitly represent the relation between the verbal and nonverbal\nmessages, which are originally conveyed by different modalities within the\nscript. We propose a two-stage fine-tuning strategy to use the large-scale\nweakly-labeled data based on a single type of contextualized knowledge and\nemploy a teacher-student paradigm to inject multiple types of contextualized\nknowledge into a student machine reader. Experimental results demonstrate that\nour method outperforms a state-of-the-art baseline by a 4.3% improvement in\naccuracy on the machine reading comprehension dataset C^3, wherein most of the\nquestions require unstated prior knowledge.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 17:20:01 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 02:22:06 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Sun", "Kai", ""], ["Yu", "Dian", ""], ["Chen", "Jianshu", ""], ["Yu", "Dong", ""], ["Cardie", "Claire", ""]]}, {"id": "2009.05834", "submitter": "Shuyang Sun", "authors": "Yi Zhou, Shuyang Sun, Chao Zhang, Yikang Li, Wanli Ouyang", "title": "Exploring the Hierarchy in Relation Labels for Scene Graph Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By assigning each relationship a single label, current approaches formulate\nthe relationship detection as a classification problem. Under this formulation,\npredicate categories are treated as completely different classes. However,\ndifferent from the object labels where different classes have explicit\nboundaries, predicates usually have overlaps in their semantic meanings. For\nexample, sit\\_on and stand\\_on have common meanings in vertical relationships\nbut different details of how these two objects are vertically placed. In order\nto leverage the inherent structures of the predicate categories, we propose to\nfirst build the language hierarchy and then utilize the Hierarchy Guided\nFeature Learning (HGFL) strategy to learn better region features of both the\ncoarse-grained level and the fine-grained level. Besides, we also propose the\nHierarchy Guided Module (HGM) to utilize the coarse-grained level to guide the\nlearning of fine-grained level features. Experiments show that the proposed\nsimple yet effective method can improve several state-of-the-art baselines by a\nlarge margin (up to $33\\%$ relative gain) in terms of Recall@50 on the task of\nScene Graph Generation in different datasets.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 17:36:53 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Zhou", "Yi", ""], ["Sun", "Shuyang", ""], ["Zhang", "Chao", ""], ["Li", "Yikang", ""], ["Ouyang", "Wanli", ""]]}, {"id": "2009.05836", "submitter": "Haihua Chen", "authors": "Haihua Chen and Huyen Nguyen", "title": "Fine-tuning Pre-trained Contextual Embeddings for Citation Content\n  Analysis in Scholarly Publication", "comments": "1 figure and three tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Citation function and citation sentiment are two essential aspects of\ncitation content analysis (CCA), which are useful for influence analysis, the\nrecommendation of scientific publications. However, existing studies are mostly\ntraditional machine learning methods, although deep learning techniques have\nalso been explored, the improvement of the performance seems not significant\ndue to insufficient training data, which brings difficulties to applications.\nIn this paper, we propose to fine-tune pre-trained contextual embeddings\nULMFiT, BERT, and XLNet for the task. Experiments on three public datasets show\nthat our strategy outperforms all the baselines in terms of the F1 score. For\ncitation function identification, the XLNet model achieves 87.2%, 86.90%, and\n81.6% on DFKI, UMICH, and TKDE2019 datasets respectively, while it achieves\n91.72% and 91.56% on DFKI and UMICH in term of citation sentiment\nidentification. Our method can be used to enhance the influence analysis of\nscholars and scholarly publications.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2020 17:46:24 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Chen", "Haihua", ""], ["Nguyen", "Huyen", ""]]}, {"id": "2009.05886", "submitter": "Dylan Slack", "authors": "Gavin Kerrigan and Dylan Slack and Jens Tuyls", "title": "Differentially Private Language Models Benefit from Public Pre-training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language modeling is a keystone task in natural language processing. When\ntraining a language model on sensitive information, differential privacy (DP)\nallows us to quantify the degree to which our private data is protected.\nHowever, training algorithms which enforce differential privacy often lead to\ndegradation in model quality. We study the feasibility of learning a language\nmodel which is simultaneously high-quality and privacy preserving by tuning a\npublic base model on a private corpus. We find that DP fine-tuning boosts the\nperformance of language models in the private domain, making the training of\nsuch models possible.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 00:50:44 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 16:04:43 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Kerrigan", "Gavin", ""], ["Slack", "Dylan", ""], ["Tuyls", "Jens", ""]]}, {"id": "2009.05935", "submitter": "Khaidzir Muhammad Shahih", "authors": "K. M. Shahih, Ayu Purwarianti", "title": "Combining Word and Character Vector Representation on Neural Machine\n  Translation", "comments": "5 pages, 5 figures. Published in 2019 Fourth International Conference\n  on Informatics and Computing (ICIC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes combinations of word vector representation and character\nvector representation in English-Indonesian neural machine translation (NMT).\nSix configurations of NMT models were built with different input vector\nrepresentations: word-based, combination of word and character representation\nusing bidirectional LSTM(bi-LSTM), combination of word and character\nrepresentation using CNN, combination of word and character representation by\ncombining bi-LSTM and CNN by three different vector operations: addition,\npointwise multiplication, and averaging. The experiment results showed that NMT\nmodels with concatenation of word and character representation obtained BLEU\nscore higher than baseline model, ranging from 9.14 points to 11.65 points, for\nall models that combining both word and character representation, except the\nmodel that combining word and character representation using both bi-LSTM and\nCNN by addition operation. The highest BLEU score achieved was 42.48 compared\nto the 30.83 of the baseline model.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 06:53:40 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Shahih", "K. M.", ""], ["Purwarianti", "Ayu", ""]]}, {"id": "2009.05940", "submitter": "Takuma Yoneda", "authors": "Takuma Yoneda, Matthew R. Walter, Jason Naradowsky", "title": "Pow-Wow: A Dataset and Study on Collaborative Communication in Pommerman", "comments": "Accepted at LaReL workshop at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-agent learning, agents must coordinate with each other in order to\nsucceed. For humans, this coordination is typically accomplished through the\nuse of language. In this work we perform a controlled study of human language\nuse in a competitive team-based game, and search for useful lessons for\nstructuring communication protocol between autonomous agents. We construct\nPow-Wow, a new dataset for studying situated goal-directed human communication.\nUsing the Pommerman game environment, we enlisted teams of humans to play\nagainst teams of AI agents, recording their observations, actions, and\ncommunications. We analyze the types of communications which result in\neffective game strategies, annotate them accordingly, and present corpus-level\nstatistical analysis of how trends in communications affect game outcomes.\nBased on this analysis, we design a communication policy for learning agents,\nand show that agents which utilize communication achieve higher win-rates\nagainst baseline systems than those which do not.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 07:11:37 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Yoneda", "Takuma", ""], ["Walter", "Matthew R.", ""], ["Naradowsky", "Jason", ""]]}, {"id": "2009.05959", "submitter": "Tongwen Huang", "authors": "Tongwen Huang, Qingyun She, Junlin Zhang", "title": "BoostingBERT:Integrating Multi-Class Boosting into BERT for NLP Tasks", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As a pre-trained Transformer model, BERT (Bidirectional Encoder\nRepresentations from Transformers) has achieved ground-breaking performance on\nmultiple NLP tasks. On the other hand, Boosting is a popular ensemble learning\ntechnique which combines many base classifiers and has been demonstrated to\nyield better generalization performance in many machine learning tasks. Some\nworks have indicated that ensemble of BERT can further improve the application\nperformance. However, current ensemble approaches focus on bagging or stacking\nand there has not been much effort on exploring the boosting. In this work, we\nproposed a novel Boosting BERT model to integrate multi-class boosting into the\nBERT. Our proposed model uses the pre-trained Transformer as the base\nclassifier to choose harder training sets to fine-tune and gains the benefits\nof both the pre-training language knowledge and boosting ensemble in NLP tasks.\nWe evaluate the proposed model on the GLUE dataset and 3 popular Chinese NLU\nbenchmarks. Experimental results demonstrate that our proposed model\nsignificantly outperforms BERT on all datasets and proves its effectiveness in\nmany NLP tasks. Replacing the BERT base with RoBERTa as base classifier,\nBoostingBERT achieves new state-of-the-art results in several NLP Tasks. We\nalso use knowledge distillation within the \"teacher-student\" framework to\nreduce the computational overhead and model storage of BoostingBERT while\nkeeping its performance for practical application.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 09:07:14 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Huang", "Tongwen", ""], ["She", "Qingyun", ""], ["Zhang", "Junlin", ""]]}, {"id": "2009.06040", "submitter": "Jonathan Herzig", "authors": "Jonathan Herzig and Jonathan Berant", "title": "Span-based Semantic Parsing for Compositional Generalization", "comments": "ACL 2021 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the success of sequence-to-sequence (seq2seq) models in semantic\nparsing, recent work has shown that they fail in compositional generalization,\ni.e., the ability to generalize to new structures built of components observed\nduring training. In this work, we posit that a span-based parser should lead to\nbetter compositional generalization. we propose SpanBasedSP, a parser that\npredicts a span tree over an input utterance, explicitly encoding how partial\nprograms compose over spans in the input. SpanBasedSP extends Pasupat et al.\n(2019) to be comparable to seq2seq models by (i) training from programs,\nwithout access to gold trees, treating trees as latent variables, (ii) parsing\na class of non-projective trees through an extension to standard CKY. On\nGeoQuery, SCAN and CLOSURE datasets, SpanBasedSP performs similarly to strong\nseq2seq baselines on random splits, but dramatically improves performance\ncompared to baselines on splits that require compositional generalization: from\n$61.0 \\rightarrow 88.9$ average accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 16:42:18 GMT"}, {"version": "v2", "created": "Sun, 13 Jun 2021 09:07:23 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Herzig", "Jonathan", ""], ["Berant", "Jonathan", ""]]}, {"id": "2009.06066", "submitter": "Unnikrishnan R Nair", "authors": "Nivedita Rufus, Unni Krishnan R Nair, K. Madhava Krishna and Vineet\n  Gandhi", "title": "Cosine meets Softmax: A tough-to-beat baseline for visual grounding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a simple baseline for visual grounding for\nautonomous driving which outperforms the state of the art methods, while\nretaining minimal design choices. Our framework minimizes the cross-entropy\nloss over the cosine distance between multiple image ROI features with a text\nembedding (representing the give sentence/phrase). We use pre-trained networks\nfor obtaining the initial embeddings and learn a transformation layer on top of\nthe text embedding. We perform experiments on the Talk2Car dataset and achieve\n68.7% AP50 accuracy, improving upon the previous state of the art by 8.6%. Our\ninvestigation suggests reconsideration towards more approaches employing\nsophisticated attention mechanisms or multi-stage reasoning or complex metric\nlearning loss functions by showing promise in simpler alternatives.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 19:35:43 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Rufus", "Nivedita", ""], ["Nair", "Unni Krishnan R", ""], ["Krishna", "K. Madhava", ""], ["Gandhi", "Vineet", ""]]}, {"id": "2009.06097", "submitter": "Shuohang Wang", "authors": "Shuohang Wang, Luowei Zhou, Zhe Gan, Yen-Chun Chen, Yuwei Fang, Siqi\n  Sun, Yu Cheng, Jingjing Liu", "title": "Cluster-Former: Clustering-based Sparse Transformer for Long-Range\n  Dependency Encoding", "comments": "ACL Findings 2021, 11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer has become ubiquitous in the deep learning field. One of the key\ningredients that destined its success is the self-attention mechanism, which\nallows fully-connected contextual encoding over input tokens. However, despite\nits effectiveness in modeling short sequences, self-attention suffers when\nhandling inputs with extreme long-range dependencies, as its complexity grows\nquadratically with respect to the sequence length. Therefore, long sequences\nare often encoded by Transformer in chunks using a sliding window. In this\npaper, we propose Cluster-Former, a novel clustering-based sparse Transformer\nto perform attention across chunked sequences. The proposed framework is\npivoted on two unique types of Transformer layer: Sliding-Window Layer and\nCluster-Former Layer, which encode local sequence information and global\ncontext jointly and iteratively. This new design allows information integration\nbeyond local windows, which is especially beneficial for question answering\n(QA) tasks that rely on long-range dependencies. Experiments show that\nCluster-Former achieves state-of-the-art performance on several major QA\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 22:09:30 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 06:08:27 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Wang", "Shuohang", ""], ["Zhou", "Luowei", ""], ["Gan", "Zhe", ""], ["Chen", "Yen-Chun", ""], ["Fang", "Yuwei", ""], ["Sun", "Siqi", ""], ["Cheng", "Yu", ""], ["Liu", "Jingjing", ""]]}, {"id": "2009.06110", "submitter": "Gasper Begus", "authors": "Ga\\v{s}per Begu\\v{s}", "title": "Identity-Based Patterns in Deep Convolutional Networks: Generative\n  Adversarial Phonology and Reduplication", "comments": "Paper accepted at TACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper models unsupervised learning of an identity-based pattern (or\ncopying) in speech called reduplication from raw continuous data with deep\nconvolutional neural networks. We use the ciwGAN architecture Begu\\v{s} (2021a;\narXiv:2006.02951) in which learning of meaningful representations in speech\nemerges from a requirement that the CNNs generate informative data. We propose\na technique to wug-test CNNs trained on speech and, based on four generative\ntests, argue that the network learns to represent an identity-based pattern in\nits latent space. By manipulating only two categorical variables in the latent\nspace, we can actively turn an unreduplicated form into a reduplicated form\nwith no other substantial changes to the output in the majority of cases. We\nalso argue that the network extends the identity-based pattern to unobserved\ndata. Exploration of how meaningful representations of identity-based patterns\nemerge in CNNs and how the latent space variables outside of the training range\ncorrelate with identity-based patterns in the output has general implications\nfor neural network interpretability.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2020 23:12:49 GMT"}, {"version": "v2", "created": "Sat, 17 Jul 2021 12:03:04 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Begu\u0161", "Ga\u0161per", ""]]}, {"id": "2009.06141", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang, Yiqing Zhang, Hai Zhao, Xi Zhou, Xiang Zhou", "title": "Composing Answer from Multi-spans for Reading Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel method to generate answers for non-extraction\nmachine reading comprehension (MRC) tasks whose answers cannot be simply\nextracted as one span from the given passages. Using a pointer network-style\nextractive decoder for such type of MRC may result in unsatisfactory\nperformance when the ground-truth answers are given by human annotators or\nhighly re-paraphrased from parts of the passages. On the other hand, using\ngenerative decoder cannot well guarantee the resulted answers with well-formed\nsyntax and semantics when encountering long sentences. Therefore, to alleviate\nthe obvious drawbacks of both sides, we propose an answer making-up method from\nextracted multi-spans that are learned by our model as highly confident\n$n$-gram candidates in the given passage. That is, the returned answers are\ncomposed of discontinuous multi-spans but not just one consecutive span in the\ngiven passages anymore. The proposed method is simple but effective: empirical\nexperiments on MS MARCO show that the proposed method has a better performance\non accurately generating long answers, and substantially outperforms two\ncompetitive typical one-span and Seq2Seq baseline decoders.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 01:44:42 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["Zhang", "Yiqing", ""], ["Zhao", "Hai", ""], ["Zhou", "Xi", ""], ["Zhou", "Xiang", ""]]}, {"id": "2009.06206", "submitter": "Ningyu Zhang", "authors": "Luoqiu Li, Xiang Chen, Hongbin Ye, Zhen Bi, Shumin Deng, Ningyu Zhang,\n  Huajun Chen", "title": "On Robustness and Bias Analysis of BERT-based Relation Extraction", "comments": "work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning pre-trained models have achieved impressive performance on\nstandard natural language processing benchmarks. However, the resultant model\ngeneralizability remains poorly understood. We do not know, for example, how\nexcellent performance can lead to the perfection of generalization models. In\nthis study, we analyze a fine-tuned BERT model from different perspectives\nusing relation extraction. We also characterize the differences in\ngeneralization techniques according to our proposed improvements. From\nempirical experimentation, we find that BERT suffers a bottleneck in terms of\nrobustness by way of randomizations, adversarial and counterfactual tests, and\nbiases (i.e., selection and semantic). These findings highlight opportunities\nfor future improvements. Our open-sourced testbed DiagnoseRE is available in\n\\url{https://github.com/zjunlp/DiagnoseRE}.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 05:24:28 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 02:34:42 GMT"}, {"version": "v3", "created": "Tue, 6 Apr 2021 14:32:46 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Li", "Luoqiu", ""], ["Chen", "Xiang", ""], ["Ye", "Hongbin", ""], ["Bi", "Zhen", ""], ["Deng", "Shumin", ""], ["Zhang", "Ningyu", ""], ["Chen", "Huajun", ""]]}, {"id": "2009.06207", "submitter": "Ningyu Zhang", "authors": "Hongbin Ye, Ningyu Zhang, Shumin Deng, Mosha Chen, Chuanqi Tan, Fei\n  Huang, Huajun Chen", "title": "Contrastive Triple Extraction with Generative Transformer", "comments": "Accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Triple extraction is an essential task in information extraction for natural\nlanguage processing and knowledge graph construction. In this paper, we revisit\nthe end-to-end triple extraction task for sequence generation. Since generative\ntriple extraction may struggle to capture long-term dependencies and generate\nunfaithful triples, we introduce a novel model, contrastive triple extraction\nwith a generative transformer. Specifically, we introduce a single shared\ntransformer module for encoder-decoder-based generation. To generate faithful\nresults, we propose a novel triplet contrastive training object. Moreover, we\nintroduce two mechanisms to further improve model performance (i.e., batch-wise\ndynamic attention-masking and triple-wise calibration). Experimental results on\nthree datasets (i.e., NYT, WebNLG, and MIE) show that our approach achieves\nbetter performance than that of baselines.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 05:29:24 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 13:48:50 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2020 14:08:29 GMT"}, {"version": "v4", "created": "Thu, 4 Feb 2021 09:25:21 GMT"}, {"version": "v5", "created": "Tue, 9 Mar 2021 17:38:03 GMT"}, {"version": "v6", "created": "Tue, 16 Mar 2021 05:25:16 GMT"}, {"version": "v7", "created": "Tue, 6 Apr 2021 08:26:04 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Ye", "Hongbin", ""], ["Zhang", "Ningyu", ""], ["Deng", "Shumin", ""], ["Chen", "Mosha", ""], ["Tan", "Chuanqi", ""], ["Huang", "Fei", ""], ["Chen", "Huajun", ""]]}, {"id": "2009.06257", "submitter": "Kumiko Tanaka-Ishii", "authors": "Kumiko Tanaka-Ishii and Shuntaro Takahashi", "title": "A Comparison of Two Fluctuation Analyses for Natural Language Clustering\n  Phenomena: Taylor and Ebeling & Neiman Methods", "comments": null, "journal-ref": "Fractals, in 2021, No.2.\n  https://www.worldscientific.com/toc/fractals/0/ja", "doi": "10.1142/S0218348X2150033X", "report-no": null, "categories": "cs.CL stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article considers the fluctuation analysis methods of Taylor and Ebeling\n& Neiman. While both have been applied to various phenomena in the statistical\nmechanics domain, their similarities and differences have not been clarified.\nAfter considering their analytical aspects, this article presents a large-scale\napplication of these methods to text. It is found that both methods can\ndistinguish real text from independently and identically distributed (i.i.d.)\nsequences. Furthermore, it is found that the Taylor exponents acquired from\nwords can roughly distinguish text categories; this is also the case for\nEbeling and Neiman exponents, but to a lesser extent. Additionally, both\nmethods show some possibility of capturing script kinds.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 08:30:24 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Tanaka-Ishii", "Kumiko", ""], ["Takahashi", "Shuntaro", ""]]}, {"id": "2009.06265", "submitter": "Chongyang Tao", "authors": "Ruijian Xu, Chongyang Tao, Daxin Jiang, Xueliang Zhao, Dongyan Zhao,\n  Rui Yan", "title": "Learning an Effective Context-Response Matching Model with\n  Self-Supervised Tasks for Retrieval-based Dialogues", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building an intelligent dialogue system with the ability to select a proper\nresponse according to a multi-turn context is a great challenging task.\nExisting studies focus on building a context-response matching model with\nvarious neural architectures or PLMs and typically learning with a single\nresponse prediction task. These approaches overlook many potential training\nsignals contained in dialogue data, which might be beneficial for context\nunderstanding and produce better features for response prediction. Besides, the\nresponse retrieved from existing dialogue systems supervised by the\nconventional way still faces some critical challenges, including incoherence\nand inconsistency. To address these issues, in this paper, we propose learning\na context-response matching model with auxiliary self-supervised tasks designed\nfor the dialogue data based on pre-trained language models. Specifically, we\nintroduce four self-supervised tasks including next session prediction,\nutterance restoration, incoherence detection and consistency discrimination,\nand jointly train the PLM-based response selection model with these auxiliary\ntasks in a multi-task manner. By this means, the auxiliary tasks can guide the\nlearning of the matching model to achieve a better local optimum and select a\nmore proper response. Experiment results on two benchmarks indicate that the\nproposed auxiliary self-supervised tasks bring significant improvement for\nmulti-turn response selection in retrieval-based dialogues, and our model\nachieves new state-of-the-art results on both datasets.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 08:44:46 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Xu", "Ruijian", ""], ["Tao", "Chongyang", ""], ["Jiang", "Daxin", ""], ["Zhao", "Xueliang", ""], ["Zhao", "Dongyan", ""], ["Yan", "Rui", ""]]}, {"id": "2009.06354", "submitter": "Michael Collins", "authors": "Matthew Lamm, Jennimaria Palomaki, Chris Alberti, Daniel Andor, Eunsol\n  Choi, Livio Baldini Soares, Michael Collins", "title": "QED: A Framework and Dataset for Explanations in Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A question answering system that in addition to providing an answer provides\nan explanation of the reasoning that leads to that answer has potential\nadvantages in terms of debuggability, extensibility and trust. To this end, we\npropose QED, a linguistically informed, extensible framework for explanations\nin question answering. A QED explanation specifies the relationship between a\nquestion and answer according to formal semantic notions such as referential\nequality, sentencehood, and entailment. We describe and publicly release an\nexpert-annotated dataset of QED explanations built upon a subset of the Google\nNatural Questions dataset, and report baseline models on two tasks -- post-hoc\nexplanation generation given an answer, and joint question answering and\nexplanation generation. In the joint setting, a promising result suggests that\ntraining on a relatively small amount of QED data can improve question\nanswering. In addition to describing the formal, language-theoretic motivations\nfor the QED approach, we describe a large user study showing that the presence\nof QED explanations significantly improves the ability of untrained raters to\nspot errors made by a strong neural QA baseline.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 23:34:18 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Lamm", "Matthew", ""], ["Palomaki", "Jennimaria", ""], ["Alberti", "Chris", ""], ["Andor", "Daniel", ""], ["Choi", "Eunsol", ""], ["Soares", "Livio Baldini", ""], ["Collins", "Michael", ""]]}, {"id": "2009.06358", "submitter": "Mehrdad Yousefzadeh", "authors": "Ruixiao Sun, Jie Yang, Mehrdad Yousefzadeh", "title": "Improving Language Generation with Sentence Coherence Objective", "comments": "11 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional story generation and contextual text continuation have become\nincreasingly popular topics in NLP community. Existing models are often prone\nto output paragraphs of texts that gradually diverge from the given prompt.\nAlthough the generated text may have a reasonable perplexity and diversity, it\ncould easily be identified by human as gibberish. The goal of our project is to\nimprove the coherence and consistency across sentences in a language-generation\nmodel. We aim to solve this issue by first training a sentence pair coherence\nclassifier with GPT-2 pretrained model, and then co-train the GPT-2 language\nmodel with this new coherence objective using a method analogous to the\nREINFORCE algorithm. This fine-tuned language model is able to generate lengthy\nparagraph conditioned on a given topic without diverging too much. The\nsimplicity of this model allows it to be applicable to a variety of underlying\nlanguage model architecture since it only modifies the final layer of the\npre-trained model.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 06:10:03 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Sun", "Ruixiao", ""], ["Yang", "Jie", ""], ["Yousefzadeh", "Mehrdad", ""]]}, {"id": "2009.06367", "submitter": "Benjamin Krause", "authors": "Ben Krause, Akhilesh Deepak Gotmare, Bryan McCann, Nitish Shirish\n  Keskar, Shafiq Joty, Richard Socher, Nazneen Fatema Rajani", "title": "GeDi: Generative Discriminator Guided Sequence Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While large-scale language models (LMs) are able to imitate the distribution\nof natural language well enough to generate realistic text, it is difficult to\ncontrol which regions of the distribution they generate. This is especially\nproblematic because datasets used for training large LMs usually contain\nsignificant toxicity, hate, bias, and negativity. We propose GeDi as an\nefficient method for using smaller LMs as generative discriminators to guide\ngeneration from large LMs to make them safer and more controllable. GeDi guides\ngeneration at each step by computing classification probabilities for all\npossible next tokens via Bayes rule by normalizing over two class-conditional\ndistributions; one conditioned on the desired attribute, or control code, and\nanother conditioned on the undesired attribute, or anti control code. We find\nthat GeDi gives stronger controllability than the state of the art method while\nalso achieving generation speeds more than 30 times faster. Additionally,\ntraining GeDi on only four topics allows us to controllably generate new topics\nzero-shot from just a keyword, unlocking a new capability that previous\ncontrollable generation methods do not have. Lastly, we show that GeDi can make\nGPT-2 (1.5B parameters) significantly less toxic without sacrificing linguistic\nquality, making it by far the most practical existing method for detoxifying\nlarge language models while maintaining a fast generation speed.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 17:45:36 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 14:14:09 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Krause", "Ben", ""], ["Gotmare", "Akhilesh Deepak", ""], ["McCann", "Bryan", ""], ["Keskar", "Nitish Shirish", ""], ["Joty", "Shafiq", ""], ["Socher", "Richard", ""], ["Rajani", "Nazneen Fatema", ""]]}, {"id": "2009.06368", "submitter": "Yanjun  Qi Dr.", "authors": "Jin Yong Yoo, John X. Morris, Eli Lifland, Yanjun Qi", "title": "Searching for a Search Method: Benchmarking Search Algorithms for\n  Generating NLP Adversarial Examples", "comments": "14 pages, 5 figures, 4 tables; Accepted by EMNLP BlackBox NLP\n  Workshop 2020 @ https://blackboxnlp.github.io/cfp.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the behavior of several black-box search algorithms used for\ngenerating adversarial examples for natural language processing (NLP) tasks. We\nperform a fine-grained analysis of three elements relevant to search: search\nalgorithm, search space, and search budget. When new search algorithms are\nproposed in past work, the attack search space is often modified alongside the\nsearch algorithm. Without ablation studies benchmarking the search algorithm\nchange with the search space held constant, one cannot tell if an increase in\nattack success rate is a result of an improved search algorithm or a less\nrestrictive search space. Additionally, many previous studies fail to properly\nconsider the search algorithms' run-time cost, which is essential for\ndownstream tasks like adversarial training. Our experiments provide a\nreproducible benchmark of search algorithms across a variety of search spaces\nand query budgets to guide future research in adversarial NLP. Based on our\nexperiments, we recommend greedy attacks with word importance ranking when\nunder a time constraint or attacking long inputs, and either beam search or\nparticle swarm optimization otherwise. Code implementation shared via\nhttps://github.com/QData/TextAttack-Search-Benchmark\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2020 17:04:42 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 19:46:36 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Yoo", "Jin Yong", ""], ["Morris", "John X.", ""], ["Lifland", "Eli", ""], ["Qi", "Yanjun", ""]]}, {"id": "2009.06372", "submitter": "Thai Hoang", "authors": "Thai Quoc Hoang and Phuong Thu Vu", "title": "Not-NUTs at W-NUT 2020 Task 2: A BERT-based System in Identifying\n  Informative COVID-19 English Tweets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As of 2020 when the COVID-19 pandemic is full-blown on a global scale,\npeople's need to have access to legitimate information regarding COVID-19 is\nmore urgent than ever, especially via online media where the abundance of\nirrelevant information overshadows the more informative ones. In response to\nsuch, we proposed a model that, given an English tweet, automatically\nidentifies whether that tweet bears informative content regarding COVID-19 or\nnot. By ensembling different BERTweet model configurations, we have achieved\ncompetitive results that are only shy of those by top performing teams by\nroughly 1% in terms of F1 score on the informative class. In the\npost-competition period, we have also experimented with various other\napproaches that potentially boost generalization to a new dataset.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 15:49:16 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Hoang", "Thai Quoc", ""], ["Vu", "Phuong Thu", ""]]}, {"id": "2009.06375", "submitter": "Nickil Maveli", "authors": "Nickil Maveli", "title": "EdinburghNLP at WNUT-2020 Task 2: Leveraging Transformers with\n  Generalized Augmentation for Identifying Informativeness in COVID-19 Tweets", "comments": "Accepted at W-NUT workshop of EMNLP 2020 (7 pages, 6 figures, 3\n  tables)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twitter and, in general, social media has become an indispensable\ncommunication channel in times of emergency. The ubiquitousness of smartphone\ngadgets enables people to declare an emergency observed in real-time. As a\nresult, more agencies are interested in programmatically monitoring Twitter\n(disaster relief organizations and news agencies). Therefore, recognizing the\ninformativeness of a Tweet can help filter noise from the large volumes of\nTweets. In this paper, we present our submission for WNUT-2020 Task 2:\nIdentification of informative COVID-19 English Tweets. Our most successful\nmodel is an ensemble of transformers, including RoBERTa, XLNet, and BERTweet\ntrained in a Semi-Supervised Learning (SSL) setting. The proposed system\nachieves an F1 score of 0.9011 on the test set (ranking 7th on the leaderboard)\nand shows significant gains in performance compared to a baseline system using\nFastText embeddings.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2020 15:57:28 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 16:47:10 GMT"}, {"version": "v3", "created": "Sun, 18 Apr 2021 12:28:14 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Maveli", "Nickil", ""]]}, {"id": "2009.06376", "submitter": "Nkechi Ifeanyi-Reuben Dr.", "authors": "Ifeanyi-Reuben Nkechi J., Ugwu Chidiebere, Adegbola Tunde", "title": "Analysis and representation of Igbo text document for a text-based\n  system", "comments": null, "journal-ref": "International Journal of Data Mining Techniques and Applications\n  (IJDMTA). Volume 06 Issue 01, June 2017, Page No 26-32", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advancement in Information Technology (IT) has assisted in inculcating\nthe three Nigeria major languages in text-based application such as text\nmining, information retrieval and natural language processing. The interest of\nthis paper is the Igbo language, which uses compounding as a common type of\nword formation and as well has many vocabularies of compound words. The issues\nof collocation, word ordering and compounding play high role in Igbo language.\nThe ambiguity in dealing with these compound words has made the representation\nof Igbo language text document very difficult because this cannot be addressed\nusing the most common and standard approach of the Bag-Of-Words (BOW) model of\ntext representation, which ignores the word order and relation. However, this\ncause for a concern and the need to develop an improved model to capture this\nsituation. This paper presents the analysis of Igbo language text document,\nconsidering its compounding nature and describes its representation with the\nWord-based N-gram model to properly prepare it for any text-based application.\nThe result shows that Bigram and Trigram n-gram text representation models\nprovide more semantic information as well addresses the issues of compounding,\nword ordering and collocations which are the major language peculiarities in\nIgbo. They are likely to give better performance when used in any Igbo\ntext-based system.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2020 19:07:17 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["J.", "Ifeanyi-Reuben Nkechi", ""], ["Chidiebere", "Ugwu", ""], ["Tunde", "Adegbola", ""]]}, {"id": "2009.06401", "submitter": "Pepa Atanasova", "authors": "Wojciech Ostrowski, Arnav Arora, Pepa Atanasova, Isabelle Augenstein", "title": "Multi-Hop Fact Checking of Political Claims", "comments": "10 pages, to be published at Proceedings of IJCAI-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has proposed multi-hop models and datasets for studying complex\nnatural language reasoning. One notable task requiring multi-hop reasoning is\nfact checking, where a set of connected evidence pieces leads to the final\nverdict of a claim. However, existing datasets either do not provide\nannotations for gold evidence pages, or the only dataset which does (FEVER)\nmostly consists of claims which can be fact-checked with simple reasoning and\nis constructed artificially. Here, we study more complex claim verification of\nnaturally occurring claims with multiple hops over interconnected evidence\nchunks. We: 1) construct a small annotated dataset, PolitiHop, of evidence\nsentences for claim verification; 2) compare it to existing multi-hop datasets;\nand 3) study how to transfer knowledge from more extensive in- and\nout-of-domain resources to PolitiHop. We find that the task is complex and\nachieve the best performance with an architecture that specifically models\nreasoning over evidence pieces in combination with in-domain transfer learning.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 13:54:15 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 17:00:26 GMT"}, {"version": "v3", "created": "Tue, 1 Jun 2021 14:06:14 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Ostrowski", "Wojciech", ""], ["Arora", "Arnav", ""], ["Atanasova", "Pepa", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "2009.06402", "submitter": "Liesbeth Allein", "authors": "Liesbeth Allein, Isabelle Augenstein and Marie-Francine Moens", "title": "Time-Aware Evidence Ranking for Fact-Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Truth can vary over time. Fact-checking decisions on claim veracity should\ntherefore take into account temporal information of both the claim and\nsupporting or refuting evidence. In this work, we investigate the hypothesis\nthat the timestamp of a Web page is crucial to how it should be ranked for a\ngiven claim. We delineate four temporal ranking methods that constrain evidence\nranking differently and simulate hypothesis-specific evidence rankings given\nthe evidence timestamps as gold standard. Evidence ranking in three\nfact-checking models is ultimately optimized using a learning-to-rank loss\nfunction. Our study reveals that time-aware evidence ranking not only surpasses\nrelevance assumptions based purely on semantic similarity or position in a\nsearch results list, but also improves veracity predictions of time-sensitive\nclaims in particular.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 13:39:49 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 09:15:20 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Allein", "Liesbeth", ""], ["Augenstein", "Isabelle", ""], ["Moens", "Marie-Francine", ""]]}, {"id": "2009.06451", "submitter": "Rajesh Kumar Mundotiya", "authors": "Rajesh Kumar Mundotiya, Shantanu Kumar, Ajeet kumar, Umesh Chandra\n  Chaudhary, Supriya Chauhan, Swasti Mishra, Praveen Gatla, Anil Kumar Singh", "title": "Development of a Dataset and a Deep Learning Baseline Named Entity\n  Recognizer for Three Low Resource Languages: Bhojpuri, Maithili and Magahi", "comments": "34 pages; 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In Natural Language Processing (NLP) pipelines, Named Entity Recognition\n(NER) is one of the preliminary problems, which marks proper nouns and other\nnamed entities such as Location, Person, Organization, Disease etc. Such\nentities, without a NER module, adversely affect the performance of a machine\ntranslation system. NER helps in overcoming this problem by recognising and\nhandling such entities separately, although it can be useful in Information\nExtraction systems also. Bhojpuri, Maithili and Magahi are low resource\nlanguages, usually known as Purvanchal languages. This paper focuses on the\ndevelopment of a NER benchmark dataset for the Machine Translation systems\ndeveloped to translate from these languages to Hindi by annotating parts of\ntheir available corpora. Bhojpuri, Maithili and Magahi corpora of sizes 228373,\n157468 and 56190 tokens, respectively, were annotated using 22 entity labels.\nThe annotation considers coarse-grained annotation labels followed by the\ntagset used in one of the Hindi NER datasets. We also report a Deep Learning\nbased baseline that uses an LSTM-CNNs-CRF model. The lower baseline F1-scores\nfrom the NER tool obtained by using Conditional Random Fields models are 96.73\nfor Bhojpuri, 93.33 for Maithili and 95.04 for Magahi. The Deep Learning-based\ntechnique (LSTM-CNNs-CRF) achieved 96.25 for Bhojpuri, 93.33 for Maithili and\n95.44 for Magahi.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 14:07:50 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Mundotiya", "Rajesh Kumar", ""], ["Kumar", "Shantanu", ""], ["kumar", "Ajeet", ""], ["Chaudhary", "Umesh Chandra", ""], ["Chauhan", "Supriya", ""], ["Mishra", "Swasti", ""], ["Gatla", "Praveen", ""], ["Singh", "Anil Kumar", ""]]}, {"id": "2009.06485", "submitter": "Jonathan Lenchner", "authors": "Jonathan Lenchner", "title": "A Finitist's Manifesto: Do we need to Reformulate the Foundations of\n  Mathematics?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a problem with the foundations of classical mathematics, and\npotentially even with the foundations of computer science, that mathematicians\nhave by-and-large ignored. This essay is a call for practicing mathematicians\nwho have been sleep-walking in their infinitary mathematical paradise to take\nheed. Much of mathematics relies upon either (i) the \"existence'\" of objects\nthat contain an infinite number of elements, (ii) our ability, \"in theory\", to\ncompute with an arbitrary level of precision, or (iii) our ability, \"in\ntheory\", to compute for an arbitrarily large number of time steps. All of\ncalculus relies on the notion of a limit. The monumental results of real and\ncomplex analysis rely on a seamless notion of the \"continuum\" of real numbers,\nwhich extends in the plane to the complex numbers and gives us, among other\nthings, \"rigorous\" definitions of continuity, the derivative, various different\nintegrals, as well as the fundamental theorems of calculus and of algebra --\nthe former of which says that the derivative and integral can be viewed as\ninverse operations, and the latter of which says that every polynomial over\n$\\mathbb{C}$ has a complex root. This essay is an inquiry into whether there is\nany way to assign meaning to the notions of \"existence\" and \"in theory'\" in (i)\nto (iii) above.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 14:44:08 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Lenchner", "Jonathan", ""]]}, {"id": "2009.06487", "submitter": "Chengyu Wang", "authors": "Chengyu Wang, Mengli Cheng, Xu Hu, Jun Huang", "title": "EasyASR: A Distributed Machine Learning Platform for End-to-end\n  Automatic Speech Recognition", "comments": "aaai 2021 demo paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present EasyASR, a distributed machine learning platform for training and\nserving large-scale Automatic Speech Recognition (ASR) models, as well as\ncollecting and processing audio data at scale. Our platform is built upon the\nMachine Learning Platform for AI of Alibaba Cloud. Its main functionality is to\nsupport efficient learning and inference for end-to-end ASR models on\ndistributed GPU clusters. It allows users to learn ASR models with either\npre-defined or user-customized network architectures via simple user interface.\nOn EasyASR, we have produced state-of-the-art results over several public\ndatasets for Mandarin speech recognition.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 14:47:02 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 09:44:27 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Wang", "Chengyu", ""], ["Cheng", "Mengli", ""], ["Hu", "Xu", ""], ["Huang", "Jun", ""]]}, {"id": "2009.06504", "submitter": "Longxiang Liu", "authors": "Longxiang Liu, Zhuosheng Zhang, Hai Zhao, Xi Zhou, Xiang Zhou", "title": "Filling the Gap of Utterance-aware and Speaker-aware Representation for\n  Multi-turn Dialogue", "comments": "accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A multi-turn dialogue is composed of multiple utterances from two or more\ndifferent speaker roles. Thus utterance- and speaker-aware clues are supposed\nto be well captured in models. However, in the existing retrieval-based\nmulti-turn dialogue modeling, the pre-trained language models (PrLMs) as\nencoder represent the dialogues coarsely by taking the pairwise dialogue\nhistory and candidate response as a whole, the hierarchical information on\neither utterance interrelation or speaker roles coupled in such representations\nis not well addressed. In this work, we propose a novel model to fill such a\ngap by modeling the effective utterance-aware and speaker-aware representations\nentailed in a dialogue history. In detail, we decouple the contextualized word\nrepresentations by masking mechanisms in Transformer-based PrLM, making each\nword only focus on the words in current utterance, other utterances, two\nspeaker roles (i.e., utterances of sender and utterances of receiver),\nrespectively. Experimental results show that our method boosts the strong\nELECTRA baseline substantially in four public benchmark datasets, and achieves\nvarious new state-of-the-art performance over previous methods. A series of\nablation studies are conducted to demonstrate the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 15:07:19 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 19:01:56 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Liu", "Longxiang", ""], ["Zhang", "Zhuosheng", ""], ["Zhao", "Hai", ""], ["Zhou", "Xi", ""], ["Zhou", "Xiang", ""]]}, {"id": "2009.06510", "submitter": "Sebastian Weigelt", "authors": "Sebastian Weigelt and Vanessa Steurer and Walter F. Tichy", "title": "At your Command! An Empirical Study on How LaypersonsTeach Robots New\n  Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Even though intelligent systems such as Siri or Google Assistant are\nenjoyable (and useful) dialog partners, users can only access predefined\nfunctionality. Enabling end-users to extend the functionality of intelligent\nsystems will be the next big thing. To promote research in this area we carried\nout an empirical study on how laypersons teach robots new functions by means of\nnatural language instructions. The result is a labeled corpus consisting of\n3168 submissions given by 870 subjects. The analysis of the dataset revealed\nthat many participants used certain wordings to express their wish to teach new\nfunctionality; two corresponding trigrams are among the most frequent. On the\ncontrary, more than one third (36.93%) did not verbalize the teaching intent at\nall. We labeled the semantic constituents in the utterances: declaration\n(including the name of the function) and intermediate steps. The full corpus is\npublicly available: http://dx.doi.org/10.21227/zecn-6c61\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 15:16:25 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Weigelt", "Sebastian", ""], ["Steurer", "Vanessa", ""], ["Tichy", "Walter F.", ""]]}, {"id": "2009.06704", "submitter": "Alberto Nogales", "authors": "Alberto Nogales, Rodrigo D\\'iaz Mor\\'on, \\'Alvaro J. Garc\\'ia-Tejedor", "title": "Food safety risk prediction with Deep Learning models using categorical\n  embeddings on European Union data", "comments": "20 pages,8 figures, 15 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The world is becoming more globalized every day and people can buy products\nfrom almost every country in the world in their local stores. Given the\ndifferent food and feed safety laws from country to country, the European Union\nbegan to register in 1977 all irregularities related to traded products to\nensure cross-border monitoring of information and a quick reaction when risks\nto public health are detected in the food chain. This information has also an\nenormous potential as a preventive tool, in order to warn actors involved in\nfood safety and optimize their resources. In this paper, a set of data related\nto food issues was scraped and analysed with Machine Learning techniques to\npredict some features of future notifications, so that pre-emptive measures can\nbe taken. The novelty of the work relies on two points: the use of categorical\nembeddings with Deep Learning models (Multilayer Perceptron and 1-Dimension\nConvolutional Neural Networks) and its application to solve the problem of\npredicting food issues in the European Union. The models allow several features\nto be predicted: product category, hazard category and finally the proper\naction to be taken. Results show that the system can predict these features\nwith an accuracy ranging from 74.08% to 93.06%.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 19:36:58 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Nogales", "Alberto", ""], ["Mor\u00f3n", "Rodrigo D\u00edaz", ""], ["Garc\u00eda-Tejedor", "\u00c1lvaro J.", ""]]}, {"id": "2009.06732", "submitter": "Yi Tay", "authors": "Yi Tay, Mostafa Dehghani, Dara Bahri, Donald Metzler", "title": "Efficient Transformers: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer model architectures have garnered immense interest lately due to\ntheir effectiveness across a range of domains like language, vision and\nreinforcement learning. In the field of natural language processing for\nexample, Transformers have become an indispensable staple in the modern deep\nlearning stack. Recently, a dizzying number of \"X-former\" models have been\nproposed - Reformer, Linformer, Performer, Longformer, to name a few - which\nimprove upon the original Transformer architecture, many of which make\nimprovements around computational and memory efficiency. With the aim of\nhelping the avid researcher navigate this flurry, this paper characterizes a\nlarge and thoughtful selection of recent efficiency-flavored \"X-former\" models,\nproviding an organized and comprehensive overview of existing work and models\nacross multiple domains.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 20:38:14 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 07:23:37 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Tay", "Yi", ""], ["Dehghani", "Mostafa", ""], ["Bahri", "Dara", ""], ["Metzler", "Donald", ""]]}, {"id": "2009.06775", "submitter": "Tuomo Raitio", "authors": "Tuomo Raitio, Ramya Rasipuram, Dan Castellani", "title": "Controllable neural text-to-speech synthesis using intuitive prosodic\n  features", "comments": "Accepted for publication in Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern neural text-to-speech (TTS) synthesis can generate speech that is\nindistinguishable from natural speech. However, the prosody of generated\nutterances often represents the average prosodic style of the database instead\nof having wide prosodic variation. Moreover, the generated prosody is solely\ndefined by the input text, which does not allow for different styles for the\nsame sentence. In this work, we train a sequence-to-sequence neural network\nconditioned on acoustic speech features to learn a latent prosody space with\nintuitive and meaningful dimensions. Experiments show that a model conditioned\non sentence-wise pitch, pitch range, phone duration, energy, and spectral tilt\ncan effectively control each prosodic dimension and generate a wide variety of\nspeaking styles, while maintaining similar mean opinion score (4.23) to our\nTacotron baseline (4.26).\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 22:37:44 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Raitio", "Tuomo", ""], ["Rasipuram", "Ramya", ""], ["Castellani", "Dan", ""]]}, {"id": "2009.06810", "submitter": "Andrew Flores", "authors": "Andrew Z. Flores, Jessica Montag, Jon Willits", "title": "Using Known Words to Learn More Words: A Distributional Analysis of\n  Child Vocabulary Development", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Why do children learn some words before others? Understanding individual\nvariability across children and also variability across words, may be\ninformative of the learning processes that underlie language learning. We\ninvestigated item-based variability in vocabulary development using lexical\nproperties of distributional statistics derived from a large corpus of\nchild-directed speech. Unlike previous analyses, we predicted word trajectories\ncross-sectionally, shedding light on trends in vocabulary development that may\nnot have been evident at a single time point. We also show that whether one\nlooks at a single age group or across ages as a whole, the best distributional\npredictor of whether a child knows a word is the number of other known words\nwith which that word tends to co-occur. Keywords: age of acquisition;\nvocabulary development; lexical diversity; child-directed speech;\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 01:18:21 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Flores", "Andrew Z.", ""], ["Montag", "Jessica", ""], ["Willits", "Jon", ""]]}, {"id": "2009.06819", "submitter": "Pawan Goyal", "authors": "Souradip Guha, Ankan Mullick, Jatin Agrawal, Swetarekha Ram, Samir\n  Ghui, Seung-Cheol Lee, Satadeep Bhattacharjee, Pawan Goyal", "title": "MatScIE: An automated tool for the generation of databases of methods\n  and parameters used in the computational materials science literature", "comments": "13 pages, 8 figures, Accepted for publication in Computational\n  Material Science", "journal-ref": "Computational Material Science, 2021", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The number of published articles in the field of materials science is growing\nrapidly every year. This comparatively unstructured data source, which contains\na large amount of information, has a restriction on its re-usability, as the\ninformation needed to carry out further calculations using the data in it must\nbe extracted manually. It is very important to obtain valid and contextually\ncorrect information from the online (offline) data, as it can be useful not\nonly to generate inputs for further calculations, but also to incorporate them\ninto a querying framework. Retaining this context as a priority, we have\ndeveloped an automated tool, MatScIE (Material Scince Information Extractor)\nthat can extract relevant information from material science literature and make\na structured database that is much easier to use for material simulations.\nSpecifically, we extract the material details, methods, code, parameters, and\nstructure from the various research articles. Finally, we created a web\napplication where users can upload published articles and view/download the\ninformation obtained from this tool and can create their own databases for\ntheir personal uses.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 01:52:47 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 03:30:55 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Guha", "Souradip", ""], ["Mullick", "Ankan", ""], ["Agrawal", "Jatin", ""], ["Ram", "Swetarekha", ""], ["Ghui", "Samir", ""], ["Lee", "Seung-Cheol", ""], ["Bhattacharjee", "Satadeep", ""], ["Goyal", "Pawan", ""]]}, {"id": "2009.06823", "submitter": "Zhenglun Kong", "authors": "Wei Niu, Zhenglun Kong, Geng Yuan, Weiwen Jiang, Jiexiong Guan, Caiwen\n  Ding, Pu Zhao, Sijia Liu, Bin Ren, Yanzhi Wang", "title": "Real-Time Execution of Large-scale Language Models on Mobile", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained large-scale language models have increasingly demonstrated high\naccuracy on many natural language processing (NLP) tasks. However, the limited\nweight storage and computational speed on hardware platforms have impeded the\npopularity of pre-trained models, especially in the era of edge computing. In\nthis paper, we seek to find the best model structure of BERT for a given\ncomputation size to match specific devices. We propose the first compiler-aware\nneural architecture optimization framework. Our framework can guarantee the\nidentified model to meet both resource and real-time specifications of mobile\ndevices, thus achieving real-time execution of large transformer-based models\nlike BERT variants. We evaluate our model on several NLP tasks, achieving\ncompetitive results on well-known benchmarks with lower latency on mobile\ndevices. Specifically, our model is 5.2x faster on CPU and 4.1x faster on GPU\nwith 0.5-2% accuracy loss compared with BERT-base. Our overall framework\nachieves up to 7.8x speedup compared with TensorFlow-Lite with only minor\naccuracy loss.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 01:59:17 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 17:53:07 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Niu", "Wei", ""], ["Kong", "Zhenglun", ""], ["Yuan", "Geng", ""], ["Jiang", "Weiwen", ""], ["Guan", "Jiexiong", ""], ["Ding", "Caiwen", ""], ["Zhao", "Pu", ""], ["Liu", "Sijia", ""], ["Ren", "Bin", ""], ["Wang", "Yanzhi", ""]]}, {"id": "2009.06851", "submitter": "Xinyuan Zhang", "authors": "Xinyuan Zhang, Ruiyi Zhang, Manzil Zaheer, Amr Ahmed", "title": "Unsupervised Abstractive Dialogue Summarization for Tete-a-Tetes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-quality dialogue-summary paired data is expensive to produce and\ndomain-sensitive, making abstractive dialogue summarization a challenging task.\nIn this work, we propose the first unsupervised abstractive dialogue\nsummarization model for tete-a-tetes (SuTaT). Unlike standard text\nsummarization, a dialogue summarization method should consider the\nmulti-speaker scenario where the speakers have different roles, goals, and\nlanguage styles. In a tete-a-tete, such as a customer-agent conversation, SuTaT\naims to summarize for each speaker by modeling the customer utterances and the\nagent utterances separately while retaining their correlations. SuTaT consists\nof a conditional generative module and two unsupervised summarization modules.\nThe conditional generative module contains two encoders and two decoders in a\nvariational autoencoder framework where the dependencies between two latent\nspaces are captured. With the same encoders and decoders, two unsupervised\nsummarization modules equipped with sentence-level self-attention mechanisms\ngenerate summaries without using any annotations. Experimental results show\nthat SuTaT is superior on unsupervised dialogue summarization for both\nautomatic and human evaluations, and is capable of dialogue classification and\nsingle-turn conversation generation.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 03:27:52 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Zhang", "Xinyuan", ""], ["Zhang", "Ruiyi", ""], ["Zaheer", "Manzil", ""], ["Ahmed", "Amr", ""]]}, {"id": "2009.06857", "submitter": "Aran Komatsuzaki", "authors": "Aran Komatsuzaki", "title": "Current Limitations of Language Models: What You Need is Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We classify and re-examine some of the current approaches to improve the\nperformance-computes trade-off of language models, including (1) non-causal\nmodels (such as masked language models), (2) extension of batch length with\nefficient attention, (3) recurrence, (4) conditional computation and (5)\nretrieval. We identify some limitations (1) - (4) suffer from. For example, (1)\ncurrently struggles with open-ended text generation with the output loosely\nconstrained by the input as well as performing general textual tasks like\nGPT-2/3 due to its need for a specific fine-tuning dataset. (2) and (3) do not\nimprove the prediction of the first $\\sim 10^3$ tokens. Scaling up a model size\n(e.g. efficiently with (4)) still results in poor performance scaling for some\ntasks. We argue (5) would resolve many of these limitations, and it can (a)\nreduce the amount of supervision and (b) efficiently extend the context over\nthe entire training dataset and the entire past of the current sample. We\nspeculate how to modify MARGE to perform unsupervised causal modeling that\nachieves (b) with the retriever jointly trained.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 04:04:20 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Komatsuzaki", "Aran", ""]]}, {"id": "2009.06891", "submitter": "Ye Ma", "authors": "Ye Ma, Zixun Lan, Lu Zong, Kaizhu Huang", "title": "Global-aware Beam Search for Neural Abstractive Summarization", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study develops a calibrated beam-based algorithm with global awareness\nfor neural abstractive summarization, aiming to improve the local optimality\nproblem of the original beam search in a rigorous way. Specifically, a novel\nglobal protocol is proposed based on the attention distribution to stipulate\nhow a global optimal hypothesis should attend to the source. A global scoring\nfunction is then developed to regulate beam search to generate summaries in a\nmore near-global optimal fashion. This novel design enjoys a distinctive\nproperty, i.e. the global attention distribution could be predicted before\ninference, enabling stepwise improvements on the beam search through the global\nscoring function. Extensive experiments on $9$ datasets show that the\nglobal-aware inference significantly improves state-of-the-art summarization\nmodels even using empirical hyper-parameters. The algorithm is also proven\nrobust as it remains to generate meaningful texts with corrupted attention\ndistributions. The codes and a comprehensive set of examples are available.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 07:09:26 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 14:35:12 GMT"}, {"version": "v3", "created": "Mon, 5 Apr 2021 16:20:11 GMT"}, {"version": "v4", "created": "Mon, 7 Jun 2021 11:02:21 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Ma", "Ye", ""], ["Lan", "Zixun", ""], ["Zong", "Lu", ""], ["Huang", "Kaizhu", ""]]}, {"id": "2009.06957", "submitter": "Hao Fei", "authors": "Hao Fei and Yafeng Ren and Donghong Ji", "title": "High-order Refining for End-to-end Chinese Semantic Role Labeling", "comments": "Accepted at AACL2020 as short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current end-to-end semantic role labeling is mostly accomplished via\ngraph-based neural models. However, these all are first-order models, where\neach decision for detecting any predicate-argument pair is made in isolation\nwith local features. In this paper, we present a high-order refining mechanism\nto perform interaction between all predicate-argument pairs. Based on the\nbaseline graph model, our high-order refining module learns higher-order\nfeatures between all candidate pairs via attention calculation, which are later\nused to update the original token representations. After several iterations of\nrefinement, the underlying token representations can be enriched with globally\ninteracted features. Our high-order model achieves state-of-the-art results on\nChinese SRL data, including CoNLL09 and Universal Proposition Bank, meanwhile\nrelieving the long-range dependency issues.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 10:01:27 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Fei", "Hao", ""], ["Ren", "Yafeng", ""], ["Ji", "Donghong", ""]]}, {"id": "2009.06978", "submitter": "Xiang Gao", "authors": "Xiang Gao, Yizhe Zhang, Michel Galley, Chris Brockett, Bill Dolan", "title": "Dialogue Response Ranking Training with Large-Scale Human Feedback Data", "comments": "Accepted to appear at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing open-domain dialog models are generally trained to minimize the\nperplexity of target human responses. However, some human replies are more\nengaging than others, spawning more followup interactions. Current\nconversational models are increasingly capable of producing turns that are\ncontext-relevant, but in order to produce compelling agents, these models need\nto be able to predict and optimize for turns that are genuinely engaging. We\nleverage social media feedback data (number of replies and upvotes) to build a\nlarge-scale training dataset for feedback prediction. To alleviate possible\ndistortion between the feedback and engagingness, we convert the ranking\nproblem to a comparison of response pairs which involve few confounding\nfactors. We trained DialogRPT, a set of GPT-2 based models on 133M pairs of\nhuman feedback data and the resulting ranker outperformed several baselines.\nParticularly, our ranker outperforms the conventional dialog perplexity\nbaseline with a large margin on predicting Reddit feedback. We finally combine\nthe feedback prediction models and a human-like scoring model to rank the\nmachine-generated dialog responses. Crowd-sourced human evaluation shows that\nour ranking method correlates better with real human preferences than baseline\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 10:50:05 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Gao", "Xiang", ""], ["Zhang", "Yizhe", ""], ["Galley", "Michel", ""], ["Brockett", "Chris", ""], ["Dolan", "Bill", ""]]}, {"id": "2009.07022", "submitter": "Ningyu Zhang", "authors": "Haiyang Yu, Ningyu Zhang, Shumin Deng, Zonggang Yuan, Yantao Jia,\n  Huajun Chen", "title": "The Devil is the Classifier: Investigating Long Tail Relation\n  Classification with Decoupling Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long-tailed relation classification is a challenging problem as the head\nclasses may dominate the training phase, thereby leading to the deterioration\nof the tail performance. Existing solutions usually address this issue via\nclass-balancing strategies, e.g., data re-sampling and loss re-weighting, but\nall these methods adhere to the schema of entangling learning of the\nrepresentation and classifier. In this study, we conduct an in-depth empirical\ninvestigation into the long-tailed problem and found that pre-trained models\nwith instance-balanced sampling already capture the well-learned\nrepresentations for all classes; moreover, it is possible to achieve better\nlong-tailed classification ability at low cost by only adjusting the\nclassifier. Inspired by this observation, we propose a robust classifier with\nattentive relation routing, which assigns soft weights by automatically\naggregating the relations. Extensive experiments on two datasets demonstrate\nthe effectiveness of our proposed approach. Code and datasets are available in\nhttps://github.com/zjunlp/deepke.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 12:47:00 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Yu", "Haiyang", ""], ["Zhang", "Ningyu", ""], ["Deng", "Shumin", ""], ["Yuan", "Zonggang", ""], ["Jia", "Yantao", ""], ["Chen", "Huajun", ""]]}, {"id": "2009.07032", "submitter": "Yang Liu", "authors": "Yang Liu, Sheng Shen, Mirella Lapata", "title": "Noisy Self-Knowledge Distillation for Text Summarization", "comments": "update proceeding version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we apply self-knowledge distillation to text summarization\nwhich we argue can alleviate problems with maximum-likelihood training on\nsingle reference and noisy datasets. Instead of relying on one-hot annotation\nlabels, our student summarization model is trained with guidance from a teacher\nwhich generates smoothed labels to help regularize training. Furthermore, to\nbetter model uncertainty during training, we introduce multiple noise signals\nfor both teacher and student models. We demonstrate experimentally on three\nbenchmarks that our framework boosts the performance of both pretrained and\nnon-pretrained summarizers achieving state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 12:53:09 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 15:38:55 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Liu", "Yang", ""], ["Shen", "Sheng", ""], ["Lapata", "Mirella", ""]]}, {"id": "2009.07053", "submitter": "Joseph DeRose", "authors": "Joseph F DeRose, Jiayao Wang, and Matthew Berger", "title": "Attention Flows: Analyzing and Comparing Attention Mechanisms in\n  Language Models", "comments": "11 pages, 12 figures, to be published in IEEE Transactions on\n  Visualization and Computer Graphics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in language modeling have led to the development of deep\nattention-based models that are performant across a wide variety of natural\nlanguage processing (NLP) problems. These language models are typified by a\npre-training process on large unlabeled text corpora and subsequently\nfine-tuned for specific tasks. Although considerable work has been devoted to\nunderstanding the attention mechanisms of pre-trained models, it is less\nunderstood how a model's attention mechanisms change when trained for a target\nNLP task. In this paper, we propose a visual analytics approach to\nunderstanding fine-tuning in attention-based language models. Our\nvisualization, Attention Flows, is designed to support users in querying,\ntracing, and comparing attention within layers, across layers, and amongst\nattention heads in Transformer-based language models. To help users gain\ninsight on how a classification decision is made, our design is centered on\ndepicting classification-based attention at the deepest layer and how attention\nfrom prior layers flows throughout words in the input. Attention Flows supports\nthe analysis of a single model, as well as the visual comparison between\npre-trained and fine-tuned models via their similarities and differences. We\nuse Attention Flows to study attention mechanisms in various sentence\nunderstanding tasks and highlight how attention evolves to address the nuances\nof solving these tasks.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2020 19:56:30 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["DeRose", "Joseph F", ""], ["Wang", "Jiayao", ""], ["Berger", "Matthew", ""]]}, {"id": "2009.07057", "submitter": "Parthasarathy Suryanarayanan", "authors": "Parthasarathy Suryanarayanan, Ching-Huei Tsou, Ananya Poddar, Diwakar\n  Mahajan, Bharath Dandala, Piyush Madan, Anshul Agrawal, Charles Wachira,\n  Osebe Mogaka Samuel, Osnat Bar-Shira, Clifton Kipchirchir, Sharon Okwako,\n  William Ogallo, Fred Otieno, Timothy Nyota, Fiona Matu, Vesna Resende Barros,\n  Daniel Shats, Oren Kagan, Sekou Remy, Oliver Bent, Pooja Guhan, Shilpa\n  Mahatma, Aisha Walcott-Bryant, Divya Pathak, Michal Rosen-Zvi", "title": "WNTRAC: AI Assisted Tracking of Non-pharmaceutical Interventions\n  Implemented Worldwide for COVID-19", "comments": "Updated title (Artificial Intelligence => AI). Updated figures.\n  Referenced the open-sourced code repository in Code Availability section.\n  Updated figures in the Usage Notes section", "journal-ref": null, "doi": "10.1038/s41597-021-00878-y", "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Coronavirus disease 2019 (COVID-19) global pandemic has transformed\nalmost every facet of human society throughout the world. Against an emerging,\nhighly transmissible disease with no definitive treatment or vaccine,\ngovernments worldwide have implemented non-pharmaceutical intervention (NPI) to\nslow the spread of the virus. Examples of such interventions include community\nactions (e.g. school closures, restrictions on mass gatherings), individual\nactions (e.g. mask wearing, self-quarantine), and environmental actions (e.g.\npublic facility cleaning). We present the Worldwide Non-pharmaceutical\nInterventions Tracker for COVID-19 (WNTRAC), a comprehensive dataset consisting\nof over 6,000 NPIs implemented worldwide since the start of the pandemic.\nWNTRAC covers NPIs implemented across 261 countries and territories, and\nclassifies NPI measures into a taxonomy of sixteen NPI types. NPI measures are\nautomatically extracted daily from Wikipedia articles using natural language\nprocessing techniques and manually validated to ensure accuracy and veracity.\nWe hope that the dataset is valuable for policymakers, public health leaders,\nand researchers in modeling and analysis efforts for controlling the spread of\nCOVID-19.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 18:06:20 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 14:07:07 GMT"}, {"version": "v3", "created": "Sat, 5 Dec 2020 17:39:22 GMT"}, {"version": "v4", "created": "Mon, 4 Jan 2021 19:12:48 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Suryanarayanan", "Parthasarathy", ""], ["Tsou", "Ching-Huei", ""], ["Poddar", "Ananya", ""], ["Mahajan", "Diwakar", ""], ["Dandala", "Bharath", ""], ["Madan", "Piyush", ""], ["Agrawal", "Anshul", ""], ["Wachira", "Charles", ""], ["Samuel", "Osebe Mogaka", ""], ["Bar-Shira", "Osnat", ""], ["Kipchirchir", "Clifton", ""], ["Okwako", "Sharon", ""], ["Ogallo", "William", ""], ["Otieno", "Fred", ""], ["Nyota", "Timothy", ""], ["Matu", "Fiona", ""], ["Barros", "Vesna Resende", ""], ["Shats", "Daniel", ""], ["Kagan", "Oren", ""], ["Remy", "Sekou", ""], ["Bent", "Oliver", ""], ["Guhan", "Pooja", ""], ["Mahatma", "Shilpa", ""], ["Walcott-Bryant", "Aisha", ""], ["Pathak", "Divya", ""], ["Rosen-Zvi", "Michal", ""]]}, {"id": "2009.07058", "submitter": "Louis Clouatre", "authors": "Louis Clouatre, Philippe Trempe, Amal Zouaq, Sarath Chandar", "title": "MLMLM: Link Prediction with Mean Likelihood Masked Language Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Bases (KBs) are easy to query, verifiable, and interpretable. They\nhowever scale with man-hours and high-quality data. Masked Language Models\n(MLMs), such as BERT, scale with computing power as well as unstructured raw\ntext data. The knowledge contained within those models is however not directly\ninterpretable. We propose to perform link prediction with MLMs to address both\nthe KBs scalability issues and the MLMs interpretability issues. To do that we\nintroduce MLMLM, Mean Likelihood Masked Language Model, an approach comparing\nthe mean likelihood of generating the different entities to perform link\nprediction in a tractable manner. We obtain State of the Art (SotA) results on\nthe WN18RR dataset and the best non-entity-embedding based results on the\nFB15k-237 dataset. We also obtain convincing results on link prediction on\npreviously unseen entities, making MLMLM a suitable approach to introducing new\nentities to a KB.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 13:11:13 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Clouatre", "Louis", ""], ["Trempe", "Philippe", ""], ["Zouaq", "Amal", ""], ["Chandar", "Sarath", ""]]}, {"id": "2009.07117", "submitter": "Tianyu Zhao", "authors": "Tianyu Zhao and Tatsuya Kawahara", "title": "Multi-Referenced Training for Dialogue Response Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In open-domain dialogue response generation, a dialogue context can be\ncontinued with diverse responses, and the dialogue models should capture such\none-to-many relations. In this work, we first analyze the training objective of\ndialogue models from the view of Kullback-Leibler divergence (KLD) and show\nthat the gap between the real world probability distribution and the\nsingle-referenced data's probability distribution prevents the model from\nlearning the one-to-many relations efficiently. Then we explore approaches to\nmulti-referenced training in two aspects. Data-wise, we generate diverse pseudo\nreferences from a powerful pretrained model to build multi-referenced data that\nprovides a better approximation of the real-world distribution. Model-wise, we\npropose to equip variational models with an expressive prior, named linear\nGaussian model (LGM). Experimental results of automated evaluation and human\nevaluation show that the methods yield significant improvements over baselines.\nWe will release our code and data in\nhttps://github.com/ZHAOTING/dialog-processing.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 14:17:53 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2020 08:02:58 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Zhao", "Tianyu", ""], ["Kawahara", "Tatsuya", ""]]}, {"id": "2009.07118", "submitter": "Timo Schick", "authors": "Timo Schick, Hinrich Sch\\\"utze", "title": "It's Not Just Size That Matters: Small Language Models Are Also Few-Shot\n  Learners", "comments": "Accepted at NAACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When scaled to hundreds of billions of parameters, pretrained language models\nsuch as GPT-3 (Brown et al., 2020) achieve remarkable few-shot performance.\nHowever, enormous amounts of compute are required for training and applying\nsuch big models, resulting in a large carbon footprint and making it difficult\nfor researchers and practitioners to use them. We show that performance similar\nto GPT-3 can be obtained with language models that are much \"greener\" in that\ntheir parameter count is several orders of magnitude smaller. This is achieved\nby converting textual inputs into cloze questions that contain a task\ndescription, combined with gradient-based optimization; exploiting unlabeled\ndata gives further improvements. We identify key factors required for\nsuccessful natural language understanding with small language models.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 14:18:53 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 08:16:59 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Schick", "Timo", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "2009.07119", "submitter": "Sidik Soleman", "authors": "Miftahul Mahfuzh, Sidik Soleman, Ayu Purwarianti", "title": "Improving Joint Layer RNN based Keyphrase Extraction by Using\n  Syntactical Features", "comments": "6 pages", "journal-ref": "2019 International Conference of Advanced Informatics: Concepts,\n  Theory and Applications (ICAICTA)", "doi": "10.1109/ICAICTA.2019.8904194", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyphrase extraction as a task to identify important words or phrases from a\ntext, is a crucial process to identify main topics when analyzing texts from a\nsocial media platform. In our study, we focus on text written in Indonesia\nlanguage taken from Twitter. Different from the original joint layer recurrent\nneural network (JRNN) with output of one sequence of keywords and using only\nword embedding, here we propose to modify the input layer of JRNN to extract\nmore than one sequence of keywords by additional information of syntactical\nfeatures, namely part of speech, named entity types, and dependency structures.\nSince JRNN in general requires a large amount of data as the training examples\nand creating those examples is expensive, we used a data augmentation method to\nincrease the number of training examples. Our experiment had shown that our\nmethod outperformed the baseline methods. Our method achieved .9597 in accuracy\nand .7691 in F1.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 14:20:04 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Mahfuzh", "Miftahul", ""], ["Soleman", "Sidik", ""], ["Purwarianti", "Ayu", ""]]}, {"id": "2009.07148", "submitter": "Juyong Jiang", "authors": "Juyong Jiang, Jie Zhang, Kai Zhang", "title": "Cascaded Semantic and Positional Self-Attention Network for Document\n  Classification", "comments": "Accepted to Proc. Conf. Empirical Methods in Natural Language\n  Processing 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers have shown great success in learning representations for\nlanguage modelling. However, an open challenge still remains on how to\nsystematically aggregate semantic information (word embedding) with positional\n(or temporal) information (word orders). In this work, we propose a new\narchitecture to aggregate the two sources of information using cascaded\nsemantic and positional self-attention network (CSPAN) in the context of\ndocument classification. The CSPAN uses a semantic self-attention layer\ncascaded with Bi-LSTM to process the semantic and positional information in a\nsequential manner, and then adaptively combine them together through a residue\nconnection. Compared with commonly used positional encoding schemes, CSPAN can\nexploit the interaction between semantics and word positions in a more\ninterpretable and adaptive manner, and the classification performance can be\nnotably improved while simultaneously preserving a compact model size and high\nconvergence rate. We evaluate the CSPAN model on several benchmark data sets\nfor document classification with careful ablation studies, and demonstrate the\nencouraging results compared with state of the art.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 15:02:28 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 18:43:59 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Jiang", "Juyong", ""], ["Zhang", "Jie", ""], ["Zhang", "Kai", ""]]}, {"id": "2009.07162", "submitter": "Haoran Li", "authors": "Tiangang Zhu, Yue Wang, Haoran Li, Youzheng Wu, Xiaodong He and Bowen\n  Zhou", "title": "Multimodal Joint Attribute Prediction and Value Extraction for\n  E-commerce Product", "comments": "Accepted by EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Product attribute values are essential in many e-commerce scenarios, such as\ncustomer service robots, product recommendations, and product retrieval. While\nin the real world, the attribute values of a product are usually incomplete and\nvary over time, which greatly hinders the practical applications. In this\npaper, we propose a multimodal method to jointly predict product attributes and\nextract values from textual product descriptions with the help of the product\nimages. We argue that product attributes and values are highly correlated,\ne.g., it will be easier to extract the values on condition that the product\nattributes are given. Thus, we jointly model the attribute prediction and value\nextraction tasks from multiple aspects towards the interactions between\nattributes and values. Moreover, product images have distinct effects on our\ntasks for different product attributes and values. Thus, we selectively draw\nuseful visual information from product images to enhance our model. We annotate\na multimodal product attribute value dataset that contains 87,194 instances,\nand the experimental results on this dataset demonstrate that explicitly\nmodeling the relationship between attributes and values facilitates our method\nto establish the correspondence between them, and selectively utilizing visual\nproduct information is necessary for the task. Our code and dataset will be\nreleased to the public.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 15:10:51 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Zhu", "Tiangang", ""], ["Wang", "Yue", ""], ["Li", "Haoran", ""], ["Wu", "Youzheng", ""], ["He", "Xiaodong", ""], ["Zhou", "Bowen", ""]]}, {"id": "2009.07177", "submitter": "Jason Lee", "authors": "Jason Lee, Raphael Shu, Kyunghyun Cho", "title": "Iterative Refinement in the Continuous Space for Non-Autoregressive\n  Neural Machine Translation", "comments": "Accepted to EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient inference procedure for non-autoregressive machine\ntranslation that iteratively refines translation purely in the continuous\nspace. Given a continuous latent variable model for machine translation (Shu et\nal., 2020), we train an inference network to approximate the gradient of the\nmarginal log probability of the target sentence, using only the latent variable\nas input. This allows us to use gradient-based optimization to find the target\nsentence at inference time that approximately maximizes its marginal\nprobability. As each refinement step only involves computation in the latent\nspace of low dimensionality (we use 8 in our experiments), we avoid\ncomputational overhead incurred by existing non-autoregressive inference\nprocedures that often refine in token space. We compare our approach to a\nrecently proposed EM-like inference procedure (Shu et al., 2020) that optimizes\nin a hybrid space, consisting of both discrete and continuous variables. We\nevaluate our approach on WMT'14 En-De, WMT'16 Ro-En and IWSLT'16 De-En, and\nobserve two advantages over the EM-like inference: (1) it is computationally\nefficient, i.e. each refinement step is twice as fast, and (2) it is more\neffective, resulting in higher marginal probabilities and BLEU scores with the\nsame number of refinement steps. On WMT'14 En-De, for instance, our approach is\nable to decode 6.2 times faster than the autoregressive model with minimal\ndegradation to translation quality (0.9 BLEU).\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 15:30:14 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Lee", "Jason", ""], ["Shu", "Raphael", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "2009.07185", "submitter": "Gregor Betz", "authors": "Gregor Betz and Christian Voigt and Kyle Richardson", "title": "Critical Thinking for Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper takes a first step towards a critical thinking curriculum for\nneural auto-regressive language models. We introduce a synthetic corpus of\ndeductively valid arguments, and generate artificial argumentative texts to\ntrain and evaluate GPT-2. Significant transfer learning effects can be\nobserved: Training a model on three simple core schemes allows it to accurately\ncomplete conclusions of different, and more complex types of arguments, too.\nThe language models generalize the core argument schemes in a correct way.\nMoreover, we obtain consistent and promising results for NLU benchmarks. In\nparticular, pre-training on the argument schemes raises zero-shot accuracy on\nthe GLUE diagnostics by up to 15 percentage points. The findings suggest that\nintermediary pre-training on texts that exemplify basic reasoning abilities\n(such as typically covered in critical thinking textbooks) might help language\nmodels to acquire a broad range of reasoning skills. The synthetic\nargumentative texts presented in this paper are a promising starting point for\nbuilding such a \"critical thinking curriculum for language models.\"\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 15:49:19 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 14:42:42 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Betz", "Gregor", ""], ["Voigt", "Christian", ""], ["Richardson", "Kyle", ""]]}, {"id": "2009.07188", "submitter": "Parul Awasthy", "authors": "Parul Awasthy and Tahira Naseem and Jian Ni and Taesun Moon and Radu\n  Florian", "title": "Event Presence Prediction Helps Trigger Detection Across Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of event detection and classification is central to most information\nretrieval applications. We show that a Transformer based architecture can\neffectively model event extraction as a sequence labeling task. We propose a\ncombination of sentence level and token level training objectives that\nsignificantly boosts the performance of a BERT based event extraction model.\nOur approach achieves a new state-of-the-art performance on ACE 2005 data for\nEnglish and Chinese. We also test our model on ERE Spanish, achieving an\naverage gain of 2 absolute F1 points over prior best performing model.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 15:52:21 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Awasthy", "Parul", ""], ["Naseem", "Tahira", ""], ["Ni", "Jian", ""], ["Moon", "Taesun", ""], ["Florian", "Radu", ""]]}, {"id": "2009.07238", "submitter": "Victor Makarenkov", "authors": "Victor Makarenkov and Lior Rokach", "title": "Lessons Learned from Applying off-the-shelf BERT: There is no Silver\n  Bullet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the challenges in the NLP field is training large classification\nmodels, a task that is both difficult and tedious. It is even harder when GPU\nhardware is unavailable. The increased availability of pre-trained and\noff-the-shelf word embeddings, models, and modules aim at easing the process of\ntraining large models and achieving a competitive performance. We explore the\nuse of off-the-shelf BERT models and share the results of our experiments and\ncompare their results to those of LSTM networks and more simple baselines. We\nshow that the complexity and computational cost of BERT is not a guarantee for\nenhanced predictive performance in the classification tasks at hand.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 17:24:52 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 12:58:35 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Makarenkov", "Victor", ""], ["Rokach", "Lior", ""]]}, {"id": "2009.07243", "submitter": "Moin Nadeem", "authors": "Moin Nadeem, Tianxing He, Kyunghyun Cho, James Glass", "title": "A Systematic Characterization of Sampling Algorithms for Open-ended\n  Language Generation", "comments": "To appear at AACL 2020; 9 pages, 12 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the widely adopted ancestral sampling algorithms for\nauto-regressive language models, which is not widely studied in the literature.\nWe use the quality-diversity (Q-D) trade-off to investigate three popular\nsampling algorithms (top-k, nucleus and tempered sampling). We focus on the\ntask of open-ended language generation. We first show that the existing\nsampling algorithms have similar performance. After carefully inspecting the\ntransformations defined by different sampling algorithms, we identify three key\nproperties that are shared among them: entropy reduction, order preservation,\nand slope preservation. To validate the importance of the identified\nproperties, we design two sets of new sampling algorithms: one set in which\neach algorithm satisfies all three properties, and one set in which each\nalgorithm violates at least one of the properties. We compare their performance\nwith existing sampling algorithms, and find that violating the identified\nproperties could lead to drastic performance degradation, as measured by the\nQ-D trade-off. On the other hand, we find that the set of sampling algorithms\nthat satisfies these properties performs on par with the existing sampling\nalgorithms. Our data and code are available at\nhttps://github.com/moinnadeem/characterizing-sampling-algorithms\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 17:28:42 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Nadeem", "Moin", ""], ["He", "Tianxing", ""], ["Cho", "Kyunghyun", ""], ["Glass", "James", ""]]}, {"id": "2009.07253", "submitter": "Alexander Lin", "authors": "Alexander Lin, Jeremy Wohlwend, Howard Chen, and Tao Lei", "title": "Autoregressive Knowledge Distillation through Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of autoregressive models on natural language generation tasks\nhas dramatically improved due to the adoption of deep, self-attentive\narchitectures. However, these gains have come at the cost of hindering\ninference speed, making state-of-the-art models cumbersome to deploy in\nreal-world, time-sensitive settings. We develop a compression technique for\nautoregressive models that is driven by an imitation learning perspective on\nknowledge distillation. The algorithm is designed to address the exposure bias\nproblem. On prototypical language generation tasks such as translation and\nsummarization, our method consistently outperforms other distillation\nalgorithms, such as sequence-level knowledge distillation. Student models\ntrained with our method attain 1.4 to 4.8 BLEU/ROUGE points higher than those\ntrained from scratch, while increasing inference speed by up to 14 times in\ncomparison to the teacher model.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 17:43:02 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 00:40:45 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Lin", "Alexander", ""], ["Wohlwend", "Jeremy", ""], ["Chen", "Howard", ""], ["Lei", "Tao", ""]]}, {"id": "2009.07258", "submitter": "Kai Hui", "authors": "Zhi Zheng, Kai Hui, Ben He, Xianpei Han, Le Sun, Andrew Yates", "title": "BERT-QE: Contextualized Query Expansion for Document Re-ranking", "comments": "Accepted in EMNLP-Findings 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Query expansion aims to mitigate the mismatch between the language used in a\nquery and in a document. However, query expansion methods can suffer from\nintroducing non-relevant information when expanding the query. To bridge this\ngap, inspired by recent advances in applying contextualized models like BERT to\nthe document retrieval task, this paper proposes a novel query expansion model\nthat leverages the strength of the BERT model to select relevant document\nchunks for expansion. In evaluation on the standard TREC Robust04 and GOV2 test\ncollections, the proposed BERT-QE model significantly outperforms BERT-Large\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 17:50:09 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 16:08:25 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Zheng", "Zhi", ""], ["Hui", "Kai", ""], ["He", "Ben", ""], ["Han", "Xianpei", ""], ["Sun", "Le", ""], ["Yates", "Andrew", ""]]}, {"id": "2009.07310", "submitter": "Ozan Caglayan", "authors": "Ozan Caglayan, Julia Ive, Veneta Haralampieva, Pranava Madhyastha,\n  Lo\\\"ic Barrault and Lucia Specia", "title": "Simultaneous Machine Translation with Visual Context", "comments": "Long paper accepted to EMNLP 2020, Camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneous machine translation (SiMT) aims to translate a continuous input\ntext stream into another language with the lowest latency and highest quality\npossible. The translation thus has to start with an incomplete source text,\nwhich is read progressively, creating the need for anticipation. In this paper,\nwe seek to understand whether the addition of visual information can compensate\nfor the missing source context. To this end, we analyse the impact of different\nmultimodal approaches and visual features on state-of-the-art SiMT frameworks.\nOur results show that visual context is helpful and that visually-grounded\nmodels based on explicit object region information are much better than\ncommonly used global features, reaching up to 3 BLEU points improvement under\nlow latency scenarios. Our qualitative analysis illustrates cases where only\nthe multimodal systems are able to translate correctly from English into\ngender-marked languages, as well as deal with differences in word order, such\nas adjective-noun placement between English and French.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 18:19:11 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 10:27:15 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 10:45:18 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Caglayan", "Ozan", ""], ["Ive", "Julia", ""], ["Haralampieva", "Veneta", ""], ["Madhyastha", "Pranava", ""], ["Barrault", "Lo\u00efc", ""], ["Specia", "Lucia", ""]]}, {"id": "2009.07317", "submitter": "Parul Awasthy", "authors": "Parul Awasthy and Taesun Moon and Jian Ni and Radu Florian", "title": "Cascaded Models for Better Fine-Grained Named Entity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named Entity Recognition (NER) is an essential precursor task for many\nnatural language applications, such as relation extraction or event extraction.\nMuch of the NER research has been done on datasets with few classes of entity\ntypes (e.g. PER, LOC, ORG, MISC), but many real world applications (disaster\nrelief, complex event extraction, law enforcement) can benefit from a larger\nNER typeset. More recently, datasets were created that have hundreds to\nthousands of types of entities, sparking new lines of research (Sekine,\n2008;Ling and Weld, 2012; Gillick et al., 2014; Choiet al., 2018). In this\npaper we present a cascaded approach to labeling fine-grained NER, applying to\na newly released fine-grained NER dataset that was used in the TAC KBP 2019\nevaluation (Ji et al., 2019), inspired by the fact that training data is\navailable for some of the coarse labels. Using a combination of transformer\nnetworks, we show that performance can be improved by about 20 F1 absolute, as\ncompared with the straightforward model built on the full fine-grained types,\nand show that, surprisingly, using course-labeled data in three languages leads\nto an improvement in the English data.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 18:41:29 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Awasthy", "Parul", ""], ["Moon", "Taesun", ""], ["Ni", "Jian", ""], ["Florian", "Radu", ""]]}, {"id": "2009.07364", "submitter": "Zining Zhu", "authors": "Zining Zhu, Frank Rudzicz", "title": "An information theoretic view on selecting linguistic probes", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is increasing interest in assessing the linguistic knowledge encoded in\nneural representations. A popular approach is to attach a diagnostic classifier\n-- or \"probe\" -- to perform supervised classification from internal\nrepresentations. However, how to select a good probe is in debate. Hewitt and\nLiang (2019) showed that a high performance on diagnostic classification itself\nis insufficient, because it can be attributed to either \"the representation\nbeing rich in knowledge\", or \"the probe learning the task\", which Pimentel et\nal. (2020) challenged. We show this dichotomy is valid\ninformation-theoretically. In addition, we find that the methods to construct\nand select good probes proposed by the two papers, *control task* (Hewitt and\nLiang, 2019) and *control function* (Pimentel et al., 2020), are equivalent --\nthe errors of their approaches are identical (modulo irrelevant terms).\nEmpirically, these two selection criteria lead to results that highly agree\nwith each other.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 21:52:16 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 14:50:57 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Zhu", "Zining", ""], ["Rudzicz", "Frank", ""]]}, {"id": "2009.07365", "submitter": "Matthias Lindemann", "authors": "Matthias Lindemann, Jonas Groschwitz, Alexander Koller", "title": "Fast semantic parsing with well-typedness guarantees", "comments": "Accepted at EMNLP 2020, camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AM dependency parsing is a linguistically principled method for neural\nsemantic parsing with high accuracy across multiple graphbanks. It relies on a\ntype system that models semantic valency but makes existing parsers slow. We\ndescribe an A* parser and a transition-based parser for AM dependency parsing\nwhich guarantee well-typedness and improve parsing speed by up to 3 orders of\nmagnitude, while maintaining or improving accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 21:54:01 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 14:49:04 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Lindemann", "Matthias", ""], ["Groschwitz", "Jonas", ""], ["Koller", "Alexander", ""]]}, {"id": "2009.07373", "submitter": "Rujun Han", "authors": "Rujun Han, Yichao Zhou, Nanyun Peng", "title": "Domain Knowledge Empowered Structured Neural Net for End-to-End Event\n  Temporal Relation Extraction", "comments": "Appear in EMNLP'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting event temporal relations is a critical task for information\nextraction and plays an important role in natural language understanding. Prior\nsystems leverage deep learning and pre-trained language models to improve the\nperformance of the task. However, these systems often suffer from two\nshort-comings: 1) when performing maximum a posteriori (MAP) inference based on\nneural models, previous systems only used structured knowledge that are assumed\nto be absolutely correct, i.e., hard constraints; 2) biased predictions on\ndominant temporal relations when training with a limited amount of data. To\naddress these issues, we propose a framework that enhances deep neural network\nwith distributional constraints constructed by probabilistic domain knowledge.\nWe solve the constrained inference problem via Lagrangian Relaxation and apply\nit on end-to-end event temporal relation extraction tasks. Experimental results\nshow our framework is able to improve the baseline neural network models with\nstrong statistical significance on two widely used datasets in news and\nclinical domains.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 22:20:27 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 16:58:49 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Han", "Rujun", ""], ["Zhou", "Yichao", ""], ["Peng", "Nanyun", ""]]}, {"id": "2009.07382", "submitter": "Junjie Yang", "authors": "Junjie Yang, Zhuosheng Zhang, Hai Zhao", "title": "Multi-span Style Extraction for Generative Reading Comprehension", "comments": "AAAI-21 SDU Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative machine reading comprehension (MRC) requires a model to generate\nwell-formed answers. For this type of MRC, answer generation method is crucial\nto the model performance. However, generative models, which are supposed to be\nthe right model for the task, in generally perform poorly. At the same time,\nsingle-span extraction models have been proven effective for extractive MRC,\nwhere the answer is constrained to a single span in the passage. Nevertheless,\nthey generally suffer from generating incomplete answers or introducing\nredundant words when applied to the generative MRC. Thus, we extend the\nsingle-span extraction method to multi-span, proposing a new framework which\nenables generative MRC to be smoothly solved as multi-span extraction. Thorough\nexperiments demonstrate that this novel approach can alleviate the dilemma\nbetween generative models and single-span models and produce answers with\nbetter-formed syntax and semantics.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 23:06:48 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 13:56:13 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Yang", "Junjie", ""], ["Zhang", "Zhuosheng", ""], ["Zhao", "Hai", ""]]}, {"id": "2009.07391", "submitter": "Haley Lepp", "authors": "Haley Lepp, Gina-Anne Levow", "title": "Pardon the Interruption: An Analysis of Gender and Turn-Taking in U.S.\n  Supreme Court Oral Arguments", "comments": "To be appear in Proceedings of INTERSPEECH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study presents a corpus of turn changes between speakers in U.S. Supreme\nCourt oral arguments. Each turn change is labeled on a spectrum of\n\"cooperative\" to \"competitive\" by a human annotator with legal experience in\nthe United States. We analyze the relationship between speech features, the\nnature of exchanges, and the gender and legal role of the speakers. Finally, we\ndemonstrate that the models can be used to predict the label of an exchange\nwith moderate success. The automatic classification of the nature of exchanges\nindicates that future studies of turn-taking in oral arguments can rely on\nlarger, unlabeled corpora.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 23:37:48 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Lepp", "Haley", ""], ["Levow", "Gina-Anne", ""]]}, {"id": "2009.07396", "submitter": "Victor Zhong", "authors": "Victor Zhong, Mike Lewis, Sida I. Wang, Luke Zettlemoyer", "title": "Grounded Adaptation for Zero-shot Executable Semantic Parsing", "comments": "EMNLP 2020 long paper. 14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Grounded Adaptation for Zero-shot Executable Semantic Parsing\n(GAZP) to adapt an existing semantic parser to new environments (e.g. new\ndatabase schemas). GAZP combines a forward semantic parser with a backward\nutterance generator to synthesize data (e.g. utterances and SQL queries) in the\nnew environment, then selects cycle-consistent examples to adapt the parser.\nUnlike data-augmentation, which typically synthesizes unverified examples in\nthe training environment, GAZP synthesizes examples in the new environment\nwhose input-output consistency are verified. On the Spider, Sparc, and CoSQL\nzero-shot semantic parsing tasks, GAZP improves logical form and execution\naccuracy of the baseline parser. Our analyses show that GAZP outperforms\ndata-augmentation in the training environment, performance increases with the\namount of GAZP-synthesized data, and cycle-consistency is central to successful\nadaptation.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 00:16:59 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 00:37:15 GMT"}, {"version": "v3", "created": "Mon, 1 Feb 2021 20:44:05 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Zhong", "Victor", ""], ["Lewis", "Mike", ""], ["Wang", "Sida I.", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "2009.07397", "submitter": "Fouzi Harrag", "authors": "Fouzi Harrag, Abdulmalik Salman Al-Salman and Alaa Alquahtani", "title": "Arabic Opinion Mining Using a Hybrid Recommender System Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recommender systems nowadays are playing an important role in the delivery of\nservices and information to users. Sentiment analysis (also known as opinion\nmining) is the process of determining the attitude of textual opinions, whether\nthey are positive, negative or neutral. Data sparsity is representing a big\nissue for recommender systems because of the insufficiency of user rating or\nabsence of data about users or items. This research proposed a hybrid approach\ncombining sentiment analysis and recommender systems to tackle the problem of\ndata sparsity problems by predicting the rating of products from users reviews\nusing text mining and NLP techniques. This research focuses especially on\nArabic reviews, where the model is evaluated using Opinion Corpus for Arabic\n(OCA) dataset. Our system was efficient, and it showed a good accuracy of\nnearly 85 percent in predicting rating from reviews\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 00:21:56 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Harrag", "Fouzi", ""], ["Al-Salman", "Abdulmalik Salman", ""], ["Alquahtani", "Alaa", ""]]}, {"id": "2009.07402", "submitter": "Xiyao Ma", "authors": "Xiyao Ma, Qile Zhu, Yanlin Zhou, Xiaolin Li, Dapeng Wu", "title": "Asking Complex Questions with Multi-hop Answer-focused Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asking questions from natural language text has attracted increasing\nattention recently, and several schemes have been proposed with promising\nresults by asking the right question words and copy relevant words from the\ninput to the question. However, most state-of-the-art methods focus on asking\nsimple questions involving single-hop relations. In this paper, we propose a\nnew task called multihop question generation that asks complex and semantically\nrelevant questions by additionally discovering and modeling the multiple\nentities and their semantic relations given a collection of documents and the\ncorresponding answer 1. To solve the problem, we propose multi-hop\nanswer-focused reasoning on the grounded answer-centric entity graph to include\ndifferent granularity levels of semantic information including the word-level\nand document-level semantics of the entities and their semantic relations.\nThrough extensive experiments on the HOTPOTQA dataset, we demonstrate the\nsuperiority and effectiveness of our proposed model that serves as a baseline\nto motivate future work.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 00:30:49 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Ma", "Xiyao", ""], ["Zhu", "Qile", ""], ["Zhou", "Yanlin", ""], ["Li", "Xiaolin", ""], ["Wu", "Dapeng", ""]]}, {"id": "2009.07406", "submitter": "Martin Kuo", "authors": "Martin Kuo, Yaobo Liang, Lei Ji, Nan Duan, Linjun Shou, Ming Gong,\n  Peng Chen", "title": "Tag and Correct: Question aware Open Information Extraction with\n  Two-stage Decoding", "comments": "11 pages, 1 figure, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question Aware Open Information Extraction (Question aware Open IE) takes\nquestion and passage as inputs, outputting an answer tuple which contains a\nsubject, a predicate, and one or more arguments. Each field of answer is a\nnatural language word sequence and is extracted from the passage. The\nsemi-structured answer has two advantages which are more readable and\nfalsifiable compared to span answer. There are two approaches to solve this\nproblem. One is an extractive method which extracts candidate answers from the\npassage with the Open IE model, and ranks them by matching with questions. It\nfully uses the passage information at the extraction step, but the extraction\nis independent to the question. The other one is the generative method which\nuses a sequence to sequence model to generate answers directly. It combines the\nquestion and passage as input at the same time, but it generates the answer\nfrom scratch, which does not use the facts that most of the answer words come\nfrom in the passage. To guide the generation by passage, we present a two-stage\ndecoding model which contains a tagging decoder and a correction decoder. At\nthe first stage, the tagging decoder will tag keywords from the passage. At the\nsecond stage, the correction decoder will generate answers based on tagged\nkeywords. Our model could be trained end-to-end although it has two stages.\nCompared to previous generative models, we generate better answers by\ngenerating coarse to fine. We evaluate our model on WebAssertions (Yan et al.,\n2018) which is a Question aware Open IE dataset. Our model achieves a BLEU\nscore of 59.32, which is better than previous generative methods.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 00:58:13 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Kuo", "Martin", ""], ["Liang", "Yaobo", ""], ["Ji", "Lei", ""], ["Duan", "Nan", ""], ["Shou", "Linjun", ""], ["Gong", "Ming", ""], ["Chen", "Peng", ""]]}, {"id": "2009.07408", "submitter": "Hao Fei", "authors": "Hao Fei and Yafeng Ren and Donghong Ji", "title": "Retrofitting Structure-aware Transformer Language Model for End Tasks", "comments": "Accepted as long paper in EMNLP2020 main proceeding", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider retrofitting structure-aware Transformer-based language model for\nfacilitating end tasks by proposing to exploit syntactic distance to encode\nboth the phrasal constituency and dependency connection into the language\nmodel. A middle-layer structural learning strategy is leveraged for structure\nintegration, accomplished with main semantic task training under multi-task\nlearning scheme. Experimental results show that the retrofitted structure-aware\nTransformer language model achieves improved perplexity, meanwhile inducing\naccurate syntactic phrases. By performing structure-aware fine-tuning, our\nmodel achieves significant improvements for both semantic- and\nsyntactic-dependent tasks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 01:07:07 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Fei", "Hao", ""], ["Ren", "Yafeng", ""], ["Ji", "Donghong", ""]]}, {"id": "2009.07411", "submitter": "Hao Fei", "authors": "Hao Fei and Yafeng Ren and Donghong Ji", "title": "Mimic and Conquer: Heterogeneous Tree Structure Distillation for\n  Syntactic NLP", "comments": "To appear at EMNLP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syntax has been shown useful for various NLP tasks, while existing work\nmostly encodes singleton syntactic tree using one hierarchical neural network.\nIn this paper, we investigate a simple and effective method, Knowledge\nDistillation, to integrate heterogeneous structure knowledge into a unified\nsequential LSTM encoder. Experimental results on four typical syntax-dependent\ntasks show that our method outperforms tree encoders by effectively integrating\nrich heterogeneous structure syntax, meanwhile reducing error propagation, and\nalso outperforms ensemble methods, in terms of both the efficiency and\naccuracy.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 01:30:21 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Fei", "Hao", ""], ["Ren", "Yafeng", ""], ["Ji", "Donghong", ""]]}, {"id": "2009.07453", "submitter": "Se Jung Kwon", "authors": "Insoo Chung, Byeongwook Kim, Yoonjung Choi, Se Jung Kwon, Yongkweon\n  Jeon, Baeseong Park, Sangha Kim and Dongsoo Lee", "title": "Extremely Low Bit Transformer Quantization for On-Device Neural Machine\n  Translation", "comments": "Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deployment of widely used Transformer architecture is challenging because\nof heavy computation load and memory overhead during inference, especially when\nthe target device is limited in computational resources such as mobile or edge\ndevices. Quantization is an effective technique to address such challenges. Our\nanalysis shows that for a given number of quantization bits, each block of\nTransformer contributes to translation quality and inference computations in\ndifferent manners. Moreover, even inside an embedding block, each word presents\nvastly different contributions. Correspondingly, we propose a mixed precision\nquantization strategy to represent Transformer weights by an extremely low\nnumber of bits (e.g., under 3 bits). For example, for each word in an embedding\nblock, we assign different quantization bits based on statistical property. Our\nquantized Transformer model achieves 11.8$\\times$ smaller model size than the\nbaseline model, with less than -0.5 BLEU. We achieve 8.3$\\times$ reduction in\nrun-time memory footprints and 3.5$\\times$ speed up (Galaxy N10+) such that our\nproposed compression strategy enables efficient implementation for on-device\nNMT.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 03:58:01 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 05:23:31 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Chung", "Insoo", ""], ["Kim", "Byeongwook", ""], ["Choi", "Yoonjung", ""], ["Kwon", "Se Jung", ""], ["Jeon", "Yongkweon", ""], ["Park", "Baeseong", ""], ["Kim", "Sangha", ""], ["Lee", "Dongsoo", ""]]}, {"id": "2009.07465", "submitter": "Yuyu Zhang", "authors": "Ping Nie, Yuyu Zhang, Arun Ramamurthy, Le Song", "title": "Answering Any-hop Open-domain Questions with Iterative Document\n  Reranking", "comments": "Accepted by SIGIR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing approaches for open-domain question answering (QA) are typically\ndesigned for questions that require either single-hop or multi-hop reasoning,\nwhich make strong assumptions of the complexity of questions to be answered.\nAlso, multi-step document retrieval often incurs higher number of relevant but\nnon-supporting documents, which dampens the downstream noise-sensitive reader\nmodule for answer extraction. To address these challenges, we propose a unified\nQA framework to answer any-hop open-domain questions, which iteratively\nretrieves, reranks and filters documents, and adaptively determines when to\nstop the retrieval process. To improve the retrieval accuracy, we propose a\ngraph-based reranking model that perform multi-document interaction as the core\nof our iterative reranking framework. Our method consistently achieves\nperformance comparable to or better than the state-of-the-art on both\nsingle-hop and multi-hop open-domain QA datasets, including Natural Questions\nOpen, SQuAD Open, and HotpotQA.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 04:31:38 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2021 09:57:56 GMT"}, {"version": "v3", "created": "Tue, 16 Mar 2021 22:33:25 GMT"}, {"version": "v4", "created": "Tue, 18 May 2021 22:22:33 GMT"}, {"version": "v5", "created": "Mon, 24 May 2021 06:15:40 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Nie", "Ping", ""], ["Zhang", "Yuyu", ""], ["Ramamurthy", "Arun", ""], ["Song", "Le", ""]]}, {"id": "2009.07473", "submitter": "Mayank Raj", "authors": "Mayank Raj, Ajay Jaiswal, Rohit R.R, Ankita Gupta, Sudeep Kumar Sahoo,\n  Vertika Srivastava, Yeon Hyang Kim", "title": "Solomon at SemEval-2020 Task 11: Ensemble Architecture for Fine-Tuned\n  Propaganda Detection in News Articles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes our system (Solomon) details and results of\nparticipation in the SemEval 2020 Task 11 \"Detection of Propaganda Techniques\nin News Articles\"\\cite{DaSanMartinoSemeval20task11}. We participated in Task\n\"Technique Classification\" (TC) which is a multi-class classification task. To\naddress the TC task, we used RoBERTa based transformer architecture for\nfine-tuning on the propaganda dataset. The predictions of RoBERTa were further\nfine-tuned by class-dependent-minority-class classifiers. A special classifier,\nwhich employs dynamically adapted Least Common Sub-sequence algorithm, is used\nto adapt to the intricacies of repetition class. Compared to the other\nparticipating systems, our submission is ranked 4th on the leaderboard.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 05:00:40 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Raj", "Mayank", ""], ["Jaiswal", "Ajay", ""], ["R", "Rohit R.", ""], ["Gupta", "Ankita", ""], ["Sahoo", "Sudeep Kumar", ""], ["Srivastava", "Vertika", ""], ["Kim", "Yeon Hyang", ""]]}, {"id": "2009.07481", "submitter": "Zongyi Li", "authors": "Zongyi Li and Xiaoqing Zheng", "title": "Unsupervised Summarization by Jointly Extracting Sentences and Keywords", "comments": "10 pages(includes 2 pages references), 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present RepRank, an unsupervised graph-based ranking model for extractive\nmulti-document summarization in which the similarity between words, sentences,\nand word-to-sentence can be estimated by the distances between their vector\nrepresentations in a unified vector space. In order to obtain desirable\nrepresentations, we propose a self-attention based learning method that\nrepresent a sentence by the weighted sum of its word embeddings, and the\nweights are concentrated to those words hopefully better reflecting the content\nof a document. We show that salient sentences and keywords can be extracted in\na joint and mutual reinforcement process using our learned representations, and\nprove that this process always converges to a unique solution leading to\nimprovement in performance. A variant of absorbing random walk and the\ncorresponding sampling-based algorithm are also described to avoid redundancy\nand increase diversity in the summaries. Experiment results with multiple\nbenchmark datasets show that RepRank achieved the best or comparable\nperformance in ROUGE.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 05:58:00 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Li", "Zongyi", ""], ["Zheng", "Xiaoqing", ""]]}, {"id": "2009.07489", "submitter": "Sufeng Duan", "authors": "Sufeng Duan, Hai Zhao and Rui Wang", "title": "Graph-to-Sequence Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) usually works in a seq2seq learning way by\nviewing either source or target sentence as a linear sequence of words, which\ncan be regarded as a special case of graph, taking words in the sequence as\nnodes and relationships between words as edges. In the light of the current NMT\nmodels more or less capture graph information among the sequence in a latent\nway, we present a graph-to-sequence model facilitating explicit graph\ninformation capturing. In detail, we propose a graph-based SAN-based NMT model\ncalled Graph-Transformer by capturing information of subgraphs of different\norders in every layers. Subgraphs are put into different groups according to\ntheir orders, and every group of subgraphs respectively reflect different\nlevels of dependency between words. For fusing subgraph representations, we\nempirically explore three methods which weight different groups of subgraphs of\ndifferent orders. Results of experiments on WMT14 English-German and IWSLT14\nGerman-English show that our method can effectively boost the Transformer with\nan improvement of 1.1 BLEU points on WMT14 English-German dataset and 1.0 BLEU\npoints on IWSLT14 German-English dataset.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 06:28:58 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Duan", "Sufeng", ""], ["Zhao", "Hai", ""], ["Wang", "Rui", ""]]}, {"id": "2009.07494", "submitter": "Ninghao Liu", "authors": "Ninghao Liu, Yunsong Meng, Xia Hu, Tie Wang, Bo Long", "title": "Are Interpretations Fairly Evaluated? A Definition Driven Pipeline for\n  Post-Hoc Interpretability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed an increasing number of interpretation methods\nbeing developed for improving transparency of NLP models. Meanwhile,\nresearchers also try to answer the question that whether the obtained\ninterpretation is faithful in explaining mechanisms behind model prediction?\nSpecifically, (Jain and Wallace, 2019) proposes that \"attention is not\nexplanation\" by comparing attention interpretation with gradient alternatives.\nHowever, it raises a new question that can we safely pick one interpretation\nmethod as the ground-truth? If not, on what basis can we compare different\ninterpretation methods? In this work, we propose that it is crucial to have a\nconcrete definition of interpretation before we could evaluate faithfulness of\nan interpretation. The definition will affect both the algorithm to obtain\ninterpretation and, more importantly, the metric used in evaluation. Through\nboth theoretical and experimental analysis, we find that although\ninterpretation methods perform differently under a certain evaluation metric,\nsuch a difference may not result from interpretation quality or faithfulness,\nbut rather the inherent bias of the evaluation metric.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 06:38:03 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Liu", "Ninghao", ""], ["Meng", "Yunsong", ""], ["Hu", "Xia", ""], ["Wang", "Tie", ""], ["Long", "Bo", ""]]}, {"id": "2009.07502", "submitter": "Dianqi Li", "authors": "Dianqi Li, Yizhe Zhang, Hao Peng, Liqun Chen, Chris Brockett,\n  Ming-Ting Sun, Bill Dolan", "title": "Contextualized Perturbation for Textual Adversarial Attack", "comments": "Accepted by NAACL 2021, long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples expose the vulnerabilities of natural language\nprocessing (NLP) models, and can be used to evaluate and improve their\nrobustness. Existing techniques of generating such examples are typically\ndriven by local heuristic rules that are agnostic to the context, often\nresulting in unnatural and ungrammatical outputs. This paper presents CLARE, a\nContextuaLized AdversaRial Example generation model that produces fluent and\ngrammatical outputs through a mask-then-infill procedure. CLARE builds on a\npre-trained masked language model and modifies the inputs in a context-aware\nmanner. We propose three contextualized perturbations, Replace, Insert and\nMerge, allowing for generating outputs of varied lengths. With a richer range\nof available strategies, CLARE is able to attack a victim model more\nefficiently with fewer edits. Extensive experiments and human evaluation\ndemonstrate that CLARE outperforms the baselines in terms of attack success\nrate, textual similarity, fluency and grammaticality.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 06:53:15 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 04:56:31 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Li", "Dianqi", ""], ["Zhang", "Yizhe", ""], ["Peng", "Hao", ""], ["Chen", "Liqun", ""], ["Brockett", "Chris", ""], ["Sun", "Ming-Ting", ""], ["Dolan", "Bill", ""]]}, {"id": "2009.07503", "submitter": "Ranran Haoran Zhang", "authors": "Ranran Haoran Zhang, Qianying Liu, Aysa Xuemo Fan, Heng Ji, Daojian\n  Zeng, Fei Cheng, Daisuke Kawahara and Sadao Kurohashi", "title": "Minimize Exposure Bias of Seq2Seq Models in Joint Entity and Relation\n  Extraction", "comments": "EMNLP 2020 Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint entity and relation extraction aims to extract relation triplets from\nplain text directly. Prior work leverages Sequence-to-Sequence (Seq2Seq) models\nfor triplet sequence generation. However, Seq2Seq enforces an unnecessary order\non the unordered triplets and involves a large decoding length associated with\nerror accumulation. These introduce exposure bias, which may cause the models\noverfit to the frequent label combination, thus deteriorating the\ngeneralization. We propose a novel Sequence-to-Unordered-Multi-Tree\n(Seq2UMTree) model to minimize the effects of exposure bias by limiting the\ndecoding length to three within a triplet and removing the order among\ntriplets. We evaluate our model on two datasets, DuIE and NYT, and\nsystematically study how exposure bias alters the performance of Seq2Seq\nmodels. Experiments show that the state-of-the-art Seq2Seq model overfits to\nboth datasets while Seq2UMTree shows significantly better generalization. Our\ncode is available at https://github.com/WindChimeRan/OpenJERE .\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 06:53:34 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 08:56:20 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Zhang", "Ranran Haoran", ""], ["Liu", "Qianying", ""], ["Fan", "Aysa Xuemo", ""], ["Ji", "Heng", ""], ["Zeng", "Daojian", ""], ["Cheng", "Fei", ""], ["Kawahara", "Daisuke", ""], ["Kurohashi", "Sadao", ""]]}, {"id": "2009.07526", "submitter": "Yuan Chai", "authors": "Jing Yu, Yuan Chai, Yujing Wang, Yue Hu, Qi Wu", "title": "CogTree: Cognition Tree Loss for Unbiased Scene Graph Generation", "comments": "Accepted by IJCAI 2021. SOLE copyright holder is IJCAI (International\n  Joint Conferences on Artificial Intelligence)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scene graphs are semantic abstraction of images that encourage visual\nunderstanding and reasoning. However, the performance of Scene Graph Generation\n(SGG) is unsatisfactory when faced with biased data in real-world scenarios.\nConventional debiasing research mainly studies from the view of balancing data\ndistribution or learning unbiased models and representations, ignoring the\ncorrelations among the biased classes. In this work, we analyze this problem\nfrom a novel cognition perspective: automatically building a hierarchical\ncognitive structure from the biased predictions and navigating that hierarchy\nto locate the relationships, making the tail relationships receive more\nattention in a coarse-to-fine mode. To this end, we propose a novel debiasing\nCognition Tree (CogTree) loss for unbiased SGG. We first build a cognitive\nstructure CogTree to organize the relationships based on the prediction of a\nbiased SGG model. The CogTree distinguishes remarkably different relationships\nat first and then focuses on a small portion of easily confused ones. Then, we\npropose a debiasing loss specially for this cognitive structure, which supports\ncoarse-to-fine distinction for the correct relationships. The loss is\nmodel-agnostic and consistently boosting the performance of several\nstate-of-the-art models. The code is available at:\nhttps://github.com/CYVincent/Scene-Graph-Transformer-CogTree.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 07:47:26 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 06:27:33 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Yu", "Jing", ""], ["Chai", "Yuan", ""], ["Wang", "Yujing", ""], ["Hu", "Yue", ""], ["Wu", "Qi", ""]]}, {"id": "2009.07543", "submitter": "Hengyi Cai", "authors": "Hengyi Cai, Hongshen Chen, Yonghao Song, Zhuoye Ding, Yongjun Bao,\n  Weipeng Yan, Xiaofang Zhao", "title": "Group-wise Contrastive Learning for Neural Dialogue Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural dialogue response generation has gained much popularity in recent\nyears. Maximum Likelihood Estimation (MLE) objective is widely adopted in\nexisting dialogue model learning. However, models trained with MLE objective\nfunction are plagued by the low-diversity issue when it comes to the\nopen-domain conversational setting. Inspired by the observation that humans not\nonly learn from the positive signals but also benefit from correcting behaviors\nof undesirable actions, in this work, we introduce contrastive learning into\ndialogue generation, where the model explicitly perceives the difference\nbetween the well-chosen positive and negative utterances. Specifically, we\nemploy a pretrained baseline model as a reference. During contrastive learning,\nthe target dialogue model is trained to give higher conditional probabilities\nfor the positive samples, and lower conditional probabilities for those\nnegative samples, compared to the reference model. To manage the multi-mapping\nrelations prevailed in human conversation, we augment contrastive dialogue\nlearning with group-wise dual sampling. Extensive experimental results show\nthat the proposed group-wise contrastive learning framework is suited for\ntraining a wide range of neural dialogue generation models with very favorable\nperformance over the baseline training approaches.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 08:28:30 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 04:12:07 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Cai", "Hengyi", ""], ["Chen", "Hongshen", ""], ["Song", "Yonghao", ""], ["Ding", "Zhuoye", ""], ["Bao", "Yongjun", ""], ["Yan", "Weipeng", ""], ["Zhao", "Xiaofang", ""]]}, {"id": "2009.07602", "submitter": "Jian Guan", "authors": "Jian Guan, Minlie Huang", "title": "UNION: An Unreferenced Metric for Evaluating Open-ended Story Generation", "comments": "Long paper; Accepted by EMNLP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the success of existing referenced metrics (e.g., BLEU and\nMoverScore), they correlate poorly with human judgments for open-ended text\ngeneration including story or dialog generation because of the notorious\none-to-many issue: there are many plausible outputs for the same input, which\nmay differ substantially in literal or semantics from the limited number of\ngiven references. To alleviate this issue, we propose UNION, a learnable\nunreferenced metric for evaluating open-ended story generation, which measures\nthe quality of a generated story without any reference. Built on top of BERT,\nUNION is trained to distinguish human-written stories from negative samples and\nrecover the perturbation in negative stories. We propose an approach of\nconstructing negative samples by mimicking the errors commonly observed in\nexisting NLG models, including repeated plots, conflicting logic, and\nlong-range incoherence. Experiments on two story datasets demonstrate that\nUNION is a reliable measure for evaluating the quality of generated stories,\nwhich correlates better with human judgments and is more generalizable than\nexisting state-of-the-art metrics.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 11:01:46 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Guan", "Jian", ""], ["Huang", "Minlie", ""]]}, {"id": "2009.07610", "submitter": "Alexandra Chronopoulou", "authors": "Alexandra Chronopoulou, Dario Stojanovski, Alexander Fraser", "title": "Reusing a Pretrained Language Model on Languages with Limited Corpora\n  for Unsupervised NMT", "comments": "EMNLP 2020, main conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using a language model (LM) pretrained on two languages with large\nmonolingual data in order to initialize an unsupervised neural machine\ntranslation (UNMT) system yields state-of-the-art results. When limited data is\navailable for one language, however, this method leads to poor translations. We\npresent an effective approach that reuses an LM that is pretrained only on the\nhigh-resource language. The monolingual LM is fine-tuned on both languages and\nis then used to initialize a UNMT model. To reuse the pretrained LM, we have to\nmodify its predefined vocabulary, to account for the new language. We therefore\npropose a novel vocabulary extension method. Our approach, RE-LM, outperforms a\ncompetitive cross-lingual pretraining model (XLM) in English-Macedonian (En-Mk)\nand English-Albanian (En-Sq), yielding more than +8.3 BLEU points for all four\ntranslation directions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 11:37:10 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 09:41:20 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 13:54:47 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Chronopoulou", "Alexandra", ""], ["Stojanovski", "Dario", ""], ["Fraser", "Alexander", ""]]}, {"id": "2009.07615", "submitter": "Junfan Chen", "authors": "Junfan Chen, Richong Zhang, Yongyi Mao, Jie Xu", "title": "Neural Dialogue State Tracking with Temporally Expressive Networks", "comments": "Accepted by Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue state tracking (DST) is an important part of a spoken dialogue\nsystem. Existing DST models either ignore temporal feature dependencies across\ndialogue turns or fail to explicitly model temporal state dependencies in a\ndialogue. In this work, we propose Temporally Expressive Networks (TEN) to\njointly model the two types of temporal dependencies in DST. The TEN model\nutilizes the power of recurrent networks and probabilistic graphical models.\nEvaluating on standard datasets, TEN is demonstrated to be effective in\nimproving the accuracy of turn-level-state prediction and the state\naggregation.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 11:53:00 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 07:36:07 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Chen", "Junfan", ""], ["Zhang", "Richong", ""], ["Mao", "Yongyi", ""], ["Xu", "Jie", ""]]}, {"id": "2009.07616", "submitter": "Junfan Chen", "authors": "Junfan Chen, Richong Zhang, Yongyi Mao, Jie Xu", "title": "Parallel Interactive Networks for Multi-Domain Dialogue State Generation", "comments": "Accepted by EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dependencies between system and user utterances in the same turn and\nacross different turns are not fully considered in existing multidomain\ndialogue state tracking (MDST) models. In this study, we argue that the\nincorporation of these dependencies is crucial for the design of MDST and\npropose Parallel Interactive Networks (PIN) to model these dependencies.\nSpecifically, we integrate an interactive encoder to jointly model the in-turn\ndependencies and cross-turn dependencies. The slot-level context is introduced\nto extract more expressive features for different slots. And a distributed copy\nmechanism is utilized to selectively copy words from historical system\nutterances or historical user utterances. Empirical studies demonstrated the\nsuperiority of the proposed PIN model.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 11:54:15 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 07:32:21 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 14:19:12 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Chen", "Junfan", ""], ["Zhang", "Richong", ""], ["Mao", "Yongyi", ""], ["Xu", "Jie", ""]]}, {"id": "2009.07659", "submitter": "Heiko Paulheim", "authors": "Jan Portisch, Michael Hladik, Heiko Paulheim", "title": "RDF2Vec Light -- A Lightweight Approach for Knowledge Graph Embeddings", "comments": "Accepted at International Semantic Web Conference (ISWC) 2020,\n  Posters and Demonstrations Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge graph embedding approaches represent nodes and edges of graphs as\nmathematical vectors. Current approaches focus on embedding complete knowledge\ngraphs, i.e. all nodes and edges. This leads to very high computational\nrequirements on large graphs such as DBpedia or Wikidata. However, for most\ndownstream application scenarios, only a small subset of concepts is of actual\ninterest. In this paper, we present RDF2Vec Light, a lightweight embedding\napproach based on RDF2Vec which generates vectors for only a subset of\nentities. To that end, RDF2Vec Light only traverses and processes a subgraph of\nthe knowledge graph. Our method allows the application of embeddings of very\nlarge knowledge graphs in scenarios where such embeddings were not possible\nbefore due to a significantly lower runtime and significantly reduced hardware\nrequirements.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 12:58:31 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 11:53:12 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Portisch", "Jan", ""], ["Hladik", "Michael", ""], ["Paulheim", "Heiko", ""]]}, {"id": "2009.07661", "submitter": "Kristina Gligoric", "authors": "Kristina Gligori\\'c, Ashton Anderson, Robert West", "title": "Adoption of Twitter's New Length Limit: Is 280 the New 140?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In November 2017, Twitter doubled the maximum allowed tweet length from 140\nto 280 characters, a drastic switch on one of the world's most influential\nsocial media platforms. In the first long-term study of how the new length\nlimit was adopted by Twitter users, we ask: Does the effect of the new length\nlimit resemble that of the old one? Or did the doubling of the limit\nfundamentally change how Twitter is shaped by the limited length of posted\ncontent? By analyzing Twitter's publicly available 1% sample over a period of\naround 3 years, we find that, when the length limit was raised from 140 to 280\ncharacters, the prevalence of tweets around 140 characters dropped immediately,\nwhile the prevalence of tweets around 280 characters rose steadily for about 6\nmonths. Despite this rise, tweets approaching the length limit have been far\nless frequent after than before the switch. We find widely different adoption\nrates across languages and client-device types. The prevalence of tweets around\n140 characters before the switch in a given language is strongly correlated\nwith the prevalence of tweets around 280 characters after the switch in the\nsame language, and very long tweets are vastly more popular on Web clients than\non mobile clients. Moreover, tweets of around 280 characters after the switch\nare syntactically and semantically similar to tweets of around 140 characters\nbefore the switch, manifesting patterns of message squeezing in both cases.\nTaken together, these findings suggest that the new 280-character limit\nconstitutes a new, less intrusive version of the old 140-character limit. The\nlength limit remains an important factor that should be considered in all\nstudies using Twitter data.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 13:01:05 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Gligori\u0107", "Kristina", ""], ["Anderson", "Ashton", ""], ["West", "Robert", ""]]}, {"id": "2009.07690", "submitter": "Li Zhang", "authors": "Li Zhang, Qing Lyu, Chris Callison-Burch", "title": "Reasoning about Goals, Steps, and Temporal Ordering with WikiHow", "comments": "In EMNLP 2020", "journal-ref": "Proceedings of the 2020 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP) (2020) 4630-4639", "doi": "10.18653/v1/2020.emnlp-main.374", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a suite of reasoning tasks on two types of relations between\nprocedural events: goal-step relations (\"learn poses\" is a step in the larger\ngoal of \"doing yoga\") and step-step temporal relations (\"buy a yoga mat\"\ntypically precedes \"learn poses\"). We introduce a dataset targeting these two\nrelations based on wikiHow, a website of instructional how-to articles. Our\nhuman-validated test set serves as a reliable benchmark for commonsense\ninference, with a gap of about 10% to 20% between the performance of\nstate-of-the-art transformer models and human performance. Our\nautomatically-generated training set allows models to effectively transfer to\nout-of-domain tasks requiring knowledge of procedural events, with greatly\nimproved performances on SWAG, Snips, and the Story Cloze Test in zero- and\nfew-shot settings.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 13:50:09 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 15:38:45 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Zhang", "Li", ""], ["Lyu", "Qing", ""], ["Callison-Burch", "Chris", ""]]}, {"id": "2009.07698", "submitter": "Reuben Tan", "authors": "Reuben Tan, Bryan A. Plummer, Kate Saenko", "title": "Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News", "comments": "Accepted at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale dissemination of disinformation online intended to mislead or\ndeceive the general population is a major societal problem. Rapid progression\nin image, video, and natural language generative models has only exacerbated\nthis situation and intensified our need for an effective defense mechanism.\nWhile existing approaches have been proposed to defend against neural fake\nnews, they are generally constrained to the very limited setting where articles\nonly have text and metadata such as the title and authors. In this paper, we\nintroduce the more realistic and challenging task of defending against\nmachine-generated news that also includes images and captions. To identify the\npossible weaknesses that adversaries can exploit, we create a NeuralNews\ndataset composed of 4 different types of generated articles as well as conduct\na series of human user study experiments based on this dataset. In addition to\nthe valuable insights gleaned from our user study experiments, we provide a\nrelatively effective approach based on detecting visual-semantic\ninconsistencies, which will serve as an effective first line of defense and a\nuseful reference for future work in defending against machine-generated\ndisinformation.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 14:13:15 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 01:17:19 GMT"}, {"version": "v3", "created": "Tue, 22 Sep 2020 21:37:02 GMT"}, {"version": "v4", "created": "Thu, 24 Sep 2020 21:10:15 GMT"}, {"version": "v5", "created": "Wed, 21 Oct 2020 15:16:20 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Tan", "Reuben", ""], ["Plummer", "Bryan A.", ""], ["Saenko", "Kate", ""]]}, {"id": "2009.07715", "submitter": "Diego Moussallem", "authors": "Diego Moussallem", "title": "Knowledge Graphs for Multilingual Language Translation and Generation", "comments": null, "journal-ref": null, "doi": "10.17619/UNIPB/1-980", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Natural Language Processing (NLP) community has recently seen outstanding\nprogress, catalysed by the release of different Neural Network (NN)\narchitectures. Neural-based approaches have proven effective by significantly\nincreasing the output quality of a large number of automated solutions for NLP\ntasks (Belinkov and Glass, 2019). Despite these notable advancements, dealing\nwith entities still poses a difficult challenge as they are rarely seen in\ntraining data. Entities can be classified into two groups, i.e., proper nouns\nand common nouns. Proper nouns are also known as Named Entities (NE) and\ncorrespond to the name of people, organizations, or locations, e.g., John, WHO,\nor Canada. Common nouns describe classes of objects, e.g., spoon or cancer.\nBoth types of entities can be found in a Knowledge Graph (KG). Recent work has\nsuccessfully exploited the contribution of KGs in NLP tasks, such as Natural\nLanguage Inference (NLI) (KM et al.,2018) and Question Answering (QA) (Sorokin\nand Gurevych, 2018). Only a few works had exploited the benefits of KGs in\nNeural Machine Translation (NMT) when the work presented herein began.\nAdditionally, few works had studied the contribution of KGs to Natural Language\nGeneration (NLG) tasks. Moreover, the multilinguality also remained an open\nresearch area in these respective tasks (Young et al., 2018). In this thesis,\nwe focus on the use of KGs for machine translation and the generation of texts\nto deal with the problems caused by entities and consequently enhance the\nquality of automatically generated texts.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 14:36:41 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Moussallem", "Diego", ""]]}, {"id": "2009.07726", "submitter": "Nandana Mihindukulasooriya", "authors": "Nandana Mihindukulasooriya, Gaetano Rossiello, Pavan Kapanipathi,\n  Ibrahim Abdelaziz, Srinivas Ravishankar, Mo Yu, Alfio Gliozzo, Salim Roukos\n  and Alexander Gray", "title": "Leveraging Semantic Parsing for Relation Linking over Knowledge Bases", "comments": "Accepted at the 19th International Semantic Web Conference (ISWC\n  2020)", "journal-ref": null, "doi": "10.1007/978-3-030-62419-4_23", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledgebase question answering systems are heavily dependent on relation\nextraction and linking modules. However, the task of extracting and linking\nrelations from text to knowledgebases faces two primary challenges; the\nambiguity of natural language and lack of training data. To overcome these\nchallenges, we present SLING, a relation linking framework which leverages\nsemantic parsing using Abstract Meaning Representation (AMR) and distant\nsupervision. SLING integrates multiple relation linking approaches that capture\ncomplementary signals such as linguistic cues, rich semantic representation,\nand information from the knowledgebase. The experiments on relation linking\nusing three KBQA datasets; QALD-7, QALD-9, and LC-QuAD 1.0 demonstrate that the\nproposed approach achieves state-of-the-art performance on all benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 14:56:11 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Mihindukulasooriya", "Nandana", ""], ["Rossiello", "Gaetano", ""], ["Kapanipathi", "Pavan", ""], ["Abdelaziz", "Ibrahim", ""], ["Ravishankar", "Srinivas", ""], ["Yu", "Mo", ""], ["Gliozzo", "Alfio", ""], ["Roukos", "Salim", ""], ["Gray", "Alexander", ""]]}, {"id": "2009.07728", "submitter": "Diego Moussallem", "authors": "Diego Moussallem and Dwaraknath Gnaneshwar and Thiago Castro Ferreira\n  and Axel-Cyrille Ngonga Ngomo", "title": "NABU $\\mathrm{-}$ Multilingual Graph-based Neural RDF Verbalizer", "comments": "International Semantic Web Conference (ISWC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The RDF-to-text task has recently gained substantial attention due to\ncontinuous growth of Linked Data. In contrast to traditional pipeline models,\nrecent studies have focused on neural models, which are now able to convert a\nset of RDF triples into text in an end-to-end style with promising results.\nHowever, English is the only language widely targeted. We address this research\ngap by presenting NABU, a multilingual graph-based neural model that verbalizes\nRDF data to German, Russian, and English. NABU is based on an encoder-decoder\narchitecture, uses an encoder inspired by Graph Attention Networks and a\nTransformer as decoder. Our approach relies on the fact that knowledge graphs\nare language-agnostic and they hence can be used to generate multilingual text.\nWe evaluate NABU in monolingual and multilingual settings on standard\nbenchmarking WebNLG datasets. Our results show that NABU outperforms\nstate-of-the-art approaches on English with 66.21 BLEU, and achieves consistent\nresults across all languages on the multilingual scenario with 56.04 BLEU.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 14:59:06 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 14:14:05 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Moussallem", "Diego", ""], ["Gnaneshwar", "Dwaraknath", ""], ["Ferreira", "Thiago Castro", ""], ["Ngomo", "Axel-Cyrille Ngonga", ""]]}, {"id": "2009.07740", "submitter": "Juan Cruz-Benito", "authors": "Juan Cruz-Benito, Sanjay Vishwakarma, Francisco Martin-Fernandez,\n  Ismael Faro", "title": "Automated Source Code Generation and Auto-completion Using Deep\n  Learning: Comparing and Discussing Current Language-Model-Related Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the use of deep learning in language models gained much\nattention. Some research projects claim that they can generate text that can be\ninterpreted as human-writing, enabling new possibilities in many application\nareas. Among the different areas related to language processing, one of the\nmost notable in applying this type of modeling is programming languages. For\nyears, the Machine Learning community has been researching this software\nengineering area, pursuing goals like applying different approaches to\nauto-complete, generate, fix, or evaluate code programmed by humans.\nConsidering the increasing popularity of the Deep-Learning-enabled language\nmodels approach, we detected a lack of empirical papers that compare different\ndeep learning architectures to create and use language models based on\nprogramming code. This paper compares different neural network architectures\nlike AWD-LSTMs, AWD-QRNNs, and Transformer while using transfer learning and\ndifferent tokenizations to see how they behave in building language models\nusing a Python dataset for code generation and filling mask tasks. Considering\nthe results, we discuss each approach's different strengths and weaknesses and\nwhat gaps we find to evaluate the language models or apply them in a real\nprogramming context.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 15:17:04 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 15:37:47 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 10:52:51 GMT"}, {"version": "v4", "created": "Tue, 12 Jan 2021 10:54:20 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Cruz-Benito", "Juan", ""], ["Vishwakarma", "Sanjay", ""], ["Martin-Fernandez", "Francisco", ""], ["Faro", "Ismael", ""]]}, {"id": "2009.07755", "submitter": "Guillaume Salha", "authors": "Elena V. Epure and Guillaume Salha and Romain Hennequin", "title": "Multilingual Music Genre Embeddings for Effective Cross-Lingual Music\n  Item Annotation", "comments": "21st International Society for Music Information Retrieval Conference\n  (ISMIR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Annotating music items with music genres is crucial for music recommendation\nand information retrieval, yet challenging given that music genres are\nsubjective concepts. Recently, in order to explicitly consider this\nsubjectivity, the annotation of music items was modeled as a translation task:\npredict for a music item its music genres within a target vocabulary or\ntaxonomy (tag system) from a set of music genre tags originating from other tag\nsystems. However, without a parallel corpus, previous solutions could not\nhandle tag systems in other languages, being limited to the English-language\nonly. Here, by learning multilingual music genre embeddings, we enable\ncross-lingual music genre translation without relying on a parallel corpus.\nFirst, we apply compositionality functions on pre-trained word embeddings to\nrepresent multi-word tags.Second, we adapt the tag representations to the music\ndomain by leveraging multilingual music genres graphs with a modified\nretrofitting algorithm. Experiments show that our method: 1) is effective in\ntranslating music genres across tag systems in multiple languages (English,\nFrench and Spanish); 2) outperforms the previous baseline in an\nEnglish-language multi-source translation task. We publicly release the new\nmultilingual data and code.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 15:39:04 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Epure", "Elena V.", ""], ["Salha", "Guillaume", ""], ["Hennequin", "Romain", ""]]}, {"id": "2009.07758", "submitter": "Aditya Kalyanpur", "authors": "Nasrin Mostafazadeh, Aditya Kalyanpur, Lori Moon, David Buchanan,\n  Lauren Berkowitz, Or Biran, Jennifer Chu-Carroll", "title": "GLUCOSE: GeneraLized and COntextualized Story Explanations", "comments": "EMNLP 2020 Camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When humans read or listen, they make implicit commonsense inferences that\nframe their understanding of what happened and why. As a step toward AI systems\nthat can build similar mental models, we introduce GLUCOSE, a large-scale\ndataset of implicit commonsense causal knowledge, encoded as causal\nmini-theories about the world, each grounded in a narrative context. To\nconstruct GLUCOSE, we drew on cognitive psychology to identify ten dimensions\nof causal explanation, focusing on events, states, motivations, and emotions.\nEach GLUCOSE entry includes a story-specific causal statement paired with an\ninference rule generalized from the statement. This paper details two concrete\ncontributions. First, we present our platform for effectively crowdsourcing\nGLUCOSE data at scale, which uses semi-structured templates to elicit causal\nexplanations. Using this platform, we collected a total of ~670K specific\nstatements and general rules that capture implicit commonsense knowledge about\neveryday situations. Second, we show that existing knowledge resources and\npretrained language models do not include or readily predict GLUCOSE's rich\ninferential content. However, when state-of-the-art neural models are trained\non this knowledge, they can start to make commonsense inferences on unseen\nstories that match humans' mental models.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 15:41:21 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 18:10:39 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Mostafazadeh", "Nasrin", ""], ["Kalyanpur", "Aditya", ""], ["Moon", "Lori", ""], ["Buchanan", "David", ""], ["Berkowitz", "Lauren", ""], ["Biran", "Or", ""], ["Chu-Carroll", "Jennifer", ""]]}, {"id": "2009.07780", "submitter": "Sicheng Zhou", "authors": "Yadan Fan, Sicheng Zhou, Yifan Li, Rui Zhang", "title": "Deep Learning Approaches for Extracting Adverse Events and Indications\n  of Dietary Supplements from Clinical Text", "comments": null, "journal-ref": "J Am Med Inform Assoc. 2020 Nov 5:ocaa218. PMID: 33150942", "doi": "10.1093/jamia/ocaa218", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of our work is to demonstrate the feasibility of utilizing deep\nlearning models to extract safety signals related to the use of dietary\nsupplements (DS) in clinical text. Two tasks were performed in this study. For\nthe named entity recognition (NER) task, Bi-LSTM-CRF (Bidirectional\nLong-Short-Term-Memory Conditional Random Fields) and BERT (Bidirectional\nEncoder Representations from Transformers) models were trained and compared\nwith CRF model as a baseline to recognize the named entities of DS and Events\nfrom clinical notes. In the relation extraction (RE) task, two deep learning\nmodels, including attention-based Bi-LSTM and CNN (Convolutional Neural\nNetwork), and a random forest model were trained to extract the relations\nbetween DS and Events, which were categorized into three classes: positive\n(i.e., indication), negative (i.e., adverse events), and not related. The best\nperformed NER and RE models were further applied on clinical notes mentioning\n88 DS for discovering DS adverse events and indications, which were compared\nwith a DS knowledge base. For the NER task, deep learning models achieved a\nbetter performance than CRF, with F1 scores above 0.860. The attention-based\nBi-LSTM model performed the best in the relation extraction task, with the F1\nscore of 0.893. When comparing DS event pairs generated by the deep learning\nmodels with the knowledge base for DS and Event, we found both known and\nunknown pairs. Deep learning models can detect adverse events and indication of\nDS in clinical notes, which hold great potential for monitoring the safety of\nDS use.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 16:18:04 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 06:00:02 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Fan", "Yadan", ""], ["Zhou", "Sicheng", ""], ["Li", "Yifan", ""], ["Zhang", "Rui", ""]]}, {"id": "2009.07783", "submitter": "Shuhei Kurita", "authors": "Shuhei Kurita and Kyunghyun Cho", "title": "Generative Language-Grounded Policy in Vision-and-Language Navigation\n  with Bayes' Rule", "comments": "13 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision-and-language navigation (VLN) is a task in which an agent is embodied\nin a realistic 3D environment and follows an instruction to reach the goal\nnode. While most of the previous studies have built and investigated a\ndiscriminative approach, we notice that there are in fact two possible\napproaches to building such a VLN agent: discriminative \\textit{and}\ngenerative. In this paper, we design and investigate a generative\nlanguage-grounded policy which uses a language model to compute the\ndistribution over all possible instructions i.e. all possible sequences of\nvocabulary tokens given action and the transition history. In experiments, we\nshow that the proposed generative approach outperforms the discriminative\napproach in the Room-2-Room (R2R) and Room-4-Room (R4R) datasets, especially in\nthe unseen environments. We further show that the combination of the generative\nand discriminative policies achieves close to the state-of-the art results in\nthe R2R dataset, demonstrating that the generative and discriminative policies\ncapture the different aspects of VLN.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 16:23:17 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 18:57:09 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 17:16:49 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Kurita", "Shuhei", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "2009.07806", "submitter": "Dustin Wright", "authors": "Dustin Wright and Isabelle Augenstein", "title": "Transformer Based Multi-Source Domain Adaptation", "comments": "12 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practical machine learning settings, the data on which a model must make\npredictions often come from a different distribution than the data it was\ntrained on. Here, we investigate the problem of unsupervised multi-source\ndomain adaptation, where a model is trained on labelled data from multiple\nsource domains and must make predictions on a domain for which no labelled data\nhas been seen. Prior work with CNNs and RNNs has demonstrated the benefit of\nmixture of experts, where the predictions of multiple domain expert classifiers\nare combined; as well as domain adversarial training, to induce a domain\nagnostic representation space. Inspired by this, we investigate how such\nmethods can be effectively applied to large pretrained transformer models. We\nfind that domain adversarial training has an effect on the learned\nrepresentations of these models while having little effect on their\nperformance, suggesting that large transformer-based models are already\nrelatively robust across domains. Additionally, we show that mixture of experts\nleads to significant performance improvements by comparing several variants of\nmixing functions, including one novel mixture based on attention. Finally, we\ndemonstrate that the predictions of large pretrained transformer based domain\nexperts are highly homogenous, making it challenging to learn effective\nfunctions for mixing their predictions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 16:56:23 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Wright", "Dustin", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "2009.07810", "submitter": "Tara Safavi", "authors": "Tara Safavi, Danai Koutra", "title": "CoDEx: A Comprehensive Knowledge Graph Completion Benchmark", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present CoDEx, a set of knowledge graph completion datasets extracted from\nWikidata and Wikipedia that improve upon existing knowledge graph completion\nbenchmarks in scope and level of difficulty. In terms of scope, CoDEx comprises\nthree knowledge graphs varying in size and structure, multilingual descriptions\nof entities and relations, and tens of thousands of hard negative triples that\nare plausible but verified to be false. To characterize CoDEx, we contribute\nthorough empirical analyses and benchmarking experiments. First, we analyze\neach CoDEx dataset in terms of logical relation patterns. Next, we report\nbaseline link prediction and triple classification results on CoDEx for five\nextensively tuned embedding models. Finally, we differentiate CoDEx from the\npopular FB15K-237 knowledge graph completion dataset by showing that CoDEx\ncovers more diverse and interpretable content, and is a more difficult link\nprediction benchmark. Data, code, and pretrained models are available at\nhttps://bit.ly/2EPbrJs.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 17:08:23 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 09:10:10 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Safavi", "Tara", ""], ["Koutra", "Danai", ""]]}, {"id": "2009.07839", "submitter": "Richard Yuanzhe Pang", "authors": "Richard Yuanzhe Pang, He He", "title": "Text Generation by Learning from Demonstrations", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current approaches to text generation largely rely on autoregressive models\nand maximum likelihood estimation. This paradigm leads to (i) diverse but\nlow-quality samples due to mismatched learning objective and evaluation metric\n(likelihood vs. quality) and (ii) exposure bias due to mismatched history\ndistributions (gold vs. model-generated). To alleviate these problems, we frame\ntext generation as an offline reinforcement learning (RL) problem with expert\ndemonstrations (i.e., the reference), where the goal is to maximize quality\ngiven model-generated histories. We propose GOLD (generation by off-policy\nlearning from demonstrations): an easy-to-optimize algorithm that learns from\nthe demonstrations by importance weighting. Intuitively, GOLD upweights\nconfident tokens and downweights unconfident ones in the reference during\ntraining, avoiding optimization issues faced by prior RL approaches that rely\non online data collection. According to both automatic and human evaluation,\nmodels trained by GOLD outperform those trained by MLE and policy gradient on\nsummarization, question generation, and machine translation. Further, our\nmodels are less sensitive to decoding algorithms and alleviate exposure bias.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 17:58:37 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 03:43:28 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Pang", "Richard Yuanzhe", ""], ["He", "He", ""]]}, {"id": "2009.07936", "submitter": "Aurelie Herbelot", "authors": "Katrin Erk, Aurelie Herbelot", "title": "How to marry a star: probabilistic constraints for meaning in context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we derive a notion of 'word meaning in context' which accounts\nfor the wide range of lexical shifts and ambiguities observed in utterance\ninterpretation. We characterize the lexical comprehension process as a\ncombination of cognitive semantics and Discourse Representation Theory,\nformalized as a 'situation description system': a probabilistic model which\ntakes utterance understanding to be the mental process of describing one or\nmore situations that would account for an observed utterance. Our model uses\ninsights from different types of generative models to capture the interplay of\nlocal and global contexts and their joint influence upon the lexical\nrepresentation of sentence constituents. We implement the system using a\ndirected graphical model, and apply it to examples containing various\ncontextualisation phenomena.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 21:11:23 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 15:47:51 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Erk", "Katrin", ""], ["Herbelot", "Aurelie", ""]]}, {"id": "2009.07938", "submitter": "Zijun Cui", "authors": "Zijun Cui, Pavan Kapanipathi, Kartik Talamadupula, Tian Gao, Qiang Ji", "title": "Type-augmented Relation Prediction in Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs (KGs) are of great importance to many real world\napplications, but they generally suffer from incomplete information in the form\nof missing relations between entities. Knowledge graph completion (also known\nas relation prediction) is the task of inferring missing facts given existing\nones. Most of the existing work is proposed by maximizing the likelihood of\nobserved instance-level triples. Not much attention, however, is paid to the\nontological information, such as type information of entities and relations. In\nthis work, we propose a type-augmented relation prediction (TaRP) method, where\nwe apply both the type information and instance-level information for relation\nprediction. In particular, type information and instance-level information are\nencoded as prior probabilities and likelihoods of relations respectively, and\nare combined by following Bayes' rule. Our proposed TaRP method achieves\nsignificantly better performance than state-of-the-art methods on four\nbenchmark datasets: FB15K, FB15K-237, YAGO26K-906, and DB111K-174. In addition,\nwe show that TaRP achieves significantly improved data efficiency. More\nimportantly, the type information extracted from a specific dataset can\ngeneralize well to other datasets through the proposed TaRP model.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 21:14:18 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 01:59:56 GMT"}, {"version": "v3", "created": "Fri, 26 Feb 2021 22:57:09 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Cui", "Zijun", ""], ["Kapanipathi", "Pavan", ""], ["Talamadupula", "Kartik", ""], ["Gao", "Tian", ""], ["Ji", "Qiang", ""]]}, {"id": "2009.07964", "submitter": "Zhijing Jin", "authors": "Xiaoyu Xing, Zhijing Jin, Di Jin, Bingning Wang, Qi Zhang, and\n  Xuanjing Huang", "title": "Tasty Burgers, Soggy Fries: Probing Aspect Robustness in Aspect-Based\n  Sentiment Analysis", "comments": "EMNLP 2020, long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Aspect-based sentiment analysis (ABSA) aims to predict the sentiment towards\na specific aspect in the text. However, existing ABSA test sets cannot be used\nto probe whether a model can distinguish the sentiment of the target aspect\nfrom the non-target aspects. To solve this problem, we develop a simple but\neffective approach to enrich ABSA test sets. Specifically, we generate new\nexamples to disentangle the confounding sentiments of the non-target aspects\nfrom the target aspect's sentiment. Based on the SemEval 2014 dataset, we\nconstruct the Aspect Robustness Test Set (ARTS) as a comprehensive probe of the\naspect robustness of ABSA models. Over 92% data of ARTS show high fluency and\ndesired sentiment on all aspects by human evaluation. Using ARTS, we analyze\nthe robustness of nine ABSA models, and observe, surprisingly, that their\naccuracy drops by up to 69.73%. We explore several ways to improve aspect\nrobustness, and find that adversarial training can improve models' performance\non ARTS by up to 32.85%. Our code and new test set are available at\nhttps://github.com/zhijing-jin/ARTS_TestSet\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 22:38:18 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 05:36:10 GMT"}, {"version": "v3", "created": "Sun, 4 Oct 2020 15:35:36 GMT"}, {"version": "v4", "created": "Wed, 28 Oct 2020 08:19:36 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Xing", "Xiaoyu", ""], ["Jin", "Zhijing", ""], ["Jin", "Di", ""], ["Wang", "Bingning", ""], ["Zhang", "Qi", ""], ["Huang", "Xuanjing", ""]]}, {"id": "2009.07968", "submitter": "Giovanni Campagna", "authors": "Giovanni Campagna, Sina J. Semnani, Ryan Kearns, Lucas Jun Koba Sato,\n  Silei Xu, Monica S. Lam", "title": "SKIM : Few-Shot Conversational Semantic Parsers with Formal Dialogue\n  Contexts", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The traditional dialogue state tracking (DST) task tracks the dialogue state\ngiven the past history of user and agent utterances. This paper proposes to\nreplace the utterances before the current turn with a formal representation,\nwhich is used as the context in a semantic parser mapping the current user\nutterance to its formal meaning. In addition, we propose TOC (Task-Oriented\nContext), a formal dialogue state representation. This approach eliminates the\nneed to parse a long history of natural language utterances; however, it adds\ncomplexity to the dialogue annotations. We propose Skim, a contextual semantic\nparser, trained with a sample-efficient training strategy: (1) a novel abstract\ndialogue state machine to synthesize training sets with TOC annotations; (2)\ndata augmentation with automatic paraphrasing, (3) few-shot training, and (4)\nself-training. This paper also presents MultiWOZ 2.4, which consists of the\nfull test set and a partial validation set of MultiWOZ 2.1, reannotated with\nthe TOC representation. Skim achieves 78% turn-by-turn exact match accuracy and\n85% slot accuracy, while our annotation effort amounts to only 2% of the\ntraining data used in MultiWOZ 2.1. The MultiWOZ 2.4 dataset will be released\nupon publication.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 22:52:46 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 21:46:08 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Campagna", "Giovanni", ""], ["Semnani", "Sina J.", ""], ["Kearns", "Ryan", ""], ["Sato", "Lucas Jun Koba", ""], ["Xu", "Silei", ""], ["Lam", "Monica S.", ""]]}, {"id": "2009.08018", "submitter": "Xiyan Fu", "authors": "Xiyan Fu and Jun Wang and Zhenglu Yang", "title": "Multi-modal Summarization for Video-containing Documents", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Summarization of multimedia data becomes increasingly significant as it is\nthe basis for many real-world applications, such as question answering, Web\nsearch, and so forth. Most existing multi-modal summarization works however\nhave used visual complementary features extracted from images rather than\nvideos, thereby losing abundant information. Hence, we propose a novel\nmulti-modal summarization task to summarize from a document and its associated\nvideo. In this work, we also build a baseline general model with effective\nstrategies, i.e., bi-hop attention and improved late fusion mechanisms to\nbridge the gap between different modalities, and a bi-stream summarization\nstrategy to employ text and video summarization simultaneously. Comprehensive\nexperiments show that the proposed model is beneficial for multi-modal\nsummarization and superior to existing methods. Moreover, we collect a novel\ndataset and it provides a new resource for future study that results from\ndocuments and videos.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 02:13:14 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Fu", "Xiyan", ""], ["Wang", "Jun", ""], ["Yang", "Zhenglu", ""]]}, {"id": "2009.08034", "submitter": "Ye Lin", "authors": "Ye Lin, Yanyang Li, Tengbo Liu, Tong Xiao, Tongran Liu and Jingbo Zhu", "title": "Towards Fully 8-bit Integer Inference for the Transformer Model", "comments": "accepted by IJCAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  8-bit integer inference, as a promising direction in reducing both the\nlatency and storage of deep neural networks, has made great progress recently.\nOn the other hand, previous systems still rely on 32-bit floating point for\ncertain functions in complex models (e.g., Softmax in Transformer), and make\nheavy use of quantization and de-quantization. In this work, we show that after\na principled modification on the Transformer architecture, dubbed Integer\nTransformer, an (almost) fully 8-bit integer inference algorithm Scale\nPropagation could be derived. De-quantization is adopted when necessary, which\nmakes the network more efficient. Our experiments on WMT16 En<->Ro, WMT14\nEn<->De and En->Fr translation tasks as well as the WikiText-103 language\nmodelling task show that the fully 8-bit Transformer system achieves comparable\nperformance with the floating point baseline but requires nearly 4x less memory\nfootprint.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 03:09:10 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 06:12:27 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Lin", "Ye", ""], ["Li", "Yanyang", ""], ["Liu", "Tengbo", ""], ["Xiao", "Tong", ""], ["Liu", "Tongran", ""], ["Zhu", "Jingbo", ""]]}, {"id": "2009.08043", "submitter": "Seonhoon Kim", "authors": "Seonhoon Kim, Seohyeong Jeong, Eunbyul Kim, Inho Kang, Nojun Kwak", "title": "Self-supervised pre-training and contrastive representation learning for\n  multiple-choice video QA", "comments": "Accepted at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video Question Answering (Video QA) requires fine-grained understanding of\nboth video and language modalities to answer the given questions. In this\npaper, we propose novel training schemes for multiple-choice video question\nanswering with a self-supervised pre-training stage and a supervised\ncontrastive learning in the main stage as an auxiliary learning. In the\nself-supervised pre-training stage, we transform the original problem format of\npredicting the correct answer into the one that predicts the relevant question\nto provide a model with broader contextual inputs without any further dataset\nor annotation. For contrastive learning in the main stage, we add a masking\nnoise to the input corresponding to the ground-truth answer, and consider the\noriginal input of the ground-truth answer as a positive sample, while treating\nthe rest as negative samples. By mapping the positive sample closer to the\nmasked input, we show that the model performance is improved. We further employ\nlocally aligned attention to focus more effectively on the video frames that\nare particularly relevant to the given corresponding subtitle sentences. We\nevaluate our proposed model on highly competitive benchmark datasets related to\nmultiple-choice video QA: TVQA, TVQA+, and DramaQA. Experimental results show\nthat our model achieves state-of-the-art performance on all datasets. We also\nvalidate our approaches through further analyses.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 03:37:37 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 11:32:24 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Kim", "Seonhoon", ""], ["Jeong", "Seohyeong", ""], ["Kim", "Eunbyul", ""], ["Kang", "Inho", ""], ["Kwak", "Nojun", ""]]}, {"id": "2009.08065", "submitter": "Zhenglun Kong", "authors": "Bingbing Li, Zhenglun Kong, Tianyun Zhang, Ji Li, Zhengang Li, Hang\n  Liu, Caiwen Ding", "title": "Efficient Transformer-based Large Scale Language Representations using\n  Hardware-friendly Block Structured Pruning", "comments": "Accepted to Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained large-scale language models have increasingly demonstrated high\naccuracy on many natural language processing (NLP) tasks. However, the limited\nweight storage and computational speed on hardware platforms have impeded the\npopularity of pre-trained models, especially in the era of edge computing. In\nthis work, we propose an efficient transformer-based large-scale language\nrepresentation using hardware-friendly block structure pruning. We incorporate\nthe reweighted group Lasso into block-structured pruning for optimization.\nBesides the significantly reduced weight storage and computation, the proposed\napproach achieves high compression rates. Experimental results on different\nmodels (BERT, RoBERTa, and DistilBERT) on the General Language Understanding\nEvaluation (GLUE) benchmark tasks show that we achieve up to 5.0x with zero or\nminor accuracy degradation on certain task(s). Our proposed method is also\northogonal to existing compact pre-trained language models such as DistilBERT\nusing knowledge distillation, since a further 1.79x average compression rate\ncan be achieved on top of DistilBERT with zero or minor accuracy degradation.\nIt is suitable to deploy the final compressed model on resource-constrained\nedge devices.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 04:45:47 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 20:09:04 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 19:14:32 GMT"}, {"version": "v4", "created": "Mon, 16 Nov 2020 22:13:31 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Li", "Bingbing", ""], ["Kong", "Zhenglun", ""], ["Zhang", "Tianyun", ""], ["Li", "Ji", ""], ["Li", "Zhengang", ""], ["Liu", "Hang", ""], ["Ding", "Caiwen", ""]]}, {"id": "2009.08070", "submitter": "Yi Lu", "authors": "Shayne Longpre, Yi Lu, Christopher DuBois", "title": "On the Transferability of Minimal Prediction Preserving Inputs in\n  Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work (Feng et al., 2018) establishes the presence of short,\nuninterpretable input fragments that yield high confidence and accuracy in\nneural models. We refer to these as Minimal Prediction Preserving Inputs\n(MPPIs). In the context of question answering, we investigate competing\nhypotheses for the existence of MPPIs, including poor posterior calibration of\nneural models, lack of pretraining, and \"dataset bias\" (where a model learns to\nattend to spurious, non-generalizable cues in the training data). We discover a\nperplexing invariance of MPPIs to random training seed, model architecture,\npretraining, and training domain. MPPIs demonstrate remarkable transferability\nacross domains achieving significantly higher performance than comparably short\nqueries. Additionally, penalizing over-confidence on MPPIs fails to improve\neither generalization or adversarial robustness. These results suggest the\ninterpretability of MPPIs is insufficient to characterize generalization\ncapacity of these models. We hope this focused investigation encourages more\nsystematic analysis of model behavior outside of the human interpretable\ndistribution of examples.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 04:58:39 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 02:55:51 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Longpre", "Shayne", ""], ["Lu", "Yi", ""], ["DuBois", "Christopher", ""]]}, {"id": "2009.08088", "submitter": "Zhen Yang", "authors": "Zhen Yang, Bojie Hu, Ambyera Han, Shen Huang and Qi Ju", "title": "Code-switching pre-training for neural machine translation", "comments": "10 pages, EMNLP2020 main conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new pre-training method, called Code-Switching\nPre-training (CSP for short) for Neural Machine Translation (NMT). Unlike\ntraditional pre-training method which randomly masks some fragments of the\ninput sentence, the proposed CSP randomly replaces some words in the source\nsentence with their translation words in the target language. Specifically, we\nfirstly perform lexicon induction with unsupervised word embedding mapping\nbetween the source and target languages, and then randomly replace some words\nin the input sentence with their translation words according to the extracted\ntranslation lexicons. CSP adopts the encoder-decoder framework: its encoder\ntakes the code-mixed sentence as input, and its decoder predicts the replaced\nfragment of the input sentence. In this way, CSP is able to pre-train the NMT\nmodel by explicitly making the most of the cross-lingual alignment information\nextracted from the source and target monolingual corpus. Additionally, we\nrelieve the pretrain-finetune discrepancy caused by the artificial symbols like\n[mask]. To verify the effectiveness of the proposed method, we conduct\nextensive experiments on unsupervised and supervised NMT. Experimental results\nshow that CSP achieves significant improvements over baselines without\npre-training or with other pre-training methods.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 06:10:07 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Yang", "Zhen", ""], ["Hu", "Bojie", ""], ["Han", "Ambyera", ""], ["Huang", "Shen", ""], ["Ju", "Qi", ""]]}, {"id": "2009.08100", "submitter": "Kunwoo Park", "authors": "Kunwoo Park, Haewoon Kwak, Jisun An, and Sanjay Chawla", "title": "How-to Present News on Social Media: A Causal Analysis of Editing News\n  Headlines for Boosting User Engagement", "comments": "ICWSM'21 full paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To reach a broader audience and optimize traffic toward news articles, media\noutlets commonly run social media accounts and share their content with a short\ntext summary. Despite its importance of writing a compelling message in sharing\narticles, the research community does not own a sufficient understanding of\nwhat kinds of editing strategies effectively promote audience engagement. In\nthis study, we aim to fill the gap by analyzing media outlets' current\npractices using a data-driven approach. We first build a parallel corpus of\noriginal news articles and their corresponding tweets that eight media outlets\nshared. Then, we explore how those media edited tweets against original\nheadlines and the effects of such changes. To estimate the effects of editing\nnews headlines for social media sharing in audience engagement, we present a\nsystematic analysis that incorporates a causal inference technique with deep\nlearning; using propensity score matching, it allows for estimating potential\n(dis-)advantages of an editing style compared to counterfactual cases where a\nsimilar news article is shared with a different style. According to the\nanalyses of various editing styles, we report common and differing effects of\nthe styles across the outlets. To understand the effects of various editing\nstyles, media outlets could apply our easy-to-use tool by themselves.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 06:39:49 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 01:52:10 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Park", "Kunwoo", ""], ["Kwak", "Haewoon", ""], ["An", "Jisun", ""], ["Chawla", "Sanjay", ""]]}, {"id": "2009.08114", "submitter": "Mariona Coll Ardanuy", "authors": "Mariona Coll Ardanuy, Kasra Hosseini, Katherine McDonough, Amrey\n  Krause, Daniel van Strien and Federico Nanni", "title": "A Deep Learning Approach to Geographical Candidate Selection through\n  Toponym Matching", "comments": "10 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recognizing toponyms and resolving them to their real-world referents is\nrequired for providing advanced semantic access to textual data. This process\nis often hindered by the high degree of variation in toponyms. Candidate\nselection is the task of identifying the potential entities that can be\nreferred to by a toponym previously recognized. While it has traditionally\nreceived little attention in the research community, it has been shown that\ncandidate selection has a significant impact on downstream tasks (i.e. entity\nresolution), especially in noisy or non-standard text. In this paper, we\nintroduce a flexible deep learning method for candidate selection through\ntoponym matching, using state-of-the-art neural network architectures. We\nperform an intrinsic toponym matching evaluation based on several new realistic\ndatasets, which cover various challenging scenarios (cross-lingual and regional\nvariations, as well as OCR errors). We report its performance on candidate\nselection in the context of the downstream task of toponym resolution, both on\nexisting datasets and on a new manually-annotated resource of\nnineteenth-century English OCR'd text.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 07:24:56 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 14:24:12 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Ardanuy", "Mariona Coll", ""], ["Hosseini", "Kasra", ""], ["McDonough", "Katherine", ""], ["Krause", "Amrey", ""], ["van Strien", "Daniel", ""], ["Nanni", "Federico", ""]]}, {"id": "2009.08115", "submitter": "Yichi Zhang", "authors": "Yichi Zhang, Zhijian Ou, Huixin Wang, Junlan Feng", "title": "A Probabilistic End-To-End Task-Oriented Dialog Model with Latent Belief\n  States towards Semi-Supervised Learning", "comments": "Accepted by EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured belief states are crucial for user goal tracking and database\nquery in task-oriented dialog systems. However, training belief trackers often\nrequires expensive turn-level annotations of every user utterance. In this\npaper we aim at alleviating the reliance on belief state labels in building\nend-to-end dialog systems, by leveraging unlabeled dialog data towards\nsemi-supervised learning. We propose a probabilistic dialog model, called the\nLAtent BElief State (LABES) model, where belief states are represented as\ndiscrete latent variables and jointly modeled with system responses given user\ninputs. Such latent variable modeling enables us to develop semi-supervised\nlearning under the principled variational learning framework. Furthermore, we\nintroduce LABES-S2S, which is a copy-augmented Seq2Seq model instantiation of\nLABES. In supervised experiments, LABES-S2S obtains strong results on three\nbenchmark datasets of different scales. In utilizing unlabeled dialog data,\nsemi-supervised LABES-S2S significantly outperforms both supervised-only and\nsemi-supervised baselines. Remarkably, we can reduce the annotation demands to\n50% without performance loss on MultiWOZ.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 07:26:37 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 06:43:09 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 14:18:09 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Zhang", "Yichi", ""], ["Ou", "Zhijian", ""], ["Wang", "Huixin", ""], ["Feng", "Junlan", ""]]}, {"id": "2009.08128", "submitter": "Youngbin Ro", "authors": "Youngbin Ro, Yukyung Lee, Pilsung Kang", "title": "Multi$^2$OIE: Multilingual Open Information Extraction Based on\n  Multi-Head Attention with BERT", "comments": "11 pages, Findings of EMNLP 2020", "journal-ref": null, "doi": "10.18653/v1/2020.findings-emnlp.99", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Multi$^2$OIE, which performs open information\nextraction (open IE) by combining BERT with multi-head attention. Our model is\na sequence-labeling system with an efficient and effective argument extraction\nmethod. We use a query, key, and value setting inspired by the Multimodal\nTransformer to replace the previously used bidirectional long short-term memory\narchitecture with multi-head attention. Multi$^2$OIE outperforms existing\nsequence-labeling systems with high computational efficiency on two benchmark\nevaluation datasets, Re-OIE2016 and CaRB. Additionally, we apply the proposed\nmethod to multilingual open IE using multilingual BERT. Experimental results on\nnew benchmark datasets introduced for two languages (Spanish and Portuguese)\ndemonstrate that our model outperforms other multilingual systems without\ntraining data for the target languages.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 08:03:42 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 06:41:03 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Ro", "Youngbin", ""], ["Lee", "Yukyung", ""], ["Kang", "Pilsung", ""]]}, {"id": "2009.08138", "submitter": "Yutai Hou", "authors": "Yutai Hou, Jiafeng Mao, Yongkui Lai, Cheng Chen, Wanxiang Che, Zhigang\n  Chen, Ting Liu", "title": "FewJoint: A Few-shot Learning Benchmark for Joint Language Understanding", "comments": "Code and dataset is available at:\n  https://github.com/AtmaHou/MetaDialog", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Few-shot learning (FSL) is one of the key future steps in machine learning\nand has raised a lot of attention. However, in contrast to the rapid\ndevelopment in other domains, such as Computer Vision, the progress of FSL in\nNature Language Processing (NLP) is much slower. One of the key reasons for\nthis is the lacking of public benchmarks. NLP FSL researches always report new\nresults on their own constructed few-shot datasets, which is pretty inefficient\nin results comparison and thus impedes cumulative progress. In this paper, we\npresent FewJoint, a novel Few-Shot Learning benchmark for NLP. Different from\nmost NLP FSL research that only focus on simple N-classification problems, our\nbenchmark introduces few-shot joint dialogue language understanding, which\nadditionally covers the structure prediction and multi-task reliance problems.\nThis allows our benchmark to reflect the real-word NLP complexity beyond simple\nN-classification. Our benchmark is used in the few-shot learning contest of\nSMP2020-ECDT task-1. We also provide a compatible FSL platform to ease\nexperiment set-up.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 08:17:12 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 15:19:05 GMT"}, {"version": "v3", "created": "Sun, 13 Dec 2020 06:24:12 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Hou", "Yutai", ""], ["Mao", "Jiafeng", ""], ["Lai", "Yongkui", ""], ["Chen", "Cheng", ""], ["Che", "Wanxiang", ""], ["Chen", "Zhigang", ""], ["Liu", "Ting", ""]]}, {"id": "2009.08153", "submitter": "Yaojie Lu", "authors": "Yaojie Lu and Hongyu Lin and Jialong Tang and Xianpei Han and Le Sun", "title": "End-to-End Neural Event Coreference Resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional event coreference systems usually rely on pipeline framework and\nhand-crafted features, which often face error propagation problem and have poor\ngeneralization ability. In this paper, we propose an End-to-End Event\nCoreference approach -- E3C neural network, which can jointly model event\ndetection and event coreference resolution tasks, and learn to extract features\nfrom raw text automatically. Furthermore, because event mentions are highly\ndiversified and event coreference is intricately governed by long-distance,\nsemantic-dependent decisions, a type-guided event coreference mechanism is\nfurther proposed in our E3C neural network. Experiments show that our method\nachieves new state-of-the-art performance on two standard datasets.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 09:00:59 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Lu", "Yaojie", ""], ["Lin", "Hongyu", ""], ["Tang", "Jialong", ""], ["Han", "Xianpei", ""], ["Sun", "Le", ""]]}, {"id": "2009.08171", "submitter": "Yaojie Lu", "authors": "Yaojie Lu and Annan Li and Hongyu Lin and Xianpei Han and Le Sun", "title": "ISCAS at SemEval-2020 Task 5: Pre-trained Transformers for\n  Counterfactual Statement Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ISCAS participated in two subtasks of SemEval 2020 Task 5: detecting\ncounterfactual statements and detecting antecedent and consequence. This paper\ndescribes our system which is based on pre-trained transformers. For the first\nsubtask, we train several transformer-based classifiers for detecting\ncounterfactual statements. For the second subtask, we formulate antecedent and\nconsequence extraction as a query-based question answering problem. The two\nsubsystems both achieved third place in the evaluation. Our system is openly\nreleased at https://github.com/casnlu/ISCAS-SemEval2020Task5.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 09:28:07 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Lu", "Yaojie", ""], ["Li", "Annan", ""], ["Lin", "Hongyu", ""], ["Han", "Xianpei", ""], ["Sun", "Le", ""]]}, {"id": "2009.08180", "submitter": "Priyanshu Kumar", "authors": "Aadarsh Singh, Priyanshu Kumar and Aman Sinha", "title": "DSC IIT-ISM at SemEval-2020 Task 6: Boosting BERT with Dependencies for\n  Definition Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We explore the performance of Bidirectional Encoder Representations from\nTransformers (BERT) at definition extraction. We further propose a joint model\nof BERT and Text Level Graph Convolutional Network so as to incorporate\ndependencies into the model. Our proposed model produces better results than\nBERT and achieves comparable results to BERT with fine tuned language model in\nDeftEval (Task 6 of SemEval 2020), a shared task of classifying whether a\nsentence contains a definition or not (Subtask 1).\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 09:48:59 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Singh", "Aadarsh", ""], ["Kumar", "Priyanshu", ""], ["Sinha", "Aman", ""]]}, {"id": "2009.08205", "submitter": "Dustin Wright", "authors": "Pepa Atanasova, Dustin Wright, and Isabelle Augenstein", "title": "Generating Label Cohesive and Well-Formed Adversarial Claims", "comments": "9 pages, 1 figure, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks reveal important vulnerabilities and flaws of trained\nmodels. One potent type of attack are universal adversarial triggers, which are\nindividual n-grams that, when appended to instances of a class under attack,\ncan trick a model into predicting a target class. However, for inference tasks\nsuch as fact checking, these triggers often inadvertently invert the meaning of\ninstances they are inserted in. In addition, such attacks produce semantically\nnonsensical inputs, as they simply concatenate triggers to existing samples.\nHere, we investigate how to generate adversarial attacks against fact checking\nsystems that preserve the ground truth meaning and are semantically valid. We\nextend the HotFlip attack algorithm used for universal trigger generation by\njointly minimising the target class loss of a fact checking model and the\nentailment class loss of an auxiliary natural language inference model. We then\ntrain a conditional language model to generate semantically valid statements,\nwhich include the found universal triggers. We find that the generated attacks\nmaintain the directionality and semantic validity of the claim better than\nprevious work.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 10:50:42 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Atanasova", "Pepa", ""], ["Wright", "Dustin", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "2009.08229", "submitter": "Xinyu Wang", "authors": "Xinyu Wang, Yong Jiang, Nguyen Bach, Tao Wang, Zhongqiang Huang, Fei\n  Huang, Kewei Tu", "title": "AIN: Fast and Accurate Sequence Labeling with Approximate Inference\n  Network", "comments": "Accept to Main Conference of EMNLP 2020 (Short). Camera-ready, 8\n  Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The linear-chain Conditional Random Field (CRF) model is one of the most\nwidely-used neural sequence labeling approaches. Exact probabilistic inference\nalgorithms such as the forward-backward and Viterbi algorithms are typically\napplied in training and prediction stages of the CRF model. However, these\nalgorithms require sequential computation that makes parallelization\nimpossible. In this paper, we propose to employ a parallelizable approximate\nvariational inference algorithm for the CRF model. Based on this algorithm, we\ndesign an approximate inference network that can be connected with the encoder\nof the neural CRF model to form an end-to-end network, which is amenable to\nparallelization for faster training and prediction. The empirical results show\nthat our proposed approaches achieve a 12.7-fold improvement in decoding speed\nwith long sentences and a competitive accuracy compared with the traditional\nCRF approach.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 12:18:43 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 11:59:20 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Wang", "Xinyu", ""], ["Jiang", "Yong", ""], ["Bach", "Nguyen", ""], ["Wang", "Tao", ""], ["Huang", "Zhongqiang", ""], ["Huang", "Fei", ""], ["Tu", "Kewei", ""]]}, {"id": "2009.08240", "submitter": "Yonatan Bilu", "authors": "Yonatan Bilu, Shai Gretz, Edo Cohen and Noam Slonim", "title": "What if we had no Wikipedia? Domain-independent Term Extraction from a\n  Large News Corpus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most impressive human endeavors of the past two decades is the\ncollection and categorization of human knowledge in the free and accessible\nformat that is Wikipedia. In this work we ask what makes a term worthy of\nentering this edifice of knowledge, and having a page of its own in Wikipedia?\nTo what extent is this a natural product of on-going human discourse and\ndiscussion rather than an idiosyncratic choice of Wikipedia editors?\nSpecifically, we aim to identify such \"wiki-worthy\" terms in a massive news\ncorpus, and see if this can be done with no, or minimal, dependency on actual\nWikipedia entries. We suggest a five-step pipeline for doing so, providing\nbaseline results for all five, and the relevant datasets for benchmarking them.\nOur work sheds new light on the domain-specific Automatic Term Extraction\nproblem, with the problem at hand being a domain-independent variant of it.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 12:45:46 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Bilu", "Yonatan", ""], ["Gretz", "Shai", ""], ["Cohen", "Edo", ""], ["Slonim", "Noam", ""]]}, {"id": "2009.08257", "submitter": "Ignacio Iacobacci", "authors": "Ieva Stali\\=unait\\.e and Ignacio Iacobacci", "title": "Compositional and Lexical Semantics in RoBERTa, BERT and DistilBERT: A\n  Case Study on CoQA", "comments": "8 pages + 2 pages references, 3 tables, 1 figure. Accepted as long\n  paper in EMNLP2020 main conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many NLP tasks have benefited from transferring knowledge from contextualized\nword embeddings, however the picture of what type of knowledge is transferred\nis incomplete. This paper studies the types of linguistic phenomena accounted\nfor by language models in the context of a Conversational Question Answering\n(CoQA) task. We identify the problematic areas for the finetuned RoBERTa, BERT\nand DistilBERT models through systematic error analysis - basic arithmetic\n(counting phrases), compositional semantics (negation and Semantic Role\nLabeling), and lexical semantics (surprisal and antonymy). When enhanced with\nthe relevant linguistic knowledge through multitask learning, the models\nimprove in performance. Ensembles of the enhanced models yield a boost between\n2.2 and 2.7 points in F1 score overall, and up to 42.1 points in F1 on the\nhardest question classes. The results show differences in ability to represent\ncompositional and lexical information between RoBERTa, BERT and DistilBERT.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 13:00:13 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Stali\u016bnait\u0117", "Ieva", ""], ["Iacobacci", "Ignacio", ""]]}, {"id": "2009.08330", "submitter": "Xinyu Wang", "authors": "Xinyu Wang, Yong Jiang, Nguyen Bach, Tao Wang, Zhongqiang Huang, Fei\n  Huang, Kewei Tu", "title": "More Embeddings, Better Sequence Labelers?", "comments": "Accepted to Findings of EMNLP 2020. Camera-ready, 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent work proposes a family of contextual embeddings that significantly\nimproves the accuracy of sequence labelers over non-contextual embeddings.\nHowever, there is no definite conclusion on whether we can build better\nsequence labelers by combining different kinds of embeddings in various\nsettings. In this paper, we conduct extensive experiments on 3 tasks over 18\ndatasets and 8 languages to study the accuracy of sequence labeling with\nvarious embedding concatenations and make three observations: (1) concatenating\nmore embedding variants leads to better accuracy in rich-resource and\ncross-domain settings and some conditions of low-resource settings; (2)\nconcatenating additional contextual sub-word embeddings with contextual\ncharacter embeddings hurts the accuracy in extremely low-resource settings; (3)\nbased on the conclusion of (1), concatenating additional similar contextual\nembeddings cannot lead to further improvements. We hope these conclusions can\nhelp people build stronger sequence labelers in various settings.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 14:28:27 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 13:55:04 GMT"}, {"version": "v3", "created": "Wed, 2 Jun 2021 03:09:58 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Wang", "Xinyu", ""], ["Jiang", "Yong", ""], ["Bach", "Nguyen", ""], ["Wang", "Tao", ""], ["Huang", "Zhongqiang", ""], ["Huang", "Fei", ""], ["Tu", "Kewei", ""]]}, {"id": "2009.08366", "submitter": "Daya Guo", "authors": "Daya Guo, Shuo Ren, Shuai Lu, Zhangyin Feng, Duyu Tang, Shujie Liu,\n  Long Zhou, Nan Duan, Alexey Svyatkovskiy, Shengyu Fu, Michele Tufano, Shao\n  Kun Deng, Colin Clement, Dawn Drain, Neel Sundaresan, Jian Yin, Daxin Jiang,\n  Ming Zhou", "title": "GraphCodeBERT: Pre-training Code Representations with Data Flow", "comments": "Accepted by ICLR2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained models for programming language have achieved dramatic empirical\nimprovements on a variety of code-related tasks such as code search, code\ncompletion, code summarization, etc. However, existing pre-trained models\nregard a code snippet as a sequence of tokens, while ignoring the inherent\nstructure of code, which provides crucial code semantics and would enhance the\ncode understanding process. We present GraphCodeBERT, a pre-trained model for\nprogramming language that considers the inherent structure of code. Instead of\ntaking syntactic-level structure of code like abstract syntax tree (AST), we\nuse data flow in the pre-training stage, which is a semantic-level structure of\ncode that encodes the relation of \"where-the-value-comes-from\" between\nvariables. Such a semantic-level structure is neat and does not bring an\nunnecessarily deep hierarchy of AST, the property of which makes the model more\nefficient. We develop GraphCodeBERT based on Transformer. In addition to using\nthe task of masked language modeling, we introduce two structure-aware\npre-training tasks. One is to predict code structure edges, and the other is to\nalign representations between source code and code structure. We implement the\nmodel in an efficient way with a graph-guided masked attention function to\nincorporate the code structure. We evaluate our model on four tasks, including\ncode search, clone detection, code translation, and code refinement. Results\nshow that code structure and newly introduced pre-training tasks can improve\nGraphCodeBERT and achieves state-of-the-art performance on the four downstream\ntasks. We further show that the model prefers structure-level attentions over\ntoken-level attentions in the task of code search.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 15:25:56 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 02:37:30 GMT"}, {"version": "v3", "created": "Wed, 24 Feb 2021 14:12:39 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Guo", "Daya", ""], ["Ren", "Shuo", ""], ["Lu", "Shuai", ""], ["Feng", "Zhangyin", ""], ["Tang", "Duyu", ""], ["Liu", "Shujie", ""], ["Zhou", "Long", ""], ["Duan", "Nan", ""], ["Svyatkovskiy", "Alexey", ""], ["Fu", "Shengyu", ""], ["Tufano", "Michele", ""], ["Deng", "Shao Kun", ""], ["Clement", "Colin", ""], ["Drain", "Dawn", ""], ["Sundaresan", "Neel", ""], ["Yin", "Jian", ""], ["Jiang", "Daxin", ""], ["Zhou", "Ming", ""]]}, {"id": "2009.08380", "submitter": "Ori Shapira", "authors": "Ori Shapira, Ramakanth Pasunuru, Hadar Ronen, Mohit Bansal, Yael\n  Amsterdamer, Ido Dagan", "title": "Evaluating Interactive Summarization: an Expansion-Based Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Allowing users to interact with multi-document summarizers is a promising\ndirection towards improving and customizing summary results. Different ideas\nfor interactive summarization have been proposed in previous work but these\nsolutions are highly divergent and incomparable. In this paper, we develop an\nend-to-end evaluation framework for expansion-based interactive summarization,\nwhich considers the accumulating information along an interactive session. Our\nframework includes a procedure of collecting real user sessions and evaluation\nmeasures relying on standards, but adapted to reflect interaction. All of our\nsolutions are intended to be released publicly as a benchmark, allowing\ncomparison of future developments in interactive summarization. We demonstrate\nthe use of our framework by evaluating and comparing baseline implementations\nthat we developed for this purpose, which will serve as part of our benchmark.\nOur extensive experimentation and analysis of these systems motivate our design\nchoices and support the viability of our framework.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 15:48:13 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Shapira", "Ori", ""], ["Pasunuru", "Ramakanth", ""], ["Ronen", "Hadar", ""], ["Bansal", "Mohit", ""], ["Amsterdamer", "Yael", ""], ["Dagan", "Ido", ""]]}, {"id": "2009.08392", "submitter": "Joshua Garland", "authors": "Joshua Garland, Keyan Ghazi-Zahedi, Jean-Gabriel Young, Laurent\n  H\\'ebert-Dufresne, Mirta Galesic", "title": "Impact and dynamics of hate and counter speech online", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Citizen-generated counter speech is a promising way to fight hate speech and\npromote peaceful, non-polarized discourse. However, there is a lack of\nlarge-scale longitudinal studies of its effectiveness for reducing hate speech.\nWe investigate the effectiveness of counter speech using several different\nmacro- and micro-level measures of over 180,000 political conversations that\ntook place on German Twitter over four years. We report on the dynamic\ninteractions of hate and counter speech over time and provide insights into\nwhether, as in `classic' bullying situations, organized efforts are more\neffective than independent individuals in steering online discourse. Taken\ntogether, our results build a multifaceted picture of the dynamics of hate and\ncounter speech online. They suggest that organized hate speech produced changes\nin the public discourse. Counter speech, especially when organized, could help\nin curbing hate speech in online discussions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 01:43:28 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 16:46:04 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Garland", "Joshua", ""], ["Ghazi-Zahedi", "Keyan", ""], ["Young", "Jean-Gabriel", ""], ["H\u00e9bert-Dufresne", "Laurent", ""], ["Galesic", "Mirta", ""]]}, {"id": "2009.08395", "submitter": "Tariq Habib Afridi Mr.", "authors": "Tariq Habib Afridi, Aftab Alam, Muhammad Numan Khan, Jawad Khan,\n  Young-Koo Lee", "title": "A Multimodal Memes Classification: A Survey and Open Research Issues", "comments": "This is a survey paper on recent state of the art VL models that can\n  be used for memes classification. it has 15 pages and 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memes are graphics and text overlapped so that together they present concepts\nthat become dubious if one of them is absent. It is spread mostly on social\nmedia platforms, in the form of jokes, sarcasm, motivating, etc. After the\nsuccess of BERT in Natural Language Processing (NLP), researchers inclined to\nVisual-Linguistic (VL) multimodal problems like memes classification, image\ncaptioning, Visual Question Answering (VQA), and many more. Unfortunately, many\nmemes get uploaded each day on social media platforms that need automatic\ncensoring to curb misinformation and hate. Recently, this issue has attracted\nthe attention of researchers and practitioners. State-of-the-art methods that\nperformed significantly on other VL dataset, tends to fail on memes\nclassification. In this context, this work aims to conduct a comprehensive\nstudy on memes classification, generally on the VL multimodal problems and\ncutting edge solutions. We propose a generalized framework for VL problems. We\ncover the early and next-generation works on VL problems. Finally, we identify\nand articulate several open research issues and challenges. This is the first\nstudy that presents the generalized view of the advanced classification\ntechniques concerning memes classification to the best of our knowledge. We\nbelieve this study presents a clear road-map for the Machine Learning (ML)\nresearch community to implement and enhance memes classification techniques.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 16:13:21 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Afridi", "Tariq Habib", ""], ["Alam", "Aftab", ""], ["Khan", "Muhammad Numan", ""], ["Khan", "Jawad", ""], ["Lee", "Young-Koo", ""]]}, {"id": "2009.08424", "submitter": "Mariya Toneva", "authors": "Mariya Toneva, Otilia Stretcu, Barnabas Poczos, Leila Wehbe, Tom M.\n  Mitchell", "title": "Modeling Task Effects on Meaning Representation in the Brain via\n  Zero-Shot MEG Prediction", "comments": "accepted at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How meaning is represented in the brain is still one of the big open\nquestions in neuroscience. Does a word (e.g., bird) always have the same\nrepresentation, or does the task under which the word is processed alter its\nrepresentation (answering \"can you eat it?\" versus \"can it fly?\")? The brain\nactivity of subjects who read the same word while performing different semantic\ntasks has been shown to differ across tasks. However, it is still not\nunderstood how the task itself contributes to this difference. In the current\nwork, we study Magnetoencephalography (MEG) brain recordings of participants\ntasked with answering questions about concrete nouns. We investigate the effect\nof the task (i.e. the question being asked) on the processing of the concrete\nnoun by predicting the millisecond-resolution MEG recordings as a function of\nboth the semantics of the noun and the task. Using this approach, we test\nseveral hypotheses about the task-stimulus interactions by comparing the\nzero-shot predictions made by these hypotheses for novel tasks and nouns not\nseen during training. We find that incorporating the task semantics\nsignificantly improves the prediction of MEG recordings, across participants.\nThe improvement occurs 475-550ms after the participants first see the word,\nwhich corresponds to what is considered to be the ending time of semantic\nprocessing for a word. These results suggest that only the end of semantic\nprocessing of a word is task-dependent, and pose a challenge for future\nresearch to formulate new hypotheses for earlier task effects as a function of\nthe task and stimuli.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 17:20:18 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 22:31:22 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Toneva", "Mariya", ""], ["Stretcu", "Otilia", ""], ["Poczos", "Barnabas", ""], ["Wehbe", "Leila", ""], ["Mitchell", "Tom M.", ""]]}, {"id": "2009.08441", "submitter": "Ashish Sharma", "authors": "Ashish Sharma, Adam S. Miner, David C. Atkins, Tim Althoff", "title": "A Computational Approach to Understanding Empathy Expressed in\n  Text-Based Mental Health Support", "comments": "Accepted for publication at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empathy is critical to successful mental health support. Empathy measurement\nhas predominantly occurred in synchronous, face-to-face settings, and may not\ntranslate to asynchronous, text-based contexts. Because millions of people use\ntext-based platforms for mental health support, understanding empathy in these\ncontexts is crucial. In this work, we present a computational approach to\nunderstanding how empathy is expressed in online mental health platforms. We\ndevelop a novel unifying theoretically-grounded framework for characterizing\nthe communication of empathy in text-based conversations. We collect and share\na corpus of 10k (post, response) pairs annotated using this empathy framework\nwith supporting evidence for annotations (rationales). We develop a multi-task\nRoBERTa-based bi-encoder model for identifying empathy in conversations and\nextracting rationales underlying its predictions. Experiments demonstrate that\nour approach can effectively identify empathic conversations. We further apply\nthis model to analyze 235k mental health interactions and show that users do\nnot self-learn empathy over time, revealing opportunities for empathy training\nand feedback.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 17:47:00 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Sharma", "Ashish", ""], ["Miner", "Adam S.", ""], ["Atkins", "David C.", ""], ["Althoff", "Tim", ""]]}, {"id": "2009.08445", "submitter": "Trapit Bansal", "authors": "Trapit Bansal, Rishikesh Jha, Tsendsuren Munkhdalai, Andrew McCallum", "title": "Self-Supervised Meta-Learning for Few-Shot Natural Language\n  Classification Tasks", "comments": "To appear in EMNLP 2020, camera-ready, link to code added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-supervised pre-training of transformer models has revolutionized NLP\napplications. Such pre-training with language modeling objectives provides a\nuseful initial point for parameters that generalize well to new tasks with\nfine-tuning. However, fine-tuning is still data inefficient -- when there are\nfew labeled examples, accuracy can be low. Data efficiency can be improved by\noptimizing pre-training directly for future fine-tuning with few examples; this\ncan be treated as a meta-learning problem. However, standard meta-learning\ntechniques require many training tasks in order to generalize; unfortunately,\nfinding a diverse set of such supervised tasks is usually difficult. This paper\nproposes a self-supervised approach to generate a large, rich, meta-learning\ntask distribution from unlabeled text. This is achieved using a cloze-style\nobjective, but creating separate multi-class classification tasks by gathering\ntokens-to-be blanked from among only a handful of vocabulary terms. This yields\nas many unique meta-training tasks as the number of subsets of vocabulary\nterms. We meta-train a transformer model on this distribution of tasks using a\nrecent meta-learning framework. On 17 NLP tasks, we show that this\nmeta-training leads to better few-shot generalization than language-model\npre-training followed by finetuning. Furthermore, we show how the\nself-supervised tasks can be combined with supervised tasks for meta-learning,\nproviding substantial accuracy gains over previous supervised meta-learning.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 17:53:59 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 20:31:22 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Bansal", "Trapit", ""], ["Jha", "Rishikesh", ""], ["Munkhdalai", "Tsendsuren", ""], ["McCallum", "Andrew", ""]]}, {"id": "2009.08478", "submitter": "Ling Luo", "authors": "Ling Luo, Shankai Yan, Po-Ting Lai, Daniel Veltri, Andrew Oler,\n  Sandhya Xirasagar, Rajarshi Ghosh, Morgan Similuk, Peter N. Robinson, Zhiyong\n  Lu", "title": "PhenoTagger: A Hybrid Method for Phenotype Concept Recognition using\n  Human Phenotype Ontology", "comments": "Accepted by Bioinformatics", "journal-ref": null, "doi": "10.1093/bioinformatics/btab019", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic phenotype concept recognition from unstructured text remains a\nchallenging task in biomedical text mining research. Previous works that\naddress the task typically use dictionary-based matching methods, which can\nachieve high precision but suffer from lower recall. Recently, machine\nlearning-based methods have been proposed to identify biomedical concepts,\nwhich can recognize more unseen concept synonyms by automatic feature learning.\nHowever, most methods require large corpora of manually annotated data for\nmodel training, which is difficult to obtain due to the high cost of human\nannotation. In this paper, we propose PhenoTagger, a hybrid method that\ncombines both dictionary and machine learning-based methods to recognize Human\nPhenotype Ontology (HPO) concepts in unstructured biomedical text. We first use\nall concepts and synonyms in HPO to construct a dictionary, which is then used\nto automatically build a distantly supervised training dataset for machine\nlearning. Next, a cutting-edge deep learning model is trained to classify each\ncandidate phrase (n-gram from input sentence) into a corresponding concept\nlabel. Finally, the dictionary and machine learning-based prediction results\nare combined for improved performance. Our method is validated with two HPO\ncorpora, and the results show that PhenoTagger compares favorably to previous\nmethods. In addition, to demonstrate the generalizability of our method, we\nretrained PhenoTagger using the disease ontology MEDIC for disease concept\nrecognition to investigate the effect of training on different ontologies.\nExperimental results on the NCBI disease corpus show that PhenoTagger without\nrequiring manually annotated training data achieves competitive performance as\ncompared with state-of-the-art supervised methods.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 18:00:43 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 16:08:43 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Luo", "Ling", ""], ["Yan", "Shankai", ""], ["Lai", "Po-Ting", ""], ["Veltri", "Daniel", ""], ["Oler", "Andrew", ""], ["Xirasagar", "Sandhya", ""], ["Ghosh", "Rajarshi", ""], ["Similuk", "Morgan", ""], ["Robinson", "Peter N.", ""], ["Lu", "Zhiyong", ""]]}, {"id": "2009.08552", "submitter": "Liang Qiu", "authors": "Liang Qiu, Yizhou Zhao, Weiyan Shi, Yuan Liang, Feng Shi, Tao Yuan,\n  Zhou Yu, Song-Chun Zhu", "title": "Structured Attention for Unsupervised Dialogue Structure Induction", "comments": "Long paper accepted by EMNLP 2020", "journal-ref": null, "doi": "10.18653/v1/2020.emnlp-main.148", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inducing a meaningful structural representation from one or a set of\ndialogues is a crucial but challenging task in computational linguistics.\nAdvancement made in this area is critical for dialogue system design and\ndiscourse analysis. It can also be extended to solve grammatical inference. In\nthis work, we propose to incorporate structured attention layers into a\nVariational Recurrent Neural Network (VRNN) model with discrete latent states\nto learn dialogue structure in an unsupervised fashion. Compared to a vanilla\nVRNN, structured attention enables a model to focus on different parts of the\nsource sentence embeddings while enforcing a structural inductive bias.\nExperiments show that on two-party dialogue datasets, VRNN with structured\nattention learns semantic structures that are similar to templates used to\ngenerate this dialogue corpus. While on multi-party dialogue datasets, our\nmodel learns an interactive structure demonstrating its capability of\ndistinguishing speakers or addresses, automatically disentangling dialogues\nwithout explicit human annotation.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 23:07:03 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 18:33:18 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Qiu", "Liang", ""], ["Zhao", "Yizhou", ""], ["Shi", "Weiyan", ""], ["Liang", "Yuan", ""], ["Shi", "Feng", ""], ["Yuan", "Tao", ""], ["Yu", "Zhou", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "2009.08553", "submitter": "Yuning Mao", "authors": "Yuning Mao, Pengcheng He, Xiaodong Liu, Yelong Shen, Jianfeng Gao,\n  Jiawei Han, Weizhu Chen", "title": "Generation-Augmented Retrieval for Open-domain Question Answering", "comments": "ACL 2021 Camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Generation-Augmented Retrieval (GAR) for answering open-domain\nquestions, which augments a query through text generation of heuristically\ndiscovered relevant contexts without external resources as supervision. We\ndemonstrate that the generated contexts substantially enrich the semantics of\nthe queries and GAR with sparse representations (BM25) achieves comparable or\nbetter performance than state-of-the-art dense retrieval methods such as DPR.\nWe show that generating diverse contexts for a query is beneficial as fusing\ntheir results consistently yields better retrieval accuracy. Moreover, as\nsparse and dense representations are often complementary, GAR can be easily\ncombined with DPR to achieve even better performance. GAR achieves\nstate-of-the-art performance on Natural Questions and TriviaQA datasets under\nthe extractive QA setup when equipped with an extractive reader, and\nconsistently outperforms other retrieval methods when the same generative\nreader is used.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 23:08:01 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 03:23:27 GMT"}, {"version": "v3", "created": "Sun, 30 May 2021 22:08:35 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Mao", "Yuning", ""], ["He", "Pengcheng", ""], ["Liu", "Xiaodong", ""], ["Shen", "Yelong", ""], ["Gao", "Jianfeng", ""], ["Han", "Jiawei", ""], ["Chen", "Weizhu", ""]]}, {"id": "2009.08560", "submitter": "Li Zhang", "authors": "Li Zhang, Huaiyu Zhu, Siddhartha Brahma, Yunyao Li", "title": "Small but Mighty: New Benchmarks for Split and Rephrase", "comments": "In EMNLP 2020", "journal-ref": "Proceedings of the 2020 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP) (2020) 1198-1205", "doi": "10.18653/v1/2020.emnlp-main.91", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Split and Rephrase is a text simplification task of rewriting a complex\nsentence into simpler ones. As a relatively new task, it is paramount to ensure\nthe soundness of its evaluation benchmark and metric. We find that the widely\nused benchmark dataset universally contains easily exploitable syntactic cues\ncaused by its automatic generation process. Taking advantage of such cues, we\nshow that even a simple rule-based model can perform on par with the\nstate-of-the-art model. To remedy such limitations, we collect and release two\ncrowdsourced benchmark datasets. We not only make sure that they contain\nsignificantly more diverse syntax, but also carefully control for their quality\naccording to a well-defined set of criteria. While no satisfactory automatic\nmetric exists, we apply fine-grained manual evaluation based on these criteria\nusing crowdsourcing, showing that our datasets better represent the task and\nare significantly more challenging for the models.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 23:37:33 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 15:35:32 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Zhang", "Li", ""], ["Zhu", "Huaiyu", ""], ["Brahma", "Siddhartha", ""], ["Li", "Yunyao", ""]]}, {"id": "2009.08566", "submitter": "Tejas Gokhale", "authors": "Tejas Gokhale and Pratyay Banerjee and Chitta Baral and Yezhou Yang", "title": "MUTANT: A Training Paradigm for Out-of-Distribution Generalization in\n  Visual Question Answering", "comments": "Accepted to EMNLP 2020, Long Papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While progress has been made on the visual question answering leaderboards,\nmodels often utilize spurious correlations and priors in datasets under the\ni.i.d. setting. As such, evaluation on out-of-distribution (OOD) test samples\nhas emerged as a proxy for generalization. In this paper, we present MUTANT, a\ntraining paradigm that exposes the model to perceptually similar, yet\nsemantically distinct mutations of the input, to improve OOD generalization,\nsuch as the VQA-CP challenge. Under this paradigm, models utilize a\nconsistency-constrained training objective to understand the effect of semantic\nchanges in input (question-image pair) on the output (answer). Unlike existing\nmethods on VQA-CP, MUTANT does not rely on the knowledge about the nature of\ntrain and test answer distributions. MUTANT establishes a new state-of-the-art\naccuracy on VQA-CP with a $10.57\\%$ improvement. Our work opens up avenues for\nthe use of semantic input mutations for OOD generalization in question\nanswering.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 00:22:54 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 01:53:08 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Gokhale", "Tejas", ""], ["Banerjee", "Pratyay", ""], ["Baral", "Chitta", ""], ["Yang", "Yezhou", ""]]}, {"id": "2009.08590", "submitter": "Kumud Chauhan", "authors": "Kumud Chauhan", "title": "NEU at WNUT-2020 Task 2: Data Augmentation To Tell BERT That Death Is\n  Not Necessarily Informative", "comments": "WNUT-2020 Task 2 System Description paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millions of people around the world are sharing COVID-19 related information\non social media platforms. Since not all the information shared on the social\nmedia is useful, a machine learning system to identify informative posts can\nhelp users in finding relevant information. In this paper, we present a BERT\nclassifier system for W-NUT2020 Shared Task 2: Identification of Informative\nCOVID-19 English Tweets. Further, we show that BERT exploits some easy signals\nto identify informative tweets, and adding simple patterns to uninformative\ntweets drastically degrades BERT performance. In particular, simply adding 10\ndeaths to tweets in dev set, reduces BERT F1- score from 92.63 to 7.28. We also\npropose a simple data augmentation technique that helps in improving the\nrobustness and generalization ability of the BERT classifier.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 02:16:49 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Chauhan", "Kumud", ""]]}, {"id": "2009.08595", "submitter": "Guokun Lai", "authors": "Guokun Lai, Zihang Dai, Yiming Yang", "title": "Unsupervised Parallel Corpus Mining on Web Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With a large amount of parallel data, neural machine translation systems are\nable to deliver human-level performance for sentence-level translation.\nHowever, it is costly to label a large amount of parallel data by humans. In\ncontrast, there is a large-scale of parallel corpus created by humans on the\nInternet. The major difficulty to utilize them is how to filter them out from\nthe noise website environments. Current parallel data mining methods all\nrequire labeled parallel data as the training source. In this paper, we present\na pipeline to mine the parallel corpus from the Internet in an unsupervised\nmanner. On the widely used WMT'14 English-French and WMT'16 English-German\nbenchmarks, the machine translator trained with the data extracted by our\npipeline achieves very close performance to the supervised results. On the\nWMT'16 English-Romanian and Romanian-English benchmarks, our system produces\nnew state-of-the-art results, 39.81 and 38.95 BLEU scores, even compared with\nsupervised approaches.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 02:38:01 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Lai", "Guokun", ""], ["Dai", "Zihang", ""], ["Yang", "Yiming", ""]]}, {"id": "2009.08603", "submitter": "Wenhan Wang", "authors": "Wenhan Wang, Sijie Shen, Ge Li, Zhi Jin", "title": "Towards Full-line Code Completion with Neural Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A code completion system suggests future code elements to developers given a\npartially-complete code snippet. Code completion is one of the most useful\nfeatures in Integrated Development Environments (IDEs). Currently, most code\ncompletion techniques predict a single token at a time. In this paper, we take\na further step and discuss the probability of directly completing a whole line\nof code instead of a single token. We believe suggesting longer code sequences\ncan further improve the efficiency of developers. Recently neural language\nmodels have been adopted as a preferred approach for code completion, and we\nbelieve these models can still be applied to full-line code completion with a\nfew improvements. We conduct our experiments on two real-world python corpora\nand evaluate existing neural models based on source code tokens or syntactical\nactions. The results show that neural language models can achieve acceptable\nresults on our tasks, with significant room for improvements.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 03:12:13 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Wang", "Wenhan", ""], ["Shen", "Sijie", ""], ["Li", "Ge", ""], ["Jin", "Zhi", ""]]}, {"id": "2009.08633", "submitter": "Zhichao Geng", "authors": "Zhichao Geng, Hang Yan, Xipeng Qiu, Xuanjing Huang", "title": "fastHan: A BERT-based Multi-Task Toolkit for Chinese NLP", "comments": "ACL2021 Demo Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present fastHan, an open-source toolkit for four basic tasks in Chinese\nnatural language processing: Chinese word segmentation (CWS), Part-of-Speech\n(POS) tagging, named entity recognition (NER), and dependency parsing. The\nbackbone of fastHan is a multi-task model based on a pruned BERT, which uses\nthe first 8 layers in BERT. We also provide a 4-layer base model compressed\nfrom the 8-layer model. The joint-model is trained and evaluated on 13 corpora\nof four tasks, yielding near state-of-the-art (SOTA) performance in dependency\nparsing and NER, achieving SOTA performance in CWS and POS. Besides, fastHan's\ntransferability is also strong, performing much better than popular\nsegmentation tools on a non-training corpus. To better meet the need of\npractical application, we allow users to use their own labeled data to further\nfine-tune fastHan. In addition to its small size and excellent performance,\nfastHan is user-friendly. Implemented as a python package, fastHan isolates\nusers from the internal technical details and is convenient to use. The project\nis released on Github.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 05:41:52 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 03:54:02 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Geng", "Zhichao", ""], ["Yan", "Hang", ""], ["Qiu", "Xipeng", ""], ["Huang", "Xuanjing", ""]]}, {"id": "2009.08636", "submitter": "Jihyeon Roh", "authors": "Jihyeon Roh, Huiseong Gim, Soo-Young Lee", "title": "Hierarchical GPT with Congruent Transformers for Multi-Sentence Language\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report a GPT-based multi-sentence language model for dialogue generation\nand document understanding. First, we propose a hierarchical GPT which consists\nof three blocks, i.e., a sentence encoding block, a sentence generating block,\nand a sentence decoding block. The sentence encoding and decoding blocks are\nbasically the encoder-decoder blocks of the standard Transformers, which work\non each sentence independently. The sentence generating block is inserted\nbetween the encoding and decoding blocks, and generates the next sentence\nembedding vector from the previous sentence embedding vectors. We believe it is\nthe way human make conversation and understand paragraphs and documents. Since\neach sentence may consist of fewer words, the sentence encoding and decoding\nTransformers can use much smaller dimensional embedding vectors. Secondly, we\nnote the attention in the Transformers utilizes the inner-product similarity\nmeasure. Therefore, to compare the two vectors in the same space, we set the\ntransform matrices for queries and keys to be the same. Otherwise, the\nsimilarity concept is incongruent. We report experimental results to show that\nthese two modifications increase the language model performance for tasks with\nmultiple sentences.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 05:55:37 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Roh", "Jihyeon", ""], ["Gim", "Huiseong", ""], ["Lee", "Soo-Young", ""]]}, {"id": "2009.08666", "submitter": "Anirudh Joshi", "authors": "Anirudh Joshi, Namit Katariya, Xavier Amatriain, Anitha Kannan", "title": "Dr. Summarize: Global Summarization of Medical Dialogue by Exploiting\n  Local Structures", "comments": "Accepted for publication in Findings of EMNLP at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding a medical conversation between a patient and a physician poses\na unique natural language understanding challenge since it combines elements of\nstandard open ended conversation with very domain specific elements that\nrequire expertise and medical knowledge. Summarization of medical conversations\nis a particularly important aspect of medical conversation understanding since\nit addresses a very real need in medical practice: capturing the most important\naspects of a medical encounter so that they can be used for medical decision\nmaking and subsequent follow ups.\n  In this paper we present a novel approach to medical conversation\nsummarization that leverages the unique and independent local structures\ncreated when gathering a patient's medical history. Our approach is a variation\nof the pointer generator network where we introduce a penalty on the generator\ndistribution, and we explicitly model negations. The model also captures\nimportant properties of medical conversations such as medical knowledge coming\nfrom standardized medical ontologies better than when those concepts are\nintroduced explicitly. Through evaluation by doctors, we show that our approach\nis preferred on twice the number of summaries to the baseline pointer generator\nmodel and captures most or all of the information in 80% of the conversations\nmaking it a realistic alternative to costly manual summarization by medical\nexperts.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 07:35:44 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Joshi", "Anirudh", ""], ["Katariya", "Namit", ""], ["Amatriain", "Xavier", ""], ["Kannan", "Anitha", ""]]}, {"id": "2009.08694", "submitter": "Kuldeep Singh", "authors": "Anson Bastos, Abhishek Nadgeri, Kuldeep Singh, Isaiah Onando Mulang',\n  Saeedeh Shekarpour, Johannes Hoffart, Manohar Kaul", "title": "RECON: Relation Extraction using Knowledge Graph Context in a Graph\n  Neural Network", "comments": "The Web Conference 2021 (WWW'21) full paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel method named RECON, that automatically\nidentifies relations in a sentence (sentential relation extraction) and aligns\nto a knowledge graph (KG). RECON uses a graph neural network to learn\nrepresentations of both the sentence as well as facts stored in a KG, improving\nthe overall extraction quality. These facts, including entity attributes\n(label, alias, description, instance-of) and factual triples, have not been\ncollectively used in the state of the art methods. We evaluate the effect of\nvarious forms of representing the KG context on the performance of RECON. The\nempirical evaluation on two standard relation extraction datasets shows that\nRECON significantly outperforms all state of the art methods on NYT Freebase\nand Wikidata datasets. RECON reports 87.23 F1 score (Vs 82.29 baseline) on\nWikidata dataset whereas on NYT Freebase, reported values are 87.5(P@10) and\n74.1(P@30) compared to the previous baseline scores of 81.3(P@10) and\n63.1(P@30).\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 09:02:31 GMT"}, {"version": "v2", "created": "Sun, 17 Jan 2021 18:08:45 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Bastos", "Anson", ""], ["Nadgeri", "Abhishek", ""], ["Singh", "Kuldeep", ""], ["Mulang'", "Isaiah Onando", ""], ["Shekarpour", "Saeedeh", ""], ["Hoffart", "Johannes", ""], ["Kaul", "Manohar", ""]]}, {"id": "2009.08712", "submitter": "Stefan Daniel Dumitrescu", "authors": "Stefan Daniel Dumitrescu and Andrei-Marius Avram and Sampo Pyysalo", "title": "The birth of Romanian BERT", "comments": "5 pages (4 + reference page), accepted in Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Large-scale pretrained language models have become ubiquitous in Natural\nLanguage Processing. However, most of these models are available either in\nhigh-resource languages, in particular English, or as multilingual models that\ncompromise performance on individual languages for coverage. This paper\nintroduces Romanian BERT, the first purely Romanian transformer-based language\nmodel, pretrained on a large text corpus. We discuss corpus composition and\ncleaning, the model training process, as well as an extensive evaluation of the\nmodel on various Romanian datasets. We open source not only the model itself,\nbut also a repository that contains information on how to obtain the corpus,\nfine-tune and use this model in production (with practical examples), and how\nto fully replicate the evaluation process.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 09:30:48 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Dumitrescu", "Stefan Daniel", ""], ["Avram", "Andrei-Marius", ""], ["Pyysalo", "Sampo", ""]]}, {"id": "2009.08775", "submitter": "Shu Jiang", "authors": "Shu Jiang, Hai Zhao, Zuchao Li, Bao-Liang Lu", "title": "Document-level Neural Machine Translation with Document Embeddings", "comments": "arXiv admin note: substantial text overlap with arXiv:1910.14528", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard neural machine translation (NMT) is on the assumption of\ndocument-level context independent. Most existing document-level NMT methods\nare satisfied with a smattering sense of brief document-level information,\nwhile this work focuses on exploiting detailed document-level context in terms\nof multiple forms of document embeddings, which is capable of sufficiently\nmodeling deeper and richer document-level context. The proposed document-aware\nNMT is implemented to enhance the Transformer baseline by introducing both\nglobal and local document-level clues on the source end. Experiments show that\nthe proposed method significantly improves the translation performance over\nstrong baselines and other related studies.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 19:43:29 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Jiang", "Shu", ""], ["Zhao", "Hai", ""], ["Li", "Zuchao", ""], ["Lu", "Bao-Liang", ""]]}, {"id": "2009.08801", "submitter": "Marco Anteghini", "authors": "Marco Anteghini, Jennifer D'Souza, Vitor A. P. Martins dos Santos,\n  S\\\"oren Auer", "title": "SciBERT-based Semantification of Bioassays in the Open Research\n  Knowledge Graph", "comments": "In proceedings of the '22nd International Conference on Knowledge\n  Engineering and Knowledge Management' 'Demo and Poster section'", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a novel contribution to the problem of semantifying biological assays, in\nthis paper, we propose a neural-network-based approach to automatically\nsemantify, thereby structure, unstructured bioassay text descriptions.\nExperimental evaluations, to this end, show promise as the neural-based\nsemantification significantly outperforms a naive frequency-based baseline\napproach. Specifically, the neural method attains 72% F1 versus 47% F1 from the\nfrequency-based method.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 12:36:35 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Anteghini", "Marco", ""], ["D'Souza", "Jennifer", ""], ["Santos", "Vitor A. P. Martins dos", ""], ["Auer", "S\u00f6ren", ""]]}, {"id": "2009.08820", "submitter": "Hossein Amirkhani", "authors": "Hossein Amirkhani, Mohammad AzariJafari, Zohreh Pourjafari, Soroush\n  Faridan-Jahromi, Zeinab Kouhkan, Azadeh Amirak", "title": "FarsTail: A Persian Natural Language Inference Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language inference (NLI) is known as one of the central tasks in\nnatural language processing (NLP) which encapsulates many fundamental aspects\nof language understanding. With the considerable achievements of data-hungry\ndeep learning methods in NLP tasks, a great amount of effort has been devoted\nto develop more diverse datasets for different languages. In this paper, we\npresent a new dataset for the NLI task in the Persian language, also known as\nFarsi, which is one of the dominant languages in the Middle East. This dataset,\nnamed FarsTail, includes 10,367 samples which are provided in both the Persian\nlanguage as well as the indexed format to be useful for non-Persian\nresearchers. The samples are generated from 3,539 multiple-choice questions\nwith the least amount of annotator interventions in a way similar to the\nSciTail dataset. A carefully designed multi-step process is adopted to ensure\nthe quality of the dataset. We also present the results of traditional and\nstate-of-the-art methods on FarsTail including different embedding methods such\nas word2vec, fastText, ELMo, BERT, and LASER, as well as different modeling\napproaches such as DecompAtt, ESIM, HBMP, and ULMFiT to provide a solid\nbaseline for the future research. The best obtained test accuracy is 83.38%\nwhich shows that there is a big room for improving the current methods to be\nuseful for real-world NLP applications in different languages. We also\ninvestigate the extent to which the models exploit superficial clues, also\nknown as dataset biases, in FarsTail, and partition the test set into easy and\nhard subsets according to the success of biased models. The dataset is\navailable at https://github.com/dml-qom/FarsTail\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 13:04:04 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 15:21:54 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Amirkhani", "Hossein", ""], ["AzariJafari", "Mohammad", ""], ["Pourjafari", "Zohreh", ""], ["Faridan-Jahromi", "Soroush", ""], ["Kouhkan", "Zeinab", ""], ["Amirak", "Azadeh", ""]]}, {"id": "2009.08859", "submitter": "Neslihan Suzen", "authors": "Neslihan Suzen, Alexander Gorban, Jeremy Levesley, and Evgeny Mirkes", "title": "Principal Components of the Meaning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we argue that (lexical) meaning in science can be represented\nin a 13 dimension Meaning Space. This space is constructed using principal\ncomponent analysis (singular decomposition) on the matrix of word category\nrelative information gains, where the categories are those used by the Web of\nScience, and the words are taken from a reduced word set from texts in the Web\nof Science. We show that this reduced word set plausibly represents all texts\nin the corpus, so that the principal component analysis has some objective\nmeaning with respect to the corpus. We argue that 13 dimensions is adequate to\ndescribe the meaning of scientific texts, and hypothesise about the qualitative\nmeaning of the principal components.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 14:28:32 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Suzen", "Neslihan", ""], ["Gorban", "Alexander", ""], ["Levesley", "Jeremy", ""], ["Mirkes", "Evgeny", ""]]}, {"id": "2009.08899", "submitter": "Yurio Windiatmoko", "authors": "Dhomas Hatta Fudholi, Yurio Windiatmoko, Nurdi Afrianto, Prastyo Eko\n  Susanto, Magfirah Suyuti, Ahmad Fathan Hidayatullah, Ridho Rahmadi", "title": "Image Captioning with Attention for Smart Local Tourism using\n  EfficientNet", "comments": "10 pages, 7 figures, still in review at ICITDA Conference", "journal-ref": null, "doi": "10.1088/1757-899X/1077/1/012038", "report-no": null, "categories": "cs.CV cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Smart systems have been massively developed to help humans in various tasks.\nDeep Learning technologies push even further in creating accurate assistant\nsystems due to the explosion of data lakes. One of the smart system tasks is to\ndisseminate users needed information. This is crucial in the tourism sector to\npromote local tourism destinations. In this research, we design a model of\nlocal tourism specific image captioning, which later will support the\ndevelopment of AI-powered systems that assist various users. The model is\ndeveloped using a visual Attention mechanism and uses the state-of-the-art\nfeature extractor architecture EfficientNet. A local tourism dataset is\ncollected and is used in the research, along with two different kinds of\ncaptions. Captions that describe the image literally and captions that\nrepresent human logical responses when seeing the image. This is done to make\nthe captioning model more humane when implemented in the assistance system. We\ncompared the performance of two different models using EfficientNet\narchitectures (B0 and B4) with other well known VGG16 and InceptionV3. The best\nBLEU scores we get are 73.39 and 24.51 for the training set and the validation\nset respectively, using EfficientNetB0. The captioning result using the\ndeveloped model shows that the model can produce logical caption for local\ntourism-related images\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 15:47:25 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Fudholi", "Dhomas Hatta", ""], ["Windiatmoko", "Yurio", ""], ["Afrianto", "Nurdi", ""], ["Susanto", "Prastyo Eko", ""], ["Suyuti", "Magfirah", ""], ["Hidayatullah", "Ahmad Fathan", ""], ["Rahmadi", "Ridho", ""]]}, {"id": "2009.08928", "submitter": "Keshav Ganapathy", "authors": "Keshav Ganapathy", "title": "A Study of Genetic Algorithms for Hyperparameter Optimization of Neural\n  Networks in Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With neural networks having demonstrated their versatility and benefits, the\nneed for their optimal performance is as prevalent as ever. A defining\ncharacteristic, hyperparameters, can greatly affect its performance. Thus\nengineers go through a process, tuning, to identify and implement optimal\nhyperparameters. That being said, excess amounts of manual effort are required\nfor tuning network architectures, training configurations, and preprocessing\nsettings such as Byte Pair Encoding (BPE). In this study, we propose an\nautomatic tuning method modeled after Darwin's Survival of the Fittest Theory\nvia a Genetic Algorithm (GA). Research results show that the proposed method, a\nGA, outperforms a random selection of hyperparameters.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 02:24:16 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Ganapathy", "Keshav", ""]]}, {"id": "2009.08942", "submitter": "Tuhin Chakrabarty Mr", "authors": "Tuhin Chakrabarty, Smaranda Muresan, Nanyun Peng", "title": "Generating similes effortlessly like a Pro: A Style Transfer Approach\n  for Simile Generation", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Literary tropes, from poetry to stories, are at the crux of human imagination\nand communication. Figurative language such as a simile go beyond plain\nexpressions to give readers new insights and inspirations. In this paper, we\ntackle the problem of simile generation. Generating a simile requires proper\nunderstanding for effective mapping of properties between two concepts. To this\nend, we first propose a method to automatically construct a parallel corpus by\ntransforming a large number of similes collected from Reddit to their literal\ncounterpart using structured common sense knowledge. We then propose to\nfine-tune a pretrained sequence to sequence model, BART~\\cite{lewis2019bart},\non the literal-simile pairs to gain generalizability, so that we can generate\nnovel similes given a literal sentence. Experiments show that our approach\ngenerates $88\\%$ novel similes that do not share properties with the training\ndata. Human evaluation on an independent set of literal statements shows that\nour model generates similes better than two literary experts\n\\textit{37\\%}\\footnote{We average 32.6\\% and 41.3\\% for 2 humans.} of the\ntimes, and three baseline systems including a recent metaphor generation model\n\\textit{71\\%}\\footnote{We average 82\\% ,63\\% and 68\\% for three baselines.} of\nthe times when compared pairwise.\\footnote{The simile in the title is generated\nby our best model. Input: Generating similes effortlessly, output: Generating\nsimiles \\textit{like a Pro}.} We also show how replacing literal sentences with\nsimiles from our best model in machine generated stories improves evocativeness\nand leads to better acceptance by human judges.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 17:37:13 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 05:47:43 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Chakrabarty", "Tuhin", ""], ["Muresan", "Smaranda", ""], ["Peng", "Nanyun", ""]]}, {"id": "2009.09016", "submitter": "Dominik Mach\\'a\\v{c}ek", "authors": "Dominik Mach\\'a\\v{c}ek, Ond\\v{r}ej Bojar", "title": "Presenting Simultaneous Translation in Limited Space", "comments": null, "journal-ref": "ITAT WAFNL 2020", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some methods of automatic simultaneous translation of a long-form speech\nallow revisions of outputs, trading accuracy for low latency. Deploying these\nsystems for users faces the problem of presenting subtitles in a limited space,\nsuch as two lines on a television screen. The subtitles must be shown promptly,\nincrementally, and with adequate time for reading. We provide an algorithm for\nsubtitling. Furthermore, we propose a way how to estimate the overall usability\nof the combination of automatic translation and subtitling by measuring the\nquality, latency, and stability on a test set, and propose an improved measure\nfor translation latency.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 18:37:03 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Mach\u00e1\u010dek", "Dominik", ""], ["Bojar", "Ond\u0159ej", ""]]}, {"id": "2009.09025", "submitter": "Craig Stewart", "authors": "Ricardo Rei, Craig Stewart, Ana C Farinha, Alon Lavie", "title": "COMET: A Neural Framework for MT Evaluation", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present COMET, a neural framework for training multilingual machine\ntranslation evaluation models which obtains new state-of-the-art levels of\ncorrelation with human judgements. Our framework leverages recent breakthroughs\nin cross-lingual pretrained language modeling resulting in highly multilingual\nand adaptable MT evaluation models that exploit information from both the\nsource input and a target-language reference translation in order to more\naccurately predict MT quality. To showcase our framework, we train three models\nwith different types of human judgements: Direct Assessments, Human-mediated\nTranslation Edit Rate and Multidimensional Quality Metrics. Our models achieve\nnew state-of-the-art performance on the WMT 2019 Metrics shared task and\ndemonstrate robustness to high-performing systems.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 18:54:15 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 14:10:10 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Rei", "Ricardo", ""], ["Stewart", "Craig", ""], ["Farinha", "Ana C", ""], ["Lavie", "Alon", ""]]}, {"id": "2009.09084", "submitter": "Irene Y. Chen", "authors": "Irene Y. Chen, Emily Alsentzer, Hyesun Park, Richard Thomas, Babina\n  Gosangi, Rahul Gujrathi, Bharti Khurana", "title": "Intimate Partner Violence and Injury Prediction From Radiology Reports", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Intimate partner violence (IPV) is an urgent, prevalent, and under-detected\npublic health issue. We present machine learning models to assess patients for\nIPV and injury. We train the predictive algorithms on radiology reports with 1)\nIPV labels based on entry to a violence prevention program and 2) injury labels\nprovided by emergency radiology fellowship-trained physicians. Our dataset\nincludes 34,642 radiology reports and 1479 patients of IPV victims and control\npatients. Our best model predicts IPV a median of 3.08 years before violence\nprevention program entry with a sensitivity of 64% and a specificity of 95%. We\nconduct error analysis to determine for which patients our model has especially\nhigh or low performance and discuss next steps for a deployed clinical risk\nmodel.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2020 17:20:37 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 16:26:58 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Chen", "Irene Y.", ""], ["Alsentzer", "Emily", ""], ["Park", "Hyesun", ""], ["Thomas", "Richard", ""], ["Gosangi", "Babina", ""], ["Gujrathi", "Rahul", ""], ["Khurana", "Bharti", ""]]}, {"id": "2009.09088", "submitter": "Rudresh Mishra", "authors": "Rudresh Mishra, Ricardo Rodriguez, Valentin Portillo", "title": "An AI based talent acquisition and benchmarking for job", "comments": "26 pages , 23 figures, This paper is yet to publish in conferences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In a recruitment industry, selecting a best CV from a particular job post\nwithin a pile of thousand CV's is quite challenging. Finding a perfect\ncandidate for an organization who can be fit to work within organizational\nculture is a difficult task. In order to help the recruiters to fill these gaps\nwe leverage the help of AI. We propose a methodology to solve these problems by\nmatching the skill graph generated from CV and Job Post. In this report our\napproach is to perform the business understanding in order to justify why such\nproblems arise and how we intend to solve these problems using natural language\nprocessing and machine learning techniques. We limit our project only to solve\nthe problem in the domain of the computer science industry.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 15:57:54 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Mishra", "Rudresh", ""], ["Rodriguez", "Ricardo", ""], ["Portillo", "Valentin", ""]]}, {"id": "2009.09099", "submitter": "Anshuman Mishra", "authors": "Anshuman Mishra, Dhruvesh Patel, Aparna Vijayakumar, Xiang Li, Pavan\n  Kapanipathi, Kartik Talamadupula", "title": "Looking Beyond Sentence-Level Natural Language Inference for Downstream\n  Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the Natural Language Inference (NLI) task has garnered\nsignificant attention, with new datasets and models achieving near human-level\nperformance on it. However, the full promise of NLI -- particularly that it\nlearns knowledge that should be generalizable to other downstream NLP tasks --\nhas not been realized. In this paper, we study this unfulfilled promise from\nthe lens of two downstream tasks: question answering (QA), and text\nsummarization. We conjecture that a key difference between the NLI datasets and\nthese downstream tasks concerns the length of the premise; and that creating\nnew long premise NLI datasets out of existing QA datasets is a promising avenue\nfor training a truly generalizable NLI model. We validate our conjecture by\nshowing competitive results on the task of QA and obtaining the best reported\nresults on the task of Checking Factual Correctness of Summaries.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 21:44:35 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Mishra", "Anshuman", ""], ["Patel", "Dhruvesh", ""], ["Vijayakumar", "Aparna", ""], ["Li", "Xiang", ""], ["Kapanipathi", "Pavan", ""], ["Talamadupula", "Kartik", ""]]}, {"id": "2009.09107", "submitter": "Tian Shi", "authors": "Tian Shi and Liuqing Li and Ping Wang and Chandan K. Reddy", "title": "A Simple and Effective Self-Supervised Contrastive Learning Framework\n  for Aspect Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised aspect detection (UAD) aims at automatically extracting\ninterpretable aspects and identifying aspect-specific segments (such as\nsentences) from online reviews. However, recent deep learning-based topic\nmodels, specifically aspect-based autoencoder, suffer from several problems,\nsuch as extracting noisy aspects and poorly mapping aspects discovered by\nmodels to the aspects of interest. To tackle these challenges, in this paper,\nwe first propose a self-supervised contrastive learning framework and an\nattention-based model equipped with a novel smooth self-attention (SSA) module\nfor the UAD task in order to learn better representations for aspects and\nreview segments. Secondly, we introduce a high-resolution selective mapping\n(HRSMap) method to efficiently assign aspects discovered by the model to\naspects of interest. We also propose using a knowledge distilling technique to\nfurther improve the aspect detection performance. Our methods outperform\nseveral recent unsupervised and weakly supervised approaches on publicly\navailable benchmark user review datasets. Aspect interpretation results show\nthat extracted aspects are meaningful, have good coverage, and can be easily\nmapped to aspects of interest. Ablation studies and attention weight\nvisualization also demonstrate the effectiveness of SSA and the knowledge\ndistilling method.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 22:13:49 GMT"}, {"version": "v2", "created": "Thu, 31 Dec 2020 04:57:28 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Shi", "Tian", ""], ["Li", "Liuqing", ""], ["Wang", "Ping", ""], ["Reddy", "Chandan K.", ""]]}, {"id": "2009.09112", "submitter": "Tian Shi", "authors": "Tian Shi and Ping Wang and Chandan K. Reddy", "title": "An Interpretable and Uncertainty Aware Multi-Task Framework for\n  Multi-Aspect Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, several online platforms have seen a rapid increase in the\nnumber of review systems that request users to provide aspect-level feedback.\nDocument-level Multi-aspect Sentiment Classification (DMSC), where the goal is\nto predict the ratings/sentiment from a review at an individual aspect level,\nhas become a challenging and imminent problem. To tackle this challenge, we\npropose a deliberate self-attention-based deep neural network model, namely\nFEDAR, for the DMSC problem, which can achieve competitive performance while\nalso being able to interpret the predictions made. FEDAR is equipped with a\nhighway word embedding layer to transfer knowledge from pre-trained word\nembeddings, an RNN encoder layer with output features enriched by pooling and\nfactorization techniques, and a deliberate self-attention layer. In addition,\nwe also propose an Attention-driven Keywords Ranking (AKR) method, which can\nautomatically discover aspect keywords and aspect-level opinion keywords from\nthe review corpus based on the attention weights. These keywords are\nsignificant for rating predictions by FEDAR. Since crowdsourcing annotation can\nbe an alternate way to recover missing ratings of reviews, we propose a\nLEcture-AuDience (LEAD) strategy to estimate model uncertainty in the context\nof multi-task learning, so that valuable human resources can focus on the most\nuncertain predictions. Our extensive set of experiments on five different\nopen-domain DMSC datasets demonstrate the superiority of the proposed FEDAR and\nLEAD models. We further introduce two new DMSC datasets in the healthcare\ndomain and benchmark different baseline models and our models on them.\nAttention weights visualization results and visualization of aspect and opinion\nkeywords demonstrate the interpretability of our model and the effectiveness of\nour AKR method.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 22:32:39 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 03:44:49 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Shi", "Tian", ""], ["Wang", "Ping", ""], ["Reddy", "Chandan K.", ""]]}, {"id": "2009.09120", "submitter": "Shih-Ting Lin", "authors": "Shih-Ting Lin and Greg Durrett", "title": "Tradeoffs in Sentence Selection Techniques for Open-Domain Question\n  Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current methods in open-domain question answering (QA) usually employ a\npipeline of first retrieving relevant documents, then applying strong reading\ncomprehension (RC) models to that retrieved text. However, modern RC models are\ncomplex and expensive to run, so techniques to prune the space of retrieved\ntext are critical to allow this approach to scale. In this paper, we focus on\napproaches which apply an intermediate sentence selection step to address this\nissue, and investigate the best practices for this approach. We describe two\ngroups of models for sentence selection: QA-based approaches, which run a\nfull-fledged QA system to identify answer candidates, and retrieval-based\nmodels, which find parts of each passage specifically related to each question.\nWe examine trade-offs between processing speed and task performance in these\ntwo approaches, and demonstrate an ensemble module that represents a hybrid of\nthe two. From experiments on Open-SQuAD and TriviaQA, we show that very\nlightweight QA models can do well at this task, but retrieval-based models are\nfaster still. An ensemble module we describe balances between the two and\ngeneralizes well cross-domain.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 23:39:15 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Lin", "Shih-Ting", ""], ["Durrett", "Greg", ""]]}, {"id": "2009.09123", "submitter": "Yuval Pinter", "authors": "Yuval Pinter, Cassandra L. Jacobs, Jacob Eisenstein", "title": "Will it Unblend?", "comments": "Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language processing systems often struggle with out-of-vocabulary\n(OOV) terms, which do not appear in training data. Blends, such as\n\"innoventor\", are one particularly challenging class of OOV, as they are formed\nby fusing together two or more bases that relate to the intended meaning in\nunpredictable manners and degrees. In this work, we run experiments on a novel\ndataset of English OOV blends to quantify the difficulty of interpreting the\nmeanings of blends by large-scale contextual language models such as BERT. We\nfirst show that BERT's processing of these blends does not fully access the\ncomponent meanings, leaving their contextual representations semantically\nimpoverished. We find this is mostly due to the loss of characters resulting\nfrom blend formation. Then, we assess how easily different models can recognize\nthe structure and recover the origin of blends, and find that context-aware\nembedding systems outperform character-level and context-free embeddings,\nalthough their results are still far from satisfactory.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2020 23:59:15 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Pinter", "Yuval", ""], ["Jacobs", "Cassandra L.", ""], ["Eisenstein", "Jacob", ""]]}, {"id": "2009.09126", "submitter": "Kai Fan Dr", "authors": "Jiayi Wang, Ke Wang, Niyu Ge, Yangbing Shi, Yu Zhao, Kai Fan", "title": "Computer Assisted Translation with Neural Quality Estimation and\n  Automatic Post-Editing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of neural machine translation, there has been a marked shift\ntowards leveraging and consuming the machine translation results. However, the\ngap between machine translation systems and human translators needs to be\nmanually closed by post-editing. In this paper, we propose an end-to-end deep\nlearning framework of the quality estimation and automatic post-editing of the\nmachine translation output. Our goal is to provide error correction suggestions\nand to further relieve the burden of human translators through an interpretable\nmodel. To imitate the behavior of human translators, we design three efficient\ndelegation modules -- quality estimation, generative post-editing, and atomic\noperation post-editing and construct a hierarchical model based on them. We\nexamine this approach with the English--German dataset from WMT 2017 APE shared\ntask and our experimental results can achieve the state-of-the-art performance.\nWe also verify that the certified translators can significantly expedite their\npost-editing processing with our model in human evaluation.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 00:29:00 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 00:23:25 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Wang", "Jiayi", ""], ["Wang", "Ke", ""], ["Ge", "Niyu", ""], ["Shi", "Yangbing", ""], ["Zhao", "Yu", ""], ["Fan", "Kai", ""]]}, {"id": "2009.09127", "submitter": "Kai Fan Dr", "authors": "Pei Zhang, Boxing Chen, Niyu Ge, Kai Fan", "title": "Long-Short Term Masking Transformer: A Simple but Effective Baseline for\n  Document-level Neural Machine Translation", "comments": "accepted to EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many document-level neural machine translation (NMT) systems have explored\nthe utility of context-aware architecture, usually requiring an increasing\nnumber of parameters and computational complexity. However, few attention is\npaid to the baseline model. In this paper, we research extensively the pros and\ncons of the standard transformer in document-level translation, and find that\nthe auto-regressive property can simultaneously bring both the advantage of the\nconsistency and the disadvantage of error accumulation. Therefore, we propose a\nsurprisingly simple long-short term masking self-attention on top of the\nstandard transformer to both effectively capture the long-range dependence and\nreduce the propagation of errors. We examine our approach on the two publicly\navailable document-level datasets. We can achieve a strong result in BLEU and\ncapture discourse phenomena.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 00:29:51 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zhang", "Pei", ""], ["Chen", "Boxing", ""], ["Ge", "Niyu", ""], ["Fan", "Kai", ""]]}, {"id": "2009.09132", "submitter": "Jieh-Sheng Lee", "authors": "Jieh-Sheng Lee and Jieh Hsiang", "title": "Prior Art Search and Reranking for Generated Patent Text", "comments": "7 pages, 3 figures, 1 table", "journal-ref": "The 2nd Workshop on Patent Text Mining and Semantic Technologies\n  (PatentSemTech2021) co-located with the 44th International ACM SIGIR\n  Conference on Research and Development in Information Retrieval", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models, such as GPT-2, have demonstrated impressive results\nrecently. A fundamental question we'd like to address is: where did the\ngenerated text come from? This work is our initial effort toward answering the\nquestion by using prior art search. The purpose of the prior art search is to\nfind the most similar prior text in the training data of GPT-2. We take a\nreranking approach and apply it to the patent domain. Specifically, we\npre-train GPT-2 models from scratch by using the patent data from the USPTO.\nThe input for the prior art search is the patent text generated by the GPT-2\nmodel. We also pre-trained BERT models from scratch for converting patent text\nto embeddings. The steps of reranking are: (1) search the most similar text in\nthe training data of GPT-2 by taking a bag-of-word ranking approach (BM25), (2)\nconvert the search results in text format to BERT embeddings, and (3) provide\nthe final result by ranking the BERT embeddings based on their similarities\nwith the patent text generated by GPT-2. The experiments in this work show that\nsuch reranking is better than ranking with embeddings alone. However, our mixed\nresults also indicate that calculating the semantic similarities among long\ntext spans is still challenging. To our knowledge, this work is the first to\nimplement a reranking system to identify retrospectively the most similar\ninputs to a GPT model based on its output.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 01:16:18 GMT"}, {"version": "v2", "created": "Sun, 18 Jul 2021 06:07:21 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Lee", "Jieh-Sheng", ""], ["Hsiang", "Jieh", ""]]}, {"id": "2009.09143", "submitter": "Sayyed Zahiri", "authors": "Yun Zhu, Sayyed M. Zahiri, Jiaqi Wang, Han-Yu Chen, Faizan Javed", "title": "Active Learning for Product Type Ontology Enhancement in E-commerce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity-based semantic search has been widely adopted in modern search engines\nto improve search accuracy by understanding users' intent. In e-commerce, an\naccurate and complete product type (PT) ontology is essential for recognizing\nproduct entities in queries and retrieving relevant products from catalog.\nHowever, finding product types (PTs) to construct such an ontology is usually\nexpensive due to the considerable amount of human efforts it may involve. In\nthis work, we propose an active learning framework that efficiently utilizes\ndomain experts' knowledge for PT discovery. We also show the quality and\ncoverage of the resulting PTs in the experiment results.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 02:21:12 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 22:41:09 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Zhu", "Yun", ""], ["Zahiri", "Sayyed M.", ""], ["Wang", "Jiaqi", ""], ["Chen", "Han-Yu", ""], ["Javed", "Faizan", ""]]}, {"id": "2009.09147", "submitter": "Xin Li", "authors": "Xin Li, Piji Li, Yan Wang, Xiaojiang Liu and Wai Lam", "title": "Enhancing Dialogue Generation via Multi-Level Contrastive Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing works for dialogue generation are data-driven models\ntrained directly on corpora crawled from websites. They mainly focus on\nimproving the model architecture to produce better responses but pay little\nattention to considering the quality of the training data contrastively. In\nthis paper, we propose a multi-level contrastive learning paradigm to model the\nfine-grained quality of the responses with respect to the query. A Rank-aware\nCalibration (RC) network is designed to construct the multi-level contrastive\noptimization objectives. Since these objectives are calculated based on the\nsentence level, which may erroneously encourage/suppress the generation of\nuninformative/informative words. To tackle this incidental issue, on one hand,\nwe design an exquisite token-level strategy for estimating the instance loss\nmore accurately. On the other hand, we build a Knowledge Inference (KI)\ncomponent to capture the keyword knowledge from the reference during training\nand exploit such information to encourage the generation of informative words.\nWe evaluate the proposed model on a carefully annotated dialogue dataset and\nthe results suggest that our model can generate more relevant and diverse\nresponses compared to the baseline models.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 02:41:04 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 13:22:06 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Li", "Xin", ""], ["Li", "Piji", ""], ["Wang", "Yan", ""], ["Liu", "Xiaojiang", ""], ["Lam", "Wai", ""]]}, {"id": "2009.09152", "submitter": "Ye Lin", "authors": "Ye Lin, Yanyang Li, Ziyang Wang, Bei Li, Quan Du, Tong Xiao, Jingbo\n  Zhu", "title": "Weight Distillation: Transferring the Knowledge in Neural Network\n  Parameters", "comments": "accepted by ACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation has been proven to be effective in model acceleration\nand compression. It allows a small network to learn to generalize in the same\nway as a large network. Recent successes in pre-training suggest the\neffectiveness of transferring model parameters. Inspired by this, we\ninvestigate methods of model acceleration and compression in another line of\nresearch. We propose Weight Distillation to transfer the knowledge in the large\nnetwork parameters through a parameter generator. Our experiments on WMT16\nEn-Ro, NIST12 Zh-En, and WMT14 En-De machine translation tasks show that weight\ndistillation can train a small network that is 1.88~2.94x faster than the large\nnetwork but with competitive performance. With the same sized small network,\nweight distillation can outperform knowledge distillation by 0.51~1.82 BLEU\npoints.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 03:23:26 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 04:22:37 GMT"}, {"version": "v3", "created": "Mon, 19 Jul 2021 04:37:21 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Lin", "Ye", ""], ["Li", "Yanyang", ""], ["Wang", "Ziyang", ""], ["Li", "Bei", ""], ["Du", "Quan", ""], ["Xiao", "Tong", ""], ["Zhu", "Jingbo", ""]]}, {"id": "2009.09154", "submitter": "Ameet Deshpande", "authors": "Raeid Saqur and Ameet Deshpande", "title": "CLEVR Parser: A Graph Parser Library for Geometric Learning on Language\n  Grounded Image Scenes", "comments": "Accepted at NLP-OSS, EMNLP 2020 (2nd Workshop for Natural Language\n  Processing Open Source Software)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CLEVR dataset has been used extensively in language grounded visual\nreasoning in Machine Learning (ML) and Natural Language Processing (NLP)\ndomains. We present a graph parser library for CLEVR, that provides\nfunctionalities for object-centric attributes and relationships extraction, and\nconstruction of structural graph representations for dual modalities.\nStructural order-invariant representations enable geometric learning and can\naid in downstream tasks like language grounding to vision, robotics,\ncompositionality, interpretability, and computational grammar construction. We\nprovide three extensible main components - parser, embedder, and visualizer\nthat can be tailored to suit specific learning setups. We also provide\nout-of-the-box functionality for seamless integration with popular deep graph\nneural network (GNN) libraries. Additionally, we discuss downstream usage and\napplications of the library, and how it accelerates research for the NLP\nresearch community.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 03:32:37 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 22:56:35 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Saqur", "Raeid", ""], ["Deshpande", "Ameet", ""]]}, {"id": "2009.09162", "submitter": "Zeqiu Wu", "authors": "Zeqiu Wu, Rik Koncel-Kedziorski, Mari Ostendorf, Hannaneh Hajishirzi", "title": "Extracting Summary Knowledge Graphs from Long Documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs capture entities and relations from long documents and can\nfacilitate reasoning in many downstream applications. Extracting compact\nknowledge graphs containing only salient entities and relations is important\nbut challenging for understanding and summarizing long documents. We introduce\na new text-to-graph task of predicting summarized knowledge graphs from long\ndocuments. We develop a dataset of 200k document/graph pairs using automatic\nand human annotations. We also develop strong baselines for this task based on\ngraph learning and text summarization, and provide quantitative and qualitative\nstudies of their effect.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 04:37:33 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 05:55:46 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Wu", "Zeqiu", ""], ["Koncel-Kedziorski", "Rik", ""], ["Ostendorf", "Mari", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "2009.09173", "submitter": "Hao Fei", "authors": "Bobo Li and Hao Fei and Yafeng Ren and Donghong Ji", "title": "Nominal Compound Chain Extraction: A New Task for Semantic-enriched\n  Lexical Chain", "comments": "accepted at NLPCC2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexical chain consists of cohesion words in a document, which implies the\nunderlying structure of a text, and thus facilitates downstream NLP tasks.\nNevertheless, existing work focuses on detecting the simple surface lexicons\nwith shallow syntax associations, ignoring the semantic-aware lexical compounds\nas well as the latent semantic frames, (e.g., topic), which can be much more\ncrucial for real-world NLP applications. In this paper, we introduce a novel\ntask, Nominal Compound Chain Extraction (NCCE), extracting and clustering all\nthe nominal compounds that share identical semantic topics. In addition, we\nmodel the task as a two-stage prediction (i.e., compound extraction and chain\ndetection), which is handled via a proposed joint framework. The model employs\nthe BERT encoder to yield contextualized document representation. Also, HowNet\nis exploited as external resources for offering rich sememe information. The\nexperiments are based on our manually annotated corpus, and the results prove\nthe necessity of the NCCE task as well as the effectiveness of our joint\napproach.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 06:20:37 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Li", "Bobo", ""], ["Fei", "Hao", ""], ["Ren", "Yafeng", ""], ["Ji", "Donghong", ""]]}, {"id": "2009.09174", "submitter": "Hao Fei", "authors": "Shengqiong Wu and Hao Fei and Donghong Ji", "title": "Aggressive Language Detection with Joint Text Normalization via\n  Adversarial Multi-task Learning", "comments": "accepted at NLPCC2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aggressive language detection (ALD), detecting the abusive and offensive\nlanguage in texts, is one of the crucial applications in NLP community. Most\nexisting works treat ALD as regular classification with neural models, while\nignoring the inherent conflicts of social media text that they are quite\nunnormalized and irregular. In this work, we target improving the ALD by\njointly performing text normalization (TN), via an adversarial multi-task\nlearning framework. The private encoders for ALD and TN focus on the\ntask-specific features retrieving, respectively, and the shared encoder learns\nthe underlying common features over two tasks. During adversarial training, a\ntask discriminator distinguishes the separate learning of ALD or TN.\nExperimental results on four ALD datasets show that our model outperforms all\nbaselines under differing settings by large margins, demonstrating the\nnecessity of joint learning the TN with ALD. Further analysis is conducted for\na better understanding of our method.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 06:26:07 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Wu", "Shengqiong", ""], ["Fei", "Hao", ""], ["Ji", "Donghong", ""]]}, {"id": "2009.09191", "submitter": "Fanchao Qi", "authors": "Guoyang Zeng, Fanchao Qi, Qianrui Zhou, Tingji Zhang, Bairu Hou, Yuan\n  Zang, Zhiyuan Liu, Maosong Sun", "title": "OpenAttack: An Open-source Textual Adversarial Attack Toolkit", "comments": "Work in progress, 8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Textual adversarial attacking has received wide and increasing attention in\nrecent years. Various attack models have been proposed, which are enormously\ndistinct and implemented with different programming frameworks and settings.\nThese facts hinder quick utilization and apt comparison of attack models. In\nthis paper, we present an open-source textual adversarial attack toolkit named\nOpenAttack. It currently builds in 12 typical attack models that cover all the\nattack types. Its highly inclusive modular design not only supports quick\nutilization of existing attack models, but also enables great flexibility and\nextensibility. OpenAttack has broad uses including comparing and evaluating\nattack models, measuring robustness of a victim model, assisting in developing\nnew attack models, and adversarial training. Source code, built-in models and\ndocumentation can be obtained at https://github.com/thunlp/OpenAttack.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 09:02:56 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zeng", "Guoyang", ""], ["Qi", "Fanchao", ""], ["Zhou", "Qianrui", ""], ["Zhang", "Tingji", ""], ["Hou", "Bairu", ""], ["Zang", "Yuan", ""], ["Liu", "Zhiyuan", ""], ["Sun", "Maosong", ""]]}, {"id": "2009.09192", "submitter": "Fanchao Qi", "authors": "Yuan Zang, Bairu Hou, Fanchao Qi, Zhiyuan Liu, Xiaojun Meng, Maosong\n  Sun", "title": "Learning to Attack: Towards Textual Adversarial Attacking in Real-world\n  Situations", "comments": "work in progress, 10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacking aims to fool deep neural networks with adversarial\nexamples. In the field of natural language processing, various textual\nadversarial attack models have been proposed, varying in the accessibility to\nthe victim model. Among them, the attack models that only require the output of\nthe victim model are more fit for real-world situations of adversarial\nattacking. However, to achieve high attack performance, these models usually\nneed to query the victim model too many times, which is neither efficient nor\nviable in practice. To tackle this problem, we propose a reinforcement learning\nbased attack model, which can learn from attack history and launch attacks more\nefficiently. In experiments, we evaluate our model by attacking several\nstate-of-the-art models on the benchmark datasets of multiple tasks including\nsentiment analysis, text classification and natural language inference.\nExperimental results demonstrate that our model consistently achieves both\nbetter attack performance and higher efficiency than recently proposed baseline\nmethods. We also find our attack model can bring more robustness improvement to\nthe victim model by adversarial training. All the code and data of this paper\nwill be made public.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 09:12:24 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zang", "Yuan", ""], ["Hou", "Bairu", ""], ["Qi", "Fanchao", ""], ["Liu", "Zhiyuan", ""], ["Meng", "Xiaojun", ""], ["Sun", "Maosong", ""]]}, {"id": "2009.09223", "submitter": "Usman Naseem", "authors": "Usman Naseem, Matloob Khushi, Vinay Reddy, Sakthivel Rajendran, Imran\n  Razzak, Jinman Kim", "title": "BioALBERT: A Simple and Effective Pre-trained Language Model for\n  Biomedical Named Entity Recognition", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, with the growing amount of biomedical documents, coupled\nwith advancement in natural language processing algorithms, the research on\nbiomedical named entity recognition (BioNER) has increased exponentially.\nHowever, BioNER research is challenging as NER in the biomedical domain are:\n(i) often restricted due to limited amount of training data, (ii) an entity can\nrefer to multiple types and concepts depending on its context and, (iii) heavy\nreliance on acronyms that are sub-domain specific. Existing BioNER approaches\noften neglect these issues and directly adopt the state-of-the-art (SOTA)\nmodels trained in general corpora which often yields unsatisfactory results. We\npropose biomedical ALBERT (A Lite Bidirectional Encoder Representations from\nTransformers for Biomedical Text Mining) bioALBERT, an effective\ndomain-specific language model trained on large-scale biomedical corpora\ndesigned to capture biomedical context-dependent NER. We adopted a\nself-supervised loss used in ALBERT that focuses on modelling inter-sentence\ncoherence to better learn context-dependent representations and incorporated\nparameter reduction techniques to lower memory consumption and increase the\ntraining speed in BioNER. In our experiments, BioALBERT outperformed\ncomparative SOTA BioNER models on eight biomedical NER benchmark datasets with\nfour different entity types. We trained four different variants of BioALBERT\nmodels which are available for the research community to be used in future\nresearch.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 12:58:47 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Naseem", "Usman", ""], ["Khushi", "Matloob", ""], ["Reddy", "Vinay", ""], ["Rajendran", "Sakthivel", ""], ["Razzak", "Imran", ""], ["Kim", "Jinman", ""]]}, {"id": "2009.09226", "submitter": "Chaojun Xiao", "authors": "Zheni Zeng, Chaojun Xiao, Yuan Yao, Ruobing Xie, Zhiyuan Liu, Fen Lin,\n  Leyu Lin and Maosong Sun", "title": "Knowledge Transfer via Pre-training for Recommendation: A Review and\n  Prospect", "comments": "This paper is submitted to Frontiers in Big Data and is under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems aim to provide item recommendations for users, and are\nusually faced with data sparsity problem (e.g., cold start) in real-world\nscenarios. Recently pre-trained models have shown their effectiveness in\nknowledge transfer between domains and tasks, which can potentially alleviate\nthe data sparsity problem in recommender systems. In this survey, we first\nprovide a review of recommender systems with pre-training. In addition, we show\nthe benefits of pre-training to recommender systems through experiments.\nFinally, we discuss several promising directions for future research for\nrecommender systems with pre-training.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 13:06:27 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zeng", "Zheni", ""], ["Xiao", "Chaojun", ""], ["Yao", "Yuan", ""], ["Xie", "Ruobing", ""], ["Liu", "Zhiyuan", ""], ["Lin", "Fen", ""], ["Lin", "Leyu", ""], ["Sun", "Maosong", ""]]}, {"id": "2009.09241", "submitter": "Bai Li", "authors": "Bai Li, Guillaume Thomas, Yang Xu, Frank Rudzicz", "title": "Word class flexibility: A deep contextualized approach", "comments": "To appear in EMNLP 2020 (Long Paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word class flexibility refers to the phenomenon whereby a single word form is\nused across different grammatical categories. Extensive work in linguistic\ntypology has sought to characterize word class flexibility across languages,\nbut quantifying this phenomenon accurately and at scale has been fraught with\ndifficulties. We propose a principled methodology to explore regularity in word\nclass flexibility. Our method builds on recent work in contextualized word\nembeddings to quantify semantic shift between word classes (e.g., noun-to-verb,\nverb-to-noun), and we apply this method to 37 languages. We find that\ncontextualized embeddings not only capture human judgment of class variation\nwithin words in English, but also uncover shared tendencies in class\nflexibility across languages. Specifically, we find greater semantic variation\nwhen flexible lemmas are used in their dominant word class, supporting the view\nthat word class flexibility is a directional process. Our work highlights the\nutility of deep contextualized models in linguistic typology.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 14:41:50 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Li", "Bai", ""], ["Thomas", "Guillaume", ""], ["Xu", "Yang", ""], ["Rudzicz", "Frank", ""]]}, {"id": "2009.09290", "submitter": "Gabriela Surita", "authors": "Gabriela Surita, Rodrigo Nogueira, Roberto Lotufo", "title": "Can questions summarize a corpus? Using question generation for\n  characterizing COVID-19 research", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What are the latent questions on some textual data? In this work, we\ninvestigate using question generation models for exploring a collection of\ndocuments. Our method, dubbed corpus2question, consists of applying a\npre-trained question generation model over a corpus and aggregating the\nresulting questions by frequency and time. This technique is an alternative to\nmethods such as topic modelling and word cloud for summarizing large amounts of\ntextual data. Results show that applying corpus2question on a corpus of\nscientific articles related to COVID-19 yields relevant questions about the\ntopic. The most frequent questions are \"what is covid 19\" and \"what is the\ntreatment for covid\". Among the 1000 most frequent questions are \"what is the\nthreshold for herd immunity\" and \"what is the role of ace2 in viral entry\". We\nshow that the proposed method generated similar questions for 13 of the 27\nexpert-made questions from the CovidQA question answering dataset.\n  The code to reproduce our experiments and the generated questions are\navailable at: https://github.com/unicamp-dl/corpus2question\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 19:57:44 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Surita", "Gabriela", ""], ["Nogueira", "Rodrigo", ""], ["Lotufo", "Roberto", ""]]}, {"id": "2009.09309", "submitter": "Fajri Koto", "authors": "Fajri Koto, Ikhwan Koto", "title": "Towards Computational Linguistics in Minangkabau Language: Studies on\n  Sentiment Analysis and Machine Translation", "comments": "Accepted at PACLIC 2020 - The 34th Pacific Asia Conference on\n  Language, Information and Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although some linguists (Rusmali et al., 1985; Crouch, 2009) have fairly\nattempted to define the morphology and syntax of Minangkabau, information\nprocessing in this language is still absent due to the scarcity of the\nannotated resource. In this work, we release two Minangkabau corpora: sentiment\nanalysis and machine translation that are harvested and constructed from\nTwitter and Wikipedia. We conduct the first computational linguistics in\nMinangkabau language employing classic machine learning and\nsequence-to-sequence models such as LSTM and Transformer. Our first experiments\nshow that the classification performance over Minangkabau text significantly\ndrops when tested with the model trained in Indonesian. Whereas, in the machine\ntranslation experiment, a simple word-to-word translation using a bilingual\ndictionary outperforms LSTM and Transformer model in terms of BLEU score.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2020 22:13:27 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Koto", "Fajri", ""], ["Koto", "Ikhwan", ""]]}, {"id": "2009.09335", "submitter": "Kung-Hsiang Huang", "authors": "Kung-Hsiang Huang, Mu Yang, Nanyun Peng", "title": "Biomedical Event Extraction with Hierarchical Knowledge Graphs", "comments": "8 pages, 3 figures, Findings of EMNLP 2020 (short)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biomedical event extraction is critical in understanding biomolecular\ninteractions described in scientific corpus. One of the main challenges is to\nidentify nested structured events that are associated with non-indicative\ntrigger words. We propose to incorporate domain knowledge from Unified Medical\nLanguage System (UMLS) to a pre-trained language model via Graph\nEdge-conditioned Attention Networks (GEANet) and hierarchical graph\nrepresentation. To better recognize the trigger words, each sentence is first\ngrounded to a sentence graph based on a jointly modeled hierarchical knowledge\ngraph from UMLS. The grounded graphs are then propagated by GEANet, a novel\ngraph neural networks for enhanced capabilities in inferring complex events. On\nBioNLP 2011 GENIA Event Extraction task, our approach achieved 1.41% F1 and\n3.19% F1 improvements on all events and complex events, respectively. Ablation\nstudies confirm the importance of GEANet and hierarchical KG.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 02:25:05 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 18:09:50 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 16:38:31 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Huang", "Kung-Hsiang", ""], ["Yang", "Mu", ""], ["Peng", "Nanyun", ""]]}, {"id": "2009.09359", "submitter": "Rifat Shahriyar", "authors": "Tahmid Hasan, Abhik Bhattacharjee, Kazi Samin, Masum Hasan, Madhusudan\n  Basak, M. Sohel Rahman, Rifat Shahriyar", "title": "Not Low-Resource Anymore: Aligner Ensembling, Batch Filtering, and New\n  Datasets for Bengali-English Machine Translation", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite being the seventh most widely spoken language in the world, Bengali\nhas received much less attention in machine translation literature due to being\nlow in resources. Most publicly available parallel corpora for Bengali are not\nlarge enough; and have rather poor quality, mostly because of incorrect\nsentence alignments resulting from erroneous sentence segmentation, and also\nbecause of a high volume of noise present in them. In this work, we build a\ncustomized sentence segmenter for Bengali and propose two novel methods for\nparallel corpus creation on low-resource setups: aligner ensembling and batch\nfiltering. With the segmenter and the two methods combined, we compile a\nhigh-quality Bengali-English parallel corpus comprising of 2.75 million\nsentence pairs, more than 2 million of which were not available before.\nTraining on neural models, we achieve an improvement of more than 9 BLEU score\nover previous approaches to Bengali-English machine translation. We also\nevaluate on a new test set of 1000 pairs made with extensive quality control.\nWe release the segmenter, parallel corpus, and the evaluation set, thus\nelevating Bengali from its low-resource status. To the best of our knowledge,\nthis is the first ever large scale study on Bengali-English machine\ntranslation. We believe our study will pave the way for future research on\nBengali-English machine translation as well as other low-resource languages.\nOur data and code are available at https://github.com/csebuetnlp/banglanmt.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 06:06:27 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 05:33:13 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Hasan", "Tahmid", ""], ["Bhattacharjee", "Abhik", ""], ["Samin", "Kazi", ""], ["Hasan", "Masum", ""], ["Basak", "Madhusudan", ""], ["Rahman", "M. Sohel", ""], ["Shahriyar", "Rifat", ""]]}, {"id": "2009.09363", "submitter": "Zhaofeng Wu", "authors": "Zhaofeng Wu, Matt Gardner", "title": "Understanding Mention Detector-Linker Interaction for Neural Coreference\n  Resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coreference resolution is an important task for discourse-level natural\nlanguage understanding. However, despite significant recent progress, the\nquality of current state-of-the-art systems still considerably trails behind\nhuman-level performance. Using the CoNLL-2012 and PreCo datasets, we dissect\nthe best instantiation of the mainstream end-to-end coreference resolution\nmodel that underlies most current best-performing coreference systems, and\nempirically analyze the behavior of its two components: the mention detector\nand mention linker. While the detector traditionally focuses heavily on recall\nas a design decision, we demonstrate the importance of precision, calling for\ntheir balance. However, we point out the difficulty in building a precise\ndetector due to its inability to make important anaphoricity decisions. We also\nhighlight the enormous room for improving the linker and that the rest of its\nerrors mainly involve pronoun resolution. We hope our findings will help future\nresearch in building coreference resolution systems.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 06:30:45 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Wu", "Zhaofeng", ""], ["Gardner", "Matt", ""]]}, {"id": "2009.09372", "submitter": "Prasanna Raj Noel Dabre", "authors": "Raj Dabre and Atsushi Fujita", "title": "Softmax Tempering for Training Neural Machine Translation Models", "comments": "The paper is about prediction smoothing for improving sequence to\n  sequence performance. Related to but not the same as label smoothing. Work in\n  progress. Updates with deeper analyses and comparisons to related methods to\n  follow. Rejected from EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) models are typically trained using a softmax\ncross-entropy loss where the softmax distribution is compared against smoothed\ngold labels. In low-resource scenarios, NMT models tend to over-fit because the\nsoftmax distribution quickly approaches the gold label distribution. To address\nthis issue, we propose to divide the logits by a temperature coefficient, prior\nto applying softmax, during training. In our experiments on 11 language pairs\nin the Asian Language Treebank dataset and the WMT 2019 English-to-German\ntranslation task, we observed significant improvements in translation quality\nby up to 3.9 BLEU points. Furthermore, softmax tempering makes the greedy\nsearch to be as good as beam search decoding in terms of translation quality,\nenabling 1.5 to 3.5 times speed-up. We also study the impact of softmax\ntempering on multilingual NMT and recurrently stacked NMT, both of which aim to\nreduce the NMT model size by parameter sharing thereby verifying the utility of\ntemperature in developing compact NMT models. Finally, an analysis of softmax\nentropies and gradients reveal the impact of our method on the internal\nbehavior of NMT models.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 07:06:22 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Dabre", "Raj", ""], ["Fujita", "Atsushi", ""]]}, {"id": "2009.09378", "submitter": "Chujie Zheng", "authors": "Chujie Zheng, Yunbo Cao, Daxin Jiang, Minlie Huang", "title": "Difference-aware Knowledge Selection for Knowledge-grounded Conversation\n  Generation", "comments": "Accepted to Findings of EMNLP 2020 (Long Paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a multi-turn knowledge-grounded dialog, the difference between the\nknowledge selected at different turns usually provides potential clues to\nknowledge selection, which has been largely neglected in previous research. In\nthis paper, we propose a difference-aware knowledge selection method. It first\ncomputes the difference between the candidate knowledge sentences provided at\nthe current turn and those chosen in the previous turns. Then, the differential\ninformation is fused with or disentangled from the contextual information to\nfacilitate final knowledge selection. Automatic, human observational, and\ninteractive evaluation shows that our method is able to select knowledge more\naccurately and generate more informative responses, significantly outperforming\nthe state-of-the-art baselines. The codes are available at\nhttps://github.com/chujiezheng/DiffKS.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 07:47:26 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Zheng", "Chujie", ""], ["Cao", "Yunbo", ""], ["Jiang", "Daxin", ""], ["Huang", "Minlie", ""]]}, {"id": "2009.09417", "submitter": "Byung-Ju Choi", "authors": "Byung-Ju Choi, Jimin Hong, David Keetae Park, Sang Wan Lee", "title": "F^2-Softmax: Diversifying Neural Text Generation via Frequency\n  Factorized Softmax", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent advances in neural text generation, encoding the rich\ndiversity in human language remains elusive. We argue that the sub-optimal text\ngeneration is mainly attributable to the imbalanced token distribution, which\nparticularly misdirects the learning model when trained with the\nmaximum-likelihood objective. As a simple yet effective remedy, we propose two\nnovel methods, F^2-Softmax and MefMax, for a balanced training even with the\nskewed frequency distribution. MefMax assigns tokens uniquely to frequency\nclasses, trying to group tokens with similar frequencies and equalize frequency\nmass between the classes. F^2-Softmax then decomposes a probability\ndistribution of the target token into a product of two conditional\nprobabilities of (i) frequency class, and (ii) token from the target frequency\nclass. Models learn more uniform probability distributions because they are\nconfined to subsets of vocabularies. Significant performance gains on seven\nrelevant metrics suggest the supremacy of our approach in improving not only\nthe diversity but also the quality of generated texts.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 12:03:58 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 08:46:58 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Choi", "Byung-Ju", ""], ["Hong", "Jimin", ""], ["Park", "David Keetae", ""], ["Lee", "Sang Wan", ""]]}, {"id": "2009.09427", "submitter": "Rongsheng Zhang", "authors": "Rongsheng Zhang, Yinhe Zheng, Jianzhi Shao, Xiaoxi Mao, Yadong Xi,\n  Minlie Huang", "title": "Dialogue Distillation: Open-Domain Dialogue Augmentation Using Unpaired\n  Data", "comments": "accepted as long paper by emnlp2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in open-domain dialogue systems rely on the success of neural\nmodels that are trained on large-scale data. However, collecting large-scale\ndialogue data is usually time-consuming and labor-intensive. To address this\ndata dilemma, we propose a novel data augmentation method for training\nopen-domain dialogue models by utilizing unpaired data. Specifically, a\ndata-level distillation process is first proposed to construct augmented\ndialogues where both post and response are retrieved from the unpaired data. A\nranking module is employed to filter out low-quality dialogues. Further, a\nmodel-level distillation process is employed to distill a teacher model trained\non high-quality paired data to augmented dialogue pairs, thereby preventing\ndialogue models from being affected by the noise in the augmented data.\nAutomatic and manual evaluation indicates that our method can produce\nhigh-quality dialogue pairs with diverse contents, and the proposed data-level\nand model-level dialogue distillation can improve the performance of\ncompetitive baselines.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 13:06:38 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 08:50:49 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Zhang", "Rongsheng", ""], ["Zheng", "Yinhe", ""], ["Shao", "Jianzhi", ""], ["Mao", "Xiaoxi", ""], ["Xi", "Yadong", ""], ["Huang", "Minlie", ""]]}, {"id": "2009.09435", "submitter": "Francisco Vargas", "authors": "Francisco Vargas and Ryan Cotterell", "title": "Exploring the Linear Subspace Hypothesis in Gender Bias Mitigation", "comments": null, "journal-ref": "Proceedings of the 2020 Conference on Empirical Methods in Natural\n  Language Processing", "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bolukbasi et al. (2016) presents one of the first gender bias mitigation\ntechniques for word embeddings. Their method takes pre-trained word embeddings\nas input and attempts to isolate a linear subspace that captures most of the\ngender bias in the embeddings. As judged by an analogical evaluation task,\ntheir method virtually eliminates gender bias in the embeddings. However, an\nimplicit and untested assumption of their method is that the bias sub-space is\nactually linear. In this work, we generalize their method to a kernelized,\nnon-linear version. We take inspiration from kernel principal component\nanalysis and derive a non-linear bias isolation technique. We discuss and\novercome some of the practical drawbacks of our method for non-linear gender\nbias mitigation in word embeddings and analyze empirically whether the bias\nsubspace is actually linear. Our analysis shows that gender bias is in fact\nwell captured by a linear subspace, justifying the assumption of Bolukbasi et\nal. (2016).\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 14:13:45 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 12:11:40 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Vargas", "Francisco", ""], ["Cotterell", "Ryan", ""]]}, {"id": "2009.09474", "submitter": "Ehsan Doostmohammadi", "authors": "Ehsan Doostmohammadi, Minoo Nassajian, Adel Rahimi", "title": "Persian Ezafe Recognition Using Transformers and Its Role in\n  Part-Of-Speech Tagging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ezafe is a grammatical particle in some Iranian languages that links two\nwords together. Regardless of the important information it conveys, it is\nalmost always not indicated in Persian script, resulting in mistakes in reading\ncomplex sentences and errors in natural language processing tasks. In this\npaper, we experiment with different machine learning methods to achieve\nstate-of-the-art results in the task of ezafe recognition. Transformer-based\nmethods, BERT and XLMRoBERTa, achieve the best results, the latter achieving\n2.68% F1-score more than the previous state-of-the-art. We, moreover, use ezafe\ninformation to improve Persian part-of-speech tagging results and show that\nsuch information will not be useful to transformer-based methods and explain\nwhy that might be the case.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 17:01:43 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 19:52:11 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Doostmohammadi", "Ehsan", ""], ["Nassajian", "Minoo", ""], ["Rahimi", "Adel", ""]]}, {"id": "2009.09509", "submitter": "Shweta Yadav Shweta", "authors": "Shweta Yadav, Srivatsa Ramesh, Sriparna Saha, and Asif Ekbal", "title": "Relation Extraction from Biomedical and Clinical Text: Unified Multitask\n  Learning Framework", "comments": "Accepted for publication at IEEE/ACM Transaction on Computational\n  Biology and Bioinformatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To minimize the accelerating amount of time invested in the biomedical\nliterature search, numerous approaches for automated knowledge extraction have\nbeen proposed. Relation extraction is one such task where semantic relations\nbetween the entities are identified from the free text. In the biomedical\ndomain, extraction of regulatory pathways, metabolic processes, adverse drug\nreaction or disease models necessitates knowledge from the individual\nrelations, for example, physical or regulatory interactions between genes,\nproteins, drugs, chemical, disease or phenotype. In this paper, we study the\nrelation extraction task from three major biomedical and clinical tasks, namely\ndrug-drug interaction, protein-protein interaction, and medical concept\nrelation extraction. Towards this, we model the relation extraction problem in\nmulti-task learning (MTL) framework and introduce for the first time the\nconcept of structured self-attentive network complemented with the adversarial\nlearning approach for the prediction of relationships from the biomedical and\nclinical text. The fundamental notion of MTL is to simultaneously learn\nmultiple problems together by utilizing the concepts of the shared\nrepresentation. Additionally, we also generate the highly efficient single task\nmodel which exploits the shortest dependency path embedding learned over the\nattentive gated recurrent unit to compare our proposed MTL models. The\nframework we propose significantly improves overall the baselines (deep\nlearning techniques) and single-task models for predicting the relationships,\nwithout compromising on the performance of all the tasks.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 19:50:28 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Yadav", "Shweta", ""], ["Ramesh", "Srivatsa", ""], ["Saha", "Sriparna", ""], ["Ekbal", "Asif", ""]]}, {"id": "2009.09568", "submitter": "Su Zhu", "authors": "Su Zhu, Ruisheng Cao, Lu Chen and Kai Yu", "title": "Vector Projection Network for Few-shot Slot Tagging in Natural Language\n  Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot slot tagging becomes appealing for rapid domain transfer and\nadaptation, motivated by the tremendous development of conversational dialogue\nsystems. In this paper, we propose a vector projection network for few-shot\nslot tagging, which exploits projections of contextual word embeddings on each\ntarget label vector as word-label similarities. Essentially, this approach is\nequivalent to a normalized linear model with an adaptive bias. The contrastive\nexperiment demonstrates that our proposed vector projection based similarity\nmetric can significantly surpass other variants. Specifically, in the five-shot\nsetting on benchmarks SNIPS and NER, our method outperforms the strongest\nfew-shot learning baseline by $6.30$ and $13.79$ points on F$_1$ score,\nrespectively. Our code will be released at\nhttps://github.com/sz128/few_shot_slot_tagging_and_NER.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 01:52:32 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 07:48:21 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Zhu", "Su", ""], ["Cao", "Ruisheng", ""], ["Chen", "Lu", ""], ["Yu", "Kai", ""]]}, {"id": "2009.09587", "submitter": "Jiwei Li", "authors": "Jiawei Wu, Xiaoya Li, Xiang Ao, Yuxian Meng, Fei Wu and Jiwei Li", "title": "Improving Robustness and Generality of NLP Models Using Disentangled\n  Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised neural networks, which first map an input $x$ to a single\nrepresentation $z$, and then map $z$ to the output label $y$, have achieved\nremarkable success in a wide range of natural language processing (NLP) tasks.\nDespite their success, neural models lack for both robustness and generality:\nsmall perturbations to inputs can result in absolutely different outputs; the\nperformance of a model trained on one domain drops drastically when tested on\nanother domain.\n  In this paper, we present methods to improve robustness and generality of NLP\nmodels from the standpoint of disentangled representation learning. Instead of\nmapping $x$ to a single representation $z$, the proposed strategy maps $x$ to a\nset of representations $\\{z_1,z_2,...,z_K\\}$ while forcing them to be\ndisentangled. These representations are then mapped to different logits $l$s,\nthe ensemble of which is used to make the final prediction $y$. We propose\ndifferent methods to incorporate this idea into currently widely-used models,\nincluding adding an $L$2 regularizer on $z$s or adding Total Correlation (TC)\nunder the framework of variational information bottleneck (VIB). We show that\nmodels trained with the proposed criteria provide better robustness and domain\nadaptation ability in a wide range of supervised learning tasks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 02:48:46 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Wu", "Jiawei", ""], ["Li", "Xiaoya", ""], ["Ao", "Xiang", ""], ["Meng", "Yuxian", ""], ["Wu", "Fei", ""], ["Li", "Jiwei", ""]]}, {"id": "2009.09600", "submitter": "Shweta Yadav Shweta", "authors": "Shweta Yadav, Joy Prakash Sain, Amit Sheth, Asif Ekbal, Sriparna Saha,\n  Pushpak Bhattacharyya", "title": "Assessing the Severity of Health States based on Social Media Posts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The unprecedented growth of Internet users has resulted in an abundance of\nunstructured information on social media including health forums, where\npatients request health-related information or opinions from other users.\nPrevious studies have shown that online peer support has limited effectiveness\nwithout expert intervention. Therefore, a system capable of assessing the\nseverity of health state from the patients' social media posts can help health\nprofessionals (HP) in prioritizing the user's post. In this study, we inspect\nthe efficacy of different aspects of Natural Language Understanding (NLU) to\nidentify the severity of the user's health state in relation to two\nperspectives(tasks) (a) Medical Condition (i.e., Recover, Exist, Deteriorate,\nOther) and (b) Medication (i.e., Effective, Ineffective, Serious Adverse\nEffect, Other) in online health communities. We propose a multiview learning\nframework that models both the textual content as well as\ncontextual-information to assess the severity of the user's health state.\nSpecifically, our model utilizes the NLU views such as sentiment, emotions,\npersonality, and use of figurative language to extract the contextual\ninformation. The diverse NLU views demonstrate its effectiveness on both the\ntasks and as well as on the individual disease to assess a user's health.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 03:45:14 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Yadav", "Shweta", ""], ["Sain", "Joy Prakash", ""], ["Sheth", "Amit", ""], ["Ekbal", "Asif", ""], ["Saha", "Sriparna", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "2009.09609", "submitter": "Shamik Roy", "authors": "Shamik Roy, Dan Goldwasser", "title": "Weakly Supervised Learning of Nuanced Frames for Analyzing Polarization\n  in News Media", "comments": "19 pages, 6 figures, Will appear in EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we suggest a minimally-supervised approach for identifying\nnuanced frames in news article coverage of politically divisive topics. We\nsuggest to break the broad policy frames suggested by Boydstun et al., 2014\ninto fine-grained subframes which can capture differences in political ideology\nin a better way. We evaluate the suggested subframes and their embedding,\nlearned using minimal supervision, over three topics, namely, immigration,\ngun-control and abortion. We demonstrate the ability of the subframes to\ncapture ideological differences and analyze political discourse in news media.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 04:29:54 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Roy", "Shamik", ""], ["Goldwasser", "Dan", ""]]}, {"id": "2009.09629", "submitter": "Wenliang Dai", "authors": "Wenliang Dai, Zihan Liu, Tiezheng Yu and Pascale Fung", "title": "Modality-Transferable Emotion Embeddings for Low-Resource Multimodal\n  Emotion Recognition", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the recent achievements made in the multi-modal emotion recognition\ntask, two problems still exist and have not been well investigated: 1) the\nrelationship between different emotion categories are not utilized, which leads\nto sub-optimal performance; and 2) current models fail to cope well with\nlow-resource emotions, especially for unseen emotions. In this paper, we\npropose a modality-transferable model with emotion embeddings to tackle the\naforementioned issues. We use pre-trained word embeddings to represent emotion\ncategories for textual data. Then, two mapping functions are learned to\ntransfer these embeddings into visual and acoustic spaces. For each modality,\nthe model calculates the representation distance between the input sequence and\ntarget emotions and makes predictions based on the distances. By doing so, our\nmodel can directly adapt to the unseen emotions in any modality since we have\ntheir pre-trained embeddings and modality mapping functions. Experiments show\nthat our model achieves state-of-the-art performance on most of the emotion\ncategories. In addition, our model also outperforms existing baselines in the\nzero-shot and few-shot scenarios for unseen emotions.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 06:10:39 GMT"}, {"version": "v2", "created": "Sat, 26 Sep 2020 07:29:25 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 05:09:31 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Dai", "Wenliang", ""], ["Liu", "Zihan", ""], ["Yu", "Tiezheng", ""], ["Fung", "Pascale", ""]]}, {"id": "2009.09654", "submitter": "Quanyu Long", "authors": "Quanyu Long, Mingxuan Wang, Lei Li", "title": "Generative Imagination Elevates Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are common semantics shared across text and images. Given a sentence in\na source language, whether depicting the visual scene helps translation into a\ntarget language? Existing multimodal neural machine translation methods (MNMT)\nrequire triplets of bilingual sentence - image for training and tuples of\nsource sentence - image for inference. In this paper, we propose ImagiT, a\nnovel machine translation method via visual imagination. ImagiT first learns to\ngenerate visual representation from the source sentence, and then utilizes both\nsource sentence and the \"imagined representation\" to produce a target\ntranslation. Unlike previous methods, it only needs the source sentence at the\ninference time. Experiments demonstrate that ImagiT benefits from visual\nimagination and significantly outperforms the text-only neural machine\ntranslation baselines. Further analysis reveals that the imagination process in\nImagiT helps fill in missing information when performing the degradation\nstrategy.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 07:44:04 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 03:02:15 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Long", "Quanyu", ""], ["Wang", "Mingxuan", ""], ["Li", "Lei", ""]]}, {"id": "2009.09672", "submitter": "Zewei Sun", "authors": "Zewei Sun, Shujian Huang, Xinyu Dai, Jiajun Chen", "title": "Alleviating the Inequality of Attention Heads for Neural Machine\n  Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies show that the attention heads in Transformer are not equal. We\nrelate this phenomenon to the imbalance training of multi-head attention and\nthe model dependence on specific heads. To tackle this problem, we propose a\nsimple masking method: HeadMask, in two specific ways. Experiments show that\ntranslation improvements are achieved on multiple language pairs. Subsequent\nempirical analyses also support our assumption and confirm the effectiveness of\nthe method.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 08:14:30 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Sun", "Zewei", ""], ["Huang", "Shujian", ""], ["Dai", "Xinyu", ""], ["Chen", "Jiajun", ""]]}, {"id": "2009.09679", "submitter": "Hideyuki Tachibana", "authors": "Hideyuki Tachibana, Yotaro Katayama", "title": "Accent Estimation of Japanese Words from Their Surfaces and\n  Romanizations for Building Large Vocabulary Accent Dictionaries", "comments": "7 pages, 2 figures. IEEE ICASSP 2020", "journal-ref": "Proc. ICASSP (2020) 8059-8063", "doi": "10.1109/ICASSP40776.2020.9054081", "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Japanese text-to-speech (TTS), it is necessary to add accent information\nto the input sentence. However, there are a limited number of publicly\navailable accent dictionaries, and those dictionaries e.g. UniDic, do not\ncontain many compound words, proper nouns, etc., which are required in a\npractical TTS system. In order to build a large scale accent dictionary that\ncontains those words, the authors developed an accent estimation technique that\npredicts the accent of a word from its limited information, namely the surface\n(e.g. kanji) and the yomi (simplified phonetic information). It is\nexperimentally shown that the technique can estimate accents with high\naccuracies, especially for some categories of words. The authors applied this\ntechnique to an existing large vocabulary Japanese dictionary NEologd, and\nobtained a large vocabulary Japanese accent dictionary. Many cases have been\nobserved in which the use of this dictionary yields more appropriate phonetic\ninformation than UniDic.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 08:38:21 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Tachibana", "Hideyuki", ""], ["Katayama", "Yotaro", ""]]}, {"id": "2009.09680", "submitter": "Haoyu Song", "authors": "Haoyu Song, Yan Wang, Wei-Nan Zhang, Zhengyu Zhao, Ting Liu, Xiaojiang\n  Liu", "title": "Profile Consistency Identification for Open-domain Dialogue Agents", "comments": "EMNLP20", "journal-ref": null, "doi": "10.18653/v1/2020.emnlp-main.539", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maintaining a consistent attribute profile is crucial for dialogue agents to\nnaturally converse with humans. Existing studies on improving attribute\nconsistency mainly explored how to incorporate attribute information in the\nresponses, but few efforts have been made to identify the consistency relations\nbetween response and attribute profile. To facilitate the study of profile\nconsistency identification, we create a large-scale human-annotated dataset\nwith over 110K single-turn conversations and their key-value attribute\nprofiles. Explicit relation between response and profile is manually labeled.\nWe also propose a key-value structure information enriched BERT model to\nidentify the profile consistency, and it gained improvements over strong\nbaselines. Further evaluations on downstream tasks demonstrate that the profile\nconsistency identification model is conducive for improving dialogue\nconsistency.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 08:38:23 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 23:36:07 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2020 05:55:46 GMT"}, {"version": "v4", "created": "Wed, 31 Mar 2021 07:09:47 GMT"}, {"version": "v5", "created": "Mon, 17 May 2021 03:13:50 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Song", "Haoyu", ""], ["Wang", "Yan", ""], ["Zhang", "Wei-Nan", ""], ["Zhao", "Zhengyu", ""], ["Liu", "Ting", ""], ["Liu", "Xiaojiang", ""]]}, {"id": "2009.09704", "submitter": "Qianqian Dong", "authors": "Qianqian Dong, Rong Ye, Mingxuan Wang, Hao Zhou, Shuang Xu, Bo Xu, Lei\n  Li", "title": "\"Listen, Understand and Translate\": Triple Supervision Decouples\n  End-to-end Speech-to-text Translation", "comments": "Accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An end-to-end speech-to-text translation (ST) takes audio in a source\nlanguage and outputs the text in a target language. Existing methods are\nlimited by the amount of parallel corpus. Can we build a system to fully\nutilize signals in a parallel ST corpus? We are inspired by human understanding\nsystem which is composed of auditory perception and cognitive processing. In\nthis paper, we propose Listen-Understand-Translate, (LUT), a unified framework\nwith triple supervision signals to decouple the end-to-end speech-to-text\ntranslation task. LUT is able to guide the acoustic encoder to extract as much\ninformation from the auditory input. In addition, LUT utilizes a pre-trained\nBERT model to enforce the upper encoder to produce as much semantic information\nas possible, without extra data. We perform experiments on a diverse set of\nspeech translation benchmarks, including Librispeech English-French, IWSLT\nEnglish-German and TED English-Chinese. Our results demonstrate LUT achieves\nthe state-of-the-art performance, outperforming previous methods. The code is\navailable at https://github.com/dqqcasia/st.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 09:19:07 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 07:28:44 GMT"}, {"version": "v3", "created": "Mon, 5 Apr 2021 12:36:42 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Dong", "Qianqian", ""], ["Ye", "Rong", ""], ["Wang", "Mingxuan", ""], ["Zhou", "Hao", ""], ["Xu", "Shuang", ""], ["Xu", "Bo", ""], ["Li", "Lei", ""]]}, {"id": "2009.09708", "submitter": "Qintong Li", "authors": "Qintong Li, Piji Li, Zhumin Chen, Zhaochun Ren", "title": "Towards Empathetic Dialogue Generation over Multi-type Knowledge", "comments": "arXiv admin note: text overlap with arXiv:1911.08698", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enabling the machines with empathetic abilities to provide context-consistent\nresponses is crucial on both semantic and emotional levels. The task of\nempathetic dialogue generation is proposed to address this problem. However,\nlacking external knowledge makes it difficult to perceive implicit emotions\nfrom limited dialogue history. To address the above challenges, we propose to\nleverage multi-type knowledge, i.e, the commonsense knowledge and emotional\nlexicon, to explicitly understand and express emotions in empathetic dialogue\ngeneration. We first enrich the dialogue history by jointly interacting with\ntwo-type knowledge and construct an emotional context graph. Then we introduce\na multi-type knowledge-aware context encoder to learn emotional context\nrepresentations and distill emotional signals, which are the prerequisites to\npredicate emotions expressed in responses. Finally, we propose an emotional\ncross-attention mechanism to exploit the emotional dependencies between the\nemotional context graph and the target empathetic response. Conducted on a\nbenchmark dataset, extensive experimental results show that our proposed\nframework outperforms state-of-the-art baselines in terms of automatic metrics\nand human evaluations.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 09:21:52 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 04:27:38 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Li", "Qintong", ""], ["Li", "Piji", ""], ["Chen", "Zhumin", ""], ["Ren", "Zhaochun", ""]]}, {"id": "2009.09730", "submitter": "Daniel Fern\\'andez-Gonz\\'alez", "authors": "Daniel Fern\\'andez-Gonz\\'alez and Carlos G\\'omez-Rodr\\'iguez", "title": "Multitask Pointer Network for Multi-Representational Parsing", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a transition-based approach that, by training a single model, can\nefficiently parse any input sentence with both constituent and dependency\ntrees, supporting both continuous/projective and discontinuous/non-projective\nsyntactic structures. To that end, we develop a Pointer Network architecture\nwith two separate task-specific decoders and a common encoder, and follow a\nmultitask learning strategy to jointly train them. The resulting quadratic\nsystem, not only becomes the first parser that can jointly produce both\nunrestricted constituent and dependency trees from a single model, but also\nproves that both syntactic formalisms can benefit from each other during\ntraining, achieving state-of-the-art accuracies in several widely-used\nbenchmarks such as the continuous English and Chinese Penn Treebanks, as well\nas the discontinuous German NEGRA and TIGER datasets.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 10:04:07 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Fern\u00e1ndez-Gonz\u00e1lez", "Daniel", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "2009.09737", "submitter": "Qianqian Dong", "authors": "Qianqian Dong, Mingxuan Wang, Hao Zhou, Shuang Xu, Bo Xu, Lei Li", "title": "Consecutive Decoding for Speech-to-text Translation", "comments": "Accepted by AAAI 2021. arXiv admin note: text overlap with\n  arXiv:2009.09704", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech-to-text translation (ST), which directly translates the source\nlanguage speech to the target language text, has attracted intensive attention\nrecently. However, the combination of speech recognition and machine\ntranslation in a single model poses a heavy burden on the direct cross-modal\ncross-lingual mapping. To reduce the learning difficulty, we propose\nCOnSecutive Transcription and Translation (COSTT), an integral approach for\nspeech-to-text translation. The key idea is to generate source transcript and\ntarget translation text with a single decoder. It benefits the model training\nso that additional large parallel text corpus can be fully exploited to enhance\nthe speech translation training. Our method is verified on three mainstream\ndatasets, including Augmented LibriSpeech English-French dataset, TED\nEnglish-German dataset, and TED English-Chinese dataset. Experiments show that\nour proposed COSTT outperforms the previous state-of-the-art methods. The code\nis available at https://github.com/dqqcasia/st.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 10:10:45 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 08:53:32 GMT"}, {"version": "v3", "created": "Mon, 5 Apr 2021 12:28:39 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Dong", "Qianqian", ""], ["Wang", "Mingxuan", ""], ["Zhou", "Hao", ""], ["Xu", "Shuang", ""], ["Xu", "Bo", ""], ["Li", "Lei", ""]]}, {"id": "2009.09761", "submitter": "Wei Ping", "authors": "Zhifeng Kong, Wei Ping, Jiaji Huang, Kexin Zhao, Bryan Catanzaro", "title": "DiffWave: A Versatile Diffusion Model for Audio Synthesis", "comments": "ICLR 2021 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose DiffWave, a versatile diffusion probabilistic model\nfor conditional and unconditional waveform generation. The model is\nnon-autoregressive, and converts the white noise signal into structured\nwaveform through a Markov chain with a constant number of steps at synthesis.\nIt is efficiently trained by optimizing a variant of variational bound on the\ndata likelihood. DiffWave produces high-fidelity audios in different waveform\ngeneration tasks, including neural vocoding conditioned on mel spectrogram,\nclass-conditional generation, and unconditional generation. We demonstrate that\nDiffWave matches a strong WaveNet vocoder in terms of speech quality (MOS: 4.44\nversus 4.43), while synthesizing orders of magnitude faster. In particular, it\nsignificantly outperforms autoregressive and GAN-based waveform models in the\nchallenging unconditional generation task in terms of audio quality and sample\ndiversity from various automatic and human evaluations.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 11:20:38 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 09:47:28 GMT"}, {"version": "v3", "created": "Tue, 30 Mar 2021 19:48:38 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Kong", "Zhifeng", ""], ["Ping", "Wei", ""], ["Huang", "Jiaji", ""], ["Zhao", "Kexin", ""], ["Catanzaro", "Bryan", ""]]}, {"id": "2009.09781", "submitter": "Ziming Li", "authors": "Ziming Li and Julia Kiseleva and Maarten de Rijke", "title": "Rethinking Supervised Learning and Reinforcement Learning in\n  Task-Oriented Dialogue Systems", "comments": "10 pages", "journal-ref": "Findings of EMNLP 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue policy learning for task-oriented dialogue systems has enjoyed great\nprogress recently mostly through employing reinforcement learning methods.\nHowever, these approaches have become very sophisticated. It is time to\nre-evaluate it. Are we really making progress developing dialogue agents only\nbased on reinforcement learning? We demonstrate how (1)~traditional supervised\nlearning together with (2)~a simulator-free adversarial learning method can be\nused to achieve performance comparable to state-of-the-art RL-based methods.\nFirst, we introduce a simple dialogue action decoder to predict the appropriate\nactions. Then, the traditional multi-label classification solution for dialogue\npolicy learning is extended by adding dense layers to improve the dialogue\nagent performance. Finally, we employ the Gumbel-Softmax estimator to\nalternatively train the dialogue agent and the dialogue reward model without\nusing reinforcement learning. Based on our extensive experimentation, we can\nconclude the proposed methods can achieve more stable and higher performance\nwith fewer efforts, such as the domain knowledge required to design a user\nsimulator and the intractable parameter tuning in reinforcement learning. Our\nmain goal is not to beat reinforcement learning with supervised learning, but\nto demonstrate the value of rethinking the role of reinforcement learning and\nsupervised learning in optimizing task-oriented dialogue systems.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 12:04:18 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Li", "Ziming", ""], ["Kiseleva", "Julia", ""], ["de Rijke", "Maarten", ""]]}, {"id": "2009.09841", "submitter": "Zifeng Wang", "authors": "Zifeng Wang, Rui Wen, Xi Chen, Shao-Lun Huang, Ningyu Zhang, Yefeng\n  Zheng", "title": "Finding Influential Instances for Distantly Supervised Relation\n  Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distant supervision has been demonstrated to be highly beneficial to enhance\nrelation extraction models, but it often suffers from high label noise. In this\nwork, we propose a novel model-agnostic instance subsampling method for\ndistantly supervised relation extraction, namely REIF, which bridges the gap of\nrealizing influence subsampling in deep learning. It encompasses two key steps:\nfirst calculating instance-level influences that measure how much each training\ninstance contributes to the validation loss change of our model, then deriving\nsampling probabilities via the proposed sigmoid sampling function to perform\nbatch-in-bag sampling. We design a fast influence subsampling scheme that\nreduces the computational complexity from O(mn) to O(1), and analyze its\nrobustness when the sigmoid sampling function is employed. Empirical\nexperiments demonstrate our method's superiority over the baselines, and its\nability to support interpretable instance selection.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 02:02:07 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Wang", "Zifeng", ""], ["Wen", "Rui", ""], ["Chen", "Xi", ""], ["Huang", "Shao-Lun", ""], ["Zhang", "Ningyu", ""], ["Zheng", "Yefeng", ""]]}, {"id": "2009.09870", "submitter": "Seraphina Goldfarb-Tarrant", "authors": "Seraphina Goldfarb-Tarrant, Tuhin Chakrabarty, Ralph Weischedel,\n  Nanyun Peng", "title": "Content Planning for Neural Story Generation with Aristotelian Rescoring", "comments": "EMNLP 2020, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Long-form narrative text generated from large language models manages a\nfluent impersonation of human writing, but only at the local sentence level,\nand lacks structure or global cohesion. We posit that many of the problems of\nstory generation can be addressed via high-quality content planning, and\npresent a system that focuses on how to learn good plot structures to guide\nstory generation. We utilize a plot-generation language model along with an\nensemble of rescoring models that each implement an aspect of good\nstory-writing as detailed in Aristotle's Poetics. We find that stories written\nwith our more principled plot-structure are both more relevant to a given\nprompt and higher quality than baselines that do not content plan, or that plan\nin an unprincipled way.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 13:41:32 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 16:28:23 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Goldfarb-Tarrant", "Seraphina", ""], ["Chakrabarty", "Tuhin", ""], ["Weischedel", "Ralph", ""], ["Peng", "Nanyun", ""]]}, {"id": "2009.09879", "submitter": "Amina Gaber Abdelnabi", "authors": "Ahmed Sultan (WideBot), Mahmoud Salim (WideBot), Amina Gaber\n  (WideBot), Islam El Hosary (WideBot)", "title": "WESSA at SemEval-2020 Task 9: Code-Mixed Sentiment Analysis using\n  Transformers", "comments": "Proceedings of SemEval-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we describe our system submitted for SemEval 2020 Task 9,\nSentiment Analysis for Code-Mixed Social Media Text alongside other\nexperiments. Our best performing system is a Transfer Learning-based model that\nfine-tunes \"XLM-RoBERTa\", a transformer-based multilingual masked language\nmodel, on monolingual English and Spanish data and Spanish-English code-mixed\ndata. Our system outperforms the official task baseline by achieving a 70.1%\naverage F1-Score on the official leaderboard using the test set. For later\nsubmissions, our system manages to achieve a 75.9% average F1-Score on the test\nset using CodaLab username \"ahmed0sultan\".\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 13:59:24 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Sultan", "Ahmed", "", "WideBot"], ["Salim", "Mahmoud", "", "WideBot"], ["Gaber", "Amina", "", "WideBot"], ["Hosary", "Islam El", "", "WideBot"]]}, {"id": "2009.09961", "submitter": "Galen Weld", "authors": "Galen Weld, Peter West, Maria Glenski, David Arbour, Ryan Rossi, Tim\n  Althoff", "title": "Adjusting for Confounders with Text: Challenges and an Empirical\n  Evaluation Framework for Causal Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging text, such as social media posts, for causal inferences requires\nthe use of NLP models to 'learn' and adjust for confounders, which could\notherwise impart bias. However, evaluating such models is challenging, as\nground truth is almost never available. We demonstrate the need for empirical\nevaluation frameworks for causal inference in natural language by showing that\nexisting, commonly used models regularly disagree with one another on real\nworld tasks. We contribute the first such framework, generalizing several\nchallenges across these real world tasks. Using this framework, we evaluate a\nlarge set of commonly used causal inference models based on propensity scores\nand identify their strengths and weaknesses to inform future improvements. We\nmake all tasks, data, and models public to inform applications and encourage\nadditional research.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 15:38:45 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Weld", "Galen", ""], ["West", "Peter", ""], ["Glenski", "Maria", ""], ["Arbour", "David", ""], ["Rossi", "Ryan", ""], ["Althoff", "Tim", ""]]}, {"id": "2009.10026", "submitter": "Mirantha Jayathilaka", "authors": "Mirantha Jayathilaka, Tingting Mu, Uli Sattler", "title": "Visual-Semantic Embedding Model Informed by Structured Knowledge", "comments": "European Starting AI Researchers' Symposium 2020 (STAIRS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach to improve a visual-semantic embedding model by\nincorporating concept representations captured from an external structured\nknowledge base. We investigate its performance on image classification under\nboth standard and zero-shot settings. We propose two novel evaluation\nframeworks to analyse classification errors with respect to the class hierarchy\nindicated by the knowledge base. The approach is tested using the ILSVRC 2012\nimage dataset and a WordNet knowledge base. With respect to both standard and\nzero-shot image classification, our approach shows superior performance\ncompared with the original approach, which uses word embeddings.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 17:04:32 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Jayathilaka", "Mirantha", ""], ["Mu", "Tingting", ""], ["Sattler", "Uli", ""]]}, {"id": "2009.10047", "submitter": "Congcong Wang", "authors": "Congcong Wang and David Lillis", "title": "UCD-CS at W-NUT 2020 Shared Task-3: A Text to Text Approach for COVID-19\n  Event Extraction on Social Media", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we describe our approach in the shared task: COVID-19 event\nextraction from Twitter. The objective of this task is to extract answers from\nCOVID-related tweets to a set of predefined slot-filling questions. Our\napproach treats the event extraction task as a question answering task by\nleveraging the transformer-based T5 text-to-text model.\n  According to the official evaluation scores returned, namely F1, our\nsubmitted run achieves competitive performance compared to other participating\nruns (Top 3). However, we argue that this evaluation may underestimate the\nactual performance of runs based on text-generation. Although some such runs\nmay answer the slot questions well, they may not be an exact string match for\nthe gold standard answers. To measure the extent of this underestimation, we\nadopt a simple exact-answer transformation method aiming at converting the\nwell-answered predictions to exactly-matched predictions. The results show that\nafter this transformation our run overall reaches the same level of performance\nas the best participating run and state-of-the-art F1 scores in three of five\nCOVID-related events. Our code is publicly available to aid reproducibility\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 17:39:00 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 16:18:53 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Wang", "Congcong", ""], ["Lillis", "David", ""]]}, {"id": "2009.10053", "submitter": "David Bamman", "authors": "David Bamman and Patrick J. Burns", "title": "Latin BERT: A Contextual Language Model for Classical Philology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Latin BERT, a contextual language model for the Latin language,\ntrained on 642.7 million words from a variety of sources spanning the Classical\nera to the 21st century. In a series of case studies, we illustrate the\naffordances of this language-specific model both for work in natural language\nprocessing for Latin and in using computational methods for traditional\nscholarship: we show that Latin BERT achieves a new state of the art for\npart-of-speech tagging on all three Universal Dependency datasets for Latin and\ncan be used for predicting missing text (including critical emendations); we\ncreate a new dataset for assessing word sense disambiguation for Latin and\ndemonstrate that Latin BERT outperforms static word embeddings; and we show\nthat it can be used for semantically-informed search by querying contextual\nnearest neighbors. We publicly release trained models to help drive future work\nin this space.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 17:47:44 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Bamman", "David", ""], ["Burns", "Patrick J.", ""]]}, {"id": "2009.10056", "submitter": "Congying Xia", "authors": "Congying Xia, Caiming Xiong, Philip Yu, Richard Socher", "title": "Composed Variational Natural Language Generation for Few-shot Intents", "comments": "10 pages, accepted to Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on generating training examples for few-shot intents\nin the realistic imbalanced scenario. To build connections between existing\nmany-shot intents and few-shot intents, we consider an intent as a combination\nof a domain and an action, and propose a composed variational natural language\ngenerator (CLANG), a transformer-based conditional variational autoencoder.\nCLANG utilizes two latent variables to represent the utterances corresponding\nto two different independent parts (domain and action) in the intent, and the\nlatent variables are composed together to generate natural examples.\nAdditionally, to improve the generator learning, we adopt the contrastive\nregularization loss that contrasts the in-class with the out-of-class utterance\ngeneration given the intent. To evaluate the quality of the generated\nutterances, experiments are conducted on the generalized few-shot intent\ndetection task. Empirical results show that our proposed model achieves\nstate-of-the-art performances on two real-world intent detection datasets.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 17:48:43 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Xia", "Congying", ""], ["Xiong", "Caiming", ""], ["Yu", "Philip", ""], ["Socher", "Richard", ""]]}, {"id": "2009.10155", "submitter": "Shweta Yadav Shweta", "authors": "Shweta Yadav, Usha Lokala, Raminta Daniulaityte, Krishnaprasad\n  Thirunarayan, Francois Lamy, Amit Sheth", "title": "\"When they say weed causes depression, but it's your fav\n  antidepressant\": Knowledge-aware Attention Framework for Relationship\n  Extraction", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0248299", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing legalization of medical and recreational use of cannabis,\nmore research is needed to understand the association between depression and\nconsumer behavior related to cannabis consumption. Big social media data has\npotential to provide deeper insights about these associations to public health\nanalysts. In this interdisciplinary study, we demonstrate the value of\nincorporating domain-specific knowledge in the learning process to identify the\nrelationships between cannabis use and depression. We develop an end-to-end\nknowledge infused deep learning framework (Gated-K-BERT) that leverages the\npre-trained BERT language representation model and domain-specific declarative\nknowledge source (Drug Abuse Ontology (DAO)) to jointly extract entities and\ntheir relationship using gated fusion sharing mechanism. Our model is further\ntailored to provide more focus to the entities mention in the sentence through\nentity-position aware attention layer, where ontology is used to locate the\ntarget entities position. Experimental results show that inclusion of the\nknowledge-aware attentive representation in association with BERT can extract\nthe cannabis-depression relationship with better coverage in comparison to the\nstate-of-the-art relation extractor.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 19:54:42 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Yadav", "Shweta", ""], ["Lokala", "Usha", ""], ["Daniulaityte", "Raminta", ""], ["Thirunarayan", "Krishnaprasad", ""], ["Lamy", "Francois", ""], ["Sheth", "Amit", ""]]}, {"id": "2009.10195", "submitter": "Nathan Ng", "authors": "Nathan Ng, Kyunghyun Cho, Marzyeh Ghassemi", "title": "SSMBA: Self-Supervised Manifold Based Data Augmentation for Improving\n  Out-of-Domain Robustness", "comments": "16 pages, 8 figures, to be published in EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models that perform well on a training domain often fail to generalize to\nout-of-domain (OOD) examples. Data augmentation is a common method used to\nprevent overfitting and improve OOD generalization. However, in natural\nlanguage, it is difficult to generate new examples that stay on the underlying\ndata manifold. We introduce SSMBA, a data augmentation method for generating\nsynthetic training examples by using a pair of corruption and reconstruction\nfunctions to move randomly on a data manifold. We investigate the use of SSMBA\nin the natural language domain, leveraging the manifold assumption to\nreconstruct corrupted text with masked language models. In experiments on\nrobustness benchmarks across 3 tasks and 9 datasets, SSMBA consistently\noutperforms existing data augmentation methods and baseline models on both\nin-domain and OOD data, achieving gains of 0.8% accuracy on OOD Amazon reviews,\n1.8% accuracy on OOD MNLI, and 1.4 BLEU on in-domain IWSLT14 German-English.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 22:02:33 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 22:47:00 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Ng", "Nathan", ""], ["Cho", "Kyunghyun", ""], ["Ghassemi", "Marzyeh", ""]]}, {"id": "2009.10205", "submitter": "Mohammad Sadegh Rasooli", "authors": "Mohammad Sadegh Rasooli, Pegah Safari, Amirsaeid Moloodi, Alireza\n  Nourian", "title": "The Persian Dependency Treebank Made Universal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe an automatic method for converting the Persian Dependency\nTreebank (Rasooli et al, 2013) to Universal Dependencies. This treebank\ncontains 29107 sentences. Our experiments along with manual linguistic analysis\nshow that our data is more compatible with Universal Dependencies than the\nUppsala Persian Universal Dependency Treebank (Seraji et al., 2016), and is\nlarger in size and more diverse in vocabulary. Our data brings in a labeled\nattachment F-score of 85.2 in supervised parsing. Our delexicalized\nPersian-to-English parser transfer experiments show that a parsing model\ntrained on our data is ~2% absolutely more accurate than that of Seraji et al.\n(2016) in terms of labeled attachment score.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 22:34:13 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 02:44:07 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Rasooli", "Mohammad Sadegh", ""], ["Safari", "Pegah", ""], ["Moloodi", "Amirsaeid", ""], ["Nourian", "Alireza", ""]]}, {"id": "2009.10229", "submitter": "Eric Yuan", "authors": "Rui Meng, Xingdi Yuan, Tong Wang, Sanqiang Zhao, Adam Trischler,\n  Daqing He", "title": "An Empirical Study on Neural Keyphrase Generation", "comments": "NAACL 2021, added more results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen a flourishing of neural keyphrase generation (KPG)\nworks, including the release of several large-scale datasets and a host of new\nmodels to tackle them. Model performance on KPG tasks has increased\nsignificantly with evolving deep learning research. However, there lacks a\ncomprehensive comparison among different model designs, and a thorough\ninvestigation on related factors that may affect a KPG system's generalization\nperformance. In this empirical study, we aim to fill this gap by providing\nextensive experimental results and analyzing the most crucial factors impacting\nthe generalizability of KPG models. We hope this study can help clarify some of\nthe uncertainties surrounding the KPG task and facilitate future research on\nthis topic.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:11:32 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 17:13:49 GMT"}, {"version": "v3", "created": "Thu, 15 Apr 2021 15:33:40 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Meng", "Rui", ""], ["Yuan", "Xingdi", ""], ["Wang", "Tong", ""], ["Zhao", "Sanqiang", ""], ["Trischler", "Adam", ""], ["He", "Daqing", ""]]}, {"id": "2009.10239", "submitter": "EPTCS", "authors": "Kinjal Basu, Sarat Chandra Varanasi, Farhad Shakerin, Gopal Gupta", "title": "SQuARE: Semantics-based Question Answering and Reasoning Engine", "comments": "In Proceedings ICLP 2020, arXiv:2009.09158", "journal-ref": "EPTCS 325, 2020, pp. 73-86", "doi": "10.4204/EPTCS.325.13", "report-no": null, "categories": "cs.AI cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the meaning of a text is a fundamental challenge of natural\nlanguage understanding (NLU) and from its early days, it has received\nsignificant attention through question answering (QA) tasks. We introduce a\ngeneral semantics-based framework for natural language QA and also describe the\nSQuARE system, an application of this framework. The framework is based on the\ndenotational semantics approach widely used in programming language research.\nIn our framework, valuation function maps syntax tree of the text to its\ncommonsense meaning represented using basic knowledge primitives (the semantic\nalgebra) coded using answer set programming (ASP). We illustrate an application\nof this framework by using VerbNet primitives as our semantic algebra and a\nnovel algorithm based on partial tree matching that generates an answer set\nprogram that represents the knowledge in the text. A question posed against\nthat text is converted into an ASP query using the same framework and executed\nusing the s(CASP) goal-directed ASP system. Our approach is based purely on\n(commonsense) reasoning. SQuARE achieves 100% accuracy on all the five datasets\nof bAbI QA tasks that we have tested. The significance of our work is that,\nunlike other machine learning based approaches, ours is based on\n\"understanding\" the text and does not require any training. SQuARE can also\ngenerate an explanation for an answer while maintaining high accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 00:48:18 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Basu", "Kinjal", ""], ["Varanasi", "Sarat Chandra", ""], ["Shakerin", "Farhad", ""], ["Gupta", "Gopal", ""]]}, {"id": "2009.10259", "submitter": "Weixin Liang", "authors": "Weixin Liang, James Zou, Zhou Yu", "title": "ALICE: Active Learning with Contrastive Natural Language Explanations", "comments": null, "journal-ref": "EMNLP 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a supervised neural network classifier typically requires many\nannotated training samples. Collecting and annotating a large number of data\npoints are costly and sometimes even infeasible. Traditional annotation process\nuses a low-bandwidth human-machine communication interface: classification\nlabels, each of which only provides several bits of information. We propose\nActive Learning with Contrastive Explanations (ALICE), an expert-in-the-loop\ntraining framework that utilizes contrastive natural language explanations to\nimprove data efficiency in learning. ALICE learns to first use active learning\nto select the most informative pairs of label classes to elicit contrastive\nnatural language explanations from experts. Then it extracts knowledge from\nthese explanations using a semantic parser. Finally, it incorporates the\nextracted knowledge through dynamically changing the learning model's\nstructure. We applied ALICE in two visual recognition tasks, bird species\nclassification and social relationship classification. We found by\nincorporating contrastive explanations, our models outperform baseline models\nthat are trained with 40-100% more training data. We found that adding 1\nexplanation leads to similar performance gain as adding 13-30 labeled training\ndata points.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 01:02:07 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Liang", "Weixin", ""], ["Zou", "James", ""], ["Yu", "Zhou", ""]]}, {"id": "2009.10277", "submitter": "Chris Kennedy", "authors": "Chris J. Kennedy, Geoff Bacon, Alexander Sahn, Claudia von Vacano", "title": "Constructing interval variables via faceted Rasch measurement and\n  multitask deep learning: a hate speech application", "comments": "35 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general method for measuring complex variables on a continuous,\ninterval spectrum by combining supervised deep learning with the Constructing\nMeasures approach to faceted Rasch item response theory (IRT). We decompose the\ntarget construct, hate speech in our case, into multiple constituent components\nthat are labeled as ordinal survey items. Those survey responses are\ntransformed via IRT into a debiased, continuous outcome measure. Our method\nestimates the survey interpretation bias of the human labelers and eliminates\nthat influence on the generated continuous measure. We further estimate the\nresponse quality of each labeler using faceted IRT, allowing responses from\nlow-quality labelers to be removed.\n  Our faceted Rasch scaling procedure integrates naturally with a multitask\ndeep learning architecture for automated prediction on new data. The ratings on\nthe theorized components of the target outcome are used as supervised, ordinal\nvariables for the neural networks' internal concept learning. We test the use\nof an activation function (ordinal softmax) and loss function (ordinal\ncross-entropy) designed to exploit the structure of ordinal outcome variables.\nOur multitask architecture leads to a new form of model interpretation because\neach continuous prediction can be directly explained by the constituent\ncomponents in the penultimate layer.\n  We demonstrate this new method on a dataset of 50,000 social media comments\nsourced from YouTube, Twitter, and Reddit and labeled by 11,000 U.S.-based\nAmazon Mechanical Turk workers to measure a continuous spectrum from hate\nspeech to counterspeech. We evaluate Universal Sentence Encoders, BERT, and\nRoBERTa as language representation models for the comment text, and compare our\npredictive accuracy to Google Jigsaw's Perspective API models, showing\nsignificant improvement over this standard benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 02:15:05 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Kennedy", "Chris J.", ""], ["Bacon", "Geoff", ""], ["Sahn", "Alexander", ""], ["von Vacano", "Claudia", ""]]}, {"id": "2009.10288", "submitter": "Xinyu Zuo", "authors": "Xinyu Zuo, Yubo Chen, Kang Liu and Jun Zhao", "title": "Towards Causal Explanation Detection with Pyramid Salient-Aware Network", "comments": "Accepted to CCL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal explanation analysis (CEA) can assist us to understand the reasons\nbehind daily events, which has been found very helpful for understanding the\ncoherence of messages. In this paper, we focus on Causal Explanation Detection,\nan important subtask of causal explanation analysis, which determines whether a\ncausal explanation exists in one message. We design a Pyramid Salient-Aware\nNetwork (PSAN) to detect causal explanations on messages. PSAN can assist in\ncausal explanation detection via capturing the salient semantics of discourses\ncontained in their keywords with a bottom graph-based word-level salient\nnetwork. Furthermore, PSAN can modify the dominance of discourses via a top\nattention-based discourse-level salient network to enhance explanatory\nsemantics of messages. The experiments on the commonly used dataset of CEA\nshows that the PSAN outperforms the state-of-the-art method by 1.8% F1 value on\nthe Causal Explanation Detection task.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 02:35:45 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 02:13:21 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Zuo", "Xinyu", ""], ["Chen", "Yubo", ""], ["Liu", "Kang", ""], ["Zhao", "Jun", ""]]}, {"id": "2009.10290", "submitter": "Xinyu Zuo", "authors": "Xinyu Zuo, Yubo Chen, Kang Liu and Jun Zhao", "title": "Event Coreference Resolution via a Multi-loss Neural Network without\n  Using Argument Information", "comments": "Published on SCIENCE CHINA Information Sciences", "journal-ref": "SCIENCE CHINA Information Sciences, Volume 62, Issue\n  11:212101(2019)", "doi": "10.1007/s11432-018-9833-1", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event coreference resolution(ECR) is an important task in Natural Language\nProcessing (NLP) and nearly all the existing approaches to this task rely on\nevent argument information. However, these methods tend to suffer from error\npropagation from the stage of event argument extraction. Besides, not every\nevent mention contains all arguments of an event, and argument information may\nconfuse the model that events have arguments to detect event coreference in\nreal text. Furthermore, the context information of an event is useful to infer\nthe coreference between events. Thus, in order to reduce the errors propagated\nfrom event argument extraction and use context information effectively, we\npropose a multi-loss neural network model that does not need any argument\ninformation to do the within-document event coreference resolution task and\nachieve a significant performance than the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 02:48:48 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Zuo", "Xinyu", ""], ["Chen", "Yubo", ""], ["Liu", "Kang", ""], ["Zhao", "Jun", ""]]}, {"id": "2009.10297", "submitter": "Shuo Ren", "authors": "Shuo Ren, Daya Guo, Shuai Lu, Long Zhou, Shujie Liu, Duyu Tang, Neel\n  Sundaresan, Ming Zhou, Ambrosio Blanco, Shuai Ma", "title": "CodeBLEU: a Method for Automatic Evaluation of Code Synthesis", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluation metrics play a vital role in the growth of an area as it defines\nthe standard of distinguishing between good and bad models. In the area of code\nsynthesis, the commonly used evaluation metric is BLEU or perfect accuracy, but\nthey are not suitable enough to evaluate codes, because BLEU is originally\ndesigned to evaluate the natural language, neglecting important syntactic and\nsemantic features of codes, and perfect accuracy is too strict thus it\nunderestimates different outputs with the same semantic logic. To remedy this,\nwe introduce a new automatic evaluation metric, dubbed CodeBLEU. It absorbs the\nstrength of BLEU in the n-gram match and further injects code syntax via\nabstract syntax trees (AST) and code semantics via data-flow. We conduct\nexperiments by evaluating the correlation coefficient between CodeBLEU and\nquality scores assigned by the programmers on three code synthesis tasks, i.e.,\ntext-to-code, code translation, and code refinement. Experimental results show\nthat our proposed CodeBLEU can achieve a better correlation with programmer\nassigned scores compared with BLEU and accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 03:10:49 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 04:07:11 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Ren", "Shuo", ""], ["Guo", "Daya", ""], ["Lu", "Shuai", ""], ["Zhou", "Long", ""], ["Liu", "Shujie", ""], ["Tang", "Duyu", ""], ["Sundaresan", "Neel", ""], ["Zhou", "Ming", ""], ["Blanco", "Ambrosio", ""], ["Ma", "Shuai", ""]]}, {"id": "2009.10298", "submitter": "Paria Jamshid Lou", "authors": "Paria Jamshid Lou and Mark Johnson", "title": "End-to-End Speech Recognition and Disfluency Removal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disfluency detection is usually an intermediate step between an automatic\nspeech recognition (ASR) system and a downstream task. By contrast, this paper\naims to investigate the task of end-to-end speech recognition and disfluency\nremoval. We specifically explore whether it is possible to train an ASR model\nto directly map disfluent speech into fluent transcripts, without relying on a\nseparate disfluency detection model. We show that end-to-end models do learn to\ndirectly generate fluent transcripts; however, their performance is slightly\nworse than a baseline pipeline approach consisting of an ASR system and a\ndisfluency detection model. We also propose two new metrics that can be used\nfor evaluating integrated ASR and disfluency models. The findings of this paper\ncan serve as a benchmark for further research on the task of end-to-end speech\nrecognition and disfluency removal in the future.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 03:11:37 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 08:13:32 GMT"}, {"version": "v3", "created": "Mon, 28 Sep 2020 23:07:21 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Lou", "Paria Jamshid", ""], ["Johnson", "Mark", ""]]}, {"id": "2009.10315", "submitter": "Aneesh Vartakavi", "authors": "Aneesh Vartakavi and Amanmeet Garg", "title": "PodSumm -- Podcast Audio Summarization", "comments": "For PodRecs: Workshop on Podcast Recommendations at RecSys 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The diverse nature, scale, and specificity of podcasts present a unique\nchallenge to content discovery systems. Listeners often rely on text\ndescriptions of episodes provided by the podcast creators to discover new\ncontent. Some factors like the presentation style of the narrator and\nproduction quality are significant indicators of subjective user preference but\nare difficult to quantify and not reflected in the text descriptions provided\nby the podcast creators. We propose the automated creation of podcast audio\nsummaries to aid in content discovery and help listeners to quickly preview\npodcast content before investing time in listening to an entire episode. In\nthis paper, we present a method to automatically construct a podcast summary\nvia guidance from the text-domain. Our method performs two key steps, namely,\naudio to text transcription and text summary generation. Motivated by a lack of\ndatasets for this task, we curate an internal dataset, find an effective scheme\nfor data augmentation, and design a protocol to gather summaries from\nannotators. We fine-tune a PreSumm[10] model with our augmented dataset and\nperform an ablation study. Our method achieves ROUGE-F(1/2/L) scores of\n0.63/0.53/0.63 on our dataset. We hope these results may inspire future\nresearch in this direction.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 04:49:33 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Vartakavi", "Aneesh", ""], ["Garg", "Amanmeet", ""]]}, {"id": "2009.10321", "submitter": "Zhi Chen", "authors": "Zhi Chen, Lu Chen, Xiang Zhou and Kai Yu", "title": "Deep Reinforcement Learning for On-line Dialogue State Tracking", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue state tracking (DST) is a crucial module in dialogue management. It\nis usually cast as a supervised training problem, which is not convenient for\non-line optimization. In this paper, a novel companion teaching based deep\nreinforcement learning (DRL) framework for on-line DST optimization is\nproposed. To the best of our knowledge, this is the first effort to optimize\nthe DST module within DRL framework for on-line task-oriented spoken dialogue\nsystems. In addition, dialogue policy can be further jointly updated.\nExperiments show that on-line DST optimization can effectively improve the\ndialogue manager performance while keeping the flexibility of using predefined\npolicy. Joint training of both DST and policy can further improve the\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 05:08:48 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Chen", "Zhi", ""], ["Chen", "Lu", ""], ["Zhou", "Xiang", ""], ["Yu", "Kai", ""]]}, {"id": "2009.10326", "submitter": "Zhi Chen", "authors": "Zhi Chen, Lu Chen, Xiaoyuan Liu, and Kai Yu", "title": "Distributed Structured Actor-Critic Reinforcement Learning for Universal\n  Dialogue Management", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": "10.1109/TASLP.2020.3013392", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task-oriented spoken dialogue system (SDS) aims to assist a human user in\naccomplishing a specific task (e.g., hotel booking). The dialogue management is\na core part of SDS. There are two main missions in dialogue management:\ndialogue belief state tracking (summarising conversation history) and dialogue\ndecision-making (deciding how to reply to the user). In this work, we only\nfocus on devising a policy that chooses which dialogue action to respond to the\nuser. The sequential system decision-making process can be abstracted into a\npartially observable Markov decision process (POMDP). Under this framework,\nreinforcement learning approaches can be used for automated policy\noptimization. In the past few years, there are many deep reinforcement learning\n(DRL) algorithms, which use neural networks (NN) as function approximators,\ninvestigated for dialogue policy.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 05:39:31 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Chen", "Zhi", ""], ["Chen", "Lu", ""], ["Liu", "Xiaoyuan", ""], ["Yu", "Kai", ""]]}, {"id": "2009.10334", "submitter": "Yerbolat Khassanov", "authors": "Yerbolat Khassanov, Saida Mussakhojayeva, Almas Mirzakhmetov, Alen\n  Adiyev, Mukhamet Nurpeiissov and Huseyin Atakan Varol", "title": "A Crowdsourced Open-Source Kazakh Speech Corpus and Initial Speech\n  Recognition Baseline", "comments": "10 pages, 5 figures, 4 tables, accepted by EACL2021", "journal-ref": "https://aclanthology.org/2021.eacl-main.58", "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an open-source speech corpus for the Kazakh language. The Kazakh\nspeech corpus (KSC) contains around 332 hours of transcribed audio comprising\nover 153,000 utterances spoken by participants from different regions and age\ngroups, as well as both genders. It was carefully inspected by native Kazakh\nspeakers to ensure high quality. The KSC is the largest publicly available\ndatabase developed to advance various Kazakh speech and language processing\napplications. In this paper, we first describe the data collection and\npreprocessing procedures followed by a description of the database\nspecifications. We also share our experience and challenges faced during the\ndatabase construction, which might benefit other researchers planning to build\na speech corpus for a low-resource language. To demonstrate the reliability of\nthe database, we performed preliminary speech recognition experiments. The\nexperimental results imply that the quality of audio and transcripts is\npromising (2.8% character error rate and 8.7% word error rate on the test set).\nTo enable experiment reproducibility and ease the corpus usage, we also\nreleased an ESPnet recipe for our speech recognition models.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 05:57:15 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2021 09:08:07 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Khassanov", "Yerbolat", ""], ["Mussakhojayeva", "Saida", ""], ["Mirzakhmetov", "Almas", ""], ["Adiyev", "Alen", ""], ["Nurpeiissov", "Mukhamet", ""], ["Varol", "Huseyin Atakan", ""]]}, {"id": "2009.10355", "submitter": "Zhi Chen", "authors": "Zhi Chen, Xiaoyuan Liu, Lu Chen and Kai Yu", "title": "Structured Hierarchical Dialogue Policy with Graph Neural Networks", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue policy training for composite tasks, such as restaurant reservation\nin multiple places, is a practically important and challenging problem.\nRecently, hierarchical deep reinforcement learning (HDRL) methods have achieved\ngood performance in composite tasks. However, in vanilla HDRL, both top-level\nand low-level policies are all represented by multi-layer perceptrons (MLPs)\nwhich take the concatenation of all observations from the environment as the\ninput for predicting actions. Thus, traditional HDRL approach often suffers\nfrom low sampling efficiency and poor transferability. In this paper, we\naddress these problems by utilizing the flexibility of graph neural networks\n(GNNs). A novel ComNet is proposed to model the structure of a hierarchical\nagent. The performance of ComNet is tested on composited tasks of the PyDial\nbenchmark. Experiments show that ComNet outperforms vanilla HDRL systems with\nperformance close to the upper bound. It not only achieves sample efficiency\nbut also is more robust to noise while maintaining the transferability to other\ncomposite tasks.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 07:23:02 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Chen", "Zhi", ""], ["Liu", "Xiaoyuan", ""], ["Chen", "Lu", ""], ["Yu", "Kai", ""]]}, {"id": "2009.10359", "submitter": "Wei Hu", "authors": "Difeng Wang and Wei Hu and Ermei Cao and Weijian Sun", "title": "Global-to-Local Neural Networks for Document-Level Relation Extraction", "comments": "Accepted in the 2020 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation extraction (RE) aims to identify the semantic relations between\nnamed entities in text. Recent years have witnessed it raised to the document\nlevel, which requires complex reasoning with entities and mentions throughout\nan entire document. In this paper, we propose a novel model to document-level\nRE, by encoding the document information in terms of entity global and local\nrepresentations as well as context relation representations. Entity global\nrepresentations model the semantic information of all entities in the document,\nentity local representations aggregate the contextual information of multiple\nmentions of specific entities, and context relation representations encode the\ntopic information of other relations. Experimental results demonstrate that our\nmodel achieves superior performance on two public datasets for document-level\nRE. It is particularly effective in extracting relations between entities of\nlong distance and having multiple mentions.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 07:30:19 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Wang", "Difeng", ""], ["Hu", "Wei", ""], ["Cao", "Ermei", ""], ["Sun", "Weijian", ""]]}, {"id": "2009.10387", "submitter": "Richard Moot", "authors": "Richard Moot (TEXTE, LIRMM, CNRS), Symon Stevens-Guille", "title": "Logical foundations for hybrid type-logical grammars", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores proof-theoretic aspects of hybrid type-logical grammars ,\na logic combining Lambek grammars with lambda grammars. We prove some basic\nproperties of the calculus, such as normalisation and the subformula property\nand also present both a sequent and a proof net calculus for hybrid\ntype-logical grammars. In addition to clarifying the logical foundations of\nhybrid type-logical grammars, the current study opens the way to variants and\nextensions of the original system, including but not limited to a\nnon-associative version and a multimodal version incorporating structural rules\nand unary modes.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 08:26:14 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Moot", "Richard", "", "TEXTE, LIRMM, CNRS"], ["Stevens-Guille", "Symon", ""]]}, {"id": "2009.10430", "submitter": "Zhi Chen", "authors": "Zhi Chen, Lu Chen, Yanbin Zhao, Su Zhu and Kai Yu", "title": "Dual Learning for Dialogue State Tracking", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In task-oriented multi-turn dialogue systems, dialogue state refers to a\ncompact representation of the user goal in the context of dialogue history.\nDialogue state tracking (DST) is to estimate the dialogue state at each turn.\nDue to the dependency on complicated dialogue history contexts, DST data\nannotation is more expensive than single-sentence language understanding, which\nmakes the task more challenging. In this work, we formulate DST as a sequence\ngeneration problem and propose a novel dual-learning framework to make full use\nof unlabeled data. In the dual-learning framework, there are two agents: the\nprimal tracker agent (utterance-to-state generator) and the dual utterance\ngenerator agent (state-to-utterance genera-tor). Compared with traditional\nsupervised learning framework, dual learning can iteratively update both agents\nthrough the reconstruction error and reward signal respectively without labeled\ndata. Reward sparsity problem is hard to solve in previous DST methods. In this\nwork, the reformulation of DST as a sequence generation model effectively\nalleviates this problem. We call this primal tracker agent dual-DST.\nExperimental results on MultiWOZ2.1 dataset show that the proposed dual-DST\nworks very well, especially when labelled data is limited. It achieves\ncomparable performance to the system where labeled data is fully used.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 10:15:09 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Chen", "Zhi", ""], ["Chen", "Lu", ""], ["Zhao", "Yanbin", ""], ["Zhu", "Su", ""], ["Yu", "Kai", ""]]}, {"id": "2009.10435", "submitter": "Zhi Chen", "authors": "Zhi Chen, Lu Chen, Zihan Xu, Yanbin Zhao, Su Zhu and Kai Yu", "title": "CREDIT: Coarse-to-Fine Sequence Generation for Dialogue State Tracking", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In dialogue systems, a dialogue state tracker aims to accurately find a\ncompact representation of the current dialogue status, based on the entire\ndialogue history. While previous approaches often define dialogue states as a\ncombination of separate triples ({\\em domain-slot-value}), in this paper, we\nemploy a structured state representation and cast dialogue state tracking as a\nsequence generation problem. Based on this new formulation, we propose a {\\bf\nC}oa{\\bf R}s{\\bf E}-to-fine {\\bf DI}alogue state {\\bf T}racking ({\\bf CREDIT})\napproach. Taking advantage of the structured state representation, which is a\nmarked language sequence, we can further fine-tune the pre-trained model (by\nsupervised learning) by optimizing natural language metrics with the policy\ngradient method. Like all generative state tracking methods, CREDIT does not\nrely on pre-defined dialogue ontology enumerating all possible slot values.\nExperiments demonstrate our tracker achieves encouraging joint goal accuracy\nfor the five domains in MultiWOZ 2.0 and MultiWOZ 2.1 datasets.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 10:27:18 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Chen", "Zhi", ""], ["Chen", "Lu", ""], ["Xu", "Zihan", ""], ["Zhao", "Yanbin", ""], ["Zhu", "Su", ""], ["Yu", "Kai", ""]]}, {"id": "2009.10447", "submitter": "Hwaran Lee", "authors": "Hwaran Lee, Seokhwan Jo, HyungJun Kim, Sangkeun Jung, Tae-Yoon Kim", "title": "SUMBT+LaRL: End-to-end Neural Task-oriented Dialog System with\n  Reinforcement Learning", "comments": "13 pages, 5 figures. This work has been submitted to the IEEE/ACM\n  Transactions on Audio Speech and Language Processing for possible\n  publication. Copyright may be transferred without notice, after which this\n  version may no longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advent of neural approaches for developing each dialog component\nin task-oriented dialog systems has remarkably improved, yet optimizing the\noverall system performance remains a challenge. In this paper, we propose an\nend-to-end trainable neural dialog system with reinforcement learning, named\nSUMBT+LaRL. The SUMBT+ estimates user-acts as well as dialog belief states, and\nthe LaRL models latent system action spaces and generates responses given the\nestimated contexts. We experimentally demonstrate that the training framework\nin which the SUMBT+ and LaRL are separately pretrained and then the entire\nsystem is fine-tuned significantly increases dialog success rates. We propose\nnew success criteria for reinforcement learning to the end-to-end dialog system\nas well as provide experimental analysis on a different result aspect depending\non the success criteria and evaluation methods. Consequently, our model\nachieved the new state-of-the-art success rate of 85.4% on corpus-based\nevaluation, and a comparable success rate of 81.40% on simulator-based\nevaluation provided by the DSTC8 challenge.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 11:02:21 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 02:17:27 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Lee", "Hwaran", ""], ["Jo", "Seokhwan", ""], ["Kim", "HyungJun", ""], ["Jung", "Sangkeun", ""], ["Kim", "Tae-Yoon", ""]]}, {"id": "2009.10542", "submitter": "Daoud Clarke", "authors": "Daoud Clarke", "title": "Context-theoretic Semantics for Natural Language: an Algebraic Framework", "comments": "PhD thesis submitted September 2007. 162 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Techniques in which words are represented as vectors have proved useful in\nmany applications in computational linguistics, however there is currently no\ngeneral semantic formalism for representing meaning in terms of vectors. We\npresent a framework for natural language semantics in which words, phrases and\nsentences are all represented as vectors, based on a theoretical analysis which\nassumes that meaning is determined by context.\n  In the theoretical analysis, we define a corpus model as a mathematical\nabstraction of a text corpus. The meaning of a string of words is assumed to be\na vector representing the contexts it occurs in in the corpus model. Based on\nthis assumption, we can show that the vector representations of words can be\nconsidered as elements of an algebra over a field. We note that in applications\nof vector spaces to representing meanings of words there is an underlying\nlattice structure; we interpret the partial ordering of the lattice as\ndescribing entailment between meanings. We also define the context-theoretic\nprobability of a string, and, based on this and the lattice structure, a degree\nof entailment between strings.\n  Together these properties form guidelines as to how to construct semantic\nrepresentations within the framework. A context theory is an implementation of\nthe framework; in an implementation strings are represented as vectors with the\nproperties deduced from the theoretical analysis.\n  We show how to incorporate logical semantics into context theories; this\nenables us to represent statistical information about uncertainty by taking\nweighted sums of individual representations. We also use the framework to\nanalyse approaches to the task of recognising textual entailment, to\nontological representations of meaning and to representing syntactic structure.\nFor the latter, we give new algebraic descriptions of link grammar.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 13:31:37 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Clarke", "Daoud", ""]]}, {"id": "2009.10557", "submitter": "Huaishao Luo", "authors": "Huaishao Luo, Lei Ji, Tianrui Li, Nan Duan, Daxin Jiang", "title": "GRACE: Gradient Harmonized and Cascaded Labeling for Aspect-based\n  Sentiment Analysis", "comments": "to appear in Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on the imbalance issue, which is rarely studied in\naspect term extraction and aspect sentiment classification when regarding them\nas sequence labeling tasks. Besides, previous works usually ignore the\ninteraction between aspect terms when labeling polarities. We propose a\nGRadient hArmonized and CascadEd labeling model (GRACE) to solve these\nproblems. Specifically, a cascaded labeling module is developed to enhance the\ninterchange between aspect terms and improve the attention of sentiment tokens\nwhen labeling sentiment polarities. The polarities sequence is designed to\ndepend on the generated aspect terms labels. To alleviate the imbalance issue,\nwe extend the gradient harmonized mechanism used in object detection to the\naspect-based sentiment analysis by adjusting the weight of each label\ndynamically. The proposed GRACE adopts a post-pretraining BERT as its backbone.\nExperimental results demonstrate that the proposed model achieves consistency\nimprovement on multiple benchmark datasets and generates state-of-the-art\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 13:55:34 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 03:19:54 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Luo", "Huaishao", ""], ["Ji", "Lei", ""], ["Li", "Tianrui", ""], ["Duan", "Nan", ""], ["Jiang", "Daxin", ""]]}, {"id": "2009.10680", "submitter": "Wei Zhu", "authors": "Wei Zhu, Xipeng Qiu, Yuan Ni and Guotong Xie", "title": "AutoRC: Improving BERT Based Relation Classification Models via\n  Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although BERT based relation classification (RC) models have achieved\nsignificant improvements over the traditional deep learning models, it seems\nthat no consensus can be reached on what is the optimal architecture. Firstly,\nthere are multiple alternatives for entity span identification. Second, there\nare a collection of pooling operations to aggregate the representations of\nentities and contexts into fixed length vectors. Third, it is difficult to\nmanually decide which feature vectors, including their interactions, are\nbeneficial for classifying the relation types. In this work, we design a\ncomprehensive search space for BERT based RC models and employ neural\narchitecture search (NAS) method to automatically discover the design choices\nmentioned above. Experiments on seven benchmark RC tasks show that our method\nis efficient and effective in finding better architectures than the baseline\nBERT based RC model. Ablation study demonstrates the necessity of our search\nspace design and the effectiveness of our search method.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 16:55:49 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 02:37:03 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Zhu", "Wei", ""], ["Qiu", "Xipeng", ""], ["Ni", "Yuan", ""], ["Xie", "Guotong", ""]]}, {"id": "2009.10684", "submitter": "Bruno Taill\\'e", "authors": "Bruno Taill\\'e, Vincent Guigue, Geoffrey Scoutheeten and Patrick\n  Gallinari", "title": "Let's Stop Incorrect Comparisons in End-to-end Relation Extraction!", "comments": "Accepted at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite efforts to distinguish three different evaluation setups (Bekoulis et\nal., 2018), numerous end-to-end Relation Extraction (RE) articles present\nunreliable performance comparison to previous work. In this paper, we first\nidentify several patterns of invalid comparisons in published papers and\ndescribe them to avoid their propagation. We then propose a small empirical\nstudy to quantify the impact of the most common mistake and evaluate it leads\nto overestimating the final RE performance by around 5% on ACE05. We also seize\nthis opportunity to study the unexplored ablations of two recent developments:\nthe use of language model pretraining (specifically BERT) and span-level NER.\nThis meta-analysis emphasizes the need for rigor in the report of both the\nevaluation setting and the datasets statistics and we call for unifying the\nevaluation setting in end-to-end RE.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 16:59:15 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 16:43:35 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Taill\u00e9", "Bruno", ""], ["Guigue", "Vincent", ""], ["Scoutheeten", "Geoffrey", ""], ["Gallinari", "Patrick", ""]]}, {"id": "2009.10750", "submitter": "Sahisnu Mazumder", "authors": "Bing Liu, Sahisnu Mazumder", "title": "Lifelong Learning Dialogue Systems: Chatbots that Self-Learn On the Job", "comments": "A revised version of this work has been published in AAAI-2021 with\n  title: \"Lifelong and Continual Learning Dialogue Systems: Learning during\n  Conversation\". Please use this revised AAAI-21 version for citation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue systems, also called chatbots, are now used in a wide range of\napplications. However, they still have some major weaknesses. One key weakness\nis that they are typically trained from manually-labeled data and/or written\nwith handcrafted rules, and their knowledge bases (KBs) are also compiled by\nhuman experts. Due to the huge amount of manual effort involved, they are\ndifficult to scale and also tend to produce many errors ought to their limited\nability to understand natural language and the limited knowledge in their KBs.\nThus, the level of user satisfactory is often low. In this paper, we propose to\ndramatically improve this situation by endowing the system the ability to\ncontinually learn (1) new world knowledge, (2) new language expressions to\nground them to actions, and (3) new conversational skills, during conversation\nor \"on the job\" by themselves so that as the systems chat more and more with\nusers, they become more and more knowledgeable and are better and better able\nto understand diverse natural language expressions and improve their\nconversational skills. A key approach to achieving these is to exploit the\nmulti-user environment of such systems to self-learn through interactions with\nusers via verb and non-verb means. The paper discusses not only key challenges\nand promising directions to learn from users during conversation but also how\nto ensure the correctness of the learned knowledge.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 18:10:08 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 00:10:21 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Liu", "Bing", ""], ["Mazumder", "Sahisnu", ""]]}, {"id": "2009.10778", "submitter": "Danqing Zhang", "authors": "Danqing Zhang, Tao Li, Haiyang Zhang, Bing Yin", "title": "On Data Augmentation for Extreme Multi-label Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on data augmentation for the extreme multi-label\nclassification (XMC) problem. One of the most challenging issues of XMC is the\nlong tail label distribution where even strong models suffer from insufficient\nsupervision. To mitigate such label bias, we propose a simple and effective\naugmentation framework and a new state-of-the-art classifier. Our augmentation\nframework takes advantage of the pre-trained GPT-2 model to generate\nlabel-invariant perturbations of the input texts to augment the existing\ntraining data. As a result, it present substantial improvements over baseline\nmodels. Our contributions are two-factored: (1) we introduce a new\nstate-of-the-art classifier that uses label attention with RoBERTa and combine\nit with our augmentation framework for further improvement; (2) we present a\nbroad study on how effective are different augmentation methods in the XMC\ntask.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 19:31:08 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Zhang", "Danqing", ""], ["Li", "Tao", ""], ["Zhang", "Haiyang", ""], ["Yin", "Bing", ""]]}, {"id": "2009.10792", "submitter": "Ehsan Doostmohammadi", "authors": "Ehsan Doostmohammadi, Hossein Sameti, Ali Saffar", "title": "Ghmerti at SemEval-2019 Task 6: A Deep Word- and Character-based\n  Approach to Offensive Language Identification", "comments": null, "journal-ref": null, "doi": "10.18653/v1/S19-2110", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the models submitted by Ghmerti team for subtasks A and B\nof the OffensEval shared task at SemEval 2019. OffensEval addresses the problem\nof identifying and categorizing offensive language in social media in three\nsubtasks; whether or not a content is offensive (subtask A), whether it is\ntargeted (subtask B) towards an individual, a group, or other entities (subtask\nC). The proposed approach includes character-level Convolutional Neural\nNetwork, word-level Recurrent Neural Network, and some preprocessing. The\nperformance achieved by the proposed model for subtask A is 77.93%\nmacro-averaged F1-score.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 20:13:48 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Doostmohammadi", "Ehsan", ""], ["Sameti", "Hossein", ""], ["Saffar", "Ali", ""]]}, {"id": "2009.10794", "submitter": "Ehsan Doostmohammadi", "authors": "Ehsan Doostmohammadi, Minoo Nassajian", "title": "Investigating Machine Learning Methods for Language and Dialect\n  Identification of Cuneiform Texts", "comments": null, "journal-ref": null, "doi": "10.18653/v1/W19-1420", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identification of the languages written using cuneiform symbols is a\ndifficult task due to the lack of resources and the problem of tokenization.\nThe Cuneiform Language Identification task in VarDial 2019 addresses the\nproblem of identifying seven languages and dialects written in cuneiform;\nSumerian and six dialects of Akkadian language: Old Babylonian, Middle\nBabylonian Peripheral, Standard Babylonian, Neo-Babylonian, Late Babylonian,\nand Neo-Assyrian. This paper describes the approaches taken by SharifCL team to\nthis problem in VarDial 2019. The best result belongs to an ensemble of Support\nVector Machines and a naive Bayes classifier, both working on character-level\nfeatures, with macro-averaged F1-score of 72.10%.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 20:17:45 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Doostmohammadi", "Ehsan", ""], ["Nassajian", "Minoo", ""]]}, {"id": "2009.10795", "submitter": "Swabha Swayamdipta", "authors": "Swabha Swayamdipta, Roy Schwartz, Nicholas Lourie, Yizhong Wang,\n  Hannaneh Hajishirzi, Noah A. Smith, Yejin Choi", "title": "Dataset Cartography: Mapping and Diagnosing Datasets with Training\n  Dynamics", "comments": "Proceedings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large datasets have become commonplace in NLP research. However, the\nincreased emphasis on data quantity has made it challenging to assess the\nquality of data. We introduce Data Maps---a model-based tool to characterize\nand diagnose datasets. We leverage a largely ignored source of information: the\nbehavior of the model on individual instances during training (training\ndynamics) for building data maps. This yields two intuitive measures for each\nexample---the model's confidence in the true class, and the variability of this\nconfidence across epochs---obtained in a single run of training. Experiments\nacross four datasets show that these model-dependent measures reveal three\ndistinct regions in the data map, each with pronounced characteristics. First,\nour data maps show the presence of \"ambiguous\" regions with respect to the\nmodel, which contribute the most towards out-of-distribution generalization.\nSecond, the most populous regions in the data are \"easy to learn\" for the\nmodel, and play an important role in model optimization. Finally, data maps\nuncover a region with instances that the model finds \"hard to learn\"; these\noften correspond to labeling errors. Our results indicate that a shift in focus\nfrom quantity to quality of data could lead to robust models and improved\nout-of-distribution generalization.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 20:19:41 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 05:53:46 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Swayamdipta", "Swabha", ""], ["Schwartz", "Roy", ""], ["Lourie", "Nicholas", ""], ["Wang", "Yizhong", ""], ["Hajishirzi", "Hannaneh", ""], ["Smith", "Noah A.", ""], ["Choi", "Yejin", ""]]}, {"id": "2009.10815", "submitter": "Ritam Dutt", "authors": "Ritam Dutt, Rishabh Joshi, Carolyn Penstein Rose", "title": "Keeping Up Appearances: Computational Modeling of Face Acts in\n  Persuasion Oriented Discussions", "comments": "To appear at Proceedings of the 2020 Conference on Empirical Methods\n  in Natural Language Processing (EMNLP, 2020) as a full paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of face refers to the public self-image of an individual that\nemerges both from the individual's own actions as well as from the interaction\nwith others. Modeling face and understanding its state changes throughout a\nconversation is critical to the study of maintenance of basic human needs in\nand through interaction. Grounded in the politeness theory of Brown and\nLevinson (1978), we propose a generalized framework for modeling face acts in\npersuasion conversations, resulting in a reliable coding manual, an annotated\ncorpus, and computational models. The framework reveals insights about\ndifferences in face act utilization between asymmetric roles in persuasion\nconversations. Using computational models, we are able to successfully identify\nface acts as well as predict a key conversational outcome (e.g. donation\nsuccess). Finally, we model a latent representation of the conversational state\nto analyze the impact of predicted face acts on the probability of a positive\nconversational outcome and observe several correlations that corroborate\nprevious findings.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 21:02:14 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 02:10:44 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Dutt", "Ritam", ""], ["Joshi", "Rishabh", ""], ["Rose", "Carolyn Penstein", ""]]}, {"id": "2009.10847", "submitter": "Mikhail Galkin", "authors": "Mikhail Galkin, Priyansh Trivedi, Gaurav Maheshwari, Ricardo Usbeck,\n  Jens Lehmann", "title": "Message Passing for Hyper-Relational Knowledge Graphs", "comments": "Accepted to EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyper-relational knowledge graphs (KGs) (e.g., Wikidata) enable associating\nadditional key-value pairs along with the main triple to disambiguate, or\nrestrict the validity of a fact. In this work, we propose a message passing\nbased graph encoder - StarE capable of modeling such hyper-relational KGs.\nUnlike existing approaches, StarE can encode an arbitrary number of additional\ninformation (qualifiers) along with the main triple while keeping the semantic\nroles of qualifiers and triples intact. We also demonstrate that existing\nbenchmarks for evaluating link prediction (LP) performance on hyper-relational\nKGs suffer from fundamental flaws and thus develop a new Wikidata-based dataset\n- WD50K. Our experiments demonstrate that StarE based LP model outperforms\nexisting approaches across multiple benchmarks. We also confirm that leveraging\nqualifiers is vital for link prediction with gains up to 25 MRR points compared\nto triple-based representations.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 22:38:54 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Galkin", "Mikhail", ""], ["Trivedi", "Priyansh", ""], ["Maheshwari", "Gaurav", ""], ["Usbeck", "Ricardo", ""], ["Lehmann", "Jens", ""]]}, {"id": "2009.10855", "submitter": "Y-Lan Boureau", "authors": "Eric Michael Smith, Diana Gonzalez-Rico, Emily Dinan, Y-Lan Boureau", "title": "Controlling Style in Generated Dialogue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-domain conversation models have become good at generating\nnatural-sounding dialogue, using very large architectures with billions of\ntrainable parameters. The vast training data required to train these\narchitectures aggregates many different styles, tones, and qualities. Using\nthat data to train a single model makes it difficult to use the model as a\nconsistent conversational agent, e.g. with a stable set of persona traits and a\ntypical style of expression. Several architectures affording control mechanisms\nover generation architectures have been proposed, each with different\ntrade-offs. However, it remains unclear whether their use in dialogue is\nviable, and what the trade-offs look like with the most recent state-of-the-art\nconversational architectures. In this work, we adapt three previously proposed\ncontrollable generation architectures to open-domain dialogue generation,\ncontrolling the style of the generation to match one among about 200 possible\nstyles. We compare their respective performance and tradeoffs, and show how\nthey can be used to provide insights into existing conversational datasets, and\ngenerate a varied set of styled conversation replies.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 23:21:04 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Smith", "Eric Michael", ""], ["Gonzalez-Rico", "Diana", ""], ["Dinan", "Emily", ""], ["Boureau", "Y-Lan", ""]]}, {"id": "2009.10938", "submitter": "Xinyi Zhang", "authors": "Xinyi Zhang and Jiahao Xu and Charlie Soh and Lihui Chen", "title": "LA-HCN: Label-based Attention for Hierarchical Multi-label\n  TextClassification Neural Network", "comments": "code is available at https://github.com/XinyiZ001/LA-HCN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical multi-label text classification (HMTC) has been gaining\npopularity in recent years thanks to its applicability to a plethora of\nreal-world applications. The existing HMTC algorithms largely focus on the\ndesign of classifiers, such as the local, global, or a combination of them.\nHowever, very few studies have focused on hierarchical feature extraction and\nexplore the association between the hierarchical labels and the text. In this\npaper, we propose a Label-based Attention for Hierarchical Mutlti-label Text\nClassification Neural Network (LA-HCN), where the novel label-based attention\nmodule is designed to hierarchically extract important information from the\ntext based on the labels from different hierarchy levels. Besides, hierarchical\ninformation is shared across levels while preserving the hierarchical\nlabel-based information. Separate local and global document embeddings are\nobtained and used to facilitate the respective local and global\nclassifications. In our experiments, LA-HCN outperforms other state-of-the-art\nneural network-based HMTC algorithms on four public HMTC datasets. The ablation\nstudy also demonstrates the effectiveness of the proposed label-based attention\nmodule as well as the novel local and global embeddings and classifications. By\nvisualizing the learned attention (words), we find that LA-HCN is able to\nextract meaningful information corresponding to the different labels which\nprovides explainability that may be helpful for the human analyst.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 06:18:25 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 10:43:11 GMT"}, {"version": "v3", "created": "Sat, 10 Apr 2021 12:20:53 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Zhang", "Xinyi", ""], ["Xu", "Jiahao", ""], ["Soh", "Charlie", ""], ["Chen", "Lihui", ""]]}, {"id": "2009.11005", "submitter": "Khang Nguyen", "authors": "Khang Phuoc-Quy Nguyen and Kiet Van Nguyen", "title": "Exploiting Vietnamese Social Media Characteristics for Textual Emotion\n  Recognition in Vietnamese", "comments": "6 pages, 9 tables, 2 figures of table, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Textual emotion recognition has been a promising research topic in recent\nyears. Many researchers aim to build more accurate and robust emotion detection\nsystems. In this paper, we conduct several experiments to indicate how data\npre-processing affects a machine learning method on textual emotion\nrecognition. These experiments are performed on the Vietnamese Social Media\nEmotion Corpus (UIT-VSMEC) as the benchmark dataset. We explore Vietnamese\nsocial media characteristics to propose different pre-processing techniques,\nand key-clause extraction with emotional context to improve the machine\nperformance on UIT-VSMEC. Our experimental evaluation shows that with\nappropriate pre-processing techniques based on Vietnamese social media\ncharacteristics, Multinomial Logistic Regression (MLR) achieves the best\nF1-score of 64.40%, a significant improvement of 4.66% over the CNN model built\nby the authors of UIT-VSMEC (59.74%).\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 08:49:39 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 15:46:49 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 14:39:40 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Nguyen", "Khang Phuoc-Quy", ""], ["Van Nguyen", "Kiet", ""]]}, {"id": "2009.11023", "submitter": "Oana-Maria Camburu", "authors": "Oana-Maria Camburu, Eleonora Giunchiglia, Jakob Foerster, Thomas\n  Lukasiewicz, Phil Blunsom", "title": "The Struggles of Feature-Based Explanations: Shapley Values vs. Minimal\n  Sufficient Subsets", "comments": null, "journal-ref": "Explainable Agency in Artificial Intelligence Workshop at AAAI\n  2021", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For neural models to garner widespread public trust and ensure fairness, we\nmust have human-intelligible explanations for their predictions. Recently, an\nincreasing number of works focus on explaining the predictions of neural models\nin terms of the relevance of the input features. In this work, we show that\nfeature-based explanations pose problems even for explaining trivial models. We\nshow that, in certain cases, there exist at least two ground-truth\nfeature-based explanations, and that, sometimes, neither of them is enough to\nprovide a complete view of the decision-making process of the model. Moreover,\nwe show that two popular classes of explainers, Shapley explainers and minimal\nsufficient subsets explainers, target fundamentally different types of\nground-truth explanations, despite the apparently implicit assumption that\nexplainers should look for one specific feature-based explanation. These\nfindings bring an additional dimension to consider in both developing and\nchoosing explainers.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 09:45:23 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 13:46:26 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Camburu", "Oana-Maria", ""], ["Giunchiglia", "Eleonora", ""], ["Foerster", "Jakob", ""], ["Lukasiewicz", "Thomas", ""], ["Blunsom", "Phil", ""]]}, {"id": "2009.11027", "submitter": "Zorik Gekhman", "authors": "Zorik Gekhman, Roee Aharoni, Genady Beryozkin, Markus Freitag,\n  Wolfgang Macherey", "title": "KoBE: Knowledge-Based Machine Translation Evaluation", "comments": "Accepted as a short paper in Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple and effective method for machine translation evaluation\nwhich does not require reference translations. Our approach is based on (1)\ngrounding the entity mentions found in each source sentence and candidate\ntranslation against a large-scale multilingual knowledge base, and (2)\nmeasuring the recall of the grounded entities found in the candidate vs. those\nfound in the source. Our approach achieves the highest correlation with human\njudgements on 9 out of the 18 language pairs from the WMT19 benchmark for\nevaluation without references, which is the largest number of wins for a single\nevaluation method on this task. On 4 language pairs, we also achieve higher\ncorrelation with human judgements than BLEU. To foster further research, we\nrelease a dataset containing 1.8 million grounded entity mentions across 18\nlanguage pairs from the WMT19 metrics track data.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 09:52:28 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Gekhman", "Zorik", ""], ["Aharoni", "Roee", ""], ["Beryozkin", "Genady", ""], ["Freitag", "Markus", ""], ["Macherey", "Wolfgang", ""]]}, {"id": "2009.11032", "submitter": "Arie Cattan", "authors": "Arie Cattan, Alon Eirew, Gabriel Stanovsky, Mandar Joshi, and Ido\n  Dagan", "title": "Streamlining Cross-Document Coreference Resolution: Evaluation and\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent evaluation protocols for Cross-document (CD) coreference resolution\nhave often been inconsistent or lenient, leading to incomparable results across\nworks and overestimation of performance. To facilitate proper future research\non this task, our primary contribution is proposing a pragmatic evaluation\nmethodology which assumes access to only raw text -- rather than assuming gold\nmentions, disregards singleton prediction, and addresses typical targeted\nsettings in CD coreference resolution. Aiming to set baseline results for\nfuture research that would follow our evaluation methodology, we build the\nfirst end-to-end model for this task. Our model adapts and extends recent\nneural models for within-document coreference resolution to address the CD\ncoreference setting, which outperforms state-of-the-art results by a\nsignificant margin.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 10:02:10 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 12:18:01 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 13:40:30 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Cattan", "Arie", ""], ["Eirew", "Alon", ""], ["Stanovsky", "Gabriel", ""], ["Joshi", "Mandar", ""], ["Dagan", "Ido", ""]]}, {"id": "2009.11119", "submitter": "Qi Qin", "authors": "Qi Qin, Wenpeng Hu, Bing Liu", "title": "Text Classification with Novelty Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of detecting novel or unexpected instances in\ntext classification. In traditional text classification, the classes appeared\nin testing must have been seen in training. However, in many applications, this\nis not the case because in testing, we may see unexpected instances that are\nnot from any of the training classes. In this paper, we propose a significantly\nmore effective approach that converts the original problem to a pair-wise\nmatching problem and then outputs how probable two instances belong to the same\nclass. Under this approach, we present two models. The more effective model\nuses two embedding matrices of a pair of instances as two channels of a CNN.\nThe output probabilities from such pairs are used to judge whether a test\ninstance is from a seen class or is novel/unexpected. Experimental results show\nthat the proposed method substantially outperforms the state-of-the-art\nbaselines.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 12:54:34 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Qin", "Qi", ""], ["Hu", "Wenpeng", ""], ["Liu", "Bing", ""]]}, {"id": "2009.11129", "submitter": "Saba Nazir", "authors": "Saba Nazir, Taner Cagali, Chris Newell, Mehrnoosh Sadrzadeh", "title": "Cosine Similarity of Multimodal Content Vectors for TV Programmes", "comments": "3 pages, 1 figure, Machine Learning for Media Discovery (ML4MD)\n  Workshop at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multimodal information originates from a variety of sources: audiovisual\nfiles, textual descriptions, and metadata. We show how one can represent the\ncontent encoded by each individual source using vectors, how to combine the\nvectors via middle and late fusion techniques, and how to compute the semantic\nsimilarities between the contents. Our vectorial representations are built from\nspectral features and Bags of Audio Words, for audio, LSI topics and Doc2vec\nembeddings for subtitles, and the categorical features, for metadata. We\nimplement our model on a dataset of BBC TV programmes and evaluate the fused\nrepresentations to provide recommendations. The late fused similarity matrices\nsignificantly improve the precision and diversity of recommendations.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 13:12:30 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Nazir", "Saba", ""], ["Cagali", "Taner", ""], ["Newell", "Chris", ""], ["Sadrzadeh", "Mehrnoosh", ""]]}, {"id": "2009.11136", "submitter": "Felix Stahlberg", "authors": "Felix Stahlberg and Shankar Kumar", "title": "Seq2Edits: Sequence Transduction Using Span-level Edit Operations", "comments": "Accepted at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Seq2Edits, an open-vocabulary approach to sequence editing for\nnatural language processing (NLP) tasks with a high degree of overlap between\ninput and output texts. In this approach, each sequence-to-sequence\ntransduction is represented as a sequence of edit operations, where each\noperation either replaces an entire source span with target tokens or keeps it\nunchanged. We evaluate our method on five NLP tasks (text normalization,\nsentence fusion, sentence splitting & rephrasing, text simplification, and\ngrammatical error correction) and report competitive results across the board.\nFor grammatical error correction, our method speeds up inference by up to 5.2x\ncompared to full sequence models because inference time depends on the number\nof edits rather than the number of target tokens. For text normalization,\nsentence fusion, and grammatical error correction, our approach improves\nexplainability by associating each edit operation with a human-readable tag.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 13:28:38 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Stahlberg", "Felix", ""], ["Kumar", "Shankar", ""]]}, {"id": "2009.11138", "submitter": "Sheng Zhang", "authors": "Sheng Zhang, Xin Zhang, Weiming Zhang, Anders S{\\o}gaard", "title": "Worst-Case-Aware Curriculum Learning for Zero and Few Shot Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task transfer learning based on pre-trained language encoders achieves\nstate-of-the-art performance across a range of tasks. Standard approaches\nimplicitly assume the tasks, for which we have training data, are equally\nrepresentative of the tasks we are interested in, an assumption which is often\nhard to justify. This paper presents a more agnostic approach to multi-task\ntransfer learning, which uses automated curriculum learning to minimize a new\nfamily of worst-case-aware losses across tasks. Not only do these losses lead\nto better performance on outlier tasks; they also lead to better performance in\nzero-shot and few-shot transfer settings.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 13:32:39 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Zhang", "Sheng", ""], ["Zhang", "Xin", ""], ["Zhang", "Weiming", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "2009.11144", "submitter": "Bai Li", "authors": "Bai Li", "title": "Evolution of Part-of-Speech in Classical Chinese", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical Chinese is a language notable for its word class flexibility: the\nsame word may often be used as a noun or a verb. Bisang (2008) claimed that\nClassical Chinese is a precategorical language, where the syntactic position of\na word determines its part-of-speech category. In this paper, we apply\nentropy-based metrics to evaluate these claims on historical corpora. We\nfurther explore differences between nouns and verbs in Classical Chinese: using\npsycholinguistic norms, we find a positive correlation between concreteness and\nnoun usage. Finally, we align character embeddings from Classical and Modern\nChinese, and find that verbs undergo more semantic change than nouns.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 13:41:27 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Li", "Bai", ""]]}, {"id": "2009.11152", "submitter": "Pierre Colombo", "authors": "Emile Chapuis and Pierre Colombo, Matteo Manica, Matthieu Labeau,\n  Chloe Clavel", "title": "Hierarchical Pre-training for Sequence Labelling in Spoken Dialog", "comments": null, "journal-ref": "EMNLP 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence labelling tasks like Dialog Act and Emotion/Sentiment identification\nare a key component of spoken dialog systems. In this work, we propose a new\napproach to learn generic representations adapted to spoken dialog, which we\nevaluate on a new benchmark we call Sequence labellIng evaLuatIon benChmark fOr\nspoken laNguagE benchmark (\\texttt{SILICONE}). \\texttt{SILICONE} is\nmodel-agnostic and contains 10 different datasets of various sizes. We obtain\nour representations with a hierarchical encoder based on transformer\narchitectures, for which we extend two well-known pre-training objectives.\nPre-training is performed on OpenSubtitles: a large corpus of spoken dialog\ncontaining over $2.3$ billion of tokens. We demonstrate how hierarchical\nencoders achieve competitive results with consistently fewer parameters\ncompared to state-of-the-art models and we show their importance for both\npre-training and fine-tuning.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 13:54:57 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 15:58:48 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2021 13:49:19 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Chapuis", "Emile", ""], ["Colombo", "Pierre", ""], ["Manica", "Matteo", ""], ["Labeau", "Matthieu", ""], ["Clavel", "Chloe", ""]]}, {"id": "2009.11201", "submitter": "Xavier Garcia", "authors": "Xavier Garcia, Aditya Siddhant, Orhan Firat, Ankur P. Parikh", "title": "Harnessing Multilinguality in Unsupervised Machine Translation for Rare\n  Languages", "comments": "Accepted to NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised translation has reached impressive performance on resource-rich\nlanguage pairs such as English-French and English-German. However, early\nstudies have shown that in more realistic settings involving low-resource, rare\nlanguages, unsupervised translation performs poorly, achieving less than 3.0\nBLEU. In this work, we show that multilinguality is critical to making\nunsupervised systems practical for low-resource settings. In particular, we\npresent a single model for 5 low-resource languages (Gujarati, Kazakh, Nepali,\nSinhala, and Turkish) to and from English directions, which leverages\nmonolingual and auxiliary parallel data from other high-resource language pairs\nvia a three-stage training scheme. We outperform all current state-of-the-art\nunsupervised baselines for these languages, achieving gains of up to 14.4 BLEU.\nAdditionally, we outperform a large collection of supervised WMT submissions\nfor various language pairs as well as match the performance of the current\nstate-of-the-art supervised model for Nepali-English. We conduct a series of\nablation studies to establish the robustness of our model under different\ndegrees of data quality, as well as to analyze the factors which led to the\nsuperior performance of the proposed approach over traditional unsupervised\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 15:07:33 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 15:59:49 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Garcia", "Xavier", ""], ["Siddhant", "Aditya", ""], ["Firat", "Orhan", ""], ["Parikh", "Ankur P.", ""]]}, {"id": "2009.11207", "submitter": "Tiziano Piccardi", "authors": "Tiziano Piccardi, Robert West", "title": "Crosslingual Topic Modeling with WikiPDA", "comments": "10 pages, WWW - The Web Conference, 2021", "journal-ref": null, "doi": "10.1145/3442381.3449805", "report-no": null, "categories": "cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Wikipedia-based Polyglot Dirichlet Allocation (WikiPDA), a\ncrosslingual topic model that learns to represent Wikipedia articles written in\nany language as distributions over a common set of language-independent topics.\nIt leverages the fact that Wikipedia articles link to each other and are mapped\nto concepts in the Wikidata knowledge base, such that, when represented as bags\nof links, articles are inherently language-independent. WikiPDA works in two\nsteps, by first densifying bags of links using matrix completion and then\ntraining a standard monolingual topic model. A human evaluation shows that\nWikiPDA produces more coherent topics than monolingual text-based LDA, thus\noffering crosslinguality at no cost. We demonstrate WikiPDA's utility in two\napplications: a study of topical biases in 28 Wikipedia editions, and\ncrosslingual supervised classification. Finally, we highlight WikiPDA's\ncapacity for zero-shot language transfer, where a model is reused for new\nlanguages without any fine-tuning. Researchers can benefit from WikiPDA as a\npractical tool for studying Wikipedia's content across its 299 language\neditions in interpretable ways, via an easy-to-use library publicly available\nat https://github.com/epfl-dlab/WikiPDA.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 15:19:27 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2021 13:28:18 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Piccardi", "Tiziano", ""], ["West", "Robert", ""]]}, {"id": "2009.11226", "submitter": "Alexander Kalinowski", "authors": "Alexander Kalinowski and Yuan An", "title": "A Comparative Study on Structural and Semantic Properties of Sentence\n  Embeddings", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence embeddings encode natural language sentences as low-dimensional\ndense vectors. A great deal of effort has been put into using sentence\nembeddings to improve several important natural language processing tasks.\nRelation extraction is such an NLP task that aims at identifying structured\nrelations defined in a knowledge base from unstructured text. A promising and\nmore efficient approach would be to embed both the text and structured\nknowledge in low-dimensional spaces and discover semantic alignments or\nmappings between them. Although a number of techniques have been proposed in\nthe literature for embedding both sentences and knowledge graphs, little is\nknown about the structural and semantic properties of these embedding spaces in\nterms of relation extraction. In this paper, we investigate the aforementioned\nproperties by evaluating the extent to which sentences carrying similar senses\nare embedded in close proximity sub-spaces, and if we can exploit that\nstructure to align sentences to a knowledge graph. We propose a set of\nexperiments using a widely-used large-scale data set for relation extraction\nand focusing on a set of key sentence embedding methods. We additionally\nprovide the code for reproducing these experiments at\nhttps://github.com/akalino/semantic-structural-sentences. These embedding\nmethods cover a wide variety of techniques ranging from simple word embedding\ncombination to transformer-based BERT-style model. Our experimental results\nshow that different embedding spaces have different degrees of strength for the\nstructural and semantic properties. These results provide useful information\nfor developing embedding-based relation extraction methods.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 15:45:32 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Kalinowski", "Alexander", ""], ["An", "Yuan", ""]]}, {"id": "2009.11260", "submitter": "Weiwei Hou", "authors": "Weiwei Hou, Hanna Suominen, Piotr Koniusz, Sabrina Caldwell and Tom\n  Gedeon", "title": "A Token-wise CNN-based Method for Sentence Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence compression is a Natural Language Processing (NLP) task aimed at\nshortening original sentences and preserving their key information. Its\napplications can benefit many fields e.g. one can build tools for language\neducation. However, current methods are largely based on Recurrent Neural\nNetwork (RNN) models which suffer from poor processing speed. To address this\nissue, in this paper, we propose a token-wise Convolutional Neural Network, a\nCNN-based model along with pre-trained Bidirectional Encoder Representations\nfrom Transformers (BERT) features for deletion-based sentence compression. We\nalso compare our model with RNN-based models and fine-tuned BERT. Although one\nof the RNN-based models outperforms marginally other models given the same\ninput, our CNN-based model was ten times faster than the RNN-based approach.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 17:12:06 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Hou", "Weiwei", ""], ["Suominen", "Hanna", ""], ["Koniusz", "Piotr", ""], ["Caldwell", "Sabrina", ""], ["Gedeon", "Tom", ""]]}, {"id": "2009.11264", "submitter": "Satwik Bhattamishra", "authors": "Satwik Bhattamishra, Kabir Ahuja, Navin Goyal", "title": "On the Ability and Limitations of Transformers to Recognize Formal\n  Languages", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers have supplanted recurrent models in a large number of NLP tasks.\nHowever, the differences in their abilities to model different syntactic\nproperties remain largely unknown. Past works suggest that LSTMs generalize\nvery well on regular languages and have close connections with counter\nlanguages. In this work, we systematically study the ability of Transformers to\nmodel such languages as well as the role of its individual components in doing\nso. We first provide a construction of Transformers for a subclass of counter\nlanguages, including well-studied languages such as n-ary Boolean Expressions,\nDyck-1, and its generalizations. In experiments, we find that Transformers do\nwell on this subclass, and their learned mechanism strongly correlates with our\nconstruction. Perhaps surprisingly, in contrast to LSTMs, Transformers do well\nonly on a subset of regular languages with degrading performance as we make\nlanguages more complex according to a well-known measure of complexity. Our\nanalysis also provides insights on the role of self-attention mechanism in\nmodeling certain behaviors and the influence of positional encoding schemes on\nthe learning and generalization abilities of the model.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 17:21:33 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 12:55:37 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Bhattamishra", "Satwik", ""], ["Ahuja", "Kabir", ""], ["Goyal", "Navin", ""]]}, {"id": "2009.11278", "submitter": "Jaemin Cho", "authors": "Jaemin Cho, Jiasen Lu, Dustin Schwenk, Hannaneh Hajishirzi, Aniruddha\n  Kembhavi", "title": "X-LXMERT: Paint, Caption and Answer Questions with Multi-Modal\n  Transformers", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mirroring the success of masked language models, vision-and-language\ncounterparts like ViLBERT, LXMERT and UNITER have achieved state of the art\nperformance on a variety of multimodal discriminative tasks like visual\nquestion answering and visual grounding. Recent work has also successfully\nadapted such models towards the generative task of image captioning. This begs\nthe question: Can these models go the other way and generate images from pieces\nof text? Our analysis of a popular representative from this model family -\nLXMERT - finds that it is unable to generate rich and semantically meaningful\nimagery with its current training setup. We introduce X-LXMERT, an extension to\nLXMERT with training refinements including: discretizing visual\nrepresentations, using uniform masking with a large range of masking ratios and\naligning the right pre-training datasets to the right objectives which enables\nit to paint. X-LXMERT's image generation capabilities rival state of the art\ngenerative models while its question answering and captioning abilities remains\ncomparable to LXMERT. Finally, we demonstrate the generality of these training\nrefinements by adding image generation capabilities into UNITER to produce\nX-UNITER.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 17:45:17 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Cho", "Jaemin", ""], ["Lu", "Jiasen", ""], ["Schwenk", "Dustin", ""], ["Hajishirzi", "Hannaneh", ""], ["Kembhavi", "Aniruddha", ""]]}, {"id": "2009.11321", "submitter": "Ananya B Sai", "authors": "Ananya B. Sai, Akash Kumar Mohankumar, Siddhartha Arora, Mitesh M.\n  Khapra", "title": "Improving Dialog Evaluation with a Multi-reference Adversarial Dataset\n  and Large Scale Pretraining", "comments": "Accepted for publication in TACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing focus on model-based dialog evaluation metrics such as\nADEM, RUBER, and the more recent BERT-based metrics. These models aim to assign\na high score to all relevant responses and a low score to all irrelevant\nresponses. Ideally, such models should be trained using multiple relevant and\nirrelevant responses for any given context. However, no such data is publicly\navailable, and hence existing models are usually trained using a single\nrelevant response and multiple randomly selected responses from other contexts\n(random negatives). To allow for better training and robust evaluation of\nmodel-based metrics, we introduce the DailyDialog++ dataset, consisting of (i)\nfive relevant responses for each context and (ii) five adversarially crafted\nirrelevant responses for each context. Using this dataset, we first show that\neven in the presence of multiple correct references, n-gram based metrics and\nembedding based metrics do not perform well at separating relevant responses\nfrom even random negatives. While model-based metrics perform better than\nn-gram and embedding based metrics on random negatives, their performance drops\nsubstantially when evaluated on adversarial examples. To check if large scale\npretraining could help, we propose a new BERT-based evaluation metric called\nDEB, which is pretrained on 727M Reddit conversations and then finetuned on our\ndataset. DEB significantly outperforms existing models, showing better\ncorrelation with human judgements and better performance on random negatives\n(88.27% accuracy). However, its performance again drops substantially, when\nevaluated on adversarial responses, thereby highlighting that even large-scale\npretrained evaluation models are not robust to the adversarial examples in our\ndataset. The dataset and code are publicly available.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 18:06:52 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Sai", "Ananya B.", ""], ["Mohankumar", "Akash Kumar", ""], ["Arora", "Siddhartha", ""], ["Khapra", "Mitesh M.", ""]]}, {"id": "2009.11340", "submitter": "Tanvi Dinkar", "authors": "Tanvi Dinkar, Pierre Colombo, Matthieu Labeau and Chlo\\'e Clavel", "title": "The importance of fillers for text representations of speech transcripts", "comments": "To appear in EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While being an essential component of spoken language, fillers (e.g.\"um\" or\n\"uh\") often remain overlooked in Spoken Language Understanding (SLU) tasks. We\nexplore the possibility of representing them with deep contextualised\nembeddings, showing improvements on modelling spoken language and two\ndownstream tasks - predicting a speaker's stance and expressed confidence.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 19:03:58 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 10:02:57 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Dinkar", "Tanvi", ""], ["Colombo", "Pierre", ""], ["Labeau", "Matthieu", ""], ["Clavel", "Chlo\u00e9", ""]]}, {"id": "2009.11352", "submitter": "Mohammad Aliannejadi", "authors": "Mohammad Aliannejadi and Julia Kiseleva and Aleksandr Chuklin and Jeff\n  Dalton and Mikhail Burtsev", "title": "ConvAI3: Generating Clarifying Questions for Open-Domain Dialogue\n  Systems (ClariQ)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document presents a detailed description of the challenge on clarifying\nquestions for dialogue systems (ClariQ). The challenge is organized as part of\nthe Conversational AI challenge series (ConvAI3) at Search Oriented\nConversational AI (SCAI) EMNLP workshop in 2020. The main aim of the\nconversational systems is to return an appropriate answer in response to the\nuser requests. However, some user requests might be ambiguous. In IR settings\nsuch a situation is handled mainly thought the diversification of the search\nresult page. It is however much more challenging in dialogue settings with\nlimited bandwidth. Therefore, in this challenge, we provide a common evaluation\nframework to evaluate mixed-initiative conversations. Participants are asked to\nrank clarifying questions in an information-seeking conversations. The\nchallenge is organized in two stages where in Stage 1 we evaluate the\nsubmissions in an offline setting and single-turn conversations. Top\nparticipants of Stage 1 get the chance to have their model tested by human\nannotators.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 19:48:02 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Aliannejadi", "Mohammad", ""], ["Kiseleva", "Julia", ""], ["Chuklin", "Aleksandr", ""], ["Dalton", "Jeff", ""], ["Burtsev", "Mikhail", ""]]}, {"id": "2009.11355", "submitter": "Yasmin Salehi", "authors": "Kian Ahrabian, Aarash Feizi, Yasmin Salehi, William L. Hamilton and\n  Avishek Joey Bose", "title": "Structure Aware Negative Sampling in Knowledge Graphs", "comments": "Accepted to EMNLP 2020. Camera-ready submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning low-dimensional representations for entities and relations in\nknowledge graphs using contrastive estimation represents a scalable and\neffective method for inferring connectivity patterns. A crucial aspect of\ncontrastive learning approaches is the choice of corruption distribution that\ngenerates hard negative samples, which force the embedding model to learn\ndiscriminative representations and find critical characteristics of observed\ndata. While earlier methods either employ too simple corruption distributions,\ni.e. uniform, yielding easy uninformative negatives or sophisticated\nadversarial distributions with challenging optimization schemes, they do not\nexplicitly incorporate known graph structure resulting in suboptimal negatives.\nIn this paper, we propose Structure Aware Negative Sampling (SANS), an\ninexpensive negative sampling strategy that utilizes the rich graph structure\nby selecting negative samples from a node's k-hop neighborhood. Empirically, we\ndemonstrate that SANS finds semantically meaningful negatives and is\ncompetitive with SOTA approaches while requires no additional parameters nor\ndifficult adversarial optimization.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 19:57:00 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 02:23:58 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Ahrabian", "Kian", ""], ["Feizi", "Aarash", ""], ["Salehi", "Yasmin", ""], ["Hamilton", "William L.", ""], ["Bose", "Avishek Joey", ""]]}, {"id": "2009.11382", "submitter": "Chiori Hori Ph.D.", "authors": "Peng Gao, Chiori Hori, Shijie Geng, Takaaki Hori, Jonathan Le Roux", "title": "Multi-Pass Transformer for Machine Translation", "comments": "10 pages, 5 figures and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In contrast with previous approaches where information flows only towards\ndeeper layers of a stack, we consider a multi-pass transformer (MPT)\narchitecture in which earlier layers are allowed to process information in\nlight of the output of later layers. To maintain a directed acyclic graph\nstructure, the encoder stack of a transformer is repeated along a new\nmulti-pass dimension, keeping the parameters tied, and information is allowed\nto proceed unidirectionally both towards deeper layers within an encoder stack\nand towards any layer of subsequent stacks. We consider both soft (i.e.,\ncontinuous) and hard (i.e., discrete) connections between parallel encoder\nstacks, relying on a neural architecture search to find the best connection\npattern in the hard case. We perform an extensive ablation study of the\nproposed MPT architecture and compare it with other state-of-the-art\ntransformer architectures. Surprisingly, Base Transformer equipped with MPT can\nsurpass the performance of Large Transformer on the challenging machine\ntranslation En-De and En-Fr datasets. In the hard connection case, the optimal\nconnection pattern found for En-De also leads to improved performance for\nEn-Fr.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 21:22:15 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Gao", "Peng", ""], ["Hori", "Chiori", ""], ["Geng", "Shijie", ""], ["Hori", "Takaaki", ""], ["Roux", "Jonathan Le", ""]]}, {"id": "2009.11423", "submitter": "Jacob Andreas", "authors": "Semantic Machines, Jacob Andreas, John Bufe, David Burkett, Charles\n  Chen, Josh Clausman, Jean Crawford, Kate Crim, Jordan DeLoach, Leah Dorner,\n  Jason Eisner, Hao Fang, Alan Guo, David Hall, Kristin Hayes, Kellie Hill,\n  Diana Ho, Wendy Iwaszuk, Smriti Jha, Dan Klein, Jayant Krishnamurthy, Theo\n  Lanman, Percy Liang, Christopher H Lin, Ilya Lintsbakh, Andy McGovern,\n  Aleksandr Nisnevich, Adam Pauls, Dmitrij Petters, Brent Read, Dan Roth,\n  Subhro Roy, Jesse Rusak, Beth Short, Div Slomin, Ben Snyder, Stephon\n  Striplin, Yu Su, Zachary Tellman, Sam Thomson, Andrei Vorobev, Izabela\n  Witoszko, Jason Wolfe, Abby Wray, Yuchen Zhang, Alexander Zotov", "title": "Task-Oriented Dialogue as Dataflow Synthesis", "comments": null, "journal-ref": "Transactions of the Association for Computational Linguistics 2020\n  Vol. 8, 556-571", "doi": "10.1162/tacl_a_00333", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an approach to task-oriented dialogue in which dialogue state is\nrepresented as a dataflow graph. A dialogue agent maps each user utterance to a\nprogram that extends this graph. Programs include metacomputation operators for\nreference and revision that reuse dataflow fragments from previous turns. Our\ngraph-based state enables the expression and manipulation of complex user\nintents, and explicit metacomputation makes these intents easier for learned\nmodels to predict. We introduce a new dataset, SMCalFlow, featuring complex\ndialogues about events, weather, places, and people. Experiments show that\ndataflow graphs and metacomputation substantially improve representability and\npredictability in these natural dialogues. Additional experiments on the\nMultiWOZ dataset show that our dataflow representation enables an otherwise\noff-the-shelf sequence-to-sequence model to match the best existing\ntask-specific state tracking model. The SMCalFlow dataset and code for\nreplicating experiments are available at\nhttps://www.microsoft.com/en-us/research/project/dataflow-based-dialogue-semantic-machines.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 00:35:26 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 20:01:18 GMT"}, {"version": "v3", "created": "Thu, 11 Feb 2021 00:10:56 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Machines", "Semantic", ""], ["Andreas", "Jacob", ""], ["Bufe", "John", ""], ["Burkett", "David", ""], ["Chen", "Charles", ""], ["Clausman", "Josh", ""], ["Crawford", "Jean", ""], ["Crim", "Kate", ""], ["DeLoach", "Jordan", ""], ["Dorner", "Leah", ""], ["Eisner", "Jason", ""], ["Fang", "Hao", ""], ["Guo", "Alan", ""], ["Hall", "David", ""], ["Hayes", "Kristin", ""], ["Hill", "Kellie", ""], ["Ho", "Diana", ""], ["Iwaszuk", "Wendy", ""], ["Jha", "Smriti", ""], ["Klein", "Dan", ""], ["Krishnamurthy", "Jayant", ""], ["Lanman", "Theo", ""], ["Liang", "Percy", ""], ["Lin", "Christopher H", ""], ["Lintsbakh", "Ilya", ""], ["McGovern", "Andy", ""], ["Nisnevich", "Aleksandr", ""], ["Pauls", "Adam", ""], ["Petters", "Dmitrij", ""], ["Read", "Brent", ""], ["Roth", "Dan", ""], ["Roy", "Subhro", ""], ["Rusak", "Jesse", ""], ["Short", "Beth", ""], ["Slomin", "Div", ""], ["Snyder", "Ben", ""], ["Striplin", "Stephon", ""], ["Su", "Yu", ""], ["Tellman", "Zachary", ""], ["Thomson", "Sam", ""], ["Vorobev", "Andrei", ""], ["Witoszko", "Izabela", ""], ["Wolfe", "Jason", ""], ["Wray", "Abby", ""], ["Zhang", "Yuchen", ""], ["Zotov", "Alexander", ""]]}, {"id": "2009.11436", "submitter": "Daiki Takeuchi", "authors": "Daiki Takeuchi, Yuma Koizumi, Yasunori Ohishi, Noboru Harada, Kunio\n  Kashino", "title": "Effects of Word-frequency based Pre- and Post- Processings for Audio\n  Captioning", "comments": "Accepted to DCASE2020 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The system we used for Task 6 (Automated Audio Captioning)of the Detection\nand Classification of Acoustic Scenes and Events(DCASE) 2020 Challenge combines\nthree elements, namely, dataaugmentation, multi-task learning, and\npost-processing, for audiocaptioning. The system received the highest\nevaluation scores, butwhich of the individual elements most fully contributed\nto its perfor-mance has not yet been clarified. Here, to asses their\ncontributions,we first conducted an element-wise ablation study on our systemto\nestimate to what extent each element is effective. We then con-ducted a\ndetailed module-wise ablation study to further clarify thekey processing\nmodules for improving accuracy. The results showthat data augmentation and\npost-processing significantly improvethe score in our system. In particular,\nmix-up data augmentationand beam search in post-processing improve SPIDEr by\n0.8 and 1.6points, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 01:07:33 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Takeuchi", "Daiki", ""], ["Koizumi", "Yuma", ""], ["Ohishi", "Yasunori", ""], ["Harada", "Noboru", ""], ["Kashino", "Kunio", ""]]}, {"id": "2009.11462", "submitter": "Suchin Gururangan", "authors": "Samuel Gehman, Suchin Gururangan, Maarten Sap, Yejin Choi, Noah A.\n  Smith", "title": "RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language\n  Models", "comments": "Findings in EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretrained neural language models (LMs) are prone to generating racist,\nsexist, or otherwise toxic language which hinders their safe deployment. We\ninvestigate the extent to which pretrained LMs can be prompted to generate\ntoxic language, and the effectiveness of controllable text generation\nalgorithms at preventing such toxic degeneration. We create and release\nRealToxicityPrompts, a dataset of 100K naturally occurring, sentence-level\nprompts derived from a large corpus of English web text, paired with toxicity\nscores from a widely-used toxicity classifier. Using RealToxicityPrompts, we\nfind that pretrained LMs can degenerate into toxic text even from seemingly\ninnocuous prompts. We empirically assess several controllable generation\nmethods, and find that while data- or compute-intensive methods (e.g., adaptive\npretraining on non-toxic data) are more effective at steering away from\ntoxicity than simpler solutions (e.g., banning \"bad\" words), no current method\nis failsafe against neural toxic degeneration. To pinpoint the potential cause\nof such persistent toxic degeneration, we analyze two web text corpora used to\npretrain several LMs (including GPT-2; Radford et. al, 2019), and find a\nsignificant amount of offensive, factually unreliable, and otherwise toxic\ncontent. Our work provides a test bed for evaluating toxic generations by LMs\nand stresses the need for better data selection processes for pretraining.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 03:17:19 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 20:22:26 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Gehman", "Samuel", ""], ["Gururangan", "Suchin", ""], ["Sap", "Maarten", ""], ["Choi", "Yejin", ""], ["Smith", "Noah A.", ""]]}, {"id": "2009.11473", "submitter": "Huishuang Tian", "authors": "Huishuang Tian, Kexin Yang, Dayiheng Liu, Jiancheng Lv", "title": "AnchiBERT: A Pre-Trained Model for Ancient ChineseLanguage Understanding\n  and Generation", "comments": "10 pages with 3 figures", "journal-ref": "ijcnn 2021", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ancient Chinese is the essence of Chinese culture. There are several natural\nlanguage processing tasks of ancient Chinese domain, such as ancient-modern\nChinese translation, poem generation, and couplet generation. Previous studies\nusually use the supervised models which deeply rely on parallel data. However,\nit is difficult to obtain large-scale parallel data of ancient Chinese. In\norder to make full use of the more easily available monolingual ancient Chinese\ncorpora, we release AnchiBERT, a pre-trained language model based on the\narchitecture of BERT, which is trained on large-scale ancient Chinese corpora.\nWe evaluate AnchiBERT on both language understanding and generation tasks,\nincluding poem classification, ancient-modern Chinese translation, poem\ngeneration, and couplet generation. The experimental results show that\nAnchiBERT outperforms BERT as well as the non-pretrained models and achieves\nstate-of-the-art results in all cases.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 03:41:13 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 03:42:41 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Tian", "Huishuang", ""], ["Yang", "Kexin", ""], ["Liu", "Dayiheng", ""], ["Lv", "Jiancheng", ""]]}, {"id": "2009.11485", "submitter": "Zehong Cao Dr.", "authors": "Xinping Liu, Zehong Cao, Son Tran", "title": "CogniFNN: A Fuzzy Neural Network Framework for Cognitive Word Embedding\n  Evaluation", "comments": "The method and results need to be further investigated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Word embeddings can reflect the semantic representations, and the embedding\nqualities can be comprehensively evaluated with human natural reading-related\ncognitive data sources. In this paper, we proposed the CogniFNN framework,\nwhich is the first attempt at using fuzzy neural networks to extract non-linear\nand non-stationary characteristics for evaluations of English word embeddings\nagainst the corresponding cognitive datasets. In our experiment, we used 15\nhuman cognitive datasets across three modalities: EEG, fMRI, and eye-tracking,\nand selected the mean square error and multiple hypotheses testing as metrics\nto evaluate our proposed CogniFNN framework. Compared to the recent pioneer\nframework, our proposed CogniFNN showed smaller prediction errors of both\ncontext-independent (GloVe) and context-sensitive (BERT) word embeddings, and\nachieved higher significant ratios with randomly generated word embeddings. Our\nfindings suggested that the CogniFNN framework could provide a more accurate\nand comprehensive evaluation of cognitive word embeddings. It will potentially\nbe beneficial to the further word embeddings evaluation on extrinsic natural\nlanguage processing tasks.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 04:39:38 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 05:34:32 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Liu", "Xinping", ""], ["Cao", "Zehong", ""], ["Tran", "Son", ""]]}, {"id": "2009.11506", "submitter": "Liang Wang", "authors": "Wei Zhao, Mingyue Shang, Yang Liu, Liang Wang, Jingming Liu", "title": "Ape210K: A Large-Scale and Template-Rich Dataset of Math Word Problems", "comments": "We decide to withdraw this paper, since the proposed Ape210K dataset\n  is not going public, the experiments in this paper is meaningless and\n  irreproducible without access to the dataset. Please contact\n  wangliang01@fenbi.com if you have any questions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic math word problem solving has attracted growing attention in recent\nyears. The evaluation datasets used by previous works have serious limitations\nin terms of scale and diversity. In this paper, we release a new large-scale\nand template-rich math word problem dataset named Ape210K. It consists of 210K\nChinese elementary school-level math problems, which is 9 times the size of the\nlargest public dataset Math23K. Each problem contains both the gold answer and\nthe equations needed to derive the answer. Ape210K is also of greater diversity\nwith 56K templates, which is 25 times more than Math23K. Our analysis shows\nthat solving Ape210K requires not only natural language understanding but also\ncommonsense knowledge. We expect Ape210K to be a benchmark for math word\nproblem solving systems. Experiments indicate that state-of-the-art models on\nthe Math23K dataset perform poorly on Ape210K. We propose a copy-augmented and\nfeature-enriched sequence to sequence (seq2seq) model, which outperforms\nexisting models by 3.2% on the Math23K dataset and serves as a strong baseline\nof the Ape210K dataset. The gap is still significant between human and our\nbaseline model, calling for further research efforts. We make Ape210K dataset\npublicly available at https://github.com/yuantiku/ape210k\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 06:17:10 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 01:36:35 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Zhao", "Wei", ""], ["Shang", "Mingyue", ""], ["Liu", "Yang", ""], ["Wang", "Liang", ""], ["Liu", "Jingming", ""]]}, {"id": "2009.11523", "submitter": "Nikolaos Pappas", "authors": "Nikolaos Pappas, Phoebe Mulcaire, Noah A. Smith", "title": "Grounded Compositional Outputs for Adaptive Language Modeling", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language models have emerged as a central component across NLP, and a great\ndeal of progress depends on the ability to cheaply adapt them (e.g., through\nfinetuning) to new domains and tasks. A language model's vocabulary$-$typically\nselected before training and permanently fixed later$-$affects its size and is\npart of what makes it resistant to such adaptation. Prior work has used\ncompositional input embeddings based on surface forms to ameliorate this issue.\nIn this work, we go one step beyond and propose a fully compositional output\nembedding layer for language models, which is further grounded in information\nfrom a structured lexicon (WordNet), namely semantically related words and\nfree-text definitions. To our knowledge, the result is the first word-level\nlanguage model with a size that does not depend on the training vocabulary. We\nevaluate the model on conventional language modeling as well as challenging\ncross-domain settings with an open vocabulary, finding that it matches or\noutperforms previous state-of-the-art output embedding methods and adaptation\napproaches. Our analysis attributes the improvements to sample efficiency: our\nmodel is more accurate for low-frequency words.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 07:21:14 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 18:26:38 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Pappas", "Nikolaos", ""], ["Mulcaire", "Phoebe", ""], ["Smith", "Noah A.", ""]]}, {"id": "2009.11538", "submitter": "Hai Ye", "authors": "Hai Ye, Qingyu Tan, Ruidan He, Juntao Li, Hwee Tou Ng, Lidong Bing", "title": "Feature Adaptation of Pre-Trained Language Models across Languages and\n  Domains with Robust Self-Training", "comments": "To appear at EMNLP 2020. 14 pages. Code is available at:\n  https://github.com/oceanypt/CFd", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adapting pre-trained language models (PrLMs) (e.g., BERT) to new domains has\ngained much attention recently. Instead of fine-tuning PrLMs as done in most\nprevious work, we investigate how to adapt the features of PrLMs to new domains\nwithout fine-tuning. We explore unsupervised domain adaptation (UDA) in this\npaper. With the features from PrLMs, we adapt the models trained with labeled\ndata from the source domain to the unlabeled target domain. Self-training is\nwidely used for UDA which predicts pseudo labels on the target domain data for\ntraining. However, the predicted pseudo labels inevitably include noise, which\nwill negatively affect training a robust model. To improve the robustness of\nself-training, in this paper we present class-aware feature self-distillation\n(CFd) to learn discriminative features from PrLMs, in which PrLM features are\nself-distilled into a feature adaptation module and the features from the same\nclass are more tightly clustered. We further extend CFd to a cross-language\nsetting, in which language discrepancy is studied. Experiments on two\nmonolingual and multilingual Amazon review datasets show that CFd can\nconsistently improve the performance of self-training in cross-domain and\ncross-language settings.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 08:04:37 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 03:45:44 GMT"}, {"version": "v3", "created": "Mon, 30 Nov 2020 05:50:30 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Ye", "Hai", ""], ["Tan", "Qingyu", ""], ["He", "Ruidan", ""], ["Li", "Juntao", ""], ["Ng", "Hwee Tou", ""], ["Bing", "Lidong", ""]]}, {"id": "2009.11616", "submitter": "Libo Qin", "authors": "Wanxiang Che, Yunlong Feng, Libo Qin, Ting Liu", "title": "N-LTP: A Open-source Neural Chinese Language Technology Platform with\n  Pretrained Models", "comments": "Work in progress. Code is available at\n  [GitHub](https://github.com/HIT-SCIR/ltp)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce N-LTP, an open-source neural language technology platform\nsupporting six fundamental Chinese NLP tasks: lexical analysis (Chinese word\nsegmentation, part-of-speech tagging, and named entity recognition), {syntactic\nparsing} (dependency parsing), and {semantic parsing} (semantic dependency\nparsing and semantic role labeling). Unlike the existing state-of-the-art\ntoolkits, such as Stanza, that adopt an independent model for each task, N-LTP\nadopts the multi-task framework by using a shared pre-trained model, which has\nthe advantage of capturing the shared knowledge across relevant Chinese tasks.\nIn addition, knowledge distillation where the single-task model teaches the\nmulti-task model is further introduced to encourage the multi-task model to\nsurpass its single-task teacher. Finally, we provide a collection of\neasy-to-use APIs and a visualization tool to make users easier to use and view\nthe processing results directly. To the best of our knowledge, this is the\nfirst toolkit to support six Chinese NLP fundamental tasks. Source code,\ndocumentation, and pre-trained models are available at \\url{https://ltp.ai/}.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 11:45:39 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 14:20:33 GMT"}, {"version": "v3", "created": "Thu, 29 Apr 2021 15:33:53 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Che", "Wanxiang", ""], ["Feng", "Yunlong", ""], ["Qin", "Libo", ""], ["Liu", "Ting", ""]]}, {"id": "2009.11684", "submitter": "Fenglin Li", "authors": "Feng-Lin Li, Hehong Chen, Guohai Xu, Tian Qiu, Feng Ji, Ji Zhang,\n  Haiqing Chen", "title": "AliMe KG: Domain Knowledge Graph Construction and Application in\n  E-commerce", "comments": null, "journal-ref": null, "doi": "10.1145/3340531.3412685", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Pre-sales customer service is of importance to E-commerce platforms as it\ncontributes to optimizing customers' buying process. To better serve users, we\npropose AliMe KG, a domain knowledge graph in E-commerce that captures user\nproblems, points of interests (POI), item information and relations thereof. It\nhelps to understand user needs, answer pre-sales questions and generate\nexplanation texts. We applied AliMe KG to several online business scenarios\nsuch as shopping guide, question answering over properties and recommendation\nreason generation, and gained positive results. In the paper, we systematically\nintroduce how we construct domain knowledge graph from free text, and\ndemonstrate its business value with several applications. Our experience shows\nthat mining structured knowledge from free text in vertical domain is\npracticable, and can be of substantial value in industrial settings.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 13:40:18 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Li", "Feng-Lin", ""], ["Chen", "Hehong", ""], ["Xu", "Guohai", ""], ["Qiu", "Tian", ""], ["Ji", "Feng", ""], ["Zhang", "Ji", ""], ["Chen", "Haiqing", ""]]}, {"id": "2009.11692", "submitter": "Haozhe Ji", "authors": "Haozhe Ji, Pei Ke, Shaohan Huang, Furu Wei, Xiaoyan Zhu, Minlie Huang", "title": "Language Generation with Multi-Hop Reasoning on Commonsense Knowledge\n  Graph", "comments": "accepted by EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the success of generative pre-trained language models on a series of\ntext generation tasks, they still suffer in cases where reasoning over\nunderlying commonsense knowledge is required during generation. Existing\napproaches that integrate commonsense knowledge into generative pre-trained\nlanguage models simply transfer relational knowledge by post-training on\nindividual knowledge triples while ignoring rich connections within the\nknowledge graph. We argue that exploiting both the structural and semantic\ninformation of the knowledge graph facilitates commonsense-aware text\ngeneration. In this paper, we propose Generation with Multi-Hop Reasoning Flow\n(GRF) that enables pre-trained models with dynamic multi-hop reasoning on\nmulti-relational paths extracted from the external commonsense knowledge graph.\nWe empirically show that our model outperforms existing baselines on three text\ngeneration tasks that require reasoning over commonsense knowledge. We also\ndemonstrate the effectiveness of the dynamic multi-hop reasoning module with\nreasoning paths inferred by the model that provide rationale to the generation.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 13:55:32 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Ji", "Haozhe", ""], ["Ke", "Pei", ""], ["Huang", "Shaohan", ""], ["Wei", "Furu", ""], ["Zhu", "Xiaoyan", ""], ["Huang", "Minlie", ""]]}, {"id": "2009.11753", "submitter": "Haozhe Ji", "authors": "Haozhe Ji, Pei Ke, Shaohan Huang, Furu Wei, Minlie Huang", "title": "Generating Commonsense Explanation by Extracting Bridge Concepts from\n  Reasoning Paths", "comments": "Accepted by AACL-IJCNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense explanation generation aims to empower the machine's sense-making\ncapability by generating plausible explanations to statements against\ncommonsense. While this task is easy to human, the machine still struggles to\ngenerate reasonable and informative explanations. In this work, we propose a\nmethod that first extracts the underlying concepts which are served as\n\\textit{bridges} in the reasoning chain and then integrates these concepts to\ngenerate the final explanation. To facilitate the reasoning process, we utilize\nexternal commonsense knowledge to build the connection between a statement and\nthe bridge concepts by extracting and pruning multi-hop paths to build a\nsubgraph. We design a bridge concept extraction model that first scores the\ntriples, routes the paths in the subgraph, and further selects bridge concepts\nwith weak supervision at both the triple level and the concept level. We\nconduct experiments on the commonsense explanation generation task and our\nmodel outperforms the state-of-the-art baselines in both automatic and human\nevaluation.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 15:27:20 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Ji", "Haozhe", ""], ["Ke", "Pei", ""], ["Huang", "Shaohan", ""], ["Wei", "Furu", ""], ["Huang", "Minlie", ""]]}, {"id": "2009.11795", "submitter": "Boon Peng Yap", "authors": "Boon Peng Yap, Andrew Koh and Eng Siong Chng", "title": "Adapting BERT for Word Sense Disambiguation with Gloss Selection\n  Objective and Example Sentences", "comments": "Accepted to appear in Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation or transfer learning using pre-trained language models such\nas BERT has proven to be an effective approach for many natural language\nprocessing tasks. In this work, we propose to formulate word sense\ndisambiguation as a relevance ranking task, and fine-tune BERT on sequence-pair\nranking task to select the most probable sense definition given a context\nsentence and a list of candidate sense definitions. We also introduce a data\naugmentation technique for WSD using existing example sentences from WordNet.\nUsing the proposed training objective and data augmentation technique, our\nmodels are able to achieve state-of-the-art results on the English all-words\nbenchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 16:37:04 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 06:06:39 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Yap", "Boon Peng", ""], ["Koh", "Andrew", ""], ["Chng", "Eng Siong", ""]]}, {"id": "2009.11832", "submitter": "Junade Ali", "authors": "Malgorzata Pikies, Andronicus Riyono, Junade Ali", "title": "Novel Keyword Extraction and Language Detection Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzy string matching and language classification are important tools in\nNatural Language Processing pipelines, this paper provides advances in both\nareas. We propose a fast novel approach to string tokenisation for fuzzy\nlanguage matching and experimentally demonstrate an 83.6% decrease in\nprocessing time with an estimated improvement in recall of 3.1% at the cost of\na 2.6% decrease in precision. This approach is able to work even where keywords\nare subdivided into multiple words, without needing to scan\ncharacter-to-character. So far there has been little work considering using\nmetadata to enhance language classification algorithms. We provide\nobservational data and find the Accept-Language header is 14% more likely to\nmatch the classification than the IP Address.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 17:28:59 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Pikies", "Malgorzata", ""], ["Riyono", "Andronicus", ""], ["Ali", "Junade", ""]]}, {"id": "2009.11896", "submitter": "Subhajit Chaudhury", "authors": "Subhajit Chaudhury, Daiki Kimura, Kartik Talamadupula, Michiaki\n  Tatsubori, Asim Munawar and Ryuki Tachibana", "title": "Bootstrapped Q-learning with Context Relevant Observation Pruning to\n  Generalize in Text-based Games", "comments": "Accepted to EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that Reinforcement Learning (RL) methods for solving Text-Based Games\n(TBGs) often fail to generalize on unseen games, especially in small data\nregimes. To address this issue, we propose Context Relevant Episodic State\nTruncation (CREST) for irrelevant token removal in observation text for\nimproved generalization. Our method first trains a base model using Q-learning,\nwhich typically overfits the training games. The base model's action token\ndistribution is used to perform observation pruning that removes irrelevant\ntokens. A second bootstrapped model is then retrained on the pruned observation\ntext. Our bootstrapped agent shows improved generalization in solving unseen\nTextWorld games, using 10x-20x fewer training games compared to previous\nstate-of-the-art methods despite requiring less number of training episodes.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 18:38:30 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Chaudhury", "Subhajit", ""], ["Kimura", "Daiki", ""], ["Talamadupula", "Kartik", ""], ["Tatsubori", "Michiaki", ""], ["Munawar", "Asim", ""], ["Tachibana", "Ryuki", ""]]}, {"id": "2009.11898", "submitter": "Anna Glazkova", "authors": "Anna Glazkova, Yury Egorov, Maksim Glazkov", "title": "A Comparative Study of Feature Types for Age-Based Text Classification", "comments": "Accepted to AIST-2020 (The 9th International Conference on Analysis\n  of Images, Social Networks and Texts)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ability to automatically determine the age audience of a novel provides\nmany opportunities for the development of information retrieval tools. Firstly,\ndevelopers of book recommendation systems and electronic libraries may be\ninterested in filtering texts by the age of the most likely readers. Further,\nparents may want to select literature for children. Finally, it will be useful\nfor writers and publishers to determine which features influence whether the\ntexts are suitable for children. In this article, we compare the empirical\neffectiveness of various types of linguistic features for the task of age-based\nclassification of fiction texts. For this purpose, we collected a text corpus\nof book previews labeled with one of two categories -- children's or adult. We\nevaluated the following types of features: readability indices, sentiment,\nlexical, grammatical and general features, and publishing attributes. The\nresults obtained show that the features describing the text at the document\nlevel can significantly increase the quality of machine learning models.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 18:41:10 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Glazkova", "Anna", ""], ["Egorov", "Yury", ""], ["Glazkov", "Maksim", ""]]}, {"id": "2009.11963", "submitter": "Jonathan Enderle", "authors": "Jonathan Scott Enderle", "title": "Toward a Thermodynamics of Meaning", "comments": "To be published in the proceedings of CHR 2020: Workshop on\n  Computational Humanities Research, November 18-20, 2020, Amsterdam, The\n  Netherlands", "journal-ref": "Proceedings of the Workshop on Computational Humanities Research\n  CEUR Vol-2723 (2020) 191-201", "doi": "10.5281/zenodo.4302259", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As language models such as GPT-3 become increasingly successful at generating\nrealistic text, questions about what purely text-based modeling can learn about\nthe world have become more urgent. Is text purely syntactic, as skeptics argue?\nOr does it in fact contain some semantic information that a sufficiently\nsophisticated language model could use to learn about the world without any\nadditional inputs? This paper describes a new model that suggests some\nqualified answers to those questions. By theorizing the relationship between\ntext and the world it describes as an equilibrium relationship between a\nthermodynamic system and a much larger reservoir, this paper argues that even\nvery simple language models do learn structural facts about the world, while\nalso proposing relatively precise limits on the nature and extent of those\nfacts. This perspective promises not only to answer questions about what\nlanguage models actually learn, but also to explain the consistent and\nsurprising success of cooccurrence prediction as a meaning-making strategy in\nAI.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 21:56:02 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Enderle", "Jonathan Scott", ""]]}, {"id": "2009.11982", "submitter": "Ana Valeria Gonzalez", "authors": "Ana Valeria Gonzalez, Maria Barrett, Rasmus Hvingelby, Kellie Webster,\n  Anders S{\\o}gaard", "title": "Type B Reflexivization as an Unambiguous Testbed for Multilingual\n  Multi-Task Gender Bias", "comments": "To appear in EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The one-sided focus on English in previous studies of gender bias in NLP\nmisses out on opportunities in other languages: English challenge datasets such\nas GAP and WinoGender highlight model preferences that are \"hallucinatory\",\ne.g., disambiguating gender-ambiguous occurrences of 'doctor' as male doctors.\nWe show that for languages with type B reflexivization, e.g., Swedish and\nRussian, we can construct multi-task challenge datasets for detecting gender\nbias that lead to unambiguously wrong model predictions: In these languages,\nthe direct translation of 'the doctor removed his mask' is not ambiguous\nbetween a coreferential reading and a disjoint reading. Instead, the\ncoreferential reading requires a non-gendered pronoun, and the gendered,\npossessive pronouns are anti-reflexive. We present a multilingual, multi-task\nchallenge dataset, which spans four languages and four NLP tasks and focuses\nonly on this phenomenon. We find evidence for gender bias across all\ntask-language combinations and correlate model bias with national labor market\nstatistics.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 23:47:18 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 05:12:48 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Gonzalez", "Ana Valeria", ""], ["Barrett", "Maria", ""], ["Hvingelby", "Rasmus", ""], ["Webster", "Kellie", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "2009.12005", "submitter": "Zhaojiang Lin", "authors": "Zhaojiang Lin, Andrea Madotto, Genta Indra Winata, Pascale Fung", "title": "MinTL: Minimalist Transfer Learning for Task-Oriented Dialogue Systems", "comments": "EMNLP 2020 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Minimalist Transfer Learning (MinTL) to simplify\nthe system design process of task-oriented dialogue systems and alleviate the\nover-dependency on annotated data. MinTL is a simple yet effective transfer\nlearning framework, which allows us to plug-and-play pre-trained seq2seq\nmodels, and jointly learn dialogue state tracking and dialogue response\ngeneration. Unlike previous approaches, which use a copy mechanism to\n\"carryover\" the old dialogue states to the new one, we introduce Levenshtein\nbelief spans (Lev), that allows efficient dialogue state tracking with a\nminimal generation length. We instantiate our learning framework with two\npre-trained backbones: T5 and BART, and evaluate them on MultiWOZ. Extensive\nexperiments demonstrate that: 1) our systems establish new state-of-the-art\nresults on end-to-end response generation, 2) MinTL-based systems are more\nrobust than baseline methods in the low resource setting, and they achieve\ncompetitive results with only 20\\% training data, and 3) Lev greatly improves\nthe inference efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 02:19:13 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 06:43:17 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Lin", "Zhaojiang", ""], ["Madotto", "Andrea", ""], ["Winata", "Genta Indra", ""], ["Fung", "Pascale", ""]]}, {"id": "2009.12013", "submitter": "Liyan Xu", "authors": "Liyan Xu, Jinho D. Choi", "title": "Revealing the Myth of Higher-Order Inference in Coreference Resolution", "comments": "Accepted to EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes the impact of higher-order inference (HOI) on the task of\ncoreference resolution. HOI has been adapted by almost all recent coreference\nresolution models without taking much investigation on its true effectiveness\nover representation learning. To make a comprehensive analysis, we implement an\nend-to-end coreference system as well as four HOI approaches, attended\nantecedent, entity equalization, span clustering, and cluster merging, where\nthe latter two are our original methods. We find that given a high-performing\nencoder such as SpanBERT, the impact of HOI is negative to marginal, providing\na new perspective of HOI to this task. Our best model using cluster merging\nshows the Avg-F1 of 80.2 on the CoNLL 2012 shared task dataset in English.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 03:28:07 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 22:47:33 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Xu", "Liyan", ""], ["Choi", "Jinho D.", ""]]}, {"id": "2009.12030", "submitter": "Guanglin Niu", "authors": "Guanglin Niu, Bo Li, Yongfei Zhang, Shiliang Pu, Jingyang Li", "title": "AutoETER: Automated Entity Type Representation for Knowledge Graph\n  Embedding", "comments": "10 pages, 3 figures, the full version of a paper accepted to EMNLP\n  2020 Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Knowledge Graph Embedding (KGE) allow for representing\nentities and relations in continuous vector spaces. Some traditional KGE models\nleveraging additional type information can improve the representation of\nentities which however totally rely on the explicit types or neglect the\ndiverse type representations specific to various relations. Besides, none of\nthe existing methods is capable of inferring all the relation patterns of\nsymmetry, inversion and composition as well as the complex properties of 1-N,\nN-1 and N-N relations, simultaneously. To explore the type information for any\nKG, we develop a novel KGE framework with Automated Entity TypE Representation\n(AutoETER), which learns the latent type embedding of each entity by regarding\neach relation as a translation operation between the types of two entities with\na relation-aware projection mechanism. Particularly, our designed automated\ntype representation learning mechanism is a pluggable module which can be\neasily incorporated with any KGE model. Besides, our approach could model and\ninfer all the relation patterns and complex relations. Experiments on four\ndatasets demonstrate the superior performance of our model compared to\nstate-of-the-art baselines on link prediction tasks, and the visualization of\ntype clustering provides clearly the explanation of type embeddings and\nverifies the effectiveness of our model.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 04:27:35 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 13:52:59 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Niu", "Guanglin", ""], ["Li", "Bo", ""], ["Zhang", "Yongfei", ""], ["Pu", "Shiliang", ""], ["Li", "Jingyang", ""]]}, {"id": "2009.12046", "submitter": "Lei Shu", "authors": "Lei Shu, Alexandros Papangelis, Yi-Chia Wang, Gokhan Tur, Hu Xu,\n  Zhaleh Feizollahi, Bing Liu, Piero Molino", "title": "Controllable Text Generation with Focused Variation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces Focused-Variation Network (FVN), a novel model to\ncontrol language generation. The main problems in previous controlled language\ngeneration models range from the difficulty of generating text according to the\ngiven attributes, to the lack of diversity of the generated texts. FVN\naddresses these issues by learning disjoint discrete latent spaces for each\nattribute inside codebooks, which allows for both controllability and\ndiversity, while at the same time generating fluent text. We evaluate FVN on\ntwo text generation datasets with annotated content and style, and show\nstate-of-the-art performance as assessed by automatic and human evaluations.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 06:31:06 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Shu", "Lei", ""], ["Papangelis", "Alexandros", ""], ["Wang", "Yi-Chia", ""], ["Tur", "Gokhan", ""], ["Xu", "Hu", ""], ["Feizollahi", "Zhaleh", ""], ["Liu", "Bing", ""], ["Molino", "Piero", ""]]}, {"id": "2009.12056", "submitter": "Xuguang Wang", "authors": "Xuguang Wang, Linjun Shou, Ming Gong, Nan Duan and Daxin Jiang", "title": "No Answer is Better Than Wrong Answer: A Reflection Model for Document\n  Level Machine Reading Comprehension", "comments": "Accepted by Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Natural Questions (NQ) benchmark set brings new challenges to Machine\nReading Comprehension: the answers are not only at different levels of\ngranularity (long and short), but also of richer types (including no-answer,\nyes/no, single-span and multi-span). In this paper, we target at this challenge\nand handle all answer types systematically. In particular, we propose a novel\napproach called Reflection Net which leverages a two-step training procedure to\nidentify the no-answer and wrong-answer cases. Extensive experiments are\nconducted to verify the effectiveness of our approach. At the time of paper\nwriting (May.~20,~2020), our approach achieved the top 1 on both long and short\nanswer leaderboard, with F1 scores of 77.2 and 64.1, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 06:57:52 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 09:29:57 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Wang", "Xuguang", ""], ["Shou", "Linjun", ""], ["Gong", "Ming", ""], ["Duan", "Nan", ""], ["Jiang", "Daxin", ""]]}, {"id": "2009.12061", "submitter": "Yan Zhang", "authors": "Yan Zhang, Ruidan He, Zuozhu Liu, Kwan Hui Lim, Lidong Bing", "title": "An Unsupervised Sentence Embedding Method by Mutual Information\n  Maximization", "comments": "Accepted to EMNLP 2020, code is released", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BERT is inefficient for sentence-pair tasks such as clustering or semantic\nsearch as it needs to evaluate combinatorially many sentence pairs which is\nvery time-consuming. Sentence BERT (SBERT) attempted to solve this challenge by\nlearning semantically meaningful representations of single sentences, such that\nsimilarity comparison can be easily accessed. However, SBERT is trained on\ncorpus with high-quality labeled sentence pairs, which limits its application\nto tasks where labeled data is extremely scarce. In this paper, we propose a\nlightweight extension on top of BERT and a novel self-supervised learning\nobjective based on mutual information maximization strategies to derive\nmeaningful sentence embeddings in an unsupervised manner. Unlike SBERT, our\nmethod is not restricted by the availability of labeled data, such that it can\nbe applied on different domain-specific corpus. Experimental results show that\nthe proposed method significantly outperforms other unsupervised sentence\nembedding baselines on common semantic textual similarity (STS) tasks and\ndownstream supervised tasks. It also outperforms SBERT in a setting where\nin-domain labeled data is not available, and achieves performance competitive\nwith supervised methods on various tasks.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 07:16:51 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 03:15:25 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Zhang", "Yan", ""], ["He", "Ruidan", ""], ["Liu", "Zuozhu", ""], ["Lim", "Kwan Hui", ""], ["Bing", "Lidong", ""]]}, {"id": "2009.12064", "submitter": "Shunsuke Kitada", "authors": "Shunsuke Kitada and Hitoshi Iyatomi", "title": "Attention Meets Perturbations: Robust and Interpretable Attention with\n  Adversarial Training", "comments": "12 pages, 4 figures. Accepted by IEEE Access on Jun. 21, 2021", "journal-ref": "IEEE Access, 2021", "doi": "10.1109/ACCESS.2021.3093456", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although attention mechanisms have been applied to a variety of deep learning\nmodels and have been shown to improve the prediction performance, it has been\nreported to be vulnerable to perturbations to the mechanism. To overcome the\nvulnerability to perturbations in the mechanism, we are inspired by adversarial\ntraining (AT), which is a powerful regularization technique for enhancing the\nrobustness of the models. In this paper, we propose a general training\ntechnique for natural language processing tasks, including AT for attention\n(Attention AT) and more interpretable AT for attention (Attention iAT). The\nproposed techniques improved the prediction performance and the model\ninterpretability by exploiting the mechanisms with AT. In particular, Attention\niAT boosts those advantages by introducing adversarial perturbation, which\nenhances the difference in the attention of the sentences. Evaluation\nexperiments with ten open datasets revealed that AT for attention mechanisms,\nespecially Attention iAT, demonstrated (1) the best performance in nine out of\nten tasks and (2) more interpretable attention (i.e., the resulting attention\ncorrelated more strongly with gradient-based word importance) for all tasks.\nAdditionally, the proposed techniques are (3) much less dependent on\nperturbation size in AT. Our code is available at\nhttps://github.com/shunk031/attention-meets-perturbation\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 07:26:45 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 02:31:22 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Kitada", "Shunsuke", ""], ["Iyatomi", "Hitoshi", ""]]}, {"id": "2009.12081", "submitter": "Robin Hirsch", "authors": "Robin Hirsch, Szabolcs Mikul\\'as and Tim Stokes", "title": "The algebra of non-deterministic programs: demonic operators, orders and\n  axioms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Demonic composition, demonic refinement and demonic union are alternatives to\nthe usual \"angelic\" composition, angelic refinement (inclusion) and angelic\n(usual) union defined on binary relations. We first motivate both the angelic\nand demonic via an analysis of the behaviour of non-deterministic programs,\nwith the angelic associated with partial correctness and demonic with total\ncorrectness, both cases emerging from a richer algebraic model of\nnon-deterministic programs incorporating both aspects. Zareckii has shown that\nthe isomorphism class of algebras of binary relations under angelic composition\nand inclusion is finitely axiomatised as the class of ordered semigroups. The\nproof can be used to establish that the same axiomatisation applies to binary\nrelations under demonic composition and refinement, and a further modification\nof the proof can be used to incorporate a zero element representing the empty\nrelation in the angelic case and the full relation in the demonic case. For the\nsignature of angelic composition and union, it is known that no finite\naxiomatisation exists, and we show the analogous result for demonic composition\nand demonic union by showing that the same axiomatisation holds for both. We\nshow that the isomorphism class of algebras of binary relations with the\n\"mixed\" signature of demonic composition and angelic inclusion has no finite\naxiomatisation. As a contrast, we show that the isomorphism class of partial\nalgebras of binary relations with the partial operation of constellation\nproduct and inclusion (also a \"mixed\" signature) is finitely axiomatisable.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 08:13:07 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2021 10:01:53 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Hirsch", "Robin", ""], ["Mikul\u00e1s", "Szabolcs", ""], ["Stokes", "Tim", ""]]}, {"id": "2009.12102", "submitter": "Zhi Cui", "authors": "Zhi Cui, Yanran Li, Jiayi Zhang, Jianwei Cui, Chen Wei, Bin Wang", "title": "Focus-Constrained Attention Mechanism for CVAE-based Response Generation", "comments": "To appear in findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To model diverse responses for a given post, one promising way is to\nintroduce a latent variable into Seq2Seq models. The latent variable is\nsupposed to capture the discourse-level information and encourage the\ninformativeness of target responses. However, such discourse-level information\nis often too coarse for the decoder to be utilized. To tackle it, our idea is\nto transform the coarse-grained discourse-level information into fine-grained\nword-level information. Specifically, we firstly measure the semantic\nconcentration of corresponding target response on the post words by introducing\na fine-grained focus signal. Then, we propose a focus-constrained attention\nmechanism to take full advantage of focus in well aligning the input to the\ntarget response. The experimental results demonstrate that by exploiting the\nfine-grained signal, our model can generate more diverse and informative\nresponses compared with several state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 09:38:59 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Cui", "Zhi", ""], ["Li", "Yanran", ""], ["Zhang", "Jiayi", ""], ["Cui", "Jianwei", ""], ["Wei", "Chen", ""], ["Wang", "Bin", ""]]}, {"id": "2009.12192", "submitter": "Benjamin Chamberlain", "authors": "Benjamin P. Chamberlain, Emanuele Rossi, Dan Shiebler, Suvash Sedhain,\n  Michael M. Bronstein", "title": "Tuning Word2vec for Large Scale Recommendation Systems", "comments": "11 pages, 4 figures, Fourteenth ACM Conference on Recommender Systems", "journal-ref": "Fourteenth ACM Conference on Recommender Systems (RecSys '20),\n  September 22--26, 2020, Virtual Event, Brazil", "doi": "10.1145/3383313.3418486", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word2vec is a powerful machine learning tool that emerged from Natural\nLan-guage Processing (NLP) and is now applied in multiple domains, including\nrecom-mender systems, forecasting, and network analysis. As Word2vec is often\nused offthe shelf, we address the question of whether the default\nhyperparameters are suit-able for recommender systems. The answer is\nemphatically no. In this paper, wefirst elucidate the importance of\nhyperparameter optimization and show that un-constrained optimization yields an\naverage 221% improvement in hit rate over thedefault parameters. However,\nunconstrained optimization leads to hyperparametersettings that are very\nexpensive and not feasible for large scale recommendationtasks. To this end, we\ndemonstrate 138% average improvement in hit rate with aruntime\nbudget-constrained hyperparameter optimization. Furthermore, to\nmakehyperparameter optimization applicable for large scale recommendation\nproblemswhere the target dataset is too large to search over, we investigate\ngeneralizinghyperparameters settings from samples. We show that applying\nconstrained hy-perparameter optimization using only a 10% sample of the data\nstill yields a 91%average improvement in hit rate over the default parameters\nwhen applied to thefull datasets. Finally, we apply hyperparameters learned\nusing our method of con-strained optimization on a sample to the Who To Follow\nrecommendation serviceat Twitter and are able to increase follow rates by 15%.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 10:50:19 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Chamberlain", "Benjamin P.", ""], ["Rossi", "Emanuele", ""], ["Shiebler", "Dan", ""], ["Sedhain", "Suvash", ""], ["Bronstein", "Michael M.", ""]]}, {"id": "2009.12240", "submitter": "Mark Riedl", "authors": "Mark Riedl", "title": "Weird AI Yankovic: Generating Parody Lyrics", "comments": "9 pages, serious paper about a silly task, written accordingly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lyrics parody swaps one set of words that accompany a melody with a new set\nof words, preserving the number of syllables per line and the rhyme scheme.\nLyrics parody generation is a challenge for controllable text generation. We\nshow how a specialized sampling procedure, combined with backward text\ngeneration with XLNet can produce parody lyrics that reliably meet the syllable\nand rhyme scheme constraints.We introduce the Weird AI Yankovic system and\nprovide a case study evaluation. We conclude with societal implications of\nneural lyric parody generation.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 13:56:20 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Riedl", "Mark", ""]]}, {"id": "2009.12269", "submitter": "Ehsan Doostmohammadi", "authors": "Ehsan Doostmohammadi, Mohammad Hadi Bokaei, Hossein Sameti", "title": "PerKey: A Persian News Corpus for Keyphrase Extraction and Generation", "comments": null, "journal-ref": null, "doi": "10.1109/ISTEL.2018.8661095", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyphrases provide an extremely dense summary of a text. Such information can\nbe used in many Natural Language Processing tasks, such as information\nretrieval and text summarization. Since previous studies on Persian keyword or\nkeyphrase extraction have not published their data, the field suffers from the\nlack of a human extracted keyphrase dataset. In this paper, we introduce\nPerKey, a corpus of 553k news articles from six Persian news websites and\nagencies with relatively high quality author extracted keyphrases, which is\nthen filtered and cleaned to achieve higher quality keyphrases. The resulted\ndata was put into human assessment to ensure the quality of the keyphrases. We\nalso measured the performance of different supervised and unsupervised\ntechniques, e.g. TFIDF, MultipartiteRank, KEA, etc. on the dataset using\nprecision, recall, and F1-score.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 14:36:41 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Doostmohammadi", "Ehsan", ""], ["Bokaei", "Mohammad Hadi", ""], ["Sameti", "Hossein", ""]]}, {"id": "2009.12271", "submitter": "Ehsan Doostmohammadi", "authors": "Ehsan Doostmohammadi, Mohammad Hadi Bokaei, Hossein Sameti", "title": "Persian Keyphrase Generation Using Sequence-to-Sequence Models", "comments": null, "journal-ref": null, "doi": "10.1109/IranianCEE.2019.8786505", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyphrases are a very short summary of an input text and provide the main\nsubjects discussed in the text. Keyphrase extraction is a useful upstream task\nand can be used in various natural language processing problems, for example,\ntext summarization and information retrieval, to name a few. However, not all\nthe keyphrases are explicitly mentioned in the body of the text. In real-world\nexamples there are always some topics that are discussed implicitly. Extracting\nsuch keyphrases requires a generative approach, which is adopted here. In this\npaper, we try to tackle the problem of keyphrase generation and extraction from\nnews articles using deep sequence-to-sequence models. These models\nsignificantly outperform the conventional methods such as Topic Rank, KPMiner,\nand KEA in the task of keyphrase extraction.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 14:40:14 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Doostmohammadi", "Ehsan", ""], ["Bokaei", "Mohammad Hadi", ""], ["Sameti", "Hossein", ""]]}, {"id": "2009.12303", "submitter": "Prasetya Ajie Utama", "authors": "Prasetya Ajie Utama, Nafise Sadat Moosavi, Iryna Gurevych", "title": "Towards Debiasing NLU Models from Unknown Biases", "comments": "Accepted at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NLU models often exploit biases to achieve high dataset-specific performance\nwithout properly learning the intended task. Recently proposed debiasing\nmethods are shown to be effective in mitigating this tendency. However, these\nmethods rely on a major assumption that the types of bias should be known\na-priori, which limits their application to many NLU tasks and datasets. In\nthis work, we present the first step to bridge this gap by introducing a\nself-debiasing framework that prevents models from mainly utilizing biases\nwithout knowing them in advance. The proposed framework is general and\ncomplementary to the existing debiasing methods. We show that it allows these\nexisting methods to retain the improvement on the challenge datasets (i.e.,\nsets of examples designed to expose models' reliance on biases) without\nspecifically targeting certain biases. Furthermore, the evaluation suggests\nthat applying the framework results in improved overall robustness.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 15:49:39 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 11:00:39 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 11:52:22 GMT"}, {"version": "v4", "created": "Tue, 13 Oct 2020 12:37:27 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Utama", "Prasetya Ajie", ""], ["Moosavi", "Nafise Sadat", ""], ["Gurevych", "Iryna", ""]]}, {"id": "2009.12313", "submitter": "Iacer Calixto", "authors": "Victor Milewski and Marie-Francine Moens and Iacer Calixto", "title": "Are scene graphs good enough to improve Image Captioning?", "comments": "Published at AACL-IJCNLP 2020. 12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many top-performing image captioning models rely solely on object features\ncomputed with an object detection model to generate image descriptions.\nHowever, recent studies propose to directly use scene graphs to introduce\ninformation about object relations into captioning, hoping to better describe\ninteractions between objects. In this work, we thoroughly investigate the use\nof scene graphs in image captioning. We empirically study whether using\nadditional scene graph encoders can lead to better image descriptions and\npropose a conditional graph attention network (C-GAT), where the image\ncaptioning decoder state is used to condition the graph updates. Finally, we\ndetermine to what extent noise in the predicted scene graphs influence caption\nquality. Overall, we find no significant difference between models that use\nscene graph features and models that only use object detection features across\ndifferent captioning metrics, which suggests that existing scene graph\ngeneration models are still too noisy to be useful in image captioning.\nMoreover, although the quality of predicted scene graphs is very low in\ngeneral, when using high quality scene graphs we obtain gains of up to 3.3\nCIDEr compared to a strong Bottom-Up Top-Down baseline. We open source code to\nreproduce all our experiments in\nhttps://github.com/iacercalixto/butd-image-captioning.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 16:09:08 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 17:55:55 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Milewski", "Victor", ""], ["Moens", "Marie-Francine", ""], ["Calixto", "Iacer", ""]]}, {"id": "2009.12319", "submitter": "Son T. Luu", "authors": "Son T. Luu, Kiet Van Nguyen and Ngan Luu-Thuy Nguyen", "title": "Empirical Study of Text Augmentation on Social Media Text in Vietnamese", "comments": "Accepted by The 34th Pacific Asia Conference on Language, Information\n  and Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the text classification problem, the imbalance of labels in datasets\naffect the performance of the text-classification models. Practically, the data\nabout user comments on social networking sites not altogether appeared - the\nadministrators often only allow positive comments and hide negative comments.\nThus, when collecting the data about user comments on the social network, the\ndata is usually skewed about one label, which leads the dataset to become\nimbalanced and deteriorate the model's ability. The data augmentation\ntechniques are applied to solve the imbalance problem between classes of the\ndataset, increasing the prediction model's accuracy. In this paper, we\nperformed augmentation techniques on the VLSP2019 Hate Speech Detection on\nVietnamese social texts and the UIT - VSFC: Vietnamese Students' Feedback\nCorpus for Sentiment Analysis. The result of augmentation increases by about\n1.5% in the F1-macro score on both corpora.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 16:18:52 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 09:40:30 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Luu", "Son T.", ""], ["Van Nguyen", "Kiet", ""], ["Nguyen", "Ngan Luu-Thuy", ""]]}, {"id": "2009.12341", "submitter": "Yurio Windiatmoko", "authors": "Yurio Windiatmoko, Ahmad Fathan Hidayatullah, Ridho Rahmadi", "title": "Developing FB Chatbot Based on Deep Learning Using RASA Framework for\n  University Enquiries", "comments": "15 pages, 11 figures, prepare for ICITDA conference Batch 3", "journal-ref": null, "doi": "10.1088/1757-899X/1077/1/012060", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart systems for Universities powered by Artificial Intelligence have been\nmassively developed to help humans in various tasks. The chatbot concept is not\nsomething new in today society which is developing with recent technology.\nCollege students or candidates of college students often need actual\ninformation like asking for something to customer service, especially during\nthis pandemic, when it is difficult to have an immediate face-to-face meeting.\nChatbots are functionally helping in several things such as curriculum\ninformation, admission for new students, schedule info for any lecture courses,\nstudents grade information, and some adding features for Muslim worships\nschedule, also weather forecast information. This Chatbot is developed by Deep\nLearning models, which was adopted by an artificial intelligence model that\nreplicates human intelligence with some specific training schemes. This kind of\nDeep Learning is based on RNN which has some specific memory savings scheme for\nthe Deep Learning Model, specifically this chatbot using LSTM which already\nintegrates by RASA framework. LSTM is also known as Long Short Term Memory\nwhich efficiently saves some required memory but will remove some memory that\nis not needed. This Chatbot uses the FB platform because of the FB users have\nalready reached up to 60.8% of its entire population in Indonesia. Here's the\nchatbot only focuses on case studies at campus of the Magister Informatics FTI\nUniversity of Islamic Indonesia. This research is a first stage development\nwithin fairly sufficient simulate data.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 17:01:19 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Windiatmoko", "Yurio", ""], ["Hidayatullah", "Ahmad Fathan", ""], ["Rahmadi", "Ridho", ""]]}, {"id": "2009.12344", "submitter": "Tommi Gr\\\"ondahl", "authors": "Mika Juuti, Tommi Gr\\\"ondahl, Adrian Flanagan and N. Asokan", "title": "A little goes a long way: Improving toxic language classification\n  despite data scarcity", "comments": "To appear in Findings of ACL: EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detection of some types of toxic language is hampered by extreme scarcity of\nlabeled training data. Data augmentation - generating new synthetic data from a\nlabeled seed dataset - can help. The efficacy of data augmentation on toxic\nlanguage classification has not been fully explored. We present the first\nsystematic study on how data augmentation techniques impact performance across\ntoxic language classifiers, ranging from shallow logistic regression\narchitectures to BERT - a state-of-the-art pre-trained Transformer network. We\ncompare the performance of eight techniques on very scarce seed datasets. We\nshow that while BERT performed the best, shallow classifiers performed\ncomparably when trained on data augmented with a combination of three\ntechniques, including GPT-2-generated sentences. We discuss the interplay of\nperformance and computational overhead, which can inform the choice of\ntechniques under different constraints.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 17:04:17 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 19:31:34 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Juuti", "Mika", ""], ["Gr\u00f6ndahl", "Tommi", ""], ["Flanagan", "Adrian", ""], ["Asokan", "N.", ""]]}, {"id": "2009.12404", "submitter": "Yanpeng Zhao", "authors": "Yanpeng Zhao and Ivan Titov", "title": "Visually Grounded Compound PCFGs", "comments": "Accepted to EMNLP 2020. Our code is available at\n  https://github.com/zhaoyanpeng/vpcfg", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Exploiting visual groundings for language understanding has recently been\ndrawing much attention. In this work, we study visually grounded grammar\ninduction and learn a constituency parser from both unlabeled text and its\nvisual groundings. Existing work on this task (Shi et al., 2019) optimizes a\nparser via Reinforce and derives the learning signal only from the alignment of\nimages and sentences. While their model is relatively accurate overall, its\nerror distribution is very uneven, with low performance on certain constituents\ntypes (e.g., 26.2% recall on verb phrases, VPs) and high on others (e.g., 79.6%\nrecall on noun phrases, NPs). This is not surprising as the learning signal is\nlikely insufficient for deriving all aspects of phrase-structure syntax and\ngradient estimates are noisy. We show that using an extension of probabilistic\ncontext-free grammar model we can do fully-differentiable end-to-end visually\ngrounded learning. Additionally, this enables us to complement the image-text\nalignment loss with a language modeling objective. On the MSCOCO test captions,\nour model establishes a new state of the art, outperforming its non-grounded\nversion and, thus, confirming the effectiveness of visual groundings in\nconstituency grammar induction. It also substantially outperforms the previous\ngrounded model, with largest improvements on more `abstract' categories (e.g.,\n+55.1% recall on VPs).\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 19:07:00 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Zhao", "Yanpeng", ""], ["Titov", "Ivan", ""]]}, {"id": "2009.12421", "submitter": "Victor Prokhorov", "authors": "Victor Prokhorov, Yingzhen Li, Ehsan Shareghi, Nigel Collier", "title": "Learning Sparse Sentence Encoding without Supervision: An Exploration of\n  Sparsity in Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been long known that sparsity is an effective inductive bias for\nlearning efficient representation of data in vectors with fixed dimensionality,\nand it has been explored in many areas of representation learning. Of\nparticular interest to this work is the investigation of the sparsity within\nthe VAE framework which has been explored a lot in the image domain, but has\nbeen lacking even a basic level of exploration in NLP. Additionally, NLP is\nalso lagging behind in terms of learning sparse representations of large units\nof text e.g., sentences. We use the VAEs that induce sparse latent\nrepresentations of large units of text to address the aforementioned\nshortcomings. First, we move in this direction by measuring the success of\nunsupervised state-of-the-art (SOTA) and other strong VAE-based sparsification\nbaselines for text and propose a hierarchical sparse VAE model to address the\nstability issue of SOTA. Then, we look at the implications of sparsity on text\nclassification across 3 datasets, and highlight a link between performance of\nsparse latent representations on downstream tasks and its ability to encode\ntask-related information.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 20:08:32 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 23:43:09 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Prokhorov", "Victor", ""], ["Li", "Yingzhen", ""], ["Shareghi", "Ehsan", ""], ["Collier", "Nigel", ""]]}, {"id": "2009.12431", "submitter": "Vivian Silva", "authors": "Vivian S. Silva, Andr\\'e Freitas, Siegfried Handschuh", "title": "XTE: Explainable Text Entailment", "comments": "44 pages, 7 figures. Submitted to the Artificial Intelligence Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text entailment, the task of determining whether a piece of text logically\nfollows from another piece of text, is a key component in NLP, providing input\nfor many semantic applications such as question answering, text summarization,\ninformation extraction, and machine translation, among others. Entailment\nscenarios can range from a simple syntactic variation to more complex semantic\nrelationships between pieces of text, but most approaches try a\none-size-fits-all solution that usually favors some scenario to the detriment\nof another. Furthermore, for entailments requiring world knowledge, most\nsystems still work as a \"black box\", providing a yes/no answer that does not\nexplain the underlying reasoning process. In this work, we introduce XTE -\nExplainable Text Entailment - a novel composite approach for recognizing text\nentailment which analyzes the entailment pair to decide whether it must be\nresolved syntactically or semantically. Also, if a semantic matching is\ninvolved, we make the answer interpretable, using external knowledge bases\ncomposed of structured lexical definitions to generate natural language\njustifications that explain the semantic relationship holding between the\npieces of text. Besides outperforming well-established entailment algorithms,\nour composite approach gives an important step towards Explainable AI, allowing\nthe inference model interpretation, making the semantic reasoning process\nexplicit and understandable.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 20:49:07 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Silva", "Vivian S.", ""], ["Freitas", "Andr\u00e9", ""], ["Handschuh", "Siegfried", ""]]}, {"id": "2009.12452", "submitter": "Jean-Philippe Corbeil", "authors": "Jean-Philippe Corbeil and Hadi Abdi Ghadivel", "title": "BET: A Backtranslation Approach for Easy Data Augmentation in\n  Transformer-based Paraphrase Identification Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Newly-introduced deep learning architectures, namely BERT, XLNet, RoBERTa and\nALBERT, have been proved to be robust on several NLP tasks. However, the\ndatasets trained on these architectures are fixed in terms of size and\ngeneralizability. To relieve this issue, we apply one of the most inexpensive\nsolutions to update these datasets. We call this approach BET by which we\nanalyze the backtranslation data augmentation on the transformer-based\narchitectures. Using the Google Translate API with ten intermediary languages\nfrom ten different language families, we externally evaluate the results in the\ncontext of automatic paraphrase identification in a transformer-based\nframework. Our findings suggest that BET improves the paraphrase identification\nperformance on the Microsoft Research Paraphrase Corpus (MRPC) to more than 3%\non both accuracy and F1 score. We also analyze the augmentation in the low-data\nregime with downsampled versions of MRPC, Twitter Paraphrase Corpus (TPC) and\nQuora Question Pairs. In many low-data cases, we observe a switch from a\nfailing model on the test set to reasonable performances. The results\ndemonstrate that BET is a highly promising data augmentation technique: to push\nthe current state-of-the-art of existing datasets and to bootstrap the\nutilization of deep learning architectures in the low-data regime of a hundred\nsamples.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 22:06:06 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Corbeil", "Jean-Philippe", ""], ["Ghadivel", "Hadi Abdi", ""]]}, {"id": "2009.12496", "submitter": "Qiang Liu", "authors": "Qiang Liu", "title": "Modeling Dyadic Conversations for Personality Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, automatical personality inference is drawing extensive attention\nfrom both academia and industry. Conventional methods are mainly based on user\ngenerated contents, e.g., profiles, likes, and texts of an individual, on\nsocial media, which are actually not very reliable. In contrast, dyadic\nconversations between individuals can not only capture how one expresses\noneself, but also reflect how one reacts to different situations. Rich\ncontextual information in dyadic conversation can explain an individual's\nresponse during his or her conversation. In this paper, we propose a novel\naugmented Gated Recurrent Unit (GRU) model for learning unsupervised Personal\nConversational Embeddings (PCE) based on dyadic conversations between\nindividuals. We adjust the formulation of each layer of a conventional GRU with\nsequence to sequence learning and personal information of both sides of the\nconversation. Based on the learned PCE, we can infer the personality of each\nindividual. We conduct experiments on the Movie Script dataset, which is\ncollected from conversations between characters in movie scripts. We find that\nmodeling dyadic conversations between individuals can significantly improve\npersonality inference accuracy. Experimental results illustrate the successful\nperformance of our proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 01:25:42 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Liu", "Qiang", ""]]}, {"id": "2009.12506", "submitter": "Sashank Santhanam", "authors": "Sashank Santhanam, Zhuo Cheng, Brodie Mather, Bonnie Dorr, Archna\n  Bhatia, Bryanna Hebenstreit, Alan Zemel, Adam Dalton, Tomek Strzalkowski and\n  Samira Shaikh", "title": "Learning to Plan and Realize Separately for Open-Ended Dialogue Systems", "comments": "Accepted at EMNLP 2020 (Findings)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Achieving true human-like ability to conduct a conversation remains an\nelusive goal for open-ended dialogue systems. We posit this is because extant\napproaches towards natural language generation (NLG) are typically construed as\nend-to-end architectures that do not adequately model human generation\nprocesses. To investigate, we decouple generation into two separate phases:\nplanning and realization. In the planning phase, we train two planners to\ngenerate plans for response utterances. The realization phase uses response\nplans to produce an appropriate response. Through rigorous evaluations, both\nautomated and human, we demonstrate that decoupling the process into planning\nand realization performs better than an end-to-end approach.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 02:31:42 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 23:57:43 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Santhanam", "Sashank", ""], ["Cheng", "Zhuo", ""], ["Mather", "Brodie", ""], ["Dorr", "Bonnie", ""], ["Bhatia", "Archna", ""], ["Hebenstreit", "Bryanna", ""], ["Zemel", "Alan", ""], ["Dalton", "Adam", ""], ["Strzalkowski", "Tomek", ""], ["Shaikh", "Samira", ""]]}, {"id": "2009.12517", "submitter": "Dai Quoc Nguyen", "authors": "Dai Quoc Nguyen and Thanh Vu and Tu Dinh Nguyen and Dinh Phung", "title": "QuatRE: Relation-Aware Quaternions for Knowledge Graph Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple and effective embedding model, named QuatRE, to learn\nquaternion embeddings for entities and relations in knowledge graphs. QuatRE\naims to enhance correlations between head and tail entities given a relation\nwithin the Quaternion space with Hamilton product. QuatRE achieves this by\nassociating each relation with two quaternion vectors which are used to rotate\nthe quaternion embeddings of the head and tail entities, respectively. To\nobtain the triple score, QuatRE rotates the rotated embedding of the head\nentity using the normalized quaternion embedding of the relation, followed by a\nquaternion-inner product with the rotated embedding of the tail entity.\nExperimental results show that our QuatRE outperforms up-to-date embedding\nmodels on well-known benchmark datasets for knowledge graph completion.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 04:44:25 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Nguyen", "Dai Quoc", ""], ["Vu", "Thanh", ""], ["Nguyen", "Tu Dinh", ""], ["Phung", "Dinh", ""]]}, {"id": "2009.12534", "submitter": "Gaurav Arora", "authors": "Gaurav Arora", "title": "iNLTK: Natural Language Toolkit for Indic Languages", "comments": "Accepted at EMNLP2020's NLP-OSS workshop", "journal-ref": null, "doi": "10.18653/v1/2020.nlposs-1.10", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present iNLTK, an open-source NLP library consisting of pre-trained\nlanguage models and out-of-the-box support for Data Augmentation, Textual\nSimilarity, Sentence Embeddings, Word Embeddings, Tokenization and Text\nGeneration in 13 Indic Languages. By using pre-trained models from iNLTK for\ntext classification on publicly available datasets, we significantly outperform\npreviously reported results. On these datasets, we also show that by using\npre-trained models and data augmentation from iNLTK, we can achieve more than\n95% of the previous best performance by using less than 10% of the training\ndata. iNLTK is already being widely used by the community and has 40,000+\ndownloads, 600+ stars and 100+ forks on GitHub. The library is available at\nhttps://github.com/goru001/inltk.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 08:21:32 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 07:46:21 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Arora", "Gaurav", ""]]}, {"id": "2009.12539", "submitter": "Yi Xu", "authors": "Yi Xu, Hai Zhao, Zhuosheng Zhang", "title": "Topic-Aware Multi-turn Dialogue Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the retrieval-based multi-turn dialogue modeling, it remains a challenge\nto select the most appropriate response according to extracting salient\nfeatures in context utterances. As a conversation goes on, topic shift at\ndiscourse-level naturally happens through the continuous multi-turn dialogue\ncontext. However, all known retrieval-based systems are satisfied with\nexploiting local topic words for context utterance representation but fail to\ncapture such essential global topic-aware clues at discourse-level. Instead of\ntaking topic-agnostic n-gram utterance as processing unit for matching purpose\nin existing systems, this paper presents a novel topic-aware solution for\nmulti-turn dialogue modeling, which segments and extracts topic-aware\nutterances in an unsupervised way, so that the resulted model is capable of\ncapturing salient topic shift at discourse-level in need and thus effectively\ntrack topic flow during multi-turn conversation. Our topic-aware modeling is\nimplemented by a newly proposed unsupervised topic-aware segmentation algorithm\nand Topic-Aware Dual-attention Matching (TADAM) Network, which matches each\ntopic segment with the response in a dual cross-attention way. Experimental\nresults on three public datasets show TADAM can outperform the state-of-the-art\nmethod, especially by 3.3% on E-commerce dataset that has an obvious topic\nshift.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 08:43:06 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 05:46:27 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Xu", "Yi", ""], ["Zhao", "Hai", ""], ["Zhang", "Zhuosheng", ""]]}, {"id": "2009.12565", "submitter": "Shashwat Aggarwal", "authors": "Shashwat Aggarwal, Ramesh Singh", "title": "Metaphor Detection using Deep Contextualized Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metaphors are ubiquitous in natural language, and their detection plays an\nessential role in many natural language processing tasks, such as language\nunderstanding, sentiment analysis, etc. Most existing approaches for metaphor\ndetection rely on complex, hand-crafted and fine-tuned feature pipelines, which\ngreatly limit their applicability. In this work, we present an end-to-end\nmethod composed of deep contextualized word embeddings, bidirectional LSTMs and\nmulti-head attention mechanism to address the task of automatic metaphor\ndetection. Our method, unlike many other existing approaches, requires only the\nraw text sequences as input features to detect the metaphoricity of a phrase.\nWe compare the performance of our method against the existing baselines on two\nbenchmark datasets, TroFi, and MOH-X respectively. Experimental evaluations\nconfirm the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 11:00:35 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Aggarwal", "Shashwat", ""], ["Singh", "Ramesh", ""]]}, {"id": "2009.12615", "submitter": "Tsolak Ghukasyan", "authors": "Arthur Malajyan, Karen Avetisyan, Tsolak Ghukasyan", "title": "ARPA: Armenian Paraphrase Detection Corpus and Models", "comments": "To be published in the proceedings of Ivannikov Memorial Workshop\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we employ a semi-automatic method based on back translation to\ngenerate a sentential paraphrase corpus for the Armenian language. The initial\ncollection of sentences is translated from Armenian to English and back twice,\nresulting in pairs of lexically distant but semantically similar sentences. The\ngenerated paraphrases are then manually reviewed and annotated. Using the\nmethod train and test datasets are created, containing 2360 paraphrases in\ntotal. In addition, the datasets are used to train and evaluate BERTbased\nmodels for detecting paraphrase in Armenian, achieving results comparable to\nthe state-of-the-art of other languages.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 14:56:57 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Malajyan", "Arthur", ""], ["Avetisyan", "Karen", ""], ["Ghukasyan", "Tsolak", ""]]}, {"id": "2009.12622", "submitter": "Maha Jarallah Althobaiti", "authors": "Maha J. Althobaiti", "title": "Automatic Arabic Dialect Identification Systems for Written Texts: A\n  Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arabic dialect identification is a specific task of natural language\nprocessing, aiming to automatically predict the Arabic dialect of a given text.\nArabic dialect identification is the first step in various natural language\nprocessing applications such as machine translation, multilingual\ntext-to-speech synthesis, and cross-language text generation. Therefore, in the\nlast decade, interest has increased in addressing the problem of Arabic dialect\nidentification. In this paper, we present a comprehensive survey of Arabic\ndialect identification research in written texts. We first define the problem\nand its challenges. Then, the survey extensively discusses in a critical manner\nmany aspects related to Arabic dialect identification task. So, we review the\ntraditional machine learning methods, deep learning architectures, and complex\nlearning approaches to Arabic dialect identification. We also detail the\nfeatures and techniques for feature representations used to train the proposed\nsystems. Moreover, we illustrate the taxonomy of Arabic dialects studied in the\nliterature, the various levels of text processing at which Arabic dialect\nidentification are conducted (e.g., token, sentence, and document level), as\nwell as the available annotated resources, including evaluation benchmark\ncorpora. Open challenges and issues are discussed at the end of the survey.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 15:33:16 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Althobaiti", "Maha J.", ""]]}, {"id": "2009.12626", "submitter": "Klim Zaporojets", "authors": "Klim Zaporojets, Johannes Deleu, Chris Develder, Thomas Demeester", "title": "DWIE: an entity-centric dataset for multi-task document-level\n  information extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents DWIE, the 'Deutsche Welle corpus for Information\nExtraction', a newly created multi-task dataset that combines four main\nInformation Extraction (IE) annotation subtasks: (i) Named Entity Recognition\n(NER), (ii) Coreference Resolution, (iii) Relation Extraction (RE), and (iv)\nEntity Linking. DWIE is conceived as an entity-centric dataset that describes\ninteractions and properties of conceptual entities on the level of the complete\ndocument. This contrasts with currently dominant mention-driven approaches that\nstart from the detection and classification of named entity mentions in\nindividual sentences. Further, DWIE presented two main challenges when building\nand evaluating IE models for it. First, the use of traditional mention-level\nevaluation metrics for NER and RE tasks on entity-centric DWIE dataset can\nresult in measurements dominated by predictions on more frequently mentioned\nentities. We tackle this issue by proposing a new entity-driven metric that\ntakes into account the number of mentions that compose each of the predicted\nand ground truth entities. Second, the document-level multi-task annotations\nrequire the models to transfer information between entity mentions located in\ndifferent parts of the document, as well as between different tasks, in a joint\nlearning setting. To realize this, we propose to use graph-based neural message\npassing techniques between document-level mention spans. Our experiments show\nan improvement of up to 5.5 F1 percentage points when incorporating neural\ngraph propagation into our joint model. This demonstrates DWIE's potential to\nstimulate further research in graph neural networks for representation learning\nin multi-task IE. We make DWIE publicly available at\nhttps://github.com/klimzaporojets/DWIE.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 15:53:22 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 13:46:09 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Zaporojets", "Klim", ""], ["Deleu", "Johannes", ""], ["Develder", "Chris", ""], ["Demeester", "Thomas", ""]]}, {"id": "2009.12643", "submitter": "Ning Shi", "authors": "Ning Shi, Ziheng Zeng, Haotian Zhang, Yichen Gong", "title": "Recurrent Inference in Text Editing", "comments": "12 pages, 4 figures, 3 tables, and 1 page appendix", "journal-ref": null, "doi": "10.18653/v1/2020.findings-emnlp.159", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neural text editing, prevalent sequence-to-sequence based approaches\ndirectly map the unedited text either to the edited text or the editing\noperations, in which the performance is degraded by the limited source text\nencoding and long, varying decoding steps. To address this problem, we propose\na new inference method, Recurrence, that iteratively performs editing actions,\nsignificantly narrowing the problem space. In each iteration, encoding the\npartially edited text, Recurrence decodes the latent representation, generates\nan action of short, fixed-length, and applies the action to complete a single\nedit. For a comprehensive comparison, we introduce three types of text editing\ntasks: Arithmetic Operators Restoration (AOR), Arithmetic Equation\nSimplification (AES), Arithmetic Equation Correction (AEC). Extensive\nexperiments on these tasks with varying difficulties demonstrate that\nRecurrence achieves improvements over conventional inference methods.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 17:06:29 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 04:12:05 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Shi", "Ning", ""], ["Zeng", "Ziheng", ""], ["Zhang", "Haotian", ""], ["Gong", "Yichen", ""]]}, {"id": "2009.12677", "submitter": "Ye Liu", "authors": "Ye Liu, Yao Wan, Lifang He, Hao Peng, Philip S. Yu", "title": "KG-BART: Knowledge Graph-Augmented BART for Generative Commonsense\n  Reasoning", "comments": "10 pages, 7 figures, Appear in AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative commonsense reasoning which aims to empower machines to generate\nsentences with the capacity of reasoning over a set of concepts is a critical\nbottleneck for text generation. Even the state-of-the-art pre-trained language\ngeneration models struggle at this task and often produce implausible and\nanomalous sentences. One reason is that they rarely consider incorporating the\nknowledge graph which can provide rich relational information among the\ncommonsense concepts. To promote the ability of commonsense reasoning for text\ngeneration, we propose a novel knowledge graph augmented pre-trained language\ngeneration model KG-BART, which encompasses the complex relations of concepts\nthrough the knowledge graph and produces more logical and natural sentences as\noutput. Moreover, KG-BART can leverage the graph attention to aggregate the\nrich concept semantics that enhances the model generalization on unseen concept\nsets. Experiments on benchmark CommonGen dataset verify the effectiveness of\nour proposed approach by comparing with several strong pre-trained language\ngeneration models, particularly KG-BART outperforms BART by 5.80, 4.60, in\nterms of BLEU-3, 4. Moreover, we also show that the generated context by our\nmodel can work as background scenarios to benefit downstream commonsense QA\ntasks.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 19:57:49 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 06:02:59 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Liu", "Ye", ""], ["Wan", "Yao", ""], ["He", "Lifang", ""], ["Peng", "Hao", ""], ["Yu", "Philip S.", ""]]}, {"id": "2009.12681", "submitter": "Hoda Eldardiry", "authors": "Chenhan Yuan, Ryan Rossi, Andrew Katz, and Hoda Eldardiry", "title": "Clustering-based Unsupervised Generative Relation Extraction", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the problem of unsupervised relation extraction.\nExisting probabilistic generative model-based relation extraction methods work\nby extracting sentence features and using these features as inputs to train a\ngenerative model. This model is then used to cluster similar relations.\nHowever, these methods do not consider correlations between sentences with the\nsame entity pair during training, which can negatively impact model\nperformance. To address this issue, we propose a Clustering-based Unsupervised\ngenerative Relation Extraction (CURE) framework that leverages an\n\"Encoder-Decoder\" architecture to perform self-supervised learning so the\nencoder can extract relation information. Given multiple sentences with the\nsame entity pair as inputs, self-supervised learning is deployed by predicting\nthe shortest path between entity pairs on the dependency graph of one of the\nsentences. After that, we extract the relation information using the\nwell-trained encoder. Then, entity pairs that share the same relation are\nclustered based on their corresponding relation information. Each cluster is\nlabeled with a few words based on the words in the shortest paths corresponding\nto the entity pairs in each cluster. These cluster labels also describe the\nmeaning of these relation clusters. We compare the triplets extracted by our\nproposed framework (CURE) and baseline methods with a ground-truth Knowledge\nBase. Experimental results show that our model performs better than\nstate-of-the-art models on both New York Times (NYT) and United Nations\nParallel Corpus (UNPC) standard datasets.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 20:36:40 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Yuan", "Chenhan", ""], ["Rossi", "Ryan", ""], ["Katz", "Andrew", ""], ["Eldardiry", "Hoda", ""]]}, {"id": "2009.12683", "submitter": "Hoda Eldardiry", "authors": "Chenhan Yuan, Ryan Rossi, Andrew Katz, and Hoda Eldardiry", "title": "Reinforcement Learning-based N-ary Cross-Sentence Relation Extraction", "comments": "10 pages, 3 figures, submitted to AAAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The models of n-ary cross sentence relation extraction based on distant\nsupervision assume that consecutive sentences mentioning n entities describe\nthe relation of these n entities. However, on one hand, this assumption\nintroduces noisy labeled data and harms the models' performance. On the other\nhand, some non-consecutive sentences also describe one relation and these\nsentences cannot be labeled under this assumption. In this paper, we relax this\nstrong assumption by a weaker distant supervision assumption to address the\nsecond issue and propose a novel sentence distribution estimator model to\naddress the first problem. This estimator selects correctly labeled sentences\nto alleviate the effect of noisy data is a two-level agent reinforcement\nlearning model. In addition, a novel universal relation extractor with a hybrid\napproach of attention mechanism and PCNN is proposed such that it can be\ndeployed in any tasks, including consecutive and nonconsecutive sentences.\nExperiments demonstrate that the proposed model can reduce the impact of noisy\ndata and achieve better performance on general n-ary cross sentence relation\nextraction task compared to baseline models.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 20:39:55 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Yuan", "Chenhan", ""], ["Rossi", "Ryan", ""], ["Katz", "Andrew", ""], ["Eldardiry", "Hoda", ""]]}, {"id": "2009.12695", "submitter": "Tabish Maniar", "authors": "Chejui Liao, Tabish Maniar, Sravanajyothi N and Anantha Sharma", "title": "Techniques to Improve Q&A Accuracy with Transformer-based models on\n  Large Complex Documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper discusses the effectiveness of various text processing techniques,\ntheir combinations, and encodings to achieve a reduction of complexity and size\nin a given text corpus. The simplified text corpus is sent to BERT (or similar\ntransformer based models) for question and answering and can produce more\nrelevant responses to user queries. This paper takes a scientific approach to\ndetermine the benefits and effectiveness of various techniques and concludes a\nbest-fit combination that produces a statistically significant improvement in\naccuracy.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 21:56:22 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Liao", "Chejui", ""], ["Maniar", "Tabish", ""], ["N", "Sravanajyothi", ""], ["Sharma", "Anantha", ""]]}, {"id": "2009.12702", "submitter": "Konstantinos Kogkalidis", "authors": "Konstantinos Kogkalidis, Michael Moortgat, Richard Moot", "title": "Neural Proof Nets", "comments": "14 pages, CoNLL2020", "journal-ref": "Proceedings of the 24th Conference on Computational Natural\n  Language Learning (2020)", "doi": "10.18653/v1/2020.conll-1.3", "report-no": null, "categories": "cs.CL cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear logic and the linear {\\lambda}-calculus have a long standing tradition\nin the study of natural language form and meaning. Among the proof calculi of\nlinear logic, proof nets are of particular interest, offering an attractive\ngeometric representation of derivations that is unburdened by the bureaucratic\ncomplications of conventional prooftheoretic formats. Building on recent\nadvances in set-theoretic learning, we propose a neural variant of proof nets\nbased on Sinkhorn networks, which allows us to translate parsing as the problem\nof extracting syntactic primitives and permuting them into alignment. Our\nmethodology induces a batch-efficient, end-to-end differentiable architecture\nthat actualizes a formally grounded yet highly efficient neuro-symbolic parser.\nWe test our approach on {\\AE}Thel, a dataset of type-logical derivations for\nwritten Dutch, where it manages to correctly transcribe raw text sentences into\nproofs and terms of the linear {\\lambda}-calculus with an accuracy of as high\nas 70%.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 22:48:47 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Kogkalidis", "Konstantinos", ""], ["Moortgat", "Michael", ""], ["Moot", "Richard", ""]]}, {"id": "2009.12711", "submitter": "Gasper Begus", "authors": "Ga\\v{s}per Begu\\v{s}", "title": "Local and non-local dependency learning and emergence of rule-like\n  representations in speech data by Deep Convolutional Generative Adversarial\n  Networks", "comments": "In press at Computer Speech & Language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper argues that training GANs on local and non-local dependencies in\nspeech data offers insights into how deep neural networks discretize continuous\ndata and how symbolic-like rule-based morphophonological processes emerge in a\ndeep convolutional architecture. Acquisition of speech has recently been\nmodeled as a dependency between latent space and data generated by GANs in\nBegu\\v{s} (2020b; arXiv:2006.03965), who models learning of a simple local\nallophonic distribution. We extend this approach to test learning of local and\nnon-local phonological processes that include approximations of morphological\nprocesses. We further parallel outputs of the model to results of a behavioral\nexperiment where human subjects are trained on the data used for training the\nGAN network. Four main conclusions emerge: (i) the networks provide useful\ninformation for computational models of speech acquisition even if trained on a\ncomparatively small dataset of an artificial grammar learning experiment; (ii)\nlocal processes are easier to learn than non-local processes, which matches\nboth behavioral data in human subjects and typology in the world's languages.\nThis paper also proposes (iii) how we can actively observe the network's\nprogress in learning and explore the effect of training steps on learning\nrepresentations by keeping latent space constant across different training\nsteps. Finally, this paper shows that (iv) the network learns to encode the\npresence of a prefix with a single latent variable; by interpolating this\nvariable, we can actively observe the operation of a non-local phonological\nprocess. The proposed technique for retrieving learning representations has\ngeneral implications for our understanding of how GANs discretize continuous\nspeech data and suggests that rule-like generalizations in the training data\nare represented as an interaction between variables in the network's latent\nspace.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 00:02:34 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 07:28:49 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Begu\u0161", "Ga\u0161per", ""]]}, {"id": "2009.12719", "submitter": "Yinhe Zheng Dr.", "authors": "Yinhe Zheng, Zikai Chen, Rongsheng Zhang, Shilei Huang, Xiaoxi Mao,\n  Minlie Huang", "title": "Stylized Dialogue Response Generation Using Stylized Unpaired Texts", "comments": "Accepted by AAAI2021 (Long Paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating stylized responses is essential to build intelligent and engaging\ndialogue systems. However, this task is far from well-explored due to the\ndifficulties of rendering a particular style in coherent responses, especially\nwhen the target style is embedded only in unpaired texts that cannot be\ndirectly used to train the dialogue model. This paper proposes a stylized\ndialogue generation method that can capture stylistic features embedded in\nunpaired texts. Specifically, our method can produce dialogue responses that\nare both coherent to the given context and conform to the target style. In this\nstudy, an inverse dialogue model is first introduced to predict possible posts\nfor the input responses, and then this inverse model is used to generate\nstylized pseudo dialogue pairs based on these stylized unpaired texts. Further,\nthese pseudo pairs are employed to train the stylized dialogue model with a\njoint training process, and a style routing approach is proposed to intensify\nstylistic features in the decoder. Automatic and manual evaluations on two\ndatasets demonstrate that our method outperforms competitive baselines in\nproducing coherent and style-intensive dialogue responses.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 01:04:06 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 02:21:48 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Zheng", "Yinhe", ""], ["Chen", "Zikai", ""], ["Zhang", "Rongsheng", ""], ["Huang", "Shilei", ""], ["Mao", "Xiaoxi", ""], ["Huang", "Minlie", ""]]}, {"id": "2009.12721", "submitter": "Hongming Zhang", "authors": "Hongming Zhang, Xinran Zhao, Yangqiu Song", "title": "A Brief Survey and Comparative Study of Recent Development of Pronoun\n  Coreference Resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pronoun Coreference Resolution (PCR) is the task of resolving pronominal\nexpressions to all mentions they refer to. Compared with the general\ncoreference resolution task, the main challenge of PCR is the coreference\nrelation prediction rather than the mention detection. As one important natural\nlanguage understanding (NLU) component, pronoun resolution is crucial for many\ndownstream tasks and still challenging for existing models, which motivates us\nto survey existing approaches and think about how to do better. In this survey,\nwe first introduce representative datasets and models for the ordinary pronoun\ncoreference resolution task. Then we focus on recent progress on hard pronoun\ncoreference resolution problems (e.g., Winograd Schema Challenge) to analyze\nhow well current models can understand commonsense. We conduct extensive\nexperiments to show that even though current models are achieving good\nperformance on the standard evaluation set, they are still not ready to be used\nin real applications (e.g., all SOTA models struggle on correctly resolving\npronouns to infrequent objects). All experiment codes are available at\nhttps://github.com/HKUST-KnowComp/PCR.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 01:40:01 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Zhang", "Hongming", ""], ["Zhao", "Xinran", ""], ["Song", "Yangqiu", ""]]}, {"id": "2009.12727", "submitter": "Javier Turek", "authors": "Shivangi Mahto, Vy A. Vo, Javier S. Turek, Alexander G. Huth", "title": "Multi-timescale Representation Learning in LSTM Language Models", "comments": null, "journal-ref": "International Conference on Learning Representations 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language models must capture statistical dependencies between words at\ntimescales ranging from very short to very long. Earlier work has demonstrated\nthat dependencies in natural language tend to decay with distance between words\naccording to a power law. However, it is unclear how this knowledge can be used\nfor analyzing or designing neural network language models. In this work, we\nderived a theory for how the memory gating mechanism in long short-term memory\n(LSTM) language models can capture power law decay. We found that unit\ntimescales within an LSTM, which are determined by the forget gate bias, should\nfollow an Inverse Gamma distribution. Experiments then showed that LSTM\nlanguage models trained on natural English text learn to approximate this\ntheoretical distribution. Further, we found that explicitly imposing the\ntheoretical distribution upon the model during training yielded better language\nmodel perplexity overall, with particular improvements for predicting\nlow-frequency (rare) words. Moreover, the explicit multi-timescale model\nselectively routes information about different types of words through units\nwith different timescales, potentially improving model interpretability. These\nresults demonstrate the importance of careful, theoretically-motivated analysis\nof memory and timescale in language models.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 02:13:38 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 00:06:08 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Mahto", "Shivangi", ""], ["Vo", "Vy A.", ""], ["Turek", "Javier S.", ""], ["Huth", "Alexander G.", ""]]}, {"id": "2009.12735", "submitter": "Hainan Zhang", "authors": "Hainan Zhang, Yanyan Lan, Liang Pang, Hongshen Chen, Zhuoye Ding and\n  Dawei Yin", "title": "Modeling Topical Relevance for Multi-Turn Dialogue Generation", "comments": null, "journal-ref": "the 29th International Joint Conference on Artificial\n  Intelligence(IJCAI 2020)", "doi": null, "report-no": null, "categories": "cs.CL cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic drift is a common phenomenon in multi-turn dialogue. Therefore, an\nideal dialogue generation models should be able to capture the topic\ninformation of each context, detect the relevant context, and produce\nappropriate responses accordingly. However, existing models usually use word or\nsentence level similarities to detect the relevant contexts, which fail to well\ncapture the topical level relevance. In this paper, we propose a new model,\nnamed STAR-BTM, to tackle this problem. Firstly, the Biterm Topic Model is\npre-trained on the whole training dataset. Then, the topic level attention\nweights are computed based on the topic representation of each context.\nFinally, the attention weights and the topic distribution are utilized in the\ndecoding process to generate the corresponding responses. Experimental results\non both Chinese customer services data and English Ubuntu dialogue data show\nthat STAR-BTM significantly outperforms several state-of-the-art methods, in\nterms of both metric-based and human evaluations.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 03:33:22 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Zhang", "Hainan", ""], ["Lan", "Yanyan", ""], ["Pang", "Liang", ""], ["Chen", "Hongshen", ""], ["Ding", "Zhuoye", ""], ["Yin", "Dawei", ""]]}, {"id": "2009.12756", "submitter": "Barlas Oguz", "authors": "Wenhan Xiong, Xiang Lorraine Li, Srini Iyer, Jingfei Du, Patrick\n  Lewis, William Yang Wang, Yashar Mehdad, Wen-tau Yih, Sebastian Riedel, Douwe\n  Kiela, Barlas O\\u{g}uz", "title": "Answering Complex Open-Domain Questions with Multi-Hop Dense Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple and efficient multi-hop dense retrieval approach for\nanswering complex open-domain questions, which achieves state-of-the-art\nperformance on two multi-hop datasets, HotpotQA and multi-evidence FEVER.\nContrary to previous work, our method does not require access to any\ncorpus-specific information, such as inter-document hyperlinks or\nhuman-annotated entity markers, and can be applied to any unstructured text\ncorpus. Our system also yields a much better efficiency-accuracy trade-off,\nmatching the best published accuracy on HotpotQA while being 10 times faster at\ninference time.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 06:12:29 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 22:15:03 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Xiong", "Wenhan", ""], ["Li", "Xiang Lorraine", ""], ["Iyer", "Srini", ""], ["Du", "Jingfei", ""], ["Lewis", "Patrick", ""], ["Wang", "William Yang", ""], ["Mehdad", "Yashar", ""], ["Yih", "Wen-tau", ""], ["Riedel", "Sebastian", ""], ["Kiela", "Douwe", ""], ["O\u011fuz", "Barlas", ""]]}, {"id": "2009.12765", "submitter": "Damai Dai", "authors": "Damai Dai, Hua Zheng, Fuli Luo, Pengcheng Yang, Baobao Chang, Zhifang\n  Sui", "title": "Inductively Representing Out-of-Knowledge-Graph Entities by Optimal\n  Estimation Under Translational Assumptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional Knowledge Graph Completion (KGC) assumes that all test entities\nappear during training. However, in real-world scenarios, Knowledge Graphs (KG)\nevolve fast with out-of-knowledge-graph (OOKG) entities added frequently, and\nwe need to represent these entities efficiently. Most existing Knowledge Graph\nEmbedding (KGE) methods cannot represent OOKG entities without costly\nretraining on the whole KG. To enhance efficiency, we propose a simple and\neffective method that inductively represents OOKG entities by their optimal\nestimation under translational assumptions. Given pretrained embeddings of the\nin-knowledge-graph (IKG) entities, our method needs no additional learning.\nExperimental results show that our method outperforms the state-of-the-art\nmethods with higher efficiency on two KGC tasks with OOKG entities.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 07:12:18 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Dai", "Damai", ""], ["Zheng", "Hua", ""], ["Luo", "Fuli", ""], ["Yang", "Pengcheng", ""], ["Chang", "Baobao", ""], ["Sui", "Zhifang", ""]]}, {"id": "2009.12770", "submitter": "Deepak Gupta", "authors": "Deepak Gupta, Swati Suman, Asif Ekbal", "title": "Hierarchical Deep Multi-modal Network for Medical Visual Question\n  Answering", "comments": "Accepted for publication at Expert Systems with Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Visual Question Answering in Medical domain (VQA-Med) plays an important role\nin providing medical assistance to the end-users. These users are expected to\nraise either a straightforward question with a Yes/No answer or a challenging\nquestion that requires a detailed and descriptive answer. The existing\ntechniques in VQA-Med fail to distinguish between the different question types\nsometimes complicates the simpler problems, or over-simplifies the complicated\nones. It is certainly true that for different question types, several distinct\nsystems can lead to confusion and discomfort for the end-users. To address this\nissue, we propose a hierarchical deep multi-modal network that analyzes and\nclassifies end-user questions/queries and then incorporates a query-specific\napproach for answer prediction. We refer our proposed approach as Hierarchical\nQuestion Segregation based Visual Question Answering, in short HQS-VQA. Our\ncontributions are three-fold, viz. firstly, we propose a question segregation\n(QS) technique for VQAMed; secondly, we integrate the QS model to the\nhierarchical deep multi-modal neural network to generate proper answers to the\nqueries related to medical images; and thirdly, we study the impact of QS in\nMedical-VQA by comparing the performance of the proposed model with QS and a\nmodel without QS. We evaluate the performance of our proposed model on two\nbenchmark datasets, viz. RAD and CLEF18. Experimental results show that our\nproposed HQS-VQA technique outperforms the baseline models with significant\nmargins. We also conduct a detailed quantitative and qualitative analysis of\nthe obtained results and discover potential causes of errors and their\nsolutions.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 07:24:41 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Gupta", "Deepak", ""], ["Suman", "Swati", ""], ["Ekbal", "Asif", ""]]}, {"id": "2009.12812", "submitter": "Wei Zhang", "authors": "Wei Zhang, Lu Hou, Yichun Yin, Lifeng Shang, Xiao Chen, Xin Jiang, Qun\n  Liu", "title": "TernaryBERT: Distillation-aware Ultra-low Bit BERT", "comments": "Accepted by EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer-based pre-training models like BERT have achieved remarkable\nperformance in many natural language processing tasks.However, these models are\nboth computation and memory expensive, hindering their deployment to\nresource-constrained devices. In this work, we propose TernaryBERT, which\nternarizes the weights in a fine-tuned BERT model. Specifically, we use both\napproximation-based and loss-aware ternarization methods and empirically\ninvestigate the ternarization granularity of different parts of BERT. Moreover,\nto reduce the accuracy degradation caused by the lower capacity of low bits, we\nleverage the knowledge distillation technique in the training process.\nExperiments on the GLUE benchmark and SQuAD show that our proposed TernaryBERT\noutperforms the other BERT quantization methods, and even achieves comparable\nperformance as the full-precision model while being 14.9x smaller.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 10:17:28 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 01:56:35 GMT"}, {"version": "v3", "created": "Sat, 10 Oct 2020 07:24:54 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Zhang", "Wei", ""], ["Hou", "Lu", ""], ["Yin", "Yichun", ""], ["Shang", "Lifeng", ""], ["Chen", "Xiao", ""], ["Jiang", "Xin", ""], ["Liu", "Qun", ""]]}, {"id": "2009.12862", "submitter": "Rochelle Choenni", "authors": "Rochelle Choenni, Ekaterina Shutova", "title": "What does it mean to be language-agnostic? Probing multilingual sentence\n  encoders for typological properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual sentence encoders have seen much success in cross-lingual model\ntransfer for downstream NLP tasks. Yet, we know relatively little about the\nproperties of individual languages or the general patterns of linguistic\nvariation that they encode. We propose methods for probing sentence\nrepresentations from state-of-the-art multilingual encoders (LASER, M-BERT, XLM\nand XLM-R) with respect to a range of typological properties pertaining to\nlexical, morphological and syntactic structure. In addition, we investigate how\nthis information is distributed across all layers of the models. Our results\nshow interesting differences in encoding linguistic variation associated with\ndifferent pretraining strategies.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 15:00:52 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Choenni", "Rochelle", ""], ["Shutova", "Ekaterina", ""]]}, {"id": "2009.12952", "submitter": "Trapit Bansal", "authors": "Vaishnavi Kommaraju, Karthick Gunasekaran, Kun Li, Trapit Bansal,\n  Andrew McCallum, Ivana Williams, Ana-Maria Istrate", "title": "Unsupervised Pre-training for Biomedical Question Answering", "comments": "To appear in BioASQ workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the suitability of unsupervised representation learning methods on\nbiomedical text -- BioBERT, SciBERT, and BioSentVec -- for biomedical question\nanswering. To further improve unsupervised representations for biomedical QA,\nwe introduce a new pre-training task from unlabeled data designed to reason\nabout biomedical entities in the context. Our pre-training method consists of\ncorrupting a given context by randomly replacing some mention of a biomedical\nentity with a random entity mention and then querying the model with the\ncorrect entity mention in order to locate the corrupted part of the context.\nThis de-noising task enables the model to learn good representations from\nabundant, unlabeled biomedical text that helps QA tasks and minimizes the\ntrain-test mismatch between the pre-training task and the downstream QA tasks\nby requiring the model to predict spans. Our experiments show that pre-training\nBioBERT on the proposed pre-training task significantly boosts performance and\noutperforms the previous best model from the 7th BioASQ Task 7b-Phase B\nchallenge.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 21:07:51 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Kommaraju", "Vaishnavi", ""], ["Gunasekaran", "Karthick", ""], ["Li", "Kun", ""], ["Bansal", "Trapit", ""], ["McCallum", "Andrew", ""], ["Williams", "Ivana", ""], ["Istrate", "Ana-Maria", ""]]}, {"id": "2009.12997", "submitter": "Haoding Meng Souray", "authors": "Haoding Meng, Qingcheng Zeng, Xiaoyang Fang, Zhexin Liang", "title": "Fancy Man Lauches Zippo at WNUT 2020 Shared Task-1: A Bert Case Model\n  for Wet Lab Entity Extraction", "comments": "EMNLP2020 WNUT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic or semi-automatic conversion of protocols specifying steps in\nperforming a lab procedure into machine-readable format benefits biological\nresearch a lot. These noisy, dense, and domain-specific lab protocols\nprocessing draws more and more interests with the development of deep learning.\nThis paper presents our teamwork on WNUT 2020 shared task-1: wet lab entity\nextract, that we conducted studies in several models, including a BiLSTM CRF\nmodel and a Bert case model which can be used to complete wet lab entity\nextraction. And we mainly discussed the performance differences of \\textbf{Bert\ncase} under different situations such as \\emph{transformers} versions, case\nsensitivity that may don't get enough attention before.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 01:05:08 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Meng", "Haoding", ""], ["Zeng", "Qingcheng", ""], ["Fang", "Xiaoyang", ""], ["Liang", "Zhexin", ""]]}, {"id": "2009.13013", "submitter": "Tiancheng Zhao", "authors": "Tiancheng Zhao, Xiaopeng Lu, Kyusong Lee", "title": "SPARTA: Efficient Open-Domain Question Answering via Sparse Transformer\n  Matching Retrieval", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce SPARTA, a novel neural retrieval method that shows great promise\nin performance, generalization, and interpretability for open-domain question\nanswering. Unlike many neural ranking methods that use dense vector nearest\nneighbor search, SPARTA learns a sparse representation that can be efficiently\nimplemented as an Inverted Index. The resulting representation enables scalable\nneural retrieval that does not require expensive approximate vector search and\nleads to better performance than its dense counterpart. We validated our\napproaches on 4 open-domain question answering (OpenQA) tasks and 11 retrieval\nquestion answering (ReQA) tasks. SPARTA achieves new state-of-the-art results\nacross a variety of open-domain question answering tasks in both English and\nChinese datasets, including open SQuAD, Natuarl Question, CMRC and etc.\nAnalysis also confirms that the proposed method creates human interpretable\nrepresentation and allows flexible control over the trade-off between\nperformance and efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 02:11:02 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Zhao", "Tiancheng", ""], ["Lu", "Xiaopeng", ""], ["Lee", "Kyusong", ""]]}, {"id": "2009.13028", "submitter": "Haochen Liu", "authors": "Haochen Liu, Wentao Wang, Yiqi Wang, Hui Liu, Zitao Liu and Jiliang\n  Tang", "title": "Mitigating Gender Bias for Neural Dialogue Generation with Adversarial\n  Learning", "comments": "Accepted by EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue systems play an increasingly important role in various aspects of\nour daily life. It is evident from recent research that dialogue systems\ntrained on human conversation data are biased. In particular, they can produce\nresponses that reflect people's gender prejudice. Many debiasing methods have\nbeen developed for various NLP tasks, such as word embedding. However, they are\nnot directly applicable to dialogue systems because they are likely to force\ndialogue models to generate similar responses for different genders. This\ngreatly degrades the diversity of the generated responses and immensely hurts\nthe performance of the dialogue models. In this paper, we propose a novel\nadversarial learning framework Debiased-Chat to train dialogue models free from\ngender bias while keeping their performance. Extensive experiments on two\nreal-world conversation datasets show that our framework significantly reduces\ngender bias in dialogue models while maintaining the response quality. The\nimplementation of the proposed framework is released.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 02:46:59 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2020 19:36:49 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Liu", "Haochen", ""], ["Wang", "Wentao", ""], ["Wang", "Yiqi", ""], ["Liu", "Hui", ""], ["Liu", "Zitao", ""], ["Tang", "Jiliang", ""]]}, {"id": "2009.13059", "submitter": "Shashwat Aggarwal", "authors": "Shashwat Aggarwal, Ramesh Singh", "title": "Visual Exploration and Knowledge Discovery from Biomedical Dark Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data visualization techniques proffer efficient means to organize and present\ndata in graphically appealing formats, which not only speeds up the process of\ndecision making and pattern recognition but also enables decision-makers to\nfully understand data insights and make informed decisions. Over time, with the\nrise in technological and computational resources, there has been an\nexponential increase in the world's scientific knowledge. However, most of it\nlacks structure and cannot be easily categorized and imported into regular\ndatabases. This type of data is often termed as Dark Data. Data visualization\ntechniques provide a promising solution to explore such data by allowing quick\ncomprehension of information, the discovery of emerging trends, identification\nof relationships and patterns, etc. In this empirical research study, we use\nthe rich corpus of PubMed comprising of more than 30 million citations from\nbiomedical literature to visually explore and understand the underlying\nkey-insights using various information visualization techniques. We employ a\nnatural language processing based pipeline to discover knowledge out of the\nbiomedical dark data. The pipeline comprises of different lexical analysis\ntechniques like Topic Modeling to extract inherent topics and major focus\nareas, Network Graphs to study the relationships between various entities like\nscientific documents and journals, researchers, and, keywords and terms, etc.\nWith this analytical research, we aim to proffer a potential solution to\novercome the problem of analyzing overwhelming amounts of information and\ndiminish the limitation of human cognition and perception in handling and\nexamining such large volumes of data.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 04:27:05 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Aggarwal", "Shashwat", ""], ["Singh", "Ramesh", ""]]}, {"id": "2009.13060", "submitter": "Duc Huy Huynh", "authors": "Huy Duc Huynh, Hang Thi-Thuy Do, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen", "title": "A Simple and Efficient Ensemble Classifier Combining Multiple Neural\n  Network Models on Social Media Datasets in Vietnamese", "comments": "Accepted by The 34th Pacific Asia Conference on Language, Information\n  and Computation (PACLIC2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Text classification is a popular topic of natural language processing, which\nhas currently attracted numerous research efforts worldwide. The significant\nincrease of data in social media requires the vast attention of researchers to\nanalyze such data. There are various studies in this field in many languages\nbut limited to the Vietnamese language. Therefore, this study aims to classify\nVietnamese texts on social media from three different Vietnamese benchmark\ndatasets. Advanced deep learning models are used and optimized in this study,\nincluding CNN, LSTM, and their variants. We also implement the BERT, which has\nnever been applied to the datasets. Our experiments find a suitable model for\nclassification tasks on each specific dataset. To take advantage of single\nmodels, we propose an ensemble model, combining the highest-performance models.\nOur single models reach positive results on each dataset. Moreover, our\nensemble model achieves the best performance on all three datasets. We reach\n86.96% of F1- score for the HSD-VLSP dataset, 65.79% of F1-score for the\nUIT-VSMEC dataset, 92.79% and 89.70% for sentiments and topics on the UIT-VSFC\ndataset, respectively. Therefore, our models achieve better performances as\ncompared to previous studies on these datasets.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 04:28:48 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 01:32:26 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Huynh", "Huy Duc", ""], ["Do", "Hang Thi-Thuy", ""], ["Van Nguyen", "Kiet", ""], ["Nguyen", "Ngan Luu-Thuy", ""]]}, {"id": "2009.13080", "submitter": "Boaz Shmueli", "authors": "Boaz Shmueli, Lun-Wei Ku, Soumya Ray", "title": "Reactive Supervision: A New Method for Collecting Sarcasm Data", "comments": "7 pages, 2 figures, 8 tables. To be published in Proceedings of the\n  2020 Conference on Empirical Methods in Natural Language Processing (EMNLP\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sarcasm detection is an important task in affective computing, requiring\nlarge amounts of labeled data. We introduce reactive supervision, a novel data\ncollection method that utilizes the dynamics of online conversations to\novercome the limitations of existing data collection techniques. We use the new\nmethod to create and release a first-of-its-kind large dataset of tweets with\nsarcasm perspective labels and new contextual features. The dataset is expected\nto advance sarcasm detection research. Our method can be adapted to other\naffective computing domains, thus opening up new research opportunities.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 05:04:22 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Shmueli", "Boaz", ""], ["Ku", "Lun-Wei", ""], ["Ray", "Soumya", ""]]}, {"id": "2009.13081", "submitter": "Di Jin", "authors": "Di Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng, Hanyi Fang and\n  Peter Szolovits", "title": "What Disease does this Patient Have? A Large-scale Open Domain Question\n  Answering Dataset from Medical Exams", "comments": "Submitted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open domain question answering (OpenQA) tasks have been recently attracting\nmore and more attention from the natural language processing (NLP) community.\nIn this work, we present the first free-form multiple-choice OpenQA dataset for\nsolving medical problems, MedQA, collected from the professional medical board\nexams. It covers three languages: English, simplified Chinese, and traditional\nChinese, and contains 12,723, 34,251, and 14,123 questions for the three\nlanguages, respectively. We implement both rule-based and popular neural\nmethods by sequentially combining a document retriever and a machine\ncomprehension model. Through experiments, we find that even the current best\nmethod can only achieve 36.7\\%, 42.0\\%, and 70.1\\% of test accuracy on the\nEnglish, traditional Chinese, and simplified Chinese questions, respectively.\nWe expect MedQA to present great challenges to existing OpenQA systems and hope\nthat it can serve as a platform to promote much stronger OpenQA models from the\nNLP community in the future.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 05:07:51 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Jin", "Di", ""], ["Pan", "Eileen", ""], ["Oufattole", "Nassim", ""], ["Weng", "Wei-Hung", ""], ["Fang", "Hanyi", ""], ["Szolovits", "Peter", ""]]}, {"id": "2009.13102", "submitter": "Xian Li", "authors": "Xian Li, Asa Cooper Stickland, Yuqing Tang, and Xiang Kong", "title": "Deep Transformers with Latent Depth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Transformer model has achieved state-of-the-art performance in many\nsequence modeling tasks. However, how to leverage model capacity with large or\nvariable depths is still an open challenge. We present a probabilistic\nframework to automatically learn which layer(s) to use by learning the\nposterior distributions of layer selection. As an extension of this framework,\nwe propose a novel method to train one shared Transformer network for\nmultilingual machine translation with different layer selection posteriors for\neach language pair. The proposed method alleviates the vanishing gradient issue\nand enables stable training of deep Transformers (e.g. 100 layers). We evaluate\non WMT English-German machine translation and masked language modeling tasks,\nwhere our method outperforms existing approaches for training deeper\nTransformers. Experiments on multilingual machine translation demonstrate that\nthis approach can effectively leverage increased model capacity and bring\nuniversal improvement for both many-to-one and one-to-many translation with\ndiverse language pairs.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 07:13:23 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 03:50:56 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Li", "Xian", ""], ["Stickland", "Asa Cooper", ""], ["Tang", "Yuqing", ""], ["Kong", "Xiang", ""]]}, {"id": "2009.13116", "submitter": "Anh Khoa Ngo Ho", "authors": "Anh Khoa Ngo Ho (LIMSI), Fran\\c{c}ois Yvon", "title": "Neural Baselines for Word Alignment", "comments": "The 16th International Workshop on Spoken Language Translation, Nov\n  2019, Hong Kong, Hong Kong SAR China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word alignments identify translational correspondences between words in a\nparallel sentence pair and is used, for instance, to learn bilingual\ndictionaries, to train statistical machine translation systems , or to perform\nquality estimation. In most areas of natural language processing, neural\nnetwork models nowadays constitute the preferred approach, a situation that\nmight also apply to word alignment models. In this work, we study and\ncomprehensively evaluate neural models for unsupervised word alignment for four\nlanguage pairs, contrasting several variants of neural models. We show that in\nmost settings, neural versions of the IBM-1 and hidden Markov models vastly\noutperform their discrete counterparts. We also analyze typical alignment\nerrors of the baselines that our models overcome to illustrate the benefits-and\nthe limitations-of these new models for morphologically rich languages.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 07:51:03 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Ho", "Anh Khoa Ngo", "", "LIMSI"], ["Yvon", "Fran\u00e7ois", ""]]}, {"id": "2009.13117", "submitter": "Anh Khoa Ngo Ho", "authors": "Anh Khoa Ngo Ho (LIMSI), Fran\\c{c}ois Yvon", "title": "Generative latent neural models for automatic word alignment", "comments": null, "journal-ref": "The Association for Machine Translation in the Americas, Oct 2020,\n  Florida, United States", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word alignments identify translational correspondences between words in a\nparallel sentence pair and are used, for instance, to learn bilingual\ndictionaries, to train statistical machine translation systems or to perform\nquality estimation. Variational autoencoders have been recently used in various\nof natural language processing to learn in an unsupervised way latent\nrepresentations that are useful for language generation tasks. In this paper,\nwe study these models for the task of word alignment and propose and assess\nseveral evolutions of a vanilla variational autoencoders. We demonstrate that\nthese techniques can yield competitive results as compared to Giza++ and to a\nstrong neural network alignment system for two language pairs.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 07:54:09 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Ho", "Anh Khoa Ngo", "", "LIMSI"], ["Yvon", "Fran\u00e7ois", ""]]}, {"id": "2009.13166", "submitter": "Qian Liu", "authors": "Qian Liu, Bei Chen, Jian-Guang Lou, Bin Zhou, Dongmei Zhang", "title": "Incomplete Utterance Rewriting as Semantic Segmentation", "comments": "To appear in EMNLP 2020 (Long Paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years the task of incomplete utterance rewriting has raised a large\nattention. Previous works usually shape it as a machine translation task and\nemploy sequence to sequence based architecture with copy mechanism. In this\npaper, we present a novel and extensive approach, which formulates it as a\nsemantic segmentation task. Instead of generating from scratch, such a\nformulation introduces edit operations and shapes the problem as prediction of\na word-level edit matrix. Benefiting from being able to capture both local and\nglobal information, our approach achieves state-of-the-art performance on\nseveral public datasets. Furthermore, our approach is four times faster than\nthe standard approach in inference.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 09:29:49 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Liu", "Qian", ""], ["Chen", "Bei", ""], ["Lou", "Jian-Guang", ""], ["Zhou", "Bin", ""], ["Zhang", "Dongmei", ""]]}, {"id": "2009.13199", "submitter": "Zhihan Zhang", "authors": "Zhihan Zhang, Xiubo Geng, Tao Qin, Yunfang Wu, Daxin Jiang", "title": "Knowledge-Aware Procedural Text Understanding with Multi-Stage Training", "comments": "Published as full paper in Proceedings of the Web Conference 2021\n  (WWW'21)", "journal-ref": null, "doi": "10.1145/3442381.3450126", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Procedural text describes dynamic state changes during a step-by-step natural\nprocess (e.g., photosynthesis). In this work, we focus on the task of\nprocedural text understanding, which aims to comprehend such documents and\ntrack entities' states and locations during a process. Although recent\napproaches have achieved substantial progress, their results are far behind\nhuman performance. Two challenges, the difficulty of commonsense reasoning and\ndata insufficiency, still remain unsolved, which require the incorporation of\nexternal knowledge bases. Previous works on external knowledge injection\nusually rely on noisy web mining tools and heuristic rules with limited\napplicable scenarios. In this paper, we propose a novel KnOwledge-Aware\nproceduraL text understAnding (KOALA) model, which effectively leverages\nmultiple forms of external knowledge in this task. Specifically, we retrieve\ninformative knowledge triples from ConceptNet and perform knowledge-aware\nreasoning while tracking the entities. Besides, we employ a multi-stage\ntraining schema which fine-tunes the BERT model over unlabeled data collected\nfrom Wikipedia before further fine-tuning it on the final model. Experimental\nresults on two procedural text datasets, ProPara and Recipes, verify the\neffectiveness of the proposed methods, in which our model achieves\nstate-of-the-art performance in comparison to various baselines.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 10:28:40 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 14:28:25 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Zhang", "Zhihan", ""], ["Geng", "Xiubo", ""], ["Qin", "Tao", ""], ["Wu", "Yunfang", ""], ["Jiang", "Daxin", ""]]}, {"id": "2009.13252", "submitter": "Xueping Peng", "authors": "Xueping Peng, Guodong Long, Tao Shen, Sen Wang, Jing Jiang, Chengqi\n  Zhang", "title": "BiteNet: Bidirectional Temporal Encoder Network to Predict Medical\n  Outcomes", "comments": "10 pages, 8 figures, accepted by IEEE ICDM 2020. arXiv admin note:\n  substantial text overlap with arXiv:2006.10516", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic health records (EHRs) are longitudinal records of a patient's\ninteractions with healthcare systems. A patient's EHR data is organized as a\nthree-level hierarchy from top to bottom: patient journey - all the experiences\nof diagnoses and treatments over a period of time; individual visit - a set of\nmedical codes in a particular visit; and medical code - a specific record in\nthe form of medical codes. As EHRs begin to amass in millions, the potential\nbenefits, which these data might hold for medical research and medical outcome\nprediction, are staggering - including, for example, predicting future\nadmissions to hospitals, diagnosing illnesses or determining the efficacy of\nmedical treatments. Each of these analytics tasks requires a domain knowledge\nextraction method to transform the hierarchical patient journey into a vector\nrepresentation for further prediction procedure. The representations should\nembed a sequence of visits and a set of medical codes with a specific\ntimestamp, which are crucial to any downstream prediction tasks. Hence,\nexpressively powerful representations are appealing to boost learning\nperformance. To this end, we propose a novel self-attention mechanism that\ncaptures the contextual dependency and temporal relationships within a\npatient's healthcare journey. An end-to-end bidirectional temporal encoder\nnetwork (BiteNet) then learns representations of the patient's journeys, based\nsolely on the proposed attention mechanism. We have evaluated the effectiveness\nof our methods on two supervised prediction and two unsupervised clustering\ntasks with a real-world EHR dataset. The empirical results demonstrate the\nproposed BiteNet model produces higher-quality representations than\nstate-of-the-art baseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2020 00:42:36 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Peng", "Xueping", ""], ["Long", "Guodong", ""], ["Shen", "Tao", ""], ["Wang", "Sen", ""], ["Jiang", "Jing", ""], ["Zhang", "Chengqi", ""]]}, {"id": "2009.13267", "submitter": "Pedram Rooshenas", "authors": "Sumanta Bhattacharyya, Amirmohammad Rooshenas, Subhajit Naskar, Simeng\n  Sun, Mohit Iyyer, Andrew McCallum", "title": "Energy-Based Reranking: Improving Neural Machine Translation Using\n  Energy-Based Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discrepancy between maximum likelihood estimation (MLE) and task measures\nsuch as BLEU score has been studied before for autoregressive neural machine\ntranslation (NMT) and resulted in alternative training algorithms (Ranzato et\nal., 2016; Norouzi et al., 2016; Shen et al., 2016; Wu et al., 2018). However,\nMLE training remains the de facto approach for autoregressive NMT because of\nits computational efficiency and stability. Despite this mismatch between the\ntraining objective and task measure, we notice that the samples drawn from an\nMLE-based trained NMT support the desired distribution -- there are samples\nwith much higher BLEU score comparing to the beam decoding output. To benefit\nfrom this observation, we train an energy-based model to mimic the behavior of\nthe task measure (i.e., the energy-based model assigns lower energy to samples\nwith higher BLEU score), which is resulted in a re-ranking algorithm based on\nthe samples drawn from NMT: energy-based re-ranking (EBR). We use both marginal\nenergy models (over target sentence) and joint energy models (over both source\nand target sentences). Our EBR with the joint energy model consistently\nimproves the performance of the Transformer-based NMT: +4 BLEU points on\nIWSLT'14 German-English, +3.0 BELU points on Sinhala-English, +1.2 BLEU on\nWMT'16 English-German tasks.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 02:50:52 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 04:57:59 GMT"}, {"version": "v3", "created": "Sat, 2 Jan 2021 05:39:16 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Bhattacharyya", "Sumanta", ""], ["Rooshenas", "Amirmohammad", ""], ["Naskar", "Subhajit", ""], ["Sun", "Simeng", ""], ["Iyyer", "Mohit", ""], ["McCallum", "Andrew", ""]]}, {"id": "2009.13270", "submitter": "Rajiv Movva", "authors": "Rajiv Movva, Jason Y. Zhao", "title": "Dissecting Lottery Ticket Transformers: Structural and Behavioral Study\n  of Sparse Neural Machine Translation", "comments": "Camera-ready for BlackboxNLP @ EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent work on the lottery ticket hypothesis has produced highly sparse\nTransformers for NMT while maintaining BLEU. However, it is unclear how such\npruning techniques affect a model's learned representations. By probing\nTransformers with more and more low-magnitude weights pruned away, we find that\ncomplex semantic information is first to be degraded. Analysis of internal\nactivations reveals that higher layers diverge most over the course of pruning,\ngradually becoming less complex than their dense counterparts. Meanwhile, early\nlayers of sparse models begin to perform more encoding. Attention mechanisms\nremain remarkably consistent as sparsity increases.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 02:08:45 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 18:55:22 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Movva", "Rajiv", ""], ["Zhao", "Jason Y.", ""]]}, {"id": "2009.13272", "submitter": "Ben Athiwaratkun", "authors": "Ben Athiwaratkun, Cicero Nogueira dos Santos, Jason Krone, Bing Xiang", "title": "Augmented Natural Language for Generative Sequence Labeling", "comments": "To appear at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generative framework for joint sequence labeling and\nsentence-level classification. Our model performs multiple sequence labeling\ntasks at once using a single, shared natural language output space. Unlike\nprior discriminative methods, our model naturally incorporates label semantics\nand shares knowledge across tasks. Our framework is general purpose, performing\nwell on few-shot, low-resource, and high-resource tasks. We demonstrate these\nadvantages on popular named entity recognition, slot labeling, and intent\nclassification benchmarks. We set a new state-of-the-art for few-shot slot\nlabeling, improving substantially upon the previous 5-shot ($75.0\\% \\rightarrow\n90.9\\%$) and 1-shot ($70.4\\% \\rightarrow 81.0\\%$) state-of-the-art results.\nFurthermore, our model generates large improvements ($46.27\\% \\rightarrow\n63.83\\%$) in low-resource slot labeling over a BERT baseline by incorporating\nlabel semantics. We also maintain competitive results on high-resource tasks,\nperforming within two points of the state-of-the-art on all tasks and setting a\nnew state-of-the-art on the SNIPS dataset.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 19:23:53 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Athiwaratkun", "Ben", ""], ["Santos", "Cicero Nogueira dos", ""], ["Krone", "Jason", ""], ["Xiang", "Bing", ""]]}, {"id": "2009.13275", "submitter": "Edgar Altszyler", "authors": "Edgar Altszyler, Pablo Brusco, Nikoletta Basiou, John Byrnes and\n  Dimitra Vergyri", "title": "Zero-shot Multi-Domain Dialog State Tracking Using Descriptive Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a framework for incorporating descriptive logical\nrules in state-of-the-art neural networks, enabling them to learn how to handle\nunseen labels without the introduction of any new training data. The rules are\nintegrated into existing networks without modifying their architecture, through\nan additional term in the network's loss function that penalizes states of the\nnetwork that do not obey the designed rules. As a case of study, the framework\nis applied to an existing neural-based Dialog State Tracker. Our experiments\ndemonstrate that the inclusion of logical rules allows the prediction of unseen\nlabels, without deteriorating the predictive capacity of the original system.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2020 18:14:25 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Altszyler", "Edgar", ""], ["Brusco", "Pablo", ""], ["Basiou", "Nikoletta", ""], ["Byrnes", "John", ""], ["Vergyri", "Dimitra", ""]]}, {"id": "2009.13282", "submitter": "Liang Zhao", "authors": "Liang Zhao, Jingjing Xu, Junyang Lin, Yichang Zhang, Hongxia Yang, Xu\n  Sun", "title": "Graph-based Multi-hop Reasoning for Long Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long text generation is an important but challenging task.The main problem\nlies in learning sentence-level semantic dependencies which traditional\ngenerative models often suffer from. To address this problem, we propose a\nMulti-hop Reasoning Generation (MRG) approach that incorporates multi-hop\nreasoning over a knowledge graph to learn semantic dependencies among\nsentences. MRG consists of twoparts, a graph-based multi-hop reasoning module\nand a path-aware sentence realization module. The reasoning module is\nresponsible for searching skeleton paths from a knowledge graph to imitate the\nimagination process in the human writing for semantic transfer. Based on the\ninferred paths, the sentence realization module then generates a complete\nsentence. Unlike previous black-box models, MRG explicitly infers the skeleton\npath, which provides explanatory views tounderstand how the proposed model\nworks. We conduct experiments on three representative tasks, including story\ngeneration, review generation, and product description generation. Automatic\nand manual evaluation show that our proposed method can generate more\ninformative and coherentlong text than strong baselines, such as pre-trained\nmodels(e.g. GPT-2) and knowledge-enhanced models.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 12:47:59 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Zhao", "Liang", ""], ["Xu", "Jingjing", ""], ["Lin", "Junyang", ""], ["Zhang", "Yichang", ""], ["Yang", "Hongxia", ""], ["Sun", "Xu", ""]]}, {"id": "2009.13284", "submitter": "Hongjin Qian", "authors": "Hongjin Qian, Xiaohe Li, Hanxun Zhong, Yu Guo, Yueyuan Ma, Yutao Zhu,\n  Zhanliang Liu, Zhicheng Dou, Ji-Rong Wen", "title": "Pchatbot: A Large-Scale Dataset for Personalized Chatbot", "comments": "Camera-ready version, SIGIR 2021 (Resource Track), the dataset and\n  codes are available at https://github.com/qhjqhj00/Pchatbot", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language dialogue systems raise great attention recently. As many\ndialogue models are data-driven, high-quality datasets are essential to these\nsystems. In this paper, we introduce Pchatbot, a large-scale dialogue dataset\nthat contains two subsets collected from Weibo and Judicial forums\nrespectively. To adapt the raw dataset to dialogue systems, we elaborately\nnormalize the raw dataset via processes such as anonymization, deduplication,\nsegmentation, and filtering. The scale of Pchatbot is significantly larger than\nexisting Chinese datasets, which might benefit the data-driven models. Besides,\ncurrent dialogue datasets for personalized chatbot usually contain several\npersona sentences or attributes. Different from existing datasets, Pchatbot\nprovides anonymized user IDs and timestamps for both posts and responses. This\nenables the development of personalized dialogue models that directly learn\nimplicit user personality from the user's dialogue history. Our preliminary\nexperimental study benchmarks several state-of-the-art dialogue models to\nprovide a comparison for future work. The dataset can be publicly accessed at\nGithub.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 12:49:07 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 02:51:35 GMT"}, {"version": "v3", "created": "Mon, 31 May 2021 05:53:44 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Qian", "Hongjin", ""], ["Li", "Xiaohe", ""], ["Zhong", "Hanxun", ""], ["Guo", "Yu", ""], ["Ma", "Yueyuan", ""], ["Zhu", "Yutao", ""], ["Liu", "Zhanliang", ""], ["Dou", "Zhicheng", ""], ["Wen", "Ji-Rong", ""]]}, {"id": "2009.13292", "submitter": "Itzik Malkiel", "authors": "Itzik Malkiel, Oren Barkan, Avi Caciularu, Noam Razin, Ori Katz and\n  Noam Koenigstein", "title": "RecoBERT: A Catalog Language Model for Text-Based Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language models that utilize extensive self-supervised pre-training from\nunlabeled text, have recently shown to significantly advance the\nstate-of-the-art performance in a variety of language understanding tasks.\nHowever, it is yet unclear if and how these recent models can be harnessed for\nconducting text-based recommendations. In this work, we introduce RecoBERT, a\nBERT-based approach for learning catalog-specialized language models for\ntext-based item recommendations. We suggest novel training and inference\nprocedures for scoring similarities between pairs of items, that don't require\nitem similarity labels. Both the training and the inference techniques were\ndesigned to utilize the unlabeled structure of textual catalogs, and minimize\nthe discrepancy between them. By incorporating four scores during inference,\nRecoBERT can infer text-based item-to-item similarities more accurately than\nother techniques. In addition, we introduce a new language understanding task\nfor wine recommendations using similarities based on professional wine reviews.\nAs an additional contribution, we publish annotated recommendations dataset\ncrafted by human wine experts. Finally, we evaluate RecoBERT and compare it to\nvarious state-of-the-art NLP models on wine and fashion recommendations tasks.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 14:23:38 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Malkiel", "Itzik", ""], ["Barkan", "Oren", ""], ["Caciularu", "Avi", ""], ["Razin", "Noam", ""], ["Katz", "Ori", ""], ["Koenigstein", "Noam", ""]]}, {"id": "2009.13295", "submitter": "Pepa Atanasova", "authors": "Pepa Atanasova, Jakob Grue Simonsen, Christina Lioma, Isabelle\n  Augenstein", "title": "A Diagnostic Study of Explainability Techniques for Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in machine learning have introduced models that approach\nhuman performance at the cost of increased architectural complexity. Efforts to\nmake the rationales behind the models' predictions transparent have inspired an\nabundance of new explainability techniques. Provided with an already trained\nmodel, they compute saliency scores for the words of an input instance.\nHowever, there exists no definitive guide on (i) how to choose such a technique\ngiven a particular application task and model architecture, and (ii) the\nbenefits and drawbacks of using each such technique. In this paper, we develop\na comprehensive list of diagnostic properties for evaluating existing\nexplainability techniques. We then employ the proposed list to compare a set of\ndiverse explainability techniques on downstream text classification tasks and\nneural network architectures. We also compare the saliency scores assigned by\nthe explainability techniques with human annotations of salient input regions\nto find relations between a model's performance and the agreement of its\nrationales with human ones. Overall, we find that the gradient-based\nexplanations perform best across tasks and model architectures, and we present\nfurther insights into the properties of the reviewed explainability techniques.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 12:01:53 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Atanasova", "Pepa", ""], ["Simonsen", "Jakob Grue", ""], ["Lioma", "Christina", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "2009.13299", "submitter": "Shuqing Bian", "authors": "Shuqing Bian, Xu Chen, Wayne Xin Zhao, Kun Zhou, Yupeng Hou, Yang\n  Song, Tao Zhang and Ji-Rong Wen", "title": "Learning to Match Jobs with Resumes from Sparse Interaction Data using\n  Multi-View Co-Teaching Network", "comments": null, "journal-ref": "CIKM 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the ever-increasing growth of online recruitment data, job-resume\nmatching has become an important task to automatically match jobs with suitable\nresumes. This task is typically casted as a supervised text matching problem.\nSupervised learning is powerful when the labeled data is sufficient. However,\non online recruitment platforms, job-resume interaction data is sparse and\nnoisy, which affects the performance of job-resume match algorithms. To\nalleviate these problems, in this paper, we propose a novel multi-view\nco-teaching network from sparse interaction data for job-resume matching. Our\nnetwork consists of two major components, namely text-based matching model and\nrelation-based matching model. The two parts capture semantic compatibility in\ntwo different views, and complement each other. In order to address the\nchallenges from sparse and noisy data, we design two specific strategies to\ncombine the two components. First, two components share the learned parameters\nor representations, so that the original representations of each component can\nbe enhanced. More importantly, we adopt a co-teaching mechanism to reduce the\ninfluence of noise in training data. The core idea is to let the two components\nhelp each other by selecting more reliable training instances. The two\nstrategies focus on representation enhancement and data enhancement,\nrespectively. Compared with pure text-based matching models, the proposed\napproach is able to learn better data representations from limited or even\nsparse interaction data, which is more resistible to noise in training data.\nExperiment results have demonstrated that our model is able to outperform\nstate-of-the-art methods for job-resume matching.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 03:09:54 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Bian", "Shuqing", ""], ["Chen", "Xu", ""], ["Zhao", "Wayne Xin", ""], ["Zhou", "Kun", ""], ["Hou", "Yupeng", ""], ["Song", "Yang", ""], ["Zhang", "Tao", ""], ["Wen", "Ji-Rong", ""]]}, {"id": "2009.13312", "submitter": "Zheng Zhao", "authors": "Zheng Zhao, Shay B. Cohen, Bonnie Webber", "title": "Reducing Quantity Hallucinations in Abstractive Summarization", "comments": "Accepted to Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that abstractive summaries are subject to\nhallucination---including material that is not supported by the original text.\nWhile summaries can be made hallucination-free by limiting them to general\nphrases, such summaries would fail to be very informative. Alternatively, one\ncan try to avoid hallucinations by verifying that any specific entities in the\nsummary appear in the original text in a similar context. This is the approach\ntaken by our system, Herman. The system learns to recognize and verify quantity\nentities (dates, numbers, sums of money, etc.) in a beam-worth of abstractive\nsummaries produced by state-of-the-art models, in order to up-rank those\nsummaries whose quantity terms are supported by the original text. Experimental\nresults demonstrate that the ROUGE scores of such up-ranked summaries have a\nhigher Precision than summaries that have not been up-ranked, without a\ncomparable loss in Recall, resulting in higher F$_1$. Preliminary human\nevaluation of up-ranked vs. original summaries shows people's preference for\nthe former.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 13:32:59 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Zhao", "Zheng", ""], ["Cohen", "Shay B.", ""], ["Webber", "Bonnie", ""]]}, {"id": "2009.13367", "submitter": "Inna Vogel", "authors": "Inna Vogel, Jeong-Eun Choi, Meghana Meghana", "title": "Similarity Detection Pipeline for Crawling a Topic Related Fake News\n  Corpus", "comments": "Further development done", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fake news detection is a challenging task aiming to reduce human time and\neffort to check the truthfulness of news. Automated approaches to combat fake\nnews, however, are limited by the lack of labeled benchmark datasets,\nespecially in languages other than English. Moreover, many publicly available\ncorpora have specific limitations that make them difficult to use. To address\nthis problem, our contribution is threefold. First, we propose a new, publicly\navailable German topic related corpus for fake news detection. To the best of\nour knowledge, this is the first corpus of its kind. In this regard, we\ndeveloped a pipeline for crawling similar news articles. As our third\ncontribution, we conduct different learning experiments to detect fake news.\nThe best performance was achieved using sentence level embeddings from SBERT in\ncombination with a Bi-LSTM (k=0.88).\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 14:35:31 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 12:32:57 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Vogel", "Inna", ""], ["Choi", "Jeong-Eun", ""], ["Meghana", "Meghana", ""]]}, {"id": "2009.13375", "submitter": "Antonios Maronikolakis", "authors": "Antonis Maronikolakis, Hinrich Schutze, Mark Stevenson", "title": "Identifying Automatically Generated Headlines using Transformers", "comments": "NLP4IF 2021 Proceedings, NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  False information spread via the internet and social media influences public\nopinion and user activity, while generative models enable fake content to be\ngenerated faster and more cheaply than had previously been possible. In the not\nso distant future, identifying fake content generated by deep learning models\nwill play a key role in protecting users from misinformation. To this end, a\ndataset containing human and computer-generated headlines was created and a\nuser study indicated that humans were only able to identify the fake headlines\nin 47.8% of the cases. However, the most accurate automatic approach,\ntransformers, achieved an overall accuracy of 85.7%, indicating that content\ngenerated from language models can be filtered out accurately.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 14:48:27 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 11:52:01 GMT"}, {"version": "v3", "created": "Sun, 25 Apr 2021 09:39:20 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Maronikolakis", "Antonis", ""], ["Schutze", "Hinrich", ""], ["Stevenson", "Mark", ""]]}, {"id": "2009.13398", "submitter": "Mihael Arcan", "authors": "Daniel Torregrosa and Nivranshu Pasricha and Maraim Masoud and\n  Bharathi Raja Chakravarthi and Juan Alonso and Noe Casas and Mihael Arcan", "title": "Aspects of Terminological and Named Entity Knowledge within Rule-Based\n  Machine Translation Models for Under-Resourced Neural Machine Translation\n  Scenarios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rule-based machine translation is a machine translation paradigm where\nlinguistic knowledge is encoded by an expert in the form of rules that\ntranslate text from source to target language. While this approach grants\nextensive control over the output of the system, the cost of formalising the\nneeded linguistic knowledge is much higher than training a corpus-based system,\nwhere a machine learning approach is used to automatically learn to translate\nfrom examples. In this paper, we describe different approaches to leverage the\ninformation contained in rule-based machine translation systems to improve a\ncorpus-based one, namely, a neural machine translation model, with a focus on a\nlow-resource scenario. Three different kinds of information were used:\nmorphological information, named entities and terminology. In addition to\nevaluating the general performance of the system, we systematically analysed\nthe performance of the proposed approaches when dealing with the targeted\nphenomena. Our results suggest that the proposed models have limited ability to\nlearn from external information, and most approaches do not significantly alter\nthe results of the automatic evaluation, but our preliminary qualitative\nevaluation shows that in certain cases the hypothesis generated by our system\nexhibit favourable behaviour such as keeping the use of passive voice.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 15:19:23 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Torregrosa", "Daniel", ""], ["Pasricha", "Nivranshu", ""], ["Masoud", "Maraim", ""], ["Chakravarthi", "Bharathi Raja", ""], ["Alonso", "Juan", ""], ["Casas", "Noe", ""], ["Arcan", "Mihael", ""]]}, {"id": "2009.13401", "submitter": "Wenhao Yu", "authors": "Xiangyu Dong, Wenhao Yu, Chenguang Zhu, Meng Jiang", "title": "Injecting Entity Types into Entity-Guided Text Generation", "comments": "Preprint; Code is available at: https://github.com/wyu97/InjType", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent successes in deep generative modeling have led to significant advances\nin natural language generation (NLG). Incorporating entities into neural\ngeneration models has demonstrated great improvements by assisting to infer the\nsummary topic and to generate coherent content. In order to enhance the role of\nentity in NLG, in this paper, we aim to model the entity type in the decoding\nphase to generate contextual words accurately. We develop a novel NLG model to\nproduce a target sequence (i.e., a news article) based on a given list of\nentities. The generation quality depends significantly on whether the input\nentities are logically connected and expressed in the output. Our model has a\nmulti-step decoder that injects the entity types into the process of entity\nmention generation. It first predicts the token of being a contextual word or\nan entity, then if an entity, predicts the entity mention. It effectively\nembeds the entity's meaning into hidden states, making the generated words\nprecise. Experiments on two public datasets demonstrate type injection performs\nbetter than type embedding concatenation baselines.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 15:19:28 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 15:50:26 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Dong", "Xiangyu", ""], ["Yu", "Wenhao", ""], ["Zhu", "Chenguang", ""], ["Jiang", "Meng", ""]]}, {"id": "2009.13431", "submitter": "Peilin Zhou", "authors": "Peilin Zhou, Zhiqi Huang, Fenglin Liu, Yuexian Zou", "title": "PIN: A Novel Parallel Interactive Network for Spoken Language\n  Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken Language Understanding (SLU) is an essential part of the spoken\ndialogue system, which typically consists of intent detection (ID) and slot\nfilling (SF) tasks. Recently, recurrent neural networks (RNNs) based methods\nachieved the state-of-the-art for SLU. It is noted that, in the existing\nRNN-based approaches, ID and SF tasks are often jointly modeled to utilize the\ncorrelation information between them. However, we noted that, so far, the\nefforts to obtain better performance by supporting bidirectional and explicit\ninformation exchange between ID and SF are not well studied.In addition, few\nstudies attempt to capture the local context information to enhance the\nperformance of SF. Motivated by these findings, in this paper, Parallel\nInteractive Network (PIN) is proposed to model the mutual guidance between ID\nand SF. Specifically, given an utterance, a Gaussian self-attentive encoder is\nintroduced to generate the context-aware feature embedding of the utterance\nwhich is able to capture local context information. Taking the feature\nembedding of the utterance, Slot2Intent module and Intent2Slot module are\ndeveloped to capture the bidirectional information flow for ID and SF tasks.\nFinally, a cooperation mechanism is constructed to fuse the information\nobtained from Slot2Intent and Intent2Slot modules to further reduce the\nprediction bias.The experiments on two benchmark datasets, i.e., SNIPS and\nATIS, demonstrate the effectiveness of our approach, which achieves a\ncompetitive result with state-of-the-art models. More encouragingly, by using\nthe feature embedding of the utterance generated by the pre-trained language\nmodel BERT, our method achieves the state-of-the-art among all comparison\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 15:59:31 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Zhou", "Peilin", ""], ["Huang", "Zhiqi", ""], ["Liu", "Fenglin", ""], ["Zou", "Yuexian", ""]]}, {"id": "2009.13570", "submitter": "Mihail Eric", "authors": "Shikib Mehri, Mihail Eric, Dilek Hakkani-Tur", "title": "DialoGLUE: A Natural Language Understanding Benchmark for Task-Oriented\n  Dialogue", "comments": "Benchmark hosted on:\n  https://evalai.cloudcv.org/web/challenges/challenge-page/708/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A long-standing goal of task-oriented dialogue research is the ability to\nflexibly adapt dialogue models to new domains. To progress research in this\ndirection, we introduce DialoGLUE (Dialogue Language Understanding Evaluation),\na public benchmark consisting of 7 task-oriented dialogue datasets covering 4\ndistinct natural language understanding tasks, designed to encourage dialogue\nresearch in representation-based transfer, domain adaptation, and\nsample-efficient task learning. We release several strong baseline models,\ndemonstrating performance improvements over a vanilla BERT architecture and\nstate-of-the-art results on 5 out of 7 tasks, by pre-training on a large\nopen-domain dialogue corpus and task-adaptive self-supervised training. Through\nthe DialoGLUE benchmark, the baseline methods, and our evaluation scripts, we\nhope to facilitate progress towards the goal of developing more general\ntask-oriented dialogue models.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 18:36:23 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 00:00:19 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Mehri", "Shikib", ""], ["Eric", "Mihail", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "2009.13602", "submitter": "Mahboobeh Parsapoor", "authors": "Jonathan Smith, Borna Ghotbi, Seungeun Yi, Mahboobeh Parsapoor", "title": "Non-Pharmaceutical Intervention Discovery with Topic Modeling", "comments": "ML for Global Health (ICML 2020 Workshop)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of discovering categories of non-pharmaceutical\ninterventions during the evolving COVID-19 pandemic. We explore topic modeling\non two corpora with national and international scope. These models discover\nexisting categories when compared with human intervention labels while reduced\nhuman effort needed.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 11:37:00 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Smith", "Jonathan", ""], ["Ghotbi", "Borna", ""], ["Yi", "Seungeun", ""], ["Parsapoor", "Mahboobeh", ""]]}, {"id": "2009.13603", "submitter": "Fangyu Liu", "authors": "Fangyu Liu, Muhao Chen, Dan Roth, Nigel Collier", "title": "Visual Pivoting for (Unsupervised) Entity Alignment", "comments": "To appear at AAAI-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the use of visual semantic representations to align\nentities in heterogeneous knowledge graphs (KGs). Images are natural components\nof many existing KGs. By combining visual knowledge with other auxiliary\ninformation, we show that the proposed new approach, EVA, creates a holistic\nentity representation that provides strong signals for cross-graph entity\nalignment. Besides, previous entity alignment methods require human labelled\nseed alignment, restricting availability. EVA provides a completely\nunsupervised solution by leveraging the visual similarity of entities to create\nan initial seed dictionary (visual pivots). Experiments on benchmark data sets\nDBP15k and DWY15k show that EVA offers state-of-the-art performance on both\nmonolingual and cross-lingual entity alignment tasks. Furthermore, we discover\nthat images are particularly useful to align long-tail KG entities, which\ninherently lack the structural contexts necessary for capturing the\ncorrespondences.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 20:09:40 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 02:18:41 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Liu", "Fangyu", ""], ["Chen", "Muhao", ""], ["Roth", "Dan", ""], ["Collier", "Nigel", ""]]}, {"id": "2009.13613", "submitter": "Danish Contractor", "authors": "Danish Contractor, Shashank Goel, Mausam, Parag Singla", "title": "Joint Spatio-Textual Reasoning for Answering Tourism Questions", "comments": "Updated version", "journal-ref": null, "doi": "10.1145/3442381.3449857", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is to answer real-world tourism questions that seek\nPoints-of-Interest (POI) recommendations. Such questions express various kinds\nof spatial and non-spatial constraints, necessitating a combination of textual\nand spatial reasoning. In response, we develop the first joint spatio-textual\nreasoning model, which combines geo-spatial knowledge with information in\ntextual corpora to answer questions. We first develop a modular\nspatial-reasoning network that uses geo-coordinates of location names mentioned\nin a question, and of candidate answer POIs, to reason over only spatial\nconstraints. We then combine our spatial-reasoner with a textual reasoner in a\njoint model and present experiments on a real world POI recommendation task. We\nreport substantial improvements over existing models with-out joint\nspatio-textual reasoning.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 20:35:00 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 07:18:42 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Contractor", "Danish", ""], ["Goel", "Shashank", ""], ["Mausam", "", ""], ["Singla", "Parag", ""]]}, {"id": "2009.13655", "submitter": "Armen Aghajanyan", "authors": "Armen Aghajanyan, Jean Maillard, Akshat Shrivastava, Keith Diedrick,\n  Mike Haeger, Haoran Li, Yashar Mehdad, Ves Stoyanov, Anuj Kumar, Mike Lewis,\n  Sonal Gupta", "title": "Conversational Semantic Parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The structured representation for semantic parsing in task-oriented assistant\nsystems is geared towards simple understanding of one-turn queries. Due to the\nlimitations of the representation, the session-based properties such as\nco-reference resolution and context carryover are processed downstream in a\npipelined system. In this paper, we propose a semantic representation for such\ntask-oriented conversational systems that can represent concepts such as\nco-reference and context carryover, enabling comprehensive understanding of\nqueries in a session. We release a new session-based, compositional\ntask-oriented parsing dataset of 20k sessions consisting of 60k utterances.\nUnlike Dialog State Tracking Challenges, the queries in the dataset have\ncompositional forms. We propose a new family of Seq2Seq models for the\nsession-based parsing above, which achieve better or comparable performance to\nthe current state-of-the-art on ATIS, SNIPS, TOP and DSTC2. Notably, we improve\nthe best known results on DSTC2 by up to 5 points for slot-carryover.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 22:08:00 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Aghajanyan", "Armen", ""], ["Maillard", "Jean", ""], ["Shrivastava", "Akshat", ""], ["Diedrick", "Keith", ""], ["Haeger", "Mike", ""], ["Li", "Haoran", ""], ["Mehdad", "Yashar", ""], ["Stoyanov", "Ves", ""], ["Kumar", "Anuj", ""], ["Lewis", "Mike", ""], ["Gupta", "Sonal", ""]]}, {"id": "2009.13656", "submitter": "Andrea Madotto Mr", "authors": "Andrea Madotto, Samuel Cahyawijaya, Genta Indra Winata, Yan Xu, Zihan\n  Liu, Zhaojiang Lin, Pascale Fung", "title": "Learning Knowledge Bases with Parameters for Task-Oriented Dialogue\n  Systems", "comments": "Accepted EMNLP findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-oriented dialogue systems are either modularized with separate dialogue\nstate tracking (DST) and management steps or end-to-end trainable. In either\ncase, the knowledge base (KB) plays an essential role in fulfilling user\nrequests. Modularized systems rely on DST to interact with the KB, which is\nexpensive in terms of annotation and inference time. End-to-end systems use the\nKB directly as input, but they cannot scale when the KB is larger than a few\nhundred entries. In this paper, we propose a method to embed the KB, of any\nsize, directly into the model parameters. The resulting model does not require\nany DST or template responses, nor the KB as input, and it can dynamically\nupdate its KB via fine-tuning. We evaluate our solution in five task-oriented\ndialogue datasets with small, medium, and large KB size. Our experiments show\nthat end-to-end models can effectively embed knowledge bases in their\nparameters and achieve competitive performance in all evaluated datasets.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 22:13:54 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Madotto", "Andrea", ""], ["Cahyawijaya", "Samuel", ""], ["Winata", "Genta Indra", ""], ["Xu", "Yan", ""], ["Liu", "Zihan", ""], ["Lin", "Zhaojiang", ""], ["Fung", "Pascale", ""]]}, {"id": "2009.13658", "submitter": "Zhiheng Huang", "authors": "Zhiheng Huang, Davis Liang, Peng Xu, Bing Xiang", "title": "Improve Transformer Models with Better Relative Position Embeddings", "comments": "Accepted as Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer architectures rely on explicit position encodings in order to\npreserve a notion of word order. In this paper, we argue that existing work\ndoes not fully utilize position information. For example, the initial proposal\nof a sinusoid embedding is fixed and not learnable. In this paper, we first\nreview absolute position embeddings and existing methods for relative position\nembeddings. We then propose new techniques that encourage increased interaction\nbetween query, key and relative position embeddings in the self-attention\nmechanism. Our most promising approach is a generalization of the absolute\nposition embedding, improving results on SQuAD1.1 compared to previous position\nembeddings approaches. In addition, we address the inductive property of\nwhether a position embedding can be robust enough to handle long sequences. We\ndemonstrate empirically that our relative position embedding method is\nreasonably generalized and robust from the inductive perspective. Finally, we\nshow that our proposed method can be adopted as a near drop-in replacement for\nimproving the accuracy of large models with a small computational budget.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 22:18:58 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Huang", "Zhiheng", ""], ["Liang", "Davis", ""], ["Xu", "Peng", ""], ["Xiang", "Bing", ""]]}, {"id": "2009.13682", "submitter": "Xiaowei Hu", "authors": "Xiaowei Hu, Xi Yin, Kevin Lin, Lijuan Wang, Lei Zhang, Jianfeng Gao,\n  Zicheng Liu", "title": "VIVO: Visual Vocabulary Pre-Training for Novel Object Captioning", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is highly desirable yet challenging to generate image captions that can\ndescribe novel objects which are unseen in caption-labeled training data, a\ncapability that is evaluated in the novel object captioning challenge (nocaps).\nIn this challenge, no additional image-caption training data, other thanCOCO\nCaptions, is allowed for model training. Thus, conventional Vision-Language\nPre-training (VLP) methods cannot be applied. This paper presents VIsual\nVOcabulary pretraining (VIVO) that performs pre-training in the absence of\ncaption annotations. By breaking the dependency of paired image-caption\ntraining data in VLP, VIVO can leverage large amounts of paired image-tag data\nto learn a visual vocabulary. This is done by pre-training a multi-layer\nTransformer model that learns to align image-level tags with their\ncorresponding image region features. To address the unordered nature of image\ntags, VIVO uses a Hungarian matching loss with masked tag prediction to conduct\npre-training. We validate the effectiveness of VIVO by fine-tuning the\npre-trained model for image captioning. In addition, we perform an analysis of\nthe visual-text alignment inferred by our model. The results show that our\nmodel can not only generate fluent image captions that describe novel objects,\nbut also identify the locations of these objects. Our single model has achieved\nnew state-of-the-art results on nocaps and surpassed the human CIDEr score.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 23:20:02 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 20:01:10 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Hu", "Xiaowei", ""], ["Yin", "Xi", ""], ["Lin", "Kevin", ""], ["Wang", "Lijuan", ""], ["Zhang", "Lei", ""], ["Gao", "Jianfeng", ""], ["Liu", "Zicheng", ""]]}, {"id": "2009.13699", "submitter": "Brian Lester", "authors": "Brian Lester", "title": "Leader: Prefixing a Length for Faster Word Vector Serialization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two competing file formats have become the de facto standards for\ndistributing pre-trained word embeddings. Both are named after the most popular\npre-trained embeddings that are distributed in that format. The GloVe format is\nan entirely text based format that suffers from huge file sizes and slow reads,\nand the word2vec format is a smaller binary format that mixes a textual\nrepresentation of words with a binary representation of the vectors themselves.\nBoth formats have problems that we solve with a new format we call the Leader\nformat. We include a word length prefix for faster reads while maintaining the\nsmaller file size a binary format offers. We also created a minimalist library\nto facilitate the reading and writing of various word vector formats, as well\nas tools for converting pre-trained embeddings to our new Leader format.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 00:25:24 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 04:49:24 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Lester", "Brian", ""]]}, {"id": "2009.13720", "submitter": "Sharan Raja", "authors": "Sharan Raja, Rudraksh Tuwani", "title": "Adversarial Attacks Against Deep Learning Systems for ICD-9 Code\n  Assignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manual annotation of ICD-9 codes is a time consuming and error-prone process.\nDeep learning based systems tackling the problem of automated ICD-9 coding have\nachieved competitive performance. Given the increased proliferation of\nelectronic medical records, such automated systems are expected to eventually\nreplace human coders. In this work, we investigate how a simple typo-based\nadversarial attack strategy can impact the performance of state-of-the-art\nmodels for the task of predicting the top 50 most frequent ICD-9 codes from\ndischarge summaries. Preliminary results indicate that a malicious adversary,\nusing gradient information, can craft specific perturbations, that appear as\nregular human typos, for less than 3% of words in the discharge summary to\nsignificantly affect the performance of the baseline model.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 01:45:11 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Raja", "Sharan", ""], ["Tuwani", "Rudraksh", ""]]}, {"id": "2009.13752", "submitter": "Shuang Zeng", "authors": "Shuang Zeng, Runxin Xu, Baobao Chang and Lei Li", "title": "Double Graph Based Reasoning for Document-level Relation Extraction", "comments": "Accepted as long paper to appear at the EMNLP 2020 main conference,\n  11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Document-level relation extraction aims to extract relations among entities\nwithin a document. Different from sentence-level relation extraction, it\nrequires reasoning over multiple sentences across a document. In this paper, we\npropose Graph Aggregation-and-Inference Network (GAIN) featuring double graphs.\nGAIN first constructs a heterogeneous mention-level graph (hMG) to model\ncomplex interaction among different mentions across the document. It also\nconstructs an entity-level graph (EG), based on which we propose a novel path\nreasoning mechanism to infer relations between entities. Experiments on the\npublic dataset, DocRED, show GAIN achieves a significant performance\nimprovement (2.85 on F1) over the previous state-of-the-art. Our code is\navailable at https://github.com/DreamInvoker/GAIN .\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 03:41:01 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Zeng", "Shuang", ""], ["Xu", "Runxin", ""], ["Chang", "Baobao", ""], ["Li", "Lei", ""]]}, {"id": "2009.13815", "submitter": "Yinfei Yang", "authors": "Yinfei Yang, Ning Jin, Kuo Lin, Mandy Guo, Daniel Cer", "title": "Neural Retrieval for Question Answering with Cross-Attention Supervised\n  Data Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural models that independently project questions and answers into a shared\nembedding space allow for efficient continuous space retrieval from large\ncorpora. Independently computing embeddings for questions and answers results\nin late fusion of information related to matching questions to their answers.\nWhile critical for efficient retrieval, late fusion underperforms models that\nmake use of early fusion (e.g., a BERT based classifier with cross-attention\nbetween question-answer pairs). We present a supervised data mining method\nusing an accurate early fusion model to improve the training of an efficient\nlate fusion retrieval model. We first train an accurate classification model\nwith cross-attention between questions and answers. The accurate\ncross-attention model is then used to annotate additional passages in order to\ngenerate weighted training examples for a neural retrieval model. The resulting\nretrieval model with additional data significantly outperforms retrieval models\ndirectly trained with gold annotations on Precision at $N$ (P@N) and Mean\nReciprocal Rank (MRR).\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 07:02:19 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Yang", "Yinfei", ""], ["Jin", "Ning", ""], ["Lin", "Kuo", ""], ["Guo", "Mandy", ""], ["Cer", "Daniel", ""]]}, {"id": "2009.13818", "submitter": "Dinghan Shen", "authors": "Dinghan Shen, Mingzhi Zheng, Yelong Shen, Yanru Qu, Weizhu Chen", "title": "A Simple but Tough-to-Beat Data Augmentation Approach for Natural\n  Language Understanding and Generation", "comments": "Source code is available at: https://github.com/dinghanshen/cutoff", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training has been shown effective at endowing the learned\nrepresentations with stronger generalization ability. However, it typically\nrequires expensive computation to determine the direction of the injected\nperturbations. In this paper, we introduce a set of simple yet effective data\naugmentation strategies dubbed cutoff, where part of the information within an\ninput sentence is erased to yield its restricted views (during the fine-tuning\nstage). Notably, this process relies merely on stochastic sampling and thus\nadds little computational overhead. A Jensen-Shannon Divergence consistency\nloss is further utilized to incorporate these augmented samples into the\ntraining objective in a principled manner. To verify the effectiveness of the\nproposed strategies, we apply cutoff to both natural language understanding and\ngeneration problems. On the GLUE benchmark, it is demonstrated that cutoff, in\nspite of its simplicity, performs on par or better than several competitive\nadversarial-based approaches. We further extend cutoff to machine translation\nand observe significant gains in BLEU scores (based upon the Transformer Base\nmodel). Moreover, cutoff consistently outperforms adversarial training and\nachieves state-of-the-art results on the IWSLT2014 German-English dataset.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 07:08:35 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 03:19:58 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Shen", "Dinghan", ""], ["Zheng", "Mingzhi", ""], ["Shen", "Yelong", ""], ["Qu", "Yanru", ""], ["Chen", "Weizhu", ""]]}, {"id": "2009.13826", "submitter": "Yanlin Li", "authors": "Yanlin Li, Shi An, Ruisheng Zhang", "title": "EEMC: Embedding Enhanced Multi-tag Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently occurred representation learning make an attractive performance\nin NLP and complex network, it is becoming a fundamental technology in machine\nlearning and data mining. How to use representation learning to improve the\nperformance of classifiers is a very significance research direction. We using\nrepresentation learning technology to map raw data(node of graph) to a\nlow-dimensional feature space. In this space, each raw data obtained a lower\ndimensional vector representation, we do some simple linear operations for\nthose vectors to produce some virtual data, using those vectors and virtual\ndata to training multi-tag classifier. After that we measured the performance\nof classifier by F1 score(Macro% F1 and Micro% F1). Our method make Macro F1\nrise from 28 % - 450% and make average F1 score rise from 12 % - 224%. By\ncontrast, we trained the classifier directly with the lower dimensional vector,\nand measured the performance of classifiers. We validate our algorithm on three\npublic data sets, we found that the virtual data helped the classifier greatly\nimprove the F1 score. Therefore, our algorithm is a effective way to improve\nthe performance of classifier. These result suggest that the virtual data\ngenerated by simple linear operation, in representation space, still retains\nthe information of the raw data. It's also have great significance to the\nlearning of small sample data sets.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 07:29:34 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Li", "Yanlin", ""], ["An", "Shi", ""], ["Zhang", "Ruisheng", ""]]}, {"id": "2009.13827", "submitter": "Jiaming Shen", "authors": "Jiaming Shen and Wenda Qiu and Jingbo Shang and Michelle Vanni and\n  Xiang Ren and Jiawei Han", "title": "SynSetExpan: An Iterative Framework for Joint Entity Set Expansion and\n  Synonym Discovery", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity set expansion and synonym discovery are two critical NLP tasks.\nPrevious studies accomplish them separately, without exploring their\ninterdependencies. In this work, we hypothesize that these two tasks are\ntightly coupled because two synonymous entities tend to have similar\nlikelihoods of belonging to various semantic classes. This motivates us to\ndesign SynSetExpan, a novel framework that enables two tasks to mutually\nenhance each other. SynSetExpan uses a synonym discovery model to include\npopular entities' infrequent synonyms into the set, which boosts the set\nexpansion recall. Meanwhile, the set expansion model, being able to determine\nwhether an entity belongs to a semantic class, can generate pseudo training\ndata to fine-tune the synonym discovery model towards better accuracy. To\nfacilitate the research on studying the interplays of these two tasks, we\ncreate the first large-scale Synonym-Enhanced Set Expansion (SE2) dataset via\ncrowdsourcing. Extensive experiments on the SE2 dataset and previous benchmarks\ndemonstrate the effectiveness of SynSetExpan for both entity set expansion and\nsynonym discovery tasks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 07:32:17 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Shen", "Jiaming", ""], ["Qiu", "Wenda", ""], ["Shang", "Jingbo", ""], ["Vanni", "Michelle", ""], ["Ren", "Xiang", ""], ["Han", "Jiawei", ""]]}, {"id": "2009.13833", "submitter": "Gaurav Arora", "authors": "Gaurav Arora, Chirag Jain, Manas Chaturvedi, Krupal Modi", "title": "HINT3: Raising the bar for Intent Detection in the Wild", "comments": "Accepted at EMNLP-2020's Insights workshop", "journal-ref": "Proceedings of the First Workshop on Insights from Negative\n  Results in NLP @ EMNLP 2020", "doi": "10.18653/v1/2020.insights-1.16", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intent Detection systems in the real world are exposed to complexities of\nimbalanced datasets containing varying perception of intent, unintended\ncorrelations and domain-specific aberrations. To facilitate benchmarking which\ncan reflect near real-world scenarios, we introduce 3 new datasets created from\nlive chatbots in diverse domains. Unlike most existing datasets that are\ncrowdsourced, our datasets contain real user queries received by the chatbots\nand facilitates penalising unwanted correlations grasped during the training\nprocess. We evaluate 4 NLU platforms and a BERT based classifier and find that\nperformance saturates at inadequate levels on test sets because all systems\nlatch on to unintended patterns in training data.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 07:44:37 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 07:52:18 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Arora", "Gaurav", ""], ["Jain", "Chirag", ""], ["Chaturvedi", "Manas", ""], ["Modi", "Krupal", ""]]}, {"id": "2009.13845", "submitter": "Xi Victoria Lin", "authors": "Tao Yu and Chien-Sheng Wu and Xi Victoria Lin and Bailin Wang and Yi\n  Chern Tan and Xinyi Yang and Dragomir Radev and Richard Socher and Caiming\n  Xiong", "title": "GraPPa: Grammar-Augmented Pre-Training for Table Semantic Parsing", "comments": "16 pages; Accepted to ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present GraPPa, an effective pre-training approach for table semantic\nparsing that learns a compositional inductive bias in the joint representations\nof textual and tabular data. We construct synthetic question-SQL pairs over\nhigh-quality tables via a synchronous context-free grammar (SCFG) induced from\nexisting text-to-SQL datasets. We pre-train our model on the synthetic data\nusing a novel text-schema linking objective that predicts the syntactic role of\na table field in the SQL for each question-SQL pair. To maintain the model's\nability to represent real-world data, we also include masked language modeling\n(MLM) over several existing table-and-language datasets to regularize the\npre-training process. On four popular fully supervised and weakly supervised\ntable semantic parsing benchmarks, GraPPa significantly outperforms\nRoBERTa-large as the feature representation layers and establishes new\nstate-of-the-art results on all of them.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 08:17:58 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 01:30:29 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Yu", "Tao", ""], ["Wu", "Chien-Sheng", ""], ["Lin", "Xi Victoria", ""], ["Wang", "Bailin", ""], ["Tan", "Yi Chern", ""], ["Yang", "Xinyi", ""], ["Radev", "Dragomir", ""], ["Socher", "Richard", ""], ["Xiong", "Caiming", ""]]}, {"id": "2009.13859", "submitter": "Inna Vogel", "authors": "Inna Vogel and Meghana Meghana", "title": "Fake News Spreader Detection on Twitter using Character N-Grams.\n  Notebook for PAN at CLEF 2020", "comments": "CLEF 2020 Labs and Workshops, Notebook Papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The authors of fake news often use facts from verified news sources and mix\nthem with misinformation to create confusion and provoke unrest among the\nreaders. The spread of fake news can thereby have serious implications on our\nsociety. They can sway political elections, push down the stock price or crush\nreputations of corporations or public figures. Several websites have taken on\nthe mission of checking rumors and allegations, but are often not fast enough\nto check the content of all the news being disseminated. Especially social\nmedia websites have offered an easy platform for the fast propagation of\ninformation. Towards limiting fake news from being propagated among social\nmedia users, the task of this year's PAN 2020 challenge lays the focus on the\nfake news spreaders. The aim of the task is to determine whether it is possible\nto discriminate authors that have shared fake news in the past from those that\nhave never done it. In this notebook, we describe our profiling system for the\nfake news detection task on Twitter. For this, we conduct different feature\nextraction techniques and learning experiments from a multilingual perspective,\nnamely English and Spanish. Our final submitted systems use character n-grams\nas features in combination with a linear SVM for English and Logistic\nRegression for the Spanish language. Our submitted models achieve an overall\naccuracy of 73% and 79% on the English and Spanish official test set,\nrespectively. Our experiments show that it is difficult to differentiate\nsolidly fake news spreaders on Twitter from users who share credible\ninformation leaving room for further investigations. Our model ranked 3rd out\nof 72 competitors.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 08:32:32 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Vogel", "Inna", ""], ["Meghana", "Meghana", ""]]}, {"id": "2009.13888", "submitter": "Kawin Ethayarajh", "authors": "Kawin Ethayarajh, Dan Jurafsky", "title": "Utility is in the Eye of the User: A Critique of NLP Leaderboards", "comments": "EMNLP 2020 (updated with additional references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Benchmarks such as GLUE have helped drive advances in NLP by incentivizing\nthe creation of more accurate models. While this leaderboard paradigm has been\nremarkably successful, a historical focus on performance-based evaluation has\nbeen at the expense of other qualities that the NLP community values in models,\nsuch as compactness, fairness, and energy efficiency. In this opinion paper, we\nstudy the divergence between what is incentivized by leaderboards and what is\nuseful in practice through the lens of microeconomic theory. We frame both the\nleaderboard and NLP practitioners as consumers and the benefit they get from a\nmodel as its utility to them. With this framing, we formalize how leaderboards\n-- in their current form -- can be poor proxies for the NLP community at large.\nFor example, a highly inefficient model would provide less utility to\npractitioners but not to a leaderboard, since it is a cost that only the former\nmust bear. To allow practitioners to better estimate a model's utility to them,\nwe advocate for more transparency on leaderboards, such as the reporting of\nstatistics that are of practical concern (e.g., model size, energy efficiency,\nand inference latency).\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 09:25:31 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 23:04:29 GMT"}, {"version": "v3", "created": "Thu, 15 Oct 2020 00:40:13 GMT"}, {"version": "v4", "created": "Wed, 3 Mar 2021 06:22:32 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Ethayarajh", "Kawin", ""], ["Jurafsky", "Dan", ""]]}, {"id": "2009.13889", "submitter": "Ferdiant Joshua Muis", "authors": "Ferdiant Joshua Muis (1) and Ayu Purwarianti (1 and 2) ((1) Institut\n  Teknologi Bandung, (2) U-CoE AI-VLB)", "title": "Sequence-to-Sequence Learning for Indonesian Automatic Question\n  Generator", "comments": "6 pages, 4 figures", "journal-ref": "2020 International Conference on Advanced Informatics: Concept,\n  Theory and Application (ICAICTA)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic question generation is defined as the task of automating the\ncreation of question given a various of textual data. Research in automatic\nquestion generator (AQG) has been conducted for more than 10 years, mainly\nfocused on factoid question. In all these studies, the state-of-the-art is\nattained using sequence-to-sequence approach. However, AQG system for\nIndonesian has not ever been researched intensely. In this work we construct an\nIndonesian automatic question generator, adapting the architecture from some\nprevious works. In summary, we used sequence-to-sequence approach using BiGRU,\nBiLSTM, and Transformer with additional linguistic features, copy mechanism,\nand coverage mechanism. Since there is no public large dan popular Indonesian\ndataset for question generation, we translated SQuAD v2.0 factoid question\nanswering dataset, with additional Indonesian TyDiQA dev set for testing. The\nsystem achieved BLEU1, BLEU2, BLEU3, BLEU4, and ROUGE-L score at 38,35, 20,96,\n10,68, 5,78, and 43,4 for SQuAD, and 39.9, 20.78, 10.26, 6.31, 44.13 for\nTyDiQA, respectively. The system performed well when the expected answers are\nnamed entities and are syntactically close with the context explaining them.\nAdditionally, from native Indonesian perspective, the best questions generated\nby our best models on their best cases are acceptable and reasonably useful.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 09:25:54 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Muis", "Ferdiant Joshua", "", "1 and 2"], ["Purwarianti", "Ayu", "", "1 and 2"]]}, {"id": "2009.13902", "submitter": "Soujanya Poria", "authors": "Deepanway Ghosal, Navonil Majumder, Rada Mihalcea, Soujanya Poria", "title": "Utterance-level Dialogue Understanding: An Empirical Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The recent abundance of conversational data on the Web and elsewhere calls\nfor effective NLP systems for dialog understanding. Complete utterance-level\nunderstanding often requires context understanding, defined by nearby\nutterances. In recent years, a number of approaches have been proposed for\nvarious utterance-level dialogue understanding tasks. Most of these approaches\naccount for the context for effective understanding. In this paper, we explore\nand quantify the role of context for different aspects of a dialogue, namely\nemotion, intent, and dialogue act identification, using state-of-the-art dialog\nunderstanding methods as baselines. Specifically, we employ various\nperturbations to distort the context of a given utterance and study its impact\non the different tasks and baselines. This provides us with insights into the\nfundamental contextual controlling factors of different aspects of a dialogue.\nSuch insights can inspire more effective dialogue understanding models, and\nprovide support for future text generation approaches. The implementation\npertaining to this work is available at\nhttps://github.com/declare-lab/dialogue-understanding.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 09:50:21 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 16:12:59 GMT"}, {"version": "v3", "created": "Sun, 11 Oct 2020 14:38:07 GMT"}, {"version": "v4", "created": "Mon, 19 Oct 2020 03:03:05 GMT"}, {"version": "v5", "created": "Thu, 22 Oct 2020 11:16:56 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Ghosal", "Deepanway", ""], ["Majumder", "Navonil", ""], ["Mihalcea", "Rada", ""], ["Poria", "Soujanya", ""]]}, {"id": "2009.13905", "submitter": "Jacopo Amidei", "authors": "Jacopo Amidei", "title": "Aligning Intraobserver Agreement by Transitivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Annotation reproducibility and accuracy rely on good consistency within\nannotators. We propose a novel method for measuring within annotator\nconsistency or annotator Intraobserver Agreement (IA). The proposed approach is\nbased on transitivity, a measure that has been thoroughly studied in the\ncontext of rational decision-making. The transitivity measure, in contrast with\nthe commonly used test-retest strategy for annotator IA, is less sensitive to\nthe several types of bias introduced by the test-retest strategy. We present a\nrepresentation theorem to the effect that relative judgement data that meet\ntransitivity can be mapped to a scale (in terms of measurement theory). We also\ndiscuss a further application of transitivity as part of data collection design\nfor addressing the problem of the quadratic complexity of data collection of\nrelative judgements.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 09:55:04 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Amidei", "Jacopo", ""]]}, {"id": "2009.13964", "submitter": "Yusheng Su", "authors": "Yusheng Su, Xu Han, Zhengyan Zhang, Peng Li, Zhiyuan Liu, Yankai Lin,\n  Jie Zhou and Maosong Sun", "title": "CokeBERT: Contextual Knowledge Selection and Embedding towards Enhanced\n  Pre-Trained Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recent efforts have been devoted to enhancing pre-trained language\nmodels (PLMs) by utilizing extra heterogeneous knowledge in knowledge graphs\n(KGs) and achieved consistent improvements on various knowledge-driven NLP\ntasks. However, most of these knowledge-enhanced PLMs embed static sub-graphs\nof KGs (\"knowledge context\"), regardless of that the knowledge required by PLMs\nmay change dynamically according to specific text (\"textual context\"). In this\npaper, we propose a novel framework named Coke to dynamically select contextual\nknowledge and embed knowledge context according to textual context for PLMs,\nwhich can avoid the effect of redundant and ambiguous knowledge in KGs that\ncannot match the input text. Our experimental results show that Coke\noutperforms various baselines on typical knowledge-driven NLP tasks, indicating\nthe effectiveness of utilizing dynamic knowledge context for language\nunderstanding. Besides the performance improvements, the dynamically selected\nknowledge in Coke can describe the semantics of text-related knowledge in a\nmore interpretable form than the conventional PLMs. Our source code and\ndatasets will be available to provide more details for Coke.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 12:29:04 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 09:31:29 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 09:04:48 GMT"}, {"version": "v4", "created": "Sat, 5 Dec 2020 15:25:11 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Su", "Yusheng", ""], ["Han", "Xu", ""], ["Zhang", "Zhengyan", ""], ["Li", "Peng", ""], ["Liu", "Zhiyuan", ""], ["Lin", "Yankai", ""], ["Zhou", "Jie", ""], ["Sun", "Maosong", ""]]}, {"id": "2009.13971", "submitter": "Xuemeng Hu", "authors": "Xuemeng Hu, Rui Wang, Deyu Zhou, Yuxuan Xiong", "title": "Neural Topic Modeling with Cycle-Consistent Adversarial Training", "comments": "Accepted by EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances on deep generative models have attracted significant research\ninterest in neural topic modeling. The recently proposed Adversarial-neural\nTopic Model models topics with an adversarially trained generator network and\nemploys Dirichlet prior to capture the semantic patterns in latent topics. It\nis effective in discovering coherent topics but unable to infer topic\ndistributions for given documents or utilize available document labels. To\novercome such limitations, we propose Topic Modeling with Cycle-consistent\nAdversarial Training (ToMCAT) and its supervised version sToMCAT. ToMCAT\nemploys a generator network to interpret topics and an encoder network to infer\ndocument topics. Adversarial training and cycle-consistent constraints are used\nto encourage the generator and the encoder to produce realistic samples that\ncoordinate with each other. sToMCAT extends ToMCAT by incorporating document\nlabels into the topic modeling process to help discover more coherent topics.\nThe effectiveness of the proposed models is evaluated on\nunsupervised/supervised topic modeling and text classification. The\nexperimental results show that our models can produce both coherent and\ninformative topics, outperforming a number of competitive baselines.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 12:41:27 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Hu", "Xuemeng", ""], ["Wang", "Rui", ""], ["Zhou", "Deyu", ""], ["Xiong", "Yuxuan", ""]]}, {"id": "2009.13972", "submitter": "Xuemeng Hu", "authors": "Deyu Zhou, Xuemeng Hu, Rui Wang", "title": "Neural Topic Modeling by Incorporating Document Relationship Graph", "comments": "Accepted by EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) that capture the relationships between graph\nnodes via message passing have been a hot research direction in the natural\nlanguage processing community. In this paper, we propose Graph Topic Model\n(GTM), a GNN based neural topic model that represents a corpus as a document\nrelationship graph. Documents and words in the corpus become nodes in the graph\nand are connected based on document-word co-occurrences. By introducing the\ngraph structure, the relationships between documents are established through\ntheir shared words and thus the topical representation of a document is\nenriched by aggregating information from its neighboring nodes using graph\nconvolution. Extensive experiments on three datasets were conducted and the\nresults demonstrate the effectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 12:45:55 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Zhou", "Deyu", ""], ["Hu", "Xuemeng", ""], ["Wang", "Rui", ""]]}, {"id": "2009.13984", "submitter": "Raymond Lee", "authors": "Nuobei Shi, Qin Zeng and Raymond Lee", "title": "The design and implementation of Language Learning Chatbot with XAI\n  using Ontology and Transfer Learning", "comments": "19 pages, 20 figures, published paper in International Conference on\n  NLP & Big Data (NLPD 2020)", "journal-ref": "Dhinaharan Nagamalai et al. (Eds): CSEIT, WiMoNe, NCS, CIoT, CMLA,\n  DMSE, NLPD - 2020 pp. 305-323, 2020. CS & IT - CSCP 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we proposed a transfer learning-based English language\nlearning chatbot, whose output generated by GPT-2 can be explained by\ncorresponding ontology graph rooted by fine-tuning dataset. We design three\nlevels for systematically English learning, including phonetics level for\nspeech recognition and pronunciation correction, semantic level for specific\ndomain conversation, and the simulation of free-style conversation in English -\nthe highest level of language chatbot communication as free-style conversation\nagent. For academic contribution, we implement the ontology graph to explain\nthe performance of free-style conversation, following the concept of XAI\n(Explainable Artificial Intelligence) to visualize the connections of neural\nnetwork in bionics, and explain the output sentence from language model. From\nimplementation perspective, our Language Learning agent integrated the\nmini-program in WeChat as front-end, and fine-tuned GPT-2 model of transfer\nlearning as back-end to interpret the responses by ontology graph.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 13:11:40 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Shi", "Nuobei", ""], ["Zeng", "Qin", ""], ["Lee", "Raymond", ""]]}, {"id": "2009.14083", "submitter": "Vu Tran", "authors": "Vu Tran and Minh Le Nguyen and Ken Satoh", "title": "Building Legal Case Retrieval Systems with Lexical Matching and\n  Summarization using A Pre-Trained Phrase Scoring Model", "comments": null, "journal-ref": null, "doi": "10.1145/3322640.3326740", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our method for tackling the legal case retrieval task of the\nCompetition on Legal Information Extraction/Entailment 2019. Our approach is\nbased on the idea that summarization is important for retrieval. On one hand,\nwe adopt a summarization based model called encoded summarization which encodes\na given document into continuous vector space which embeds the summary\nproperties of the document. We utilize the resource of COLIEE 2018 on which we\ntrain the document representation model. On the other hand, we extract lexical\nfeatures on different parts of a given query and its candidates. We observe\nthat by comparing different parts of the query and its candidates, we can\nachieve better performance. Furthermore, the combination of the lexical\nfeatures with latent features by the summarization-based method achieves even\nbetter performance. We have achieved the state-of-the-art result for the task\non the benchmark of the competition.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 15:10:59 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Tran", "Vu", ""], ["Nguyen", "Minh Le", ""], ["Satoh", "Ken", ""]]}, {"id": "2009.14109", "submitter": "Jonathan K Kummerfeld", "authors": "Charles Welch, Rada Mihalcea, Jonathan K. Kummerfeld", "title": "Improving Low Compute Language Modeling with In-Domain Embedding\n  Initialisation", "comments": "To appear at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many NLP applications, such as biomedical data and technical support, have\n10-100 million tokens of in-domain data and limited computational resources for\nlearning from it. How should we train a language model in this scenario? Most\nlanguage modeling research considers either a small dataset with a closed\nvocabulary (like the standard 1 million token Penn Treebank), or the whole web\nwith byte-pair encoding. We show that for our target setting in English,\ninitialising and freezing input embeddings using in-domain data can improve\nlanguage model performance by providing a useful representation of rare words,\nand this pattern holds across several different domains. In the process, we\nshow that the standard convention of tying input and output embeddings does not\nimprove perplexity when initializing with embeddings trained on in-domain data.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 15:48:58 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 15:40:39 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Welch", "Charles", ""], ["Mihalcea", "Rada", ""], ["Kummerfeld", "Jonathan K.", ""]]}, {"id": "2009.14116", "submitter": "Pawan Kumar", "authors": "Pawan Kumar and Srikanta Bedathur", "title": "A Survey on Semantic Parsing from the perspective of Compositionality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.GL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different from previous surveys in semantic parsing (Kamath and Das, 2018)\nand knowledge base question answering(KBQA)(Chakraborty et al., 2019; Zhu et\nal., 2019; Hoffner et al., 2017) we try to takes a different perspective on the\nstudy of semantic parsing. Specifically, we will focus on (a)meaning\ncomposition from syntactical structure(Partee, 1975), and (b) the ability of\nsemantic parsers to handle lexical variation given the context of a knowledge\nbase (KB). In the following section after an introduction of the field of\nsemantic parsing and its uses in KBQA, we will describe meaning representation\nusing grammar formalism CCG (Steedman, 1996). We will discuss semantic\ncomposition using formal languages in Section 2. In section 3 we will consider\nsystems that uses formal languages e.g. $\\lambda$-calculus (Steedman, 1996),\n$\\lambda$-DCS (Liang, 2013). Section 4 and 5 consider semantic parser using\nstructured-language for logical form. Section 6 is on different benchmark\ndatasets ComplexQuestions (Bao et al.,2016) and GraphQuestions (Su et al.,\n2016) that can be used to evaluate semantic parser on their ability to answer\ncomplex questions that are highly compositional in nature.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 16:03:13 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Kumar", "Pawan", ""], ["Bedathur", "Srikanta", ""]]}, {"id": "2009.14124", "submitter": "Ethan Chau", "authors": "Ethan C. Chau, Lucy H. Lin, Noah A. Smith", "title": "Parsing with Multilingual BERT, a Small Corpus, and a Small Treebank", "comments": "In Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretrained multilingual contextual representations have shown great success,\nbut due to the limits of their pretraining data, their benefits do not apply\nequally to all language varieties. This presents a challenge for language\nvarieties unfamiliar to these models, whose labeled \\emph{and unlabeled} data\nis too limited to train a monolingual model effectively. We propose the use of\nadditional language-specific pretraining and vocabulary augmentation to adapt\nmultilingual models to low-resource settings. Using dependency parsing of four\ndiverse low-resource language varieties as a case study, we show that these\nmethods significantly improve performance over baselines, especially in the\nlowest-resource cases, and demonstrate the importance of the relationship\nbetween such models' pretraining data and target language varieties.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 16:12:52 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2020 07:56:50 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Chau", "Ethan C.", ""], ["Lin", "Lucy H.", ""], ["Smith", "Noah A.", ""]]}, {"id": "2009.14167", "submitter": "Zhe Gan", "authors": "Siqi Sun, Zhe Gan, Yu Cheng, Yuwei Fang, Shuohang Wang, Jingjing Liu", "title": "Contrastive Distillation on Intermediate Representations for Language\n  Model Compression", "comments": "Accepted by EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing language model compression methods mostly use a simple L2 loss to\ndistill knowledge in the intermediate representations of a large BERT model to\na smaller one. Although widely used, this objective by design assumes that all\nthe dimensions of hidden representations are independent, failing to capture\nimportant structural knowledge in the intermediate layers of the teacher\nnetwork. To achieve better distillation efficacy, we propose Contrastive\nDistillation on Intermediate Representations (CoDIR), a principled knowledge\ndistillation framework where the student is trained to distill knowledge\nthrough intermediate layers of the teacher via a contrastive objective. By\nlearning to distinguish positive sample from a large set of negative samples,\nCoDIR facilitates the student's exploitation of rich information in teacher's\nhidden layers. CoDIR can be readily applied to compress large-scale language\nmodels in both pre-training and finetuning stages, and achieves superb\nperformance on the GLUE benchmark, outperforming state-of-the-art compression\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 17:31:43 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Sun", "Siqi", ""], ["Gan", "Zhe", ""], ["Cheng", "Yu", ""], ["Fang", "Yuwei", ""], ["Wang", "Shuohang", ""], ["Liu", "Jingjing", ""]]}, {"id": "2009.14237", "submitter": "Andrew Head", "authors": "Andrew Head (UC Berkeley), Kyle Lo (Allen Institute for AI), Dongyeop\n  Kang (UC Berkeley), Raymond Fok (University of Washington), Sam Skjonsberg\n  (Allen Institute for AI), Daniel S. Weld (Allen Institute for AI, University\n  of Washington), Marti A. Hearst (UC Berkeley)", "title": "Augmenting Scientific Papers with Just-in-Time, Position-Sensitive\n  Definitions of Terms and Symbols", "comments": "18 pages, 17 figures, 2 tables. To appear at the 2021 ACM CHI\n  Conference on Human Factors in Computing Systems. For associated video, see\n  https://youtu.be/yYcQf-Yq8B0. v2 changes: expanded discussion of design\n  process and implementation; improved figure design. v3 changes: fixed typo in\n  cell of Table 2; updated HEDDEx and Schwarz-Hearst accuracy in Section 5.3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Despite the central importance of research papers to scientific progress,\nthey can be difficult to read. Comprehension is often stymied when the\ninformation needed to understand a passage resides somewhere else: in another\nsection, or in another paper. In this work, we envision how interfaces can\nbring definitions of technical terms and symbols to readers when and where they\nneed them most. We introduce ScholarPhi, an augmented reading interface with\nfour novel features: (1) tooltips that surface position-sensitive definitions\nfrom elsewhere in a paper, (2) a filter over the paper that \"declutters\" it to\nreveal how the term or symbol is used across the paper, (3) automatic equation\ndiagrams that expose multiple definitions in parallel, and (4) an automatically\ngenerated glossary of important terms and symbols. A usability study showed\nthat the tool helps researchers of all experience levels read papers.\nFurthermore, researchers were eager to have ScholarPhi's definitions available\nto support their everyday reading.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 18:11:19 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 19:05:59 GMT"}, {"version": "v3", "created": "Tue, 27 Apr 2021 18:32:46 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Head", "Andrew", "", "UC Berkeley"], ["Lo", "Kyle", "", "Allen Institute for AI"], ["Kang", "Dongyeop", "", "UC Berkeley"], ["Fok", "Raymond", "", "University of Washington"], ["Skjonsberg", "Sam", "", "Allen Institute for AI"], ["Weld", "Daniel S.", "", "Allen Institute for AI, University\n  of Washington"], ["Hearst", "Marti A.", "", "UC Berkeley"]]}, {"id": "2009.14259", "submitter": "Peter Jansen", "authors": "Peter A. Jansen", "title": "Visually-Grounded Planning without Vision: Language Models Infer\n  Detailed Plans from High-level Instructions", "comments": "Accepted to Findings of EMNLP. V2: corrected typo Table 1; margins\n  Table 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recently proposed ALFRED challenge task aims for a virtual robotic agent\nto complete complex multi-step everyday tasks in a virtual home environment\nfrom high-level natural language directives, such as \"put a hot piece of bread\non a plate\". Currently, the best-performing models are able to complete less\nthan 5% of these tasks successfully. In this work we focus on modeling the\ntranslation problem of converting natural language directives into detailed\nmulti-step sequences of actions that accomplish those goals in the virtual\nenvironment. We empirically demonstrate that it is possible to generate gold\nmulti-step plans from language directives alone without any visual input in 26%\nof unseen cases. When a small amount of visual information is incorporated,\nnamely the starting location in the virtual environment, our best-performing\nGPT-2 model successfully generates gold command sequences in 58% of cases. Our\nresults suggest that contextualized language models may provide strong visual\nsemantic planning modules for grounded virtual agents.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 18:52:39 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 19:16:00 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Jansen", "Peter A.", ""]]}, {"id": "2009.14261", "submitter": "Remesh Babu K R", "authors": "Dincy Davis, Reena Murali, Remesh Babu", "title": "Abusive Language Detection and Characterization of Twitter Behavior", "comments": "7 pages, 7 figures and 8 tables", "journal-ref": "International Journal of Computer Sciences and Engineering, Vol.8,\n  Issue.7, July 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, abusive language detection in online content is performed using\nBidirectional Recurrent Neural Network (BiRNN) method. Here the main objective\nis to focus on various forms of abusive behaviors on Twitter and to detect\nwhether a speech is abusive or not. The results are compared for various\nabusive behaviors in social media, with Convolutional Neural Netwrok (CNN) and\nRecurrent Neural Network (RNN) methods and proved that the proposed BiRNN is a\nbetter deep learning model for automatic abusive speech detection.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2020 07:38:11 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Davis", "Dincy", ""], ["Murali", "Reena", ""], ["Babu", "Remesh", ""]]}, {"id": "2009.14262", "submitter": "Jiaqi Wang", "authors": "Chacha Chen, Chieh-Yang Huang, Yaqi Hou, Yang Shi, Enyan Dai, Jiaqi\n  Wang", "title": "TEST_POSITIVE at W-NUT 2020 Shared Task-3: Joint Event Multi-task\n  Learning for Slot Filling in Noisy Text", "comments": "6 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The competition of extracting COVID-19 events from Twitter is to develop\nsystems that can automatically extract related events from tweets. The built\nsystem should identify different pre-defined slots for each event, in order to\nanswer important questions (e.g., Who is tested positive? What is the age of\nthe person? Where is he/she?). To tackle these challenges, we propose the Joint\nEvent Multi-task Learning (JOELIN) model. Through a unified global learning\nframework, we make use of all the training data across different events to\nlearn and fine-tune the language model. Moreover, we implement a type-aware\npost-processing procedure using named entity recognition (NER) to further\nfilter the predictions. JOELIN outperforms the BERT baseline by 17.2% in micro\nF1.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 19:08:45 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Chen", "Chacha", ""], ["Huang", "Chieh-Yang", ""], ["Hou", "Yaqi", ""], ["Shi", "Yang", ""], ["Dai", "Enyan", ""], ["Wang", "Jiaqi", ""]]}, {"id": "2009.14304", "submitter": "Saurabh Kulshreshtha", "authors": "Saurabh Kulshreshtha, Jos\\'e Luis Redondo-Garc\\'ia, Ching-Yun Chang", "title": "Cross-lingual Alignment Methods for Multilingual BERT: A Comparative\n  Study", "comments": "Accepted as a long paper in Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual BERT (mBERT) has shown reasonable capability for zero-shot\ncross-lingual transfer when fine-tuned on downstream tasks. Since mBERT is not\npre-trained with explicit cross-lingual supervision, transfer performance can\nfurther be improved by aligning mBERT with cross-lingual signal. Prior work\nproposes several approaches to align contextualised embeddings. In this paper\nwe analyse how different forms of cross-lingual supervision and various\nalignment methods influence the transfer capability of mBERT in zero-shot\nsetting. Specifically, we compare parallel corpora vs. dictionary-based\nsupervision and rotational vs. fine-tuning based alignment methods. We evaluate\nthe performance of different alignment methodologies across eight languages on\ntwo tasks: Name Entity Recognition and Semantic Slot Filling. In addition, we\npropose a novel normalisation method which consistently improves the\nperformance of rotation-based alignment including a notable 3% F1 improvement\nfor distant and typologically dissimilar languages. Importantly we identify the\nbiases of the alignment methods to the type of task and proximity to the\ntransfer language. We also find that supervision from parallel corpus is\ngenerally superior to dictionary alignments.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 20:56:57 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Kulshreshtha", "Saurabh", ""], ["Redondo-Garc\u00eda", "Jos\u00e9 Luis", ""], ["Chang", "Ching-Yun", ""]]}, {"id": "2009.14306", "submitter": "Shirley Anugrah Hayati", "authors": "Shirley Anugrah Hayati, Dongyeop Kang, Qingxiaoyang Zhu, Weiyan Shi,\n  and Zhou Yu", "title": "INSPIRED: Toward Sociable Recommendation Dialog Systems", "comments": "Accepted as a long paper at EMNLP 2020, corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In recommendation dialogs, humans commonly disclose their preference and make\nrecommendations in a friendly manner. However, this is a challenge when\ndeveloping a sociable recommendation dialog system, due to the lack of dialog\ndataset annotated with such sociable strategies. Therefore, we present\nINSPIRED, a new dataset of 1,001 human-human dialogs for movie recommendation\nwith measures for successful recommendations. To better understand how humans\nmake recommendations in communication, we design an annotation scheme related\nto recommendation strategies based on social science theories and annotate\nthese dialogs. Our analysis shows that sociable recommendation strategies, such\nas sharing personal opinions or communicating with encouragement, more\nfrequently lead to successful recommendations. Based on our dataset, we train\nend-to-end recommendation dialog systems with and without our strategy labels.\nIn both automatic and human evaluation, our model with strategy incorporation\noutperforms the baseline model. This work is a first step for building sociable\nrecommendation dialog systems with a basis of social science theories.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 21:03:44 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 06:17:22 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Hayati", "Shirley Anugrah", ""], ["Kang", "Dongyeop", ""], ["Zhu", "Qingxiaoyang", ""], ["Shi", "Weiyan", ""], ["Yu", "Zhou", ""]]}, {"id": "2009.14335", "submitter": "Zewei Chu", "authors": "Zewei Chu, Karl Stratos, Kevin Gimpel", "title": "Natcat: Weakly Supervised Text Classification with Naturally Annotated\n  Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We seek to improve text classification by leveraging naturally annotated\ndata. In particular, we construct a general purpose text categorization dataset\n(NatCat) from three online resources: Wikipedia, Reddit, and Stack Exchange.\nThese datasets consist of document-category pairs derived from manual curation\nthat occurs naturally by their communities. We build general purpose text\nclassifiers by training on NatCat and evaluate them on a suite of 11 text\nclassification tasks (CatEval). We benchmark different modeling choices and\ndataset combinations, and show how each task benefits from different NatCat\ntraining resources.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 22:49:15 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Chu", "Zewei", ""], ["Stratos", "Karl", ""], ["Gimpel", "Kevin", ""]]}, {"id": "2009.14348", "submitter": "Huaishao Luo", "authors": "Huaishao Luo, Yu Shi, Ming Gong, Linjun Shou, Tianrui Li", "title": "MaP: A Matrix-based Prediction Approach to Improve Span Extraction in\n  Machine Reading Comprehension", "comments": "to appear at AACL-IJCNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Span extraction is an essential problem in machine reading comprehension.\nMost of the existing algorithms predict the start and end positions of an\nanswer span in the given corresponding context by generating two probability\nvectors. In this paper, we propose a novel approach that extends the\nprobability vector to a probability matrix. Such a matrix can cover more\nstart-end position pairs. Precisely, to each possible start index, the method\nalways generates an end probability vector. Besides, we propose a\nsampling-based training strategy to address the computational cost and memory\nissue in the matrix training phase. We evaluate our method on SQuAD 1.1 and\nthree other question answering benchmarks. Leveraging the most competitive\nmodels BERT and BiDAF as the backbone, our proposed approach can get consistent\nimprovements in all datasets, demonstrating the effectiveness of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2020 23:53:50 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Luo", "Huaishao", ""], ["Shi", "Yu", ""], ["Gong", "Ming", ""], ["Shou", "Linjun", ""], ["Li", "Tianrui", ""]]}, {"id": "2009.14361", "submitter": "Angus Addlesee", "authors": "Angus Addlesee and Pierre Albert", "title": "Ethically Collecting Multi-Modal Spontaneous Conversations with People\n  that have Cognitive Impairments", "comments": "Published at LREC's Workshop on Legal and Ethical Issues in Human\n  Language Technologies 2020", "journal-ref": "LREC Workshop on Legal and Ethical Issues in Human Language\n  Technologies (2020) 15-20", "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to make spoken dialogue systems (such as Amazon Alexa or Google\nAssistant) more accessible and naturally interactive for people with cognitive\nimpairments, appropriate data must be obtainable. Recordings of multi-modal\nspontaneous conversations with vulnerable user groups are scarce however and\nthis valuable data is challenging to collect. Researchers that call for this\ndata are commonly inexperienced in ethical and legal issues around working with\nvulnerable participants. Additionally, standard recording equipment is insecure\nand should not be used to capture sensitive data. We spent a year consulting\nexperts on how to ethically capture and share recordings of multi-modal\nspontaneous conversations with vulnerable user groups. In this paper we provide\nguidance, collated from these experts, on how to ethically collect such data\nand we present a new system - \"CUSCO\" - to capture, transport and exchange\nsensitive data securely. This framework is intended to be easily followed and\nimplemented to encourage further publications of similar corpora. Using this\nguide and secure recording system, researchers can review and refine their\nethical measures.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 00:57:33 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Addlesee", "Angus", ""], ["Albert", "Pierre", ""]]}, {"id": "2009.14375", "submitter": "Dhruv Kumar", "authors": "Olga Vechtomova, Gaurav Sahu, Dhruv Kumar", "title": "Generation of lyrics lines conditioned on music audio clips", "comments": "Accepted to First Workshop on NLP for Music and Audio (NLP4MusA) at\n  ISMIR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system for generating novel lyrics lines conditioned on music\naudio. A bimodal neural network model learns to generate lines conditioned on\nany given short audio clip. The model consists of a spectrogram variational\nautoencoder (VAE) and a text VAE. Both automatic and human evaluations\ndemonstrate effectiveness of our model in generating lines that have an\nemotional impact matching a given audio clip. The system is intended to serve\nas a creativity tool for songwriters.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 01:22:58 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Vechtomova", "Olga", ""], ["Sahu", "Gaurav", ""], ["Kumar", "Dhruv", ""]]}, {"id": "2009.14384", "submitter": "B Mansurov", "authors": "B. Mansurov and A. Mansurov", "title": "Development of Word Embeddings for Uzbek Language", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we share the process of developing word embeddings for the\nCyrillic variant of the Uzbek language. The result of our work is the first\npublicly available set of word vectors trained on the word2vec, GloVe, and\nfastText algorithms using a high-quality web crawl corpus developed in-house.\nThe developed word embeddings can be used in many natural language processing\ndownstream tasks.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 01:52:00 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Mansurov", "B.", ""], ["Mansurov", "A.", ""]]}, {"id": "2009.14386", "submitter": "Hong-Kwang Jeff Kuo", "authors": "Hong-Kwang J. Kuo, Zolt\\'an T\\\"uske, Samuel Thomas, Yinghui Huang,\n  Kartik Audhkhasi, Brian Kingsbury, Gakuto Kurata, Zvi Kons, Ron Hoory, and\n  Luis Lastras", "title": "End-to-End Spoken Language Understanding Without Full Transcripts", "comments": "5 pages, to be published in Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An essential component of spoken language understanding (SLU) is slot\nfilling: representing the meaning of a spoken utterance using semantic entity\nlabels. In this paper, we develop end-to-end (E2E) spoken language\nunderstanding systems that directly convert speech input to semantic entities\nand investigate if these E2E SLU models can be trained solely on semantic\nentity annotations without word-for-word transcripts. Training such models is\nvery useful as they can drastically reduce the cost of data collection. We\ncreated two types of such speech-to-entities models, a CTC model and an\nattention-based encoder-decoder model, by adapting models trained originally\nfor speech recognition. Given that our experiments involve speech input, these\nsystems need to recognize both the entity label and words representing the\nentity value correctly. For our speech-to-entities experiments on the ATIS\ncorpus, both the CTC and attention models showed impressive ability to skip\nnon-entity words: there was little degradation when trained on just entities\nversus full transcripts. We also explored the scenario where the entities are\nin an order not necessarily related to spoken order in the utterance. With its\nability to do re-ordering, the attention model did remarkably well, achieving\nonly about 2% degradation in speech-to-bag-of-entities F1 score.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 01:54:13 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Kuo", "Hong-Kwang J.", ""], ["T\u00fcske", "Zolt\u00e1n", ""], ["Thomas", "Samuel", ""], ["Huang", "Yinghui", ""], ["Audhkhasi", "Kartik", ""], ["Kingsbury", "Brian", ""], ["Kurata", "Gakuto", ""], ["Kons", "Zvi", ""], ["Hoory", "Ron", ""], ["Lastras", "Luis", ""]]}, {"id": "2009.14394", "submitter": "Brian Lester", "authors": "Brian Lester, Daniel Pressel, Amy Hemmeter, Sagnik Ray Choudhury and\n  Srinivas Bangalore", "title": "Multiple Word Embeddings for Increased Diversity of Representation", "comments": "arXiv admin note: text overlap with arXiv:2001.01167", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most state-of-the-art models in natural language processing (NLP) are neural\nmodels built on top of large, pre-trained, contextual language models that\ngenerate representations of words in context and are fine-tuned for the task at\nhand. The improvements afforded by these \"contextual embeddings\" come with a\nhigh computational cost. In this work, we explore a simple technique that\nsubstantially and consistently improves performance over a strong baseline with\nnegligible increase in run time. We concatenate multiple pre-trained embeddings\nto strengthen our representation of words. We show that this concatenation\ntechnique works across many tasks, datasets, and model types. We analyze\naspects of pre-trained embedding similarity and vocabulary coverage and find\nthat the representational diversity between different pre-trained embeddings is\nthe driving force of why this technique works. We provide open source\nimplementations of our models in both TensorFlow and PyTorch.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 02:33:09 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 04:40:15 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Lester", "Brian", ""], ["Pressel", "Daniel", ""], ["Hemmeter", "Amy", ""], ["Choudhury", "Sagnik Ray", ""], ["Bangalore", "Srinivas", ""]]}, {"id": "2009.14395", "submitter": "Shamil Chollampatt", "authors": "Shamil Chollampatt, Raymond Hendy Susanto, Liling Tan, Ewa Szymanska", "title": "Can Automatic Post-Editing Improve NMT?", "comments": "In EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic post-editing (APE) aims to improve machine translations, thereby\nreducing human post-editing effort. APE has had notable success when used with\nstatistical machine translation (SMT) systems but has not been as successful\nover neural machine translation (NMT) systems. This has raised questions on the\nrelevance of APE task in the current scenario. However, the training of APE\nmodels has been heavily reliant on large-scale artificial corpora combined with\nonly limited human post-edited data. We hypothesize that APE models have been\nunderperforming in improving NMT translations due to the lack of adequate\nsupervision. To ascertain our hypothesis, we compile a larger corpus of human\npost-edits of English to German NMT. We empirically show that a state-of-art\nneural APE model trained on this corpus can significantly improve a strong\nin-domain NMT system, challenging the current understanding in the field. We\nfurther investigate the effects of varying training data sizes, using\nartificial training data, and domain specificity for the APE task. We release\nthis new corpus under CC BY-NC-SA 4.0 license at\nhttps://github.com/shamilcm/pedra.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 02:34:19 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Chollampatt", "Shamil", ""], ["Susanto", "Raymond Hendy", ""], ["Tan", "Liling", ""], ["Szymanska", "Ewa", ""]]}, {"id": "2009.14445", "submitter": "Soroush Vosoughi Dr", "authors": "Weicheng Ma, Ruibo Liu, Lili Wang and Soroush Vosoughi", "title": "Towards Improved Model Design for Authorship Identification: A Survey on\n  Writing Style Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authorship identification tasks, which rely heavily on linguistic styles,\nhave always been an important part of Natural Language Understanding (NLU)\nresearch. While other tasks based on linguistic style understanding benefit\nfrom deep learning methods, these methods have not behaved as well as\ntraditional machine learning methods in many authorship-based tasks. With these\ntasks becoming more and more challenging, however, traditional machine learning\nmethods based on handcrafted feature sets are already approaching their\nperformance limits. Thus, in order to inspire future applications of deep\nlearning methods in authorship-based tasks in ways that benefit the extraction\nof stylistic features, we survey authorship-based tasks and other tasks related\nto writing style understanding. We first describe our survey results on the\ncurrent state of research in both sets of tasks and summarize existing\nachievements and problems in authorship-related tasks. We then describe\noutstanding methods in style-related tasks in general and analyze how they are\nused in combination in the top-performing models. We are optimistic about the\napplicability of these models to authorship-based tasks and hope our survey\nwill help advance research in this field.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 05:17:42 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Ma", "Weicheng", ""], ["Liu", "Ruibo", ""], ["Wang", "Lili", ""], ["Vosoughi", "Soroush", ""]]}, {"id": "2009.14457", "submitter": "Subhojeet Pramanik", "authors": "Subhojeet Pramanik, Shashank Mujumdar, Hima Patel", "title": "Towards a Multi-modal, Multi-task Learning based Pre-training Framework\n  for Document Representation Learning", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a multi-task learning-based framework that utilizes\na combination of self-supervised and supervised pre-training tasks to learn a\ngeneric document representation. We design the network architecture and the\npre-training tasks to incorporate the multi-modal document information across\ntext, layout, and image dimensions and allow the network to work with\nmulti-page documents. We showcase the applicability of our pre-training\nframework on a variety of different real-world document tasks such as document\nclassification, document information extraction, and document retrieval. We\nconduct exhaustive experiments to compare performance against different\nablations of our framework and state-of-the-art baselines. We discuss the\ncurrent limitations and next steps for our work.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 05:39:04 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Pramanik", "Subhojeet", ""], ["Mujumdar", "Shashank", ""], ["Patel", "Hima", ""]]}, {"id": "2009.14459", "submitter": "Mireille Makary", "authors": "Reda Khalaf and Mireille Makary", "title": "LEBANONUPRISING: a thorough study of Lebanese tweets", "comments": "9 pages, published at the CMLA 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies showed a huge interest in social networks sentiment analysis.\nTwitter, which is a microblogging service, can be a great source of information\non how the users feel about a certain topic, or what their opinion is regarding\na social, economic and even political matter. On October 17, Lebanon witnessed\nthe start of a revolution; the LebanonUprising hashtag became viral on Twitter.\nA dataset consisting of a 100,0000 tweets was collected between 18 and 21\nOctober. In this paper, we conducted a sentiment analysis study for the tweets\nin spoken Lebanese Arabic related to the LebanonUprising hashtag using\ndifferent machine learning algorithms. The dataset was manually annotated to\nmeasure the precision and recall metrics and to compare between the different\nalgorithms. Furthermore, the work completed in this paper provides two more\ncontributions. The first is related to building a Lebanese to Modern Standard\nArabic mapping dictionary that was used for the preprocessing of the tweets and\nthe second is an attempt to move from sentiment analysis to emotion detection\nusing emojis, and the two emotions we tried to predict were the \"sarcastic\" and\n\"funny\" emotions. We built a training set from the tweets collected in October\n2019 and then we used this set to predict sentiments and emotions of the tweets\nwe collected between May and August 2020. The analysis we conducted shows the\nvariation in sentiments, emotions and users between the two datasets. The\nresults we obtained seem satisfactory especially considering that there was no\nprevious or similar work done involving Lebanese Arabic tweets, to our\nknowledge.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 05:50:08 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Khalaf", "Reda", ""], ["Makary", "Mireille", ""]]}, {"id": "2009.14463", "submitter": "Grigorii Guz", "authors": "Grigorii Guz, Peyman Bateni, Darius Muglich, Giuseppe Carenini", "title": "Neural RST-based Evaluation of Discourse Coherence", "comments": "8 pages, 5 figures, to be published in AACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper evaluates the utility of Rhetorical Structure Theory (RST) trees\nand relations in discourse coherence evaluation. We show that incorporating\nsilver-standard RST features can increase accuracy when classifying coherence.\nWe demonstrate this through our tree-recursive neural model, namely\nRST-Recursive, which takes advantage of the text's RST features produced by a\nstate of the art RST parser. We evaluate our approach on the Grammarly Corpus\nfor Discourse Coherence (GCDC) and show that when ensembled with the current\nstate of the art, we can achieve the new state of the art accuracy on this\nbenchmark. Furthermore, when deployed alone, RST-Recursive achieves competitive\naccuracy while having 62% fewer parameters.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 06:00:37 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Guz", "Grigorii", ""], ["Bateni", "Peyman", ""], ["Muglich", "Darius", ""], ["Carenini", "Giuseppe", ""]]}, {"id": "2009.14505", "submitter": "Somak Aditya", "authors": "Pratik Joshi, Somak Aditya, Aalok Sathe, Monojit Choudhury", "title": "TaxiNLI: Taking a Ride up the NLU Hill", "comments": "15 pages, 9 figures, 4 tables. Accepted at CoNLL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Pre-trained Transformer-based neural architectures have consistently achieved\nstate-of-the-art performance in the Natural Language Inference (NLI) task.\nSince NLI examples encompass a variety of linguistic, logical, and reasoning\nphenomena, it remains unclear as to which specific concepts are learnt by the\ntrained systems and where they can achieve strong generalization. To\ninvestigate this question, we propose a taxonomic hierarchy of categories that\nare relevant for the NLI task. We introduce TAXINLI, a new dataset, that has\n10k examples from the MNLI dataset (Williams et al., 2018) with these taxonomic\nlabels. Through various experiments on TAXINLI, we observe that whereas for\ncertain taxonomic categories SOTA neural models have achieved near perfect\naccuracies - a large jump over the previous models - some categories still\nremain difficult. Our work adds to the growing body of literature that shows\nthe gaps in the current NLI systems and datasets through a systematic\npresentation and analysis of reasoning categories.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 08:45:25 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 04:28:04 GMT"}, {"version": "v3", "created": "Fri, 9 Oct 2020 11:07:49 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Joshi", "Pratik", ""], ["Aditya", "Somak", ""], ["Sathe", "Aalok", ""], ["Choudhury", "Monojit", ""]]}, {"id": "2009.14510", "submitter": "Zihan Liu", "authors": "Zihan Liu, Genta Indra Winata, Peng Xu, Zhaojiang Lin, Pascale Fung", "title": "Cross-lingual Spoken Language Understanding with Regularized\n  Representation Alignment", "comments": "EMNLP-2020 Long Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the promising results of current cross-lingual models for spoken\nlanguage understanding systems, they still suffer from imperfect cross-lingual\nrepresentation alignments between the source and target languages, which makes\nthe performance sub-optimal. To cope with this issue, we propose a\nregularization approach to further align word-level and sentence-level\nrepresentations across languages without any external resource. First, we\nregularize the representation of user utterances based on their corresponding\nlabels. Second, we regularize the latent variable model (Liu et al., 2019) by\nleveraging adversarial training to disentangle the latent variables.\nExperiments on the cross-lingual spoken language understanding task show that\nour model outperforms current state-of-the-art methods in both few-shot and\nzero-shot scenarios, and our model, trained on a few-shot setting with only 3\\%\nof the target language training data, achieves comparable performance to the\nsupervised training with all the training data.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 08:56:53 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Liu", "Zihan", ""], ["Winata", "Genta Indra", ""], ["Xu", "Peng", ""], ["Lin", "Zhaojiang", ""], ["Fung", "Pascale", ""]]}, {"id": "2009.14539", "submitter": "Marco Valentino", "authors": "Marco Valentino, Mokanarangan Thayaparan, Andr\\'e Freitas", "title": "Explainable Natural Language Reasoning via Conceptual Unification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an abductive framework for multi-hop and interpretable\ntextual inference. The reasoning process is guided by the notions unification\npower and plausibility of an explanation, computed through the interaction of\ntwo major architectural components: (a) An analogical reasoning model that\nranks explanatory facts by leveraging unification patterns in a corpus of\nexplanations; (b) An abductive reasoning model that performs a search for the\nbest explanation, which is realised via conceptual abstraction and subsequent\nunification. We demonstrate that the Step-wise Conceptual Unification can be\neffective for unsupervised question answering, and as an explanation extractor\nin combination with state-of-the-art Transformers. An empirical evaluation on\nthe Worldtree corpus and the ARC Challenge resulted in the following\nconclusions: (1) The question answering model outperforms competitive neural\nand multi-hop baselines without requiring any explicit training on answer\nprediction; (2) When used as an explanation extractor, the proposed model\nsignificantly improves the performance of Transformers, leading to\nstate-of-the-art results on the Worldtree corpus; (3) Analogical and abductive\nreasoning are highly complementary for achieving sound explanatory inference, a\nfeature that demonstrates the impact of the unification patterns on performance\nand interpretability.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 09:50:39 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Valentino", "Marco", ""], ["Thayaparan", "Mokanarangan", ""], ["Freitas", "Andr\u00e9", ""]]}, {"id": "2009.14578", "submitter": "Shaoxiong Ji", "authors": "Shaoxiong Ji, Erik Cambria and Pekka Marttinen", "title": "Dilated Convolutional Attention Network for Medical Code Assignment from\n  Clinical Text", "comments": "The 3rd Clinical Natural Language Processing Workshop at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical code assignment, which predicts medical codes from clinical texts, is\na fundamental task of intelligent medical information systems. The emergence of\ndeep models in natural language processing has boosted the development of\nautomatic assignment methods. However, recent advanced neural architectures\nwith flat convolutions or multi-channel feature concatenation ignore the\nsequential causal constraint within a text sequence and may not learn\nmeaningful clinical text representations, especially for lengthy clinical notes\nwith long-term sequential dependency. This paper proposes a Dilated\nConvolutional Attention Network (DCAN), integrating dilated convolutions,\nresidual connections, and label attention, for medical code assignment. It\nadopts dilated convolutions to capture complex medical patterns with a\nreceptive field which increases exponentially with dilation size. Experiments\non a real-world clinical dataset empirically show that our model improves the\nstate of the art.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 11:55:58 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Ji", "Shaoxiong", ""], ["Cambria", "Erik", ""], ["Marttinen", "Pekka", ""]]}, {"id": "2009.14658", "submitter": "Hongfei Xu", "authors": "Hongfei Xu and Qiuhui Liu", "title": "Learning Hard Retrieval Cross Attention for Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Transformer translation model that based on the multi-head attention\nmechanism can be parallelized easily and lead to competitive performance in\nmachine translation. The multi-head attention network performs the scaled\ndot-product attention function in parallel, empowering the model by jointly\nattending to information from different representation subspaces at different\npositions. Though its advantages in parallelization, many previous works\nsuggest the computation of the attention mechanism is not sufficiently\nefficient, especially when processing long sequences, and propose approaches to\nimprove its efficiency with long sentences. In this paper, we accelerate the\ninference of the scaled dot-product attention in another perspective.\nSpecifically, instead of squeezing the sequence to attend, we simplify the\ncomputation of the scaled dot-product attention by learning a hard retrieval\nattention which only attends to one token in the sentence rather than all\ntokens. Since the hard attention mechanism only attends to one position, the\nmatrix multiplication between attention probabilities and the value sequence in\nthe standard scaled dot-product attention can be replaced by a simple and\nefficient retrieval operation. As a result, our hard retrieval attention\nmechanism can empirically accelerate the scaled dot-product attention for both\nlong and short sequences by 66.5%, while performing competitively in a wide\nrange of machine translation tasks when using for cross attention networks.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 13:18:57 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Xu", "Hongfei", ""], ["Liu", "Qiuhui", ""]]}, {"id": "2009.14722", "submitter": "Guoqing Luo", "authors": "Guoqing Luo, Jiaxin Pan, Min Peng", "title": "RDSGAN: Rank-based Distant Supervision Relation Extraction with\n  Generative Adversarial Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distant supervision has been widely used for relation extraction but suffers\nfrom noise labeling problem. Neural network models are proposed to denoise with\nattention mechanism but cannot eliminate noisy data due to its non-zero\nweights. Hard decision is proposed to remove wrongly-labeled instances from the\npositive set though causes loss of useful information contained in removed\ninstances. In this paper, we propose a novel generative neural framework named\nRDSGAN (Rank-based Distant Supervision GAN) which automatically generates valid\ninstances for distant supervision relation extraction. Our framework combines\nsoft attention and hard decision to learn the distribution of true positive\ninstances via adversarial training and selects valid instances conforming to\nthe distribution via rank-based distant supervision, which addresses the false\npositive problem. Experimental results show the superiority of our framework\nover strong baselines.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 14:59:09 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Luo", "Guoqing", ""], ["Pan", "Jiaxin", ""], ["Peng", "Min", ""]]}, {"id": "2009.14725", "submitter": "Kiet Nguyen", "authors": "Kiet Van Nguyen, Duc-Vu Nguyen, Anh Gia-Tuan Nguyen, Ngan Luu-Thuy\n  Nguyen", "title": "A Vietnamese Dataset for Evaluating Machine Reading Comprehension", "comments": "Accepted by The 28th International Conference on Computational\n  Linguistics (COLING 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Over 97 million people speak Vietnamese as their native language in the\nworld. However, there are few research studies on machine reading comprehension\n(MRC) for Vietnamese, the task of understanding a text and answering questions\nrelated to it. Due to the lack of benchmark datasets for Vietnamese, we present\nthe Vietnamese Question Answering Dataset (UIT-ViQuAD), a new dataset for the\nlow-resource language as Vietnamese to evaluate MRC models. This dataset\ncomprises over 23,000 human-generated question-answer pairs based on 5,109\npassages of 174 Vietnamese articles from Wikipedia. In particular, we propose a\nnew process of dataset creation for Vietnamese MRC. Our in-depth analyses\nillustrate that our dataset requires abilities beyond simple reasoning like\nword matching and demands single-sentence and multiple-sentence inferences.\nBesides, we conduct experiments on state-of-the-art MRC methods for English and\nChinese as the first experimental models on UIT-ViQuAD. We also estimate human\nperformance on the dataset and compare it to the experimental results of\npowerful machine learning models. As a result, the substantial differences\nbetween human performance and the best model performance on the dataset\nindicate that improvements can be made on UIT-ViQuAD in future research. Our\ndataset is freely available on our website to encourage the research community\nto overcome challenges in Vietnamese MRC.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 15:06:56 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 14:22:12 GMT"}, {"version": "v3", "created": "Sat, 7 Nov 2020 06:40:46 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Van Nguyen", "Kiet", ""], ["Nguyen", "Duc-Vu", ""], ["Nguyen", "Anh Gia-Tuan", ""], ["Nguyen", "Ngan Luu-Thuy", ""]]}, {"id": "2009.14734", "submitter": "Nikolaos Aletras", "authors": "Danae S\\'anchez Villegas, Daniel Preo\\c{t}iuc-Pietro, Nikolaos Aletras", "title": "Point-of-Interest Type Inference from Social Media Text", "comments": "Accepted at AACL-IJCNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Physical places help shape how we perceive the experiences we have there. For\nthe first time, we study the relationship between social media text and the\ntype of the place from where it was posted, whether a park, restaurant, or\nsomeplace else. To facilitate this, we introduce a novel data set of\n$\\sim$200,000 English tweets published from 2,761 different points-of-interest\nin the U.S., enriched with place type information. We train classifiers to\npredict the type of the location a tweet was sent from that reach a macro F1 of\n43.67 across eight classes and uncover the linguistic markers associated with\neach type of place. The ability to predict semantic place information from a\ntweet has applications in recommendation systems, personalization services and\ncultural geography.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 15:21:19 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 10:31:02 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Villegas", "Danae S\u00e1nchez", ""], ["Preo\u0163iuc-Pietro", "Daniel", ""], ["Aletras", "Nikolaos", ""]]}, {"id": "2009.14780", "submitter": "Yevgeni Berzak", "authors": "Jonathan Malmaud, Roger Levy, Yevgeni Berzak", "title": "Bridging Information-Seeking Human Gaze and Machine Reading\n  Comprehension", "comments": "CoNLL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we analyze how human gaze during reading comprehension is\nconditioned on the given reading comprehension question, and whether this\nsignal can be beneficial for machine reading comprehension. To this end, we\ncollect a new eye-tracking dataset with a large number of participants engaging\nin a multiple choice reading comprehension task. Our analysis of this data\nreveals increased fixation times over parts of the text that are most relevant\nfor answering the question. Motivated by this finding, we propose making\nautomated reading comprehension more human-like by mimicking human\ninformation-seeking reading behavior during reading comprehension. We\ndemonstrate that this approach leads to performance gains on multiple choice\nquestion answering in English for a state-of-the-art reading comprehension\nmodel.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 16:34:27 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 16:08:02 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Malmaud", "Jonathan", ""], ["Levy", "Roger", ""], ["Berzak", "Yevgeni", ""]]}, {"id": "2009.14786", "submitter": "Nicolas Gontier", "authors": "Nicolas Gontier and Koustuv Sinha and Siva Reddy and Christopher Pal", "title": "Measuring Systematic Generalization in Neural Proof Generation with\n  Transformers", "comments": "NeurIPS 2020; 17 pages; 9 figures; 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in understanding how well Transformer language models\n(TLMs) can perform reasoning tasks when trained on knowledge encoded in the\nform of natural language. We investigate their systematic generalization\nabilities on a logical reasoning task in natural language, which involves\nreasoning over relationships between entities grounded in first-order logical\nproofs. Specifically, we perform soft theorem-proving by leveraging TLMs to\ngenerate natural language proofs. We test the generated proofs for logical\nconsistency, along with the accuracy of the final inference. We observe\nlength-generalization issues when evaluated on longer-than-trained sequences.\nHowever, we observe TLMs improve their generalization performance after being\nexposed to longer, exhaustive proofs. In addition, we discover that TLMs are\nable to generalize better using backward-chaining proofs compared to their\nforward-chaining counterparts, while they find it easier to generate forward\nchaining proofs. We observe that models that are not trained to generate proofs\nare better at generalizing to problems based on longer proofs. This suggests\nthat Transformers have efficient internal reasoning strategies that are harder\nto interpret. These results highlight the systematic generalization behavior of\nTLMs in the context of logical reasoning, and we believe this work motivates\ndeeper inspection of their underlying reasoning strategies.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 16:54:37 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 20:31:11 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Gontier", "Nicolas", ""], ["Sinha", "Koustuv", ""], ["Reddy", "Siva", ""], ["Pal", "Christopher", ""]]}, {"id": "2009.14790", "submitter": "Hang Yan", "authors": "Hang Yan, Xiaonan Li, Xipeng Qiu", "title": "BERT for Monolingual and Cross-Lingual Reverse Dictionary", "comments": "Accepted as EMNLP 2020 Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reverse dictionary is the task to find the proper target word given the word\ndescription. In this paper, we tried to incorporate BERT into this task.\nHowever, since BERT is based on the byte-pair-encoding (BPE) subword encoding,\nit is nontrivial to make BERT generate a word given the description. We propose\na simple but effective method to make BERT generate the target word for this\nspecific task. Besides, the cross-lingual reverse dictionary is the task to\nfind the proper target word described in another language. Previous models have\nto keep two different word embeddings and learn to align these embeddings.\nNevertheless, by using the Multilingual BERT (mBERT), we can efficiently\nconduct the cross-lingual reverse dictionary with one subword embedding, and\nthe alignment between languages is not necessary. More importantly, mBERT can\nachieve remarkable cross-lingual reverse dictionary performance even without\nthe parallel corpus, which means it can conduct the cross-lingual reverse\ndictionary with only corresponding monolingual data. Code is publicly available\nat https://github.com/yhcc/BertForRD.git.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 17:00:10 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Yan", "Hang", ""], ["Li", "Xiaonan", ""], ["Qiu", "Xipeng", ""]]}, {"id": "2009.14794", "submitter": "Xingyou Song", "authors": "Krzysztof Choromanski, Valerii Likhosherstov, David Dohan, Xingyou\n  Song, Andreea Gane, Tamas Sarlos, Peter Hawkins, Jared Davis, Afroz\n  Mohiuddin, Lukasz Kaiser, David Belanger, Lucy Colwell, Adrian Weller", "title": "Rethinking Attention with Performers", "comments": "Published as a conference paper + oral presentation at ICLR 2021. 38\n  pages. See\n  https://github.com/google-research/google-research/tree/master/protein_lm for\n  protein language model code, and\n  https://github.com/google-research/google-research/tree/master/performer for\n  Performer code. See\n  https://ai.googleblog.com/2020/10/rethinking-attention-with-performers.html\n  for Google AI Blog", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Performers, Transformer architectures which can estimate regular\n(softmax) full-rank-attention Transformers with provable accuracy, but using\nonly linear (as opposed to quadratic) space and time complexity, without\nrelying on any priors such as sparsity or low-rankness. To approximate softmax\nattention-kernels, Performers use a novel Fast Attention Via positive\nOrthogonal Random features approach (FAVOR+), which may be of independent\ninterest for scalable kernel methods. FAVOR+ can be also used to efficiently\nmodel kernelizable attention mechanisms beyond softmax. This representational\npower is crucial to accurately compare softmax with other kernels for the first\ntime on large-scale tasks, beyond the reach of regular Transformers, and\ninvestigate optimal attention-kernels. Performers are linear architectures\nfully compatible with regular Transformers and with strong theoretical\nguarantees: unbiased or nearly-unbiased estimation of the attention matrix,\nuniform convergence and low estimation variance. We tested Performers on a rich\nset of tasks stretching from pixel-prediction through text models to protein\nsequence modeling. We demonstrate competitive results with other examined\nefficient sparse and dense attention methods, showcasing effectiveness of the\nnovel attention-learning paradigm leveraged by Performers.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 17:09:09 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 21:40:24 GMT"}, {"version": "v3", "created": "Tue, 9 Mar 2021 16:26:47 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Choromanski", "Krzysztof", ""], ["Likhosherstov", "Valerii", ""], ["Dohan", "David", ""], ["Song", "Xingyou", ""], ["Gane", "Andreea", ""], ["Sarlos", "Tamas", ""], ["Hawkins", "Peter", ""], ["Davis", "Jared", ""], ["Mohiuddin", "Afroz", ""], ["Kaiser", "Lukasz", ""], ["Belanger", "David", ""], ["Colwell", "Lucy", ""], ["Weller", "Adrian", ""]]}, {"id": "2009.14809", "submitter": "Sanxing Chen", "authors": "Sanxing Chen, Aidan San, Xiaodong Liu, Yangfeng Ji", "title": "A Tale of Two Linkings: Dynamically Gating between Schema Linking and\n  Structural Linking for Text-to-SQL Parsing", "comments": "COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In Text-to-SQL semantic parsing, selecting the correct entities (tables and\ncolumns) for the generated SQL query is both crucial and challenging; the\nparser is required to connect the natural language (NL) question and the SQL\nquery to the structured knowledge in the database. We formulate two linking\nprocesses to address this challenge: schema linking which links explicit NL\nmentions to the database and structural linking which links the entities in the\noutput SQL with their structural relationships in the database schema.\nIntuitively, the effectiveness of these two linking processes changes based on\nthe entity being generated, thus we propose to dynamically choose between them\nusing a gating mechanism. Integrating the proposed method with two graph neural\nnetwork-based semantic parsers together with BERT representations demonstrates\nsubstantial gains in parsing accuracy on the challenging Spider dataset.\nAnalyses show that our proposed method helps to enhance the structure of the\nmodel output when generating complicated SQL queries and offers more\nexplainable predictions.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 17:32:27 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 20:48:52 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Chen", "Sanxing", ""], ["San", "Aidan", ""], ["Liu", "Xiaodong", ""], ["Ji", "Yangfeng", ""]]}, {"id": "2009.14824", "submitter": "Chantal Amrhein", "authors": "Chantal Amrhein and Rico Sennrich", "title": "On Romanization for Model Transfer Between Scripts in Neural Machine\n  Translation", "comments": "accepted at Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Transfer learning is a popular strategy to improve the quality of\nlow-resource machine translation. For an optimal transfer of the embedding\nlayer, the child and parent model should share a substantial part of the\nvocabulary. This is not the case when transferring to languages with a\ndifferent script. We explore the benefit of romanization in this scenario. Our\nresults show that romanization entails information loss and is thus not always\nsuperior to simpler vocabulary transfer methods, but can improve the transfer\nbetween related languages with different scripts. We compare two romanization\ntools and find that they exhibit different degrees of information loss, which\naffects translation quality. Finally, we extend romanization to the target\nside, showing that this can be a successful strategy when coupled with a simple\nderomanization model.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 17:54:56 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Amrhein", "Chantal", ""], ["Sennrich", "Rico", ""]]}]