[{"id": "1911.00069", "submitter": "Jian Ni", "authors": "Jian Ni, Radu Florian", "title": "Neural Cross-Lingual Relation Extraction Based on Bilingual Word\n  Embedding Mapping", "comments": "11 pages, Conference on Empirical Methods in Natural Language\n  Processing (EMNLP), 2019", "journal-ref": null, "doi": "10.18653/v1/D19-1038", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation extraction (RE) seeks to detect and classify semantic relationships\nbetween entities, which provides useful information for many NLP applications.\nSince the state-of-the-art RE models require large amounts of manually\nannotated data and language-specific resources to achieve high accuracy, it is\nvery challenging to transfer an RE model of a resource-rich language to a\nresource-poor language. In this paper, we propose a new approach for\ncross-lingual RE model transfer based on bilingual word embedding mapping. It\nprojects word embeddings from a target language to a source language, so that a\nwell-trained source-language neural network RE model can be directly applied to\nthe target language. Experiment results show that the proposed approach\nachieves very good performance for a number of target languages on both\nin-house and open datasets, using a small bilingual dictionary with only 1K\nword pairs.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 19:30:54 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Ni", "Jian", ""], ["Florian", "Radu", ""]]}, {"id": "1911.00133", "submitter": "Elsbeth Turcan", "authors": "Elsbeth Turcan, Kathleen McKeown", "title": "Dreaddit: A Reddit Dataset for Stress Analysis in Social Media", "comments": "To appear in the proceedings of the Tenth International Workshop on\n  Health Text Mining and Information Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stress is a nigh-universal human experience, particularly in the online\nworld. While stress can be a motivator, too much stress is associated with many\nnegative health outcomes, making its identification useful across a range of\ndomains. However, existing computational research typically only studies stress\nin domains such as speech, or in short genres such as Twitter. We present\nDreaddit, a new text corpus of lengthy multi-domain social media data for the\nidentification of stress. Our dataset consists of 190K posts from five\ndifferent categories of Reddit communities; we additionally label 3.5K total\nsegments taken from 3K posts using Amazon Mechanical Turk. We present\npreliminary supervised learning methods for identifying stress, both neural and\ntraditional, and analyze the complexity and diversity of the data and\ncharacteristics of each category.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 22:28:45 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Turcan", "Elsbeth", ""], ["McKeown", "Kathleen", ""]]}, {"id": "1911.00152", "submitter": "Volodymyr Sokolov", "authors": "V. Buriachok, M. Hadzhyiev, V. Sokolov, P. Skladannyi, L. Kuzmenko", "title": "Implementation of an Index Optimize Technology for Highly Specialized\n  Terms based on the Phonetic Algorithm Metaphone", "comments": null, "journal-ref": "Eastern-European Journal of Enterprise Technologies (ISSN:\n  1729-4061). 2019. Vol. 5. No. 2(101)", "doi": "10.15587/1729-4061.2019.181943", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When compiling databases, for example to meet the needs of healthcare\nestablishments, there is quite a common problem with the introduction and\nfurther processing of names and last names of doctors and patients that are\nhighly specialized both in terms of pronunciation and writing. This is because\nnames and last names of people cannot be unique, their notation is not subject\nto any rules of phonetics, while their length in different languages may not\nmatch. With the advent of the Internet, this situation has become generally\ncritical and can lead to that multiple copies of e-mails are sent to one\naddress. It is possible to solve the specified problem by using phonetic\nalgorithms for comparing words Daitch-Mokotoff, Soundex, NYSIIS, Polyphone, and\nMetaphone, as well as the Levenshtein and Jaro algorithms, Q-gram-based\nalgorithms, which make it possible to find distances between words. The most\nwidespread among them are the Soundex and Metaphone algorithms, which are\ndesigned to index the words based on their sound, taking into consideration the\nrules of pronunciation. By applying the Metaphone algorithm, an attempt has\nbeen made to optimize the phonetic search processes for tasks of fuzzy\ncoincidence, for example, at data deduplication in various databases and\nregistries, in order to reduce the number of errors of incorrect input of last\nnames. An analysis of the most common last names reveals that some of them are\nof the Ukrainian or Russian origin. At the same time, the rules following which\nthe names are pronounced and written, for example in Ukrainian, differ\nradically from basic algorithms for English and differ quite significantly for\nthe Russian language. That is why a phonetic algorithm should take into\nconsideration first of all the peculiarities in the formation of Ukrainian last\nnames, which is of special relevance now.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 23:54:41 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Buriachok", "V.", ""], ["Hadzhyiev", "M.", ""], ["Sokolov", "V.", ""], ["Skladannyi", "P.", ""], ["Kuzmenko", "L.", ""]]}, {"id": "1911.00172", "submitter": "Urvashi Khandelwal", "authors": "Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettlemoyer and Mike\n  Lewis", "title": "Generalization through Memorization: Nearest Neighbor Language Models", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce $k$NN-LMs, which extend a pre-trained neural language model (LM)\nby linearly interpolating it with a $k$-nearest neighbors ($k$NN) model. The\nnearest neighbors are computed according to distance in the pre-trained LM\nembedding space, and can be drawn from any text collection, including the\noriginal LM training data. Applying this augmentation to a strong Wikitext-103\nLM, with neighbors drawn from the original training set, our $k$NN-LM achieves\na new state-of-the-art perplexity of 15.79 - a 2.9 point improvement with no\nadditional training. We also show that this approach has implications for\nefficiently scaling up to larger training sets and allows for effective domain\nadaptation, by simply varying the nearest neighbor datastore, again without\nfurther training. Qualitatively, the model is particularly helpful in\npredicting rare patterns, such as factual knowledge. Together, these results\nstrongly suggest that learning similarity between sequences of text is easier\nthan predicting the next word, and that nearest neighbor search is an effective\napproach for language modeling in the long tail.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 01:09:53 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 01:04:52 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Khandelwal", "Urvashi", ""], ["Levy", "Omer", ""], ["Jurafsky", "Dan", ""], ["Zettlemoyer", "Luke", ""], ["Lewis", "Mike", ""]]}, {"id": "1911.00176", "submitter": "Dmitrii Emelianenko", "authors": "Dmitrii Emelianenko, Elena Voita, Pavel Serdyukov", "title": "Sequence Modeling with Unconstrained Generation Order", "comments": "Camera-ready version for NeurIPS2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dominant approach to sequence generation is to produce a sequence in some\npredefined order, e.g. left to right. In contrast, we propose a more general\nmodel that can generate the output sequence by inserting tokens in any\narbitrary order. Our model learns decoding order as a result of its training\nprocedure. Our experiments show that this model is superior to fixed order\nmodels on a number of sequence generation tasks, such as Machine Translation,\nImage-to-LaTeX and Image Captioning.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 01:36:24 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Emelianenko", "Dmitrii", ""], ["Voita", "Elena", ""], ["Serdyukov", "Pavel", ""]]}, {"id": "1911.00202", "submitter": "Ying Xu", "authors": "Y. Xu, X. Zhong, A. J. J. Yepes, J. H. Lau", "title": "Forget Me Not: Reducing Catastrophic Forgetting for Domain Adaptation in\n  Reading Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The creation of large-scale open domain reading comprehension data sets in\nrecent years has enabled the development of end-to-end neural comprehension\nmodels with promising results. To use these models for domains with limited\ntraining data, one of the most effective approach is to first pretrain them on\nlarge out-of-domain source data and then fine-tune them with the limited target\ndata. The caveat of this is that after fine-tuning the comprehension models\ntend to perform poorly in the source domain, a phenomenon known as catastrophic\nforgetting. In this paper, we explore methods that overcome catastrophic\nforgetting during fine-tuning without assuming access to data from the source\ndomain. We introduce new auxiliary penalty terms and observe the best\nperformance when a combination of auxiliary penalty terms is used to regularise\nthe fine-tuning process for adapting comprehension models. To test our methods,\nwe develop and release 6 narrow domain data sets that could potentially be used\nas reading comprehension benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 05:07:06 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 05:19:17 GMT"}, {"version": "v3", "created": "Fri, 20 Nov 2020 02:19:55 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Xu", "Y.", ""], ["Zhong", "X.", ""], ["Yepes", "A. J. J.", ""], ["Lau", "J. H.", ""]]}, {"id": "1911.00203", "submitter": "Pan Zhou", "authors": "Pan Zhou, Ruchao Fan, Wei Chen, Jia Jia", "title": "Improving Generalization of Transformer for Speech Recognition with\n  Parallel Schedule Sampling and Relative Positional Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer has shown promising results in many sequence to sequence\ntransformation tasks recently. It utilizes a number of feed-forward\nself-attention layers to replace the recurrent neural networks (RNN) in\nattention-based encoder decoder (AED) architecture. Self-attention layer learns\ntemporal dependence by incorporating sinusoidal positional embedding of tokens\nin a sequence for parallel computing. Quicker iteration speed in training than\nsequential operation of RNN can be obtained. Deeper layers of the transformer\nalso make it perform better than RNN-based AED. However, this parallelization\nability is lost when applying scheduled sampling training. Self-attention with\nsinusoidal positional embedding may cause performance degradations for longer\nsequences that have similar acoustic or semantic information at different\npositions as well. To address these problems, we propose to use parallel\nscheduled sampling (PSS) and relative positional embedding (RPE) to help the\ntransformer generalize to unseen data. Our proposed methods achieve a 7%\nrelative improvement for short utterances and a 70% relative gain for long\nutterances on a 10,000-hour Mandarin ASR task.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 05:16:12 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 14:41:44 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Zhou", "Pan", ""], ["Fan", "Ruchao", ""], ["Chen", "Wei", ""], ["Jia", "Jia", ""]]}, {"id": "1911.00212", "submitter": "Siyu Huang", "authors": "Tao Jin, Siyu Huang, Yingming Li, Zhongfei Zhang", "title": "Low-Rank HOCA: Efficient High-Order Cross-Modal Attention for Video\n  Captioning", "comments": "Accepted as a long paper at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the challenging task of video captioning which aims to\ngenerate descriptions for video data. Recently, the attention-based\nencoder-decoder structures have been widely used in video captioning. In\nexisting literature, the attention weights are often built from the information\nof an individual modality, while, the association relationships between\nmultiple modalities are neglected. Motivated by this observation, we propose a\nvideo captioning model with High-Order Cross-Modal Attention (HOCA) where the\nattention weights are calculated based on the high-order correlation tensor to\ncapture the frame-level cross-modal interaction of different modalities\nsufficiently. Furthermore, we novelly introduce Low-Rank HOCA which adopts\ntensor decomposition to reduce the extremely large space requirement of HOCA,\nleading to a practical and efficient implementation in real-world applications.\nExperimental results on two benchmark datasets, MSVD and MSR-VTT, show that\nLow-rank HOCA establishes a new state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 05:53:50 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Jin", "Tao", ""], ["Huang", "Siyu", ""], ["Li", "Yingming", ""], ["Zhang", "Zhongfei", ""]]}, {"id": "1911.00225", "submitter": "Naoya Inoue", "authors": "Pride Kavumba, Naoya Inoue, Benjamin Heinzerling, Keshav Singh, Paul\n  Reisert, Kentaro Inui", "title": "When Choosing Plausible Alternatives, Clever Hans can be Clever", "comments": "Accepted to the COmmonsense INference in Natural Language Processing\n  workshop (COIN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretrained language models, such as BERT and RoBERTa, have shown large\nimprovements in the commonsense reasoning benchmark COPA. However, recent work\nfound that many improvements in benchmarks of natural language understanding\nare not due to models learning the task, but due to their increasing ability to\nexploit superficial cues, such as tokens that occur more often in the correct\nanswer than the wrong one. Are BERT's and RoBERTa's good performance on COPA\nalso caused by this? We find superficial cues in COPA, as well as evidence that\nBERT exploits these cues. To remedy this problem, we introduce Balanced COPA,\nan extension of COPA that does not suffer from easy-to-exploit single token\ncues. We analyze BERT's and RoBERTa's performance on original and Balanced\nCOPA, finding that BERT relies on superficial cues when they are present, but\nstill achieves comparable performance once they are made ineffective,\nsuggesting that BERT learns the task to a certain degree when forced to. In\ncontrast, RoBERTa does not appear to rely on superficial cues.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 06:48:07 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Kavumba", "Pride", ""], ["Inoue", "Naoya", ""], ["Heinzerling", "Benjamin", ""], ["Singh", "Keshav", ""], ["Reisert", "Paul", ""], ["Inui", "Kentaro", ""]]}, {"id": "1911.00226", "submitter": "Daniel Kasenberg", "authors": "Daniel Kasenberg, Antonio Roque, Ravenna Thielstrom, Meia\n  Chita-Tegmark, and Matthias Scheutz", "title": "Generating Justifications for Norm-Related Agent Decisions", "comments": "Accepted to the Proceedings of the 12th International Conference on\n  Natural Language Generation (INLG 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to generating natural language justifications of\ndecisions derived from norm-based reasoning. Assuming an agent which maximally\nsatisfies a set of rules specified in an object-oriented temporal logic, the\nuser can ask factual questions (about the agent's rules, actions, and the\nextent to which the agent violated the rules) as well as \"why\" questions that\nrequire the agent comparing actual behavior to counterfactual trajectories with\nrespect to these rules. To produce natural-sounding explanations, we focus on\nthe subproblem of producing natural language clauses from statements in a\nfragment of temporal logic, and then describe how to embed these clauses into\nexplanatory sentences. We use a human judgment evaluation on a testbed task to\ncompare our approach to variants in terms of intelligibility, mental model and\nperceived trust.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 06:53:12 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Kasenberg", "Daniel", ""], ["Roque", "Antonio", ""], ["Thielstrom", "Ravenna", ""], ["Chita-Tegmark", "Meia", ""], ["Scheutz", "Matthias", ""]]}, {"id": "1911.00229", "submitter": "Daniel Kasenberg", "authors": "Daniel Kasenberg, Antonio Roque, Ravenna Thielstrom, and Matthias\n  Scheutz", "title": "Engaging in Dialogue about an Agent's Norms and Behaviors", "comments": "Accepted to the 1st Workshop on Interactive Natural Language\n  Technology for Explainable Artificial Intelligence (NL4XAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a set of capabilities allowing an agent planning with moral and\nsocial norms represented in temporal logic to respond to queries about its\nnorms and behaviors in natural language, and for the human user to add and\nremove norms directly in natural language. The user may also pose hypothetical\nmodifications to the agent's norms and inquire about their effects.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 07:01:52 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Kasenberg", "Daniel", ""], ["Roque", "Antonio", ""], ["Thielstrom", "Ravenna", ""], ["Scheutz", "Matthias", ""]]}, {"id": "1911.00262", "submitter": "Marko Mihajlovic", "authors": "Marko Mihajlovic, Ning Xiong", "title": "Finding the most similar textual documents using Case-Based Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, huge amounts of unstructured textual data on the Internet\nare a big difficulty for AI algorithms to provide the best recommendations for\nusers and their search queries. Since the Internet became widespread, a lot of\nresearch has been done in the field of Natural Language Processing (NLP) and\nmachine learning. Almost every solution transforms documents into Vector Space\nModels (VSM) in order to apply AI algorithms over them. One such approach is\nbased on Case-Based Reasoning (CBR). Therefore, the most important part of\nthose systems is to compute the similarity between numerical data points. In\n2016, the new similarity TS-SS metric is proposed, which showed\nstate-of-the-art results in the field of textual mining for unsupervised\nlearning. However, no one before has investigated its performances for\nsupervised learning (classification task). In this work, we devised a CBR\nsystem capable of finding the most similar documents for a given query aiming\nto investigate performances of the new state-of-the-art metric, TS-SS, in\naddition to the two other geometrical similarity measures --- Euclidean\ndistance and Cosine similarity --- that showed the best predictive results over\nseveral benchmark corpora. The results show surprising inappropriateness of\nTS-SS measure for high dimensional features.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 08:46:35 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Mihajlovic", "Marko", ""], ["Xiong", "Ning", ""]]}, {"id": "1911.00269", "submitter": "Vevake Balaraman", "authors": "Vevake Balaraman and Bernardo Magnini", "title": "A Robust Data-Driven Approach for Dialogue State Tracking of Unseen Slot\n  Values", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Dialogue State Tracker is a key component in dialogue systems which\nestimates the beliefs of possible user goals at each dialogue turn. Deep\nlearning approaches using recurrent neural networks have shown state-of-the-art\nperformance for the task of dialogue state tracking. Generally, these\napproaches assume a predefined candidate list and struggle to predict any new\ndialogue state values that are not seen during training. This makes extending\nthe candidate list for a slot without model retaining infeasible and also has\nlimitations in modelling for low resource domains where training data for slot\nvalues are expensive. In this paper, we propose a novel dialogue state tracker\nbased on copying mechanism that can effectively track such unseen slot values\nwithout compromising performance on slot values seen during training. The\nproposed model is also flexible in extending the candidate list without\nrequiring any retraining or change in the model. We evaluate the proposed model\non various benchmark datasets (DSTC2, DSTC3 and WoZ2.0) and show that our\napproach, outperform other end-to-end data-driven approaches in tracking unseen\nslot values and also provides significant advantages in modelling for DST.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 09:08:58 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Balaraman", "Vevake", ""], ["Magnini", "Bernardo", ""]]}, {"id": "1911.00274", "submitter": "Ning Miao", "authors": "Ning Miao, Hao Zhou, Chengqi Zhao, Wenxian Shi, Lei Li", "title": "Kernelized Bayesian Softmax for Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural models for text generation require a softmax layer with proper token\nembeddings during the decoding phase. Most existing approaches adopt single\npoint embedding for each token. However, a word may have multiple senses\naccording to different context, some of which might be distinct. In this paper,\nwe propose KerBS, a novel approach for learning better embeddings for text\ngeneration. KerBS embodies two advantages: (a) it employs a Bayesian\ncomposition of embeddings for words with multiple senses; (b) it is adaptive to\nsemantic variances of words and robust to rare sentence context by imposing\nlearned kernels to capture the closeness of words (senses) in the embedding\nspace. Empirical studies show that KerBS significantly boosts the performance\nof several text generation tasks.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 09:20:14 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Miao", "Ning", ""], ["Zhou", "Hao", ""], ["Zhao", "Chengqi", ""], ["Shi", "Wenxian", ""], ["Li", "Lei", ""]]}, {"id": "1911.00288", "submitter": "Avinash Madasu", "authors": "Avinash Madasu, Sivasankar E", "title": "Efficient Feature Selection techniques for Sentiment Analysis", "comments": "Accepted for publication at the springer journal Multimedia Tools And\n  Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis is a domain of study that focuses on identifying and\nclassifying the ideas expressed in the form of text into positive, negative and\nneutral polarities. Feature selection is a crucial process in machine learning.\nIn this paper, we aim to study the performance of different feature selection\ntechniques for sentiment analysis. Term Frequency Inverse Document Frequency\n(TF-IDF) is used as the feature extraction technique for creating feature\nvocabulary. Various Feature Selection (FS) techniques are experimented to\nselect the best set of features from feature vocabulary. The selected features\nare trained using different machine learning classifiers Logistic Regression\n(LR), Support Vector Machines (SVM), Decision Tree (DT) and Naive Bayes (NB).\nEnsemble techniques Bagging and Random Subspace are applied on classifiers to\nenhance the performance on sentiment analysis. We show that, when the best FS\ntechniques are trained using ensemble methods achieve remarkable results on\nsentiment analysis. We also compare the performance of FS methods trained using\nBagging, Random Subspace with varied neural network architectures. We show that\nFS techniques trained using ensemble classifiers outperform neural networks\nrequiring significantly less training time and parameters thereby eliminating\nthe need for extensive hyper-parameter tuning.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 10:20:05 GMT"}, {"version": "v2", "created": "Sun, 2 Feb 2020 13:55:21 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Madasu", "Avinash", ""], ["E", "Sivasankar", ""]]}, {"id": "1911.00317", "submitter": "Nadir Durrani Dr", "authors": "Yonatan Belinkov, Nadir Durrani, Fahim Dalvi, Hassan Sajjad, James\n  Glass", "title": "On the Linguistic Representational Power of Neural Machine Translation\n  Models", "comments": "Accepted to appear in the Journal of Computational Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent success of deep neural networks in natural language\nprocessing (NLP), their interpretability remains a challenge. We analyze the\nrepresentations learned by neural machine translation models at various levels\nof granularity and evaluate their quality through relevant extrinsic\nproperties. In particular, we seek answers to the following questions: (i) How\naccurately is word-structure captured within the learned representations, an\nimportant aspect in translating morphologically-rich languages? (ii) Do the\nrepresentations capture long-range dependencies, and effectively handle\nsyntactically divergent languages? (iii) Do the representations capture lexical\nsemantics? We conduct a thorough investigation along several parameters: (i)\nWhich layers in the architecture capture each of these linguistic phenomena;\n(ii) How does the choice of translation unit (word, character, or subword unit)\nimpact the linguistic properties captured by the underlying representations?\n(iii) Do the encoder and decoder learn differently and independently? (iv) Do\nthe representations learned by multilingual NMT models capture the same amount\nof linguistic information as their bilingual counterparts? Our data-driven,\nquantitative evaluation illuminates important aspects in NMT models and their\nability to capture various linguistic phenomena. We show that deep NMT models\nlearn a non-trivial amount of linguistic information. Notable findings include:\ni) Word morphology and part-of-speech information are captured at the lower\nlayers of the model; (ii) In contrast, lexical semantics or non-local syntactic\nand semantic dependencies are better represented at the higher layers; (iii)\nRepresentations learned using characters are more informed about wordmorphology\ncompared to those learned using subword units; and (iv) Representations learned\nby multilingual models are richer compared to bilingual models.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 12:13:45 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Belinkov", "Yonatan", ""], ["Durrani", "Nadir", ""], ["Dalvi", "Fahim", ""], ["Sajjad", "Hassan", ""], ["Glass", "James", ""]]}, {"id": "1911.00337", "submitter": "Anthony Ferritto", "authors": "Anthony Ferritto, Lin Pan, Rishav Chakravarti, Salim Roukos, Radu\n  Florian, J. William Murdock, Avirup Sil", "title": "Ensembling Strategies for Answering Natural Questions", "comments": "arXiv admin note: text overlap with arXiv:1909.05286", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many of the top question answering systems today utilize ensembling to\nimprove their performance on tasks such as the Stanford Question Answering\nDataset (SQuAD) and Natural Questions (NQ) challenges. Unfortunately most of\nthese systems do not publish their ensembling strategies used in their\nleaderboard submissions. In this work, we investigate a number of ensembling\ntechniques and demonstrate a strategy which improves our F1 score for short\nanswers on the dev set for NQ by 2.3 F1 points over our single model (which\noutperforms the previous SOTA by 1.9 F1 points).\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 19:18:14 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 13:43:28 GMT"}, {"version": "v3", "created": "Wed, 6 Nov 2019 13:26:50 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Ferritto", "Anthony", ""], ["Pan", "Lin", ""], ["Chakravarti", "Rishav", ""], ["Roukos", "Salim", ""], ["Florian", "Radu", ""], ["Murdock", "J. William", ""], ["Sil", "Avirup", ""]]}, {"id": "1911.00359", "submitter": "Marie-Anne Lachaux", "authors": "Guillaume Wenzek, Marie-Anne Lachaux, Alexis Conneau, Vishrav\n  Chaudhary, Francisco Guzm\\'an, Armand Joulin, Edouard Grave", "title": "CCNet: Extracting High Quality Monolingual Datasets from Web Crawl Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-training text representations have led to significant improvements in\nmany areas of natural language processing. The quality of these models benefits\ngreatly from the size of the pretraining corpora as long as its quality is\npreserved. In this paper, we describe an automatic pipeline to extract massive\nhigh-quality monolingual datasets from Common Crawl for a variety of languages.\nOur pipeline follows the data processing introduced in fastText (Mikolov et\nal., 2017; Grave et al., 2018), that deduplicates documents and identifies\ntheir language. We augment this pipeline with a filtering step to select\ndocuments that are close to high quality corpora like Wikipedia.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 13:09:28 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 00:03:54 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Wenzek", "Guillaume", ""], ["Lachaux", "Marie-Anne", ""], ["Conneau", "Alexis", ""], ["Chaudhary", "Vishrav", ""], ["Guzm\u00e1n", "Francisco", ""], ["Joulin", "Armand", ""], ["Grave", "Edouard", ""]]}, {"id": "1911.00461", "submitter": "Omar U. Florez", "authors": "Omar U. Florez", "title": "On the Unintended Social Bias of Training Language Generation Models\n  with Data from Local Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There are concerns that neural language models may preserve some of the\nstereotypes of the underlying societies that generate the large corpora needed\nto train these models. For example, gender bias is a significant problem when\ngenerating text, and its unintended memorization could impact the user\nexperience of many applications (e.g., the smart-compose feature in Gmail).\n  In this paper, we introduce a novel architecture that decouples the\nrepresentation learning of a neural model from its memory management role. This\narchitecture allows us to update a memory module with an equal ratio across\ngender types addressing biased correlations directly in the latent space. We\nexperimentally show that our approach can mitigate the gender bias\namplification in the automatic generation of articles news while providing\nsimilar perplexity values when extending the Sequence2Sequence architecture.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 16:52:02 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Florez", "Omar U.", ""]]}, {"id": "1911.00473", "submitter": "Emad Elwany", "authors": "Emad Elwany, Dave Moore, Gaurav Oberoi", "title": "BERT Goes to Law School: Quantifying the Competitive Advantage of Access\n  to Large Legal Corpora in Contract Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning language models, such as BERT, on domain specific corpora has\nproven to be valuable in domains like scientific papers and biomedical text. In\nthis paper, we show that fine-tuning BERT on legal documents similarly provides\nvaluable improvements on NLP tasks in the legal domain. Demonstrating this\noutcome is significant for analyzing commercial agreements, because obtaining\nlarge legal corpora is challenging due to their confidential nature. As such,\nwe show that having access to large legal corpora is a competitive advantage\nfor commercial applications, and academic research on analyzing contracts.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 17:30:21 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Elwany", "Emad", ""], ["Moore", "Dave", ""], ["Oberoi", "Gaurav", ""]]}, {"id": "1911.00484", "submitter": "Ming Tu", "authors": "Ming Tu, Kevin Huang, Guangtao Wang, Jing Huang, Xiaodong He, Bowen\n  Zhou", "title": "Select, Answer and Explain: Interpretable Multi-hop Reading\n  Comprehension over Multiple Documents", "comments": "Accepted to AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretable multi-hop reading comprehension (RC) over multiple documents is\na challenging problem because it demands reasoning over multiple information\nsources and explaining the answer prediction by providing supporting evidences.\nIn this paper, we propose an effective and interpretable Select, Answer and\nExplain (SAE) system to solve the multi-document RC problem. Our system first\nfilters out answer-unrelated documents and thus reduce the amount of\ndistraction information. This is achieved by a document classifier trained with\na novel pairwise learning-to-rank loss. The selected answer-related documents\nare then input to a model to jointly predict the answer and supporting\nsentences. The model is optimized with a multi-task learning objective on both\ntoken level for answer prediction and sentence level for supporting sentences\nprediction, together with an attention-based interaction between these two\ntasks. Evaluated on HotpotQA, a challenging multi-hop RC data set, the proposed\nSAE system achieves top competitive performance in distractor setting compared\nto other existing systems on the leaderboard.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 17:48:38 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 01:45:25 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 05:18:30 GMT"}, {"version": "v4", "created": "Mon, 10 Feb 2020 21:45:52 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Tu", "Ming", ""], ["Huang", "Kevin", ""], ["Wang", "Guangtao", ""], ["Huang", "Jing", ""], ["He", "Xiaodong", ""], ["Zhou", "Bowen", ""]]}, {"id": "1911.00492", "submitter": "Saatviga Sudhahar", "authors": "Saatviga Sudhahar, Ian Roberts and Andrea Pierleoni", "title": "Reasoning Over Paths via Knowledge Base Completion", "comments": "Submitted at the TextGraphs2019 Workshop at EMNLP 2019 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning over paths in large scale knowledge graphs is an important problem\nfor many applications. In this paper we discuss a simple approach to\nautomatically build and rank paths between a source and target entity pair with\nlearned embeddings using a knowledge base completion model (KBC). We assembled\na knowledge graph by mining the available biomedical scientific literature and\nextracted a set of high frequency paths to use for validation. We demonstrate\nthat our method is able to effectively rank a list of known paths between a\npair of entities and also come up with plausible paths that are not present in\nthe knowledge graph. For a given entity pair we are able to reconstruct the\nhighest ranking path 60% of the time within the the top 10 ranked paths and\nachieve 49% mean average precision. Our approach is compositional since any KBC\nmodel that can produce vector representations of entities can be used.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 17:59:38 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Sudhahar", "Saatviga", ""], ["Roberts", "Ian", ""], ["Pierleoni", "Andrea", ""]]}, {"id": "1911.00497", "submitter": "Nicholas Waytowich", "authors": "Nicholas Waytowich, Sean L. Barton, Vernon Lawhern, Garrett Warnell", "title": "A Narration-based Reward Shaping Approach using Grounded Natural\n  Language Commands", "comments": "Presented at the Imitation, Intent and Interaction (I3) workshop,\n  ICML 2019. arXiv admin note: substantial text overlap with arXiv:1906.02671", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep reinforcement learning techniques have led to agents that are\nsuccessfully able to learn to perform a number of tasks that had been\npreviously unlearnable, these techniques are still susceptible to the\nlongstanding problem of reward sparsity. This is especially true for tasks such\nas training an agent to play StarCraft II, a real-time strategy game where\nreward is only given at the end of a game which is usually very long. While\nthis problem can be addressed through reward shaping, such approaches typically\nrequire a human expert with specialized knowledge. Inspired by the vision of\nenabling reward shaping through the more-accessible paradigm of\nnatural-language narration, we develop a technique that can provide the\nbenefits of reward shaping using natural language commands. Our\nnarration-guided RL agent projects sequences of natural-language commands into\nthe same high-dimensional representation space as corresponding goal states. We\nshow that we can get improved performance with our method compared to\ntraditional reward-shaping approaches. Additionally, we demonstrate the ability\nof our method to generalize to unseen natural-language commands.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 22:37:54 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Waytowich", "Nicholas", ""], ["Barton", "Sean L.", ""], ["Lawhern", "Vernon", ""], ["Warnell", "Garrett", ""]]}, {"id": "1911.00523", "submitter": "Chenhao Tan", "authors": "David Atkinson, Kumar Bhargav Srinivasan, Chenhao Tan", "title": "What Gets Echoed? Understanding the \"Pointers\" in Explanations of\n  Persuasive Arguments", "comments": "19 pages, 3 figures, EMNLP 2019, the code and dataset are available\n  at https://chenhaot.com/papers/explanation-pointers.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explanations are central to everyday life, and are a topic of growing\ninterest in the AI community. To investigate the process of providing natural\nlanguage explanations, we leverage the dynamics of the /r/ChangeMyView\nsubreddit to build a dataset with 36K naturally occurring explanations of why\nan argument is persuasive. We propose a novel word-level prediction task to\ninvestigate how explanations selectively reuse, or echo, information from what\nis being explained (henceforth, explanandum). We develop features to capture\nthe properties of a word in the explanandum, and show that our proposed\nfeatures not only have relatively strong predictive power on the echoing of a\nword in an explanation, but also enhance neural methods of generating\nexplanations. In particular, while the non-contextual properties of a word\nitself are more valuable for stopwords, the interaction between the constituent\nparts of an explanandum is crucial in predicting the echoing of content words.\nWe also find intriguing patterns of a word being echoed. For example, although\nnouns are generally less likely to be echoed, subjects and objects can,\ndepending on their source, be more likely to be echoed in the explanations.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 18:00:05 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Atkinson", "David", ""], ["Srinivasan", "Kumar Bhargav", ""], ["Tan", "Chenhao", ""]]}, {"id": "1911.00536", "submitter": "Yizhe Zhang", "authors": "Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett,\n  Xiang Gao, Jianfeng Gao, Jingjing Liu, Bill Dolan", "title": "DialoGPT: Large-Scale Generative Pre-training for Conversational\n  Response Generation", "comments": "Accepted by ACL 2020 system demonstration", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a large, tunable neural conversational response generation model,\nDialoGPT (dialogue generative pre-trained transformer). Trained on 147M\nconversation-like exchanges extracted from Reddit comment chains over a period\nspanning from 2005 through 2017, DialoGPT extends the Hugging Face PyTorch\ntransformer to attain a performance close to human both in terms of automatic\nand human evaluation in single-turn dialogue settings. We show that\nconversational systems that leverage DialoGPT generate more relevant,\ncontentful and context-consistent responses than strong baseline systems. The\npre-trained model and training pipeline are publicly released to facilitate\nresearch into neural response generation and the development of more\nintelligent open-domain dialogue systems.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 18:16:54 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 05:45:19 GMT"}, {"version": "v3", "created": "Sat, 2 May 2020 07:09:50 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Zhang", "Yizhe", ""], ["Sun", "Siqi", ""], ["Galley", "Michel", ""], ["Chen", "Yen-Chun", ""], ["Brockett", "Chris", ""], ["Gao", "Xiang", ""], ["Gao", "Jianfeng", ""], ["Liu", "Jingjing", ""], ["Dolan", "Bill", ""]]}, {"id": "1911.00547", "submitter": "Yingchi Liu", "authors": "Yingchi Liu, Quanzhi Li, Marika Cifor, Xiaozhong Liu, Qiong Zhang and\n  Luo Si", "title": "Uncover Sexual Harassment Patterns from Personal Stories by Joint Key\n  Element Extraction and Categorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of personal stories about sexual harassment shared online has\nincreased exponentially in recent years. This is in part inspired by the\n\\#MeToo and \\#TimesUp movements. Safecity is an online forum for people who\nexperienced or witnessed sexual harassment to share their personal experiences.\nIt has collected \\textgreater 10,000 stories so far. Sexual harassment occurred\nin a variety of situations, and categorization of the stories and extraction of\ntheir key elements will provide great help for the related parties to\nunderstand and address sexual harassment. In this study, we manually annotated\nthose stories with labels in the dimensions of location, time, and harassers'\ncharacteristics, and marked the key elements related to these dimensions.\nFurthermore, we applied natural language processing technologies with joint\nlearning schemes to automatically categorize these stories in those dimensions\nand extract key elements at the same time. We also uncovered significant\npatterns from the categorized sexual harassment stories. We believe our\nannotated data set, proposed algorithms, and analysis will help people who have\nbeen harassed, authorities, researchers and other related parties in various\nways, such as automatically filling reports, enlightening the public in order\nto prevent future harassment, and enabling more effective, faster action to be\ntaken.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 18:38:27 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Liu", "Yingchi", ""], ["Li", "Quanzhi", ""], ["Cifor", "Marika", ""], ["Liu", "Xiaozhong", ""], ["Zhang", "Qiong", ""], ["Si", "Luo", ""]]}, {"id": "1911.00637", "submitter": "Chiyu Zhang", "authors": "Muhammad Abdul-Mageed, Chiyu Zhang, Arun Rajendran, AbdelRahim\n  Elmadany, Michael Przystupa and Lyle Ungar", "title": "Sentence-Level BERT and Multi-Task Learning of Age and Gender in Social\n  Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social media currently provide a window on our lives, making it possible to\nlearn how people from different places, with different backgrounds, ages, and\ngenders use language. In this work we exploit a newly-created Arabic dataset\nwith ground truth age and gender labels to learn these attributes both\nindividually and in a multi-task setting at the sentence level. Our models are\nbased on variations of deep bidirectional neural networks. More specifically,\nwe build models with gated recurrent units and bidirectional encoder\nrepresentations from transformers (BERT). We show the utility of multi-task\nlearning (MTL) on the two tasks and identify task-specific attention as a\nsuperior choice in this context. We also find that a single-task BERT model\noutperform our best MTL models on the two tasks. We report tweet-level accuracy\nof 51.43% for the age task (three-way) and 65.30% on the gender task (binary),\nboth of which outperforms our baselines with a large margin. Our models are\nlanguage-agnostic, and so can be applied to other languages.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 03:39:19 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Abdul-Mageed", "Muhammad", ""], ["Zhang", "Chiyu", ""], ["Rajendran", "Arun", ""], ["Elmadany", "AbdelRahim", ""], ["Przystupa", "Michael", ""], ["Ungar", "Lyle", ""]]}, {"id": "1911.00643", "submitter": "Xinyi Zhou", "authors": "Niraj Sitaula, Chilukuri K. Mohan, Jennifer Grygiel, Xinyi Zhou, Reza\n  Zafarani", "title": "Credibility-based Fake News Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fake news can significantly misinform people who often rely on online sources\nand social media for their information. Current research on fake news detection\nhas mostly focused on analyzing fake news content and how it propagates on a\nnetwork of users. In this paper, we emphasize the detection of fake news by\nassessing its credibility. By analyzing public fake news data, we show that\ninformation on news sources (and authors) can be a strong indicator of\ncredibility. Our findings suggest that an author's history of association with\nfake news, and the number of authors of a news article, can play a significant\nrole in detecting fake news. Our approach can help improve traditional fake\nnews detection methods, wherein content features are often used to detect fake\nnews.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 04:06:30 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Sitaula", "Niraj", ""], ["Mohan", "Chilukuri K.", ""], ["Grygiel", "Jennifer", ""], ["Zhou", "Xinyi", ""], ["Zafarani", "Reza", ""]]}, {"id": "1911.00650", "submitter": "Daniel Duckworth", "authors": "Daphne Ippolito, Daniel Duckworth, Chris Callison-Burch, Douglas Eck", "title": "Automatic Detection of Generated Text is Easiest when Humans are Fooled", "comments": "ACL 2020 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in neural language modelling make it possible to rapidly\ngenerate vast amounts of human-sounding text. The capabilities of humans and\nautomatic discriminators to detect machine-generated text have been a large\nsource of research interest, but humans and machines rely on different cues to\nmake their decisions. Here, we perform careful benchmarking and analysis of\nthree popular sampling-based decoding strategies---top-$k$, nucleus sampling,\nand untruncated random sampling---and show that improvements in decoding\nmethods have primarily optimized for fooling humans. This comes at the expense\nof introducing statistical abnormalities that make detection easy for automatic\nsystems. We also show that though both human and automatic detector performance\nimprove with longer excerpt length, even multi-sentence excerpts can fool\nexpert human raters over 30% of the time. Our findings reveal the importance of\nusing both human and automatic detectors to assess the humanness of text\ngeneration systems.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 04:52:00 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 21:32:16 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Ippolito", "Daphne", ""], ["Duckworth", "Daniel", ""], ["Callison-Burch", "Chris", ""], ["Eck", "Douglas", ""]]}, {"id": "1911.00681", "submitter": "Rakesh Khobragade", "authors": "Rakesh Khobragade, Heaven Patel, Anand Namdev, Anish Mishra, Pushpak\n  Bhattacharyya", "title": "Machine Translation Evaluation using Bi-directional Entailment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new metric for Machine Translation (MT)\nevaluation, based on bi-directional entailment. We show that machine generated\ntranslation can be evaluated by determining paraphrasing with a reference\ntranslation provided by a human translator. We hypothesize, and show through\nexperiments, that paraphrasing can be detected by evaluating entailment\nrelationship in the forward and backward direction. Unlike conventional\nmetrics, like BLEU or METEOR, our approach uses deep learning to determine the\nsemantic similarity between candidate and reference translation for generating\nscores rather than relying upon simple n-gram overlap. We use BERT's\npre-trained implementation of transformer networks, fine-tuned on MNLI corpus,\nfor natural language inferencing. We apply our evaluation metric on WMT'14 and\nWMT'17 dataset to evaluate systems participating in the translation task and\nfind that our metric has a better correlation with the human annotated score\ncompared to the other traditional metrics at system level.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 08:45:24 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Khobragade", "Rakesh", ""], ["Patel", "Heaven", ""], ["Namdev", "Anand", ""], ["Mishra", "Anish", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1911.00712", "submitter": "Sanjay Kamath", "authors": "Sanjay Kamath, Brigitte Grau, Yue Ma", "title": "How to Pre-Train Your Model? Comparison of Different Pre-Training Models\n  for Biomedical Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using deep learning models on small scale datasets would result in\noverfitting. To overcome this problem, the process of pre-training a model and\nfine-tuning it to the small scale dataset has been used extensively in domains\nsuch as image processing. Similarly for question answering, pre-training and\nfine-tuning can be done in several ways. Commonly reading comprehension models\nare used for pre-training, but we show that other types of pre-training can\nwork better. We compare two pre-training models based on reading comprehension\nand open domain question answering models and determine the performance when\nfine-tuned and tested over BIOASQ question answering dataset. We find open\ndomain question answering model to be a better fit for this task rather than\nreading comprehension model.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 13:25:15 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Kamath", "Sanjay", ""], ["Grau", "Brigitte", ""], ["Ma", "Yue", ""]]}, {"id": "1911.00720", "submitter": "Shizhe Diao", "authors": "Shizhe Diao, Jiaxin Bai, Yan Song, Tong Zhang, Yonggang Wang", "title": "ZEN: Pre-training Chinese Text Encoder Enhanced by N-gram\n  Representations", "comments": "Natural Language Processing. 11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pre-training of text encoders normally processes text as a sequence of\ntokens corresponding to small text units, such as word pieces in English and\ncharacters in Chinese. It omits information carried by larger text granularity,\nand thus the encoders cannot easily adapt to certain combinations of\ncharacters. This leads to a loss of important semantic information, which is\nespecially problematic for Chinese because the language does not have explicit\nword boundaries. In this paper, we propose ZEN, a BERT-based Chinese (Z) text\nencoder Enhanced by N-gram representations, where different combinations of\ncharacters are considered during training. As a result, potential word or phase\nboundaries are explicitly pre-trained and fine-tuned with the character encoder\n(BERT). Therefore ZEN incorporates the comprehensive information of both the\ncharacter sequence and words or phrases it contains. Experimental results\nillustrated the effectiveness of ZEN on a series of Chinese NLP tasks. We show\nthat ZEN, using less resource than other published encoders, can achieve\nstate-of-the-art performance on most tasks. Moreover, it is shown that\nreasonable performance can be obtained when ZEN is trained on a small corpus,\nwhich is important for applying pre-training techniques to scenarios with\nlimited data. The code and pre-trained models of ZEN are available at\nhttps://github.com/sinovation/zen.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 14:32:08 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Diao", "Shizhe", ""], ["Bai", "Jiaxin", ""], ["Song", "Yan", ""], ["Zhang", "Tong", ""], ["Wang", "Yonggang", ""]]}, {"id": "1911.00760", "submitter": "Sendong Zhao", "authors": "Sendong Zhao, Chang Su, Andrea Sboner, Fei Wang", "title": "GRAPHENE: A Precise Biomedical Literature Retrieval Engine with Graph\n  Augmented Deep Learning and External Knowledge Empowerment", "comments": "CIKM 2019", "journal-ref": null, "doi": "10.1145/3357384.3358038", "report-no": null, "categories": "cs.IR cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective biomedical literature retrieval (BLR) plays a central role in\nprecision medicine informatics. In this paper, we propose GRAPHENE, which is a\ndeep learning based framework for precise BLR. GRAPHENE consists of three main\ndifferent modules 1) graph-augmented document representation learning; 2) query\nexpansion and representation learning and 3) learning to rank biomedical\narticles. The graph-augmented document representation learning module\nconstructs a document-concept graph containing biomedical concept nodes and\ndocument nodes so that global biomedical related concept from external\nknowledge source can be captured, which is further connected to a BiLSTM so\nboth local and global topics can be explored. Query expansion and\nrepresentation learning module expands the query with abbreviations and\ndifferent names, and then builds a CNN-based model to convolve the expanded\nquery and obtain a vector representation for each query. Learning to rank\nminimizes a ranking loss between biomedical articles with the query to learn\nthe retrieval function. Experimental results on applying our system to TREC\nPrecision Medicine track data are provided to demonstrate its effectiveness.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 18:05:20 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 20:39:33 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Zhao", "Sendong", ""], ["Su", "Chang", ""], ["Sboner", "Andrea", ""], ["Wang", "Fei", ""]]}, {"id": "1911.00773", "submitter": "Changmao Li", "authors": "Changmao Li, Tianhao Liu, Jinho D. Choi", "title": "Design and Challenges of Cloze-Style Reading Comprehension Tasks on\n  Multiparty Dialogue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes challenges in cloze-style reading comprehension on\nmultiparty dialogue and suggests two new tasks for more comprehensive\npredictions of personal entities in daily conversations. We first demonstrate\nthat there are substantial limitations to the evaluation methods of previous\nwork, namely that randomized assignment of samples to training and test data\nsubstantially decreases the complexity of cloze-style reading comprehension.\nAccording to our analysis, replacing the random data split with a chronological\ndata split reduces test accuracy on previous single-variable passage completion\ntask from 72\\% to 34\\%, that leaves much more room to improve. Our proposed\ntasks extend the previous single-variable passage completion task by replacing\nmore character mentions with variables. Several deep learning models are\ndeveloped to validate these three tasks. A thorough error analysis is provided\nto understand the challenges and guide the future direction of this research.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 19:19:28 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 20:48:25 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Li", "Changmao", ""], ["Liu", "Tianhao", ""], ["Choi", "Jinho D.", ""]]}, {"id": "1911.00811", "submitter": "Atticus Geiger", "authors": "Atticus Geiger, Ignacio Cases, Lauri Karttunen, Chris Potts", "title": "Posing Fair Generalization Tasks for Natural Language Inference", "comments": null, "journal-ref": "Proceedings of the 2019 conference on Empircal Methods in Natural\n  Lanuage Processing", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models for semantics are generally evaluated using naturalistic\ncorpora. Adversarial methods, in which models are evaluated on new examples\nwith known semantic properties, have begun to reveal that good performance at\nthese naturalistic tasks can hide serious shortcomings. However, we should\ninsist that these evaluations be fair -that the models are given data\nsufficient to support the requisite kinds of generalization. In this paper, we\ndefine and motivate a formal notion of fairness in this sense. We then apply\nthese ideas to natural language inference by constructing very challenging but\nprovably fair artificial datasets and showing that standard neural models fail\nto generalize in the required ways; only task-specific models that jointly\ncompose the premise and hypothesis are able to achieve high performance, and\neven these models do not solve the task perfectly.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 02:47:51 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Geiger", "Atticus", ""], ["Cases", "Ignacio", ""], ["Karttunen", "Lauri", ""], ["Potts", "Chris", ""]]}, {"id": "1911.00835", "submitter": "Sweta Agrawal", "authors": "Sweta Agrawal and Marine Carpuat", "title": "Controlling Text Complexity in Neural Machine Translation", "comments": "Accepted to EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces a machine translation task where the output is aimed at\naudiences of different levels of target language proficiency. We collect a high\nquality dataset of news articles available in English and Spanish, written for\ndiverse grade levels and propose a method to align segments across comparable\nbilingual articles. The resulting dataset makes it possible to train multi-task\nsequence-to-sequence models that translate Spanish into English targeted at an\neasier reading grade level than the original Spanish. We show that these\nmulti-task models outperform pipeline approaches that translate and simplify\ntext independently.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 05:41:53 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Agrawal", "Sweta", ""], ["Carpuat", "Marine", ""]]}, {"id": "1911.00841", "submitter": "Abhilasha Ravichander", "authors": "Abhilasha Ravichander, Alan W Black, Shomir Wilson, Thomas Norton,\n  Norman Sadeh", "title": "Question Answering for Privacy Policies: Combining Computational and\n  Legal Perspectives", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy policies are long and complex documents that are difficult for users\nto read and understand, and yet, they have legal effects on how user data is\ncollected, managed and used. Ideally, we would like to empower users to inform\nthemselves about issues that matter to them, and enable them to selectively\nexplore those issues. We present PrivacyQA, a corpus consisting of 1750\nquestions about the privacy policies of mobile applications, and over 3500\nexpert annotations of relevant answers. We observe that a strong neural\nbaseline underperforms human performance by almost 0.3 F1 on PrivacyQA,\nsuggesting considerable room for improvement for future systems. Further, we\nuse this dataset to shed light on challenges to question answerability, with\ndomain-general implications for any question answering system. The PrivacyQA\ncorpus offers a challenging corpus for question answering, with genuine\nreal-world utility.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 06:25:17 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Ravichander", "Abhilasha", ""], ["Black", "Alan W", ""], ["Wilson", "Shomir", ""], ["Norton", "Thomas", ""], ["Sadeh", "Norman", ""]]}, {"id": "1911.00845", "submitter": "Xiaolei Lu", "authors": "Xiaolei Lu and Bin Ni", "title": "Low-dimensional Semantic Space: from Text to Word Embedding", "comments": "in Chinese", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article focuses on the study of Word Embedding, a feature-learning\ntechnique in Natural Language Processing that maps words or phrases to\nlow-dimensional vectors. Beginning with the linguistic theories concerning\ncontextual similarities - \"Distributional Hypothesis\" and \"Context of\nSituation\", this article introduces two ways of numerical representation of\ntext: One-hot and Distributed Representation. In addition, this article\npresents statistical-based Language Models(such as Co-occurrence Matrix and\nSingular Value Decomposition) as well as Neural Network Language Models (NNLM,\nsuch as Continuous Bag-of-Words and Skip-Gram). This article also analyzes how\nWord Embedding can be applied to the study of word-sense disambiguation and\ndiachronic linguistics.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 07:11:58 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Lu", "Xiaolei", ""], ["Ni", "Bin", ""]]}, {"id": "1911.00850", "submitter": "Sahana Ramnath", "authors": "Sahana Ramnath, Amrita Saha, Soumen Chakrabarti, Mitesh M. Khapra", "title": "Scene Graph based Image Retrieval -- A case study on the CLEVR Dataset", "comments": "3 pages including references, Accepted at the ICCV 2019 Workshop -\n  'Linguistics Meets Image and Video Retrieval' (received Best Paper Award)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the prolification of multimodal interaction in various domains, recently\nthere has been much interest in text based image retrieval in the computer\nvision community. However most of the state of the art techniques model this\nproblem in a purely neural way, which makes it difficult to incorporate\npragmatic strategies in searching a large scale catalog especially when the\nsearch requirements are insufficient and the model needs to resort to an\ninteractive retrieval process through multiple iterations of\nquestion-answering. Motivated by this, we propose a neural-symbolic approach\nfor a one-shot retrieval of images from a large scale catalog, given the\ncaption description. To facilitate this, we represent the catalog and caption\nas scene-graphs and model the retrieval task as a learnable graph matching\nproblem, trained end-to-end with a REINFORCE algorithm. Further, we briefly\ndescribe an extension of this pipeline to an iterative retrieval framework,\nbased on interactive questioning and answering.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 08:00:38 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Ramnath", "Sahana", ""], ["Saha", "Amrita", ""], ["Chakrabarti", "Soumen", ""], ["Khapra", "Mitesh M.", ""]]}, {"id": "1911.00891", "submitter": "Debanjan Ghosh", "authors": "Debanjan Ghosh, Elena Musi, Kartikeya Upasani, Smaranda Muresan", "title": "Interpreting Verbal Irony: Linguistic Strategies and the Connection to\n  the Type of Semantic Incongruity", "comments": "Accepted at Society for Computation in Linguistics (SCiL), 2020\n  Conference", "journal-ref": null, "doi": "10.7275/91ey-3n44", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human communication often involves the use of verbal irony or sarcasm, where\nthe speakers usually mean the opposite of what they say. To better understand\nhow verbal irony is expressed by the speaker and interpreted by the hearer we\nconduct a crowdsourcing task: given an utterance expressing verbal irony, users\nare asked to verbalize their interpretation of the speaker's ironic message. We\npropose a typology of linguistic strategies for verbal irony interpretation and\nlink it to various theoretical linguistic frameworks. We design computational\nmodels to capture these strategies and present empirical studies aimed to\nanswer three questions: (1) what is the distribution of linguistic strategies\nused by hearers to interpret ironic messages?; (2) do hearers adopt similar\nstrategies for interpreting the speaker's ironic intent?; and (3) does the type\nof semantic incongruity in the ironic message (explicit vs. implicit) influence\nthe choice of interpretation strategies by the hearers?\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 14:05:55 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 12:25:55 GMT"}, {"version": "v3", "created": "Sat, 9 May 2020 18:49:28 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Ghosh", "Debanjan", ""], ["Musi", "Elena", ""], ["Upasani", "Kartikeya", ""], ["Muresan", "Smaranda", ""]]}, {"id": "1911.00932", "submitter": "Hairong Liu", "authors": "Hairong Liu, Mingbo Ma, Liang Huang", "title": "Machine Translation in Pronunciation Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research in machine translation community focus on translation in text\nspace. However, humans are in fact also good at direct translation in\npronunciation space. Some existing translation systems, such as simultaneous\nmachine translation, are inherently more natural and thus potentially more\nrobust by directly translating in pronunciation space. In this paper, we\nconduct large scale experiments on a self-built dataset with about $20$M En-Zh\npairs of text sentences and corresponding pronunciation sentences. We proposed\nthree new categories of translations: $1)$ translating a pronunciation sentence\nin source language into a pronunciation sentence in target language (P2P-Tran),\n$2)$ translating a text sentence in source language into a pronunciation\nsentence in target language (T2P-Tran), and $3)$ translating a pronunciation\nsentence in source language into a text sentence in target language (P2T-Tran),\nand compare them with traditional text translation (T2T-Tran). Our experiments\nclearly show that all $4$ categories of translations have comparable\nperformances, with small and sometimes ignorable differences.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 17:24:48 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Liu", "Hairong", ""], ["Ma", "Mingbo", ""], ["Huang", "Liang", ""]]}, {"id": "1911.00949", "submitter": "Zhongfang Zhuang", "authors": "Zhongfang Zhuang, Xiangnan Kong, Elke Rundensteiner, Jihane Zouaoui,\n  Aditya Arora", "title": "Attributed Sequence Embedding", "comments": "Accepted by IEEE Big Data 2019", "journal-ref": null, "doi": "10.1109/BigData47090.2019.9006481", "report-no": null, "categories": "cs.LG cs.CL cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining tasks over sequential data, such as clickstreams and gene sequences,\nrequire a careful design of embeddings usable by learning algorithms. Recent\nresearch in feature learning has been extended to sequential data, where each\ninstance consists of a sequence of heterogeneous items with a variable length.\nHowever, many real-world applications often involve attributed sequences, where\neach instance is composed of both a sequence of categorical items and a set of\nattributes. In this paper, we study this new problem of attributed sequence\nembedding, where the goal is to learn the representations of attributed\nsequences in an unsupervised fashion. This problem is core to many important\ndata mining tasks ranging from user behavior analysis to the clustering of gene\nsequences. This problem is challenging due to the dependencies between\nsequences and their associated attributes. We propose a deep multimodal\nlearning framework, called NAS, to produce embeddings of attributed sequences.\nThe embeddings are task independent and can be used on various mining tasks of\nattributed sequences. We demonstrate the effectiveness of our embeddings of\nattributed sequences in various unsupervised learning tasks on real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 19:16:51 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Zhuang", "Zhongfang", ""], ["Kong", "Xiangnan", ""], ["Rundensteiner", "Elke", ""], ["Zouaoui", "Jihane", ""], ["Arora", "Aditya", ""]]}, {"id": "1911.00964", "submitter": "Tolgahan Cakaloglu", "authors": "Tolgahan Cakaloglu, Xiaowei Xu", "title": "MRNN: A Multi-Resolution Neural Network with Duplex Attention for\n  Document Retrieval in the Context of Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The primary goal of ad-hoc retrieval (document retrieval in the context of\nquestion answering) is to find relevant documents satisfied the information\nneed posted in a natural language query. It requires a good understanding of\nthe query and all the documents in a corpus, which is difficult because the\nmeaning of natural language texts depends on the context, syntax,and semantics.\nRecently deep neural networks have been used to rank search results in response\nto a query. In this paper, we devise a multi-resolution neural network(MRNN) to\nleverage the whole hierarchy of representations for document retrieval. The\nproposed MRNN model is capable of deriving a representation that integrates\nrepresentations of different levels of abstraction from all the layers of the\nlearned hierarchical representation.Moreover, a duplex attention component is\ndesigned to refinethe multi-resolution representation so that an optimal\ncontextfor matching the query and document can be determined. More\nspecifically, the first attention mechanism determines optimal context from the\nlearned multi-resolution representation for the query and document. The latter\nattention mechanism aims to fine-tune the representation so that the query and\nthe relevant document are closer in proximity. The empirical study shows that\nMRNN with the duplex attention is significantly superior to existing models\nused for ad-hoc retrieval on benchmark datasets including SQuAD, WikiQA,\nQUASAR, and TrecQA.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 20:38:38 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Cakaloglu", "Tolgahan", ""], ["Xu", "Xiaowei", ""]]}, {"id": "1911.00985", "submitter": "Karol Chlasta", "authors": "Karol Chlasta", "title": "Sentiment analysis model for Twitter data in Polish language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text mining analysis of tweets gathered during Polish presidential election\non May 10th, 2015. The project included implementation of engine to retrieve\ninformation from Twitter, building document corpora, corpora cleaning, and\ncreating Term-Document Matrix. Each tweet from the text corpora was assigned a\ncategory based on its sentiment score. The score was calculated using the\nnumber of positive and/or negative emoticons and Polish words in each document.\nThe result data set was used to train and test four machine learning\nclassifiers, to select these providing most accurate automatic tweet\nclassification results. The Naive Bayes and Maximum Entropy algorithms achieved\nthe best accuracy of respectively 71.76% and 77.32%. All implementation tasks\nwere completed using R programming language.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 22:06:03 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Chlasta", "Karol", ""]]}, {"id": "1911.01026", "submitter": "Jeremy Wohlwend", "authors": "Jeremy Wohlwend, Ethan R. Elenberg, Samuel Altschul, Shawn Henry, Tao\n  Lei", "title": "Metric Learning for Dynamic Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional text classifiers are limited to predicting over a fixed set of\nlabels. However, in many real-world applications the label set is frequently\nchanging. For example, in intent classification, new intents may be added over\ntime while others are removed. We propose to address the problem of dynamic\ntext classification by replacing the traditional, fixed-size output layer with\na learned, semantically meaningful metric space. Here the distances between\ntextual inputs are optimized to perform nearest-neighbor classification across\noverlapping label sets. Changing the label set does not involve removing\nparameters, but rather simply adding or removing support points in the metric\nspace. Then the learned metric can be fine-tuned with only a few additional\ntraining examples. We demonstrate that this simple strategy is robust to\nchanges in the label space. Furthermore, our results show that learning a\nnon-Euclidean metric can improve performance in the low data regime, suggesting\nthat further work on metric spaces may benefit low-resource research.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 04:27:29 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Wohlwend", "Jeremy", ""], ["Elenberg", "Ethan R.", ""], ["Altschul", "Samuel", ""], ["Henry", "Shawn", ""], ["Lei", "Tao", ""]]}, {"id": "1911.01055", "submitter": "Tuan Nguyen", "authors": "Tuan Ngo Nguyen, Franck Dernoncourt and Thien Huu Nguyen", "title": "On the Effectiveness of the Pooling Methods for Biomedical Relation\n  Extraction with Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have achieved state-of-the-art performances on many\nrelation extraction datasets. A common element in these deep learning models\ninvolves the pooling mechanisms where a sequence of hidden vectors is\naggregated to generate a single representation vector, serving as the features\nto perform prediction for RE. Unfortunately, the models in the literature tend\nto employ different strategies to perform pooling for RE, leading to the\nchallenge to determine the best pooling mechanism for this problem, especially\nin the biomedical domain. In order to answer this question, in this work, we\nconduct a comprehensive study to evaluate the effectiveness of different\npooling mechanisms for the deep learning models in biomedical RE. The\nexperimental results suggest that dependency-based pooling is the best pooling\nstrategy for RE in the biomedical domain, yielding the state-of-the-art\nperformance on two benchmark datasets for this problem.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 07:15:05 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Nguyen", "Tuan Ngo", ""], ["Dernoncourt", "Franck", ""], ["Nguyen", "Thien Huu", ""]]}, {"id": "1911.01098", "submitter": "Shangmin Guo", "authors": "Shangmin Guo", "title": "Emergence of Numeric Concepts in Multi-Agent Autonomous Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of deep learning, most of current state-of-the-art\ntechniques in natural langauge processing are based on deep learning models\ntrained with argescaled static textual corpora. However, we human beings learn\nand understand in a different way. Thus, grounded language learning argues that\nmodels need to learn and understand language by the experience and perceptions\nobtained by interacting with enviroments, like how humans do. With the help of\ndeep reinforcement learning techniques, there are already lots of works\nfocusing on facilitating the emergence of communication protocols that have\ncompositionalities like natural languages among computational agents\npopulation. Unlike these works, we, on the other hand, focus on the numeric\nconcepts which correspond to abstractions in cognition and function words in\nnatural language. Based on a specifically designed language game, we verify\nthat computational agents are capable of transmitting numeric concepts during\nautonomous communication, and the emergent communication protocols can reflect\nthe underlying structure of meaning space. Although their encodeing method is\nnot compositional like natural languages from a perspective of human beings,\nthe emergent languages can be generalised to unseen inputs and, more\nimportantly, are easier for models to learn. Besides, iterated learning can\nhelp further improving the compositionality of the emergent languages, under\nthe measurement of topological similarity. Furthermore, we experiment another\nrepresentation method, i.e. directly encode numerals into concatenations of\none-hot vectors, and find that the emergent languages would become\ncompositional like human natural languages. Thus, we argue that there are 2\nimportant factors for the emergence of compositional languages.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 09:58:23 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Guo", "Shangmin", ""]]}, {"id": "1911.01102", "submitter": "Chung-Yi Li", "authors": "Chung-Yi Li, Pei-Chieh Yuan, Hung-Yi Lee", "title": "What does a network layer hear? Analyzing hidden representations of\n  end-to-end ASR through speech synthesis", "comments": "submitted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end speech recognition systems have achieved competitive results\ncompared to traditional systems. However, the complex transformations involved\nbetween layers given highly variable acoustic signals are hard to analyze. In\nthis paper, we present our ASR probing model, which synthesizes speech from\nhidden representations of end-to-end ASR to examine the information maintain\nafter each layer calculation. Listening to the synthesized speech, we observe\ngradual removal of speaker variability and noise as the layer goes deeper,\nwhich aligns with the previous studies on how deep network functions in speech\nrecognition. This paper is the first study analyzing the end-to-end speech\nrecognition model by demonstrating what each layer hears. Speaker verification\nand speech enhancement measurements on synthesized speech are also conducted to\nconfirm our observation further.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 10:07:13 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Li", "Chung-Yi", ""], ["Yuan", "Pei-Chieh", ""], ["Lee", "Hung-Yi", ""]]}, {"id": "1911.01188", "submitter": "Cristina Espa\\~na-Bonet", "authors": "Ekaterina Lapshinova-Koltunski, Cristina Espa\\~na-Bonet and Josef van\n  Genabith", "title": "Analysing Coreference in Transformer Outputs", "comments": "12 pages, 1 figure", "journal-ref": "Fourth Workshop on Discourse in Machine Translation (DiscoMT 2019)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse coreference phenomena in three neural machine translation systems\ntrained with different data settings with or without access to explicit intra-\nand cross-sentential anaphoric information. We compare system performance on\ntwo different genres: news and TED talks. To do this, we manually annotate (the\npossibly incorrect) coreference chains in the MT outputs and evaluate the\ncoreference chain translations. We define an error typology that aims to go\nfurther than pronoun translation adequacy and includes types such as incorrect\nword selection or missing words. The features of coreference chains in\nautomatic translations are also compared to those of the source texts and human\ntranslations. The analysis shows stronger potential translationese effects in\nmachine translated outputs than in human translations.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 13:25:26 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Lapshinova-Koltunski", "Ekaterina", ""], ["Espa\u00f1a-Bonet", "Cristina", ""], ["van Genabith", "Josef", ""]]}, {"id": "1911.01196", "submitter": "Yu Meng", "authors": "Yu Meng, Jiaxin Huang, Guangyuan Wang, Chao Zhang, Honglei Zhuang,\n  Lance Kaplan, Jiawei Han", "title": "Spherical Text Embedding", "comments": "NeurIPS 2019. (Code:\n  https://github.com/yumeng5/Spherical-Text-Embedding)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised text embedding has shown great power in a wide range of NLP\ntasks. While text embeddings are typically learned in the Euclidean space,\ndirectional similarity is often more effective in tasks such as word similarity\nand document clustering, which creates a gap between the training stage and\nusage stage of text embedding. To close this gap, we propose a spherical\ngenerative model based on which unsupervised word and paragraph embeddings are\njointly learned. To learn text embeddings in the spherical space, we develop an\nefficient optimization algorithm with convergence guarantee based on Riemannian\noptimization. Our model enjoys high efficiency and achieves state-of-the-art\nperformances on various text embedding tasks including word similarity and\ndocument clustering.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 18:36:12 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Meng", "Yu", ""], ["Huang", "Jiaxin", ""], ["Wang", "Guangyuan", ""], ["Zhang", "Chao", ""], ["Zhuang", "Honglei", ""], ["Kaplan", "Lance", ""], ["Han", "Jiawei", ""]]}, {"id": "1911.01198", "submitter": "Yanwei Cui", "authors": "Yanwei Cui, Xavier Illy", "title": "Understand customer reviews with less data and in short time: pretrained\n  language representation and active learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address customer review understanding problems by using\nsupervised machine learning approaches, in order to achieve a fully automatic\nreview aspects categorisation and sentiment analysis. In general, such\nsupervised learning algorithms require domain-specific expert knowledge for\ngenerating high quality labeled training data, and the cost of labeling can be\nvery high. To achieve an in-production customer review machine learning enabled\nanalysis tool with only a limited amount of data and within a reasonable\ntraining data collection time, we propose to use pre-trained language\nrepresentation to boost model performance and active learning framework for\naccelerating the iterative training process. The results show that with\nintegration of both components, the fully automatic review analysis can be\nachieved at a much faster pace.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 12:39:37 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Cui", "Yanwei", ""], ["Illy", "Xavier", ""]]}, {"id": "1911.01208", "submitter": "Alon Kipnis", "authors": "Alon Kipnis", "title": "Higher Criticism for Discriminating Word-Frequency Tables and Testing\n  Authorship", "comments": "under review (AOAS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We adapt the Higher Criticism (HC) goodness-of-fit test to measure closeness\nbetween word-frequency tables. We apply this measure to authorship attribution\nchallenges, where the goal is to identify the author of a document using other\ndocuments whose authorship is known. The method is simple yet performs well\nwithout handcrafting and tuning; reporting accuracy at the state of the art\nlevel in various current challenges. As an inherent side effect, the HC\ncalculation identifies a subset of discriminating words. In practice, the\nidentified words have low variance across documents belonging to a corpus of\nhomogeneous authorship. We conclude that in comparing the similarity of a new\ndocument and a corpus of a single author, HC is mostly affected by words\ncharacteristic of the author and is relatively unaffected by topic structure.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 23:47:25 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 19:41:44 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 20:04:32 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Kipnis", "Alon", ""]]}, {"id": "1911.01212", "submitter": "Tamali Banerjee", "authors": "Tamali Banerjee, Rudra Murthy V, Pushpak Bhattacharyya", "title": "Scrambled Translation Problem: A Problem of Denoising UNMT", "comments": "Accepted by MT Summit 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we identify an interesting kind of error in the output of\nUnsupervised Neural Machine Translation (UNMT) systems like\n\\textit{Undreamt}(footnote). We refer to this error type as \\textit{Scrambled\nTranslation problem}. We observe that UNMT models which use \\textit{word\nshuffle} noise (as in case of Undreamt) can generate correct words, but fail to\nstitch them together to form phrases. As a result, words of the translated\nsentence look \\textit{scrambled}, resulting in decreased BLEU. We hypothesise\nthat the reason behind \\textit{scrambled translation problem} is 'shuffling\nnoise' which is introduced in every input sentence as a denoising strategy. To\ntest our hypothesis, we experiment by retraining UNMT models with a simple\n\\textit{retraining} strategy. We stop the training of the Denoising UNMT model\nafter a pre-decided number of iterations and resume the training for the\nremaining iterations -- which number is also pre-decided -- using original\nsentence as input without adding any noise. Our proposed solution achieves\nsignificant performance improvement UNMT models that train conventionally. We\ndemonstrate these performance gains on four language pairs, \\textit{viz.},\nEnglish-French, English-German, English-Spanish, Hindi-Punjabi. Our qualitative\nand quantitative analysis shows that the retraining strategy helps achieve\nbetter alignment as observed by attention heatmap and better phrasal\ntranslation, leading to statistically significant improvement in BLEU scores.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 12:22:37 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 10:57:15 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Banerjee", "Tamali", ""], ["Murthy", "Rudra", "V"], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1911.01214", "submitter": "Andreas Hanselowski Dr.", "authors": "Andreas Hanselowski, Christian Stab, Claudia Schulz, Zile Li, Iryna\n  Gurevych", "title": "A Richly Annotated Corpus for Different Tasks in Automated Fact-Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated fact-checking based on machine learning is a promising approach to\nidentify false information distributed on the web. In order to achieve\nsatisfactory performance, machine learning methods require a large corpus with\nreliable annotations for the different tasks in the fact-checking process.\nHaving analyzed existing fact-checking corpora, we found that none of them\nmeets these criteria in full. They are either too small in size, do not provide\ndetailed annotations, or are limited to a single domain. Motivated by this gap,\nwe present a new substantially sized mixed-domain corpus with annotations of\ngood quality for the core fact-checking tasks: document retrieval, evidence\nextraction, stance detection, and claim validation. To aid future corpus\nconstruction, we describe our methodology for corpus creation and annotation,\nand demonstrate that it results in substantial inter-annotator agreement. As\nbaselines for future research, we perform experiments on our corpus with a\nnumber of model architectures that reach high performance in similar problem\nsettings. Finally, to support the development of future models, we provide a\ndetailed error analysis for each of the tasks. Our results show that the\nrealistic, multi-domain setting defined by our data poses new challenges for\nthe existing models, providing opportunities for considerable improvement by\nfuture systems.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 16:07:12 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Hanselowski", "Andreas", ""], ["Stab", "Christian", ""], ["Schulz", "Claudia", ""], ["Li", "Zile", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1911.01217", "submitter": "Nikhil Oswal", "authors": "Deepshi Mediratta and Nikhil Oswal", "title": "Detect Toxic Content to Improve Online Conversations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media is filled with toxic content. The aim of this paper is to build\na model that can detect insincere questions. We use the 'Quora Insincere\nQuestions Classification' dataset for our analysis. The dataset is composed of\nsincere and insincere questions, with the majority of sincere questions. The\ndataset is processed and analyzed using Python and its libraries such as\nsklearn, numpy, pandas, keras etc. The dataset is converted to vector form\nusing word embeddings such as GloVe, Wiki-news and TF-IDF. The imbalance in the\ndataset is handled by resampling techniques. We train and compare various\nmachine learning and deep learning models to come up with the best results.\nModels discussed include SVM, Naive Bayes, GRU and LSTM.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 01:42:22 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Mediratta", "Deepshi", ""], ["Oswal", "Nikhil", ""]]}, {"id": "1911.01226", "submitter": "Ruibin Ma", "authors": "Ruibin Ma and Po-Hsuan Cameron Chen and Gang Li and Wei-Hung Weng and\n  Angela Lin and Krishna Gadepalli and Yuannan Cai", "title": "Human-centric Metric for Accelerating Pathology Reports Annotation", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pathology reports contain useful information such as the main involved organ,\ndiagnosis, etc. These information can be identified from the free text reports\nand used for large-scale statistical analysis or serve as annotation for other\nmodalities such as pathology slides images. However, manual classification for\na huge number of reports on multiple tasks is labor-intensive. In this paper,\nwe have developed an automatic text classifier based on BERT and we propose a\nhuman-centric metric to evaluate the model. According to the model confidence,\nwe identify low-confidence cases that require further expert annotation and\nhigh-confidence cases that are automatically classified. We report the\npercentage of low-confidence cases and the performance of automatically\nclassified cases. On the high-confidence cases, the model achieves\nclassification accuracy comparable to pathologists. This leads a potential of\nreducing 80% to 98% of the manual annotation workload.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 22:09:19 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 15:12:45 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Ma", "Ruibin", ""], ["Chen", "Po-Hsuan Cameron", ""], ["Li", "Gang", ""], ["Weng", "Wei-Hung", ""], ["Lin", "Angela", ""], ["Gadepalli", "Krishna", ""], ["Cai", "Yuannan", ""]]}, {"id": "1911.01248", "submitter": "Diego Moussallem", "authors": "Axel-Cyrille Ngonga Ngomo and Diego Moussallem and Lorenz B\\\"uhmann", "title": "A Holistic Natural Language Generation Framework for the Semantic Web", "comments": "International Conference Recent Advances in Natural Language\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the ever-growing generation of data for the Semantic Web comes an\nincreasing demand for this data to be made available to non-semantic Web\nexperts. One way of achieving this goal is to translate the languages of the\nSemantic Web into natural language. We present LD2NL, a framework for\nverbalizing the three key languages of the Semantic Web, i.e., RDF, OWL, and\nSPARQL. Our framework is based on a bottom-up approach to verbalization. We\nevaluated LD2NL in an open survey with 86 persons. Our results suggest that our\nframework can generate verbalizations that are close to natural languages and\nthat can be easily understood by non-experts. Therewith, it enables non-domain\nexperts to interpret Semantic Web data with more than 91\\% of the accuracy of\ndomain experts.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 14:35:59 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Ngomo", "Axel-Cyrille Ngonga", ""], ["Moussallem", "Diego", ""], ["B\u00fchmann", "Lorenz", ""]]}, {"id": "1911.01256", "submitter": "Arijit Das", "authors": "Arijit Das and Diganta Saha", "title": "A Novel Approach to Enhance the Performance of Semantic Search in\n  Bengali using Neural Net and other Classification Techniques", "comments": "12 pages, 5 figures", "journal-ref": "IJEAT Vol 9 Issue 3 year 2020 ISSN 2249-8958", "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search has for a long time been an important tool for users to retrieve\ninformation. Syntactic search is matching documents or objects containing\nspecific keywords like user-history, location, preference etc. to improve the\nresults. However, it is often possible that the query and the best answer have\nno term or very less number of terms in common and syntactic search can not\nperform properly in such cases. Semantic search, on the other hand, resolves\nthese issues but suffers from lack of annotation, absence of WordNet in case of\nlow resource languages. In this work, we have demonstrated an end to end\nprocedure to improve the performance of semantic search using semi-supervised\nand unsupervised learning algorithms. An available Bengali repository was\nchosen to have seven types of semantic properties primarily to develop the\nsystem. Performance has been tested using Support Vector Machine, Naive Bayes,\nDecision Tree and Artificial Neural Network (ANN). Our system has achieved the\nefficiency to predict the correct semantics using knowledge base over the time\nof learning. A repository containing around a million sentences, a product of\nTDIL project of Govt. of India, was used to test our system at first instance.\nThen the testing has been done for other languages. Being a cognitive system it\nmay be very useful for improving user satisfaction in e-Governance or\nm-Governance in the multilingual environment and also for other applications.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 14:47:33 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 18:22:01 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Das", "Arijit", ""], ["Saha", "Diganta", ""]]}, {"id": "1911.01324", "submitter": "Bennett Kleinberg", "authors": "Bennett Kleinberg and Paul McFarlane", "title": "Examining UK drill music through sentiment trajectory analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents how techniques from natural language processing can be\nused to examine the sentiment trajectories of gang-related drill music in the\nUnited Kingdom (UK). This work is important because key public figures are\nloosely making controversial linkages between drill music and recent\nescalations in youth violence in London. Thus, this paper examines the dynamic\nuse of sentiment in gang-related drill music lyrics. The findings suggest two\ndistinct sentiment use patterns and statistical analyses revealed that lyrics\nwith a markedly positive tone attract more views and engagement on YouTube than\nnegative ones. Our work provides the first empirical insights into the language\nuse of London drill music, and it can, therefore, be used in future studies and\nby policymakers to help understand the alleged drill-gang nexus.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 16:39:21 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Kleinberg", "Bennett", ""], ["McFarlane", "Paul", ""]]}, {"id": "1911.01352", "submitter": "Ziqi Wang", "authors": "Ziqi Wang, Yujia Qin, Wenxuan Zhou, Jun Yan, Qinyuan Ye, Leonardo\n  Neves, Zhiyuan Liu, Xiang Ren", "title": "Learning from Explanations with Neural Execution Tree", "comments": "18 pages, 8 figures, 12 tables. Published as a conference paper at\n  ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep neural networks have achieved impressive performance on a range of\nNLP tasks, these data-hungry models heavily rely on labeled data, which\nrestricts their applications in scenarios where data annotation is expensive.\nNatural language (NL) explanations have been demonstrated very useful\nadditional supervision, which can provide sufficient domain knowledge for\ngenerating more labeled data over new instances, while the annotation time only\ndoubles. However, directly applying them for augmenting model learning\nencounters two challenges: (1) NL explanations are unstructured and inherently\ncompositional, which asks for a modularized model to represent their semantics,\n(2) NL explanations often have large numbers of linguistic variants, resulting\nin low recall and limited generalization ability. In this paper, we propose a\nnovel Neural Execution Tree (NExT) framework to augment training data for text\nclassification using NL explanations. After transforming NL explanations into\nexecutable logical forms by semantic parsing, NExT generalizes different types\nof actions specified by the logical forms for labeling data instances, which\nsubstantially increases the coverage of each NL explanation. Experiments on two\nNLP tasks (relation extraction and sentiment analysis) demonstrate its\nsuperiority over baseline methods. Its extension to multi-hop question\nanswering achieves performance gain with light annotation effort.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 17:31:02 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 03:13:16 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 10:59:51 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Wang", "Ziqi", ""], ["Qin", "Yujia", ""], ["Zhou", "Wenxuan", ""], ["Yan", "Jun", ""], ["Ye", "Qinyuan", ""], ["Neves", "Leonardo", ""], ["Liu", "Zhiyuan", ""], ["Ren", "Xiang", ""]]}, {"id": "1911.01371", "submitter": "Giuliano Tortoreto", "authors": "Giuliano Tortoreto, Evgeny A. Stepanov, Alessandra Cervone, Mateusz\n  Dubiel, Giuseppe Riccardi", "title": "Affective Behaviour Analysis of On-line User Interactions: Are On-line\n  Support Groups more Therapeutic than Twitter?", "comments": null, "journal-ref": null, "doi": "10.18653/v1/W19-3211", "report-no": null, "categories": "cs.HC cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The increase in the prevalence of mental health problems has coincided with a\ngrowing popularity of health related social networking sites. Regardless of\ntheir therapeutic potential, On-line Support Groups (OSGs) can also have\nnegative effects on patients. In this work we propose a novel methodology to\nautomatically verify the presence of therapeutic factors in social networking\nwebsites by using Natural Language Processing (NLP) techniques. The methodology\nis evaluated on On-line asynchronous multi-party conversations collected from\nan OSG and Twitter. The results of the analysis indicate that therapeutic\nfactors occur more frequently in OSG conversations than in Twitter\nconversations. Moreover, the analysis of OSG conversations reveals that the\nusers of that platform are supportive, and interactions are likely to lead to\nthe improvement of their emotional state. We believe that our method provides a\nstepping stone towards automatic analysis of emotional states of users of\nonline platforms. Possible applications of the method include provision of\nguidelines that highlight potential implications of using such platforms on\nusers' mental health, and/or support in the analysis of their impact on\nspecific individuals.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 17:59:18 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Tortoreto", "Giuliano", ""], ["Stepanov", "Evgeny A.", ""], ["Cervone", "Alessandra", ""], ["Dubiel", "Mateusz", ""], ["Riccardi", "Giuseppe", ""]]}, {"id": "1911.01421", "submitter": "Sunil Kumar Kopparapu Dr", "authors": "Bansi Shah and Sunil Kumar Kopparapu", "title": "A Deep Learning approach for Hindi Named Entity Recognition", "comments": "7 pages; work done during internship at TCS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named Entity Recognition is one of the most important text processing\nrequirement in many NLP tasks. In this paper we use a deep architecture to\naccomplish the task of recognizing named entities in a given Hindi text\nsentence. Bidirectional Long Short Term Memory (BiLSTM) based techniques have\nbeen used for NER task in literature. In this paper, we first tune BiLSTM\nlow-resource scenario to work for Hindi NER and propose two enhancements namely\n(a) de-noising auto-encoder (DAE) LSTM and (b) conditioning LSTM which show\nimprovement in NER task compared to the BiLSTM approach. We use pre-trained\nword embedding to represent the words in the corpus, and the NER tags of the\nwords are as defined by the used annotated corpora. Experiments have been\nperformed to analyze the performance of different word embeddings and batch\nsizes which is essential for training deep models.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 05:47:22 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Shah", "Bansi", ""], ["Kopparapu", "Sunil Kumar", ""]]}, {"id": "1911.01456", "submitter": "Sarik Ghazarian", "authors": "Sarik Ghazarian, Ralph Weischedel, Aram Galstyan, Nanyun Peng", "title": "Predictive Engagement: An Efficient Metric For Automatic Evaluation of\n  Open-Domain Dialogue Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User engagement is a critical metric for evaluating the quality of\nopen-domain dialogue systems. Prior work has focused on conversation-level\nengagement by using heuristically constructed features such as the number of\nturns and the total time of the conversation. In this paper, we investigate the\npossibility and efficacy of estimating utterance-level engagement and define a\nnovel metric, {\\em predictive engagement}, for automatic evaluation of\nopen-domain dialogue systems. Our experiments demonstrate that (1) human\nannotators have high agreement on assessing utterance-level engagement scores;\n(2) conversation-level engagement scores can be predicted from properly\naggregated utterance-level engagement scores. Furthermore, we show that the\nutterance-level engagement scores can be learned from data. These scores can\nimprove automatic evaluation metrics for open-domain dialogue systems, as shown\nby correlation with human judgements. This suggests that predictive engagement\ncan be used as a real-time feedback for training better dialogue models.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 19:21:48 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 17:01:19 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Ghazarian", "Sarik", ""], ["Weischedel", "Ralph", ""], ["Galstyan", "Aram", ""], ["Peng", "Nanyun", ""]]}, {"id": "1911.01460", "submitter": "Hu Xu", "authors": "Hu Xu, Bing Liu, Lei Shu and Philip S. Yu", "title": "A Failure of Aspect Sentiment Classifiers and an Adaptive Re-weighting\n  Solution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-based sentiment classification (ASC) is an important task in\nfine-grained sentiment analysis.~Deep supervised ASC approaches typically model\nthis task as a pair-wise classification task that takes an aspect and a\nsentence containing the aspect and outputs the polarity of the aspect in that\nsentence. However, we discovered that many existing approaches fail to learn an\neffective ASC classifier but more like a sentence-level sentiment classifier\nbecause they have difficulty to handle sentences with different polarities for\ndifferent aspects.~This paper first demonstrates this problem using several\nstate-of-the-art ASC models. It then proposes a novel and general adaptive\nre-weighting (ARW) scheme to adjust the training to dramatically improve ASC\nfor such complex sentences. Experimental results show that the proposed\nframework is effective \\footnote{The dataset and code are available at\n\\url{https://github.com/howardhsu/ASC_failure}.}.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 19:27:50 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Xu", "Hu", ""], ["Liu", "Bing", ""], ["Shu", "Lei", ""], ["Yu", "Philip S.", ""]]}, {"id": "1911.01464", "submitter": "Shijie Wu", "authors": "Shijie Wu and Alexis Conneau and Haoran Li and Luke Zettlemoyer and\n  Veselin Stoyanov", "title": "Emerging Cross-lingual Structure in Pretrained Language Models", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of multilingual masked language modeling, i.e. the\ntraining of a single model on concatenated text from multiple languages, and\npresent a detailed study of several factors that influence why these models are\nso effective for cross-lingual transfer. We show, contrary to what was\npreviously hypothesized, that transfer is possible even when there is no shared\nvocabulary across the monolingual corpora and also when the text comes from\nvery different domains. The only requirement is that there are some shared\nparameters in the top layers of the multi-lingual encoder. To better understand\nthis result, we also show that representations from independently trained\nmodels in different languages can be aligned post-hoc quite effectively,\nstrongly suggesting that, much like for non-contextual word embeddings, there\nare universal latent symmetries in the learned embedding spaces. For\nmultilingual masked language modeling, these symmetries seem to be\nautomatically discovered and aligned during the joint training process.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 19:41:13 GMT"}, {"version": "v2", "created": "Sun, 10 Nov 2019 06:55:02 GMT"}, {"version": "v3", "created": "Thu, 7 May 2020 18:13:08 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Wu", "Shijie", ""], ["Conneau", "Alexis", ""], ["Li", "Haoran", ""], ["Zettlemoyer", "Luke", ""], ["Stoyanov", "Veselin", ""]]}, {"id": "1911.01474", "submitter": "Alborz Rezazadeh Sereshkeh", "authors": "Alborz Rezazadeh Sereshkeh, Gary Leung, Krish Perumal, Caleb Phillips,\n  Minfan Zhang, Afsaneh Fazly, Iqbal Mohomed", "title": "VASTA: A Vision and Language-assisted Smartphone Task Automation System", "comments": "Submitted to ACM IUI'20, 10 figures, 11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present VASTA, a novel vision and language-assisted Programming By\nDemonstration (PBD) system for smartphone task automation. Development of a\nrobust PBD automation system requires overcoming three key challenges: first,\nhow to make a particular demonstration robust to positional and visual changes\nin the user interface (UI) elements; secondly, how to recognize changes in the\nautomation parameters to make the demonstration as generalizable as possible;\nand thirdly, how to recognize from the user utterance what automation the user\nwishes to carry out. To address the first challenge, VASTA leverages\nstate-of-the-art computer vision techniques, including object detection and\noptical character recognition, to accurately label interactions demonstrated by\na user, without relying on the underlying UI structures. To address the second\nand third challenges, VASTA takes advantage of advanced natural language\nunderstanding algorithms for analyzing the user utterance to trigger the VASTA\nautomation scripts, and to determine the automation parameters for\ngeneralization. We run an initial user study that demonstrates the\neffectiveness of VASTA at clustering user utterances, understanding changes in\nthe automation parameters, detecting desired UI elements, and, most\nimportantly, automating various tasks. A demo video of the system is available\nhere: http://y2u.be/kr2xE-FixjI\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 20:21:32 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Sereshkeh", "Alborz Rezazadeh", ""], ["Leung", "Gary", ""], ["Perumal", "Krish", ""], ["Phillips", "Caleb", ""], ["Zhang", "Minfan", ""], ["Fazly", "Afsaneh", ""], ["Mohomed", "Iqbal", ""]]}, {"id": "1911.01485", "submitter": "Yi Chern Tan", "authors": "Yi Chern Tan, L. Elisa Celis", "title": "Assessing Social and Intersectional Biases in Contextualized Word\n  Representations", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social bias in machine learning has drawn significant attention, with work\nranging from demonstrations of bias in a multitude of applications, curating\ndefinitions of fairness for different contexts, to developing algorithms to\nmitigate bias. In natural language processing, gender bias has been shown to\nexist in context-free word embeddings. Recently, contextual word\nrepresentations have outperformed word embeddings in several downstream NLP\ntasks. These word representations are conditioned on their context within a\nsentence, and can also be used to encode the entire sentence. In this paper, we\nanalyze the extent to which state-of-the-art models for contextual word\nrepresentations, such as BERT and GPT-2, encode biases with respect to gender,\nrace, and intersectional identities. Towards this, we propose assessing bias at\nthe contextual word level. This novel approach captures the contextual effects\nof bias missing in context-free word embeddings, yet avoids confounding effects\nthat underestimate bias at the sentence encoding level. We demonstrate evidence\nof bias at the corpus level, find varying evidence of bias in embedding\nassociation tests, show in particular that racial bias is strongly encoded in\ncontextual word models, and observe that bias effects for intersectional\nminorities are exacerbated beyond their constituent minority identities.\nFurther, evaluating bias effects at the contextual word level captures biases\nthat are not captured at the sentence level, confirming the need for our novel\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 20:57:54 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Tan", "Yi Chern", ""], ["Celis", "L. Elisa", ""]]}, {"id": "1911.01497", "submitter": "Vikas Raunak", "authors": "Vikas Raunak, Vaibhav Kumar and Florian Metze", "title": "On Compositionality in Neural Machine Translation", "comments": "Accepted at Context and Compositionality Workshop, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate two specific manifestations of compositionality in Neural\nMachine Translation (NMT) : (1) Productivity - the ability of the model to\nextend its predictions beyond the observed length in training data and (2)\nSystematicity - the ability of the model to systematically recombine known\nparts and rules. We evaluate a standard Sequence to Sequence model on tests\ndesigned to assess these two properties in NMT. We quantitatively demonstrate\nthat inadequate temporal processing, in the form of poor encoder\nrepresentations is a bottleneck for both Productivity and Systematicity. We\npropose a simple pre-training mechanism which alleviates model performance on\nthe two properties and leads to a significant improvement in BLEU scores.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 21:31:36 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 21:18:08 GMT"}, {"version": "v3", "created": "Sat, 14 Dec 2019 15:10:47 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Raunak", "Vikas", ""], ["Kumar", "Vaibhav", ""], ["Metze", "Florian", ""]]}, {"id": "1911.01528", "submitter": "Jamshid Mozafari", "authors": "Jamshid Mozafari, Afsaneh Fatemi, Mohammad Ali Nematbakhsh", "title": "BAS: An Answer Selection Method Using BERT Language Model", "comments": "28 pages, 19 figures, 8 tables, Natural Language Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Question Answering systems have become more popular and\nwidely used by users. Despite the increasing popularity of these systems, the\ntheir performance is not even sufficient for textual data and requires further\nresearch. These systems consist of several parts that one of them is the Answer\nSelection component. This component detects the most relevant answer from a\nlist of candidate answers. The methods presented in previous researches have\nattempted to provide an independent model to undertake the answer-selection\ntask. An independent model cannot comprehend the syntactic and semantic\nfeatures of questions and answers with a small training dataset. To fill this\ngap, language models can be employed in implementing the answer selection part.\nThis action enables the model to have a better understanding of the language in\norder to understand questions and answers better than previous works. In this\nresearch, we will present the \"BAS\" (BERT Answer Selection) that uses the BERT\nlanguage model to comprehend language. The empirical results of applying the\nmodel on the TrecQA Raw, TrecQA Clean, and WikiQA datasets demonstrate that\nusing a robust language model such as BERT can enhance the performance. Using a\nmore robust classifier also enhances the effect of the language model on the\nanswer selection component. The results demonstrate that language comprehension\nis an essential requirement in natural language processing tasks such as\nanswer-selection.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 23:16:47 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 19:31:09 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 14:20:01 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Mozafari", "Jamshid", ""], ["Fatemi", "Afsaneh", ""], ["Nematbakhsh", "Mohammad Ali", ""]]}, {"id": "1911.01542", "submitter": "Florian Heimerl", "authors": "Florian Heimerl, Christoph Kralj, Torsten M\\\"oller, Michael Gleicher", "title": "embComp: Visual Interactive Comparison of Vector Embeddings", "comments": "published in IEEE Transactions on Visualization and Computer Graphics\n  (2020)", "journal-ref": null, "doi": "10.1109/TVCG.2020.3045918", "report-no": null, "categories": "cs.HC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces embComp, a novel approach for comparing two embeddings\nthat capture the similarity between objects, such as word and document\nembeddings. We survey scenarios where comparing these embedding spaces is\nuseful. From those scenarios, we derive common tasks, introduce visual analysis\nmethods that support these tasks, and combine them into a comprehensive system.\nOne of embComp's central features are overview visualizations that are based on\nmetrics for measuring differences in the local structure around objects.\nSummarizing these local metrics over the embeddings provides global overviews\nof similarities and differences. Detail views allow comparison of the local\nstructure around selected objects and relating this local information to the\nglobal views. Integrating and connecting all of these components, embComp\nsupports a range of analysis workflows that help understand similarities and\ndifferences between embedding spaces. We assess our approach by applying it in\nseveral use cases, including understanding corpora differences via word vector\nembeddings, and understanding algorithmic differences in generating embeddings.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 00:06:41 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 00:44:34 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Heimerl", "Florian", ""], ["Kralj", "Christoph", ""], ["M\u00f6ller", "Torsten", ""], ["Gleicher", "Michael", ""]]}, {"id": "1911.01556", "submitter": "Qian Yu", "authors": "Qian Yu, Lidong Bing, Qiong Zhang, Wai Lam, Luo Si", "title": "Review-based Question Generation with Adaptive Instance Transfer and\n  Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online reviews provide rich information about products and service, while it\nremains inefficient for potential consumers to exploit the reviews for\nfulfilling their specific information need. We propose to explore question\ngeneration as a new way of exploiting review information. One major challenge\nof this task is the lack of review-question pairs for training a neural\ngeneration model. We propose an iterative learning framework for handling this\nchallenge via adaptive transfer and augmentation of the training instances with\nthe help of the available user-posed question-answer data. To capture the\naspect characteristics in reviews, the augmentation and generation procedures\nincorporate related features extracted via unsupervised learning. Experiments\non data from 10 categories of a popular E-commerce site demonstrate the\neffectiveness of the framework, as well as the usefulness of the new task.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 01:19:50 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 04:11:31 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Yu", "Qian", ""], ["Bing", "Lidong", ""], ["Zhang", "Qiong", ""], ["Lam", "Wai", ""], ["Si", "Luo", ""]]}, {"id": "1911.01597", "submitter": "Yong Shan", "authors": "Yong Shan, Yang Feng, Jinchao Zhang, Fandong Meng, Wen Zhang", "title": "Improving Bidirectional Decoding with Dynamic Target Semantics in Neural\n  Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generally, Neural Machine Translation models generate target words in a\nleft-to-right (L2R) manner and fail to exploit any future (right) semantics\ninformation, which usually produces an unbalanced translation. Recent works\nattempt to utilize the right-to-left (R2L) decoder in bidirectional decoding to\nalleviate this problem. In this paper, we propose a novel \\textbf{D}ynamic\n\\textbf{I}nteraction \\textbf{M}odule (\\textbf{DIM}) to dynamically exploit\ntarget semantics from R2L translation for enhancing the L2R translation\nquality. Different from other bidirectional decoding approaches, DIM firstly\nextracts helpful target information through addressing and reading operations,\nthen updates target semantics for tracking the interactive history.\nAdditionally, we further introduce an \\textbf{agreement regularization} term\ninto the training objective to narrow the gap between L2R and R2L translations.\nExperimental results on NIST Chinese$\\Rightarrow$English and WMT'16\nEnglish$\\Rightarrow$Romanian translation tasks show that our system achieves\nsignificant improvements over baseline systems, which also reaches comparable\nresults compared to the state-of-the-art Transformer model with much fewer\nparameters of it.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 03:43:14 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Shan", "Yong", ""], ["Feng", "Yang", ""], ["Zhang", "Jinchao", ""], ["Meng", "Fandong", ""], ["Zhang", "Wen", ""]]}, {"id": "1911.01599", "submitter": "Nikolai Rozanov", "authors": "Edward Collins, Nikolai Rozanov, Bingbing Zhang", "title": "LIDA: Lightweight Interactive Dialogue Annotator", "comments": "9 pages, 7 figures, 1 table, EMNLP 2019", "journal-ref": "ACL, EMNLP(D19-3021), 121--126, (2019)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dialogue systems have the potential to change how people interact with\nmachines but are highly dependent on the quality of the data used to train\nthem. It is therefore important to develop good dialogue annotation tools which\ncan improve the speed and quality of dialogue data annotation. With this in\nmind, we introduce LIDA, an annotation tool designed specifically for\nconversation data. As far as we know, LIDA is the first dialogue annotation\nsystem that handles the entire dialogue annotation pipeline from raw text, as\nmay be the output of transcription services, to structured conversation data.\nFurthermore it supports the integration of arbitrary machine learning models as\nannotation recommenders and also has a dedicated interface to resolve\ninter-annotator disagreements such as after crowdsourcing annotations for a\ndataset. LIDA is fully open source, documented and publicly available [\nhttps://github.com/Wluper/lida ]\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 03:49:20 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Collins", "Edward", ""], ["Rozanov", "Nikolai", ""], ["Zhang", "Bingbing", ""]]}, {"id": "1911.01600", "submitter": "Hamada Nayel", "authors": "Hamada A. Nayel and Shashrekha H. L", "title": "Integrating Dictionary Feature into A Deep Learning Model for Disease\n  Named Entity Recognition", "comments": "16 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, Deep Learning (DL) models are becoming important due to\ntheir demonstrated success at overcoming complex learning problems. DL models\nhave been applied effectively for different Natural Language Processing (NLP)\ntasks such as part-of-Speech (PoS) tagging and Machine Translation (MT).\nDisease Named Entity Recognition (Disease-NER) is a crucial task which aims at\nextracting disease Named Entities (NEs) from text. In this paper, a DL model\nfor Disease-NER using dictionary information is proposed and evaluated on\nNational Center for Biotechnology Information (NCBI) disease corpus and BC5CDR\ndataset. Word embeddings trained over general domain texts as well as\nbiomedical texts have been used to represent input to the proposed model. This\nstudy also compares two different Segment Representation (SR) schemes, namely\nIOB2 and IOBES for Disease-NER. The results illustrate that using dictionary\ninformation, pre-trained word embeddings, character embeddings and CRF with\nglobal score improves the performance of Disease-NER system.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 03:50:16 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Nayel", "Hamada A.", ""], ["L", "Shashrekha H.", ""]]}, {"id": "1911.01616", "submitter": "Haiyun Peng", "authors": "Haiyun Peng, Lu Xu, Lidong Bing, Fei Huang, Wei Lu, Luo Si", "title": "Knowing What, How and Why: A Near Complete Solution for Aspect-based\n  Sentiment Analysis", "comments": "This paper is accepted in AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Target-based sentiment analysis or aspect-based sentiment analysis (ABSA)\nrefers to addressing various sentiment analysis tasks at a fine-grained level,\nwhich includes but is not limited to aspect extraction, aspect sentiment\nclassification, and opinion extraction. There exist many solvers of the above\nindividual subtasks or a combination of two subtasks, and they can work\ntogether to tell a complete story, i.e. the discussed aspect, the sentiment on\nit, and the cause of the sentiment. However, no previous ABSA research tried to\nprovide a complete solution in one shot. In this paper, we introduce a new\nsubtask under ABSA, named aspect sentiment triplet extraction (ASTE).\nParticularly, a solver of this task needs to extract triplets (What, How, Why)\nfrom the inputs, which show WHAT the targeted aspects are, HOW their sentiment\npolarities are and WHY they have such polarities (i.e. opinion reasons). For\ninstance, one triplet from \"Waiters are very friendly and the pasta is simply\naverage\" could be ('Waiters', positive, 'friendly'). We propose a two-stage\nframework to address this task. The first stage predicts what, how and why in a\nunified model, and then the second stage pairs up the predicted what (how) and\nwhy from the first stage to output triplets. In the experiments, our framework\nhas set a benchmark performance in this novel triplet extraction task.\nMeanwhile, it outperforms a few strong baselines adapted from state-of-the-art\nrelated methods.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 04:36:52 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 05:26:04 GMT"}, {"version": "v3", "created": "Wed, 20 Nov 2019 10:58:12 GMT"}, {"version": "v4", "created": "Thu, 21 Nov 2019 08:14:13 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Peng", "Haiyun", ""], ["Xu", "Lu", ""], ["Bing", "Lidong", ""], ["Huang", "Fei", ""], ["Lu", "Wei", ""], ["Si", "Luo", ""]]}, {"id": "1911.01621", "submitter": "Lu Ji", "authors": "Lu Ji, Zhongyu Wei, Jing Li, Qi Zhang, Xuanjing Huang", "title": "Discrete Argument Representation Learning for Interactive Argument Pair\n  Identification", "comments": "10 pages, 5 figures, 3 tables submitted for consideration of\n  publication to the IEEE Transactions on Audio, Speech, and Language\n  Processing, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on extracting interactive argument pairs from two\nposts with opposite stances to a certain topic. Considering opinions are\nexchanged from different perspectives of the discussing topic, we study the\ndiscrete representations for arguments to capture varying aspects in\nargumentation languages (e.g., the debate focus and the participant behavior).\nMoreover, we utilize hierarchical structure to model post-wise information\nincorporating contextual knowledge. Experimental results on the large-scale\ndataset collected from CMV show that our proposed framework can significantly\noutperform the competitive baselines. Further analyses reveal why our model\nyields superior performance and prove the usefulness of our learned\nrepresentations.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 05:08:08 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Ji", "Lu", ""], ["Wei", "Zhongyu", ""], ["Li", "Jing", ""], ["Zhang", "Qi", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1911.01622", "submitter": "Yuan Yao", "authors": "Yuan Yao, Haoxi Zhong, Zhengyan Zhang, Xu Han, Xiaozhi Wang, Chaojun\n  Xiao, Guoyang Zeng, Zhiyuan Liu and Maosong Sun", "title": "Adversarial Language Games for Advanced Natural Language Intelligence", "comments": "Accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of adversarial language games, in which multiple agents\nwith conflicting goals compete with each other via natural language\ninteractions. While adversarial language games are ubiquitous in human\nactivities, little attention has been devoted to this field in natural language\nprocessing. In this work, we propose a challenging adversarial language game\ncalled Adversarial Taboo as an example, in which an attacker and a defender\ncompete around a target word. The attacker is tasked with inducing the defender\nto utter the target word invisible to the defender, while the defender is\ntasked with detecting the target word before being induced by the attacker. In\nAdversarial Taboo, a successful attacker must hide its intention and subtly\ninduce the defender, while a competitive defender must be cautious with its\nutterances and infer the intention of the attacker. Such language abilities can\nfacilitate many important downstream NLP tasks. To instantiate the game, we\ncreate a game environment and a competition platform. Comprehensive experiments\nand empirical studies on several baseline attack and defense strategies show\npromising and interesting results. Based on the analysis on the game and\nexperiments, we discuss multiple promising directions for future research.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 05:14:08 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 14:00:45 GMT"}, {"version": "v3", "created": "Fri, 1 May 2020 02:51:04 GMT"}, {"version": "v4", "created": "Thu, 17 Dec 2020 06:07:51 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Yao", "Yuan", ""], ["Zhong", "Haoxi", ""], ["Zhang", "Zhengyan", ""], ["Han", "Xu", ""], ["Wang", "Xiaozhi", ""], ["Xiao", "Chaojun", ""], ["Zeng", "Guoyang", ""], ["Liu", "Zhiyuan", ""], ["Sun", "Maosong", ""]]}, {"id": "1911.01623", "submitter": "Xinyi Jiang", "authors": "Xinyi Jiang, Zhengzhe Yang, Jinho D. Choi", "title": "Incremental Sense Weight Training for the Interpretation of\n  Contextualized Word Embeddings", "comments": "Accepted to AAAI Conference on Artificial Intelligence: Student\n  Abstract and Poster Program, AAAI:SAP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel online algorithm that learns the essence of each dimension\nin word embeddings by minimizing the within-group distance of contextualized\nembedding groups. Three state-of-the-art neural-based language models are used,\nFlair, ELMo, and BERT, to generate contextualized word embeddings such that\ndifferent embeddings are generated for the same word type, which are grouped by\ntheir senses manually annotated in the SemCor dataset. We hypothesize that not\nall dimensions are equally important for downstream tasks so that our algorithm\ncan detect unessential dimensions and discard them without hurting the\nperformance. To verify this hypothesis, we first mask dimensions determined\nunessential by our algorithm, apply the masked word embeddings to a word sense\ndisambiguation task (WSD), and compare its performance against the one achieved\nby the original embeddings. Several KNN approaches are experimented to\nestablish strong baselines for WSD. Our results show that the masked word\nembeddings do not hurt the performance and can improve it by 3%. Our work can\nbe used to conduct future research on the interpretability of contextualized\nembeddings.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 05:14:54 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 02:56:25 GMT"}, {"version": "v3", "created": "Sat, 23 May 2020 18:04:41 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Jiang", "Xinyi", ""], ["Yang", "Zhengzhe", ""], ["Choi", "Jinho D.", ""]]}, {"id": "1911.01625", "submitter": "Wenye Li", "authors": "Wenye Li and Senyue Hao", "title": "Sparse Lifting of Dense Vectors: Unifying Word and Sentence\n  Representations", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the first step in automated natural language processing, representing\nwords and sentences is of central importance and has attracted significant\nresearch attention. Different approaches, from the early one-hot and\nbag-of-words representation to more recent distributional dense and sparse\nrepresentations, were proposed. Despite the successful results that have been\nachieved, such vectors tend to consist of uninterpretable components and face\nnontrivial challenge in both memory and computational requirement in practical\napplications. In this paper, we designed a novel representation model that\nprojects dense word vectors into a higher dimensional space and favors a highly\nsparse and binary representation of word vectors with potentially interpretable\ncomponents, while trying to maintain pairwise inner products between original\nvectors as much as possible. Computationally, our model is relaxed as a\nsymmetric non-negative matrix factorization problem which admits a fast yet\neffective solution. In a series of empirical evaluations, the proposed model\nexhibited consistent improvement and high potential in practical applications.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 05:28:05 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Li", "Wenye", ""], ["Hao", "Senyue", ""]]}, {"id": "1911.01629", "submitter": "Mahaveer Jain", "authors": "Mahaveer Jain, Kjell Schubert, Jay Mahadeokar, Ching-Feng Yeh,\n  Kaustubh Kalgaonkar, Anuroop Sriram, Christian Fuegen, Michael L. Seltzer", "title": "RNN-T For Latency Controlled ASR With Improved Beam Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural transducer-based systems such as RNN Transducers (RNN-T) for automatic\nspeech recognition (ASR) blend the individual components of a traditional\nhybrid ASR systems (acoustic model, language model, punctuation model, inverse\ntext normalization) into one single model. This greatly simplifies training and\ninference and hence makes RNN-T a desirable choice for ASR systems. In this\nwork, we investigate use of RNN-T in applications that require a tune-able\nlatency budget during inference time. We also improved the decoding speed of\nthe originally proposed RNN-T beam search algorithm. We evaluated our proposed\nsystem on English videos ASR dataset and show that neural RNN-T models can\nachieve comparable WER and better computational efficiency compared to a well\ntuned hybrid ASR baseline.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 05:46:52 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 15:45:47 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Jain", "Mahaveer", ""], ["Schubert", "Kjell", ""], ["Mahadeokar", "Jay", ""], ["Yeh", "Ching-Feng", ""], ["Kalgaonkar", "Kaustubh", ""], ["Sriram", "Anuroop", ""], ["Fuegen", "Christian", ""], ["Seltzer", "Michael L.", ""]]}, {"id": "1911.01678", "submitter": "Amir Pouran Ben Veyseh", "authors": "Amir Pouran Ben Veyseh, Franck Dernoncourt, Dejing Dou, Thien Huu\n  Nguyen", "title": "A Joint Model for Definition Extraction with Syntactic Connection and\n  Semantic Consistency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Definition Extraction (DE) is one of the well-known topics in Information\nExtraction that aims to identify terms and their corresponding definitions in\nunstructured texts. This task can be formalized either as a sentence\nclassification task (i.e., containing term-definition pairs or not) or a\nsequential labeling task (i.e., identifying the boundaries of the terms and\ndefinitions). The previous works for DE have only focused on one of the two\napproaches, failing to model the inter-dependencies between the two tasks. In\nthis work, we propose a novel model for DE that simultaneously performs the two\ntasks in a single framework to benefit from their inter-dependencies. Our model\nfeatures deep learning architectures to exploit the global structures of the\ninput sentences as well as the semantic consistencies between the terms and the\ndefinitions, thereby improving the quality of the representation vectors for\nDE. Besides the joint inference between sentence classification and sequential\nlabeling, the proposed model is fundamentally different from the prior work for\nDE in that the prior work has only employed the local structures of the input\nsentences (i.e., word-to-word relations), and not yet considered the semantic\nconsistencies between terms and definitions. In order to implement these novel\nideas, our model presents a multi-task learning framework that employs graph\nconvolutional neural networks and predicts the dependency paths between the\nterms and the definitions. We also seek to enforce the consistency between the\nrepresentations of the terms and definitions both globally (i.e., increasing\nsemantic consistency between the representations of the entire sentences and\nthe terms/definitions) and locally (i.e., promoting the similarity between the\nrepresentations of the terms and the definitions).\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 09:23:58 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 20:28:01 GMT"}, {"version": "v3", "created": "Sun, 17 Nov 2019 23:54:37 GMT"}, {"version": "v4", "created": "Wed, 29 Apr 2020 19:24:15 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Veyseh", "Amir Pouran Ben", ""], ["Dernoncourt", "Franck", ""], ["Dou", "Dejing", ""], ["Nguyen", "Thien Huu", ""]]}, {"id": "1911.01680", "submitter": "Amir Pouran Ben Veyseh", "authors": "Amir Pouran Ben Veyseh, Franck Dernoncourt, Thien Huu Nguyen", "title": "Improving Slot Filling by Utilizing Contextual Information", "comments": "Accepted at NLP4ConvAI Workshop at ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Slot Filling (SF) is one of the sub-tasks of Spoken Language Understanding\n(SLU) which aims to extract semantic constituents from a given natural language\nutterance. It is formulated as a sequence labeling task. Recently, it has been\nshown that contextual information is vital for this task. However, existing\nmodels employ contextual information in a restricted manner, e.g., using\nself-attention. Such methods fail to distinguish the effects of the context on\nthe word representation and the word label. To address this issue, in this\npaper, we propose a novel method to incorporate the contextual information in\ntwo different levels, i.e., representation level and task-specific (i.e.,\nlabel) level. Our extensive experiments on three benchmark datasets on SF show\nthe effectiveness of our model leading to new state-of-the-art results on all\nthree benchmark datasets for the task of SF.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 09:29:07 GMT"}, {"version": "v2", "created": "Sat, 30 May 2020 06:32:43 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Veyseh", "Amir Pouran Ben", ""], ["Dernoncourt", "Franck", ""], ["Nguyen", "Thien Huu", ""]]}, {"id": "1911.01702", "submitter": "Johannes Rausch", "authors": "Johannes Rausch, Octavio Martinez, Fabian Bissig, Ce Zhang, Stefan\n  Feuerriegel", "title": "DocParser: Hierarchical Structure Parsing of Document Renderings", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Translating renderings (e. g. PDFs, scans) into hierarchical document\nstructures is extensively demanded in the daily routines of many real-world\napplications. However, a holistic, principled approach to inferring the\ncomplete hierarchical structure of documents is missing. As a remedy, we\ndeveloped \"DocParser\": an end-to-end system for parsing the complete document\nstructure - including all text elements, nested figures, tables, and table cell\nstructures. Our second contribution is to provide a dataset for evaluating\nhierarchical document structure parsing. Our third contribution is to propose a\nscalable learning framework for settings where domain-specific data are scarce,\nwhich we address by a novel approach to weak supervision that significantly\nimproves the document structure parsing performance. Our experiments confirm\nthe effectiveness of our proposed weak supervision: Compared to the baseline\nwithout weak supervision, it improves the mean average precision for detecting\ndocument entities by 39.1 % and improves the F1 score of classifying\nhierarchical relations by 35.8 %.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 10:42:08 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 11:54:38 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Rausch", "Johannes", ""], ["Martinez", "Octavio", ""], ["Bissig", "Fabian", ""], ["Zhang", "Ce", ""], ["Feuerriegel", "Stefan", ""]]}, {"id": "1911.01746", "submitter": "Jiwei Li", "authors": "Wei Wu, Fei Wang, Arianna Yuan, Fei Wu, Jiwei Li", "title": "Coreference Resolution as Query-based Span Prediction", "comments": null, "journal-ref": "ACL2020", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present an accurate and extensible approach for the\ncoreference resolution task. We formulate the problem as a span prediction\ntask, like in machine reading comprehension (MRC): A query is generated for\neach candidate mention using its surrounding context, and a span prediction\nmodule is employed to extract the text spans of the coreferences within the\ndocument using the generated query. This formulation comes with the following\nkey advantages: (1) The span prediction strategy provides the flexibility of\nretrieving mentions left out at the mention proposal stage; (2) In the MRC\nframework, encoding the mention and its context explicitly in a query makes it\npossible to have a deep and thorough examination of cues embedded in the\ncontext of coreferent mentions; and (3) A plethora of existing MRC datasets can\nbe used for data augmentation to improve the model's generalization capability.\nExperiments demonstrate significant performance boost over previous models,\nwith 87.5 (+2.5) F1 score on the GAP benchmark and 83.1 (+3.5) F1 score on the\nCoNLL-2012 benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 12:44:36 GMT"}, {"version": "v2", "created": "Sun, 21 Jun 2020 07:15:00 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 04:19:18 GMT"}, {"version": "v4", "created": "Sat, 18 Jul 2020 05:05:55 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Wu", "Wei", ""], ["Wang", "Fei", ""], ["Yuan", "Arianna", ""], ["Wu", "Fei", ""], ["Li", "Jiwei", ""]]}, {"id": "1911.01770", "submitter": "Matthias Fontanellaz", "authors": "Matthias Fontanellaz and Stergios Christodoulidis and Stavroula\n  Mougiakakou", "title": "Self-Attention and Ingredient-Attention Based Model for Recipe Retrieval\n  from Image Queries", "comments": "MADiMa 2019,5th International Workshop on Multimedia Assisted Dietary\n  Management", "journal-ref": null, "doi": "10.1145/3347448.3357163", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Direct computer vision based-nutrient content estimation is a demanding task,\ndue to deformation and occlusions of ingredients, as well as high intra-class\nand low inter-class variability between meal classes. In order to tackle these\nissues, we propose a system for recipe retrieval from images. The recipe\ninformation can subsequently be used to estimate the nutrient content of the\nmeal. In this study, we utilize the multi-modal Recipe1M dataset, which\ncontains over 1 million recipes accompanied by over 13 million images. The\nproposed model can operate as a first step in an automatic pipeline for the\nestimation of nutrition content by supporting hints related to ingredient and\ninstruction. Through self-attention, our model can directly process raw recipe\ntext, making the upstream instruction sentence embedding process redundant and\nthus reducing training time, while providing desirable retrieval results.\nFurthermore, we propose the use of an ingredient attention mechanism, in order\nto gain insight into which instructions, parts of instructions or single\ninstruction words are of importance for processing a single ingredient within a\ncertain recipe. Attention-based recipe text encoding contributes to solving the\nissue of high intra-class/low inter-class variability by focusing on\npreparation steps specific to the meal. The experimental results demonstrate\nthe potential of such a system for recipe retrieval from images. A comparison\nwith respect to two baseline methods is also presented.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 13:42:30 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Fontanellaz", "Matthias", ""], ["Christodoulidis", "Stergios", ""], ["Mougiakakou", "Stavroula", ""]]}, {"id": "1911.01799", "submitter": "Lantian Li Mr.", "authors": "Yue Fan, Jiawen Kang, Lantian Li, Kaicheng Li, Haolin Chen, Sitong\n  Cheng, Pengyuan Zhang, Ziya Zhou, Yunqi Cai, Dong Wang", "title": "CN-CELEB: a challenging Chinese speaker recognition dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, researchers set an ambitious goal of conducting speaker recognition\nin unconstrained conditions where the variations on ambient, channel and\nemotion could be arbitrary. However, most publicly available datasets are\ncollected under constrained environments, i.e., with little noise and limited\nchannel variation. These datasets tend to deliver over optimistic performance\nand do not meet the request of research on speaker recognition in unconstrained\nconditions. In this paper, we present CN-Celeb, a large-scale speaker\nrecognition dataset collected `in the wild'. This dataset contains more than\n130,000 utterances from 1,000 Chinese celebrities, and covers 11 different\ngenres in real world. Experiments conducted with two state-of-the-art speaker\nrecognition approaches (i-vector and x-vector) show that the performance on\nCN-Celeb is far inferior to the one obtained on VoxCeleb, a widely used speaker\nrecognition dataset. This result demonstrates that in real-life conditions, the\nperformance of existing techniques might be much worse than it was thought. Our\ndatabase is free for researchers and can be downloaded from\nhttp://project.cslt.org.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 08:25:45 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Fan", "Yue", ""], ["Kang", "Jiawen", ""], ["Li", "Lantian", ""], ["Li", "Kaicheng", ""], ["Chen", "Haolin", ""], ["Cheng", "Sitong", ""], ["Zhang", "Pengyuan", ""], ["Zhou", "Ziya", ""], ["Cai", "Yunqi", ""], ["Wang", "Dong", ""]]}, {"id": "1911.01803", "submitter": "Taejun Kim", "authors": "Taejun Kim and Juhan Nam", "title": "Temporal Feedback Convolutional Recurrent Neural Networks for Keyword\n  Spotting", "comments": "This paper is submitted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While end-to-end learning has become a trend in deep learning, the model\narchitecture is often designed to incorporate domain knowledge. We propose a\nnovel convolutional recurrent neural network (CRNN) architecture with temporal\nfeedback connections, inspired by the feedback pathways from the brain to ears\nin the human auditory system. The proposed architecture uses a hidden state of\nthe RNN module at the previous time to control the sensitivity of channel-wise\nfeature activations in the CNN blocks at the current time, which is analogous\nto the mechanism of the outer hair-cell. We apply the proposed model to keyword\nspotting where the speech commands have sequential nature. We show the proposed\nmodel consistently outperforms the compared model without temporal feedback for\ndifferent input/output settings in the CRNN framework. We also investigate the\ndetails of the performance improvement by conducting a failure analysis of the\nkeyword spotting task and a visualization of the channel-wise feature scaling\nin each CNN block.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 04:11:29 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Kim", "Taejun", ""], ["Nam", "Juhan", ""]]}, {"id": "1911.01892", "submitter": "Roberto Dess\\`i", "authors": "Roberto Dess\\`i, Diane Bouchacourt, Davide Crepaldi, Marco Baroni", "title": "Focus on What's Informative and Ignore What's not: Communication\n  Strategies in a Referential Game", "comments": "3rd NeurIPS Workshop on Emergent Communication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in multi-agent cooperation has shown that artificial agents are able\nto learn to play a simple referential game while developing a shared lexicon.\nThis lexicon is not easy to analyze, as it does not show many properties of a\nnatural language. In a simple referential game with two neural network-based\nagents, we analyze the object-symbol mapping trying to understand what kind of\nstrategy was used to develop the emergent language. We see that, when the\nenvironment is uniformly distributed, the agents rely on a random subset of\nfeatures to describe the objects. When we modify the objects making one feature\nnon-uniformly distributed,the agents realize it is less informative and start\nto ignore it, and, surprisingly, they make a better use of the remaining\nfeatures. This interesting result suggests that more natural, less uniformly\ndistributed environments might aid in spurring the emergence of better-behaved\nlanguages.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 15:55:19 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Dess\u00ec", "Roberto", ""], ["Bouchacourt", "Diane", ""], ["Crepaldi", "Davide", ""], ["Baroni", "Marco", ""]]}, {"id": "1911.01917", "submitter": "John Licato", "authors": "John Licato, Zaid Marji, Sophia Abraham", "title": "Scenarios and Recommendations for Ethical Interpretive AI", "comments": "To appear in the Proceedings of the Human-Centered AI:\n  Trustworthiness of AI Models & Data (HAI) track at AAAI Fall Symposium, DC,\n  November 7-9, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Artificially intelligent systems, given a set of non-trivial ethical rules to\nfollow, will inevitably be faced with scenarios which call into question the\nscope of those rules. In such cases, human reasoners typically will engage in\ninterpretive reasoning, where interpretive arguments are used to support or\nattack claims that some rule should be understood a certain way. Artificially\nintelligent reasoners, however, currently lack the ability to carry out\nhuman-like interpretive reasoning, and we argue that bridging this gulf is of\ntremendous importance to human-centered AI. In order to better understand how\nfuture artificial reasoners capable of human-like interpretive reasoning must\nbe developed, we have collected a dataset of ethical rules, scenarios designed\nto invoke interpretive reasoning, and interpretations of those scenarios. We\nperform a qualitative analysis of our dataset, and summarize our findings in\nthe form of practical recommendations.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 16:23:01 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Licato", "John", ""], ["Marji", "Zaid", ""], ["Abraham", "Sophia", ""]]}, {"id": "1911.01933", "submitter": "Amelia Drew", "authors": "Amelia Drew and Alexander Heinecke", "title": "Training Neural Machine Translation (NMT) Models using Tensor Train\n  Decomposition on TensorFlow (T3F)", "comments": "10 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We implement a Tensor Train layer in the TensorFlow Neural Machine\nTranslation (NMT) model using the t3f library. We perform training runs on the\nIWSLT English-Vietnamese '15 and WMT German-English '16 datasets with learning\nrates $\\in \\{0.0004,0.0008,0.0012\\}$, maximum ranks $\\in \\{2,4,8,16\\}$ and a\nrange of core dimensions. We compare against a target BLEU test score of 24.0,\nobtained by our benchmark run. For the IWSLT English-Vietnamese training, we\nobtain BLEU test/dev scores of 24.0/21.9 and 24.2/21.9 using core dimensions\n$(2, 2, 256) \\times (2, 2, 512)$ with learning rate 0.0012 and rank\ndistributions $(1,4,4,1)$ and $(1,4,16,1)$ respectively. These runs use 113\\%\nand 397\\% of the flops of the benchmark run respectively. We find that, of the\nparameters surveyed, a higher learning rate and more `rectangular' core\ndimensions generally produce higher BLEU scores. For the WMT German-English\ndataset, we obtain BLEU scores of 24.0/23.8 using core dimensions $(4, 4, 128)\n\\times (4, 4, 256)$ with learning rate 0.0012 and rank distribution\n$(1,2,2,1)$. We discuss the potential for future optimization and application\nof Tensor Train decomposition to other NMT models.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 16:48:30 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Drew", "Amelia", ""], ["Heinecke", "Alexander", ""]]}, {"id": "1911.01940", "submitter": "Junjie Yang", "authors": "Junjie Yang and Hai Zhao", "title": "Deepening Hidden Representations from Pre-trained Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer-based pre-trained language models have proven to be effective for\nlearning contextualized language representation. However, current approaches\nonly take advantage of the output of the encoder's final layer when fine-tuning\nthe downstream tasks. We argue that only taking single layer's output restricts\nthe power of pre-trained representation. Thus we deepen the representation\nlearned by the model by fusing the hidden representation in terms of an\nexplicit HIdden Representation Extractor (HIRE), which automatically absorbs\nthe complementary representation with respect to the output from the final\nlayer. Utilizing RoBERTa as the backbone encoder, our proposed improvement over\nthe pre-trained models is shown effective on multiple natural language\nunderstanding tasks and help our model rival with the state-of-the-art models\non the GLUE benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 16:59:50 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 13:04:59 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Yang", "Junjie", ""], ["Zhao", "Hai", ""]]}, {"id": "1911.01986", "submitter": "Xuan Phi Nguyen", "authors": "Xuan-Phi Nguyen, Shafiq Joty, Wu Kui, Ai Ti Aw", "title": "Data Diversification: A Simple Strategy For Neural Machine Translation", "comments": "Accepted as a conference paper at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Data Diversification: a simple but effective strategy to boost\nneural machine translation (NMT) performance. It diversifies the training data\nby using the predictions of multiple forward and backward models and then\nmerging them with the original dataset on which the final NMT model is trained.\nOur method is applicable to all NMT models. It does not require extra\nmonolingual data like back-translation, nor does it add more computations and\nparameters like ensembles of models. Our method achieves state-of-the-art BLEU\nscores of 30.7 and 43.7 in the WMT'14 English-German and English-French\ntranslation tasks, respectively. It also substantially improves on 8 other\ntranslation tasks: 4 IWSLT tasks (English-German and English-French) and 4\nlow-resource translation tasks (English-Nepali and English-Sinhala). We\ndemonstrate that our method is more effective than knowledge distillation and\ndual learning, it exhibits strong correlation with ensembles of models, and it\ntrades perplexity off for better BLEU score. We have released our source code\nat https://github.com/nxphi47/data_diversification\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 18:25:42 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 10:32:18 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 16:06:04 GMT"}, {"version": "v4", "created": "Sun, 4 Oct 2020 15:08:17 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Nguyen", "Xuan-Phi", ""], ["Joty", "Shafiq", ""], ["Kui", "Wu", ""], ["Aw", "Ai Ti", ""]]}, {"id": "1911.02002", "submitter": "Luca Celotti", "authors": "Luca Celotti, Simon Brodeur, Jean Rouat", "title": "Language coverage and generalization in RNN-based continuous sentence\n  embeddings for interacting agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous sentence embeddings using recurrent neural networks (RNNs), where\nvariable-length sentences are encoded into fixed-dimensional vectors, are often\nthe main building blocks of architectures applied to language tasks such as\ndialogue generation. While it is known that those embeddings are able to learn\nsome structures of language (e.g. grammar) in a purely data-driven manner,\nthere is very little work on the objective evaluation of their ability to cover\nthe whole language space and to generalize to sentences outside the language\nbias of the training data. Using a manually designed context-free grammar (CFG)\nto generate a large-scale dataset of sentences related to the content of\nrealistic 3D indoor scenes, we evaluate the language coverage and\ngeneralization abilities of the most common continuous sentence embeddings\nbased on RNNs. We also propose a new embedding method based on arithmetic\ncoding, AriEL, that is not data-driven and that efficiently encodes in\ncontinuous space any sentence from the CFG. We find that RNN-based embeddings\nunderfit the training data and cover only a small subset of the language\ndefined by the CFG. They also fail to learn the underlying CFG and generalize\nto unbiased sentences from that same CFG. We found that AriEL provides an\ninsightful baseline.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 18:57:50 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Celotti", "Luca", ""], ["Brodeur", "Simon", ""], ["Rouat", "Jean", ""]]}, {"id": "1911.02060", "submitter": "Pavan Kapanipathi", "authors": "Pavan Kapanipathi, Veronika Thost, Siva Sankalp Patel, Spencer\n  Whitehead, Ibrahim Abdelaziz, Avinash Balakrishnan, Maria Chang, Kshitij\n  Fadnis, Chulaka Gunasekara, Bassem Makni, Nicholas Mattei, Kartik\n  Talamadupula, Achille Fokoue", "title": "Infusing Knowledge into the Textual Entailment Task Using Graph\n  Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Textual entailment is a fundamental task in natural language processing. Most\napproaches for solving the problem use only the textual content present in\ntraining data. A few approaches have shown that information from external\nknowledge sources like knowledge graphs (KGs) can add value, in addition to the\ntextual content, by providing background knowledge that may be critical for a\ntask. However, the proposed models do not fully exploit the information in the\nusually large and noisy KGs, and it is not clear how it can be effectively\nencoded to be useful for entailment. We present an approach that complements\ntext-based entailment models with information from KGs by (1) using\nPersonalized PageR- ank to generate contextual subgraphs with reduced noise and\n(2) encoding these subgraphs using graph convolutional networks to capture KG\nstructure. Our technique extends the capability of text models exploiting\nstructural and semantic information found in KGs. We evaluate our approach on\nmultiple textual entailment datasets and show that the use of external\nknowledge helps improve prediction accuracy. This is particularly evident in\nthe challenging BreakingNLI dataset, where we see an absolute improvement of\n5-20% over multiple text-based entailment models.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 19:52:34 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 00:20:31 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Kapanipathi", "Pavan", ""], ["Thost", "Veronika", ""], ["Patel", "Siva Sankalp", ""], ["Whitehead", "Spencer", ""], ["Abdelaziz", "Ibrahim", ""], ["Balakrishnan", "Avinash", ""], ["Chang", "Maria", ""], ["Fadnis", "Kshitij", ""], ["Gunasekara", "Chulaka", ""], ["Makni", "Bassem", ""], ["Mattei", "Nicholas", ""], ["Talamadupula", "Kartik", ""], ["Fokoue", "Achille", ""]]}, {"id": "1911.02085", "submitter": "Kshitij Fadnis", "authors": "Kshitij Fadnis, Kartik Talamadupula, Pavan Kapanipathi, Haque Ishfaq,\n  Salim Roukos, Achille Fokoue", "title": "Path-Based Contextualization of Knowledge Graphs for Textual Entailment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the problem of knowledge graph contextualization\n-- that is, given a specific NLP task, the problem of extracting meaningful and\nrelevant sub-graphs from a given knowledge graph. The task in the case of this\npaper is the textual entailment problem, and the context is a relevant\nsub-graph for an instance of the textual entailment problem -- where given two\nsentences p and h, the entailment relationship between them has to be predicted\nautomatically. We base our methodology on finding paths in a cost-customized\nexternal knowledge graph, and building the most relevant sub-graph that\nconnects p and h. We show that our path selection mechanism to generate\nsub-graphs not only reduces noise, but also retrieves meaningful information\nfrom large knowledge graphs. Our evaluation shows that using information on\nentities as well as the relationships between them improves on the performance\nof purely text-based systems.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 21:06:04 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 04:17:44 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Fadnis", "Kshitij", ""], ["Talamadupula", "Kartik", ""], ["Kapanipathi", "Pavan", ""], ["Ishfaq", "Haque", ""], ["Roukos", "Salim", ""], ["Fokoue", "Achille", ""]]}, {"id": "1911.02086", "submitter": "Simon Mittermaier", "authors": "Simon Mittermaier, Ludwig K\\\"urzinger, Bernd Waschneck, Gerhard Rigoll", "title": "Small-Footprint Keyword Spotting on Raw Audio Data with\n  Sinc-Convolutions", "comments": "Accepted at ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyword Spotting (KWS) enables speech-based user interaction on smart\ndevices. Always-on and battery-powered application scenarios for smart devices\nput constraints on hardware resources and power consumption, while also\ndemanding high accuracy as well as real-time capability. Previous architectures\nfirst extracted acoustic features and then applied a neural network to classify\nkeyword probabilities, optimizing towards memory footprint and execution time.\nCompared to previous publications, we took additional steps to reduce power and\nmemory consumption without reducing classification accuracy. Power-consuming\naudio preprocessing and data transfer steps are eliminated by directly\nclassifying from raw audio. For this, our end-to-end architecture extracts\nspectral features using parametrized Sinc-convolutions. Its memory footprint is\nfurther reduced by grouping depthwise separable convolutions. Our network\nachieves the competitive accuracy of 96.4% on Google's Speech Commands test set\nwith only 62k parameters.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 21:13:19 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 12:07:28 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Mittermaier", "Simon", ""], ["K\u00fcrzinger", "Ludwig", ""], ["Waschneck", "Bernd", ""], ["Rigoll", "Gerhard", ""]]}, {"id": "1911.02103", "submitter": "Xavier Gir\\'o-i-Nieto", "authors": "Alba Herrera-Palacio, Carles Ventura, Carina Silberer, Ionut-Teodor\n  Sorodoc, Gemma Boleda and Xavier Giro-i-Nieto", "title": "Recurrent Instance Segmentation using Sequences of Referring Expressions", "comments": "3rd NeurIPS Workshop on Visually Grounded Interaction and Language\n  (ViGIL, 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this work is to segment the objects in an image that are referred\nto by a sequence of linguistic descriptions (referring expressions). We propose\na deep neural network with recurrent layers that output a sequence of binary\nmasks, one for each referring expression provided by the user. The recurrent\nlayers in the architecture allow the model to condition each predicted mask on\nthe previous ones, from a spatial perspective within the same image. Our\nmultimodal approach uses off-the-shelf architectures to encode both the image\nand the referring expressions. The visual branch provides a tensor of pixel\nembeddings that are concatenated with the phrase embeddings produced by a\nlanguage encoder. Our experiments on the RefCOCO dataset for still images\nindicate how the proposed architecture successfully exploits the sequences of\nreferring expressions to solve a pixel-wise task of instance segmentation.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 21:49:55 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Herrera-Palacio", "Alba", ""], ["Ventura", "Carles", ""], ["Silberer", "Carina", ""], ["Sorodoc", "Ionut-Teodor", ""], ["Boleda", "Gemma", ""], ["Giro-i-Nieto", "Xavier", ""]]}, {"id": "1911.02116", "submitter": "Alexis Conneau", "authors": "Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary,\n  Guillaume Wenzek, Francisco Guzm\\'an, Edouard Grave, Myle Ott, Luke\n  Zettlemoyer, and Veselin Stoyanov", "title": "Unsupervised Cross-lingual Representation Learning at Scale", "comments": "ACL 2020 (+ updated results)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that pretraining multilingual language models at scale leads\nto significant performance gains for a wide range of cross-lingual transfer\ntasks. We train a Transformer-based masked language model on one hundred\nlanguages, using more than two terabytes of filtered CommonCrawl data. Our\nmodel, dubbed XLM-R, significantly outperforms multilingual BERT (mBERT) on a\nvariety of cross-lingual benchmarks, including +14.6% average accuracy on XNLI,\n+13% average F1 score on MLQA, and +2.4% F1 score on NER. XLM-R performs\nparticularly well on low-resource languages, improving 15.7% in XNLI accuracy\nfor Swahili and 11.4% for Urdu over previous XLM models. We also present a\ndetailed empirical analysis of the key factors that are required to achieve\nthese gains, including the trade-offs between (1) positive transfer and\ncapacity dilution and (2) the performance of high and low resource languages at\nscale. Finally, we show, for the first time, the possibility of multilingual\nmodeling without sacrificing per-language performance; XLM-R is very\ncompetitive with strong monolingual models on the GLUE and XNLI benchmarks. We\nwill make our code, data and models publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 22:42:00 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 01:02:17 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Conneau", "Alexis", ""], ["Khandelwal", "Kartikay", ""], ["Goyal", "Naman", ""], ["Chaudhary", "Vishrav", ""], ["Wenzek", "Guillaume", ""], ["Guzm\u00e1n", "Francisco", ""], ["Grave", "Edouard", ""], ["Ott", "Myle", ""], ["Zettlemoyer", "Luke", ""], ["Stoyanov", "Veselin", ""]]}, {"id": "1911.02133", "submitter": "Farley Lai", "authors": "Farley Lai, Ning Xie, Derek Doran and Asim Kadav", "title": "Contextual Grounding of Natural Language Entities in Images", "comments": "Accepted to NeurIPS 2019 workshop on Visually Grounded Interaction\n  and Language (ViGIL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a contextual grounding approach that captures the\ncontext in corresponding text entities and image regions to improve the\ngrounding accuracy. Specifically, the proposed architecture accepts pre-trained\ntext token embeddings and image object features from an off-the-shelf object\ndetector as input. Additional encoding to capture the positional and spatial\ninformation can be added to enhance the feature quality. There are separate\ntext and image branches facilitating respective architectural refinements for\ndifferent modalities. The text branch is pre-trained on a large-scale masked\nlanguage modeling task while the image branch is trained from scratch. Next,\nthe model learns the contextual representations of the text tokens and image\nobjects through layers of high-order interaction respectively. The final\ngrounding head ranks the correspondence between the textual and visual\nrepresentations through cross-modal interaction. In the evaluation, we show\nthat our model achieves the state-of-the-art grounding accuracy of 71.36% over\nthe Flickr30K Entities dataset. No additional pre-training is necessary to\ndeliver competitive results compared with related work that often requires\ntask-agnostic and task-specific pre-training on cross-modal dadasets. The\nimplementation is publicly available at https://gitlab.com/necla-ml/grounding.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 23:23:58 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Lai", "Farley", ""], ["Xie", "Ning", ""], ["Doran", "Derek", ""], ["Kadav", "Asim", ""]]}, {"id": "1911.02147", "submitter": "Chenyang Huang", "authors": "Chenyang Huang, Amine Trabelsi, Xuebin Qin, Nawshad Farruque, Osmar R.\n  Za\\\"iane", "title": "Seq2Emo for Multi-label Emotion Classification Based on Latent Variable\n  Chains Transformation", "comments": "10 pages, 2 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion detection in text is an important task in NLP and is essential in\nmany applications. Most of the existing methods treat this task as a problem of\nsingle-label multi-class text classification. To predict multiple emotions for\none instance, most of the existing works regard it as a general Multi-label\nClassification (MLC) problem, where they usually either apply a manually\ndetermined threshold on the last output layer of their neural network models or\ntrain multiple binary classifiers and make predictions in the fashion of\none-vs-all. However, compared to labels in the general MLC datasets, the number\nof emotion categories are much fewer (less than 10). Additionally, emotions\ntend to have more correlations with each other. For example, the human usually\ndoes not express \"joy\" and \"anger\" at the same time, but it is very likely to\nhave \"joy\" and \"love\" expressed together. Given this intuition, in this paper,\nwe propose a Latent Variable Chain (LVC) transformation and a tailored model --\nSeq2Emo model that not only naturally predicts multiple emotion labels but also\ntakes into consideration their correlations. We perform the experiments on the\nexisting multi-label emotion datasets as well as on our newly collected\ndatasets. The results show that our model compares favorably with existing\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 00:08:19 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 04:55:18 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Huang", "Chenyang", ""], ["Trabelsi", "Amine", ""], ["Qin", "Xuebin", ""], ["Farruque", "Nawshad", ""], ["Za\u00efane", "Osmar R.", ""]]}, {"id": "1911.02150", "submitter": "Noam Shazeer", "authors": "Noam Shazeer", "title": "Fast Transformer Decoding: One Write-Head is All You Need", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-head attention layers, as used in the Transformer neural sequence\nmodel, are a powerful alternative to RNNs for moving information across and\nbetween sequences. While training these layers is generally fast and simple,\ndue to parallelizability across the length of the sequence, incremental\ninference (where such paralleization is impossible) is often slow, due to the\nmemory-bandwidth cost of repeatedly loading the large \"keys\" and \"values\"\ntensors. We propose a variant called multi-query attention, where the keys and\nvalues are shared across all of the different attention \"heads\", greatly\nreducing the size of these tensors and hence the memory bandwidth requirements\nof incremental decoding. We verify experimentally that the resulting models can\nindeed be much faster to decode, and incur only minor quality degradation from\nthe baseline.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 00:19:05 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Shazeer", "Noam", ""]]}, {"id": "1911.02168", "submitter": "Quan Wang", "authors": "Quan Wang, Pingping Huang, Haifeng Wang, Songtai Dai, Wenbin Jiang,\n  Jing Liu, Yajuan Lyu, Yong Zhu, Hua Wu", "title": "CoKE: Contextualized Knowledge Graph Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph embedding, which projects symbolic entities and relations\ninto continuous vector spaces, is gaining increasing attention. Previous\nmethods allow a single static embedding for each entity or relation, ignoring\ntheir intrinsic contextual nature, i.e., entities and relations may appear in\ndifferent graph contexts, and accordingly, exhibit different properties. This\nwork presents Contextualized Knowledge Graph Embedding (CoKE), a novel paradigm\nthat takes into account such contextual nature, and learns dynamic, flexible,\nand fully contextualized entity and relation embeddings. Two types of graph\ncontexts are studied: edges and paths, both formulated as sequences of entities\nand relations. CoKE takes a sequence as input and uses a Transformer encoder to\nobtain contextualized representations. These representations are hence\nnaturally adaptive to the input, capturing contextual meanings of entities and\nrelations therein. Evaluation on a wide variety of public benchmarks verifies\nthe superiority of CoKE in link prediction and path query answering. It\nperforms consistently better than, or at least equally well as current\nstate-of-the-art in almost every case, in particular offering an absolute\nimprovement of 21.0% in H@10 on path query answering. Our code is available at\n\\url{https://github.com/PaddlePaddle/Research/tree/master/KG/CoKE}.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 02:27:39 GMT"}, {"version": "v2", "created": "Sat, 4 Apr 2020 07:22:20 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Wang", "Quan", ""], ["Huang", "Pingping", ""], ["Wang", "Haifeng", ""], ["Dai", "Songtai", ""], ["Jiang", "Wenbin", ""], ["Liu", "Jing", ""], ["Lyu", "Yajuan", ""], ["Zhu", "Yong", ""], ["Wu", "Hua", ""]]}, {"id": "1911.02170", "submitter": "Deming Ye", "authors": "Deming Ye, Yankai Lin, Zhenghao Liu, Zhiyuan Liu, Maosong Sun", "title": "Multi-Paragraph Reasoning with Knowledge-enhanced Graph Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-paragraph reasoning is indispensable for open-domain question answering\n(OpenQA), which receives less attention in the current OpenQA systems. In this\nwork, we propose a knowledge-enhanced graph neural network (KGNN), which\nperforms reasoning over multiple paragraphs with entities. To explicitly\ncapture the entities' relatedness, KGNN utilizes relational facts in knowledge\ngraph to build the entity graph. The experimental results show that KGNN\noutperforms in both distractor and full wiki settings than baselines methods on\nHotpotQA dataset. And our further analysis illustrates KGNN is effective and\nrobust with more retrieved paragraphs.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 02:34:10 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Ye", "Deming", ""], ["Lin", "Yankai", ""], ["Liu", "Zhenghao", ""], ["Liu", "Zhiyuan", ""], ["Sun", "Maosong", ""]]}, {"id": "1911.02215", "submitter": "Yankai Lin", "authors": "Qiu Ran, Yankai Lin, Peng Li, Jie Zhou", "title": "Guiding Non-Autoregressive Neural Machine Translation Decoding with\n  Reordering Information", "comments": "Accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-autoregressive neural machine translation (NAT) generates each target\nword in parallel and has achieved promising inference acceleration. However,\nexisting NAT models still have a big gap in translation quality compared to\nautoregressive neural machine translation models due to the enormous decoding\nspace. To address this problem, we propose a novel NAT framework named\nReorderNAT which explicitly models the reordering information in the decoding\nprocedure. We further introduce deterministic and non-deterministic decoding\nstrategies that utilize reordering information to narrow the decoding search\nspace in our proposed ReorderNAT. Experimental results on various widely-used\ndatasets show that our proposed model achieves better performance compared to\nexisting NAT models, and even achieves comparable translation quality as\nautoregressive translation models with a significant speedup.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 06:17:16 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 11:27:01 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Ran", "Qiu", ""], ["Lin", "Yankai", ""], ["Li", "Peng", ""], ["Zhou", "Jie", ""]]}, {"id": "1911.02242", "submitter": "Chung-Cheng Chiu", "authors": "Chung-Cheng Chiu, Wei Han, Yu Zhang, Ruoming Pang, Sergey Kishchenko,\n  Patrick Nguyen, Arun Narayanan, Hank Liao, Shuyuan Zhang, Anjuli Kannan,\n  Rohit Prabhavalkar, Zhifeng Chen, Tara Sainath, Yonghui Wu", "title": "A comparison of end-to-end models for long-form speech recognition", "comments": "ASRU camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end automatic speech recognition (ASR) models, including both\nattention-based models and the recurrent neural network transducer (RNN-T),\nhave shown superior performance compared to conventional systems. However,\nprevious studies have focused primarily on short utterances that typically last\nfor just a few seconds or, at most, a few tens of seconds. Whether such\narchitectures are practical on long utterances that last from minutes to hours\nremains an open question. In this paper, we both investigate and improve the\nperformance of end-to-end models on long-form transcription. We first present\nan empirical comparison of different end-to-end models on a real world\nlong-form task and demonstrate that the RNN-T model is much more robust than\nattention-based systems in this regime. We next explore two improvements to\nattention-based systems that significantly improve its performance: restricting\nthe attention to be monotonic, and applying a novel decoding algorithm that\nbreaks long utterances into shorter overlapping segments. Combining these two\nimprovements, we show that attention-based end-to-end models can be very\ncompetitive to RNN-T on long-form speech recognition.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 08:01:16 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Chiu", "Chung-Cheng", ""], ["Han", "Wei", ""], ["Zhang", "Yu", ""], ["Pang", "Ruoming", ""], ["Kishchenko", "Sergey", ""], ["Nguyen", "Patrick", ""], ["Narayanan", "Arun", ""], ["Liao", "Hank", ""], ["Zhang", "Shuyuan", ""], ["Kannan", "Anjuli", ""], ["Prabhavalkar", "Rohit", ""], ["Chen", "Zhifeng", ""], ["Sainath", "Tara", ""], ["Wu", "Yonghui", ""]]}, {"id": "1911.02247", "submitter": "Arthur Bra\\v{z}inskas", "authors": "Arthur Bra\\v{z}inskas, Mirella Lapata and Ivan Titov", "title": "Unsupervised Opinion Summarization as Copycat-Review Generation", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opinion summarization is the task of automatically creating summaries that\nreflect subjective information expressed in multiple documents, such as product\nreviews. While the majority of previous work has focused on the extractive\nsetting, i.e., selecting fragments from input reviews to produce a summary, we\nlet the model generate novel sentences and hence produce abstractive summaries.\nRecent progress in summarization has seen the development of supervised models\nwhich rely on large quantities of document-summary pairs. Since such training\ndata is expensive to acquire, we instead consider the unsupervised setting, in\nother words, we do not use any summaries in training. We define a generative\nmodel for a review collection which capitalizes on the intuition that when\ngenerating a new review given a set of other reviews of a product, we should be\nable to control the \"amount of novelty\" going into the new review or,\nequivalently, vary the extent to which it deviates from the input. At test\ntime, when generating summaries, we force the novelty to be minimal, and\nproduce a text reflecting consensus opinions. We capture this intuition by\ndefining a hierarchical variational autoencoder model. Both individual reviews\nand the products they correspond to are associated with stochastic latent\ncodes, and the review generator (\"decoder\") has direct access to the text of\ninput reviews through the pointer-generator mechanism. Experiments on Amazon\nand Yelp datasets, show that setting at test time the review's latent code to\nits mean, allows the model to produce fluent and coherent summaries reflecting\ncommon opinions.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 08:20:13 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 15:49:31 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Bra\u017einskas", "Arthur", ""], ["Lapata", "Mirella", ""], ["Titov", "Ivan", ""]]}, {"id": "1911.02257", "submitter": "Ying Luo", "authors": "Ying Luo, Fengshun Xiao, Hai Zhao", "title": "Hierarchical Contextualized Representation for Named Entity Recognition", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity recognition (NER) models are typically based on the architecture\nof Bi-directional LSTM (BiLSTM). The constraints of sequential nature and the\nmodeling of single input prevent the full utilization of global information\nfrom larger scope, not only in the entire sentence, but also in the entire\ndocument (dataset). In this paper, we address these two deficiencies and\npropose a model augmented with hierarchical contextualized representation:\nsentence-level representation and document-level representation. In\nsentence-level, we take different contributions of words in a single sentence\ninto consideration to enhance the sentence representation learned from an\nindependent BiLSTM via label embedding attention mechanism. In document-level,\nthe key-value memory network is adopted to record the document-aware\ninformation for each unique word which is sensitive to similarity of context\ninformation. Our two-level hierarchical contextualized representations are\nfused with each input token embedding and corresponding hidden state of BiLSTM,\nrespectively. The experimental results on three benchmark NER datasets\n(CoNLL-2003 and Ontonotes 5.0 English datasets, CoNLL-2002 Spanish dataset)\nshow that we establish new state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 08:52:52 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 14:02:29 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Luo", "Ying", ""], ["Xiao", "Fengshun", ""], ["Zhao", "Hai", ""]]}, {"id": "1911.02290", "submitter": "Amir Vakili Tahami", "authors": "Amir Vakili Tahami and Azadeh Shakery", "title": "Enriching Conversation Context in Retrieval-based Chatbots", "comments": "8 pages, 1 figure, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Work on retrieval-based chatbots, like most sequence pair matching tasks, can\nbe divided into Cross-encoders that perform word matching over the pair, and\nBi-encoders that encode the pair separately. The latter has better performance,\nhowever since candidate responses cannot be encoded offline, it is also much\nslower. Lately, multi-layer transformer architectures pre-trained as language\nmodels have been used to great effect on a variety of natural language\nprocessing and information retrieval tasks. Recent work has shown that these\nlanguage models can be used in text-matching scenarios to create Bi-encoders\nthat perform almost as well as Cross-encoders while having a much faster\ninference speed. In this paper, we expand upon this work by developing a\nsequence matching architecture that %takes into account contexts in the\ntraining dataset at inference time. utilizes the entire training set as a\nmakeshift knowledge-base during inference. We perform detailed experiments\ndemonstrating that this architecture can be used to further improve Bi-encoders\nperformance while still maintaining a relatively high inference speed.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 10:24:45 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Tahami", "Amir Vakili", ""], ["Shakery", "Azadeh", ""]]}, {"id": "1911.02365", "submitter": "Tassilo Klein", "authors": "Tassilo Klein, Moin Nabi", "title": "Learning to Answer by Learning to Ask: Getting the Best of GPT-2 and\n  BERT Worlds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic question generation aims at the generation of questions from a\ncontext, with the corresponding answers being sub-spans of the given passage.\nWhereas, most of the methods mostly rely on heuristic rules to generate\nquestions, more recently also neural network approaches have been proposed. In\nthis work, we propose a variant of the self-attention Transformer network\narchitectures model to generate meaningful and diverse questions. To this end,\nwe propose an easy to use model consisting of the conjunction of the\nTransformer decoder GPT-2 model with Transformer encoder BERT for the\ndownstream task for question answering. The model is trained in an end-to-end\nfashion, where the language model is trained to produce a question-answer-aware\ninput representation that facilitates to generate an answer focused question.\nOur result of neural question generation from text on the SQuAD 1.1 dataset\nsuggests that our method can produce semantically correct and diverse\nquestions. Additionally, we assessed the performance of our proposed method for\nthe downstream task of question answering. The analysis shows that our proposed\ngeneration & answering collaboration framework relatively improves both tasks\nand is particularly powerful in the semi-supervised setup. The results further\nsuggest a robust and comparably lean pipeline facilitating question generation\nin the small-data regime.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 13:23:41 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Klein", "Tassilo", ""], ["Nabi", "Moin", ""]]}, {"id": "1911.02390", "submitter": "Bowen Wu", "authors": "Bowen Wu, Mengyuan Li, Zongsheng Wang, Yifu Chen, Derek Wong, Qihang\n  Feng, Junhong Huang, Baoxun Wang", "title": "Guiding Variational Response Generator to Exploit Persona", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging persona information of users in Neural Response Generators (NRG)\nto perform personalized conversations has been considered as an attractive and\nimportant topic in the research of conversational agents over the past few\nyears. Despite of the promising progresses achieved by recent studies in this\nfield, persona information tends to be incorporated into neural networks in the\nform of user embeddings, with the expectation that the persona can be involved\nvia the End-to-End learning. This paper proposes to adopt the\npersonality-related characteristics of human conversations into variational\nresponse generators, by designing a specific conditional variational\nautoencoder based deep model with two new regularization terms employed to the\nloss function, so as to guide the optimization towards the direction of\ngenerating both persona-aware and relevant responses. Besides, to reasonably\nevaluate the performances of various persona modeling approaches, this paper\nfurther presents three direct persona-oriented metrics from different\nperspectives. The experimental results have shown that our proposed methodology\ncan notably improve the performance of persona-aware response generation, and\nthe metrics are reasonable to evaluate the results.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 13:53:46 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 05:13:09 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Wu", "Bowen", ""], ["Li", "Mengyuan", ""], ["Wang", "Zongsheng", ""], ["Chen", "Yifu", ""], ["Wong", "Derek", ""], ["Feng", "Qihang", ""], ["Huang", "Junhong", ""], ["Wang", "Baoxun", ""]]}, {"id": "1911.02471", "submitter": "Agathe Balayn", "authors": "Agathe Balayn, Alessandro Bozzon", "title": "Designing Evaluations of Machine Learning Models for Subjective\n  Inference: The Case of Sentence Toxicity", "comments": "presented at the Rigorous Evaluation of Artificial Intelligence\n  Systems (REAIS) workshop co-located with HCOMP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) is increasingly applied in real-life scenarios, raising\nconcerns about bias in automatic decision making. We focus on bias as a notion\nof opinion exclusion, that stems from the direct application of traditional ML\npipelines to infer subjective properties. We argue that such ML systems should\nbe evaluated with subjectivity and bias in mind. Considering the lack of\nevaluation standards yet to create evaluation benchmarks, we propose an initial\nlist of specifications to define prior to creating evaluation datasets, in\norder to later accurately evaluate the biases. With the example of a sentence\ntoxicity inference system, we illustrate how the specifications support the\nanalysis of biases related to subjectivity. We highlight difficulties in\ninstantiating these specifications and list future work for the crowdsourcing\ncommunity to help the creation of appropriate evaluation datasets.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 16:38:19 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Balayn", "Agathe", ""], ["Bozzon", "Alessandro", ""]]}, {"id": "1911.02493", "submitter": "Pei Ke", "authors": "Pei Ke, Haozhe Ji, Siyang Liu, Xiaoyan Zhu, Minlie Huang", "title": "SentiLARE: Sentiment-Aware Language Representation Learning with\n  Linguistic Knowledge", "comments": "Accepted by EMNLP 2020 (Main Conference)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing pre-trained language representation models neglect to\nconsider the linguistic knowledge of texts, which can promote language\nunderstanding in NLP tasks. To benefit the downstream tasks in sentiment\nanalysis, we propose a novel language representation model called SentiLARE,\nwhich introduces word-level linguistic knowledge including part-of-speech tag\nand sentiment polarity (inferred from SentiWordNet) into pre-trained models. We\nfirst propose a context-aware sentiment attention mechanism to acquire the\nsentiment polarity of each word with its part-of-speech tag by querying\nSentiWordNet. Then, we devise a new pre-training task called label-aware masked\nlanguage model to construct knowledge-aware language representation.\nExperiments show that SentiLARE obtains new state-of-the-art performance on a\nvariety of sentiment analysis tasks.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 17:05:26 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 13:14:08 GMT"}, {"version": "v3", "created": "Thu, 24 Sep 2020 05:58:01 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Ke", "Pei", ""], ["Ji", "Haozhe", ""], ["Liu", "Siyang", ""], ["Zhu", "Xiaoyan", ""], ["Huang", "Minlie", ""]]}, {"id": "1911.02499", "submitter": "Sungjoon Park", "authors": "Sungjoon Park, Jiseon Kim, Jaeyeol Jeon, Heeyoung Park, Alice Oh", "title": "Toward Dimensional Emotion Detection from Categorical Emotion\n  Annotations", "comments": "9 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework which makes a model predict fine-grained dimensional\nemotions (valence-arousal-dominance, VAD) trained on corpus annotated with\ncoarse-grained categorical emotions. We train a model by minimizing EMD\ndistances between predicted VAD score distribution and \\textit{sorted}\ncategorical emotion distributions in terms of VAD, as a proxy of target VAD\nscore distributions. With our model, we can simultaneously classify a given\nsentence to categorical emotions as well as predict VAD scores. We use\npre-trained BERT-Large and fine-tune on SemEval dataset (11 categorical\nemotions) and evaluate on EmoBank (VAD dimensional emotions), in order to show\nour approach reaches comparable performance to that of the state-of-the-art\nclassifiers in categorical emotion classification task and significant positive\ncorrelations with ground truth VAD scores. Also, if one continues training our\nmodel with supervision of VAD labels, it outperforms state-of-the-art VAD\nregression models. We further present examples showing our model can annotate\nemotional words suitable for a given text even those words are not seen as\ncategorical labels during training.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 17:16:26 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Park", "Sungjoon", ""], ["Kim", "Jiseon", ""], ["Jeon", "Jaeyeol", ""], ["Park", "Heeyoung", ""], ["Oh", "Alice", ""]]}, {"id": "1911.02524", "submitter": "Georgiy Platonov", "authors": "Georgiy Platonov, Benjamin Kane, Aaron Gindi, Lenhart K. Schubert", "title": "A Spoken Dialogue System for Spatial Question Answering in a Physical\n  Blocks World", "comments": "9 pages (with references), 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The blocks world is a classic toy domain that has long been used to build and\ntest spatial reasoning systems. Despite its relative simplicity, tackling this\ndomain in its full complexity requires the agent to exhibit a rich set of\nfunctional capabilities, ranging from vision to natural language understanding.\nThere is currently a resurgence of interest in solving problems in such limited\ndomains using modern techniques. In this work we tackle spatial question\nanswering in a holistic way, using a vision system, speech input and output\nmediated by an animated avatar, a dialogue system that robustly interprets\nspatial queries, and a constraint solver that derives answers based on 3-D\nspatial modeling. The contributions of this work include a semantic parser that\nmaps spatial questions into logical forms consistent with a general approach to\nmeaning representation, a dialog manager based on a schema representation, and\na constraint solver for spatial questions that provides answers in agreement\nwith human perception. These and other components are integrated into a\nmulti-modal human-computer interaction pipeline.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 18:05:13 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Platonov", "Georgiy", ""], ["Kane", "Benjamin", ""], ["Gindi", "Aaron", ""], ["Schubert", "Lenhart K.", ""]]}, {"id": "1911.02541", "submitter": "Yuhao Zhang", "authors": "Yuhao Zhang, Derek Merck, Emily Bao Tsai, Christopher D. Manning,\n  Curtis P. Langlotz", "title": "Optimizing the Factual Correctness of a Summary: A Study of Summarizing\n  Radiology Reports", "comments": "ACL2020. 13 pages with appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural abstractive summarization models are able to generate summaries which\nhave high overlap with human references. However, existing models are not\noptimized for factual correctness, a critical metric in real-world\napplications. In this work, we develop a general framework where we evaluate\nthe factual correctness of a generated summary by fact-checking it\nautomatically against its reference using an information extraction module. We\nfurther propose a training strategy which optimizes a neural summarization\nmodel with a factual correctness reward via reinforcement learning. We apply\nthe proposed method to the summarization of radiology reports, where factual\ncorrectness is a key requirement. On two separate datasets collected from\nhospitals, we show via both automatic and human evaluation that the proposed\napproach substantially improves the factual correctness and overall quality of\noutputs over a competitive neural summarization system, producing radiology\nsummaries that approach the quality of human-authored ones.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 18:25:00 GMT"}, {"version": "v2", "created": "Fri, 8 Nov 2019 07:39:03 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2020 01:33:49 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Zhang", "Yuhao", ""], ["Merck", "Derek", ""], ["Tsai", "Emily Bao", ""], ["Manning", "Christopher D.", ""], ["Langlotz", "Curtis P.", ""]]}, {"id": "1911.02562", "submitter": "Robert O'Shea", "authors": "Robert O'Shea", "title": "Gextext: Disease Network Extraction from Biomedical Literature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PURPOSE: We propose a fully unsupervised method to learn latent disease\nnetworks directly from unstructured biomedical text corpora. This method\naddresses current challenges in unsupervised knowledge extraction, such as the\ndetection of long-range dependencies and requirements for large training\ncorpora. METHODS: Let C be a corpus of n text chunks. Let V be a set of p\ndisease terms occurring in the corpus. Let X indicate the occurrence of V in C.\nGextext identifies disease similarities by positively correlated occurrence\npatterns. This information is combined to generate a graph on which geodesic\ndistance describes dissimilarity. Diseasomes were learned by Gextext and GloVE\non corpora of 100-1000 PubMed abstracts. Similarity matrix estimates were\nvalidated against biomedical semantic similarity metrics and gene profile\nsimilarity. RESULTS: Geodesic distance on Gextext-inferred diseasomes\ncorrelated inversely with external measures of semantic similarity. Gene\nprofile similarity also correlated significant with proximity on the inferred\ngraph. Gextext outperformed GloVE in our experiments. The information contained\non the Gextext graph exceeded the explicit information content within the text.\nCONCLUSIONS: Gextext extracts latent relationships from unstructured text,\nenabling fully unsupervised modelling of diseasome graphs from PubMed\nabstracts.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 10:57:38 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 10:15:39 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["O'Shea", "Robert", ""]]}, {"id": "1911.02639", "submitter": "Kian Kenyon-Dean", "authors": "Kian Kenyon-Dean", "title": "Word Embedding Algorithms as Generalized Low Rank Models and their\n  Canonical Form", "comments": "82 pages; McGill University master's thesis, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding algorithms produce very reliable feature representations of\nwords that are used by neural network models across a constantly growing\nmultitude of NLP tasks. As such, it is imperative for NLP practitioners to\nunderstand how their word representations are produced, and why they are so\nimpactful.\n  The present work presents the Simple Embedder framework, generalizing the\nstate-of-the-art existing word embedding algorithms (including Word2vec (SGNS)\nand GloVe) under the umbrella of generalized low rank models. We derive that\nboth of these algorithms attempt to produce embedding inner products that\napproximate pointwise mutual information (PMI) statistics in the corpus. Once\ncast as Simple Embedders, comparison of these models reveals that these\nsuccessful embedders all resemble a straightforward maximum likelihood estimate\n(MLE) of the PMI parametrized by the inner product (between embeddings). This\nMLE induces our proposed novel word embedding model, Hilbert-MLE, as the\ncanonical representative of the Simple Embedder framework.\n  We empirically compare these algorithms with evaluations on 17 different\ndatasets. Hilbert-MLE consistently observes second-best performance on every\nextrinsic evaluation (news classification, sentiment analysis, POS-tagging, and\nsupersense tagging), while the first-best model depends varying on the task.\nMoreover, Hilbert-MLE consistently observes the least variance in results with\nrespect to the random initialization of the weights in bidirectional LSTMs. Our\nempirical results demonstrate that Hilbert-MLE is a very consistent word\nembedding algorithm that can be reliably integrated into existing NLP systems\nto obtain high-quality results.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 21:40:34 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Kenyon-Dean", "Kian", ""]]}, {"id": "1911.02645", "submitter": "Yadollah Yaghoobzadeh", "authors": "Alexandre Rochette, Yadollah Yaghoobzadeh, Timothy J. Hazen", "title": "Unsupervised Domain Adaptation of Contextual Embeddings for Low-Resource\n  Duplicate Question Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering questions is a primary goal of many conversational systems or\nsearch products. While most current systems have focused on answering questions\nagainst structured databases or curated knowledge graphs, on-line community\nforums or frequently asked questions (FAQ) lists offer an alternative source of\ninformation for question answering systems. Automatic duplicate question\ndetection (DQD) is the key technology need for question answering systems to\nutilize existing online forums like StackExchange. Existing annotations of\nduplicate questions in such forums are community-driven, making them sparse or\neven completely missing for many domains. Therefore, it is important to\ntransfer knowledge from related domains and tasks. Recently, contextual\nembedding models such as BERT have been outperforming many baselines by\ntransferring self-supervised information to downstream tasks. In this paper, we\napply BERT to DQD and advance it by unsupervised adaptation to StackExchange\ndomains using self-supervised learning. We show the effectiveness of this\nadaptation for low-resource settings, where little or no training data is\navailable from the target domain. Our analysis reveals that unsupervised BERT\ndomain adaptation on even small amounts of data boosts the performance of BERT.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 22:01:18 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Rochette", "Alexandre", ""], ["Yaghoobzadeh", "Yadollah", ""], ["Hazen", "Timothy J.", ""]]}, {"id": "1911.02648", "submitter": "Philippe Vincent-Lamarre", "authors": "Philippe Vincent-Lamarre and Vincent Larivi\\`ere", "title": "Textual analysis of artificial intelligence manuscripts reveals features\n  associated with peer review outcome", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We analysed a dataset of scientific manuscripts that were submitted to\nvarious conferences in artificial intelligence. We performed a combination of\nsemantic, lexical and psycholinguistic analyses of the full text of the\nmanuscripts and compared them with the outcome of the peer review process. We\nfound that accepted manuscripts scored lower than rejected manuscripts on two\nindicators of readability, and that they also used more scientific and\nartificial intelligence jargon. We also found that accepted manuscripts were\nwritten with words that are less frequent, that are acquired at an older age,\nand that are more abstract than rejected manuscripts. The analysis of\nreferences included in the manuscripts revealed that the subset of accepted\nsubmissions were more likely to cite the same publications. This finding was\nechoed by pairwise comparisons of the word content of the manuscripts (i.e. an\nindicator or semantic similarity), which were more similar in the subset of\naccepted manuscripts. Finally, we predicted the peer review outcome of\nmanuscripts with their word content, with words related to machine learning and\nneural networks positively related with acceptance, whereas words related to\nlogic, symbolic processing and knowledge-based systems negatively related with\nacceptance.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 16:36:51 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 21:07:13 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Vincent-Lamarre", "Philippe", ""], ["Larivi\u00e8re", "Vincent", ""]]}, {"id": "1911.02655", "submitter": "Timothy Hazen", "authors": "Timothy J. Hazen, Shehzaad Dhuliawala, Daniel Boies", "title": "Towards Domain Adaptation from Limited Data for Question Answering Using\n  Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores domain adaptation for enabling question answering (QA)\nsystems to answer questions posed against documents in new specialized domains.\nCurrent QA systems using deep neural network (DNN) technology have proven\neffective for answering general purpose factoid-style questions. However,\ncurrent general purpose DNN models tend to be ineffective for use in new\nspecialized domains. This paper explores the effectiveness of transfer learning\ntechniques for this problem. In experiments on question answering in the\nautomobile manual domain we demonstrate that standard DNN transfer learning\ntechniques work surprisingly well in adapting DNN models to a new domain using\nlimited amounts of annotated training data in the new domain.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 22:35:00 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Hazen", "Timothy J.", ""], ["Dhuliawala", "Shehzaad", ""], ["Boies", "Daniel", ""]]}, {"id": "1911.02656", "submitter": "Karthik Bharath", "authors": "Rachel Carrington, Karthik Bharath and Simon Preston", "title": "Invariance and identifiability issues for word embeddings", "comments": "NIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are commonly obtained as optimizers of a criterion function\n$f$ of a text corpus, but assessed on word-task performance using a different\nevaluation function $g$ of the test data. We contend that a possible source of\ndisparity in performance on tasks is the incompatibility between classes of\ntransformations that leave $f$ and $g$ invariant. In particular, word\nembeddings defined by $f$ are not unique; they are defined only up to a class\nof transformations to which $f$ is invariant, and this class is larger than the\nclass to which $g$ is invariant. One implication of this is that the apparent\nsuperiority of one word embedding over another, as measured by word task\nperformance, may largely be a consequence of the arbitrary elements selected\nfrom the respective solution sets. We provide a formal treatment of the above\nidentifiability issue, present some numerical examples, and discuss possible\nresolutions.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 22:41:04 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Carrington", "Rachel", ""], ["Bharath", "Karthik", ""], ["Preston", "Simon", ""]]}, {"id": "1911.02671", "submitter": "Li Xiong", "authors": "Lee Xiong, Chuan Hu, Chenyan Xiong, Daniel Campos, Arnold Overwijk", "title": "Open Domain Web Keyphrase Extraction Beyond Language Modeling", "comments": null, "journal-ref": "EMNLP-IJCNLP 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies keyphrase extraction in real-world scenarios where\ndocuments are from diverse domains and have variant content quality. We curate\nand release OpenKP, a large scale open domain keyphrase extraction dataset with\nnear one hundred thousand web documents and expert keyphrase annotations. To\nhandle the variations of domain and content quality, we develop BLING-KPE, a\nneural keyphrase extraction model that goes beyond language understanding using\nvisual presentations of documents and weak supervision from search queries.\nExperimental results on OpenKP confirm the effectiveness of BLING-KPE and the\ncontributions of its neural architecture, visual features, and search log weak\nsupervision. Zero-shot evaluations on DUC-2001 demonstrate the improved\ngeneralization ability of learning from the open domain data compared to a\nspecific domain.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 23:12:56 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Xiong", "Lee", ""], ["Hu", "Chuan", ""], ["Xiong", "Chenyan", ""], ["Campos", "Daniel", ""], ["Overwijk", "Arnold", ""]]}, {"id": "1911.02683", "submitter": "Jesse Mu", "authors": "Jesse Mu, Percy Liang, Noah Goodman", "title": "Shaping Visual Representations with Language for Few-shot Classification", "comments": "ACL 2020. Version 1 appeared at the NeurIPS 2019 Workshop on Visually\n  Grounded Interaction and Language (ViGIL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By describing the features and abstractions of our world, language is a\ncrucial tool for human learning and a promising source of supervision for\nmachine learning models. We use language to improve few-shot visual\nclassification in the underexplored scenario where natural language task\ndescriptions are available during training, but unavailable for novel tasks at\ntest time. Existing models for this setting sample new descriptions at test\ntime and use those to classify images. Instead, we propose language-shaped\nlearning (LSL), an end-to-end model that regularizes visual representations to\npredict language. LSL is conceptually simpler, more data efficient, and\noutperforms baselines in two challenging few-shot domains.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 23:47:32 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 18:35:31 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Mu", "Jesse", ""], ["Liang", "Percy", ""], ["Goodman", "Noah", ""]]}, {"id": "1911.02690", "submitter": "Paul Crook", "authors": "Paul A. Crook, Shivani Poddar, Ankita De, Semir Shafi, David Whitney,\n  Alborz Geramifard, Rajen Subba", "title": "SIMMC: Situated Interactive Multi-Modal Conversational Data Collection\n  And Evaluation Platform", "comments": "ASRU 2019 (demonstration)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As digital virtual assistants become ubiquitous, it becomes increasingly\nimportant to understand the situated behaviour of users as they interact with\nthese assistants. To this end, we introduce SIMMC, an extension to ParlAI for\nmulti-modal conversational data collection and system evaluation. SIMMC\nsimulates an immersive setup, where crowd workers are able to interact with\nenvironments constructed in AI Habitat or Unity while engaging in a\nconversation. The assistant in SIMMC can be a crowd worker or Artificial\nIntelligent (AI) agent. This enables both (i) a multi-player / Wizard of Oz\nsetting for data collection, or (ii) a single player mode for model / system\nevaluation. We plan to open-source a situated conversational data-set collected\non this platform for the Conversational AI research community.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 00:52:38 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 19:07:39 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Crook", "Paul A.", ""], ["Poddar", "Shivani", ""], ["De", "Ankita", ""], ["Shafi", "Semir", ""], ["Whitney", "David", ""], ["Geramifard", "Alborz", ""], ["Subba", "Rajen", ""]]}, {"id": "1911.02692", "submitter": "Haoming Jiang", "authors": "Haoming Jiang, Chen Liang, Chong Wang, Tuo Zhao", "title": "Multi-Domain Neural Machine Translation with Word-Level Adaptive\n  Layer-wise Domain Mixing", "comments": null, "journal-ref": "The 58th annual meeting of the Association for Computational\n  Linguistics (ACL 2020)", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many multi-domain neural machine translation (NMT) models achieve knowledge\ntransfer by enforcing one encoder to learn shared embedding across domains.\nHowever, this design lacks adaptation to individual domains. To overcome this\nlimitation, we propose a novel multi-domain NMT model using individual modules\nfor each domain, on which we apply word-level, adaptive and layer-wise domain\nmixing. We first observe that words in a sentence are often related to multiple\ndomains. Hence, we assume each word has a domain proportion, which indicates\nits domain preference. Then word representations are obtained by mixing their\nembedding in individual domains based on their domain proportions. We show this\ncan be achieved by carefully designing multi-head dot-product attention modules\nfor different domains, and eventually taking weighted averages of their\nparameters by word-level layer-wise domain proportions. Through this, we can\nachieve effective domain knowledge sharing, and capture fine-grained\ndomain-specific knowledge as well. Our experiments show that our proposed model\noutperforms existing ones in several NMT tasks.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 00:54:06 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 19:21:33 GMT"}, {"version": "v3", "created": "Fri, 12 Feb 2021 07:30:17 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Jiang", "Haoming", ""], ["Liang", "Chen", ""], ["Wang", "Chong", ""], ["Zhao", "Tuo", ""]]}, {"id": "1911.02707", "submitter": "Houyu Zhang", "authors": "Houyu Zhang, Zhenghao Liu, Chenyan Xiong, Zhiyuan Liu", "title": "Grounded Conversation Generation as Guided Traverses in Commonsense\n  Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human conversations naturally evolve around related concepts and scatter to\nmulti-hop concepts. This paper presents a new conversation generation model,\nConceptFlow, which leverages commonsense knowledge graphs to explicitly model\nconversation flows. By grounding conversations to the concept space,\nConceptFlow represents the potential conversation flow as traverses in the\nconcept space along commonsense relations. The traverse is guided by graph\nattentions in the concept graph, moving towards more meaningful directions in\nthe concept space, in order to generate more semantic and informative\nresponses. Experiments on Reddit conversations demonstrate ConceptFlow's\neffectiveness over previous knowledge-aware conversation models and GPT-2 based\nmodels while using 70% fewer parameters, confirming the advantage of explicit\nmodeling conversation structures. All source codes of this work are available\nat https://github.com/thunlp/ConceptFlow.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 01:40:39 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 04:02:51 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 18:12:41 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Zhang", "Houyu", ""], ["Liu", "Zhenghao", ""], ["Xiong", "Chenyan", ""], ["Liu", "Zhiyuan", ""]]}, {"id": "1911.02709", "submitter": "Zhong Zhou", "authors": "Zhong Zhou, Lori Levin, David R. Mortensen, Alex Waibel", "title": "Using Interlinear Glosses as Pivot in Low-Resource Multilingual Machine\n  Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate a new approach to Neural Machine Translation (NMT) for\nlow-resource languages using a ubiquitous linguistic resource, Interlinear\nGlossed Text (IGT). IGT represents a non-English sentence as a sequence of\nEnglish lemmas and morpheme labels. As such, it can serve as a pivot or\ninterlingua for NMT. Our contribution is four-fold. Firstly, we pool IGT for\n1,497 languages in ODIN (54,545 glosses) and 70,918 glosses in Arapaho and\ntrain a gloss-to-target NMT system from IGT to English, with a BLEU score of\n25.94. We introduce a multilingual NMT model that tags all glossed text with\ngloss-source language tags and train a universal system with shared attention\nacross 1,497 languages. Secondly, we use the IGT gloss-to-target translation as\na key step in an English-Turkish MT system trained on only 865 lines from ODIN.\nThirdly, we we present five metrics for evaluating extremely low-resource\ntranslation when BLEU is no longer sufficient and evaluate the Turkish\nlow-resource system using BLEU and also using accuracy of matching nouns,\nverbs, agreement, tense, and spurious repetition, showing large improvements.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 01:45:33 GMT"}, {"version": "v2", "created": "Sun, 16 Feb 2020 05:51:32 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 14:57:40 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Zhou", "Zhong", ""], ["Levin", "Lori", ""], ["Mortensen", "David R.", ""], ["Waibel", "Alex", ""]]}, {"id": "1911.02711", "submitter": "Sen Yang", "authors": "Sen Yang, Leyang Cui, Jun Xie and Yue Zhang", "title": "Making the Best Use of Review Summary for Sentiment Analysis", "comments": "To be published in COLING-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentiment analysis provides a useful overview of customer review contents.\nMany review websites allow a user to enter a summary in addition to a full\nreview. Intuitively, summary information may give additional benefit for review\nsentiment analysis. In this paper, we conduct a study to exploit methods for\nbetter use of summary information. We start by finding out that the sentimental\nsignal distribution of a review and that of its corresponding summary are in\nfact complementary to each other. We thus explore various architectures to\nbetter guide the interactions between the two and propose a\nhierarchically-refined review-centric attention model. Empirical results show\nthat our review-centric model can make better use of user-written summaries for\nreview sentiment analysis, and is also more effective compared to existing\nmethods when the user summary is replaced with summary generated by an\nautomatic summarization system.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 01:46:54 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 07:15:01 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Yang", "Sen", ""], ["Cui", "Leyang", ""], ["Xie", "Jun", ""], ["Zhang", "Yue", ""]]}, {"id": "1911.02727", "submitter": "Chunting Zhou", "authors": "Chunting Zhou and Graham Neubig and Jiatao Gu", "title": "Understanding Knowledge Distillation in Non-autoregressive Machine\n  Translation", "comments": "fix a typo; accepted by ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-autoregressive machine translation (NAT) systems predict a sequence of\noutput tokens in parallel, achieving substantial improvements in generation\nspeed compared to autoregressive models. Existing NAT models usually rely on\nthe technique of knowledge distillation, which creates the training data from a\npretrained autoregressive model for better performance. Knowledge distillation\nis empirically useful, leading to large gains in accuracy for NAT models, but\nthe reason for this success has, as of yet, been unclear. In this paper, we\nfirst design systematic experiments to investigate why knowledge distillation\nis crucial to NAT training. We find that knowledge distillation can reduce the\ncomplexity of data sets and help NAT to model the variations in the output\ndata. Furthermore, a strong correlation is observed between the capacity of an\nNAT model and the optimal complexity of the distilled data for the best\ntranslation quality. Based on these findings, we further propose several\napproaches that can alter the complexity of data sets to improve the\nperformance of NAT models. We achieve the state-of-the-art performance for the\nNAT-based models, and close the gap with the autoregressive baseline on WMT14\nEn-De benchmark.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 02:47:26 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 05:20:18 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2021 20:17:07 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Zhou", "Chunting", ""], ["Neubig", "Graham", ""], ["Gu", "Jiatao", ""]]}, {"id": "1911.02733", "submitter": "Xue Mengge", "authors": "Xue Mengge, Yu Bowen, Liu Tingwen, Zhang Yue, Meng Erli, Wang Bin", "title": "Porous Lattice-based Transformer Encoder for Chinese NER", "comments": "9 pages, 4 figures", "journal-ref": "COLING 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating lattices into character-level Chinese named entity recognition\nis an effective method to exploit explicit word information. Recent works\nextend recurrent and convolutional neural networks to model lattice inputs.\nHowever, due to the DAG structure or the variable-sized potential word set for\nlattice inputs, these models prevent the convenient use of batched computation,\nresulting in serious inefficient. In this paper, we propose a porous\nlattice-based transformer encoder for Chinese named entity recognition, which\nis capable to better exploit the GPU parallelism and batch the computation\nowing to the mask mechanism in transformer. We first investigate the\nlattice-aware self-attention coupled with relative position representations to\nexplore effective word information in the lattice structure. Besides, to\nstrengthen the local dependencies among neighboring tokens, we propose a novel\nporous structure during self-attentional computation processing, in which every\ntwo non-neighboring tokens are connected through a shared pivot node.\nExperimental results on four datasets show that our model performs up to 9.47\ntimes faster than state-of-the-art models, while is roughly on a par with its\nperformance. The source code of this paper can be obtained from\nhttps://github.com/xxx/xxx.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 02:58:17 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 14:46:51 GMT"}, {"version": "v3", "created": "Wed, 28 Oct 2020 12:52:24 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Mengge", "Xue", ""], ["Bowen", "Yu", ""], ["Tingwen", "Liu", ""], ["Yue", "Zhang", ""], ["Erli", "Meng", ""], ["Bin", "Wang", ""]]}, {"id": "1911.02737", "submitter": "Wei Zhang", "authors": "Wei Zhang, Feifei Lin, Xiaodong Wang, Zhenshuang Liang, Zhen Huang", "title": "SubCharacter Chinese-English Neural Machine Translation with Wubi\n  encoding", "comments": "10 pages, 3 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) is one of the best methods for understanding\nthe differences in semantic rules between two languages. Especially for\nIndo-European languages, subword-level models have achieved impressive results.\nHowever, when the translation task involves Chinese, semantic granularity\nremains at the word and character level, so there is still need more\nfine-grained translation model of Chinese. In this paper, we introduce a simple\nand effective method for Chinese translation at the sub-character level. Our\napproach uses the Wubi method to translate Chinese into English; byte-pair\nencoding (BPE) is then applied. Our method for Chinese-English translation\neliminates the need for a complicated word segmentation algorithm during\npreprocessing. Furthermore, our method allows for sub-character-level neural\ntranslation based on recurrent neural network (RNN) architecture, without\npreprocessing. The empirical results show that for Chinese-English translation\ntasks, our sub-character-level model has a comparable BLEU score to the subword\nmodel, despite having a much smaller vocabulary. Additionally, the small\nvocabulary is highly advantageous for NMT model compression.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 03:13:26 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Zhang", "Wei", ""], ["Lin", "Feifei", ""], ["Wang", "Xiaodong", ""], ["Liang", "Zhenshuang", ""], ["Huang", "Zhen", ""]]}, {"id": "1911.02739", "submitter": "Zhihan Zhang", "authors": "Zhihan Zhang, Zhiyi Yin, Shuhuai Ren, Xinhang Li, Shicheng Li", "title": "DCA: Diversified Co-Attention towards Informative Live Video Commenting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the task of Automatic Live Video Commenting (ALVC), which aims to\ngenerate real-time video comments with both video frames and other viewers'\ncomments as inputs. A major challenge in this task is how to properly leverage\nthe rich and diverse information carried by video and text. In this paper, we\naim to collect diversified information from video and text for informative\ncomment generation. To achieve this, we propose a Diversified Co-Attention\n(DCA) model for this task. Our model builds bidirectional interactions between\nvideo frames and surrounding comments from multiple perspectives via metric\nlearning, to collect a diversified and informative context for comment\ngeneration. We also propose an effective parameter orthogonalization technique\nto avoid excessive overlap of information learned from different perspectives.\nResults show that our approach outperforms existing methods in the ALVC task,\nachieving new state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 03:28:38 GMT"}, {"version": "v2", "created": "Sat, 4 Apr 2020 05:14:34 GMT"}, {"version": "v3", "created": "Sat, 8 Aug 2020 13:37:10 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Zhang", "Zhihan", ""], ["Yin", "Zhiyi", ""], ["Ren", "Shuhuai", ""], ["Li", "Xinhang", ""], ["Li", "Shicheng", ""]]}, {"id": "1911.02747", "submitter": "Zhenxin Fu", "authors": "Zhenxin Fu, Feng Ji, Wenpeng Hu, Wei Zhou, Dongyan Zhao, Haiqing Chen,\n  Rui Yan", "title": "Query-bag Matching with Mutual Coverage for Information-seeking\n  Conversations in E-commerce", "comments": "CIKM 2019 Short", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information-seeking conversation system aims at satisfying the information\nneeds of users through conversations. Text matching between a user query and a\npre-collected question is an important part of the information-seeking\nconversation in E-commerce. In the practical scenario, a sort of questions\nalways correspond to a same answer. Naturally, these questions can form a bag.\nLearning the matching between user query and bag directly may improve the\nconversation performance, denoted as query-bag matching. Inspired by such\nopinion, we propose a query-bag matching model which mainly utilizes the mutual\ncoverage between query and bag and measures the degree of the content in the\nquery mentioned by the bag, and vice verse. In addition, the learned bag\nrepresentation in word level helps find the main points of a bag in a fine\ngrade and promotes the query-bag matching performance. Experiments on two\ndatasets show the effectiveness of our model.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 04:11:03 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Fu", "Zhenxin", ""], ["Ji", "Feng", ""], ["Hu", "Wenpeng", ""], ["Zhou", "Wei", ""], ["Zhao", "Dongyan", ""], ["Chen", "Haiqing", ""], ["Yan", "Rui", ""]]}, {"id": "1911.02750", "submitter": "Mingbo Ma", "authors": "Mingbo Ma, Baigong Zheng, Kaibo Liu, Renjie Zheng, Hairong Liu, Kainan\n  Peng, Kenneth Church, Liang Huang", "title": "Incremental Text-to-Speech Synthesis with Prefix-to-Prefix Framework", "comments": "Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-to-speech synthesis (TTS) has witnessed rapid progress in recent years,\nwhere neural methods became capable of producing audios with high naturalness.\nHowever, these efforts still suffer from two types of latencies: (a) the {\\em\ncomputational latency} (synthesizing time), which grows linearly with the\nsentence length even with parallel approaches, and (b) the {\\em input latency}\nin scenarios where the input text is incrementally generated (such as in\nsimultaneous translation, dialog generation, and assistive technologies). To\nreduce these latencies, we devise the first neural incremental TTS approach\nbased on the recently proposed prefix-to-prefix framework. We synthesize speech\nin an online fashion, playing a segment of audio while generating the next,\nresulting in an $O(1)$ rather than $O(n)$ latency.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 04:22:54 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 02:14:34 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 01:58:17 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Ma", "Mingbo", ""], ["Zheng", "Baigong", ""], ["Liu", "Kaibo", ""], ["Zheng", "Renjie", ""], ["Liu", "Hairong", ""], ["Peng", "Kainan", ""], ["Church", "Kenneth", ""], ["Huang", "Liang", ""]]}, {"id": "1911.02782", "submitter": "Lucy Lu Wang", "authors": "Kyle Lo, Lucy Lu Wang, Mark Neumann, Rodney Kinney, Dan S. Weld", "title": "S2ORC: The Semantic Scholar Open Research Corpus", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce S2ORC, a large corpus of 81.1M English-language academic papers\nspanning many academic disciplines. The corpus consists of rich metadata, paper\nabstracts, resolved bibliographic references, as well as structured full text\nfor 8.1M open access papers. Full text is annotated with automatically-detected\ninline mentions of citations, figures, and tables, each linked to their\ncorresponding paper objects. In S2ORC, we aggregate papers from hundreds of\nacademic publishers and digital archives into a unified source, and create the\nlargest publicly-available collection of machine-readable academic text to\ndate. We hope this resource will facilitate research and development of tools\nand tasks for text mining over academic text.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 07:34:43 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 03:48:03 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 00:40:21 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Lo", "Kyle", ""], ["Wang", "Lucy Lu", ""], ["Neumann", "Mark", ""], ["Kinney", "Rodney", ""], ["Weld", "Dan S.", ""]]}, {"id": "1911.02808", "submitter": "Ratish Puduppully", "authors": "Ratish Puduppully, Yue Zhang, Manish Shrivastava", "title": "Transition-Based Deep Input Linearization", "comments": "Published in EACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional methods for deep NLG adopt pipeline approaches comprising stages\nsuch as constructing syntactic input, predicting function words, linearizing\nthe syntactic input and generating the surface forms. Though easier to\nvisualize, pipeline approaches suffer from error propagation. In addition,\ninformation available across modules cannot be leveraged by all modules. We\nconstruct a transition-based model to jointly perform linearization, function\nword prediction and morphological generation, which considerably improves upon\nthe accuracy compared to a pipelined baseline system. On a standard deep input\nlinearization shared task, our system achieves the best results reported so\nfar.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 08:58:02 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Puduppully", "Ratish", ""], ["Zhang", "Yue", ""], ["Shrivastava", "Manish", ""]]}, {"id": "1911.02821", "submitter": "Yanzeng Li", "authors": "Yanzeng Li, Bowen Yu, Mengge Xue, Tingwen Liu", "title": "Enhancing Pre-trained Chinese Character Representation with Word-aligned\n  Attention", "comments": "Accepted to appear at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most Chinese pre-trained models take character as the basic unit and learn\nrepresentation according to character's external contexts, ignoring the\nsemantics expressed in the word, which is the smallest meaningful utterance in\nChinese. Hence, we propose a novel word-aligned attention to exploit explicit\nword information, which is complementary to various character-based Chinese\npre-trained language models. Specifically, we devise a pooling mechanism to\nalign the character-level attention to the word level and propose to alleviate\nthe potential issue of segmentation error propagation by multi-source\ninformation fusion. As a result, word and character information are explicitly\nintegrated at the fine-tuning procedure. Experimental results on five Chinese\nNLP benchmark tasks demonstrate that our model could bring another significant\ngain over several pre-trained models.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 09:50:21 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 04:29:33 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Li", "Yanzeng", ""], ["Yu", "Bowen", ""], ["Xue", "Mengge", ""], ["Liu", "Tingwen", ""]]}, {"id": "1911.02825", "submitter": "Wangchunshu Zhou", "authors": "Wangchunshu Zhou, Tao Ge, Chang Mu, Ke Xu, Furu Wei, Ming Zhou", "title": "Improving Grammatical Error Correction with Machine Translation Pairs", "comments": "EMNLP 2020 Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel data synthesis method to generate diverse error-corrected\nsentence pairs for improving grammatical error correction, which is based on a\npair of machine translation models of different qualities (i.e., poor and\ngood). The poor translation model resembles the ESL (English as a second\nlanguage) learner and tends to generate translations of low quality in terms of\nfluency and grammatical correctness, while the good translation model generally\ngenerates fluent and grammatically correct translations. We build the poor and\ngood translation model with phrase-based statistical machine translation model\nwith decreased language model weight and neural machine translation model\nrespectively. By taking the pair of their translations of the same sentences in\na bridge language as error-corrected sentence pairs, we can construct unlimited\npseudo parallel data. Our approach is capable of generating diverse\nfluency-improving patterns without being limited by the pre-defined rule set\nand the seed error-corrected data. Experimental results demonstrate the\neffectiveness of our approach and show that it can be combined with other\nsynthetic data sources to yield further improvements.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 10:08:04 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 17:21:51 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Zhou", "Wangchunshu", ""], ["Ge", "Tao", ""], ["Mu", "Chang", ""], ["Xu", "Ke", ""], ["Wei", "Furu", ""], ["Zhou", "Ming", ""]]}, {"id": "1911.02839", "submitter": "Rui Liu", "authors": "Rui Liu, Berrak Sisman, Jingdong Li, Feilong Bao, Guanglai Gao,\n  Haizhou Li", "title": "Teacher-Student Training for Robust Tacotron-based TTS", "comments": "To appear at ICASSP2020, Barcelona, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural end-to-end text-to-speech (TTS) is superior to conventional\nstatistical methods in many ways, the exposure bias problem in the\nautoregressive models remains an issue to be resolved. The exposure bias\nproblem arises from the mismatch between the training and inference process,\nthat results in unpredictable performance for out-of-domain test data at\nrun-time. To overcome this, we propose a teacher-student training scheme for\nTacotron-based TTS by introducing a distillation loss function in addition to\nthe feature loss function. We first train a Tacotron2-based TTS model by always\nproviding natural speech frames to the decoder, that serves as a teacher model.\nWe then train another Tacotron2-based model as a student model, of which the\ndecoder takes the predicted speech frames as input, similar to how the decoder\nworks during run-time inference. With the distillation loss, the student model\nlearns the output probabilities from the teacher model, that is called\nknowledge distillation. Experiments show that our proposed training scheme\nconsistently improves the voice quality for out-of-domain test data both in\nChinese and English systems.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 10:47:30 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 15:20:19 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Liu", "Rui", ""], ["Sisman", "Berrak", ""], ["Li", "Jingdong", ""], ["Bao", "Feilong", ""], ["Gao", "Guanglai", ""], ["Li", "Haizhou", ""]]}, {"id": "1911.02847", "submitter": "Raphael Tang", "authors": "Yinan Zhang, Raphael Tang, Jimmy Lin", "title": "Explicit Pairwise Word Interaction Modeling Improves Pretrained\n  Transformers for English Semantic Similarity Tasks", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In English semantic similarity tasks, classic word embedding-based approaches\nexplicitly model pairwise \"interactions\" between the word representations of a\nsentence pair. Transformer-based pretrained language models disregard this\nnotion, instead modeling pairwise word interactions globally and implicitly\nthrough their self-attention mechanism. In this paper, we hypothesize that\nintroducing an explicit, constrained pairwise word interaction mechanism to\npretrained language models improves their effectiveness on semantic similarity\ntasks. We validate our hypothesis using BERT on four tasks in semantic textual\nsimilarity and answer sentence selection. We demonstrate consistent\nimprovements in quality by adding an explicit pairwise word interaction module\nto BERT.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 10:59:40 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Zhang", "Yinan", ""], ["Tang", "Raphael", ""], ["Lin", "Jimmy", ""]]}, {"id": "1911.02850", "submitter": "Rishiraj Saha Roy", "authors": "Magdalena Kaiser, Rishiraj Saha Roy, Gerhard Weikum", "title": "CROWN: Conversational Passage Ranking by Reasoning over Word Networks", "comments": "TREC 2019, 14 pages", "journal-ref": "TREC 2019", "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information needs around a topic cannot be satisfied in a single turn; users\ntypically ask follow-up questions referring to the same theme and a system must\nbe capable of understanding the conversational context of a request to retrieve\ncorrect answers. In this paper, we present our submission to the TREC\nConversational Assistance Track 2019, in which such a conversational setting is\nexplored. We propose a simple unsupervised method for conversational passage\nranking by formulating the passage score for a query as a combination of\nsimilarity and coherence. To be specific, passages are preferred that contain\nwords semantically similar to the words used in the question, and where such\nwords appear close by. We built a word-proximity network (WPN) from a large\ncorpus, where words are nodes and there is an edge between two nodes if they\nco-occur in the same passages in a statistically significant way, within a\ncontext window. Our approach, named CROWN, improved nDCG scores over a provided\nIndri baseline on the CAsT training data. On the evaluation data for CAsT, our\nbest run submission achieved above-average performance with respect to AP@5 and\nnDCG@1000.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 11:02:21 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 23:54:15 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 10:36:32 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Kaiser", "Magdalena", ""], ["Roy", "Rishiraj Saha", ""], ["Weikum", "Gerhard", ""]]}, {"id": "1911.02851", "submitter": "Zuchao Li", "authors": "Zuchao Li, Hai Zhao, Junru Zhou, Kevin Parnow, Shexia He", "title": "Dependency and Span, Cross-Style Semantic Role Labeling on PropBank and\n  NomBank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The latest developments in neural semantic role labeling (SRL) have shown\ngreat performance improvements with both the dependency and span\nformalisms/styles. Although the two styles share many similarities in\nlinguistic meaning and computation, most previous studies focus on a single\nstyle. In this paper, we define a new cross-style semantic role label\nconvention and propose a new cross-style joint optimization model designed\naround the most basic linguistic meaning of a semantic role, providing a\nsolution to make the results of the two styles more comparable and allowing\nboth formalisms of SRL to benefit from their natural connections in both\nlinguistics and computation. Our model learns a general semantic argument\nstructure and is capable of outputting in either style. Additionally, we\npropose a syntax-aided method to uniformly enhance the learning of both\ndependency and span representations. Experiments show that the proposed methods\nare effective on both span and dependency SRL benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 11:02:39 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 06:37:06 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Li", "Zuchao", ""], ["Zhao", "Hai", ""], ["Zhou", "Junru", ""], ["Parnow", "Kevin", ""], ["He", "Shexia", ""]]}, {"id": "1911.02855", "submitter": "Jiwei Li", "authors": "Xiaoya Li, Xiaofei Sun, Yuxian Meng, Junjun Liang, Fei Wu and Jiwei Li", "title": "Dice Loss for Data-imbalanced NLP Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many NLP tasks such as tagging and machine reading comprehension are faced\nwith the severe data imbalance issue: negative examples significantly outnumber\npositive examples, and the huge number of background examples (or easy-negative\nexamples) overwhelms the training. The most commonly used cross entropy (CE)\ncriteria is actually an accuracy-oriented objective, and thus creates a\ndiscrepancy between training and test: at training time, each training instance\ncontributes equally to the objective function, while at test time F1 score\nconcerns more about positive examples. In this paper, we propose to use dice\nloss in replacement of the standard cross-entropy objective for data-imbalanced\nNLP tasks. Dice loss is based on the Sorensen-Dice coefficient or Tversky\nindex, which attaches similar importance to false positives and false\nnegatives, and is more immune to the data-imbalance issue. To further alleviate\nthe dominating influence from easy-negative examples in training, we propose to\nassociate training examples with dynamically adjusted weights to deemphasize\neasy-negative examples.Theoretical analysis shows that this strategy narrows\ndown the gap between the F1 score in evaluation and the dice loss in training.\nWith the proposed training objective, we observe significant performance boost\non a wide range of data imbalanced NLP tasks. Notably, we are able to achieve\nSOTA results on CTB5, CTB6 and UD1.4 for the part of speech tagging task; SOTA\nresults on CoNLL03, OntoNotes5.0, MSRA and OntoNotes4.0 for the named entity\nrecognition task; along with competitive results on the tasks of machine\nreading comprehension and paraphrase identification.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 11:14:05 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 10:24:50 GMT"}, {"version": "v3", "created": "Sat, 29 Aug 2020 06:59:03 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Li", "Xiaoya", ""], ["Sun", "Xiaofei", ""], ["Meng", "Yuxian", ""], ["Liang", "Junjun", ""], ["Wu", "Fei", ""], ["Li", "Jiwei", ""]]}, {"id": "1911.02891", "submitter": "Lifu Tu", "authors": "Lifu Tu, Richard Yuanzhe Pang, Kevin Gimpel", "title": "Improving Joint Training of Inference Networks and Structured Prediction\n  Energy Networks", "comments": "EMNLP 2020 Workshop on Structured Prediction for NLP (SPNLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep energy-based models are powerful, but pose challenges for learning and\ninference (Belanger and McCallum, 2016). Tu and Gimpel (2018) developed an\nefficient framework for energy-based models by training \"inference networks\" to\napproximate structured inference instead of using gradient descent. However,\ntheir alternating optimization approach suffers from instabilities during\ntraining, requiring additional loss terms and careful hyperparameter tuning. In\nthis paper, we contribute several strategies to stabilize and improve this\njoint training of energy functions and inference networks for structured\nprediction. We design a compound objective to jointly train both cost-augmented\nand test-time inference networks along with the energy function. We propose\njoint parameterizations for the inference networks that encourage them to\ncapture complementary functionality during learning. We empirically validate\nour strategies on two sequence labeling tasks, showing easier paths to strong\nperformance than prior work, as well as further improvements with global energy\nterms.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 13:26:07 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 16:19:50 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Tu", "Lifu", ""], ["Pang", "Richard Yuanzhe", ""], ["Gimpel", "Kevin", ""]]}, {"id": "1911.02896", "submitter": "Jinhyuk Lee", "authors": "Jinhyuk Lee, Minjoon Seo, Hannaneh Hajishirzi, Jaewoo Kang", "title": "Contextualized Sparse Representations for Real-Time Open-Domain Question\n  Answering", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-domain question answering can be formulated as a phrase retrieval\nproblem, in which we can expect huge scalability and speed benefit but often\nsuffer from low accuracy due to the limitation of existing phrase\nrepresentation models. In this paper, we aim to improve the quality of each\nphrase embedding by augmenting it with a contextualized sparse representation\n(Sparc). Unlike previous sparse vectors that are term-frequency-based (e.g.,\ntf-idf) or directly learned (only few thousand dimensions), we leverage\nrectified self-attention to indirectly learn sparse vectors in n-gram\nvocabulary space. By augmenting the previous phrase retrieval model (Seo et\nal., 2019) with Sparc, we show 4%+ improvement in CuratedTREC and SQuAD-Open.\nOur CuratedTREC score is even better than the best known retrieve & read model\nwith at least 45x faster inference speed.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 13:34:54 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 06:36:08 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Lee", "Jinhyuk", ""], ["Seo", "Minjoon", ""], ["Hajishirzi", "Hannaneh", ""], ["Kang", "Jaewoo", ""]]}, {"id": "1911.02898", "submitter": "Lo\\\"ic Vial", "authors": "Lo\\\"ic Vial, Benjamin Lecouteux, Didier Schwab, Hang Le and Laurent\n  Besacier", "title": "The LIG system for the English-Czech Text Translation Task of IWSLT 2019", "comments": "IWSLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present our submission for the English to Czech Text\nTranslation Task of IWSLT 2019. Our system aims to study how pre-trained\nlanguage models, used as input embeddings, can improve a specialized machine\ntranslation system trained on few data. Therefore, we implemented a\nTransformer-based encoder-decoder neural system which is able to use the output\nof a pre-trained language model as input embeddings, and we compared its\nperformance under three configurations: 1) without any pre-trained language\nmodel (constrained), 2) using a language model trained on the monolingual parts\nof the allowed English-Czech data (constrained), and 3) using a language model\ntrained on a large quantity of external monolingual data (unconstrained). We\nused BERT as external pre-trained language model (configuration 3), and BERT\narchitecture for training our own language model (configuration 2). Regarding\nthe training data, we trained our MT system on a small quantity of parallel\ntext: one set only consists of the provided MuST-C corpus, and the other set\nconsists of the MuST-C corpus and the News Commentary corpus from WMT. We\nobserved that using the external pre-trained BERT improves the scores of our\nsystem by +0.8 to +1.5 of BLEU on our development set, and +0.97 to +1.94 of\nBLEU on the test set. However, using our own language model trained only on the\nallowed parallel data seems to improve the machine translation performances\nonly when the system is trained on the smallest dataset.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 13:40:54 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Vial", "Lo\u00efc", ""], ["Lecouteux", "Benjamin", ""], ["Schwab", "Didier", ""], ["Le", "Hang", ""], ["Besacier", "Laurent", ""]]}, {"id": "1911.02914", "submitter": "Wenpeng Hu", "authors": "Wenpeng Hu, Mengyu Wang, Bing Liu, Feng Ji, Haiqing Chen, Dongyan\n  Zhao, Jinwen Ma, Rui Yan", "title": "Transformation of Dense and Sparse Text Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparsity is regarded as a desirable property of representations, especially\nin terms of explanation. However, its usage has been limited due to the gap\nwith dense representations. Most NLP research progresses in recent years are\nbased on dense representations. Thus the desirable property of sparsity cannot\nbe leveraged. Inspired by Fourier Transformation, in this paper, we propose a\nnovel Semantic Transformation method to bridge the dense and sparse spaces,\nwhich can facilitate the NLP research to shift from dense space to sparse space\nor to jointly use both spaces. The key idea of the proposed approach is to use\na Forward Transformation to transform dense representations to sparse\nrepresentations. Then some useful operations in the sparse space can be\nperformed over the sparse representations, and the sparse representations can\nbe used directly to perform downstream tasks such as text classification and\nnatural language inference. Then, a Backward Transformation can also be carried\nout to transform those processed sparse representations to dense\nrepresentations. Experiments using classification tasks and natural language\ninference task show that the proposed Semantic Transformation is effective.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 14:06:36 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Hu", "Wenpeng", ""], ["Wang", "Mengyu", ""], ["Liu", "Bing", ""], ["Ji", "Feng", ""], ["Chen", "Haiqing", ""], ["Zhao", "Dongyan", ""], ["Ma", "Jinwen", ""], ["Yan", "Rui", ""]]}, {"id": "1911.02929", "submitter": "Leyang Cui", "authors": "Yile Wang, Leyang Cui, Yue Zhang", "title": "How Can BERT Help Lexical Semantics Tasks?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextualized embeddings such as BERT can serve as strong input\nrepresentations to NLP tasks, outperforming their static embeddings\ncounterparts such as skip-gram, CBOW and GloVe. However, such embeddings are\ndynamic, calculated according to a sentence-level context, which limits their\nuse in lexical semantics tasks. We address this issue by making use of dynamic\nembeddings as word representations in training static embeddings, thereby\nleveraging their strong representation power for disambiguating context\ninformation. Results show that this method leads to improvements over\ntraditional static embeddings on a range of lexical semantics tasks, obtaining\nthe best reported results on seven datasets.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 14:23:05 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 04:28:03 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Wang", "Yile", ""], ["Cui", "Leyang", ""], ["Zhang", "Yue", ""]]}, {"id": "1911.02969", "submitter": "Tom McCoy", "authors": "R. Thomas McCoy and Junghyun Min and Tal Linzen", "title": "BERTs of a feather do not generalize together: Large variability in\n  generalization across models with similar test set performance", "comments": "11 pages, 7 figures; accepted to the 2020 BlackboxNLP workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If the same neural network architecture is trained multiple times on the same\ndataset, will it make similar linguistic generalizations across runs? To study\nthis question, we fine-tuned 100 instances of BERT on the Multi-genre Natural\nLanguage Inference (MNLI) dataset and evaluated them on the HANS dataset, which\nevaluates syntactic generalization in natural language inference. On the MNLI\ndevelopment set, the behavior of all instances was remarkably consistent, with\naccuracy ranging between 83.6% and 84.8%. In stark contrast, the same models\nvaried widely in their generalization performance. For example, on the simple\ncase of subject-object swap (e.g., determining that \"the doctor visited the\nlawyer\" does not entail \"the lawyer visited the doctor\"), accuracy ranged from\n0.00% to 66.2%. Such variation is likely due to the presence of many local\nminima that are equally attractive to a low-bias learner such as a neural\nnetwork; decreasing the variability may therefore require models with stronger\ninductive biases.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 16:20:40 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 18:02:49 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["McCoy", "R. Thomas", ""], ["Min", "Junghyun", ""], ["Linzen", "Tal", ""]]}, {"id": "1911.02970", "submitter": "Liang Ma", "authors": "Swati Rallapalli, Liang Ma, Mudhakar Srivatsa, Ananthram Swami,\n  Heesung Kwon, Graham Bent, Christopher Simpkin", "title": "SENSE: Semantically Enhanced Node Sequence Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effectively capturing graph node sequences in the form of vector embeddings\nis critical to many applications. We achieve this by (i) first learning vector\nembeddings of single graph nodes and (ii) then composing them to compactly\nrepresent node sequences. Specifically, we propose SENSE-S (Semantically\nEnhanced Node Sequence Embedding - for Single nodes), a skip-gram based novel\nembedding mechanism, for single graph nodes that co-learns graph structure as\nwell as their textual descriptions. We demonstrate that SENSE-S vectors\nincrease the accuracy of multi-label classification tasks by up to 50% and\nlink-prediction tasks by up to 78% under a variety of scenarios using real\ndatasets. Based on SENSE-S, we next propose generic SENSE to compute composite\nvectors that represent a sequence of nodes, where preserving the node order is\nimportant. We prove that this approach is efficient in embedding node\nsequences, and our experiments on real data confirm its high accuracy in node\norder decoding.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 16:21:40 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Rallapalli", "Swati", ""], ["Ma", "Liang", ""], ["Srivatsa", "Mudhakar", ""], ["Swami", "Ananthram", ""], ["Kwon", "Heesung", ""], ["Bent", "Graham", ""], ["Simpkin", "Christopher", ""]]}, {"id": "1911.02971", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang, Rui Wang, Kehai Chen, Masao Utiyama, Eiichiro Sumita,\n  Hai Zhao", "title": "Probing Contextualized Sentence Representations with Visual Awareness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a universal framework to model contextualized sentence\nrepresentations with visual awareness that is motivated to overcome the\nshortcomings of the multimodal parallel data with manual annotations. For each\nsentence, we first retrieve a diversity of images from a shared cross-modal\nembedding space, which is pre-trained on a large-scale of text-image pairs.\nThen, the texts and images are respectively encoded by transformer encoder and\nconvolutional neural network. The two sequences of representations are further\nfused by a simple and effective attention layer. The architecture can be easily\napplied to text-only natural language processing tasks without manually\nannotating multimodal parallel corpora. We apply the proposed method on three\ntasks, including neural machine translation, natural language inference and\nsequence labeling and experimental results verify the effectiveness.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 16:34:31 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["Wang", "Rui", ""], ["Chen", "Kehai", ""], ["Utiyama", "Masao", ""], ["Sumita", "Eiichiro", ""], ["Zhao", "Hai", ""]]}, {"id": "1911.02972", "submitter": "Jiezhong Qiu", "authors": "Jiezhong Qiu, Hao Ma, Omer Levy, Scott Wen-tau Yih, Sinong Wang, Jie\n  Tang", "title": "Blockwise Self-Attention for Long Document Understanding", "comments": "Accepted at Findings of EMNLP'20 and SustaiNLP 2020 at EMNLP'20, 12\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present BlockBERT, a lightweight and efficient BERT model for better\nmodeling long-distance dependencies. Our model extends BERT by introducing\nsparse block structures into the attention matrix to reduce both memory\nconsumption and training/inference time, which also enables attention heads to\ncapture either short- or long-range contextual information. We conduct\nexperiments on language model pre-training and several benchmark question\nanswering datasets with various paragraph lengths. BlockBERT uses 18.7-36.1%\nless memory and 12.0-25.1% less time to learn the model. During testing,\nBlockBERT saves 27.8% inference time, while having comparable and sometimes\nbetter prediction accuracy, compared to an advanced BERT-based model, RoBERTa.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 16:35:53 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 12:48:03 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Qiu", "Jiezhong", ""], ["Ma", "Hao", ""], ["Levy", "Omer", ""], ["Yih", "Scott Wen-tau", ""], ["Wang", "Sinong", ""], ["Tang", "Jie", ""]]}, {"id": "1911.02984", "submitter": "Vittorio Castelli", "authors": "Vittorio Castelli, Rishav Chakravarti, Saswati Dana, Anthony Ferritto,\n  Radu Florian, Martin Franz, Dinesh Garg, Dinesh Khandelwal, Scott McCarley,\n  Mike McCawley, Mohamed Nasr, Lin Pan, Cezar Pendus, John Pitrelli, Saurabh\n  Pujar, Salim Roukos, Andrzej Sakrajda, Avirup Sil, Rosario Uceda-Sosa, Todd\n  Ward, Rong Zhang", "title": "The TechQA Dataset", "comments": "Long version of conference paper to be submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce TechQA, a domain-adaptation question answering dataset for the\ntechnical support domain. The TechQA corpus highlights two real-world issues\nfrom the automated customer support domain. First, it contains actual questions\nposed by users on a technical forum, rather than questions generated\nspecifically for a competition or a task. Second, it has a real-world size --\n600 training, 310 dev, and 490 evaluation question/answer pairs -- thus\nreflecting the cost of creating large labeled datasets with actual data.\nConsequently, TechQA is meant to stimulate research in domain adaptation rather\nthan being a resource to build QA systems from scratch. The dataset was\nobtained by crawling the IBM Developer and IBM DeveloperWorks forums for\nquestions with accepted answers that appear in a published IBM Technote---a\ntechnical document that addresses a specific technical issue. We also release a\ncollection of the 801,998 publicly available Technotes as of April 4, 2019 as a\ncompanion resource that might be used for pretraining, to learn representations\nof the IT domain language.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 02:04:39 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Castelli", "Vittorio", ""], ["Chakravarti", "Rishav", ""], ["Dana", "Saswati", ""], ["Ferritto", "Anthony", ""], ["Florian", "Radu", ""], ["Franz", "Martin", ""], ["Garg", "Dinesh", ""], ["Khandelwal", "Dinesh", ""], ["McCarley", "Scott", ""], ["McCawley", "Mike", ""], ["Nasr", "Mohamed", ""], ["Pan", "Lin", ""], ["Pendus", "Cezar", ""], ["Pitrelli", "John", ""], ["Pujar", "Saurabh", ""], ["Roukos", "Salim", ""], ["Sakrajda", "Andrzej", ""], ["Sil", "Avirup", ""], ["Uceda-Sosa", "Rosario", ""], ["Ward", "Todd", ""], ["Zhang", "Rong", ""]]}, {"id": "1911.02989", "submitter": "Jimmy Lin", "authors": "Peng Shi and Jimmy Lin", "title": "Cross-Lingual Relevance Transfer for Document Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown the surprising ability of multi-lingual BERT to serve\nas a zero-shot cross-lingual transfer model for a number of language processing\ntasks. We combine this finding with a similarly-recently proposal on\nsentence-level relevance modeling for document retrieval to demonstrate the\nability of multi-lingual BERT to transfer models of relevance across languages.\nExperiments on test collections in five different languages from diverse\nlanguage families (Chinese, Arabic, French, Hindi, and Bengali) show that\nmodels trained with English data improve ranking quality, without any special\nprocessing, both for (non-English) mono-lingual retrieval as well as\ncross-lingual retrieval.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 02:19:52 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Shi", "Peng", ""], ["Lin", "Jimmy", ""]]}, {"id": "1911.03014", "submitter": "Simeng Han", "authors": "Simeng Han, Xiang Lin and Shafiq Joty", "title": "Resurrecting Submodularity for Neural Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodularity is desirable for a variety of objectives in content selection\nwhere the current neural encoder-decoder framework is inadequate. However, it\nhas so far not been explored in the neural encoder-decoder system for text\ngeneration. In this work, we define diminishing attentions with submodular\nfunctions and in turn, prove the submodularity of the effective neural\ncoverage. The greedy algorithm approximating the solution to the submodular\nmaximization problem is not suited to attention score optimization in\nauto-regressive generation. Therefore instead of following how submodular\nfunction has been widely used, we propose a simplified yet principled solution.\nThe resulting attention module offers an architecturally simple and empirically\neffective method to improve the coverage of neural text generation. We run\nexperiments on three directed text generation tasks with different levels of\nrecovering rate, across two modalities, three different neural model\narchitectures and two training strategy variations. The results and analyses\ndemonstrate that our method generalizes well across these settings, produces\ntexts of good quality and outperforms state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 03:17:54 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 16:47:33 GMT"}, {"version": "v3", "created": "Sun, 4 Oct 2020 08:09:57 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Han", "Simeng", ""], ["Lin", "Xiang", ""], ["Joty", "Shafiq", ""]]}, {"id": "1911.03024", "submitter": "Sunjae Kwon", "authors": "Sunjae Kwon, Cheongwoong Kang, Jiyeon Han, Jaesik Choi", "title": "Why Do Masked Neural Language Models Still Need Common Sense Knowledge?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, contextualized word representations are learned by intricate\nneural network models, such as masked neural language models (MNLMs). The new\nrepresentations significantly enhanced the performance in automated question\nanswering by reading paragraphs. However, identifying the detailed knowledge\ntrained in the MNLMs is difficult owing to numerous and intermingled\nparameters. This paper provides empirical but insightful analyses on the\npretrained MNLMs with respect to common sense knowledge. First, we propose a\ntest that measures what types of common sense knowledge do pretrained MNLMs\nunderstand. From the test, we observed that MNLMs partially understand various\ntypes of common sense knowledge but do not accurately understand the semantic\nmeaning of relations. In addition, based on the difficulty of the\nquestion-answering task problems, we observed that pretrained MLM-based models\nare still vulnerable to problems that require common sense knowledge. We also\nexperimentally demonstrated that we can elevate existing MNLM-based models by\ncombining knowledge from an external common sense repository.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 03:45:55 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Kwon", "Sunjae", ""], ["Kang", "Cheongwoong", ""], ["Han", "Jiyeon", ""], ["Choi", "Jaesik", ""]]}, {"id": "1911.03042", "submitter": "Shikhar Vashishth", "authors": "Shikhar Vashishth", "title": "Neural Graph Embedding Methods for Natural Language Processing", "comments": "168 pages, PhD thesis (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs are structured representations of facts in a graph, where\nnodes represent entities and edges represent relationships between them. Recent\nresearch has resulted in the development of several large KGs. However, all of\nthem tend to be sparse with very few facts per entity. In the first part of the\nthesis, we propose two solutions to alleviate this problem: (1) KG\nCanonicalization, i.e., identifying and merging duplicate entities in a KG, (2)\nRelation Extraction which involves automating the process of extracting\nsemantic relationships between entities from unstructured text. Traditional\nNeural Networks like CNNs and RNNs are constrained to handle Euclidean data.\nHowever, graphs in Natural Language Processing (NLP) are prominent. Recently,\nGraph Convolutional Networks (GCNs) have been proposed to address this\nshortcoming and have been successfully applied for several problems. In the\nsecond part of the thesis, we utilize GCNs for Document Timestamping problem\nand for learning word embeddings using dependency context of a word instead of\nsequential context. In this third part of the thesis, we address two\nlimitations of existing GCN models, i.e., (1) The standard neighborhood\naggregation scheme puts no constraints on the number of nodes that can\ninfluence the representation of a target node. This leads to a noisy\nrepresentation of hub-nodes which coves almost the entire graph in a few hops.\n(2) Most of the existing GCN models are limited to handle undirected graphs.\nHowever, a more general and pervasive class of graphs are relational graphs\nwhere each edge has a label and direction associated with it. Existing\napproaches to handle such graphs suffer from over-parameterization and are\nrestricted to learning representation of nodes only.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 04:31:59 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 07:24:19 GMT"}, {"version": "v3", "created": "Tue, 7 Apr 2020 19:36:40 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Vashishth", "Shikhar", ""]]}, {"id": "1911.03047", "submitter": "Woon Sang Cho", "authors": "Woon Sang Cho, Yizhe Zhang, Sudha Rao, Asli Celikyilmaz, Chenyan\n  Xiong, Jianfeng Gao, Mengdi Wang, Bill Dolan", "title": "Contrastive Multi-document Question Generation", "comments": "EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-document question generation focuses on generating a question that\ncovers the common aspect of multiple documents. Such a model is useful in\ngenerating clarifying options. However, a naive model trained only using the\ntargeted (\"positive\") document set may generate too generic questions that\ncover a larger scope than delineated by the document set. To address this\nchallenge, we introduce the contrastive learning strategy where given\n\"positive\" and \"negative\" sets of documents, we generate a question that is\nclosely related to the \"positive\" set but is far away from the \"negative\" set.\nThis setting allows generated questions to be more specific and related to the\ntarget document set. To generate such specific questions, we propose\nMulti-Source Coordinated Question Generator (MSCQG), a novel framework that\nincludes a supervised learning (SL) stage and a reinforcement learning (RL)\nstage. In the SL stage, a single-document question generator is trained. In the\nRL stage, a coordinator model is trained to find optimal attention weights to\nalign multiple single-document generators, by optimizing a reward designed to\npromote specificity of generated questions. We also develop an effective\nauxiliary objective, named Set-induced Contrastive Regularization (SCR) that\nimproves the coordinator's contrastive learning during the RL stage. We show\nthat our model significantly outperforms several strong baselines, as measured\nby automatic metrics and human evaluation. The source repository is publicly\navailable at \\url{www.github.com/woonsangcho/contrast_qgen}.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 04:45:55 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 13:16:57 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 11:36:50 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Cho", "Woon Sang", ""], ["Zhang", "Yizhe", ""], ["Rao", "Sudha", ""], ["Celikyilmaz", "Asli", ""], ["Xiong", "Chenyan", ""], ["Gao", "Jianfeng", ""], ["Wang", "Mengdi", ""], ["Dolan", "Bill", ""]]}, {"id": "1911.03058", "submitter": "Antonios Anastasopoulos", "authors": "Antonios Anastasopoulos and Graham Neubig", "title": "Should All Cross-Lingual Embeddings Speak English?", "comments": "accepted for publication at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of recent work in cross-lingual word embeddings is severely\nAnglocentric. The vast majority of lexicon induction evaluation dictionaries\nare between English and another language, and the English embedding space is\nselected by default as the hub when learning in a multilingual setting. With\nthis work, however, we challenge these practices. First, we show that the\nchoice of hub language can significantly impact downstream lexicon induction\nperformance. Second, we both expand the current evaluation dictionary\ncollection to include all language pairs using triangulation, and also create\nnew dictionaries for under-represented languages. Evaluating established\nmethods over all these language pairs sheds light into their suitability and\npresents new challenges for the field. Finally, in our analysis we identify\ngeneral guidelines for strong cross-lingual embeddings baselines, based on more\nthan just Anglocentric experiments.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 05:29:57 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 03:22:36 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Anastasopoulos", "Antonios", ""], ["Neubig", "Graham", ""]]}, {"id": "1911.03059", "submitter": "Chowdhury Rahman", "authors": "Afra Anika, Md. Hasibur Rahman, Salekul Islam, Abu Shafin Mohammad\n  Mahdee Jameel and Chowdhury Rafeed Rahman", "title": "A Comprehensive Comparison of Machine Learning Based Methods Used in\n  Bengali Question Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  QA classification system maps questions asked by humans to an appropriate\nanswer category. A sound question classification (QC) system model is the\npre-requisite of a sound QA system. This work demonstrates phases of assembling\na QA type classification model. We present a comprehensive comparison\n(performance and computational complexity) among some machine learning based\napproaches used in QC for Bengali language.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 05:30:33 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 16:37:41 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Anika", "Afra", ""], ["Rahman", "Md. Hasibur", ""], ["Islam", "Salekul", ""], ["Jameel", "Abu Shafin Mohammad Mahdee", ""], ["Rahman", "Chowdhury Rafeed", ""]]}, {"id": "1911.03064", "submitter": "Po-Sen Huang", "authors": "Po-Sen Huang, Huan Zhang, Ray Jiang, Robert Stanforth, Johannes Welbl,\n  Jack Rae, Vishal Maini, Dani Yogatama, Pushmeet Kohli", "title": "Reducing Sentiment Bias in Language Models via Counterfactual Evaluation", "comments": "Accepted in the Findings of EMNLP, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in language modeling architectures and the availability of large\ntext corpora have driven progress in automatic text generation. While this\nresults in models capable of generating coherent texts, it also prompts models\nto internalize social biases present in the training corpus. This paper aims to\nquantify and reduce a particular type of bias exhibited by language models:\nbias in the sentiment of generated text. Given a conditioning context (e.g., a\nwriting prompt) and a language model, we analyze if (and how) the sentiment of\nthe generated text is affected by changes in values of sensitive attributes\n(e.g., country names, occupations, genders) in the conditioning context using a\nform of counterfactual evaluation. We quantify sentiment bias by adopting\nindividual and group fairness metrics from the fair machine learning\nliterature, and demonstrate that large-scale models trained on two different\ncorpora (news articles, and Wikipedia) exhibit considerable levels of bias. We\nthen propose embedding and sentiment prediction-derived regularization on the\nlanguage model's latent representations. The regularizations improve fairness\nmetrics while retaining comparable levels of perplexity and semantic\nsimilarity.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 05:56:01 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 17:51:20 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 17:58:35 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Huang", "Po-Sen", ""], ["Zhang", "Huan", ""], ["Jiang", "Ray", ""], ["Stanforth", "Robert", ""], ["Welbl", "Johannes", ""], ["Rae", "Jack", ""], ["Maini", "Vishal", ""], ["Yogatama", "Dani", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1911.03070", "submitter": "Mozhi Zhang", "authors": "Michelle Yuan, Mozhi Zhang, Benjamin Van Durme, Leah Findlater, Jordan\n  Boyd-Graber", "title": "Interactive Refinement of Cross-Lingual Word Embeddings", "comments": "EMNLP 2020; first two authors contribute equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual word embeddings transfer knowledge between languages: models\ntrained on high-resource languages can predict in low-resource languages. We\nintroduce CLIME, an interactive system to quickly refine cross-lingual word\nembeddings for a given classification problem. First, CLIME ranks words by\ntheir salience to the downstream task. Then, users mark similarity between\nkeywords and their nearest neighbors in the embedding space. Finally, CLIME\nupdates the embeddings using the annotations. We evaluate CLIME on identifying\nhealth-related text in four low-resource languages: Ilocano, Sinhalese,\nTigrinya, and Uyghur. Embeddings refined by CLIME capture more nuanced word\nsemantics and have higher test accuracy than the original embeddings. CLIME\noften improves accuracy faster than an active learning baseline and can be\neasily combined with active learning to improve results.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 06:07:25 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 17:58:45 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 17:49:50 GMT"}, {"version": "v4", "created": "Thu, 3 Jun 2021 17:20:11 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Yuan", "Michelle", ""], ["Zhang", "Mozhi", ""], ["Van Durme", "Benjamin", ""], ["Findlater", "Leah", ""], ["Boyd-Graber", "Jordan", ""]]}, {"id": "1911.03078", "submitter": "Xu Li", "authors": "Xu Li, Jinghua Zhong, Xixin Wu, Jianwei Yu, Xunying Liu and Helen Meng", "title": "Adversarial Attacks on GMM i-vector based Speaker Verification Systems", "comments": "Accepted by ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.CR cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates the vulnerability of Gaussian Mixture Model (GMM)\ni-vector based speaker verification systems to adversarial attacks, and the\ntransferability of adversarial samples crafted from GMM i-vector based systems\nto x-vector based systems. In detail, we formulate the GMM i-vector system as a\nscoring function of enrollment and testing utterance pairs. Then we leverage\nthe fast gradient sign method (FGSM) to optimize testing utterances for\nadversarial samples generation. These adversarial samples are used to attack\nboth GMM i-vector and x-vector systems. We measure the system vulnerability by\nthe degradation of equal error rate and false acceptance rate. Experiment\nresults show that GMM i-vector systems are seriously vulnerable to adversarial\nattacks, and the crafted adversarial samples prove to be transferable and pose\nthreats to neuralnetwork speaker embedding based systems (e.g. x-vector\nsystems).\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 06:38:14 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 13:54:35 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Li", "Xu", ""], ["Zhong", "Jinghua", ""], ["Wu", "Xixin", ""], ["Yu", "Jianwei", ""], ["Liu", "Xunying", ""], ["Meng", "Helen", ""]]}, {"id": "1911.03083", "submitter": "Bhavan Jasani", "authors": "Bhavan Jasani, Rohit Girdhar, Deva Ramanan", "title": "Are we asking the right questions in MovieQA?", "comments": "Spotlight presentation at CLVL workshop, ICCV 2019. Project page:\n  https://bhavanj.github.io/MovieQAWithoutMovies/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint vision and language tasks like visual question answering are\nfascinating because they explore high-level understanding, but at the same\ntime, can be more prone to language biases. In this paper, we explore the\nbiases in the MovieQA dataset and propose a strikingly simple model which can\nexploit them. We find that using the right word embedding is of utmost\nimportance. By using an appropriately trained word embedding, about half the\nQuestion-Answers (QAs) can be answered by looking at the questions and answers\nalone, completely ignoring narrative context from video clips, subtitles, and\nmovie scripts. Compared to the best published papers on the leaderboard, our\nsimple question + answer only model improves accuracy by 5% for video +\nsubtitle category, 5% for subtitle, 15% for DVS and 6% higher for scripts.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 06:49:45 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Jasani", "Bhavan", ""], ["Girdhar", "Rohit", ""], ["Ramanan", "Deva", ""]]}, {"id": "1911.03090", "submitter": "Raphael Tang", "authors": "Jaejun Lee, Raphael Tang, Jimmy Lin", "title": "What Would Elsa Do? Freezing Layers During Transformer Fine-Tuning", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretrained transformer-based language models have achieved state of the art\nacross countless tasks in natural language processing. These models are highly\nexpressive, comprising at least a hundred million parameters and a dozen\nlayers. Recent evidence suggests that only a few of the final layers need to be\nfine-tuned for high quality on downstream tasks. Naturally, a subsequent\nresearch question is, \"how many of the last layers do we need to fine-tune?\" In\nthis paper, we precisely answer this question. We examine two recent pretrained\nlanguage models, BERT and RoBERTa, across standard tasks in textual entailment,\nsemantic similarity, sentiment analysis, and linguistic acceptability. We vary\nthe number of final layers that are fine-tuned, then study the resulting change\nin task-specific effectiveness. We show that only a fourth of the final layers\nneed to be fine-tuned to achieve 90% of the original quality. Surprisingly, we\nalso find that fine-tuning all layers does not always help.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 07:05:20 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Lee", "Jaejun", ""], ["Tang", "Raphael", ""], ["Lin", "Jimmy", ""]]}, {"id": "1911.03091", "submitter": "Ningyu Zhang", "authors": "Ningyu Zhang, Shumin Deng, Zhanlin Sun, Jiaoayan Chen, Wei Zhang,\n  Huajun Chen", "title": "Relation Adversarial Network for Low Resource Knowledge Graph Completion", "comments": "WWW2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graph Completion (KGC) has been proposed to improve Knowledge\nGraphs by filling in missing connections via link prediction or relation\nextraction. One of the main difficulties for KGC is a low resource problem.\nPrevious approaches assume sufficient training triples to learn versatile\nvectors for entities and relations, or a satisfactory number of labeled\nsentences to train a competent relation extraction model. However, low resource\nrelations are very common in KGs, and those newly added relations often do not\nhave many known samples for training. In this work, we aim at predicting new\nfacts under a challenging setting where only limited training instances are\navailable. We propose a general framework called Weighted Relation Adversarial\nNetwork, which utilizes an adversarial procedure to help adapt\nknowledge/features learned from high resource relations to different but\nrelated low resource relations. Specifically, the framework takes advantage of\na relation discriminator to distinguish between samples from different\nrelations, and help learn relation-invariant features more transferable from\nsource relations to target relations. Experimental results show that the\nproposed approach outperforms previous methods regarding low resource settings\nfor both link prediction and relation extraction.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 07:05:25 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 02:27:35 GMT"}, {"version": "v3", "created": "Mon, 20 Jan 2020 04:02:46 GMT"}, {"version": "v4", "created": "Sun, 23 Feb 2020 18:39:12 GMT"}, {"version": "v5", "created": "Thu, 9 Apr 2020 18:36:43 GMT"}, {"version": "v6", "created": "Mon, 22 Jun 2020 08:39:41 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Zhang", "Ningyu", ""], ["Deng", "Shumin", ""], ["Sun", "Zhanlin", ""], ["Chen", "Jiaoayan", ""], ["Zhang", "Wei", ""], ["Chen", "Huajun", ""]]}, {"id": "1911.03109", "submitter": "Mathias M\\\"uller", "authors": "Mathias M\\\"uller, Annette Rios, Rico Sennrich", "title": "Domain Robustness in Neural Machine Translation", "comments": "V2: AMTA camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Translating text that diverges from the training domain is a key challenge\nfor machine translation. Domain robustness---the generalization of models to\nunseen test domains---is low for both statistical (SMT) and neural machine\ntranslation (NMT). In this paper, we study the performance of SMT and NMT\nmodels on out-of-domain test sets. We find that in unknown domains, SMT and NMT\nsuffer from very different problems: SMT systems are mostly adequate but not\nfluent, while NMT systems are mostly fluent, but not adequate. For NMT, we\nidentify such hallucinations (translations that are fluent but unrelated to the\nsource) as a key reason for low domain robustness. To mitigate this problem, we\nempirically compare methods that are reported to improve adequacy or in-domain\nrobustness in terms of their effectiveness at improving domain robustness. In\nexperiments on German to English OPUS data, and German to Romansh (a\nlow-resource setting) we find that several methods improve domain robustness.\nWhile those methods do lead to higher BLEU scores overall, they only slightly\nincrease the adequacy of translations compared to SMT.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 07:57:46 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 07:31:33 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["M\u00fcller", "Mathias", ""], ["Rios", "Annette", ""], ["Sennrich", "Rico", ""]]}, {"id": "1911.03110", "submitter": "Liangyou Li", "authors": "Liangyou Li, Xin Jiang, Qun Liu", "title": "Pretrained Language Models for Document-Level Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work on document-level NMT usually focuses on limited contexts\nbecause of degraded performance on larger contexts. In this paper, we\ninvestigate on using large contexts with three main contributions: (1)\nDifferent from previous work which pertrained models on large-scale\nsentence-level parallel corpora, we use pretrained language models,\nspecifically BERT, which are trained on monolingual documents; (2) We propose\ncontext manipulation methods to control the influence of large contexts, which\nlead to comparable results on systems using small and large contexts; (3) We\nintroduce a multi-task training for regularization to avoid models overfitting\nour training corpora, which further improves our systems together with a deeper\nencoder. Experiments are conducted on the widely used IWSLT data sets with\nthree language pairs, i.e., Chinese--English, French--English and\nSpanish--English. Results show that our systems are significantly better than\nthree previously reported document-level systems.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 08:00:45 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Li", "Liangyou", ""], ["Jiang", "Xin", ""], ["Liu", "Qun", ""]]}, {"id": "1911.03118", "submitter": "Segev Shlomov", "authors": "Ateret Anaby-Tavor, Boaz Carmeli, Esther Goldbraich, Amir Kantor,\n  George Kour, Segev Shlomov, Naama Tepper, and Naama Zwerdling", "title": "Not Enough Data? Deep Learning to the Rescue!", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on recent advances in natural language modeling and those in text\ngeneration capabilities, we propose a novel data augmentation method for text\nclassification tasks. We use a powerful pre-trained neural network model to\nartificially synthesize new labeled data for supervised learning. We mainly\nfocus on cases with scarce labeled data. Our method, referred to as\nlanguage-model-based data augmentation (LAMBADA), involves fine-tuning a\nstate-of-the-art language generator to a specific task through an initial\ntraining phase on the existing (usually small) labeled data. Using the\nfine-tuned model and given a class label, new sentences for the class are\ngenerated. Our process then filters these new sentences by using a classifier\ntrained on the original data. In a series of experiments, we show that LAMBADA\nimproves classifiers' performance on a variety of datasets. Moreover, LAMBADA\nsignificantly improves upon the state-of-the-art techniques for data\naugmentation, specifically those applicable to text classification tasks with\nlittle data.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 08:30:22 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 12:15:52 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Anaby-Tavor", "Ateret", ""], ["Carmeli", "Boaz", ""], ["Goldbraich", "Esther", ""], ["Kantor", "Amir", ""], ["Kour", "George", ""], ["Shlomov", "Segev", ""], ["Tepper", "Naama", ""], ["Zwerdling", "Naama", ""]]}, {"id": "1911.03123", "submitter": "Silviu Oprea", "authors": "Silviu Oprea and Walid Magdy", "title": "iSarcasm: A Dataset of Intended Sarcasm", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the distinction between intended and perceived sarcasm in the\ncontext of textual sarcasm detection. The former occurs when an utterance is\nsarcastic from the perspective of its author, while the latter occurs when the\nutterance is interpreted as sarcastic by the audience. We show the limitations\nof previous labelling methods in capturing intended sarcasm and introduce the\niSarcasm dataset of tweets labeled for sarcasm directly by their authors.\nExamining the state-of-the-art sarcasm detection models on our dataset showed\nlow performance compared to previously studied datasets, which indicates that\nthese datasets might be biased or obvious and sarcasm could be a phenomenon\nunder-studied computationally thus far. By providing the iSarcasm dataset, we\naim to encourage future NLP research to develop methods for detecting sarcasm\nin text as intended by the authors of the text, not as labeled under\nassumptions that we demonstrate to be sub-optimal.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 08:40:22 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 19:40:12 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Oprea", "Silviu", ""], ["Magdy", "Walid", ""]]}, {"id": "1911.03154", "submitter": "Yun Chen", "authors": "Yun Chen, Liangyou Li, Xin Jiang, Xiao Chen, Qun Liu", "title": "A General Framework for Adaptation of Neural Machine Translation to\n  Simultaneous Translation", "comments": "Accepted by AACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the success of neural machine translation (NMT), simultaneous neural\nmachine translation (SNMT), the task of translating in real time before a full\nsentence has been observed, remains challenging due to the syntactic structure\ndifference and simultaneity requirements. In this paper, we propose a general\nframework for adapting neural machine translation to translate simultaneously.\nOur framework contains two parts: prefix translation that utilizes a\nconsecutive NMT model to translate source prefixes and a stopping criterion\nthat determines when to stop the prefix translation. Experiments on three\ntranslation corpora and two language pairs show the efficacy of the proposed\nframework on balancing the quality and latency in adapting NMT to perform\nsimultaneous translation.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 09:55:37 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 02:39:36 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Chen", "Yun", ""], ["Li", "Liangyou", ""], ["Jiang", "Xin", ""], ["Chen", "Xiao", ""], ["Liu", "Qun", ""]]}, {"id": "1911.03167", "submitter": "Javier Iranzo-S\\'anchez", "authors": "Javier Iranzo-S\\'anchez, Joan Albert Silvestre-Cerd\\`a, Javier Jorge,\n  Nahuel Rosell\\'o, Adri\\`a Gim\\'enez, Albert Sanchis, Jorge Civera, Alfons\n  Juan", "title": "Europarl-ST: A Multilingual Corpus For Speech Translation Of\n  Parliamentary Debates", "comments": "Accepted by ICASSP2020. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current research into spoken language translation (SLT),or speech-to-text\ntranslation, is often hampered by the lack of specific data resources for this\ntask, as currently available SLT datasets are restricted to a limited set of\nlanguage pairs. In this paper we present Europarl-ST, a novel multilingual SLT\ncorpus containing paired audio-text samples for SLT from and into 6 European\nlanguages, for a total of 30 different translation directions. This corpus has\nbeen compiled using the debates held in the European Parliament in the period\nbetween 2008 and 2012. This paper describes the corpus creation process and\npresents a series of automatic speech recognition, machine translation and\nspoken language translation experiments that highlight the potential of this\nnew resource. The corpus is released under a Creative Commons license and is\nfreely accessible and downloadable.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 10:22:10 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 16:52:35 GMT"}, {"version": "v3", "created": "Wed, 12 Feb 2020 12:14:43 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Iranzo-S\u00e1nchez", "Javier", ""], ["Silvestre-Cerd\u00e0", "Joan Albert", ""], ["Jorge", "Javier", ""], ["Rosell\u00f3", "Nahuel", ""], ["Gim\u00e9nez", "Adri\u00e0", ""], ["Sanchis", "Albert", ""], ["Civera", "Jorge", ""], ["Juan", "Alfons", ""]]}, {"id": "1911.03179", "submitter": "Hongfei Xu", "authors": "Hongfei Xu and Qiuhui Liu and Josef van Genabith and Deyi Xiong and\n  Jingyi Zhang", "title": "Lipschitz Constrained Parameter Initialization for Deep Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Transformer translation model employs residual connection and layer\nnormalization to ease the optimization difficulties caused by its multi-layer\nencoder/decoder structure. Previous research shows that even with residual\nconnection and layer normalization, deep Transformers still have difficulty in\ntraining, and particularly Transformer models with more than 12 encoder/decoder\nlayers fail to converge. In this paper, we first empirically demonstrate that a\nsimple modification made in the official implementation, which changes the\ncomputation order of residual connection and layer normalization, can\nsignificantly ease the optimization of deep Transformers. We then compare the\nsubtle differences in computation order in considerable detail, and present a\nparameter initialization method that leverages the Lipschitz constraint on the\ninitialization of Transformer parameters that effectively ensures training\nconvergence. In contrast to findings in previous research we further\ndemonstrate that with Lipschitz parameter initialization, deep Transformers\nwith the original computation order can converge, and obtain significant BLEU\nimprovements with up to 24 layers. In contrast to previous research which\nfocuses on deep encoders, our approach additionally enables Transformers to\nalso benefit from deep decoders.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 10:52:43 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 13:08:37 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Xu", "Hongfei", ""], ["Liu", "Qiuhui", ""], ["van Genabith", "Josef", ""], ["Xiong", "Deyi", ""], ["Zhang", "Jingyi", ""]]}, {"id": "1911.03219", "submitter": "Nicolas Lair", "authors": "Nicolas Lair, C\\'edric Colas, R\\'emy Portelas, Jean-Michel Dussoux,\n  Peter Ford Dominey, Pierre-Yves Oudeyer", "title": "Language Grounding through Social Interactions and Curiosity-Driven\n  Multi-Goal Learning", "comments": "NeurIPS 2019 Workshop ViGIL : Visually Grounded Interaction and\n  Language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous reinforcement learning agents, like children, do not have access\nto predefined goals and reward functions. They must discover potential goals,\nlearn their own reward functions and engage in their own learning trajectory.\nChildren, however, benefit from exposure to language, helping to organize and\nmediate their thought. We propose LE2 (Language Enhanced Exploration), a\nlearning algorithm leveraging intrinsic motivations and natural language (NL)\ninteractions with a descriptive social partner (SP). Using NL descriptions from\nthe SP, it can learn an NL-conditioned reward function to formulate goals for\nintrinsically motivated goal exploration and learn a goal-conditioned policy.\nBy exploring, collecting descriptions from the SP and jointly learning the\nreward function and the policy, the agent grounds NL descriptions into real\nbehavioral goals. From simple goals discovered early to more complex goals\ndiscovered by experimenting on simpler ones, our agent autonomously builds its\nown behavioral repertoire. This naturally occurring curriculum is supplemented\nby an active learning curriculum resulting from the agent's intrinsic\nmotivations. Experiments are presented with a simulated robotic arm that\ninteracts with several objects including tools.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 12:42:22 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Lair", "Nicolas", ""], ["Colas", "C\u00e9dric", ""], ["Portelas", "R\u00e9my", ""], ["Dussoux", "Jean-Michel", ""], ["Dominey", "Peter Ford", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1911.03243", "submitter": "Paul Roit", "authors": "Paul Roit, Ayal Klein, Daniela Stepanov, Jonathan Mamou, Julian\n  Michael, Gabriel Stanovsky, Luke Zettlemoyer and Ido Dagan", "title": "Controlled Crowdsourcing for High-Quality QA-SRL Annotation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question-answer driven Semantic Role Labeling (QA-SRL) was proposed as an\nattractive open and natural flavour of SRL, potentially attainable from laymen.\nRecently, a large-scale crowdsourced QA-SRL corpus and a trained parser were\nreleased. Trying to replicate the QA-SRL annotation for new texts, we found\nthat the resulting annotations were lacking in quality, particularly in\ncoverage, making them insufficient for further research and evaluation. In this\npaper, we present an improved crowdsourcing protocol for complex semantic\nannotation, involving worker selection and training, and a data consolidation\nphase. Applying this protocol to QA-SRL yielded high-quality annotation with\ndrastically higher coverage, producing a new gold evaluation dataset. We\nbelieve that our annotation protocol and gold standard will facilitate future\nreplicable research of natural semantic annotations.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 13:22:12 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 16:12:20 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Roit", "Paul", ""], ["Klein", "Ayal", ""], ["Stepanov", "Daniela", ""], ["Mamou", "Jonathan", ""], ["Michael", "Julian", ""], ["Stanovsky", "Gabriel", ""], ["Zettlemoyer", "Luke", ""], ["Dagan", "Ido", ""]]}, {"id": "1911.03249", "submitter": "Tomas Kliegr", "authors": "Tom\\'a\\v{s} Kliegr, \\v{S}t\\v{e}p\\'an Bahn\\'ik, Johannes F\\\"urnkranz", "title": "Advances in Machine Learning for the Behavioral Sciences", "comments": null, "journal-ref": "American Behavioral Scientist 64.2 (2020): 145-175", "doi": "10.1177/0002764219859639", "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The areas of machine learning and knowledge discovery in databases have\nconsiderably matured in recent years. In this article, we briefly review recent\ndevelopments as well as classical algorithms that stood the test of time. Our\ngoal is to provide a general introduction into different tasks such as learning\nfrom tabular data, behavioral data, or textual data, with a particular focus on\nactual and potential applications in behavioral sciences. The supplemental\nappendix to the article also provides practical guidance for using the methods\nby pointing the reader to proven software implementations. The focus is on R,\nbut we also cover some libraries in other programming languages as well as\nsystems with easy-to-use graphical interfaces.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 13:30:21 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Kliegr", "Tom\u00e1\u0161", ""], ["Bahn\u00edk", "\u0160t\u011bp\u00e1n", ""], ["F\u00fcrnkranz", "Johannes", ""]]}, {"id": "1911.03268", "submitter": "Dan Schwartz", "authors": "Dan Schwartz, Mariya Toneva, Leila Wehbe", "title": "Inducing brain-relevant bias in natural language processing models", "comments": "To be published in the proceedings of the 33rd Conference on Neural\n  Information Processing Systems (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Progress in natural language processing (NLP) models that estimate\nrepresentations of word sequences has recently been leveraged to improve the\nunderstanding of language processing in the brain. However, these models have\nnot been specifically designed to capture the way the brain represents language\nmeaning. We hypothesize that fine-tuning these models to predict recordings of\nbrain activity of people reading text will lead to representations that encode\nmore brain-activity-relevant language information. We demonstrate that a\nversion of BERT, a recently introduced and powerful language model, can improve\nthe prediction of brain activity after fine-tuning. We show that the\nrelationship between language and brain activity learned by BERT during this\nfine-tuning transfers across multiple participants. We also show that, for some\nparticipants, the fine-tuned representations learned from both\nmagnetoencephalography (MEG) and functional magnetic resonance imaging (fMRI)\nare better for predicting fMRI than the representations learned from fMRI\nalone, indicating that the learned representations capture\nbrain-activity-relevant information that is not simply an artifact of the\nmodality. While changes to language representations help the model predict\nbrain activity, they also do not harm the model's ability to perform downstream\nNLP tasks. Our findings are notable for research on language understanding in\nthe brain.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 23:28:16 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Schwartz", "Dan", ""], ["Toneva", "Mariya", ""], ["Wehbe", "Leila", ""]]}, {"id": "1911.03270", "submitter": "Ekaterina Artemova", "authors": "Taisiya Glushkova and Ekaterina Artemova", "title": "Char-RNN and Active Learning for Hashtag Segmentation", "comments": "to appear in Cicling2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We explore the abilities of character recurrent neural network (char-RNN) for\nhashtag segmentation. Our approach to the task is the following: we generate\nsynthetic training dataset according to frequent n-grams that satisfy\npredefined morpho-syntactic patterns to avoid any manual annotation. The active\nlearning strategy limits the training dataset and selects informative training\nsubset. The approach does not require any language-specific settings and is\ncompared for two languages, which differ in inflection degree.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 14:03:55 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Glushkova", "Taisiya", ""], ["Artemova", "Ekaterina", ""]]}, {"id": "1911.03283", "submitter": "Casey Kennington", "authors": "Daniele Moro, Stacy Black, Casey Kennington", "title": "Composing and Embedding the Words-as-Classifiers Model of Grounded\n  Semantics", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The words-as-classifiers model of grounded lexical semantics learns a\nsemantic fitness score between physical entities and the words that are used to\ndenote those entities. In this paper, we explore how such a model can\nincrementally perform composition and how the model can be unified with a\ndistributional representation. For the latter, we leverage the classifier\ncoefficients as an embedding. For composition, we leverage the underlying\nmechanics of three different classifier types (i.e., logistic regression,\ndecision trees, and multi-layer perceptrons) to arrive at a several systematic\napproaches to composition unique to each classifier including both denotational\nand connotational methods of composition. We compare these approaches to each\nother and to prior work in a visual reference resolution task using the refCOCO\ndataset. Our results demonstrate the need to expand upon existing composition\nstrategies and bring together grounded and distributional representations.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 14:33:06 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Moro", "Daniele", ""], ["Black", "Stacy", ""], ["Kennington", "Casey", ""]]}, {"id": "1911.03310", "submitter": "Jind\\v{r}ich Libovick\\'y", "authors": "Jind\\v{r}ich Libovick\\'y and Rudolf Rosa and Alexander Fraser", "title": "How Language-Neutral is Multilingual BERT?", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual BERT (mBERT) provides sentence representations for 104\nlanguages, which are useful for many multi-lingual tasks. Previous work probed\nthe cross-linguality of mBERT using zero-shot transfer learning on\nmorphological and syntactic tasks. We instead focus on the semantic properties\nof mBERT. We show that mBERT representations can be split into a\nlanguage-specific component and a language-neutral component, and that the\nlanguage-neutral component is sufficiently general in terms of modeling\nsemantics to allow high-accuracy word-alignment and sentence retrieval but is\nnot yet good enough for the more difficult task of MT quality estimation. Our\nwork presents interesting challenges which must be solved to build better\nlanguage-neutral representations, particularly for tasks requiring linguistic\ntransfer of semantics.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 15:12:36 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Libovick\u00fd", "Jind\u0159ich", ""], ["Rosa", "Rudolf", ""], ["Fraser", "Alexander", ""]]}, {"id": "1911.03324", "submitter": "Haichao Zhu", "authors": "Haichao Zhu, Li Dong, Furu Wei, Bing Qin, Ting Liu", "title": "Transforming Wikipedia into Augmented Data for Query-Focused\n  Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The manual construction of a query-focused summarization corpus is costly and\ntimeconsuming. The limited size of existing datasets renders training\ndata-driven summarization models challenging. In this paper, we use Wikipedia\nto automatically collect a large query-focused summarization dataset (named as\nWIKIREF) of more than 280,000 examples, which can serve as a means of data\naugmentation. Moreover, we develop a query-focused summarization model based on\nBERT to extract summaries from the documents. Experimental results on three DUC\nbenchmarks show that the model pre-trained on WIKIREF has already achieved\nreasonable performance. After fine-tuning on the specific datasets, the model\nwith data augmentation outperforms the state of the art on the benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 15:28:21 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Zhu", "Haichao", ""], ["Dong", "Li", ""], ["Wei", "Furu", ""], ["Qin", "Bing", ""], ["Liu", "Ting", ""]]}, {"id": "1911.03329", "submitter": "Stuart Shieber", "authors": "Mirac Suzgun and Sebastian Gehrmann and Yonatan Belinkov and Stuart M.\n  Shieber", "title": "Memory-Augmented Recurrent Neural Networks Can Learn Generalized Dyck\n  Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce three memory-augmented Recurrent Neural Networks (MARNNs) and\nexplore their capabilities on a series of simple language modeling tasks whose\nsolutions require stack-based mechanisms. We provide the first demonstration of\nneural networks recognizing the generalized Dyck languages, which express the\ncore of what it means to be a language with hierarchical structure. Our\nmemory-augmented architectures are easy to train in an end-to-end fashion and\ncan learn the Dyck languages over as many as six parenthesis-pairs, in addition\nto two deterministic palindrome languages and the string-reversal transduction\ntask, by emulating pushdown automata. Our experiments highlight the increased\nmodeling capacity of memory-augmented models over simple RNNs, while inflecting\nour understanding of the limitations of these models.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 15:33:51 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Suzgun", "Mirac", ""], ["Gehrmann", "Sebastian", ""], ["Belinkov", "Yonatan", ""], ["Shieber", "Stuart M.", ""]]}, {"id": "1911.03343", "submitter": "Nora Kassner", "authors": "Nora Kassner, Hinrich Sch\\\"utze", "title": "Negated and Misprimed Probes for Pretrained Language Models: Birds Can\n  Talk, But Cannot Fly", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on Petroni et al. (2019), we propose two new probing tasks analyzing\nfactual knowledge stored in Pretrained Language Models (PLMs). (1) Negation. We\nfind that PLMs do not distinguish between negated (\"Birds cannot [MASK]\") and\nnon-negated (\"Birds can [MASK]\") cloze questions. (2) Mispriming. Inspired by\npriming methods in human psychology, we add \"misprimes\" to cloze questions\n(\"Talk? Birds can [MASK]\"). We find that PLMs are easily distracted by\nmisprimes. These results suggest that PLMs still have a long way to go to\nadequately learn human-like factual knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 16:08:48 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 18:16:26 GMT"}, {"version": "v3", "created": "Fri, 15 May 2020 17:11:56 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Kassner", "Nora", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1911.03350", "submitter": "Jacopo Staiano", "authors": "Thomas Scialom, Jacopo Staiano", "title": "Ask to Learn: A Study on Curiosity-driven Question Generation", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel text generation task, namely Curiosity-driven Question\nGeneration. We start from the observation that the Question Generation task has\ntraditionally been considered as the dual problem of Question Answering, hence\ntackling the problem of generating a question given the text that contains its\nanswer. Such questions can be used to evaluate machine reading comprehension.\nHowever, in real life, and especially in conversational settings, humans tend\nto ask questions with the goal of enriching their knowledge and/or clarifying\naspects of previously gathered information. We refer to these inquisitive\nquestions as Curiosity-driven: these questions are generated with the goal of\nobtaining new information (the answer) which is not present in the input text.\nIn this work, we experiment on this new task using a conversational Question\nAnswering (QA) dataset; further, since the majority of QA dataset are not built\nin a conversational manner, we describe a methodology to derive data for this\nnovel task from non-conversational QA data. We investigate several automated\nmetrics to measure the different properties of Curious Questions, and\nexperiment different approaches on the Curiosity-driven Question Generation\ntask, including model pre-training and reinforcement learning. Finally, we\nreport a qualitative evaluation of the generated outputs.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 16:17:40 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Scialom", "Thomas", ""], ["Staiano", "Jacopo", ""]]}, {"id": "1911.03353", "submitter": "Tan Yan", "authors": "Tan Yan, Heyan Huang, Xian-Ling Mao", "title": "SEPT: Improving Scientific Named Entity Recognition with Span\n  Representation", "comments": "This work is outdated. The result should not be trusted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new scientific named entity recognizer called SEPT, which\nstands for Span Extractor with Pre-trained Transformers. In recent papers, span\nextractors have been demonstrated to be a powerful model compared with sequence\nlabeling models. However, we discover that with the development of pre-trained\nlanguage models, the performance of span extractors appears to become similar\nto sequence labeling models. To keep the advantages of span representation, we\nmodified the model by under-sampling to balance the positive and negative\nsamples and reduce the search space. Furthermore, we simplify the origin\nnetwork architecture to combine the span extractor with BERT. Experiments\ndemonstrate that even simplified architecture achieves the same performance and\nSEPT achieves a new state of the art result in scientific named entity\nrecognition even without relation information involved.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 16:19:26 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 04:25:25 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Yan", "Tan", ""], ["Huang", "Heyan", ""], ["Mao", "Xian-Ling", ""]]}, {"id": "1911.03362", "submitter": "Nikolay Bogoychev Dr", "authors": "Nikolay Bogoychev and Rico Sennrich", "title": "Domain, Translationese and Noise in Synthetic Data for Neural Machine\n  Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of neural machine translation can be improved by leveraging\nadditional monolingual resources to create synthetic training data. Source-side\nmonolingual data can be (forward-)translated into the target language for\nself-training; target-side monolingual data can be back-translated. It has been\nwidely reported that back-translation delivers superior results, but could this\nbe due to artefacts in the test sets? We perform a case study using\nFrench-English news translation task and separate test sets based on their\noriginal languages. We show that forward translation delivers superior gains in\nterms of BLEU on sentences that were originally in the source language,\ncomplementing previous studies which show large improvements with\nback-translation on sentences that were originally in the target language. To\nbetter understand when and why forward and back-translation are effective, we\nstudy the role of domains, translationese, and noise. While translationese\neffects are well known to influence MT evaluation, we also find evidence that\nnews data from different languages shows subtle domain differences, which is\nanother explanation for varying performance on different portions of the test\nset. We perform additional low-resource experiments which demonstrate that\nforward translation is more sensitive to the quality of the initial translation\nsystem than back-translation, and tends to perform worse in low-resource\nsettings.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 17:30:57 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 17:14:02 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Bogoychev", "Nikolay", ""], ["Sennrich", "Rico", ""]]}, {"id": "1911.03373", "submitter": "Chris Kedzie", "authors": "Chris Kedzie and Kathleen McKeown", "title": "A Good Sample is Hard to Find: Noise Injection Sampling and\n  Self-Training for Neural Language Generation Models", "comments": "Accepted as a long paper at INLG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) are quickly becoming the de facto standard\nmodeling method for many natural language generation (NLG) tasks. In order for\nsuch models to truly be useful, they must be capable of correctly generating\nutterances for novel meaning representations (MRs) at test time. In practice,\neven sophisticated DNNs with various forms of semantic control frequently fail\nto generate utterances faithful to the input MR. In this paper, we propose an\narchitecture agnostic self-training method to sample novel MR/text utterance\npairs to augment the original training data. Remarkably, after training on the\naugmented data, even simple encoder-decoder models with greedy decoding are\ncapable of generating semantically correct utterances that are as good as\nstate-of-the-art outputs in both automatic and human evaluations of quality.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 16:54:58 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Kedzie", "Chris", ""], ["McKeown", "Kathleen", ""]]}, {"id": "1911.03378", "submitter": "Maryam Fazel-Zarandi", "authors": "Maryam Fazel-Zarandi, Longshaokan Wang, Aditya Tiwari, Spyros\n  Matsoukas", "title": "Investigation of Error Simulation Techniques for Learning Dialog\n  Policies for Conversational Error Recovery", "comments": "The 3rd Conversational AI workshop - today's practice and tomorrow's\n  potential", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training dialog policies for speech-based virtual assistants requires a\nplethora of conversational data. The data collection phase is often expensive\nand time consuming due to human involvement. To address this issue, a common\nsolution is to build user simulators for data generation. For the successful\ndeployment of the trained policies into real world domains, it is vital that\nthe user simulator mimics realistic conditions. In particular, speech-based\nassistants are heavily affected by automatic speech recognition and language\nunderstanding errors, hence the user simulator should be able to simulate\nsimilar errors. In this paper, we review the existing error simulation methods\nthat induce errors at audio, phoneme, text, or semantic level; and conduct\ndetailed comparisons between the audio-level and text-level methods. In the\nprocess, we improve the existing text-level method by introducing confidence\nscore prediction and out-of-vocabulary word mapping. We also explore the impact\nof audio-level and text-level methods on learning a simple clarification dialog\npolicy to recover from errors to provide insight on future improvement for both\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 16:59:17 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Fazel-Zarandi", "Maryam", ""], ["Wang", "Longshaokan", ""], ["Tiwari", "Aditya", ""], ["Matsoukas", "Spyros", ""]]}, {"id": "1911.03385", "submitter": "Chris Kedzie", "authors": "Katy Gero, Chris Kedzie, Jonathan Reeve, and Lydia Chilton", "title": "Low-Level Linguistic Controls for Style Transfer and Content\n  Preservation", "comments": "Accepted as a long paper at INLG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the success of style transfer in image processing, it has seen\nlimited progress in natural language generation. Part of the problem is that\ncontent is not as easily decoupled from style in the text domain. Curiously, in\nthe field of stylometry, content does not figure prominently in practical\nmethods of discriminating stylistic elements, such as authorship and genre.\nRather, syntax and function words are the most salient features. Drawing on\nthis work, we model style as a suite of low-level linguistic controls, such as\nfrequency of pronouns, prepositions, and subordinate clause constructions. We\ntrain a neural encoder-decoder model to reconstruct reference sentences given\nonly content words and the setting of the controls. We perform style transfer\nby keeping the content words fixed while adjusting the controls to be\nindicative of another style. In experiments, we show that the model reliably\nresponds to the linguistic controls and perform both automatic and manual\nevaluations on style transfer. We find we can fool a style classifier 84% of\nthe time, and that our model produces highly diverse and stylistically\ndistinctive outputs. This work introduces a formal, extendable model of style\nthat can add control to any neural text generation system.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 17:10:49 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Gero", "Katy", ""], ["Kedzie", "Chris", ""], ["Reeve", "Jonathan", ""], ["Chilton", "Lydia", ""]]}, {"id": "1911.03407", "submitter": "Vishwajeet Kumar", "authors": "Vishwajeet Kumar, Raktim Chaki, Sai Teja Talluri, Ganesh Ramakrishnan,\n  Yuan-Fang Li, Gholamreza Haffari", "title": "Question Generation from Paragraphs: A Tale of Two Hierarchical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic question generation from paragraphs is an important and challenging\nproblem, particularly due to the long context from paragraphs. In this paper,\nwe propose and study two hierarchical models for the task of question\ngeneration from paragraphs. Specifically, we propose (a) a novel hierarchical\nBiLSTM model with selective attention and (b) a novel hierarchical Transformer\narchitecture, both of which learn hierarchical representations of paragraphs.\nWe model a paragraph in terms of its constituent sentences, and a sentence in\nterms of its constituent words. While the introduction of the attention\nmechanism benefits the hierarchical BiLSTM model, the hierarchical Transformer,\nwith its inherent attention and positional encoding mechanisms also performs\nbetter than flat transformer model. We conducted empirical evaluation on the\nwidely used SQuAD and MS MARCO datasets using standard metrics. The results\ndemonstrate the overall effectiveness of the hierarchical models over their\nflat counterparts. Qualitatively, our hierarchical models are able to generate\nfluent and relevant questions\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 17:49:08 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Kumar", "Vishwajeet", ""], ["Chaki", "Raktim", ""], ["Talluri", "Sai Teja", ""], ["Ramakrishnan", "Ganesh", ""], ["Li", "Yuan-Fang", ""], ["Haffari", "Gholamreza", ""]]}, {"id": "1911.03429", "submitter": "Jay DeYoung", "authors": "Jay DeYoung, Sarthak Jain, Nazneen Fatema Rajani, Eric Lehman, Caiming\n  Xiong, Richard Socher, Byron C. Wallace", "title": "ERASER: A Benchmark to Evaluate Rationalized NLP Models", "comments": "Accepted as a long paper to ACL2020 Website and leaderboard available\n  at http://www.eraserbenchmark.com/ Code available at\n  https://github.com/jayded/eraserbenchmark", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  State-of-the-art models in NLP are now predominantly based on deep neural\nnetworks that are opaque in terms of how they come to make predictions. This\nlimitation has increased interest in designing more interpretable deep models\nfor NLP that reveal the `reasoning' behind model outputs. But work in this\ndirection has been conducted on different datasets and tasks with\ncorrespondingly unique aims and metrics; this makes it difficult to track\nprogress. We propose the Evaluating Rationales And Simple English Reasoning\n(ERASER) benchmark to advance research on interpretable models in NLP. This\nbenchmark comprises multiple datasets and tasks for which human annotations of\n\"rationales\" (supporting evidence) have been collected. We propose several\nmetrics that aim to capture how well the rationales provided by models align\nwith human rationales, and also how faithful these rationales are (i.e., the\ndegree to which provided rationales influenced the corresponding predictions).\nOur hope is that releasing this benchmark facilitates progress on designing\nmore interpretable NLP systems. The benchmark, code, and documentation are\navailable at https://www.eraserbenchmark.com/\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 18:29:03 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 17:25:40 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["DeYoung", "Jay", ""], ["Jain", "Sarthak", ""], ["Rajani", "Nazneen Fatema", ""], ["Lehman", "Eric", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""], ["Wallace", "Byron C.", ""]]}, {"id": "1911.03437", "submitter": "Haoming Jiang", "authors": "Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu, Jianfeng Gao,\n  Tuo Zhao", "title": "SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language\n  Models through Principled Regularized Optimization", "comments": "The 58th annual meeting of the Association for Computational\n  Linguistics (ACL 2020)", "journal-ref": null, "doi": "10.18653/v1/2020.acl-main.197", "report-no": null, "categories": "cs.CL cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning has fundamentally changed the landscape of natural language\nprocessing (NLP) research. Many existing state-of-the-art models are first\npre-trained on a large text corpus and then fine-tuned on downstream tasks.\nHowever, due to limited data resources from downstream tasks and the extremely\nlarge capacity of pre-trained models, aggressive fine-tuning often causes the\nadapted model to overfit the data of downstream tasks and forget the knowledge\nof the pre-trained model. To address the above issue in a more principled\nmanner, we propose a new computational framework for robust and efficient\nfine-tuning for pre-trained language models. Specifically, our proposed\nframework contains two important ingredients: 1. Smoothness-inducing\nregularization, which effectively manages the capacity of the model; 2. Bregman\nproximal point optimization, which is a class of trust-region methods and can\nprevent knowledge forgetting. Our experiments demonstrate that our proposed\nmethod achieves the state-of-the-art performance on multiple NLP benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 18:41:31 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 18:44:04 GMT"}, {"version": "v3", "created": "Mon, 18 Jan 2021 19:58:17 GMT"}, {"version": "v4", "created": "Mon, 15 Feb 2021 17:52:35 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Jiang", "Haoming", ""], ["He", "Pengcheng", ""], ["Chen", "Weizhu", ""], ["Liu", "Xiaodong", ""], ["Gao", "Jianfeng", ""], ["Zhao", "Tuo", ""]]}, {"id": "1911.03514", "submitter": "Jiaqi Li", "authors": "Jiaqi Li, Ming Liu, Bing Qin, Zihao Zheng, Ting Liu", "title": "An Annotation Scheme of A Large-scale Multi-party Dialogues Dataset for\n  Discourse Parsing and Machine Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the scheme for annotating large-scale multi-party\nchat dialogues for discourse parsing and machine comprehension. The main goal\nof this project is to help understand multi-party dialogues. Our dataset is\nbased on the Ubuntu Chat Corpus. For each multi-party dialogue, we annotate the\ndiscourse structure and question-answer pairs for dialogues. As we know, this\nis the first large scale corpus for multi-party dialogues discourse parsing,\nand we firstly propose the task for multi-party dialogues machine reading\ncomprehension.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 19:33:06 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Li", "Jiaqi", ""], ["Liu", "Ming", ""], ["Qin", "Bing", ""], ["Zheng", "Zihao", ""], ["Liu", "Ting", ""]]}, {"id": "1911.03531", "submitter": "Ali Fadel", "authors": "Ali Fadel, Ibraheem Tuffaha, Bara' Al-Jawarneh, Mahmoud Al-Ayyoub", "title": "Neural Arabic Text Diacritization: State of the Art Results and a Novel\n  Approach for Machine Translation", "comments": "18 pages, 17 figures, 14 tables", "journal-ref": null, "doi": "10.18653/v1/D19-5229", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present several deep learning models for the automatic\ndiacritization of Arabic text. Our models are built using two main approaches,\nviz. Feed-Forward Neural Network (FFNN) and Recurrent Neural Network (RNN),\nwith several enhancements such as 100-hot encoding, embeddings, Conditional\nRandom Field (CRF) and Block-Normalized Gradient (BNG). The models are tested\non the only freely available benchmark dataset and the results show that our\nmodels are either better or on par with other models, which require\nlanguage-dependent post-processing steps, unlike ours. Moreover, we show that\ndiacritics in Arabic can be used to enhance the models of NLP tasks such as\nMachine Translation (MT) by proposing the Translation over Diacritization (ToD)\napproach.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 20:52:12 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Fadel", "Ali", ""], ["Tuffaha", "Ibraheem", ""], ["Al-Jawarneh", "Bara'", ""], ["Al-Ayyoub", "Mahmoud", ""]]}, {"id": "1911.03561", "submitter": "Alireza Mohammadshahi", "authors": "Alireza Mohammadshahi and James Henderson", "title": "Graph-to-Graph Transformer for Transition-based Dependency Parsing", "comments": "Accepted to Findings of EMNLP 2020", "journal-ref": null, "doi": "10.18653/v1/2020.findings-emnlp.294", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Graph2Graph Transformer architecture for conditioning on and\npredicting arbitrary graphs, and apply it to the challenging task of\ntransition-based dependency parsing. After proposing two novel Transformer\nmodels of transition-based dependency parsing as strong baselines, we show that\nadding the proposed mechanisms for conditioning on and predicting graphs of\nGraph2Graph Transformer results in significant improvements, both with and\nwithout BERT pre-training. The novel baselines and their integration with\nGraph2Graph Transformer significantly outperform the state-of-the-art in\ntraditional transition-based dependency parsing on both English Penn Treebank,\nand 13 languages of Universal Dependencies Treebanks. Graph2Graph Transformer\ncan be integrated with many previous structured prediction methods, making it\neasy to apply to a wide range of NLP tasks.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 22:14:35 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 09:11:16 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 10:22:09 GMT"}, {"version": "v4", "created": "Fri, 30 Oct 2020 09:37:18 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Mohammadshahi", "Alireza", ""], ["Henderson", "James", ""]]}, {"id": "1911.03562", "submitter": "Saif Mohammad Dr.", "authors": "Saif M. Mohammad", "title": "The State of NLP Literature: A Diachronic Analysis of the ACL Anthology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ACL Anthology (AA) is a digital repository of tens of thousands of\narticles on Natural Language Processing (NLP). This paper examines the\nliterature as a whole to identify broad trends in productivity, focus, and\nimpact. It presents the analyses in a sequence of questions and answers. The\ngoal is to record the state of the AA literature: who and how many of us are\npublishing? what are we publishing on? where and in what form are we\npublishing? and what is the impact of our publications? The answers are usually\nin the form of numbers, graphs, and inter-connected visualizations. Special\nemphasis is laid on the demographics and inclusiveness of NLP publishing.\nNotably, we find that only about 30% of first authors are female, and that this\npercentage has not improved since the year 2000. We also show that, on average,\nfemale first authors are cited less than male first authors, even when\ncontrolling for experience. We hope that recording citation and participation\ngaps across demographic groups will encourage more inclusiveness and fairness\nin research.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 22:15:32 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Mohammad", "Saif M.", ""]]}, {"id": "1911.03584", "submitter": "Jean-Baptiste Cordonnier", "authors": "Jean-Baptiste Cordonnier, Andreas Loukas, Martin Jaggi", "title": "On the Relationship between Self-Attention and Convolutional Layers", "comments": "To appear at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent trends of incorporating attention mechanisms in vision have led\nresearchers to reconsider the supremacy of convolutional layers as a primary\nbuilding block. Beyond helping CNNs to handle long-range dependencies,\nRamachandran et al. (2019) showed that attention can completely replace\nconvolution and achieve state-of-the-art performance on vision tasks. This\nraises the question: do learned attention layers operate similarly to\nconvolutional layers? This work provides evidence that attention layers can\nperform convolution and, indeed, they often learn to do so in practice.\nSpecifically, we prove that a multi-head self-attention layer with sufficient\nnumber of heads is at least as expressive as any convolutional layer. Our\nnumerical experiments then show that self-attention layers attend to pixel-grid\npatterns similarly to CNN layers, corroborating our analysis. Our code is\npublicly available.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 23:48:38 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 09:06:09 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Cordonnier", "Jean-Baptiste", ""], ["Loukas", "Andreas", ""], ["Jaggi", "Martin", ""]]}, {"id": "1911.03587", "submitter": "Fabio Petroni", "authors": "Luca Massarelli, Fabio Petroni, Aleksandra Piktus, Myle Ott, Tim\n  Rockt\\\"aschel, Vassilis Plachouras, Fabrizio Silvestri, Sebastian Riedel", "title": "How Decoding Strategies Affect the Verifiability of Generated Text", "comments": "accepted at Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in pre-trained language models led to systems that are able\nto generate text of an increasingly high quality. While several works have\ninvestigated the fluency and grammatical correctness of such models, it is\nstill unclear to which extent the generated text is consistent with factual\nworld knowledge. Here, we go beyond fluency and also investigate the\nverifiability of text generated by state-of-the-art pre-trained language\nmodels. A generated sentence is verifiable if it can be corroborated or\ndisproved by Wikipedia, and we find that the verifiability of generated text\nstrongly depends on the decoding strategy. In particular, we discover a\ntradeoff between factuality (i.e., the ability of generating Wikipedia\ncorroborated text) and repetitiveness. While decoding strategies such as top-k\nand nucleus sampling lead to less repetitive generations, they also produce\nless verifiable text. Based on these finding, we introduce a simple and\neffective decoding strategy which, in comparison to previously used decoding\nstrategies, produces less repetitive and more verifiable text.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 00:16:03 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 07:39:38 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Massarelli", "Luca", ""], ["Petroni", "Fabio", ""], ["Piktus", "Aleksandra", ""], ["Ott", "Myle", ""], ["Rockt\u00e4schel", "Tim", ""], ["Plachouras", "Vassilis", ""], ["Silvestri", "Fabrizio", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1911.03588", "submitter": "Linqing Liu", "authors": "Linqing Liu, Huan Wang, Jimmy Lin, Richard Socher, Caiming Xiong", "title": "MKD: a Multi-Task Knowledge Distillation Approach for Pretrained\n  Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretrained language models have led to significant performance gains in many\nNLP tasks. However, the intensive computing resources to train such models\nremain an issue. Knowledge distillation alleviates this problem by learning a\nlight-weight student model. So far the distillation approaches are all\ntask-specific. In this paper, we explore knowledge distillation under the\nmulti-task learning setting. The student is jointly distilled across different\ntasks. It acquires more general representation capacity through multi-tasking\ndistillation and can be further fine-tuned to improve the model in the target\ndomain. Unlike other BERT distillation methods which specifically designed for\nTransformer-based architectures, we provide a general learning framework. Our\napproach is model agnostic and can be easily applied on different future\nteacher model architectures. We evaluate our approach on a Transformer-based\nand LSTM based student model. Compared to a strong, similarly LSTM-based\napproach, we achieve better quality under the same computational constraints.\nCompared to the present state of the art, we reach comparable results with much\nfaster inference speed.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 00:22:05 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 23:19:01 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Liu", "Linqing", ""], ["Wang", "Huan", ""], ["Lin", "Jimmy", ""], ["Socher", "Richard", ""], ["Xiong", "Caiming", ""]]}, {"id": "1911.03597", "submitter": "Yinpeng Guo", "authors": "Yinpeng Guo, Yi Liao, Xin Jiang, Qing Zhang, Yibo Zhang, Qun Liu", "title": "Zero-Shot Paraphrase Generation with Multilingual Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging multilingual parallel texts to automatically generate paraphrases\nhas drawn much attention as size of high-quality paraphrase corpus is limited.\nRound-trip translation, also known as the pivoting method, is a typical\napproach to this end. However, we notice that the pivoting process involves\nmultiple machine translation models and is likely to incur semantic drift\nduring the two-step translations. In this paper, inspired by the\nTransformer-based language models, we propose a simple and unified paraphrasing\nmodel, which is purely trained on multilingual parallel data and can conduct\nzero-shot paraphrase generation in one step. Compared with the pivoting\napproach, paraphrases generated by our model is more semantically similar to\nthe input sentence. Moreover, since our model shares the same architecture as\nGPT (Radford et al., 2018), we are able to pre-train the model on large-scale\nunparallel corpus, which further improves the fluency of the output sentences.\nIn addition, we introduce the mechanism of denoising auto-encoder (DAE) to\nimprove diversity and robustness of the model. Experimental results show that\nour model surpasses the pivoting method in terms of relevance, diversity,\nfluency and efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 02:49:31 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Guo", "Yinpeng", ""], ["Liao", "Yi", ""], ["Jiang", "Xin", ""], ["Zhang", "Qing", ""], ["Zhang", "Yibo", ""], ["Liu", "Qun", ""]]}, {"id": "1911.03598", "submitter": "Lili Yu", "authors": "Lili Yu, Howard Chen, Sida Wang, Tao Lei, Yoav Artzi", "title": "Interactive Classification by Asking Informative Questions", "comments": "Accepted at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the potential for interaction in natural language classification. We\nadd a limited form of interaction for intent classification, where users\nprovide an initial query using natural language, and the system asks for\nadditional information using binary or multi-choice questions. At each turn,\nour system decides between asking the most informative question or making the\nfinal classification prediction.The simplicity of the model allows for\nbootstrapping of the system without interaction data, instead relying on simple\ncrowdsourcing tasks. We evaluate our approach on two domains, showing the\nbenefit of interaction and the advantage of learning to balance between asking\nadditional questions and making the final prediction.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 03:05:50 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 19:47:51 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Yu", "Lili", ""], ["Chen", "Howard", ""], ["Wang", "Sida", ""], ["Lei", "Tao", ""], ["Artzi", "Yoav", ""]]}, {"id": "1911.03601", "submitter": "Tianyu Liu", "authors": "Tianyu Liu and Wei Wei and William Yang Wang", "title": "Table-to-Text Natural Language Generation with Unseen Schemas", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional table-to-text natural language generation (NLG) tasks focus on\ngenerating text from schemas that are already seen in the training set. This\nlimitation curbs their generalizabilities towards real-world scenarios, where\nthe schemas of input tables are potentially infinite. In this paper, we propose\nthe new task of table-to-text NLG with unseen schemas, which specifically aims\nto test the generalization of NLG for input tables with attribute types that\nnever appear during training. To do this, we construct a new benchmark dataset\nfor this task. To deal with the problem of unseen attribute types, we propose a\nnew model that first aligns unseen table schemas to seen ones, and then\ngenerates text with updated table representations. Experimental evaluation on\nthe new benchmark demonstrates that our model outperforms baseline methods by a\nlarge margin. In addition, comparison with standard data-to-text settings shows\nthe challenges and uniqueness of our proposed task.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 03:18:02 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Liu", "Tianyu", ""], ["Wei", "Wei", ""], ["Wang", "William Yang", ""]]}, {"id": "1911.03604", "submitter": "Bharat Venkitesh", "authors": "Alex Bie, Bharat Venkitesh, Joao Monteiro, Md. Akmal Haidar, Mehdi\n  Rezagholizadeh", "title": "A Simplified Fully Quantized Transformer for End-to-end Speech\n  Recognition", "comments": "Submitted to IEEE Signal Processing Letters Minor changes in Section\n  3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While significant improvements have been made in recent years in terms of\nend-to-end automatic speech recognition (ASR) performance, such improvements\nwere obtained through the use of very large neural networks, unfit for embedded\nuse on edge devices. That being said, in this paper, we work on simplifying and\ncompressing Transformer-based encoder-decoder architectures for the end-to-end\nASR task. We empirically introduce a more compact Speech-Transformer by\ninvestigating the impact of discarding particular modules on the performance of\nthe model. Moreover, we evaluate reducing the numerical precision of our\nnetwork's weights and activations while maintaining the performance of the\nfull-precision model. Our experiments show that we can reduce the number of\nparameters of the full-precision model and then further compress the model 4x\nby fully quantizing to 8-bit fixed point precision.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 03:29:06 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 20:23:02 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 19:25:24 GMT"}, {"version": "v4", "created": "Tue, 24 Mar 2020 15:00:44 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Bie", "Alex", ""], ["Venkitesh", "Bharat", ""], ["Monteiro", "Joao", ""], ["Haidar", "Md. Akmal", ""], ["Rezagholizadeh", "Mehdi", ""]]}, {"id": "1911.03614", "submitter": "Yiming Cui", "authors": "Ziqing Yang, Yiming Cui, Wanxiang Che, Ting Liu, Shijin Wang, Guoping\n  Hu", "title": "Improving Machine Reading Comprehension via Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training (AT) as a regularization method has proved its\neffectiveness in various tasks, such as image classification and text\nclassification. Though there are successful applications of AT in many tasks of\nnatural language processing (NLP), the mechanism behind it is still unclear. In\nthis paper, we aim to apply AT on machine reading comprehension (MRC) and study\nits effects from multiple perspectives. We experiment with three different\nkinds of RC tasks: span-based RC, span-based RC with unanswerable questions and\nmulti-choice RC. The experimental results show that the proposed method can\nimprove the performance significantly and universally on SQuAD1.1, SQuAD2.0 and\nRACE. With virtual adversarial training (VAT), we explore the possibility of\nimproving the RC models with semi-supervised learning and prove that examples\nfrom a different task are also beneficial. We also find that AT helps little in\ndefending against artificial adversarial examples, but AT helps the model to\nlearn better on examples that contain more low-frequency words.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 05:31:40 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Yang", "Ziqing", ""], ["Cui", "Yiming", ""], ["Che", "Wanxiang", ""], ["Liu", "Ting", ""], ["Wang", "Shijin", ""], ["Hu", "Guoping", ""]]}, {"id": "1911.03626", "submitter": "Chun Yuan Yuan", "authors": "Qianwen Ma, Chunyuan Yuan, Wei Zhou, Jizhong Han, Songlin Hu", "title": "Beyond Statistical Relations: Integrating Knowledge Relations into Style\n  Correlations for Multi-Label Music Style Classification", "comments": "Accepted as WSDM 2020 Regular Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Automatically labeling multiple styles for every song is a comprehensive\napplication in all kinds of music websites. Recently, some researches explore\nreview-driven multi-label music style classification and exploit style\ncorrelations for this task. However, their methods focus on mining the\nstatistical relations between different music styles and only consider shallow\nstyle relations. Moreover, these statistical relations suffer from the\nunderfitting problem because some music styles have little training data.\n  To tackle these problems, we propose a novel knowledge relations integrated\nframework (KRF) to capture the complete style correlations, which jointly\nexploits the inherent relations between music styles according to external\nknowledge and their statistical relations. Based on the two types of relations,\nwe use a graph convolutional network to learn the deep correlations between\nstyles automatically. Experimental results show that our framework\nsignificantly outperforms state-of-the-art methods. Further studies demonstrate\nthat our framework can effectively alleviate the underfitting problem and learn\nmeaningful style correlations. The source code can be available at\nhttps://github.com/Makwen1995/MusicGenre.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 06:55:39 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 08:30:13 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Ma", "Qianwen", ""], ["Yuan", "Chunyuan", ""], ["Zhou", "Wei", ""], ["Han", "Jizhong", ""], ["Hu", "Songlin", ""]]}, {"id": "1911.03627", "submitter": "Xuancheng Huang", "authors": "Xuancheng Huang, Yang Liu, Huanbo Luan, Jingfang Xu and Maosong Sun", "title": "Learning to Copy for Automatic Post-Editing", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic post-editing (APE), which aims to correct errors in the output of\nmachine translation systems in a post-processing step, is an important task in\nnatural language processing. While recent work has achieved considerable\nperformance gains by using neural networks, how to model the copying mechanism\nfor APE remains a challenge. In this work, we propose a new method for modeling\ncopying for APE. To better identify translation errors, our method learns the\nrepresentations of source sentences and system outputs in an interactive way.\nThese representations are used to explicitly indicate which words in the system\noutputs should be copied, which is useful to help CopyNet (Gu et al., 2016)\nbetter generate post-edited translations. Experiments on the datasets of the\nWMT 2016-2017 APE shared tasks show that our approach outperforms all best\npublished results.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 06:58:29 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Huang", "Xuancheng", ""], ["Liu", "Yang", ""], ["Luan", "Huanbo", ""], ["Xu", "Jingfang", ""], ["Sun", "Maosong", ""]]}, {"id": "1911.03631", "submitter": "Yuwei Fang", "authors": "Yuwei Fang, Siqi Sun, Zhe Gan, Rohit Pillai, Shuohang Wang, Jingjing\n  Liu", "title": "Hierarchical Graph Network for Multi-hop Question Answering", "comments": "Accepted to EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present Hierarchical Graph Network (HGN) for multi-hop\nquestion answering. To aggregate clues from scattered texts across multiple\nparagraphs, a hierarchical graph is created by constructing nodes on different\nlevels of granularity (questions, paragraphs, sentences, entities), the\nrepresentations of which are initialized with pre-trained contextual encoders.\nGiven this hierarchical graph, the initial node representations are updated\nthrough graph propagation, and multi-hop reasoning is performed via traversing\nthrough the graph edges for each subsequent sub-task (e.g., paragraph\nselection, supporting facts extraction, answer prediction). By weaving\nheterogeneous nodes into an integral unified graph, this hierarchical\ndifferentiation of node granularity enables HGN to support different question\nanswering sub-tasks simultaneously. Experiments on the HotpotQA benchmark\ndemonstrate that the proposed model achieves new state of the art,\noutperforming existing multi-hop QA approaches.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 07:18:47 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 19:40:03 GMT"}, {"version": "v3", "created": "Sun, 27 Sep 2020 05:00:08 GMT"}, {"version": "v4", "created": "Tue, 6 Oct 2020 08:17:58 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Fang", "Yuwei", ""], ["Sun", "Siqi", ""], ["Gan", "Zhe", ""], ["Pillai", "Rohit", ""], ["Wang", "Shuohang", ""], ["Liu", "Jingjing", ""]]}, {"id": "1911.03642", "submitter": "Andrew Gaut", "authors": "Andrew Gaut, Tony Sun, Shirlyn Tang, Yuxin Huang, Jing Qian, Mai\n  ElSherief, Jieyu Zhao, Diba Mirza, Elizabeth Belding, Kai-Wei Chang, William\n  Yang Wang", "title": "Towards Understanding Gender Bias in Relation Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in Neural Relation Extraction (NRE) have made significant\nstrides towards Automated Knowledge Base Construction (AKBC). While much\nattention has been dedicated towards improvements in accuracy, there have been\nno attempts in the literature to our knowledge to evaluate social biases in NRE\nsystems. We create WikiGenderBias, a distantly supervised dataset with a human\nannotated test set. WikiGenderBias has sentences specifically curated to\nanalyze gender bias in relation extraction systems. We use WikiGenderBias to\nevaluate systems for bias and find that NRE systems exhibit gender biased\npredictions and lay groundwork for future evaluation of bias in NRE. We also\nanalyze how name anonymization, hard debiasing for word embeddings, and\ncounterfactual data augmentation affect gender bias in predictions and\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 08:43:02 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 22:38:12 GMT"}, {"version": "v3", "created": "Sat, 8 Aug 2020 23:59:54 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Gaut", "Andrew", ""], ["Sun", "Tony", ""], ["Tang", "Shirlyn", ""], ["Huang", "Yuxin", ""], ["Qian", "Jing", ""], ["ElSherief", "Mai", ""], ["Zhao", "Jieyu", ""], ["Mirza", "Diba", ""], ["Belding", "Elizabeth", ""], ["Chang", "Kai-Wei", ""], ["Wang", "William Yang", ""]]}, {"id": "1911.03644", "submitter": "Kiet Nguyen Van", "authors": "Tin Van Huynh, Vu Duc Nguyen, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen,\n  Anh Gia-Tuan Nguyen", "title": "Hate Speech Detection on Vietnamese Social Media Text using the\n  Bi-GRU-LSTM-CNN Model", "comments": "Technical Report, VLSP Workshop 2019", "journal-ref": "VLSP Workshop 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Hate Speech Detection has become one of the interesting\nfields in natural language processing or computational linguistics. In this\npaper, we present the description of our system to solve this problem at the\nVLSP shared task 2019: Hate Speech Detection on Social Networks with the corpus\nwhich contains 20,345 human-labeled comments/posts for training and 5,086 for\npublic-testing. We implement a deep learning method based on the\nBi-GRU-LSTM-CNN classifier into this task. Our result in this task is 70.576%\nof F1-score, ranking the 5th of performance on public-test set.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 09:12:58 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 12:39:15 GMT"}, {"version": "v3", "created": "Sun, 22 Dec 2019 03:46:49 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Van Huynh", "Tin", ""], ["Nguyen", "Vu Duc", ""], ["Van Nguyen", "Kiet", ""], ["Nguyen", "Ngan Luu-Thuy", ""], ["Nguyen", "Anh Gia-Tuan", ""]]}, {"id": "1911.03648", "submitter": "Kiet Nguyen Van", "authors": "Hang Thi-Thuy Do, Huy Duc Huynh, Kiet Van Nguyen, Ngan Luu-Thuy\n  Nguyen, Anh Gia-Tuan Nguyen", "title": "Hate Speech Detection on Vietnamese Social Media Text using the\n  Bidirectional-LSTM Model", "comments": null, "journal-ref": "VLSP Workshop 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we describe our system which participates in the shared task\nof Hate Speech Detection on Social Networks of VLSP 2019 evaluation campaign.\nWe are provided with the pre-labeled dataset and an unlabeled dataset for\nsocial media comments or posts. Our mission is to pre-process and build machine\nlearning models to classify comments/posts. In this report, we use\nBidirectional Long Short-Term Memory to build the model that can predict labels\nfor social media text according to Clean, Offensive, Hate. With this system, we\nachieve comparative results with 71.43% on the public standard test set of VLSP\n2019.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 09:33:42 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Do", "Hang Thi-Thuy", ""], ["Huynh", "Huy Duc", ""], ["Van Nguyen", "Kiet", ""], ["Nguyen", "Ngan Luu-Thuy", ""], ["Nguyen", "Anh Gia-Tuan", ""]]}, {"id": "1911.03663", "submitter": "Dongyeop Kang", "authors": "Dongyeop Kang, Eduard Hovy", "title": "Style is NOT a single variable: Case Studies for Cross-Style Language\n  Understanding", "comments": "Accepted to ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every natural text is written in some style. Style is formed by a complex\ncombination of different stylistic factors, including formality markers,\nemotions, metaphors, etc. One cannot form a complete understanding of a text\nwithout considering these factors. The factors combine and co-vary in complex\nways to form styles. Studying the nature of the co-varying combinations sheds\nlight on stylistic language in general, sometimes called cross-style language\nunderstanding. This paper provides the benchmark corpus (xSLUE) that combines\nexisting datasets and collects a new one for sentence-level cross-style\nlanguage understanding and evaluation. The benchmark contains text in 15\ndifferent styles under the proposed four theoretical groupings: figurative,\npersonal, affective, and interpersonal groups. For valid evaluation, we collect\nan additional diagnostic set by annotating all 15 styles on the same text.\nUsing xSLUE, we propose three interesting cross-style applications in\nclassification, correlation, and generation. First, our proposed cross-style\nclassifier trained with multiple styles together helps improve overall\nclassification performance against individually-trained style classifiers.\nSecond, our study shows that some styles are highly dependent on each other in\nhuman-written text. Finally, we find that combinations of some contradictive\nstyles likely generate stylistically less appropriate text. We believe our\nbenchmark and case studies help explore interesting future directions for\ncross-style research. The preprocessed datasets and code are publicly\navailable.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 10:55:34 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 00:41:40 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Kang", "Dongyeop", ""], ["Hovy", "Eduard", ""]]}, {"id": "1911.03668", "submitter": "Zhen Cheng", "authors": "Zhen Cheng, Zaixiang Zheng, Xin-Yu Dai, Shujian Huang, Jiajun Chen", "title": "Multi-Perspective Inferrer: Reasoning Sentences Relationship from\n  Holistic Perspective", "comments": "In progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Language Inference (NLI) aims to determine the logic relationships\n(i.e., entailment, neutral and contradiction) between a pair of premise and\nhypothesis. Recently, the alignment mechanism effectively helps NLI by\ncapturing the aligned parts (i.e., the similar segments) in the sentence pairs,\nwhich imply the perspective of entailment and contradiction. However, these\naligned parts will sometimes mislead the judgment of neutral relations.\nIntuitively, NLI should rely more on multiple perspectives to form a holistic\nview to eliminate bias. In this paper, we propose the Multi-Perspective\nInferrer (MPI), a novel NLI model that reasons relationships from multiple\nperspectives associated with the three relationships. The MPI determines the\nperspectives of different parts of the sentences via a routing-by-agreement\npolicy and makes the final decision from a holistic view. Additionally, we\nintroduce an auxiliary supervised signal to ensure the MPI to learn the\nexpected perspectives. Experiments on SNLI and MultiNLI show that 1) the MPI\nachieves substantial improvements on the base model, which verifies the\nmotivation of multi-perspective inference; 2) visualized evidence verifies that\nthe MPI learns highly interpretable perspectives as expected; 3) more\nimportantly, the MPI is architecture-free and compatible with the powerful\nBERT.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 11:21:48 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Cheng", "Zhen", ""], ["Zheng", "Zaixiang", ""], ["Dai", "Xin-Yu", ""], ["Huang", "Shujian", ""], ["Chen", "Jiajun", ""]]}, {"id": "1911.03677", "submitter": "Wei Zou", "authors": "Wei Zou, Shujian Huang, Jun Xie, Xinyu Dai, Jiajun Chen", "title": "A Reinforced Generation of Adversarial Examples for Neural Machine\n  Translation", "comments": "12 pages, ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation systems tend to fail on less decent inputs despite\nits significant efficacy, which may significantly harm the credibility of this\nsystems-fathoming how and when neural-based systems fail in such cases is\ncritical for industrial maintenance. Instead of collecting and analyzing bad\ncases using limited handcrafted error features, here we investigate this issue\nby generating adversarial examples via a new paradigm based on reinforcement\nlearning. Our paradigm could expose pitfalls for a given performance metric,\ne.g., BLEU, and could target any given neural machine translation architecture.\nWe conduct experiments of adversarial attacks on two mainstream neural machine\ntranslation architectures, RNN-search, and Transformer. The results show that\nour method efficiently produces stable attacks with meaning-preserving\nadversarial examples. We also present a qualitative and quantitative analysis\nfor the preference pattern of the attack, demonstrating its capability of\npitfall exposure.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 12:33:47 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 14:36:00 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Zou", "Wei", ""], ["Huang", "Shujian", ""], ["Xie", "Jun", ""], ["Dai", "Xinyu", ""], ["Chen", "Jiajun", ""]]}, {"id": "1911.03678", "submitter": "Desmond Elliott", "authors": "\\'Akos K\\'ad\\'ar, Grzegorz Chrupa{\\l}a, Afra Alishahi, Desmond Elliott", "title": "Bootstrapping Disjoint Datasets for Multilingual Multimodal\n  Representation Learning", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has highlighted the advantage of jointly learning grounded\nsentence representations from multiple languages. However, the data used in\nthese studies has been limited to an aligned scenario: the same images\nannotated with sentences in multiple languages. We focus on the more realistic\ndisjoint scenario in which there is no overlap between the images in\nmultilingual image--caption datasets. We confirm that training with aligned\ndata results in better grounded sentence representations than training with\ndisjoint data, as measured by image--sentence retrieval performance. In order\nto close this gap in performance, we propose a pseudopairing method to generate\nsynthetically aligned English--German--image triplets from the disjoint sets.\nThe method works by first training a model on the disjoint data, and then\ncreating new triples across datasets using sentence similarity under the\nlearned model. Experiments show that pseudopairs improve image--sentence\nretrieval performance compared to disjoint training, despite requiring no\nexternal data or models. However, we do find that using an external machine\ntranslation model to generate the synthetic data sets results in better\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 12:34:01 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["K\u00e1d\u00e1r", "\u00c1kos", ""], ["Chrupa\u0142a", "Grzegorz", ""], ["Alishahi", "Afra", ""], ["Elliott", "Desmond", ""]]}, {"id": "1911.03681", "submitter": "Nina Poerner", "authors": "Nina Poerner and Ulli Waltinger and Hinrich Sch\\\"utze", "title": "E-BERT: Efficient-Yet-Effective Entity Embeddings for BERT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel way of injecting factual knowledge about entities into the\npretrained BERT model (Devlin et al., 2019): We align Wikipedia2Vec entity\nvectors (Yamada et al., 2016) with BERT's native wordpiece vector space and use\nthe aligned entity vectors as if they were wordpiece vectors. The resulting\nentity-enhanced version of BERT (called E-BERT) is similar in spirit to ERNIE\n(Zhang et al., 2019) and KnowBert (Peters et al., 2019), but it requires no\nexpensive further pretraining of the BERT encoder. We evaluate E-BERT on\nunsupervised question answering (QA), supervised relation classification (RC)\nand entity linking (EL). On all three tasks, E-BERT outperforms BERT and other\nbaselines. We also show quantitatively that the original BERT model is overly\nreliant on the surface form of entity names (e.g., guessing that someone with\nan Italian-sounding name speaks Italian), and that E-BERT mitigates this\nproblem.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 13:08:25 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 09:19:35 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Poerner", "Nina", ""], ["Waltinger", "Ulli", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1911.03688", "submitter": "Ivan Vuli\\'c", "authors": "Matthew Henderson, I\\~nigo Casanueva, Nikola Mrk\\v{s}i\\'c, Pei-Hao Su,\n  Tsung-Hsien Wen, Ivan Vuli\\'c", "title": "ConveRT: Efficient and Accurate Conversational Representations from\n  Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  General-purpose pretrained sentence encoders such as BERT are not ideal for\nreal-world conversational AI applications; they are computationally heavy,\nslow, and expensive to train. We propose ConveRT (Conversational\nRepresentations from Transformers), a pretraining framework for conversational\ntasks satisfying all the following requirements: it is effective, affordable,\nand quick to train. We pretrain using a retrieval-based response selection\ntask, effectively leveraging quantization and subword-level parameterization in\nthe dual encoder to build a lightweight memory- and energy-efficient model. We\nshow that ConveRT achieves state-of-the-art performance across widely\nestablished response selection tasks. We also demonstrate that the use of\nextended dialog history as context yields further performance gains. Finally,\nwe show that pretrained representations from the proposed encoder can be\ntransferred to the intent classification task, yielding strong results across\nthree diverse data sets. ConveRT trains substantially faster than standard\nsentence encoders or previous state-of-the-art dual encoders. With its reduced\nsize and superior performance, we believe this model promises wider portability\nand scalability for Conversational AI applications.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 13:35:18 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 17:23:52 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Henderson", "Matthew", ""], ["Casanueva", "I\u00f1igo", ""], ["Mrk\u0161i\u0107", "Nikola", ""], ["Su", "Pei-Hao", ""], ["Wen", "Tsung-Hsien", ""], ["Vuli\u0107", "Ivan", ""]]}, {"id": "1911.03698", "submitter": "Alice Coucke", "authors": "St\\'ephane d'Ascoli, Alice Coucke, Francesco Caltagirone, Alexandre\n  Caulier, Marc Lelarge", "title": "Conditioned Query Generation for Task-Oriented Dialogue Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scarcity of training data for task-oriented dialogue systems is a well known\nproblem that is usually tackled with costly and time-consuming manual data\nannotation. An alternative solution is to rely on automatic text generation\nwhich, although less accurate than human supervision, has the advantage of\nbeing cheap and fast. In this paper we propose a novel controlled data\ngeneration method that could be used as a training augmentation framework for\nclosed-domain dialogue. Our contribution is twofold. First we show how to\noptimally train and control the generation of intent-specific sentences using a\nconditional variational autoencoder. Then we introduce a novel protocol called\nquery transfer that allows to leverage a broad, unlabelled dataset to extract\nrelevant information. Comparison with two different baselines shows that our\nmethod, in the appropriate regime, consistently improves the diversity of the\ngenerated queries without compromising their quality.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 14:22:57 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["d'Ascoli", "St\u00e9phane", ""], ["Coucke", "Alice", ""], ["Caltagirone", "Francesco", ""], ["Caulier", "Alexandre", ""], ["Lelarge", "Marc", ""]]}, {"id": "1911.03700", "submitter": "Nina Poerner", "authors": "Nina Poerner and Ulli Waltinger and Hinrich Sch\\\"utze", "title": "Sentence Meta-Embeddings for Unsupervised Semantic Textual Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the task of unsupervised Semantic Textual Similarity (STS) by\nensembling diverse pre-trained sentence encoders into sentence meta-embeddings.\nWe apply, extend and evaluate different meta-embedding methods from the word\nembedding literature at the sentence level, including dimensionality reduction\n(Yin and Sch\\\"utze, 2016), generalized Canonical Correlation Analysis (Rastogi\net al., 2015) and cross-view auto-encoders (Bollegala and Bao, 2018). Our\nsentence meta-embeddings set a new unsupervised State of The Art (SoTA) on the\nSTS Benchmark and on the STS12-STS16 datasets, with gains of between 3.7% and\n6.4% Pearson's r over single-source systems.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 14:31:03 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 09:47:11 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 17:58:19 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Poerner", "Nina", ""], ["Waltinger", "Ulli", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1911.03705", "submitter": "Bill Yuchen Lin", "authors": "Bill Yuchen Lin, Wangchunshu Zhou, Ming Shen, Pei Zhou, Chandra\n  Bhagavatula, Yejin Choi, Xiang Ren", "title": "CommonGen: A Constrained Text Generation Challenge for Generative\n  Commonsense Reasoning", "comments": "Accepted to EMNLP 2020 Findings. Add one more human reference for\n  each test example: Table 1,3 & Figure 4 & Section 3.3, 3.4 are updated.\n  Project page: https://inklab.usc.edu/CommonGen/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, large-scale pre-trained language models have demonstrated\nimpressive performance on several commonsense-reasoning benchmark datasets.\nHowever, building machines with commonsense to compose realistically plausible\nsentences remains challenging. In this paper, we present a constrained text\ngeneration task, CommonGen associated with a benchmark dataset, to explicitly\ntest machines for the ability of generative commonsense reasoning. Given a set\nof common concepts (e.g., {dog, frisbee, catch, throw}); the task is to\ngenerate a coherent sentence describing an everyday scenario using these\nconcepts (e.g., \"a man throws a frisbee and his dog catches it\").\n  The CommonGen task is challenging because it inherently requires 1)\nrelational reasoning with background commonsense knowledge, and 2)\ncompositional generalization ability to work on unseen concept combinations.\nOur dataset, constructed through a combination of crowdsourced and existing\ncaption corpora, consists of 79k commonsense descriptions over 35k unique\nconcept-sets. Experiments show that there is a large gap between\nstate-of-the-art text generation models (e.g., T5) and human performance.\nFurthermore, we demonstrate that the learned generative commonsense reasoning\ncapability can be transferred to improve downstream tasks such as CommonsenseQA\nby generating additional context.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 14:53:59 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 01:26:38 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2020 00:57:08 GMT"}, {"version": "v4", "created": "Mon, 30 Nov 2020 07:53:50 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Lin", "Bill Yuchen", ""], ["Zhou", "Wangchunshu", ""], ["Shen", "Ming", ""], ["Zhou", "Pei", ""], ["Bhagavatula", "Chandra", ""], ["Choi", "Yejin", ""], ["Ren", "Xiang", ""]]}, {"id": "1911.03724", "submitter": "Kiet Nguyen Van", "authors": "Kiet Van Nguyen, Ngan Luu-Thuy Nguyen", "title": "Error Analysis for Vietnamese Dependency Parsing", "comments": null, "journal-ref": "2015 Seventh International Conference on Knowledge and Systems\n  Engineering (KSE)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dependency parsing is needed in different applications of natural language\nprocessing. In this paper, we present a thorough error analysis for dependency\nparsing for the Vietnamese language, using two state-of-the-art parsers:\nMSTParser and MaltParser. The error analysis results provide us insights in\norder to improve the performance of dependency parsing for the Vietnamese\nlanguage.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 16:00:26 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Van Nguyen", "Kiet", ""], ["Nguyen", "Ngan Luu-Thuy", ""]]}, {"id": "1911.03726", "submitter": "Kiet Nguyen Van", "authors": "Kiet Van Nguyen, Ngan Luu-Thuy Nguyen", "title": "Vietnamese transition-based dependency parsing with supertag features", "comments": "2016 Eighth International Conference on Knowledge and Systems\n  Engineering (KSE)", "journal-ref": "In Proceeding of the 2016 Eighth International Conference on\n  Knowledge and Systems Engineering (KSE)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, dependency parsing is a fascinating research topic and has a\nlot of applications in natural language processing. In this paper, we present\nan effective approach to improve dependency parsing by utilizing supertag\nfeatures. We performed experiments with the transition-based dependency parsing\napproach because it can take advantage of rich features. Empirical evaluation\non Vietnamese Dependency Treebank showed that, we achieved an improvement of\n18.92% in labeled attachment score with gold supertags and an improvement of\n3.57% with automatic supertags.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 16:07:38 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Van Nguyen", "Kiet", ""], ["Nguyen", "Ngan Luu-Thuy", ""]]}, {"id": "1911.03738", "submitter": "Marc Tanti", "authors": "Marc Tanti and Albert Gatt and Kenneth P. Camilleri", "title": "On Architectures for Including Visual Information in Neural Language\n  Models for Image Description", "comments": "145 pages, 41 figures, 15 tables, Doctoral thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A neural language model can be conditioned into generating descriptions for\nimages by providing visual information apart from the sentence prefix. This\nvisual information can be included into the language model through different\npoints of entry resulting in different neural architectures. We identify four\nmain architectures which we call init-inject, pre-inject, par-inject, and\nmerge.\n  We analyse these four architectures and conclude that the best performing one\nis init-inject, which is when the visual information is injected into the\ninitial state of the recurrent neural network. We confirm this using both\nautomatic evaluation measures and human annotation.\n  We then analyse how much influence the images have on each architecture. This\nis done by measuring how different the output probabilities of a model are when\na partial sentence is combined with a completely different image from the one\nit is meant to be combined with. We find that init-inject tends to quickly\nbecome less influenced by the image as more words are generated. A different\narchitecture called merge, which is when the visual information is merged with\nthe recurrent neural network's hidden state vector prior to output, loses\nvisual influence much more slowly, suggesting that it would work better for\ngenerating longer sentences.\n  We also observe that the merge architecture can have its recurrent neural\nnetwork pre-trained in a text-only language model (transfer learning) rather\nthan be initialised randomly as usual. This results in even better performance\nthan the other architectures, provided that the source language model is not\ntoo good at language modelling or it will overspecialise and be less effective\nat image description generation.\n  Our work opens up new avenues of research in neural architectures,\nexplainable AI, and transfer learning.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 17:07:23 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Tanti", "Marc", ""], ["Gatt", "Albert", ""], ["Camilleri", "Kenneth P.", ""]]}, {"id": "1911.03743", "submitter": "Homagni Saha", "authors": "Homagni Saha, Vijay Venkataraman, Alberto Speranzon, Soumik Sarkar", "title": "A perspective on multi-agent communication for information fusion", "comments": "NeuRIPS 2019, Workshop on Visually Grounded Interaction and Language,\n  Vancouver, CA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative decision making in multi-agent systems typically requires a\npredefined communication protocol among agents. Usually, agent-level\nobservations are locally processed and information is exchanged using the\npredefined protocol, enabling the team to perform more efficiently than each\nagent operating in isolation. In this work, we consider the situation where\nagents, with complementary sensing modalities must co-operate to achieve a\ncommon goal/task by learning an efficient communication protocol. We frame the\nproblem within an actor-critic scheme, where the agents learn optimal policies\nin a centralized fashion, while taking action in a distributed manner. We\nprovide an interpretation of the emergent communication between the agents. We\nobserve that the information exchanged is not just an encoding of the raw\nsensor data but is, rather, a specific set of directive actions that depend on\nthe overall task. Simulation results demonstrate the interpretability of the\nlearnt communication in a variety of tasks.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 17:56:47 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Saha", "Homagni", ""], ["Venkataraman", "Vijay", ""], ["Speranzon", "Alberto", ""], ["Sarkar", "Soumik", ""]]}, {"id": "1911.03762", "submitter": "Zhong Meng", "authors": "Zhong Meng, Yashesh Gaur, Jinyu Li, Yifan Gong", "title": "Speaker Adaptation for Attention-Based End-to-End Speech Recognition", "comments": "5 pages, 3 figures, Interspeech 2019", "journal-ref": "Interspeech 2019, Graz, Austria", "doi": "10.21437/Interspeech.2019-3135", "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose three regularization-based speaker adaptation approaches to adapt\nthe attention-based encoder-decoder (AED) model with very limited adaptation\ndata from target speakers for end-to-end automatic speech recognition. The\nfirst method is Kullback-Leibler divergence (KLD) regularization, in which the\noutput distribution of a speaker-dependent (SD) AED is forced to be close to\nthat of the speaker-independent (SI) model by adding a KLD regularization to\nthe adaptation criterion. To compensate for the asymmetric deficiency in KLD\nregularization, an adversarial speaker adaptation (ASA) method is proposed to\nregularize the deep-feature distribution of the SD AED through the adversarial\nlearning of an auxiliary discriminator and the SD AED. The third approach is\nthe multi-task learning, in which an SD AED is trained to jointly perform the\nprimary task of predicting a large number of output units and an auxiliary task\nof predicting a small number of output units to alleviate the target sparsity\nissue. Evaluated on a Microsoft short message dictation task, all three methods\nare highly effective in adapting the AED model, achieving up to 12.2% and 3.0%\nword error rate improvement over an SI AED trained from 3400 hours data for\nsupervised and unsupervised adaptation, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 19:41:50 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Meng", "Zhong", ""], ["Gaur", "Yashesh", ""], ["Li", "Jinyu", ""], ["Gong", "Yifan", ""]]}, {"id": "1911.03766", "submitter": "Patrick Xia", "authors": "Seth Ebner, Patrick Xia, Ryan Culkin, Kyle Rawlins, Benjamin Van Durme", "title": "Multi-Sentence Argument Linking", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel document-level model for finding argument spans that fill\nan event's roles, connecting related ideas in sentence-level semantic role\nlabeling and coreference resolution. Because existing datasets for\ncross-sentence linking are small, development of our neural model is supported\nthrough the creation of a new resource, Roles Across Multiple Sentences (RAMS),\nwhich contains 9,124 annotated events across 139 types. We demonstrate strong\nperformance of our model on RAMS and other event-related datasets.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 20:00:03 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 23:25:10 GMT"}, {"version": "v3", "created": "Sat, 9 May 2020 01:36:58 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Ebner", "Seth", ""], ["Xia", "Patrick", ""], ["Culkin", "Ryan", ""], ["Rawlins", "Kyle", ""], ["Van Durme", "Benjamin", ""]]}, {"id": "1911.03768", "submitter": "Kurt Shuster", "authors": "Kurt Shuster, Da Ju, Stephen Roller, Emily Dinan, Y-Lan Boureau, Jason\n  Weston", "title": "The Dialogue Dodecathlon: Open-Domain Knowledge and Image Grounded\n  Conversational Agents", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce dodecaDialogue: a set of 12 tasks that measures if a\nconversational agent can communicate engagingly with personality and empathy,\nask questions, answer questions by utilizing knowledge resources, discuss\ntopics and situations, and perceive and converse about images. By multi-tasking\non such a broad large-scale set of data, we hope to both move towards and\nmeasure progress in producing a single unified agent that can perceive, reason\nand converse with humans in an open-domain setting. We show that such\nmulti-tasking improves over a BERT pre-trained baseline, largely due to\nmulti-tasking with very large dialogue datasets in a similar domain, and that\nthe multi-tasking in general provides gains to both text and image-based tasks\nusing several metrics in both the fine-tune and task transfer settings. We\nobtain state-of-the-art results on many of the tasks, providing a strong\nbaseline for this challenge.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 20:05:06 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 19:38:03 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Shuster", "Kurt", ""], ["Ju", "Da", ""], ["Roller", "Stephen", ""], ["Dinan", "Emily", ""], ["Boureau", "Y-Lan", ""], ["Weston", "Jason", ""]]}, {"id": "1911.03772", "submitter": "Soumil Mandal", "authors": "Sainik Kumar Mahata, Soumil Mandal, Dipankar Das, Sivaji Bandyopadhyay", "title": "Code-Mixed to Monolingual Translation Framework", "comments": "6 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The use of multilingualism in the new generation is widespread in the form of\ncode-mixed data on social media, and therefore a robust translation system is\nrequired for catering to the monolingual users, as well as for easier\ncomprehension by language processing models. In this work, we present a\ntranslation framework that uses a translation-transliteration strategy for\ntranslating code-mixed data into their equivalent monolingual instances. For\nconverting the output to a more fluent form, it is reordered using a target\nlanguage model. The most important advantage of the proposed framework is that\nit does not require a code-mixed to monolingual parallel corpus at any point.\nOn testing the framework, it achieved BLEU and TER scores of 16.47 and 55.45,\nrespectively. Since the proposed framework deals with various sub-modules, we\ndive deeper into the importance of each of them, analyze the errors and\nfinally, discuss some improvement strategies.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 20:41:54 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 07:03:56 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Mahata", "Sainik Kumar", ""], ["Mandal", "Soumil", ""], ["Das", "Dipankar", ""], ["Bandyopadhyay", "Sivaji", ""]]}, {"id": "1911.03776", "submitter": "Sadik Bessou", "authors": "Sadik Bessou, Rania Aberkane", "title": "Subjective Sentiment Analysis for Arabic Newswire Comments", "comments": "7 pages, 7 tables, article in journal", "journal-ref": "Journal of Digital Information Management ISSN 0972-7272 2019", "doi": "10.6025/jdim/2019/17/5/289-295", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an approach based on supervised machine learning methods\nto discriminate between positive, negative and neutral Arabic reviews in online\nnewswire. The corpus is labeled for subjectivity and sentiment analysis (SSA)\nat the sentence-level. The model uses both count and TF-IDF representations and\napply six machine learning algorithms; Multinomial Naive Bayes, Support Vector\nMachines (SVM), Random Forest, Logistic Regression, Multi-layer perceptron and\nk-nearest neighbors using uni-grams, bi-grams features. With the goal of\nextracting users sentiment from written text. Experimental results showed that\nn-gram features could substantially improve performance; and showed that the\nMultinomial Naive Bayes approach is the most accurate in predicting topic\npolarity. Best results were achieved using count vectors trained by combination\nof word-based uni-grams and bi-grams with an overall accuracy of 85.57% over\ntwo classes and 65.64% over three classes.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 20:59:40 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Bessou", "Sadik", ""], ["Aberkane", "Rania", ""]]}, {"id": "1911.03782", "submitter": "Abdelrahman Mohamed", "authors": "Siddharth Dalmia, Abdelrahman Mohamed, Mike Lewis, Florian Metze, Luke\n  Zettlemoyer", "title": "Enforcing Encoder-Decoder Modularity in Sequence-to-Sequence Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by modular software design principles of independence,\ninterchangeability, and clarity of interface, we introduce a method for\nenforcing encoder-decoder modularity in seq2seq models without sacrificing the\noverall model quality or its full differentiability. We discretize the encoder\noutput units into a predefined interpretable vocabulary space using the\nConnectionist Temporal Classification (CTC) loss. Our modular systems achieve\nnear SOTA performance on the 300h Switchboard benchmark, with WER of 8.3% and\n17.6% on the SWB and CH subsets, using seq2seq models with encoder and decoder\nmodules which are independent and interchangeable.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 21:36:28 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Dalmia", "Siddharth", ""], ["Mohamed", "Abdelrahman", ""], ["Lewis", "Mike", ""], ["Metze", "Florian", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1911.03785", "submitter": "Chenguang Wang", "authors": "Yichun Yin, Chenguang Wang, Ming Zhang", "title": "PoD: Positional Dependency-Based Word Embedding for Aspect Term\n  Extraction", "comments": "7 pages, 1 figure, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dependency context-based word embedding jointly learns the representations of\nword and dependency context, and has been proved effective in aspect term\nextraction. In this paper, we design the positional dependency-based word\nembedding (PoD) which considers both dependency context and positional context\nfor aspect term extraction. Specifically, the positional context is modeled via\nrelative position encoding. Besides, we enhance the dependency context by\nintegrating more lexical information (e.g., POS tags) along dependency paths.\nExperiments on SemEval 2014/2015/2016 datasets show that our approach\noutperforms other embedding methods in aspect term extraction.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 22:06:39 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 06:08:44 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Yin", "Yichun", ""], ["Wang", "Chenguang", ""], ["Zhang", "Ming", ""]]}, {"id": "1911.03814", "submitter": "Fabio Petroni", "authors": "Ledell Wu, Fabio Petroni, Martin Josifoski, Sebastian Riedel, Luke\n  Zettlemoyer", "title": "Scalable Zero-shot Entity Linking with Dense Entity Retrieval", "comments": "accepted at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a conceptually simple, scalable, and highly effective\nBERT-based entity linking model, along with an extensive evaluation of its\naccuracy-speed trade-off. We present a two-stage zero-shot linking algorithm,\nwhere each entity is defined only by a short textual description. The first\nstage does retrieval in a dense space defined by a bi-encoder that\nindependently embeds the mention context and the entity descriptions. Each\ncandidate is then re-ranked with a cross-encoder, that concatenates the mention\nand entity text. Experiments demonstrate that this approach is state of the art\non recent zero-shot benchmarks (6 point absolute gains) and also on more\nestablished non-zero-shot evaluations (e.g. TACKBP-2010), despite its relative\nsimplicity (e.g. no explicit entity embeddings or manually engineered mention\ntables). We also show that bi-encoder linking is very fast with nearest\nneighbour search (e.g. linking with 5.9 million candidates in 2 milliseconds),\nand that much of the accuracy gain from the more expensive cross-encoder can be\ntransferred to the bi-encoder via knowledge distillation. Our code and models\nare available at https://github.com/facebookresearch/BLINK.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 01:01:45 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 10:06:20 GMT"}, {"version": "v3", "created": "Tue, 29 Sep 2020 08:13:47 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Wu", "Ledell", ""], ["Petroni", "Fabio", ""], ["Josifoski", "Martin", ""], ["Riedel", "Sebastian", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1911.03817", "submitter": "Gaurav Sahu", "authors": "Kashif Khan, Gaurav Sahu, Vikash Balasubramanian, Lili Mou, Olga\n  Vechtomova", "title": "Adversarial Learning on the Latent Space for Diverse Dialog Generation", "comments": "Accepted to COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generating relevant responses in a dialog is challenging, and requires not\nonly proper modeling of context in the conversation but also being able to\ngenerate fluent sentences during inference. In this paper, we propose a\ntwo-step framework based on generative adversarial nets for generating\nconditioned responses. Our model first learns a meaningful representation of\nsentences by autoencoding and then learns to map an input query to the response\nrepresentation, which is in turn decoded as a response sentence. Both\nquantitative and qualitative evaluations show that our model generates more\nfluent, relevant, and diverse responses than existing state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 01:32:02 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 15:58:57 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 14:35:36 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Khan", "Kashif", ""], ["Sahu", "Gaurav", ""], ["Balasubramanian", "Vikash", ""], ["Mou", "Lili", ""], ["Vechtomova", "Olga", ""]]}, {"id": "1911.03821", "submitter": "Gaurav Sahu", "authors": "Gaurav Sahu, Olga Vechtomova", "title": "Adaptive Fusion Techniques for Multimodal Data", "comments": "Camera-ready version for EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective fusion of data from multiple modalities, such as video, speech, and\ntext, is challenging due to the heterogeneous nature of multimodal data. In\nthis paper, we propose adaptive fusion techniques that aim to model context\nfrom different modalities effectively. Instead of defining a deterministic\nfusion operation, such as concatenation, for the network, we let the network\ndecide \"how\" to combine a given set of multimodal features more effectively. We\npropose two networks: 1) Auto-Fusion, which learns to compress information from\ndifferent modalities while preserving the context, and 2) GAN-Fusion, which\nregularizes the learned latent space given context from complementing\nmodalities. A quantitative evaluation on the tasks of multimodal machine\ntranslation and emotion recognition suggests that our lightweight, adaptive\nnetworks can better model context from other modalities than existing methods,\nmany of which employ massive transformer-based networks.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 01:39:46 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 08:08:02 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Sahu", "Gaurav", ""], ["Vechtomova", "Olga", ""]]}, {"id": "1911.03822", "submitter": "Zhengbao Jiang", "authors": "Zhengbao Jiang, Wei Xu, Jun Araki, Graham Neubig", "title": "Generalizing Natural Language Analysis through Span-relation\n  Representations", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language processing covers a wide variety of tasks predicting syntax,\nsemantics, and information content, and usually each type of output is\ngenerated with specially designed architectures. In this paper, we provide the\nsimple insight that a great variety of tasks can be represented in a single\nunified format consisting of labeling spans and relations between spans, thus a\nsingle task-independent model can be used across different tasks. We perform\nextensive experiments to test this insight on 10 disparate tasks spanning\ndependency parsing (syntax), semantic role labeling (semantics), relation\nextraction (information content), aspect based sentiment analysis (sentiment),\nand many others, achieving performance comparable to state-of-the-art\nspecialized models. We further demonstrate benefits of multi-task learning, and\nalso show that the proposed method makes it easy to analyze differences and\nsimilarities in how the model handles different tasks. Finally, we convert\nthese datasets into a unified format to build a benchmark, which provides a\nholistic testbed for evaluating future models for generalized natural language\nanalysis.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 01:42:14 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 20:07:51 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Jiang", "Zhengbao", ""], ["Xu", "Wei", ""], ["Araki", "Jun", ""], ["Neubig", "Graham", ""]]}, {"id": "1911.03823", "submitter": "Parker Riley", "authors": "Parker Riley, Isaac Caswell, Markus Freitag, David Grangier", "title": "Translationese as a Language in \"Multilingual\" NMT", "comments": null, "journal-ref": "Proceedings of the 58th Annual Meeting of the Association for\n  Computational Linguistics (2020) 7737-7746", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine translation has an undesirable propensity to produce \"translationese\"\nartifacts, which can lead to higher BLEU scores while being liked less by human\nraters. Motivated by this, we model translationese and original (i.e. natural)\ntext as separate languages in a multilingual model, and pose the question: can\nwe perform zero-shot translation between original source text and original\ntarget text? There is no data with original source and original target, so we\ntrain sentence-level classifiers to distinguish translationese from original\ntarget text, and use this classifier to tag the training data for an NMT model.\nUsing this technique we bias the model to produce more natural outputs at test\ntime, yielding gains in human evaluation scores on both accuracy and fluency.\nAdditionally, we demonstrate that it is possible to bias the model to produce\ntranslationese and game the BLEU score, increasing it while decreasing\nhuman-rated quality. We analyze these models using metrics to measure the\ndegree of translationese in the output, and present an analysis of the\ncapriciousness of heuristically-based train-data tagging.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 01:43:22 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 20:31:57 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Riley", "Parker", ""], ["Caswell", "Isaac", ""], ["Freitag", "Markus", ""], ["Grangier", "David", ""]]}, {"id": "1911.03828", "submitter": "Amirpasha Ghabussi", "authors": "Amirpasha Ghabussi, Lili Mou, Olga Vechtomova", "title": "Stylized Text Generation Using Wasserstein Autoencoders with a Mixture\n  of Gaussian Prior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wasserstein autoencoders are effective for text generation. They do not\nhowever provide any control over the style and topic of the generated sentences\nif the dataset has multiple classes and includes different topics. In this\nwork, we present a semi-supervised approach for generating stylized sentences.\nOur model is trained on a multi-class dataset and learns the latent\nrepresentation of the sentences using a mixture of Gaussian prior without any\nadversarial losses. This allows us to generate sentences in the style of a\nspecified class or multiple classes by sampling from their corresponding prior\ndistributions. Moreover, we can train our model on relatively small datasets\nand learn the latent representation of a specified class by adding external\ndata with other styles/classes to our dataset. While a simple WAE or VAE cannot\ngenerate diverse sentences in this case, generated sentences with our approach\nare diverse, fluent, and preserve the style and the content of the desired\nclasses.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 02:06:23 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Ghabussi", "Amirpasha", ""], ["Mou", "Lili", ""], ["Vechtomova", "Olga", ""]]}, {"id": "1911.03829", "submitter": "Yen-Chun Chen", "authors": "Yen-Chun Chen, Zhe Gan, Yu Cheng, Jingzhou Liu, Jingjing Liu", "title": "Distilling Knowledge Learned in BERT for Text Generation", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale pre-trained language model such as BERT has achieved great\nsuccess in language understanding tasks. However, it remains an open question\nhow to utilize BERT for language generation. In this paper, we present a novel\napproach, Conditional Masked Language Modeling (C-MLM), to enable the\nfinetuning of BERT on target generation tasks. The finetuned BERT (teacher) is\nexploited as extra supervision to improve conventional Seq2Seq models (student)\nfor better text generation performance. By leveraging BERT's idiosyncratic\nbidirectional nature, distilling knowledge learned in BERT can encourage\nauto-regressive Seq2Seq models to plan ahead, imposing global sequence-level\nsupervision for coherent text generation. Experiments show that the proposed\napproach significantly outperforms strong Transformer baselines on multiple\nlanguage generation tasks such as machine translation and text summarization.\nOur proposed model also achieves new state of the art on IWSLT German-English\nand English-Vietnamese MT datasets. Code is available at\nhttps://github.com/ChenRocks/Distill-BERT-Textgen.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 02:12:38 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 01:59:18 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 22:24:29 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Chen", "Yen-Chun", ""], ["Gan", "Zhe", ""], ["Cheng", "Yu", ""], ["Liu", "Jingzhou", ""], ["Liu", "Jingjing", ""]]}, {"id": "1911.03834", "submitter": "Andrej Zukov Gregoric", "authors": "Haotian Chen, Andrej Zukov-Gregoric, Xi David Li, Sahil Wadhwa", "title": "Contextualized End-to-End Neural Entity Linking", "comments": "5 pages, 1 figure, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose yet another entity linking model (YELM) which links words to\nentities instead of spans. This overcomes any difficulties associated with the\nselection of good candidate mention spans and makes the joint training of\nmention detection (MD) and entity disambiguation (ED) easily possible. Our\nmodel is based on BERT and produces contextualized word embeddings which are\ntrained against a joint MD and ED objective. We achieve state-of-the-art\nresults on several standard entity linking (EL) datasets.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 02:26:19 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 17:46:36 GMT"}, {"version": "v3", "created": "Sat, 7 Nov 2020 09:43:39 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Chen", "Haotian", ""], ["Zukov-Gregoric", "Andrej", ""], ["Li", "Xi David", ""], ["Wadhwa", "Sahil", ""]]}, {"id": "1911.03842", "submitter": "Angela Fan", "authors": "Emily Dinan, Angela Fan, Adina Williams, Jack Urbanek, Douwe Kiela,\n  Jason Weston", "title": "Queens are Powerful too: Mitigating Gender Bias in Dialogue Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models often easily learn biases present in the training data, and their\npredictions directly reflect this bias. We analyze gender bias in dialogue\ndata, and examine how this bias is actually amplified in subsequent generative\nchit-chat dialogue models. We measure gender bias in six existing dialogue\ndatasets, and focus on the most biased one, the multi-player text-based fantasy\nadventure dataset LIGHT, as a testbed for our bias mitigation techniques. The\nLIGHT dataset is highly imbalanced with respect to gender, containing\npredominantly male characters, likely because it is entirely collected by\ncrowdworkers and reflects common biases that exist in fantasy or medieval\nsettings. We consider three techniques to mitigate gender bias: counterfactual\ndata augmentation, targeted data collection, and bias controlled training. We\nshow that our proposed techniques mitigate gender bias in LIGHT by balancing\nthe genderedness of generated dialogue utterances and are particularly\neffective in combination. We quantify performance using various evaluation\nmethods---such as quantity of gendered words, a dialogue safety classifier, and\nhuman studies---all of which show that our models generate less gendered, but\nequally engaging chit-chat responses.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 03:10:50 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 14:42:47 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Dinan", "Emily", ""], ["Fan", "Angela", ""], ["Williams", "Adina", ""], ["Urbanek", "Jack", ""], ["Kiela", "Douwe", ""], ["Weston", "Jason", ""]]}, {"id": "1911.03850", "submitter": "Daniel Khashabi Mr.", "authors": "Erfan Sadeqi Azer, Daniel Khashabi, Ashish Sabharwal, Dan Roth", "title": "Not All Claims are Created Equal: Choosing the Right Statistical\n  Approach to Assess Hypotheses", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirical research in Natural Language Processing (NLP) has adopted a narrow\nset of principles for assessing hypotheses, relying mainly on p-value\ncomputation, which suffers from several known issues. While alternative\nproposals have been well-debated and adopted in other fields, they remain\nrarely discussed or used within the NLP community. We address this gap by\ncontrasting various hypothesis assessment techniques, especially those not\ncommonly used in the field (such as evaluations based on Bayesian inference).\nSince these statistical techniques differ in the hypotheses they can support,\nwe argue that practitioners should first decide their target hypothesis before\nchoosing an assessment method. This is crucial because common fallacies,\nmisconceptions, and misinterpretation surrounding hypothesis assessment methods\noften stem from a discrepancy between what one would like to claim versus what\nthe method used actually assesses. Our survey reveals that these issues are\nomnipresent in the NLP research community. As a step forward, we provide best\npractices and guidelines tailored to NLP research, as well as an easy-to-use\npackage called 'HyBayes' for Bayesian assessment of hypotheses, complementing\nexisting tools.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 04:41:31 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 17:13:55 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 00:19:19 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Azer", "Erfan Sadeqi", ""], ["Khashabi", "Daniel", ""], ["Sabharwal", "Ashish", ""], ["Roth", "Dan", ""]]}, {"id": "1911.03853", "submitter": "Rakesh Bal", "authors": "Rakesh Bal and Sayan Sinha", "title": "Modelling Bahdanau Attention using Election methods aided by Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation has lately gained a lot of \"attention\" with the\nadvent of more and more sophisticated but drastically improved models.\nAttention mechanism has proved to be a boon in this direction by providing\nweights to the input words, making it easy for the decoder to identify words\nrepresenting the present context. But by and by, as newer attention models with\nmore complexity came into development, they involved large computation, making\ninference slow. In this paper, we have modelled the attention network using\ntechniques resonating with social choice theory. Along with that, the attention\nmechanism, being a Markov Decision Process, has been represented by\nreinforcement learning techniques. Thus, we propose to use an election method\n($k$-Borda), fine-tuned using Q-learning, as a replacement for attention\nnetworks. The inference time for this network is less than a standard Bahdanau\ntranslator, and the results of the translation are comparable. This not only\nexperimentally verifies the claims stated above but also helped provide a\nfaster inference.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 04:55:46 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 14:46:21 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Bal", "Rakesh", ""], ["Sinha", "Sayan", ""]]}, {"id": "1911.03854", "submitter": "Kai Nakamura", "authors": "Kai Nakamura, Sharon Levy, William Yang Wang", "title": "r/Fakeddit: A New Multimodal Benchmark Dataset for Fine-grained Fake\n  News Detection", "comments": "Accepted LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fake news has altered society in negative ways in politics and culture. It\nhas adversely affected both online social network systems as well as offline\ncommunities and conversations. Using automatic machine learning classification\nmodels is an efficient way to combat the widespread dissemination of fake news.\nHowever, a lack of effective, comprehensive datasets has been a problem for\nfake news research and detection model development. Prior fake news datasets do\nnot provide multimodal text and image data, metadata, comment data, and\nfine-grained fake news categorization at the scale and breadth of our dataset.\nWe present Fakeddit, a novel multimodal dataset consisting of over 1 million\nsamples from multiple categories of fake news. After being processed through\nseveral stages of review, the samples are labeled according to 2-way, 3-way,\nand 6-way classification categories through distant supervision. We construct\nhybrid text+image models and perform extensive experiments for multiple\nvariations of classification, demonstrating the importance of the novel aspect\nof multimodality and fine-grained classification unique to Fakeddit.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 05:06:38 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 17:55:57 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Nakamura", "Kai", ""], ["Levy", "Sharon", ""], ["Wang", "William Yang", ""]]}, {"id": "1911.03855", "submitter": "Salvatore Giorgi", "authors": "Salvatore Giorgi, Veronica Lynn, Keshav Gupta, Farhan Ahmed, Sandra\n  Matz, Lyle Ungar and H. Andrew Schwartz", "title": "Correcting Sociodemographic Selection Biases for Population Prediction\n  from Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media is increasingly used for large-scale population predictions,\nsuch as estimating community health statistics. However, social media users are\nnot typically a representative sample of the intended population -- a\n\"selection bias\". Within the social sciences, such a bias is typically\naddressed with restratification techniques, where observations are reweighted\naccording to how under- or over-sampled their socio-demographic groups are.\nYet, restratifaction is rarely evaluated for improving prediction. Across four\ntasks of predicting U.S. county population health statistics from Twitter, we\nfind standard restratification techniques provide no improvement and often\ndegrade prediction accuracies. The core reasons for this seems to be both\nshrunken estimates (reduced variance of model predicted values) and sparse\nestimates of each population's socio-demographics. We thus develop and evaluate\nthree methods to address these problems: estimator redistribution to account\nfor shrinking, and adaptive binning and informed smoothing to handle sparse\nsocio-demographic estimates. We show that each of these methods significantly\noutperforms the standard restratification approaches. Combining approaches, we\nfind substantial improvements over non-restratified models, yielding a 53.0%\nincrease in predictive accuracy (R^2) in the case of surveyed life\nsatisfaction, and a 17.8% average increase across all tasks.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 05:13:29 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 20:05:06 GMT"}, {"version": "v3", "created": "Fri, 23 Jul 2021 21:48:35 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Giorgi", "Salvatore", ""], ["Lynn", "Veronica", ""], ["Gupta", "Keshav", ""], ["Ahmed", "Farhan", ""], ["Matz", "Sandra", ""], ["Ungar", "Lyle", ""], ["Schwartz", "H. Andrew", ""]]}, {"id": "1911.03860", "submitter": "Jason  Weston", "authors": "Margaret Li, Stephen Roller, Ilia Kulikov, Sean Welleck, Y-Lan\n  Boureau, Kyunghyun Cho, Jason Weston", "title": "Don't Say That! Making Inconsistent Dialogue Unlikely with Unlikelihood\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative dialogue models currently suffer from a number of problems which\nstandard maximum likelihood training does not address. They tend to produce\ngenerations that (i) rely too much on copying from the context, (ii) contain\nrepetitions within utterances, (iii) overuse frequent words, and (iv) at a\ndeeper level, contain logical flaws. In this work we show how all of these\nproblems can be addressed by extending the recently introduced unlikelihood\nloss (Welleck et al., 2019) to these cases. We show that appropriate loss\nfunctions which regularize generated outputs to match human distributions are\neffective for the first three issues. For the last important general issue, we\nshow applying unlikelihood to collected data of what a model should not do is\neffective for improving logical consistency, potentially paving the way to\ngenerative models with greater reasoning ability. We demonstrate the efficacy\nof our approach across several dialogue tasks.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 05:53:40 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 14:13:02 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Li", "Margaret", ""], ["Roller", "Stephen", ""], ["Kulikov", "Ilia", ""], ["Welleck", "Sean", ""], ["Boureau", "Y-Lan", ""], ["Cho", "Kyunghyun", ""], ["Weston", "Jason", ""]]}, {"id": "1911.03861", "submitter": "Yadollah Yaghoobzadeh", "authors": "Yadollah Yaghoobzadeh, Soroush Mehri, Remi Tachet, T.J. Hazen,\n  Alessandro Sordoni", "title": "Increasing Robustness to Spurious Correlations using Forgettable\n  Examples", "comments": "14 pages, Accepted at EACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural NLP models tend to rely on spurious correlations between labels and\ninput features to perform their tasks. Minority examples, i.e., examples that\ncontradict the spurious correlations present in the majority of data points,\nhave been shown to increase the out-of-distribution generalization of\npre-trained language models. In this paper, we first propose using example\nforgetting to find minority examples without prior knowledge of the spurious\ncorrelations present in the dataset. Forgettable examples are instances either\nlearned and then forgotten during training or never learned. We empirically\nshow how these examples are related to minorities in our training sets. Then,\nwe introduce a new approach to robustify models by fine-tuning our models\ntwice, first on the full training data and second on the minorities only. We\nobtain substantial improvements in out-of-distribution generalization when\napplying our approach to the MNLI, QQP, and FEVER datasets.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 05:56:41 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 03:10:10 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Yaghoobzadeh", "Yadollah", ""], ["Mehri", "Soroush", ""], ["Tachet", "Remi", ""], ["Hazen", "T. J.", ""], ["Sordoni", "Alessandro", ""]]}, {"id": "1911.03862", "submitter": "Jingqing Zhang", "authors": "Jingqing Zhang, Xiaoyu Zhang, Kai Sun, Xian Yang, Chengliang Dai, Yike\n  Guo", "title": "Unsupervised Annotation of Phenotypic Abnormalities via Semantic Latent\n  Representations on Electronic Health Records", "comments": "Accepted by BIBM 2019 (Regular)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extraction of phenotype information which is naturally contained in\nelectronic health records (EHRs) has been found to be useful in various\nclinical informatics applications such as disease diagnosis. However, due to\nimprecise descriptions, lack of gold standards and the demand for efficiency,\nannotating phenotypic abnormalities on millions of EHR narratives is still\nchallenging. In this work, we propose a novel unsupervised deep learning\nframework to annotate the phenotypic abnormalities from EHRs via semantic\nlatent representations. The proposed framework takes the advantage of Human\nPhenotype Ontology (HPO), which is a knowledge base of phenotypic\nabnormalities, to standardize the annotation results. Experiments have been\nconducted on 52,722 EHRs from MIMIC-III dataset. Quantitative and qualitative\nanalysis have shown the proposed framework achieves state-of-the-art annotation\nperformance and computational efficiency compared with other methods.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 06:04:35 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Zhang", "Jingqing", ""], ["Zhang", "Xiaoyu", ""], ["Sun", "Kai", ""], ["Yang", "Xian", ""], ["Dai", "Chengliang", ""], ["Guo", "Yike", ""]]}, {"id": "1911.03863", "submitter": "Trapit Bansal", "authors": "Trapit Bansal, Rishikesh Jha, Andrew McCallum", "title": "Learning to Few-Shot Learn Across Diverse Natural Language\n  Classification Tasks", "comments": "To appear at COLING 2020, camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-supervised pre-training of transformer models has shown enormous success\nin improving performance on a number of downstream tasks. However, fine-tuning\non a new task still requires large amounts of task-specific labelled data to\nachieve good performance. We consider this problem of learning to generalize to\nnew tasks with few examples as a meta-learning problem. While meta-learning has\nshown tremendous progress in recent years, its application is still limited to\nsimulated problems or problems with limited diversity across tasks. We develop\na novel method, LEOPARD, which enables optimization-based meta-learning across\ntasks with different number of classes, and evaluate different methods on\ngeneralization to diverse NLP classification tasks. LEOPARD is trained with the\nstate-of-the-art transformer architecture and shows better generalization to\ntasks not seen at all during training, with as few as 4 examples per label.\nAcross 17 NLP tasks, including diverse domains of entity typing, natural\nlanguage inference, sentiment analysis, and several other text classification\ntasks, we show that LEOPARD learns better initial parameters for few-shot\nlearning than self-supervised pre-training or multi-task training,\noutperforming many strong baselines, for example, yielding 14.5% average\nrelative gain in accuracy on unseen tasks with only 4 examples per label.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 06:10:47 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 00:59:14 GMT"}, {"version": "v3", "created": "Sun, 15 Nov 2020 20:57:53 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Bansal", "Trapit", ""], ["Jha", "Rishikesh", ""], ["McCallum", "Andrew", ""]]}, {"id": "1911.03864", "submitter": "Ofir Press", "authors": "Ofir Press, Noah A. Smith, Omer Levy", "title": "Improving Transformer Models by Reordering their Sublayers", "comments": "To appear at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilayer transformer networks consist of interleaved self-attention and\nfeedforward sublayers. Could ordering the sublayers in a different pattern lead\nto better performance? We generate randomly ordered transformers and train them\nwith the language modeling objective. We observe that some of these models are\nable to achieve better performance than the interleaved baseline, and that\nthose successful variants tend to have more self-attention at the bottom and\nmore feedforward sublayers at the top. We propose a new transformer pattern\nthat adheres to this property, the sandwich transformer, and show that it\nimproves perplexity on multiple word-level and character-level language\nmodeling benchmarks, at no cost in parameters, memory, or training time.\nHowever, the sandwich reordering pattern does not guarantee performance gains\nacross every task, as we demonstrate on machine translation models. Instead, we\nsuggest that further exploration of task-specific sublayer reorderings is\nneeded in order to unlock additional gains.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 06:14:15 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 10:16:33 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Press", "Ofir", ""], ["Smith", "Noah A.", ""], ["Levy", "Omer", ""]]}, {"id": "1911.03868", "submitter": "Sewon Min", "authors": "Sewon Min, Danqi Chen, Luke Zettlemoyer, Hannaneh Hajishirzi", "title": "Knowledge Guided Text Retrieval and Reading for Open Domain Question\n  Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an approach for open-domain question answering (QA) that\nretrieves and reads a passage graph, where vertices are passages of text and\nedges represent relationships that are derived from an external knowledge base\nor co-occurrence in the same article. Our goals are to boost coverage by using\nknowledge-guided retrieval to find more relevant passages than text-matching\nmethods, and to improve accuracy by allowing for better knowledge-guided fusion\nof information across related passages. Our graph retrieval method expands a\nset of seed keyword-retrieved passages by traversing the graph structure of the\nknowledge base. Our reader extends a BERT-based architecture and updates\npassage representations by propagating information from related passages and\ntheir relations, instead of reading each passage in isolation. Experiments on\nthree open-domain QA datasets, WebQuestions, Natural Questions and TriviaQA,\nshow improved performance over non-graph baselines by 2-11% absolute. Our\napproach also matches or exceeds the state-of-the-art in every case, without\nusing an expensive end-to-end training regime.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 06:58:44 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 16:25:54 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Min", "Sewon", ""], ["Chen", "Danqi", ""], ["Zettlemoyer", "Luke", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "1911.03869", "submitter": "Pratyay Banerjee", "authors": "Pratyay Banerjee, Kuntal Kumar Pal, Murthy Devarakonda, Chitta Baral", "title": "Knowledge Guided Named Entity Recognition for BioMedical Text", "comments": "6 pages, 2 figures, 5 tables, WIP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we formulate the NER task as a multi-answer knowledge guided QA\ntask (KGQA) which helps to predict entities only by assigning B, I and O tags\nwithout associating entity types with the tags. We provide different knowledge\ncontexts, such as, entity types, questions, definitions and examples along with\nthe text and train on a combined dataset of 18 biomedical corpora. This\nformulation (a) enables systems to jointly learn NER specific features from\nvaried NER datasets, (b) can use knowledge-text attention to identify words\nhaving higher similarity to provided knowledge, improving performance, (c)\nreduces system confusion by reducing the prediction classes to B, I, O only,\nand (d) makes detection of nested entities easier. We perform extensive\nexperiments of this KGQA formulation on 18 biomedical NER datasets, and through\nexperiments we note that knowledge helps in achieving better performance. Our\nproblem formulation is able to achieve state-of-the-art results in 12 datasets.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 07:05:25 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 03:15:54 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 07:42:01 GMT"}, {"version": "v4", "created": "Fri, 18 Sep 2020 04:38:31 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Banerjee", "Pratyay", ""], ["Pal", "Kuntal Kumar", ""], ["Devarakonda", "Murthy", ""], ["Baral", "Chitta", ""]]}, {"id": "1911.03875", "submitter": "Khalil Mrini", "authors": "Khalil Mrini, Franck Dernoncourt, Quan Tran, Trung Bui, Walter Chang,\n  Ndapa Nakashole", "title": "Rethinking Self-Attention: Towards Interpretability in Neural Parsing", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanisms have improved the performance of NLP tasks while\nallowing models to remain explainable. Self-attention is currently widely used,\nhowever interpretability is difficult due to the numerous attention\ndistributions. Recent work has shown that model representations can benefit\nfrom label-specific information, while facilitating interpretation of\npredictions. We introduce the Label Attention Layer: a new form of\nself-attention where attention heads represent labels. We test our novel layer\nby running constituency and dependency parsing experiments and show our new\nmodel obtains new state-of-the-art results for both tasks on both the Penn\nTreebank (PTB) and Chinese Treebank. Additionally, our model requires fewer\nself-attention layers compared to existing work. Finally, we find that the\nLabel Attention heads learn relations between syntactic categories and show\npathways to analyze errors.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 08:17:11 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 04:34:52 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2020 06:17:11 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Mrini", "Khalil", ""], ["Dernoncourt", "Franck", ""], ["Tran", "Quan", ""], ["Bui", "Trung", ""], ["Chang", "Walter", ""], ["Nakashole", "Ndapa", ""]]}, {"id": "1911.03876", "submitter": "Antoine Bosselut", "authors": "Antoine Bosselut, Ronan Le Bras, Yejin Choi", "title": "Dynamic Neuro-Symbolic Knowledge Graph Construction for Zero-shot\n  Commonsense Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding narratives requires reasoning about implicit world knowledge\nrelated to the causes, effects, and states of situations described in text. At\nthe core of this challenge is how to access contextually relevant knowledge on\ndemand and reason over it.\n  In this paper, we present initial studies toward zero-shot commonsense\nquestion answering by formulating the task as inference over dynamically\ngenerated commonsense knowledge graphs. In contrast to previous studies for\nknowledge integration that rely on retrieval of existing knowledge from static\nknowledge graphs, our study requires commonsense knowledge integration where\ncontextually relevant knowledge is often not present in existing knowledge\nbases. Therefore, we present a novel approach that generates\ncontextually-relevant symbolic knowledge structures on demand using generative\nneural commonsense knowledge models.\n  Empirical results on two datasets demonstrate the efficacy of our\nneuro-symbolic approach for dynamically constructing knowledge graphs for\nreasoning. Our approach achieves significant performance boosts over pretrained\nlanguage models and vanilla knowledge models, all while providing interpretable\nreasoning paths for its predictions.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 08:20:20 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 07:30:59 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Bosselut", "Antoine", ""], ["Bras", "Ronan Le", ""], ["Choi", "Yejin", ""]]}, {"id": "1911.03882", "submitter": "Canwen Xu", "authors": "Yu Duan, Canwen Xu, Jiaxin Pei, Jialong Han, Chenliang Li", "title": "Pre-train and Plug-in: Flexible Conditional Text Generation with\n  Variational Auto-Encoders", "comments": "Accepted as a long paper at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional Text Generation has drawn much attention as a topic of Natural\nLanguage Generation (NLG) which provides the possibility for humans to control\nthe properties of generated contents. Current conditional generation models\ncannot handle emerging conditions due to their joint end-to-end learning\nfashion. When a new condition added, these techniques require full retraining.\nIn this paper, we present a new framework named Pre-train and Plug-in\nVariational Auto-Encoder (PPVAE) towards flexible conditional text generation.\nPPVAE decouples the text generation module from the condition representation\nmodule to allow \"one-to-many\" conditional generation. When a fresh condition\nemerges, only a lightweight network needs to be trained and works as a plug-in\nfor PPVAE, which is efficient and desirable for real-world applications.\nExtensive experiments demonstrate the superiority of PPVAE against the existing\nalternatives with better conditionality and diversity but less training effort.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 09:23:42 GMT"}, {"version": "v2", "created": "Sat, 4 Apr 2020 15:34:10 GMT"}, {"version": "v3", "created": "Sat, 25 Apr 2020 07:44:11 GMT"}, {"version": "v4", "created": "Fri, 8 May 2020 06:28:46 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Duan", "Yu", ""], ["Xu", "Canwen", ""], ["Pei", "Jiaxin", ""], ["Han", "Jialong", ""], ["Li", "Chenliang", ""]]}, {"id": "1911.03891", "submitter": "Maarten Sap", "authors": "Maarten Sap, Saadia Gabriel, Lianhui Qin, Dan Jurafsky, Noah A. Smith,\n  Yejin Choi", "title": "Social Bias Frames: Reasoning about Social and Power Implications of\n  Language", "comments": "ACL 2020 Camera Ready; Data available at\n  http://tinyurl.com/social-bias-frames", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Warning: this paper contains content that may be offensive or upsetting.\n  Language has the power to reinforce stereotypes and project social biases\nonto others. At the core of the challenge is that it is rarely what is stated\nexplicitly, but rather the implied meanings, that frame people's judgments\nabout others. For example, given a statement that \"we shouldn't lower our\nstandards to hire more women,\" most listeners will infer the implicature\nintended by the speaker -- that \"women (candidates) are less qualified.\" Most\nsemantic formalisms, to date, do not capture such pragmatic implications in\nwhich people express social biases and power differentials in language.\n  We introduce Social Bias Frames, a new conceptual formalism that aims to\nmodel the pragmatic frames in which people project social biases and\nstereotypes onto others. In addition, we introduce the Social Bias Inference\nCorpus to support large-scale modelling and evaluation with 150k structured\nannotations of social media posts, covering over 34k implications about a\nthousand demographic groups.\n  We then establish baseline approaches that learn to recover Social Bias\nFrames from unstructured text. We find that while state-of-the-art neural\nmodels are effective at high-level categorization of whether a given statement\nprojects unwanted social bias (80% F1), they are not effective at spelling out\nmore detailed explanations in terms of Social Bias Frames. Our study motivates\nfuture work that combines structured pragmatic inference with commonsense\nreasoning on social implications.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 10:38:27 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 20:49:16 GMT"}, {"version": "v3", "created": "Thu, 23 Apr 2020 20:24:02 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Sap", "Maarten", ""], ["Gabriel", "Saadia", ""], ["Qin", "Lianhui", ""], ["Jurafsky", "Dan", ""], ["Smith", "Noah A.", ""], ["Choi", "Yejin", ""]]}, {"id": "1911.03892", "submitter": "Yichen Huang", "authors": "Yichen Huang and Yizhe Zhang and Oussama Elachqar and Yu Cheng", "title": "INSET: Sentence Infilling with INter-SEntential Transformer", "comments": "Y.H. and Y.Z. contributed equally to this work. v2: published version\n  with updated results and references", "journal-ref": "Proceedings of the 58th Annual Meeting of the Association for\n  Computational Linguistics, pages 2502-2515 (long paper), 2020", "doi": "10.18653/v1/2020.acl-main.226", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing sentence generation (or sentence infilling) fosters a wide range of\napplications in natural language generation, such as document auto-completion\nand meeting note expansion. This task asks the model to generate intermediate\nmissing sentences that can syntactically and semantically bridge the\nsurrounding context. Solving the sentence infilling task requires techniques in\nnatural language processing ranging from understanding to discourse-level\nplanning to generation. In this paper, we propose a framework to decouple the\nchallenge and address these three aspects respectively, leveraging the power of\nexisting large-scale pre-trained models such as BERT and GPT-2. We empirically\ndemonstrate the effectiveness of our model in learning a sentence\nrepresentation for generation and further generating a missing sentence that\nfits the context.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 10:41:52 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 22:54:51 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Huang", "Yichen", ""], ["Zhang", "Yizhe", ""], ["Elachqar", "Oussama", ""], ["Cheng", "Yu", ""]]}, {"id": "1911.03894", "submitter": "Pedro Javier Ortiz Su\\'arez", "authors": "Louis Martin, Benjamin Muller, Pedro Javier Ortiz Su\\'arez, Yoann\n  Dupont, Laurent Romary, \\'Eric Villemonte de la Clergerie, Djam\\'e Seddah,\n  Beno\\^it Sagot", "title": "CamemBERT: a Tasty French Language Model", "comments": "ACL 2020 long paper. Web site: https://camembert-model.fr", "journal-ref": "Proceedings of the 58th Annual Meeting of the Association for\n  Computational Linguistics, July 2020, Online", "doi": "10.18653/v1/2020.acl-main.645", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Pretrained language models are now ubiquitous in Natural Language Processing.\nDespite their success, most available models have either been trained on\nEnglish data or on the concatenation of data in multiple languages. This makes\npractical use of such models --in all languages except English-- very limited.\nIn this paper, we investigate the feasibility of training monolingual\nTransformer-based language models for other languages, taking French as an\nexample and evaluating our language models on part-of-speech tagging,\ndependency parsing, named entity recognition and natural language inference\ntasks. We show that the use of web crawled data is preferable to the use of\nWikipedia data. More surprisingly, we show that a relatively small web crawled\ndataset (4GB) leads to results that are as good as those obtained using larger\ndatasets (130+GB). Our best performing model CamemBERT reaches or improves the\nstate of the art in all four downstream tasks.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 10:46:37 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 17:07:02 GMT"}, {"version": "v3", "created": "Thu, 21 May 2020 23:20:48 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Martin", "Louis", ""], ["Muller", "Benjamin", ""], ["Su\u00e1rez", "Pedro Javier Ortiz", ""], ["Dupont", "Yoann", ""], ["Romary", "Laurent", ""], ["de la Clergerie", "\u00c9ric Villemonte", ""], ["Seddah", "Djam\u00e9", ""], ["Sagot", "Beno\u00eet", ""]]}, {"id": "1911.03895", "submitter": "John Wieting", "authors": "John Wieting, Graham Neubig, Taylor Berg-Kirkpatrick", "title": "A Bilingual Generative Transformer for Semantic Sentence Embedding", "comments": "Published as a long paper at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic sentence embedding models encode natural language sentences into\nvectors, such that closeness in embedding space indicates closeness in the\nsemantics between the sentences. Bilingual data offers a useful signal for\nlearning such embeddings: properties shared by both sentences in a translation\npair are likely semantic, while divergent properties are likely stylistic or\nlanguage-specific. We propose a deep latent variable model that attempts to\nperform source separation on parallel sentences, isolating what they have in\ncommon in a latent semantic vector, and explaining what is left over with\nlanguage-specific latent vectors. Our proposed approach differs from past work\non semantic sentence encoding in two ways. First, by using a variational\nprobabilistic framework, we introduce priors that encourage source separation,\nand can use our model's posterior to predict sentence embeddings for\nmonolingual data at test time. Second, we use high-capacity transformers as\nboth data generating distributions and inference networks -- contrasting with\nmost past work on sentence embeddings. In experiments, our approach\nsubstantially outperforms the state-of-the-art on a standard suite of\nunsupervised semantic similarity evaluations. Further, we demonstrate that our\napproach yields the largest gains on more difficult subsets of these\nevaluations where simple word overlap is not a good indicator of similarity.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 10:48:09 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 17:21:10 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Wieting", "John", ""], ["Neubig", "Graham", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}, {"id": "1911.03897", "submitter": "Yaoyiran Li", "authors": "Yaoyiran Li, Jing Jiang", "title": "Two-Headed Monster And Crossed Co-Attention Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents some preliminary investigations of a new co-attention\nmechanism in neural transduction models. We propose a paradigm, termed\nTwo-Headed Monster (THM), which consists of two symmetric encoder modules and\none decoder module connected with co-attention. As a specific and concrete\nimplementation of THM, Crossed Co-Attention Networks (CCNs) are designed based\non the Transformer model. We demonstrate CCNs on WMT 2014 EN-DE and WMT 2016\nEN-FI translation tasks and our model outperforms the strong Transformer\nbaseline by 0.51 (big) and 0.74 (base) BLEU points on EN-DE and by 0.17 (big)\nand 0.47 (base) BLEU points on EN-FI.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 10:55:12 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Li", "Yaoyiran", ""], ["Jiang", "Jing", ""]]}, {"id": "1911.03898", "submitter": "Joris Baan", "authors": "Joris Baan, Maartje ter Hoeve, Marlies van der Wees, Anne Schuth,\n  Maarten de Rijke", "title": "Understanding Multi-Head Attention in Abstractive Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanisms in deep learning architectures have often been used as a\nmeans of transparency and, as such, to shed light on the inner workings of the\narchitectures. Recently, there has been a growing interest in whether or not\nthis assumption is correct. In this paper we investigate the interpretability\nof multi-head attention in abstractive summarization, a sequence-to-sequence\ntask for which attention does not have an intuitive alignment role, such as in\nmachine translation. We first introduce three metrics to gain insight in the\nfocus of attention heads and observe that these heads specialize towards\nrelative positions, specific part-of-speech tags, and named entities. However,\nwe also find that ablating and pruning these heads does not lead to a\nsignificant drop in performance, indicating redundancy. By replacing the\nsoftmax activation functions with sparsemax activation functions, we find that\nattention heads behave seemingly more transparent: we can ablate fewer heads\nand heads score higher on our interpretability metrics. However, if we apply\npruning to the sparsemax model we find that we can prune even more heads,\nraising the question whether enforced sparsity actually improves transparency.\nFinally, we find that relative positions heads seem integral to summarization\nperformance and persistently remain after pruning.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 10:56:10 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Baan", "Joris", ""], ["ter Hoeve", "Maartje", ""], ["van der Wees", "Marlies", ""], ["Schuth", "Anne", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1911.03903", "submitter": "Shikhar Vashishth", "authors": "Zhiqing Sun, Shikhar Vashishth, Soumya Sanyal, Partha Talukdar, Yiming\n  Yang", "title": "A Re-evaluation of Knowledge Graph Completion Methods", "comments": "Accepted at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graph Completion (KGC) aims at automatically predicting missing\nlinks for large-scale knowledge graphs. A vast number of state-of-the-art KGC\ntechniques have got published at top conferences in several research fields,\nincluding data mining, machine learning, and natural language processing.\nHowever, we notice that several recent papers report very high performance,\nwhich largely outperforms previous state-of-the-art methods. In this paper, we\nfind that this can be attributed to the inappropriate evaluation protocol used\nby them and propose a simple evaluation protocol to address this problem. The\nproposed protocol is robust to handle bias in the model, which can\nsubstantially affect the final results. We conduct extensive experiments and\nreport the performance of several existing methods using our protocol. The\nreproducible code has been made publicly available\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 11:19:08 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 21:29:32 GMT"}, {"version": "v3", "created": "Wed, 8 Jul 2020 19:32:34 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Sun", "Zhiqing", ""], ["Vashishth", "Shikhar", ""], ["Sanyal", "Soumya", ""], ["Talukdar", "Partha", ""], ["Yang", "Yiming", ""]]}, {"id": "1911.03904", "submitter": "Deli Chen", "authors": "Deli Chen, Xiaoqian Liu, Yankai Lin, Peng Li, Jie Zhou, Qi Su, Xu Sun", "title": "HighwayGraph: Modelling Long-distance Node Relations for Improving\n  General Graph Neural Network", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) are efficient approaches to process\ngraph-structured data. Modelling long-distance node relations is essential for\nGNN training and applications. However, conventional GNNs suffer from bad\nperformance in modelling long-distance node relations due to limited-layer\ninformation propagation. Existing studies focus on building deep GNN\narchitectures, which face the over-smoothing issue and cannot model node\nrelations in particularly long distance. To address this issue, we propose to\nmodel long-distance node relations by simply relying on shallow GNN\narchitectures with two solutions: (1) Implicitly modelling by learning to\npredict node pair relations (2) Explicitly modelling by adding edges between\nnodes that potentially have the same label. To combine our two solutions, we\npropose a model-agnostic training framework named HighwayGraph, which overcomes\nthe challenge of insufficient labeled nodes by sampling node pairs from the\ntraining set and adopting the self-training method. Extensive experimental\nresults show that our HighwayGraph achieves consistent and significant\nimprovements over four representative GNNs on three benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 11:23:37 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 05:18:55 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Chen", "Deli", ""], ["Liu", "Xiaoqian", ""], ["Lin", "Yankai", ""], ["Li", "Peng", ""], ["Zhou", "Jie", ""], ["Su", "Qi", ""], ["Sun", "Xu", ""]]}, {"id": "1911.03905", "submitter": "Ond\\v{r}ej Du\\v{s}ek", "authors": "Ond\\v{r}ej Du\\v{s}ek, David M. Howcroft and Verena Rieser", "title": "Semantic Noise Matters for Neural Natural Language Generation", "comments": "In Proceedings of INLG 2019, Tokyo, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural natural language generation (NNLG) systems are known for their\npathological outputs, i.e. generating text which is unrelated to the input\nspecification. In this paper, we show the impact of semantic noise on\nstate-of-the-art NNLG models which implement different semantic control\nmechanisms. We find that cleaned data can improve semantic correctness by up to\n97%, while maintaining fluency. We also find that the most common error is\nomitting information, rather than hallucination.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 11:24:02 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Du\u0161ek", "Ond\u0159ej", ""], ["Howcroft", "David M.", ""], ["Rieser", "Verena", ""]]}, {"id": "1911.03906", "submitter": "Sungdong Kim", "authors": "Sungdong Kim, Sohee Yang, Gyuwan Kim, Sang-Woo Lee", "title": "Efficient Dialogue State Tracking by Selectively Overwriting Memory", "comments": "Accepted to ACL2020 as a long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works in dialogue state tracking (DST) focus on an open\nvocabulary-based setting to resolve scalability and generalization issues of\nthe predefined ontology-based approaches. However, they are inefficient in that\nthey predict the dialogue state at every turn from scratch. Here, we consider\ndialogue state as an explicit fixed-sized memory and propose a selectively\noverwriting mechanism for more efficient DST. This mechanism consists of two\nsteps: (1) predicting state operation on each of the memory slots, and (2)\noverwriting the memory with new values, of which only a few are generated\naccording to the predicted state operations. Our method decomposes DST into two\nsub-tasks and guides the decoder to focus only on one of the tasks, thus\nreducing the burden of the decoder. This enhances the effectiveness of training\nand DST performance. Our SOM-DST (Selectively Overwriting Memory for Dialogue\nState Tracking) model achieves state-of-the-art joint goal accuracy with 51.72%\nin MultiWOZ 2.0 and 53.01% in MultiWOZ 2.1 in an open vocabulary-based DST\nsetting. In addition, we analyze the accuracy gaps between the current and the\nground truth-given situations and suggest that it is a promising direction to\nimprove state operation prediction to boost the DST performance.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 11:27:53 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 03:05:23 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Kim", "Sungdong", ""], ["Yang", "Sohee", ""], ["Kim", "Gyuwan", ""], ["Lee", "Sang-Woo", ""]]}, {"id": "1911.03911", "submitter": "Lukasz Borchmann", "authors": "{\\L}ukasz Borchmann and Dawid Wi\\'sniewski and Andrzej Gretkowski and\n  Izabela Kosmala and Dawid Jurkiewicz and {\\L}ukasz Sza{\\l}kiewicz and\n  Gabriela Pa{\\l}ka and Karol Kaczmarek and Agnieszka Kaliska and Filip\n  Grali\\'nski", "title": "Contract Discovery: Dataset and a Few-Shot Semantic Retrieval Challenge\n  with Competitive Baselines", "comments": "Submitted to Findings of EMNLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new shared task of semantic retrieval from legal texts, in which\na so-called contract discovery is to be performed, where legal clauses are\nextracted from documents, given a few examples of similar clauses from other\nlegal acts. The task differs substantially from conventional NLI and shared\ntasks on legal information extraction (e.g., one has to identify text span\ninstead of a single document, page, or paragraph). The specification of the\nproposed task is followed by an evaluation of multiple solutions within the\nunified framework proposed for this branch of methods. It is shown that\nstate-of-the-art pretrained encoders fail to provide satisfactory results on\nthe task proposed. In contrast, Language Model-based solutions perform better,\nespecially when unsupervised fine-tuning is applied. Besides the ablation\nstudies, we addressed questions regarding detection accuracy for relevant text\nfragments depending on the number of examples available. In addition to the\ndataset and reference results, LMs specialized in the legal domain were made\npublicly available.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 11:50:09 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 12:36:24 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Borchmann", "\u0141ukasz", ""], ["Wi\u015bniewski", "Dawid", ""], ["Gretkowski", "Andrzej", ""], ["Kosmala", "Izabela", ""], ["Jurkiewicz", "Dawid", ""], ["Sza\u0142kiewicz", "\u0141ukasz", ""], ["Pa\u0142ka", "Gabriela", ""], ["Kaczmarek", "Karol", ""], ["Kaliska", "Agnieszka", ""], ["Grali\u0144ski", "Filip", ""]]}, {"id": "1911.03912", "submitter": "Abdelrahman Mohamed", "authors": "Alexei Baevski, Michael Auli, Abdelrahman Mohamed", "title": "Effectiveness of self-supervised pre-training for speech recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare self-supervised representation learning algorithms which either\nexplicitly quantize the audio data or learn representations without\nquantization. We find the former to be more accurate since it builds a good\nvocabulary of the data through vq-wav2vec [1] to enable learning of effective\nrepresentations in subsequent BERT training. Different to previous work, we\ndirectly fine-tune the pre-trained BERT models on transcribed speech using a\nConnectionist Temporal Classification (CTC) loss instead of feeding the\nrepresentations into a task-specific model. We also propose a BERT-style model\nlearning directly from the continuous audio data and compare pre-training on\nraw audio to spectral features. Fine-tuning a BERT model on 10 hour of labeled\nLibrispeech data with a vq-wav2vec vocabulary is almost as good as the best\nknown reported system trained on 100 hours of labeled data on testclean, while\nachieving a 25% WER reduction on test-other. When using only 10 minutes of\nlabeled data, WER is 25.2 on test-other and 16.3 on test-clean. This\ndemonstrates that self-supervision can enable speech recognition systems\ntrained on a near-zero amount of transcribed data.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 11:50:14 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 21:54:00 GMT"}, {"version": "v3", "created": "Mon, 18 May 2020 21:39:19 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Baevski", "Alexei", ""], ["Auli", "Michael", ""], ["Mohamed", "Abdelrahman", ""]]}, {"id": "1911.03913", "submitter": "Li Dong", "authors": "Zewen Chi, Li Dong, Furu Wei, Xian-Ling Mao, Heyan Huang", "title": "Can Monolingual Pretrained Models Help Cross-Lingual Classification?", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual pretrained language models (such as multilingual BERT) have\nachieved impressive results for cross-lingual transfer. However, due to the\nconstant model capacity, multilingual pre-training usually lags behind the\nmonolingual competitors. In this work, we present two approaches to improve\nzero-shot cross-lingual classification, by transferring the knowledge from\nmonolingual pretrained models to multilingual ones. Experimental results on two\ncross-lingual classification benchmarks show that our methods outperform\nvanilla multilingual fine-tuning.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 11:53:26 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Chi", "Zewen", ""], ["Dong", "Li", ""], ["Wei", "Furu", ""], ["Mao", "Xian-Ling", ""], ["Huang", "Heyan", ""]]}, {"id": "1911.03914", "submitter": "Y-Lan Boureau", "authors": "Eric Michael Smith, Diana Gonzalez-Rico, Emily Dinan, Y-Lan Boureau", "title": "Zero-Shot Fine-Grained Style Transfer: Leveraging Distributed Continuous\n  Style Representations to Transfer To Unseen Styles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text style transfer is usually performed using attributes that can take a\nhandful of discrete values (e.g., positive to negative reviews). In this work,\nwe introduce an architecture that can leverage pre-trained consistent\ncontinuous distributed style representations and use them to transfer to an\nattribute unseen during training, without requiring any re-tuning of the style\ntransfer model. We demonstrate the method by training an architecture to\ntransfer text conveying one sentiment to another sentiment, using a\nfine-grained set of over 20 sentiment labels rather than the binary\npositive/negative often used in style transfer. Our experiments show that this\nmodel can then rewrite text to match a target sentiment that was unseen during\ntraining.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 11:53:43 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Smith", "Eric Michael", ""], ["Gonzalez-Rico", "Diana", ""], ["Dinan", "Emily", ""], ["Boureau", "Y-Lan", ""]]}, {"id": "1911.03918", "submitter": "Wenxuan Zhou", "authors": "Wenxuan Zhou, Junyi Du, Xiang Ren", "title": "Improving BERT Fine-tuning with Embedding Normalization", "comments": "work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large pre-trained sentence encoders like BERT start a new chapter in natural\nlanguage processing. A common practice to apply pre-trained BERT to sequence\nclassification tasks (e.g., classification of sentences or sentence pairs) is\nby feeding the embedding of [CLS] token (in the last layer) to a task-specific\nclassification layer, and then fine tune the model parameters of BERT and\nclassifier jointly. In this paper, we conduct systematic analysis over several\nsequence classification datasets to examine the embedding values of [CLS] token\nbefore the fine tuning phase, and present the biased embedding distribution\nissue---i.e., embedding values of [CLS] concentrate on a few dimensions and are\nnon-zero centered. Such biased embedding brings challenge to the optimization\nprocess during fine-tuning as gradients of [CLS] embedding may explode and\nresult in degraded model performance. We further propose several simple yet\neffective normalization methods to modify the [CLS] embedding during the\nfine-tuning. Compared with the previous practice, neural classification model\nwith the normalized embedding shows improvements on several text classification\ntasks, demonstrates the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 12:17:35 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 14:40:15 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Zhou", "Wenxuan", ""], ["Du", "Junyi", ""], ["Ren", "Xiang", ""]]}, {"id": "1911.03922", "submitter": "Sadik Bessou", "authors": "Sadik Bessou, Mohamed Louail, Allaoua Refoufi, Zehour Kadem, Mohamed\n  Touahria", "title": "Un systeme de lemmatisation pour les applications de TALN", "comments": "in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a method of stemming for the Arabian texts based on the\nlinguistic techniques of the natural language processing. This method leans on\nthe notion of scheme (one of the strong points of the morphology of the Arabian\nlanguage). The advantage of this approach is that it doesn't use a dictionary\nof inflexions but a smart dynamic recognition of the different words of the\nlanguage.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 12:53:38 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 13:16:20 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Bessou", "Sadik", ""], ["Louail", "Mohamed", ""], ["Refoufi", "Allaoua", ""], ["Kadem", "Zehour", ""], ["Touahria", "Mohamed", ""]]}, {"id": "1911.03934", "submitter": "Brij Mohan Lal Srivastava", "authors": "Brij Mohan Lal Srivastava, Nathalie Vauquier, Md Sahidullah,\n  Aur\\'elien Bellet, Marc Tommasi, Emmanuel Vincent", "title": "Evaluating Voice Conversion-based Privacy Protection against Informed\n  Attackers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech data conveys sensitive speaker attributes like identity or accent.\nWith a small amount of found data, such attributes can be inferred and\nexploited for malicious purposes: voice cloning, spoofing, etc. Anonymization\naims to make the data unlinkable, i.e., ensure that no utterance can be linked\nto its original speaker. In this paper, we investigate anonymization methods\nbased on voice conversion. In contrast to prior work, we argue that various\nlinkage attacks can be designed depending on the attackers' knowledge about the\nanonymization scheme. We compare two frequency warping-based conversion methods\nand a deep learning based method in three attack scenarios. The utility of\nconverted speech is measured via the word error rate achieved by automatic\nspeech recognition, while privacy protection is assessed by the increase in\nequal error rate achieved by state-of-the-art i-vector or x-vector based\nspeaker verification. Our results show that voice conversion schemes are unable\nto effectively protect against an attacker that has extensive knowledge of the\ntype of conversion and how it has been applied, but may provide some protection\nagainst less knowledgeable attackers.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 13:45:06 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 13:29:41 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Srivastava", "Brij Mohan Lal", ""], ["Vauquier", "Nathalie", ""], ["Sahidullah", "Md", ""], ["Bellet", "Aur\u00e9lien", ""], ["Tommasi", "Marc", ""], ["Vincent", "Emmanuel", ""]]}, {"id": "1911.03936", "submitter": "Philipp Sadler", "authors": "Philipp Sadler, Tatjana Scheffler and David Schlangen", "title": "Can Neural Image Captioning be Controlled via Forced Attention?", "comments": "Accepted shortpaper for the 12th International Conference on Natural\n  Language Generation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learned dynamic weighting of the conditioning signal (attention) has been\nshown to improve neural language generation in a variety of settings. The\nweights applied when generating a particular output sequence have also been\nviewed as providing a potentially explanatory insight into the internal\nworkings of the generator. In this paper, we reverse the direction of this\nconnection and ask whether through the control of the attention of the model we\ncan control its output. Specifically, we take a standard neural image\ncaptioning model that uses attention, and fix the attention to pre-determined\nareas in the image. We evaluate whether the resulting output is more likely to\nmention the class of the object in that area than the normally generated\ncaption. We introduce three effective methods to control the attention and find\nthat these are producing expected results in up to 28.56% of the cases.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 14:00:27 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Sadler", "Philipp", ""], ["Scheffler", "Tatjana", ""], ["Schlangen", "David", ""]]}, {"id": "1911.03937", "submitter": "Wei Zhang", "authors": "Wei Zhang, Youyuan Lin, Ruoran Ren, Xiaodong Wang, Zhenshuang Liang,\n  Zhen Huang", "title": "Language Model-Driven Unsupervised Neural Machine Translation", "comments": "11 pages, 3 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised neural machine translation(NMT) is associated with noise and\nerrors in synthetic data when executing vanilla back-translations. Here, we\nexplicitly exploits language model(LM) to drive construction of an unsupervised\nNMT system. This features two steps. First, we initialize NMT models using\nsynthetic data generated via temporary statistical machine translation(SMT).\nSecond, unlike vanilla back-translation, we formulate a weight function, that\nscores synthetic data at each step of subsequent iterative training; this\nallows unsupervised training to an improved outcome. We present the detailed\nmathematical construction of our method. Experimental WMT2014 English-French,\nand WMT2016 English-German and English-Russian translation tasks revealed that\nour method outperforms the best prior systems by more than 3 BLEU points.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 14:04:59 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Zhang", "Wei", ""], ["Lin", "Youyuan", ""], ["Ren", "Ruoran", ""], ["Wang", "Xiaodong", ""], ["Liang", "Zhenshuang", ""], ["Huang", "Zhen", ""]]}, {"id": "1911.03962", "submitter": "Sergey A. Slavnov", "authors": "Sergey Slavnov", "title": "Classical linear logic, cobordisms and categorial grammars", "comments": "This is an improved version of the previously posted paper \"Classical\n  linear logic, cobordisms and categorical semantics of categorial grammars\"\n  with reduced amonunt of category theory, much simplified definitions and a\n  number of examples. Also, a treatment of tree languages is added", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a categorial grammar based on classical multiplicative linear\nlogic.\n  This can be seen as an extension of abstract categorial grammars (ACG) and is\nat least as expressive. However, constituents of {\\it linear logic grammars\n(LLG)} are not abstract ${\\lambda}$-terms, but simply tuples of words with\nlabeled endpoints and supplied with specific {\\it plugging instructions}: the\nsets of endpoints are subdivided into the {\\it incoming} and the {\\it outgoing}\nparts. We call such objects {\\it word cobordisms}.\n  A key observation is that word cobordisms can be organized in a category,\nvery similar to the familiar category of topological cobordisms. This category\nis symmetric monoidal closed and compact closed and thus is a model of linear\n$\\lambda$-calculus and classical, as well as intuitionistic linear logic. This\nallows us using linear logic as a typing system for word cobordisms.\n  At least, this gives a concrete and intuitive representation of ACG.\n  We think, however, that the category of word cobordisms, which has a rich\nstructure and is independent of any grammar, might be interesting on its own\nright.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 16:56:25 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 14:44:28 GMT"}, {"version": "v3", "created": "Fri, 31 Jul 2020 18:28:14 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Slavnov", "Sergey", ""]]}, {"id": "1911.03970", "submitter": "Yassir Fathullah", "authors": "Yassir Fathullah, Chao Zhang, Philip C. Woodland", "title": "Improved Large-margin Softmax Loss for Speaker Diarisation", "comments": "ICASSP 2020", "journal-ref": "ICASSP 2020, Barcelona, Spain, 2020, pp. 7104-7108", "doi": "10.1109/ICASSP40776.2020.9053373", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker diarisation systems nowadays use embeddings generated from speech\nsegments in a bottleneck layer, which are needed to be discriminative for\nunseen speakers. It is well-known that large-margin training can improve the\ngeneralisation ability to unseen data, and its use in such open-set problems\nhas been widespread. Therefore, this paper introduces a general approach to the\nlarge-margin softmax loss without any approximations to improve the quality of\nspeaker embeddings for diarisation. Furthermore, a novel and simple way to\nstabilise training, when large-margin softmax is used, is proposed. Finally, to\ncombat the effect of overlapping speech, different training margins are used to\nreduce the negative effect overlapping speech has on creating discriminative\nembeddings. Experiments on the AMI meeting corpus show that the use of\nlarge-margin softmax significantly improves the speaker error rate (SER). By\nusing all hyper parameters of the loss in a unified way, further improvements\nwere achieved which reached a relative SER reduction of 24.6% over the\nbaseline. However, by training overlapping and single speaker speech samples\nwith different margins, the best result was achieved, giving overall a 29.5%\nSER reduction relative to the baseline.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 17:41:11 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 17:34:53 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 09:32:49 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Fathullah", "Yassir", ""], ["Zhang", "Chao", ""], ["Woodland", "Philip C.", ""]]}, {"id": "1911.03976", "submitter": "Teng Long", "authors": "Teng Long, Yanshuai Cao, Jackie Chi Kit Cheung", "title": "On Posterior Collapse and Encoder Feature Dispersion in Sequence VAEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs) hold great potential for modelling text, as\nthey could in theory separate high-level semantic and syntactic properties from\nlocal regularities of natural language. Practically, however, VAEs with\nautoregressive decoders often suffer from posterior collapse, a phenomenon\nwhere the model learns to ignore the latent variables, causing the sequence VAE\nto degenerate into a language model. In this paper, we argue that posterior\ncollapse is in part caused by the lack of dispersion in encoder features. We\nprovide empirical evidence to verify this hypothesis, and propose a\nstraightforward fix using pooling. This simple technique effectively prevents\nposterior collapse, allowing model to achieve significantly better data\nlog-likelihood than standard sequence VAEs. Comparing to existing work, our\nproposed method is able to achieve comparable or superior performances while\nbeing more computationally efficient.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 18:50:46 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 17:38:27 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Long", "Teng", ""], ["Cao", "Yanshuai", ""], ["Cheung", "Jackie Chi Kit", ""]]}, {"id": "1911.03977", "submitter": "Chao Zhang", "authors": "Chao Zhang, Zichao Yang, Xiaodong He, Li Deng", "title": "Multimodal Intelligence: Representation Learning, Information Fusion,\n  and Applications", "comments": null, "journal-ref": null, "doi": "10.1109/JSTSP.2020.2987728", "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods have revolutionized speech recognition, image\nrecognition, and natural language processing since 2010. Each of these tasks\ninvolves a single modality in their input signals. However, many applications\nin the artificial intelligence field involve multiple modalities. Therefore, it\nis of broad interest to study the more difficult and complex problem of\nmodeling and learning across multiple modalities. In this paper, we provide a\ntechnical review of available models and learning methods for multimodal\nintelligence. The main focus of this review is the combination of vision and\nnatural language modalities, which has become an important topic in both the\ncomputer vision and natural language processing research communities. This\nreview provides a comprehensive analysis of recent works on multimodal deep\nlearning from three perspectives: learning multimodal representations, fusing\nmultimodal signals at various levels, and multimodal applications. Regarding\nmultimodal representation learning, we review the key concepts of embedding,\nwhich unify multimodal signals into a single vector space and thereby enable\ncross-modality signal processing. We also review the properties of many types\nof embeddings that are constructed and learned for general downstream tasks.\nRegarding multimodal fusion, this review focuses on special architectures for\nthe integration of representations of unimodal signals for a particular task.\nRegarding applications, selected areas of a broad interest in the current\nliterature are covered, including image-to-text caption generation,\ntext-to-image generation, and visual question answering. We believe that this\nreview will facilitate future studies in the emerging field of multimodal\nintelligence for related communities.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 18:58:20 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 11:00:48 GMT"}, {"version": "v3", "created": "Fri, 10 Apr 2020 09:16:13 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Zhang", "Chao", ""], ["Yang", "Zichao", ""], ["He", "Xiaodong", ""], ["Deng", "Li", ""]]}, {"id": "1911.04015", "submitter": "Sunjae Kwon", "authors": "Sunjae Kwon, Dongsuk Oh, Youngjoong Ko", "title": "Word Sense Disambiguation using Knowledge-based Word Similarity", "comments": "Since we changed some hyper-parameters, experimental results must be\n  changed. We will resubmit with the retest results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In natural language processing, word-sense disambiguation (WSD) is an open\nproblem concerned with identifying the correct sense of words in a particular\ncontext. To address this problem, we introduce a novel knowledge-based WSD\nsystem. We suggest the adoption of two methods in our system. First, we suggest\na novel method to encode the word vector representation by considering the\ngraphical semantic relationships from the lexical knowledge-base. Second, we\npropose a method for extracting the contextual words from the text for\nanalyzing an ambiguous word based on the similarity of word vector\nrepresentations. To validate the effectiveness of our WSD system, we conducted\nexperiments on the five benchmark English WSD corpora (Senseval-02,\nSenseval-03, SemEval-07, SemEval-13, and SemEval-15). The obtained results\ndemonstrated that the suggested methods significantly enhanced the WSD\nperformance. Furthermore, our system outperformed the existing knowledge-based\nWSD systems and showed a performance comparable to that of the state-of-the-art\nsupervised WSD systems.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 00:07:02 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 02:09:44 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Kwon", "Sunjae", ""], ["Oh", "Dongsuk", ""], ["Ko", "Youngjoong", ""]]}, {"id": "1911.04053", "submitter": "Xiang Kong", "authors": "Xiang Kong, Xianyang Chen, Eduard Hovy", "title": "Decompressing Knowledge Graph Representations for Link Prediction", "comments": "code has been released", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of predicting missing relationships between\nentities in knowledge graphs through learning their representations. Currently,\nthe majority of existing link prediction models employ simple but intuitive\nscoring functions and relatively small embedding size so that they could be\napplied to large-scale knowledge graphs. However, these properties also\nrestrict the ability to learn more expressive and robust features. Therefore,\ndiverging from most of the prior works which focus on designing new objective\nfunctions, we propose, DeCom, a simple but effective mechanism to boost the\nperformance of existing link predictors such as DistMult, ComplEx, etc, through\nextracting more expressive features while preventing overfitting by adding just\na few extra parameters. Specifically, embeddings of entities and relationships\nare first decompressed to a more expressive and robust space by decompressing\nfunctions, then knowledge graph embedding models are trained in this new\nfeature space. Experimental results on several benchmark knowledge graphs and\nadvanced link prediction systems demonstrate the generalization and\neffectiveness of our method. Especially, RESCAL + DeCom achieves\nstate-of-the-art performance on the FB15k-237 benchmark across all evaluation\nmetrics. In addition, we also show that compared with DeCom, explicitly\nincreasing the embedding size significantly increase the number of parameters\nbut could not achieve promising performance improvement.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 03:15:22 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 17:30:19 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Kong", "Xiang", ""], ["Chen", "Xianyang", ""], ["Hovy", "Eduard", ""]]}, {"id": "1911.04065", "submitter": "Yunan Zhang", "authors": "Yunan Zhang, Xiang Cheng, Yufeng Zhang, Zihan Wang, Zhengqi Fang,\n  Xiaoyan Wang, Zhenya Huang, Chengxiang Zhai", "title": "Learning to Order Sub-questions for Complex Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering complex questions involving multiple entities and relations is a\nchallenging task. Logically, the answer to a complex question should be derived\nby decomposing the complex question into multiple simple sub-questions and then\nanswering those sub-questions. Existing work has followed this strategy but has\nnot attempted to optimize the order of how those sub-questions are answered. As\na result, the sub-questions are answered in an arbitrary order, leading to\nlarger search space and a higher risk of missing an answer. In this paper, we\npropose a novel reinforcement learning(RL) approach to answering complex\nquestions that can learn a policy to dynamically decide which sub-question\nshould be answered at each stage of reasoning. We lever-age the expected\nvalue-variance criterion to enable the learned policy to balance between the\nrisk and utility of answering a sub-question. Experiment results show that the\nRL approach can substantially improve the optimality of ordering the\nsub-questions, leading to improved accuracy of question answering. The proposed\nmethod for learning to order sub-questions is general and can thus be\npotentially combined with many existing ideas for answering complex questions\nto enhance their performance.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 04:06:46 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 03:03:25 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Zhang", "Yunan", ""], ["Cheng", "Xiang", ""], ["Zhang", "Yufeng", ""], ["Wang", "Zihan", ""], ["Fang", "Zhengqi", ""], ["Wang", "Xiaoyan", ""], ["Huang", "Zhenya", ""], ["Zhai", "Chengxiang", ""]]}, {"id": "1911.04070", "submitter": "Zihao Ye", "authors": "Zihao Ye, Qipeng Guo, Quan Gan, Xipeng Qiu, Zheng Zhang", "title": "BP-Transformer: Modelling Long-Range Context via Binary Partitioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Transformer model is widely successful on many natural language\nprocessing tasks. However, the quadratic complexity of self-attention limit its\napplication on long text. In this paper, adopting a fine-to-coarse attention\nmechanism on multi-scale spans via binary partitioning (BP), we propose\nBP-Transformer (BPT for short). BPT yields $O(k\\cdot n\\log (n/k))$ connections\nwhere $k$ is a hyperparameter to control the density of attention. BPT has a\ngood balance between computation complexity and model capacity. A series of\nexperiments on text classification, machine translation and language modeling\nshows BPT has a superior performance for long text than previous self-attention\nmodels. Our code, hyperparameters and CUDA kernels for sparse attention are\navailable in PyTorch.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 04:31:23 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Ye", "Zihao", ""], ["Guo", "Qipeng", ""], ["Gan", "Quan", ""], ["Qiu", "Xipeng", ""], ["Zhang", "Zheng", ""]]}, {"id": "1911.04081", "submitter": "Zihan Liu", "authors": "Zihan Liu, Jamin Shin, Yan Xu, Genta Indra Winata, Peng Xu, Andrea\n  Madotto, Pascale Fung", "title": "Zero-shot Cross-lingual Dialogue Systems with Transferable Latent\n  Variables", "comments": "Accepted in EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the surging demands for multilingual task-oriented dialog systems\n(e.g., Alexa, Google Home), there has been less research done in multilingual\nor cross-lingual scenarios. Hence, we propose a zero-shot adaptation of\ntask-oriented dialogue system to low-resource languages. To tackle this\nchallenge, we first use a set of very few parallel word pairs to refine the\naligned cross-lingual word-level representations. We then employ a latent\nvariable model to cope with the variance of similar sentences across different\nlanguages, which is induced by imperfect cross-lingual alignments and inherent\ndifferences in languages. Finally, the experimental results show that even\nthough we utilize much less external resources, our model achieves better\nadaptation performance for natural language understanding task (i.e., the\nintent detection and slot filling) compared to the current state-of-the-art\nmodel in the zero-shot scenario.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 05:22:26 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Liu", "Zihan", ""], ["Shin", "Jamin", ""], ["Xu", "Yan", ""], ["Winata", "Genta Indra", ""], ["Xu", "Peng", ""], ["Madotto", "Andrea", ""], ["Fung", "Pascale", ""]]}, {"id": "1911.04088", "submitter": "Zhuoxuan Jiang", "authors": "Zhuoxuan Jiang and Ziming Huang and Dong Sheng Li and Xian-Ling Mao", "title": "DialogAct2Vec: Towards End-to-End Dialogue Agent by Multi-Task\n  Representation Learning", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In end-to-end dialogue modeling and agent learning, it is important to (1)\neffectively learn knowledge from data, and (2) fully utilize heterogeneous\ninformation, e.g., dialogue act flow and utterances. However, the majority of\nexisting methods cannot simultaneously satisfy the two conditions. For example,\nrule definition and data labeling during system design take too much manual\nwork, and sequence-to-sequence methods only model one-side utterance\ninformation. In this paper, we propose a novel joint end-to-end model by\nmulti-task representation learning, which can capture the knowledge from\nheterogeneous information through automatically learning knowledgeable\nlow-dimensional embeddings from data, named with DialogAct2Vec. The model\nrequires little manual work for intervention in system design and we find that\nthe multi-task learning can greatly improve the effectiveness of representation\nlearning. Extensive experiments on a public dataset for restaurant reservation\nshow that the proposed method leads to significant improvements against the\nstate-of-the-art baselines on both the act prediction task and utterance\nprediction task.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 05:43:45 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Jiang", "Zhuoxuan", ""], ["Huang", "Ziming", ""], ["Li", "Dong Sheng", ""], ["Mao", "Xian-Ling", ""]]}, {"id": "1911.04111", "submitter": "Junjie Pan", "authors": "Junjie Pan, Xiang Yin, Zhiling Zhang, Shichao Liu, Yang Zhang, Zejun\n  Ma, Yuxuan Wang", "title": "A unified sequence-to-sequence front-end model for Mandarin\n  text-to-speech synthesis", "comments": "Submitted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Mandarin text-to-speech (TTS) system, the front-end text processing module\nsignificantly influences the intelligibility and naturalness of synthesized\nspeech. Building a typical pipeline-based front-end which consists of multiple\nindividual components requires extensive efforts. In this paper, we proposed a\nunified sequence-to-sequence front-end model for Mandarin TTS that converts raw\ntexts to linguistic features directly. Compared to the pipeline-based\nfront-end, our unified front-end can achieve comparable performance in\npolyphone disambiguation and prosody word prediction, and improve intonation\nphrase prediction by 0.0738 in F1 score. We also implemented the unified\nfront-end with Tacotron and WaveRNN to build a Mandarin TTS system. The\nsynthesized speech by that got a comparable MOS (4.38) with the pipeline-based\nfront-end (4.37) and close to human recordings (4.49).\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 06:54:46 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Pan", "Junjie", ""], ["Yin", "Xiang", ""], ["Zhang", "Zhiling", ""], ["Liu", "Shichao", ""], ["Zhang", "Yang", ""], ["Ma", "Zejun", ""], ["Wang", "Yuxuan", ""]]}, {"id": "1911.04115", "submitter": "Bin Liu", "authors": "Bin Liu, Guosheng Yin, Wenbin Du", "title": "Text classification with pixel embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework to understand the text by converting sentences\nor articles into video-like 3-dimensional tensors. Each frame, corresponding to\na slice of the tensor, is a word image that is rendered by the word's shape.\nThe length of the tensor equals to the number of words in the sentence or\narticle. The proposed transformation from the text to a 3-dimensional tensor\nmakes it very convenient to implement an $n$-gram model with convolutional\nneural networks for text analysis. Concretely, we impose a 3-dimensional\nconvolutional kernel on the 3-dimensional text tensor. The first two dimensions\nof the convolutional kernel size equal the size of the word image and the last\ndimension of the kernel size is $n$. That is, every time when we slide the\n3-dimensional kernel over a word sequence, the convolution covers $n$ word\nimages and outputs a scalar. By iterating this process continuously for each\n$n$-gram along with the sentence or article with multiple kernels, we obtain a\n2-dimensional feature map. A subsequent 1-dimensional max-over-time pooling is\napplied to this feature map, and three fully-connected layers are used for\nconducting text classification finally. Experiments of several text\nclassification datasets demonstrate surprisingly superior performances using\nthe proposed model in comparison with existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 07:28:25 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 09:23:27 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Liu", "Bin", ""], ["Yin", "Guosheng", ""], ["Du", "Wenbin", ""]]}, {"id": "1911.04118", "submitter": "Siddhant Garg", "authors": "Siddhant Garg, Thuy Vu, Alessandro Moschitti", "title": "TANDA: Transfer and Adapt Pre-Trained Transformer Models for Answer\n  Sentence Selection", "comments": "Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI 2020),\n  Oral Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose TANDA, an effective technique for fine-tuning pre-trained\nTransformer models for natural language tasks. Specifically, we first transfer\na pre-trained model into a model for a general task by fine-tuning it with a\nlarge and high-quality dataset. We then perform a second fine-tuning step to\nadapt the transferred model to the target domain. We demonstrate the benefits\nof our approach for answer sentence selection, which is a well-known inference\ntask in Question Answering. We built a large scale dataset to enable the\ntransfer step, exploiting the Natural Questions dataset. Our approach\nestablishes the state of the art on two well-known benchmarks, WikiQA and\nTREC-QA, achieving MAP scores of 92% and 94.3%, respectively, which largely\noutperform the previous highest scores of 83.4% and 87.5%, obtained in very\nrecent work. We empirically show that TANDA generates more stable and robust\nmodels reducing the effort required for selecting optimal hyper-parameters.\nAdditionally, we show that the transfer step of TANDA makes the adaptation step\nmore robust to noise. This enables a more effective use of noisy datasets for\nfine-tuning. Finally, we also confirm the positive impact of TANDA in an\nindustrial setting, using domain specific datasets subject to different types\nof noise.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 07:40:37 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 05:21:22 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Garg", "Siddhant", ""], ["Vu", "Thuy", ""], ["Moschitti", "Alessandro", ""]]}, {"id": "1911.04123", "submitter": "Linfeng Song", "authors": "Linfeng Song, Yue Zhang, Daniel Gildea, Mo Yu, Zhiguo Wang and Jinsong\n  Su", "title": "Leveraging Dependency Forest for Neural Medical Relation Extraction", "comments": "EMNLP 2020, with \"correct\" source-code address:\n  http://github.com/freesunshine0316/dep-forest-re", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical relation extraction discovers relations between entity mentions in\ntext, such as research articles. For this task, dependency syntax has been\nrecognized as a crucial source of features. Yet in the medical domain, 1-best\nparse trees suffer from relatively low accuracies, diminishing their\nusefulness. We investigate a method to alleviate this problem by utilizing\ndependency forests. Forests contain many possible decisions and therefore have\nhigher recall but more noise compared with 1-best outputs. A graph neural\nnetwork is used to represent the forests, automatically distinguishing the\nuseful syntactic information from parsing noise. Results on two biomedical\nbenchmarks show that our method outperforms the standard tree-based methods,\ngiving the state-of-the-art results in the literature.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 07:58:52 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 07:38:01 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Song", "Linfeng", ""], ["Zhang", "Yue", ""], ["Gildea", "Daniel", ""], ["Yu", "Mo", ""], ["Wang", "Zhiguo", ""], ["Su", "Jinsong", ""]]}, {"id": "1911.04128", "submitter": "Junhui Zhang", "authors": "Junhui Zhang, Junjie Pan, Xiang Yin, Chen Li, Shichao Liu, Yang Zhang,\n  Yuxuan Wang, Zejun Ma", "title": "A hybrid text normalization system using multi-head self-attention for\n  mandarin", "comments": "4 pages of content, 1 page of reference, 3 figures, submitted to\n  ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a hybrid text normalization system using multi-head\nself-attention. The system combines the advantages of a rule-based model and a\nneural model for text preprocessing tasks. Previous studies in Mandarin text\nnormalization usually use a set of hand-written rules, which are hard to\nimprove on general cases. The idea of our proposed system is motivated by the\nneural models from recent studies and has a better performance on our internal\nnews corpus. This paper also includes different attempts to deal with\nimbalanced pattern distribution of the dataset. Overall, the performance of the\nsystem is improved by over 1.5% on sentence-level and it has a potential to\nimprove further.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 08:19:49 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 02:46:00 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Zhang", "Junhui", ""], ["Pan", "Junjie", ""], ["Yin", "Xiang", ""], ["Li", "Chen", ""], ["Liu", "Shichao", ""], ["Zhang", "Yang", ""], ["Wang", "Yuxuan", ""], ["Ma", "Zejun", ""]]}, {"id": "1911.04156", "submitter": "Jordan Boyd-Graber", "authors": "Benjamin Borschinger, Jordan Boyd-Graber, Christian Buck, Jannis\n  Bulian, Massimiliano Ciaramita, Michelle Chen Huebscher, Wojciech Gajewski,\n  Yannic Kilcher, Rodrigo Nogueira, Lierni Sestorain Saralegu", "title": "Meta Answering for Machine Reading", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a framework for machine reading, inspired by real world\ninformation-seeking problems, where a meta question answering system interacts\nwith a black box environment. The environment encapsulates a competitive\nmachine reader based on BERT, providing candidate answers to questions, and\npossibly some context. To validate the realism of our formulation, we ask\nhumans to play the role of a meta-answerer. With just a small snippet of text\naround an answer, humans can outperform the machine reader, improving recall.\nSimilarly, a simple machine meta-answerer outperforms the environment,\nimproving both precision and recall on the Natural Questions dataset. The\nsystem relies on joint training of answer scoring and the selection of\nconditioning information.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 10:07:57 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 19:33:19 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Borschinger", "Benjamin", ""], ["Boyd-Graber", "Jordan", ""], ["Buck", "Christian", ""], ["Bulian", "Jannis", ""], ["Ciaramita", "Massimiliano", ""], ["Huebscher", "Michelle Chen", ""], ["Gajewski", "Wojciech", ""], ["Kilcher", "Yannic", ""], ["Nogueira", "Rodrigo", ""], ["Saralegu", "Lierni Sestorain", ""]]}, {"id": "1911.04192", "submitter": "Ruize Wang", "authors": "Ruize Wang, Zhongyu Wei, Ying Cheng, Piji Li, Haijun Shan, Ji Zhang,\n  Qi Zhang, Xuanjing Huang", "title": "Keep it Consistent: Topic-Aware Storytelling from an Image Stream via\n  Iterative Multi-agent Communication", "comments": "Accepted to COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual storytelling aims to generate a narrative paragraph from a sequence of\nimages automatically. Existing approaches construct text description\nindependently for each image and roughly concatenate them as a story, which\nleads to the problem of generating semantically incoherent content. In this\npaper, we propose a new way for visual storytelling by introducing a topic\ndescription task to detect the global semantic context of an image stream. A\nstory is then constructed with the guidance of the topic description. In order\nto combine the two generation tasks, we propose a multi-agent communication\nframework that regards the topic description generator and the story generator\nas two agents and learn them simultaneously via iterative updating mechanism.\nWe validate our approach on VIST dataset, where quantitative results,\nablations, and human evaluation demonstrate our method's good ability in\ngenerating stories with higher quality compared to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 11:35:21 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 07:08:10 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Wang", "Ruize", ""], ["Wei", "Zhongyu", ""], ["Cheng", "Ying", ""], ["Li", "Piji", ""], ["Shan", "Haijun", ""], ["Zhang", "Ji", ""], ["Zhang", "Qi", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1911.04211", "submitter": "Aditya Khandelwal", "authors": "Aditya Khandelwal and Suraj Sawant", "title": "NegBERT: A Transfer Learning Approach for Negation Detection and Scope\n  Resolution", "comments": "The 12th Language Resources and Evaluation Conference (LREC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Negation is an important characteristic of language, and a major component of\ninformation extraction from text. This subtask is of considerable importance to\nthe biomedical domain. Over the years, multiple approaches have been explored\nto address this problem: Rule-based systems, Machine Learning classifiers,\nConditional Random Field Models, CNNs and more recently BiLSTMs. In this paper,\nwe look at applying Transfer Learning to this problem. First, we extensively\nreview previous literature addressing Negation Detection and Scope Resolution\nacross the 3 datasets that have gained popularity over the years: the BioScope\nCorpus, the Sherlock dataset, and the SFU Review Corpus. We then explore the\ndecision choices involved with using BERT, a popular transfer learning model,\nfor this task, and report state-of-the-art results for scope resolution across\nall 3 datasets. Our model, referred to as NegBERT, achieves a token level F1\nscore on scope resolution of 92.36 on the Sherlock dataset, 95.68 on the\nBioScope Abstracts subcorpus, 91.24 on the BioScope Full Papers subcorpus,\n90.95 on the SFU Review Corpus, outperforming the previous state-of-the-art\nsystems by a significant margin. We also analyze the model's generalizability\nto datasets on which it is not trained.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 12:28:29 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 15:25:22 GMT"}, {"version": "v3", "created": "Sat, 14 Dec 2019 14:03:06 GMT"}, {"version": "v4", "created": "Sun, 24 May 2020 12:18:12 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Khandelwal", "Aditya", ""], ["Sawant", "Suraj", ""]]}, {"id": "1911.04283", "submitter": "Sathish Indurthi", "authors": "Sathish Indurthi, Houjeung Han, Nikhil Kumar Lakumarapu, Beomseok Lee,\n  Insoo Chung, Sangha Kim, Chanwoo Kim", "title": "Data Efficient Direct Speech-to-Text Translation with Modality Agnostic\n  Meta-Learning", "comments": "ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end Speech Translation (ST) models have several advantages such as\nlower latency, smaller model size, and less error compounding over conventional\npipelines that combine Automatic Speech Recognition (ASR) and text Machine\nTranslation (MT) models. However, collecting large amounts of parallel data for\nST task is more difficult compared to the ASR and MT tasks. Previous studies\nhave proposed the use of transfer learning approaches to overcome the above\ndifficulty. These approaches benefit from weakly supervised training data, such\nas ASR speech-to-transcript or MT text-to-text translation pairs. However, the\nparameters in these models are updated independently of each task, which may\nlead to sub-optimal solutions. In this work, we adopt a meta-learning algorithm\nto train a modality agnostic multi-task model that transfers knowledge from\nsource tasks=ASR+MT to target task=ST where ST task severely lacks data. In the\nmeta-learning phase, the parameters of the model are exposed to vast amounts of\nspeech transcripts (e.g., English ASR) and text translations (e.g.,\nEnglish-German MT). During this phase, parameters are updated in such a way to\nunderstand speech, text representations, the relation between them, as well as\nact as a good initialization point for the target ST task. We evaluate the\nproposed meta-learning approach for ST tasks on English-German (En-De) and\nEnglish-French (En-Fr) language pairs from the Multilingual Speech Translation\nCorpus (MuST-C). Our method outperforms the previous transfer learning\napproaches and sets new state-of-the-art results for En-De and En-Fr ST tasks\nby obtaining 9.18, and 11.76 BLEU point improvements, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 14:03:52 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 03:33:56 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Indurthi", "Sathish", ""], ["Han", "Houjeung", ""], ["Lakumarapu", "Nikhil Kumar", ""], ["Lee", "Beomseok", ""], ["Chung", "Insoo", ""], ["Kim", "Sangha", ""], ["Kim", "Chanwoo", ""]]}, {"id": "1911.04286", "submitter": "Guy Rotman", "authors": "Guy Rotman and Roi Reichart", "title": "Deep Contextualized Self-training for Low Resource Dependency Parsing", "comments": "Accepted to TACL in September 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural dependency parsing has proven very effective, achieving\nstate-of-the-art results on numerous domains and languages. Unfortunately, it\nrequires large amounts of labeled data, that is costly and laborious to create.\nIn this paper we propose a self-training algorithm that alleviates this\nannotation bottleneck by training a parser on its own output. Our Deep\nContextualized Self-training (DCST) algorithm utilizes representation models\ntrained on sequence labeling tasks that are derived from the parser's output\nwhen applied to unlabeled data, and integrates these models with the base\nparser through a gating mechanism. We conduct experiments across multiple\nlanguages, both in low resource in-domain and in cross-domain setups, and\ndemonstrate that DCST substantially outperforms traditional self-training as\nwell as recent semi-supervised training methods.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 14:07:46 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Rotman", "Guy", ""], ["Reichart", "Roi", ""]]}, {"id": "1911.04292", "submitter": "Jia Xu Dr.", "authors": "Abdul Rafae Khan and Jia Xu", "title": "Diversity by Phonetics and its Application in Neural Machine Translation", "comments": "In openreview.net (28 May 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a powerful approach for Neural Machine Translation (NMT),\nwhereby, during training and testing, together with the input we provide its\nphonetic encoding and the variants of such an encoding. This way we obtain very\nsignificant improvements up to 4 BLEU points over the state-of-the-art\nlarge-scale system. The phonetic encoding is the first part of our\ncontribution, with a second being a theory that aims to understand the reason\nfor this improvement. Our hypothesis states that the phonetic encoding helps\nNMT because it encodes a procedure to emphasize the difference between\nsemantically diverse sentences. We conduct an empirical geometric validation of\nour hypothesis in support of which we obtain overwhelming evidence.\nSubsequently, as our third contribution and based on our theory, we develop\nartificial mechanisms that leverage during learning the hypothesized (and\nverified) effect phonetics. We achieve significant and consistent improvements\noverall language pairs and datasets: French-English, German-English, and\nChinese-English in medium task IWSLT'17 and French-English in large task WMT'18\nBio, with up to 4 BLEU points over the state-of-the-art. Moreover, our\napproaches are more robust than baselines when evaluated on unknown\nout-of-domain test sets with up to a 5 BLEU point increase.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 14:11:21 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Khan", "Abdul Rafae", ""], ["Xu", "Jia", ""]]}, {"id": "1911.04361", "submitter": "Pengxiang Cheng", "authors": "Pengxiang Cheng, Katrin Erk", "title": "Attending to Entities for Better Text Understanding", "comments": "Accepted at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in NLP witnessed the development of large-scale pre-trained\nlanguage models (GPT, BERT, XLNet, etc.) based on Transformer (Vaswani et al.\n2017), and in a range of end tasks, such models have achieved state-of-the-art\nresults, approaching human performance. This demonstrates the power of the\nstacked self-attention architecture when paired with a sufficient number of\nlayers and a large amount of pre-training data. However, on tasks that require\ncomplex and long-distance reasoning where surface-level cues are not enough,\nthere is still a large gap between the pre-trained models and human\nperformance. Strubell et al. (2018) recently showed that it is possible to\ninject knowledge of syntactic structure into a model through supervised\nself-attention. We conjecture that a similar injection of semantic knowledge,\nin particular, coreference information, into an existing model would improve\nperformance on such complex problems. On the LAMBADA (Paperno et al. 2016)\ntask, we show that a model trained from scratch with coreference as auxiliary\nsupervision for self-attention outperforms the largest GPT-2 model, setting the\nnew state-of-the-art, while only containing a tiny fraction of parameters\ncompared to GPT-2. We also conduct a thorough analysis of different variants of\nmodel architectures and supervision configurations, suggesting future\ndirections on applying similar techniques to other problems.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 16:04:55 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Cheng", "Pengxiang", ""], ["Erk", "Katrin", ""]]}, {"id": "1911.04362", "submitter": "Nicole Fitzgerald", "authors": "Nicole Fitzgerald", "title": "To Populate is To Regulate", "comments": "EmeCom Neurips 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the effects of instantiating Lewis signaling games within a\npopulation of speaker and listener agents with the aim of producing a set of\ngeneral and robust representations of unstructured pixel data. Preliminary\nexperiments suggest that the set of representations associated with languages\ngenerated within a population outperform those generated between a single\nspeaker-listener pair on this objective, making a case for the adoption of\npopulation-based approaches in emergent communication studies. Furthermore,\npost-hoc analysis reveals that population-based learning induces a number of\nnovel factors to the conventional emergent communication setup, inviting a wide\nrange of future research questions regarding communication dynamics and the\nflow of information within them.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 23:51:45 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Fitzgerald", "Nicole", ""]]}, {"id": "1911.04427", "submitter": "Manirupa Das", "authors": "Manirupa Das, Juanxi Li, Eric Fosler-Lussier, Simon Lin, Soheil\n  Moosavinasab, Steve Rust, Yungui Huang and Rajiv Ramnath", "title": "Sequence-to-Set Semantic Tagging: End-to-End Multi-label Prediction\n  using Neural Attention for Complex Query Reformulation and Automated Text\n  Categorization", "comments": "8 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novel contexts may often arise in complex querying scenarios such as in\nevidence-based medicine (EBM) involving biomedical literature, that may not\nexplicitly refer to entities or canonical concept forms occurring in any fact-\nor rule-based knowledge source such as an ontology like the UMLS. Moreover,\nhidden associations between candidate concepts meaningful in the current\ncontext, may not exist within a single document, but within the collection, via\nalternate lexical forms. Therefore, inspired by the recent success of\nsequence-to-sequence neural models in delivering the state-of-the-art in a wide\nrange of NLP tasks, we develop a novel sequence-to-set framework with neural\nattention for learning document representations that can effect term transfer\nwithin the corpus, for semantically tagging a large collection of documents. We\ndemonstrate that our proposed method can be effective in both a supervised\nmulti-label classification setup for text categorization, as well as in a\nunique unsupervised setting with no human-annotated document labels that uses\nno external knowledge resources and only corpus-derived term statistics to\ndrive the training. Further, we show that semi-supervised training using our\narchitecture on large amounts of unlabeled data can augment performance on the\ntext categorization task when limited labeled data is available. Our approach\nto generate document encodings employing our sequence-to-set models for\ninference of semantic tags, gives to the best of our knowledge, the\nstate-of-the-art for both, the unsupervised query expansion task for the TREC\nCDS 2016 challenge dataset when evaluated on an Okapi BM25--based document\nretrieval system; and also over the MLTM baseline (Soleimani et al, 2016), for\nboth supervised and semi-supervised multi-label prediction tasks on the\ndel.icio.us and Ohsumed datasets. We will make our code and data publicly\navailable.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 18:13:05 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Das", "Manirupa", ""], ["Li", "Juanxi", ""], ["Fosler-Lussier", "Eric", ""], ["Lin", "Simon", ""], ["Moosavinasab", "Soheil", ""], ["Rust", "Steve", ""], ["Huang", "Yungui", ""], ["Ramnath", "Rajiv", ""]]}, {"id": "1911.04474", "submitter": "Hang Yan", "authors": "Hang Yan, Bocao Deng, Xiaonan Li, Xipeng Qiu", "title": "TENER: Adapting Transformer Encoder for Named Entity Recognition", "comments": "Corrept typos, update performance based on the public available codes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bidirectional long short-term memory networks (BiLSTM) have been widely\nused as an encoder in models solving the named entity recognition (NER) task.\nRecently, the Transformer is broadly adopted in various Natural Language\nProcessing (NLP) tasks owing to its parallelism and advantageous performance.\nNevertheless, the performance of the Transformer in NER is not as good as it is\nin other NLP tasks. In this paper, we propose TENER, a NER architecture\nadopting adapted Transformer Encoder to model the character-level features and\nword-level features. By incorporating the direction and relative distance aware\nattention and the un-scaled attention, we prove the Transformer-like encoder is\njust as effective for NER as other NLP tasks.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 15:05:48 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 17:34:19 GMT"}, {"version": "v3", "created": "Tue, 10 Dec 2019 07:01:25 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Yan", "Hang", ""], ["Deng", "Bocao", ""], ["Li", "Xiaonan", ""], ["Qiu", "Xipeng", ""]]}, {"id": "1911.04525", "submitter": "Yiqing Hua", "authors": "Yiqing Hua", "title": "Understanding BERT performance in propaganda analysis", "comments": null, "journal-ref": "Proceedings of the Second Workshop on Natural Language Processing\n  for Internet Freedom: Censorship, Disinformation, and Propaganda (2019)", "doi": "10.18653/v1/D19-5019", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe our system used in the shared task for\nfine-grained propaganda analysis at sentence level. Despite the challenging\nnature of the task, our pretrained BERT model (team YMJA) fine tuned on the\ntraining dataset provided by the shared task scored 0.62 F1 on the test set and\nranked third among 25 teams who participated in the contest. We present a set\nof illustrative experiments to better understand the performance of our BERT\nmodel on this shared task. Further, we explore beyond the given dataset for\nfalse-positive cases that likely to be produced by our system. We show that\ndespite the high performance on the given testset, our system may have the\ntendency of classifying opinion pieces as propaganda and cannot distinguish\nquotations of propaganda speech from actual usage of propaganda techniques.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 19:16:01 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Hua", "Yiqing", ""]]}, {"id": "1911.04571", "submitter": "Sarangarajan Parthasarathy", "authors": "Sarangarajan Parthasarathy, William Gale, Xie Chen, George Polovets,\n  Shuangyu Chang", "title": "Long-span language modeling for speech recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore neural language modeling for speech recognition where the context\nspans multiple sentences. Rather than encode history beyond the current\nsentence using a cache of words or document-level features, we focus our study\non the ability of LSTM and Transformer language models to implicitly learn to\ncarry over context across sentence boundaries. We introduce a new architecture\nthat incorporates an attention mechanism into LSTM to combine the benefits of\nrecurrent and attention architectures. We conduct language modeling and speech\nrecognition experiments on the publicly available LibriSpeech corpus. We show\nthat conventional training on a paragraph-level corpus results in significant\nreductions in perplexity compared to training on a sentence-level corpus. We\nalso describe speech recognition experiments using long-span language models in\nsecond-pass re-ranking, and provide insights into the ability of such models to\ntake advantage of context beyond the current sentence.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 21:18:53 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Parthasarathy", "Sarangarajan", ""], ["Gale", "William", ""], ["Chen", "Xie", ""], ["Polovets", "George", ""], ["Chang", "Shuangyu", ""]]}, {"id": "1911.04641", "submitter": "Qingrong Xia", "authors": "Qingrong Xia, Zhenghua Li, Min Zhang", "title": "A Syntax-aware Multi-task Learning Framework for Chinese Semantic Role\n  Labeling", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic role labeling (SRL) aims to identify the predicate-argument\nstructure of a sentence. Inspired by the strong correlation between syntax and\nsemantics, previous works pay much attention to improve SRL performance on\nexploiting syntactic knowledge, achieving significant results. Pipeline methods\nbased on automatic syntactic trees and multi-task learning (MTL) approaches\nusing standard syntactic trees are two common research orientations. In this\npaper, we adopt a simple unified span-based model for both span-based and\nword-based Chinese SRL as a strong baseline. Besides, we present a MTL\nframework that includes the basic SRL module and a dependency parser module.\nDifferent from the commonly used hard parameter sharing strategy in MTL, the\nmain idea is to extract implicit syntactic representations from the dependency\nparser as external inputs for the basic SRL model. Experiments on the\nbenchmarks of Chinese Proposition Bank 1.0 and CoNLL-2009 Chinese datasets show\nthat our proposed framework can effectively improve the performance over the\nstrong baselines. With the external BERT representations, our framework\nachieves new state-of-the-art 87.54 and 88.5 F1 scores on the two test data of\nthe two benchmarks, respectively. In-depth analysis are conducted to gain more\ninsights on the proposed framework and the effectiveness of syntax.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 02:49:38 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Xia", "Qingrong", ""], ["Li", "Zhenghua", ""], ["Zhang", "Min", ""]]}, {"id": "1911.04669", "submitter": "Yekun Chai", "authors": "Yekun Chai, Naomi Saphra, Adam Lopez", "title": "How to Evaluate Word Representations of Informal Domain?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diverse word representations have surged in most state-of-the-art natural\nlanguage processing (NLP) applications. Nevertheless, how to efficiently\nevaluate such word embeddings in the informal domain such as Twitter or forums,\nremains an ongoing challenge due to the lack of sufficient evaluation dataset.\nWe derived a large list of variant spelling pairs from UrbanDictionary with the\nautomatic approaches of weakly-supervised pattern-based bootstrapping and\nself-training linear-chain conditional random field (CRF). With these extracted\nrelation pairs we promote the odds of eliding the text normalization procedure\nof traditional NLP pipelines and directly adopting representations of\nnon-standard words in the informal domain. Our code is available.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 04:38:19 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 04:32:00 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Chai", "Yekun", ""], ["Saphra", "Naomi", ""], ["Lopez", "Adam", ""]]}, {"id": "1911.04700", "submitter": "Yinhe Zheng Dr.", "authors": "Yinhe Zheng, Rongsheng Zhang, Xiaoxi Mao, Minlie Huang", "title": "A Pre-training Based Personalized Dialogue Generation Model with\n  Persona-sparse Data", "comments": "Long paper accepted at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Endowing dialogue systems with personas is essential to deliver more\nhuman-like conversations. However, this problem is still far from well explored\ndue to the difficulties of both embodying personalities in natural languages\nand the persona sparsity issue observed in most dialogue corpora. This paper\nproposes a pre-training based personalized dialogue model that can generate\ncoherent responses using persona-sparse dialogue data. In this method, a\npre-trained language model is used to initialize an encoder and decoder, and\npersonal attribute embeddings are devised to model richer dialogue contexts by\nencoding speakers' personas together with dialogue histories. Further, to\nincorporate the target persona in the decoding process and to balance its\ncontribution, an attention routing structure is devised in the decoder to merge\nfeatures extracted from the target persona and dialogue contexts using\ndynamically predicted weights. Our model can utilize persona-sparse dialogues\nin a unified manner during the training process, and can also control the\namount of persona-related features to exhibit during the inference process.\nBoth automatic and manual evaluation demonstrates that the proposed model\noutperforms state-of-the-art methods for generating more coherent and persona\nconsistent responses with persona-sparse data.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 07:13:42 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Zheng", "Yinhe", ""], ["Zhang", "Rongsheng", ""], ["Mao", "Xiaoxi", ""], ["Huang", "Minlie", ""]]}, {"id": "1911.04759", "submitter": "Mehdi Mirzapour", "authors": "K\\'evin Cousot (TEXTE), Mehdi Mirzapour (TEXTE), Waleed Ragheb\n  (ADVANSE)", "title": "Prediction of Missing Semantic Relations in Lexical-Semantic Network\n  using Random Forest Classifier", "comments": null, "journal-ref": "CJC PRAXILING 2019, Nov 2019, Montpellier, France", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study focuses on the prediction of missing six semantic relations (such\nas is_a and has_part) between two given nodes in RezoJDM a French\nlexical-semantic network. The output of this prediction is a set of pairs in\nwhich the first entries are semantic relations and the second entries are the\nprobabilities of existence of such relations. Due to the statement of the\nproblem we choose the random forest (RF) predictor classifier approach to\ntackle this problem. We take for granted the existing semantic relations, for\ntraining/test dataset, gathered and validated by crowdsourcing. We describe how\nall of the mentioned ideas can be followed after using the node2vec approach in\nthe feature extraction phase. We show how this approach can lead to acceptable\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 09:41:44 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Cousot", "K\u00e9vin", "", "TEXTE"], ["Mirzapour", "Mehdi", "", "TEXTE"], ["Ragheb", "Waleed", "", "ADVANSE"]]}, {"id": "1911.04822", "submitter": "Dai Quoc Nguyen", "authors": "Dai Quoc Nguyen and Tu Dinh Nguyen and Dat Quoc Nguyen and Dinh Phung", "title": "A Capsule Network-based Model for Learning Node Embeddings", "comments": "Extended version of our CIKM 2020 paper, including inductive results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on learning low-dimensional embeddings for nodes in\ngraph-structured data. To achieve this, we propose Caps2NE -- a new\nunsupervised embedding model leveraging a network of two capsule layers.\nCaps2NE induces a routing process to aggregate feature vectors of context\nneighbors of a given target node at the first capsule layer, then feed these\nfeatures into the second capsule layer to infer a plausible embedding for the\ntarget node. Experimental results show that our proposed Caps2NE obtains\nstate-of-the-art performances on benchmark datasets for the node classification\ntask. Our code is available at: \\url{https://github.com/daiquocnguyen/Caps2NE}.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 12:44:26 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 15:48:59 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Nguyen", "Dai Quoc", ""], ["Nguyen", "Tu Dinh", ""], ["Nguyen", "Dat Quoc", ""], ["Phung", "Dinh", ""]]}, {"id": "1911.04873", "submitter": "Bartosz Piotrowski", "authors": "Bartosz Piotrowski, Josef Urban, Chad E. Brown, Cezary Kaliszyk", "title": "Can Neural Networks Learn Symbolic Rewriting?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates if the current neural architectures are adequate for\nlearning symbolic rewriting. Two kinds of data sets are proposed for this\nresearch -- one based on automated proofs and the other being a synthetic set\nof polynomial terms. The experiments with use of the current neural machine\ntranslation models are performed and its results are discussed. Ideas for\nextending this line of research are proposed, and its relevance is motivated.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 11:22:44 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 23:43:51 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Piotrowski", "Bartosz", ""], ["Urban", "Josef", ""], ["Brown", "Chad E.", ""], ["Kaliszyk", "Cezary", ""]]}, {"id": "1911.04879", "submitter": "Manvi Breja", "authors": "Manvi Breja and Sanjay Kumar Jain", "title": "A Survey on Why-Type Question Answering Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search engines such as Google, Yahoo and Baidu yield information in the form\nof a relevant set of web pages according to the need of the user. Question\nAnswering Systems reduce the time taken to get an answer, to a query asked in\nnatural language by providing the one most relevant answer. To the best of our\nknowledge, major research in Why-type questions began in early 2000's and our\nwork on Why-type questions can help explore newer avenues for fact-finding and\nanalysis. The paper presents a survey on Why-type Question Answering System,\ndetails the architecture, the processes involved in the system and suggests\nfurther areas of research.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 14:25:53 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Breja", "Manvi", ""], ["Jain", "Sanjay Kumar", ""]]}, {"id": "1911.04890", "submitter": "Takaki Makino", "authors": "Takaki Makino (1), Hank Liao (1), Yannis Assael (2), Brendan\n  Shillingford (2), Basilio Garcia (1), Otavio Braga (1), Olivier Siohan (1)\n  ((1) Google Inc. (2) DeepMind)", "title": "Recurrent Neural Network Transducer for Audio-Visual Speech Recognition", "comments": "Will be presented in 2019 IEEE Automatic Speech Recognition and\n  Understanding Workshop (ASRU 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.CV cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a large-scale audio-visual speech recognition system based\non a recurrent neural network transducer (RNN-T) architecture. To support the\ndevelopment of such a system, we built a large audio-visual (A/V) dataset of\nsegmented utterances extracted from YouTube public videos, leading to 31k hours\nof audio-visual training content. The performance of an audio-only,\nvisual-only, and audio-visual system are compared on two large-vocabulary test\nsets: a set of utterance segments from public YouTube videos called YTDEV18 and\nthe publicly available LRS3-TED set. To highlight the contribution of the\nvisual modality, we also evaluated the performance of our system on the YTDEV18\nset artificially corrupted with background noise and overlapping speech. To the\nbest of our knowledge, our system significantly improves the state-of-the-art\non the LRS3-TED set.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 22:01:42 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Makino", "Takaki", "", "Google Inc"], ["Liao", "Hank", "", "Google Inc"], ["Assael", "Yannis", "", "DeepMind"], ["Shillingford", "Brendan", "", "DeepMind"], ["Garcia", "Basilio", "", "Google Inc"], ["Braga", "Otavio", "", "Google Inc"], ["Siohan", "Olivier", "", "Google Inc"]]}, {"id": "1911.04910", "submitter": "Guangtao Wang", "authors": "Yun Tang, Jing Huang, Guangtao Wang, Xiaodong He, Bowen Zhou", "title": "Orthogonal Relation Transforms with Graph Context Modeling for Knowledge\n  Graph Embedding", "comments": "Accepted by ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Translational distance-based knowledge graph embedding has shown progressive\nimprovements on the link prediction task, from TransE to the latest\nstate-of-the-art RotatE. However, N-1, 1-N and N-N predictions still remain\nchallenging. In this work, we propose a novel translational distance-based\napproach for knowledge graph link prediction. The proposed method includes\ntwo-folds, first we extend the RotatE from 2D complex domain to high dimension\nspace with orthogonal transforms to model relations for better modeling\ncapacity. Second, the graph context is explicitly modeled via two directed\ncontext representations. These context representations are used as part of the\ndistance scoring function to measure the plausibility of the triples during\ntraining and inference. The proposed approach effectively improves prediction\naccuracy on the difficult N-1, 1-N and N-N cases for knowledge graph link\nprediction task. The experimental results show that it achieves better\nperformance on two benchmark data sets compared to the baseline RotatE,\nespecially on data set (FB15k-237) with many high in-degree connection nodes.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 07:02:33 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 20:32:11 GMT"}, {"version": "v3", "created": "Wed, 15 Apr 2020 20:13:30 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Tang", "Yun", ""], ["Huang", "Jing", ""], ["Wang", "Guangtao", ""], ["He", "Xiaodong", ""], ["Zhou", "Bowen", ""]]}, {"id": "1911.04913", "submitter": "Brij Mohan Lal Srivastava", "authors": "Brij Mohan Lal Srivastava, Aur\\'elien Bellet, Marc Tommasi, Emmanuel\n  Vincent", "title": "Privacy-Preserving Adversarial Representation Learning in ASR: Reality\n  or Illusion?", "comments": null, "journal-ref": null, "doi": "10.21437/Interspeech.2019-2415", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speech recognition (ASR) is a key technology in many services and\napplications. This typically requires user devices to send their speech data to\nthe cloud for ASR decoding. As the speech signal carries a lot of information\nabout the speaker, this raises serious privacy concerns. As a solution, an\nencoder may reside on each user device which performs local computations to\nanonymize the representation. In this paper, we focus on the protection of\nspeaker identity and study the extent to which users can be recognized based on\nthe encoded representation of their speech as obtained by a deep\nencoder-decoder architecture trained for ASR. Through speaker identification\nand verification experiments on the Librispeech corpus with open and closed\nsets of speakers, we show that the representations obtained from a standard\narchitecture still carry a lot of information about speaker identity. We then\npropose to use adversarial training to learn representations that perform well\nin ASR while hiding speaker identity. Our results demonstrate that adversarial\ntraining dramatically reduces the closed-set classification accuracy, but this\ndoes not translate into increased open-set verification error hence into\nincreased protection of the speaker identity in practice. We suggest several\npossible reasons behind this negative result.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 14:53:34 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Srivastava", "Brij Mohan Lal", ""], ["Bellet", "Aur\u00e9lien", ""], ["Tommasi", "Marc", ""], ["Vincent", "Emmanuel", ""]]}, {"id": "1911.04916", "submitter": "Ryan Cotterell", "authors": "Ryan Cotterell, Arun Kumar, Hinrich Sch\\\"utze", "title": "Morphological Segmentation Inside-Out", "comments": "EMNLP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Morphological segmentation has traditionally been modeled with\nnon-hierarchical models, which yield flat segmentations as output. In many\ncases, however, proper morphological analysis requires hierarchical structure\n-- especially in the case of derivational morphology. In this work, we\nintroduce a discriminative, joint model of morphological segmentation along\nwith the orthographic changes that occur during word formation. To the best of\nour knowledge, this is the first attempt to approach discriminative\nsegmentation with a context-free model. Additionally, we release an annotated\ntreebank of 7454 English words with constituency parses, encouraging future\nresearch in this area.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 14:57:28 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 19:46:32 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Cotterell", "Ryan", ""], ["Kumar", "Arun", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1911.04942", "submitter": "Bailin Wang", "authors": "Bailin Wang, Richard Shin, Xiaodong Liu, Oleksandr Polozov, Matthew\n  Richardson", "title": "RAT-SQL: Relation-Aware Schema Encoding and Linking for Text-to-SQL\n  Parsers", "comments": "Fix some errors of ACL 2020 camera-ready; 12 pages, 5 figures, 7\n  tables. arXiv admin note: text overlap with arXiv:1906.11790", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When translating natural language questions into SQL queries to answer\nquestions from a database, contemporary semantic parsing models struggle to\ngeneralize to unseen database schemas. The generalization challenge lies in (a)\nencoding the database relations in an accessible way for the semantic parser,\nand (b) modeling alignment between database columns and their mentions in a\ngiven query. We present a unified framework, based on the relation-aware\nself-attention mechanism, to address schema encoding, schema linking, and\nfeature representation within a text-to-SQL encoder. On the challenging Spider\ndataset this framework boosts the exact match accuracy to 57.2%, surpassing its\nbest counterparts by 8.7% absolute improvement. Further augmented with BERT, it\nachieves the new state-of-the-art performance of 65.6% on the Spider\nleaderboard. In addition, we observe qualitative improvements in the model's\nunderstanding of schema linking and alignment. Our implementation will be\nopen-sourced at https://github.com/Microsoft/rat-sql.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 09:09:13 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 02:08:16 GMT"}, {"version": "v3", "created": "Sat, 20 Jun 2020 07:11:06 GMT"}, {"version": "v4", "created": "Sun, 5 Jul 2020 10:03:54 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Wang", "Bailin", ""], ["Shin", "Richard", ""], ["Liu", "Xiaodong", ""], ["Polozov", "Oleksandr", ""], ["Richardson", "Matthew", ""]]}, {"id": "1911.04944", "submitter": "Holger Schwenk", "authors": "Holger Schwenk, Guillaume Wenzek, Sergey Edunov, Edouard Grave, Armand\n  Joulin", "title": "CCMatrix: Mining Billions of High-Quality Parallel Sentences on the WEB", "comments": "13 pages, 4 figures. arXiv admin note: text overlap with\n  arXiv:1907.05791", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that margin-based bitext mining in a multilingual sentence space can\nbe applied to monolingual corpora of billions of sentences. We are using ten\nsnapshots of a curated common crawl corpus (Wenzek et al., 2019) totalling 32.7\nbillion unique sentences. Using one unified approach for 38 languages, we were\nable to mine 4.5 billions parallel sentences, out of which 661 million are\naligned with English. 20 language pairs have more then 30 million parallel\nsentences, 112 more then 10 million, and most more than one million, including\ndirect alignments between many European or Asian languages.\n  To evaluate the quality of the mined bitexts, we train NMT systems for most\nof the language pairs and evaluate them on TED, WMT and WAT test sets. Using\nour mined bitexts only and no human translated parallel data, we achieve a new\nstate-of-the-art for a single system on the WMT'19 test set for translation\nbetween English and German, Russian and Chinese, as well as German/French. In\nparticular, our English/German system outperforms the best single one by close\nto 4 BLEU points and is almost on pair with best WMT'19 evaluation system which\nuses system combination and back-translation. We also achieve excellent results\nfor distant languages pairs like Russian/Japanese, outperforming the best\nsubmission at the 2019 workshop on Asian Translation (WAT).\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 12:09:46 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 10:49:00 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Schwenk", "Holger", ""], ["Wenzek", "Guillaume", ""], ["Edunov", "Sergey", ""], ["Grave", "Edouard", ""], ["Joulin", "Armand", ""]]}, {"id": "1911.04952", "submitter": "Isabella Czedik-Eysenberg", "authors": "Isabella Czedik-Eysenberg and Oliver Wieczorek and Christoph Reuter", "title": "'Warriors of the Word' -- Deciphering Lyrical Topics in Music and Their\n  Connection to Audio Feature Dimensions Based on a Corpus of Over 100,000\n  Metal Songs", "comments": "Corrected typo in abstract (subsample)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We look into the connection between the musical and lyrical content of metal\nmusic by combining automated extraction of high-level audio features and\nquantitative text analysis on a corpus of 124.288 song lyrics from this genre.\nBased on this text corpus, a topic model was first constructed using Latent\nDirichlet Allocation (LDA). For a subsample of 503 songs, scores for predicting\nperceived musical hardness/heaviness and darkness/gloominess were extracted\nusing audio feature models. By combining both audio feature and text analysis,\nwe (1) offer a comprehensive overview of the lyrical topics present within the\nmetal genre and (2) are able to establish whether or not levels of hardness and\nother music dimensions are associated with the occurrence of particularly harsh\n(and other) textual topics. Twenty typical topics were identified and projected\ninto a topic space using multidimensional scaling (MDS). After Bonferroni\ncorrection, positive correlations were found between musical hardness and\ndarkness and textual topics dealing with 'brutal death', 'dystopia', 'archaisms\nand occultism', 'religion and satanism', 'battle' and '(psychological)\nmadness', while there is a negative associations with topics like 'personal\nlife' and 'love and romance'.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 15:53:40 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 11:06:13 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Czedik-Eysenberg", "Isabella", ""], ["Wieczorek", "Oliver", ""], ["Reuter", "Christoph", ""]]}, {"id": "1911.04997", "submitter": "Laurent Besacier", "authors": "Rohit Gupta and Laurent Besacier and Marc Dymetman and Matthias\n  Gall\\'e", "title": "Character-based NMT with Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Character-based translation has several appealing advantages, but its\nperformance is in general worse than a carefully tuned BPE baseline. In this\npaper we study the impact of character-based input and output with the\nTransformer architecture. In particular, our experiments on EN-DE show that\ncharacter-based Transformer models are more robust than their BPE counterpart,\nboth when translating noisy text, and when translating text from a different\ndomain. To obtain comparable BLEU scores in clean, in-domain data and close the\ngap with BPE-based models we use known techniques to train deeper Transformer\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 16:32:38 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Gupta", "Rohit", ""], ["Besacier", "Laurent", ""], ["Dymetman", "Marc", ""], ["Gall\u00e9", "Matthias", ""]]}, {"id": "1911.05013", "submitter": "Vishaal Udandarao", "authors": "Abhishek Agarwal, Nikhil Sachdeva, Raj Kamal Yadav, Vishaal Udandarao,\n  Vrinda Mittal, Anubha Gupta, Abhinav Mathur", "title": "EDUQA: Educational Domain Question Answering System using Conceptual\n  Network Mapping", "comments": "Published in the 44th International Conference on Acoustics, Speech,\n  and Signal Processing (ICASSP) 2019", "journal-ref": "IEEE ICASSP (2019) 8137-8141", "doi": "10.1109/ICASSP.2019.8683538", "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing question answering models can be largely compiled into\ntwo categories: i) open domain question answering models that answer generic\nquestions and use large-scale knowledge base along with the targeted web-corpus\nretrieval and ii) closed domain question answering models that address focused\nquestioning area and use complex deep learning models. Both the above models\nderive answers through textual comprehension methods. Due to their inability to\ncapture the pedagogical meaning of textual content, these models are not\nappropriately suited to the educational field for pedagogy. In this paper, we\npropose an on-the-fly conceptual network model that incorporates educational\nsemantics. The proposed model preserves correlations between conceptual\nentities by applying intelligent indexing algorithms on the concept network so\nas to improve answer generation. This model can be utilized for building\ninteractive conversational agents for aiding classroom learning.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 17:11:55 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Agarwal", "Abhishek", ""], ["Sachdeva", "Nikhil", ""], ["Yadav", "Raj Kamal", ""], ["Udandarao", "Vishaal", ""], ["Mittal", "Vrinda", ""], ["Gupta", "Anubha", ""], ["Mathur", "Abhinav", ""]]}, {"id": "1911.05034", "submitter": "Tianxiang Sun", "authors": "Tianxiang Sun, Yunfan Shao, Xiaonan Li, Pengfei Liu, Hang Yan, Xipeng\n  Qiu, Xuanjing Huang", "title": "Learning Sparse Sharing Architectures for Multiple Tasks", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing deep multi-task learning models are based on parameter sharing,\nsuch as hard sharing, hierarchical sharing, and soft sharing. How choosing a\nsuitable sharing mechanism depends on the relations among the tasks, which is\nnot easy since it is difficult to understand the underlying shared factors\namong these tasks. In this paper, we propose a novel parameter sharing\nmechanism, named \\emph{Sparse Sharing}. Given multiple tasks, our approach\nautomatically finds a sparse sharing structure. We start with an\nover-parameterized base network, from which each task extracts a subnetwork.\nThe subnetworks of multiple tasks are partially overlapped and trained in\nparallel. We show that both hard sharing and hierarchical sharing can be\nformulated as particular instances of the sparse sharing framework. We conduct\nextensive experiments on three sequence labeling tasks. Compared with\nsingle-task models and three typical multi-task learning baselines, our\nproposed approach achieves consistent improvement while requiring fewer\nparameters.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 17:50:35 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 13:53:10 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Sun", "Tianxiang", ""], ["Shao", "Yunfan", ""], ["Li", "Xiaonan", ""], ["Liu", "Pengfei", ""], ["Yan", "Hang", ""], ["Qiu", "Xipeng", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1911.05153", "submitter": "Arash Einolghozati", "authors": "Arash Einolghozati, Sonal Gupta, Mrinal Mohit, Rushin Shah", "title": "Improving Robustness of Task Oriented Dialog Systems", "comments": null, "journal-ref": "3rd Conversational AI Workshop at 33rd Conference on Neural\n  Information Processing Systems (NeurIPS 2019)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task oriented language understanding in dialog systems is often modeled using\nintents (task of a query) and slots (parameters for that task). Intent\ndetection and slot tagging are, in turn, modeled using sentence classification\nand word tagging techniques respectively. Similar to adversarial attack\nproblems with computer vision models discussed in existing literature, these\nintent-slot tagging models are often over-sensitive to small variations in\ninput -- predicting different and often incorrect labels when small changes are\nmade to a query, thus reducing their accuracy and reliability. However,\nevaluating a model's robustness to these changes is harder for language since\nwords are discrete and an automated change (e.g. adding `noise') to a query\nsometimes changes the meaning and thus labels of a query. In this paper, we\nfirst describe how to create an adversarial test set to measure the robustness\nof these models. Furthermore, we introduce and adapt adversarial training\nmethods as well as data augmentation using back-translation to mitigate these\nissues. Our experiments show that both techniques improve the robustness of the\nsystem substantially and can be combined to yield the best results.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 21:34:15 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Einolghozati", "Arash", ""], ["Gupta", "Sonal", ""], ["Mohit", "Mrinal", ""], ["Shah", "Rushin", ""]]}, {"id": "1911.05186", "submitter": "Wei Zou", "authors": "Wubo Li, Wei Zou, Xiangang Li", "title": "TCT: A Cross-supervised Learning Method for Multimodal Sequence\n  Representation", "comments": "submitted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodalities provide promising performance than unimodality in most tasks.\nHowever, learning the semantic of the representations from multimodalities\nefficiently is extremely challenging. To tackle this, we propose the\nTransformer based Cross-modal Translator (TCT) to learn unimodal sequence\nrepresentations by translating from other related multimodal sequences on a\nsupervised learning method. Combined TCT with Multimodal Transformer Network\n(MTN), we evaluate MTN-TCT on the video-grounded dialogue which uses\nmultimodality. The proposed method reports new state-of-the-art performance on\nvideo-grounded dialogue which indicates representations learned by TCT are more\nsemantics compared to directly use unimodality.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 05:02:15 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Li", "Wubo", ""], ["Zou", "Wei", ""], ["Li", "Xiangang", ""]]}, {"id": "1911.05202", "submitter": "Liangyi Kang", "authors": "Liangyi Kang, Jie Liu, Lingqiao Liu, Qinfeng Shi, and Dan Ye", "title": "Creating Auxiliary Representations from Charge Definitions for Criminal\n  Charge Prediction", "comments": "8 pages, 5figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Charge prediction, determining charges for criminal cases by analyzing the\ntextual fact descriptions, is a promising technology in legal assistant\nsystems. In practice, the fact descriptions could exhibit a significant\nintra-class variation due to factors like non-normative use of language, which\nmakes the prediction task very challenging, especially for charge classes with\ntoo few samples to cover the expression variation. In this work, we explore to\nuse the charge definitions from criminal law to alleviate this issue. The key\nidea is that the expressions in a fact description should have corresponding\nformal terms in charge definitions, and those terms are shared across classes\nand could account for the diversity in the fact descriptions. Thus, we propose\nto create auxiliary fact representations from charge definitions to augment\nfact descriptions representation. The generated auxiliary representations are\ncreated through the interaction of fact description with the relevant charge\ndefinitions and terms in those definitions by integrated sentence- and\nword-level attention scheme. Experimental results on two datasets show that our\nmodel achieves significant improvement than baselines, especially for classes\nwith few samples.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 23:31:12 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Kang", "Liangyi", ""], ["Liu", "Jie", ""], ["Liu", "Lingqiao", ""], ["Shi", "Qinfeng", ""], ["Ye", "Dan", ""]]}, {"id": "1911.05241", "submitter": "Sravan Babu Bodapati", "authors": "Sravan Bodapati, Hyokun Yun, Yaser Al-Onaizan", "title": "Robustness to Capitalization Errors in Named Entity Recognition", "comments": "Accepted to EMNLP 2019 Workshop : W-NUT 2019 5th Workshop on Noisy\n  User Generated Text", "journal-ref": "http://noisy-text.github.io/2019/", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness to capitalization errors is a highly desirable characteristic of\nnamed entity recognizers, yet we find standard models for the task are\nsurprisingly brittle to such noise. Existing methods to improve robustness to\nthe noise completely discard given orthographic information, mwhich\nsignificantly degrades their performance on well-formed text. We propose a\nsimple alternative approach based on data augmentation, which allows the model\nto \\emph{learn} to utilize or ignore orthographic information depending on its\nusefulness in the context. It achieves competitive robustness to capitalization\nerrors while making negligible compromise to its performance on well-formed\ntext and significantly improving generalization power on noisy user-generated\ntext. Our experiments clearly and consistently validate our claim across\ndifferent types of machine learning models, languages, and dataset sizes.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 01:52:27 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Bodapati", "Sravan", ""], ["Yun", "Hyokun", ""], ["Al-Onaizan", "Yaser", ""]]}, {"id": "1911.05263", "submitter": "Pedram Hosseini", "authors": "Behnam Sabeti, Pedram Hosseini, Gholamreza Ghassem-Sani, Seyed\n  Abolghasem Mirroshandel", "title": "LexiPers: An ontology based sentiment lexicon for Persian", "comments": null, "journal-ref": null, "doi": "10.29007/f4j4", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis refers to the use of natural language processing to\nidentify and extract subjective information from textual resources. One\napproach for sentiment extraction is using a sentiment lexicon. A sentiment\nlexicon is a set of words associated with the sentiment orientation that they\nexpress. In this paper, we describe the process of generating a general purpose\nsentiment lexicon for Persian. A new graph-based method is introduced for seed\nselection and expansion based on an ontology. Sentiment lexicon generation is\nthen mapped to a document classification problem. We used the K-nearest\nneighbors and nearest centroid methods for classification. These classifiers\nhave been evaluated based on a set of hand labeled synsets. The final sentiment\nlexicon has been generated by the best classifier. The results show an\nacceptable performance in terms of accuracy and F-measure in the generated\nsentiment lexicon.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 02:48:33 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Sabeti", "Behnam", ""], ["Hosseini", "Pedram", ""], ["Ghassem-Sani", "Gholamreza", ""], ["Mirroshandel", "Seyed Abolghasem", ""]]}, {"id": "1911.05343", "submitter": "Ruizhe Li", "authors": "Ruizhe Li, Xiao Li, Chenghua Lin, Matthew Collinson and Rui Mao", "title": "A Stable Variational Autoencoder for Text Modelling", "comments": "Accepted by INLG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Autoencoder (VAE) is a powerful method for learning\nrepresentations of high-dimensional data. However, VAEs can suffer from an\nissue known as latent variable collapse (or KL loss vanishing), where the\nposterior collapses to the prior and the model will ignore the latent codes in\ngenerative tasks. Such an issue is particularly prevalent when employing\nVAE-RNN architectures for text modelling (Bowman et al., 2016). In this paper,\nwe present a simple architecture called holistic regularisation VAE (HR-VAE),\nwhich can effectively avoid latent variable collapse. Compared to existing\nVAE-RNN architectures, we show that our model can achieve much more stable\ntraining process and can generate text with significantly better quality.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 08:11:42 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Li", "Ruizhe", ""], ["Li", "Xiao", ""], ["Lin", "Chenghua", ""], ["Collinson", "Matthew", ""], ["Mao", "Rui", ""]]}, {"id": "1911.05483", "submitter": "Mohamed Elhag Mohamed Abo", "authors": "Mohamed Elhag M. Abo, Ram Gopal Raj, Atika Qazi, Abubakar Zakari", "title": "Sentiment Analysis for Arabic in Social Media Network: A Systematic\n  Mapping Study", "comments": "34 pages, 10 figures, Articles, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the expansion in tenders on the Internet and social media, Arabic\nSentiment Analysis (ASA) has assumed a significant position in the field of\ntext mining study and has since remained used to explore the sentiments of\nusers about services, various products or topics conversed over the Internet.\nThis mapping paper designs to comprehensively investigate the papers\ndemographics, fertility, and directions of the ASA research domain.\nFurthermore, plans to analyze current ASA techniques and find movements in the\nresearch. This paper describes a systematic mapping study (SMS) of 51 primary\nselected studies (PSS) is handled with the approval of an evidence-based\nsystematic method to ensure handling of all related papers. The analyzed\nresults showed the increase of both the ASA research area and numbers of\npublications per year since 2015. Three main research facets were found, i.e.\nvalidation, solution, and evaluation research, with solution research becoming\nmore treatment than another research type. Therefore numerous contribution\nfacets were singled out. In totality, the general demographics of the ASA\nresearch field were highlighted and discussed\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 08:38:19 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Abo", "Mohamed Elhag M.", ""], ["Raj", "Ram Gopal", ""], ["Qazi", "Atika", ""], ["Zakari", "Abubakar", ""]]}, {"id": "1911.05585", "submitter": "Ekaterina Lobacheva Ms", "authors": "Ekaterina Lobacheva, Nadezhda Chirkova, Alexander Markovich, Dmitry\n  Vetrov", "title": "Structured Sparsification of Gated Recurrent Neural Networks", "comments": "Published in Workshop on Context and Compositionality in Biological\n  and Artificial Neural Systems, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a lot of techniques were developed to sparsify the weights of\nneural networks and to remove networks' structure units, e.g. neurons. We\nadjust the existing sparsification approaches to the gated recurrent\narchitectures. Specifically, in addition to the sparsification of weights and\nneurons, we propose sparsifying the preactivations of gates. This makes some\ngates constant and simplifies LSTM structure. We test our approach on the text\nclassification and language modeling tasks. We observe that the resulting\nstructure of gate sparsity depends on the task and connect the learned\nstructure to the specifics of the particular tasks. Our method also improves\nneuron-wise compression of the model in most of the tasks.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 16:26:22 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Lobacheva", "Ekaterina", ""], ["Chirkova", "Nadezhda", ""], ["Markovich", "Alexander", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1911.05594", "submitter": "Andreas R\\\"uckl\\'e", "authors": "Andreas R\\\"uckl\\'e, Nafise Sadat Moosavi, Iryna Gurevych", "title": "Neural Duplicate Question Detection without Labeled Training Data", "comments": "Accepted as long paper at EMNLP-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised training of neural models to duplicate question detection in\ncommunity Question Answering (cQA) requires large amounts of labeled question\npairs, which are costly to obtain. To minimize this cost, recent works thus\noften used alternative methods, e.g., adversarial domain adaptation. In this\nwork, we propose two novel methods: (1) the automatic generation of duplicate\nquestions, and (2) weak supervision using the title and body of a question. We\nshow that both can achieve improved performances even though they do not\nrequire any labeled data. We provide comprehensive comparisons of popular\ntraining strategies, which provides important insights on how to best train\nmodels in different scenarios. We show that our proposed approaches are more\neffective in many cases because they can utilize larger amounts of unlabeled\ndata from cQA forums. Finally, we also show that our proposed approach for weak\nsupervision with question title and body information is also an effective\nmethod to train cQA answer selection models without direct answer supervision.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 16:38:30 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 10:51:46 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["R\u00fcckl\u00e9", "Andreas", ""], ["Moosavi", "Nafise Sadat", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1911.05604", "submitter": "Jungwei Fan", "authors": "Andrew Wen, Mohamed Y. Elwazir, Sungrim Moon, Jungwei Fan", "title": "Adapting and evaluating a deep learning language model for clinical\n  why-question answering", "comments": null, "journal-ref": null, "doi": "10.1093/jamiaopen/ooz072", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objectives: To adapt and evaluate a deep learning language model for\nanswering why-questions based on patient-specific clinical text. Materials and\nMethods: Bidirectional encoder representations from transformers (BERT) models\nwere trained with varying data sources to perform SQuAD 2.0 style why-question\nanswering (why-QA) on clinical notes. The evaluation focused on: 1) comparing\nthe merits from different training data, 2) error analysis. Results: The best\nmodel achieved an accuracy of 0.707 (or 0.760 by partial match). Training\ntoward customization for the clinical language helped increase 6% in accuracy.\nDiscussion: The error analysis suggested that the model did not really perform\ndeep reasoning and that clinical why-QA might warrant more sophisticated\nsolutions. Conclusion: The BERT model achieved moderate accuracy in clinical\nwhy-QA and should benefit from the rapidly evolving technology. Despite the\nidentified limitations, it could serve as a competent proxy for question-driven\nclinical information extraction.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 16:43:22 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Wen", "Andrew", ""], ["Elwazir", "Mohamed Y.", ""], ["Moon", "Sungrim", ""], ["Fan", "Jungwei", ""]]}, {"id": "1911.05636", "submitter": "Charles Copley", "authors": "Monika Obrocka, Charles Copley, Themba Gqaza, Eli Grant", "title": "Prevalence of code mixing in semi-formal patient communication in low\n  resource languages of South Africa", "comments": "3 pages, Presented at NeurIPS 2019 Workshop on Machine Learning for\n  the Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper we address the problem of code-mixing in resource-poor language\nsettings. We examine data consisting of 182k unique questions generated by\nusers of the MomConnect helpdesk, part of a national scale public health\nplatform in South Africa. We show evidence of code-switching at the level of\napproximately 10% within this dataset -- a level that is likely to pose\nchallenges for future services. We use a natural language processing library\n(Polyglot) that supports detection of 196 languages and attempt to evaluate its\nperformance at identifying English, isiZulu and code-mixed questions.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 17:12:40 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 05:50:55 GMT"}, {"version": "v3", "created": "Tue, 10 Dec 2019 14:55:37 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Obrocka", "Monika", ""], ["Copley", "Charles", ""], ["Gqaza", "Themba", ""], ["Grant", "Eli", ""]]}, {"id": "1911.05652", "submitter": "Petr Plechac", "authors": "Petr Plech\\'a\\v{c}", "title": "Relative contributions of Shakespeare and Fletcher in Henry VIII: An\n  Analysis Based on Most Frequent Words and Most Frequent Rhythmic Patterns", "comments": null, "journal-ref": null, "doi": "10.1093/llc/fqaa032", "report-no": null, "categories": "cs.CL cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The versified play Henry VIII is nowadays widely recognized to be a\ncollaborative work not written solely by William Shakespeare. We employ\ncombined analysis of vocabulary and versification together with machine\nlearning techniques to determine which authors also took part in the writing of\nthe play and what were their relative contributions. Unlike most previous\nstudies, we go beyond the attribution of particular scenes and use the rolling\nattribution approach to determine the probabilities of authorship of pieces of\ntexts, without respecting the scene boundaries. Our results highly support the\ncanonical division of the play between William Shakespeare and John Fletcher\nproposed by James Spedding, but also bring new evidence supporting the\nmodifications proposed later by Thomas Merriam.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 22:40:05 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Plech\u00e1\u010d", "Petr", ""]]}, {"id": "1911.05659", "submitter": "Trisha Mittal", "authors": "Trisha Mittal, Uttaran Bhattacharya, Rohan Chandra, Aniket Bera,\n  Dinesh Manocha", "title": "M3ER: Multiplicative Multimodal Emotion Recognition Using Facial,\n  Textual, and Speech Cues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present M3ER, a learning-based method for emotion recognition from\nmultiple input modalities. Our approach combines cues from multiple\nco-occurring modalities (such as face, text, and speech) and also is more\nrobust than other methods to sensor noise in any of the individual modalities.\nM3ER models a novel, data-driven multiplicative fusion method to combine the\nmodalities, which learn to emphasize the more reliable cues and suppress others\non a per-sample basis. By introducing a check step which uses Canonical\nCorrelational Analysis to differentiate between ineffective and effective\nmodalities, M3ER is robust to sensor noise. M3ER also generates proxy features\nin place of the ineffectual modalities. We demonstrate the efficiency of our\nnetwork through experimentation on two benchmark datasets, IEMOCAP and\nCMU-MOSEI. We report a mean accuracy of 82.7% on IEMOCAP and 89.0% on\nCMU-MOSEI, which, collectively, is an improvement of about 5% over prior work.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 01:58:03 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 18:48:47 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Mittal", "Trisha", ""], ["Bhattacharya", "Uttaran", ""], ["Chandra", "Rohan", ""], ["Bera", "Aniket", ""], ["Manocha", "Dinesh", ""]]}, {"id": "1911.05689", "submitter": "Ian Porada", "authors": "Ian Porada, Kaheer Suleman, Jackie Chi Kit Cheung", "title": "Can a Gorilla Ride a Camel? Learning Semantic Plausibility from Text", "comments": "Accepted at COIN@EMNLP 2019", "journal-ref": "Proceedings of the First Workshop on Commonsense Inference in\n  Natural Language Processing. (2019) 123-129", "doi": "10.18653/v1/D19-6015", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling semantic plausibility requires commonsense knowledge about the world\nand has been used as a testbed for exploring various knowledge representations.\nPrevious work has focused specifically on modeling physical plausibility and\nshown that distributional methods fail when tested in a supervised setting. At\nthe same time, distributional models, namely large pretrained language models,\nhave led to improved results for many natural language understanding tasks. In\nthis work, we show that these pretrained language models are in fact effective\nat modeling physical plausibility in the supervised setting. We therefore\npresent the more difficult problem of learning to model physical plausibility\ndirectly from text. We create a training set by extracting attested events from\na large corpus, and we provide a baseline for training on these attested events\nin a self-supervised manner and testing on a physical plausibility task. We\nbelieve results could be further improved by injecting explicit commonsense\nknowledge into a distributional model.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 18:13:07 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Porada", "Ian", ""], ["Suleman", "Kaheer", ""], ["Cheung", "Jackie Chi Kit", ""]]}, {"id": "1911.05715", "submitter": "Timothee Mickus", "authors": "Timothee Mickus, Denis Paperno, Mathieu Constant", "title": "Mark my Word: A Sequence-to-Sequence Approach to Definition Modeling", "comments": null, "journal-ref": "Proceedings of the First NLPL Workshop on Deep Learning for\n  Natural Language Processing, 30 September, 2019, University of Turku, Turku,\n  Finland", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Defining words in a textual context is a useful task both for practical\npurposes and for gaining insight into distributed word representations.\nBuilding on the distributional hypothesis, we argue here that the most natural\nformalization of definition modeling is to treat it as a sequence-to-sequence\ntask, rather than a word-to-sequence task: given an input sequence with a\nhighlighted word, generate a contextually appropriate definition for it. We\nimplement this approach in a Transformer-based sequence-to-sequence model. Our\nproposal allows to train contextualization and definition generation in an\nend-to-end fashion, which is a conceptual improvement over earlier works. We\nachieve state-of-the-art results both in contextual and non-contextual\ndefinition modeling.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 18:44:15 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Mickus", "Timothee", ""], ["Paperno", "Denis", ""], ["Constant", "Mathieu", ""]]}, {"id": "1911.05733", "submitter": "Shahan Ali Memon", "authors": "Hira Dhamyal, Shahan Ali Memon, Bhiksha Raj, Rita Singh", "title": "The phonetic bases of vocal expressed emotion: natural versus acted", "comments": "5 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can vocal emotions be emulated? This question has been a recurrent concern of\nthe speech community, and has also been vigorously investigated. It has been\nfueled further by its link to the issue of validity of acted emotion databases.\nMuch of the speech and vocal emotion research has relied on acted emotion\ndatabases as valid proxies for studying natural emotions. To create models that\ngeneralize to natural settings, it is crucial to work with valid prototypes --\nones that can be assumed to reliably represent natural emotions. More\nconcretely, it is important to study emulated emotions against natural emotions\nin terms of their physiological, and psychological concomitants. In this paper,\nwe present an on-scale systematic study of the differences between natural and\nacted vocal emotions. We use a self-attention based emotion classification\nmodel to understand the phonetic bases of emotions by discovering the most\n'attended' phonemes for each class of emotions. We then compare these\nattended-phonemes in their importance and distribution across acted and natural\nclasses. Our tests show significant differences in the manner and choice of\nphonemes in acted and natural speech, concluding moderate to low validity and\nvalue in using acted speech databases for emotion classification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 03:44:08 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 20:49:50 GMT"}, {"version": "v3", "created": "Sat, 25 Jul 2020 02:49:50 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Dhamyal", "Hira", ""], ["Memon", "Shahan Ali", ""], ["Raj", "Bhiksha", ""], ["Singh", "Rita", ""]]}, {"id": "1911.05758", "submitter": "Timothee Mickus", "authors": "Timothee Mickus, Denis Paperno, Mathieu Constant, Kees van Deemter", "title": "What do you mean, BERT? Assessing BERT as a Distributional Semantics\n  Model", "comments": null, "journal-ref": "Proceedings of the Society for Computation in Linguistics: Vol. 3\n  (2020), Article 34", "doi": "10.7275/t778-ja71", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Contextualized word embeddings, i.e. vector representations for words in\ncontext, are naturally seen as an extension of previous noncontextual\ndistributional semantic models. In this work, we focus on BERT, a deep neural\nnetwork that produces contextualized embeddings and has set the\nstate-of-the-art in several semantic tasks, and study the semantic coherence of\nits embedding space. While showing a tendency towards coherence, BERT does not\nfully live up to the natural expectations for a semantic vector space. In\nparticular, we find that the position of the sentence in which a word occurs,\nwhile having no meaning correlates, leaves a noticeable trace on the word\nembeddings and disturbs similarity relationships.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 19:04:42 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 14:40:36 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Mickus", "Timothee", ""], ["Paperno", "Denis", ""], ["Constant", "Mathieu", ""], ["van Deemter", "Kees", ""]]}, {"id": "1911.05889", "submitter": "Haoyu Song", "authors": "Haoyu Song, Wei-Nan Zhang, Jingwen Hu, Ting Liu", "title": "Generating Persona Consistent Dialogues by Exploiting Natural Language\n  Inference", "comments": "AAAI20. Update code links", "journal-ref": null, "doi": "10.1609/aaai.v34i05.6417", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consistency is one of the major challenges faced by dialogue agents. A\nhuman-like dialogue agent should not only respond naturally, but also maintain\na consistent persona. In this paper, we exploit the advantages of natural\nlanguage inference (NLI) technique to address the issue of generating persona\nconsistent dialogues. Different from existing work that re-ranks the retrieved\nresponses through an NLI model, we cast the task as a reinforcement learning\nproblem and propose to exploit the NLI signals from response-persona pairs as\nrewards for the process of dialogue generation. Specifically, our generator\nemploys an attention-based encoder-decoder to generate persona-based responses.\nOur evaluator consists of two components: an adversarially trained naturalness\nmodule and an NLI based consistency module. Moreover, we use another\nwell-performed NLI model in the evaluation of persona-consistency. Experimental\nresults on both human and automatic metrics, including the model-based\nconsistency evaluation, demonstrate that the proposed approach outperforms\nstrong generative baselines, especially in the persona-consistency of generated\nresponses.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 01:47:53 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 04:15:30 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 01:47:14 GMT"}, {"version": "v4", "created": "Mon, 22 Mar 2021 06:05:31 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Song", "Haoyu", ""], ["Zhang", "Wei-Nan", ""], ["Hu", "Jingwen", ""], ["Liu", "Ting", ""]]}, {"id": "1911.05930", "submitter": "Ruobing Xie", "authors": "Ruobing Xie, Yanan Lu, Fen Lin, Leyu Lin", "title": "FAQ-based Question Answering via Knowledge Anchors", "comments": "12 pages, accepted by NLPCC-2020", "journal-ref": "NLPCC-2020", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering (QA) aims to understand questions and find appropriate\nanswers. In real-world QA systems, Frequently Asked Question (FAQ) based QA is\nusually a practical and effective solution, especially for some complicated\nquestions (e.g., How and Why). Recent years have witnessed the great successes\nof knowledge graphs (KGs) in KBQA systems, while there are still few works\nfocusing on making full use of KGs in FAQ-based QA. In this paper, we propose a\nnovel Knowledge Anchor based Question Answering (KAQA) framework for FAQ-based\nQA to better understand questions and retrieve more appropriate answers. More\nspecifically, KAQA mainly consists of three modules: knowledge graph\nconstruction, query anchoring and query-document matching. We consider entities\nand triples of KGs in texts as knowledge anchors to precisely capture the core\nsemantics, which brings in higher precision and better interpretability. The\nmulti-channel matching strategy also enables most sentence matching models to\nbe flexibly plugged in our KAQA framework to fit different real-world\ncomputation limitations. In experiments, we evaluate our models on both offline\nand online query-document matching tasks on a real-world FAQ-based QA system in\nWeChat Search, with detailed analysis, ablation tests and case studies. The\nsignificant improvements confirm the effectiveness and robustness of the KAQA\nframework in real-world FAQ-based QA.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 04:18:55 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 07:50:31 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Xie", "Ruobing", ""], ["Lu", "Yanan", ""], ["Lin", "Fen", ""], ["Lin", "Leyu", ""]]}, {"id": "1911.05953", "submitter": "Jae-Yun Kim", "authors": "Jae-Yun Kim, Jun-Mo Lee, Yeon-Jae Koo, Sang-Hyeon Park, Soo-Mook Moon", "title": "Ethanos: Lightweight Bootstrapping for Ethereum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As ethereum blockchain has become popular, the number of users and\ntransactions has skyrocketed, causing an explosive increase of its data size.\nAs a result, ordinary clients using PCs or smartphones cannot easily bootstrap\nas a full node, but rely on other full nodes such as the miners to run or\nverify transactions. This may affect the security of ethereum, so light\nbootstrapping techniques such as fast sync has been proposed to download only\nparts of full data, yet the space overhead is still too high. One of the\nbiggest space overhead that cannot easily be reduced is caused by saving the\nstate of all accounts in the block's state trie. Fortunately, we found that\nmore than 90% of accounts are inactive and old transactions are hard to be\nmanipulated. Based on these observations, this paper propose a novel\noptimization technique called ethanos that can reduce bootstrapping cost by\nsweeping inactive accounts periodically and by not downloading old\ntransactions. If an inactive account becomes active, ethanos restore its state\nby running a restoration transaction. Also, ethanos gives incentives for\narchive nodes to maintain the old transactions for possible re-verification. We\nimplemented ethanos by instrumenting the go-ethereum (geth) client and\nevaluated with the real 113 million transactions from 14 million accounts\nbetween 7M-th and 8M-th blocks in ethereum. Our experimental result shows that\nethanos can reduce the size of the account state by half, which, if combined\nwith removing old transactions, may reduce the storage size for bootstrapping\nto around 1GB. This would be reasonable enough for ordinary clients to\nbootstrap on their personal devices.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 05:55:17 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Kim", "Jae-Yun", ""], ["Lee", "Jun-Mo", ""], ["Koo", "Yeon-Jae", ""], ["Park", "Sang-Hyeon", ""], ["Moon", "Soo-Mook", ""]]}, {"id": "1911.05960", "submitter": "Yiming Cui", "authors": "Yiming Cui, Wei-Nan Zhang, Wanxiang Che, Ting Liu, Zhipeng Chen,\n  Shijin Wang, Guoping Hu", "title": "Contextual Recurrent Units for Cloze-style Reading Comprehension", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNN) are known as powerful models for handling\nsequential data, and especially widely utilized in various natural language\nprocessing tasks. In this paper, we propose Contextual Recurrent Units (CRU)\nfor enhancing local contextual representations in neural networks. The proposed\nCRU injects convolutional neural networks (CNN) into the recurrent units to\nenhance the ability to model the local context and reducing word ambiguities\neven in bi-directional RNNs. We tested our CRU model on sentence-level and\ndocument-level modeling NLP tasks: sentiment classification and reading\ncomprehension. Experimental results show that the proposed CRU model could give\nsignificant improvements over traditional CNN or RNN models, including\nbidirectional conditions, as well as various state-of-the-art systems on both\ntasks, showing its promising future of extensibility to other NLP tasks as\nwell.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 06:33:24 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Cui", "Yiming", ""], ["Zhang", "Wei-Nan", ""], ["Che", "Wanxiang", ""], ["Liu", "Ting", ""], ["Chen", "Zhipeng", ""], ["Wang", "Shijin", ""], ["Hu", "Guoping", ""]]}, {"id": "1911.05978", "submitter": "Pradyumna Narayana", "authors": "Pradyumna Narayana, Aniket Pednekar, Abishek Krishnamoorthy, Kazoo\n  Sone, Sugato Basu", "title": "HUSE: Hierarchical Universal Semantic Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a recent surge of interest in cross-modal representation learning\ncorresponding to images and text. The main challenge lies in mapping images and\ntext to a shared latent space where the embeddings corresponding to a similar\nsemantic concept lie closer to each other than the embeddings corresponding to\ndifferent semantic concepts, irrespective of the modality. Ranking losses are\ncommonly used to create such shared latent space -- however, they do not impose\nany constraints on inter-class relationships resulting in neighboring clusters\nto be completely unrelated. The works in the domain of visual semantic\nembeddings address this problem by first constructing a semantic embedding\nspace based on some external knowledge and projecting image embeddings onto\nthis fixed semantic embedding space. These works are confined only to image\ndomain and constraining the embeddings to a fixed space adds additional burden\non learning. This paper proposes a novel method, HUSE, to learn cross-modal\nrepresentation with semantic information. HUSE learns a shared latent space\nwhere the distance between any two universal embeddings is similar to the\ndistance between their corresponding class embeddings in the semantic embedding\nspace. HUSE also uses a classification objective with a shared classification\nlayer to make sure that the image and text embeddings are in the same shared\nlatent space. Experiments on UPMC Food-101 show our method outperforms previous\nstate-of-the-art on retrieval, hierarchical precision and classification\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 07:45:32 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Narayana", "Pradyumna", ""], ["Pednekar", "Aniket", ""], ["Krishnamoorthy", "Abishek", ""], ["Sone", "Kazoo", ""], ["Basu", "Sugato", ""]]}, {"id": "1911.06003", "submitter": "Shun-Po Chuang", "authors": "Shun-Po Chuang, Tzu-Wei Sung, Hung-Yi Lee", "title": "Training a code-switching language model with monolingual data", "comments": "Accepted as an oral presentation in ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A lack of code-switching data complicates the training of code-switching (CS)\nlanguage models. We propose an approach to train such CS language models on\nmonolingual data only. By constraining and normalizing the output projection\nmatrix in RNN-based language models, we bring embeddings of different languages\ncloser to each other. Numerical and visualization results show that the\nproposed approaches remarkably improve the performance of CS language models\ntrained on monolingual data. The proposed approaches are comparable or even\nbetter than training CS language models with artificially generated CS data. We\nadditionally use unsupervised bilingual word translation to analyze whether\nsemantically equivalent words in different languages are mapped together.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 09:09:10 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 14:40:15 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Chuang", "Shun-Po", ""], ["Sung", "Tzu-Wei", ""], ["Lee", "Hung-Yi", ""]]}, {"id": "1911.06111", "submitter": "Andrew O. Arnold", "authors": "Andrew O. Arnold, William W. Cohen", "title": "Instance-based Transfer Learning for Multilingual Deep Retrieval", "comments": null, "journal-ref": "The Web Conference Workshop on Multilingual Search, 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the problem of search in the multilingual setting. Examining the\nproblems of next-sentence prediction and inverse cloze, we show that at large\nscale, instance-based transfer learning is surprisingly effective in the\nmultilingual setting, leading to positive transfer on all of the 35 target\nlanguages and two tasks tested. We analyze this improvement and argue that the\nmost natural explanation, namely direct vocabulary overlap between languages,\nonly partially explains the performance gains: in fact, we demonstrate\ntarget-language improvement can occur after adding data from an auxiliary\nlanguage even with no vocabulary in common with the target. This surprising\nresult is due to the effect of transitive vocabulary overlaps between pairs of\nauxiliary and target languages.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 22:23:30 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 18:11:37 GMT"}, {"version": "v3", "created": "Thu, 15 Apr 2021 15:22:31 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Arnold", "Andrew O.", ""], ["Cohen", "William W.", ""]]}, {"id": "1911.06118", "submitter": "Jayashree P.", "authors": "P. Jayashree, Ballijepalli Shreya, and P.K. Srijith", "title": "Learning Multi-Sense Word Distributions using Approximate\n  Kullback-Leibler Divergence", "comments": "7 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning word representations has garnered greater attention in the recent\npast due to its diverse text applications. Word embeddings encapsulate the\nsyntactic and semantic regularities of sentences. Modelling word embedding as\nmulti-sense gaussian mixture distributions, will additionally capture\nuncertainty and polysemy of words. We propose to learn the Gaussian mixture\nrepresentation of words using a Kullback-Leibler (KL) divergence based\nobjective function. The KL divergence based energy function provides a better\ndistance metric which can effectively capture entailment and distribution\nsimilarity among the words. Due to the intractability of KL divergence for\nGaussian mixture, we go for a KL approximation between Gaussian mixtures. We\nperform qualitative and quantitative experiments on benchmark word similarity\nand entailment datasets which demonstrate the effectiveness of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 06:59:38 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Jayashree", "P.", ""], ["Shreya", "Ballijepalli", ""], ["Srijith", "P. K.", ""]]}, {"id": "1911.06121", "submitter": "Eduardo Brito", "authors": "Eduardo Brito, Max L\\\"ubbering, David Biesner, Lars Patrick\n  Hillebrand, Christian Bauckhage", "title": "Towards Supervised Extractive Text Summarization via RNN-based Sequence\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article briefly explains our submitted approach to the DocEng'19\ncompetition on extractive summarization. We implemented a recurrent neural\nnetwork based model that learns to classify whether an article's sentence\nbelongs to the corresponding extractive summary or not. We bypass the lack of\nlarge annotated news corpora for extractive summarization by generating\nextractive summaries from abstractive ones, which are available from the CNN\ncorpus.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 15:51:23 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Brito", "Eduardo", ""], ["L\u00fcbbering", "Max", ""], ["Biesner", "David", ""], ["Hillebrand", "Lars Patrick", ""], ["Bauckhage", "Christian", ""]]}, {"id": "1911.06136", "submitter": "Xiaozhi Wang", "authors": "Xiaozhi Wang, Tianyu Gao, Zhaocheng Zhu, Zhengyan Zhang, Zhiyuan Liu,\n  Juanzi Li, Jian Tang", "title": "KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language\n  Representation", "comments": "Accepted to TACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language representation models (PLMs) cannot well capture factual\nknowledge from text. In contrast, knowledge embedding (KE) methods can\neffectively represent the relational facts in knowledge graphs (KGs) with\ninformative entity embeddings, but conventional KE models cannot take full\nadvantage of the abundant textual information. In this paper, we propose a\nunified model for Knowledge Embedding and Pre-trained LanguagE Representation\n(KEPLER), which can not only better integrate factual knowledge into PLMs but\nalso produce effective text-enhanced KE with the strong PLMs. In KEPLER, we\nencode textual entity descriptions with a PLM as their embeddings, and then\njointly optimize the KE and language modeling objectives. Experimental results\nshow that KEPLER achieves state-of-the-art performances on various NLP tasks,\nand also works remarkably well as an inductive KE model on KG link prediction.\nFurthermore, for pre-training and evaluating KEPLER, we construct Wikidata5M, a\nlarge-scale KG dataset with aligned entity descriptions, and benchmark\nstate-of-the-art KE methods on it. It shall serve as a new KE benchmark and\nfacilitate the research on large KG, inductive KE, and KG with text. The source\ncode can be obtained from https://github.com/THU-KEG/KEPLER.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 05:21:45 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 07:46:52 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2020 12:31:05 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Wang", "Xiaozhi", ""], ["Gao", "Tianyu", ""], ["Zhu", "Zhaocheng", ""], ["Zhang", "Zhengyan", ""], ["Liu", "Zhiyuan", ""], ["Li", "Juanzi", ""], ["Tang", "Jian", ""]]}, {"id": "1911.06137", "submitter": "Yu Cao", "authors": "Yu Cao, Meng Fang, Baosheng Yu, Joey Tianyi Zhou", "title": "Unsupervised Domain Adaptation on Reading Comprehension", "comments": "8 pages, 6 figures, 5 tables, Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reading comprehension (RC) has been studied in a variety of datasets with the\nboosted performance brought by deep neural networks. However, the\ngeneralization capability of these models across different domains remains\nunclear. To alleviate this issue, we are going to investigate unsupervised\ndomain adaptation on RC, wherein a model is trained on labeled source domain\nand to be applied to the target domain with only unlabeled samples. We first\nshow that even with the powerful BERT contextual representation, the\nperformance is still unsatisfactory when the model trained on one dataset is\ndirectly applied to another target dataset. To solve this, we provide a novel\nconditional adversarial self-training method (CASe). Specifically, our approach\nleverages a BERT model fine-tuned on the source dataset along with the\nconfidence filtering to generate reliable pseudo-labeled samples in the target\ndomain for self-training. On the other hand, it further reduces domain\ndistribution discrepancy through conditional adversarial learning across\ndomains. Extensive experiments show our approach achieves comparable accuracy\nto supervised models on multiple large-scale benchmark datasets.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 00:54:39 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 02:19:15 GMT"}, {"version": "v3", "created": "Sat, 25 Jan 2020 10:59:15 GMT"}, {"version": "v4", "created": "Thu, 7 May 2020 09:37:36 GMT"}, {"version": "v5", "created": "Mon, 27 Jul 2020 02:44:59 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Cao", "Yu", ""], ["Fang", "Meng", ""], ["Yu", "Baosheng", ""], ["Zhou", "Joey Tianyi", ""]]}, {"id": "1911.06146", "submitter": "Sendong Zhao", "authors": "Sendong Zhao, Fei Wang", "title": "Biomedical Evidence Generation Engine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of precision medicine, a large amount of health\ndata (such as electronic health records, gene sequencing, medical images, etc.)\nhas been produced. It encourages more and more interest in data-driven insight\ndiscovery from these data. It is a reasonable way to verify the derived\ninsights in biomedical literature. However, manual verification is inefficient\nand not scalable. Therefore, an intelligent technique is necessary to solve\nthis problem. In this paper, we propose a task of biomedical evidence\ngeneration, which is very novel and different from existing NLP tasks.\nFurthermore, we developed a biomedical evidence generation engine for this task\nwith the pipeline of three components which are a literature retrieval module,\na skeleton information identification module, and a text summarization module.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 23:10:15 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 22:22:18 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Zhao", "Sendong", ""], ["Wang", "Fei", ""]]}, {"id": "1911.06147", "submitter": "Sergio Gast\\'on Burdisso", "authors": "Sergio G. Burdisso, Marcelo Errecalde, Manuel Montes-y-G\\'omez", "title": "t-SS3: a text classifier with dynamic n-grams for early risk detection\n  over text streams", "comments": "Highlights: (*) A classifier that is able to dynamically learn and\n  recognize important word n-grams. (*) A novel text classifier having the\n  ability to visually explain its rationale. (*) Support for incremental\n  learning and text classification over streams. (*) Efficient model for\n  addressing early risk detection problems", "journal-ref": "Pattern Recognition Letters, Elsevier, 2020", "doi": "10.1016/j.patrec.2020.07.001", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recently introduced classifier, called SS3, has shown to be well suited to\ndeal with early risk detection (ERD) problems on text streams. It obtained\nstate-of-the-art performance on early depression and anorexia detection on\nReddit in the CLEF's eRisk open tasks. SS3 was created to deal with ERD\nproblems naturally since: it supports incremental training and classification\nover text streams, and it can visually explain its rationale. However, SS3\nprocesses the input using a bag-of-word model lacking the ability to recognize\nimportant word sequences. This aspect could negatively affect the\nclassification performance and also reduces the descriptiveness of visual\nexplanations. In the standard document classification field, it is very common\nto use word n-grams to try to overcome some of these limitations.\nUnfortunately, when working with text streams, using n-grams is not trivial\nsince the system must learn and recognize which n-grams are important \"on the\nfly\". This paper introduces t-SS3, an extension of SS3 that allows it to\nrecognize useful patterns over text streams dynamically. We evaluated our model\nin the eRisk 2017 and 2018 tasks on early depression and anorexia detection.\nExperimental results suggest that t-SS3 is able to improve both current results\nand the richness of visual explanations.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 22:06:40 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 23:04:03 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Burdisso", "Sergio G.", ""], ["Errecalde", "Marcelo", ""], ["Montes-y-G\u00f3mez", "Manuel", ""]]}, {"id": "1911.06149", "submitter": "Tae-Ho Kim", "authors": "Tae-Ho Kim, Sungjae Cho, Shinkook Choi, Sejik Park and Soo-Young Lee", "title": "Emotional Voice Conversion using Multitask Learning with Text-to-speech", "comments": "4 pages, 3 figures, submitted to ICASSP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice conversion (VC) is a task to transform a person's voice to different\nstyle while conserving linguistic contents. Previous state-of-the-art on VC is\nbased on sequence-to-sequence (seq2seq) model, which could mislead linguistic\ninformation. There was an attempt to overcome it by using textual supervision,\nit requires explicit alignment which loses the benefit of using seq2seq model.\nIn this paper, a voice converter using multitask learning with text-to-speech\n(TTS) is presented. The embedding space of seq2seq-based TTS has abundant\ninformation on the text. The role of the decoder of TTS is to convert embedding\nspace to speech, which is same to VC. In the proposed model, the whole network\nis trained to minimize loss of VC and TTS. VC is expected to capture more\nlinguistic information and to preserve training stability by multitask\nlearning. Experiments of VC were performed on a male Korean emotional\ntext-speech dataset, and it is shown that multitask learning is helpful to keep\nlinguistic contents in VC.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 19:53:58 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 08:17:13 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Kim", "Tae-Ho", ""], ["Cho", "Sungjae", ""], ["Choi", "Shinkook", ""], ["Park", "Sejik", ""], ["Lee", "Soo-Young", ""]]}, {"id": "1911.06154", "submitter": "Ahmed El-Kishky", "authors": "Ahmed El-Kishky, Vishrav Chaudhary, Francisco Guzman, Philipp Koehn", "title": "CCAligned: A Massive Collection of Cross-Lingual Web-Document Pairs", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual document alignment aims to identify pairs of documents in two\ndistinct languages that are of comparable content or translations of each\nother. In this paper, we exploit the signals embedded in URLs to label web\ndocuments at scale with an average precision of 94.5% across different language\npairs. We mine sixty-eight snapshots of the Common Crawl corpus and identify\nweb document pairs that are translations of each other. We release a new web\ndataset consisting of over 392 million URL pairs from Common Crawl covering\ndocuments in 8144 language pairs of which 137 pairs include English. In\naddition to curating this massive dataset, we introduce baseline methods that\nleverage cross-lingual representations to identify aligned documents based on\ntheir textual content. Finally, we demonstrate the value of this parallel\ndocuments dataset through a downstream task of mining parallel sentences and\nmeasuring the quality of machine translations from models trained on this mined\ndata. Our objective in releasing this dataset is to foster new research in\ncross-lingual NLP across a variety of low, medium, and high-resource languages.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 02:09:11 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 06:00:35 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["El-Kishky", "Ahmed", ""], ["Chaudhary", "Vishrav", ""], ["Guzman", "Francisco", ""], ["Koehn", "Philipp", ""]]}, {"id": "1911.06155", "submitter": "Jianmin Guo", "authors": "Jianmin Guo, Yue Zhao, Quan Zhang, Yu Jiang", "title": "RNN-Test: Towards Adversarial Testing for Recurrent Neural Network\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While massive efforts have been investigated in adversarial testing of\nconvolutional neural networks (CNN), testing for recurrent neural networks\n(RNN) is still limited and leaves threats for vast sequential application\ndomains. In this paper, we propose an adversarial testing framework RNN-Test\nfor RNN systems, focusing on the main sequential domains, not only\nclassification tasks. First, we design a novel search methodology customized\nfor RNN models by maximizing the inconsistency of RNN states to produce\nadversarial inputs. Next, we introduce two state-based coverage metrics\naccording to the distinctive structure of RNNs to explore more inference\nlogics. Finally, RNN-Test solves the joint optimization problem to maximize\nstate inconsistency and state coverage, and crafts adversarial inputs for\nvarious tasks of different kinds of inputs.\n  For evaluations, we apply RNN-Test on three sequential models of common RNN\nstructures. On the tested models, the RNN-Test approach is demonstrated to be\ncompetitive in generating adversarial inputs, outperforming FGSM-based and\nDLFuzz-based methods to reduce the model performance more sharply with 2.78% to\n32.5% higher success (or generation) rate. RNN-Test could also achieve 52.65%\nto 66.45% higher adversary rate on MNIST-LSTM model than relevant work testRNN.\nCompared with the neuron coverage, the proposed state coverage metrics as\nguidance excel with 4.17% to 97.22% higher success (or generation) rate.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 05:30:53 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 03:28:00 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Guo", "Jianmin", ""], ["Zhao", "Yue", ""], ["Zhang", "Quan", ""], ["Jiang", "Yu", ""]]}, {"id": "1911.06156", "submitter": "Dhanasekar Sundararaman", "authors": "Dhanasekar Sundararaman, Vivek Subramanian, Guoyin Wang, Shijing Si,\n  Dinghan Shen, Dong Wang, Lawrence Carin", "title": "Syntax-Infused Transformer and BERT models for Machine Translation and\n  Natural Language Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based models have shown significant improvement over traditional\nalgorithms in several NLP tasks. The Transformer, for instance, is an\nillustrative example that generates abstract representations of tokens inputted\nto an encoder based on their relationships to all tokens in a sequence. Recent\nstudies have shown that although such models are capable of learning syntactic\nfeatures purely by seeing examples, explicitly feeding this information to deep\nlearning models can significantly enhance their performance. Leveraging\nsyntactic information like part of speech (POS) may be particularly beneficial\nin limited training data settings for complex models such as the Transformer.\nWe show that the syntax-infused Transformer with multiple features achieves an\nimprovement of 0.7 BLEU when trained on the full WMT 14 English to German\ntranslation dataset and a maximum improvement of 1.99 BLEU points when trained\non a fraction of the dataset. In addition, we find that the incorporation of\nsyntax into BERT fine-tuning outperforms baseline on a number of downstream\ntasks from the GLUE benchmark.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 04:42:13 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Sundararaman", "Dhanasekar", ""], ["Subramanian", "Vivek", ""], ["Wang", "Guoyin", ""], ["Si", "Shijing", ""], ["Shen", "Dinghan", ""], ["Wang", "Dong", ""], ["Carin", "Lawrence", ""]]}, {"id": "1911.06161", "submitter": "Qianhui Wu", "authors": "Qianhui Wu, Zijia Lin, Guoxin Wang, Hui Chen, B\\\"orje F. Karlsson,\n  Biqing Huang, Chin-Yew Lin", "title": "Enhanced Meta-Learning for Cross-lingual Named Entity Recognition with\n  Minimal Resources", "comments": "This paper is accepted by AAAI2020. Code is available at\n  https://github.com/microsoft/vert-papers/tree/master/papers/Meta-Cross", "journal-ref": "In AAAI, pages 9274-9281, 2020", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For languages with no annotated resources, transferring knowledge from\nrich-resource languages is an effective solution for named entity recognition\n(NER). While all existing methods directly transfer from source-learned model\nto a target language, in this paper, we propose to fine-tune the learned model\nwith a few similar examples given a test case, which could benefit the\nprediction by leveraging the structural and semantic information conveyed in\nsuch similar examples. To this end, we present a meta-learning algorithm to\nfind a good model parameter initialization that could fast adapt to the given\ntest case and propose to construct multiple pseudo-NER tasks for meta-training\nby computing sentence similarities. To further improve the model's\ngeneralization ability across different languages, we introduce a masking\nscheme and augment the loss function with an additional maximum term during\nmeta-training. We conduct extensive experiments on cross-lingual named entity\nrecognition with minimal resources over five target languages. The results show\nthat our approach significantly outperforms existing state-of-the-art methods\nacross the board.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 15:01:15 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 14:17:02 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Wu", "Qianhui", ""], ["Lin", "Zijia", ""], ["Wang", "Guoxin", ""], ["Chen", "Hui", ""], ["Karlsson", "B\u00f6rje F.", ""], ["Huang", "Biqing", ""], ["Lin", "Chin-Yew", ""]]}, {"id": "1911.06171", "submitter": "Yuanxin Liu", "authors": "Yuanxin Liu and Zheng Lin", "title": "Unsupervised Pre-training for Natural Language Generation: A Literature\n  Review", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, unsupervised pre-training is gaining increasing popularity in the\nrealm of computational linguistics, thanks to its surprising success in\nadvancing natural language understanding (NLU) and the potential to effectively\nexploit large-scale unlabelled corpus. However, regardless of the success in\nNLU, the power of unsupervised pre-training is only partially excavated when it\ncomes to natural language generation (NLG). The major obstacle stems from an\nidiosyncratic nature of NLG: Texts are usually generated based on certain\ncontext, which may vary with the target applications. As a result, it is\nintractable to design a universal architecture for pre-training as in NLU\nscenarios. Moreover, retaining the knowledge learned from pre-training when\nlearning on the target task is also a non-trivial problem. This review\nsummarizes the recent efforts to enhance NLG systems with unsupervised\npre-training, with a special focus on the methods to catalyse the integration\nof pre-trained models into downstream tasks. They are classified into\narchitecture-based methods and strategy-based methods, based on their way of\nhandling the above obstacle. Discussions are also provided to give further\ninsights into the relationship between these two lines of work, some\ninformative empirical phenomenons, as well as some possible directions where\nfuture work can be devoted to.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 16:09:59 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Liu", "Yuanxin", ""], ["Lin", "Zheng", ""]]}, {"id": "1911.06172", "submitter": "Michael Stewart", "authors": "Michael Stewart, Wei Liu and Rachel Cardell-Oliver", "title": "Word-level Lexical Normalisation using Context-Dependent Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexical normalisation (LN) is the process of correcting each word in a\ndataset to its canonical form so that it may be more easily and more accurately\nanalysed. Most lexical normalisation systems operate at the character-level,\nwhile word-level models are seldom used. Recent language models offer solutions\nto the drawbacks of word-level LN models, yet, to the best of our knowledge, no\nresearch has investigated their effectiveness on LN. In this paper we introduce\na word-level GRU-based LN model and investigate the effectiveness of recent\nembedding techniques on word-level LN. Our results show that our GRU-based\nword-level model produces greater results than character-level models, and\noutperforms existing deep-learning based LN techniques on Twitter data. We also\nfind that randomly-initialised embeddings are capable of outperforming\npre-trained embedding models in certain scenarios. Finally, we release a\nsubstantial lexical normalisation dataset to the community.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 14:42:55 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Stewart", "Michael", ""], ["Liu", "Wei", ""], ["Cardell-Oliver", "Rachel", ""]]}, {"id": "1911.06182", "submitter": "Itzik Malkiel", "authors": "Itzik Malkiel, Lior Wolf", "title": "MML: Maximal Multiverse Learning for Robust Fine-Tuning of Language\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent state-of-the-art language models utilize a two-phase training\nprocedure comprised of (i) unsupervised pre-training on unlabeled text, and\n(ii) fine-tuning for a specific supervised task. More recently, many studies\nhave been focused on trying to improve these models by enhancing the\npre-training phase, either via better choice of hyperparameters or by\nleveraging an improved formulation. However, the pre-training phase is\ncomputationally expensive and often done on private datasets. In this work, we\npresent a method that leverages BERT's fine-tuning phase to its fullest, by\napplying an extensive number of parallel classifier heads, which are enforced\nto be orthogonal, while adaptively eliminating the weaker heads during\ntraining. Our method allows the model to converge to an optimal number of\nparallel classifiers, depending on the given dataset at hand.\n  We conduct an extensive inter- and intra-dataset evaluations, showing that\nour method improves the robustness of BERT, sometimes leading to a +9\\% gain in\naccuracy. These results highlight the importance of a proper fine-tuning\nprocedure, especially for relatively smaller-sized datasets. Our code is\nattached as supplementary and our models will be made completely public.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 21:21:40 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Malkiel", "Itzik", ""], ["Wolf", "Lior", ""]]}, {"id": "1911.06191", "submitter": "Yingce Xia", "authors": "Yingce Xia, Xu Tan, Fei Tian, Fei Gao, Weicong Chen, Yang Fan, Linyuan\n  Gong, Yichong Leng, Renqian Luo, Yiren Wang, Lijun Wu, Jinhua Zhu, Tao Qin,\n  Tie-Yan Liu", "title": "Microsoft Research Asia's Systems for WMT19", "comments": "Accepted to \"Fourth Conference on Machine Translation (WMT19)\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We Microsoft Research Asia made submissions to 11 language directions in the\nWMT19 news translation tasks. We won the first place for 8 of the 11 directions\nand the second place for the other three. Our basic systems are built on\nTransformer, back translation and knowledge distillation. We integrate several\nof our rececent techniques to enhance the baseline systems: multi-agent dual\nlearning (MADL), masked sequence-to-sequence pre-training (MASS), neural\narchitecture optimization (NAO), and soft contextual data augmentation (SCA).\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 03:55:53 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Xia", "Yingce", ""], ["Tan", "Xu", ""], ["Tian", "Fei", ""], ["Gao", "Fei", ""], ["Chen", "Weicong", ""], ["Fan", "Yang", ""], ["Gong", "Linyuan", ""], ["Leng", "Yichong", ""], ["Luo", "Renqian", ""], ["Wang", "Yiren", ""], ["Wu", "Lijun", ""], ["Zhu", "Jinhua", ""], ["Qin", "Tao", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1911.06192", "submitter": "Li Zhou", "authors": "Li Zhou and Kevin Small", "title": "Multi-domain Dialogue State Tracking as Dynamic Knowledge Graph Enhanced\n  Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-domain dialogue state tracking (DST) is a critical component for\nconversational AI systems. The domain ontology (i.e., specification of domains,\nslots, and values) of a conversational AI system is generally incomplete,\nmaking the capability for DST models to generalize to new slots, values, and\ndomains during inference imperative. In this paper, we propose to model\nmulti-domain DST as a question answering problem, referred to as Dialogue State\nTracking via Question Answering (DSTQA). Within DSTQA, each turn generates a\nquestion asking for the value of a (domain, slot) pair, thus making it\nnaturally extensible to unseen domains, slots, and values. Additionally, we use\na dynamically-evolving knowledge graph to explicitly learn relationships\nbetween (domain, slot) pairs. Our model has a 5.80% and 12.21% relative\nimprovement over the current state-of-the-art model on MultiWOZ 2.0 and\nMultiWOZ 2.1 datasets, respectively. Additionally, our model consistently\noutperforms the state-of-the-art model in domain adaptation settings. (Code is\nreleased at https://github.com/alexa/dstqa )\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 10:00:16 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 21:07:14 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Zhou", "Li", ""], ["Small", "Kevin", ""]]}, {"id": "1911.06194", "submitter": "Xisen Jin", "authors": "Xisen Jin, Zhongyu Wei, Junyi Du, Xiangyang Xue, Xiang Ren", "title": "Towards Hierarchical Importance Attribution: Explaining Compositional\n  Semantics for Neural Sequence Models", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impressive performance of neural networks on natural language processing\ntasks attributes to their ability to model complicated word and phrase\ncompositions. To explain how the model handles semantic compositions, we study\nhierarchical explanation of neural network predictions. We identify\nnon-additivity and context independent importance attributions within\nhierarchies as two desirable properties for highlighting word and phrase\ncompositions. We show some prior efforts on hierarchical explanations, e.g.\ncontextual decomposition, do not satisfy the desired properties mathematically,\nleading to inconsistent explanation quality in different models. In this paper,\nwe start by proposing a formal and general way to quantify the importance of\neach word and phrase. Following the formulation, we propose Sampling and\nContextual Decomposition (SCD) algorithm and Sampling and Occlusion (SOC)\nalgorithm. Human and metrics evaluation on both LSTM models and BERT\nTransformer models on multiple datasets show that our algorithms outperform\nprior hierarchical explanation algorithms. Our algorithms help to visualize\nsemantic composition captured by models, extract classification rules and\nimprove human trust of models. Project page: https://inklab.usc.edu/hiexpl/\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 03:25:04 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 05:47:05 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Jin", "Xisen", ""], ["Wei", "Zhongyu", ""], ["Du", "Junyi", ""], ["Xue", "Xiangyang", ""], ["Ren", "Xiang", ""]]}, {"id": "1911.06197", "submitter": "Vivian Chou", "authors": "Vivian T. Chou, LeAnna Kent, Joel A. G\\'ongora, Sam Ballerini, Carl D.\n  Hoover", "title": "Towards automatic extractive text summarization of A-133 Single Audit\n  reports with machine learning", "comments": "8 pages, first version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth of text data has motivated the development of\nmachine-learning based automatic text summarization strategies that concisely\ncapture the essential ideas in a larger text. This study aimed to devise an\nextractive summarization method for A-133 Single Audits, which assess if\nrecipients of federal grants are compliant with program requirements for use of\nfederal funding. Currently, these voluminous audits must be manually analyzed\nby officials for oversight, risk management, and prioritization purposes.\nAutomated summarization has the potential to streamline these processes.\nAnalysis focused on the \"Findings\" section of ~20,000 Single Audits spanning\n2016-2018. Following text preprocessing and GloVe embedding, sentence-level\nk-means clustering was performed to partition sentences by topic and to\nestablish the importance of each sentence. For each audit, key summary\nsentences were extracted by proximity to cluster centroids. Summaries were\njudged by non-expert human evaluation and compared to human-generated summaries\nusing the ROUGE metric. Though the goal was to fully automate summarization of\nA-133 audits, human input was required at various stages due to large\nvariability in audit writing style, content, and context. Examples of human\ninputs include the number of clusters, the choice to keep or discard certain\nclusters based on their content relevance, and the definition of a top\nsentence. Overall, this approach made progress towards automated extractive\nsummaries of A-133 audits, with future work to focus on full automation and\nimproving summary consistency. This work highlights the inherent difficulty and\nsubjective nature of automated summarization in a real-world application.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 14:49:25 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Chou", "Vivian T.", ""], ["Kent", "LeAnna", ""], ["G\u00f3ngora", "Joel A.", ""], ["Ballerini", "Sam", ""], ["Hoover", "Carl D.", ""]]}, {"id": "1911.06241", "submitter": "Xiaolei Lu", "authors": "Xiaolei Lu and Bin Ni", "title": "BERT-CNN: a Hierarchical Patent Classifier Based on a Pre-Trained\n  Language Model", "comments": "in Chinese", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automatic classification is a process of automatically assigning text\ndocuments to predefined categories. An accurate automatic patent classifier is\ncrucial to patent inventors and patent examiners in terms of intellectual\nproperty protection, patent management, and patent information retrieval. We\npresent BERT-CNN, a hierarchical patent classifier based on pre-trained\nlanguage model by training the national patent application documents collected\nfrom the State Information Center, China. The experimental results show that\nBERT-CNN achieves 84.3% accuracy, which is far better than the two compared\nbaseline methods, Convolutional Neural Networks and Recurrent Neural Networks.\nWe didn't apply our model to the third and fourth hierarchical level of the\nInternational Patent Classification - \"subclass\" and \"group\".The visualization\nof the Attention Mechanism shows that BERT-CNN obtains new state-of-the-art\nresults in representing vocabularies and semantics. This article demonstrates\nthe practicality and effectiveness of BERT-CNN in the field of automatic patent\nclassification.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 07:21:41 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Lu", "Xiaolei", ""], ["Ni", "Bin", ""]]}, {"id": "1911.06258", "submitter": "Ronghang Hu", "authors": "Ronghang Hu, Amanpreet Singh, Trevor Darrell, Marcus Rohrbach", "title": "Iterative Answer Prediction with Pointer-Augmented Multimodal\n  Transformers for TextVQA", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many visual scenes contain text that carries crucial information, and it is\nthus essential to understand text in images for downstream reasoning tasks. For\nexample, a deep water label on a warning sign warns people about the danger in\nthe scene. Recent work has explored the TextVQA task that requires reading and\nunderstanding text in images to answer a question. However, existing approaches\nfor TextVQA are mostly based on custom pairwise fusion mechanisms between a\npair of two modalities and are restricted to a single prediction step by\ncasting TextVQA as a classification task. In this work, we propose a novel\nmodel for the TextVQA task based on a multimodal transformer architecture\naccompanied by a rich representation for text in images. Our model naturally\nfuses different modalities homogeneously by embedding them into a common\nsemantic space where self-attention is applied to model inter- and intra-\nmodality context. Furthermore, it enables iterative answer decoding with a\ndynamic pointer network, allowing the model to form an answer through\nmulti-step prediction instead of one-step classification. Our model outperforms\nexisting approaches on three benchmark datasets for the TextVQA task by a large\nmargin.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 17:32:10 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 07:41:07 GMT"}, {"version": "v3", "created": "Tue, 24 Mar 2020 23:59:59 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Hu", "Ronghang", ""], ["Singh", "Amanpreet", ""], ["Darrell", "Trevor", ""], ["Rohrbach", "Marcus", ""]]}, {"id": "1911.06311", "submitter": "\\c{C}a\\u{g}atay Demiralp", "authors": "Dan Zhang and Yoshihiko Suhara and Jinfeng Li and Madelon Hulsebos and\n  \\c{C}a\\u{g}atay Demiralp and Wang-Chiew Tan", "title": "Sato: Contextual Semantic Type Detection in Tables", "comments": "VLDB'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting the semantic types of data columns in relational tables is\nimportant for various data preparation and information retrieval tasks such as\ndata cleaning, schema matching, data discovery, and semantic search. However,\nexisting detection approaches either perform poorly with dirty data, support\nonly a limited number of semantic types, fail to incorporate the table context\nof columns or rely on large sample sizes for training data. We introduce Sato,\na hybrid machine learning model to automatically detect the semantic types of\ncolumns in tables, exploiting the signals from the context as well as the\ncolumn values. Sato combines a deep learning model trained on a large-scale\ntable corpus with topic modeling and structured prediction to achieve\nsupport-weighted and macro average F1 scores of 0.925 and 0.735, respectively,\nexceeding the state-of-the-art performance by a significant margin. We\nextensively analyze the overall and per-type performance of Sato, discussing\nhow individual modeling components, as well as feature categories, contribute\nto its performance.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 18:51:59 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 03:47:14 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 04:54:28 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Zhang", "Dan", ""], ["Suhara", "Yoshihiko", ""], ["Li", "Jinfeng", ""], ["Hulsebos", "Madelon", ""], ["Demiralp", "\u00c7a\u011fatay", ""], ["Tan", "Wang-Chiew", ""]]}, {"id": "1911.06352", "submitter": "Jingjing Pan", "authors": "Jingjing Pan, Yash Goyal, Stefan Lee", "title": "Question-Conditioned Counterfactual Image Generation for VQA", "comments": "Accepted by the VQA Workshop at CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Visual Question Answering (VQA) models continue to push the\nstate-of-the-art forward, they largely remain black-boxes - failing to provide\ninsight into how or why an answer is generated. In this ongoing work, we\npropose addressing this shortcoming by learning to generate counterfactual\nimages for a VQA model - i.e. given a question-image pair, we wish to generate\na new image such that i) the VQA model outputs a different answer, ii) the new\nimage is minimally different from the original, and iii) the new image is\nrealistic. Our hope is that providing such counterfactual examples allows users\nto investigate and understand the VQA model's internal mechanisms.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 19:37:33 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Pan", "Jingjing", ""], ["Goyal", "Yash", ""], ["Lee", "Stefan", ""]]}, {"id": "1911.06394", "submitter": "Seokhwan Kim", "authors": "Seokhwan Kim, Michel Galley, Chulaka Gunasekara, Sungjin Lee, Adam\n  Atkinson, Baolin Peng, Hannes Schulz, Jianfeng Gao, Jinchao Li, Mahmoud\n  Adada, Minlie Huang, Luis Lastras, Jonathan K. Kummerfeld, Walter S. Lasecki,\n  Chiori Hori, Anoop Cherian, Tim K. Marks, Abhinav Rastogi, Xiaoxue Zang,\n  Srinivas Sunkara, Raghav Gupta", "title": "The Eighth Dialog System Technology Challenge", "comments": "Submitted to NeurIPS 2019 3rd Conversational AI Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the Eighth Dialog System Technology Challenge. In line\nwith recent challenges, the eighth edition focuses on applying end-to-end\ndialog technologies in a pragmatic way for multi-domain task-completion, noetic\nresponse selection, audio visual scene-aware dialog, and schema-guided dialog\nstate tracking tasks. This paper describes the task definition, provided\ndatasets, and evaluation set-up for each track. We also summarize the results\nof the submitted systems to highlight the overall trends of the\nstate-of-the-art technologies for the tasks.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 21:42:48 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Kim", "Seokhwan", ""], ["Galley", "Michel", ""], ["Gunasekara", "Chulaka", ""], ["Lee", "Sungjin", ""], ["Atkinson", "Adam", ""], ["Peng", "Baolin", ""], ["Schulz", "Hannes", ""], ["Gao", "Jianfeng", ""], ["Li", "Jinchao", ""], ["Adada", "Mahmoud", ""], ["Huang", "Minlie", ""], ["Lastras", "Luis", ""], ["Kummerfeld", "Jonathan K.", ""], ["Lasecki", "Walter S.", ""], ["Hori", "Chiori", ""], ["Cherian", "Anoop", ""], ["Marks", "Tim K.", ""], ["Rastogi", "Abhinav", ""], ["Zang", "Xiaoxue", ""], ["Sunkara", "Srinivas", ""], ["Gupta", "Raghav", ""]]}, {"id": "1911.06415", "submitter": "Max Raphael Sobroza Marques", "authors": "Max Raphael Sobroza, Tales Marra, Deok-Hee Kim-Dufor, Claude Berrou", "title": "Sparse associative memory based on contextual code learning for\n  disambiguating word senses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent literature, contextual pretrained Language Models (LMs)\ndemonstrated their potential in generalizing the knowledge to several Natural\nLanguage Processing (NLP) tasks including supervised Word Sense Disambiguation\n(WSD), a challenging problem in the field of Natural Language Understanding\n(NLU). However, word representations from these models are still very dense,\ncostly in terms of memory footprint, as well as minimally interpretable. In\norder to address such issues, we propose a new supervised biologically inspired\ntechnique for transferring large pre-trained language model representations\ninto a compressed representation, for the case of WSD. Our produced\nrepresentation contributes to increase the general interpretability of the\nframework and to decrease memory footprint, while enhancing performance.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 23:31:02 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Sobroza", "Max Raphael", ""], ["Marra", "Tales", ""], ["Kim-Dufor", "Deok-Hee", ""], ["Berrou", "Claude", ""]]}, {"id": "1911.06488", "submitter": "Son Doan <", "authors": "Son Doan, Elly W Yang, Sameer Tilak, Manabu Torii", "title": "Using natural language processing to extract health-related causality\n  from Twitter messages", "comments": "5 pages", "journal-ref": "2018 IEEE International Conference on Healthcare Informatics\n  Workshop", "doi": "10.1109/ICHI-W.2018.00031", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Twitter messages (tweets) contain various types of information, which include\nhealth-related information. Analysis of health-related tweets would help us\nunderstand health conditions and concerns encountered in our daily life. In\nthis work, we evaluated an approach to extracting causal relations from tweets\nusing natural language processing (NLP) techniques. We focused on three\nhealth-related topics: stress\", \"insomnia\", and \"headache\". We proposed a set\nof lexico-syntactic patterns based on dependency parser outputs to extract\ncausal information. A large dataset consisting of 24 million tweets were used.\nThe results show that our approach achieved an average precision between 74.59%\nand 92.27%. Analysis of extracted relations revealed interesting findings about\nhealth-related in Twitter.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 06:30:25 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Doan", "Son", ""], ["Yang", "Elly W", ""], ["Tilak", "Sameer", ""], ["Torii", "Manabu", ""]]}, {"id": "1911.06489", "submitter": "Yanjie Gou", "authors": "Yanjie Gou, Yinjie Lei, Lingqiao Liu, Pingping Zhang, Xi Peng", "title": "Improving Distant Supervised Relation Extraction by Dynamic Neural\n  Network", "comments": "29 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distant Supervised Relation Extraction (DSRE) is usually formulated as a\nproblem of classifying a bag of sentences that contain two query entities, into\nthe predefined relation classes. Most existing methods consider those relation\nclasses as distinct semantic categories while ignoring their potential\nconnection to query entities. In this paper, we propose to leverage this\nconnection to improve the relation extraction accuracy. Our key ideas are\ntwofold: (1) For sentences belonging to the same relation class, the expression\nstyle, i.e. words choice, can vary according to the query entities. To account\nfor this style shift, the model should adjust its parameters in accordance with\nentity types. (2) Some relation classes are semantically similar, and the\nentity types appear in one relation may also appear in others. Therefore, it\ncan be trained cross different relation classes and further enhance those\nclasses with few samples, i.e., long-tail classes. To unify these two\narguments, we developed a novel Dynamic Neural Network for Relation Extraction\n(DNNRE). The network adopts a novel dynamic parameter generator that\ndynamically generates the network parameters according to the query entity\ntypes and relation classes. By using this mechanism, the network can\nsimultaneously handle the style shift problem and enhance the prediction\naccuracy for long-tail classes. Through our experimental study, we demonstrate\nthe effectiveness of the proposed method and show that it can achieve superior\nperformance over the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 06:31:13 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 04:29:41 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Gou", "Yanjie", ""], ["Lei", "Yinjie", ""], ["Liu", "Lingqiao", ""], ["Zhang", "Pingping", ""], ["Peng", "Xi", ""]]}, {"id": "1911.06573", "submitter": "Juliette Millet", "authors": "Maud Parrot and Juliette Millet and Ewan Dunbar", "title": "Independent and automatic evaluation of acoustic-to-articulatory\n  inversion models", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstruction of articulatory trajectories from the acoustic speech signal\nhas been proposed for improving speech recognition and text-to-speech\nsynthesis. However, to be useful in these settings, articulatory reconstruction\nmust be speaker independent. Furthermore, as most research focuses on single,\nsmall datasets with few speakers, robust articulatory reconstrucion could\nprofit from combining datasets. Standard evaluation measures such as root mean\nsquare error and Pearson correlation are inappropriate for evaluating the\nspeaker-independence of models or the usefulness of combining datasets. We\npresent a new evaluation for articulatory reconstruction which is independent\nof the articulatory data set used for training: the phone discrimination ABX\ntask. We use the ABX measure to evaluate a Bi-LSTM based model trained on 3\ndatasets (14 speakers), and show that it gives information complementary to the\nstandard measures, and enables us to evaluate the effects of dataset merging,\nas well as the speaker independence of the model.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 11:33:50 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Parrot", "Maud", ""], ["Millet", "Juliette", ""], ["Dunbar", "Ewan", ""]]}, {"id": "1911.06602", "submitter": "Toby St Clere Smithe", "authors": "Toby B. St Clere Smithe", "title": "Radically Compositional Cognitive Concepts", "comments": "6 pages, 2 figures; NeurIPS 2019 Context and Compositionality\n  workshop. Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.CL cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite ample evidence that our concepts, our cognitive architecture, and\nmathematics itself are all deeply compositional, few models take advantage of\nthis structure. We therefore propose a radically compositional approach to\ncomputational neuroscience, drawing on the methods of applied category theory.\nWe describe how these tools grant us a means to overcome complexity and improve\ninterpretability, and supply a rigorous common language for scientific\nmodelling, analogous to the type theories of computer science. As a case study,\nwe sketch how to translate from compositional narrative concepts to neural\ncircuits and back again.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 18:20:36 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Smithe", "Toby B. St Clere", ""]]}, {"id": "1911.06603", "submitter": "Pavel Karpov Dr", "authors": "Pavel Karpov and Guillaume Godin and Igor V. Tetko", "title": "Transformer-CNN: Fast and Reliable tool for QSAR", "comments": null, "journal-ref": null, "doi": "10.1186/s13321-020-00423-w", "report-no": null, "categories": "q-bio.QM cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present SMILES-embeddings derived from the internal encoder state of a\nTransformer [1] model trained to canonize SMILES as a Seq2Seq problem. Using a\nCharNN [2] architecture upon the embeddings results in higher quality\ninterpretable QSAR/QSPR models on diverse benchmark datasets including\nregression and classification tasks. The proposed Transformer-CNN method uses\nSMILES augmentation for training and inference, and thus the prognosis is based\non an internal consensus. That both the augmentation and transfer learning are\nbased on embeddings allows the method to provide good results for small\ndatasets. We discuss the reasons for such effectiveness and draft future\ndirections for the development of the method. The source code and the\nembeddings needed to train a QSAR model are available on\nhttps://github.com/bigchem/transformer-cnn. The repository also has a\nstandalone program for QSAR prognosis which calculates individual atoms\ncontributions, thus interpreting the model's result. OCHEM [3] environment\n(https://ochem.eu) hosts the on-line implementation of the method proposed.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 12:49:55 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 13:35:29 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2020 14:43:18 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Karpov", "Pavel", ""], ["Godin", "Guillaume", ""], ["Tetko", "Igor V.", ""]]}, {"id": "1911.06641", "submitter": "Zhiwei Liang", "authors": "Zhiyue Liu, Jiahai Wang, Zhiwei Liang", "title": "CatGAN: Category-aware Generative Adversarial Networks with Hierarchical\n  Evolutionary Learning for Category Text Generation", "comments": "15 pages, 4 figures. Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating multiple categories of texts is a challenging task and draws more\nand more attention. Since generative adversarial nets (GANs) have shown\ncompetitive results on general text generation, they are extended for category\ntext generation in some previous works. However, the complicated model\nstructures and learning strategies limit their performance and exacerbate the\ntraining instability. This paper proposes a category-aware GAN (CatGAN) which\nconsists of an efficient category-aware model for category text generation and\na hierarchical evolutionary learning algorithm for training our model. The\ncategory-aware model directly measures the gap between real samples and\ngenerated samples on each category, then reducing this gap will guide the model\nto generate high-quality category samples. The Gumbel-Softmax relaxation\nfurther frees our model from complicated learning strategies for updating\nCatGAN on discrete data. Moreover, only focusing on the sample quality normally\nleads the mode collapse problem, thus a hierarchical evolutionary learning\nalgorithm is introduced to stabilize the training procedure and obtain the\ntrade-off between quality and diversity while training CatGAN. Experimental\nresults demonstrate that CatGAN outperforms most of the existing\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 14:03:30 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 09:16:28 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Liu", "Zhiyue", ""], ["Wang", "Jiahai", ""], ["Liang", "Zhiwei", ""]]}, {"id": "1911.06673", "submitter": "Shubham Kapoor", "authors": "Shubham Kapoor, Caglar Tirkaz", "title": "Bootstrapping NLU Models with Multi-task Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bootstrapping natural language understanding (NLU) systems with minimal\ntraining data is a fundamental challenge of extending digital assistants like\nAlexa and Siri to a new language. A common approach that is adapted in digital\nassistants when responding to a user query is to process the input in a\npipeline manner where the first task is to predict the domain, followed by the\ninference of intent and slots. However, this cascaded approach instigates error\npropagation and prevents information sharing among these tasks. Further, the\nuse of words as the atomic units of meaning as done in many studies might lead\nto coverage problems for morphologically rich languages such as German and\nFrench when data is limited. We address these issues by introducing a\ncharacter-level unified neural architecture for joint modeling of the domain,\nintent, and slot classification. We compose word-embeddings from characters and\njointly optimize all classification tasks via multi-task learning. In our\nresults, we show that the proposed architecture is an optimal choice for\nbootstrapping NLU systems in low-resource settings thus saving time, cost and\nhuman effort.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 14:47:02 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Kapoor", "Shubham", ""], ["Tirkaz", "Caglar", ""]]}, {"id": "1911.06747", "submitter": "Maryam Fazel-Zarandi", "authors": "Maryam Fazel-Zarandi, Sampat Biswas, Ryan Summers, Ahmed Elmalt, Andy\n  McCraw, Michael McPhilips, John Peach", "title": "Towards Personalized Dialog Policies for Conversational Skill Discovery", "comments": "The 3rd Conversational AI workshop - today's practice and tomorrow's\n  potential", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many businesses and consumers are extending the capabilities of voice-based\nservices such as Amazon Alexa, Google Home, Microsoft Cortana, and Apple Siri\nto create custom voice experiences (also known as skills). As the number of\nthese experiences increases, a key problem is the discovery of skills that can\nbe used to address a user's request. In this paper, we focus on conversational\nskill discovery and present a conversational agent which engages in a dialog\nwith users to help them find the skills that fulfill their needs. To this end,\nwe start with a rule-based agent and improve it by using reinforcement\nlearning. In this way, we enable the agent to adapt to different user\nattributes and conversational styles as it interacts with users. We evaluate\nour approach in a real production setting by deploying the agent to interact\nwith real users, and show the effectiveness of the conversational agent in\nhelping users find the skills that serve their request.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 16:56:17 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Fazel-Zarandi", "Maryam", ""], ["Biswas", "Sampat", ""], ["Summers", "Ryan", ""], ["Elmalt", "Ahmed", ""], ["McCraw", "Andy", ""], ["McPhilips", "Michael", ""], ["Peach", "John", ""]]}, {"id": "1911.06815", "submitter": "Preslav Nakov", "authors": "Seunghak Yu, Giovanni Da San Martino, Preslav Nakov", "title": "Experiments in Detecting Persuasion Techniques in the News", "comments": "arXiv admin note: substantial text overlap with arXiv:1910.02517", "journal-ref": "NeurIPS-2019 workshop on AI for Social Good", "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent political events, like the 2016 US Presidential elections or the\n2018 Brazilian elections have raised the attention of institutions and of the\ngeneral public on the role of Internet and social media in influencing the\noutcome of these events. We argue that a safe democracy is one in which\ncitizens have tools to make them aware of propaganda campaigns. We propose a\nnovel task: performing fine-grained analysis of texts by detecting all\nfragments that contain propaganda techniques as well as their type. We further\ndesign a novel multi-granularity neural network, and we show that it\noutperforms several strong BERT-based baselines.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 07:14:35 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Yu", "Seunghak", ""], ["Martino", "Giovanni Da San", ""], ["Nakov", "Preslav", ""]]}, {"id": "1911.06848", "submitter": "Han-Chin Shing", "authors": "Han-Chin Shing, Guoli Wang, Philip Resnik", "title": "Assigning Medical Codes at the Encounter Level by Paying Attention to\n  Documents", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vast majority of research in computer assisted medical coding focuses on\ncoding at the document level, but a substantial proportion of medical coding in\nthe real world involves coding at the level of clinical encounters, each of\nwhich is typically represented by a potentially large set of documents. We\nintroduce encounter-level document attention networks, which use hierarchical\nattention to explicitly take the hierarchical structure of encounter\ndocumentation into account. Experimental evaluation demonstrates improvements\nin coding accuracy as well as facilitation of human reviewers in their ability\nto identify which documents within an encounter play a role in determining the\nencounter level codes.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 19:40:57 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Shing", "Han-Chin", ""], ["Wang", "Guoli", ""], ["Resnik", "Philip", ""]]}, {"id": "1911.06910", "submitter": "Bo Peng", "authors": "Bo Peng, Renqiang Min, Xia Ning", "title": "CNN-based Dual-Chain Models for Knowledge Graph Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge graph learning plays a critical role in integrating domain specific\nknowledge bases when deploying machine learning and data mining models in\npractice. Existing methods on knowledge graph learning primarily focus on\nmodeling the relations among entities as translations among the relations and\nentities, and many of these methods are not able to handle zero-shot problems,\nwhen new entities emerge. In this paper, we present a new convolutional neural\nnetwork (CNN)-based dual-chain model. Different from translation based methods,\nin our model, interactions among relations and entities are directly captured\nvia CNN over their embeddings. Moreover, a secondary chain of learning is\nconducted simultaneously to incorporate additional information and to enable\nbetter performance. We also present an extension of this model, which\nincorporates descriptions of entities and learns a second set of entity\nembeddings from the descriptions. As a result, the extended model is able to\neffectively handle zero-shot problems. We conducted comprehensive experiments,\ncomparing our methods with 15 methods on 8 benchmark datasets. Extensive\nexperimental results demonstrate that our proposed methods achieve or\noutperform the state-of-the-art results on knowledge graph learning, and\noutperform other methods on zero-shot problems. In addition, our methods\napplied to real-world biomedical data are able to produce results that conform\nto expert domain knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 23:24:17 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 13:40:35 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Peng", "Bo", ""], ["Min", "Renqiang", ""], ["Ning", "Xia", ""]]}, {"id": "1911.06915", "submitter": "Ilya Valmianski", "authors": "Ilya Valmianski, Caleb Goodwin, Ian M. Finn, Naqi Khan and Daniel S.\n  Zisook", "title": "Evaluating robustness of language models for chief complaint extraction\n  from patient-generated text", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated classification of chief complaints from patient-generated text is a\ncritical first step in developing scalable platforms to triage patients without\nhuman intervention. In this work, we evaluate several approaches to chief\ncomplaint classification using a novel Chief Complaint (CC) Dataset that\ncontains ~200,000 patient-generated reasons-for-visit entries mapped to a set\nof 795 discrete chief complaints. We examine the use of several fine-tuned\nbidirectional transformer (BERT) models trained on both unrelated texts as well\nas on the CC dataset. We contrast this performance with a TF-IDF baseline. Our\nevaluation has three components: (1) a random test hold-out from the original\ndataset; (2) a \"misspelling set,\" consisting of a hand-selected subset of the\ntest set, where every entry has at least one misspelling; (3) a separate\nexperimenter-generated free-text set. We find that the TF-IDF model performs\nsignificantly better than the strongest BERT-based model on the test (best BERT\nPR-AUC $0.3597 \\pm 0.0041$ vs TF-IDF PR-AUC $0.3878 \\pm 0.0148$, $p=7\\cdot\n10^{-5}$), and is statistically comparable to the misspelling sets (best BERT\nPR-AUC $0.2579 \\pm 0.0079$ vs TF-IDF PR-AUC $0.2733 \\pm 0.0130$, $p=0.06$).\nHowever, when examining model predictions on experimenter-generated queries,\nsome concerns arise about TF-IDF baseline's robustness. Our results suggest\nthat in certain tasks, simple language embedding baselines may be very\nperformant; however, truly understanding their robustness requires further\nanalysis.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 23:37:41 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Valmianski", "Ilya", ""], ["Goodwin", "Caleb", ""], ["Finn", "Ian M.", ""], ["Khan", "Naqi", ""], ["Zisook", "Daniel S.", ""]]}, {"id": "1911.06919", "submitter": "Fajri Koto", "authors": "Fajri Koto, Jey Han Lau, Timothy Baldwin", "title": "Improved Document Modelling with a Neural Discourse Parser", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the success of attention-based neural models for natural language\ngeneration and classification tasks, they are unable to capture the discourse\nstructure of larger documents. We hypothesize that explicit discourse\nrepresentations have utility for NLP tasks over longer documents or document\nsequences, which sequence-to-sequence models are unable to capture. For\nabstractive summarization, for instance, conventional neural models simply\nmatch source documents and the summary in a latent space without explicit\nrepresentation of text structure or relations. In this paper, we propose to use\nneural discourse representations obtained from a rhetorical structure theory\n(RST) parser to enhance document representations. Specifically, document\nrepresentations are generated for discourse spans, known as the elementary\ndiscourse units (EDUs). We empirically investigate the benefit of the proposed\napproach on two different tasks: abstractive summarization and popularity\nprediction of online petitions. We find that the proposed approach leads to\nimprovements in all cases.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 00:07:09 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Koto", "Fajri", ""], ["Lau", "Jey Han", ""], ["Baldwin", "Timothy", ""]]}, {"id": "1911.06940", "submitter": "Jia-Chen Gu", "authors": "Jia-Chen Gu, Zhen-Hua Ling, Quan Liu", "title": "Utterance-to-Utterance Interactive Matching Network for Multi-Turn\n  Response Selection in Retrieval-Based Chatbots", "comments": "Accepted by IEEE/ACM Transactions on Audio, Speech and Language\n  Processing. arXiv admin note: substantial text overlap with arXiv:1901.01824", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an utterance-to-utterance interactive matching network\n(U2U-IMN) for multi-turn response selection in retrieval-based chatbots.\nDifferent from previous methods following context-to-response matching or\nutterance-to-response matching frameworks, this model treats both contexts and\nresponses as sequences of utterances when calculating the matching degrees\nbetween them. For a context-response pair, the U2U-IMN model first encodes each\nutterance separately using recurrent and self-attention layers. Then, a global\nand bidirectional interaction between the context and the response is conducted\nusing the attention mechanism to collect the matching information between them.\nThe distances between context and response utterances are employed as a prior\ncomponent when calculating the attention weights. Finally, sentence-level\naggregation and context-response-level aggregation are executed in turn to\nobtain the feature vector for matching degree prediction. Experiments on four\npublic datasets showed that our proposed method outperformed baseline methods\non all metrics, achieving a new state-of-the-art performance and demonstrating\ncompatibility across domains for multi-turn response selection.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 02:47:03 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Gu", "Jia-Chen", ""], ["Ling", "Zhen-Hua", ""], ["Liu", "Quan", ""]]}, {"id": "1911.06948", "submitter": "Mantong Zhou", "authors": "Mantong Zhou, Minlie Huang, Xiaoyan Zhu", "title": "Robust Reading Comprehension with Linguistic Constraints via Posterior\n  Regularization", "comments": "In TASLP Revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of great advancements of machine reading comprehension (RC),\nexisting RC models are still vulnerable and not robust to different types of\nadversarial examples. Neural models over-confidently predict wrong answers to\nsemantic different adversarial examples, while over-sensitively predict wrong\nanswers to semantic equivalent adversarial examples. Existing methods which\nimprove the robustness of such neural models merely mitigate one of the two\nissues but ignore the other. In this paper, we address the over-confidence\nissue and the over-sensitivity issue existing in current RC models\nsimultaneously with the help of external linguistic knowledge. We first\nincorporate external knowledge to impose different linguistic constraints\n(entity constraint, lexical constraint, and predicate constraint), and then\nregularize RC models through posterior regularization. Linguistic constraints\ninduce more reasonable predictions for both semantic different and semantic\nequivalent adversarial examples, and posterior regularization provides an\neffective mechanism to incorporate these constraints. Our method can be applied\nto any existing neural RC models including state-of-the-art BERT models.\nExtensive experiments show that our method remarkably improves the robustness\nof base RC models, and is better to cope with these two issues simultaneously.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 03:41:40 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Zhou", "Mantong", ""], ["Huang", "Minlie", ""], ["Zhu", "Xiaoyan", ""]]}, {"id": "1911.06961", "submitter": "Naeemul Hassan", "authors": "Naeemul Hassan, Amrit Poudel, Jason Hale, Claire Hubacek, Khandakar\n  Tasnim Huq, Shubhra Kanti Karmaker Santu, Syed Ishtiaque Ahmed", "title": "Towards Automated Sexual Violence Report Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tracking sexual violence is a challenging task. In this paper, we present a\nsupervised learning-based automated sexual violence report tracking model that\nis more scalable, and reliable than its crowdsource based counterparts. We\ndefine the sexual violence report tracking problem by considering victim,\nperpetrator contexts and the nature of the violence. We find that our model\ncould identify sexual violence reports with a precision and recall of 80.4% and\n83.4%, respectively. Moreover, we also applied the model during and after the\n\\#MeToo movement. Several interesting findings are discovered which are not\neasily identifiable from a shallow analysis.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 05:25:01 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Hassan", "Naeemul", ""], ["Poudel", "Amrit", ""], ["Hale", "Jason", ""], ["Hubacek", "Claire", ""], ["Huq", "Khandakar Tasnim", ""], ["Santu", "Shubhra Kanti Karmaker", ""], ["Ahmed", "Syed Ishtiaque", ""]]}, {"id": "1911.06964", "submitter": "Mina Lee", "authors": "Mina Lee, Tatsunori B. Hashimoto, Percy Liang", "title": "Learning Autocomplete Systems as a Communication Game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study textual autocomplete---the task of predicting a full sentence from a\npartial sentence---as a human-machine communication game. Specifically, we\nconsider three competing goals for effective communication: use as few tokens\nas possible (efficiency), transmit sentences faithfully (accuracy), and be\nlearnable to humans (interpretability). We propose an unsupervised approach\nwhich tackles all three desiderata by constraining the communication scheme to\nkeywords extracted from a source sentence for interpretability and optimizing\nthe efficiency-accuracy tradeoff. Our experiments show that this approach\nresults in an autocomplete system that is 52% more accurate at a given\nefficiency level compared to baselines, is robust to user variations, and saves\ntime by nearly 50% compared to typing full sentences.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 05:34:47 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Lee", "Mina", ""], ["Hashimoto", "Tatsunori B.", ""], ["Liang", "Percy", ""]]}, {"id": "1911.07013", "submitter": "Jingjing Xu", "authors": "Jingjing Xu, Xu Sun, Zhiyuan Zhang, Guangxiang Zhao, Junyang Lin", "title": "Understanding and Improving Layer Normalization", "comments": "Accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Layer normalization (LayerNorm) is a technique to normalize the distributions\nof intermediate layers. It enables smoother gradients, faster training, and\nbetter generalization accuracy. However, it is still unclear where the\neffectiveness stems from. In this paper, our main contribution is to take a\nstep further in understanding LayerNorm. Many of previous studies believe that\nthe success of LayerNorm comes from forward normalization. Unlike them, we find\nthat the derivatives of the mean and variance are more important than forward\nnormalization by re-centering and re-scaling backward gradients. Furthermore,\nwe find that the parameters of LayerNorm, including the bias and gain, increase\nthe risk of over-fitting and do not work in most cases. Experiments show that a\nsimple version of LayerNorm (LayerNorm-simple) without the bias and gain\noutperforms LayerNorm on four datasets. It obtains the state-of-the-art\nperformance on En-Vi machine translation. To address the over-fitting problem,\nwe propose a new normalization method, Adaptive Normalization (AdaNorm), by\nreplacing the bias and gain with a new transformation function. Experiments\nshow that AdaNorm demonstrates better results than LayerNorm on seven out of\neight datasets.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 11:00:16 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Xu", "Jingjing", ""], ["Sun", "Xu", ""], ["Zhang", "Zhiyuan", ""], ["Zhao", "Guangxiang", ""], ["Lin", "Junyang", ""]]}, {"id": "1911.07030", "submitter": "Sadik Bessou", "authors": "Sadik Bessou", "title": "Contribution au Niveau de l'Approche Indirecte \\`a Base de Transfert\n  dans la Traduction Automatique", "comments": "in French", "journal-ref": "Phd Thesis, 2015", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis, we address several important issues concerning the\nmorphological analysis of Arabic language applied to textual data and machine\ntranslation. First, we provided an overview on machine translation, its history\nand its development, then we exposed human translation techniques for eventual\ninspiration in machine translation, and we exposed linguistic approaches and\nparticularly indirect transfer approaches. Finally, we presented our\ncontributions to the resolution of morphosyntactic problems in computer\nlinguistics as multilingual information retrieval and machine translation. As a\nfirst contribution, we developed a morphological analyzer for Arabic, and we\nhave exploited it in the bilingual information retrieval such as a computer\napplication of multilingual documentary. Results validation showed a\nstatistically significant performance. In a second contribution, we proposed a\nlist of morphosyntactic transfer rules from English to Arabic for translation\nin three phases: analysis, transfer, generation. We focused on the transfer\nphase without semantic distortion for an abstraction of English in a sufficient\nsubset of Arabic.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 13:34:16 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Bessou", "Sadik", ""]]}, {"id": "1911.07056", "submitter": "Pattarawat Chormai", "authors": "Pattarawat Chormai and Ponrawee Prasertsom and Attapol Rutherford", "title": "AttaCut: A Fast and Accurate Neural Thai Word Segmenter", "comments": "14 pages, 7 figures, accepted as oral presentation at New in ML\n  Workshop, NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word segmentation is a fundamental pre-processing step for Thai Natural\nLanguage Processing. The current off-the-shelf solutions are not benchmarked\nconsistently, so it is difficult to compare their trade-offs. We conducted a\nspeed and accuracy comparison of the popular systems on three different domains\nand found that the state-of-the-art deep learning system is slow and moreover\ndoes not use sub-word structures to guide the model. Here, we propose a fast\nand accurate neural Thai Word Segmenter that uses dilated CNN filters to\ncapture the environment of each character and uses syllable embeddings as\nfeatures. Our system runs at least 5.6x faster and outperforms the previous\nstate-of-the-art system on some domains. In addition, we develop the first\nML-based Thai orthographical syllable segmenter, which yields syllable\nembeddings to be used as features by the word segmenter.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 16:27:44 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Chormai", "Pattarawat", ""], ["Prasertsom", "Ponrawee", ""], ["Rutherford", "Attapol", ""]]}, {"id": "1911.07141", "submitter": "Ricky Loynd", "authors": "Ricky Loynd, Roland Fernandez, Asli Celikyilmaz, Adith Swaminathan and\n  Matthew Hausknecht", "title": "Working Memory Graphs", "comments": "11 pages, 6 figures, 7 page appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers have increasingly outperformed gated RNNs in obtaining new\nstate-of-the-art results on supervised tasks involving text sequences. Inspired\nby this trend, we study the question of how Transformer-based models can\nimprove the performance of sequential decision-making agents. We present the\nWorking Memory Graph (WMG), an agent that employs multi-head self-attention to\nreason over a dynamic set of vectors representing observed and recurrent state.\nWe evaluate WMG in three environments featuring factored observation spaces: a\nPathfinding environment that requires complex reasoning over past observations,\nBabyAI gridworld levels that involve variable goals, and Sokoban which\nemphasizes future planning. We find that the combination of WMG's\nTransformer-based architecture with factored observation spaces leads to\nsignificant gains in learning efficiency compared to baseline architectures\nacross all tasks. WMG demonstrates how Transformer-based models can\ndramatically boost sample efficiency in RL environments for which observations\ncan be factored.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 03:14:02 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 02:09:20 GMT"}, {"version": "v3", "created": "Wed, 8 Jul 2020 16:51:20 GMT"}, {"version": "v4", "created": "Tue, 18 Aug 2020 15:56:25 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Loynd", "Ricky", ""], ["Fernandez", "Roland", ""], ["Celikyilmaz", "Asli", ""], ["Swaminathan", "Adith", ""], ["Hausknecht", "Matthew", ""]]}, {"id": "1911.07156", "submitter": "Haozhe Wu", "authors": "Haozhe Wu, Zhiyuan Hu, Jia Jia, Yaohua Bu, Xiangnan He, Tat-Seng Chua", "title": "Mining Unfollow Behavior in Large-Scale Online Social Networks via\n  Spatial-Temporal Interaction", "comments": "8 pages, 7 figures, Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online Social Networks (OSNs) evolve through two pervasive behaviors: follow\nand unfollow, which respectively signify relationship creation and relationship\ndissolution. Researches on social network evolution mainly focus on the follow\nbehavior, while the unfollow behavior has largely been ignored. Mining unfollow\nbehavior is challenging because user's decision on unfollow is not only\naffected by the simple combination of user's attributes like informativeness\nand reciprocity, but also affected by the complex interaction among them.\nMeanwhile, prior datasets seldom contain sufficient records for inferring such\ncomplex interaction. To address these issues, we first construct a large-scale\nreal-world Weibo dataset, which records detailed post content and relationship\ndynamics of 1.8 million Chinese users. Next, we define user's attributes as two\ncategories: spatial attributes (e.g., social role of user) and temporal\nattributes (e.g., post content of user). Leveraging the constructed dataset, we\nsystematically study how the interaction effects between user's spatial and\ntemporal attributes contribute to the unfollow behavior. Afterwards, we propose\na novel unified model with heterogeneous information (UMHI) for unfollow\nprediction. Specifically, our UMHI model: 1) captures user's spatial attributes\nthrough social network structure; 2) infers user's temporal attributes through\nuser-posted content and unfollow history; and 3) models the interaction between\nspatial and temporal attributes by the nonlinear MLP layers. Comprehensive\nevaluations on the constructed dataset demonstrate that the proposed UMHI model\noutperforms baseline methods by 16.44% on average in terms of precision. In\naddition, factor analyses verify that both spatial attributes and temporal\nattributes are essential for mining unfollow behavior.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 05:40:17 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Wu", "Haozhe", ""], ["Hu", "Zhiyuan", ""], ["Jia", "Jia", ""], ["Bu", "Yaohua", ""], ["He", "Xiangnan", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "1911.07176", "submitter": "Vikas Yadav", "authors": "Vikas Yadav, Steven Bethard and Mihai Surdeanu", "title": "Quick and (not so) Dirty: Unsupervised Selection of Justification\n  Sentences for Multi-hop Question Answering", "comments": "Published at EMNLP-IJCNLP 2019 as long conference paper. Corrected\n  the name reference for Speer et.al, 2017", "journal-ref": "EMNLP-IJCNLP, 2578--2589 (2019)", "doi": "10.18653/v1/D19-1260", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an unsupervised strategy for the selection of justification\nsentences for multi-hop question answering (QA) that (a) maximizes the\nrelevance of the selected sentences, (b) minimizes the overlap between the\nselected facts, and (c) maximizes the coverage of both question and answer.\nThis unsupervised sentence selection method can be coupled with any supervised\nQA approach. We show that the sentences selected by our method improve the\nperformance of a state-of-the-art supervised QA model on two multi-hop QA\ndatasets: AI2's Reasoning Challenge (ARC) and Multi-Sentence Reading\nComprehension (MultiRC). We obtain new state-of-the-art performance on both\ndatasets among approaches that do not use external resources for training the\nQA system: 56.82% F1 on ARC (41.24% on Challenge and 64.49% on Easy) and 26.1%\nEM0 on MultiRC. Our justification sentences have higher quality than the\njustifications selected by a strong information retrieval baseline, e.g., by\n5.4% F1 in MultiRC. We also show that our unsupervised selection of\njustification sentences is more stable across domains than a state-of-the-art\nsupervised sentence selection method.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 07:51:42 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 02:46:19 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Yadav", "Vikas", ""], ["Bethard", "Steven", ""], ["Surdeanu", "Mihai", ""]]}, {"id": "1911.07184", "submitter": "Fandong Meng", "authors": "Fandong Meng, Jinchao Zhang, Yang Liu and Jie Zhou", "title": "Multi-Zone Unit for Recurrent Neural Networks", "comments": "Accepted at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) have been widely used to deal with sequence\nlearning problems. The input-dependent transition function, which folds new\nobservations into hidden states to sequentially construct fixed-length\nrepresentations of arbitrary-length sequences, plays a critical role in RNNs.\nBased on single space composition, transition functions in existing RNNs often\nhave difficulty in capturing complicated long-range dependencies. In this\npaper, we introduce a new Multi-zone Unit (MZU) for RNNs. The key idea is to\ndesign a transition function that is capable of modeling multiple space\ncomposition. The MZU consists of three components: zone generation, zone\ncomposition, and zone aggregation. Experimental results on multiple datasets of\nthe character-level language modeling task and the aspect-based sentiment\nanalysis task demonstrate the superiority of the MZU.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 08:27:26 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Meng", "Fandong", ""], ["Zhang", "Jinchao", ""], ["Liu", "Yang", ""], ["Zhou", "Jie", ""]]}, {"id": "1911.07199", "submitter": "Quanzhi Li", "authors": "Quanzhi Li, Qiong Zhang, Luo Si, Yingchi Liu", "title": "Rumor Detection on Social Media: Datasets, Methods and Opportunities", "comments": "10 pages", "journal-ref": "EMNLP 2019", "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media platforms have been used for information and news gathering, and\nthey are very valuable in many applications. However, they also lead to the\nspreading of rumors and fake news. Many efforts have been taken to detect and\ndebunk rumors on social media by analyzing their content and social context\nusing machine learning techniques. This paper gives an overview of the recent\nstudies in the rumor detection field. It provides a comprehensive list of\ndatasets used for rumor detection, and reviews the important studies based on\nwhat types of information they exploit and the approaches they take. And more\nimportantly, we also present several new directions for future research.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 09:40:24 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Li", "Quanzhi", ""], ["Zhang", "Qiong", ""], ["Si", "Luo", ""], ["Liu", "Yingchi", ""]]}, {"id": "1911.07223", "submitter": "Kiet Nguyen Van", "authors": "Phu X. V. Nguyen, Tham T. T. Hong, Kiet Van Nguyen, Ngan Luu-Thuy\n  Nguyen", "title": "Deep Learning versus Traditional Classifiers on Vietnamese Students'\n  Feedback Corpus", "comments": "In Proceeding of the 5th NAFOSTED Conference on Information and\n  Computer Science (NICS 2018)", "journal-ref": "5th NAFOSTED Conference on Information and Computer Science (NICS\n  2018)", "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Student's feedback is an important source of collecting students' opinions to\nimprove the quality of training activities. Implementing sentiment analysis\ninto student feedback data, we can determine sentiments polarities which\nexpress all problems in the institution since changes necessary will be applied\nto improve the quality of teaching and learning. This study focused on machine\nlearning and natural language processing techniques (NaiveBayes, Maximum\nEntropy, Long Short-Term Memory, Bi-Directional Long Short-Term Memory) on the\nVietnameseStudents' Feedback Corpus collected from a university. The final\nresults were compared and evaluated to find the most effective model based on\ndifferent evaluation criteria. The experimental results show that the\nBi-Directional LongShort-Term Memory algorithm outperformed than three other\nalgorithms in terms of the F1-score measurement with 92.0% on the sentiment\nclassification task and 89.6% on the topic classification task. In addition, we\ndeveloped a sentiment analysis application analyzing student feedback. The\napplication will help the institution to recognize students' opinions about a\nproblem and identify shortcomings that still exist. With the use of this\napplication, the institution can propose an appropriate method to improve the\nquality of training activities in the future.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 12:32:50 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Nguyen", "Phu X. V.", ""], ["Hong", "Tham T. T.", ""], ["Van Nguyen", "Kiet", ""], ["Nguyen", "Ngan Luu-Thuy", ""]]}, {"id": "1911.07228", "submitter": "Kiet Nguyen Van", "authors": "Binh An Nguyen, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen", "title": "Error Analysis for Vietnamese Named Entity Recognition on Deep Neural\n  Network Models", "comments": "19th International Conference on Computational Linguistics and\n  Intelligent Text Processing (CICLING 2018)", "journal-ref": "19th International Conference on Computational Linguistics and\n  Intelligent Text Processing (CICLING 2018)", "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Vietnamese Named Entity Recognition (NER) systems have had a\ngreat breakthrough when using Deep Neural Network methods. This paper describes\nthe primary errors of the state-of-the-art NER systems on Vietnamese language.\nAfter conducting experiments on BLSTM-CNN-CRF and BLSTM-CRF models with\ndifferent word embeddings on the Vietnamese NER dataset. This dataset is\nprovided by VLSP in 2016 and used to evaluate most of the current Vietnamese\nNER systems. We noticed that BLSTM-CNN-CRF gives better results, therefore, we\nanalyze the errors on this model in detail. Our error-analysis results provide\nus thorough insights in order to increase the performance of NER for the\nVietnamese language and improve the quality of the corpus in the future works.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 13:03:07 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 13:08:38 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Nguyen", "Binh An", ""], ["Van Nguyen", "Kiet", ""], ["Nguyen", "Ngan Luu-Thuy", ""]]}, {"id": "1911.07251", "submitter": "Xiaoze Jiang", "authors": "Xiaoze Jiang, Jing Yu, Zengchang Qin, Yingying Zhuang, Xingxing Zhang,\n  Yue Hu, Qi Wu", "title": "DualVD: An Adaptive Dual Encoding Model for Deep Visual Understanding in\n  Visual Dialogue", "comments": "Accepted by the Thirty-Fourth AAAI Conference on Artificial\n  Intelligence (AAAI-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different from Visual Question Answering task that requires to answer only\none question about an image, Visual Dialogue involves multiple questions which\ncover a broad range of visual content that could be related to any objects,\nrelationships or semantics. The key challenge in Visual Dialogue task is thus\nto learn a more comprehensive and semantic-rich image representation which may\nhave adaptive attentions on the image for variant questions. In this research,\nwe propose a novel model to depict an image from both visual and semantic\nperspectives. Specifically, the visual view helps capture the appearance-level\ninformation, including objects and their relationships, while the semantic view\nenables the agent to understand high-level visual semantics from the whole\nimage to the local regions. Futhermore, on top of such multi-view image\nfeatures, we propose a feature selection framework which is able to adaptively\ncapture question-relevant information hierarchically in fine-grained level. The\nproposed method achieved state-of-the-art results on benchmark Visual Dialogue\ndatasets. More importantly, we can tell which modality (visual or semantic) has\nmore contribution in answering the current question by visualizing the gate\nvalues. It gives us insights in understanding of human cognition in Visual\nDialogue.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 14:58:17 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Jiang", "Xiaoze", ""], ["Yu", "Jing", ""], ["Qin", "Zengchang", ""], ["Zhuang", "Yingying", ""], ["Zhang", "Xingxing", ""], ["Hu", "Yue", ""], ["Wu", "Qi", ""]]}, {"id": "1911.07335", "submitter": "Haw-Shiuan Chang", "authors": "Haw-Shiuan Chang, Shankar Vembu, Sunil Mohan, Rheeya Uppaal, Andrew\n  McCallum", "title": "Using Error Decay Prediction to Overcome Practical Issues of Deep Active\n  Learning for Named Entity Recognition", "comments": "This is a pre-print of an article published in Springer Machine\n  Learning journal. The final authenticated version is available online at:\n  https://doi.org/10.1007/s10994-020-05897-1", "journal-ref": null, "doi": "10.1007/s10994-020-05897-1", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing deep active learning algorithms achieve impressive sampling\nefficiency on natural language processing tasks. However, they exhibit several\nweaknesses in practice, including (a) inability to use uncertainty sampling\nwith black-box models, (b) lack of robustness to labeling noise, and (c) lack\nof transparency. In response, we propose a transparent batch active sampling\nframework by estimating the error decay curves of multiple feature-defined\nsubsets of the data. Experiments on four named entity recognition (NER) tasks\ndemonstrate that the proposed methods significantly outperform\ndiversification-based methods for black-box NER taggers, and can make the\nsampling process more robust to labeling noise when combined with\nuncertainty-based methods. Furthermore, the analysis of experimental results\nsheds light on the weaknesses of different active sampling strategies, and when\ntraditional uncertainty-based or diversification-based methods can be expected\nto work well.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 20:41:32 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 00:33:11 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Chang", "Haw-Shiuan", ""], ["Vembu", "Shankar", ""], ["Mohan", "Sunil", ""], ["Uppaal", "Rheeya", ""], ["McCallum", "Andrew", ""]]}, {"id": "1911.07405", "submitter": "Qiang Huang Huang", "authors": "Qiang Huang, Jianhui Bu, Weijian Xie, Shengwen Yang, Weijia Wu, Liping\n  Liu", "title": "Multi-task Sentence Encoding Model for Semantic Retrieval in Question\n  Answering Systems", "comments": "IJCNN 2019 - International Joint Conference on Neural Networks,\n  Budapest Hungary, 14-19 July 2019", "journal-ref": null, "doi": null, "report-no": "paper N-20437.pdf", "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Question Answering (QA) systems are used to provide proper responses to\nusers' questions automatically. Sentence matching is an essential task in the\nQA systems and is usually reformulated as a Paraphrase Identification (PI)\nproblem. Given a question, the aim of the task is to find the most similar\nquestion from a QA knowledge base. In this paper, we propose a Multi-task\nSentence Encoding Model (MSEM) for the PI problem, wherein a connected graph is\nemployed to depict the relation between sentences, and a multi-task learning\nmodel is applied to address both the sentence matching and sentence intent\nclassification problem. In addition, we implement a general semantic retrieval\nframework that combines our proposed model and the Approximate Nearest Neighbor\n(ANN) technology, which enables us to find the most similar question from all\navailable candidates very quickly during online serving. The experiments show\nthe superiority of our proposed method as compared with the existing sentence\nmatching models.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 03:11:36 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Huang", "Qiang", ""], ["Bu", "Jianhui", ""], ["Xie", "Weijian", ""], ["Yang", "Shengwen", ""], ["Wu", "Weijia", ""], ["Liu", "Liping", ""]]}, {"id": "1911.07470", "submitter": "Deng Cai", "authors": "Deng Cai and Wai Lam", "title": "Graph Transformer for Graph-to-Sequence Learning", "comments": "accepted by AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dominant graph-to-sequence transduction models employ graph neural\nnetworks for graph representation learning, where the structural information is\nreflected by the receptive field of neurons. Unlike graph neural networks that\nrestrict the information exchange between immediate neighborhood, we propose a\nnew model, known as Graph Transformer, that uses explicit relation encoding and\nallows direct communication between two distant nodes. It provides a more\nefficient way for global graph structure modeling. Experiments on the\napplications of text generation from Abstract Meaning Representation (AMR) and\nsyntax-based neural machine translation show the superiority of our proposed\nmodel. Specifically, our model achieves 27.4 BLEU on LDC2015E86 and 29.7 BLEU\non LDC2017T10 for AMR-to-text generation, outperforming the state-of-the-art\nresults by up to 2.2 points. On the syntax-based translation tasks, our model\nestablishes new single-model state-of-the-art BLEU scores, 21.3 for\nEnglish-to-German and 14.1 for English-to-Czech, improving over the existing\nbest results, including ensembles, by over 1 BLEU.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 07:45:19 GMT"}, {"version": "v2", "created": "Sat, 30 Nov 2019 12:49:24 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Cai", "Deng", ""], ["Lam", "Wai", ""]]}, {"id": "1911.07474", "submitter": "Devin Pelser", "authors": "Devin Pelser, Hugh Murrell", "title": "Deep and Dense Sarcasm Detection", "comments": "8 pages, 2 figures, plan to present paper at a conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in automated sarcasm detection has placed a heavy focus on\ncontext and meta-data. Whilst certain utterances indeed require background\nknowledge and commonsense reasoning, previous works have only explored shallow\nmodels for capturing the lexical, syntactic and semantic cues present within a\ntext. In this paper, we propose a deep 56 layer network, implemented with dense\nconnectivity to model the isolated utterance and extract richer features\ntherein. We compare our approach against recent state-of-the-art architectures\nwhich make considerable use of extrinsic information, and demonstrate\ncompetitive results whilst using only the local features of the text. Further,\nwe provide an analysis of the dependency of prior convolution outputs in\ngenerating the final feature maps. Finally a case study is presented,\nsupporting that our approach accurately classifies additional uses of clear\nsarcasm, which a standard CNN misclassifies.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 07:49:13 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 10:07:18 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Pelser", "Devin", ""], ["Murrell", "Hugh", ""]]}, {"id": "1911.07523", "submitter": "Ramtine Tofighi-Shirazi", "authors": "Ramtine Tofighi-Shirazi (TL), Irina Mariuca Asavoae (TL), Philippe\n  Elbaz-Vincent (IF)", "title": "Fine-Grained Static Detection of Obfuscation Transforms Using\n  Ensemble-Learning and Semantic Reasoning", "comments": "Software Security, Protection, and Reverse Engineering Workshop\n  (SSPREW9), Dec 2019, San Juan, United States", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to efficiently detect the software protections used is at a prime\nto facilitate the selection and application of adequate deob-fuscation\ntechniques. We present a novel approach that combines semantic reasoning\ntechniques with ensemble learning classification for the purpose of providing a\nstatic detection framework for obfuscation transformations. By contrast to\nexisting work, we provide a methodology that can detect multiple layers of\nobfuscation, without depending on knowledge of the underlying functionality of\nthe training-set used. We also extend our work to detect constructions of\nobfuscation transformations, thus providing a fine-grained methodology. To that\nend, we provide several studies for the best practices of the use of machine\nlearning techniques for a scalable and efficient model. According to our\nexperimental results and evaluations on obfuscators such as Tigress and OLLVM,\nour models have up to 91% accuracy on state-of-the-art obfuscation\ntransformations. Our overall accuracies for their constructions are up to 100%.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 10:16:38 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Tofighi-Shirazi", "Ramtine", "", "TL"], ["Asavoae", "Irina Mariuca", "", "TL"], ["Elbaz-Vincent", "Philippe", "", "IF"]]}, {"id": "1911.07555", "submitter": "Bernardt Duvenhage", "authors": "Bernardt Duvenhage", "title": "Short Text Language Identification for Under Resourced Languages", "comments": "Presented at NeurIPS 2019 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a hierarchical naive Bayesian and lexicon based classifier\nfor short text language identification (LID) useful for under resourced\nlanguages. The algorithm is evaluated on short pieces of text for the 11\nofficial South African languages some of which are similar languages. The\nalgorithm is compared to recent approaches using test sets from previous works\non South African languages as well as the Discriminating between Similar\nLanguages (DSL) shared tasks' datasets. Remaining research opportunities and\npressing concerns in evaluating and comparing LID approaches are also\ndiscussed.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 11:34:38 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 04:53:48 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Duvenhage", "Bernardt", ""]]}, {"id": "1911.07588", "submitter": "Takuma Udagawa", "authors": "Takuma Udagawa, Akiko Aizawa", "title": "An Annotated Corpus of Reference Resolution for Interpreting Common\n  Grounding", "comments": "9 pages, 7 figures, 6 tables, Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common grounding is the process of creating, repairing and updating mutual\nunderstandings, which is a fundamental aspect of natural language conversation.\nHowever, interpreting the process of common grounding is a challenging task,\nespecially under continuous and partially-observable context where complex\nambiguity, uncertainty, partial understandings and misunderstandings are\nintroduced. Interpretation becomes even more challenging when we deal with\ndialogue systems which still have limited capability of natural language\nunderstanding and generation. To address this problem, we consider reference\nresolution as the central subtask of common grounding and propose a new\nresource to study its intermediate process. Based on a simple and general\nannotation schema, we collected a total of 40,172 referring expressions in\n5,191 dialogues curated from an existing corpus, along with multiple judgements\nof referent interpretations. We show that our annotation is highly reliable,\ncaptures the complexity of common grounding through a natural degree of\nreasonable disagreements, and allows for more detailed and quantitative\nanalyses of common grounding strategies. Finally, we demonstrate the advantages\nof our annotation for interpreting, analyzing and improving common grounding in\nbaseline dialogue systems.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 12:41:25 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Udagawa", "Takuma", ""], ["Aizawa", "Akiko", ""]]}, {"id": "1911.07613", "submitter": "Md Saiful Islam", "authors": "Aisha Khatun, Anisur Rahman, Hemayet Ahmed Chowdhury, Md. Saiful Islam\n  and Ayesha Tasnim", "title": "A Subword Level Language Model for Bangla Language", "comments": "12 pages, Conference Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Language models are at the core of natural language processing. The ability\nto represent natural language gives rise to its applications in numerous NLP\ntasks including text classification, summarization, and translation. Research\nin this area is very limited in Bangla due to the scarcity of resources, except\nfor some count-based models and very recent neural language models being\nproposed, which are all based on words and limited in practical tasks due to\ntheir high perplexity. This paper attempts to approach this issue of perplexity\nand proposes a subword level neural language model with the AWD-LSTM\narchitecture and various other techniques suitable for training in Bangla\nlanguage. The model is trained on a corpus of Bangla newspaper articles of an\nappreciable size consisting of more than 28.5 million word tokens. The\nperformance comparison with various other models depicts the significant\nreduction in perplexity the proposed model provides, reaching as low as 39.84,\nin just 20 epochs.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 08:22:33 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Khatun", "Aisha", ""], ["Rahman", "Anisur", ""], ["Chowdhury", "Hemayet Ahmed", ""], ["Islam", "Md. Saiful", ""], ["Tasnim", "Ayesha", ""]]}, {"id": "1911.07620", "submitter": "Achyudh Ram", "authors": "Achyudh Ram, Ji Xin, Meiyappan Nagappan, Yaoliang Yu, Roc\\'io Cabrera\n  Lozoya, Antonino Sabetta, Jimmy Lin", "title": "Exploiting Token and Path-based Representations of Code for Identifying\n  Security-Relevant Commits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public vulnerability databases such as CVE and NVD account for only 60% of\nsecurity vulnerabilities present in open-source projects, and are known to\nsuffer from inconsistent quality. Over the last two years, there has been\nconsiderable growth in the number of known vulnerabilities across projects\navailable in various repositories such as NPM and Maven Central. Such an\nincreasing risk calls for a mechanism to infer the presence of security threats\nin a timely manner. We propose novel hierarchical deep learning models for the\nidentification of security-relevant commits from either the commit diff or the\nsource code for the Java classes. By comparing the performance of our model\nagainst code2vec, a state-of-the-art model that learns from path-based\nrepresentations of code, and a logistic regression baseline, we show that deep\nlearning models show promising results in identifying security-related commits.\nWe also conduct a comparative analysis of how various deep learning models\nlearn across different input representations and the effect of regularization\non the generalization of our models.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 03:16:12 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Ram", "Achyudh", ""], ["Xin", "Ji", ""], ["Nagappan", "Meiyappan", ""], ["Yu", "Yaoliang", ""], ["Lozoya", "Roc\u00edo Cabrera", ""], ["Sabetta", "Antonino", ""], ["Lin", "Jimmy", ""]]}, {"id": "1911.07629", "submitter": "Atul Sahay", "authors": "Atul Sahay, Smita Gholkar, Kavi Arya", "title": "Selection-based Question Answering of an MOOC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  e-Yantra Robotics Competition (eYRC) is a unique Robotics Competition hosted\nby IIT Bombay that is actually an Embedded Systems and Robotics MOOC.\nRegistrations have been growing exponentially in each year from 4500 in 2012 to\nover 34000 in 2019. In this 5-month long competition students learn complex\nskills under severe time pressure and have access to a discussion forum to post\ndoubts about the learning material. Responding to questions in real-time is a\nchallenge for project staff. Here, we illustrate the advantage of Deep Learning\nfor real-time question answering in the eYRC discussion forum. We illustrate\nthe advantage of Transformer based contextual embedding mechanisms such as\nBidirectional Encoder Representation From Transformer (BERT) over word\nembedding mechanisms such as Word2Vec. We propose a weighted similarity metric\nas a measure of matching and find it more reliable than Content-Content or\nTitle-Title similarities alone. The automation of replying to questions has\nbrought the turn around response time(TART) down from a minimum of 21 mins to a\nminimum of 0.3 secs.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 09:20:32 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Sahay", "Atul", ""], ["Gholkar", "Smita", ""], ["Arya", "Kavi", ""]]}, {"id": "1911.07819", "submitter": "Ioana Baldini", "authors": "Shivashankar Subramanian, Ioana Baldini, Sushma Ravichandran, Dmitriy\n  A. Katz-Rogozhnikov, Karthikeyan Natesan Ramamurthy, Prasanna Sattigeri, Kush\n  R. Varshney, Annmarie Wang, Pradeep Mangalath, Laura B. Kleiman", "title": "Drug Repurposing for Cancer: An NLP Approach to Identify Low-Cost\n  Therapies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More than 200 generic drugs approved by the U.S. Food and Drug Administration\nfor non-cancer indications have shown promise for treating cancer. Due to their\nlong history of safe patient use, low cost, and widespread availability,\nrepurposing of generic drugs represents a major opportunity to rapidly improve\noutcomes for cancer patients and reduce healthcare costs worldwide. Evidence on\nthe efficacy of non-cancer generic drugs being tested for cancer exists in\nscientific publications, but trying to manually identify and extract such\nevidence is intractable. In this paper, we introduce a system to automate this\nevidence extraction from PubMed abstracts. Our primary contribution is to\ndefine the natural language processing pipeline required to obtain such\nevidence, comprising the following modules: querying, filtering, cancer type\nentity extraction, therapeutic association classification, and study type\nclassification. Using the subject matter expertise on our team, we create our\nown datasets for these specialized domain-specific tasks. We obtain promising\nperformance in each of the modules by utilizing modern language modeling\ntechniques and plan to treat them as baseline approaches for future improvement\nof individual components.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 18:32:25 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 16:22:39 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Subramanian", "Shivashankar", ""], ["Baldini", "Ioana", ""], ["Ravichandran", "Sushma", ""], ["Katz-Rogozhnikov", "Dmitriy A.", ""], ["Ramamurthy", "Karthikeyan Natesan", ""], ["Sattigeri", "Prasanna", ""], ["Varshney", "Kush R.", ""], ["Wang", "Annmarie", ""], ["Mangalath", "Pradeep", ""], ["Kleiman", "Laura B.", ""]]}, {"id": "1911.07918", "submitter": "Vivek Gupta", "authors": "Vivek Gupta, Ankit Saw, Pegah Nokhiz, Harshit Gupta, Partha Talukdar", "title": "Improving Document Classification with Multi-Sense Embeddings", "comments": "8 Pages, 7 Figures, 12 Tables, under review at ECAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Efficient representation of text documents is an important building block in\nmany NLP tasks. Research on long text categorization has shown that simple\nweighted averaging of word vectors for sentence representation often\noutperforms more sophisticated neural models. Recently proposed Sparse\nComposite Document Vector (SCDV) (Mekala et. al, 2017) extends this approach\nfrom sentences to documents using soft clustering over word vectors. However,\nSCDV disregards the multi-sense nature of words, and it also suffers from the\ncurse of higher dimensionality. In this work, we address these shortcomings and\npropose SCDV-MS. SCDV-MS utilizes multi-sense word embeddings and learns a\nlower dimensional manifold. Through extensive experiments on multiple\nreal-world datasets, we show that SCDV-MS embeddings outperform previous\nstate-of-the-art embeddings on multi-class and multi-label text categorization\ntasks. Furthermore, SCDV-MS embeddings are more efficient than SCDV in terms of\ntime and space complexity on textual classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 20:30:06 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Gupta", "Vivek", ""], ["Saw", "Ankit", ""], ["Nokhiz", "Pegah", ""], ["Gupta", "Harshit", ""], ["Talukdar", "Partha", ""]]}, {"id": "1911.08112", "submitter": "Hongwei Zeng", "authors": "Hongwei Zeng, Zhuo Zhi, Jun Liu, Bifan Wei", "title": "Extended Answer and Uncertainty Aware Neural Question Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study automatic question generation, the task of creating\nquestions from corresponding text passages where some certain spans of the text\ncan serve as the answers. We propose an Extended Answer-aware Network (EAN)\nwhich is trained with Word-based Coverage Mechanism (WCM) and decodes with\nUncertainty-aware Beam Search (UBS). The EAN represents the target answer by\nits surrounding sentence with an encoder, and incorporates the information of\nthe extended answer into paragraph representation with gated\nparagraph-to-answer attention to tackle the problem of the inadequate\nrepresentation of the target answer. To reduce undesirable repetition, the WCM\npenalizes repeatedly attending to the same words at different time-steps in the\ntraining stage. The UBS aims to seek a better balance between the model\nconfidence in copying words from an input text paragraph and the confidence in\ngenerating words from a vocabulary. We conduct experiments on the SQuAD\ndataset, and the results show our approach achieves significant performance\nimprovement.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 06:38:14 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Zeng", "Hongwei", ""], ["Zhi", "Zhuo", ""], ["Liu", "Jun", ""], ["Wei", "Bifan", ""]]}, {"id": "1911.08113", "submitter": "Preslav Nakov", "authors": "Todor Mihaylov, Preslav Nakov", "title": "Hunting for Troll Comments in News Community Forums", "comments": null, "journal-ref": "ACL-2016", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are different definitions of what a troll is. Certainly, a troll can be\nsomebody who teases people to make them angry, or somebody who offends people,\nor somebody who wants to dominate any single discussion, or somebody who tries\nto manipulate people's opinion (sometimes for money), etc. The last definition\nis the one that dominates the public discourse in Bulgaria and Eastern Europe,\nand this is our focus in this paper. In our work, we examine two types of\nopinion manipulation trolls: paid trolls that have been revealed from leaked\nreputation management contracts and mentioned trolls that have been called such\nby several different people. We show that these definitions are sensible: we\nbuild two classifiers that can distinguish a post by such a paid troll from one\nby a non-troll with 81-82% accuracy; the same classifier achieves 81-82%\naccuracy on so called mentioned troll vs. non-troll posts.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 06:42:23 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Mihaylov", "Todor", ""], ["Nakov", "Preslav", ""]]}, {"id": "1911.08117", "submitter": "Preslav Nakov", "authors": "Minh-Thang Luong, Preslav Nakov, Min-Yen Kan", "title": "A Hybrid Morpheme-Word Representation for Machine Translation of\n  Morphologically Rich Languages", "comments": null, "journal-ref": "EMNLP-2010", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a language-independent approach for improving statistical machine\ntranslation for morphologically rich languages using a hybrid morpheme-word\nrepresentation where the basic unit of translation is the morpheme, but word\nboundaries are respected at all stages of the translation process. Our model\nextends the classic phrase-based model by means of (1) word boundary-aware\nmorpheme-level phrase extraction, (2) minimum error-rate training for a\nmorpheme-level translation model using word-level BLEU, and (3) joint scoring\nwith morpheme- and word-level language models. Further improvements are\nachieved by combining our model with the classic one. The evaluation on English\nto Finnish using Europarl (714K sentence pairs; 15.5M English words) shows\nstatistically significant improvements over the classic model based on BLEU and\nhuman judgments.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 06:50:59 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Luong", "Minh-Thang", ""], ["Nakov", "Preslav", ""], ["Kan", "Min-Yen", ""]]}, {"id": "1911.08125", "submitter": "Preslav Nakov", "authors": "Momchil Hardalov, Ivan Koychev, Preslav Nakov", "title": "In Search of Credible News", "comments": "Credibility, veracity, fact checking, humor detection", "journal-ref": "AIMSA-2016", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of finding fake online news. This is an important\nproblem as news of questionable credibility have recently been proliferating in\nsocial media at an alarming scale. As this is an understudied problem,\nespecially for languages other than English, we first collect and release to\nthe research community three new balanced credible vs. fake news datasets\nderived from four online sources. We then propose a language-independent\napproach for automatically distinguishing credible from fake news, based on a\nrich feature set. In particular, we use linguistic (n-gram),\ncredibility-related (capitalization, punctuation, pronoun use, sentiment\npolarity), and semantic (embeddings and DBPedia data) features. Our experiments\non three different testsets show that our model can distinguish credible from\nfake news with very high accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 07:06:22 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Hardalov", "Momchil", ""], ["Koychev", "Ivan", ""], ["Nakov", "Preslav", ""]]}, {"id": "1911.08151", "submitter": "Jiahuan Pei", "authors": "Jiahuan Pei, Pengjie Ren, Christof Monz, Maarten de Rijke", "title": "Retrospective and Prospective Mixture-of-Generators for Task-oriented\n  Dialogue Response Generation", "comments": "The paper is accepted by 24th European Conference on Artificial\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue response generation (DRG) is a critical component of task-oriented\ndialogue systems (TDSs). Its purpose is to generate proper natural language\nresponses given some context, e.g., historical utterances, system states, etc.\nState-of-the-art work focuses on how to better tackle DRG in an end-to-end way.\nTypically, such studies assume that each token is drawn from a single\ndistribution over the output vocabulary, which may not always be optimal.\nResponses vary greatly with different intents, e.g., domains, system actions.\n  We propose a novel mixture-of-generators network (MoGNet) for DRG, where we\nassume that each token of a response is drawn from a mixture of distributions.\nMoGNet consists of a chair generator and several expert generators. Each expert\nis specialized for DRG w.r.t. a particular intent. The chair coordinates\nmultiple experts and combines the output they have generated to produce more\nappropriate responses. We propose two strategies to help the chair make better\ndecisions, namely, a retrospective mixture-of-generators (RMoG) and prospective\nmixture-of-generators (PMoG). The former only considers the historical\nexpert-generated responses until the current time step while the latter also\nconsiders possible expert-generated responses in the future by encouraging\nexploration. In order to differentiate experts, we also devise a\nglobal-and-local (GL) learning scheme that forces each expert to be specialized\ntowards a particular intent using a local loss and trains the chair and all\nexperts to coordinate using a global loss.\n  We carry out extensive experiments on the MultiWOZ benchmark dataset. MoGNet\nsignificantly outperforms state-of-the-art methods in terms of both automatic\nand human evaluations, demonstrating its effectiveness for DRG.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 08:20:45 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 11:04:28 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Pei", "Jiahuan", ""], ["Ren", "Pengjie", ""], ["Monz", "Christof", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1911.08212", "submitter": "Dayiheng Liu", "authors": "Yusen Liu, Dayiheng Liu, Jiancheng Lv", "title": "Deep Poetry: A Chinese Classical Poetry Generation System", "comments": "Association for the Advancement of Artificial Intelligence,\n  Demonstrations Program. AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we demonstrate a Chinese classical poetry generation system\ncalled Deep Poetry. Existing systems for Chinese classical poetry generation\nare mostly template-based and very few of them can accept multi-modal input.\nUnlike previous systems, Deep Poetry uses neural networks that are trained on\nover 200 thousand poems and 3 million ancient Chinese prose. Our system can\naccept plain text, images or artistic conceptions as inputs to generate Chinese\nclassical poetry. More importantly, users are allowed to participate in the\nprocess of writing poetry by our system. For the user's convenience, we deploy\nthe system at the WeChat applet platform, users can use the system on the\nmobile device whenever and wherever possible. The demo video of this paper is\navailable at https://youtu.be/jD1R_u9TA3M.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 11:41:02 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Liu", "Yusen", ""], ["Liu", "Dayiheng", ""], ["Lv", "Jiancheng", ""]]}, {"id": "1911.08249", "submitter": "Sadik Bessou", "authors": "Sadik Bessou, Mohamed Touahria", "title": "An Accuracy-Enhanced Stemming Algorithm for Arabic Information Retrieval", "comments": null, "journal-ref": "Neural Network World, 24(2), p.117-128. 2014", "doi": "10.14311/NNW.2014.24.007", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a method for indexing and retrieving Arabic texts, based\non natural language processing. Our approach exploits the notion of template in\nword stemming and replaces the words by their stems. This technique has proven\nto be effective since it has returned significant relevant retrieval results by\ndecreasing silence during the retrieval phase. Series of experiments have been\nconducted to test the performance of the proposed algorithm ESAIR (Enhanced\nStemmer for Arabic Information Retrieval). The results obtained indicate that\nthe algorithm extracts the exact root with an accuracy rate up to 96% and\nhence, improving information retrieval.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 20:17:06 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Bessou", "Sadik", ""], ["Touahria", "Mohamed", ""]]}, {"id": "1911.08332", "submitter": "Dhananjay Ram", "authors": "Dhananjay Ram, Lesly Miculicich and Herv\\'e Bourlard", "title": "Neural Network based End-to-End Query by Example Spoken Term Detection", "comments": "Submitted to IEEE/ACM TRANSACTIONS ON AUDIO, SPEECH, AND LANGUAGE\n  PROCESSING", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the problem of query by example spoken term detection\n(QbE-STD) in zero-resource scenario. State-of-the-art approaches primarily rely\non dynamic time warping (DTW) based template matching techniques using phone\nposterior or bottleneck features extracted from a deep neural network (DNN). We\nuse both monolingual and multilingual bottleneck features, and show that\nmultilingual features perform increasingly better with more training languages.\nPreviously, it has been shown that the DTW based matching can be replaced with\na CNN based matching while using posterior features. Here, we show that the CNN\nbased matching outperforms DTW based matching using bottleneck features as\nwell. In this case, the feature extraction and pattern matching stages of our\nQbE-STD system are optimized independently of each other. We propose to\nintegrate these two stages in a fully neural network based end-to-end learning\nframework to enable joint optimization of those two stages simultaneously. The\nproposed approaches are evaluated on two challenging multilingual datasets:\nSpoken Web Search 2013 and Query by Example Search on Speech Task 2014,\ndemonstrating in each case significant improvements.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 15:07:07 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Ram", "Dhananjay", ""], ["Miculicich", "Lesly", ""], ["Bourlard", "Herv\u00e9", ""]]}, {"id": "1911.08340", "submitter": "Martin Andrews", "authors": "Martin Andrews, Sam Witteveen", "title": "Unsupervised Natural Question Answering with a Small Model", "comments": "Accepted paper for FEVER workshop at EMNLP-IJCNLP 2019. (4 pages +\n  references)", "journal-ref": null, "doi": "10.18653/v1/D19-6606", "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent (2019-02) demonstration of the power of huge language models such\nas GPT-2 to memorise the answers to factoid questions raises questions about\nthe extent to which knowledge is being embedded directly within these large\nmodels. This short paper describes an architecture through which much smaller\nmodels can also answer such questions - by making use of 'raw' external\nknowledge. The contribution of this work is that the methods presented here\nrely on unsupervised learning techniques, complementing the unsupervised\ntraining of the Language Model. The goal of this line of research is to be able\nto add knowledge explicitly, without extensive training.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 15:18:39 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Andrews", "Martin", ""], ["Witteveen", "Sam", ""]]}, {"id": "1911.08370", "submitter": "Vladimir Vargas-Calder\\'on", "authors": "Vladimir Vargas-Calder\\'on and Nicol\\'as Parra-A. and Jorge E. Camargo\n  and Herbert Vinck-Posada", "title": "Event detection in Colombian security Twitter news using fine-grained\n  latent topic analysis", "comments": "pre-print exposed at CATAI (Bogot\\'a, Colombia)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Cultural and social dynamics are important concepts that must be understood\nin order to grasp what a community cares about. To that end, an excellent\nsource of information on what occurs in a community is the news, especially in\nrecent years, when mass media giants use social networks to communicate and\ninteract with their audience. In this work, we use a method to discover latent\ntopics in tweets from Colombian Twitter news accounts in order to identify the\nmost prominent events in the country. We pay particular attention to security,\nviolence and crime-related tweets because of the violent environment that\nsurrounds Colombian society. The latent topic discovery method that we use\nbuilds vector representations of the tweets by using FastText and finds\nclusters of tweets through the K-means clustering algorithm. The number of\nclusters is found by measuring the $C_V$ coherence for a range of number of\ntopics of the Latent Dirichlet Allocation (LDA) model. We finally use Uniform\nManifold Approximation and Projection (UMAP) for dimensionality reduction to\nvisualise the tweets vectors. Once the clusters related to security, violence\nand crime are identified, we proceed to apply the same method within each\ncluster to perform a fine-grained analysis in which specific events mentioned\nin the news are grouped together. Our method is able to discover event-specific\nsets of news, which is the baseline to perform an extensive analysis of how\npeople engage in Twitter threads on the different types of news, with an\nemphasis on security, violence and crime-related tweets.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 15:58:14 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Vargas-Calder\u00f3n", "Vladimir", ""], ["Parra-A.", "Nicol\u00e1s", ""], ["Camargo", "Jorge E.", ""], ["Vinck-Posada", "Herbert", ""]]}, {"id": "1911.08373", "submitter": "Jibin Wu", "authors": "Jibin Wu, Emre Yilmaz, Malu Zhang, Haizhou Li and Kay Chen Tan", "title": "Deep Spiking Neural Networks for Large Vocabulary Automatic Speech\n  Recognition", "comments": "Submitted to Frontier of Neuroscience", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks (ANN) have become the mainstream acoustic modeling\ntechnique for large vocabulary automatic speech recognition (ASR). A\nconventional ANN features a multi-layer architecture that requires massive\namounts of computation. The brain-inspired spiking neural networks (SNN)\nclosely mimic the biological neural networks and can operate on low-power\nneuromorphic hardware with spike-based computation. Motivated by their\nunprecedented energyefficiency and rapid information processing capability, we\nexplore the use of SNNs for speech recognition. In this work, we use SNNs for\nacoustic modeling and evaluate their performance on several large vocabulary\nrecognition scenarios. The experimental results demonstrate competitive ASR\naccuracies to their ANN counterparts, while require significantly reduced\ncomputational cost and inference time. Integrating the algorithmic power of\ndeep SNNs with energy-efficient neuromorphic hardware, therefore, offer an\nattractive solution for ASR applications running locally on mobile and embedded\ndevices.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 16:09:02 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Wu", "Jibin", ""], ["Yilmaz", "Emre", ""], ["Zhang", "Malu", ""], ["Li", "Haizhou", ""], ["Tan", "Kay Chen", ""]]}, {"id": "1911.08437", "submitter": "Mohammad Hashir", "authors": "Mohammad Hashir and Rapinder Sawhney", "title": "Towards unstructured mortality prediction with free-text clinical notes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Healthcare data continues to flourish yet a relatively small portion, mostly\nstructured, is being utilized effectively for predicting clinical outcomes. The\nrich subjective information available in unstructured clinical notes can\npossibly facilitate higher discrimination but tends to be under-utilized in\nmortality prediction. This work attempts to assess the gain in performance when\nmultiple notes that have been minimally preprocessed are used as an input for\nprediction. A hierarchical architecture consisting of both convolutional and\nrecurrent layers is used to concurrently model the different notes compiled in\nan individual hospital stay. This approach is evaluated on predicting\nin-hospital mortality on the MIMIC-III dataset. On comparison to approaches\nutilizing structured data, it achieved higher metrics despite requiring less\ncleaning and preprocessing. This demonstrates the potential of unstructured\ndata in enhancing mortality prediction and signifies the need to incorporate\nmore raw unstructured data into current clinical prediction methods.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 18:02:06 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Hashir", "Mohammad", ""], ["Sawhney", "Rapinder", ""]]}, {"id": "1911.08460", "submitter": "Tatiana Likhomanenko", "authors": "Gabriel Synnaeve, Qiantong Xu, Jacob Kahn, Tatiana Likhomanenko,\n  Edouard Grave, Vineel Pratap, Anuroop Sriram, Vitaliy Liptchinsky, Ronan\n  Collobert", "title": "End-to-end ASR: from Supervised to Semi-Supervised Learning with Modern\n  Architectures", "comments": "Published at the workshop on Self-supervision in Audio and Speech\n  (SAS) at the 37th International Conference on Machine Learning (ICML 2020),\n  Vienna, Austria", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study pseudo-labeling for the semi-supervised training of ResNet,\nTime-Depth Separable ConvNets, and Transformers for speech recognition, with\neither CTC or Seq2Seq loss functions. We perform experiments on the standard\nLibriSpeech dataset, and leverage additional unlabeled data from LibriVox\nthrough pseudo-labeling. We show that while Transformer-based acoustic models\nhave superior performance with the supervised dataset alone, semi-supervision\nimproves all models across architectures and loss functions and bridges much of\nthe performance gaps between them. In doing so, we reach a new state-of-the-art\nfor end-to-end acoustic models decoded with an external language model in the\nstandard supervised learning setting, and a new absolute state-of-the-art with\nsemi-supervised training. Finally, we study the effect of leveraging different\namounts of unlabeled audio, propose several ways of evaluating the\ncharacteristics of unlabeled audio which improve acoustic modeling, and show\nthat acoustic models trained with more audio rely less on external language\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 18:40:02 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 00:52:22 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2020 00:51:23 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Synnaeve", "Gabriel", ""], ["Xu", "Qiantong", ""], ["Kahn", "Jacob", ""], ["Likhomanenko", "Tatiana", ""], ["Grave", "Edouard", ""], ["Pratap", "Vineel", ""], ["Sriram", "Anuroop", ""], ["Liptchinsky", "Vitaliy", ""], ["Collobert", "Ronan", ""]]}, {"id": "1911.08522", "submitter": "Omar U. Florez", "authors": "Omar U. Florez and Erik Mueller", "title": "Aging Memories Generate More Fluent Dialogue Responses with Memory\n  Augmented Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory Networks have emerged as effective models to incorporate Knowledge\nBases (KB) into neural networks. By storing KB embeddings into a memory\ncomponent, these models can learn meaningful representations that are grounded\nto external knowledge. However, as the memory unit becomes full, the oldest\nmemories are replaced by newer representations.\n  In this paper, we question this approach and provide experimental evidence\nthat conventional Memory Networks store highly correlated vectors during\ntraining. While increasing the memory size mitigates this problem, this also\nleads to overfitting as the memory stores a large number of training latent\nrepresentations. To address these issues, we propose a novel regularization\nmechanism named memory dropout which 1) Samples a single latent vector from the\ndistribution of redundant memories. 2) Ages redundant memories thus increasing\ntheir probability of overwriting them during training. This fully\ndifferentiable technique allows us to achieve state-of-the-art response\ngeneration in the Stanford Multi-Turn Dialogue and Cambridge Restaurant\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 19:34:15 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 02:42:46 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Florez", "Omar U.", ""], ["Mueller", "Erik", ""]]}, {"id": "1911.08554", "submitter": "Sam Shleifer", "authors": "Sam Shleifer, Manish Chablani, Anitha Kannan, Namit Katariya, Xavier\n  Amatriain", "title": "Classification as Decoder: Trading Flexibility for Control in Medical\n  Dialogue", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract. arXiv admin note: substantial text overlap with arXiv:1910.03476", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative seq2seq dialogue systems are trained to predict the next word in\ndialogues that have already occurred. They can learn from large unlabeled\nconversation datasets, build a deeper understanding of conversational context,\nand generate a wide variety of responses. This flexibility comes at the cost of\ncontrol, a concerning tradeoff in doctor/patient interactions. Inaccuracies,\ntypos, or undesirable content in the training data will be reproduced by the\nmodel at inference time. We trade a small amount of labeling effort and some\nloss of response variety in exchange for quality control. More specifically, a\npretrained language model encodes the conversational context, and we finetune a\nclassification head to map an encoded conversational context to a response\nclass, where each class is a noisily labeled group of interchangeable\nresponses. Experts can update these exemplar responses over time as best\npractices change without retraining the classifier or invalidating old training\ndata. Expert evaluation of 775 unseen doctor/patient conversations shows that\nonly 12% of the discriminative model's responses are worse than the what the\ndoctor ended up writing, compared to 18% for the generative model.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2019 01:58:27 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Shleifer", "Sam", ""], ["Chablani", "Manish", ""], ["Kannan", "Anitha", ""], ["Katariya", "Namit", ""], ["Amatriain", "Xavier", ""]]}, {"id": "1911.08648", "submitter": "Zhou Xiaorui", "authors": "Xiaorui Zhou, Senlin Luo, Yunfang Wu", "title": "Co-Attention Hierarchical Network: Generating Coherent Long Distractors\n  for Reading Comprehension", "comments": "8 pages, 3 figures. Accepted by AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reading comprehension, generating sentence-level distractors is a\nsignificant task, which requires a deep understanding of the article and\nquestion. The traditional entity-centered methods can only generate word-level\nor phrase-level distractors. Although recently proposed neural-based methods\nlike sequence-to-sequence (Seq2Seq) model show great potential in generating\ncreative text, the previous neural methods for distractor generation ignore two\nimportant aspects. First, they didn't model the interactions between the\narticle and question, making the generated distractors tend to be too general\nor not relevant to question context. Second, they didn't emphasize the\nrelationship between the distractor and article, making the generated\ndistractors not semantically relevant to the article and thus fail to form a\nset of meaningful options. To solve the first problem, we propose a\nco-attention enhanced hierarchical architecture to better capture the\ninteractions between the article and question, thus guide the decoder to\ngenerate more coherent distractors. To alleviate the second problem, we add an\nadditional semantic similarity loss to push the generated distractors more\nrelevant to the article. Experimental results show that our model outperforms\nseveral strong baselines on automatic metrics, achieving state-of-the-art\nperformance. Further human evaluation indicates that our generated distractors\nare more coherent and more educative compared with those distractors generated\nby baselines.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 00:48:36 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Zhou", "Xiaorui", ""], ["Luo", "Senlin", ""], ["Wu", "Yunfang", ""]]}, {"id": "1911.08673", "submitter": "Zuchao Li", "authors": "Zuchao Li, Hai Zhao, Kevin Parnow", "title": "Global Greedy Dependency Parsing", "comments": "Accepted by AAAI-20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most syntactic dependency parsing models may fall into one of two categories:\ntransition- and graph-based models. The former models enjoy high inference\nefficiency with linear time complexity, but they rely on the stacking or\nre-ranking of partially-built parse trees to build a complete parse tree and\nare stuck with slower training for the necessity of dynamic oracle training.\nThe latter, graph-based models, may boast better performance but are\nunfortunately marred by polynomial time inference. In this paper, we propose a\nnovel parsing order objective, resulting in a novel dependency parsing model\ncapable of both global (in sentence scope) feature extraction as in graph\nmodels and linear time inference as in transitional models. The proposed global\ngreedy parser only uses two arc-building actions, left and right arcs, for\nprojective parsing. When equipped with two extra non-projective arc-building\nactions, the proposed parser may also smoothly support non-projective parsing.\nUsing multiple benchmark treebanks, including the Penn Treebank (PTB), the\nCoNLL-X treebanks, and the Universal Dependency Treebanks, we evaluate our\nparser and demonstrate that the proposed novel parser achieves good performance\nwith faster training and decoding.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 02:57:53 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 06:24:18 GMT"}, {"version": "v3", "created": "Wed, 12 Feb 2020 12:19:07 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Li", "Zuchao", ""], ["Zhao", "Hai", ""], ["Parnow", "Kevin", ""]]}, {"id": "1911.08698", "submitter": "Qintong Li", "authors": "Qintong Li, Hongshen Chen, Zhaochun Ren, Pengjie Ren, Zhaopeng Tu,\n  Zhumin Chen", "title": "EmpDG: Multiresolution Interactive Empathetic Dialogue Generation", "comments": "Accepted by COLING 2020. arXiv admin note: text overlap with\n  arXiv:2009.09708", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A humanized dialogue system is expected to generate empathetic replies, which\nshould be sensitive to the users' expressed emotion. The task of empathetic\ndialogue generation is proposed to address this problem. The essential\nchallenges lie in accurately capturing the nuances of human emotion and\nconsidering the potential of user feedback, which are overlooked by the\nmajority of existing work. In response to this problem, we propose a\nmulti-resolution adversarial model -- EmpDG, to generate more empathetic\nresponses. EmpDG exploits both the coarse-grained dialogue-level and\nfine-grained token-level emotions, the latter of which helps to better capture\nthe nuances of user emotion. In addition, we introduce an interactive\nadversarial learning framework which exploits the user feedback, to identify\nwhether the generated responses evoke emotion perceptivity in dialogues.\nExperimental results show that the proposed approach significantly outperforms\nthe state-of-the-art baselines in both content quality and emotion\nperceptivity.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 04:25:20 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 13:19:03 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Li", "Qintong", ""], ["Chen", "Hongshen", ""], ["Ren", "Zhaochun", ""], ["Ren", "Pengjie", ""], ["Tu", "Zhaopeng", ""], ["Chen", "Zhumin", ""]]}, {"id": "1911.08706", "submitter": "Xing Niu", "authors": "Xing Niu, Marine Carpuat", "title": "Controlling Neural Machine Translation Formality with Synthetic\n  Supervision", "comments": "Accepted at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work aims to produce translations that convey source language content at\na formality level that is appropriate for a particular audience. Framing this\nproblem as a neural sequence-to-sequence task ideally requires training\ntriplets consisting of a bilingual sentence pair labeled with target language\nformality. However, in practice, available training examples are limited to\nEnglish sentence pairs of different styles, and bilingual parallel sentences of\nunknown formality. We introduce a novel training scheme for multi-task models\nthat automatically generates synthetic training triplets by inferring the\nmissing element on the fly, thus enabling end-to-end training. Comprehensive\nautomatic and human assessments show that our best model outperforms existing\nmodels by producing translations that better match desired formality levels\nwhile preserving the source meaning.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 04:54:21 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 00:55:36 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Niu", "Xing", ""], ["Carpuat", "Marine", ""]]}, {"id": "1911.08743", "submitter": "Preslav Nakov", "authors": "Todor Mihaylov, Preslav Nakov", "title": "SemanticZ at SemEval-2016 Task 3: Ranking Relevant Answers in Community\n  Question Answering Using Semantic Similarity Based on Fine-tuned Word\n  Embeddings", "comments": "community question answering, semantic similarity", "journal-ref": "SemEval-2016", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe our system for finding good answers in a community forum, as\ndefined in SemEval-2016, Task 3 on Community Question Answering. Our approach\nrelies on several semantic similarity features based on fine-tuned word\nembeddings and topics similarities. In the main Subtask C, our primary\nsubmission was ranked third, with a MAP of 51.68 and accuracy of 69.94. In\nSubtask A, our primary submission was also third, with MAP of 77.58 and\naccuracy of 73.39.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 07:16:16 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Mihaylov", "Todor", ""], ["Nakov", "Preslav", ""]]}, {"id": "1911.08755", "submitter": "Preslav Nakov", "authors": "Shafiq Joty, Alberto Barr\\'on-Cede\\~no, Giovanni Da San Martino,\n  Simone Filice, Llu\\'is M\\`arquez, Alessandro Moschitti, Preslav Nakov", "title": "Global Thread-Level Inference for Comment Classification in Community\n  Question Answering", "comments": "community question answering, thread-level inference, graph-cut,\n  inductive logic programming", "journal-ref": "EMNLP-2015", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community question answering, a recent evolution of question answering in the\nWeb context, allows a user to quickly consult the opinion of a number of people\non a particular topic, thus taking advantage of the wisdom of the crowd. Here\nwe try to help the user by deciding automatically which answers are good and\nwhich are bad for a given question. In particular, we focus on exploiting the\noutput structure at the thread level in order to make more consistent global\ndecisions. More specifically, we exploit the relations between pairs of\ncomments at any distance in the thread, which we incorporate in a graph-cut and\nin an ILP frameworks. We evaluated our approach on the benchmark dataset of\nSemEval-2015 Task 3. Results improved over the state of the art, confirming the\nimportance of using thread level information.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 08:09:36 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Joty", "Shafiq", ""], ["Barr\u00f3n-Cede\u00f1o", "Alberto", ""], ["Martino", "Giovanni Da San", ""], ["Filice", "Simone", ""], ["M\u00e0rquez", "Llu\u00eds", ""], ["Moschitti", "Alessandro", ""], ["Nakov", "Preslav", ""]]}, {"id": "1911.08762", "submitter": "Preslav Nakov", "authors": "Preslav Nakov", "title": "Paraphrasing Verbs for Noun Compound Interpretation", "comments": "noun compounds, paraphrasing verbs, semantic interpretation,\n  multi-word expressions, MWEs", "journal-ref": "MWE-2008", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important challenge for the automatic analysis of English written text is\nthe abundance of noun compounds: sequences of nouns acting as a single noun. In\nour view, their semantics is best characterized by the set of all possible\nparaphrasing verbs, with associated weights, e.g., malaria mosquito is carry\n(23), spread (16), cause (12), transmit (9), etc. Using Amazon's Mechanical\nTurk, we collect paraphrasing verbs for 250 noun-noun compounds previously\nproposed in the linguistic literature, thus creating a valuable resource for\nnoun compound interpretation. Using these verbs, we further construct a dataset\nof pairs of sentences representing a special kind of textual entailment task,\nwhere a binary decision is to be made about whether an expression involving a\nverb and two nouns can be transformed into a noun compound, while preserving\nthe sentence meaning.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 08:29:10 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Nakov", "Preslav", ""]]}, {"id": "1911.08776", "submitter": "Siyu Yao", "authors": "Siyu Yao, Ruijie Wang, Shen Sun, Derui Bu, Jun Liu", "title": "Joint Embedding Learning of Educational Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an efficient model for knowledge organization, the knowledge graph has\nbeen widely adopted in several fields, e.g., biomedicine, sociology, and\neducation. And there is a steady trend of learning embedding representations of\nknowledge graphs to facilitate knowledge graph construction and downstream\ntasks. In general, knowledge graph embedding techniques aim to learn vectorized\nrepresentations which preserve the structural information of the graph. And\nconventional embedding learning models rely on structural relationships among\nentities and relations. However, in educational knowledge graphs, structural\nrelationships are not the focus. Instead, rich literals of the graphs are more\nvaluable. In this paper, we focus on this problem and propose a novel model for\nembedding learning of educational knowledge graphs. Our model considers both\nstructural and literal information and jointly learns embedding\nrepresentations. Three experimental graphs were constructed based on an\neducational knowledge graph which has been applied in real-world teaching. We\nconducted two experiments on the three graphs and other common benchmark\ngraphs. The experimental results proved the effectiveness of our model and its\nsuperiority over other baselines when processing educational knowledge graphs.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 09:05:11 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 14:52:03 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Yao", "Siyu", ""], ["Wang", "Ruijie", ""], ["Sun", "Shen", ""], ["Bu", "Derui", ""], ["Liu", "Jun", ""]]}, {"id": "1911.08779", "submitter": "Zheng Wang", "authors": "Donglin Chen, Jianbin Fang, Chuanfu Xu, Shizhao Chen, Zheng Wang", "title": "Characterizing Scalability of Sparse Matrix-Vector Multiplications on\n  Phytium FT-2000+ Many-cores", "comments": "Accepted to be published at IJPP", "journal-ref": null, "doi": "10.1007/s10766-019-00646-x", "report-no": null, "categories": "cs.DC cs.CL cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding the scalability of parallel programs is crucial for software\noptimization and hardware architecture design. As HPC hardware is moving\ntowards many-core design, it becomes increasingly difficult for a parallel\nprogram to make effective use of all available processor cores. This makes\nscalability analysis increasingly important. This paper presents a quantitative\nstudy for characterizing the scalability of sparse matrix-vector\nmultiplications (SpMV) on Phytium FT-2000+, an ARM-based many-core architecture\nfor HPC computing. We choose to study SpMV as it is a common operation in\nscientific and HPC applications. Due to the newness of ARM-based many-core\narchitectures, there is little work on understanding the SpMV scalability on\nsuch hardware design. To close the gap, we carry out a large-scale empirical\nevaluation involved over 1,000 representative SpMV datasets. We show that,\nwhile many computation-intensive SpMV applications contain extensive\nparallelism, achieving a linear speedup is non-trivial on Phytium FT-2000+. To\nbetter understand what software and hardware parameters are most important for\ndetermining the scalability of a given SpMV kernel, we develop a performance\nanalytical model based on the regression tree. We show that our model is highly\neffective in characterizing SpMV scalability, offering useful insights to help\napplication developers for better optimizing SpMV on an emerging HPC\narchitecture.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 09:12:58 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Chen", "Donglin", ""], ["Fang", "Jianbin", ""], ["Xu", "Chuanfu", ""], ["Chen", "Shizhao", ""], ["Wang", "Zheng", ""]]}, {"id": "1911.08782", "submitter": "Isabelle Augenstein", "authors": "Luna De Bruyne, Pepa Atanasova, Isabelle Augenstein", "title": "Joint Emotion Label Space Modelling for Affect Lexica", "comments": "Computer Speech and Language journal, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion lexica are commonly used resources to combat data poverty in\nautomatic emotion detection. However, vocabulary coverage issues, differences\nin construction method and discrepancies in emotion framework and\nrepresentation result in a heterogeneous landscape of emotion detection\nresources, calling for a unified approach to utilising them. To combat this, we\npresent an extended emotion lexicon of 30,273 unique entries, which is a result\nof merging eight existing emotion lexica by means of a multi-view variational\nautoencoder (VAE). We showed that a VAE is a valid approach for combining\nlexica with different label spaces into a joint emotion label space with a\nchosen number of dimensions, and that these dimensions are still interpretable.\nWe tested the utility of the unified VAE lexicon by employing the lexicon\nvalues as features in an emotion detection model. We found that the VAE lexicon\noutperformed individual lexica, but contrary to our expectations, it did not\noutperform a naive concatenation of lexica, although it did contribute to the\nnaive concatenation when added as an extra lexicon. Furthermore, using lexicon\ninformation as additional features on top of state-of-the-art language models\nusually resulted in a better performance than when no lexicon information was\nused.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 09:24:38 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 11:01:54 GMT"}, {"version": "v3", "created": "Fri, 18 Jun 2021 05:34:57 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["De Bruyne", "Luna", ""], ["Atanasova", "Pepa", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "1911.08794", "submitter": "Ehud Reiter", "authors": "Ehud Reiter", "title": "Natural Language Generation Challenges for Explainable AI", "comments": "Presented at the NL4XAI workshop\n  (https://sites.google.com/view/nl4xai2019/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Good quality explanations of artificial intelligence (XAI) reasoning must be\nwritten (and evaluated) for an explanatory purpose, targeted towards their\nreaders, have a good narrative and causal structure, and highlight where\nuncertainty and data quality affect the AI output. I discuss these challenges\nfrom a Natural Language Generation (NLG) perspective, and highlight four\nspecific NLG for XAI research challenges.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 09:52:23 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Reiter", "Ehud", ""]]}, {"id": "1911.08827", "submitter": "Ofer Givoli", "authors": "Ofer Givoli and Roi Reichart", "title": "Zero-Shot Semantic Parsing for Instructions", "comments": "ACL 2019", "journal-ref": "In Proceedings of the 57th Annual Meeting of the Association for\n  Computational Linguistics, pages 4454-4464 (2019)", "doi": "10.18653/v1/P19-1438", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a zero-shot semantic parsing task: parsing instructions into\ncompositional logical forms, in domains that were not seen during training. We\npresent a new dataset with 1,390 examples from 7 application domains (e.g. a\ncalendar or a file manager), each example consisting of a triplet: (a) the\napplication's initial state, (b) an instruction, to be carried out in the\ncontext of that state, and (c) the state of the application after carrying out\nthe instruction. We introduce a new training algorithm that aims to train a\nsemantic parser on examples from a set of source domains, so that it can\neffectively parse instructions from an unknown target domain. We integrate our\nalgorithm into the floating parser of Pasupat and Liang (2015), and further\naugment the parser with features and a logical form candidate filtering logic,\nto support zero-shot adaptation. Our experiments with various zero-shot\nadaptation setups demonstrate substantial performance gains over a non-adapted\nparser.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 11:14:07 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Givoli", "Ofer", ""], ["Reichart", "Roi", ""]]}, {"id": "1911.08829", "submitter": "Hessel Haagsma", "authors": "Hessel Haagsma and Malvina Nissim and Johan Bos", "title": "Casting a Wide Net: Robust Extraction of Potentially Idiomatic\n  Expressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Idiomatic expressions like `out of the woods' and `up the ante' present a\nrange of difficulties for natural language processing applications. We present\nwork on the annotation and extraction of what we term potentially idiomatic\nexpressions (PIEs), a subclass of multiword expressions covering both literal\nand non-literal uses of idiomatic expressions. Existing corpora of PIEs are\nsmall and have limited coverage of different PIE types, which hampers research.\nTo further progress on the extraction and disambiguation of potentially\nidiomatic expressions, larger corpora of PIEs are required. In addition, larger\ncorpora are a potential source for valuable linguistic insights into idiomatic\nexpressions and their variability. We propose automatic tools to facilitate the\nbuilding of larger PIE corpora, by investigating the feasibility of using\ndictionary-based extraction of PIEs as a pre-extraction tool for English. We do\nthis by assessing the reliability and coverage of idiom dictionaries, the\nannotation of a PIE corpus, and the automatic extraction of PIEs from a large\ncorpus. Results show that combinations of dictionaries are a reliable source of\nidiomatic expressions, that PIEs can be annotated with a high reliability\n(0.74-0.91 Fleiss' Kappa), and that parse-based PIE extraction yields highly\naccurate performance (88% F1-score). Combining complementary PIE extraction\nmethods increases reliability further, to over 92% F1-score. Moreover, the\nextraction method presented here could be extended to other types of multiword\nexpressions and to other languages, given that sufficient NLP tools are\navailable.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 11:15:47 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Haagsma", "Hessel", ""], ["Nissim", "Malvina", ""], ["Bos", "Johan", ""]]}, {"id": "1911.08836", "submitter": "R\\'emi Juge", "authors": "Najah-Imane Bentabet, R\\'emi Juge, Sira Ferradans", "title": "Table-Of-Contents generation on contemporary documents", "comments": "ICDAR 2019 Main Conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generation of precise and detailed Table-Of-Contents (TOC) from a\ndocument is a problem of major importance for document understanding and\ninformation extraction. Despite its importance, it is still a challenging task,\nespecially for non-standardized documents with rich layout information such as\ncommercial documents. In this paper, we present a new neural-based pipeline for\nTOC generation applicable to any searchable document. Unlike previous methods,\nwe do not use semantic labeling nor assume the presence of parsable TOC pages\nin the document. Moreover, we analyze the influence of using external knowledge\nencoded as a template. We empirically show that this approach is only useful in\na very low resource environment. Finally, we propose a new domain-specific data\nset that sheds some light on the difficulties of TOC generation in real-world\ndocuments. The proposed method shows better performance than the\nstate-of-the-art on a public data set and on the newly released data set.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 11:29:47 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Bentabet", "Najah-Imane", ""], ["Juge", "R\u00e9mi", ""], ["Ferradans", "Sira", ""]]}, {"id": "1911.08870", "submitter": "Parnia Bahar", "authors": "Parnia Bahar, Tobias Bieschke, and Hermann Ney", "title": "A Comparative Study on End-to-end Speech to Text Translation", "comments": "8 pages, IEEE Automatic Speech Recognition and Understanding Workshop\n  (ASRU), Sentosa, Singapore, December 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep learning show that end-to-end speech to text\ntranslation model is a promising approach to direct the speech translation\nfield. In this work, we provide an overview of different end-to-end\narchitectures, as well as the usage of an auxiliary connectionist temporal\nclassification (CTC) loss for better convergence. We also investigate on\npre-training variants such as initializing different components of a model\nusing pre-trained models, and their impact on the final performance, which\ngives boosts up to 4% in BLEU and 5% in TER. Our experiments are performed on\n270h IWSLT TED-talks En->De, and 100h LibriSpeech Audiobooks En->Fr. We also\nshow improvements over the current end-to-end state-of-the-art systems on both\ntasks.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 13:01:56 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Bahar", "Parnia", ""], ["Bieschke", "Tobias", ""], ["Ney", "Hermann", ""]]}, {"id": "1911.08876", "submitter": "Parnia Bahar", "authors": "Parnia Bahar, Albert Zeyer, Ralf Schl\\\"uter and Hermann Ney", "title": "On Using SpecAugment for End-to-End Speech Translation", "comments": "8 pages, International Workshop on Spoken Language Translation\n  (IWSLT), Hong Kong, China, November 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates a simple data augmentation technique, SpecAugment, for\nend-to-end speech translation. SpecAugment is a low-cost implementation method\napplied directly to the audio input features and it consists of masking blocks\nof frequency channels, and/or time steps. We apply SpecAugment on end-to-end\nspeech translation tasks and achieve up to +2.2\\% \\BLEU on LibriSpeech\nAudiobooks En->Fr and +1.2% on IWSLT TED-talks En->De by alleviating\noverfitting to some extent. We also examine the effectiveness of the method in\na variety of data scenarios and show that the method also leads to significant\nimprovements in various data conditions irrespective of the amount of training\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 13:11:41 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Bahar", "Parnia", ""], ["Zeyer", "Albert", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "1911.08888", "submitter": "Parnia Bahar", "authors": "Parnia Bahar, Albert Zeyer, Ralf Schl\\\"uter, and Hermann Ney", "title": "On using 2D sequence-to-sequence models for speech recognition", "comments": "5 pages, IEEE International Conference on Acoustics, Speech, and\n  Signal Processing (ICASSP), Brighton, UK, May 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based sequence-to-sequence models have shown promising results in\nautomatic speech recognition. Using these architectures, one-dimensional input\nand output sequences are related by an attention approach, thereby replacing\nmore explicit alignment processes, like in classical HMM-based modeling. In\ncontrast, here we apply a novel two-dimensional long short-term memory (2DLSTM)\narchitecture to directly model the input/output relation between audio/feature\nvector sequences and word sequences. The proposed model is an alternative model\nsuch that instead of using any type of attention components, we apply a 2DLSTM\nlayer to assimilate the context from both input observations and output\ntranscriptions. The experimental evaluation on the Switchboard 300h automatic\nspeech recognition task shows word error rates for the 2DLSTM model that are\ncompetitive to end-to-end attention-based model.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 13:25:06 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Bahar", "Parnia", ""], ["Zeyer", "Albert", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "1911.08891", "submitter": "Ting-En Lin", "authors": "Ting-En Lin, Hua Xu, Hanlei Zhang", "title": "Discovering New Intents via Constrained Deep Adaptive Clustering with\n  Cluster Refinement", "comments": "Accepted by AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying new user intents is an essential task in the dialogue system.\nHowever, it is hard to get satisfying clustering results since the definition\nof intents is strongly guided by prior knowledge. Existing methods incorporate\nprior knowledge by intensive feature engineering, which not only leads to\noverfitting but also makes it sensitive to the number of clusters. In this\npaper, we propose constrained deep adaptive clustering with cluster refinement\n(CDAC+), an end-to-end clustering method that can naturally incorporate\npairwise constraints as prior knowledge to guide the clustering process.\nMoreover, we refine the clusters by forcing the model to learn from the high\nconfidence assignments. After eliminating low confidence assignments, our\napproach is surprisingly insensitive to the number of clusters. Experimental\nresults on the three benchmark datasets show that our method can yield\nsignificant improvements over strong baselines.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 13:26:43 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Lin", "Ting-En", ""], ["Xu", "Hua", ""], ["Zhang", "Hanlei", ""]]}, {"id": "1911.08895", "submitter": "Jens Heitkaemper", "authors": "Jens Heitkaemper and Darius Jakobeit and Christoph Boeddeker and Lukas\n  Drude and Reinhold Haeb-Umbach", "title": "Demystifying TasNet: A Dissecting Approach", "comments": "Accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years time domain speech separation has excelled over frequency\ndomain separation in single channel scenarios and noise-free environments. In\nthis paper we dissect the gains of the time-domain audio separation network\n(TasNet) approach by gradually replacing components of an utterance-level\npermutation invariant training (u-PIT) based separation system in the frequency\ndomain until the TasNet system is reached, thus blending components of\nfrequency domain approaches with those of time domain approaches. Some of the\nintermediate variants achieve comparable signal-to-distortion ratio (SDR) gains\nto TasNet, but retain the advantage of frequency domain processing:\ncompatibility with classic signal processing tools such as frequency-domain\nbeamforming and the human interpretability of the masks. Furthermore, we show\nthat the scale invariant signal-to-distortion ratio (si-SDR) criterion used as\nloss function in TasNet is related to a logarithmic mean square error criterion\nand that it is this criterion which contributes most reliable to the\nperformance advantage of TasNet. Finally, we critically assess which gains in a\nnoise-free single channel environment generalize to more realistic reverberant\nconditions.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 13:28:34 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 11:46:57 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Heitkaemper", "Jens", ""], ["Jakobeit", "Darius", ""], ["Boeddeker", "Christoph", ""], ["Drude", "Lukas", ""], ["Haeb-Umbach", "Reinhold", ""]]}, {"id": "1911.08915", "submitter": "Diego Espitia", "authors": "Diego Espitia, Hern\\'an Larralde", "title": "Universal and non-universal text statistics: Clustering coefficient for\n  language identification", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": "10.1016/j.physa.2019.123905", "report-no": null, "categories": "physics.soc-ph cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we analyze statistical properties of 91 relatively small texts\nin 7 different languages (Spanish, English, French, German, Turkish, Russian,\nIcelandic) as well as texts with randomly inserted spaces. Despite the size\n(around 11260 different words), the well known universal statistical laws --\nnamely Zipf and Herdan-Heap's laws -- are confirmed, and are in close agreement\nwith results obtained elsewhere. We also construct a word co-occurrence network\nof each text. While the degree distribution is again universal, we note that\nthe distribution of Clustering Coefficients, which depend strongly on the local\nstructure of networks, can be used to differentiate between languages, as well\nas to distinguish natural languages from random texts.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 21:39:19 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 01:26:11 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Espitia", "Diego", ""], ["Larralde", "Hern\u00e1n", ""]]}, {"id": "1911.08935", "submitter": "Guanglin Niu", "authors": "Guanglin Niu, Yongfei Zhang, Bo Li, Peng Cui, Si Liu, Jingyang Li,\n  Xiaowei Zhang", "title": "Rule-Guided Compositional Representation Learning on Knowledge Graphs", "comments": "The full version of a paper accepted to AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning on a knowledge graph (KG) is to embed entities and\nrelations of a KG into low-dimensional continuous vector spaces. Early KG\nembedding methods only pay attention to structured information encoded in\ntriples, which would cause limited performance due to the structure sparseness\nof KGs. Some recent attempts consider paths information to expand the structure\nof KGs but lack explainability in the process of obtaining the path\nrepresentations. In this paper, we propose a novel Rule and Path-based Joint\nEmbedding (RPJE) scheme, which takes full advantage of the explainability and\naccuracy of logic rules, the generalization of KG embedding as well as the\nsupplementary semantic structure of paths. Specifically, logic rules of\ndifferent lengths (the number of relations in rule body) in the form of Horn\nclauses are first mined from the KG and elaborately encoded for representation\nlearning. Then, the rules of length 2 are applied to compose paths accurately\nwhile the rules of length 1 are explicitly employed to create semantic\nassociations among relations and constrain relation embeddings. Besides, the\nconfidence level of each rule is also considered in optimization to guarantee\nthe availability of applying the rule to representation learning. Extensive\nexperimental results illustrate that RPJE outperforms other state-of-the-art\nbaselines on KG completion task, which also demonstrate the superiority of\nutilizing logic rules as well as paths for improving the accuracy and\nexplainability of representation learning.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 14:38:58 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 15:33:17 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Niu", "Guanglin", ""], ["Zhang", "Yongfei", ""], ["Li", "Bo", ""], ["Cui", "Peng", ""], ["Liu", "Si", ""], ["Li", "Jingyang", ""], ["Zhang", "Xiaowei", ""]]}, {"id": "1911.08936", "submitter": "Wei Hu", "authors": "Zequn Sun, Chengming Wang, Wei Hu, Muhao Chen, Jian Dai, Wei Zhang,\n  Yuzhong Qu", "title": "Knowledge Graph Alignment Network with Gated Multi-hop Neighborhood\n  Aggregation", "comments": "Accepted by the 34th AAAI Conference on Artificial Intelligence (AAAI\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have emerged as a powerful paradigm for\nembedding-based entity alignment due to their capability of identifying\nisomorphic subgraphs. However, in real knowledge graphs (KGs), the counterpart\nentities usually have non-isomorphic neighborhood structures, which easily\ncauses GNNs to yield different representations for them. To tackle this\nproblem, we propose a new KG alignment network, namely AliNet, aiming at\nmitigating the non-isomorphism of neighborhood structures in an end-to-end\nmanner. As the direct neighbors of counterpart entities are usually dissimilar\ndue to the schema heterogeneity, AliNet introduces distant neighbors to expand\nthe overlap between their neighborhood structures. It employs an attention\nmechanism to highlight helpful distant neighbors and reduce noises. Then, it\ncontrols the aggregation of both direct and distant neighborhood information\nusing a gating mechanism. We further propose a relation loss to refine entity\nrepresentations. We perform thorough experiments with detailed ablation studies\nand analyses on five entity alignment datasets, demonstrating the effectiveness\nof AliNet.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 14:40:23 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Sun", "Zequn", ""], ["Wang", "Chengming", ""], ["Hu", "Wei", ""], ["Chen", "Muhao", ""], ["Dai", "Jian", ""], ["Zhang", "Wei", ""], ["Qu", "Yuzhong", ""]]}, {"id": "1911.08946", "submitter": "Sergei Monakhov", "authors": "Sergei Monakhov", "title": "Understanding Troll Writing as a Linguistic Phenomenon", "comments": "30 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current study yielded a number of important findings. We managed to build\na neural network that achieved an accuracy score of 91 per cent in classifying\ntroll and genuine tweets. By means of regression analysis, we identified a\nnumber of features that make a tweet more susceptible to correct labelling and\nfound that they are inherently present in troll tweets as a special type of\ndiscourse. We hypothesised that those features are grounded in the\nsociolinguistic limitations of troll writing, which can be best described as a\ncombination of two factors: speaking with a purpose and trying to mask the\npurpose of speaking. Next, we contended that the orthogonal nature of these\nfactors must necessarily result in the skewed distribution of many different\nlanguage parameters of troll messages. Having chosen as an example distribution\nof the topics and vocabulary associated with those topics, we showed some very\npronounced distributional anomalies, thus confirming our prediction.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 19:49:50 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Monakhov", "Sergei", ""]]}, {"id": "1911.08962", "submitter": "Haoxi Zhong", "authors": "Chaojun Xiao and Haoxi Zhong and Zhipeng Guo and Cunchao Tu and\n  Zhiyuan Liu and Maosong Sun and Tianyang Zhang and Xianpei Han and Zhen Hu\n  and Heng Wang and Jianfeng Xu", "title": "CAIL2019-SCM: A Dataset of Similar Case Matching in Legal Domain", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce CAIL2019-SCM, Chinese AI and Law 2019 Similar\nCase Matching dataset. CAIL2019-SCM contains 8,964 triplets of cases published\nby the Supreme People's Court of China. CAIL2019-SCM focuses on detecting\nsimilar cases, and the participants are required to check which two cases are\nmore similar in the triplets. There are 711 teams who participated in this\nyear's competition, and the best team has reached a score of 71.88. We have\nalso implemented several baselines to help researchers better understand this\ntask. The dataset and more details can be found from\nhttps://github.com/china-ai-law-challenge/CAIL2019/tree/master/scm.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 15:23:59 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 03:25:35 GMT"}, {"version": "v3", "created": "Mon, 25 Nov 2019 14:26:52 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Xiao", "Chaojun", ""], ["Zhong", "Haoxi", ""], ["Guo", "Zhipeng", ""], ["Tu", "Cunchao", ""], ["Liu", "Zhiyuan", ""], ["Sun", "Maosong", ""], ["Zhang", "Tianyang", ""], ["Han", "Xianpei", ""], ["Hu", "Zhen", ""], ["Wang", "Heng", ""], ["Xu", "Jianfeng", ""]]}, {"id": "1911.08976", "submitter": "Martin Andrews", "authors": "Yew Ken Chia, Sam Witteveen, Martin Andrews", "title": "Red Dragon AI at TextGraphs 2019 Shared Task: Language Model Assisted\n  Explanation Generation", "comments": "Accepted paper for TextGraphs-13 workshop at EMNLP-IJCNLP 2019. (5\n  pages including references)", "journal-ref": null, "doi": "10.18653/v1/D19-5311", "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The TextGraphs-13 Shared Task on Explanation Regeneration asked participants\nto develop methods to reconstruct gold explanations for elementary science\nquestions. Red Dragon AI's entries used the language of the questions and\nexplanation text directly, rather than a constructing a separate graph-like\nrepresentation. Our leaderboard submission placed us 3rd in the competition,\nbut we present here three methods of increasing sophistication, each of which\nscored successively higher on the test set after the competition close.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 15:41:47 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Chia", "Yew Ken", ""], ["Witteveen", "Sam", ""], ["Andrews", "Martin", ""]]}, {"id": "1911.09075", "submitter": "Wenxiang Jiao", "authors": "Wenxiang Jiao, Michael R. Lyu, Irwin King", "title": "Real-Time Emotion Recognition via Attention Gated Hierarchical Memory\n  Network", "comments": "AAAI 2020, 8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time emotion recognition (RTER) in conversations is significant for\ndeveloping emotionally intelligent chatting machines. Without the future\ncontext in RTER, it becomes critical to build the memory bank carefully for\ncapturing historical context and summarize the memories appropriately to\nretrieve relevant information. We propose an Attention Gated Hierarchical\nMemory Network (AGHMN) to address the problems of prior work: (1) Commonly used\nconvolutional neural networks (CNNs) for utterance feature extraction are less\ncompatible in the memory modules; (2) Unidirectional gated recurrent units\n(GRUs) only allow each historical utterance to have context before it,\npreventing information propagation in the opposite direction; (3) The Soft\nAttention for summarizing loses the positional and ordering information of\nmemories, regardless of how the memory bank is built. Particularly, we propose\na Hierarchical Memory Network (HMN) with a bidirectional GRU (BiGRU) as the\nutterance reader and a BiGRU fusion layer for the interaction between\nhistorical utterances. For memory summarizing, we propose an Attention GRU\n(AGRU) where we utilize the attention weights to update the internal state of\nGRU. We further promote the AGRU to a bidirectional variant (BiAGRU) to balance\nthe contextual information from recent memories and that from distant memories.\nWe conduct experiments on two emotion conversation datasets with extensive\nanalysis, demonstrating the efficacy of our AGHMN models.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 18:27:22 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Jiao", "Wenxiang", ""], ["Lyu", "Michael R.", ""], ["King", "Irwin", ""]]}, {"id": "1911.09194", "submitter": "Angela Fan", "authors": "Angela Fan, Jack Urbanek, Pratik Ringshia, Emily Dinan, Emma Qian,\n  Siddharth Karamcheti, Shrimai Prabhumoye, Douwe Kiela, Tim Rocktaschel,\n  Arthur Szlam, Jason Weston", "title": "Generating Interactive Worlds with Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Procedurally generating cohesive and interesting game environments is\nchallenging and time-consuming. In order for the relationships between the game\nelements to be natural, common-sense has to be encoded into arrangement of the\nelements. In this work, we investigate a machine learning approach for world\ncreation using content from the multi-player text adventure game environment\nLIGHT. We introduce neural network based models to compositionally arrange\nlocations, characters, and objects into a coherent whole. In addition to\ncreating worlds based on existing elements, our models can generate new game\ncontent. Humans can also leverage our models to interactively aid in\nworldbuilding. We show that the game environments created with our approach are\ncohesive, diverse, and preferred by human evaluators compared to other machine\nlearning based world construction algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 22:20:52 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 19:46:21 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Fan", "Angela", ""], ["Urbanek", "Jack", ""], ["Ringshia", "Pratik", ""], ["Dinan", "Emily", ""], ["Qian", "Emma", ""], ["Karamcheti", "Siddharth", ""], ["Prabhumoye", "Shrimai", ""], ["Kiela", "Douwe", ""], ["Rocktaschel", "Tim", ""], ["Szlam", "Arthur", ""], ["Weston", "Jason", ""]]}, {"id": "1911.09241", "submitter": "Saku Sugawara", "authors": "Saku Sugawara, Pontus Stenetorp, Kentaro Inui, Akiko Aizawa", "title": "Assessing the Benchmarking Capacity of Machine Reading Comprehension\n  Datasets", "comments": "11 pages, AAAI2020, with extra examples, data:\n  https://github.com/Alab-NII/mrc-ablation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing analysis work in machine reading comprehension (MRC) is largely\nconcerned with evaluating the capabilities of systems. However, the\ncapabilities of datasets are not assessed for benchmarking language\nunderstanding precisely. We propose a semi-automated, ablation-based\nmethodology for this challenge; By checking whether questions can be solved\neven after removing features associated with a skill requisite for language\nunderstanding, we evaluate to what degree the questions do not require the\nskill. Experiments on 10 datasets (e.g., CoQA, SQuAD v2.0, and RACE) with a\nstrong baseline model show that, for example, the relative scores of a baseline\nmodel provided with content words only and with shuffled sentence words in the\ncontext are on average 89.2% and 78.5% of the original score, respectively.\nThese results suggest that most of the questions already answered correctly by\nthe model do not necessarily require grammatical and complex reasoning. For\nprecise benchmarking, MRC datasets will need to take extra care in their design\nto ensure that questions can correctly evaluate the intended skills.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 02:04:52 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Sugawara", "Saku", ""], ["Stenetorp", "Pontus", ""], ["Inui", "Kentaro", ""], ["Aizawa", "Akiko", ""]]}, {"id": "1911.09242", "submitter": "Son Doan <", "authors": "Son Doan, Amanda Ritchart, Nicholas Perry, Juan D Chaparro, Mike\n  Conway", "title": "How Do You #relax When You're #stressed? A Content Analysis and\n  Infodemiology Study of Stress-Related Tweets", "comments": "38 pages,12 figures, 6 tables, 5 Appendix (full version) -- shorter\n  version published in JMIR Public Health Surveill 2017;3(2):e35", "journal-ref": "JMIR Public Health Surveill 2017;3(2):e35", "doi": "10.2196/publichealth.5939", "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background: Stress is a contributing factor to many major health problems in\nthe United States, such as heart disease, depression, and autoimmune diseases.\nRelaxation is often recommended in mental health treatment as a frontline\nstrategy to reduce stress, thereby improving health conditions.\n  Objective: The objective of our study was to understand how people express\ntheir feelings of stress and relaxation through Twitter messages.\n  Methods: We first performed a qualitative content analysis of 1326 and 781\ntweets containing the keywords \"stress\" and \"relax\", respectively. We then\ninvestigated the use of machine learning algorithms to automatically classify\ntweets as stress versus non stress and relaxation versus non relaxation.\nFinally, we applied these classifiers to sample datasets drawn from 4 cities\nwith the goal of evaluating the extent of any correlation between our automatic\nclassification of tweets and results from public stress surveys.\n  Results: Content analysis showed that the most frequent topic of stress\ntweets was education, followed by work and social relationships. The most\nfrequent topic of relaxation tweets was rest and vacation, followed by nature\nand water. When we applied the classifiers to the cities dataset, the\nproportion of stress tweets in New York and San Diego was substantially higher\nthan that in Los Angeles and San Francisco.\n  Conclusions: This content analysis and infodemiology study revealed that\nTwitter, when used in conjunction with natural language processing techniques,\nis a useful data source for understanding stress and stress management\nstrategies, and can potentially supplement infrequently collected survey-based\nstress data.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 02:08:14 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 19:06:20 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Doan", "Son", ""], ["Ritchart", "Amanda", ""], ["Perry", "Nicholas", ""], ["Chaparro", "Juan D", ""], ["Conway", "Mike", ""]]}, {"id": "1911.09247", "submitter": "Zewei Chu", "authors": "Zewei Chu, Mingda Chen, Jing Chen, Miaosen Wang, Kevin Gimpel, Manaal\n  Faruqui and Xiance Si", "title": "How to Ask Better Questions? A Large-Scale Multi-Domain Dataset for\n  Rewriting Ill-Formed Questions", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a large-scale dataset for the task of rewriting an ill-formed\nnatural language question to a well-formed one. Our multi-domain question\nrewriting MQR dataset is constructed from human contributed Stack Exchange\nquestion edit histories. The dataset contains 427,719 question pairs which come\nfrom 303 domains. We provide human annotations for a subset of the dataset as a\nquality estimate. When moving from ill-formed to well-formed questions, the\nquestion quality improves by an average of 45 points across three aspects. We\ntrain sequence-to-sequence neural models on the constructed dataset and obtain\nan improvement of 13.2% in BLEU-4 over baseline methods built from other data\nresources. We release the MQR dataset to encourage research on the problem of\nquestion rewriting.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 02:24:21 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Chu", "Zewei", ""], ["Chen", "Mingda", ""], ["Chen", "Jing", ""], ["Wang", "Miaosen", ""], ["Gimpel", "Kevin", ""], ["Faruqui", "Manaal", ""], ["Si", "Xiance", ""]]}, {"id": "1911.09271", "submitter": "Bryan Li", "authors": "Bryan Li, Xinyue Wang, Homayoon Beigi", "title": "Cantonese Automatic Speech Recognition Using Transfer Learning from\n  Mandarin", "comments": "v1, to be presented as poster at Natural Language, Dialog and Speech\n  Symposium 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a system to develop a basic automatic speech recognizer(ASR) for\nCantonese, a low-resource language, through transfer learning of Mandarin, a\nhigh-resource language. We take a time-delayed neural network trained on\nMandarin, and perform weight transfer of several layers to a newly initialized\nmodel for Cantonese. We experiment with the number of layers transferred, their\nlearning rates, and pretraining i-vectors. Key findings are that this approach\nallows for quicker training time with less data. We find that for every epoch,\nlog-probability is smaller for transfer learning models compared to a\nCantonese-only model. The transfer learning models show slight improvement in\nCER.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 03:48:46 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Li", "Bryan", ""], ["Wang", "Xinyue", ""], ["Beigi", "Homayoon", ""]]}, {"id": "1911.09273", "submitter": "Zihan Liu", "authors": "Zihan Liu, Genta Indra Winata, Zhaojiang Lin, Peng Xu, Pascale Fung", "title": "Attention-Informed Mixed-Language Training for Zero-shot Cross-lingual\n  Task-oriented Dialogue Systems", "comments": "Accepted as an oral presentation in AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, data-driven task-oriented dialogue systems have achieved promising\nperformance in English. However, developing dialogue systems that support\nlow-resource languages remains a long-standing challenge due to the absence of\nhigh-quality data. In order to circumvent the expensive and time-consuming data\ncollection, we introduce Attention-Informed Mixed-Language Training (MLT), a\nnovel zero-shot adaptation method for cross-lingual task-oriented dialogue\nsystems. It leverages very few task-related parallel word pairs to generate\ncode-switching sentences for learning the inter-lingual semantics across\nlanguages. Instead of manually selecting the word pairs, we propose to extract\nsource words based on the scores computed by the attention layer of a trained\nEnglish task-related model and then generate word pairs using existing\nbilingual dictionaries. Furthermore, intensive experiments with different\ncross-lingual embeddings demonstrate the effectiveness of our approach.\nFinally, with very few word pairs, our model achieves significant zero-shot\nadaptation performance improvements in both cross-lingual dialogue state\ntracking and natural language understanding (i.e., intent detection and slot\nfilling) tasks compared to the current state-of-the-art approaches, which\nutilize a much larger amount of bilingual data.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 03:52:50 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Liu", "Zihan", ""], ["Winata", "Genta Indra", ""], ["Lin", "Zhaojiang", ""], ["Xu", "Peng", ""], ["Fung", "Pascale", ""]]}, {"id": "1911.09304", "submitter": "Hang Jiang", "authors": "Hang Jiang, Xianzhe Zhang, Jinho D. Choi", "title": "Automatic Text-based Personality Recognition on Monologues and\n  Multiparty Dialogues Using Attentive Networks and Contextual Embeddings", "comments": "Paper Accepted to AAAI-20 Student Abstract and Poster Program", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous works related to automatic personality recognition focus on using\ntraditional classification models with linguistic features. However, attentive\nneural networks with contextual embeddings, which have achieved huge success in\ntext classification, are rarely explored for this task. In this project, we\nhave two major contributions. First, we create the first dialogue-based\npersonality dataset, FriendsPersona, by annotating 5 personality traits of\nspeakers from Friends TV Show through crowdsourcing. Second, we present a novel\napproach to automatic personality recognition using pre-trained contextual\nembeddings (BERT and RoBERTa) and attentive neural networks. Our models largely\nimprove the state-of-art results on the monologue Essays dataset by 2.49%, and\nestablish a solid benchmark on our FriendsPersona. By comparing results in two\ndatasets, we demonstrate the challenges of modeling personality in multi-party\ndialogue.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 06:14:05 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Jiang", "Hang", ""], ["Zhang", "Xianzhe", ""], ["Choi", "Jinho D.", ""]]}, {"id": "1911.09319", "submitter": "Son Doan <", "authors": "Son Doan, Mike Conway, Nigel Collier", "title": "An Empirical Study of Sections in Classifying Disease Outbreak Reports", "comments": "13 pages, 2 tables, book chapter in Web-Based Applications in\n  Healthcare and Biomedicine. Annals of Information Systems, vol 7. Springer,\n  Boston, MA, 2010", "journal-ref": "Web-Based Applications in Healthcare and Biomedicine, pp 47-58,\n  2010", "doi": "10.1007/978-1-4419-1274-9_4", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying articles that relate to infectious diseases is a necessary step\nfor any automatic bio-surveillance system that monitors news articles from the\nInternet. Unlike scientific articles which are available in a strongly\nstructured form, news articles are usually loosely structured. In this chapter,\nwe investigate the importance of each section and the effect of section\nweighting on performance of text classification. The experimental results show\nthat (1) classification models using the headline and leading sentence achieve\na high performance in terms of F-score compared to other parts of the article;\n(2) all section with bag-of-word representation (full text) achieves the\nhighest recall; and (3) section weighting information can help to improve\naccuracy.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 07:22:03 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Doan", "Son", ""], ["Conway", "Mike", ""], ["Collier", "Nigel", ""]]}, {"id": "1911.09320", "submitter": "Chenze Shao", "authors": "Chenze Shao, Jinchao Zhang, Yang Feng, Fandong Meng and Jie Zhou", "title": "Minimizing the Bag-of-Ngrams Difference for Non-Autoregressive Neural\n  Machine Translation", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-Autoregressive Neural Machine Translation (NAT) achieves significant\ndecoding speedup through generating target words independently and\nsimultaneously. However, in the context of non-autoregressive translation, the\nword-level cross-entropy loss cannot model the target-side sequential\ndependency properly, leading to its weak correlation with the translation\nquality. As a result, NAT tends to generate influent translations with\nover-translation and under-translation errors. In this paper, we propose to\ntrain NAT to minimize the Bag-of-Ngrams (BoN) difference between the model\noutput and the reference sentence. The bag-of-ngrams training objective is\ndifferentiable and can be efficiently calculated, which encourages NAT to\ncapture the target-side sequential dependency and correlates well with the\ntranslation quality. We validate our approach on three translation tasks and\nshow that our approach largely outperforms the NAT baseline by about 5.0 BLEU\nscores on WMT14 En$\\leftrightarrow$De and about 2.5 BLEU scores on WMT16\nEn$\\leftrightarrow$Ro.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 07:26:05 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Shao", "Chenze", ""], ["Zhang", "Jinchao", ""], ["Feng", "Yang", ""], ["Meng", "Fandong", ""], ["Zhou", "Jie", ""]]}, {"id": "1911.09333", "submitter": "Zewei Sun", "authors": "Zewei Sun, Shujian Huang, Hao-Ran Wei, Xin-yu Dai, Jiajun Chen", "title": "Generating Diverse Translation by Manipulating Multi-Head Attention", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer model has been widely used on machine translation tasks and\nobtained state-of-the-art results. In this paper, we report an interesting\nphenomenon in its encoder-decoder multi-head attention: different attention\nheads of the final decoder layer align to different word translation\ncandidates. We empirically verify this discovery and propose a method to\ngenerate diverse translations by manipulating heads. Furthermore, we make use\nof these diverse translations with the back-translation technique for better\ndata augmentation. Experiment results show that our method generates diverse\ntranslations without severe drop in translation quality. Experiments also show\nthat back-translation with these diverse translations could bring significant\nimprovement on performance on translation tasks. An auxiliary experiment of\nconversation response generation task proves the effect of diversity as well.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 08:22:07 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Sun", "Zewei", ""], ["Huang", "Shujian", ""], ["Wei", "Hao-Ran", ""], ["Dai", "Xin-yu", ""], ["Chen", "Jiajun", ""]]}, {"id": "1911.09334", "submitter": "Tianyi Li", "authors": "Tianyi Li, Sujian Li", "title": "Incorporating Textual Evidence in Visual Storytelling", "comments": null, "journal-ref": "In Proceeding of DSNNLG 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work on visual storytelling mainly focused on exploring image\nsequence as evidence for storytelling and neglected textual evidence for\nguiding story generation. Motivated by human storytelling process which recalls\nstories for familiar images, we exploit textual evidence from similar images to\nhelp generate coherent and meaningful stories. To pick the images which may\nprovide textual experience, we propose a two-step ranking method based on image\nobject recognition techniques. To utilize textual information, we design an\nextended Seq2Seq model with two-channel encoder and attention. Experiments on\nthe VIST dataset show that our method outperforms state-of-the-art baseline\nmodels without heavy engineering.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 08:22:37 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Li", "Tianyi", ""], ["Li", "Sujian", ""]]}, {"id": "1911.09339", "submitter": "Kiet Nguyen Van", "authors": "Vong Anh Ho, Duong Huynh-Cong Nguyen, Danh Hoang Nguyen, Linh Thi-Van\n  Pham, Duc-Vu Nguyen, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen", "title": "Emotion Recognition for Vietnamese Social Media Text", "comments": "PACLING 2019", "journal-ref": "In Proceeding of PACLING 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Emotion recognition or emotion prediction is a higher approach or a special\ncase of sentiment analysis. In this task, the result is not produced in terms\nof either polarity: positive or negative or in the form of rating (from 1 to 5)\nbut of a more detailed level of analysis in which the results are depicted in\nmore expressions like sadness, enjoyment, anger, disgust, fear, and surprise.\nEmotion recognition plays a critical role in measuring the brand value of a\nproduct by recognizing specific emotions of customers' comments. In this study,\nwe have achieved two targets. First and foremost, we built a standard\nVietnamese Social Media Emotion Corpus (UIT-VSMEC) with exactly 6,927\nemotion-annotated sentences, contributing to emotion recognition research in\nVietnamese which is a low-resource language in natural language processing\n(NLP). Secondly, we assessed and measured machine learning and deep neural\nnetwork models on our UIT-VSMEC corpus. As a result, the CNN model achieved the\nhighest performance with the weighted F1-score of 59.74%. Our corpus is\navailable at our research website.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 08:39:21 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 04:40:33 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Ho", "Vong Anh", ""], ["Nguyen", "Duong Huynh-Cong", ""], ["Nguyen", "Danh Hoang", ""], ["Pham", "Linh Thi-Van", ""], ["Nguyen", "Duc-Vu", ""], ["Van Nguyen", "Kiet", ""], ["Nguyen", "Ngan Luu-Thuy", ""]]}, {"id": "1911.09345", "submitter": "Naveed Akhtar Dr.", "authors": "Nayyer Aafaq, Naveed Akhtar, Wei Liu, Ajmal Mian", "title": "Empirical Autopsy of Deep Video Captioning Frameworks", "comments": "09 pages, 05 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contemporary deep learning based video captioning follows encoder-decoder\nframework. In encoder, visual features are extracted with 2D/3D Convolutional\nNeural Networks (CNNs) and a transformed version of those features is passed to\nthe decoder. The decoder uses word embeddings and a language model to map\nvisual features to natural language captions. Due to its composite nature, the\nencoder-decoder pipeline provides the freedom of multiple choices for each of\nits components, e.g the choices of CNNs models, feature transformations, word\nembeddings, and language models etc. Component selection can have drastic\neffects on the overall video captioning performance. However, current\nliterature is void of any systematic investigation in this regard. This article\nfills this gap by providing the first thorough empirical analysis of the role\nthat each major component plays in a contemporary video captioning pipeline. We\nperform extensive experiments by varying the constituent components of the\nvideo captioning framework, and quantify the performance gains that are\npossible by mere component selection. We use the popular MSVD dataset as the\ntest-bed, and demonstrate that substantial performance gains are possible by\ncareful selection of the constituent components without major changes to the\npipeline itself. These results are expected to provide guiding principles for\nfuture research in the fast growing direction of video captioning.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 08:47:36 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Aafaq", "Nayyer", ""], ["Akhtar", "Naveed", ""], ["Liu", "Wei", ""], ["Mian", "Ajmal", ""]]}, {"id": "1911.09373", "submitter": "Zeyi Wen", "authors": "Zeyi Wen, Zeyu Huang and Rui Zhang", "title": "Entity Extraction with Knowledge from Web Scale Corpora", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity extraction is an important task in text mining and natural language\nprocessing. A popular method for entity extraction is by comparing substrings\nfrom free text against a dictionary of entities. In this paper, we present\nseveral techniques as a post-processing step for improving the effectiveness of\nthe existing entity extraction technique. These techniques utilise models\ntrained with the web-scale corpora which makes our techniques robust and\nversatile. Experiments show that our techniques bring a notable improvement on\nefficiency and effectiveness.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 10:01:16 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Wen", "Zeyi", ""], ["Huang", "Zeyu", ""], ["Zhang", "Rui", ""]]}, {"id": "1911.09375", "submitter": "Monika Sharma", "authors": "Monika Sharma, Shikha Gupta, Arindam Chowdhury, Lovekesh Vig", "title": "ChartNet: Visual Reasoning over Statistical Charts using MAC-Networks", "comments": null, "journal-ref": "International Joint Conference on Neural Networks (IJCNN) 2019", "doi": "10.1109/IJCNN.2019.8852427", "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the improvements in perception accuracies brought about via deep\nlearning, developing systems combining accurate visual perception with the\nability to reason over the visual percepts remains extremely challenging. A\nparticular application area of interest from an accessibility perspective is\nthat of reasoning over statistical charts such as bar and pie charts. To this\nend, we formulate the problem of reasoning over statistical charts as a\nclassification task using MAC-Networks to give answers from a predefined\nvocabulary of generic answers. Additionally, we enhance the capabilities of\nMAC-Networks to give chart-specific answers to open-ended questions by\nreplacing the classification layer by a regression layer to localize the\ntextual answers present over the images. We call our network ChartNet, and\ndemonstrate its efficacy on predicting both in vocabulary and out of vocabulary\nanswers. To test our methods, we generated our own dataset of statistical chart\nimages and corresponding question answer pairs. Results show that ChartNet\nconsistently outperform other state-of-the-art methods on reasoning over these\nquestions and may be a viable candidate for applications containing images of\nstatistical charts.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 10:03:25 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Sharma", "Monika", ""], ["Gupta", "Shikha", ""], ["Chowdhury", "Arindam", ""], ["Vig", "Lovekesh", ""]]}, {"id": "1911.09419", "submitter": "Jie Wang", "authors": "Zhanqiu Zhang, Jianyu Cai, Yongdong Zhang, and Jie Wang", "title": "Learning Hierarchy-Aware Knowledge Graph Embeddings for Link Prediction", "comments": "Accepted to AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph embedding, which aims to represent entities and relations as\nlow dimensional vectors (or matrices, tensors, etc.), has been shown to be a\npowerful technique for predicting missing links in knowledge graphs. Existing\nknowledge graph embedding models mainly focus on modeling relation patterns\nsuch as symmetry/antisymmetry, inversion, and composition. However, many\nexisting approaches fail to model semantic hierarchies, which are common in\nreal-world applications. To address this challenge, we propose a novel\nknowledge graph embedding model---namely, Hierarchy-Aware Knowledge Graph\nEmbedding (HAKE)---which maps entities into the polar coordinate system. HAKE\nis inspired by the fact that concentric circles in the polar coordinate system\ncan naturally reflect the hierarchy. Specifically, the radial coordinate aims\nto model entities at different levels of the hierarchy, and entities with\nsmaller radii are expected to be at higher levels; the angular coordinate aims\nto distinguish entities at the same level of the hierarchy, and these entities\nare expected to have roughly the same radii but different angles. Experiments\ndemonstrate that HAKE can effectively model the semantic hierarchies in\nknowledge graphs, and significantly outperforms existing state-of-the-art\nmethods on benchmark datasets for the link prediction task.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 11:37:18 GMT"}, {"version": "v2", "created": "Wed, 25 Dec 2019 12:31:40 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Zhang", "Zhanqiu", ""], ["Cai", "Jianyu", ""], ["Zhang", "Yongdong", ""], ["Wang", "Jie", ""]]}, {"id": "1911.09478", "submitter": "Victor Petr\\'en Bach Hansen", "authors": "Victor Petr\\'en Bach Hansen, Anders S{\\o}gaard", "title": "What Do You Mean `Why?': Resolving Sluices in Conversations", "comments": "Accepted at the 34TH AAAI Conference on Artificial Intelligence\n  (AAAI-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In conversation, we often ask one-word questions such as `Why?' or `Who?'.\nSuch questions are typically easy for humans to answer, but can be hard for\ncomputers, because their resolution requires retrieving both the right semantic\nframes and the right arguments from context. This paper introduces the novel\nellipsis resolution task of resolving such one-word questions, referred to as\nsluices in linguistics. We present a crowd-sourced dataset containing\nannotations of sluices from over 4,000 dialogues collected from conversational\nQA datasets, as well as a series of strong baseline architectures.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 14:09:33 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Hansen", "Victor Petr\u00e9n Bach", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "1911.09483", "submitter": "Deli Chen", "authors": "Guangxiang Zhao, Xu Sun, Jingjing Xu, Zhiyuan Zhang, Liangchen Luo", "title": "MUSE: Parallel Multi-Scale Attention for Sequence to Sequence Learning", "comments": "Achieve state-of-the-art BLEU scores on WMT14 En-De, En-Fr, and IWSLT\n  De-En", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In sequence to sequence learning, the self-attention mechanism proves to be\nhighly effective, and achieves significant improvements in many tasks. However,\nthe self-attention mechanism is not without its own flaws. Although\nself-attention can model extremely long dependencies, the attention in deep\nlayers tends to overconcentrate on a single token, leading to insufficient use\nof local information and difficultly in representing long sequences. In this\nwork, we explore parallel multi-scale representation learning on sequence data,\nstriving to capture both long-range and short-range language structures. To\nthis end, we propose the Parallel MUlti-Scale attEntion (MUSE) and MUSE-simple.\nMUSE-simple contains the basic idea of parallel multi-scale sequence\nrepresentation learning, and it encodes the sequence in parallel, in terms of\ndifferent scales with the help from self-attention, and pointwise\ntransformation. MUSE builds on MUSE-simple and explores combining convolution\nand self-attention for learning sequence representations from more different\nscales. We focus on machine translation and the proposed approach achieves\nsubstantial performance improvements over Transformer, especially on long\nsequences. More importantly, we find that although conceptually simple, its\nsuccess in practice requires intricate considerations, and the multi-scale\nattention must build on unified semantic space. Under common setting, the\nproposed model achieves substantial performance and outperforms all previous\nmodels on three main machine translation tasks. In addition, MUSE has potential\nfor accelerating inference due to its parallelism. Code will be available at\nhttps://github.com/lancopku/MUSE\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 09:36:07 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Zhao", "Guangxiang", ""], ["Sun", "Xu", ""], ["Xu", "Jingjing", ""], ["Zhang", "Zhiyuan", ""], ["Luo", "Liangchen", ""]]}, {"id": "1911.09487", "submitter": "Cong Sun", "authors": "Cong Sun, Zhihao Yang, Leilei Su, Lei Wang, Yin Zhang, Hongfei Lin and\n  Jian Wang", "title": "Chemical-protein Interaction Extraction via Gaussian Probability\n  Distribution and External Biomedical Knowledge", "comments": "8 pages, 4 figures, Bioinformatics manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: The biomedical literature contains a wealth of chemical-protein\ninteractions (CPIs). Automatically extracting CPIs described in biomedical\nliterature is essential for drug discovery, precision medicine, as well as\nbasic biomedical research. Most existing methods focus only on the sentence\nsequence to identify these CPIs. However, the local structure of sentences and\nexternal biomedical knowledge also contain valuable information. Effective use\nof such information may improve the performance of CPI extraction. Results: In\nthis paper, we propose a novel neural network-based approach to improve CPI\nextraction. Specifically, the approach first employs BERT to generate\nhigh-quality contextual representations of the title sequence, instance\nsequence, and knowledge sequence. Then, the Gaussian probability distribution\nis introduced to capture the local structure of the instance. Meanwhile, the\nattention mechanism is applied to fuse the title information and biomedical\nknowledge, respectively. Finally, the related representations are concatenated\nand fed into the softmax function to extract CPIs. We evaluate our proposed\nmodel on the CHEMPROT corpus. Our proposed model is superior in performance as\ncompared with other state-of-the-art models. The experimental results show that\nthe Gaussian probability distribution and external knowledge are complementary\nto each other. Integrating them can effectively improve the CPI extraction\nperformance. Furthermore, the Gaussian probability distribution can effectively\nimprove the extraction performance of sentences with overlapping relations in\nbiomedical relation extraction tasks. Availability: Data and code are available\nat https://github.com/CongSun-dlut/CPI_extraction. Contact: yangzh@dlut.edu.cn,\nwangleibihami@gmail.com Supplementary information: Supplementary data are\navailable at Bioinformatics online.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 14:29:42 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 02:47:49 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Sun", "Cong", ""], ["Yang", "Zhihao", ""], ["Su", "Leilei", ""], ["Wang", "Lei", ""], ["Zhang", "Yin", ""], ["Lin", "Hongfei", ""], ["Wang", "Jian", ""]]}, {"id": "1911.09515", "submitter": "Sandeep Nallan Chakravarthula", "authors": "Sandeep Nallan Chakravarthula, Brian Baucom, Shrikanth Narayanan,\n  Panayiotis Georgiou", "title": "An analysis of observation length requirements for machine understanding\n  of human behaviors from spoken language", "comments": "converted to CSL format, restructured presentation of analysis and\n  methodology, moved finer details to Appendix, enlarged figures and text,\n  fixed typos and notational inconsistency", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The task of quantifying human behavior by observing interaction cues is an\nimportant and useful one across a range of domains in psychological research\nand practice. Machine learning-based approaches typically perform this task by\nfirst estimating behavior based on cues within an observation window, such as a\nfixed number of words, and then aggregating the behavior over all the windows\nin that interaction. The length of this window directly impacts the accuracy of\nestimation by controlling the amount of information being used. The exact link\nbetween window length and accuracy, however, has not been well studied,\nespecially in spoken language. In this paper, we investigate this link and\npresent an analysis framework that determines appropriate window lengths for\nthe task of behavior estimation. Our proposed framework utilizes a two-pronged\nevaluation approach: (a) extrinsic similarity between machine predictions and\nhuman expert annotations, and (b) intrinsic consistency between intra-machine\nand intra-human behavior relations. We apply our analysis to real-life\nconversations that are annotated for a large and diverse set of behavior codes\nand examine the relation between the nature of a behavior and how long it\nshould be observed. We find that behaviors describing negative and positive\naffect can be accurately estimated from short to medium-length expressions\nwhereas behaviors related to problem-solving and dysphoria require much longer\nobservations and are difficult to quantify from language alone. These findings\nare found to be generally consistent across different behavior modeling\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 15:05:10 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 03:39:11 GMT"}, {"version": "v3", "created": "Wed, 26 Aug 2020 23:47:36 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Chakravarthula", "Sandeep Nallan", ""], ["Baucom", "Brian", ""], ["Narayanan", "Shrikanth", ""], ["Georgiou", "Panayiotis", ""]]}, {"id": "1911.09532", "submitter": "Juntao Yu", "authors": "Juntao Yu, Alexandra Uma, Massimo Poesio", "title": "A Cluster Ranking Model for Full Anaphora Resolution", "comments": "LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anaphora resolution (coreference) systems designed for the CONLL 2012 dataset\ntypically cannot handle key aspects of the full anaphora resolution task such\nas the identification of singletons and of certain types of non-referring\nexpressions (e.g., expletives), as these aspects are not annotated in that\ncorpus. However, the recently released dataset for the CRAC 2018 Shared Task\ncan now be used for that purpose. In this paper, we introduce an architecture\nto simultaneously identify non-referring expressions (including expletives,\npredicative s, and other types) and build coreference chains, including\nsingletons. Our cluster-ranking system uses an attention mechanism to determine\nthe relative importance of the mentions in the same cluster. Additional\nclassifiers are used to identify singletons and non-referring markables. Our\ncontributions are as follows. First all, we report the first result on the CRAC\ndata using system mentions; our result is 5.8% better than the shared task\nbaseline system, which used gold mentions. Second, we demonstrate that the\navailability of singleton clusters and non-referring expressions can lead to\nsubstantially improved performance on non-singleton clusters as well. Third, we\nshow that despite our model not being designed specifically for the CONLL data,\nit achieves a score equivalent to that of the state-of-the-art system by Kantor\nand Globerson (2019) on that dataset.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 15:14:39 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 13:27:09 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Yu", "Juntao", ""], ["Uma", "Alexandra", ""], ["Poesio", "Massimo", ""]]}, {"id": "1911.09572", "submitter": "Wenxin Hu", "authors": "Wenxin Hu, Xiaofeng Zhang, Gang Yang", "title": "Automatically Generating Macro Research Reports from a Piece of News", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically generating macro research reports from economic news is an\nimportant yet challenging task. As we all know, it requires the macro analysts\nto write such reports within a short period of time after the important\neconomic news are released. This motivates our work, i.e., using AI techniques\nto save manual cost. The goal of the proposed system is to generate macro\nresearch reports as the draft for macro analysts. Essentially, the core\nchallenge is the long text generation issue. To address this issue, we propose\na novel deep learning technique based approach which includes two components,\ni.e., outline generation and macro research report generation.For the model\nperformance evaluation, we first crawl a large news-to-report dataset and then\nevaluate our approach on this dataset, and the generated reports are given for\nthe subjective evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 16:05:02 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Hu", "Wenxin", ""], ["Zhang", "Xiaofeng", ""], ["Yang", "Gang", ""]]}, {"id": "1911.09602", "submitter": "David Harwath", "authors": "David Harwath, Wei-Ning Hsu, James Glass", "title": "Learning Hierarchical Discrete Linguistic Units from Visually-Grounded\n  Speech", "comments": "Camera-ready version for ICLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a method for learning discrete linguistic units by\nincorporating vector quantization layers into neural models of visually\ngrounded speech. We show that our method is capable of capturing both\nword-level and sub-word units, depending on how it is configured. What\ndifferentiates this paper from prior work on speech unit learning is the choice\nof training objective. Rather than using a reconstruction-based loss, we use a\ndiscriminative, multimodal grounding objective which forces the learned units\nto be useful for semantic image retrieval. We evaluate the sub-word units on\nthe ZeroSpeech 2019 challenge, achieving a 27.3\\% reduction in ABX error rate\nover the top-performing submission, while keeping the bitrate approximately the\nsame. We also present experiments demonstrating the noise robustness of these\nunits. Finally, we show that a model with multiple quantizers can\nsimultaneously learn phone-like detectors at a lower layer and word-like\ndetectors at a higher layer. We show that these detectors are highly accurate,\ndiscovering 279 words with an F1 score of greater than 0.5.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 16:54:14 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 18:38:28 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Harwath", "David", ""], ["Hsu", "Wei-Ning", ""], ["Glass", "James", ""]]}, {"id": "1911.09645", "submitter": "Zahra Shakeri", "authors": "Siddharth Gururani, Kilol Gupta, Dhaval Shah, Zahra Shakeri, Jervis\n  Pinto", "title": "Prosody Transfer in Neural Text to Speech Using Global Pitch and\n  Loudness Features", "comments": "5 pages, in review for conference publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a simple yet effective method to achieve prosody transfer\nfrom a reference speech signal to synthesized speech. The main idea is to\nincorporate well-known acoustic correlates of prosody such as pitch and\nloudness contours of the reference speech into a modern neural text-to-speech\n(TTS) synthesizer such as Tacotron2 (TC2). More specifically, a small set of\nacoustic features are extracted from reference audio and then used to condition\na TC2 synthesizer. The trained model is evaluated using subjective listening\ntests and a novel objective evaluation of prosody transfer is proposed.\nListening tests show that the synthesized speech is rated as highly natural and\nthat prosody is successfully transferred from the reference speech signal to\nthe synthesized signal.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 18:04:47 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 20:46:24 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Gururani", "Siddharth", ""], ["Gupta", "Kilol", ""], ["Shah", "Dhaval", ""], ["Shakeri", "Zahra", ""], ["Pinto", "Jervis", ""]]}, {"id": "1911.09655", "submitter": "Haytham Fayek", "authors": "Haytham M. Fayek, Justin Johnson", "title": "Temporal Reasoning via Audio Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal question answering tasks can be used as proxy tasks to study\nsystems that can perceive and reason about the world. Answering questions about\ndifferent types of input modalities stresses different aspects of reasoning\nsuch as visual reasoning, reading comprehension, story understanding, or\nnavigation. In this paper, we use the task of Audio Question Answering (AQA) to\nstudy the temporal reasoning abilities of machine learning models. To this end,\nwe introduce the Diagnostic Audio Question Answering (DAQA) dataset comprising\naudio sequences of natural sound events and programmatically generated\nquestions and answers that probe various aspects of temporal reasoning. We\nadapt several recent state-of-the-art methods for visual question answering to\nthe AQA task, and use DAQA to demonstrate that they perform poorly on questions\nthat require in-depth temporal reasoning. Finally, we propose a new model,\nMultiple Auxiliary Controllers for Linear Modulation (MALiMo) that extends the\nrecent Feature-wise Linear Modulation (FiLM) model and significantly improves\nits temporal reasoning capabilities. We envisage DAQA to foster research on AQA\nand temporal reasoning and MALiMo a step towards models for AQA.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 18:26:30 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Fayek", "Haytham M.", ""], ["Johnson", "Justin", ""]]}, {"id": "1911.09661", "submitter": "Martin Andrews", "authors": "Sam Witteveen, Martin Andrews", "title": "Paraphrasing with Large Language Models", "comments": "Accepted paper for WNGT workshop at EMNLP-IJCNLP 2019. (7 pages\n  including references and supplemental material)", "journal-ref": null, "doi": "10.18653/v1/D19-5623", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, large language models such as GPT-2 have shown themselves to be\nextremely adept at text generation and have also been able to achieve\nhigh-quality results in many downstream NLP tasks such as text classification,\nsentiment analysis and question answering with the aid of fine-tuning. We\npresent a useful technique for using a large language model to perform the task\nof paraphrasing on a variety of texts and subjects. Our approach is\ndemonstrated to be capable of generating paraphrases not only at a sentence\nlevel but also for longer spans of text such as paragraphs without needing to\nbreak the text into smaller chunks.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 18:45:54 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Witteveen", "Sam", ""], ["Andrews", "Martin", ""]]}, {"id": "1911.09709", "submitter": "Reid Pryzant", "authors": "Reid Pryzant, Richard Diehl Martinez, Nathan Dass, Sadao Kurohashi,\n  Dan Jurafsky, Diyi Yang", "title": "Automatically Neutralizing Subjective Bias in Text", "comments": "To appear at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Texts like news, encyclopedias, and some social media strive for objectivity.\nYet bias in the form of inappropriate subjectivity - introducing attitudes via\nframing, presupposing truth, and casting doubt - remains ubiquitous. This kind\nof bias erodes our collective trust and fuels social conflict. To address this\nissue, we introduce a novel testbed for natural language generation:\nautomatically bringing inappropriately subjective text into a neutral point of\nview (\"neutralizing\" biased text). We also offer the first parallel corpus of\nbiased language. The corpus contains 180,000 sentence pairs and originates from\nWikipedia edits that removed various framings, presuppositions, and attitudes\nfrom biased sentences. Last, we propose two strong encoder-decoder baselines\nfor the task. A straightforward yet opaque CONCURRENT system uses a BERT\nencoder to identify subjective words as part of the generation process. An\ninterpretable and controllable MODULAR algorithm separates these steps, using\n(1) a BERT-based classifier to identify problematic words and (2) a novel join\nembedding through which the classifier can edit the hidden states of the\nencoder. Large-scale human evaluation across four domains (encyclopedias, news\nheadlines, books, and political speeches) suggests that these algorithms are a\nfirst step towards the automatic identification and reduction of bias.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 19:15:03 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 16:30:40 GMT"}, {"version": "v3", "created": "Thu, 12 Dec 2019 16:04:17 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Pryzant", "Reid", ""], ["Martinez", "Richard Diehl", ""], ["Dass", "Nathan", ""], ["Kurohashi", "Sadao", ""], ["Jurafsky", "Dan", ""], ["Yang", "Diyi", ""]]}, {"id": "1911.09728", "submitter": "Yacine Jernite", "authors": "Xinyi Wang, Jason Weston, Michael Auli, Yacine Jernite", "title": "Improving Conditioning in Context-Aware Sequence to Sequence Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural sequence to sequence models are well established for applications\nwhich can be cast as mapping a single input sequence into a single output\nsequence. In this work, we focus on cases where generation is conditioned on\nboth a short query and a long context, such as abstractive question answering\nor document-level translation. We modify the standard sequence-to-sequence\napproach to make better use of both the query and the context by expanding the\nconditioning mechanism to intertwine query and context attention. We also\nintroduce a simple and efficient data augmentation method for the proposed\nmodel. Experiments on three different tasks show that both changes lead to\nconsistent improvements.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 20:01:46 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Wang", "Xinyi", ""], ["Weston", "Jason", ""], ["Auli", "Michael", ""], ["Jernite", "Yacine", ""]]}, {"id": "1911.09732", "submitter": "Yu Meng", "authors": "Yu Meng, Maryam Karimzadehgan, Honglei Zhuang, Donald Metzler", "title": "Separate and Attend in Personal Email Search", "comments": "WSDM 2020", "journal-ref": null, "doi": "10.1145/3336191.3371775", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In personal email search, user queries often impose different requirements on\ndifferent aspects of the retrieved emails. For example, the query \"my recent\nflight to the US\" requires emails to be ranked based on both textual contents\nand recency of the email documents, while other queries such as \"medical\nhistory\" do not impose any constraints on the recency of the email. Recent deep\nlearning-to-rank models for personal email search often directly concatenate\ndense numerical features (e.g., document age) with embedded sparse features\n(e.g., n-gram embeddings). In this paper, we first show with a set of\nexperiments on synthetic datasets that direct concatenation of dense and sparse\nfeatures does not lead to the optimal search performance of deep neural ranking\nmodels. To effectively incorporate both sparse and dense email features into\npersonal email search ranking, we propose a novel neural model, SepAttn.\nSepAttn first builds two separate neural models to learn from sparse and dense\nfeatures respectively, and then applies an attention mechanism at the\nprediction level to derive the final prediction from these two models. We\nconduct a comprehensive set of experiments on a large-scale email search\ndataset, and demonstrate that our SepAttn model consistently improves the\nsearch quality over the baseline models.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 20:19:28 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Meng", "Yu", ""], ["Karimzadehgan", "Maryam", ""], ["Zhuang", "Honglei", ""], ["Metzler", "Donald", ""]]}, {"id": "1911.09735", "submitter": "Son Doan <", "authors": "Son Doan, Quoc-Hung Ngo, Ai Kawazoe, Nigel Collier", "title": "Global Health Monitor: A Web-based System for Detecting and Mapping\n  Infectious Diseases", "comments": "6 pages, 3 figures, Proc. of IJCNLP 2008", "journal-ref": "Proc. of the International Joint Conference on Natural Language\n  Processing (IJCNLP) 2008, pages 951-956", "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Global Health Monitor, an online Web-based system for\ndetecting and mapping infectious disease outbreaks that appear in news stories.\nThe system analyzes English news stories from news feed providers, classifies\nthem for topical relevance and plots them onto a Google map using geo-coding\ninformation, helping public health workers to monitor the spread of diseases in\na geo-temporal context. The background knowledge for the system is contained in\nthe BioCaster ontology (BCO) (Collier et al., 2007a) which includes both\ninformation on infectious diseases as well as geographical locations with their\nlatitudes/longitudes. The system consists of four main stages: topic\nclassification, named entity recognition (NER), disease/location detection and\nvisualization. Evaluation of the system shows that it achieved high accuracy on\na gold standard corpus. The system is now in practical use. Running on a\nclustercomputer, it monitors more than 1500 news feeds 24/7, updating the map\nevery hour.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 20:26:29 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Doan", "Son", ""], ["Ngo", "Quoc-Hung", ""], ["Kawazoe", "Ai", ""], ["Collier", "Nigel", ""]]}, {"id": "1911.09753", "submitter": "Paul Hongsuck Seo", "authors": "Paul Hongsuck Seo, Piyush Sharma, Tomer Levinboim, Bohyung Han, Radu\n  Soricut", "title": "Reinforcing an Image Caption Generator Using Off-Line Human Feedback", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human ratings are currently the most accurate way to assess the quality of an\nimage captioning model, yet most often the only used outcome of an expensive\nhuman rating evaluation is a few overall statistics over the evaluation\ndataset. In this paper, we show that the signal from instance-level human\ncaption ratings can be leveraged to improve captioning models, even when the\namount of caption ratings is several orders of magnitude less than the caption\ntraining data. We employ a policy gradient method to maximize the human ratings\nas rewards in an off-policy reinforcement learning setting, where policy\ngradients are estimated by samples from a distribution that focuses on the\ncaptions in a caption ratings dataset. Our empirical evidence indicates that\nthe proposed method learns to generalize the human raters' judgments to a\npreviously unseen set of images, as judged by a different set of human judges,\nand additionally on a different, multi-dimensional side-by-side human\nevaluation procedure.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 21:26:28 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Seo", "Paul Hongsuck", ""], ["Sharma", "Piyush", ""], ["Levinboim", "Tomer", ""], ["Han", "Bohyung", ""], ["Soricut", "Radu", ""]]}, {"id": "1911.09762", "submitter": "Zhiyun Lu", "authors": "Zhiyun Lu, Liangliang Cao, Yu Zhang, Chung-Cheng Chiu, James Fan", "title": "Speech Sentiment Analysis via Pre-trained Features from End-to-end ASR\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose to use pre-trained features from end-to-end ASR\nmodels to solve speech sentiment analysis as a down-stream task. We show that\nend-to-end ASR features, which integrate both acoustic and text information\nfrom speech, achieve promising results. We use RNN with self-attention as the\nsentiment classifier, which also provides an easy visualization through\nattention weights to help interpret model predictions. We use well benchmarked\nIEMOCAP dataset and a new large-scale speech sentiment dataset SWBD-sentiment\nfor evaluation. Our approach improves the-state-of-the-art accuracy on IEMOCAP\nfrom 66.6% to 71.7%, and achieves an accuracy of 70.10% on SWBD-sentiment with\nmore than 49,500 utterances.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 21:38:36 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 00:21:49 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Lu", "Zhiyun", ""], ["Cao", "Liangliang", ""], ["Zhang", "Yu", ""], ["Chiu", "Chung-Cheng", ""], ["Fan", "James", ""]]}, {"id": "1911.09787", "submitter": "Busra Celikkaya", "authors": "Ming Zhu, Busra Celikkaya, Parminder Bhatia, Chandan K. Reddy", "title": "LATTE: Latent Type Modeling for Biomedical Entity Linking", "comments": "AAAI 2020 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity linking is the task of linking mentions of named entities in natural\nlanguage text, to entities in a curated knowledge-base. This is of significant\nimportance in the biomedical domain, where it could be used to semantically\nannotate a large volume of clinical records and biomedical literature, to\nstandardized concepts described in an ontology such as Unified Medical Language\nSystem (UMLS). We observe that with precise type information, entity\ndisambiguation becomes a straightforward task. However, fine-grained type\ninformation is usually not available in biomedical domain. Thus, we propose\nLATTE, a LATent Type Entity Linking model, that improves entity linking by\nmodeling the latent fine-grained type information about mentions and entities.\nUnlike previous methods that perform entity linking directly between the\nmentions and the entities, LATTE jointly does entity disambiguation, and latent\nfine-grained type learning, without direct supervision. We evaluate our model\non two biomedical datasets: MedMentions, a large scale public dataset annotated\nwith UMLS concepts, and a de-identified corpus of dictated doctor's notes that\nhas been annotated with ICD concepts. Extensive experimental evaluation shows\nour model achieves significant performance improvements over several\nstate-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 23:55:15 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 23:17:27 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Zhu", "Ming", ""], ["Celikkaya", "Busra", ""], ["Bhatia", "Parminder", ""], ["Reddy", "Chandan K.", ""]]}, {"id": "1911.09788", "submitter": "Yu-Ming Shang", "authors": "Yuming Shang", "title": "Are Noisy Sentences Useless for Distant Supervised Relation Extraction?", "comments": "9 pages 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The noisy labeling problem has been one of the major obstacles for distant\nsupervised relation extraction. Existing approaches usually consider that the\nnoisy sentences are useless and will harm the model's performance. Therefore,\nthey mainly alleviate this problem by reducing the influence of noisy\nsentences, such as applying bag-level selective attention or removing noisy\nsentences from sentence-bags. However, the underlying cause of the noisy\nlabeling problem is not the lack of useful information, but the missing\nrelation labels. Intuitively, if we can allocate credible labels for noisy\nsentences, they will be transformed into useful training data and benefit the\nmodel's performance. Thus, in this paper, we propose a novel method for distant\nsupervised relation extraction, which employs unsupervised deep clustering to\ngenerate reliable labels for noisy sentences. Specifically, our model contains\nthree modules: a sentence encoder, a noise detector and a label generator. The\nsentence encoder is used to obtain feature representations. The noise detector\ndetects noisy sentences from sentence-bags, and the label generator produces\nhigh-confidence relation labels for noisy sentences. Extensive experimental\nresults demonstrate that our model outperforms the state-of-the-art baselines\non a popular benchmark dataset, and can indeed alleviate the noisy labeling\nproblem.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 00:00:31 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Shang", "Yuming", ""]]}, {"id": "1911.09789", "submitter": "Zhiwei Wang", "authors": "Zhiwei Wang, Hui Liu, Jiliang Tang, Songfan Yang, Gale Yan Huang,\n  Zitao Liu", "title": "Learning Multi-level Dependencies for Robust Word Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust language processing systems are becoming increasingly important given\nthe recent awareness of dangerous situations where brittle machine learning\nmodels can be easily broken with the presence of noises. In this paper, we\nintroduce a robust word recognition framework that captures multi-level\nsequential dependencies in noised sentences. The proposed framework employs a\nsequence-to-sequence model over characters of each word, whose output is given\nto a word-level bi-directional recurrent neural network. We conduct extensive\nexperiments to verify the effectiveness of the framework. The results show that\nthe proposed framework outperforms state-of-the-art methods by a large margin\nand they also suggest that character-level dependencies can play an important\nrole in word recognition.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 00:04:07 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Wang", "Zhiwei", ""], ["Liu", "Hui", ""], ["Tang", "Jiliang", ""], ["Yang", "Songfan", ""], ["Huang", "Gale Yan", ""], ["Liu", "Zitao", ""]]}, {"id": "1911.09801", "submitter": "Yang Deng", "authors": "Yang Deng, Wai Lam, Yuexiang Xie, Daoyuan Chen, Yaliang Li, Min Yang,\n  Ying Shen", "title": "Joint Learning of Answer Selection and Answer Summary Generation in\n  Community Question Answering", "comments": "Accepted by AAAI 2020 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community question answering (CQA) gains increasing popularity in both\nacademy and industry recently. However, the redundancy and lengthiness issues\nof crowdsourced answers limit the performance of answer selection and lead to\nreading difficulties and misunderstandings for community users. To solve these\nproblems, we tackle the tasks of answer selection and answer summary generation\nin CQA with a novel joint learning model. Specifically, we design a\nquestion-driven pointer-generator network, which exploits the correlation\ninformation between question-answer pairs to aid in attending the essential\ninformation when generating answer summaries. Meanwhile, we leverage the answer\nsummaries to alleviate noise in original lengthy answers when ranking the\nrelevancy degrees of question-answer pairs. In addition, we construct a new\nlarge-scale CQA corpus, WikiHowQA, which contains long answers for answer\nselection as well as reference summaries for answer summarization. The\nexperimental results show that the joint learning method can effectively\naddress the answer redundancy issue in CQA and achieves state-of-the-art\nresults on both answer selection and text summarization tasks. Furthermore, the\nproposed model is shown to be of great transferring ability and applicability\nfor resource-poor CQA tasks, which lack of reference answer summaries.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 01:14:57 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Deng", "Yang", ""], ["Lam", "Wai", ""], ["Xie", "Yuexiang", ""], ["Chen", "Daoyuan", ""], ["Li", "Yaliang", ""], ["Yang", "Min", ""], ["Shen", "Ying", ""]]}, {"id": "1911.09812", "submitter": "M Saiful Bari", "authors": "M Saiful Bari and Shafiq Joty and Prathyusha Jwalapuram", "title": "Zero-Resource Cross-Lingual Named Entity Recognition", "comments": null, "journal-ref": "Proceedings of the 34th AAAI Conference on Artificial Intelligence\n  (AAAI-2020)", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, neural methods have achieved state-of-the-art (SOTA) results in\nNamed Entity Recognition (NER) tasks for many languages without the need for\nmanually crafted features. However, these models still require manually\nannotated training data, which is not available for many languages. In this\npaper, we propose an unsupervised cross-lingual NER model that can transfer NER\nknowledge from one language to another in a completely unsupervised way without\nrelying on any bilingual dictionary or parallel data. Our model achieves this\nthrough word-level adversarial learning and augmented fine-tuning with\nparameter sharing and feature augmentation. Experiments on five different\nlanguages demonstrate the effectiveness of our approach, outperforming existing\nmodels by a good margin and setting a new SOTA for each language pair.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 02:09:08 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Bari", "M Saiful", ""], ["Joty", "Shafiq", ""], ["Jwalapuram", "Prathyusha", ""]]}, {"id": "1911.09818", "submitter": "Jing Pan", "authors": "Jing Pan, Weian Sheng, Santanu Dey", "title": "Order Matters at Fanatics Recommending Sequentially Ordered Products by\n  LSTM Embedded with Word2Vec", "comments": "5 pages, 2 figures, KDD 2019 Workshop, Deep Learning on Graphics,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  A unique challenge for e-commerce recommendation is that customers are often\ninterested in products that are more advanced than their already purchased\nproducts, but not reversed. The few existing recommender systems modeling\nunidirectional sequence output a limited number of categories or continuous\nvariables. To model the ordered sequence, we design the first recommendation\nsystem that both embed purchased items with Word2Vec, and model the sequence\nwith stateless LSTM RNN. The click-through rate of this recommender system in\nproduction outperforms its solely Word2Vec based predecessor. Developed in\n2017, it was perhaps the first published real-world application that makes\ndistributed predictions of a single machine trained Keras model on Spark slave\nnodes at a scale of more than 0.4 million columns per row.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 02:39:41 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Pan", "Jing", ""], ["Sheng", "Weian", ""], ["Dey", "Santanu", ""]]}, {"id": "1911.09826", "submitter": "Amir Zadeh", "authors": "Amir Zadeh, Chengfeng Mao, Kelly Shi, Yiwei Zhang, Paul Pu Liang,\n  Soujanya Poria, Louis-Philippe Morency", "title": "Factorized Multimodal Transformer for Multimodal Sequential Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complex world around us is inherently multimodal and sequential\n(continuous). Information is scattered across different modalities and requires\nmultiple continuous sensors to be captured. As machine learning leaps towards\nbetter generalization to real world, multimodal sequential learning becomes a\nfundamental research area. Arguably, modeling arbitrarily distributed\nspatio-temporal dynamics within and across modalities is the biggest challenge\nin this research area. In this paper, we present a new transformer model,\ncalled the Factorized Multimodal Transformer (FMT) for multimodal sequential\nlearning. FMT inherently models the intramodal and intermodal (involving two or\nmore modalities) dynamics within its multimodal input in a factorized manner.\nThe proposed factorization allows for increasing the number of self-attentions\nto better model the multimodal phenomena at hand; without encountering\ndifficulties during training (e.g. overfitting) even on relatively low-resource\nsetups. All the attention mechanisms within FMT have a full time-domain\nreceptive field which allows them to asynchronously capture long-range\nmultimodal dynamics. In our experiments we focus on datasets that contain the\nthree commonly studied modalities of language, vision and acoustic. We perform\na wide range of experiments, spanning across 3 well-studied datasets and 21\ndistinct labels. FMT shows superior performance over previously proposed\nmodels, setting new state of the art in the studied datasets.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 03:14:32 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Zadeh", "Amir", ""], ["Mao", "Chengfeng", ""], ["Shi", "Kelly", ""], ["Zhang", "Yiwei", ""], ["Liang", "Paul Pu", ""], ["Poria", "Soujanya", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1911.09844", "submitter": "Chao Zhao", "authors": "Chao Zhao and Snigdha Chaturvedi", "title": "Weakly-Supervised Opinion Summarization by Leveraging External\n  Information", "comments": "Accepted By AAAI-20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opinion summarization from online product reviews is a challenging task,\nwhich involves identifying opinions related to various aspects of the product\nbeing reviewed. While previous works require additional human effort to\nidentify relevant aspects, we instead apply domain knowledge from external\nsources to automatically achieve the same goal. This work proposes AspMem, a\ngenerative method that contains an array of memory cells to store\naspect-related knowledge. This explicit memory can help obtain a better opinion\nrepresentation and infer the aspect information more precisely. We evaluate\nthis method on both aspect identification and opinion summarization tasks. Our\nexperiments show that AspMem outperforms the state-of-the-art methods even\nthough, unlike the baselines, it does not rely on human supervision which is\ncarefully handcrafted for the given tasks.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 04:10:46 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Zhao", "Chao", ""], ["Chaturvedi", "Snigdha", ""]]}, {"id": "1911.09845", "submitter": "Jun Gao", "authors": "Jun Gao, Wei Bi, Xiaojiang Liu, Junhui Li, Guodong Zhou, Shuming Shi", "title": "A Discrete CVAE for Response Generation on Short-Text Conversation", "comments": "Accepted for publication at EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural conversation models such as encoder-decoder models are easy to\ngenerate bland and generic responses. Some researchers propose to use the\nconditional variational autoencoder(CVAE) which maximizes the lower bound on\nthe conditional log-likelihood on a continuous latent variable. With different\nsampled la-tent variables, the model is expected to generate diverse responses.\nAlthough the CVAE-based models have shown tremendous potential, their\nimprovement of generating high-quality responses is still unsatisfactory. In\nthis paper, we introduce a discrete latent variable with an explicit semantic\nmeaning to improve the CVAE on short-text conversation. A major advantage of\nour model is that we can exploit the semantic distance between the latent\nvariables to maintain good diversity between the sampled latent variables.\nAccordingly, we pro-pose a two-stage sampling approach to enable efficient\ndiverse variable selection from a large latent space assumed in the short-text\nconversation task. Experimental results indicate that our model outperforms\nvarious kinds of generation models under both automatic and human evaluations\nand generates more diverse and in-formative responses.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 04:14:31 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Gao", "Jun", ""], ["Bi", "Wei", ""], ["Liu", "Xiaojiang", ""], ["Li", "Junhui", ""], ["Zhou", "Guodong", ""], ["Shi", "Shuming", ""]]}, {"id": "1911.09860", "submitter": "Ganesh Ramakrishnan", "authors": "Oishik Chatterjee, Ganesh Ramakrishnan, Sunita Sarawagi", "title": "Data Programming using Continuous and Quality-Guided Labeling Functions", "comments": "Accepted paper at the 34th AAAI Conference on Artificial Intelligence\n  (AAAI-18), New York, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scarcity of labeled data is a bottleneck for supervised learning models. A\nparadigm that has evolved for dealing with this problem is data programming. An\nexisting data programming paradigm allows human supervision to be provided as a\nset of discrete labeling functions (LF) that output possibly noisy labels to\ninput instances and a generative modelfor consolidating the weak labels. We\nenhance and generalize this paradigm by supporting functions that output a\ncontinuous score (instead of a hard label) that noisily correlates with labels.\nWe show across five applications that continuous LFs are more natural to\nprogram and lead to improved recall. We also show that accuracy of existing\ngenerative models is unstable with respect to initialization, training epochs,\nand learning rates. We give control to the data programmer to guide the\ntraining process by providing intuitive quality guides with each LF. We propose\nan elegant method of incorporating these guides into the generative model. Our\noverall method, called CAGE, makes the data programming paradigm more reliable\nthan other tricks based on initialization, sign-penalties, or soft-accuracy\nconstraints.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 05:05:42 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Chatterjee", "Oishik", ""], ["Ramakrishnan", "Ganesh", ""], ["Sarawagi", "Sunita", ""]]}, {"id": "1911.09877", "submitter": "Jian Li", "authors": "Jian Li, Xing Wang, Baosong Yang, Shuming Shi, Michael R. Lyu,\n  Zhaopeng Tu", "title": "Neuron Interaction Based Representation Composition for Neural Machine\n  Translation", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent NLP studies reveal that substantial linguistic information can be\nattributed to single neurons, i.e., individual dimensions of the representation\nvectors. We hypothesize that modeling strong interactions among neurons helps\nto better capture complex information by composing the linguistic properties\nembedded in individual neurons. Starting from this intuition, we propose a\nnovel approach to compose representations learned by different components in\nneural machine translation (e.g., multi-layer networks or multi-head\nattention), based on modeling strong interactions among neurons in the\nrepresentation vectors. Specifically, we leverage bilinear pooling to model\npairwise multiplicative interactions among individual neurons, and a low-rank\napproximation to make the model computationally feasible. We further propose\nextended bilinear pooling to incorporate first-order representations.\nExperiments on WMT14 English-German and English-French translation tasks show\nthat our model consistently improves performances over the SOTA Transformer\nbaseline. Further analyses demonstrate that our approach indeed captures more\nsyntactic and semantic information as expected.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 06:38:42 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Li", "Jian", ""], ["Wang", "Xing", ""], ["Yang", "Baosong", ""], ["Shi", "Shuming", ""], ["Lyu", "Michael R.", ""], ["Tu", "Zhaopeng", ""]]}, {"id": "1911.09883", "submitter": "Son Doan <", "authors": "Son Doan, Nguyen Thi Ngoc Vinh, Tu Minh Phuong", "title": "Classifying Vietnamese Disease Outbreak Reports with Important Sentences\n  and Rich Features", "comments": "5 pages, 2 tables", "journal-ref": "Proc. of the Third Symposium on Information and Communication\n  Technology (SoICT), pages 260-265, 2012", "doi": "10.1145/2350716.2350755", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text classification is an important field of research from mid 90s up to now.\nIt has many applications, one of them is in Web-based biosurveillance systems\nwhich identify and summarize online disease outbreak reports. In this paper we\nfocus on classifying Vietnamese disease outbreak reports. We investigate\nimportant properties of disease outbreak reports, e.g., sentences containing\nnames of outbreak disease, locations. Evaluation on 10-time 10- fold\ncross-validation using the Support Vector Machine algorithm shows that using\nsentences containing disease outbreak names with its preceding/following\nsentences in combination with location features achieve the best F-score with\n86.67% - an improvement of 0.38% in comparison to using all raw text. Our\nresults suggest that using important sentences and rich feature can improve\nperformance of Vietnamese disease outbreak text classification.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 06:46:11 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Doan", "Son", ""], ["Vinh", "Nguyen Thi Ngoc", ""], ["Phuong", "Tu Minh", ""]]}, {"id": "1911.09886", "submitter": "Tapas Nayak", "authors": "Tapas Nayak and Hwee Tou Ng", "title": "Effective Modeling of Encoder-Decoder Architecture for Joint Entity and\n  Relation Extraction", "comments": "Accepted at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A relation tuple consists of two entities and the relation between them, and\noften such tuples are found in unstructured text. There may be multiple\nrelation tuples present in a text and they may share one or both entities among\nthem. Extracting such relation tuples from a sentence is a difficult task and\nsharing of entities or overlapping entities among the tuples makes it more\nchallenging. Most prior work adopted a pipeline approach where entities were\nidentified first followed by finding the relations among them, thus missing the\ninteraction among the relation tuples in a sentence. In this paper, we propose\ntwo approaches to use encoder-decoder architecture for jointly extracting\nentities and relations. In the first approach, we propose a representation\nscheme for relation tuples which enables the decoder to generate one word at a\ntime like machine translation models and still finds all the tuples present in\na sentence with full entity names of different length and with overlapping\nentities. Next, we propose a pointer network-based decoding approach where an\nentire tuple is generated at every time step. Experiments on the publicly\navailable New York Times corpus show that our proposed approaches outperform\nprevious work and achieve significantly higher F1 scores.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 06:52:21 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Nayak", "Tapas", ""], ["Ng", "Hwee Tou", ""]]}, {"id": "1911.09896", "submitter": "Robert Hawkins", "authors": "Robert D. Hawkins, Minae Kwon, Dorsa Sadigh, Noah D. Goodman", "title": "Continual adaptation for efficient machine communication", "comments": "Accepted at CoNLL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To communicate with new partners in new contexts, humans rapidly form new\nlinguistic conventions. Recent neural language models are able to comprehend\nand produce the existing conventions present in their training data, but are\nnot able to flexibly and interactively adapt those conventions on the fly as\nhumans do. We introduce an interactive repeated reference task as a benchmark\nfor models of adaptation in communication and propose a regularized continual\nlearning framework that allows an artificial agent initialized with a generic\nlanguage model to more accurately and efficiently communicate with a partner\nover time. We evaluate this framework through simulations on COCO and in\nreal-time reference game experiments with human partners.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 07:26:40 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 09:39:21 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Hawkins", "Robert D.", ""], ["Kwon", "Minae", ""], ["Sadigh", "Dorsa", ""], ["Goodman", "Noah D.", ""]]}, {"id": "1911.09912", "submitter": "Yong Wang", "authors": "Yong Wang, Longyue Wang, Shuming Shi, Victor O.K. Li, Zhaopeng Tu", "title": "Go From the General to the Particular: Multi-Domain Translation with\n  Domain Transformation Networks", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key challenge of multi-domain translation lies in simultaneously encoding\nboth the general knowledge shared across domains and the particular knowledge\ndistinctive to each domain in a unified model. Previous work shows that the\nstandard neural machine translation (NMT) model, trained on mixed-domain data,\ngenerally captures the general knowledge, but misses the domain-specific\nknowledge. In response to this problem, we augment NMT model with additional\ndomain transformation networks to transform the general representations to\ndomain-specific representations, which are subsequently fed to the NMT decoder.\nTo guarantee the knowledge transformation, we also propose two complementary\nsupervision signals by leveraging the power of knowledge distillation and\nadversarial learning. Experimental results on several language pairs, covering\nboth balanced and unbalanced multi-domain translation, demonstrate the\neffectiveness and universality of the proposed approach. Encouragingly, the\nproposed unified model achieves comparable results with the fine-tuning\napproach that requires multiple models to preserve the particular knowledge.\nFurther analyses reveal that the domain transformation networks successfully\ncapture the domain-specific knowledge as expected.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 08:15:52 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Wang", "Yong", ""], ["Wang", "Longyue", ""], ["Shi", "Shuming", ""], ["Li", "Victor O. K.", ""], ["Tu", "Zhaopeng", ""]]}, {"id": "1911.09919", "submitter": "Claudia Savina Bianchini", "authors": "Fabrizio Borgia (UPS), Claudia S. Bianchini (FORELLIS), Patrice Dalle\n  (UPS), Maria de Marsico", "title": "Resource production of written forms of Sign Languages by a\n  user-centered editor, SWift (SignWriting improved fast transcriber)", "comments": "CITATION INDEX", "journal-ref": "Proceedings of the VIII International Language Resources\n  Evaluation Conference (LREC), ELRA - European Language Resources Association,\n  pp.3779-3784, 2012, 978-2-9517408-7-7", "doi": null, "report-no": "pubblicazione \\#009", "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The SignWriting improved fast transcriber (SWift), presented in this paper,\nis an advanced editor for computer-aided writing and transcribing of any Sign\nLanguage (SL) using SignWriting (SW). The application is an editor which allows\ncomposing and saving desired signs using the SW elementary components, called\n\"glyphs\". These make up a sort of alphabet, which does not depend on the\nnational Sign Language and which codes the basic components of any sign. The\nuser is guided through a fully-automated procedure, making the composition\nprocess fast and intuitive. SWift pursues the goal of helping to break down the\n\"electronic barriers\" that keep deaf people away from the web, and at the same\ntime to support linguistic research about Sign Languages features. For this\nreason it has been designed with a special attention to deaf user needs, and to\ngeneral usability issues. The editor has been developed in a modular way, so it\ncan be integrated everywhere the use of SW as an alternative to written\n\"verbal\" language may be advisable.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 08:36:42 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Borgia", "Fabrizio", "", "UPS"], ["Bianchini", "Claudia S.", "", "FORELLIS"], ["Dalle", "Patrice", "", "UPS"], ["de Marsico", "Maria", ""]]}, {"id": "1911.09923", "submitter": "Claudia Savina Bianchini", "authors": "Claudia S. Bianchini (FORELLIS), Fabrizio Borgia (UPS), Maria de\n  Marsico", "title": "SWift -- A SignWriting editor to bridge between deaf world and\n  e-learning", "comments": null, "journal-ref": "Proceedings of the International Conference on Advanced Learning\n  Technologies (ICALT), IEEE - Institute of Electrical and Electronics\n  Engineers, pp.526-530, 2012, 978-0-7695-4702-2", "doi": "10.1109/ICALT.2012.235", "report-no": "pubblicazione #010", "categories": "cs.HC cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SWift (SignWriting improved fast transcriber) is an advanced editor for\nSignWriting (SW). At present, SW is a promising alternative to provide\ndocuments in an easy-to-grasp written form of (any) Sign Language, the gestural\nway of communication which is widely adopted by the deaf community. SWift was\ndeveloped SW users, either deaf or not, to support collaboration and exchange\nof ideas. The application allows composing and saving desired signs using\nelementary components, called glyphs. The procedure that was devised guides and\nsimplifies the editing process. SWift aims at breaking the \"electronic\"\nbarriers that keep the deaf community away from ICT in general, and from\ne-learning in particular. The editor can be contained in a pluggable module;\ntherefore, it can be integrated everywhere the use of SW is an advisable\nalternative to written \"verbal\" language, which often hinders information\ngrasping by deaf users.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 08:44:23 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Bianchini", "Claudia S.", "", "FORELLIS"], ["Borgia", "Fabrizio", "", "UPS"], ["de Marsico", "Maria", ""]]}, {"id": "1911.09969", "submitter": "Ruixue Liu", "authors": "Meng Chen, Ruixue Liu, Lei Shen, Shaozu Yuan, Jingyan Zhou, Youzheng\n  Wu, Xiaodong He, Bowen Zhou", "title": "The JDDC Corpus: A Large-Scale Multi-Turn Chinese Dialogue Dataset for\n  E-commerce Customer Service", "comments": "This paper is accepted by LREC 2020 (International Conference on\n  Language Resources and Evaluation )", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human conversations are complicated and building a human-like dialogue agent\nis an extremely challenging task. With the rapid development of deep learning\ntechniques, data-driven models become more and more prevalent which need a huge\namount of real conversation data. In this paper, we construct a large-scale\nreal scenario Chinese E-commerce conversation corpus, JDDC, with more than 1\nmillion multi-turn dialogues, 20 million utterances, and 150 million words. The\ndataset reflects several characteristics of human-human conversations, e.g.,\ngoal-driven, and long-term dependency among the context. It also covers various\ndialogue types including task-oriented, chitchat and question-answering. Extra\nintent information and three well-annotated challenge sets are also provided.\nThen, we evaluate several retrieval-based and generative models to provide\nbasic benchmark performance on the JDDC corpus. And we hope JDDC can serve as\nan effective testbed and benefit the development of fundamental research in\ndialogue task\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 10:55:50 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 08:38:17 GMT"}, {"version": "v3", "created": "Wed, 18 Mar 2020 08:12:30 GMT"}, {"version": "v4", "created": "Tue, 24 Mar 2020 15:09:18 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Chen", "Meng", ""], ["Liu", "Ruixue", ""], ["Shen", "Lei", ""], ["Yuan", "Shaozu", ""], ["Zhou", "Jingyan", ""], ["Wu", "Youzheng", ""], ["He", "Xiaodong", ""], ["Zhou", "Bowen", ""]]}, {"id": "1911.09994", "submitter": "Nikhil Koditala K", "authors": "Vinay Annam, Nikhil Koditala and Radhika Mamidi", "title": "Anaphora Resolution in Dialogue Systems for South Asian Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anaphora resolution is a challenging task which has been the interest of NLP\nresearchers for a long time. Traditional resolution techniques like eliminative\nconstraints and weighted preferences were successful in many languages.\nHowever, they are ineffective in free word order languages like most SouthAsian\nlanguages.Heuristic and rule-based techniques were typical in these languages,\nwhich are constrained to context and domain.In this paper, we venture a new\nstrategy us-ing neural networks for resolving anaphora in human-human\ndialogues. The architecture chiefly consists of three components, a shallow\nparser for extracting features, a feature vector generator which produces the\nword embed-dings, and a neural network model which will predict the antecedent\nmention of an anaphora.The system has been trained and tested on Telugu\nconversation corpus we generated. Given the advantage of the semantic\ninformation in word embeddings and appending actor, gender, number, person and\npart of plural features the model has reached an F1-score of 86.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 12:20:44 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Annam", "Vinay", ""], ["Koditala", "Nikhil", ""], ["Mamidi", "Radhika", ""]]}, {"id": "1911.10038", "submitter": "Matej Ul\\v{c}ar", "authors": "Matej Ul\\v{c}ar, Kristiina Vaik, Jessica Lindstr\\\"om, Milda\n  Dailid\\.enait\\.e, Marko Robnik-\\v{S}ikonja", "title": "Multilingual Culture-Independent Word Analogy Datasets", "comments": "7 pages, LREC2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In text processing, deep neural networks mostly use word embeddings as an\ninput. Embeddings have to ensure that relations between words are reflected\nthrough distances in a high-dimensional numeric space. To compare the quality\nof different text embeddings, typically, we use benchmark datasets. We present\na collection of such datasets for the word analogy task in nine languages:\nCroatian, English, Estonian, Finnish, Latvian, Lithuanian, Russian, Slovenian,\nand Swedish. We redesigned the original monolingual analogy task to be much\nmore culturally independent and also constructed cross-lingual analogy datasets\nfor the involved languages. We present basic statistics of the created datasets\nand their initial evaluation using fastText embeddings.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 13:39:06 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 15:32:16 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Ul\u010dar", "Matej", ""], ["Vaik", "Kristiina", ""], ["Lindstr\u00f6m", "Jessica", ""], ["Dailid\u0117nait\u0117", "Milda", ""], ["Robnik-\u0160ikonja", "Marko", ""]]}, {"id": "1911.10049", "submitter": "Matej Ul\\v{c}ar", "authors": "Matej Ul\\v{c}ar, Marko Robnik-\\v{S}ikonja", "title": "High Quality ELMo Embeddings for Seven Less-Resourced Languages", "comments": "8 pages, 3 figures, LREC2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent results show that deep neural networks using contextual embeddings\nsignificantly outperform non-contextual embeddings on a majority of text\nclassification task. We offer precomputed embeddings from popular contextual\nELMo model for seven languages: Croatian, Estonian, Finnish, Latvian,\nLithuanian, Slovenian, and Swedish. We demonstrate that the quality of\nembeddings strongly depends on the size of training set and show that existing\npublicly available ELMo embeddings for listed languages shall be improved. We\ntrain new ELMo embeddings on much larger training sets and show their advantage\nover baseline non-contextual FastText embeddings. In evaluation, we use two\nbenchmarks, the analogy task and the NER task.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 14:06:21 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 17:18:53 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Ul\u010dar", "Matej", ""], ["Robnik-\u0160ikonja", "Marko", ""]]}, {"id": "1911.10082", "submitter": "Arushi Goel", "authors": "Arushi Goel, Basura Fernando, Thanh-Son Nguyen, and Hakan Bilen", "title": "Injecting Prior Knowledge into Image Caption Generation", "comments": "ECCV20 VIPriors Workshop; 14 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatically generating natural language descriptions from an image is a\nchallenging problem in artificial intelligence that requires a good\nunderstanding of the visual and textual signals and the correlations between\nthem. The state-of-the-art methods in image captioning struggles to approach\nhuman level performance, especially when data is limited. In this paper, we\npropose to improve the performance of the state-of-the-art image captioning\nmodels by incorporating two sources of prior knowledge: (i) a conditional\nlatent topic attention, that uses a set of latent variables (topics) as an\nanchor to generate highly probable words and, (ii) a regularization technique\nthat exploits the inductive biases in syntactic and semantic structure of\ncaptions and improves the generalization of image captioning models. Our\nexperiments validate that our method produces more human interpretable captions\nand also leads to significant improvements on the MSCOCO dataset in both the\nfull and low data regimes.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 15:22:34 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 14:19:51 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Goel", "Arushi", ""], ["Fernando", "Basura", ""], ["Nguyen", "Thanh-Son", ""], ["Bilen", "Hakan", ""]]}, {"id": "1911.10088", "submitter": "Xinyi Wang", "authors": "Xinyi Wang, Hieu Pham, Paul Michel, Antonios Anastasopoulos, Jaime\n  Carbonell, Graham Neubig", "title": "Optimizing Data Usage via Differentiable Rewards", "comments": "Accepted at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To acquire a new skill, humans learn better and faster if a tutor, based on\ntheir current knowledge level, informs them of how much attention they should\npay to particular content or practice problems. Similarly, a machine learning\nmodel could potentially be trained better with a scorer that \"adapts\" to its\ncurrent learning state and estimates the importance of each training data\ninstance. Training such an adaptive scorer efficiently is a challenging\nproblem; in order to precisely quantify the effect of a data instance at a\ngiven time during the training, it is typically necessary to first complete the\nentire training process. To efficiently optimize data usage, we propose a\nreinforcement learning approach called Differentiable Data Selection (DDS). In\nDDS, we formulate a scorer network as a learnable function of the training\ndata, which can be efficiently updated along with the main model being trained.\nSpecifically, DDS updates the scorer with an intuitive reward signal: it should\nup-weigh the data that has a similar gradient with a dev set upon which we\nwould finally like to perform well. Without significant computing overhead, DDS\ndelivers strong and consistent improvements over several strong baselines on\ntwo very different tasks of machine translation and image classification.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 15:38:01 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 03:46:58 GMT"}, {"version": "v3", "created": "Wed, 16 Jun 2021 18:33:21 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Wang", "Xinyi", ""], ["Pham", "Hieu", ""], ["Michel", "Paul", ""], ["Anastasopoulos", "Antonios", ""], ["Carbonell", "Jaime", ""], ["Neubig", "Graham", ""]]}, {"id": "1911.10097", "submitter": "Fangyu Liu", "authors": "Fangyu Liu, Rongtian Ye, Xun Wang, Shuaipeng Li", "title": "HAL: Improved Text-Image Matching by Mitigating Visual Semantic Hubs", "comments": "AAAI-20 (to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The hubness problem widely exists in high-dimensional embedding space and is\na fundamental source of error for cross-modal matching tasks. In this work, we\nstudy the emergence of hubs in Visual Semantic Embeddings (VSE) with\napplication to text-image matching. We analyze the pros and cons of two widely\nadopted optimization objectives for training VSE and propose a novel\nhubness-aware loss function (HAL) that addresses previous methods' defects.\nUnlike (Faghri et al.2018) which simply takes the hardest sample within a\nmini-batch, HAL takes all samples into account, using both local and global\nstatistics to scale up the weights of \"hubs\". We experiment our method with\nvarious configurations of model architectures and datasets. The method exhibits\nexceptionally good robustness and brings consistent improvement on the task of\ntext-image matching across all settings. Specifically, under the same model\narchitectures as (Faghri et al. 2018) and (Lee at al. 2018), by switching only\nthe learning objective, we report a maximum R@1improvement of 7.4% on MS-COCO\nand 8.3% on Flickr30k.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 15:51:08 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Liu", "Fangyu", ""], ["Ye", "Rongtian", ""], ["Wang", "Xun", ""], ["Li", "Shuaipeng", ""]]}, {"id": "1911.10115", "submitter": "Chiranjib Sur", "authors": "Chiranjib Sur", "title": "TPsgtR: Neural-Symbolic Tensor Product Scene-Graph-Triplet\n  Representation for Image Captioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Image captioning can be improved if the structure of the graphical\nrepresentations can be formulated with conceptual positional binding. In this\nwork, we have introduced a novel technique for caption generation using the\nneural-symbolic encoding of the scene-graphs, derived from regional visual\ninformation of the images and we call it Tensor Product Scene-Graph-Triplet\nRepresentation (TP$_{sgt}$R). While, most of the previous works concentrated on\nidentification of the object features in images, we introduce a neuro-symbolic\nembedding that can embed identified relationships among different regions of\nthe image into concrete forms, instead of relying on the model to compose for\nany/all combinations. These neural symbolic representation helps in better\ndefinition of the neural symbolic space for neuro-symbolic attention and can be\ntransformed to better captions. With this approach, we introduced two novel\narchitectures (TP$_{sgt}$R-TDBU and TP$_{sgt}$R-sTDBU) for comparison and\nexperiment result demonstrates that our approaches outperformed the other\nmodels, and generated captions are more comprehensive and natural.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:17:21 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Sur", "Chiranjib", ""]]}, {"id": "1911.10130", "submitter": "Amey Girish Parundekar", "authors": "Amey Parundekar, Susan Elias, Ashwin Ashok", "title": "A Data Set of Internet Claims and Comparison of their Sentiments with\n  Credibility", "comments": "8 pages, 6 figures, A paper accepted at the Truth Discovery and Fact\n  Checking: Theory and Practice SIGKDD 2019 Workshop, August 5th, Anchorage,\n  Alaska", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this modern era, communication has become faster and easier. This means\nfallacious information can spread as fast as reality. Considering the damage\nthat fake news kindles on the psychology of people and the fact that such news\nproliferates faster than truth, we need to study the phenomenon that helps\nspread fake news. An unbiased data set that depends on reality for rating news\nis necessary to construct predictive models for its classification. This paper\ndescribes the methodology to create such a data set. We collect our data from\nsnopes.com which is a fact-checking organization. Furthermore, we intend to\ncreate this data set not only for classification of the news but also to find\npatterns that reason the intent behind misinformation. We also formally define\nan Internet Claim, its credibility, and the sentiment behind such a claim. We\ntry to realize the relationship between the sentiment of a claim with its\ncredibility. This relationship pours light on the bigger picture behind the\npropagation of misinformation. We pave the way for further research based on\nthe methodology described in this paper to create the data set and usage of\npredictive modeling along with research-based on psychology/mentality of people\nto understand why fake news spreads much faster than reality.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:35:37 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Parundekar", "Amey", ""], ["Elias", "Susan", ""], ["Ashok", "Ashwin", ""]]}, {"id": "1911.10132", "submitter": "Chiranjib Sur", "authors": "Chiranjib Sur", "title": "CRUR: Coupled-Recurrent Unit for Unification, Conceptualization and\n  Context Capture for Language Representation -- A Generalization of Bi\n  Directional LSTM", "comments": "in Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we have analyzed a novel concept of sequential binding based\nlearning capable network based on the coupling of recurrent units with Bayesian\nprior definition. The coupling structure encodes to generate efficient tensor\nrepresentations that can be decoded to generate efficient sentences and can\ndescribe certain events. These descriptions are derived from structural\nrepresentations of visual features of images and media. An elaborated study of\nthe different types of coupling recurrent structures are studied and some\ninsights of their performance are provided. Supervised learning performance for\nnatural language processing is judged based on statistical evaluations,\nhowever, the truth is perspective, and in this case the qualitative evaluations\nreveal the real capability of the different architectural strengths and\nvariations. Bayesian prior definition of different embedding helps in better\ncharacterization of the sentences based on the natural language structure\nrelated to parts of speech and other semantic level categorization in a form\nwhich is machine interpret-able and inherits the characteristics of the Tensor\nRepresentation binding and unbinding based on the mutually orthogonality. Our\napproach has surpassed some of the existing basic works related to image\ncaptioning.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 16:48:10 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Sur", "Chiranjib", ""]]}, {"id": "1911.10154", "submitter": "Camilo Miguel Signorelli", "authors": "Camilo M. Signorelli, Xerxes D. Arsiwalla", "title": "Moral Dilemmas for Artificial Intelligence: a position paper on an\n  application of Compositional Quantum Cognition", "comments": "15 pages, 3 figures, Conference paper at Quantum Interaction 2018,\n  Nice, France. Published in Lecture Notes in Computer Science, vol 11690,\n  Springer, Cham. Online ISBN 978-3-030-35895-2", "journal-ref": "Quantum Interaction. QI 2018. Lecture Notes in Computer Science,\n  vol 11690", "doi": "10.1007/978-3-030-35895-2_9", "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Traditionally, the way one evaluates the performance of an Artificial\nIntelligence (AI) system is via a comparison to human performance in specific\ntasks, treating humans as a reference for high-level cognition. However, these\ncomparisons leave out important features of human intelligence: the capability\nto transfer knowledge and make complex decisions based on emotional and\nrational reasoning. These decisions are influenced by current inferences as\nwell as prior experiences, making the decision process strongly subjective and\napparently biased. In this context, a definition of compositional intelligence\nis necessary to incorporate these features in future AI tests. Here, a concrete\nimplementation of this will be suggested, using recent developments in quantum\ncognition, natural language and compositional meaning of sentences, thanks to\ncategorical compositional models of meaning.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 17:25:32 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Signorelli", "Camilo M.", ""], ["Arsiwalla", "Xerxes D.", ""]]}, {"id": "1911.10180", "submitter": "Gabriele Pergola", "authors": "Gabriele Pergola, Yulan He, David Lowe", "title": "Topical Phrase Extraction from Clinical Reports by Incorporating both\n  Local and Global Context", "comments": "The 2nd AAAI Workshop on Health Intelligence, AAAI18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making sense of words often requires to simultaneously examine the\nsurrounding context of a term as well as the global themes characterizing the\noverall corpus. Several topic models have already exploited word embeddings to\nrecognize local context, however, it has been weakly combined with the global\ncontext during the topic inference. This paper proposes to extract topical\nphrases corroborating the word embedding information with the global context\ndetected by Latent Semantic Analysis, and then combine them by means of the\nP\\'{o}lya urn model. To highlight the effectiveness of this combined approach\nthe model was assessed analyzing clinical reports, a challenging scenario\ncharacterized by technical jargon and a limited word statistics available.\nResults show it outperforms the state-of-the-art approaches in terms of both\ntopic coherence and computational cost.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 18:29:19 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Pergola", "Gabriele", ""], ["He", "Yulan", ""], ["Lowe", "David", ""]]}, {"id": "1911.10183", "submitter": "Edwin D. Simpson", "authors": "Edwin Simpson, Yang Gao, Iryna Gurevych", "title": "Interactive Text Ranking with Bayesian Optimisation: A Case Study on\n  Community QA and Summarisation", "comments": "Accepted to Transactions of the ACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many NLP applications, such as question answering and summarisation, the\ngoal is to select the best solution from a large space of candidates to meet a\nparticular user's needs. To address the lack of user-specific training data, we\npropose an interactive text ranking approach that actively selects pairs of\ncandidates, from which the user selects the best. Unlike previous strategies,\nwhich attempt to learn a ranking across the whole candidate space, our method\nemploys Bayesian optimisation to focus the user's labelling effort on high\nquality candidates and integrates prior knowledge in a Bayesian manner to cope\nbetter with small data scenarios. We apply our method to community question\nanswering (cQA) and extractive summarisation, finding that it significantly\noutperforms existing interactive approaches. We also show that the ranking\nfunction learned by our method is an effective reward function for\nreinforcement learning, which improves the state of the art for interactive\nsummarisation.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 18:31:53 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 14:16:44 GMT"}, {"version": "v3", "created": "Sat, 12 Sep 2020 02:38:30 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Simpson", "Edwin", ""], ["Gao", "Yang", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1911.10235", "submitter": "Yiren Wang", "authors": "Yiren Wang, Hongzhao Huang, Zhe Liu, Yutong Pang, Yongqiang Wang,\n  ChengXiang Zhai, Fuchun Peng", "title": "Improving N-gram Language Models with Pre-trained Deep Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although n-gram language models (LMs) have been outperformed by the\nstate-of-the-art neural LMs, they are still widely used in speech recognition\ndue to its high efficiency in inference. In this paper, we demonstrate that\nn-gram LM can be improved by neural LMs through a text generation based data\naugmentation method. In contrast to previous approaches, we employ a\nlarge-scale general domain pre-training followed by in-domain fine-tuning\nstrategy to construct deep Transformer based neural LMs. Large amount of\nin-domain text data is generated with the well trained deep Transformer to\nconstruct new n-gram LMs, which are then interpolated with baseline n-gram\nsystems. Empirical studies on different speech recognition tasks show that the\nproposed approach can effectively improve recognition accuracy. In particular,\nour proposed approach brings significant relative word error rate reduction up\nto 6.0% for domains with limited in-domain data.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 20:11:40 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Wang", "Yiren", ""], ["Huang", "Hongzhao", ""], ["Liu", "Zhe", ""], ["Pang", "Yutong", ""], ["Wang", "Yongqiang", ""], ["Zhai", "ChengXiang", ""], ["Peng", "Fuchun", ""]]}, {"id": "1911.10354", "submitter": "Kohei Uehara", "authors": "Kohei Uehara, Tatsuya Harada", "title": "Unsupervised Keyword Extraction for Full-sentence VQA", "comments": "EMNLP 2020 workshop: NLP Beyond Text (NLPBT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the majority of the existing Visual Question Answering (VQA) research, the\nanswers consist of short, often single words, as per instructions given to the\nannotators during dataset construction. This study envisions a VQA task for\nnatural situations, where the answers are more likely to be sentences rather\nthan single words. To bridge the gap between this natural VQA and existing VQA\napproaches, a novel unsupervised keyword extraction method is proposed. The\nmethod is based on the principle that the full-sentence answers can be\ndecomposed into two parts: one that contains new information answering the\nquestion (i.e., keywords), and one that contains information already included\nin the question. Discriminative decoders were designed to achieve such\ndecomposition, and the method was experimentally implemented on VQA datasets\ncontaining full-sentence answers. The results show that the proposed model can\naccurately extract the keywords without being given explicit annotations\ndescribing them.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 12:18:03 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 07:37:34 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 09:20:30 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Uehara", "Kohei", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1911.10384", "submitter": "Yang Zhong", "authors": "Yang Zhong, Chao Jiang, Wei Xu, Junyi Jessy Li", "title": "Discourse Level Factors for Sentence Deletion in Text Simplification", "comments": "Accepted in AAAI 2020. Adding more details on manual data annotation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a data-driven study focusing on analyzing and predicting\nsentence deletion -- a prevalent but understudied phenomenon in document\nsimplification -- on a large English text simplification corpus. We inspect\nvarious document and discourse factors associated with sentence deletion, using\na new manually annotated sentence alignment corpus we collected. We reveal that\nprofessional editors utilize different strategies to meet readability standards\nof elementary and middle schools. To predict whether a sentence will be deleted\nduring simplification to a certain level, we harness automatically aligned data\nto train a classification model. Evaluated on our manually annotated data, our\nbest models reached F1 scores of 65.2 and 59.7 for this task at the levels of\nelementary and middle school, respectively. We find that discourse level\nfactors contribute to the challenging task of predicting sentence deletion for\nsimplification.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 16:23:21 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 03:36:42 GMT"}, {"version": "v3", "created": "Sun, 23 Aug 2020 16:34:34 GMT"}, {"version": "v4", "created": "Tue, 25 Aug 2020 18:45:00 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Zhong", "Yang", ""], ["Jiang", "Chao", ""], ["Xu", "Wei", ""], ["Li", "Junyi Jessy", ""]]}, {"id": "1911.10389", "submitter": "Fei Liu", "authors": "Kaiqiang Song and Logan Lebanoff and Qipeng Guo and Xipeng Qiu and\n  Xiangyang Xue and Chen Li and Dong Yu and Fei Liu", "title": "Joint Parsing and Generation for Abstractive Summarization", "comments": "AAAI 2020 (Main Technical Track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentences produced by abstractive summarization systems can be ungrammatical\nand fail to preserve the original meanings, despite being locally fluent. In\nthis paper we propose to remedy this problem by jointly generating a sentence\nand its syntactic dependency parse while performing abstraction. If generating\na word can introduce an erroneous relation to the summary, the behavior must be\ndiscouraged. The proposed method thus holds promise for producing grammatical\nsentences and encouraging the summary to stay true-to-original. Our\ncontributions of this work are twofold. First, we present a novel neural\narchitecture for abstractive summarization that combines a sequential decoder\nwith a tree-based decoder in a synchronized manner to generate a summary\nsentence and its syntactic parse. Secondly, we describe a novel human\nevaluation protocol to assess if, and to what extent, a summary remains true to\nits original meanings. We evaluate our method on a number of summarization\ndatasets and demonstrate competitive results against strong baselines.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 17:28:54 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Song", "Kaiqiang", ""], ["Lebanoff", "Logan", ""], ["Guo", "Qipeng", ""], ["Qiu", "Xipeng", ""], ["Xue", "Xiangyang", ""], ["Li", "Chen", ""], ["Yu", "Dong", ""], ["Liu", "Fei", ""]]}, {"id": "1911.10390", "submitter": "Fei Liu", "authors": "Kaiqiang Song and Bingqing Wang and Zhe Feng and Liu Ren and Fei Liu", "title": "Controlling the Amount of Verbatim Copying in Abstractive Summarization", "comments": "AAAI 2020 (Main Technical Track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An abstract must not change the meaning of the original text. A single most\neffective way to achieve that is to increase the amount of copying while still\nallowing for text abstraction. Human editors can usually exercise control over\ncopying, resulting in summaries that are more extractive than abstractive, or\nvice versa. However, it remains poorly understood whether modern neural\nabstractive summarizers can provide the same flexibility, i.e., learning from\nsingle reference summaries to generate multiple summary hypotheses with varying\ndegrees of copying. In this paper, we present a neural summarization model\nthat, by learning from single human abstracts, can produce a broad spectrum of\nsummaries ranging from purely extractive to highly generative ones. We frame\nthe task of summarization as language modeling and exploit alternative\nmechanisms to generate summary hypotheses. Our method allows for control over\ncopying during both training and decoding stages of a neural summarization\nmodel. Through extensive experiments we illustrate the significance of our\nproposed method on controlling the amount of verbatim copying and achieve\ncompetitive results over strong baselines. Our analysis further reveals\ninteresting and unobvious facts.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 17:34:19 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Song", "Kaiqiang", ""], ["Wang", "Bingqing", ""], ["Feng", "Zhe", ""], ["Ren", "Liu", ""], ["Liu", "Fei", ""]]}, {"id": "1911.10392", "submitter": "Mohsen Mesgar", "authors": "Mohsen Mesgar, Paul Youssef, Lin Li, Dominik Bierwirth, Yihao Li,\n  Christian M. Meyer, Iryna Gurevych", "title": "When is ACL's Deadline? A Scientific Conversational Agent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our conversational agent UKP-ATHENA assists NLP researchers in finding and\nexploring scientific literature, identifying relevant authors, planning or\npost-processing conference visits, and preparing paper submissions using a\nunified interface based on natural language inputs and responses. UKP-ATHENA\nenables new access paths to our swiftly evolving research area with its massive\namounts of scientific information and high turnaround times. UKP-ATHENA's\nresponses connect information from multiple heterogeneous sources which\nresearchers currently have to explore manually one after another. Unlike a\nsearch engine, UKP-ATHENA maintains the context of a conversation to allow for\nefficient information access on papers, researchers, and conferences. Our\narchitecture consists of multiple components with reference implementations\nthat can be easily extended by new skills and domains. Our user-based\nevaluation shows that UKP-ATHENA already responds 45% of different formulations\nof defined intents with 37% information coverage rate.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 17:41:02 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Mesgar", "Mohsen", ""], ["Youssef", "Paul", ""], ["Li", "Lin", ""], ["Bierwirth", "Dominik", ""], ["Li", "Yihao", ""], ["Meyer", "Christian M.", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1911.10401", "submitter": "Rolandos Alexandros Potamias", "authors": "Rolandos Alexandros Potamias, Georgios Siolas, Andreas - Georgios\n  Stafylopatis", "title": "A Transformer-based approach to Irony and Sarcasm detection", "comments": "Neural Comput & Applic (2020)", "journal-ref": null, "doi": "10.1007/s00521-020-05102-3", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Figurative Language (FL) seems ubiquitous in all social-media discussion\nforums and chats, posing extra challenges to sentiment analysis endeavors.\nIdentification of FL schemas in short texts remains largely an unresolved issue\nin the broader field of Natural Language Processing (NLP), mainly due to their\ncontradictory and metaphorical meaning content. The main FL expression forms\nare sarcasm, irony and metaphor. In the present paper we employ advanced Deep\nLearning (DL) methodologies to tackle the problem of identifying the\naforementioned FL forms. Significantly extending our previous work [71], we\npropose a neural network methodology that builds on a recently proposed\npre-trained transformer-based network architecture which, is further enhanced\nwith the employment and devise of a recurrent convolutional neural network\n(RCNN). With this set-up, data preprocessing is kept in minimum. The\nperformance of the devised hybrid neural architecture is tested on four\nbenchmark datasets, and contrasted with other relevant state of the art\nmethodologies and systems. Results demonstrate that the proposed methodology\nachieves state of the art performance under all benchmark datasets,\noutperforming, even by a large margin, all other methodologies and published\nstudies.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 18:37:48 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 12:56:51 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Potamias", "Rolandos Alexandros", ""], ["Siolas", "Georgios", ""], ["Stafylopatis", "Andreas - Georgios", ""]]}, {"id": "1911.10421", "submitter": "Preslav Nakov", "authors": "Iris Hendrickx, Preslav Nakov, Stan Szpakowicz, Zornitsa Kozareva,\n  Diarmuid \\'O S\\'eaghdha, Tony Veale", "title": "SemEval-2013 Task 4: Free Paraphrases of Noun Compounds", "comments": "noun compounds, paraphrasing verbs, semantic interpretation,\n  multi-word expressions, MWEs", "journal-ref": "SemEval-2013", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe SemEval-2013 Task 4: the definition, the data, the\nevaluation and the results. The task is to capture some of the meaning of\nEnglish noun compounds via paraphrasing. Given a two-word noun compound, the\nparticipating system is asked to produce an explicitly ranked list of its\nfree-form paraphrases. The list is automatically compared and evaluated against\na similarly ranked list of paraphrases proposed by human annotators, recruited\nand managed through Amazon's Mechanical Turk. The comparison of raw paraphrases\nis sensitive to syntactic and morphological variation. The \"gold\" ranking is\nbased on the relative popularity of paraphrases among annotators. To make the\nranking more reliable, highly similar paraphrases are grouped, so as to\ndownplay superficial differences in syntax and morphology. Three systems\nparticipated in the task. They all beat a simple baseline on one of the two\nevaluation measures, but not on both measures. This shows that the task is\ndifficult.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 21:42:23 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Hendrickx", "Iris", ""], ["Nakov", "Preslav", ""], ["Szpakowicz", "Stan", ""], ["Kozareva", "Zornitsa", ""], ["S\u00e9aghdha", "Diarmuid \u00d3", ""], ["Veale", "Tony", ""]]}, {"id": "1911.10422", "submitter": "Preslav Nakov", "authors": "Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva, Preslav Nakov, Diarmuid\n  \\'O S\\'eaghdha, Sebastian Pad\\'o, Marco Pennacchiotti, Lorenza Romano, Stan\n  Szpakowicz", "title": "SemEval-2010 Task 8: Multi-Way Classification of Semantic Relations\n  Between Pairs of Nominals", "comments": "semantic relations, nominals", "journal-ref": "SemEval-2010", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In response to the continuing research interest in computational semantic\nanalysis, we have proposed a new task for SemEval-2010: multi-way\nclassification of mutually exclusive semantic relations between pairs of\nnominals. The task is designed to compare different approaches to the problem\nand to provide a standard testbed for future research. In this paper, we define\nthe task, describe the creation of the datasets, and discuss the results of the\nparticipating 28 systems submitted by 10 teams.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 21:49:10 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Hendrickx", "Iris", ""], ["Kim", "Su Nam", ""], ["Kozareva", "Zornitsa", ""], ["Nakov", "Preslav", ""], ["S\u00e9aghdha", "Diarmuid \u00d3", ""], ["Pad\u00f3", "Sebastian", ""], ["Pennacchiotti", "Marco", ""], ["Romano", "Lorenza", ""], ["Szpakowicz", "Stan", ""]]}, {"id": "1911.10436", "submitter": "Peter Jansen", "authors": "Hannah Smith, Zeyu Zhang, John Culnan, Peter Jansen", "title": "ScienceExamCER: A High-Density Fine-Grained Science-Domain Corpus for\n  Common Entity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity recognition identifies common classes of entities in text, but\nthese entity labels are generally sparse, limiting utility to downstream tasks.\nIn this work we present ScienceExamCER, a densely-labeled semantic\nclassification corpus of 133k mentions in the science exam domain where nearly\nall (96%) of content words have been annotated with one or more fine-grained\nsemantic class labels including taxonomic groups, meronym groups, verb/action\ngroups, properties and values, and synonyms. Semantic class labels are drawn\nfrom a manually-constructed fine-grained typology of 601 classes generated\nthrough a data-driven analysis of 4,239 science exam questions. We show an\noff-the-shelf BERT-based named entity recognition model modified for\nmulti-label classification achieves an accuracy of 0.85 F1 on this task,\nsuggesting strong utility for downstream tasks in science domain question\nanswering requiring densely-labeled semantic classification.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 00:08:09 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Smith", "Hannah", ""], ["Zhang", "Zeyu", ""], ["Culnan", "John", ""], ["Jansen", "Peter", ""]]}, {"id": "1911.10438", "submitter": "Ranran Haoran Zhang", "authors": "Daojian Zeng, Ranran Haoran Zhang, Qianying Liu", "title": "CopyMTL: Copy Mechanism for Joint Extraction of Entities and Relations\n  with Multi-Task Learning", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint extraction of entities and relations has received significant attention\ndue to its potential of providing higher performance for both tasks. Among\nexisting methods, CopyRE is effective and novel, which uses a\nsequence-to-sequence framework and copy mechanism to directly generate the\nrelation triplets. However, it suffers from two fatal problems. The model is\nextremely weak at differing the head and tail entity, resulting in inaccurate\nentity extraction. It also cannot predict multi-token entities (e.g.\n\\textit{Steven Jobs}). To address these problems, we give a detailed analysis\nof the reasons behind the inaccurate entity extraction problem, and then\npropose a simple but extremely effective model structure to solve this problem.\nIn addition, we propose a multi-task learning framework equipped with copy\nmechanism, called CopyMTL, to allow the model to predict multi-token entities.\nExperiments reveal the problems of CopyRE and show that our model achieves\nsignificant improvement over the current state-of-the-art method by 9% in NYT\nand 16% in WebNLG (F1 score). Our code is available at\nhttps://github.com/WindChimeRan/CopyMTL\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 00:24:32 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 15:47:57 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Zeng", "Daojian", ""], ["Zhang", "Ranran Haoran", ""], ["Liu", "Qianying", ""]]}, {"id": "1911.10439", "submitter": "Yueqi Feng", "authors": "Yueqi Feng, Jiali Lin", "title": "Enhancing Out-Of-Domain Utterance Detection with Data Augmentation Based\n  on Word Embeddings", "comments": "I see some improvements that can be done. There will be a major\n  change regarding the main idea", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For most intelligent assistant systems, it is essential to have a mechanism\nthat detects out-of-domain (OOD) utterances automatically to handle noisy input\nproperly. One typical approach would be introducing a separate class that\ncontains OOD utterance examples combined with in-domain text samples into the\nclassifier. However, since OOD utterances are usually unseen to the training\ndatasets, the detection performance largely depends on the quality of the\nattached OOD text data with restricted sizes of samples due to computing\nlimits. In this paper, we study how augmented OOD data based on sampling impact\nOOD utterance detection with a small sample size. We hypothesize that OOD\nutterance samples chosen randomly can increase the coverage of unknown OOD\nutterance space and enhance detection accuracy if they are more dispersed.\nExperiments show that given the same dataset with the same OOD sample size, the\nOOD utterance detection performance improves when OOD samples are more\nspread-out.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 00:30:30 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 23:37:47 GMT"}, {"version": "v3", "created": "Fri, 27 Mar 2020 00:34:37 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Feng", "Yueqi", ""], ["Lin", "Jiali", ""]]}, {"id": "1911.10460", "submitter": "Shizhe Chen", "authors": "Shizhe Chen, Bei Liu, Jianlong Fu, Ruihua Song, Qin Jin, Pingping Lin,\n  Xiaoyu Qi, Chunting Wang and Jin Zhou", "title": "Neural Storyboard Artist: Visualizing Stories with Coherent Image\n  Sequences", "comments": "ACM MM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A storyboard is a sequence of images to illustrate a story containing\nmultiple sentences, which has been a key process to create different story\nproducts. In this paper, we tackle a new multimedia task of automatic\nstoryboard creation to facilitate this process and inspire human artists.\nInspired by the fact that our understanding of languages is based on our past\nexperience, we propose a novel inspire-and-create framework with a\nstory-to-image retriever that selects relevant cinematic images for inspiration\nand a storyboard creator that further refines and renders images to improve the\nrelevancy and visual consistency. The proposed retriever dynamically employs\ncontextual information in the story with hierarchical attentions and applies\ndense visual-semantic matching to accurately retrieve and ground images. The\ncreator then employs three rendering steps to increase the flexibility of\nretrieved images, which include erasing irrelevant regions, unifying styles of\nimages and substituting consistent characters. We carry out extensive\nexperiments on both in-domain and out-of-domain visual story datasets. The\nproposed model achieves better quantitative performance than the\nstate-of-the-art baselines for storyboard creation. Qualitative visualizations\nand user studies further verify that our approach can create high-quality\nstoryboards even for stories in the wild.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 05:06:41 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Chen", "Shizhe", ""], ["Liu", "Bei", ""], ["Fu", "Jianlong", ""], ["Song", "Ruihua", ""], ["Jin", "Qin", ""], ["Lin", "Pingping", ""], ["Qi", "Xiaoyu", ""], ["Wang", "Chunting", ""], ["Zhou", "Jin", ""]]}, {"id": "1911.10470", "submitter": "Akari Asai Ms", "authors": "Akari Asai, Kazuma Hashimoto, Hannaneh Hajishirzi, Richard Socher,\n  Caiming Xiong", "title": "Learning to Retrieve Reasoning Paths over Wikipedia Graph for Question\n  Answering", "comments": "Published as a conference paper at ICLR 2020. Code is available at\n  https://github.com/AkariAsai/learning_to_retrieve_reasoning_paths", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering questions that require multi-hop reasoning at web-scale\nnecessitates retrieving multiple evidence documents, one of which often has\nlittle lexical or semantic relationship to the question. This paper introduces\na new graph-based recurrent retrieval approach that learns to retrieve\nreasoning paths over the Wikipedia graph to answer multi-hop open-domain\nquestions. Our retriever model trains a recurrent neural network that learns to\nsequentially retrieve evidence paragraphs in the reasoning path by conditioning\non the previously retrieved documents. Our reader model ranks the reasoning\npaths and extracts the answer span included in the best reasoning path.\nExperimental results show state-of-the-art results in three open-domain QA\ndatasets, showcasing the effectiveness and robustness of our method. Notably,\nour method achieves significant improvement in HotpotQA, outperforming the\nprevious best model by more than 14 points.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 08:27:42 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 07:43:06 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Asai", "Akari", ""], ["Hashimoto", "Kazuma", ""], ["Hajishirzi", "Hannaneh", ""], ["Socher", "Richard", ""], ["Xiong", "Caiming", ""]]}, {"id": "1911.10484", "submitter": "Yichi Zhang", "authors": "Yichi Zhang, Zhijian Ou, Zhou Yu", "title": "Task-Oriented Dialog Systems that Consider Multiple Appropriate\n  Responses under the Same Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversations have an intrinsic one-to-many property, which means that\nmultiple responses can be appropriate for the same dialog context. In\ntask-oriented dialogs, this property leads to different valid dialog policies\ntowards task completion. However, none of the existing task-oriented dialog\ngeneration approaches takes this property into account. We propose a\nMulti-Action Data Augmentation (MADA) framework to utilize the one-to-many\nproperty to generate diverse appropriate dialog responses. Specifically, we\nfirst use dialog states to summarize the dialog history, and then discover all\npossible mappings from every dialog state to its different valid system\nactions. During dialog system training, we enable the current dialog state to\nmap to all valid system actions discovered in the previous process to create\nadditional state-action pairs. By incorporating these additional pairs, the\ndialog policy learns a balanced action distribution, which further guides the\ndialog model to generate diverse responses. Experimental results show that the\nproposed framework consistently improves dialog policy diversity, and results\nin improved response diversity and appropriateness. Our model obtains\nstate-of-the-art results on MultiWOZ.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 09:32:55 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 17:37:11 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Zhang", "Yichi", ""], ["Ou", "Zhijian", ""], ["Yu", "Zhou", ""]]}, {"id": "1911.10496", "submitter": "Jiaxin Qi", "authors": "Jiaxin Qi, Yulei Niu, Jianqiang Huang, Hanwang Zhang", "title": "Two Causal Principles for Improving Visual Dialog", "comments": "Accepted by CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper unravels the design tricks adopted by us, the champion team\nMReaL-BDAI, for Visual Dialog Challenge 2019: two causal principles for\nimproving Visual Dialog (VisDial). By \"improving\", we mean that they can\npromote almost every existing VisDial model to the state-of-the-art performance\non the leader-board. Such a major improvement is only due to our careful\ninspection on the causality behind the model and data, finding that the\ncommunity has overlooked two causalities in VisDial. Intuitively, Principle 1\nsuggests: we should remove the direct input of the dialog history to the answer\nmodel, otherwise a harmful shortcut bias will be introduced; Principle 2 says:\nthere is an unobserved confounder for history, question, and answer, leading to\nspurious correlations from training data. In particular, to remove the\nconfounder suggested in Principle 2, we propose several causal intervention\nalgorithms, which make the training fundamentally different from the\ntraditional likelihood estimation. Note that the two principles are\nmodel-agnostic, so they are applicable in any VisDial model. The code is\navailable at https://github.com/simpleshinobu/visdial-principles.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 10:35:35 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 17:09:34 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Qi", "Jiaxin", ""], ["Niu", "Yulei", ""], ["Huang", "Jianqiang", ""], ["Zhang", "Hanwang", ""]]}, {"id": "1911.10524", "submitter": "Zekun Yang", "authors": "Zekun Yang, Tianlin Liu", "title": "Causally Denoise Word Embeddings Using Half-Sibling Regression", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributional representations of words, also known as word vectors, have\nbecome crucial for modern natural language processing tasks due to their wide\napplications. Recently, a growing body of word vector postprocessing algorithm\nhas emerged, aiming to render off-the-shelf word vectors even stronger. In line\nwith these investigations, we introduce a novel word vector postprocessing\nscheme under a causal inference framework. Concretely, the postprocessing\npipeline is realized by Half-Sibling Regression (HSR), which allows us to\nidentify and remove confounding noise contained in word vectors. Compared to\nprevious work, our proposed method has the advantages of interpretability and\ntransparency due to its causal inference grounding. Evaluated on a battery of\nstandard lexical-level evaluation tasks and downstream sentiment analysis\ntasks, our method reaches state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 13:06:19 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Yang", "Zekun", ""], ["Liu", "Tianlin", ""]]}, {"id": "1911.10666", "submitter": "Henghui Zhu", "authors": "Henghui Zhu, Feng Nan, Zhiguo Wang, Ramesh Nallapati, Bing Xiang", "title": "Who did They Respond to? Conversation Structure Modeling using Masked\n  Hierarchical Transformer", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversation structure is useful for both understanding the nature of\nconversation dynamics and for providing features for many downstream\napplications such as summarization of conversations. In this work, we define\nthe problem of conversation structure modeling as identifying the parent\nutterance(s) to which each utterance in the conversation responds to. Previous\nwork usually took a pair of utterances to decide whether one utterance is the\nparent of the other. We believe the entire ancestral history is a very\nimportant information source to make accurate prediction. Therefore, we design\na novel masking mechanism to guide the ancestor flow, and leverage the\ntransformer model to aggregate all ancestors to predict parent utterances. Our\nexperiments are performed on the Reddit dataset (Zhang, Culbertson, and\nParitosh 2017) and the Ubuntu IRC dataset (Kummerfeld et al. 2019). In\naddition, we also report experiments on a new larger corpus from the Reddit\nplatform and release this dataset. We show that the proposed model, that takes\ninto account the ancestral history of the conversation, significantly\noutperforms several strong baselines including the BERT model on all datasets\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 02:12:45 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Zhu", "Henghui", ""], ["Nan", "Feng", ""], ["Wang", "Zhiguo", ""], ["Nallapati", "Ramesh", ""], ["Xiang", "Bing", ""]]}, {"id": "1911.10668", "submitter": "Makoto Morishita", "authors": "Makoto Morishita, Jun Suzuki and Masaaki Nagata", "title": "JParaCrawl: A Large Scale Web-Based English-Japanese Parallel Corpus", "comments": "http://www.kecl.ntt.co.jp/icl/lirg/jparacrawl/ LREC 2020, Camera\n  Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent machine translation algorithms mainly rely on parallel corpora.\nHowever, since the availability of parallel corpora remains limited, only some\nresource-rich language pairs can benefit from them. We constructed a parallel\ncorpus for English-Japanese, for which the amount of publicly available\nparallel corpora is still limited. We constructed the parallel corpus by\nbroadly crawling the web and automatically aligning parallel sentences. Our\ncollected corpus, called JParaCrawl, amassed over 8.7 million sentence pairs.\nWe show how it includes a broader range of domains and how a neural machine\ntranslation model trained with it works as a good pre-trained model for\nfine-tuning specific domains. The pre-training and fine-tuning approaches\nachieved or surpassed performance comparable to model training from the initial\nstate and reduced the training time. Additionally, we trained the model with an\nin-domain dataset and JParaCrawl to show how we achieved the best performance\nwith them. JParaCrawl and the pre-trained models are freely available online\nfor research purposes.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 02:14:51 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 20:47:31 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Morishita", "Makoto", ""], ["Suzuki", "Jun", ""], ["Nagata", "Masaaki", ""]]}, {"id": "1911.10677", "submitter": "Yu Bao", "authors": "Yu Bao, Hao Zhou, Jiangtao Feng, Mingxuan Wang, Shujian Huang, Jiajun\n  Chen, Lei LI", "title": "Non-autoregressive Transformer by Position Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-autoregressive models are promising on various text generation tasks.\nPrevious work hardly considers to explicitly model the positions of generated\nwords. However, position modeling is an essential problem in non-autoregressive\ntext generation. In this study, we propose PNAT, which incorporates positions\nas a latent variable into the text generative process. Experimental results\nshow that PNAT achieves top results on machine translation and paraphrase\ngeneration tasks, outperforming several strong baselines.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 03:08:42 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Bao", "Yu", ""], ["Zhou", "Hao", ""], ["Feng", "Jiangtao", ""], ["Wang", "Mingxuan", ""], ["Huang", "Shujian", ""], ["Chen", "Jiajun", ""], ["LI", "Lei", ""]]}, {"id": "1911.10704", "submitter": "Elizabeth Jasmi George", "authors": "Elizabeth Jasmi George, Radhika Mamidi", "title": "Conversational implicatures in English dialogue: Annotated dataset", "comments": "8 Pages, NLP'19 Short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human dialogue often contains utterances having meanings entirely different\nfrom the sentences used and are clearly understood by the interlocutors. But in\nhuman-computer interactions, the machine fails to understand the implicated\nmeaning unless it is trained with a dataset containing the implicated meaning\nof an utterance along with the utterance and the context in which it is\nuttered. In linguistic terms, conversational implicatures are the meanings of\nthe speaker's utterance that are not part of what is explicitly said. In this\npaper, we introduce a dataset of dialogue snippets with three constituents,\nwhich are the context, the utterance, and the implicated meanings. These\nimplicated meanings are the conversational implicatures. The utterances are\ncollected by transcribing from listening comprehension sections of English\ntests like TOEFL (Test of English as a Foreign Language) as well as scraping\ndialogues from movie scripts available on IMSDb (Internet Movie Script\nDatabase). The utterances are manually annotated with implicatures.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 04:57:08 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["George", "Elizabeth Jasmi", ""], ["Mamidi", "Radhika", ""]]}, {"id": "1911.10708", "submitter": "Idris Abdulmumin", "authors": "Idris Abdulmumin and Bashir Shehu Galadanci", "title": "hauWE: Hausa Words Embedding for Natural Language Processing", "comments": "In Proceedings of the 2019 2nd International Conference of the IEEE\n  Nigeria Computer Chapter", "journal-ref": null, "doi": "10.1109/NigeriaComputConf45974.2019.8949674", "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Words embedding (distributed word vector representations) have become an\nessential component of many natural language processing (NLP) tasks such as\nmachine translation, sentiment analysis, word analogy, named entity recognition\nand word similarity. Despite this, the only work that provides word vectors for\nHausa language is that of Bojanowski et al. [1] trained using fastText,\nconsisting of only a few words vectors. This work presents words embedding\nmodels using Word2Vec's Continuous Bag of Words (CBoW) and Skip Gram (SG)\nmodels. The models, hauWE (Hausa Words Embedding), are bigger and better than\nthe only previous model, making them more useful in NLP tasks. To compare the\nmodels, they were used to predict the 10 most similar words to 30 randomly\nselected Hausa words. hauWE CBoW's 88.7% and hauWE SG's 79.3% prediction\naccuracy greatly outperformed Bojanowski et al. [1]'s 22.3%.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 05:46:56 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Abdulmumin", "Idris", ""], ["Galadanci", "Bashir Shehu", ""]]}, {"id": "1911.10732", "submitter": "Qian Cao", "authors": "Qian Cao, Shaohui Kuang, Deyi Xiong", "title": "Learning to Reuse Translations: Guiding Neural Machine Translation with\n  Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of enabling neural machine translation\n(NMT) to reuse previous translations from similar examples in target\nprediction. Distinguishing reusable translations from noisy segments and\nlearning to reuse them in NMT are non-trivial. To solve these challenges, we\npropose an Example-Guided NMT (EGNMT) framework with two models: (1) a\nnoise-masked encoder model that masks out noisy words according to word\nalignments and encodes the noise-masked sentences with an additional example\nencoder and (2) an auxiliary decoder model that predicts reusable words via an\nauxiliary decoder sharing parameters with the primary decoder. We define and\nimplement the two models with the state-of-the-art Transformer. Experiments\nshow that the noise-masked encoder model allows NMT to learn useful information\nfrom examples with low fuzzy match scores (FMS) while the auxiliary decoder\nmodel is good for high-FMS examples. More experiments on Chinese-English,\nEnglish-German and English-Spanish translation demonstrate that the combination\nof the two EGNMT models can achieve improvements of up to +9 BLEU points over\nthe baseline system and +7 BLEU points over a two-encoder Transformer.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 07:22:47 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 03:19:33 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Cao", "Qian", ""], ["Kuang", "Shaohui", ""], ["Xiong", "Deyi", ""]]}, {"id": "1911.10742", "submitter": "Yu Li", "authors": "Yu Li, Kun Qian, Weiyan Shi, Zhou Yu", "title": "End-to-End Trainable Non-Collaborative Dialog System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end task-oriented dialog models have achieved promising performance on\ncollaborative tasks where users willingly coordinate with the system to\ncomplete a given task. While in non-collaborative settings, for example,\nnegotiation and persuasion, users and systems do not share a common goal. As a\nresult, compared to collaborate tasks, people use social content to build\nrapport and trust in these non-collaborative settings in order to advance their\ngoals. To handle social content, we introduce a hierarchical intent annotation\nscheme, which can be generalized to different non-collaborative dialog tasks.\nBuilding upon TransferTransfo (Wolf et al. 2019), we propose an end-to-end\nneural network model to generate diverse coherent responses. Our model utilizes\nintent and semantic slots as the intermediate sentence representation to guide\nthe generation process. In addition, we design a filter to select appropriate\nresponses based on whether these intermediate representations fit the designed\ntask and conversation constraints. Our non-collaborative dialog model guides\nusers to complete the task while simultaneously keeps them engaged. We test our\napproach on our newly proposed ANTISCAM dataset and an existing\nPERSUASIONFORGOOD dataset. Both automatic and human evaluations suggest that\nour model outperforms multiple baselines in these two non-collaborative tasks.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 07:34:37 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Li", "Yu", ""], ["Qian", "Kun", ""], ["Shi", "Weiyan", ""], ["Yu", "Zhou", ""]]}, {"id": "1911.10750", "submitter": "Hao Wang", "authors": "Hao Wang, Bing Wang, Jianyong Duan, Jiajun Zhang", "title": "Chinese Spelling Error Detection Using a Fusion Lattice LSTM", "comments": "8 pages,5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spelling error detection serves as a crucial preprocessing in many natural\nlanguage processing applications. Due to the characteristics of Chinese\nLanguage, Chinese spelling error detection is more challenging than error\ndetection in English. Existing methods are mainly under a pipeline framework,\nwhich artificially divides error detection process into two steps. Thus, these\nmethods bring error propagation and cannot always work well due to the\ncomplexity of the language environment. Besides existing methods only adopt\ncharacter or word information, and ignore the positive effect of fusing\ncharacter, word, pinyin1 information together. We propose an LF-LSTM-CRF model,\nwhich is an extension of the LSTMCRF with word lattices and\ncharacter-pinyin-fusion inputs. Our model takes advantage of the end-to-end\nframework to detect errors as a whole process, and dynamically integrates\ncharacter, word and pinyin information. Experiments on the SIGHAN data show\nthat our LF-LSTM-CRF outperforms existing methods with similar external\nresources consistently, and confirm the feasibility of adopting the end-to-end\nframework and the availability of integrating of character, word and pinyin\ninformation.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 07:58:00 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Wang", "Hao", ""], ["Wang", "Bing", ""], ["Duan", "Jianyong", ""], ["Zhang", "Jiajun", ""]]}, {"id": "1911.10763", "submitter": "Benjamin Sznajder", "authors": "Liat Ein-Dor, Eyal Shnarch, Lena Dankin, Alon Halfon, Benjamin\n  Sznajder, Ariel Gera, Carlos Alzate, Martin Gleize, Leshem Choshen, Yufang\n  Hou, Yonatan Bilu, Ranit Aharonov and Noam Slonim", "title": "Corpus Wide Argument Mining -- a Working Solution", "comments": null, "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main tasks in argument mining is the retrieval of argumentative\ncontent pertaining to a given topic. Most previous work addressed this task by\nretrieving a relatively small number of relevant documents as the initial\nsource for such content. This line of research yielded moderate success, which\nis of limited use in a real-world system. Furthermore, for such a system to\nyield a comprehensive set of relevant arguments, over a wide range of topics,\nit requires leveraging a large and diverse corpus in an appropriate manner.\nHere we present a first end-to-end high-precision, corpus-wide argument mining\nsystem. This is made possible by combining sentence-level queries over an\nappropriate indexing of a very large corpus of newspaper articles, with an\niterative annotation scheme. This scheme addresses the inherent label bias in\nthe data and pinpoints the regions of the sample space whose manual labeling is\nrequired to obtain high-precision among top-ranked candidates.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 08:29:37 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Ein-Dor", "Liat", ""], ["Shnarch", "Eyal", ""], ["Dankin", "Lena", ""], ["Halfon", "Alon", ""], ["Sznajder", "Benjamin", ""], ["Gera", "Ariel", ""], ["Alzate", "Carlos", ""], ["Gleize", "Martin", ""], ["Choshen", "Leshem", ""], ["Hou", "Yufang", ""], ["Bilu", "Yonatan", ""], ["Aharonov", "Ranit", ""], ["Slonim", "Noam", ""]]}, {"id": "1911.10768", "submitter": "Kosuke Nishida", "authors": "Kosuke Nishida, Kyosuke Nishida, Itsumi Saito, Hisako Asano, Junji\n  Tomita", "title": "Unsupervised Domain Adaptation of Language Models for Reading\n  Comprehension", "comments": "LREC2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study tackles unsupervised domain adaptation of reading comprehension\n(UDARC). Reading comprehension (RC) is a task to learn the capability for\nquestion answering with textual sources. State-of-the-art models on RC still do\nnot have general linguistic intelligence; i.e., their accuracy worsens for\nout-domain datasets that are not used in the training. We hypothesize that this\ndiscrepancy is caused by a lack of the language modeling (LM) capability for\nthe out-domain. The UDARC task allows models to use supervised RC training data\nin the source domain and only unlabeled passages in the target domain. To solve\nthe UDARC problem, we provide two domain adaptation models. The first one\nlearns the out-domain LM and in-domain RC task sequentially. The second one is\nthe proposed model that uses a multi-task learning approach of LM and RC. The\nmodels can retain both the RC capability acquired from the supervised data in\nthe source domain and the LM capability from the unlabeled data in the target\ndomain. We evaluated the models on UDARC with five datasets in different\ndomains. The models outperformed the model without domain adaptation. In\nparticular, the proposed model yielded an improvement of 4.3/4.2 points in\nEM/F1 in an unseen biomedical domain.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 08:40:34 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 16:30:55 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Nishida", "Kosuke", ""], ["Nishida", "Kyosuke", ""], ["Saito", "Itsumi", ""], ["Asano", "Hisako", ""], ["Tomita", "Junji", ""]]}, {"id": "1911.10776", "submitter": "Xiyuan Zhang", "authors": "Xiyuan Zhang, Chengxi Li, Dian Yu, Samuel Davidson, Zhou Yu", "title": "Filling Conversation Ellipsis for Better Social Dialog Understanding", "comments": "Accepted to AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The phenomenon of ellipsis is prevalent in social conversations. Ellipsis\nincreases the difficulty of a series of downstream language understanding\ntasks, such as dialog act prediction and semantic role labeling. We propose to\nresolve ellipsis through automatic sentence completion to improve language\nunderstanding. However, automatic ellipsis completion can result in output\nwhich does not accurately reflect user intent. To address this issue, we\npropose a method which considers both the original utterance that has ellipsis\nand the automatically completed utterance in dialog act and semantic role\nlabeling tasks. Specifically, we first complete user utterances to resolve\nellipsis using an end-to-end pointer network model. We then train a prediction\nmodel using both utterances containing ellipsis and our automatically completed\nutterances. Finally, we combine the prediction results from these two\nutterances using a selection model that is guided by expert knowledge. Our\napproach improves dialog act prediction and semantic role labeling by 1.3% and\n2.5% in F1 score respectively in social conversations. We also present an\nopen-domain human-machine conversation dataset with manually completed user\nutterances and annotated semantic role labeling after manual completion.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 09:21:17 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Zhang", "Xiyuan", ""], ["Li", "Chengxi", ""], ["Yu", "Dian", ""], ["Davidson", "Samuel", ""], ["Yu", "Zhou", ""]]}, {"id": "1911.10783", "submitter": "Benjamin Sznajder", "authors": "Liat Ein-Dor, Ariel Gera, Orith Toledo-Ronen, Alon Halfon, Benjamin\n  Sznajder", "title": "Financial Event Extraction Using Wikipedia-Based Weak Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extraction of financial and economic events from text has previously been\ndone mostly using rule-based methods, with more recent works employing machine\nlearning techniques. This work is in line with this latter approach, leveraging\nrelevant Wikipedia sections to extract weak labels for sentences describing\neconomic events. Whereas previous weakly supervised approaches required a\nknowledge-base of such events, or corresponding financial figures, our approach\nrequires no such additional data, and can be employed to extract economic\nevents related to companies which are not even mentioned in the training data.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 09:35:02 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Ein-Dor", "Liat", ""], ["Gera", "Ariel", ""], ["Toledo-Ronen", "Orith", ""], ["Halfon", "Alon", ""], ["Sznajder", "Benjamin", ""]]}, {"id": "1911.10787", "submitter": "Zekun Yang", "authors": "Zekun Yang, Juan Feng", "title": "A Causal Inference Method for Reducing Gender Bias in Word Embedding\n  Relations", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding has become essential for natural language processing as it\nboosts empirical performances of various tasks. However, recent research\ndiscovers that gender bias is incorporated in neural word embeddings, and\ndownstream tasks that rely on these biased word vectors also produce\ngender-biased results. While some word-embedding gender-debiasing methods have\nbeen developed, these methods mainly focus on reducing gender bias associated\nwith gender direction and fail to reduce the gender bias presented in word\nembedding relations. In this paper, we design a causal and simple approach for\nmitigating gender bias in word vector relation by utilizing the statistical\ndependency between gender-definition word embeddings and gender-biased word\nembeddings. Our method attains state-of-the-art results on gender-debiasing\ntasks, lexical- and sentence-level evaluation tasks, and downstream coreference\nresolution tasks.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 09:47:11 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Yang", "Zekun", ""], ["Feng", "Juan", ""]]}, {"id": "1911.10835", "submitter": "Vil\\'em Zouhar", "authors": "Vil\\'em Zouhar and Ond\\v{r}ej Bojar", "title": "Outbound Translation User Interface Ptakopet: A Pilot Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is not uncommon for Internet users to have to produce a text in a foreign\nlanguage they have very little knowledge of and are unable to verify the\ntranslation quality. We call the task \"outbound translation\" and explore it by\nintroducing an open-source modular system Ptakop\\v{e}t. Its main purpose is to\ninspect human interaction with MT systems enhanced with additional subsystems,\nsuch as backward translation and quality estimation. We follow up with an\nexperiment on (Czech) human annotators tasked to produce questions in a\nlanguage they do not speak (German), with the help of Ptakop\\v{e}t. We focus on\nthree real-world use cases (communication with IT support, describing\nadministrative issues and asking encyclopedic questions) from which we gain\ninsight into different strategies users take when faced with outbound\ntranslation tasks. Round trip translation is known to be unreliable for\nevaluating MT systems but our experimental evaluation documents that it works\nvery well for users, at least on MT systems of mid-range quality.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 11:22:45 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 17:40:27 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Zouhar", "Vil\u00e9m", ""], ["Bojar", "Ond\u0159ej", ""]]}, {"id": "1911.10876", "submitter": "Yerai Doval", "authors": "Yerai Doval, Jes\\'us Vilares, Carlos G\\'omez-Rodr\\'iguez", "title": "Towards robust word embeddings for noisy texts", "comments": "15 pages, 2 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on word embeddings has mainly focused on improving their performance\non standard corpora, disregarding the difficulties posed by noisy texts in the\nform of tweets and other types of non-standard writing from social media. In\nthis work, we propose a simple extension to the skipgram model in which we\nintroduce the concept of bridge-words, which are artificial words added to the\nmodel to strengthen the similarity between standard words and their noisy\nvariants. Our new embeddings outperform baseline models on noisy texts on a\nwide range of evaluation tasks, both intrinsic and extrinsic, while retaining a\ngood performance on standard texts. To the best of our knowledge, this is the\nfirst explicit approach at dealing with this type of noisy texts at the word\nembedding level that goes beyond the support for out-of-vocabulary words.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 12:48:27 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2019 11:16:52 GMT"}, {"version": "v3", "created": "Tue, 28 Jan 2020 12:00:13 GMT"}, {"version": "v4", "created": "Wed, 30 Sep 2020 19:05:12 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Doval", "Yerai", ""], ["Vilares", "Jes\u00fas", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "1911.10882", "submitter": "Claudia Savina Bianchini", "authors": "Claudia S. Bianchini (Poitiers UFR LL), Fabrizio Borgia (UPS), Paolo\n  Bottoni, Maria de Marsico", "title": "SWift -- A SignWriting improved fast transcriber", "comments": null, "journal-ref": "Proceedings of the International Working Conference on Advanced\n  Visual Interfaces, ACM - Association for Computer Machinery, pp.390 - 393,\n  2012, ACM AVI2012, 978-1-4503-1287-5", "doi": "10.1145/2254556.2254631", "report-no": "pubblicazione #008", "categories": "cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SWift (SignWriting improved fast transcriber), an advanced editor\nfor computer-aided writing and transcribing using SignWriting (SW). SW is\ndevised to allow deaf people and linguists alike to exploit an easy-to-grasp\nwritten form of (any) sign language. Similarly, SWift has been developed for\neveryone who masters SW, and is not exclusively deaf-oriented. Using SWift, it\nis possible to compose and save any sign, using elementary components called\nglyphs. A guided procedure facilitates the composition process. SWift is aimed\nat helping to break down the \"electronic\" barriers that keep the deaf community\naway from Information and Communication Technology (ICT). The editor has been\ndeveloped modularly and can be integrated everywhere the use of SW, as an\nalternative to written vocal language, may be advisable.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 12:54:58 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Bianchini", "Claudia S.", "", "Poitiers UFR LL"], ["Borgia", "Fabrizio", "", "UPS"], ["Bottoni", "Paolo", ""], ["de Marsico", "Maria", ""]]}, {"id": "1911.10924", "submitter": "Sileye Ba", "authors": "Sileye 0. Ba", "title": "Discovering topics with neural topic models built from PLSA assumptions", "comments": "10 pages, 7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a model for unsupervised topic discovery in texts\ncorpora. The proposed model uses documents, words, and topics lookup table\nembedding as neural network model parameters to build probabilities of words\ngiven topics, and probabilities of topics given documents. These probabilities\nare used to recover by marginalization probabilities of words given documents.\nFor very large corpora where the number of documents can be in the order of\nbillions, using a neural auto-encoder based document embedding is more scalable\nthen using a lookup table embedding as classically done. We thus extended the\nlookup based document embedding model to continuous auto-encoder based model.\nOur models are trained using probabilistic latent semantic analysis (PLSA)\nassumptions. We evaluated our models on six datasets with a rich variety of\ncontents. Conducted experiments demonstrate that the proposed neural topic\nmodels are very effective in capturing relevant topics. Furthermore,\nconsidering perplexity metric, conducted evaluation benchmarks show that our\ntopic models outperform latent Dirichlet allocation (LDA) model which is\nclassically used to address topic discovery tasks.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 13:59:05 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Ba", "Sileye 0.", ""]]}, {"id": "1911.10953", "submitter": "Amir Karami", "authors": "Amir Karami, Aryya Gangopadhyay, Bin Zhou, Hadi Kharrazi", "title": "FLATM: A Fuzzy Logic Approach Topic Model for Medical Documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the challenges for text analysis in medical domains is analyzing\nlarge-scale medical documents. As a consequence, finding relevant documents has\nbecome more difficult. One of the popular methods to retrieve information based\non discovering the themes in the documents is topic modeling. The themes in the\ndocuments help to retrieve documents on the same topic with and without a\nquery. In this paper, we present a novel approach to topic modeling using fuzzy\nclustering. To evaluate our model, we experiment with two text datasets of\nmedical documents. The evaluation metrics carried out through document\nclassification and document modeling show that our model produces better\nperformance than LDA, indicating that fuzzy set theory can improve the\nperformance of topic models in medical domains.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 14:55:11 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Karami", "Amir", ""], ["Gangopadhyay", "Aryya", ""], ["Zhou", "Bin", ""], ["Kharrazi", "Hadi", ""]]}, {"id": "1911.11008", "submitter": "Jeonghyeok Park", "authors": "Jeonghyeok Park and Hai Zhao", "title": "Korean-to-Chinese Machine Translation using Chinese Character as Pivot\n  Clue", "comments": "9 pages", "journal-ref": "33rd Pacific Asia Conference on Language, Information and\n  Computation (PACLIC 33), pages 558-566, Hakodate, Japan, September 13-15,\n  2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Korean-Chinese is a low resource language pair, but Korean and Chinese have a\nlot in common in terms of vocabulary. Sino-Korean words, which can be converted\ninto corresponding Chinese characters, account for more than fifty of the\nentire Korean vocabulary. Motivated by this, we propose a simple linguistically\nmotivated solution to improve the performance of the Korean-to-Chinese neural\nmachine translation model by using their common vocabulary. We adopt Chinese\ncharacters as a translation pivot by converting Sino-Korean words in Korean\nsentences to Chinese characters and then train the machine translation model\nwith the converted Korean sentences as source sentences. The experimental\nresults on Korean-to-Chinese translation demonstrate that the models with the\nproposed method improve translation quality up to 1.5 BLEU points in comparison\nto the baseline models.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 15:55:56 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Park", "Jeonghyeok", ""], ["Zhao", "Hai", ""]]}, {"id": "1911.11025", "submitter": "Kory W Mathewson", "authors": "Lana Cuthbertson, Alex Kearney, Riley Dawson, Ashia Zawaduk, Eve\n  Cuthbertson, Ann Gordon-Tighe, Kory W Mathewson", "title": "Women, politics and Twitter: Using machine learning to change the\n  discourse", "comments": "8 pages, 2 figures. Presented at the NeurIPS Joint Workshop on AI for\n  Social Good at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Including diverse voices in political decision-making strengthens our\ndemocratic institutions. Within the Canadian political system, there is gender\ninequality across all levels of elected government. Online abuse, such as\nhateful tweets, leveled at women engaged in politics contributes to this\ninequity, particularly tweets focusing on their gender. In this paper, we\npresent ParityBOT: a Twitter bot which counters abusive tweets aimed at women\nin politics by sending supportive tweets about influential female leaders and\nfacts about women in public life. ParityBOT is the first artificial\nintelligence-based intervention aimed at affecting online discourse for women\nin politics for the better. The goal of this project is to: $1$) raise\nawareness of issues relating to gender inequity in politics, and $2$)\npositively influence public discourse in politics. The main contribution of\nthis paper is a scalable model to classify and respond to hateful tweets with\nquantitative and qualitative assessments. The ParityBOT abusive classification\nsystem was validated on public online harassment datasets. We conclude with\nanalysis of the impact of ParityBOT, drawing from data gathered during\ninterventions in both the $2019$ Alberta provincial and $2019$ Canadian federal\nelections.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 16:15:42 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Cuthbertson", "Lana", ""], ["Kearney", "Alex", ""], ["Dawson", "Riley", ""], ["Zawaduk", "Ashia", ""], ["Cuthbertson", "Eve", ""], ["Gordon-Tighe", "Ann", ""], ["Mathewson", "Kory W", ""]]}, {"id": "1911.11062", "submitter": "Md Saiful Islam", "authors": "Arnab Sen Sharma, Maruf Ahmed Mridul, Md Saiful Islam", "title": "Automatic Detection of Satire in Bangla Documents: A CNN Approach Based\n  on Hybrid Feature Extraction Model", "comments": "5 pages, Conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Widespread of satirical news in online communities is an ongoing trend. The\nnature of satires is so inherently ambiguous that sometimes it's too hard even\nfor humans to understand whether it's actually satire or not. So, research\ninterest has grown in this field. The purpose of this research is to detect\nBangla satirical news spread in online news portals as well as social media. In\nthis paper, we propose a hybrid technique for extracting features from text\ndocuments combining Word2Vec and TF-IDF. Using our proposed feature extraction\ntechnique, with standard CNN architecture we could detect whether a Bangla text\ndocument is satire or not with an accuracy of more than 96%.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 20:37:03 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Sharma", "Arnab Sen", ""], ["Mridul", "Maruf Ahmed", ""], ["Islam", "Md Saiful", ""]]}, {"id": "1911.11065", "submitter": "Siamak Shakeri", "authors": "Siamak Shakeri, Abhinav Sethy, Cheng Cheng", "title": "Knowledge Distillation in Document Retrieval", "comments": "Published at Amazon Machine Learning Conference(AMLC) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex deep learning models now achieve state of the art performance for\nmany document retrieval tasks. The best models process the query or claim\njointly with the document. However for fast scalable search it is desirable to\nhave document embeddings which are independent of the claim. In this paper we\nshow that knowledge distillation can be used to encourage a model that\ngenerates claim independent document encodings to mimic the behavior of a more\ncomplex model which generates claim dependent encodings. We explore this\napproach in document retrieval for a fact extraction and verification task. We\nshow that by using the soft labels from a complex cross attention teacher\nmodel, the performance of claim independent student LSTM or CNN models is\nimproved across all the ranking metrics. The student models we use are 12x\nfaster in runtime and 20x smaller in number of parameters than the teacher\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 21:02:54 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Shakeri", "Siamak", ""], ["Sethy", "Abhinav", ""], ["Cheng", "Cheng", ""]]}, {"id": "1911.11069", "submitter": "Arthi Krishna", "authors": "Arthi Krishna, Ye Jin, Christine Foster, Greg Gabel, Britt Hanley and\n  Abdou Youssef", "title": "Query Expansion for Patent Searching using Word Embedding and\n  Professional Crowdsourcing", "comments": "Presented at AAAI FSS-19: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The patent examination process includes a search of previous work to verify\nthat a patent application describes a novel invention. Patent examiners\nprimarily use keyword-based searches to uncover prior art. A critical part of\nkeyword searching is query expansion, which is the process of including\nalternate terms such as synonyms and other related words, since the same\nconcepts are often described differently in the literature. Patent terminology\nis often domain specific. By curating technology-specific corpora and training\nword embedding models based on these corpora, we are able to automatically\nidentify the most relevant expansions of a given word or phrase. We compare the\nperformance of several automated query expansion techniques against expert\nspecified expansions. Furthermore, we explore a novel mechanism to extract\nrelated terms not just based on one input term but several terms in conjunction\nby computing their centroid and identifying the nearest neighbors to this\ncentroid. Highly skilled patent examiners are often the best and most reliable\nsource of identifying related terms. By designing a user interface that allows\nexaminers to interact with the word embedding suggestions, we are able to use\nthese interactions to power crowdsourced modes of related terms. Learning from\nusers allows us to overcome several challenges such as identifying words that\nare bleeding edge and have not been published in the corpus yet. This paper\nstudies the effectiveness of word embedding and crowdsourced models across 11\ndisparate technical areas.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 22:34:02 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Krishna", "Arthi", ""], ["Jin", "Ye", ""], ["Foster", "Christine", ""], ["Gabel", "Greg", ""], ["Hanley", "Britt", ""], ["Youssef", "Abdou", ""]]}, {"id": "1911.11139", "submitter": "Amin Omidvar", "authors": "Amin Omidvar, Hossein Poormodheji, Aijun An, Gordon Edall", "title": "Learning to Determine the Quality of News Headlines", "comments": "10 Pages, Accepted at the 12th International Conference on Agents and\n  Artificial Intelligence (ICAART) 2020", "journal-ref": null, "doi": "10.5220/0009367504010409", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, most newsreaders read the online version of news articles rather than\ntraditional paper-based newspapers. Also, news media publishers rely heavily on\nthe income generated from subscriptions and website visits made by newsreaders.\nThus, online user engagement is a very important issue for online newspapers.\nMuch effort has been spent on writing interesting headlines to catch the\nattention of online users. On the other hand, headlines should not be\nmisleading (e.g., clickbaits); otherwise, readers would be disappointed when\nreading the content. In this paper, we propose four indicators to determine the\nquality of published news headlines based on their click count and dwell time,\nwhich are obtained by website log analysis. Then, we use soft target\ndistribution of the calculated quality indicators to train our proposed deep\nlearning model which can predict the quality of unpublished news headlines. The\nproposed model not only processes the latent features of both headline and body\nof the article to predict its headline quality but also considers the semantic\nrelation between headline and body as well. To evaluate our model, we use a\nreal dataset from a major Canadian newspaper. Results show our proposed model\noutperforms other state-of-the-art NLP models.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 00:09:30 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 23:42:19 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Omidvar", "Amin", ""], ["Poormodheji", "Hossein", ""], ["An", "Aijun", ""], ["Edall", "Gordon", ""]]}, {"id": "1911.11161", "submitter": "Sashank Santhanam", "authors": "Sashank Santhanam, Samira Shaikh", "title": "Emotional Neural Language Generation Grounded in Situational Contexts", "comments": "Oral Presentation at CCNLG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Emotional language generation is one of the keys to human-like artificial\nintelligence. Humans use different type of emotions depending on the situation\nof the conversation. Emotions also play an important role in mediating the\nengagement level with conversational partners. However, current conversational\nagents do not effectively account for emotional content in the language\ngeneration process. To address this problem, we develop a language modeling\napproach that generates affective content when the dialogue is situated in a\ngiven context. We use the recently released Empathetic-Dialogues corpus to\nbuild our models. Through detailed experiments, we find that our approach\noutperforms the state-of-the-art method on the perplexity metric by about 5\npoints and achieves a higher BLEU metric score.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 19:01:36 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Santhanam", "Sashank", ""], ["Shaikh", "Samira", ""]]}, {"id": "1911.11214", "submitter": "Naeemul Hassan", "authors": "Sima Bhowmik, Md Main Uddin Rony, Md Mahfuzul Haque, Kristen Alley\n  Swain, Naeemul Hassan", "title": "Examining the Role of Clickbait Headlines to Engage Readers with\n  Reliable Health-related Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clickbait headlines are frequently used to attract readers to read articles.\nAlthough this headline type has turned out to be a technique to engage readers\nwith misleading items, it is still unknown whether the technique can be used to\nattract readers to reliable pieces. This study takes the opportunity to test\nits efficacy to engage readers with reliable health articles. A set of online\nsurveys would be conducted to test readers' engagement with and perception\nabout clickbait headlines with reliable articles. After that, we would design\nan automation system to generate clickabit headlines to maximize user\nengagement.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 20:29:01 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Bhowmik", "Sima", ""], ["Rony", "Md Main Uddin", ""], ["Haque", "Md Mahfuzul", ""], ["Swain", "Kristen Alley", ""], ["Hassan", "Naeemul", ""]]}, {"id": "1911.11237", "submitter": "Didac Suris Coll-Vinent", "authors": "D\\'idac Sur\\'is, Dave Epstein, Heng Ji, Shih-Fu Chang, Carl Vondrick", "title": "Learning to Learn Words from Visual Scenes", "comments": "26 pages, 12 figures", "journal-ref": "European Conference on Computer Vision (ECCV), 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language acquisition is the process of learning words from the surrounding\nscene. We introduce a meta-learning framework that learns how to learn word\nrepresentations from unconstrained scenes. We leverage the natural\ncompositional structure of language to create training episodes that cause a\nmeta-learner to learn strong policies for language acquisition. Experiments on\ntwo datasets show that our approach is able to more rapidly acquire novel words\nas well as more robustly generalize to unseen compositions, significantly\noutperforming established baselines. A key advantage of our approach is that it\nis data efficient, allowing representations to be learned from scratch without\nlanguage pre-training. Visualizations and analysis suggest visual information\nhelps our approach learn a rich cross-modal representation from minimal\nexamples. Project webpage is available at https://expert.cs.columbia.edu/\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 21:19:31 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 21:19:04 GMT"}, {"version": "v3", "created": "Sun, 12 Jul 2020 21:19:49 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Sur\u00eds", "D\u00eddac", ""], ["Epstein", "Dave", ""], ["Ji", "Heng", ""], ["Chang", "Shih-Fu", ""], ["Vondrick", "Carl", ""]]}, {"id": "1911.11298", "submitter": "Chuxu Zhang", "authors": "Chuxu Zhang, Huaxiu Yao, Chao Huang, Meng Jiang, Zhenhui Li, Nitesh V.\n  Chawla", "title": "Few-Shot Knowledge Graph Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs (KGs) serve as useful resources for various natural language\nprocessing applications. Previous KG completion approaches require a large\nnumber of training instances (i.e., head-tail entity pairs) for every relation.\nThe real case is that for most of the relations, very few entity pairs are\navailable. Existing work of one-shot learning limits method generalizability\nfor few-shot scenarios and does not fully use the supervisory information;\nhowever, few-shot KG completion has not been well studied yet. In this work, we\npropose a novel few-shot relation learning model (FSRL) that aims at\ndiscovering facts of new relations with few-shot references. FSRL can\neffectively capture knowledge from heterogeneous graph structure, aggregate\nrepresentations of few-shot references, and match similar entity pairs of\nreference set for every relation. Extensive experiments on two public datasets\ndemonstrate that FSRL outperforms the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 01:01:37 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Zhang", "Chuxu", ""], ["Yao", "Huaxiu", ""], ["Huang", "Chao", ""], ["Jiang", "Meng", ""], ["Li", "Zhenhui", ""], ["Chawla", "Nitesh V.", ""]]}, {"id": "1911.11324", "submitter": "Xiaoyi Zhang", "authors": "Xiaoyi Zhang, Rodoniki Athanasiadou, Narges Razavian", "title": "Tracing State-Level Obesity Prevalence from Sentence Embeddings of\n  Tweets: A Feasibility Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twitter data has been shown broadly applicable for public health\nsurveillance. Previous public health studies based on Twitter data have largely\nrelied on keyword-matching or topic models for clustering relevant tweets.\nHowever, both methods suffer from the short-length of texts and unpredictable\nnoise that naturally occurs in user-generated contexts. In response, we\nintroduce a deep learning approach that uses hashtags as a form of supervision\nand learns tweet embeddings for extracting informative textual features. In\nthis case study, we address the specific task of estimating state-level obesity\nfrom dietary-related textual features. Our approach yields an estimation that\nstrongly correlates the textual features to government data and outperforms the\nkeyword-matching baseline. The results also demonstrate the potential of\ndiscovering risk factors using the textual features. This method is\ngeneral-purpose and can be applied to a wide range of Twitter-based public\nhealth studies.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 03:57:15 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 21:30:29 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Zhang", "Xiaoyi", ""], ["Athanasiadou", "Rodoniki", ""], ["Razavian", "Narges", ""]]}, {"id": "1911.11358", "submitter": "Saurav Manchanda", "authors": "Saurav Manchanda and George Karypis", "title": "CAWA: An Attention-Network for Credit Attribution", "comments": "To appear in AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Credit attribution is the task of associating individual parts in a document\nwith their most appropriate class labels. It is an important task with\napplications to information retrieval and text summarization. When labeled\ntraining data is available, traditional approaches for sequence tagging can be\nused for credit attribution. However, generating such labeled datasets is\nexpensive and time-consuming. In this paper, we present \"Credit Attribution\nWith Attention (CAWA)\", a neural-network-based approach, that instead of using\nsentence-level labeled data, uses the set of class labels that are associated\nwith an entire document as a source of distant-supervision. CAWA combines an\nattention mechanism with a multilabel classifier into an end-to-end learning\nframework to perform credit attribution. CAWA labels the individual sentences\nfrom the input document using the resultant attention-weights. CAWA improves\nupon the state-of-the-art credit attribution approach by not constraining a\nsentence to belong to just one class, but modeling each sentence as a\ndistribution over all classes, leading to better modeling of\nsemantically-similar classes. Experiments on the credit attribution task on a\nvariety of datasets show that the sentence class labels generated by CAWA\noutperform the competing approaches. Additionally, on the multilabel text\nclassification task, CAWA performs better than the competing credit attribution\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 06:02:33 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Manchanda", "Saurav", ""], ["Karypis", "George", ""]]}, {"id": "1911.11365", "submitter": "Yi Lin", "authors": "Bo Yang, Xianlong Tan, Zhengmao Chen, Bing Wang, Dan Li, Zhongping\n  Yang, Xiping Wu, Yi Lin", "title": "ATCSpeech: a multilingual pilot-controller speech corpus from real Air\n  Traffic Control environment", "comments": null, "journal-ref": null, "doi": "10.21437/Interspeech.2020-1020", "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic Speech Recognition (ASR) is greatly developed in recent years,\nwhich expedites many applications on other fields. For the ASR research, speech\ncorpus is always an essential foundation, especially for the vertical industry,\nsuch as Air Traffic Control (ATC). There are some speech corpora for common\napplications, public or paid. However, for the ATC, it is difficult to collect\nraw speeches from real systems due to safety issues. More importantly, for a\nsupervised learning task like ASR, annotating the transcription is a more\nlaborious work, which hugely restricts the prospect of ASR application. In this\npaper, a multilingual speech corpus (ATCSpeech) from real ATC systems,\nincluding accented Mandarin Chinese and English, is built and released to\nencourage the non-commercial ASR research in ATC domain. The corpus is detailly\nintroduced from the perspective of data amount, speaker gender and role, speech\nquality and other attributions. In addition, the performance of our baseline\nASR models is also reported. A community edition for our speech database can be\napplied and used under a special contrast. To our best knowledge, this is the\nfirst work that aims at building a real and multilingual ASR corpus for the air\ntraffic related research.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 06:35:08 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Yang", "Bo", ""], ["Tan", "Xianlong", ""], ["Chen", "Zhengmao", ""], ["Wang", "Bing", ""], ["Li", "Dan", ""], ["Yang", "Zhongping", ""], ["Wu", "Xiping", ""], ["Lin", "Yi", ""]]}, {"id": "1911.11403", "submitter": "Preslav Nakov", "authors": "Preslav Nakov, Llu\\'is M\\`arquez, Walid Magdy, Alessandro Moschitti,\n  James Glass, Bilal Randeree", "title": "SemEval-2015 Task 3: Answer Selection in Community Question Answering", "comments": "community question answering, answer selection, English, Arabic", "journal-ref": "SemEval-2015", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community Question Answering (cQA) provides new interesting research\ndirections to the traditional Question Answering (QA) field, e.g., the\nexploitation of the interaction between users and the structure of related\nposts. In this context, we organized SemEval-2015 Task 3 on \"Answer Selection\nin cQA\", which included two subtasks: (a) classifying answers as \"good\", \"bad\",\nor \"potentially relevant\" with respect to the question, and (b) answering a\nYES/NO question with \"yes\", \"no\", or \"unsure\", based on the list of all\nanswers. We set subtask A for Arabic and English on two relatively different\ncQA domains, i.e., the Qatar Living website for English, and a Quran-related\nwebsite for Arabic. We used crowdsourcing on Amazon Mechanical Turk to label a\nlarge English training dataset, which we released to the research community.\nThirteen teams participated in the challenge with a total of 61 submissions: 24\nprimary and 37 contrastive. The best systems achieved an official score\n(macro-averaged F1) of 57.19 and 63.7 for the English subtasks A and B, and\n78.55 for the Arabic subtask A.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 08:40:49 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Nakov", "Preslav", ""], ["M\u00e0rquez", "Llu\u00eds", ""], ["Magdy", "Walid", ""], ["Moschitti", "Alessandro", ""], ["Glass", "James", ""], ["Randeree", "Bilal", ""]]}, {"id": "1911.11404", "submitter": "Sashank Santhanam", "authors": "Vidhushini Srinivasan, Sashank Santhanam, Samira Shaikh", "title": "Natural Language Generation Using Reinforcement Learning with External\n  Rewards", "comments": "Oral Presentation at ICMLA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose an approach towards natural language generation using a\nbidirectional encoder-decoder which incorporates external rewards through\nreinforcement learning (RL). We use attention mechanism and maximum mutual\ninformation as an initial objective function using RL. Using a two-part\ntraining scheme, we train an external reward analyzer to predict the external\nrewards and then use the predicted rewards to maximize the expected rewards\n(both internal and external). We evaluate the system on two standard dialogue\ncorpora - Cornell Movie Dialog Corpus and Yelp Restaurant Review Corpus. We\nreport standard evaluation metrics including BLEU, ROUGE-L, and perplexity as\nwell as human evaluation to validate our approach.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 08:46:11 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Srinivasan", "Vidhushini", ""], ["Santhanam", "Sashank", ""], ["Shaikh", "Samira", ""]]}, {"id": "1911.11408", "submitter": "Avishai Gretz", "authors": "Shai Gretz, Roni Friedman, Edo Cohen-Karlik, Assaf Toledo, Dan Lahav,\n  Ranit Aharonov and Noam Slonim", "title": "A Large-scale Dataset for Argument Quality Ranking: Construction and\n  Analysis", "comments": "Accepted to AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying the quality of free-text arguments has become an important task\nin the rapidly expanding field of computational argumentation. In this work, we\nexplore the challenging task of argument quality ranking. To this end, we\ncreated a corpus of 30,497 arguments carefully annotated for point-wise\nquality, released as part of this work. To the best of our knowledge, this is\nthe largest dataset annotated for point-wise argument quality, larger by a\nfactor of five than previously released datasets. Moreover, we address the core\nissue of inducing a labeled score from crowd annotations by performing a\ncomprehensive evaluation of different approaches to this problem. In addition,\nwe analyze the quality dimensions that characterize this dataset. Finally, we\npresent a neural method for argument quality ranking, which outperforms several\nbaselines on our own dataset, as well as previous methods published for another\ndataset.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 08:53:12 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Gretz", "Shai", ""], ["Friedman", "Roni", ""], ["Cohen-Karlik", "Edo", ""], ["Toledo", "Assaf", ""], ["Lahav", "Dan", ""], ["Aharonov", "Ranit", ""], ["Slonim", "Noam", ""]]}, {"id": "1911.11423", "submitter": "Stephen Merity", "authors": "Stephen Merity", "title": "Single Headed Attention RNN: Stop Thinking With Your Head", "comments": "Addition of citations and contextual results (no attention head,\n  single attention head, attention per layer), removal of wordpiece\n  WikiText-103 numbers due to normalization issues, fix of SHA attention figure\n  Q arrow, other minor fixes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The leading approaches in language modeling are all obsessed with TV shows of\nmy youth - namely Transformers and Sesame Street. Transformers this,\nTransformers that, and over here a bonfire worth of GPU-TPU-neuromorphic wafer\nscale silicon. We opt for the lazy path of old and proven techniques with a\nfancy crypto inspired acronym: the Single Headed Attention RNN (SHA-RNN). The\nauthor's lone goal is to show that the entire field might have evolved a\ndifferent direction if we had instead been obsessed with a slightly different\nacronym and slightly different result. We take a previously strong language\nmodel based only on boring LSTMs and get it to within a stone's throw of a\nstone's throw of state-of-the-art byte level language model results on enwik8.\nThis work has undergone no intensive hyperparameter optimization and lived\nentirely on a commodity desktop machine that made the author's small studio\napartment far too warm in the midst of a San Franciscan summer. The final\nresults are achievable in plus or minus 24 hours on a single GPU as the author\nis impatient. The attention mechanism is also readily extended to large\ncontexts with minimal computation. Take that Sesame Street.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 09:45:33 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 12:00:15 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Merity", "Stephen", ""]]}, {"id": "1911.11489", "submitter": "Xin Li", "authors": "Xin Li, Piji Li, Wei Bi, Xiaojiang Liu, Wai Lam", "title": "Relevance-Promoting Language Model for Short-Text Conversation", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the effectiveness of sequence-to-sequence framework on the task of\nShort-Text Conversation (STC), the issue of under-exploitation of training data\n(i.e., the supervision signals from query text is \\textit{ignored}) still\nremains unresolved. Also, the adopted \\textit{maximization}-based decoding\nstrategies, inclined to generating the generic responses or responses with\nrepetition, are unsuited to the STC task. In this paper, we propose to\nformulate the STC task as a language modeling problem and tailor-make a\ntraining strategy to adapt a language model for response generation. To enhance\ngeneration performance, we design a relevance-promoting transformer language\nmodel, which performs additional supervised source attention after the\nself-attention to increase the importance of informative query tokens in\ncalculating the token-level representation. The model further refines the query\nrepresentation with relevance clues inferred from its multiple references\nduring training. In testing, we adopt a\n\\textit{randomization-over-maximization} strategy to reduce the generation of\ngeneric responses. Experimental results on a large Chinese STC dataset\ndemonstrate the superiority of the proposed model on relevance metrics and\ndiversity metrics.\\footnote{Code available at\nhttps://ai.tencent.com/ailab/nlp/dialogue/.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 12:17:59 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Li", "Xin", ""], ["Li", "Piji", ""], ["Bi", "Wei", ""], ["Liu", "Xiaojiang", ""], ["Lam", "Wai", ""]]}, {"id": "1911.11493", "submitter": "Yuan Ye", "authors": "Yuan Ye, Yansong Feng, Bingfeng Luo, Yuxuan Lai, Dongyan Zhao", "title": "Integrating Relation Constraints with Neural Relation Extractors", "comments": "Accepted to AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen rapid progress in identifying predefined relationship\nbetween entity pairs using neural networks NNs. However, such models often make\npredictions for each entity pair individually, thus often fail to solve the\ninconsistency among different predictions, which can be characterized by\ndiscrete relation constraints. These constraints are often defined over\ncombinations of entity-relation-entity triples, since there often lack of\nexplicitly well-defined type and cardinality requirements for the relations. In\nthis paper, we propose a unified framework to integrate relation constraints\nwith NNs by introducing a new loss term, ConstraintLoss. Particularly, we\ndevelop two efficient methods to capture how well the local predictions from\nmultiple instance pairs satisfy the relation constraints. Experiments on both\nEnglish and Chinese datasets show that our approach can help NNs learn from\ndiscrete relation constraints to reduce inconsistency among local predictions,\nand outperform popular neural relation extraction NRE models even enhanced with\nextra post-processing. Our source code and datasets will be released at\nhttps://github.com/PKUYeYuan/Constraint-Loss-AAAI-2020.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 12:29:19 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Ye", "Yuan", ""], ["Feng", "Yansong", ""], ["Luo", "Bingfeng", ""], ["Lai", "Yuxuan", ""], ["Zhao", "Dongyan", ""]]}, {"id": "1911.11503", "submitter": "Preslav Nakov", "authors": "Georgi Georgiev, Valentin Zhikov, Petya Osenova, Kiril Simov, Preslav\n  Nakov", "title": "Feature-Rich Part-of-speech Tagging for Morphologically Complex\n  Languages: Application to Bulgarian", "comments": "part-of-speech tagging, POS tagging, morpho-syntactic tags, guided\n  learning, Bulgarian, Slavic", "journal-ref": "EACL-2012", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present experiments with part-of-speech tagging for Bulgarian, a Slavic\nlanguage with rich inflectional and derivational morphology. Unlike most\nprevious work, which has used a small number of grammatical categories, we work\nwith 680 morpho-syntactic tags. We combine a large morphological lexicon with\nprior linguistic knowledge and guided learning from a POS-annotated corpus,\nachieving accuracy of 97.98%, which is a significant improvement over the\nstate-of-the-art for Bulgarian.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 13:05:33 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Georgiev", "Georgi", ""], ["Zhikov", "Valentin", ""], ["Osenova", "Petya", ""], ["Simov", "Kiril", ""], ["Nakov", "Preslav", ""]]}, {"id": "1911.11506", "submitter": "Alejandro Moreo Fern\\'andez", "authors": "Alejandro Moreo, Andrea Esuli, Fabrizio Sebastiani", "title": "Word-Class Embeddings for Multiclass Text Classification", "comments": null, "journal-ref": "Data Mining and Knowledge Discovery, 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained word embeddings encode general word semantics and lexical\nregularities of natural language, and have proven useful across many NLP tasks,\nincluding word sense disambiguation, machine translation, and sentiment\nanalysis, to name a few. In supervised tasks such as multiclass text\nclassification (the focus of this article) it seems appealing to enhance word\nrepresentations with ad-hoc embeddings that encode task-specific information.\nWe propose (supervised) word-class embeddings (WCEs), and show that, when\nconcatenated to (unsupervised) pre-trained word embeddings, they substantially\nfacilitate the training of deep-learning models in multiclass classification by\ntopic. We show empirical evidence that WCEs yield a consistent improvement in\nmulticlass classification accuracy, using four popular neural architectures and\nsix widely used and publicly available datasets for multiclass text\nclassification. Our code that implements WCEs is publicly available at\nhttps://github.com/AlexMoreo/word-class-embeddings\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 13:11:00 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Moreo", "Alejandro", ""], ["Esuli", "Andrea", ""], ["Sebastiani", "Fabrizio", ""]]}, {"id": "1911.11520", "submitter": "Jiacheng Zhang", "authors": "Jiacheng Zhang, Huanbo Luan, Maosong Sun, FeiFei Zhai, Jingfang Xu,\n  Yang Liu", "title": "Neural Machine Translation with Explicit Phrase Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural machine translation (NMT) has achieved state-of-the-art\ntranslation performance, it is unable to capture the alignment between the\ninput and output during the translation process. The lack of alignment in NMT\nmodels leads to three problems: it is hard to (1) interpret the translation\nprocess, (2) impose lexical constraints, and (3) impose structural constraints.\nTo alleviate these problems, we propose to introduce explicit phrase alignment\ninto the translation process of arbitrary NMT models. The key idea is to build\na search space similar to that of phrase-based statistical machine translation\nfor NMT where phrase alignment is readily available. We design a new decoding\nalgorithm that can easily impose lexical and structural constraints.\nExperiments show that our approach makes the translation process of NMT more\ninterpretable without sacrificing translation quality. In addition, our\napproach achieves significant improvements in lexically and structurally\nconstrained translation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 13:28:59 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 02:41:51 GMT"}, {"version": "v3", "created": "Thu, 28 Nov 2019 14:28:24 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Zhang", "Jiacheng", ""], ["Luan", "Huanbo", ""], ["Sun", "Maosong", ""], ["Zhai", "FeiFei", ""], ["Xu", "Jingfang", ""], ["Liu", "Yang", ""]]}, {"id": "1911.11522", "submitter": "Sven Buechel", "authors": "Sven Buechel, Simon Junker, Thore Schlaak, Claus Michelsen, and Udo\n  Hahn", "title": "A Time Series Analysis of Emotional Loading in Central Bank Statements", "comments": "Published at ECONLP 2019", "journal-ref": "Proceedings of the Second Workshop on Economics and Natural\n  Language Processing @ EMNLP 2019, Hong Kong, November 4, 2019, pages 16-21", "doi": "10.18653/v1/D19-5103", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the affective content of central bank press statements using\nemotion analysis. Our focus is on two major international players, the European\nCentral Bank (ECB) and the US Federal Reserve Bank (Fed), covering a time span\nfrom 1998 through 2019. We reveal characteristic patterns in the emotional\ndimensions of valence, arousal, and dominance and find---despite the commonly\nestablished attitude that emotional wording in central bank communication\nshould be avoided---a correlation between the state of the economy and\nparticularly the dominance dimension in the press releases under scrutiny and,\noverall, an impact of the president in office.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 13:31:08 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Buechel", "Sven", ""], ["Junker", "Simon", ""], ["Schlaak", "Thore", ""], ["Michelsen", "Claus", ""], ["Hahn", "Udo", ""]]}, {"id": "1911.11547", "submitter": "Dat Quoc Nguyen", "authors": "Dai Quoc Nguyen, Dat Quoc Nguyen, Son Bao Pham", "title": "A Vietnamese Text-Based Conversational Agent", "comments": "In Proceedings of the 25th International Conference on Industrial,\n  Engineering & Other Applications of Applied Intelligent Systems (IEA/AIE\n  2012)", "journal-ref": null, "doi": "10.1007/978-3-642-31087-4_71", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a Vietnamese text-based conversational agent\narchitecture on specific knowledge domain which is integrated in a question\nanswering system. When the question answering system fails to provide answers\nto users' input, our conversational agent can step in to interact with users to\nprovide answers to users. Experimental results are promising where our\nVietnamese text-based conversational agent achieves positive feedback in a\nstudy conducted in the university academic regulation domain.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 14:11:50 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Nguyen", "Dai Quoc", ""], ["Nguyen", "Dat Quoc", ""], ["Pham", "Son Bao", ""]]}, {"id": "1911.11558", "submitter": "Shouman Das", "authors": "Rupam Acharyya, Shouman Das, Ankani Chattoraj, Md. Iftekhar Tanveer", "title": "FairyTED: A Fair Rating Predictor for TED Talk Data", "comments": "9 pages, 4 figures, 3 tables. Accepted as a conference paper to be\n  presented at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent trend of applying machine learning in every aspect of human\nlife, it is important to incorporate fairness into the core of the predictive\nalgorithms. We address the problem of predicting the quality of public speeches\nwhile being fair with respect to sensitive attributes of the speakers, e.g.\ngender and race. We use the TED talks as an input repository of public speeches\nbecause it consists of speakers from a diverse community and has a wide\noutreach. Utilizing the theories of Causal Models, Counterfactual Fairness and\nstate-of-the-art neural language models, we propose a mathematical framework\nfor fair prediction of the public speaking quality. We employ grounded\nassumptions to construct a causal model capturing how different attributes\naffect public speaking quality. This causal model contributes in generating\ncounterfactual data to train a fair predictive model. Our framework is general\nenough to utilize any assumption within the causal model. Experimental results\nshow that while prediction accuracy is comparable to recent work on this\ndataset, our predictions are counterfactually fair with respect to a novel\nmetric when compared to true data labels. The FairyTED setup not only allows\norganizers to make informed and diverse selection of speakers from the\nunobserved counterfactual possibilities but it also ensures that viewers and\nnew users are not influenced by unfair and unbalanced ratings from arbitrary\nvisitors to the www.ted.com website when deciding to view a talk.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 09:55:52 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Acharyya", "Rupam", ""], ["Das", "Shouman", ""], ["Chattoraj", "Ankani", ""], ["Tanveer", "Md. Iftekhar", ""]]}, {"id": "1911.11641", "submitter": "Yonatan Bisk", "authors": "Yonatan Bisk, Rowan Zellers, Ronan Le Bras, Jianfeng Gao, Yejin Choi", "title": "PIQA: Reasoning about Physical Commonsense in Natural Language", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To apply eyeshadow without a brush, should I use a cotton swab or a\ntoothpick? Questions requiring this kind of physical commonsense pose a\nchallenge to today's natural language understanding systems. While recent\npretrained models (such as BERT) have made progress on question answering over\nmore abstract domains - such as news articles and encyclopedia entries, where\ntext is plentiful - in more physical domains, text is inherently limited due to\nreporting bias. Can AI systems learn to reliably answer physical common-sense\nquestions without experiencing the physical world? In this paper, we introduce\nthe task of physical commonsense reasoning and a corresponding benchmark\ndataset Physical Interaction: Question Answering or PIQA. Though humans find\nthe dataset easy (95% accuracy), large pretrained models struggle (77%). We\nprovide analysis about the dimensions of knowledge that existing models lack,\nwhich offers significant opportunities for future research.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 15:31:46 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Bisk", "Yonatan", ""], ["Zellers", "Rowan", ""], ["Bras", "Ronan Le", ""], ["Gao", "Jianfeng", ""], ["Choi", "Yejin", ""]]}, {"id": "1911.11657", "submitter": "Gokul S Krishnan", "authors": "Gokul S Krishnan and Sowmya Kamath S", "title": "Hybrid Text Feature Modeling for Disease Group Prediction using\n  Unstructured Physician Notes", "comments": "Submitted to the International Conference on Computational Science\n  (ICCS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing Clinical Decision Support Systems (CDSSs) largely depend on the\navailability of structured patient data and Electronic Health Records (EHRs) to\naid caregivers. However, in case of hospitals in developing countries,\nstructured patient data formats are not widely adopted, where medical\nprofessionals still rely on clinical notes in the form of unstructured text.\nSuch unstructured clinical notes recorded by medical personnel can also be a\npotential source of rich patient-specific information which can be leveraged to\nbuild CDSSs, even for hospitals in developing countries. If such unstructured\nclinical text can be used, the manual and time-consuming process of EHR\ngeneration will no longer be required, with huge person-hours and cost savings.\nIn this paper, we propose a generic ICD9 disease group prediction CDSS built on\nunstructured physician notes modeled using hybrid word embeddings. These word\nembeddings are used to train a deep neural network for effectively predicting\nICD9 disease groups. Experimental evaluation showed that the proposed approach\noutperformed the state-of-the-art disease group prediction model built on\nstructured EHRs by 15% in terms of AUROC and 40% in terms of AUPRC, thus\nproving our hypothesis and eliminating dependency on availability of structured\npatient data.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 15:55:39 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Krishnan", "Gokul S", ""], ["S", "Sowmya Kamath", ""]]}, {"id": "1911.11668", "submitter": "Travis LaCroix", "authors": "Travis LaCroix", "title": "Biology and Compositionality: Empirical Considerations for\n  Emergent-Communication Protocols", "comments": "Accepted for NeurIPS 2019 workshop Emergent Communication: Towards\n  Natural Language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significant advances have been made in artificial systems by using biological\nsystems as a guide. However, there is often little interaction between\ncomputational models for emergent communication and biological models of the\nemergence of language. Many researchers in language origins and emergent\ncommunication take compositionality as their primary target for explaining how\nsimple communication systems can become more like natural language. However,\nthere is reason to think that compositionality is the wrong target on the\nbiological side, and so too the wrong target on the machine-learning side. As\nsuch, the purpose of this paper is to explore this claim. This has theoretical\nimplications for language origins research more generally, but the focus here\nwill be the implications for research on emergent communication in computer\nscience and machine learning---specifically regarding the types of programmes\nthat might be expected to work and those which will not. I further suggest an\nalternative approach for future research which focuses on reflexivity, rather\nthan compositionality, as a target for explaining how simple communication\nsystems may become more like natural language. I end by providing some\nreference to the language origins literature that may be of some use to\nresearchers in machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 16:07:44 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 19:36:13 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["LaCroix", "Travis", ""]]}, {"id": "1911.11672", "submitter": "Bo-Hsiang (Andy) Tseng", "authors": "Bo-Hsiang Tseng, Marek Rei, Pawe{\\l} Budzianowski, Richard E. Turner,\n  Bill Byrne, Anna Korhonen", "title": "Semi-supervised Bootstrapping of Dialogue State Trackers for Task\n  Oriented Modelling", "comments": "This article is published at EMNLP-IJCNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue systems benefit greatly from optimizing on detailed annotations,\nsuch as transcribed utterances, internal dialogue state representations and\ndialogue act labels. However, collecting these annotations is expensive and\ntime-consuming, holding back development in the area of dialogue modelling. In\nthis paper, we investigate semi-supervised learning methods that are able to\nreduce the amount of required intermediate labelling. We find that by\nleveraging un-annotated data instead, the amount of turn-level annotations of\ndialogue state can be significantly reduced when building a neural dialogue\nsystem. Our analysis on the MultiWOZ corpus, covering a range of domains and\ntopics, finds that annotations can be reduced by up to 30\\% while maintaining\nequivalent system performance. We also describe and evaluate the first\nend-to-end dialogue model created for the MultiWOZ corpus.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 16:12:36 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Tseng", "Bo-Hsiang", ""], ["Rei", "Marek", ""], ["Budzianowski", "Pawe\u0142", ""], ["Turner", "Richard E.", ""], ["Byrne", "Bill", ""], ["Korhonen", "Anna", ""]]}, {"id": "1911.11698", "submitter": "Emeric Dynomant", "authors": "Emeric Dynomant, St\\'efan J. Darmoni, \\'Emeline Lejeune, Ga\\\"etan\n  Kerdelhu\\'e, Jean-Philippe Leroy, Vincent Lequertier, St\\'ephane Canu, Julien\n  Grosjean", "title": "Doc2Vec on the PubMed corpus: study of a new approach to generate\n  related articles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PubMed is the biggest and most used bibliographic database worldwide, hosting\nmore than 26M biomedical publications. One of its useful features is the\n\"similar articles\" section, allowing the end-user to find scientific articles\nlinked to the consulted document in term of context. The aim of this study is\nto analyze whether it is possible to replace the statistic model PubMed Related\nArticles (pmra) with a document embedding method. Doc2Vec algorithm was used to\ntrain models allowing to vectorize documents. Six of its parameters were\noptimised by following a grid-search strategy to train more than 1,900 models.\nParameters combination leading to the best accuracy was used to train models on\nabstracts from the PubMed database. Four evaluations tasks were defined to\ndetermine what does or does not influence the proximity between documents for\nboth Doc2Vec and pmra. The two different Doc2Vec architectures have different\nabilities to link documents about a common context. The terminological\nindexing, words and stems contents of linked documents are highly similar\nbetween pmra and Doc2Vec PV-DBOW architecture. These algorithms are also more\nlikely to bring closer documents having a similar size. In contrary, the manual\nevaluation shows much better results for the pmra algorithm. While the pmra\nalgorithm links documents by explicitly using terminological indexing in its\nformula, Doc2Vec does not need a prior indexing. It can infer relations between\ndocuments sharing a similar indexing, without any knowledge about them,\nparticularly regarding the PV-DBOW architecture. In contrary, the human\nevaluation, without any clear agreement between evaluators, implies future\nstudies to better understand this difference between PV-DBOW and pmra\nalgorithm.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 17:06:02 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Dynomant", "Emeric", ""], ["Darmoni", "St\u00e9fan J.", ""], ["Lejeune", "\u00c9meline", ""], ["Kerdelhu\u00e9", "Ga\u00ebtan", ""], ["Leroy", "Jean-Philippe", ""], ["Lequertier", "Vincent", ""], ["Canu", "St\u00e9phane", ""], ["Grosjean", "Julien", ""]]}, {"id": "1911.11744", "submitter": "Simon Stepputtis", "authors": "Simon Stepputtis, Joseph Campbell, Mariano Phielipp, Chitta Baral,\n  Heni Ben Amor", "title": "Imitation Learning of Robot Policies by Combining Language, Vision and\n  Demonstration", "comments": "Accepted to the NeurIPS 2019 Workshop on Robot Learning: Control and\n  Interaction in the Real World, Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a novel end-to-end imitation learning approach which\ncombines natural language, vision, and motion information to produce an\nabstract representation of a task, which in turn is used to synthesize specific\nmotion controllers at run-time. This multimodal approach enables generalization\nto a wide variety of environmental conditions and allows an end-user to direct\na robot policy through verbal communication. We empirically validate our\napproach with an extensive set of simulations and show that it achieves a high\ntask success rate over a variety of conditions while remaining amenable to\nprobabilistic interpretability.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:27:51 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Stepputtis", "Simon", ""], ["Campbell", "Joseph", ""], ["Phielipp", "Mariano", ""], ["Baral", "Chitta", ""], ["Amor", "Heni Ben", ""]]}, {"id": "1911.11750", "submitter": "Nino Arsov", "authors": "Nino Arsov, Milan Dukovski, Blagoja Evkoski, Stefan Cvetkovski", "title": "A Measure of Similarity in Textual Data Using Spearman's Rank\n  Correlation Coefficient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, many diverse advances have occurred in the field of\ninformation extraction from data. Information extraction in its simplest form\ntakes place in computing environments, where structured data can be extracted\nthrough a series of queries. The continuous expansion of quantities of data\nhave therefore provided an opportunity for knowledge extraction (KE) from a\ntextual document (TD). A typical problem of this kind is the extraction of\ncommon characteristics and knowledge from a group of TDs, with the possibility\nto group such similar TDs in a process known as clustering. In this paper we\npresent a technique for such KE among a group of TDs related to the common\ncharacteristics and meaning of their content. Our technique is based on the\nSpearman's Rank Correlation Coefficient (SRCC), for which the conducted\nexperiments have proven to be comprehensive measure to achieve a high-quality\nKE.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:38:59 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Arsov", "Nino", ""], ["Dukovski", "Milan", ""], ["Evkoski", "Blagoja", ""], ["Cvetkovski", "Stefan", ""]]}, {"id": "1911.11756", "submitter": "Alexander Hanbo Li", "authors": "Alexander Hanbo Li, Abhinav Sethy", "title": "Semi-Supervised Learning for Text Classification by Layer Partitioning", "comments": "ASRU 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most recent neural semi-supervised learning algorithms rely on adding small\nperturbation to either the input vectors or their representations. These\nmethods have been successful on computer vision tasks as the images form a\ncontinuous manifold, but are not appropriate for discrete input such as\nsentence. To adapt these methods to text input, we propose to decompose a\nneural network $M$ into two components $F$ and $U$ so that $M = U\\circ F$. The\nlayers in $F$ are then frozen and only the layers in $U$ will be updated during\nmost time of the training. In this way, $F$ serves as a feature extractor that\nmaps the input to high-level representation and adds systematical noise using\ndropout. We can then train $U$ using any state-of-the-art SSL algorithms such\nas $\\Pi$-model, temporal ensembling, mean teacher, etc. Furthermore, this\ngradually unfreezing schedule also prevents a pretrained model from\ncatastrophic forgetting. The experimental results demonstrate that our approach\nprovides improvements when compared to state of the art methods especially on\nshort texts.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:47:48 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Li", "Alexander Hanbo", ""], ["Sethy", "Abhinav", ""]]}, {"id": "1911.11899", "submitter": "Yang Li", "authors": "Yang Li, Guodong Long, Tao Shen, Tianyi Zhou, Lina Yao, Huan Huo, Jing\n  Jiang", "title": "Self-Attention Enhanced Selective Gate with Entity-Aware Embedding for\n  Distantly Supervised Relation Extraction", "comments": "Accepted to appear at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distantly supervised relation extraction intrinsically suffers from noisy\nlabels due to the strong assumption of distant supervision. Most prior works\nadopt a selective attention mechanism over sentences in a bag to denoise from\nwrongly labeled data, which however could be incompetent when there is only one\nsentence in a bag. In this paper, we propose a brand-new light-weight neural\nframework to address the distantly supervised relation extraction problem and\nalleviate the defects in previous selective attention framework. Specifically,\nin the proposed framework, 1) we use an entity-aware word embedding method to\nintegrate both relative position information and head/tail entity embeddings,\naiming to highlight the essence of entities for this task; 2) we develop a\nself-attention mechanism to capture the rich contextual dependencies as a\ncomplement for local dependencies captured by piecewise CNN; and 3) instead of\nusing selective attention, we design a pooling-equipped gate, which is based on\nrich contextual representations, as an aggregator to generate bag-level\nrepresentation for final relation classification. Compared to selective\nattention, one major advantage of the proposed gating mechanism is that, it\nperforms stably and promisingly even if only one sentence appears in a bag and\nthus keeps the consistency across all training examples. The experiments on NYT\ndataset demonstrate that our approach achieves a new state-of-the-art\nperformance in terms of both AUC and top-n precision metrics.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 00:55:12 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Li", "Yang", ""], ["Long", "Guodong", ""], ["Shen", "Tao", ""], ["Zhou", "Tianyi", ""], ["Yao", "Lina", ""], ["Huo", "Huan", ""], ["Jiang", "Jing", ""]]}, {"id": "1911.11926", "submitter": "Filipi Nascimento Silva", "authors": "Filipi Nascimento Silva, Aditya Tandon, Diego Raphael Amancio,\n  Alessandro Flammini, Filippo Menczer, Sta\\v{s}a Milojevi\\'c and Santo\n  Fortunato", "title": "Recency predicts bursts in the evolution of author citations", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": "10.1162/qss_a_00070", "report-no": null, "categories": "cs.DL cs.CL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The citations process for scientific papers has been studied extensively. But\nwhile the citations accrued by authors are the sum of the citations of their\npapers, translating the dynamics of citation accumulation from the paper to the\nauthor level is not trivial. Here we conduct a systematic study of the\nevolution of author citations, and in particular their bursty dynamics. We find\nempirical evidence of a correlation between the number of citations most\nrecently accrued by an author and the number of citations they receive in the\nfuture. Using a simple model where the probability for an author to receive new\ncitations depends only on the number of citations collected in the previous\n12-24 months, we are able to reproduce both the citation and burst size\ndistributions of authors across multiple decades.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 02:52:02 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Silva", "Filipi Nascimento", ""], ["Tandon", "Aditya", ""], ["Amancio", "Diego Raphael", ""], ["Flammini", "Alessandro", ""], ["Menczer", "Filippo", ""], ["Milojevi\u0107", "Sta\u0161a", ""], ["Fortunato", "Santo", ""]]}, {"id": "1911.11931", "submitter": "Xuhui Zhou", "authors": "Xuhui Zhou, Yue Zhang, Leyang Cui, Dandan Huang", "title": "Evaluating Commonsense in Pre-trained Language Models", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextualized representations trained over large raw text data have given\nremarkable improvements for NLP tasks including question answering and reading\ncomprehension. There have been works showing that syntactic, semantic and word\nsense knowledge are contained in such representations, which explains why they\nbenefit such tasks. However, relatively little work has been done investigating\ncommonsense knowledge contained in contextualized representations, which is\ncrucial for human question answering and reading comprehension. We study the\ncommonsense ability of GPT, BERT, XLNet, and RoBERTa by testing them on seven\nchallenging benchmarks, finding that language modeling and its variants are\neffective objectives for promoting models' commonsense ability while\nbi-directional context and larger training set are bonuses. We additionally\nfind that current models do poorly on tasks require more necessary inference\nsteps. Finally, we test the robustness of models by making dual test cases,\nwhich are correlated so that the correct prediction of one sample should lead\nto correct prediction of the other. Interestingly, the models show confusion on\nthese test cases, which suggests that they learn commonsense at the surface\nrather than the deep level. We release a test set, named CATs publicly, for\nfuture research.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 03:22:40 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 05:14:52 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Zhou", "Xuhui", ""], ["Zhang", "Yue", ""], ["Cui", "Leyang", ""], ["Huang", "Dandan", ""]]}, {"id": "1911.11933", "submitter": "Katsuki Chousa", "authors": "Katsuki Chousa, Katsuhito Sudoh, Satoshi Nakamura", "title": "Simultaneous Neural Machine Translation using Connectionist Temporal\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneous machine translation is a variant of machine translation that\nstarts the translation process before the end of an input. This task faces a\ntrade-off between translation accuracy and latency. We have to determine when\nwe start the translation for observed inputs so far, to achieve good practical\nperformance. In this work, we propose a neural machine translation method to\ndetermine this timing in an adaptive manner. The proposed method introduces a\nspecial token '<wait>', which is generated when the translation model chooses\nto read the next input token instead of generating an output token. It also\nintroduces an objective function to handle the ambiguity in wait timings that\ncan be optimized using an algorithm called Connectionist Temporal\nClassification (CTC). The use of CTC enables the optimization to consider all\npossible output sequences including '<wait>' that are equivalent to the\nreference translations and to choose the best one adaptively. We apply the\nproposed method into simultaneous translation from English to Japanese and\ninvestigate its performance and remaining problems.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 03:38:36 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Chousa", "Katsuki", ""], ["Sudoh", "Katsuhito", ""], ["Nakamura", "Satoshi", ""]]}, {"id": "1911.11935", "submitter": "Yi-Chen Chen", "authors": "Yi-Chen Chen, Zhaojun Yang, Ching-Feng Yeh, Mahaveer Jain, Michael L.\n  Seltzer", "title": "AIPNet: Generative Adversarial Pre-training of Accent-invariant Networks\n  for End-to-end Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one of the major sources in speech variability, accents have posed a grand\nchallenge to the robustness of speech recognition systems. In this paper, our\ngoal is to build a unified end-to-end speech recognition system that\ngeneralizes well across accents. For this purpose, we propose a novel\npre-training framework AIPNet based on generative adversarial nets (GAN) for\naccent-invariant representation learning: Accent Invariant Pre-training\nNetworks. We pre-train AIPNet to disentangle accent-invariant and\naccent-specific characteristics from acoustic features through adversarial\ntraining on accented data for which transcriptions are not necessarily\navailable. We further fine-tune AIPNet by connecting the accent-invariant\nmodule with an attention-based encoder-decoder model for multi-accent speech\nrecognition. In the experiments, our approach is compared against four\nbaselines including both accent-dependent and accent-independent models.\nExperimental results on 9 English accents show that the proposed approach\noutperforms all the baselines by 2.3 \\sim 4.5% relative reduction on average\nWER when transcriptions are available in all accents and by 1.6 \\sim 6.1%\nrelative reduction when transcriptions are only available in US accent.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 03:42:21 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Chen", "Yi-Chen", ""], ["Yang", "Zhaojun", ""], ["Yeh", "Ching-Feng", ""], ["Jain", "Mahaveer", ""], ["Seltzer", "Michael L.", ""]]}, {"id": "1911.11951", "submitter": "Chris Dulhanty", "authors": "Chris Dulhanty, Jason L. Deglint, Ibrahim Ben Daya and Alexander Wong", "title": "Taking a Stance on Fake News: Towards Automatic Disinformation\n  Assessment via Deep Bidirectional Transformer Language Models for Stance\n  Detection", "comments": "Accepted to the AI for Social Good Workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exponential rise of social media and digital news in the past decade has\nhad the unfortunate consequence of escalating what the United Nations has\ncalled a global topic of concern: the growing prevalence of disinformation.\nGiven the complexity and time-consuming nature of combating disinformation\nthrough human assessment, one is motivated to explore harnessing AI solutions\nto automatically assess news articles for the presence of disinformation. A\nvaluable first step towards automatic identification of disinformation is\nstance detection, where given a claim and a news article, the aim is to predict\nif the article agrees, disagrees, takes no position, or is unrelated to the\nclaim. Existing approaches in literature have largely relied on hand-engineered\nfeatures or shallow learned representations (e.g., word embeddings) to encode\nthe claim-article pairs, which can limit the level of representational\nexpressiveness needed to tackle the high complexity of disinformation\nidentification. In this work, we explore the notion of harnessing large-scale\ndeep bidirectional transformer language models for encoding claim-article pairs\nin an effort to construct state-of-the-art stance detection geared for\nidentifying disinformation. Taking advantage of bidirectional cross-attention\nbetween claim-article pairs via pair encoding with self-attention, we construct\na large-scale language model for stance detection by performing transfer\nlearning on a RoBERTa deep bidirectional transformer language model, and were\nable to achieve state-of-the-art performance (weighted accuracy of 90.01%) on\nthe Fake News Challenge Stage 1 (FNC-I) benchmark. These promising results\nserve as motivation for harnessing such large-scale language models as powerful\nbuilding blocks for creating effective AI solutions to combat disinformation.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 04:52:53 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Dulhanty", "Chris", ""], ["Deglint", "Jason L.", ""], ["Daya", "Ibrahim Ben", ""], ["Wong", "Alexander", ""]]}, {"id": "1911.11952", "submitter": "Siamak Shakeri", "authors": "Siamak Shakeri, Abhinav Sethy", "title": "Label Dependent Deep Variational Paraphrase Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating paraphrases that are lexically similar but semantically different\nis a challenging task. Paraphrases of this form can be used to augment data\nsets for various NLP tasks such as machine reading comprehension and question\nanswering with non-trivial negative examples. In this article, we propose a\ndeep variational model to generate paraphrases conditioned on a label that\nspecifies whether the paraphrases are semantically related or not. We also\npresent new training recipes and KL regularization techniques that improve the\nperformance of variational paraphrasing models. Our proposed model demonstrates\npromising results in enhancing the generative power of the model by employing\nlabel-dependent generation on paraphrasing datasets.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 04:54:14 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Shakeri", "Siamak", ""], ["Sethy", "Abhinav", ""]]}, {"id": "1911.12011", "submitter": "Haoxi Zhong", "authors": "Haoxi Zhong, Chaojun Xiao, Cunchao Tu, Tianyang Zhang, Zhiyuan Liu,\n  Maosong Sun", "title": "JEC-QA: A Legal-Domain Question Answering Dataset", "comments": "9 pages, 2 figures, 10 tables, accepted by AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present JEC-QA, the largest question answering dataset in the legal\ndomain, collected from the National Judicial Examination of China. The\nexamination is a comprehensive evaluation of professional skills for legal\npractitioners. College students are required to pass the examination to be\ncertified as a lawyer or a judge. The dataset is challenging for existing\nquestion answering methods, because both retrieving relevant materials and\nanswering questions require the ability of logic reasoning. Due to the high\ndemand of multiple reasoning abilities to answer legal questions, the\nstate-of-the-art models can only achieve about 28% accuracy on JEC-QA, while\nskilled humans and unskilled humans can reach 81% and 64% accuracy\nrespectively, which indicates a huge gap between humans and machines on this\ntask. We will release JEC-QA and our baselines to help improve the reasoning\nability of machine comprehension models. You can access the dataset from\nhttp://jecqa.thunlp.org/.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 08:13:27 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Zhong", "Haoxi", ""], ["Xiao", "Chaojun", ""], ["Tu", "Cunchao", ""], ["Zhang", "Tianyang", ""], ["Liu", "Zhiyuan", ""], ["Sun", "Maosong", ""]]}, {"id": "1911.12014", "submitter": "Yi Cheng", "authors": "Yi Cheng, Sujian Li", "title": "Zero-shot Chinese Discourse Dependency Parsing via Cross-lingual Mapping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the absence of labeled data, discourse parsing still remains\nchallenging in some languages. In this paper, we present a simple and efficient\nmethod to conduct zero-shot Chinese text-level dependency parsing by leveraging\nEnglish discourse labeled data and parsing techniques. We first construct the\nChinese-English mapping from the level of sentence and elementary discourse\nunit (EDU), and then exploit the parsing results of the corresponding English\ntranslations to obtain the discourse trees for the Chinese text. This method\ncan automatically conduct Chinese discourse parsing, with no need of a large\nscale of Chinese labeled data.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 08:17:45 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Cheng", "Yi", ""], ["Li", "Sujian", ""]]}, {"id": "1911.12019", "submitter": "Yo Joong Choe", "authors": "Yo Joong Choe, Kyubyong Park, Dongwoo Kim", "title": "word2word: A Collection of Bilingual Lexicons for 3,564 Language Pairs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present word2word, a publicly available dataset and an open-source Python\npackage for cross-lingual word translations extracted from sentence-level\nparallel corpora. Our dataset provides top-k word translations in 3,564\n(directed) language pairs across 62 languages in OpenSubtitles2018 (Lison et\nal., 2018). To obtain this dataset, we use a count-based bilingual lexicon\nextraction model based on the observation that not only source and target words\nbut also source words themselves can be highly correlated. We illustrate that\nthe resulting bilingual lexicons have high coverage and attain competitive\ntranslation quality for several language pairs. We wrap our dataset and model\nin an easy-to-use Python library, which supports downloading and retrieving\ntop-k word translations in any of the supported language pairs as well as\ncomputing top-k word translations for custom parallel corpora.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 08:37:32 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Choe", "Yo Joong", ""], ["Park", "Kyubyong", ""], ["Kim", "Dongwoo", ""]]}, {"id": "1911.12022", "submitter": "Raphael Cohen", "authors": "Raphael Cohen and Michael Elhadad", "title": "Sideways Transliteration: How to Transliterate Multicultural Person\n  Names?", "comments": "Rejected from a bunch of conferences - but submitted due to popular\n  demand", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In a global setting, texts contain transliterated names from many cultural\norigins. Correct transliteration depends not only on target and source\nlanguages but also, on the source language of the name. We introduce a novel\nmethodology for transliteration of names originating in different languages\nusing only monolingual resources. Our method is based on a step of noisy\ntransliteration and then ranking of the results based on origin specific letter\nmodels. The transliteration table used for noisy generation is learned in an\nunsupervised manner for each possible origin language. We present a solution\nfor gathering monolingual training data used by our method by mining of social\nmedia sites such as Facebook and Wikipedia. We present results in the context\nof transliterating from English to Hebrew and provide an online web service for\ntransliteration from English to Hebrew\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 08:38:57 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Cohen", "Raphael", ""], ["Elhadad", "Michael", ""]]}, {"id": "1911.12071", "submitter": "Yo Joong Choe", "authors": "Kyubyong Park, Yo Joong Choe, Jiyeon Ham", "title": "Jejueo Datasets for Machine Translation and Speech Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Jejueo was classified as critically endangered by UNESCO in 2010. Although\ndiverse efforts to revitalize it have been made, there have been few\ncomputational approaches. Motivated by this, we construct two new Jejueo\ndatasets: Jejueo Interview Transcripts (JIT) and Jejueo Single Speaker Speech\n(JSS). The JIT dataset is a parallel corpus containing 170k+ Jejueo-Korean\nsentences, and the JSS dataset consists of 10k high-quality audio files\nrecorded by a native Jejueo speaker and a transcript file. Subsequently, we\nbuild neural systems of machine translation and speech synthesis using them.\nAll resources are publicly available via our GitHub repository. We hope that\nthese datasets will attract interest of both language and machine learning\ncommunities.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 10:43:20 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Park", "Kyubyong", ""], ["Choe", "Yo Joong", ""], ["Ham", "Jiyeon", ""]]}, {"id": "1911.12085", "submitter": "Preslav Nakov", "authors": "Su Nam Kim, Preslav Nakov", "title": "Large-Scale Noun Compound Interpretation Using Bootstrapping and the Web\n  as a Corpus", "comments": "noun compounds, paraphrasing verbs, paraphrases, semantic\n  interpretation, bootstrapping, semi-supervised learning", "journal-ref": "EMNLP-2011", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Responding to the need for semantic lexical resources in natural language\nprocessing applications, we examine methods to acquire noun compounds (NCs),\ne.g., \"orange juice\", together with suitable fine-grained semantic\ninterpretations, e.g., \"squeezed from\", which are directly usable as\nparaphrases. We employ bootstrapping and web statistics, and utilize the\nrelationship between NCs and paraphrasing patterns to jointly extract NCs and\nsuch patterns in multiple alternating iterations. In evaluation, we found that\nhaving one compound noun fixed yields both a higher number of semantically\ninterpreted NCs and improved accuracy due to stronger semantic restrictions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 11:25:43 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Kim", "Su Nam", ""], ["Nakov", "Preslav", ""]]}, {"id": "1911.12091", "submitter": "Preslav Nakov", "authors": "Liane Guillou, Christian Hardmeier, Preslav Nakov, Sara Stymne, J\\\"org\n  Tiedemann, Yannick Versley, Mauro Cettolo, Bonnie Webber, Andrei\n  Popescu-Belis", "title": "Findings of the 2016 WMT Shared Task on Cross-lingual Pronoun Prediction", "comments": "cross-lingual pronoun prediction, WMT, shared task, English, German,\n  French", "journal-ref": "WMT-2016", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the design, the evaluation setup, and the results of the 2016 WMT\nshared task on cross-lingual pronoun prediction. This is a classification task\nin which participants are asked to provide predictions on what pronoun class\nlabel should replace a placeholder value in the target-language text, provided\nin lemmatised and PoS-tagged form. We provided four subtasks, for the\nEnglish-French and English-German language pairs, in both directions. Eleven\nteams participated in the shared task; nine for the English-French subtask,\nfive for French-English, nine for English-German, and six for German-English.\nMost of the submissions outperformed two strong language-model based baseline\nsystems, with systems using deep recurrent neural networks outperforming those\nusing other architectures for most language pairs.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 11:45:15 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Guillou", "Liane", ""], ["Hardmeier", "Christian", ""], ["Nakov", "Preslav", ""], ["Stymne", "Sara", ""], ["Tiedemann", "J\u00f6rg", ""], ["Versley", "Yannick", ""], ["Cettolo", "Mauro", ""], ["Webber", "Bonnie", ""], ["Popescu-Belis", "Andrei", ""]]}, {"id": "1911.12146", "submitter": "Erik Velldal", "authors": "Fredrik J{\\o}rgensen, Tobias Aasmoe, Anne-Stine Ruud Husev{\\aa}g,\n  Lilja {\\O}vrelid, Erik Velldal", "title": "NorNE: Annotating Named Entities for Norwegian", "comments": "Accepted for LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents NorNE, a manually annotated corpus of named entities\nwhich extends the annotation of the existing Norwegian Dependency Treebank.\nComprising both of the official standards of written Norwegian (Bokm{\\aa}l and\nNynorsk), the corpus contains around 600,000 tokens and annotates a rich set of\nentity types including persons, organizations, locations, geo-political\nentities, products, and events, in addition to a class corresponding to\nnominals derived from names. We here present details on the annotation effort,\nguidelines, inter-annotator agreement and an experimental analysis of the\ncorpus using a neural sequence labeling architecture.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 13:30:36 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 09:38:01 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["J\u00f8rgensen", "Fredrik", ""], ["Aasmoe", "Tobias", ""], ["Husev\u00e5g", "Anne-Stine Ruud", ""], ["\u00d8vrelid", "Lilja", ""], ["Velldal", "Erik", ""]]}, {"id": "1911.12237", "submitter": "Iwona Mochol", "authors": "Bogdan Gliwa, Iwona Mochol, Maciej Biesek, Aleksander Wawer", "title": "SAMSum Corpus: A Human-annotated Dialogue Dataset for Abstractive\n  Summarization", "comments": "Attachment contains the described dataset archived in 7z format.\n  Please see the attached readme and licence. Update of the previous version:\n  changed formats of train/val/test files in corpus.7z", "journal-ref": "Proceedings of the 2nd Workshop on New Frontiers in Summarization,\n  Association for Computational Linguistics. November 2019", "doi": "10.18653/v1/D19-5409", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the SAMSum Corpus, a new dataset with abstractive\ndialogue summaries. We investigate the challenges it poses for automated\nsummarization by testing several models and comparing their results with those\nobtained on a corpus of news articles. We show that model-generated summaries\nof dialogues achieve higher ROUGE scores than the model-generated summaries of\nnews -- in contrast with human evaluators' judgement. This suggests that a\nchallenging task of abstractive dialogue summarization requires dedicated\nmodels and non-standard quality measures. To our knowledge, our study is the\nfirst attempt to introduce a high-quality chat-dialogues corpus, manually\nannotated with abstractive summarizations, which can be used by the research\ncommunity for further studies.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 15:54:55 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 09:55:22 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Gliwa", "Bogdan", ""], ["Mochol", "Iwona", ""], ["Biesek", "Maciej", ""], ["Wawer", "Aleksander", ""]]}, {"id": "1911.12246", "submitter": "Phu Mon Htut", "authors": "Phu Mon Htut, Jason Phang, Shikha Bordia, Samuel R. Bowman", "title": "Do Attention Heads in BERT Track Syntactic Dependencies?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the extent to which individual attention heads in pretrained\ntransformer language models, such as BERT and RoBERTa, implicitly capture\nsyntactic dependency relations. We employ two methods---taking the maximum\nattention weight and computing the maximum spanning tree---to extract implicit\ndependency relations from the attention weights of each layer/head, and compare\nthem to the ground-truth Universal Dependency (UD) trees. We show that, for\nsome UD relation types, there exist heads that can recover the dependency type\nsignificantly better than baselines on parsed English text, suggesting that\nsome self-attention heads act as a proxy for syntactic structure. We also\nanalyze BERT fine-tuned on two datasets---the syntax-oriented CoLA and the\nsemantics-oriented MNLI---to investigate whether fine-tuning affects the\npatterns of their self-attention, but we do not observe substantial differences\nin the overall dependency relations extracted using our methods. Our results\nsuggest that these models have some specialist attention heads that track\nindividual dependency types, but no generalist head that performs holistic\nparsing significantly better than a trivial baseline, and that analyzing\nattention weights directly may not reveal much of the syntactic knowledge that\nBERT-style models are known to learn.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 16:09:11 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Htut", "Phu Mon", ""], ["Phang", "Jason", ""], ["Bordia", "Shikha", ""], ["Bowman", "Samuel R.", ""]]}, {"id": "1911.12267", "submitter": "Dat Quoc Nguyen", "authors": "Dai Quoc Nguyen, Dat Quoc Nguyen, Son Bao Pham", "title": "A Vietnamese Question Answering System", "comments": "In Proceedings of the 2009 International Conference on Knowledge and\n  Systems Engineering (KSE 2009). arXiv admin note: substantial text overlap\n  with arXiv:1412.4160", "journal-ref": null, "doi": "10.1109/KSE.2009.42", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering systems aim to produce exact answers to users' questions\ninstead of a list of related documents as used by current search engines. In\nthis paper, we propose an ontology-based Vietnamese question answering system\nthat allows users to express their questions in natural language. To the best\nof our knowledge, this is the first attempt to enable users to query an\nontological knowledge base using Vietnamese natural language. Experiments of\nour system on an organizational ontology show promising results.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 11:44:55 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Nguyen", "Dai Quoc", ""], ["Nguyen", "Dat Quoc", ""], ["Pham", "Son Bao", ""]]}, {"id": "1911.12377", "submitter": "Federico Landi", "authors": "Federico Landi, Lorenzo Baraldi, Marcella Cornia, Massimiliano\n  Corsini, Rita Cucchiara", "title": "Perceive, Transform, and Act: Multi-Modal Attention Networks for\n  Vision-and-Language Navigation", "comments": "A revised version of this paper is currently under consideration at\n  Computer Vision and Image Understanding", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision-and-Language Navigation (VLN) is a challenging task in which an agent\nneeds to follow a language-specified path to reach a target destination. In\nthis paper, we strive for the creation of an agent able to tackle three key\nissues: multi-modality, long-term dependencies, and adaptability towards\ndifferent locomotive settings. To that end, we devise \"Perceive, Transform, and\nAct\" (PTA): a fully-attentive VLN architecture that leaves the recurrent\napproach behind and the first Transformer-like architecture incorporating three\ndifferent modalities - natural language, images, and discrete actions for the\nagent control. In particular, we adopt an early fusion strategy to merge\nlingual and visual information efficiently in our encoder. We then propose to\nrefine the decoding phase with a late fusion extension between the agent's\nhistory of actions and the perception modalities. We experimentally validate\nour model on two datasets and two different action settings. PTA surpasses\nprevious state-of-the-art architectures for low-level VLN on R2R and achieves\nthe first place for both setups in the recently proposed R4R benchmark. Our\ncode is publicly available at\nhttps://github.com/aimagelab/perceive-transform-and-act.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 19:00:24 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 07:30:16 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Landi", "Federico", ""], ["Baraldi", "Lorenzo", ""], ["Cornia", "Marcella", ""], ["Corsini", "Massimiliano", ""], ["Cucchiara", "Rita", ""]]}, {"id": "1911.12385", "submitter": "Sachin Mehta", "authors": "Sachin Mehta and Rik Koncel-Kedziorski and Mohammad Rastegari and\n  Hannaneh Hajishirzi", "title": "DeFINE: DEep Factorized INput Token Embeddings for Neural Sequence\n  Modeling", "comments": "Accepted at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For sequence models with large vocabularies, a majority of network parameters\nlie in the input and output layers. In this work, we describe a new method,\nDeFINE, for learning deep token representations efficiently. Our architecture\nuses a hierarchical structure with novel skip-connections which allows for the\nuse of low dimensional input and output layers, reducing total parameters and\ntraining time while delivering similar or better performance versus existing\nmethods. DeFINE can be incorporated easily in new or existing sequence models.\nCompared to state-of-the-art methods including adaptive input representations,\nthis technique results in a 6% to 20% drop in perplexity. On WikiText-103,\nDeFINE reduces the total parameters of Transformer-XL by half with minimal\nimpact on performance. On the Penn Treebank, DeFINE improves AWD-LSTM by 4\npoints with a 17% reduction in parameters, achieving comparable performance to\nstate-of-the-art methods with fewer parameters. For machine translation, DeFINE\nimproves the efficiency of the Transformer model by about 1.4 times while\ndelivering similar performance.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 19:09:41 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 01:32:06 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Mehta", "Sachin", ""], ["Koncel-Kedziorski", "Rik", ""], ["Rastegari", "Mohammad", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "1911.12391", "submitter": "Huyen Nguyen", "authors": "Huyen Nguyen", "title": "SimpleBooks: Long-term dependency book dataset with simplified English\n  vocabulary for word-level language modeling", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With language modeling becoming the popular base task for unsupervised\nrepresentation learning in Natural Language Processing, it is important to come\nup with new architectures and techniques for faster and better training of\nlanguage models. However, due to a peculiarity of languages -- the larger the\ndataset, the higher the average number of times a word appears in that dataset\n-- datasets of different sizes have very different properties. Architectures\nperforming well on small datasets might not perform well on larger ones. For\nexample, LSTM models perform well on WikiText-2 but poorly on WikiText-103,\nwhile Transformer models perform well on WikiText-103 but not on WikiText-2.\nFor setups like architectural search, this is a challenge since it is\nprohibitively costly to run a search on the full dataset but it is not\nindicative to experiment on smaller ones. In this paper, we introduce\nSimpleBooks, a small dataset with the average word frequency as high as that of\nmuch larger ones. Created from 1,573 Gutenberg books with the highest ratio of\nword-level book length to vocabulary size, SimpleBooks contains 92M word-level\ntokens, on par with WikiText-103 (103M tokens), but has the vocabulary of 98K,\na third of WikiText-103's. SimpleBooks can be downloaded from\nhttps://dldata-public.s3.us-east-2.amazonaws.com/simplebooks.zip.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 19:37:26 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Nguyen", "Huyen", ""]]}, {"id": "1911.12478", "submitter": "Benjamin Nagy", "authors": "Benjamin Nagy", "title": "Metre as a stylometric feature in Latin hexameter poetry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper demonstrates that metre is a privileged indicator of authorial\nstyle in classical Latin hexameter poetry. Using only metrical features,\npairwise classification experiments are performed between 5 first-century\nauthors (10 comparisons) using four different machine-learning models. The\nresults showed a two-label classification accuracy of at least 95% with samples\nas small as ten lines and no greater than eighty lines (up to around 500\nwords). These sample sizes are an order of magnitude smaller than those\ntypically recommended for BOW ('bag of words') or n-gram approaches, and the\nreported accuracy is outstanding. Additionally, this paper explores the\npotential for novelty (forgery) detection, or 'one-class classification'. An\nanalysis of the disputed Aldine Additamentum (Sil. Ital. Puni. 8:144-225)\nconcludes (p=0.0013) that the metrical style differs significantly from that of\nthe rest of the poem.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 01:35:51 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 02:20:28 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Nagy", "Benjamin", ""]]}, {"id": "1911.12487", "submitter": "Chao Weng", "authors": "Chao Weng, Chengzhu Yu, Jia Cui, Chunlei Zhang, Dong Yu", "title": "Minimum Bayes Risk Training of RNN-Transducer for End-to-End Speech\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose minimum Bayes risk (MBR) training of RNN-Transducer\n(RNN-T) for end-to-end speech recognition. Specifically, initialized with a\nRNN-T trained model, MBR training is conducted via minimizing the expected edit\ndistance between the reference label sequence and on-the-fly generated N-best\nhypothesis. We also introduce a heuristic to incorporate an external neural\nnetwork language model (NNLM) in RNN-T beam search decoding and explore MBR\ntraining with the external NNLM. Experimental results demonstrate an MBR\ntrained model outperforms a RNN-T trained model substantially and further\nimprovements can be achieved if trained with an external NNLM. Our best MBR\ntrained system achieves absolute character error rate (CER) reductions of 1.2%\nand 0.5% on read and spontaneous Mandarin speech respectively over a strong\nconvolution and transformer based RNN-T baseline trained on ~21,000 hours of\nspeech.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 02:17:56 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Weng", "Chao", ""], ["Yu", "Chengzhu", ""], ["Cui", "Jia", ""], ["Zhang", "Chunlei", ""], ["Yu", "Dong", ""]]}, {"id": "1911.12543", "submitter": "Zhengbao Jiang", "authors": "Zhengbao Jiang, Frank F. Xu, Jun Araki, Graham Neubig", "title": "How Can We Know What Language Models Know?", "comments": "TACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has presented intriguing results examining the knowledge\ncontained in language models (LM) by having the LM fill in the blanks of\nprompts such as \"Obama is a _ by profession\". These prompts are usually\nmanually created, and quite possibly sub-optimal; another prompt such as \"Obama\nworked as a _\" may result in more accurately predicting the correct profession.\nBecause of this, given an inappropriate prompt, we might fail to retrieve facts\nthat the LM does know, and thus any given prompt only provides a lower bound\nestimate of the knowledge contained in an LM. In this paper, we attempt to more\naccurately estimate the knowledge contained in LMs by automatically discovering\nbetter prompts to use in this querying process. Specifically, we propose\nmining-based and paraphrasing-based methods to automatically generate\nhigh-quality and diverse prompts, as well as ensemble methods to combine\nanswers from different prompts. Extensive experiments on the LAMA benchmark for\nextracting relational knowledge from LMs demonstrate that our methods can\nimprove accuracy from 31.1% to 39.6%, providing a tighter lower bound on what\nLMs know. We have released the code and the resulting LM Prompt And Query\nArchive (LPAQA) at https://github.com/jzbjyb/LPAQA.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 05:55:42 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 20:29:05 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Jiang", "Zhengbao", ""], ["Xu", "Frank F.", ""], ["Araki", "Jun", ""], ["Neubig", "Graham", ""]]}, {"id": "1911.12544", "submitter": "Preslav Nakov", "authors": "Veselin Raychev, Preslav Nakov", "title": "Language-Independent Sentiment Analysis Using Subjectivity and\n  Positional Information", "comments": "sentiment analysis, subjectivity", "journal-ref": "RANLP-2009", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a novel language-independent approach to the task of determining\nthe polarity, positive or negative, of the author's opinion on a specific topic\nin natural language text. In particular, weights are assigned to attributes,\nindividual words or word bi-grams, based on their position and on their\nlikelihood of being subjective. The subjectivity of each attribute is estimated\nin a two-step process, where first the probability of being subjective is\ncalculated for each sentence containing the attribute, and then these\nprobabilities are used to alter the attribute's weights for polarity\nclassification. The evaluation results on a standard dataset of movie reviews\nshows 89.85% classification accuracy, which rivals the best previously\npublished results for this dataset for systems that use no additional\nlinguistic information nor external resources.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 05:55:44 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Raychev", "Veselin", ""], ["Nakov", "Preslav", ""]]}, {"id": "1911.12547", "submitter": "Preslav Nakov", "authors": "Shafiq Joty, Francisco Guzman, Lluis Marquez, Preslav Nakov", "title": "DiscoTK: Using Discourse Structure for Machine Translation Evaluation", "comments": "machine translation evaluation, machine translation, tree kernels,\n  discourse, convolutional kernels, discourse tree, RST, rhetorical structure\n  theory, ASIYA", "journal-ref": "WMT-2014", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present novel automatic metrics for machine translation evaluation that\nuse discourse structure and convolution kernels to compare the discourse tree\nof an automatic translation with that of the human reference. We experiment\nwith five transformations and augmentations of a base discourse tree\nrepresentation based on the rhetorical structure theory, and we combine the\nkernel scores for each of them into a single score. Finally, we add other\nmetrics from the ASIYA MT evaluation toolkit, and we tune the weights of the\ncombination on actual human judgments. Experiments on the WMT12 and WMT13\nmetrics shared task datasets show correlation with human judgments that\noutperforms what the best systems that participated in these years achieved,\nboth at the segment and at the system level.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 06:05:12 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Joty", "Shafiq", ""], ["Guzman", "Francisco", ""], ["Marquez", "Lluis", ""], ["Nakov", "Preslav", ""]]}, {"id": "1911.12556", "submitter": "Wenliang Chen", "authors": "Zhengqiu He and Wenliang Chen and Yuyi Wang and Wei zhang and Guanchun\n  Wang and Min Zhang", "title": "Improving Neural Relation Extraction with Positive and Unlabeled\n  Learning", "comments": "8 pages, AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to improve the performance of distant supervision\nrelation extraction with Positive and Unlabeled (PU) Learning. This approach\nfirst applies reinforcement learning to decide whether a sentence is positive\nto a given relation, and then positive and unlabeled bags are constructed. In\ncontrast to most previous studies, which mainly use selected positive instances\nonly, we make full use of unlabeled instances and propose two new\nrepresentations for positive and unlabeled bags. These two representations are\nthen combined in an appropriate way to make bag-level prediction. Experimental\nresults on a widely used real-world dataset demonstrate that this new approach\nindeed achieves significant and consistent improvements as compared to several\ncompetitive baselines.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 06:53:14 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["He", "Zhengqiu", ""], ["Chen", "Wenliang", ""], ["Wang", "Yuyi", ""], ["zhang", "Wei", ""], ["Wang", "Guanchun", ""], ["Zhang", "Min", ""]]}, {"id": "1911.12559", "submitter": "Florian Boudin", "authors": "Ygor Gallina and Florian Boudin and B\\'eatrice Daille", "title": "KPTimes: A Large-Scale Dataset for Keyphrase Generation on News\n  Documents", "comments": "Accepted at the International Conference on Natural Language\n  Generation (INLG), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Keyphrase generation is the task of predicting a set of lexical units that\nconveys the main content of a source text. Existing datasets for keyphrase\ngeneration are only readily available for the scholarly domain and include\nnon-expert annotations. In this paper we present KPTimes, a large-scale dataset\nof news texts paired with editor-curated keyphrases. Exploring the dataset, we\nshow how editors tag documents, and how their annotations differ from those\nfound in existing datasets. We also train and evaluate state-of-the-art neural\nkeyphrase generation models on KPTimes to gain insights on how well they\nperform on the news domain. The dataset is available online at\nhttps://github.com/ygorg/KPTimes .\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 07:12:30 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Gallina", "Ygor", ""], ["Boudin", "Florian", ""], ["Daille", "B\u00e9atrice", ""]]}, {"id": "1911.12569", "submitter": "Abhishek Kumar", "authors": "Abhishek Kumar, Asif Ekbal, Daisuke Kawahra, Sadao Kurohashi", "title": "Emotion helps Sentiment: A Multi-task Model for Sentiment and Emotion\n  Analysis", "comments": "Accepted in the Proceedings of The 2019 IEEE International Joint\n  Conference on Neural Networks (IJCNN 2019)", "journal-ref": null, "doi": "10.1109/IJCNN.2019.8852352", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a two-layered multi-task attention based neural\nnetwork that performs sentiment analysis through emotion analysis. The proposed\napproach is based on Bidirectional Long Short-Term Memory and uses\nDistributional Thesaurus as a source of external knowledge to improve the\nsentiment and emotion prediction. The proposed system has two levels of\nattention to hierarchically build a meaningful representation. We evaluate our\nsystem on the benchmark dataset of SemEval 2016 Task 6 and also compare it with\nthe state-of-the-art systems on Stance Sentiment Emotion Corpus. Experimental\nresults show that the proposed system improves the performance of sentiment\nanalysis by 3.2 F-score points on SemEval 2016 Task 6 dataset. Our network also\nboosts the performance of emotion analysis by 5 F-score points on Stance\nSentiment Emotion Corpus.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 07:43:04 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Kumar", "Abhishek", ""], ["Ekbal", "Asif", ""], ["Kawahra", "Daisuke", ""], ["Kurohashi", "Sadao", ""]]}, {"id": "1911.12579", "submitter": "Wazir Ali", "authors": "Wazir Ali, Jay Kumar, Junyu Lu, Zenglin Xu", "title": "Word Embedding based New Corpus for Low-resourced Language: Sindhi", "comments": "Body 21 pages, Tables 9, Figures 7", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Representing words and phrases into dense vectors of real numbers which\nencode semantic and syntactic properties is a vital constituent in natural\nlanguage processing (NLP). The success of neural network (NN) models in NLP\nlargely rely on such dense word representations learned on the large unlabeled\ncorpus. Sindhi is one of the rich morphological language, spoken by large\npopulation in Pakistan and India lacks corpora which plays an essential role of\na test-bed for generating word embeddings and developing language independent\nNLP systems. In this paper, a large corpus of more than 61 million words is\ndeveloped for low-resourced Sindhi language for training neural word\nembeddings. The corpus is acquired from multiple web-resources using\nweb-scrappy. Due to the unavailability of open source preprocessing tools for\nSindhi, the prepossessing of such large corpus becomes a challenging problem\nspecially cleaning of noisy data extracted from web resources. Therefore, a\npreprocessing pipeline is employed for the filtration of noisy text.\nAfterwards, the cleaned vocabulary is utilized for training Sindhi word\nembeddings with state-of-the-art GloVe, Skip-Gram (SG), and Continuous Bag of\nWords (CBoW) word2vec algorithms. The intrinsic evaluation approach of cosine\nsimilarity matrix and WordSim-353 are employed for the evaluation of generated\nSindhi word embeddings. Moreover, we compare the proposed word embeddings with\nrecently revealed Sindhi fastText (SdfastText) word representations. Our\nintrinsic evaluation results demonstrate the high quality of our generated\nSindhi word embeddings using SG, CBoW, and GloVe as compare to SdfastText word\nrepresentations.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 08:11:44 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 19:35:19 GMT"}, {"version": "v3", "created": "Wed, 30 Dec 2020 03:50:16 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Ali", "Wazir", ""], ["Kumar", "Jay", ""], ["Lu", "Junyu", ""], ["Xu", "Zenglin", ""]]}, {"id": "1911.12674", "submitter": "Michael G\\\"unther", "authors": "Michael G\\\"unther, Maik Thiele, Wolfgang Lehner", "title": "RETRO: Relation Retrofitting For In-Database Machine Learning on Textual\n  Data", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are massive amounts of textual data residing in databases, valuable for\nmany machine learning (ML) tasks. Since ML techniques depend on numerical input\nrepresentations, word embeddings are increasingly utilized to convert symbolic\nrepresentations such as text into meaningful numbers. However, a naive\none-to-one mapping of each word in a database to a word embedding vector is not\nsufficient and would lead to poor accuracies in ML tasks. Thus, we argue to\nadditionally incorporate the information given by the database schema into the\nembedding, e.g. which words appear in the same column or are related to each\nother. In this paper, we propose RETRO (RElational reTROfitting), a novel\napproach to learn numerical representations of text values in databases,\ncapturing the best of both worlds, the rich information encoded by word\nembeddings and the relational information encoded by database tables. We\nformulate relation retrofitting as a learning problem and present an efficient\nalgorithm solving it. We investigate the impact of various hyperparameters on\nthe learning problem and derive good settings for all of them. Our evaluation\nshows that the proposed embeddings are ready-to-use for many ML tasks such as\nclassification and regression and even outperform state-of-the-art techniques\nin integration tasks such as null value imputation and link prediction.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 12:37:26 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 07:55:38 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["G\u00fcnther", "Michael", ""], ["Thiele", "Maik", ""], ["Lehner", "Wolfgang", ""]]}, {"id": "1911.12722", "submitter": "Erik Velldal", "authors": "Lilja {\\O}vrelid, Petter M{\\ae}hlum, Jeremy Barnes, Erik Velldal", "title": "A Fine-Grained Sentiment Dataset for Norwegian", "comments": "Accepted for LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce NoReC_fine, a dataset for fine-grained sentiment analysis in\nNorwegian, annotated with respect to polar expressions, targets and holders of\nopinion. The underlying texts are taken from a corpus of professionally\nauthored reviews from multiple news-sources and across a wide variety of\ndomains, including literature, games, music, products, movies and more. We here\npresent a detailed description of this annotation effort. We provide an\noverview of the developed annotation guidelines, illustrated with examples, and\npresent an analysis of inter-annotator agreement. We also report the first\nexperimental results on the dataset, intended as a preliminary benchmark for\nfurther experiments.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 14:09:50 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 11:55:25 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["\u00d8vrelid", "Lilja", ""], ["M\u00e6hlum", "Petter", ""], ["Barnes", "Jeremy", ""], ["Velldal", "Erik", ""]]}, {"id": "1911.12753", "submitter": "Jose Camacho-Collados", "authors": "Zied Bouraoui, Jose Camacho-Collados and Steven Schockaert", "title": "Inducing Relational Knowledge from BERT", "comments": "Accepted to AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most remarkable properties of word embeddings is the fact that\nthey capture certain types of semantic and syntactic relationships. Recently,\npre-trained language models such as BERT have achieved groundbreaking results\nacross a wide range of Natural Language Processing tasks. However, it is\nunclear to what extent such models capture relational knowledge beyond what is\nalready captured by standard word embeddings. To explore this question, we\npropose a methodology for distilling relational knowledge from a pre-trained\nlanguage model. Starting from a few seed instances of a given relation, we\nfirst use a large text corpus to find sentences that are likely to express this\nrelation. We then use a subset of these extracted sentences as templates.\nFinally, we fine-tune a language model to predict whether a given word pair is\nlikely to be an instance of some relation, when given an instantiated template\nfor that relation as input.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 15:38:53 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Bouraoui", "Zied", ""], ["Camacho-Collados", "Jose", ""], ["Schockaert", "Steven", ""]]}, {"id": "1911.12760", "submitter": "Vatsal Aggarwal", "authors": "Vatsal Aggarwal, Marius Cotescu, Nishant Prateek, Jaime\n  Lorenzo-Trueba, and Roberto Barra-Chicote", "title": "Using VAEs and Normalizing Flows for One-shot Text-To-Speech Synthesis\n  of Expressive Speech", "comments": "Accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Text-to-Speech method to create an unseen expressive style using\none utterance of expressive speech of around one second. Specifically, we\nenhance the disentanglement capabilities of a state-of-the-art\nsequence-to-sequence based system with a Variational AutoEncoder (VAE) and a\nHouseholder Flow. The proposed system provides a 22% KL-divergence reduction\nwhile jointly improving perceptual metrics over state-of-the-art. At synthesis\ntime we use one example of expressive style as a reference input to the encoder\nfor generating any text in the desired style. Perceptual MUSHRA evaluations\nshow that we can create a voice with a 9% relative naturalness improvement over\nstandard Neural Text-to-Speech, while also improving the perceived emotional\nintensity (59 compared to the 55 of neutral speech).\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 15:57:14 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 13:56:04 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Aggarwal", "Vatsal", ""], ["Cotescu", "Marius", ""], ["Prateek", "Nishant", ""], ["Lorenzo-Trueba", "Jaime", ""], ["Barra-Chicote", "Roberto", ""]]}, {"id": "1911.12798", "submitter": "Umut Sulubacak", "authors": "Umut Sulubacak, Ozan Caglayan, Stig-Arne Gr\\\"onroos, Aku Rouhe,\n  Desmond Elliott, Lucia Specia, J\\\"org Tiedemann", "title": "Multimodal Machine Translation through Visuals and Speech", "comments": "34 pages, 4 tables, 8 figures. Submitted (Nov 2019) to the Machine\n  Translation journal (Springer)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal machine translation involves drawing information from more than\none modality, based on the assumption that the additional modalities will\ncontain useful alternative views of the input data. The most prominent tasks in\nthis area are spoken language translation, image-guided translation, and\nvideo-guided translation, which exploit audio and visual modalities,\nrespectively. These tasks are distinguished from their monolingual counterparts\nof speech recognition, image captioning, and video captioning by the\nrequirement of models to generate outputs in a different language. This survey\nreviews the major data resources for these tasks, the evaluation campaigns\nconcentrated around them, the state of the art in end-to-end and pipeline\napproaches, and also the challenges in performance evaluation. The paper\nconcludes with a discussion of directions for future research in these areas:\nthe need for more expansive and challenging datasets, for targeted evaluations\nof model performance, and for multimodality in both the input and output space.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 17:18:41 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Sulubacak", "Umut", ""], ["Caglayan", "Ozan", ""], ["Gr\u00f6nroos", "Stig-Arne", ""], ["Rouhe", "Aku", ""], ["Elliott", "Desmond", ""], ["Specia", "Lucia", ""], ["Tiedemann", "J\u00f6rg", ""]]}, {"id": "1911.12848", "submitter": "Sonali Rajesh Shah", "authors": "Sonali Rajesh Shah (1) and Abhishek Kaushik (1) ((1) Dublin Business\n  School)", "title": "Sentiment Analysis On Indian Indigenous Languages: A Review On\n  Multilingual Opinion Mining", "comments": null, "journal-ref": null, "doi": "10.20944/preprints201911.0338.v1", "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increase in the use of smartphones has laid to the use of the internet and\nsocial media platforms. The most commonly used social media platforms are\nTwitter, Facebook, WhatsApp and Instagram. People are sharing their personal\nexperiences, reviews, feedbacks on the web. The information which is available\non the web is unstructured and enormous. Hence, there is a huge scope of\nresearch on understanding the sentiment of the data available on the web.\nSentiment Analysis (SA) can be carried out on the reviews, feedbacks,\ndiscussions available on the web. There has been extensive research carried out\non SA in the English language, but data on the web also contains different\nother languages which should be analyzed. This paper aims to analyze, review\nand discuss the approaches, algorithms, challenges faced by the researchers\nwhile carrying out the SA on Indigenous languages.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 20:00:40 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Shah", "Sonali Rajesh", ""], ["Kaushik", "Abhishek", ""]]}, {"id": "1911.12855", "submitter": "Gushu Li", "authors": "Gushu Li, Li Zhou, Nengkun Yu, Yufei Ding, Mingsheng Ying, Yuan Xie", "title": "Proq: Projection-based Runtime Assertions for Debugging on a Quantum\n  Computer", "comments": "A major revision, in submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CL cs.ET quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Proq, a runtime assertion scheme for testing and\ndebugging quantum programs on a quantum computer. The predicates in Proq are\nrepresented by projections (or equivalently, closed subspaces of the state\nspace), following Birkhoff-von Neumann quantum logic. The satisfaction of a\nprojection by a quantum state can be directly checked upon a small number of\nprojective measurements rather than a large number of repeated executions. On\nthe theory side, we rigorously prove that checking projection-based assertions\ncan help locate bugs or statistically assure that the semantic function of the\ntested program is close to what we expect, for both exact and approximate\nquantum programs. On the practice side, we consider hardware constraints and\nintroduce several techniques to transform the assertions, making them directly\nexecutable on the measurement-restricted quantum computers. We also propose to\nachieve simplified assertion implementation using local projection technique\nwith soundness guaranteed. We compare Proq with existing quantum program\nassertions and demonstrate the effectiveness and efficiency of Proq by its\napplications to assert two ingenious quantum algorithms, the\nHarrow-Hassidim-Lloyd algorithm and Shor's algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 20:24:11 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 20:56:55 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Li", "Gushu", ""], ["Zhou", "Li", ""], ["Yu", "Nengkun", ""], ["Ding", "Yufei", ""], ["Ying", "Mingsheng", ""], ["Xie", "Yuan", ""]]}, {"id": "1911.12893", "submitter": "Masato Hagiwara", "authors": "Masato Hagiwara, Masato Mita", "title": "GitHub Typo Corpus: A Large-Scale Multilingual Dataset of Misspellings\n  and Grammatical Errors", "comments": "Submitted at LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of large-scale datasets has been a major hindrance to the\ndevelopment of NLP tasks such as spelling correction and grammatical error\ncorrection (GEC). As a complementary new resource for these tasks, we present\nthe GitHub Typo Corpus, a large-scale, multilingual dataset of misspellings and\ngrammatical errors along with their corrections harvested from GitHub, a large\nand popular platform for hosting and sharing git repositories. The dataset,\nwhich we have made publicly available, contains more than 350k edits and 65M\ncharacters in more than 15 languages, making it the largest dataset of\nmisspellings to date. We also describe our process for filtering true typo\nedits based on learned classifiers on a small annotated subset, and demonstrate\nthat typo edits can be identified with F1 ~ 0.9 using a very simple classifier\nwith only three features. The detailed analyses of the dataset show that\nexisting spelling correctors merely achieve an F-measure of approx. 0.5,\nsuggesting that the dataset serves as a new, rich source of spelling errors\nthat complement existing datasets.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 22:57:45 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Hagiwara", "Masato", ""], ["Mita", "Masato", ""]]}, {"id": "1911.12982", "submitter": "Xuewen Shi", "authors": "Xuewen Shi, Heyan Huang, Ping Jian, Yuhang Guo, Xiaochi Wei, Yi-Kun\n  Tang", "title": "Neural Chinese Word Segmentation as Sequence to Sequence Translation", "comments": "In proceedings of SMP 2017 (Chinese National Conference on Social\n  Media Processing)", "journal-ref": null, "doi": "10.1007/978-981-10-6805-8_8", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, Chinese word segmentation (CWS) methods using neural networks have\nmade impressive progress. Most of them regard the CWS as a sequence labeling\nproblem which construct models based on local features rather than considering\nglobal information of input sequence. In this paper, we cast the CWS as a\nsequence translation problem and propose a novel sequence-to-sequence CWS model\nwith an attention-based encoder-decoder framework. The model captures the\nglobal information from the input and directly outputs the segmented sequence.\nIt can also tackle other NLP tasks with CWS jointly in an end-to-end mode.\nExperiments on Weibo, PKU and MSRA benchmark datasets show that our approach\nhas achieved competitive performances compared with state-of-the-art methods.\nMeanwhile, we successfully applied our proposed model to jointly learning CWS\nand Chinese spelling correction, which demonstrates its applicability of\nmulti-task fusion.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 07:22:01 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Shi", "Xuewen", ""], ["Huang", "Heyan", ""], ["Jian", "Ping", ""], ["Guo", "Yuhang", ""], ["Wei", "Xiaochi", ""], ["Tang", "Yi-Kun", ""]]}, {"id": "1911.12986", "submitter": "Ansong Ni", "authors": "Ansong Ni, Pengcheng Yin, Graham Neubig", "title": "Merging Weak and Active Supervision for Semantic Parsing", "comments": "AAAI 2020 Main Track [Oral] (To appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A semantic parser maps natural language commands (NLs) from the users to\nexecutable meaning representations (MRs), which are later executed in certain\nenvironment to obtain user-desired results. The fully-supervised training of\nsuch parser requires NL/MR pairs, annotated by domain experts, which makes them\nexpensive to collect. However, weakly-supervised semantic parsers are learnt\nonly from pairs of NL and expected execution results, leaving the MRs latent.\nWhile weak supervision is cheaper to acquire, learning from this input poses\ndifficulties. It demands that parsers search a large space with a very weak\nlearning signal and it is hard to avoid spurious MRs that achieve the correct\nanswer in the wrong way. These factors lead to a performance gap between\nparsers trained in weakly- and fully-supervised setting. To bridge this gap, we\nexamine the intersection between weak supervision and active learning, which\nallows the learner to actively select examples and query for manual annotations\nas extra supervision to improve the model trained under weak supervision. We\nstudy different active learning heuristics for selecting examples to query, and\nvarious forms of extra supervision for such queries. We evaluate the\neffectiveness of our method on two different datasets. Experiments on the\nWikiSQL show that by annotating only 1.8% of examples, we improve over a\nstate-of-the-art weakly-supervised baseline by 6.4%, achieving an accuracy of\n79.0%, which is only 1.3% away from the model trained with full supervision.\nExperiments on WikiTableQuestions with human annotators show that our method\ncan improve the performance with only 100 active queries, especially for\nweakly-supervised parsers learnt from a cold start.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 07:48:19 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Ni", "Ansong", ""], ["Yin", "Pengcheng", ""], ["Neubig", "Graham", ""]]}, {"id": "1911.13062", "submitter": "Wladimir Sidorenko", "authors": "Wladimir Sidorenko", "title": "Sentiment Analysis of German Twitter", "comments": "Ph.D. Dissertation", "journal-ref": null, "doi": "10.25932/publishup-43742", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This thesis explores the ways by how people express their opinions on German\nTwitter, examines current approaches to automatic mining of these feelings, and\nproposes novel methods, which outperform state-of-the-art techniques. For this\npurpose, I introduce a new corpus of German tweets that have been manually\nannotated with sentiments, their targets and holders, as well as polar terms\nand their contextual modifiers. Using these data, I explore four major areas of\nsentiment research: (i) generation of sentiment lexicons, (ii) fine-grained\nopinion mining, (iii) message-level polarity classification, and (iv)\ndiscourse-aware sentiment analysis. In the first task, I compare three popular\ngroups of lexicon generation methods: dictionary-, corpus-, and\nword-embedding-based ones, finding that dictionary-based systems generally\nyield better lexicons than the last two groups. Apart from this, I propose a\nlinear projection algorithm, whose results surpass many existing automatic\nlexicons. Afterwords, in the second task, I examine two common approaches to\nautomatic prediction of sentiments, sources, and targets: conditional random\nfields and recurrent neural networks, obtaining higher scores with the former\nmodel and improving these results even further by redefining the structure of\nCRF graphs. When dealing with message-level polarity classification, I\njuxtapose three major sentiment paradigms: lexicon-, machine-learning-, and\ndeep-learning-based systems, and try to unite the first and last of these\ngroups by introducing a bidirectional neural network with lexicon-based\nattention. Finally, in order to make the new classifier aware of discourse\nstructure, I let it separately analyze the elementary discourse units of each\nmicroblog and infer the overall polarity of a message from the scores of its\nEDUs with the help of two new approaches: latent-marginalized CRFs and\nRecursive Dirichlet Process.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 11:24:10 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Sidorenko", "Wladimir", ""]]}, {"id": "1911.13066", "submitter": "Muhammad Haroon Shakeel", "authors": "Muhammad Haroon Shakeel, Asim Karim, Imdadullah Khan", "title": "A Multi-cascaded Deep Model for Bilingual SMS Classification", "comments": null, "journal-ref": "Neural Information Processing. ICONIP 2019", "doi": "10.1007/978-3-030-36708-4_24", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most studies on text classification are focused on the English language.\nHowever, short texts such as SMS are influenced by regional languages. This\nmakes the automatic text classification task challenging due to the\nmultilingual, informal, and noisy nature of language in the text. In this work,\nwe propose a novel multi-cascaded deep learning model called McM for bilingual\nSMS classification. McM exploits $n$-gram level information as well as\nlong-term dependencies of text for learning. Our approach aims to learn a model\nwithout any code-switching indication, lexical normalization, language\ntranslation, or language transliteration. The model relies entirely upon the\ntext as no external knowledge base is utilized for learning. For this purpose,\na 12 class bilingual text dataset is developed from SMS feedbacks of citizens\non public services containing mixed Roman Urdu and English languages. Our model\nachieves high accuracy for classification on this dataset and outperforms the\nprevious model for multilingual text classification, highlighting language\nindependence of McM.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 11:35:13 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Shakeel", "Muhammad Haroon", ""], ["Karim", "Asim", ""], ["Khan", "Imdadullah", ""]]}, {"id": "1911.13087", "submitter": "Hossein Hassani", "authors": "Akam Qader and Hossein Hassani", "title": "Kurdish (Sorani) Speech to Text: Presenting an Experimental Dataset", "comments": "4 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present an experimental dataset, Basic Dataset for Sorani Kurdish\nAutomatic Speech Recognition (BD-4SK-ASR), which we used in the first attempt\nin developing an automatic speech recognition for Sorani Kurdish. The objective\nof the project was to develop a system that automatically could recognize\nsimple sentences based on the vocabulary which is used in grades one to three\nof the primary schools in the Kurdistan Region of Iraq. We used CMUSphinx as\nour experimental environment. We developed a dataset to train the system. The\ndataset is publicly available for non-commercial use under the CC BY-NC-SA 4.0\nlicense.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 12:55:41 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 09:59:12 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Qader", "Akam", ""], ["Hassani", "Hossein", ""]]}, {"id": "1911.13096", "submitter": "Rujing Yao", "authors": "Rujing Yao, Linlin Hou, Yingchun Ye, Ou Wu, Ji Zhang, Jian Wu", "title": "Method and Dataset Mining in Scientific Papers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Literature analysis facilitates researchers better understanding the\ndevelopment of science and technology. The conventional literature analysis\nfocuses on the topics, authors, abstracts, keywords, references, etc., and\nrarely pays attention to the content of papers. In the field of machine\nlearning, the involved methods (M) and datasets (D) are key information in\npapers. The extraction and mining of M and D are useful for discipline analysis\nand algorithm recommendation. In this paper, we propose a novel entity\nrecognition model, called MDER, and constructe datasets from the papers of the\nPAKDD conferences (2009-2019). Some preliminary experiments are conducted to\nassess the extraction performance and the mining results are visualized.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 13:19:45 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Yao", "Rujing", ""], ["Hou", "Linlin", ""], ["Ye", "Yingchun", ""], ["Wu", "Ou", ""], ["Zhang", "Ji", ""], ["Wu", "Jian", ""]]}, {"id": "1911.13182", "submitter": "Jie Wang", "authors": "Liming Deng, Jie Wang, Hangming Liang, Hui Chen, Zhiqiang Xie, Bojin\n  Zhuang, Shaojun Wang, Jing Xiao", "title": "An Iterative Polishing Framework based on Quality Aware Masked Language\n  Model for Chinese Poetry Generation", "comments": "accepted by AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owing to its unique literal and aesthetical characteristics, automatic\ngeneration of Chinese poetry is still challenging in Artificial Intelligence,\nwhich can hardly be straightforwardly realized by end-to-end methods. In this\npaper, we propose a novel iterative polishing framework for highly qualified\nChinese poetry generation. In the first stage, an encoder-decoder structure is\nutilized to generate a poem draft. Afterwards, our proposed Quality-Aware\nMasked Language Model (QAMLM) is employed to polish the draft towards higher\nquality in terms of linguistics and literalness. Based on a multi-task learning\nscheme, QA-MLM is able to determine whether polishing is needed based on the\npoem draft. Furthermore, QAMLM is able to localize improper characters of the\npoem draft and substitute with newly predicted ones accordingly. Benefited from\nthe masked language model structure, QAMLM incorporates global context\ninformation into the polishing process, which can obtain more appropriate\npolishing results than the unidirectional sequential decoding. Moreover, the\niterative polishing process will be terminated automatically when QA-MLM\nregards the processed poem as a qualified one. Both human and automatic\nevaluation have been conducted, and the results demonstrate that our approach\nis effective to improve the performance of encoder-decoder structure.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 16:34:00 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Deng", "Liming", ""], ["Wang", "Jie", ""], ["Liang", "Hangming", ""], ["Chen", "Hui", ""], ["Xie", "Zhiqiang", ""], ["Zhuang", "Bojin", ""], ["Wang", "Shaojun", ""], ["Xiao", "Jing", ""]]}, {"id": "1911.13207", "submitter": "Claudia Savina Bianchini", "authors": "Claudia Bianchini (FORELLIS), Fabrizio Borgia, Maria de Marsico", "title": "A concrete example of inclusive design: deaf-oriented accessibility", "comments": "SCOPUS - ISI?", "journal-ref": "The Wiley Handbook of Human Computer Interaction, 2 (chapter 33),\n  Wiley (Blackwell), pp.731-756, 2018, 978-1-118-97613-5", "doi": "10.1002/9781118976005.ch33", "report-no": "pubblicazione #17", "categories": "cs.HC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the continuing challenges of Human Computer Interaction research is\nthe full inclusion of people with special needs into the digital world. In\nparticular, this crucial category includes people that experiences some kind of\nlimitation in exploiting traditional information communication channels. One\nimmediately thinks about blind people, and several researches aim at addressing\ntheir needs. On the contrary, limitations suffered by deaf people are often\nunderestimated. This often the result of a kind of ignorance or\nmisunderstanding of the real nature of their communication difficulties. This\nchapter aims at both increasing the awareness of deaf problems in the digital\nworld, and at proposing the project of a comprehensive solution for their\nbetter inclusion. As for the former goal, we will provide a bird's-eye\npresentation of history and evolution of understanding of deafness issues, and\nof strategies to address them. As for the latter, we will present the design,\nimplementation and evaluation of the first nucleus of a comprehensive digital\nframework to facilitate the access of deaf people into the digital world.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 15:01:57 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Bianchini", "Claudia", "", "FORELLIS"], ["Borgia", "Fabrizio", ""], ["de Marsico", "Maria", ""]]}, {"id": "1911.13231", "submitter": "Claudia Savina Bianchini", "authors": "Fabrizio Borgia (PCL, UPS), Claudia Bianchini (Poitiers UFR LL,\n  FORELLIS), Maria de Marsico", "title": "Towards improving the e-learning experience for deaf students: e-LUX", "comments": "anche ISBN 978-3-319-07436-9", "journal-ref": "Lecture Notes in Computer Science, Springer, 2014, Universal\n  access in human-computer interaction: universal access to information and\n  knowledge, 8514 (2), pp.221-232", "doi": "10.1007/978-3-319-07440-5", "report-no": "pubblicazione #014", "categories": "cs.HC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deaf people are more heavily affected by the digital divide than many would\nexpect. Moreover, most accessibility guidelines addressing their needs just\ndeal with captioning and audio-content transcription. However, this approach to\nthe problem does not consider that deaf people have big troubles with vocal\nlanguages, even in their written form. At present, only a few organizations,\nlike W3C, produced guidelines dealing with one of their most distinctive\nexpressions: Sign Language (SL). SL is, in fact, the visual-gestural language\nused by many deaf people to communicate with each other. The present work aims\nat supporting e-learning user experience (e-LUX) for these specific users by\nenhancing the accessibility of content and container services. In particular,\nwe propose preliminary solutions to tailor activities which can be more\nfruitful when performed in one's own \"native\" language, which for most deaf\npeople, especially younger ones, is represented by national SL.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 14:55:16 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Borgia", "Fabrizio", "", "PCL, UPS"], ["Bianchini", "Claudia", "", "Poitiers UFR LL,\n  FORELLIS"], ["de Marsico", "Maria", ""]]}, {"id": "1911.13232", "submitter": "Limeng Cui", "authors": "Limeng Cui, Siddharth Biswal, Lucas M. Glass, Greg Lever, Jimeng Sun,\n  Cao Xiao", "title": "CONAN: Complementary Pattern Augmentation for Rare Disease Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rare diseases affect hundreds of millions of people worldwide but are hard to\ndetect since they have extremely low prevalence rates (varying from 1/1,000 to\n1/200,000 patients) and are massively underdiagnosed. How do we reliably detect\nrare diseases with such low prevalence rates? How to further leverage patients\nwith possibly uncertain diagnosis to improve detection? In this paper, we\npropose a Complementary pattern Augmentation (CONAN) framework for rare disease\ndetection. CONAN combines ideas from both adversarial training and max-margin\nclassification. It first learns self-attentive and hierarchical embedding for\npatient pattern characterization. Then, we develop a complementary generative\nadversarial networks (GAN) model to generate candidate positive and negative\nsamples from the uncertain patients by encouraging a max-margin between\nclasses. In addition, CONAN has a disease detector that serves as the\ndiscriminator during the adversarial training for identifying rare diseases. We\nevaluated CONAN on two disease detection tasks. For low prevalence inflammatory\nbowel disease (IBD) detection, CONAN achieved .96 precision recall area under\nthe curve (PR-AUC) and 50.1% relative improvement over best baseline. For rare\ndisease idiopathic pulmonary fibrosis (IPF) detection, CONAN achieves .22\nPR-AUC with 41.3% relative improvement over the best baseline.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 22:18:40 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Cui", "Limeng", ""], ["Biswal", "Siddharth", ""], ["Glass", "Lucas M.", ""], ["Lever", "Greg", ""], ["Sun", "Jimeng", ""], ["Xiao", "Cao", ""]]}, {"id": "1911.13280", "submitter": "Kian Kenyon-Dean", "authors": "Edward Newell, Kian Kenyon-Dean, Jackie Chi Kit Cheung", "title": "Deconstructing and reconstructing word embedding algorithms", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncontextualized word embeddings are reliable feature representations of\nwords used to obtain high quality results for various NLP applications. Given\nthe historical success of word embeddings in NLP, we propose a retrospective on\nsome of the most well-known word embedding algorithms. In this work, we\ndeconstruct Word2vec, GloVe, and others, into a common form, unveiling some of\nthe necessary and sufficient conditions required for making performant word\nembeddings. We find that each algorithm: (1) fits vector-covector dot products\nto approximate pointwise mutual information (PMI); and, (2) modulates the loss\ngradient to balance weak and strong signals. We demonstrate that these two\nalgorithmic features are sufficient conditions to construct a novel word\nembedding algorithm, Hilbert-MLE. We find that its embeddings obtain equivalent\nor better performance against other algorithms across 17 intrinsic and\nextrinsic datasets.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 18:27:36 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Newell", "Edward", ""], ["Kenyon-Dean", "Kian", ""], ["Cheung", "Jackie Chi Kit", ""]]}]