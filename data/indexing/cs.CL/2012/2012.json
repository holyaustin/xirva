[{"id": "2012.00004", "submitter": "Pavel P\\v{r}ib\\'a\\v{n}", "authors": "Ond\\v{r}ej Pra\\v{z}\\'ak, Pavel P\\v{r}ib\\'a\\v{n}, Stephen Taylor, and\n  Jakub Sido", "title": "UWB at SemEval-2020 Task 1: Lexical Semantic Change Detection", "comments": "arXiv admin note: substantial text overlap with arXiv:2011.14678", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we describe our method for the detection of lexical semantic\nchange, i.e., word sense changes over time. We examine semantic differences\nbetween specific words in two corpora, chosen from different time periods, for\nEnglish, German, Latin, and Swedish. Our method was created for the SemEval\n2020 Task 1: \\textit{Unsupervised Lexical Semantic Change Detection.} We ranked\n$1^{st}$ in Sub-task 1: binary change detection, and $4^{th}$ in Sub-task 2:\nranked change detection. Our method is fully unsupervised and language\nindependent. It consists of preparing a semantic vector space for each corpus,\nearlier and later; computing a linear transformation between earlier and later\nspaces, using Canonical Correlation Analysis and Orthogonal Transformation; and\nmeasuring the cosines between the transformed vector for the target word from\nthe earlier corpus and the vector for the target word in the later corpus.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 10:47:45 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Pra\u017e\u00e1k", "Ond\u0159ej", ""], ["P\u0159ib\u00e1\u0148", "Pavel", ""], ["Taylor", "Stephen", ""], ["Sido", "Jakub", ""]]}, {"id": "2012.00012", "submitter": "Liye Fu", "authors": "Liye Fu, Susan R. Fussell and Cristian Danescu-Niculescu-Mizil", "title": "Facilitating the Communication of Politeness through Fine-Grained\n  Paraphrasing", "comments": "Proceedings of EMNLP 2020, 14 pages. Data and code at\n  https://convokit.cornell.edu/ and\n  https://github.com/CornellNLP/politeness-paraphrase", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Aided by technology, people are increasingly able to communicate across\ngeographical, cultural, and language barriers. This ability also results in new\nchallenges, as interlocutors need to adapt their communication approaches to\nincreasingly diverse circumstances. In this work, we take the first steps\ntowards automatically assisting people in adjusting their language to a\nspecific communication circumstance.\n  As a case study, we focus on facilitating the accurate transmission of\npragmatic intentions and introduce a methodology for suggesting paraphrases\nthat achieve the intended level of politeness under a given communication\ncircumstance. We demonstrate the feasibility of this approach by evaluating our\nmethod in two realistic communication scenarios and show that it can reduce the\npotential for misalignment between the speaker's intentions and the listener's\nperceptions in both cases.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 19:00:00 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Fu", "Liye", ""], ["Fussell", "Susan R.", ""], ["Danescu-Niculescu-Mizil", "Cristian", ""]]}, {"id": "2012.00052", "submitter": "Wen Xiao", "authors": "Wen Xiao, Giuseppe Carenini", "title": "Systematically Exploring Redundancy Reduction in Summarizing Long\n  Documents", "comments": "13 pages. Accepted at AACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Our analysis of large summarization datasets indicates that redundancy is a\nvery serious problem when summarizing long documents. Yet, redundancy reduction\nhas not been thoroughly investigated in neural summarization. In this work, we\nsystematically explore and compare different ways to deal with redundancy when\nsummarizing long documents. Specifically, we organize the existing methods into\ncategories based on when and how the redundancy is considered. Then, in the\ncontext of these categories, we propose three additional methods balancing\nnon-redundancy and importance in a general and flexible way. In a series of\nexperiments, we show that our proposed methods achieve the state-of-the-art\nwith respect to ROUGE scores on two scientific paper datasets, Pubmed and\narXiv, while reducing redundancy significantly.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 19:07:27 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Xiao", "Wen", ""], ["Carenini", "Giuseppe", ""]]}, {"id": "2012.00096", "submitter": "Arnhav Datar", "authors": "Amish Mittal, Sourav Sahoo, Arnhav Datar, Juned Kadiwala, Hrithwik\n  Shalu and Jimson Mathew", "title": "Multi-Modal Detection of Alzheimer's Disease from Speech and Text", "comments": "9 pages, 3 figures, Accepted in BIOKDD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliable detection of the prodromal stages of Alzheimer's disease (AD)\nremains difficult even today because, unlike other neurocognitive impairments,\nthere is no definitive diagnosis of AD in vivo. In this context, existing\nresearch has shown that patients often develop language impairment even in mild\nAD conditions. We propose a multimodal deep learning method that utilizes\nspeech and the corresponding transcript simultaneously to detect AD. For audio\nsignals, the proposed audio-based network, a convolutional neural network (CNN)\nbased model, predicts the diagnosis for multiple speech segments, which are\ncombined for the final prediction. Similarly, we use contextual embedding\nextracted from BERT concatenated with a CNN-generated embedding for classifying\nthe transcript. The individual predictions of the two models are then combined\nto make the final classification. We also perform experiments to analyze the\nmodel performance when Automated Speech Recognition (ASR) system generated\ntranscripts are used instead of manual transcription in the text-based model.\nThe proposed method achieves 85.3% 10-fold cross-validation accuracy when\ntrained and evaluated on the Dementiabank Pitt corpus.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 21:18:17 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 14:44:57 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Mittal", "Amish", ""], ["Sahoo", "Sourav", ""], ["Datar", "Arnhav", ""], ["Kadiwala", "Juned", ""], ["Shalu", "Hrithwik", ""], ["Mathew", "Jimson", ""]]}, {"id": "2012.00124", "submitter": "Kanthashree Mysore Sathyendra", "authors": "Kanthashree Mysore Sathyendra, Samridhi Choudhary, Leah\n  Nicolich-Henkin", "title": "Extreme Model Compression for On-device Natural Language Understanding", "comments": "Long paper at COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose and experiment with techniques for extreme\ncompression of neural natural language understanding (NLU) models, making them\nsuitable for execution on resource-constrained devices. We propose a\ntask-aware, end-to-end compression approach that performs word-embedding\ncompression jointly with NLU task learning. We show our results on a\nlarge-scale, commercial NLU system trained on a varied set of intents with huge\nvocabulary sizes. Our approach outperforms a range of baselines and achieves a\ncompression rate of 97.4% with less than 3.7% degradation in predictive\nperformance. Our analysis indicates that the signal from the downstream task is\nimportant for effective compression with minimal degradation in performance.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 21:47:48 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Sathyendra", "Kanthashree Mysore", ""], ["Choudhary", "Samridhi", ""], ["Nicolich-Henkin", "Leah", ""]]}, {"id": "2012.00133", "submitter": "Yile Gu", "authors": "Vijay Ravi, Yile Gu, Ankur Gandhe, Ariya Rastrow, Linda Liu, Denis\n  Filimonov, Scott Novotney, Ivan Bulyko", "title": "Improving accuracy of rare words for RNN-Transducer through unigram\n  shallow fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end automatic speech recognition (ASR) systems, such as recurrent\nneural network transducer (RNN-T), have become popular, but rare word remains a\nchallenge. In this paper, we propose a simple, yet effective method called\nunigram shallow fusion (USF) to improve rare words for RNN-T. In USF, we\nextract rare words from RNN-T training data based on unigram count, and apply a\nfixed reward when the word is encountered during decoding. We show that this\nsimple method can improve performance on rare words by 3.7% WER relative\nwithout degradation on general test set, and the improvement from USF is\nadditive to any additional language model based rescoring. Then, we show that\nthe same USF does not work on conventional hybrid system. Finally, we reason\nthat USF works by fixing errors in probability estimates of words due to\nViterbi search used during decoding with subword-based RNN-T.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 22:06:02 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Ravi", "Vijay", ""], ["Gu", "Yile", ""], ["Gandhe", "Ankur", ""], ["Rastrow", "Ariya", ""], ["Liu", "Linda", ""], ["Filimonov", "Denis", ""], ["Novotney", "Scott", ""], ["Bulyko", "Ivan", ""]]}, {"id": "2012.00187", "submitter": "Haitao Liu", "authors": "Shuiyuan Yu, Chunshan Xu, Haitao Liu", "title": "Statistical patterns of word frequency suggesting the probabilistic\n  nature of human languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional linguistic theories have largely regard language as a formal\nsystem composed of rigid rules. However, their failures in processing real\nlanguage, the recent successes in statistical natural language processing, and\nthe findings of many psychological experiments have suggested that language may\nbe more a probabilistic system than a formal system, and thus cannot be\nfaithfully modeled with the either/or rules of formal linguistic theory. The\npresent study, based on authentic language data, confirmed that those important\nlinguistic issues, such as linguistic universal, diachronic drift, and language\nvariations can be translated into probability and frequency patterns in parole.\nThese findings suggest that human language may well be probabilistic systems by\nnature, and that statistical may well make inherent properties of human\nlanguages.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 00:48:27 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Yu", "Shuiyuan", ""], ["Xu", "Chunshan", ""], ["Liu", "Haitao", ""]]}, {"id": "2012.00190", "submitter": "Sven Buechel", "authors": "Sven Buechel, Luise Modersohn, and Udo Hahn", "title": "Towards a Unified Framework for Emotion Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present EmoCoder, a modular encoder-decoder architecture that generalizes\nemotion analysis over different tasks (sentence-level, word-level,\nlabel-to-label mapping), domains (natural languages and their registers), and\nlabel formats (e.g., polarity classes, basic emotions, and affective\ndimensions). Experiments on 14 datasets indicate that EmoCoder learns an\ninterpretable language-independent representation of emotions, allows seamless\nabsorption of state-of-the-art models, and maintains strong prediction quality,\neven when tested on unseen combinations of domains and label formats.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 00:54:13 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Buechel", "Sven", ""], ["Modersohn", "Luise", ""], ["Hahn", "Udo", ""]]}, {"id": "2012.00209", "submitter": "Alex Calderwood", "authors": "Eric Bolton, Alex Calderwood, Niles Christensen, Jerome Kafrouni, Iddo\n  Drori", "title": "High Quality Real-Time Structured Debate Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatically generating debates is a challenging task that requires an\nunderstanding of arguments and how to negate or support them. In this work we\ndefine debate trees and paths for generating debates while enforcing a high\nlevel structure and grammar. We leverage a large corpus of tree-structured\ndebates that have metadata associated with each argument. We develop a\nframework for generating plausible debates which is agnostic to the sentence\nembedding model. Our results demonstrate the ability to generate debates in\nreal-time on complex topics at a quality that is close to humans, as evaluated\nby the style, content, and strategy metrics used for judging competitive human\ndebates. In the spirit of reproducible research we make our data, models, and\ncode publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 01:39:38 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Bolton", "Eric", ""], ["Calderwood", "Alex", ""], ["Christensen", "Niles", ""], ["Kafrouni", "Jerome", ""], ["Drori", "Iddo", ""]]}, {"id": "2012.00288", "submitter": "Mahfuz Ahmed Masum", "authors": "Mahfuz Ahmed Masum, Sheikh Junayed Ahmed, Ayesha Tasnim, Md Saiful\n  Islam", "title": "BAN-ABSA: An Aspect-Based Sentiment Analysis dataset for Bengali and\n  it's baseline evaluation", "comments": "11 pages,2 figures, 8 tables Included in proceedings of International\n  Joint Conference on Advances in Computational Intelligence (IJCACI) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to the breathtaking growth of social media or newspaper user comments,\nonline product reviews comments, sentiment analysis (SA) has captured\nsubstantial interest from the researchers. With the fast increase of domain, SA\nwork aims not only to predict the sentiment of a sentence or document but also\nto give the necessary detail on different aspects of the sentence or document\n(i.e. aspect-based sentiment analysis). A considerable number of datasets for\nSA and aspect-based sentiment analysis (ABSA) have been made available for\nEnglish and other well-known European languages. In this paper, we present a\nmanually annotated Bengali dataset of high quality, BAN-ABSA, which is\nannotated with aspect and its associated sentiment by 3 native Bengali\nspeakers. The dataset consists of 2,619 positive, 4,721 negative and 1,669\nneutral data samples from 9,009 unique comments gathered from some famous\nBengali news portals. In addition, we conducted a baseline evaluation with a\nfocus on deep learning model, achieved an accuracy of 78.75% for aspect term\nextraction and accuracy of 71.08% for sentiment classification. Experiments on\nthe BAN-ABSA dataset show that the CNN model is better in terms of accuracy\nthough Bi-LSTM significantly outperforms CNN model in terms of average\nF1-score.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 06:09:44 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Masum", "Mahfuz Ahmed", ""], ["Ahmed", "Sheikh Junayed", ""], ["Tasnim", "Ayesha", ""], ["Islam", "Md Saiful", ""]]}, {"id": "2012.00363", "submitter": "Chen Zhu", "authors": "Chen Zhu, Ankit Singh Rawat, Manzil Zaheer, Srinadh Bhojanapalli,\n  Daliang Li, Felix Yu, Sanjiv Kumar", "title": "Modifying Memories in Transformer Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large Transformer models have achieved impressive performance in many natural\nlanguage tasks. In particular, Transformer based language models have been\nshown to have great capabilities in encoding factual knowledge in their vast\namount of parameters. While the tasks of improving the memorization and\ngeneralization of Transformers have been widely studied, it is not well known\nhow to make transformers forget specific old facts and memorize new ones. In\nthis paper, we propose a new task of \\emph{explicitly modifying specific\nfactual knowledge in Transformer models while ensuring the model performance\ndoes not degrade on the unmodified facts}. This task is useful in many\nscenarios, such as updating stale knowledge, protecting privacy, and\neliminating unintended biases stored in the models. We benchmarked several\napproaches that provide natural baseline performances on this task. This leads\nto the discovery of key components of a Transformer model that are especially\neffective for knowledge modifications. The work also provides insights into the\nrole that different training phases (such as pretraining and fine-tuning) play\ntowards memorization and knowledge modification.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 09:39:13 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Zhu", "Chen", ""], ["Rawat", "Ankit Singh", ""], ["Zaheer", "Manzil", ""], ["Bhojanapalli", "Srinadh", ""], ["Li", "Daliang", ""], ["Yu", "Felix", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "2012.00366", "submitter": "Zhihao Fan", "authors": "Zhihao Fan, Yeyun Gong, Zhongyu Wei, Siyuan Wang, Yameng Huang, Jian\n  Jiao, Xuanjing Huang, Nan Duan, Ruofei Zhang", "title": "An Enhanced Knowledge Injection Model for Commonsense Generation", "comments": "Accepted to COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Commonsense generation aims at generating plausible everyday scenario\ndescription based on a set of provided concepts. Digging the relationship of\nconcepts from scratch is non-trivial, therefore, we retrieve prototypes from\nexternal knowledge to assist the understanding of the scenario for better\ndescription generation. We integrate two additional modules, namely position\nindicator and scaling module, into the pretrained encoder-decoder model for\nprototype modeling to enhance the knowledge injection procedure. We conduct\nexperiment on CommonGen benchmark, and experimental results show that our\nmethod significantly improves the performance on all the metrics.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 09:51:23 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Fan", "Zhihao", ""], ["Gong", "Yeyun", ""], ["Wei", "Zhongyu", ""], ["Wang", "Siyuan", ""], ["Huang", "Yameng", ""], ["Jiao", "Jian", ""], ["Huang", "Xuanjing", ""], ["Duan", "Nan", ""], ["Zhang", "Ruofei", ""]]}, {"id": "2012.00398", "submitter": "Naveen Elango", "authors": "Naveen Elango, Pawan Prasad K", "title": "Introducing Inter-Relatedness between Wikipedia Articles in Explicit\n  Semantic Analysis", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Explicit Semantic Analysis (ESA) is a technique used to represent a piece of\ntext as a vector in the space of concepts, such as Articles found in Wikipedia.\nWe propose a methodology to incorporate knowledge of Inter-relatedness between\nWikipedia Articles to the vectors obtained from ESA using a technique called\nRetrofitting to improve the performance of subsequent tasks that use ESA to\nform vector embeddings. Especially we use an undirected Graph to represent this\nknowledge with nodes as Articles and edges as inter relations between two\nArticles. Here, we also emphasize how the ESA step could be seen as a\npredominantly bottom-up approach using a corpus to come up with vector\nrepresentations and the incorporation of top-down knowledge which is the\nrelations between Articles to further improve it. We test our hypothesis on\nseveral smaller subsets of the Wikipedia corpus and show that our proposed\nmethodology leads to decent improvements in performance measures including\nSpearman's Rank correlation coefficient in most cases.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 10:55:07 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Elango", "Naveen", ""], ["K", "Pawan Prasad", ""]]}, {"id": "2012.00403", "submitter": "Ziye Yang", "authors": "Ziye Yang, Shanzheng Guan and Xiao-Lei Zhang", "title": "Deep Ad-hoc Beamforming Based on Speaker Extraction for Target-Dependent\n  Speech Separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the research on ad-hoc microphone arrays with deep learning has\ndrawn much attention, especially in speech enhancement and separation. Because\nan ad-hoc microphone array may cover such a large area that multiple speakers\nmay locate far apart and talk independently, target-dependent speech\nseparation, which aims to extract a target speaker from a mixed speech, is\nimportant for extracting and tracing a specific speaker in the ad-hoc array.\nHowever, this technique has not been explored yet. In this paper, we propose\ndeep ad-hoc beamforming based on speaker extraction, which is to our knowledge\nthe first work for target-dependent speech separation based on ad-hoc\nmicrophone arrays and deep learning. The algorithm contains three components.\nFirst, we propose a supervised channel selection framework based on speaker\nextraction, where the estimated utterance-level SNRs of the target speech are\nused as the basis for the channel selection. Second, we apply the selected\nchannels to a deep learning based MVDR algorithm, where a single-channel\nspeaker extraction algorithm is applied to each selected channel for estimating\nthe mask of the target speech. We conducted an extensive experiment on a\nWSJ0-adhoc corpus. Experimental results demonstrate the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 11:06:36 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Yang", "Ziye", ""], ["Guan", "Shanzheng", ""], ["Zhang", "Xiao-Lei", ""]]}, {"id": "2012.00413", "submitter": "Zhengyan Zhang", "authors": "Zhengyan Zhang, Xu Han, Hao Zhou, Pei Ke, Yuxian Gu, Deming Ye, Yujia\n  Qin, Yusheng Su, Haozhe Ji, Jian Guan, Fanchao Qi, Xiaozhi Wang, Yanan Zheng,\n  Guoyang Zeng, Huanqi Cao, Shengqi Chen, Daixuan Li, Zhenbo Sun, Zhiyuan Liu,\n  Minlie Huang, Wentao Han, Jie Tang, Juanzi Li, Xiaoyan Zhu, Maosong Sun", "title": "CPM: A Large-scale Generative Chinese Pre-trained Language Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained Language Models (PLMs) have proven to be beneficial for various\ndownstream NLP tasks. Recently, GPT-3, with 175 billion parameters and 570GB\ntraining data, drew a lot of attention due to the capacity of few-shot (even\nzero-shot) learning. However, applying GPT-3 to address Chinese NLP tasks is\nstill challenging, as the training corpus of GPT-3 is primarily English, and\nthe parameters are not publicly available. In this technical report, we release\nthe Chinese Pre-trained Language Model (CPM) with generative pre-training on\nlarge-scale Chinese training data. To the best of our knowledge, CPM, with 2.6\nbillion parameters and 100GB Chinese training data, is the largest Chinese\npre-trained language model, which could facilitate several downstream Chinese\nNLP tasks, such as conversation, essay generation, cloze test, and language\nunderstanding. Extensive experiments demonstrate that CPM achieves strong\nperformance on many NLP tasks in the settings of few-shot (even zero-shot)\nlearning. The code and parameters are available at\nhttps://github.com/TsinghuaAI/CPM-Generate.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 11:32:56 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Zhang", "Zhengyan", ""], ["Han", "Xu", ""], ["Zhou", "Hao", ""], ["Ke", "Pei", ""], ["Gu", "Yuxian", ""], ["Ye", "Deming", ""], ["Qin", "Yujia", ""], ["Su", "Yusheng", ""], ["Ji", "Haozhe", ""], ["Guan", "Jian", ""], ["Qi", "Fanchao", ""], ["Wang", "Xiaozhi", ""], ["Zheng", "Yanan", ""], ["Zeng", "Guoyang", ""], ["Cao", "Huanqi", ""], ["Chen", "Shengqi", ""], ["Li", "Daixuan", ""], ["Sun", "Zhenbo", ""], ["Liu", "Zhiyuan", ""], ["Huang", "Minlie", ""], ["Han", "Wentao", ""], ["Tang", "Jie", ""], ["Li", "Juanzi", ""], ["Zhu", "Xiaoyan", ""], ["Sun", "Maosong", ""]]}, {"id": "2012.00451", "submitter": "Antoine Yang", "authors": "Antoine Yang, Antoine Miech, Josef Sivic, Ivan Laptev, Cordelia Schmid", "title": "Just Ask: Learning to Answer Questions from Millions of Narrated Videos", "comments": "20 pages; 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent methods for visual question answering rely on large-scale annotated\ndatasets. Manual annotation of questions and answers for videos, however, is\ntedious, expensive and prevents scalability. In this work, we propose to avoid\nmanual annotation and generate a large-scale training dataset for video\nquestion answering making use of automatic cross-modal supervision. We leverage\na question generation transformer trained on text data and use it to generate\nquestion-answer pairs from transcribed video narrations. Given narrated videos,\nwe then automatically generate the HowToVQA69M dataset with 69M\nvideo-question-answer triplets. To handle the open vocabulary of diverse\nanswers in this dataset, we propose a training procedure based on a contrastive\nloss between a video-question multi-modal transformer and an answer\ntransformer. We introduce the zero-shot VideoQA task and show excellent\nresults, in particular for rare answers. Furthermore, we demonstrate our method\nto significantly outperform the state of the art on MSRVTT-QA, MSVD-QA,\nActivityNet-QA and How2QA. Finally, for a detailed evaluation we introduce a\nnew VideoQA dataset with reduced language biases and high-quality redundant\nmanual annotations. Our code and datasets will be made publicly available at\nhttps://antoyang.github.io/just-ask.html.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 12:59:20 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 14:33:37 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Yang", "Antoine", ""], ["Miech", "Antoine", ""], ["Sivic", "Josef", ""], ["Laptev", "Ivan", ""], ["Schmid", "Cordelia", ""]]}, {"id": "2012.00483", "submitter": "Markus Leippold", "authors": "Francesco S. Varini and Jordan Boyd-Graber and Massimiliano Ciaramita\n  and Markus Leippold", "title": "ClimaText: A Dataset for Climate Change Topic Detection", "comments": "Accepted for the Tackling Climate Change with Machine Learning\n  Workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Climate change communication in the mass media and other textual sources may\naffect and shape public perception. Extracting climate change information from\nthese sources is an important task, e.g., for filtering content and\ne-discovery, sentiment analysis, automatic summarization, question-answering,\nand fact-checking. However, automating this process is a challenge, as climate\nchange is a complex, fast-moving, and often ambiguous topic with scarce\nresources for popular text-based AI tasks. In this paper, we introduce\n\\textsc{ClimaText}, a dataset for sentence-based climate change topic\ndetection, which we make publicly available. We explore different approaches to\nidentify the climate change topic in various text sources. We find that popular\nkeyword-based models are not adequate for such a complex and evolving task.\nContext-based algorithms like BERT \\cite{devlin2018bert} can detect, in\naddition to many trivial cases, a variety of complex and implicit topic\npatterns. Nevertheless, our analysis reveals a great potential for improvement\nin several directions, such as, e.g., capturing the discussion on indirect\neffects of climate change. Hence, we hope this work can serve as a good\nstarting point for further research on this topic.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 13:42:37 GMT"}, {"version": "v2", "created": "Sat, 2 Jan 2021 16:13:06 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Varini", "Francesco S.", ""], ["Boyd-Graber", "Jordan", ""], ["Ciaramita", "Massimiliano", ""], ["Leippold", "Markus", ""]]}, {"id": "2012.00486", "submitter": "Weicheng Cai", "authors": "Weicheng Cai, Ming Li", "title": "A Unified Deep Speaker Embedding Framework for Mixed-Bandwidth Speech\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a unified deep speaker embedding framework for modeling\nspeech data with different sampling rates. Considering the narrowband\nspectrogram as a sub-image of the wideband spectrogram, we tackle the joint\nmodeling problem of the mixed-bandwidth data in an image classification manner.\nFrom this perspective, we elaborate several mixed-bandwidth joint training\nstrategies under different training and test data scenarios. The proposed\nsystems are able to flexibly handle the mixed-bandwidth speech data in a single\nspeaker embedding model without any additional downsampling, upsampling,\nbandwidth extension, or padding operations. We conduct extensive experimental\nstudies on the VoxCeleb1 dataset. Furthermore, the effectiveness of the\nproposed approach is validated by the SITW and NIST SRE 2016 datasets.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 13:45:38 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Cai", "Weicheng", ""], ["Li", "Ming", ""]]}, {"id": "2012.00555", "submitter": "Mohnish Dubey", "authors": "Nandana Mihindukulasooriya and Mohnish Dubey and Alfio Gliozzo and\n  Jens Lehmann and Axel-Cyrille Ngonga Ngomo and Ricardo Usbeck", "title": "SeMantic AnsweR Type prediction task (SMART) at ISWC 2020 Semantic Web\n  Challenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Each year the International Semantic Web Conference accepts a set of Semantic\nWeb Challenges to establish competitions that will advance the state of the art\nsolutions in any given problem domain. The SeMantic AnsweR Type prediction task\n(SMART) was part of ISWC 2020 challenges. Question type and answer type\nprediction can play a key role in knowledge base question answering systems\nproviding insights that are helpful to generate correct queries or rank the\nanswer candidates. More concretely, given a question in natural language, the\ntask of SMART challenge is, to predict the answer type using a target ontology\n(e.g., DBpedia or Wikidata).\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 15:02:11 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Mihindukulasooriya", "Nandana", ""], ["Dubey", "Mohnish", ""], ["Gliozzo", "Alfio", ""], ["Lehmann", "Jens", ""], ["Ngomo", "Axel-Cyrille Ngonga", ""], ["Usbeck", "Ricardo", ""]]}, {"id": "2012.00571", "submitter": "S\\'ebastien Montella", "authors": "Sebastien Montella, Betty Fabre, Tanguy Urvoy, Johannes Heinecke, Lina\n  Rojas-Barahona", "title": "Denoising Pre-Training and Data Augmentation Strategies for Enhanced RDF\n  Verbalization with Transformers", "comments": "Accepted at WebNLG+: 3rd Workshop on Natural Language Generation from\n  the Semantic Web", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of verbalization of RDF triples has known a growth in popularity due\nto the rising ubiquity of Knowledge Bases (KBs). The formalism of RDF triples\nis a simple and efficient way to store facts at a large scale. However, its\nabstract representation makes it difficult for humans to interpret. For this\npurpose, the WebNLG challenge aims at promoting automated RDF-to-text\ngeneration. We propose to leverage pre-trainings from augmented data with the\nTransformer model using a data augmentation strategy. Our experiment results\nshow a minimum relative increases of 3.73%, 126.05% and 88.16% in BLEU score\nfor seen categories, unseen entities and unseen categories respectively over\nthe standard training.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 15:25:47 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Montella", "Sebastien", ""], ["Fabre", "Betty", ""], ["Urvoy", "Tanguy", ""], ["Heinecke", "Johannes", ""], ["Rojas-Barahona", "Lina", ""]]}, {"id": "2012.00584", "submitter": "Andres Carvallo", "authors": "Andres Carvallo, Denis Parra, Gabriel Rada, Daniel Perez, Juan Ignacio\n  Vasquez and Camilo Vergara", "title": "Neural language models for text classification in evidence-based\n  medicine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 has brought about a significant challenge to the whole of\nhumanity, but with a special burden upon the medical community. Clinicians must\nkeep updated continuously about symptoms, diagnoses, and effectiveness of\nemergent treatments under a never-ending flood of scientific literature. In\nthis context, the role of evidence-based medicine (EBM) for curating the most\nsubstantial evidence to support public health and clinical practice turns\nessential but is being challenged as never before due to the high volume of\nresearch articles published and pre-prints posted daily. Artificial\nIntelligence can have a crucial role in this situation. In this article, we\nreport the results of an applied research project to classify scientific\narticles to support Epistemonikos, one of the most active foundations worldwide\nconducting EBM. We test several methods, and the best one, based on the XLNet\nneural language model, improves the current approach by 93\\% on average\nF1-score, saving valuable time from physicians who volunteer to curate COVID-19\nresearch articles manually.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 15:53:44 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Carvallo", "Andres", ""], ["Parra", "Denis", ""], ["Rada", "Gabriel", ""], ["Perez", "Daniel", ""], ["Vasquez", "Juan Ignacio", ""], ["Vergara", "Camilo", ""]]}, {"id": "2012.00600", "submitter": "Mustafa Jarrar", "authors": "Mustafa Jarrar, Eman Karajah, Muhammad Khalifa, Khaled Shaalan", "title": "Extracting Synonyms from Bilingual Dictionaries", "comments": "In Proceedings - 11th International Global Wordnet Conference\n  (GWC2021). Global Wordnet Association (2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present our progress in developing a novel algorithm to extract synonyms\nfrom bilingual dictionaries. Identification and usage of synonyms play a\nsignificant role in improving the performance of information access\napplications. The idea is to construct a translation graph from translation\npairs, then to extract and consolidate cyclic paths to form bilingual sets of\nsynonyms. The initial evaluation of this algorithm illustrates promising\nresults in extracting Arabic-English bilingual synonyms. In the evaluation, we\nfirst converted the synsets in the Arabic WordNet into translation pairs (i.e.,\nlosing word-sense memberships). Next, we applied our algorithm to rebuild these\nsynsets. We compared the original and extracted synsets obtaining an F-Measure\nof 82.3% and 82.1% for Arabic and English synsets extraction, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 16:09:22 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Jarrar", "Mustafa", ""], ["Karajah", "Eman", ""], ["Khalifa", "Muhammad", ""], ["Shaalan", "Khaled", ""]]}, {"id": "2012.00614", "submitter": "Markus Leippold", "authors": "Thomas Diggelmann and Jordan Boyd-Graber and Jannis Bulian and\n  Massimiliano Ciaramita and Markus Leippold", "title": "CLIMATE-FEVER: A Dataset for Verification of Real-World Climate Claims", "comments": "Accepted for the Tackling Climate Change with Machine Learning\n  Workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce CLIMATE-FEVER, a new publicly available dataset for verification\nof climate change-related claims. By providing a dataset for the research\ncommunity, we aim to facilitate and encourage work on improving algorithms for\nretrieving evidential support for climate-specific claims, addressing the\nunderlying language understanding challenges, and ultimately help alleviate the\nimpact of misinformation on climate change. We adapt the methodology of FEVER\n[1], the largest dataset of artificially designed claims, to real-life claims\ncollected from the Internet. While during this process, we could rely on the\nexpertise of renowned climate scientists, it turned out to be no easy task. We\ndiscuss the surprising, subtle complexity of modeling real-world\nclimate-related claims within the \\textsc{fever} framework, which we believe\nprovides a valuable challenge for general natural language understanding. We\nhope that our work will mark the beginning of a new exciting long-term joint\neffort by the climate science and AI community.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 16:32:54 GMT"}, {"version": "v2", "created": "Sat, 2 Jan 2021 16:07:48 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Diggelmann", "Thomas", ""], ["Boyd-Graber", "Jordan", ""], ["Bulian", "Jannis", ""], ["Ciaramita", "Massimiliano", ""], ["Leippold", "Markus", ""]]}, {"id": "2012.00633", "submitter": "Rahul Dubey Dr", "authors": "Shree Charran R, Rahul Kumar Dubey (Senior Member IEEE)", "title": "Meta-Embeddings for Natural Language Inference and Semantic Similarity\n  tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Word Representations form the core component for almost all advanced Natural\nLanguage Processing (NLP) applications such as text mining, question-answering,\nand text summarization, etc. Over the last two decades, immense research is\nconducted to come up with one single model to solve all major NLP tasks. The\nmajor problem currently is that there are a plethora of choices for different\nNLP tasks. Thus for NLP practitioners, the task of choosing the right model to\nbe used itself becomes a challenge. Thus combining multiple pre-trained word\nembeddings and forming meta embeddings has become a viable approach to improve\ntackle NLP tasks. Meta embedding learning is a process of producing a single\nword embedding from a given set of pre-trained input word embeddings. In this\npaper, we propose to use Meta Embedding derived from few State-of-the-Art\n(SOTA) models to efficiently tackle mainstream NLP tasks like classification,\nsemantic relatedness, and text similarity. We have compared both ensemble and\ndynamic variants to identify an efficient approach. The results obtained show\nthat even the best State-of-the-Art models can be bettered. Thus showing us\nthat meta-embeddings can be used for several NLP tasks by harnessing the power\nof several individual representations.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 16:58:01 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["R", "Shree Charran", "", "Senior Member IEEE"], ["Dubey", "Rahul Kumar", "", "Senior Member IEEE"]]}, {"id": "2012.00708", "submitter": "G\\'abor Melis", "authors": "G\\'abor Melis, Andr\\'as Gy\\\"orgy, Phil Blunsom", "title": "Mutual Information Constraints for Monte-Carlo Objectives", "comments": "32 pages, 29 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common failure mode of density models trained as variational autoencoders\nis to model the data without relying on their latent variables, rendering these\nvariables useless. Two contributing factors, the underspecification of the\nmodel and the looseness of the variational lower bound, have been studied\nseparately in the literature. We weave these two strands of research together,\nspecifically the tighter bounds of Monte-Carlo objectives and constraints on\nthe mutual information between the observable and the latent variables.\nEstimating the mutual information as the average Kullback-Leibler divergence\nbetween the easily available variational posterior $q(z|x)$ and the prior does\nnot work with Monte-Carlo objectives because $q(z|x)$ is no longer a direct\napproximation to the model's true posterior $p(z|x)$. Hence, we construct\nestimators of the Kullback-Leibler divergence of the true posterior from the\nprior by recycling samples used in the objective, with which we train models of\ncontinuous and discrete latents at much improved rate-distortion and no\nposterior collapse. While alleviated, the tradeoff between modelling the data\nand using the latents still remains, and we urge for evaluating inference\nmethods across a range of mutual information values.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 18:14:08 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Melis", "G\u00e1bor", ""], ["Gy\u00f6rgy", "Andr\u00e1s", ""], ["Blunsom", "Phil", ""]]}, {"id": "2012.00728", "submitter": "Mohit Mayank", "authors": "Mohit Mayank", "title": "Intrinsic analysis for dual word embedding space models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent word embeddings techniques represent words in a continuous vector\nspace, moving away from the atomic and sparse representations of the past. Each\nsuch technique can further create multiple varieties of embeddings based on\ndifferent settings of hyper-parameters like embedding dimension size, context\nwindow size and training method. One additional variety appears when we\nespecially consider the Dual embedding space techniques which generate not one\nbut two-word embeddings as output. This gives rise to an interesting question -\n\"is there one or a combination of the two word embeddings variety, which works\nbetter for a specific task?\". This paper tries to answer this question by\nconsidering all of these variations. Herein, we compare two classical embedding\nmethods belonging to two different methodologies - Word2Vec from window-based\nand Glove from count-based. For an extensive evaluation after considering all\nvariations, a total of 84 different models were compared against semantic,\nassociation and analogy evaluations tasks which are made up of 9 open-source\nlinguistics datasets. The final Word2vec reports showcase the preference of\nnon-default model for 2 out of 3 tasks. In case of Glove, non-default models\noutperform in all 3 evaluation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 18:40:42 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2020 12:29:19 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Mayank", "Mohit", ""]]}, {"id": "2012.00857", "submitter": "Yikang Shen", "authors": "Yikang Shen, Yi Tay, Che Zheng, Dara Bahri, Donald Metzler, Aaron\n  Courville", "title": "StructFormer: Joint Unsupervised Induction of Dependency and\n  Constituency Structure from Masked Language Modeling", "comments": "Published as a conference paper at ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There are two major classes of natural language grammar -- the dependency\ngrammar that models one-to-one correspondences between words and the\nconstituency grammar that models the assembly of one or several corresponded\nwords. While previous unsupervised parsing methods mostly focus on only\ninducing one class of grammars, we introduce a novel model, StructFormer, that\ncan simultaneously induce dependency and constituency structure. To achieve\nthis, we propose a new parsing framework that can jointly generate a\nconstituency tree and dependency graph. Then we integrate the induced\ndependency relations into the transformer, in a differentiable manner, through\na novel dependency-constrained self-attention mechanism. Experimental results\nshow that our model can achieve strong results on unsupervised constituency\nparsing, unsupervised dependency parsing, and masked language modeling at the\nsame time.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 21:54:51 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 20:55:53 GMT"}, {"version": "v3", "created": "Sun, 11 Jul 2021 01:10:26 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Shen", "Yikang", ""], ["Tay", "Yi", ""], ["Zheng", "Che", ""], ["Bahri", "Dara", ""], ["Metzler", "Donald", ""], ["Courville", "Aaron", ""]]}, {"id": "2012.00876", "submitter": "Peter Wu", "authors": "Peter Wu, Yifan Zhong, Alan W Black", "title": "Automatically Identifying Language Family from Acoustic Examples in Low\n  Resource Scenarios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing multilingual speech NLP works focus on a relatively small subset of\nlanguages, and thus current linguistic understanding of languages predominantly\nstems from classical approaches. In this work, we propose a method to analyze\nlanguage similarity using deep learning. Namely, we train a model on the\nWilderness dataset and investigate how its latent space compares with classical\nlanguage family findings. Our approach provides a new direction for\ncross-lingual data augmentation in any speech-based NLP task.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 22:44:42 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Wu", "Peter", ""], ["Zhong", "Yifan", ""], ["Black", "Alan W", ""]]}, {"id": "2012.00893", "submitter": "Danish Pruthi", "authors": "Danish Pruthi, Bhuwan Dhingra, Livio Baldini Soares, Michael Collins,\n  Zachary C. Lipton, Graham Neubig, William W. Cohen", "title": "Evaluating Explanations: How much do explanations from the teacher aid\n  students?", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While many methods purport to explain predictions by highlighting salient\nfeatures, what precise aims these explanations serve and how to evaluate their\nutility are often unstated. In this work, we formalize the value of\nexplanations using a student-teacher paradigm that measures the extent to which\nexplanations improve student models in learning to simulate the teacher model\non unseen examples for which explanations are unavailable. Student models\nincorporate explanations in training (but not prediction) procedures. Unlike\nmany prior proposals to evaluate explanations, our approach cannot be easily\ngamed, enabling principled, scalable, and automatic evaluation of attributions.\nUsing our framework, we compare multiple attribution methods and observe\nconsistent and quantitative differences amongst them across multiple learning\nstrategies.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 23:40:21 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Pruthi", "Danish", ""], ["Dhingra", "Bhuwan", ""], ["Soares", "Livio Baldini", ""], ["Collins", "Michael", ""], ["Lipton", "Zachary C.", ""], ["Neubig", "Graham", ""], ["Cohen", "William W.", ""]]}, {"id": "2012.00898", "submitter": "Zhe Liu", "authors": "Zhe Liu, Fuchun Peng", "title": "Federated Marginal Personalization for ASR Rescoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce federated marginal personalization (FMP), a novel method for\ncontinuously updating personalized neural network language models (NNLMs) on\nprivate devices using federated learning (FL). Instead of fine-tuning the\nparameters of NNLMs on personal data, FMP regularly estimates global and\npersonalized marginal distributions of words, and adjusts the probabilities\nfrom NNLMs by an adaptation factor that is specific to each word. Our presented\napproach can overcome the limitations of federated fine-tuning and efficiently\nlearn personalized NNLMs on devices. We study the application of FMP on\nsecond-pass ASR rescoring tasks. Experiments on two speech evaluation datasets\nshow modest word error rate (WER) reductions. We also demonstrate that FMP\ncould offer reasonable privacy with only a negligible cost in speech\nrecognition accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 23:54:41 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Liu", "Zhe", ""], ["Peng", "Fuchun", ""]]}, {"id": "2012.00902", "submitter": "Behrouz Bokharaeian", "authors": "Behrouz Bokharaeian, Alberto Diaz", "title": "Automatic Extraction of Ranked SNP-Phenotype Associations from\n  Literature through Detecting Neural Candidates, Negation and Modality Markers", "comments": "8 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Genome-wide association (GWA) constitutes a prominent portion of studies\nwhich have been conducted on personalized medicine and pharmacogenomics.\nRecently, very few methods have been developed for extracting mutation-diseases\nassociations. However, there is no available method for extracting the\nassociation of SNP-phenotype from text which considers degree of confidence in\nassociations. In this study, first a relation extraction method relying on\nlinguistic-based negation detection and neutral candidates is proposed. The\nexperiments show that negation cues and scope as well as detecting neutral\ncandidates can be employed for implementing a superior relation extraction\nmethod which outperforms the kernel-based counterparts due to a uniform innate\npolarity of sentences and small number of complex sentences in the corpus.\nMoreover, a modality based approach is proposed to estimate the confidence\nlevel of the extracted association which can be used to assess the reliability\nof the reported association. Keywords: SNP, Phenotype, Biomedical Relation\nExtraction, Negation Detection.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 00:03:07 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Bokharaeian", "Behrouz", ""], ["Diaz", "Alberto", ""]]}, {"id": "2012.00955", "submitter": "Zhengbao Jiang", "authors": "Zhengbao Jiang, Jun Araki, Haibo Ding, Graham Neubig", "title": "How Can We Know When Language Models Know? On the Calibration of\n  Language Models for Question Answering", "comments": "TACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have shown that language models (LM) capture different types of\nknowledge regarding facts or common sense. However, because no model is\nperfect, they still fail to provide appropriate answers in many cases. In this\npaper, we ask the question \"how can we know when language models know, with\nconfidence, the answer to a particular query?\" We examine this question from\nthe point of view of calibration, the property of a probabilistic model's\npredicted probabilities actually being well correlated with the probabilities\nof correctness. We examine three strong generative models -- T5, BART, and\nGPT-2 -- and study whether their probabilities on QA tasks are well calibrated,\nfinding the answer is a relatively emphatic no. We then examine methods to\ncalibrate such models to make their confidence scores correlate better with the\nlikelihood of correctness through fine-tuning, post-hoc probability\nmodification, or adjustment of the predicted outputs or inputs. Experiments on\na diverse range of datasets demonstrate the effectiveness of our methods. We\nalso perform analysis to study the strengths and limitations of these methods,\nshedding light on further improvements that may be made in methods for\ncalibrating LMs. We have released the code at\nhttps://github.com/jzbjyb/lm-calibration.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 03:53:13 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 09:05:03 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Jiang", "Zhengbao", ""], ["Araki", "Jun", ""], ["Ding", "Haibo", ""], ["Neubig", "Graham", ""]]}, {"id": "2012.00958", "submitter": "Qing Ping", "authors": "Qing Ping, Feiyang Niu, Govind Thattai, Joel Chengottusseriyil, Qiaozi\n  Gao, Aishwarya Reganti, Prashanth Rajagopal, Gokhan Tur, Dilek Hakkani-Tur,\n  Prem Nataraja", "title": "Interactive Teaching for Conversational AI", "comments": "Accepted at Human in the Loop Dialogue Systems Workshop @NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current conversational AI systems aim to understand a set of pre-designed\nrequests and execute related actions, which limits them to evolve naturally and\nadapt based on human interactions. Motivated by how children learn their first\nlanguage interacting with adults, this paper describes a new Teachable AI\nsystem that is capable of learning new language nuggets called concepts,\ndirectly from end users using live interactive teaching sessions. The proposed\nsetup uses three models to: a) Identify gaps in understanding automatically\nduring live conversational interactions, b) Learn the respective\ninterpretations of such unknown concepts from live interactions with users, and\nc) Manage a classroom sub-dialogue specifically tailored for interactive\nteaching sessions. We propose state-of-the-art transformer based neural\narchitectures of models, fine-tuned on top of pre-trained models, and show\naccuracy improvements on the respective components. We demonstrate that this\nmethod is very promising in leading way to build more adaptive and personalized\nlanguage understanding models.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 04:08:49 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Ping", "Qing", ""], ["Niu", "Feiyang", ""], ["Thattai", "Govind", ""], ["Chengottusseriyil", "Joel", ""], ["Gao", "Qiaozi", ""], ["Reganti", "Aishwarya", ""], ["Rajagopal", "Prashanth", ""], ["Tur", "Gokhan", ""], ["Hakkani-Tur", "Dilek", ""], ["Nataraja", "Prem", ""]]}, {"id": "2012.00974", "submitter": "Kevin Lybarger", "authors": "Kevin Lybarger, Mari Ostendorf, Matthew Thompson, Meliha Yetisgen", "title": "Extracting COVID-19 Diagnoses and Symptoms From Clinical Text: A New\n  Annotated Corpus and Neural Event Extraction Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coronavirus disease 2019 (COVID-19) is a global pandemic. Although much has\nbeen learned about the novel coronavirus since its emergence, there are many\nopen questions related to tracking its spread, describing symptomology,\npredicting the severity of infection, and forecasting healthcare utilization.\nFree-text clinical notes contain critical information for resolving these\nquestions. Data-driven, automatic information extraction models are needed to\nuse this text-encoded information in large-scale studies. This work presents a\nnew clinical corpus, referred to as the COVID-19 Annotated Clinical Text (CACT)\nCorpus, which comprises 1,472 notes with detailed annotations characterizing\nCOVID-19 diagnoses, testing, and clinical presentation. We introduce a\nspan-based event extraction model that jointly extracts all annotated\nphenomena, achieving high performance in identifying COVID-19 and symptom\nevents with associated assertion values (0.83-0.97 F1 for events and 0.73-0.79\nF1 for assertions). In a secondary use application, we explored the prediction\nof COVID-19 test results using structured patient data (e.g. vital signs and\nlaboratory results) and automatically extracted symptom information. The\nautomatically extracted symptoms improve prediction performance, beyond\nstructured data alone.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 05:25:02 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 21:36:43 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Lybarger", "Kevin", ""], ["Ostendorf", "Mari", ""], ["Thompson", "Matthew", ""], ["Yetisgen", "Meliha", ""]]}, {"id": "2012.01002", "submitter": "Xiayu Zhong", "authors": "Xiayu Zhong", "title": "Classification of Multimodal Hate Speech -- The Winning Solution of\n  Hateful Memes Challenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hateful Memes is a new challenge set for multimodal classification, focusing\non detecting hate speech in multimodal memes. Difficult examples are added to\nthe dataset to make it hard to rely on unimodal signals, which means only\nmultimodal models can succeed. According to Kiela,the state-of-the-art methods\nperform poorly compared to humans (64.73% vs. 84.7% accuracy) on Hateful Memes.\nI propose a new model that combined multimodal with rules, which achieve the\nfirst ranking of accuracy and AUROC of 86.8% and 0.923 respectively. These\nrules are extracted from training set, and focus on improving the\nclassification accuracy of difficult samples.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 07:38:26 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Zhong", "Xiayu", ""]]}, {"id": "2012.01031", "submitter": "Sendong Zhao", "authors": "Sendong Zhao, Bing Qin, Ting Liu, Fei Wang", "title": "Biomedical Knowledge Graph Refinement with Embedding and Logic Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Currently, there is a rapidly increasing need for high-quality biomedical\nknowledge graphs (BioKG) that provide direct and precise biomedical knowledge.\nIn the context of COVID-19, this issue is even more necessary to be\nhighlighted. However, most BioKG construction inevitably includes numerous\nconflicts and noises deriving from incorrect knowledge descriptions in\nliterature and defective information extraction techniques. Many studies have\ndemonstrated that reasoning upon the knowledge graph is effective in\neliminating such conflicts and noises. This paper proposes a method BioGRER to\nimprove the BioKG's quality, which comprehensively combines the knowledge graph\nembedding and logic rules that support and negate triplets in the BioKG. In the\nproposed model, the BioKG refinement problem is formulated as the probability\nestimation for triplets in the BioKG. We employ the variational EM algorithm to\noptimize knowledge graph embedding and logic rule inference alternately. In\nthis way, our model could combine efforts from both the knowledge graph\nembedding and logic rules, leading to better results than using them alone. We\nevaluate our model over a COVID-19 knowledge graph and obtain competitive\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 08:55:07 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Zhao", "Sendong", ""], ["Qin", "Bing", ""], ["Liu", "Ting", ""], ["Wang", "Fei", ""]]}, {"id": "2012.01133", "submitter": "Oren Tsur", "authors": "Eyal Arviv, Simo Hanouna, Oren Tsur", "title": "It's a Thin Line Between Love and Hate: Using the Echo in Modeling\n  Dynamics of Racist Online Communities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The (((echo))) symbol -- triple parenthesis surrounding a name, made it to\nmainstream social networks in early 2016, with the intensification of the U.S.\nPresidential race. It was used by members of the alt-right, white supremacists\nand internet trolls to tag people of Jewish heritage -- a modern incarnation of\nthe infamous yellow badge (Judenstern) used in Nazi-Germany. Tracking this\ntrending meme, its meaning, and its function has proved elusive for its\nsemantic ambiguity (e.g., a symbol for a virtual hug).\n  In this paper we report of the construction of an appropriate dataset\nallowing the reconstruction of networks of racist communities and the way they\nare embedded in the broader community. We combine natural language processing\nand structural network analysis to study communities promoting hate. In order\nto overcome dog-whistling and linguistic ambiguity, we propose a multi-modal\nneural architecture based on a BERT transformer and a BiLSTM network on the\ntweet level, while also taking into account the users ego-network and meta\nfeatures. Our multi-modal neural architecture outperforms a set of strong\nbaselines. We further show how the the use of language and network structure in\ntandem allows the detection of the leaders of the hate communities. We further\nstudy the ``intersectionality'' of hate and show that the antisemitic echo\ncorrelates with hate speech that targets other minority and protected groups.\nFinally, we analyze the role IRA trolls assumed in this network as part of the\nRussian interference campaign. Our findings allow a better understanding of\nrecent manifestations of racism and the dynamics that facilitate it.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 20:47:54 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Arviv", "Eyal", ""], ["Hanouna", "Simo", ""], ["Tsur", "Oren", ""]]}, {"id": "2012.01186", "submitter": "Hao Sheng", "authors": "Eric Li, Jingyi Su, Hao Sheng, Lawrence Wai", "title": "AGenT Zero: Zero-shot Automatic Multiple-Choice Question Generation for\n  Skill Assessments", "comments": "AAAI 2021 Workshop on AI Education/TIPCE 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple-choice questions (MCQs) offer the most promising avenue for skill\nevaluation in the era of virtual education and job recruiting, where\ntraditional performance-based alternatives such as projects and essays have\nbecome less viable, and grading resources are constrained. The automated\ngeneration of MCQs would allow assessment creation at scale. Recent advances in\nnatural language processing have given rise to many complex question generation\nmethods. However, the few methods that produce deployable results in specific\ndomains require a large amount of domain-specific training data that can be\nvery costly to acquire. Our work provides an initial foray into MCQ generation\nunder high data-acquisition cost scenarios by strategically emphasizing\nparaphrasing the question context (compared to the task). In addition to\nmaintaining semantic similarity between the question-answer pairs, our\npipeline, which we call AGenT Zero, consists of only pre-trained models and\nrequires no fine-tuning, minimizing data acquisition costs for question\ngeneration. AGenT Zero successfully outperforms other pre-trained methods in\nfluency and semantic similarity. Additionally, with some small changes, our\nassessment pipeline can be generalized to a broader question and answer space,\nincluding short answer or fill in the blank questions.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 04:06:57 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 23:46:56 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Li", "Eric", ""], ["Su", "Jingyi", ""], ["Sheng", "Hao", ""], ["Wai", "Lawrence", ""]]}, {"id": "2012.01254", "submitter": "Uwe Aickelin", "authors": "Xiang Li, Xinyu Fu, Zheng Lu, Ruibin Bai, Uwe Aickelin, Peiming Ge,\n  Gong Liu", "title": "Retrieving and ranking short medical questions with two stages neural\n  matching model", "comments": "2019 IEEE Congress on Evolutionary Computation (CEC),Pages 873-879", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Internet hospital is a rising business thanks to recent advances in mobile\nweb technology and high demand of health care services. Online medical services\nbecome increasingly popular and active. According to US data in 2018, 80\npercent of internet users have asked health-related questions online. Numerous\ndata is generated in unprecedented speed and scale. Those representative\nquestions and answers in medical fields are valuable raw data sources for\nmedical data mining. Automated machine interpretation on those sheer amount of\ndata gives an opportunity to assist doctors to answer frequently asked\nmedical-related questions from the perspective of information retrieval and\nmachine learning approaches. In this work, we propose a novel two-stage\nframework for the semantic matching of query-level medical questions.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 07:00:35 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Li", "Xiang", ""], ["Fu", "Xinyu", ""], ["Lu", "Zheng", ""], ["Bai", "Ruibin", ""], ["Aickelin", "Uwe", ""], ["Ge", "Peiming", ""], ["Liu", "Gong", ""]]}, {"id": "2012.01266", "submitter": "Haojie Pan", "authors": "Haojie Pan, Chengyu Wang, Minghui Qiu, Yichang Zhang, Yaliang Li, Jun\n  Huang", "title": "Meta-KD: A Meta Knowledge Distillation Framework for Language Model\n  Compression across Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Pre-trained language models have been applied to various NLP tasks with\nconsiderable performance gains. However, the large model sizes, together with\nthe long inference time, limit the deployment of such models in real-time\napplications. Typical approaches consider knowledge distillation to distill\nlarge teacher models into small student models. However, most of these studies\nfocus on single-domain only, which ignores the transferable knowledge from\nother domains. We argue that training a teacher with transferable knowledge\ndigested across domains can achieve better generalization capability to help\nknowledge distillation. To this end, we propose a Meta-Knowledge Distillation\n(Meta-KD) framework to build a meta-teacher model that captures transferable\nknowledge across domains inspired by meta-learning and use it to pass knowledge\nto students. Specifically, we first leverage a cross-domain learning process to\ntrain the meta-teacher on multiple domains, and then propose a\nmeta-distillation algorithm to learn single-domain student models with guidance\nfrom the meta-teacher. Experiments on two public multi-domain NLP tasks show\nthe effectiveness and superiority of the proposed Meta-KD framework. We also\ndemonstrate the capability of Meta-KD in both few-shot and zero-shot learning\nsettings.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 15:18:37 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Pan", "Haojie", ""], ["Wang", "Chengyu", ""], ["Qiu", "Minghui", ""], ["Zhang", "Yichang", ""], ["Li", "Yaliang", ""], ["Huang", "Jun", ""]]}, {"id": "2012.01285", "submitter": "Jakob Prange", "authors": "Jakob Prange, Nathan Schneider, Vivek Srikumar", "title": "Supertagging the Long Tail with Tree-Structured Decoding of Complex\n  Categories", "comments": "Accepted to appear in TACL; Authors' final version, pre-MIT Press\n  publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although current CCG supertaggers achieve high accuracy on the standard WSJ\ntest set, few systems make use of the categories' internal structure that will\ndrive the syntactic derivation during parsing. The tagset is traditionally\ntruncated, discarding the many rare and complex category types in the long\ntail. However, supertags are themselves trees. Rather than give up on rare\ntags, we investigate constructive models that account for their internal\nstructure, including novel methods for tree-structured prediction. Our best\ntagger is capable of recovering a sizeable fraction of the long-tail supertags\nand even generates CCG categories that have never been seen in training, while\napproximating the prior state of the art in overall tag accuracy with fewer\nparameters. We further investigate how well different approaches generalize to\nout-of-domain evaluation sets.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 15:51:36 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 15:10:25 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Prange", "Jakob", ""], ["Schneider", "Nathan", ""], ["Srikumar", "Vivek", ""]]}, {"id": "2012.01288", "submitter": "Ana-Sabina Uban", "authors": "Ana-Sabina Uban, Alina-Maria Ciobanu, Liviu P. Dinu", "title": "A Computational Approach to Measuring the Semantic Divergence of\n  Cognates", "comments": null, "journal-ref": "20th International Conference on Computational Linguistics and\n  Intelligent Text Processing (CICLing 2019)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Meaning is the foundation stone of intercultural communication. Languages are\ncontinuously changing, and words shift their meanings for various reasons.\nSemantic divergence in related languages is a key concern of historical\nlinguistics. In this paper we investigate semantic divergence across languages\nby measuring the semantic similarity of cognate sets in multiple languages. The\nmethod that we propose is based on cross-lingual word embeddings. In this paper\nwe implement and evaluate our method on English and five Romance languages, but\nit can be extended easily to any language pair, requiring only large\nmonolingual corpora for the involved languages and a small bilingual dictionary\nfor the pair. This language-agnostic method facilitates a quantitative analysis\nof cognates divergence -- by computing degrees of semantic similarity between\ncognate pairs -- and provides insights for identifying false friends. As a\nsecond contribution, we formulate a straightforward method for detecting false\nfriends, and introduce the notion of \"soft false friend\" and \"hard false\nfriend\", as well as a measure of the degree of \"falseness\" of a false friends\npair. Additionally, we propose an algorithm that can output suggestions for\ncorrecting false friends, which could result in a very helpful tool for\nlanguage learning or translation.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 15:52:38 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Uban", "Ana-Sabina", ""], ["Ciobanu", "Alina-Maria", ""], ["Dinu", "Liviu P.", ""]]}, {"id": "2012.01295", "submitter": "Jing Su", "authors": "Jing Su, Chenghua Lin, Mian Zhou, Qingyun Dai, Haoyu Lv", "title": "Generating Descriptions for Sequential Images with Local-Object\n  Attention and Global Semantic Context Modelling", "comments": "Accepted by INLG 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an end-to-end CNN-LSTM model for generating\ndescriptions for sequential images with a local-object attention mechanism. To\ngenerate coherent descriptions, we capture global semantic context using a\nmulti-layer perceptron, which learns the dependencies between sequential\nimages. A paralleled LSTM network is exploited for decoding the sequence\ndescriptions. Experimental results show that our model outperforms the baseline\nacross three different evaluation metrics on the datasets published by\nMicrosoft.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 16:07:32 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Su", "Jing", ""], ["Lin", "Chenghua", ""], ["Zhou", "Mian", ""], ["Dai", "Qingyun", ""], ["Lv", "Haoyu", ""]]}, {"id": "2012.01300", "submitter": "Victor Sanh", "authors": "Victor Sanh, Thomas Wolf, Yonatan Belinkov, Alexander M. Rush", "title": "Learning from others' mistakes: Avoiding dataset biases without modeling\n  them", "comments": "15 pages, 6 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  State-of-the-art natural language processing (NLP) models often learn to\nmodel dataset biases and surface form correlations instead of features that\ntarget the intended underlying task. Previous work has demonstrated effective\nmethods to circumvent these issues when knowledge of the bias is available. We\nconsider cases where the bias issues may not be explicitly identified, and show\na method for training models that learn to ignore these problematic\ncorrelations. Our approach relies on the observation that models with limited\ncapacity primarily learn to exploit biases in the dataset. We can leverage the\nerrors of such limited capacity models to train a more robust model in a\nproduct of experts, thus bypassing the need to hand-craft a biased model. We\nshow the effectiveness of this method to retain improvements in\nout-of-distribution settings even if no particular bias is targeted by the\nbiased model.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 16:10:54 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Sanh", "Victor", ""], ["Wolf", "Thomas", ""], ["Belinkov", "Yonatan", ""], ["Rush", "Alexander M.", ""]]}, {"id": "2012.01305", "submitter": "Ana-Sabina Uban", "authors": "Liviu P. Dinu, Ana-Sabina Uban", "title": "Analyzing Stylistic Variation across Different Political Regimes", "comments": null, "journal-ref": "19th International Conference on Computational Linguistics and\n  Intelligent Text Processing (CICLing 2018)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this article we propose a stylistic analysis of texts written across two\ndifferent periods, which differ not only temporally, but politically and\nculturally: communism and democracy in Romania. We aim to analyze the stylistic\nvariation between texts written during these two periods, and determine at what\nlevels the variation is more apparent (if any): at the stylistic level, at the\ntopic level etc. We take a look at the stylistic profile of these texts\ncomparatively, by performing clustering and classification experiments on the\ntexts, using traditional authorship attribution methods and features. To\nconfirm the stylistic variation is indeed an effect of the change in political\nand cultural environment, and not merely reflective of a natural change in the\nauthor's style with time, we look at various stylistic metrics over time and\nshow that the change in style between the two periods is statistically\nsignificant. We also perform an analysis of the variation in topic between the\ntwo epochs, to compare with the variation at the style level. These analyses\nshow that texts from the two periods can indeed be distinguished, both from the\npoint of view of style and from that of semantic content (topic).\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 16:16:46 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Dinu", "Liviu P.", ""], ["Uban", "Ana-Sabina", ""]]}, {"id": "2012.01414", "submitter": "Revanth Reddy", "authors": "Revanth Gangi Reddy, Bhavani Iyer, Md Arafat Sultan, Rong Zhang, Avi\n  Sil, Vittorio Castelli, Radu Florian, Salim Roukos", "title": "End-to-End QA on COVID-19: Domain Adaptation with Synthetic Training", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  End-to-end question answering (QA) requires both information retrieval (IR)\nover a large document collection and machine reading comprehension (MRC) on the\nretrieved passages. Recent work has successfully trained neural IR systems\nusing only supervised question answering (QA) examples from open-domain\ndatasets. However, despite impressive performance on Wikipedia, neural IR lags\nbehind traditional term matching approaches such as BM25 in more specific and\nspecialized target domains such as COVID-19. Furthermore, given little or no\nlabeled data, effective adaptation of QA systems can also be challenging in\nsuch target domains. In this work, we explore the application of synthetically\ngenerated QA examples to improve performance on closed-domain retrieval and\nMRC. We combine our neural IR and MRC systems and show significant improvements\nin end-to-end QA on the CORD-19 collection over a state-of-the-art open-domain\nQA baseline.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 18:59:59 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Reddy", "Revanth Gangi", ""], ["Iyer", "Bhavani", ""], ["Sultan", "Md Arafat", ""], ["Zhang", "Rong", ""], ["Sil", "Avi", ""], ["Castelli", "Vittorio", ""], ["Florian", "Radu", ""], ["Roukos", "Salim", ""]]}, {"id": "2012.01462", "submitter": "Sabit Hassan", "authors": "Hamdy Mubarak and Sabit Hassan", "title": "ArCorona: Analyzing Arabic Tweets in the Early Days of Coronavirus\n  (COVID-19) Pandemic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the past few months, there were huge numbers of circulating tweets and\ndiscussions about Coronavirus (COVID-19) in the Arab region. It is important\nfor policy makers and many people to identify types of shared tweets to better\nunderstand public behavior, topics of interest, requests from governments,\nsources of tweets, etc. It is also crucial to prevent spreading of rumors and\nmisinformation about the virus or bad cures. To this end, we present the\nlargest manually annotated dataset of Arabic tweets related to COVID-19. We\ndescribe annotation guidelines, analyze our dataset and build effective machine\nlearning and transformer based models for classification.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 19:05:25 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2020 16:07:55 GMT"}, {"version": "v3", "created": "Mon, 1 Mar 2021 12:24:15 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Mubarak", "Hamdy", ""], ["Hassan", "Sabit", ""]]}, {"id": "2012.01524", "submitter": "Milan Aggarwal", "authors": "Madhur Panwar, Shashank Shailabh, Milan Aggarwal, Balaji Krishnamurthy", "title": "TAN-NTM: Topic Attention Networks for Neural Topic Modeling", "comments": "Accepted as a long paper at ACL 2021 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models have been widely used to learn text representations and gain\ninsight into document corpora. To perform topic discovery, most existing neural\nmodels either take document bag-of-words (BoW) or sequence of tokens as input\nfollowed by variational inference and BoW reconstruction to learn topic-word\ndistribution. However, leveraging topic-word distribution for learning better\nfeatures during document encoding has not been explored much. To this end, we\ndevelop a framework TAN-NTM, which processes document as a sequence of tokens\nthrough a LSTM whose contextual outputs are attended in a topic-aware manner.\nWe propose a novel attention mechanism which factors in topic-word distribution\nto enable the model to attend on relevant words that convey topic related cues.\nThe output of topic attention module is then used to carry out variational\ninference. We perform extensive ablations and experiments resulting in ~9-15\npercentage improvement over score of existing SOTA topic models in NPMI\ncoherence on several benchmark datasets - 20Newsgroups, Yelp Review Polarity\nand AGNews. Further, we show that our method learns better latent\ndocument-topic features compared to existing topic models through improvement\non two downstream tasks: document classification and topic guided keyphrase\ngeneration.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 20:58:04 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 10:32:01 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Panwar", "Madhur", ""], ["Shailabh", "Shashank", ""], ["Aggarwal", "Milan", ""], ["Krishnamurthy", "Balaji", ""]]}, {"id": "2012.01603", "submitter": "Maur\\'icio Gruppi", "authors": "Maur\\'icio Gruppi, Sibel Adali and Pin-Yu Chen", "title": "SChME at SemEval-2020 Task 1: A Model Ensemble for Detecting Lexical\n  Semantic Change", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes SChME (Semantic Change Detection with Model Ensemble), a\nmethod usedin SemEval-2020 Task 1 on unsupervised detection of lexical semantic\nchange. SChME usesa model ensemble combining signals of distributional models\n(word embeddings) and wordfrequency models where each model casts a vote\nindicating the probability that a word sufferedsemantic change according to\nthat feature. More specifically, we combine cosine distance of wordvectors\ncombined with a neighborhood-based metric we named Mapped Neighborhood\nDistance(MAP), and a word frequency differential metric as input signals to our\nmodel. Additionally,we explore alignment-based methods to investigate the\nimportance of the landmarks used in thisprocess. Our results show evidence that\nthe number of landmarks used for alignment has a directimpact on the predictive\nperformance of the model. Moreover, we show that languages that sufferless\nsemantic change tend to benefit from using a large number of landmarks, whereas\nlanguageswith more semantic change benefit from a more careful choice of\nlandmark number for alignment.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 23:56:34 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Gruppi", "Maur\u00edcio", ""], ["Adali", "Sibel", ""], ["Chen", "Pin-Yu", ""]]}, {"id": "2012.01631", "submitter": "Wei Zhang", "authors": "Wei Zhang and Murray Campbell and Yang Yu and Sadhana Kumaravel", "title": "Circles are like Ellipses, or Ellipses are like Circles? Measuring the\n  Degree of Asymmetry of Static and Contextual Embeddings and the Implications\n  to Representation Learning", "comments": "Accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human judgments of word similarity have been a popular method of evaluating\nthe quality of word embedding. But it fails to measure the geometry properties\nsuch as asymmetry. For example, it is more natural to say \"Ellipses are like\nCircles\" than \"Circles are like Ellipses\". Such asymmetry has been observed\nfrom a psychoanalysis test called word evocation experiment, where one word is\nused to recall another. Although useful, such experimental data have been\nsignificantly understudied for measuring embedding quality. In this paper, we\nuse three well-known evocation datasets to gain insights into asymmetry\nencoding of embedding. We study both static embedding as well as contextual\nembedding, such as BERT. Evaluating asymmetry for BERT is generally hard due to\nthe dynamic nature of embedding. Thus, we probe BERT's conditional\nprobabilities (as a language model) using a large number of Wikipedia contexts\nto derive a theoretically justifiable Bayesian asymmetry score. The result\nshows that contextual embedding shows randomness than static embedding on\nsimilarity judgments while performing well on asymmetry judgment, which aligns\nwith its strong performance on \"extrinsic evaluations\" such as text\nclassification. The asymmetry judgment and the Bayesian approach provides a new\nperspective to evaluate contextual embedding on intrinsic evaluation, and its\ncomparison to similarity evaluation concludes our work with a discussion on the\ncurrent state and the future of representation learning.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 01:48:37 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Zhang", "Wei", ""], ["Campbell", "Murray", ""], ["Yu", "Yang", ""], ["Kumaravel", "Sadhana", ""]]}, {"id": "2012.01675", "submitter": "Xu Guo", "authors": "Xu Guo, Pengwei Xing, Siwei Feng, Boyang Li, Chunyan Miao", "title": "Federated Learning with Diversified Preference for Humor Recognition", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding humor is critical to creative language modeling with many\napplications in human-AI interaction. However, due to differences in the\ncognitive systems of the audience, the perception of humor can be highly\nsubjective. Thus, a given passage can be regarded as funny to different degrees\nby different readers. This makes training humorous text recognition models that\ncan adapt to diverse humor preferences highly challenging. In this paper, we\npropose the FedHumor approach to recognize humorous text contents in a\npersonalized manner through federated learning (FL). It is a federated BERT\nmodel capable of jointly considering the overall distribution of humor scores\nwith humor labels by individuals for given texts. Extensive experiments\ndemonstrate significant advantages of FedHumor in recognizing humor contents\naccurately for people with diverse humor preferences compared to 9\nstate-of-the-art humor recognition approaches.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 03:24:24 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Guo", "Xu", ""], ["Xing", "Pengwei", ""], ["Feng", "Siwei", ""], ["Li", "Boyang", ""], ["Miao", "Chunyan", ""]]}, {"id": "2012.01687", "submitter": "Guangsen Wang", "authors": "Genta Indra Winata, Guangsen Wang, Caiming Xiong, Steven Hoi", "title": "Adapt-and-Adjust: Overcoming the Long-Tail Problem of Multilingual\n  Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One crucial challenge of real-world multilingual speech recognition is the\nlong-tailed distribution problem, where some resource-rich languages like\nEnglish have abundant training data, but a long tail of low-resource languages\nhave varying amounts of limited training data. To overcome the long-tail\nproblem, in this paper, we propose Adapt-and-Adjust (A2), a transformer-based\nmulti-task learning framework for end-to-end multilingual speech recognition.\nThe A2 framework overcomes the long-tail problem via three techniques: (1)\nexploiting a pretrained multilingual language model (mBERT) to improve the\nperformance of low-resource languages; (2) proposing dual adapters consisting\nof both language-specific and language-agnostic adaptation with minimal\nadditional parameters; and (3) overcoming the class imbalance, either by\nimposing class priors in the loss during training or adjusting the logits of\nthe softmax output during inference. Extensive experiments on the CommonVoice\ncorpus show that A2 significantly outperforms conventional approaches.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 03:46:16 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Winata", "Genta Indra", ""], ["Wang", "Guangsen", ""], ["Xiong", "Caiming", ""], ["Hoi", "Steven", ""]]}, {"id": "2012.01704", "submitter": "Zhengyuan Liu", "authors": "Zhengyuan Liu, Ke Shi, Nancy F. Chen", "title": "Multilingual Neural RST Discourse Parsing", "comments": "Published in COLING2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text discourse parsing plays an important role in understanding information\nflow and argumentative structure in natural language. Previous research under\nthe Rhetorical Structure Theory (RST) has mostly focused on inducing and\nevaluating models from the English treebank. However, the parsing tasks for\nother languages such as German, Dutch, and Portuguese are still challenging due\nto the shortage of annotated data. In this work, we investigate two approaches\nto establish a neural, cross-lingual discourse parser via: (1) utilizing\nmultilingual vector representations; and (2) adopting segment-level translation\nof the source content. Experiment results show that both methods are effective\neven with limited training data, and achieve state-of-the-art performance on\ncross-lingual, document-level discourse parsing on all sub-tasks.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 05:03:38 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Liu", "Zhengyuan", ""], ["Shi", "Ke", ""], ["Chen", "Nancy F.", ""]]}, {"id": "2012.01707", "submitter": "Pavan Kapanipathi", "authors": "Pavan Kapanipathi, Ibrahim Abdelaziz, Srinivas Ravishankar, Salim\n  Roukos, Alexander Gray, Ramon Astudillo, Maria Chang, Cristina Cornelio,\n  Saswati Dana, Achille Fokoue, Dinesh Garg, Alfio Gliozzo, Sairam Gurajada,\n  Hima Karanam, Naweed Khan, Dinesh Khandelwal, Young-Suk Lee, Yunyao Li,\n  Francois Luus, Ndivhuwo Makondo, Nandana Mihindukulasooriya, Tahira Naseem,\n  Sumit Neelam, Lucian Popa, Revanth Reddy, Ryan Riegel, Gaetano Rossiello,\n  Udit Sharma, G P Shrivatsa Bhargav, Mo Yu", "title": "Leveraging Abstract Meaning Representation for Knowledge Base Question\n  Answering", "comments": "Accepted to Findings of ACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge base question answering (KBQA)is an important task in Natural\nLanguage Processing. Existing approaches face significant challenges including\ncomplex question understanding, necessity for reasoning, and lack of large\nend-to-end training datasets. In this work, we propose Neuro-Symbolic Question\nAnswering (NSQA), a modular KBQA system, that leverages (1) Abstract Meaning\nRepresentation (AMR) parses for task-independent question understanding; (2) a\nsimple yet effective graph transformation approach to convert AMR parses into\ncandidate logical queries that are aligned to the KB; (3) a pipeline-based\napproach which integrates multiple, reusable modules that are trained\nspecifically for their individual tasks (semantic parser, entity\nandrelationship linkers, and neuro-symbolic reasoner) and do not require\nend-to-end training data. NSQA achieves state-of-the-art performance on two\nprominent KBQA datasets based on DBpedia (QALD-9 and LC-QuAD1.0). Furthermore,\nour analysis emphasizes that AMR is a powerful tool for KBQA systems.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 05:17:55 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 16:04:04 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Kapanipathi", "Pavan", ""], ["Abdelaziz", "Ibrahim", ""], ["Ravishankar", "Srinivas", ""], ["Roukos", "Salim", ""], ["Gray", "Alexander", ""], ["Astudillo", "Ramon", ""], ["Chang", "Maria", ""], ["Cornelio", "Cristina", ""], ["Dana", "Saswati", ""], ["Fokoue", "Achille", ""], ["Garg", "Dinesh", ""], ["Gliozzo", "Alfio", ""], ["Gurajada", "Sairam", ""], ["Karanam", "Hima", ""], ["Khan", "Naweed", ""], ["Khandelwal", "Dinesh", ""], ["Lee", "Young-Suk", ""], ["Li", "Yunyao", ""], ["Luus", "Francois", ""], ["Makondo", "Ndivhuwo", ""], ["Mihindukulasooriya", "Nandana", ""], ["Naseem", "Tahira", ""], ["Neelam", "Sumit", ""], ["Popa", "Lucian", ""], ["Reddy", "Revanth", ""], ["Riegel", "Ryan", ""], ["Rossiello", "Gaetano", ""], ["Sharma", "Udit", ""], ["Bhargav", "G P Shrivatsa", ""], ["Yu", "Mo", ""]]}, {"id": "2012.01721", "submitter": "Qingyi Si", "authors": "Qingyi Si, Yuanxin Liu, Peng Fu, Zheng Lin, Jiangnan Li and Weiping\n  Wang", "title": "Learning Class-Transductive Intent Representations for Zero-shot Intent\n  Detection", "comments": "IJCAI-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Zero-shot intent detection (ZSID) aims to deal with the continuously emerging\nintents without annotated training data. However, existing ZSID systems suffer\nfrom two limitations: 1) They are not good at modeling the relationship between\nseen and unseen intents. 2) They cannot effectively recognize unseen intents\nunder the generalized intent detection (GZSID) setting. A critical problem\nbehind these limitations is that the representations of unseen intents cannot\nbe learned in the training stage. To address this problem, we propose a novel\nframework that utilizes unseen class labels to learn Class-Transductive Intent\nRepresentations (CTIR). Specifically, we allow the model to predict unseen\nintents during training, with the corresponding label names serving as input\nutterances. On this basis, we introduce a multi-task learning objective, which\nencourages the model to learn the distinctions among intents, and a similarity\nscorer, which estimates the connections among intents more accurately. CTIR is\neasy to implement and can be integrated with existing methods. Experiments on\ntwo real-world datasets show that CTIR brings considerable improvement to the\nbaseline systems.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 06:41:09 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 18:18:33 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Si", "Qingyi", ""], ["Liu", "Yuanxin", ""], ["Fu", "Peng", ""], ["Lin", "Zheng", ""], ["Li", "Jiangnan", ""], ["Wang", "Weiping", ""]]}, {"id": "2012.01747", "submitter": "Prithwiraj Bhattacharjee", "authors": "Prithwiraj Bhattacharjee, Avi Mallick, Md Saiful Islam,\n  Marium-E-Jannat", "title": "Bengali Abstractive News Summarization(BANS): A Neural Attention\n  Approach", "comments": "10 Pages, 2 figures, 4 tables, 2nd International Conference on Trends\n  in Computational and Cognitive Engineering(TCCE-2020)", "journal-ref": "2nd International Conference on Trends in Computational and\n  Cognitive Engineering, 2020", "doi": "10.1007/978-981-33-4673-4_4", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstractive summarization is the process of generating novel sentences based\non the information extracted from the original text document while retaining\nthe context. Due to abstractive summarization's underlying complexities, most\nof the past research work has been done on the extractive summarization\napproach. Nevertheless, with the triumph of the sequence-to-sequence (seq2seq)\nmodel, abstractive summarization becomes more viable. Although a significant\nnumber of notable research has been done in the English language based on\nabstractive summarization, only a couple of works have been done on Bengali\nabstractive news summarization (BANS). In this article, we presented a seq2seq\nbased Long Short-Term Memory (LSTM) network model with attention at\nencoder-decoder. Our proposed system deploys a local attention-based model that\nproduces a long sequence of words with lucid and human-like generated sentences\nwith noteworthy information of the original document. We also prepared a\ndataset of more than 19k articles and corresponding human-written summaries\ncollected from bangla.bdnews24.com1 which is till now the most extensive\ndataset for Bengali news document summarization and publicly published in\nKaggle2. We evaluated our model qualitatively and quantitatively and compared\nit with other published results. It showed significant improvement in terms of\nhuman evaluation scores with state-of-the-art approaches for BANS.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 08:17:31 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Bhattacharjee", "Prithwiraj", ""], ["Mallick", "Avi", ""], ["Islam", "Md Saiful", ""], ["Marium-E-Jannat", "", ""]]}, {"id": "2012.01775", "submitter": "Xiaodong Gu", "authors": "Xiaodong Gu, Kang Min Yoo, Jung-Woo Ha", "title": "DialogBERT: Discourse-Aware Response Generation via Learning to Recover\n  and Rank Utterances", "comments": "Published as a conference paper at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent advances in pre-trained language models have significantly improved\nneural response generation. However, existing methods usually view the dialogue\ncontext as a linear sequence of tokens and learn to generate the next word\nthrough token-level self-attention. Such token-level encoding hinders the\nexploration of discourse-level coherence among utterances. This paper presents\nDialogBERT, a novel conversational response generation model that enhances\nprevious PLM-based dialogue models. DialogBERT employs a hierarchical\nTransformer architecture. To efficiently capture the discourse-level coherence\namong utterances, we propose two training objectives, including masked\nutterance regression and distributed utterance order ranking in analogy to the\noriginal BERT training. Experiments on three multi-turn conversation datasets\nshow that our approach remarkably outperforms the baselines, such as BART and\nDialoGPT, in terms of quantitative evaluation. The human evaluation suggests\nthat DialogBERT generates more coherent, informative, and human-like responses\nthan the baselines with significant margins.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 09:06:23 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Gu", "Xiaodong", ""], ["Yoo", "Kang Min", ""], ["Ha", "Jung-Woo", ""]]}, {"id": "2012.01786", "submitter": "Jiwei Li", "authors": "Zijun Sun, Chun Fan, Qinghong Han, Xiaofei Sun, Yuxian Meng, Fei Wu\n  and Jiwei Li", "title": "Self-Explaining Structures Improve NLP Models", "comments": "Code is available at\n  https://github.com/ShannonAI/Self_Explaining_Structures_Improve_NLP_Models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Existing approaches to explaining deep learning models in NLP usually suffer\nfrom two major drawbacks: (1) the main model and the explaining model are\ndecoupled: an additional probing or surrogate model is used to interpret an\nexisting model, and thus existing explaining tools are not self-explainable;\n(2) the probing model is only able to explain a model's predictions by\noperating on low-level features by computing saliency scores for individual\nwords but are clumsy at high-level text units such as phrases, sentences, or\nparagraphs. To deal with these two issues, in this paper, we propose a simple\nyet general and effective self-explaining framework for deep learning models in\nNLP. The key point of the proposed framework is to put an additional layer, as\nis called by the interpretation layer, on top of any existing NLP model. This\nlayer aggregates the information for each text span, which is then associated\nwith a specific weight, and their weighted combination is fed to the softmax\nfunction for the final prediction. The proposed model comes with the following\nmerits: (1) span weights make the model self-explainable and do not require an\nadditional probing model for interpretation; (2) the proposed model is general\nand can be adapted to any existing deep learning structures in NLP; (3) the\nweight associated with each text span provides direct importance scores for\nhigher-level text units such as phrases and sentences. We for the first time\nshow that interpretability does not come at the cost of performance: a neural\nmodel of self-explaining features obtains better performances than its\ncounterpart without the self-explaining nature, achieving a new SOTA\nperformance of 59.1 on SST-5 and a new SOTA performance of 92.3 on SNLI.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 09:32:05 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 02:08:38 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Sun", "Zijun", ""], ["Fan", "Chun", ""], ["Han", "Qinghong", ""], ["Sun", "Xiaofei", ""], ["Meng", "Yuxian", ""], ["Wu", "Fei", ""], ["Li", "Jiwei", ""]]}, {"id": "2012.01815", "submitter": "Jialun Cao", "authors": "Jialun Cao and Meiziniu Li and Yeting Li and Ming Wen and Shing-Chi\n  Cheung", "title": "SemMT: A Semantic-based Testing Approach for Machine Translation Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine translation has wide applications in daily life. In mission-critical\napplications such as translating official documents, incorrect translation can\nhave unpleasant or sometimes catastrophic consequences. This motivates recent\nresearch on testing methodologies for machine translation systems. Existing\nmethodologies mostly rely on metamorphic relations designed at the textual\nlevel (e.g., Levenshtein distance) or syntactic level (e.g., the distance\nbetween grammar structures) to determine the correctness of translation\nresults. However, these metamorphic relations do not consider whether the\noriginal and translated sentences have the same meaning (i.e., Semantic\nsimilarity). Therefore, in this paper, we propose SemMT, an automatic testing\napproach for machine translation systems based on semantic similarity checking.\nSemMT applies round-trip translation and measures the semantic similarity\nbetween the original and translated sentences. Our insight is that the\nsemantics expressed by the logic and numeric constraint in sentences can be\ncaptured using regular expressions (or deterministic finite automata) where\nefficient equivalence/similarity checking algorithms are available. Leveraging\nthe insight, we propose three semantic similarity metrics and implement them in\nSemMT. The experiment result reveals SemMT can achieve higher effectiveness\ncompared with state-of-the-art works, achieving an increase of 21% and 23% on\naccuracy and F-Score, respectively. We also explore potential improvements that\ncan be achieved when proper combinations of metrics are adopted. Finally, we\ndiscuss a solution to locate the suspicious trip in round-trip translation,\nwhich may shed lights on further exploration.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 10:42:56 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Cao", "Jialun", ""], ["Li", "Meiziniu", ""], ["Li", "Yeting", ""], ["Wen", "Ming", ""], ["Cheung", "Shing-Chi", ""]]}, {"id": "2012.01873", "submitter": "Kaustubh Dhole", "authors": "Ashish Shrivastava, Kaustubh Dhole, Abhinav Bhatt, Sharvani Raghunath", "title": "Saying No is An Art: Contextualized Fallback Responses for Unanswerable\n  Dialogue Queries", "comments": "ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite end-to-end neural systems making significant progress in the last\ndecade for task-oriented as well as chit-chat based dialogue systems, most\ndialogue systems rely on hybrid approaches which use a combination of\nrule-based, retrieval and generative approaches for generating a set of ranked\nresponses. Such dialogue systems need to rely on a fallback mechanism to\nrespond to out-of-domain or novel user queries which are not answerable within\nthe scope of the dialog system. While, dialog systems today rely on static and\nunnatural responses like \"I don't know the answer to that question\" or \"I'm not\nsure about that\", we design a neural approach which generates responses which\nare contextually aware with the user query as well as say no to the user. Such\ncustomized responses provide paraphrasing ability and contextualization as well\nas improve the interaction with the user and reduce dialogue monotonicity. Our\nsimple approach makes use of rules over dependency parses and a text-to-text\ntransformer fine-tuned on synthetic data of question-response pairs generating\nhighly relevant, grammatical as well as diverse questions. We perform automatic\nand manual evaluations to demonstrate the efficacy of the system.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 12:34:22 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 12:08:45 GMT"}, {"version": "v3", "created": "Thu, 6 May 2021 07:40:16 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Shrivastava", "Ashish", ""], ["Dhole", "Kaustubh", ""], ["Bhatt", "Abhinav", ""], ["Raghunath", "Sharvani", ""]]}, {"id": "2012.01878", "submitter": "Shiyao Cui", "authors": "Shiyao Cui, Bowen Yu, Xin Cong, Tingwen Liu, Quangang Li and Jinqiao\n  Shi", "title": "Label Enhanced Event Detection with Heterogeneous Graph Attention\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event Detection (ED) aims to recognize instances of specified types of event\ntriggers in text. Different from English ED, Chinese ED suffers from the\nproblem of word-trigger mismatch due to the uncertain word boundaries. Existing\napproaches injecting word information into character-level models have achieved\npromising progress to alleviate this problem, but they are limited by two\nissues. First, the interaction between characters and lexicon words is not\nfully exploited. Second, they ignore the semantic information provided by event\nlabels. We thus propose a novel architecture named Label enhanced Heterogeneous\nGraph Attention Networks (L-HGAT). Specifically, we transform each sentence\ninto a graph, where character nodes and word nodes are connected with different\ntypes of edges, so that the interaction between words and characters is fully\nreserved. A heterogeneous graph attention networks is then introduced to\npropagate relational message and enrich information interaction. Furthermore,\nwe convert each label into a trigger-prototype-based embedding, and design a\nmargin loss to guide the model distinguish confusing event labels. Experiments\non two benchmark datasets show that our model achieves significant improvement\nover a range of competitive baseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 12:49:22 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Cui", "Shiyao", ""], ["Yu", "Bowen", ""], ["Cong", "Xin", ""], ["Liu", "Tingwen", ""], ["Li", "Quangang", ""], ["Shi", "Jinqiao", ""]]}, {"id": "2012.01936", "submitter": "Oleg Kariuk", "authors": "Oleg Kariuk and Dima Karamshuk", "title": "CUT: Controllable Unsupervised Text Simplification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on the challenge of learning controllable text\nsimplifications in unsupervised settings. While this problem has been\npreviously discussed for supervised learning algorithms, the literature on the\nanalogies in unsupervised methods is scarse. We propose two unsupervised\nmechanisms for controlling the output complexity of the generated texts,\nnamely, back translation with control tokens (a learning-based approach) and\nsimplicity-aware beam search (decoding-based approach). We show that by nudging\na back-translation algorithm to understand the relative simplicity of a text in\ncomparison to its noisy translation, the algorithm self-supervises itself to\nproduce the output of the desired complexity. This approach achieves\ncompetitive performance on well-established benchmarks: SARI score of 46.88%\nand FKGL of 3.65% on the Newsela dataset.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 14:14:30 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Kariuk", "Oleg", ""], ["Karamshuk", "Dima", ""]]}, {"id": "2012.01941", "submitter": "Adam Hare", "authors": "Adam Hare, Yu Chen, Yinan Liu, Zhenming Liu, Christopher G. Brinton", "title": "On Extending NLP Techniques from the Categorical to the Latent Space: KL\n  Divergence, Zipf's Law, and Similarity Search", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent successes of deep learning in natural language processing\n(NLP), there remains widespread usage of and demand for techniques that do not\nrely on machine learning. The advantage of these techniques is their\ninterpretability and low cost when compared to frequently opaque and expensive\nmachine learning models. Although they may not be be as performant in all\ncases, they are often sufficient for common and relatively simple problems. In\nthis paper, we aim to modernize these older methods while retaining their\nadvantages by extending approaches from categorical or bag-of-words\nrepresentations to word embeddings representations in the latent space. First,\nwe show that entropy and Kullback-Leibler divergence can be efficiently\nestimated using word embeddings and use this estimation to compare text across\nseveral categories. Next, we recast the heavy-tailed distribution known as\nZipf's law that is frequently observed in the categorical space to the latent\nspace. Finally, we look to improve the Jaccard similarity measure for sentence\nsuggestion by introducing a new method of identifying similar sentences based\non the set cover problem. We compare the performance of this algorithm against\nseveral baselines including Word Mover's Distance and the Levenshtein distance.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 17:35:49 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Hare", "Adam", ""], ["Chen", "Yu", ""], ["Liu", "Yinan", ""], ["Liu", "Zhenming", ""], ["Brinton", "Christopher G.", ""]]}, {"id": "2012.01942", "submitter": "Fuqi Song", "authors": "Fuqi Song and \\'Eric de la Clergerie", "title": "Clustering-based Automatic Construction of Legal Entity Knowledge Base\n  from Contracts", "comments": "4 pages, 3 figures", "journal-ref": null, "doi": "10.1109/BigData50022.2020.9378166", "report-no": null, "categories": "cs.CL cs.AI cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In contract analysis and contract automation, a knowledge base (KB) of legal\nentities is fundamental for performing tasks such as contract verification,\ncontract generation and contract analytic. However, such a KB does not always\nexist nor can be produced in a short time. In this paper, we propose a\nclustering-based approach to automatically generate a reliable knowledge base\nof legal entities from given contracts without any supplemental references. The\nproposed method is robust to different types of errors brought by\npre-processing such as Optical Character Recognition (OCR) and Named Entity\nRecognition (NER), as well as editing errors such as typos. We evaluate our\nmethod on a dataset that consists of 800 real contracts with various qualities\nfrom 15 clients. Compared to the collected ground-truth data, our method is\nable to recall 84\\% of the knowledge.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 17:51:27 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 09:49:26 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Song", "Fuqi", ""], ["de la Clergerie", "\u00c9ric", ""]]}, {"id": "2012.01953", "submitter": "Carlos Badenes-Olmedo", "authors": "Carlos Badenes-Olmedo, David Chaves-Fraga, Mar\\'Ia Poveda-Villal\\'On,\n  Ana Iglesias-Molina, Pablo Calleja, Socorro Bernardos, Patricia\n  Mart\\'In-Chozas, Alba Fern\\'andez-Izquierdo, Elvira Amador-Dom\\'inguez, Paola\n  Espinoza-Arias, Luis Pozo, Edna Ruckhaus, Esteban Gonz\\'alez-Guardia, Raquel\n  Cedazo, Beatriz L\\'opez-Centeno, and Oscar Corcho", "title": "Drugs4Covid: Drug-driven Knowledge Exploitation based on Scientific\n  Publications", "comments": "Ontology-based technologies, NLP, Bio-annotations, Drugs-catalogue,\n  Knowledge Graph, COVID-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the absence of sufficient medication for COVID patients due to the\nincreased demand, disused drugs have been employed or the doses of those\navailable were modified by hospital pharmacists. Some evidences for the use of\nalternative drugs can be found in the existing scientific literature that could\nassist in such decisions. However, exploiting large corpus of documents in an\nefficient manner is not easy, since drugs may not appear explicitly related in\nthe texts and could be mentioned under different brand names. Drugs4Covid\ncombines word embedding techniques and semantic web technologies to enable a\ndrug-oriented exploration of large medical literature. Drugs and diseases are\nidentified according to the ATC classification and MeSH categories\nrespectively. More than 60K articles and 2M paragraphs have been processed from\nthe CORD-19 corpus with information of COVID-19, SARS, and other related\ncoronaviruses. An open catalogue of drugs has been created and results are\npublicly available through a drug browser, a keyword-guided text explorer, and\na knowledge graph.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 14:26:54 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Badenes-Olmedo", "Carlos", ""], ["Chaves-Fraga", "David", ""], ["Poveda-Villal\u00d3n", "Mar\u00cda", ""], ["Iglesias-Molina", "Ana", ""], ["Calleja", "Pablo", ""], ["Bernardos", "Socorro", ""], ["Mart\u00cdn-Chozas", "Patricia", ""], ["Fern\u00e1ndez-Izquierdo", "Alba", ""], ["Amador-Dom\u00ednguez", "Elvira", ""], ["Espinoza-Arias", "Paola", ""], ["Pozo", "Luis", ""], ["Ruckhaus", "Edna", ""], ["Gonz\u00e1lez-Guardia", "Esteban", ""], ["Cedazo", "Raquel", ""], ["L\u00f3pez-Centeno", "Beatriz", ""], ["Corcho", "Oscar", ""]]}, {"id": "2012.02012", "submitter": "Yushi Guan", "authors": "Yushi Guan", "title": "End to End ASR System with Automatic Punctuation Insertion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent Automatic Speech Recognition systems have been moving towards\nend-to-end systems that can be trained together. Numerous techniques that have\nbeen proposed recently enabled this trend, including feature extraction with\nCNNs, context capturing and acoustic feature modeling with RNNs, automatic\nalignment of input and output sequences using Connectionist Temporal\nClassifications, as well as replacing traditional n-gram language models with\nRNN Language Models. Historically, there has been a lot of interest in\nautomatic punctuation in textual or speech to text context. However, there\nseems to be little interest in incorporating automatic punctuation into the\nemerging neural network based end-to-end speech recognition systems, partially\ndue to the lack of English speech corpus with punctuated transcripts. In this\nstudy, we propose a method to generate punctuated transcript for the TEDLIUM\ndataset using transcripts available from ted.com. We also propose an end-to-end\nASR system that outputs words and punctuations concurrently from speech\nsignals. Combining Damerau Levenshtein Distance and slot error rate into\nDLev-SER, we enable measurement of punctuation error rate when the hypothesis\ntext is not perfectly aligned with the reference. Compared with previous\nmethods, our model reduces slot error rate from 0.497 to 0.341.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 15:46:43 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Guan", "Yushi", ""]]}, {"id": "2012.02015", "submitter": "Esther Van Den Berg", "authors": "Esther van den Berg and Katja Markert", "title": "Context in Informational Bias Detection", "comments": "Accepted to COLING'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Informational bias is bias conveyed through sentences or clauses that provide\ntangential, speculative or background information that can sway readers'\nopinions towards entities. By nature, informational bias is context-dependent,\nbut previous work on informational bias detection has not explored the role of\ncontext beyond the sentence. In this paper, we explore four kinds of context\nfor informational bias in English news articles: neighboring sentences, the\nfull article, articles on the same event from other news publishers, and\narticles from the same domain (but potentially different events). We find that\nintegrating event context improves classification performance over a very\nstrong baseline. In addition, we perform the first error analysis of models on\nthis task. We find that the best-performing context-inclusive model outperforms\nthe baseline on longer sentences, and sentences from politically centrist\narticles.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 15:50:20 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Berg", "Esther van den", ""], ["Markert", "Katja", ""]]}, {"id": "2012.02028", "submitter": "Po-Hsu Allen Chen", "authors": "Po-Hsu Allen Chen, Amy Leibrand, Jordan Vasko, Mitch Gauthier", "title": "Ontology-based and User-focused Automatic Text Summarization (OATS):\n  Using COVID-19 Risk Factors as an Example", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a novel Ontology-based and user-focused Automatic Text\nSummarization (OATS) system, in the setting where the goal is to automatically\ngenerate text summarization from unstructured text by extracting sentences\ncontaining the information that aligns to the user's focus. OATS consists of\ntwo modules: ontology-based topic identification and user-focused text\nsummarization; it first utilizes an ontology-based approach to identify\nrelevant documents to user's interest, and then takes advantage of the answers\nextracted from a question answering model using questions specified from users\nfor the generation of text summarization. To support the fight against the\nCOVID-19 pandemic, we used COVID-19 risk factors as an example to demonstrate\nthe proposed OATS system with the aim of helping the medical community\naccurately identify relevant scientific literature and efficiently review the\ninformation that addresses risk factors related to COVID-19.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 20:15:01 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Chen", "Po-Hsu Allen", ""], ["Leibrand", "Amy", ""], ["Vasko", "Jordan", ""], ["Gauthier", "Mitch", ""]]}, {"id": "2012.02029", "submitter": "Swati Padhee", "authors": "Swati Padhee, Anurag Illendula, Megan Sadler, Valerie L.Shalin, Tanvi\n  Banerjee, Krishnaprasad Thirunarayan, William L. Romine", "title": "Predicting Early Indicators of Cognitive Decline from Verbal Utterances", "comments": "Camera-ready paper accepted for publication at IEEE BIBM 2020", "journal-ref": null, "doi": null, "report-no": "IEEE BIBM 2020 paper ID B686", "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dementia is a group of irreversible, chronic, and progressive\nneurodegenerative disorders resulting in impaired memory, communication, and\nthought processes. In recent years, clinical research advances in brain aging\nhave focused on the earliest clinically detectable stage of incipient dementia,\ncommonly known as mild cognitive impairment (MCI). Currently, these disorders\nare diagnosed using a manual analysis of neuropsychological examinations. We\nmeasure the feasibility of using the linguistic characteristics of verbal\nutterances elicited during neuropsychological exams of elderly subjects to\ndistinguish between elderly control groups, people with MCI, people diagnosed\nwith possible Alzheimer's disease (AD), and probable AD. We investigated the\nperformance of both theory-driven psycholinguistic features and data-driven\ncontextual language embeddings in identifying different clinically diagnosed\ngroups. Our experiments show that a combination of contextual and\npsycholinguistic features extracted by a Support Vector Machine improved\ndistinguishing the verbal utterances of elderly controls, people with MCI,\npossible AD, and probable AD. This is the first work to identify four clinical\ndiagnosis groups of dementia in a highly imbalanced dataset. Our work shows\nthat machine learning algorithms built on contextual and psycholinguistic\nfeatures can learn the linguistic biomarkers from verbal utterances and assist\nclinical diagnosis of different stages and types of dementia, even with limited\ndata.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 02:24:11 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 14:42:59 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Padhee", "Swati", ""], ["Illendula", "Anurag", ""], ["Sadler", "Megan", ""], ["Shalin", "Valerie L.", ""], ["Banerjee", "Tanvi", ""], ["Thirunarayan", "Krishnaprasad", ""], ["Romine", "William L.", ""]]}, {"id": "2012.02030", "submitter": "Rumen Dangovski", "authors": "Ileana Rugina, Rumen Dangovski, Li Jing, Preslav Nakov, Marin\n  Solja\\v{c}i\\'c", "title": "Data-Informed Global Sparseness in Attention Mechanisms for Deep Neural\n  Networks", "comments": "13 pages, 6 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The attention mechanism is a key component of the neural revolution in\nNatural Language Processing (NLP). As the size of attention-based models has\nbeen scaling with the available computational resources, a number of pruning\ntechniques have been developed to detect and to exploit sparseness in such\nmodels in order to make them more efficient. The majority of such efforts have\nfocused on looking for attention patterns and then hard-coding them to achieve\nsparseness, or pruning the weights of the attention mechanisms based on\nstatistical information from the training data. Here, we marry these two lines\nof research by proposing Attention Pruning (AP): a novel pruning framework that\ncollects observations about the attention patterns in a fixed dataset and then\ninduces a global sparseness mask for the model. This can save 90% of the\nattention computation for language modelling and about 50% for machine\ntranslation and for solving GLUE tasks, while maintaining the quality of the\nresults. Moreover, using our method, we discovered important distinctions\nbetween self- and cross-attention patterns, which could guide future NLP\nresearch in attention-based modelling. Our framework can in principle speed up\nany model that uses attention mechanism, thus helping develop better models for\nexisting or for new NLP applications. Our implementation is available at\nhttps://github.com/irugina/AP.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 13:58:21 GMT"}, {"version": "v2", "created": "Sat, 8 May 2021 23:24:17 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Rugina", "Ileana", ""], ["Dangovski", "Rumen", ""], ["Jing", "Li", ""], ["Nakov", "Preslav", ""], ["Solja\u010di\u0107", "Marin", ""]]}, {"id": "2012.02038", "submitter": "Karthikeya Ramesh Kaushik", "authors": "Karthikeya Ramesh Kaushik, Andrea E. Martin", "title": "Modelling Compositionality and Structure Dependence in Natural Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human beings possess the most sophisticated computational machinery in the\nknown universe. We can understand language of rich descriptive power, and\ncommunicate in the same environment with astonishing clarity. Two of the many\ncontributors to the interest in natural language - the properties of\nCompositionality and Structure Dependence, are well documented, and offer a\nvast space to ask interesting modelling questions. The first step to begin\nanswering these questions is to ground verbal theory in formal terms. Drawing\non linguistics and set theory, a formalisation of these ideas is presented in\nthe first half of this thesis. We see how cognitive systems that process\nlanguage need to have certain functional constraints, viz. time based,\nincremental operations that rely on a structurally defined domain. The\nobservations that result from analysing this formal setup are examined as part\nof a modelling exercise. Using the advances of word embedding techniques, a\nmodel of relational learning is simulated with a custom dataset to demonstrate\nhow a time based role-filler binding mechanism satisfies some of the\nconstraints described in the first section. The model's ability to map\nstructure, along with its symbolic-connectionist architecture makes for a\ncognitively plausible implementation. The formalisation and simulation are\ntogether an attempt to recognise the constraints imposed by linguistic theory,\nand explore the opportunities presented by a cognitive model of relation\nlearning to realise these constraints.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 17:28:50 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 17:14:13 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Kaushik", "Karthikeya Ramesh", ""], ["Martin", "Andrea E.", ""]]}, {"id": "2012.02104", "submitter": "Manuel Francisco", "authors": "Manuel Francisco and Juan Luis Castro", "title": "Discriminatory Expressions to Produce Interpretable Models in Short\n  Documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Social Networking Sites (SNS) are one of the most important ways of\ncommunication. In particular, microblogging sites are being used as analysis\navenues due to their peculiarities (promptness, short texts...). There are\ncountless researches that use SNS in novel manners, but machine learning has\nfocused mainly in classification performance rather than interpretability\nand/or other goodness metrics. Thus, state-of-the-art models are black boxes\nthat should not be used to solve problems that may have a social impact. When\nthe problem requires transparency, it is necessary to build interpretable\npipelines. Although the classifier may be interpretable, resulting models are\ntoo complex to be considered comprehensible, making it impossible for humans to\nunderstand the actual decisions. This paper presents a feature selection\nmechanism that is able to improve comprehensibility by using less but more\nmeaningful features while achieving good performance in microblogging contexts\nwhere interpretability is mandatory. Moreover, we present a ranking method to\nevaluate features in terms of statistical relevance and bias. We conducted\nexhaustive tests with five different datasets in order to evaluate\nclassification performance, generalisation capacity and complexity of the\nmodel. Results show that our proposal is better and the most stable one in\nterms of accuracy, generalisation and comprehensibility.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 19:00:50 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 14:25:09 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Francisco", "Manuel", ""], ["Castro", "Juan Luis", ""]]}, {"id": "2012.02110", "submitter": "Raphael Scheible", "authors": "Raphael Scheible, Fabian Thomczyk, Patric Tippmann, Victor Jaravine,\n  Martin Boeker", "title": "GottBERT: a pure German Language Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lately, pre-trained language models advanced the field of natural language\nprocessing (NLP). The introduction of Bidirectional Encoders for Transformers\n(BERT) and its optimized version RoBERTa have had significant impact and\nincreased the relevance of pre-trained models. First, research in this field\nmainly started on English data followed by models trained with multilingual\ntext corpora. However, current research shows that multilingual models are\ninferior to monolingual models. Currently, no German single language RoBERTa\nmodel is yet published, which we introduce in this work (GottBERT). The German\nportion of the OSCAR data set was used as text corpus. In an evaluation we\ncompare its performance on the two Named Entity Recognition (NER) tasks Conll\n2003 and GermEval 2014 as well as on the text classification tasks GermEval\n2018 (fine and coarse) and GNAD with existing German single language BERT\nmodels and two multilingual ones. GottBERT was pre-trained related to the\noriginal RoBERTa model using fairseq. All downstream tasks were trained using\nhyperparameter presets taken from the benchmark of German BERT. The experiments\nwere setup utilizing FARM. Performance was measured by the $F_{1}$ score.\nGottBERT was successfully pre-trained on a 256 core TPU pod using the RoBERTa\nBASE architecture. Even without extensive hyper-parameter optimization, in all\nNER and one text classification task, GottBERT already outperformed all other\ntested German and multilingual models. In order to support the German NLP\nfield, we publish GottBERT under the AGPLv3 license.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 17:45:03 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Scheible", "Raphael", ""], ["Thomczyk", "Fabian", ""], ["Tippmann", "Patric", ""], ["Jaravine", "Victor", ""], ["Boeker", "Martin", ""]]}, {"id": "2012.02128", "submitter": "Jing Su", "authors": "Jing Su, Qingyun Dai, Frank Guerin, Mian Zhou", "title": "BERT-hLSTMs: BERT and Hierarchical LSTMs for Visual Storytelling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual storytelling is a creative and challenging task, aiming to\nautomatically generate a story-like description for a sequence of images. The\ndescriptions generated by previous visual storytelling approaches lack\ncoherence because they use word-level sequence generation methods and do not\nadequately consider sentence-level dependencies. To tackle this problem, we\npropose a novel hierarchical visual storytelling framework which separately\nmodels sentence-level and word-level semantics. We use the transformer-based\nBERT to obtain embeddings for sentences and words. We then employ a\nhierarchical LSTM network: the bottom LSTM receives as input the sentence\nvector representation from BERT, to learn the dependencies between the\nsentences corresponding to images, and the top LSTM is responsible for\ngenerating the corresponding word vector representations, taking input from the\nbottom LSTM. Experimental results demonstrate that our model outperforms most\nclosely related baselines under automatic evaluation metrics BLEU and CIDEr,\nand also show the effectiveness of our method with human evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 18:07:28 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Su", "Jing", ""], ["Dai", "Qingyun", ""], ["Guerin", "Frank", ""], ["Zhou", "Mian", ""]]}, {"id": "2012.02144", "submitter": "Wen Xiao", "authors": "Wen Xiao, Patrick Huber, Giuseppe Carenini", "title": "Do We Really Need That Many Parameters In Transformer For Extractive\n  Summarization? Discourse Can Help !", "comments": "In the Proceeding of 1st Workshop on Computational Approaches to\n  Discourse (CODI) at EMNLP 2020. 11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The multi-head self-attention of popular transformer models is widely used\nwithin Natural Language Processing (NLP), including for the task of extractive\nsummarization. With the goal of analyzing and pruning the parameter-heavy\nself-attention mechanism, there are multiple approaches proposing more\nparameter-light self-attention alternatives. In this paper, we present a novel\nparameter-lean self-attention mechanism using discourse priors. Our new tree\nself-attention is based on document-level discourse information, extending the\nrecently proposed \"Synthesizer\" framework with another lightweight alternative.\nWe show empirical results that our tree self-attention approach achieves\ncompetitive ROUGE-scores on the task of extractive summarization. When compared\nto the original single-head transformer model, the tree attention approach\nreaches similar performance on both, EDU and sentence level, despite the\nsignificant reduction of parameters in the attention component. We further\nsignificantly outperform the 8-head transformer model on sentence level when\napplying a more balanced hyper-parameter setting, requiring an order of\nmagnitude less parameters.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 18:23:21 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Xiao", "Wen", ""], ["Huber", "Patrick", ""], ["Carenini", "Giuseppe", ""]]}, {"id": "2012.02197", "submitter": "Martin Muller", "authors": "Martin M\\\"uller, Marcel Salath\\'e", "title": "Addressing machine learning concept drift reveals declining vaccine\n  sentiment during the COVID-19 pandemic", "comments": "9 pages, 4 figures, 3 pages of SI; Minor correction in Figure 1:\n  Bracket was not visible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social media analysis has become a common approach to assess public opinion\non various topics, including those about health, in near real-time. The growing\nvolume of social media posts has led to an increased usage of modern machine\nlearning methods in natural language processing. While the rapid dynamics of\nsocial media can capture underlying trends quickly, it also poses a technical\nproblem: algorithms trained on annotated data in the past may underperform when\napplied to contemporary data. This phenomenon, known as concept drift, can be\nparticularly problematic when rapid shifts occur either in the topic of\ninterest itself, or in the way the topic is discussed. Here, we explore the\neffect of machine learning concept drift by focussing on vaccine sentiments\nexpressed on Twitter, a topic of central importance especially during the\nCOVID-19 pandemic. We show that while vaccine sentiment has declined\nconsiderably during the COVID-19 pandemic in 2020, algorithms trained on\npre-pandemic data would have largely missed this decline due to concept drift.\nOur results suggest that social media analysis systems must address concept\ndrift in a continuous fashion in order to avoid the risk of systematic\nmisclassification of data, which is particularly likely during a crisis when\nthe underlying data can change suddenly and rapidly.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 18:53:57 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 11:28:31 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["M\u00fcller", "Martin", ""], ["Salath\u00e9", "Marcel", ""]]}, {"id": "2012.02221", "submitter": "Puyuan Peng", "authors": "Puyuan Peng, Herman Kamper, Karen Livescu", "title": "A Correspondence Variational Autoencoder for Unsupervised Acoustic Word\n  Embeddings", "comments": "10 pages, 6 figures, NeurIPS 2020 Workshop Self-Supervised Learning\n  for Speech and Audio Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new unsupervised model for mapping a variable-duration speech\nsegment to a fixed-dimensional representation. The resulting acoustic word\nembeddings can form the basis of search, discovery, and indexing systems for\nlow- and zero-resource languages. Our model, which we refer to as a maximal\nsampling correspondence variational autoencoder (MCVAE), is a recurrent neural\nnetwork (RNN) trained with a novel self-supervised correspondence loss that\nencourages consistency between embeddings of different instances of the same\nword. Our training scheme improves on previous correspondence training\napproaches through the use and comparison of multiple samples from the\napproximate posterior distribution. In the zero-resource setting, the MCVAE can\nbe trained in an unsupervised way, without any ground-truth word pairs, by\nusing the word-like segments discovered via an unsupervised term discovery\nsystem. In both this setting and a semi-supervised low-resource setting (with a\nlimited set of ground-truth word pairs), the MCVAE outperforms previous\nstate-of-the-art models, such as Siamese-, CAE- and VAE-based RNNs.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 19:24:42 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Peng", "Puyuan", ""], ["Kamper", "Herman", ""], ["Livescu", "Karen", ""]]}, {"id": "2012.02223", "submitter": "Trevor Londt", "authors": "Trevor Londt, Xiaoying Gao, Bing Xue, Peter Andreae", "title": "Evolving Character-level Convolutional Neural Networks for Text\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Character-level convolutional neural networks (char-CNN) require no knowledge\nof the semantic or syntactic structure of the language they classify. This\nproperty simplifies its implementation but reduces its classification accuracy.\nIncreasing the depth of char-CNN architectures does not result in breakthrough\naccuracy improvements. Research has not established which char-CNN\narchitectures are optimal for text classification tasks. Manually designing and\ntraining char-CNNs is an iterative and time-consuming process that requires\nexpert domain knowledge. Evolutionary deep learning (EDL) techniques, including\nsurrogate-based versions, have demonstrated success in automatically searching\nfor performant CNN architectures for image analysis tasks. Researchers have not\napplied EDL techniques to search the architecture space of char-CNNs for text\nclassification tasks. This article demonstrates the first work in evolving\nchar-CNN architectures using a novel EDL algorithm based on genetic\nprogramming, an indirect encoding and surrogate models, to search for\nperformant char-CNN architectures automatically. The algorithm is evaluated on\neight text classification datasets and benchmarked against five manually\ndesigned CNN architecture and one long short-term memory (LSTM) architecture.\nExperiment results indicate that the algorithm can evolve architectures that\noutperform the LSTM in terms of classification accuracy and five of the\nmanually designed CNN architectures in terms of classification accuracy and\nparameter count.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 19:27:29 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Londt", "Trevor", ""], ["Gao", "Xiaoying", ""], ["Xue", "Bing", ""], ["Andreae", "Peter", ""]]}, {"id": "2012.02287", "submitter": "Allen Schmaltz", "authors": "Allen Schmaltz and Andrew Beam", "title": "Coarse-to-Fine Memory Matching for Joint Retrieval and Classification", "comments": "19 pages, 3 figures, 7 tables (main: 11 pages, 2 figures, 4 tables)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel end-to-end language model for joint retrieval and\nclassification, unifying the strengths of bi- and cross- encoders into a single\nlanguage model via a coarse-to-fine memory matching search procedure for\nlearning and inference. Evaluated on the standard blind test set of the FEVER\nfact verification dataset, classification accuracy is significantly higher than\napproaches that only rely on the language model parameters as a knowledge base,\nand approaches some recent multi-model pipeline systems, using only a single\nBERT base model augmented with memory layers. We further demonstrate how\ncoupled retrieval and classification can be leveraged to identify low\nconfidence instances, and we extend exemplar auditing to this setting for\nanalyzing and constraining the model. As a result, our approach yields a means\nof updating language model behavior through two distinct mechanisms: The\nretrieved information can be updated explicitly, and the model behavior can be\nmodified via the exemplar database.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 05:06:03 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Schmaltz", "Allen", ""], ["Beam", "Andrew", ""]]}, {"id": "2012.02297", "submitter": "Burcu Sayin", "authors": "Evgeny Krivosheev, Burcu Sayin, Alessandro Bozzon, Zolt\\'an Szl\\'avik", "title": "Active Learning from Crowd in Document Screening", "comments": "Crowd Science Workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we explore how to efficiently combine crowdsourcing and\nmachine intelligence for the problem of document screening, where we need to\nscreen documents with a set of machine-learning filters. Specifically, we focus\non building a set of machine learning classifiers that evaluate documents, and\nthen screen them efficiently. It is a challenging task since the budget is\nlimited and there are countless number of ways to spend the given budget on the\nproblem. We propose a multi-label active learning screening specific sampling\ntechnique -- objective-aware sampling -- for querying unlabelled documents for\nannotating. Our algorithm takes a decision on which machine filter need more\ntraining data and how to choose unlabeled items to annotate in order to\nminimize the risk of overall classification errors rather than minimizing a\nsingle filter error. We demonstrate that objective-aware sampling significantly\noutperforms the state of the art active learning sampling strategies.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 16:17:28 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Krivosheev", "Evgeny", ""], ["Sayin", "Burcu", ""], ["Bozzon", "Alessandro", ""], ["Szl\u00e1vik", "Zolt\u00e1n", ""]]}, {"id": "2012.02327", "submitter": "Trevor Londt", "authors": "Trevor Londt, Xiaoying Gao, Peter Andreae", "title": "Evolving Character-Level DenseNet Architectures using Genetic\n  Programming", "comments": "Submitted to EvoStar 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DenseNet architectures have demonstrated impressive performance in image\nclassification tasks, but limited research has been conducted on using\ncharacter-level DenseNet (char-DenseNet) architectures for text classification\ntasks. It is not clear what DenseNet architectures are optimal for text\nclassification tasks. The iterative task of designing, training and testing of\nchar-DenseNets is an NP-Hard problem that requires expert domain knowledge.\nEvolutionary deep learning (EDL) has been used to automatically design CNN\narchitectures for the image classification domain, thereby mitigating the need\nfor expert domain knowledge. This study demonstrates the first work on using\nEDL to evolve char-DenseNet architectures for text classification tasks. A\nnovel genetic programming-based algorithm (GP-Dense) coupled with an\nindirect-encoding scheme, facilitates the evolution of performant char DenseNet\narchitectures. The algorithm is evaluated on two popular text datasets, and the\nbest-evolved models are benchmarked against four current state-of-the-art\ncharacter-level CNN and DenseNet models. Results indicate that the algorithm\nevolves performant models for both datasets that outperform two of the\nstate-of-the-art models in terms of model accuracy and three of the\nstate-of-the-art models in terms of parameter size.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 23:28:56 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Londt", "Trevor", ""], ["Gao", "Xiaoying", ""], ["Andreae", "Peter", ""]]}, {"id": "2012.02339", "submitter": "Edwin Ng", "authors": "Edwin G. Ng, Bo Pang, Piyush Sharma, Radu Soricut", "title": "Understanding Guided Image Captioning Performance across Domains", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Image captioning models generally lack the capability to take into account\nuser interest, and usually default to global descriptions that try to balance\nreadability, informativeness, and information overload. On the other hand, VQA\nmodels generally lack the ability to provide long descriptive answers, while\nexpecting the textual question to be quite precise. We present a method to\ncontrol the concepts that an image caption should focus on, using an additional\ninput called the guiding text that refers to either groundable or ungroundable\nconcepts in the image. Our model consists of a Transformer-based multimodal\nencoder that uses the guiding text together with global and object-level image\nfeatures to derive early-fusion representations used to generate the guided\ncaption. While models trained on Visual Genome data have an in-domain advantage\nof fitting well when guided with automatic object labels, we find that guided\ncaptioning models trained on Conceptual Captions generalize better on\nout-of-domain images and guiding texts. Our human-evaluation results indicate\nthat attempting in-the-wild guided image captioning requires access to large,\nunrestricted-domain training datasets, and that increased style diversity (even\nwithout increasing vocabulary size) is a key factor for improved performance.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 00:05:02 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Ng", "Edwin G.", ""], ["Pang", "Bo", ""], ["Sharma", "Piyush", ""], ["Soricut", "Radu", ""]]}, {"id": "2012.02353", "submitter": "Xin Cong", "authors": "Xin Cong, Shiyao Cui, Bowen Yu, Tingwen Liu, Yubin Wang, Bin Wang", "title": "Few-Shot Event Detection with Prototypical Amortized Conditional Random\n  Field", "comments": "Accepted at ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event detection tends to struggle when it needs to recognize novel event\ntypes with a few samples. The previous work attempts to solve this problem in\nthe identify-then-classify manner but ignores the trigger discrepancy between\nevent types, thus suffering from the error propagation. In this paper, we\npresent a novel unified model which converts the task to a few-shot tagging\nproblem with a double-part tagging scheme. To this end, we first propose the\nPrototypical Amortized Conditional Random Field (PA-CRF) to model the label\ndependency in the few-shot scenario, which approximates the transition scores\nbetween labels based on the label prototypes. Then Gaussian distribution is\nintroduced for modeling of the transition scores to alleviate the uncertain\nestimation resulting from insufficient data. Experimental results show that the\nunified models work better than existing identify-then-classify models and our\nPA-CRF further achieves the best results on the benchmark dataset FewEvent. Our\ncode and data are available at http://github.com/congxin95/PA-CRF.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 01:11:13 GMT"}, {"version": "v2", "created": "Mon, 24 May 2021 09:01:48 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Cong", "Xin", ""], ["Cui", "Shiyao", ""], ["Yu", "Bowen", ""], ["Liu", "Tingwen", ""], ["Wang", "Yubin", ""], ["Wang", "Bin", ""]]}, {"id": "2012.02356", "submitter": "Pratyay Banerjee", "authors": "Pratyay Banerjee, Tejas Gokhale, Yezhou Yang, Chitta Baral", "title": "WeaQA: Weak Supervision via Captions for Visual Question Answering", "comments": "Accepted in Findings of ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methodologies for training visual question answering (VQA) models assume the\navailability of datasets with human-annotated \\textit{Image-Question-Answer}\n(I-Q-A) triplets. This has led to heavy reliance on datasets and a lack of\ngeneralization to new types of questions and scenes. Linguistic priors along\nwith biases and errors due to annotator subjectivity have been shown to\npercolate into VQA models trained on such samples. We study whether models can\nbe trained without any human-annotated Q-A pairs, but only with images and\ntheir associated textual descriptions or captions. We present a method to train\nmodels with synthetic Q-A pairs generated procedurally from captions.\nAdditionally, we demonstrate the efficacy of spatial-pyramid image patches as a\nsimple but effective alternative to dense and costly object bounding box\nannotations used in existing VQA models. Our experiments on three VQA\nbenchmarks demonstrate the efficacy of this weakly-supervised approach,\nespecially on the VQA-CP challenge, which tests performance under changing\nlinguistic priors.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 01:22:05 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 07:09:48 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Banerjee", "Pratyay", ""], ["Gokhale", "Tejas", ""], ["Yang", "Yezhou", ""], ["Baral", "Chitta", ""]]}, {"id": "2012.02360", "submitter": "Jing Qin", "authors": "Jing Qin", "title": "Research Progress of News Recommendation Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to researchers'aim to study personalized recommendations for different\nbusiness fields, the summary of recommendation methods in specific fields is of\npractical significance. News recommendation systems were the earliest research\nfield regarding recommendation systems, and were also the earliest\nrecommendation field to apply the collaborative filtering method. In addition,\nnews is real-time and rich in content, which makes news recommendation methods\nmore challenging than in other fields. Thus, this paper summarizes the research\nprogress regarding news recommendation methods. From 2018 to 2020, developed\nnews recommendation methods were mainly deep learning-based, attention-based,\nand knowledge graphs-based. As of 2020, there are many news recommendation\nmethods that combine attention mechanisms and knowledge graphs. However, these\nmethods were all developed based on basic methods (the collaborative filtering\nmethod, the content-based recommendation method, and a mixed recommendation\nmethod combining the two). In order to allow researchers to have a detailed\nunderstanding of the development process of news recommendation methods, the\nnews recommendation methods surveyed in this paper, which cover nearly 10\nyears, are divided into three categories according to the abovementioned basic\nmethods. Firstly, the paper introduces the basic ideas of each category of\nmethods and then summarizes the recommendation methods that are combined with\nother methods based on each category of methods and according to the time\nsequence of research results. Finally, this paper also summarizes the\nchallenges confronting news recommendation systems.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 01:47:24 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 01:53:42 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Qin", "Jing", ""]]}, {"id": "2012.02420", "submitter": "Junyu Luo", "authors": "Junyu Luo, Zifei Zheng, Hanzhong Ye, Muchao Ye, Yaqing Wang, Quanzeng\n  You, Cao Xiao and Fenglong Ma", "title": "A Benchmark Dataset for Understandable Medical Language Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we introduce MedLane -- a new human-annotated Medical Language\ntranslation dataset, to align professional medical sentences with\nlayperson-understandable expressions. The dataset contains 12,801 training\nsamples, 1,015 validation samples, and 1,016 testing samples. We then evaluate\none naive and six deep learning-based approaches on the MedLane dataset,\nincluding directly copying, a statistical machine translation approach Moses,\nfour neural machine translation approaches (i.e., the proposed PMBERT-MT model,\nSeq2Seq and its two variants), and a modified text summarization model\nPointerNet. To compare the results, we utilize eleven metrics, including three\nnew measures specifically designed for this task. Finally, we discuss the\nlimitations of MedLane and baselines, and point out possible research\ndirections for this task.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 06:09:02 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Luo", "Junyu", ""], ["Zheng", "Zifei", ""], ["Ye", "Hanzhong", ""], ["Ye", "Muchao", ""], ["Wang", "Yaqing", ""], ["You", "Quanzeng", ""], ["Xiao", "Cao", ""], ["Ma", "Fenglong", ""]]}, {"id": "2012.02446", "submitter": "Yiou Lin", "authors": "Yiou Lin, Hang Lei and Yu Deng", "title": "Spread Mechanism and Influence Measurement of Online Rumors in China\n  During the COVID-19 Pandemic", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In early 2020, the Corona Virus Disease 2019 (COVID-19) pandemic swept the\nworld.In China, COVID-19 has caused severe consequences. Moreover, online\nrumors during the COVID-19 pandemic increased people's panic about public\nhealth and social stability. At present, understanding and curbing the spread\nof online rumors is an urgent task. Therefore, we analyzed the rumor spreading\nmechanism and propose a method to quantify a rumors' influence by the speed of\nnew insiders. The search frequency of the rumor is used as an observation\nvariable of new insiders. The peak coefficient and the attenuation coefficient\nare calculated for the search frequency, which conforms to the exponential\ndistribution. We designed several rumor features and used the above two\ncoefficients as predictable labels. A 5-fold cross-validation experiment using\nthe mean square error (MSE) as the loss function showed that the decision tree\nwas suitable for predicting the peak coefficient, and the linear regression\nmodel was ideal for predicting the attenuation coefficient. Our feature\nanalysis showed that precursor features were the most important for the\noutbreak coefficient, while location information and rumor entity information\nwere the most important for the attenuation coefficient. Meanwhile, features\nthat were conducive to the outbreak were usually harmful to the continued\nspread of rumors. At the same time, anxiety was a crucial rumor causing factor.\nFinally, we discuss how to use deep learning technology to reduce the forecast\nloss by using the Bidirectional Encoder Representations from Transformers\n(BERT) model.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 07:55:15 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 21:00:32 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Lin", "Yiou", ""], ["Lei", "Hang", ""], ["Deng", "Yu", ""]]}, {"id": "2012.02462", "submitter": "Daniel Grie{\\ss}haber", "authors": "Daniel Grie{\\ss}haber, Johannes Maucher and Ngoc Thang Vu", "title": "Fine-tuning BERT for Low-Resource Natural Language Understanding via\n  Active Learning", "comments": "COLING'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, leveraging pre-trained Transformer based language models in down\nstream, task specific models has advanced state of the art results in natural\nlanguage understanding tasks. However, only a little research has explored the\nsuitability of this approach in low resource settings with less than 1,000\ntraining data points. In this work, we explore fine-tuning methods of BERT -- a\npre-trained Transformer based language model -- by utilizing pool-based active\nlearning to speed up training while keeping the cost of labeling new data\nconstant. Our experimental results on the GLUE data set show an advantage in\nmodel performance by maximizing the approximate knowledge gain of the model\nwhen querying from the pool of unlabeled data. Finally, we demonstrate and\nanalyze the benefits of freezing layers of the language model during\nfine-tuning to reduce the number of trainable parameters, making it more\nsuitable for low-resource settings.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 08:34:39 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Grie\u00dfhaber", "Daniel", ""], ["Maucher", "Johannes", ""], ["Vu", "Ngoc Thang", ""]]}, {"id": "2012.02498", "submitter": "Hanna Abi Akl", "authors": "Dominique Mariko, Estelle Labidurie, Yagmur Ozturk, Hanna Abi Akl,\n  Hugues de Mazancourt", "title": "Data Processing and Annotation Schemes for FinCausal Shared Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This document explains the annotation schemes used to label the data for the\nFinCausal Shared Task (Mariko et al., 2020). This task is associated to the\nJoint Workshop on Financial Narrative Processing and MultiLing Financial\nSummarisation (FNP-FNS 2020), to be held at The 28th International Conference\non Computational Linguistics (COLING'2020), on December 12, 2020.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 09:58:47 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Mariko", "Dominique", ""], ["Labidurie", "Estelle", ""], ["Ozturk", "Yagmur", ""], ["Akl", "Hanna Abi", ""], ["de Mazancourt", "Hugues", ""]]}, {"id": "2012.02505", "submitter": "Hanna Abi Akl", "authors": "Dominique Mariko, Hanna Abi Akl, Estelle Labidurie, St\\'ephane\n  Durfort, Hugues de Mazancourt, Mahmoud El-Haj", "title": "Financial Document Causality Detection Shared Task (FinCausal 2020)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present the FinCausal 2020 Shared Task on Causality Detection in Financial\nDocuments and the associated FinCausal dataset, and discuss the participating\nsystems and results. Two sub-tasks are proposed: a binary classification task\n(Task 1) and a relation extraction task (Task 2). A total of 16 teams submitted\nruns across the two Tasks and 13 of them contributed with a system description\npaper. This workshop is associated to the Joint Workshop on Financial Narrative\nProcessing and MultiLing Financial Summarisation (FNP-FNS 2020), held at The\n28th International Conference on Computational Linguistics (COLING'2020),\nBarcelona, Spain on September 12, 2020.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 10:17:42 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Mariko", "Dominique", ""], ["Akl", "Hanna Abi", ""], ["Labidurie", "Estelle", ""], ["Durfort", "St\u00e9phane", ""], ["de Mazancourt", "Hugues", ""], ["El-Haj", "Mahmoud", ""]]}, {"id": "2012.02507", "submitter": "Damai Dai", "authors": "Damai Dai, Jing Ren, Shuang Zeng, Baobao Chang, Zhifang Sui", "title": "Coarse-to-Fine Entity Representations for Document-level Relation\n  Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document-level Relation Extraction (RE) requires extracting relations\nexpressed within and across sentences. Recent works show that graph-based\nmethods, usually constructing a document-level graph that captures\ndocument-aware interactions, can obtain useful entity representations thus\nhelping tackle document-level RE. These methods either focus more on the entire\ngraph, or pay more attention to a part of the graph, e.g., paths between the\ntarget entity pair. However, we find that document-level RE may benefit from\nfocusing on both of them simultaneously. Therefore, to obtain more\ncomprehensive entity representations, we propose the Coarse-to-Fine Entity\nRepresentation model (CFER) that adopts a coarse-to-fine strategy involving two\nphases. First, CFER uses graph neural networks to integrate global information\nin the entire graph at a coarse level. Next, CFER utilizes the global\ninformation as a guidance to selectively aggregate path information between the\ntarget entity pair at a fine level. In classification, we combine the entity\nrepresentations from both two levels into more comprehensive representations\nfor relation extraction. Experimental results on two document-level RE\ndatasets, DocRED and CDR, show that CFER outperforms existing models and is\nrobust to the uneven label distribution.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 10:18:59 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 13:07:31 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Dai", "Damai", ""], ["Ren", "Jing", ""], ["Zeng", "Shuang", ""], ["Chang", "Baobao", ""], ["Sui", "Zhifang", ""]]}, {"id": "2012.02535", "submitter": "Potsawee Manakul", "authors": "Potsawee Manakul and Mark Gales", "title": "CUED_speech at TREC 2020 Podcast Summarisation Track", "comments": "TREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe our approach for the Podcast Summarisation\nchallenge in TREC 2020. Given a podcast episode with its transcription, the\ngoal is to generate a summary that captures the most important information in\nthe content. Our approach consists of two steps: (1) Filtering redundant or\nless informative sentences in the transcription using the attention of a\nhierarchical model; (2) Applying a state-of-the-art text summarisation system\n(BART) fine-tuned on the Podcast data using a sequence-level reward function.\nFurthermore, we perform ensembles of three and nine models for our submission\nruns. We also fine-tune the BART model on the Podcast data as our baseline. The\nhuman evaluation by NIST shows that our best submission achieves 1.777 in the\nEGFB scale, while the score of creator-provided description is 1.291. Our\nsystem won the Spotify Podcast Summarisation Challenge in the TREC2020 Podcast\nTrack in both human and automatic evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 11:32:55 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2021 11:33:16 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Manakul", "Potsawee", ""], ["Gales", "Mark", ""]]}, {"id": "2012.02553", "submitter": "Qi Jia", "authors": "Qi Jia, Hongru Huang, Kenny Q. Zhu", "title": "DDRel: A New Dataset for Interpersonal Relation Classification in Dyadic\n  Dialogues", "comments": "This paper has been accepted by AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpersonal language style shifting in dialogues is an interesting and\nalmost instinctive ability of human. Understanding interpersonal relationship\nfrom language content is also a crucial step toward further understanding\ndialogues. Previous work mainly focuses on relation extraction between named\nentities in texts. In this paper, we propose the task of relation\nclassification of interlocutors based on their dialogues. We crawled movie\nscripts from IMSDb, and annotated the relation labels for each session\naccording to 13 pre-defined relationships. The annotated dataset DDRel consists\nof 6300 dyadic dialogue sessions between 694 pair of speakers with 53,126\nutterances in total. We also construct session-level and pair-level relation\nclassification tasks with widely-accepted baselines. The experimental results\nshow that this task is challenging for existing models and the dataset will be\nuseful for future research.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 12:30:31 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Jia", "Qi", ""], ["Huang", "Hongru", ""], ["Zhu", "Kenny Q.", ""]]}, {"id": "2012.02558", "submitter": "Matthias A{\\ss}enmacher", "authors": "V. D. Viellieber and M. A{\\ss}enmacher", "title": "Pre-trained language models as knowledge bases for Automotive Complaint\n  Analysis", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently it has been shown that large pre-trained language models like BERT\n(Devlin et al., 2018) are able to store commonsense factual knowledge captured\nin its pre-training corpus (Petroni et al., 2019). In our work we further\nevaluate this ability with respect to an application from industry creating a\nset of probes specifically designed to reveal technical quality issues captured\nas described incidents out of unstructured customer feedback in the automotive\nindustry. After probing the out-of-the-box versions of the pre-trained models\nwith fill-in-the-mask tasks we dynamically provide it with more knowledge via\ncontinual pre-training on the Office of Defects Investigation (ODI) Complaints\ndata set. In our experiments the models exhibit performance regarding queries\non domain-specific topics compared to when queried on factual knowledge itself,\nas Petroni et al. (2019) have done. For most of the evaluated architectures the\ncorrect token is predicted with a $Precision@1$ ($P@1$) of above 60\\%, while\nfor $P@5$ and $P@10$ even values of well above 80\\% and up to 90\\% respectively\nare reached. These results show the potential of using language models as a\nknowledge base for structured analysis of customer feedback.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 12:49:47 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Viellieber", "V. D.", ""], ["A\u00dfenmacher", "M.", ""]]}, {"id": "2012.02565", "submitter": "Mahen Herath", "authors": "Thushari Atapattu, Mahen Herath, Georgia Zhang, Katrina Falkner", "title": "Automated Detection of Cyberbullying Against Women and Immigrants and\n  Cross-domain Adaptability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyberbullying is a prevalent and growing social problem due to the surge of\nsocial media technology usage. Minorities, women, and adolescents are among the\ncommon victims of cyberbullying. Despite the advancement of NLP technologies,\nthe automated cyberbullying detection remains challenging. This paper focuses\non advancing the technology using state-of-the-art NLP techniques. We use a\nTwitter dataset from SemEval 2019 - Task 5(HatEval) on hate speech against\nwomen and immigrants. Our best performing ensemble model based on DistilBERT\nhas achieved 0.73 and 0.74 of F1 score in the task of classifying hate speech\n(Task A) and aggressiveness and target (Task B) respectively. We adapt the\nensemble model developed for Task A to classify offensive language in external\ndatasets and achieved ~0.7 of F1 score using three benchmark datasets, enabling\npromising results for cross-domain adaptability. We conduct a qualitative\nanalysis of misclassified tweets to provide insightful recommendations for\nfuture cyberbullying research.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 13:12:31 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Atapattu", "Thushari", ""], ["Herath", "Mahen", ""], ["Zhang", "Georgia", ""], ["Falkner", "Katrina", ""]]}, {"id": "2012.02578", "submitter": "Mika H\\\"am\\\"al\\\"ainen", "authors": "Khalid Alnajjar, Mika H\\\"am\\\"al\\\"ainen, Jack Rueter, Niko Partanen", "title": "Ve'rdd. Narrowing the Gap between Paper Dictionaries, Low-Resource NLP\n  and Community Involvement", "comments": "Proceedings of the 28th International Conference on Computational\n  Linguistics: System Demonstrations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present an open-source online dictionary editing system, Ve'rdd, that\noffers a chance to re-evaluate and edit grassroots dictionaries that have been\nexposed to multiple amateur editors. The idea is to incorporate community\nactivities into a state-of-the-art finite-state language description of a\nseriously endangered minority language, Skolt Sami. Problems involve getting\nthe community to take part in things above the pencil-and-paper level. At\ntimes, it seems that the native speakers and the dictionary oriented are\nlacking technical understanding to utilize the infrastructures which might make\ntheir work more meaningful in the future, i.e. multiple reuse of all of their\ninput. Therefore, our system integrates with the existing tools and\ninfrastructures for Uralic language masking the technical complexities behind a\nuser-friendly UI.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 13:36:29 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Alnajjar", "Khalid", ""], ["H\u00e4m\u00e4l\u00e4inen", "Mika", ""], ["Rueter", "Jack", ""], ["Partanen", "Niko", ""]]}, {"id": "2012.02594", "submitter": "Barun Patra", "authors": "Barun Patra, Chala Fufa, Pamela Bhattacharya and Charles Lee", "title": "To Schedule or not to Schedule: Extracting Task Specific Temporal\n  Entities and Associated Negation Constraints", "comments": "Proceedings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State of the art research for date-time entity extraction from text is task\nagnostic. Consequently, while the methods proposed in literature perform well\nfor generic date-time extraction from texts, they don't fare as well on task\nspecific date-time entity extraction where only a subset of the date-time\nentities present in the text are pertinent to solving the task. Furthermore,\nsome tasks require identifying negation constraints associated with the\ndate-time entities to correctly reason over time. We showcase a novel model for\nextracting task-specific date-time entities along with their negation\nconstraints. We show the efficacy of our method on the task of date-time\nunderstanding in the context of scheduling meetings for an email-based digital\nAI scheduling assistant. Our method achieves an absolute gain of 19\\% f-score\npoints compared to baseline methods in detecting the date-time entities\nrelevant to scheduling meetings and a 4\\% improvement over baseline methods for\ndetecting negation constraints over date-time entities.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 10:07:19 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Patra", "Barun", ""], ["Fufa", "Chala", ""], ["Bhattacharya", "Pamela", ""], ["Lee", "Charles", ""]]}, {"id": "2012.02595", "submitter": "Thomas Vetterli", "authors": "Divyansh Agarwal, Yuta Baba, Pratik Sachdeva, Tanya Tandon, Thomas\n  Vetterli, Aziz Alghunaim", "title": "Accurate and Scalable Matching of Translators to Displaced Persons for\n  Overcoming Language Barriers", "comments": "Presented at NeurIPS 2020 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Residents of developing countries are disproportionately susceptible to\ndisplacement as a result of humanitarian crises. During such crises, language\nbarriers impede aid workers in providing services to those displaced. To build\nresilience, such services must be flexible and robust to a host of possible\nlanguages. \\textit{Tarjimly} aims to overcome the barriers by providing a\nplatform capable of matching bilingual volunteers to displaced persons or aid\nworkers in need of translating. However, Tarjimly's large pool of translators\ncomes with the challenge of selecting the right translator per request. In this\npaper, we describe a machine learning system that matches translator requests\nto volunteers at scale. We demonstrate that a simple logistic regression,\noperating on easily computable features, can accurately predict and rank\ntranslator response. In deployment, this lightweight system matches 82\\% of\nrequests with a median response time of 59 seconds, allowing aid workers to\naccelerate their services supporting displaced persons.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 22:50:00 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Agarwal", "Divyansh", ""], ["Baba", "Yuta", ""], ["Sachdeva", "Pratik", ""], ["Tandon", "Tanya", ""], ["Vetterli", "Thomas", ""], ["Alghunaim", "Aziz", ""]]}, {"id": "2012.02613", "submitter": "Tommi Jauhiainen", "authors": "Krister Lind\\'en and Tommi Jauhiainen and Sam Hardwick", "title": "FinnSentiment -- A Finnish Social Media Corpus for Sentiment Polarity\n  Annotation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentiment analysis and opinion mining is an important task with obvious\napplication areas in social media, e.g. when indicating hate speech and fake\nnews. In our survey of previous work, we note that there is no large-scale\nsocial media data set with sentiment polarity annotations for Finnish. This\npublications aims to remedy this shortcoming by introducing a 27,000 sentence\ndata set annotated independently with sentiment polarity by three native\nannotators. We had the same three annotators for the whole data set, which\nprovides a unique opportunity for further studies of annotator behaviour over\ntime. We analyse their inter-annotator agreement and provide two baselines to\nvalidate the usefulness of the data set.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 14:17:46 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Lind\u00e9n", "Krister", ""], ["Jauhiainen", "Tommi", ""], ["Hardwick", "Sam", ""]]}, {"id": "2012.02626", "submitter": "Aolan Sun", "authors": "Aolan Sun, Jianzong Wang, Ning Cheng, Huayi Peng, Zhen Zeng, Lingwei\n  Kong, Jing Xiao", "title": "GraphPB: Graphical Representations of Prosody Boundary in Speech\n  Synthesis", "comments": "Accepted to SLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a graphical representation approach of prosody boundary\n(GraphPB) in the task of Chinese speech synthesis, intending to parse the\nsemantic and syntactic relationship of input sequences in a graphical domain\nfor improving the prosody performance. The nodes of the graph embedding are\nformed by prosodic words, and the edges are formed by the other prosodic\nboundaries, namely prosodic phrase boundary (PPH) and intonation phrase\nboundary (IPH). Different Graph Neural Networks (GNN) like Gated Graph Neural\nNetwork (GGNN) and Graph Long Short-term Memory (G-LSTM) are utilised as graph\nencoders to exploit the graphical prosody boundary information.\nGraph-to-sequence model is proposed and formed by a graph encoder and an\nattentional decoder. Two techniques are proposed to embed sequential\ninformation into the graph-to-sequence text-to-speech model. The experimental\nresults show that this proposed approach can encode the phonetic and prosody\nrhythm of an utterance. The mean opinion score (MOS) of these GNN models shows\ncomparative results with the state-of-the-art sequence-to-sequence models with\nbetter performance in the aspect of prosody. This provides an alternative\napproach for prosody modelling in end-to-end speech synthesis.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 03:34:05 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Sun", "Aolan", ""], ["Wang", "Jianzong", ""], ["Cheng", "Ning", ""], ["Peng", "Huayi", ""], ["Zeng", "Zhen", ""], ["Kong", "Lingwei", ""], ["Xiao", "Jing", ""]]}, {"id": "2012.02640", "submitter": "Diego Elias Costa", "authors": "Ahmad Abdellatif, Khaled Badran, Diego Elias Costa, and Emad Shihab", "title": "A Comparison of Natural Language Understanding Platforms for Chatbots in\n  Software Engineering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chatbots are envisioned to dramatically change the future of Software\nEngineering, allowing practitioners to chat and inquire about their software\nprojects and interact with different services using natural language. At the\nheart of every chatbot is a Natural Language Understanding (NLU) component that\nenables the chatbot to understand natural language input. Recently, many NLU\nplatforms were provided to serve as an off-the-shelf NLU component for\nchatbots, however, selecting the best NLU for Software Engineering chatbots\nremains an open challenge.\n  Therefore, in this paper, we evaluate four of the most commonly used NLUs,\nnamely IBM Watson, Google Dialogflow, Rasa, and Microsoft LUIS to shed light on\nwhich NLU should be used in Software Engineering based chatbots. Specifically,\nwe examine the NLUs' performance in classifying intents, confidence scores\nstability, and extracting entities. To evaluate the NLUs, we use two datasets\nthat reflect two common tasks performed by Software Engineering practitioners,\n1) the task of chatting with the chatbot to ask questions about software\nrepositories 2) the task of asking development questions on Q&A forums (e.g.,\nStack Overflow). According to our findings, IBM Watson is the best performing\nNLU when considering the three aspects (intents classification, confidence\nscores, and entity extraction). However, the results from each individual\naspect show that, in intents classification, IBM Watson performs the best with\nan F1-measure > 84%, but in confidence scores, Rasa comes on top with a median\nconfidence score higher than 0.91. Our results also show that all NLUs, except\nfor Dialogflow, generally provide trustable confidence scores. For entity\nextraction, Microsoft LUIS and IBM Watson outperform other NLUs in the two SE\ntasks. Our results provide guidance to software engineering practitioners when\ndeciding which NLU to use in their chatbots.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 14:59:08 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 13:32:53 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Abdellatif", "Ahmad", ""], ["Badran", "Khaled", ""], ["Costa", "Diego Elias", ""], ["Shihab", "Emad", ""]]}, {"id": "2012.02705", "submitter": "Kaiyu Zheng", "authors": "Kaiyu Zheng, Deniz Bayazit, Rebecca Mathew, Ellie Pavlick, Stefanie\n  Tellex", "title": "Spatial Language Understanding for Object Search in Partially Observed\n  City-scale Environments", "comments": "11 pages, 12 figures, 3 table. 30th IEEE International Conference on\n  Robot and Human Interactive Communication (RO-MAN), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Humans use spatial language to naturally describe object locations and their\nrelations. Interpreting spatial language not only adds a perceptual modality\nfor robots, but also reduces the barrier of interfacing with humans. Previous\nwork primarily considers spatial language as goal specification for instruction\nfollowing tasks in fully observable domains, often paired with reference paths\nfor reward-based learning. However, spatial language is inherently subjective\nand potentially ambiguous or misleading. Hence, in this paper, we consider\nspatial language as a form of stochastic observation. We propose SLOOP (Spatial\nLanguage Object-Oriented POMDP), a new framework for partially observable\ndecision making with a probabilistic observation model for spatial language. We\napply SLOOP to object search in city-scale environments. To interpret\nambiguous, context-dependent prepositions (e.g. front), we design a simple\nconvolutional neural network that predicts the language provider's latent frame\nof reference (FoR) given the environment context. Search strategies are\ncomputed via an online POMDP planner based on Monte Carlo Tree Search.\nEvaluation based on crowdsourced language data, collected over areas of five\ncities in OpenStreetMap, shows that our approach achieves faster search and\nhigher success rate compared to baselines, with a wider margin as the spatial\nlanguage becomes more complex. Finally, we demonstrate the proposed method in\nAirSim, a realistic simulator where a drone is tasked to find cars in a\nneighborhood environment.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 16:27:59 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 19:34:58 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Zheng", "Kaiyu", ""], ["Bayazit", "Deniz", ""], ["Mathew", "Rebecca", ""], ["Pavlick", "Ellie", ""], ["Tellex", "Stefanie", ""]]}, {"id": "2012.02721", "submitter": "Amith Ananthram", "authors": "Amith Ananthram, Emily Allaway, Kathleen McKeown", "title": "Event Guided Denoising for Multilingual Relation Learning", "comments": "COLING2020, short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  General purpose relation extraction has recently seen considerable gains in\npart due to a massively data-intensive distant supervision technique from\nSoares et al. (2019) that produces state-of-the-art results across many\nbenchmarks. In this work, we present a methodology for collecting high quality\ntraining data for relation extraction from unlabeled text that achieves a\nnear-recreation of their zero-shot and few-shot results at a fraction of the\ntraining cost. Our approach exploits the predictable distributional structure\nof date-marked news articles to build a denoised corpus -- the extraction\nprocess filters out low quality examples. We show that a smaller multilingual\nencoder trained on this corpus performs comparably to the current\nstate-of-the-art (when both receive little to no fine-tuning) on few-shot and\nstandard relation benchmarks in English and Spanish despite using many fewer\nexamples (50k vs. 300mil+).\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 17:11:04 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Ananthram", "Amith", ""], ["Allaway", "Emily", ""], ["McKeown", "Kathleen", ""]]}, {"id": "2012.02757", "submitter": "Spencer Frazier", "authors": "Sahith Dambekodi, Spencer Frazier, Prithviraj Ammanabrolu, Mark O.\n  Riedl", "title": "Playing Text-Based Games with Common Sense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text based games are simulations in which an agent interacts with the world\npurely through natural language. They typically consist of a number of puzzles\ninterspersed with interactions with common everyday objects and locations. Deep\nreinforcement learning agents can learn to solve these puzzles. However, the\neveryday interactions with the environment, while trivial for human players,\npresent as additional puzzles to agents. We explore two techniques for\nincorporating commonsense knowledge into agents. Inferring possibly hidden\naspects of the world state with either a commonsense inference model COMET, or\na language model BERT. Biasing an agents exploration according to common\npatterns recognized by a language model. We test our technique in the 9to05\ngame, which is an extreme version of a text based game that requires numerous\ninteractions with common, everyday objects in common, everyday scenarios. We\nconclude that agents that augment their beliefs about the world state with\ncommonsense inferences are more robust to observational errors and omissions of\ncommon elements from text descriptions.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 18:22:59 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Dambekodi", "Sahith", ""], ["Frazier", "Spencer", ""], ["Ammanabrolu", "Prithviraj", ""], ["Riedl", "Mark O.", ""]]}, {"id": "2012.02763", "submitter": "Boya Yu", "authors": "Boya Yu, Konstantine Arkoudas, Wael Hamza", "title": "Delexicalized Paraphrase Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a neural model for paraphrasing and train it to generate\ndelexicalized sentences. We achieve this by creating training data in which\neach input is paired with a number of reference paraphrases. These sets of\nreference paraphrases represent a weak type of semantic equivalence based on\nannotated slots and intents. To understand semantics from different types of\nslots, other than anonymizing slots, we apply convolutional neural networks\n(CNN) prior to pooling on slot values and use pointers to locate slots in the\noutput. We show empirically that the generated paraphrases are of high quality,\nleading to an additional 1.29% exact match on live utterances. We also show\nthat natural language understanding (NLU) tasks, such as intent classification\nand named entity recognition, can benefit from data augmentation using\nautomatically generated paraphrases.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 18:28:30 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Yu", "Boya", ""], ["Arkoudas", "Konstantine", ""], ["Hamza", "Wael", ""]]}, {"id": "2012.02813", "submitter": "Paul Pu Liang", "authors": "Paul Pu Liang, Peter Wu, Liu Ziyin, Louis-Philippe Morency, Ruslan\n  Salakhutdinov", "title": "Cross-Modal Generalization: Learning in Low Resource Modalities via\n  Meta-Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The natural world is abundant with concepts expressed via visual, acoustic,\ntactile, and linguistic modalities. Much of the existing progress in multimodal\nlearning, however, focuses primarily on problems where the same set of\nmodalities are present at train and test time, which makes learning in\nlow-resource modalities particularly difficult. In this work, we propose\nalgorithms for cross-modal generalization: a learning paradigm to train a model\nthat can (1) quickly perform new tasks in a target modality (i.e.\nmeta-learning) and (2) doing so while being trained on a different source\nmodality. We study a key research question: how can we ensure generalization\nacross modalities despite using separate encoders for different source and\ntarget modalities? Our solution is based on meta-alignment, a novel method to\nalign representation spaces using strongly and weakly paired cross-modal data\nwhile ensuring quick generalization to new tasks across different modalities.\nWe study this problem on 3 classification tasks: text to image, image to audio,\nand text to speech. Our results demonstrate strong performance even when the\nnew target modality has only a few (1-10) labeled samples and in the presence\nof noisy labels, a scenario particularly prevalent in low-resource modalities.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 19:27:26 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Liang", "Paul Pu", ""], ["Wu", "Peter", ""], ["Ziyin", "Liu", ""], ["Morency", "Louis-Philippe", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "2012.02819", "submitter": "Shubham Vatsal", "authors": "Arun D Prabhu, Nikhil Arora, Shubham Vatsal, Gopi Ramena, Sukumar\n  Moharana, Naresh Purre", "title": "On-Device Sentence Similarity for SMS Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Determining the sentence similarity between Short Message Service (SMS)\ntexts/sentences plays a significant role in mobile device industry. Gauging the\nsimilarity between SMS data is thus necessary for various applications like\nenhanced searching and navigation, clubbing together SMS of similar type when\ngiven a custom label or tag is provided by user irrespective of their sender\netc. The problem faced with SMS data is its incomplete structure and\ngrammatical inconsistencies. In this paper, we propose a unique pipeline for\nevaluating the text similarity between SMS texts. We use Part of Speech (POS)\nmodel for keyword extraction by taking advantage of the partial structure\nembedded in SMS texts and similarity comparisons are carried out using\nstatistical methods. The proposed pipeline deals with major semantic variations\nacross SMS data as well as makes it effective for its application on-device\n(mobile phone). To showcase the capabilities of our work, our pipeline has been\ndesigned with an inclination towards one of the possible applications of SMS\ntext similarity discussed in one of the following sections but nonetheless\nguarantees scalability for other applications as well.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 19:51:24 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Prabhu", "Arun D", ""], ["Arora", "Nikhil", ""], ["Vatsal", "Shubham", ""], ["Ramena", "Gopi", ""], ["Moharana", "Sukumar", ""], ["Purre", "Naresh", ""]]}, {"id": "2012.02821", "submitter": "Fangda Han", "authors": "Fangda Han, Guoyao Hao, Ricardo Guerrero, Vladimir Pavlovic", "title": "MPG: A Multi-ingredient Pizza Image Generator with Conditional StyleGANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Multilabel conditional image generation is a challenging problem in computer\nvision. In this work we propose Multi-ingredient Pizza Generator (MPG), a\nconditional Generative Neural Network (GAN) framework for synthesizing\nmultilabel images. We design MPG based on a state-of-the-art GAN structure\ncalled StyleGAN2, in which we develop a new conditioning technique by enforcing\nintermediate feature maps to learn scalewise label information. Because of the\ncomplex nature of the multilabel image generation problem, we also regularize\nsynthetic image by predicting the corresponding ingredients as well as\nencourage the discriminator to distinguish between matched image and mismatched\nimage. To verify the efficacy of MPG, we test it on Pizza10, which is a\ncarefully annotated multi-ingredient pizza image dataset. MPG can successfully\ngenerate photo-realist pizza images with desired ingredients. The framework can\nbe easily extend to other multilabel image generation scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 19:51:31 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Han", "Fangda", ""], ["Hao", "Guoyao", ""], ["Guerrero", "Ricardo", ""], ["Pavlovic", "Vladimir", ""]]}, {"id": "2012.02875", "submitter": "Shangmin Guo", "authors": "Shangmin Guo, Yi Ren, Agnieszka S{\\l}owik, Kory Mathewson", "title": "Inductive Bias and Language Expressivity in Emergent Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Referential games and reconstruction games are the most common game types for\nstudying emergent languages. We investigate how the type of the language game\naffects the emergent language in terms of: i) language compositionality and ii)\ntransfer of an emergent language to a task different from its origin, which we\nrefer to as language expressivity. With empirical experiments on a handcrafted\nsymbolic dataset, we show that languages emerged from different games have\ndifferent compositionality and further different expressivity.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 22:20:55 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Guo", "Shangmin", ""], ["Ren", "Yi", ""], ["S\u0142owik", "Agnieszka", ""], ["Mathewson", "Kory", ""]]}, {"id": "2012.02929", "submitter": "Igor Shalyminov", "authors": "Igor Shalyminov", "title": "Data-Efficient Methods for Dialogue Systems", "comments": "PhD thesis submitted at Heriot-Watt University. Contains previously\n  published work (see the list in Section 1.4)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational User Interface (CUI) has become ubiquitous in everyday life,\nin consumer-focused products like Siri and Alexa or business-oriented\nsolutions. Deep learning underlies many recent breakthroughs in dialogue\nsystems but requires very large amounts of training data, often annotated by\nexperts. Trained with smaller data, these methods end up severely lacking\nrobustness (e.g. to disfluencies and out-of-domain input), and often just have\ntoo little generalisation power. In this thesis, we address the above issues by\nintroducing a series of methods for training robust dialogue systems from\nminimal data. Firstly, we study two orthogonal approaches to dialogue:\nlinguistically informed and machine learning-based - from the data efficiency\nperspective. We outline the steps to obtain data-efficient solutions with\neither approach. We then introduce two data-efficient models for dialogue\nresponse generation: the Dialogue Knowledge Transfer Network based on latent\nvariable dialogue representations, and the hybrid Generative-Retrieval\nTransformer model (ranked first at the DSTC 8 Fast Domain Adaptation task).\nNext, we address the problem of robustness given minimal data. As such, propose\na multitask LSTM-based model for domain-general disfluency detection. For the\nproblem of out-of-domain input, we present Turn Dropout, a data augmentation\ntechnique for anomaly detection only using in-domain data, and introduce\nautoencoder-augmented models for efficient training with Turn Dropout. Finally,\nwe focus on social dialogue and introduce a neural model for response ranking\nin social conversation used in Alana, the 3rd place winner in the Amazon Alexa\nPrize 2017 and 2018. We employ a novel technique of predicting the dialogue\nlength as the main ranking objective and show that this approach improves upon\nthe ratings-based counterpart in terms of data efficiency while matching it in\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 02:51:09 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Shalyminov", "Igor", ""]]}, {"id": "2012.02939", "submitter": "Tunazzina Islam", "authors": "Tunazzina Islam, Dan Goldwasser", "title": "Does Yoga Make You Happy? Analyzing Twitter User Happiness using Textual\n  and Temporal Information", "comments": "accepted at IEEE BigData 2020", "journal-ref": null, "doi": "10.1109/BigData50022.2020.9378461", "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although yoga is a multi-component practice to hone the body and mind and be\nknown to reduce anxiety and depression, there is still a gap in understanding\npeople's emotional state related to yoga in social media. In this study, we\ninvestigate the causal relationship between practicing yoga and being happy by\nincorporating textual and temporal information of users using Granger\ncausality. To find out causal features from the text, we measure two variables\n(i) Yoga activity level based on content analysis and (ii) Happiness level\nbased on emotional state. To understand users' yoga activity, we propose a\njoint embedding model based on the fusion of neural networks with attention\nmechanism by leveraging users' social and textual information. For measuring\nthe emotional state of yoga users (target domain), we suggest a transfer\nlearning approach to transfer knowledge from an attention-based neural network\nmodel trained on a source domain. Our experiment on Twitter dataset\ndemonstrates that there are 1447 users where \"yoga Granger-causes happiness\".\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 03:30:49 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Islam", "Tunazzina", ""], ["Goldwasser", "Dan", ""]]}, {"id": "2012.02943", "submitter": "Xiang Chen", "authors": "Tian Li and Xiang Chen and Shanghang Zhang and Zhen Dong and Kurt\n  Keutzer", "title": "Cross-Domain Sentiment Classification with In-Domain Contrastive\n  Learning", "comments": "10pages, 2 figures, accepted to NeurIPS 2020 Workshop on\n  Self-supervised Learning. arXiv admin note: text overlap with\n  arXiv:2010.16088", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrastive learning (CL) has been successful as a powerful representation\nlearning method. In this paper, we propose a contrastive learning framework for\ncross-domain sentiment classification. We aim to induce domain invariant\noptimal classifiers rather than distribution matching. To this end, we\nintroduce in-domain contrastive learning and entropy minimization. Also, we\nfind through ablation studies that these two techniques behaviour differently\nin case of large label distribution shift and conclude that the best practice\nis to choose one of them adaptively according to label distribution shift. The\nnew state-of-the-art results our model achieves on standard benchmarks show the\nefficacy of the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 03:48:32 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Li", "Tian", ""], ["Chen", "Xiang", ""], ["Zhang", "Shanghang", ""], ["Dong", "Zhen", ""], ["Keutzer", "Kurt", ""]]}, {"id": "2012.02952", "submitter": "Soroush Vosoughi Dr", "authors": "Ruibo Liu, Guangxuan Xu, Chenyan Jia, Weicheng Ma, Lili Wang, Soroush\n  Vosoughi", "title": "Data Boost: Text Data Augmentation Through Reinforcement Learning Guided\n  Conditional Generation", "comments": "In proceedings of the 2020 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP 2020). Online", "journal-ref": null, "doi": "10.18653/v1/2020.emnlp-main.726", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Data augmentation is proven to be effective in many NLU tasks, especially for\nthose suffering from data scarcity. In this paper, we present a powerful and\neasy to deploy text augmentation framework, Data Boost, which augments data\nthrough reinforcement learning guided conditional generation. We evaluate Data\nBoost on three diverse text classification tasks under five different\nclassifier architectures. The result shows that Data Boost can boost the\nperformance of classifiers especially in low-resource data scenarios. For\ninstance, Data Boost improves F1 for the three tasks by 8.7% on average when\ngiven only 10% of the whole data for training. We also compare Data Boost with\nsix prior text augmentation methods. Through human evaluations (N=178), we\nconfirm that Data Boost augmentation has comparable quality as the original\ndata with respect to readability and class consistency.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 05:21:57 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Liu", "Ruibo", ""], ["Xu", "Guangxuan", ""], ["Jia", "Chenyan", ""], ["Ma", "Weicheng", ""], ["Wang", "Lili", ""], ["Vosoughi", "Soroush", ""]]}, {"id": "2012.02954", "submitter": "Soroush Vosoughi Dr", "authors": "Ruibo Liu, Guangxuan Xu, Soroush Vosoughi", "title": "Enhanced Offensive Language Detection Through Data Augmentation", "comments": "In ICWSM 2020 Data Challenge. Online", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Detecting offensive language on social media is an important task. The\nICWSM-2020 Data Challenge Task 2 is aimed at identifying offensive content\nusing a crowd-sourced dataset containing 100k labelled tweets. The dataset,\nhowever, suffers from class imbalance, where certain labels are extremely rare\ncompared with other classes (e.g, the hateful class is only 5% of the data). In\nthis work, we present Dager (Data Augmenter), a generation-based data\naugmentation method, that improves the performance of classification on\nimbalanced and low-resource data such as the offensive language dataset. Dager\nextracts the lexical features of a given class, and uses these features to\nguide the generation of a conditional generator built on GPT-2. The generated\ntext can then be added to the training set as augmentation data. We show that\napplying Dager can increase the F1 score of the data challenge by 11% when we\nuse 1% of the whole dataset for training (using BERT for classification);\nmoreover, the generated data also preserves the original labels very well. We\ntest Dager on four different classifiers (BERT, CNN, Bi-LSTM with attention,\nand Transformer), observing universal improvement on the detection, indicating\nour method is effective and classifier-agnostic.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 05:45:16 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Liu", "Ruibo", ""], ["Xu", "Guangxuan", ""], ["Vosoughi", "Soroush", ""]]}, {"id": "2012.02957", "submitter": "Junmo Kang", "authors": "Junmo Kang, Jeonghwan Kim, Suwon Shin, Sung-Hyon Myaeng", "title": "A Sequence-Oblivious Generation Method for Context-Aware Hashtag\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Like search, a recommendation task accepts an input query or cue and provides\ndesirable items, often based on a ranking function. Such a ranking approach\nrarely considers explicit dependency among the recommended items. In this work,\nwe propose a generative approach to tag recommendation, where semantic tags are\nselected one at a time conditioned on the previously generated tags to model\ninter-dependency among the generated tags. We apply this tag recommendation\napproach to an Instagram data set where an array of context feature types\n(image, location, time, and text) are available for posts. To exploit the\ninter-dependency among the distinct types of features, we adopt a simple yet\neffective architecture using self-attention, making deep interactions possible.\nEmpirical results show that our method is significantly superior to not only\nthe usual ranking schemes but also autoregressive models for tag\nrecommendation. They indicate that it is critical to fuse mutually supporting\nfeatures at an early stage to induce extensive and comprehensive view on\ninter-context interaction in generating tags in a recurrent feedback loop.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 06:10:56 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Kang", "Junmo", ""], ["Kim", "Jeonghwan", ""], ["Shin", "Suwon", ""], ["Myaeng", "Sung-Hyon", ""]]}, {"id": "2012.02975", "submitter": "Minkai Xu", "authors": "Minkai Xu, Mingxuan Wang, Zhouhan Lin, Hao Zhou, Weinan Zhang, Lei Li", "title": "Reciprocal Supervised Learning Improves Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the recent success on image classification, self-training has only\nachieved limited gains on structured prediction tasks such as neural machine\ntranslation (NMT). This is mainly due to the compositionality of the target\nspace, where the far-away prediction hypotheses lead to the notorious\nreinforced mistake problem. In this paper, we revisit the utilization of\nmultiple diverse models and present a simple yet effective approach named\nReciprocal-Supervised Learning (RSL). RSL first exploits individual models to\ngenerate pseudo parallel data, and then cooperatively trains each model on the\ncombined synthetic corpus. RSL leverages the fact that different parameterized\nmodels have different inductive biases, and better predictions can be made by\njointly exploiting the agreement among each other. Unlike the previous\nknowledge distillation methods built upon a much stronger teacher, RSL is\ncapable of boosting the accuracy of one model by introducing other comparable\nor even weaker models. RSL can also be viewed as a more efficient alternative\nto ensemble. Extensive experiments demonstrate the superior performance of RSL\non several benchmarks with significant margins.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 08:23:13 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Xu", "Minkai", ""], ["Wang", "Mingxuan", ""], ["Lin", "Zhouhan", ""], ["Zhou", "Hao", ""], ["Zhang", "Weinan", ""], ["Li", "Lei", ""]]}, {"id": "2012.02983", "submitter": "Shubham Vatsal", "authors": "Manish Chugani, Shubham Vatsal, Gopi Ramena, Sukumar Moharana, Naresh\n  Purre", "title": "On-Device Tag Generation for Unstructured Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  With the overwhelming transition to smart phones, storing important\ninformation in the form of unstructured text has become habitual to users of\nmobile devices. From grocery lists to drafts of emails and important speeches,\nusers store a lot of data in the form of unstructured text (for eg: in the\nNotes application) on their devices, leading to cluttering of data. This not\nonly prevents users from efficient navigation in the applications but also\nprecludes them from perceiving the relations that could be present across data\nin those applications. This paper proposes a novel pipeline to generate a set\nof tags using world knowledge based on the keywords and concepts present in\nunstructured textual data. These tags can then be used to summarize, categorize\nor search for the desired information thus enhancing user experience by\nallowing them to have a holistic outlook of the kind of information stored in\nthe form of unstructured text. In the proposed system, we use an on-device\n(mobile phone) efficient CNN model with pruned ConceptNet resource to achieve\nour goal. The architecture also presents a novel ranking algorithm to extract\nthe top n tags from any given text.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 09:18:43 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Chugani", "Manish", ""], ["Vatsal", "Shubham", ""], ["Ramena", "Gopi", ""], ["Moharana", "Sukumar", ""], ["Purre", "Naresh", ""]]}, {"id": "2012.02990", "submitter": "Shubham Vatsal", "authors": "Dhruval Jain, Arun D Prabhu, Shubham Vatsal, Gopi Ramena, Naresh Purre", "title": "Codeswitched Sentence Creation using Dependency Parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Codeswitching has become one of the most common occurrences across\nmultilingual speakers of the world, especially in countries like India which\nencompasses around 23 official languages with the number of bilingual speakers\nbeing around 300 million. The scarcity of Codeswitched data becomes a\nbottleneck in the exploration of this domain with respect to various Natural\nLanguage Processing (NLP) tasks. We thus present a novel algorithm which\nharnesses the syntactic structure of English grammar to develop grammatically\nsensible Codeswitched versions of English-Hindi, English-Marathi and\nEnglish-Kannada data. Apart from maintaining the grammatical sanity to a great\nextent, our methodology also guarantees abundant generation of data from a\nminuscule snapshot of given data. We use multiple datasets to showcase the\ncapabilities of our algorithm while at the same time we assess the quality of\ngenerated Codeswitched data using some qualitative metrics along with providing\nbaseline results for couple of NLP tasks.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 10:00:06 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Jain", "Dhruval", ""], ["Prabhu", "Arun D", ""], ["Vatsal", "Shubham", ""], ["Ramena", "Gopi", ""], ["Purre", "Naresh", ""]]}, {"id": "2012.03084", "submitter": "Modestas Filipavicius", "authors": "Modestas Filipavicius, Matteo Manica, Joris Cadow, Maria Rodriguez\n  Martinez", "title": "Pre-training Protein Language Models with Label-Agnostic Binding Pairs\n  Enhances Performance in Downstream Tasks", "comments": "20 pages, 12 figures, accepted to Machine Learning for Structural\n  Biology (MLSB) workshop at the 34th Conference on Neural Information\n  Processing Systems (NeurIPS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Less than 1% of protein sequences are structurally and functionally\nannotated. Natural Language Processing (NLP) community has recently embraced\nself-supervised learning as a powerful approach to learn representations from\nunlabeled text, in large part due to the attention-based context-aware\nTransformer models. In this work we present a modification to the RoBERTa model\nby inputting during pre-training a mixture of binding and non-binding protein\nsequences (from STRING database). However, the sequence pairs have no label to\nindicate their binding status, as the model relies solely on Masked Language\nModeling (MLM) objective during pre-training. After fine-tuning, such approach\nsurpasses models trained on single protein sequences for protein-protein\nbinding prediction, TCR-epitope binding prediction, cellular-localization and\nremote homology classification tasks. We suggest that the Transformer's\nattention mechanism contributes to protein binding site discovery. Furthermore,\nwe compress protein sequences by 64% with the Byte Pair Encoding (BPE)\nvocabulary consisting of 10K subwords, each around 3-4 amino acids long.\nFinally, to expand the model input space to even larger proteins and\nmulti-protein assemblies, we pre-train Longformer models that support 2,048\ntokens. Further work in token-level classification for secondary structure\nprediction is needed. Code available at:\nhttps://github.com/PaccMann/paccmann_proteomics\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 17:37:41 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Filipavicius", "Modestas", ""], ["Manica", "Matteo", ""], ["Cadow", "Joris", ""], ["Martinez", "Maria Rodriguez", ""]]}, {"id": "2012.03091", "submitter": "Keith Cortis", "authors": "Keith Cortis and Brian Davis", "title": "Over a Decade of Social Opinion Mining: A Systematic Review", "comments": "170 pages, 3 figures. This is a preprint of an article published in\n  Artificial Intelligence Review (2021)", "journal-ref": null, "doi": "10.1007/s10462-021-10030-2", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media popularity and importance is on the increase due to people using\nit for various types of social interaction across multiple channels. This\nsystematic review focuses on the evolving research area of Social Opinion\nMining, tasked with the identification of multiple opinion dimensions, such as\nsubjectivity, sentiment polarity, emotion, affect, sarcasm and irony, from\nuser-generated content represented across multiple social media platforms and\nin various media formats, like text, image, video and audio. Through Social\nOpinion Mining, natural language can be understood in terms of the different\nopinion dimensions, as expressed by humans. This contributes towards the\nevolution of Artificial Intelligence which in turn helps the advancement of\nseveral real-world use cases, such as customer service and decision making. A\nthorough systematic review was carried out on Social Opinion Mining research\nwhich totals 485 published studies and spans a period of twelve years between\n2007 and 2018. The in-depth analysis focuses on the social media platforms,\ntechniques, social datasets, language, modality, tools and technologies, and\nother aspects derived. Social Opinion Mining can be utilised in many\napplication areas, ranging from marketing, advertising and sales for\nproduct/service management, and in multiple domains and industries, such as\npolitics, technology, finance, healthcare, sports and government. The latest\ndevelopments in Social Opinion Mining beyond 2018 are also presented together\nwith future research directions, with the aim of leaving a wider academic and\nsocietal impact in several real-world applications.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 17:59:59 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 18:24:05 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Cortis", "Keith", ""], ["Davis", "Brian", ""]]}, {"id": "2012.03118", "submitter": "Takashi Kodama", "authors": "Takashi Kodama, Ribeka Tanaka, Sadao Kurohashi", "title": "Modeling and Utilizing User's Internal State in Movie Recommendation\n  Dialogue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intelligent dialogue systems are expected as a new interface between humans\nand machines. Such an intelligent dialogue system should estimate the user's\ninternal state (UIS) in dialogues and change its response appropriately\naccording to the estimation result. In this paper, we model the UIS in\ndialogues, taking movie recommendation dialogues as examples, and construct a\ndialogue system that changes its response based on the UIS. Based on the\ndialogue data analysis, we model the UIS as three elements: knowledge,\ninterest, and engagement. We train the UIS estimators on a dialogue corpus with\nthe modeled UIS's annotations. The estimators achieved high estimation\naccuracy. We also design response change rules that change the system's\nresponses according to each UIS. We confirmed that response changes using the\nresult of the UIS estimators improved the system utterances' naturalness in\nboth dialogue-wise evaluation and utterance-wise evaluation.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 20:50:53 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Kodama", "Takashi", ""], ["Tanaka", "Ribeka", ""], ["Kurohashi", "Sadao", ""]]}, {"id": "2012.03201", "submitter": "Arvind  Kiwelekar", "authors": "Arvind W Kiwelekar, Swanand Navandar, Dharmendra K. Yadav", "title": "A Two-Systems Perspective for Computational Thinking", "comments": "Accepted version of the paper for 12th International Conference on\n  Intelligent Human Interaction (IHCI 2020) held from 24th to 26th November\n  2020 at Exco-Daegu South Korea", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational Thinking (CT) has emerged as one of the vital thinking skills\nin recent times, especially for Science, Technology, Engineering and Management\n(STEM) graduates. Educators are in search of underlying cognitive models\nagainst which CT can be analyzed and evaluated. This paper suggests adopting\nKahneman's two-systems model as a framework to understand the computational\nthought process. Kahneman's two-systems model postulates that human thinking\nhappens at two levels, i.e. fast and slow thinking. This paper illustrates\nthrough examples that CT activities can be represented and analyzed using\nKahneman's two-systems model. The potential benefits of adopting Kahneman's\ntwo-systems perspective are that it helps us to fix the biases that cause\nerrors in our reasoning. Further, it also provides a set of heuristics to speed\nup reasoning activities.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 07:33:45 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Kiwelekar", "Arvind W", ""], ["Navandar", "Swanand", ""], ["Yadav", "Dharmendra K.", ""]]}, {"id": "2012.03370", "submitter": "Zahra Shekarchi", "authors": "Aida Nematzadeh, Zahra Shekarchi, Thomas L. Griffiths, and Suzanne\n  Stevenson", "title": "Competition in Cross-situational Word Learning: A Computational Study", "comments": "38 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Children learn word meanings by tapping into the commonalities across\ndifferent situations in which words are used and overcome the high level of\nuncertainty involved in early word learning experiences. We propose a modeling\nframework to investigate the role of mutual exclusivity bias - asserting\none-to-one mappings between words and their meanings - in reducing uncertainty\nin word learning. In a set of computational studies, we show that to\nsuccessfully learn word meanings in the face of uncertainty, a learner needs to\nuse two types of competition: words competing for association to a referent\nwhen learning from an observation and referents competing for a word when the\nword is used. Our work highlights the importance of an algorithmic-level\nanalysis to shed light on the utility of different mechanisms that can\nimplement the same computational-level theory.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 20:32:56 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 05:08:21 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Nematzadeh", "Aida", ""], ["Shekarchi", "Zahra", ""], ["Griffiths", "Thomas L.", ""], ["Stevenson", "Suzanne", ""]]}, {"id": "2012.03411", "submitter": "Vineel Pratap", "authors": "Vineel Pratap, Qiantong Xu, Anuroop Sriram, Gabriel Synnaeve, Ronan\n  Collobert", "title": "MLS: A Large-Scale Multilingual Dataset for Speech Research", "comments": null, "journal-ref": "Interspeech 2020", "doi": "10.21437/Interspeech.2020-2826", "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Multilingual LibriSpeech (MLS) dataset, a large\nmultilingual corpus suitable for speech research. The dataset is derived from\nread audiobooks from LibriVox and consists of 8 languages, including about\n44.5K hours of English and a total of about 6K hours for other languages.\nAdditionally, we provide Language Models (LM) and baseline Automatic Speech\nRecognition (ASR) models and for all the languages in our dataset. We believe\nsuch a large transcribed dataset will open new avenues in ASR and\nText-To-Speech (TTS) research. The dataset will be made freely available for\nanyone at http://www.openslr.org.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 01:53:45 GMT"}, {"version": "v2", "created": "Sat, 19 Dec 2020 09:18:21 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Pratap", "Vineel", ""], ["Xu", "Qiantong", ""], ["Sriram", "Anuroop", ""], ["Synnaeve", "Gabriel", ""], ["Collobert", "Ronan", ""]]}, {"id": "2012.03418", "submitter": "Yixin Tan", "authors": "Yixin Tan, Xiaomeng Wang, Tao Jia", "title": "From syntactic structure to semantic relationship: hypernym extraction\n  from definitions by recurrent neural networks using the part of speech\n  information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hyponym-hypernym relation is an essential element in the semantic\nnetwork. Identifying the hypernym from a definition is an important task in\nnatural language processing and semantic analysis. While a public dictionary\nsuch as WordNet works for common words, its application in domain-specific\nscenarios is limited. Existing tools for hypernym extraction either rely on\nspecific semantic patterns or focus on the word representation, which all\ndemonstrate certain limitations.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 02:18:49 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Tan", "Yixin", ""], ["Wang", "Xiaomeng", ""], ["Jia", "Tao", ""]]}, {"id": "2012.03437", "submitter": "Matthew Francis-Landau", "authors": "Matthew Francis-Landau", "title": "MFST: A Python OpenFST Wrapper With Support for Custom Semirings and\n  Jupyter Notebooks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.MS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces mFST, a new Python library for working with\nFinite-State Machines based on OpenFST. mFST is a thin wrapper for OpenFST and\nexposes all of OpenFST's methods for manipulating FSTs. Additionally, mFST is\nthe only Python wrapper for OpenFST that exposes OpenFST's ability to define a\ncustom semirings. This makes mFST ideal for developing models that involve\nlearning the weights on a FST or creating neuralized FSTs. mFST has been\ndesigned to be easy to get started with and has been previously used in\nhomework assignments for a NLP class as well in projects for integrating FSTs\nand neural networks. In this paper, we exhibit mFST API and how to use mFST to\nbuild a simple neuralized FST with PyTorch.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 03:36:54 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Francis-Landau", "Matthew", ""]]}, {"id": "2012.03468", "submitter": "Soroush Vosoughi Dr", "authors": "Lili Wang, Chongyang Gao, Jason Wei, Weicheng Ma, Ruibo Liu, Soroush\n  Vosoughi", "title": "An Empirical Survey of Unsupervised Text Representation Methods on\n  Twitter Data", "comments": "In proceedings of the 6th Workshop on Noisy User-generated Text\n  (W-NUT) at EMNLP 2020", "journal-ref": null, "doi": "10.18653/v1/2020.wnut-1.27", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The field of NLP has seen unprecedented achievements in recent years. Most\nnotably, with the advent of large-scale pre-trained Transformer-based language\nmodels, such as BERT, there has been a noticeable improvement in text\nrepresentation. It is, however, unclear whether these improvements translate to\nnoisy user-generated text, such as tweets. In this paper, we present an\nexperimental survey of a wide range of well-known text representation\ntechniques for the task of text clustering on noisy Twitter data. Our results\nindicate that the more advanced models do not necessarily work best on tweets\nand that more exploration in this area is needed.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 06:14:13 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Wang", "Lili", ""], ["Gao", "Chongyang", ""], ["Wei", "Jason", ""], ["Ma", "Weicheng", ""], ["Liu", "Ruibo", ""], ["Vosoughi", "Soroush", ""]]}, {"id": "2012.03477", "submitter": "Mingzhou Xu", "authors": "Mingzhou Xu, Liangyou Li, Derek. F. Wong, Qun Liu, Lidia S. Chao", "title": "Document Graph for Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous works have shown that contextual information can improve the\nperformance of neural machine translation (NMT). However, most existing\ndocument-level NMT methods failed to leverage contexts beyond a few set of\nprevious sentences. How to make use of the whole document as global contexts is\nstill a challenge. To address this issue, we hypothesize that a document can be\nrepresented as a graph that connects relevant contexts regardless of their\ndistances. We employ several types of relations, including adjacency, syntactic\ndependency, lexical consistency, and coreference, to construct the document\ngraph. Then, we incorporate both source and target graphs into the conventional\nTransformer architecture with graph convolutional networks. Experiments on\nvarious NMT benchmarks, including IWSLT English-French, Chinese-English, WMT\nEnglish-German and Opensubtitle English-Russian, demonstrate that using\ndocument graphs can significantly improve the translation quality.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 06:48:59 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 07:03:52 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Xu", "Mingzhou", ""], ["Li", "Liangyou", ""], ["Wong", "Derek. F.", ""], ["Liu", "Qun", ""], ["Chao", "Lidia S.", ""]]}, {"id": "2012.03502", "submitter": "Xiachong Feng", "authors": "Xiachong Feng, Xiaocheng Feng, Bing Qin, Xinwei Geng", "title": "Dialogue Discourse-Aware Graph Model and Data Augmentation for Meeting\n  Summarization", "comments": "IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meeting summarization is a challenging task due to its dynamic interaction\nnature among multiple speakers and lack of sufficient training data. Existing\nmethods view the meeting as a linear sequence of utterances while ignoring the\ndiverse relations between each utterance. Besides, the limited labeled data\nfurther hinders the ability of data-hungry neural models. In this paper, we try\nto mitigate the above challenges by introducing dialogue-discourse relations.\nFirst, we present a Dialogue Discourse-Dware Meeting Summarizer (DDAMS) to\nexplicitly model the interaction between utterances in a meeting by modeling\ndifferent discourse relations. The core module is a relational graph encoder,\nwhere the utterances and discourse relations are modeled in a graph interaction\nmanner. Moreover, we devise a Dialogue Discourse-Aware Data Augmentation\n(DDADA) strategy to construct a pseudo-summarization corpus from existing input\nmeetings, which is 20 times larger than the original dataset and can be used to\npretrain DDAMS. Experimental results on AMI and ICSI meeting datasets show that\nour full system can achieve SOTA performance. Our codes will be available at:\nhttps://github.com/xcfcode/DDAMS.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 07:51:38 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 05:49:13 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Feng", "Xiachong", ""], ["Feng", "Xiaocheng", ""], ["Qin", "Bing", ""], ["Geng", "Xinwei", ""]]}, {"id": "2012.03536", "submitter": "Jhih-Wei Chen", "authors": "Jhih-Wei Chen, Tsu-Jui Fu, Chen-Kang Lee, Wei-Yun Ma", "title": "H-FND: Hierarchical False-Negative Denoising for Distant Supervision\n  Relation Extraction", "comments": "The first two authors are equally contributed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although distant supervision automatically generates training data for\nrelation extraction, it also introduces false-positive (FP) and false-negative\n(FN) training instances to the generated datasets. Whereas both types of errors\ndegrade the final model performance, previous work on distant supervision\ndenoising focuses more on suppressing FP noise and less on resolving the FN\nproblem. We here propose H-FND, a hierarchical false-negative denoising\nframework for robust distant supervision relation extraction, as an FN\ndenoising solution. H-FND uses a hierarchical policy which first determines\nwhether non-relation (NA) instances should be kept, discarded, or revised\nduring the training process. For those learning instances which are to be\nrevised, the policy further reassigns them appropriate relations, making them\nbetter training inputs. Experiments on SemEval-2010 and TACRED were conducted\nwith controlled FN ratios that randomly turn the relations of training and\nvalidation instances into negatives to generate FN instances. In this setting,\nH-FND can revise FN instances correctly and maintains high F1 scores even when\n50% of the instances have been turned into negatives. Experiment on NYT10 is\nfurther conducted to shows that H-FND is applicable in a realistic setting.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 08:58:09 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 16:40:00 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Chen", "Jhih-Wei", ""], ["Fu", "Tsu-Jui", ""], ["Lee", "Chen-Kang", ""], ["Ma", "Wei-Yun", ""]]}, {"id": "2012.03539", "submitter": "Yunyi Yang", "authors": "Yunyi Yang, Yunhao Li, Xiaojun Quan", "title": "UBAR: Towards Fully End-to-End Task-Oriented Dialog Systems with GPT-2", "comments": "Accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents our task-oriented dialog system UBAR which models\ntask-oriented dialogs on a dialog session level. Specifically, UBAR is acquired\nby fine-tuning the large pre-trained unidirectional language model GPT-2 on the\nsequence of the entire dialog session which is composed of user utterance,\nbelief state, database result, system act, and system response of every dialog\nturn. Additionally, UBAR is evaluated in a more realistic setting, where its\ndialog context has access to user utterances and all content it generated such\nas belief states, system acts, and system responses. Experimental results on\nthe MultiWOZ datasets show that UBAR achieves state-of-the-art performances in\nmultiple settings, improving the combined score of response generation, policy\noptimization, and end-to-end modeling by 4.7, 3.5, and 9.4 points respectively.\nThorough analyses demonstrate that the session-level training sequence\nformulation and the generated dialog context are essential for UBAR to operate\nas a fully end-to-end task-oriented dialog system in real life. We also examine\nthe transfer ability of UBAR to new domains with limited data and provide\nvisualization and a case study to illustrate the advantages of UBAR in modeling\non a dialog session level.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 09:08:16 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 02:34:26 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Yang", "Yunyi", ""], ["Li", "Yunhao", ""], ["Quan", "Xiaojun", ""]]}, {"id": "2012.03551", "submitter": "Bin He", "authors": "Bin He, Xin Jiang, Jinghui Xiao, Qun Liu", "title": "KgPLM: Knowledge-guided Language Model Pre-training via Generative and\n  Discriminative Learning", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies on pre-trained language models have demonstrated their ability\nto capture factual knowledge and applications in knowledge-aware downstream\ntasks. In this work, we present a language model pre-training framework guided\nby factual knowledge completion and verification, and use the generative and\ndiscriminative approaches cooperatively to learn the model. Particularly, we\ninvestigate two learning schemes, named two-tower scheme and pipeline scheme,\nin training the generator and discriminator with shared parameter. Experimental\nresults on LAMA, a set of zero-shot cloze-style question answering tasks, show\nthat our model contains richer factual knowledge than the conventional\npre-trained language models. Furthermore, when fine-tuned and evaluated on the\nMRQA shared tasks which consists of several machine reading comprehension\ndatasets, our model achieves the state-of-the-art performance, and gains large\nimprovements on NewsQA (+1.26 F1) and TriviaQA (+1.56 F1) over RoBERTa.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 09:39:25 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["He", "Bin", ""], ["Jiang", "Xin", ""], ["Xiao", "Jinghui", ""], ["Liu", "Qun", ""]]}, {"id": "2012.03573", "submitter": "Bin He", "authors": "Bin He, Di Zhou, Jing Xie, Jinghui Xiao, Xin Jiang, Qun Liu", "title": "PPKE: Knowledge Representation Learning by Path-based Pre-training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entities may have complex interactions in a knowledge graph (KG), such as\nmulti-step relationships, which can be viewed as graph contextual information\nof the entities. Traditional knowledge representation learning (KRL) methods\nusually treat a single triple as a training unit, and neglect most of the graph\ncontextual information exists in the topological structure of KGs. In this\nstudy, we propose a Path-based Pre-training model to learn Knowledge\nEmbeddings, called PPKE, which aims to integrate more graph contextual\ninformation between entities into the KRL model. Experiments demonstrate that\nour model achieves state-of-the-art results on several benchmark datasets for\nlink prediction and relation prediction tasks, indicating that our model\nprovides a feasible way to take advantage of graph contextual information in\nKGs.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 10:29:30 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["He", "Bin", ""], ["Zhou", "Di", ""], ["Xie", "Jing", ""], ["Xiao", "Jinghui", ""], ["Jiang", "Xin", ""], ["Liu", "Qun", ""]]}, {"id": "2012.03619", "submitter": "Satya Almasian", "authors": "Dennis Aumiller, Satya Almasian, Sebastian Lackner and Michael Gertz", "title": "Structural Text Segmentation of Legal Documents", "comments": null, "journal-ref": null, "doi": "10.1145/3462757.3466085", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The growing complexity of legal cases has lead to an increasing interest in\nlegal information retrieval systems that can effectively satisfy user-specific\ninformation needs. However, such downstream systems typically require documents\nto be properly formatted and segmented, which is often done with relatively\nsimple pre-processing steps, disregarding topical coherence of segments.\nSystems generally rely on representations of individual sentences or\nparagraphs, which may lack crucial context, or document-level representations,\nwhich are too long for meaningful search results. To address this issue, we\npropose a segmentation system that can predict topical coherence of sequential\ntext segments spanning several paragraphs, effectively segmenting a document\nand providing a more balanced representation for downstream applications. We\nbuild our model on top of popular transformer networks and formulate structural\ntext segmentation as topical change detection, by performing a series of\nindependent classifications that allow for efficient fine-tuning on\ntask-specific data. We crawl a novel dataset consisting of roughly $74,000$\nonline Terms-of-Service documents, including hierarchical topic annotations,\nwhich we use for training. Results show that our proposed system significantly\noutperforms baselines, and adapts well to structural peculiarities of legal\ndocuments. We release both data and trained models to the research community\nfor future work.https://github.com/dennlinger/TopicalChange\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 12:09:37 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 11:38:28 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Aumiller", "Dennis", ""], ["Almasian", "Satya", ""], ["Lackner", "Sebastian", ""], ["Gertz", "Michael", ""]]}, {"id": "2012.03656", "submitter": "Saibo Geng", "authors": "Saibo Geng, Diego Antognini", "title": "An Enhanced MeanSum Method For Generating Hotel Multi-Review\n  Summarizations", "comments": "Work is not complete and may midlead readers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-document summaritazion is the process of taking multiple texts as input\nand producing a short summary text based on the content of input texts. Up\nuntil recently, multi-document summarizers are mostly supervised extractive.\nHowever, supervised methods require datasets of large, paired document-summary\nexamples which are rare and expensive to produce. In 2018, an unsupervised\nmulti-document abstractive summarization method(Meansum) was proposed by Chu\nand Liu, and demonstrated competitive performances comparing to extractive\nmethods. Despite good evaluation results on automatic metrics, Meansum has\nmultiple limitations, notably the inability of dealing with multiple aspects.\nThe aim of this work was to use Multi-Aspect Masker(MAM) as content selector to\naddress the issue with multi-aspect. Moreover, we propose a regularizer to\ncontrol the length of the generated summaries. Through a series of experiments\non the hotel dataset from Trip Advisor, we validate our assumption and show\nthat our improved model achieves higher ROUGE, Sentiment Accuracy than the\noriginal Meansum method and also beats/ comprarable/close to the supervised\nbaseline.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 13:16:01 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 14:43:28 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Geng", "Saibo", ""], ["Antognini", "Diego", ""]]}, {"id": "2012.03662", "submitter": "Zhaokai Wang", "authors": "Zhaokai Wang, Renda Bao, Qi Wu, Si Liu", "title": "Confidence-aware Non-repetitive Multimodal Transformers for TextCaps", "comments": "9 pages; Accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When describing an image, reading text in the visual scene is crucial to\nunderstand the key information. Recent work explores the TextCaps task, i.e.\nimage captioning with reading Optical Character Recognition (OCR) tokens, which\nrequires models to read text and cover them in generated captions. Existing\napproaches fail to generate accurate descriptions because of their (1) poor\nreading ability; (2) inability to choose the crucial words among all extracted\nOCR tokens; (3) repetition of words in predicted captions. To this end, we\npropose a Confidence-aware Non-repetitive Multimodal Transformers (CNMT) to\ntackle the above challenges. Our CNMT consists of a reading, a reasoning and a\ngeneration modules, in which Reading Module employs better OCR systems to\nenhance text reading ability and a confidence embedding to select the most\nnoteworthy tokens. To address the issue of word redundancy in captions, our\nGeneration Module includes a repetition mask to avoid predicting repeated word\nin captions. Our model outperforms state-of-the-art models on TextCaps dataset,\nimproving from 81.0 to 93.0 in CIDEr. Our source code is publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 13:20:12 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 04:32:18 GMT"}, {"version": "v3", "created": "Sun, 21 Mar 2021 14:28:04 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Wang", "Zhaokai", ""], ["Bao", "Renda", ""], ["Wu", "Qi", ""], ["Liu", "Si", ""]]}, {"id": "2012.03665", "submitter": "Justin Ormont", "authors": "Phuong Pham, Vivek Jain, Lukas Dauterman, Justin Ormont, Navendu Jain", "title": "DeepTriage: Automated Transfer Assistance for Incidents in Cloud\n  Services", "comments": null, "journal-ref": "KDD '20: Proceedings of the 26th ACM SIGKDD International\n  Conference on Knowledge Discovery & Data Mining August 2020. Pages 3281-3289", "doi": "10.1145/3394486.3403380", "report-no": null, "categories": "cs.DC cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As cloud services are growing and generating high revenues, the cost of\ndowntime in these services is becoming significantly expensive. To reduce loss\nand service downtime, a critical primary step is to execute incident triage,\nthe process of assigning a service incident to the correct responsible team, in\na timely manner. An incorrect assignment risks additional incident reroutings\nand increases its time to mitigate by 10x. However, automated incident triage\nin large cloud services faces many challenges: (1) a highly imbalanced incident\ndistribution from a large number of teams, (2) wide variety in formats of input\ndata or data sources, (3) scaling to meet production-grade requirements, and\n(4) gaining engineers' trust in using machine learning recommendations. To\naddress these challenges, we introduce DeepTriage, an intelligent incident\ntransfer service combining multiple machine learning techniques - gradient\nboosted classifiers, clustering methods, and deep neural networks - in an\nensemble to recommend the responsible team to triage an incident. Experimental\nresults on real incidents in Microsoft Azure show that our service achieves\n82.9% F1 score. For highly impacted incidents, DeepTriage achieves F1 score\nfrom 76.3% - 91.3%. We have applied best practices and state-of-the-art\nframeworks to scale DeepTriage to handle incident routing for all cloud\nservices. DeepTriage has been deployed in Azure since October 2017 and is used\nby thousands of teams daily.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 03:10:11 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Pham", "Phuong", ""], ["Jain", "Vivek", ""], ["Dauterman", "Lukas", ""], ["Ormont", "Justin", ""], ["Jain", "Navendu", ""]]}, {"id": "2012.03678", "submitter": "Alkesh Patel", "authors": "Alkesh Patel, Akanksha Bindal, Hadas Kotek, Christopher Klein, Jason\n  Williams", "title": "Generating Natural Questions from Images for Multimodal Assistants", "comments": "4 pages, 1 reference page, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating natural, diverse, and meaningful questions from images is an\nessential task for multimodal assistants as it confirms whether they have\nunderstood the object and scene in the images properly. The research in visual\nquestion answering (VQA) and visual question generation (VQG) is a great step.\nHowever, this research does not capture questions that a visually-abled person\nwould ask multimodal assistants. Recently published datasets such as KB-VQA,\nFVQA, and OK-VQA try to collect questions that look for external knowledge\nwhich makes them appropriate for multimodal assistants. However, they still\ncontain many obvious and common-sense questions that humans would not usually\nask a digital assistant. In this paper, we provide a new benchmark dataset that\ncontains questions generated by human annotators keeping in mind what they\nwould ask multimodal digital assistants. Large scale annotations for several\nhundred thousand images are expensive and time-consuming, so we also present an\neffective way of automatically generating questions from unseen images. In this\npaper, we present an approach for generating diverse and meaningful questions\nthat consider image content and metadata of image (e.g., location, associated\nkeyword). We evaluate our approach using standard evaluation metrics such as\nBLEU, METEOR, ROUGE, and CIDEr to show the relevance of generated questions\nwith human-provided questions. We also measure the diversity of generated\nquestions using generative strength and inventiveness metrics. We report new\nstate-of-the-art results on the public and our datasets.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 19:12:23 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Patel", "Alkesh", ""], ["Bindal", "Akanksha", ""], ["Kotek", "Hadas", ""], ["Klein", "Christopher", ""], ["Williams", "Jason", ""]]}, {"id": "2012.03709", "submitter": "Yilin Zhao", "authors": "Yilin Zhao, Zhuosheng Zhang, Hai Zhao", "title": "Reference Knowledgeable Network for Machine Reading Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-choice Machine Reading Comprehension (MRC) as a challenge requires\nmodel to select the most appropriate answer from a set of candidates given\npassage and question. Most of the existing researches focus on the modeling of\nthe task datasets without explicitly referring to external fine-grained\nknowledge sources, which is supposed to greatly make up the deficiency of the\ngiven passage. Thus we propose a novel reference-based knowledge enhancement\nmodel called Reference Knowledgeable Network (RekNet), which refines critical\ninformation from the passage and quote explicit knowledge in necessity. In\ndetail, RekNet refines fine-grained critical information and defines it as\nReference Span, then quotes explicit knowledge quadruples by the co-occurrence\ninformation of Reference Span and candidates. The proposed RekNet is evaluated\non three multi-choice MRC benchmarks: RACE, DREAM and Cosmos QA, which shows\nconsistent and remarkable performance improvement with observable statistical\nsignificance level over strong baselines.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 14:11:33 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 12:49:41 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Zhao", "Yilin", ""], ["Zhang", "Zhuosheng", ""], ["Zhao", "Hai", ""]]}, {"id": "2012.03755", "submitter": "Bob Coecke", "authors": "Bob Coecke, Giovanni de Felice, Konstantinos Meichanetzidis, Alexis\n  Toumi", "title": "Foundations for Near-Term Quantum Natural Language Processing", "comments": "43 pages, lots of pictures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide conceptual and mathematical foundations for near-term quantum\nnatural language processing (QNLP), and do so in quantum computer scientist\nfriendly terms. We opted for an expository presentation style, and provide\nreferences for supporting empirical evidence and formal statements concerning\nmathematical generality.\n  We recall how the quantum model for natural language that we employ\ncanonically combines linguistic meanings with rich linguistic structure, most\nnotably grammar. In particular, the fact that it takes a quantum-like model to\ncombine meaning and structure, establishes QNLP as quantum-native, on par with\nsimulation of quantum systems. Moreover, the now leading Noisy\nIntermediate-Scale Quantum (NISQ) paradigm for encoding classical data on\nquantum hardware, variational quantum circuits, makes NISQ exceptionally\nQNLP-friendly: linguistic structure can be encoded as a free lunch, in contrast\nto the apparently exponentially expensive classical encoding of grammar.\n  Quantum speed-up for QNLP tasks has already been established in previous work\nwith Will Zeng. Here we provide a broader range of tasks which all enjoy the\nsame advantage.\n  Diagrammatic reasoning is at the heart of QNLP. Firstly, the quantum model\ninterprets language as quantum processes via the diagrammatic formalism of\ncategorical quantum mechanics. Secondly, these diagrams are via ZX-calculus\ntranslated into quantum circuits. Parameterisations of meanings then become the\ncircuit variables to be learned.\n  Our encoding of linguistic structure within quantum circuits also embodies a\nnovel approach for establishing word-meanings that goes beyond the current\nstandards in mainstream AI, by placing linguistic structure at the heart of\nWittgenstein's meaning-is-context.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 14:49:33 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Coecke", "Bob", ""], ["de Felice", "Giovanni", ""], ["Meichanetzidis", "Konstantinos", ""], ["Toumi", "Alexis", ""]]}, {"id": "2012.03756", "submitter": "Konstantinos Meichanetzidis", "authors": "Konstantinos Meichanetzidis, Alexis Toumi, Giovanni de Felice, Bob\n  Coecke", "title": "Grammar-Aware Question-Answering on Quantum Computers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language processing (NLP) is at the forefront of great advances in\ncontemporary AI, and it is arguably one of the most challenging areas of the\nfield. At the same time, with the steady growth of quantum hardware and notable\nimprovements towards implementations of quantum algorithms, we are approaching\nan era when quantum computers perform tasks that cannot be done on classical\ncomputers with a reasonable amount of resources. This provides a new range of\nopportunities for AI, and for NLP specifically. Earlier work has already\ndemonstrated a potential quantum advantage for NLP in a number of manners: (i)\nalgorithmic speedups for search-related or classification tasks, which are the\nmost dominant tasks within NLP, (ii) exponentially large quantum state spaces\nallow for accommodating complex linguistic structures, (iii) novel models of\nmeaning employing density matrices naturally model linguistic phenomena such as\nhyponymy and linguistic ambiguity, among others. In this work, we perform the\nfirst implementation of an NLP task on noisy intermediate-scale quantum (NISQ)\nhardware. Sentences are instantiated as parameterised quantum circuits. We\nencode word-meanings in quantum states and we explicitly account for\ngrammatical structure, which even in mainstream NLP is not commonplace, by\nfaithfully hard-wiring it as entangling operations. This makes our approach to\nquantum natural language processing (QNLP) particularly NISQ-friendly. Our\nnovel QNLP model shows concrete promise for scalability as the quality of the\nquantum hardware improves in the near future.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 14:49:34 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Meichanetzidis", "Konstantinos", ""], ["Toumi", "Alexis", ""], ["de Felice", "Giovanni", ""], ["Coecke", "Bob", ""]]}, {"id": "2012.03763", "submitter": "Pilar Oplustil-Gallegos", "authors": "Pilar Oplustil-Gallegos and Simon King", "title": "Using previous acoustic context to improve Text-to-Speech synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Many speech synthesis datasets, especially those derived from audiobooks,\nnaturally comprise sequences of utterances. Nevertheless, such data are\ncommonly treated as individual, unordered utterances both when training a model\nand at inference time. This discards important prosodic phenomena above the\nutterance level. In this paper, we leverage the sequential nature of the data\nusing an acoustic context encoder that produces an embedding of the previous\nutterance audio. This is input to the decoder in a Tacotron 2 model. The\nembedding is also used for a secondary task, providing additional supervision.\nWe compare two secondary tasks: predicting the ordering of utterance pairs, and\npredicting the embedding of the current utterance audio. Results show that the\nrelation between consecutive utterances is informative: our proposed model\nsignificantly improves naturalness over a Tacotron 2 baseline.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 15:00:18 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Oplustil-Gallegos", "Pilar", ""], ["King", "Simon", ""]]}, {"id": "2012.03805", "submitter": "Ruibin Yuan", "authors": "Ruibin Yuan, Ge Zhang, Anqiao Yang, Xinyue Zhang", "title": "Diverse Melody Generation from Chinese Lyrics via Mutual Information\n  Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.MM eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose to adapt the method of mutual information\nmaximization into the task of Chinese lyrics conditioned melody generation to\nimprove the generation quality and diversity. We employ scheduled sampling and\nforce decoding techniques to improve the alignment between lyrics and melodies.\nWith our method, which we called Diverse Melody Generation (DMG), a\nsequence-to-sequence model learns to generate diverse melodies heavily\ndepending on the input style ids, while keeping the tonality and improving the\nalignment. The experimental results of subjective tests show that DMG can\ngenerate more pleasing and coherent tunes than baseline methods.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 15:48:01 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Yuan", "Ruibin", ""], ["Zhang", "Ge", ""], ["Yang", "Anqiao", ""], ["Zhang", "Xinyue", ""]]}, {"id": "2012.03833", "submitter": "Timothee Mickus", "authors": "Timothee Mickus, Timoth\\'ee Bernard, Denis Paperno", "title": "What Meaning-Form Correlation Has to Compose With", "comments": null, "journal-ref": "Proceedings of the 28th International Conference on Computational\n  Linguistics (2020) 3737-3749", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Compositionality is a widely discussed property of natural languages,\nalthough its exact definition has been elusive. We focus on the proposal that\ncompositionality can be assessed by measuring meaning-form correlation. We\nanalyze meaning-form correlation on three sets of languages: (i) artificial toy\nlanguages tailored to be compositional, (ii) a set of English dictionary\ndefinitions, and (iii) a set of English sentences drawn from literature. We\nfind that linguistic phenomena such as synonymy and ungrounded stop-words weigh\non MFC measurements, and that straightforward methods to mitigate their effects\nhave widely varying results depending on the dataset they are applied to. Data\nand code are made publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 16:33:23 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Mickus", "Timothee", ""], ["Bernard", "Timoth\u00e9e", ""], ["Paperno", "Denis", ""]]}, {"id": "2012.03845", "submitter": "Jean-Baptiste Camps", "authors": "Jean-Baptiste Camps, Thibault Cl\\'erice, Ariane Pinche", "title": "Stylometry for Noisy Medieval Data: Evaluating Paul Meyer's Hagiographic\n  Hypothesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stylometric analysis of medieval vernacular texts is still a significant\nchallenge: the importance of scribal variation, be it spelling or more\nsubstantial, as well as the variants and errors introduced in the tradition,\ncomplicate the task of the would-be stylometrist. Basing the analysis on the\nstudy of the copy from a single hand of several texts can partially mitigate\nthese issues (Camps and Cafiero, 2013), but the limited availability of\ncomplete diplomatic transcriptions might make this difficult. In this paper, we\nuse a workflow combining handwritten text recognition and stylometric analysis,\napplied to the case of the hagiographic works contained in MS BnF, fr. 412. We\nseek to evaluate Paul Meyer's hypothesis about the constitution of groups of\nhagiographic works, as well as to examine potential authorial groupings in a\nvastly anonymous corpus.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 16:48:34 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Camps", "Jean-Baptiste", ""], ["Cl\u00e9rice", "Thibault", ""], ["Pinche", "Ariane", ""]]}, {"id": "2012.03855", "submitter": "Jos\\'e Lopes", "authors": "Jos\\'e Lopes, Francisco J. Chiyah Garcia and Helen Hastie", "title": "The Lab vs The Crowd: An Investigation into Data Quality for Neural\n  Dialogue Models", "comments": "Accepted at Human in the Loop Dialogue Systems Workshop @NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Challenges around collecting and processing quality data have hampered\nprogress in data-driven dialogue models. Previous approaches are moving away\nfrom costly, resource-intensive lab settings, where collection is slow but\nwhere the data is deemed of high quality. The advent of crowd-sourcing\nplatforms, such as Amazon Mechanical Turk, has provided researchers with an\nalternative cost-effective and rapid way to collect data. However, the\ncollection of fluid, natural spoken or textual interaction can be challenging,\nparticularly between two crowd-sourced workers. In this study, we compare the\nperformance of dialogue models for the same interaction task but collected in\ntwo different settings: in the lab vs. crowd-sourced. We find that fewer lab\ndialogues are needed to reach similar accuracy, less than half the amount of\nlab data as crowd-sourced data. We discuss the advantages and disadvantages of\neach data collection method.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 17:02:00 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Lopes", "Jos\u00e9", ""], ["Garcia", "Francisco J. Chiyah", ""], ["Hastie", "Helen", ""]]}, {"id": "2012.03864", "submitter": "Olga Golovneva", "authors": "Lizhen Tan and Olga Golovneva", "title": "Evaluating Cross-Lingual Transfer Learning Approaches in Multilingual\n  Conversational Agent Models", "comments": "7 pages, 3 figures, 3 Tables. Accepted to be presented at COLING 2020\n  conference: https://coling2020.org/pages/accepted_papers_industry_track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the recent explosion in popularity of voice assistant devices, there is\na growing interest in making them available to user populations in additional\ncountries and languages. However, to provide the highest accuracy and best\nperformance for specific user populations, most existing voice assistant models\nare developed individually for each region or language, which requires linear\ninvestment of effort. In this paper, we propose a general multilingual model\nframework for Natural Language Understanding (NLU) models, which can help\nbootstrap new language models faster and reduce the amount of effort required\nto develop each language separately. We explore how different deep learning\narchitectures affect multilingual NLU model performance. Our experimental\nresults show that these multilingual models can reach same or better\nperformance compared to monolingual models across language-specific test data\nwhile require less effort in creating features and model maintenance.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 17:14:52 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Tan", "Lizhen", ""], ["Golovneva", "Olga", ""]]}, {"id": "2012.03929", "submitter": "Lin Pan", "authors": "Haode Qi, Lin Pan, Atin Sood, Abhishek Shah, Ladislav Kunc, Mo Yu,\n  Saloni Potdar", "title": "Benchmarking Commercial Intent Detection Services with Practice-Driven\n  Evaluations", "comments": "Accepted at NAACL2021 Industry Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intent detection is a key component of modern goal-oriented dialog systems\nthat accomplish a user task by predicting the intent of users' text input.\nThere are three primary challenges in designing robust and accurate intent\ndetection models. First, typical intent detection models require a large amount\nof labeled data to achieve high accuracy. Unfortunately, in practical scenarios\nit is more common to find small, unbalanced, and noisy datasets. Secondly, even\nwith large training data, the intent detection models can see a different\ndistribution of test data when being deployed in the real world, leading to\npoor accuracy. Finally, a practical intent detection model must be\ncomputationally efficient in both training and single query inference so that\nit can be used continuously and re-trained frequently. We benchmark intent\ndetection methods on a variety of datasets. Our results show that Watson\nAssistant's intent detection model outperforms other commercial solutions and\nis comparable to large pretrained language models while requiring only a\nfraction of computational resources and training data. Watson Assistant\ndemonstrates a higher degree of robustness when the training and test\ndistributions differ.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 18:58:57 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 18:17:44 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Qi", "Haode", ""], ["Pan", "Lin", ""], ["Sood", "Atin", ""], ["Shah", "Abhishek", ""], ["Kunc", "Ladislav", ""], ["Yu", "Mo", ""], ["Potdar", "Saloni", ""]]}, {"id": "2012.03942", "submitter": "Allen Roush", "authors": "Allen Roush", "title": "CX DB8: A queryable extractive summarizer and semantic search engine", "comments": "6 pages, 4 figures, System Demonstration paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Competitive Debate's increasingly technical nature has left competitors\nlooking for tools to accelerate evidence production. We find that the unique\ntype of extractive summarization performed by competitive debaters -\nsummarization with a bias towards a particular target meaning - can be\nperformed using the latest innovations in unsupervised pre-trained text\nvectorization models. We introduce CX_DB8, a queryable word-level extractive\nsummarizer and evidence creation framework, which allows for rapid, biasable\nsummarization of arbitarily sized texts. CX_DB8s usage of the embedding\nframework Flair means that as the underlying models improve, CX_DB8 will also\nimprove. We observe that CX_DB8 also functions as a semantic search engine, and\nhas application as a supplement to traditional \"find\" functionality in programs\nand webpages. CX_DB8 is currently used by competitive debaters and is made\navailable to the public at https://github.com/Hellisotherpeople/CX_DB8\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 05:37:32 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Roush", "Allen", ""]]}, {"id": "2012.04005", "submitter": "Veysel Kocaman Vk", "authors": "Veysel Kocaman, David Talby", "title": "Improving Clinical Document Understanding on COVID-19 Research with\n  Spark NLP", "comments": "Accepted to SDU (Scientific Document Understanding) workshop at AAAI\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Following the global COVID-19 pandemic, the number of scientific papers\nstudying the virus has grown massively, leading to increased interest in\nautomated literate review. We present a clinical text mining system that\nimproves on previous efforts in three ways. First, it can recognize over 100\ndifferent entity types including social determinants of health, anatomy, risk\nfactors, and adverse events in addition to other commonly used clinical and\nbiomedical entities. Second, the text processing pipeline includes assertion\nstatus detection, to distinguish between clinical facts that are present,\nabsent, conditional, or about someone other than the patient. Third, the deep\nlearning models used are more accurate than previously available, leveraging an\nintegrated pipeline of state-of-the-art pretrained named entity recognition\nmodels, and improving on the previous best performing benchmarks for assertion\nstatus detection. We illustrate extracting trends and insights, e.g. most\nfrequent disorders and symptoms, and most common vital signs and EKG findings,\nfrom the COVID-19 Open Research Dataset (CORD-19). The system is built using\nthe Spark NLP library which natively supports scaling to use distributed\nclusters, leveraging GPUs, configurable and reusable NLP pipelines, healthcare\nspecific embeddings, and the ability to train models to support new entity\ntypes or human languages with no code changes.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 19:17:05 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Kocaman", "Veysel", ""], ["Talby", "David", ""]]}, {"id": "2012.04056", "submitter": "Viktor Schlegel", "authors": "Viktor Schlegel, Goran Nenadic, Riza Batista-Navarro", "title": "Semantics Altering Modifications for Evaluating Comprehension in Machine\n  Reading", "comments": "AAAI 2021, final version. 7 pages content + 2 pages references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Advances in NLP have yielded impressive results for the task of machine\nreading comprehension (MRC), with approaches having been reported to achieve\nperformance comparable to that of humans. In this paper, we investigate whether\nstate-of-the-art MRC models are able to correctly process Semantics Altering\nModifications (SAM): linguistically-motivated phenomena that alter the\nsemantics of a sentence while preserving most of its lexical surface form. We\npresent a method to automatically generate and align challenge sets featuring\noriginal and altered examples. We further propose a novel evaluation\nmethodology to correctly assess the capability of MRC systems to process these\nexamples independent of the data they were optimised on, by discounting for\neffects introduced by domain shift. In a large-scale empirical study, we apply\nthe methodology in order to evaluate extractive MRC models with regard to their\ncapability to correctly process SAM-enriched data. We comprehensively cover 12\ndifferent state-of-the-art neural architecture configurations and four training\ndatasets and find that -- despite their well-known remarkable performance --\noptimised models consistently struggle to correctly process semantically\naltered data.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 21:00:42 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 10:21:07 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Schlegel", "Viktor", ""], ["Nenadic", "Goran", ""], ["Batista-Navarro", "Riza", ""]]}, {"id": "2012.04080", "submitter": "Kalpani Anuradha Welivita", "authors": "Anuradha Welivita and Pearl Pu", "title": "A Taxonomy of Empathetic Response Intents in Human Social Conversations", "comments": "In Proceedings of the 28th International Conference on Computational\n  Linguistics (COLING 2020). 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Open-domain conversational agents or chatbots are becoming increasingly\npopular in the natural language processing community. One of the challenges is\nenabling them to converse in an empathetic manner. Current neural response\ngeneration methods rely solely on end-to-end learning from large scale\nconversation data to generate dialogues. This approach can produce socially\nunacceptable responses due to the lack of large-scale quality data used to\ntrain the neural models. However, recent work has shown the promise of\ncombining dialogue act/intent modelling and neural response generation. This\nhybrid method improves the response quality of chatbots and makes them more\ncontrollable and interpretable. A key element in dialog intent modelling is the\ndevelopment of a taxonomy. Inspired by this idea, we have manually labeled 500\nresponse intents using a subset of a sizeable empathetic dialogue dataset (25K\ndialogues). Our goal is to produce a large-scale taxonomy for empathetic\nresponse intents. Furthermore, using lexical and machine learning methods, we\nautomatically analysed both speaker and listener utterances of the entire\ndataset with identified response intents and 32 emotion categories. Finally, we\nuse information visualization methods to summarize emotional dialogue exchange\npatterns and their temporal progression. These results reveal novel and\nimportant empathy patterns in human-human open-domain conversations and can\nserve as heuristics for hybrid approaches.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 21:56:45 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Welivita", "Anuradha", ""], ["Pu", "Pearl", ""]]}, {"id": "2012.04094", "submitter": "Xinwei Li", "authors": "Xinwei Li, Yuanyuan Zhang, Xiaodan Zhuang, Daben Liu", "title": "Frame-level SpecAugment for Deep Convolutional Neural Networks in Hybrid\n  ASR Systems", "comments": "To appear in SLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by SpecAugment -- a data augmentation method for end-to-end ASR\nsystems, we propose a frame-level SpecAugment method (f-SpecAugment) to improve\nthe performance of deep convolutional neural networks (CNN) for hybrid HMM\nbased ASR systems. Similar to the utterance level SpecAugment, f-SpecAugment\nperforms three transformations: time warping, frequency masking, and time\nmasking. Instead of applying the transformations at the utterance level,\nf-SpecAugment applies them to each convolution window independently during\ntraining. We demonstrate that f-SpecAugment is more effective than the\nutterance level SpecAugment for deep CNN based hybrid models. We evaluate the\nproposed f-SpecAugment on 50-layer Self-Normalizing Deep CNN (SNDCNN) acoustic\nmodels trained with up to 25000 hours of training data. We observe\nf-SpecAugment reduces WER by 0.5-4.5% relatively across different ASR tasks for\nfour languages. As the benefits of augmentation techniques tend to diminish as\ntraining data size increases, the large scale training reported is important in\nunderstanding the effectiveness of f-SpecAugment. Our experiments demonstrate\nthat even with 25k training data, f-SpecAugment is still effective. We also\ndemonstrate that f-SpecAugment has benefits approximately equivalent to\ndoubling the amount of training data for deep CNNs.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 22:27:13 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Li", "Xinwei", ""], ["Zhang", "Yuanyuan", ""], ["Zhuang", "Xiaodan", ""], ["Liu", "Daben", ""]]}, {"id": "2012.04099", "submitter": "Charith Peris", "authors": "Charith Peris, Gokmen Oz, Khadige Abboud, Venkata sai Varada, Prashan\n  Wanigasekara, Haidar Khan", "title": "Using multiple ASR hypotheses to boost i18n NLU performance", "comments": "9 pages, 4 Figures, 5 Tables, Accepted to ICON 2020 (17th\n  International Conference on Natural Language Processing)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Current voice assistants typically use the best hypothesis yielded by their\nAutomatic Speech Recognition (ASR) module as input to their Natural Language\nUnderstanding (NLU) module, thereby losing helpful information that might be\nstored in lower-ranked ASR hypotheses. We explore the change in performance of\nNLU associated tasks when utilizing five-best ASR hypotheses when compared to\nstatus quo for two language datasets, German and Portuguese. To harvest\ninformation from the ASR five-best, we leverage extractive summarization and\njoint extractive-abstractive summarization models for Domain Classification\n(DC) experiments while using a sequence-to-sequence model with a pointer\ngenerator network for Intent Classification (IC) and Named Entity Recognition\n(NER) multi-task experiments. For the DC full test set, we observe significant\nimprovements of up to 7.2% and 15.5% in micro-averaged F1 scores, for German\nand Portuguese, respectively. In cases where the best ASR hypothesis was not an\nexact match to the transcribed utterance (mismatched test set), we see\nimprovements of up to 6.7% and 8.8% micro-averaged F1 scores, for German and\nPortuguese, respectively. For IC and NER multi-task experiments, when\nevaluating on the mismatched test set, we see improvements across all domains\nin German and in 17 out of 19 domains in Portuguese (improvements based on\nchange in SeMER scores). Our results suggest that the use of multiple ASR\nhypotheses, as opposed to one, can lead to significant performance improvements\nin the DC task for these non-English datasets. In addition, it could lead to\nsignificant improvement in the performance of IC and NER tasks in cases where\nthe ASR model makes mistakes.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 22:37:38 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 18:44:37 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Peris", "Charith", ""], ["Oz", "Gokmen", ""], ["Abboud", "Khadige", ""], ["Varada", "Venkata sai", ""], ["Wanigasekara", "Prashan", ""], ["Khan", "Haidar", ""]]}, {"id": "2012.04169", "submitter": "Qiwei Sun", "authors": "David Q. Sun, Hadas Kotek, Christopher Klein, Mayank Gupta, William\n  Li, Jason D. Williams", "title": "Improving Human-Labeled Data through Dynamic Automatic Conflict\n  Resolution", "comments": "Conference Paper at COLING 2020:\n  https://www.aclweb.org/anthology/2020.coling-main.316/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper develops and implements a scalable methodology for (a) estimating\nthe noisiness of labels produced by a typical crowdsourcing semantic annotation\ntask, and (b) reducing the resulting error of the labeling process by as much\nas 20-30% in comparison to other common labeling strategies. Importantly, this\nnew approach to the labeling process, which we name Dynamic Automatic Conflict\nResolution (DACR), does not require a ground truth dataset and is instead based\non inter-project annotation inconsistencies. This makes DACR not only more\naccurate but also available to a broad range of labeling tasks. In what follows\nwe present results from a text classification task performed at scale for a\ncommercial personal assistant, and evaluate the inherent ambiguity uncovered by\nthis annotation strategy as compared to other common labeling strategies.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 02:22:09 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Sun", "David Q.", ""], ["Kotek", "Hadas", ""], ["Klein", "Christopher", ""], ["Gupta", "Mayank", ""], ["Li", "William", ""], ["Williams", "Jason D.", ""]]}, {"id": "2012.04188", "submitter": "Wenhan Wang", "authors": "Wenhan Wang, Kechi Zhang, Ge Li, Zhi Jin", "title": "Learning to Represent Programs with Heterogeneous Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Program source code contains complex structure information, which can be\nrepresented in structured data forms like trees or graphs. To acquire the\nstructural information in source code, most existing researches use abstract\nsyntax trees (AST). A group of works add additional edges to ASTs to convert\nsource code into graphs and use graph neural networks to learn representations\nfor program graphs. Although these works provide additional control or data\nflow information to ASTs for downstream tasks, they neglect an important aspect\nof structure information in AST itself: the different types of nodes and edges.\nIn ASTs, different nodes contain different kinds of information like variables\nor control flow, and the relation between a node and all its children can also\nbe different.\n  To address the information of node and edge types, we bring the idea of\nheterogeneous graphs to learning on source code and present a new formula of\nbuilding heterogeneous program graphs from ASTs with additional type\ninformation for nodes and edges. We use the ASDL grammar of programming\nlanguage to define the node and edge types of program graphs. Then we use\nheterogeneous graph neural networks to learn on these graphs. We evaluate our\napproach on two tasks: code comment generation and method naming. Both tasks\nrequire reasoning on the semantics of complete code snippets. Experiment\nresults show that our approach outperforms baseline models, including\nhomogeneous graph-based models, showing that leveraging the type information of\nnodes and edges in program graphs can help in learning program semantics.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 03:14:28 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Wang", "Wenhan", ""], ["Zhang", "Kechi", ""], ["Li", "Ge", ""], ["Jin", "Zhi", ""]]}, {"id": "2012.04194", "submitter": "Zewei Chu", "authors": "Zewei Chu, Karl Stratos, Kevin Gimpel", "title": "Unsupervised Label Refinement Improves Dataless Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dataless text classification is capable of classifying documents into\npreviously unseen labels by assigning a score to any document paired with a\nlabel description. While promising, it crucially relies on accurate\ndescriptions of the label set for each downstream task. This reliance causes\ndataless classifiers to be highly sensitive to the choice of label descriptions\nand hinders the broader application of dataless classification in practice. In\nthis paper, we ask the following question: how can we improve dataless text\nclassification using the inputs of the downstream task dataset? Our primary\nsolution is a clustering based approach. Given a dataless classifier, our\napproach refines its set of predictions using k-means clustering. We\ndemonstrate the broad applicability of our approach by improving the\nperformance of two widely used classifier architectures, one that encodes\ntext-category pairs with two independent encoders and one with a single joint\nencoder. Experiments show that our approach consistently improves dataless\nclassification across different datasets and makes the classifier more robust\nto the choice of label descriptions.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 03:37:50 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Chu", "Zewei", ""], ["Stratos", "Karl", ""], ["Gimpel", "Kevin", ""]]}, {"id": "2012.04203", "submitter": "Yuqi Kong", "authors": "Yuqi Kong, Fanchao Meng, Benjamin Carterette", "title": "A Topological Method for Comparing Document Semantics", "comments": "9 pages, 3 tables, 9th International Conference on Natural Language\n  Processing (NLP 2020)", "journal-ref": "pp. 143-151, 2020. CS & IT - CSCP 2020", "doi": "10.5121/csit.2020.101411", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Comparing document semantics is one of the toughest tasks in both Natural\nLanguage Processing and Information Retrieval. To date, on one hand, the tools\nfor this task are still rare. On the other hand, most relevant methods are\ndevised from the statistic or the vector space model perspectives but nearly\nnone from a topological perspective. In this paper, we hope to make a different\nsound. A novel algorithm based on topological persistence for comparing\nsemantics similarity between two documents is proposed. Our experiments are\nconducted on a document dataset with human judges' results. A collection of\nstate-of-the-art methods are selected for comparison. The experimental results\nshow that our algorithm can produce highly human-consistent results, and also\nbeats most state-of-the-art methods though ties with NLTK.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 04:21:40 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Kong", "Yuqi", ""], ["Meng", "Fanchao", ""], ["Carterette", "Benjamin", ""]]}, {"id": "2012.04207", "submitter": "Sosuke Kobayashi", "authors": "Sosuke Kobayashi, Sho Yokoi, Jun Suzuki, Kentaro Inui", "title": "Efficient Estimation of Influence of a Training Instance", "comments": "This is an extended version of the paper presented at SustaiNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the influence of a training instance on a neural network model\nleads to improving interpretability. However, it is difficult and inefficient\nto evaluate the influence, which shows how a model's prediction would be\nchanged if a training instance were not used. In this paper, we propose an\nefficient method for estimating the influence. Our method is inspired by\ndropout, which zero-masks a sub-network and prevents the sub-network from\nlearning each training instance. By switching between dropout masks, we can use\nsub-networks that learned or did not learn each training instance and estimate\nits influence. Through experiments with BERT and VGGNet on classification\ndatasets, we demonstrate that the proposed method can capture training\ninfluences, enhance the interpretability of error predictions, and cleanse the\ntraining dataset for improving generalization.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 04:31:38 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Kobayashi", "Sosuke", ""], ["Yokoi", "Sho", ""], ["Suzuki", "Jun", ""], ["Inui", "Kentaro", ""]]}, {"id": "2012.04233", "submitter": "Chun Yuan Yuan", "authors": "Chunyuan Yuan, Qianwen Ma, Wei Zhou, Jizhong Han, Songlin Hu", "title": "Early Detection of Fake News by Utilizing the Credibility of News,\n  Publishers, and Users Based on Weakly Supervised Learning", "comments": "Accepted as a long paper at COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The dissemination of fake news significantly affects personal reputation and\npublic trust. Recently, fake news detection has attracted tremendous attention,\nand previous studies mainly focused on finding clues from news content or\ndiffusion path. However, the required features of previous models are often\nunavailable or insufficient in early detection scenarios, resulting in poor\nperformance. Thus, early fake news detection remains a tough challenge.\nIntuitively, the news from trusted and authoritative sources or shared by many\nusers with a good reputation is more reliable than other news. Using the\ncredibility of publishers and users as prior weakly supervised information, we\ncan quickly locate fake news in massive news and detect them in the early\nstages of dissemination.\n  In this paper, we propose a novel Structure-aware Multi-head Attention\nNetwork (SMAN), which combines the news content, publishing, and reposting\nrelations of publishers and users, to jointly optimize the fake news detection\nand credibility prediction tasks. In this way, we can explicitly exploit the\ncredibility of publishers and users for early fake news detection. We conducted\nexperiments on three real-world datasets, and the results show that SMAN can\ndetect fake news in 4 hours with an accuracy of over 91%, which is much faster\nthan the state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 05:53:33 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 01:27:46 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Yuan", "Chunyuan", ""], ["Ma", "Qianwen", ""], ["Zhou", "Wei", ""], ["Han", "Jizhong", ""], ["Hu", "Songlin", ""]]}, {"id": "2012.04276", "submitter": "Yinuo Guo", "authors": "Yinuo Guo, Hualei Zhu, Zeqi Lin, Bei Chen, Jian-Guang Lou, Dongmei\n  Zhang", "title": "Revisiting Iterative Back-Translation from the Perspective of\n  Compositional Generalization", "comments": "accepted in AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human intelligence exhibits compositional generalization (i.e., the capacity\nto understand and produce unseen combinations of seen components), but current\nneural seq2seq models lack such ability. In this paper, we revisit iterative\nback-translation, a simple yet effective semi-supervised method, to investigate\nwhether and how it can improve compositional generalization. In this work: (1)\nWe first empirically show that iterative back-translation substantially\nimproves the performance on compositional generalization benchmarks (CFQ and\nSCAN). (2) To understand why iterative back-translation is useful, we carefully\nexamine the performance gains and find that iterative back-translation can\nincreasingly correct errors in pseudo-parallel data. (3) To further encourage\nthis mechanism, we propose curriculum iterative back-translation, which better\nimproves the quality of pseudo-parallel data, thus further improving the\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 08:43:13 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Guo", "Yinuo", ""], ["Zhu", "Hualei", ""], ["Lin", "Zeqi", ""], ["Chen", "Bei", ""], ["Lou", "Jian-Guang", ""], ["Zhang", "Dongmei", ""]]}, {"id": "2012.04281", "submitter": "Junxian He", "authors": "Junxian He, Wojciech Kry\\'sci\\'nski, Bryan McCann, Nazneen Rajani,\n  Caiming Xiong", "title": "CTRLsum: Towards Generic Controllable Text Summarization", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current summarization systems yield generic summaries that are disconnected\nfrom users' preferences and expectations. To address this limitation, we\npresent CTRLsum, a novel framework for controllable summarization. Our approach\nenables users to control multiple aspects of generated summaries by interacting\nwith the summarization system through textual input in the form of a set of\nkeywords or descriptive prompts. Using a single unified model, CTRLsum is able\nto achieve a broad scope of summary manipulation at inference time without\nrequiring additional human annotations or pre-defining a set of control aspects\nduring training. We quantitatively demonstrate the effectiveness of our\napproach on three domains of summarization datasets and five control aspects:\n1) entity-centric and 2) length-controllable summarization, 3) contribution\nsummarization on scientific papers, 4) invention purpose summarization on\npatent filings, and 5) question-guided summarization on news articles in a\nreading comprehension setting. Moreover, when used in a standard, uncontrolled\nsummarization setting, CTRLsum achieves state-of-the-art results on the\nCNN/DailyMail dataset. Code and model checkpoints are available at\nhttps://github.com/salesforce/ctrl-sum\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 08:54:36 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["He", "Junxian", ""], ["Kry\u015bci\u0144ski", "Wojciech", ""], ["McCann", "Bryan", ""], ["Rajani", "Nazneen", ""], ["Xiong", "Caiming", ""]]}, {"id": "2012.04293", "submitter": "Aykut Erdem", "authors": "Tayfun Ates, Muhammed Samil Atesoglu, Cagatay Yigit, Ilker Kesen, Mert\n  Kobas, Erkut Erdem, Aykut Erdem, Tilbe Goksun, Deniz Yuret", "title": "CRAFT: A Benchmark for Causal Reasoning About Forces and inTeractions", "comments": "Submitted to the 35th Conference on Neural Information Processing\n  Systems (NeurIPS 2021) Track on Datasets and Benchmarks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Humans are able to perceive, understand and reason about physical events.\nDeveloping models with similar physical understanding capabilities is a\nlong-standing goal of artificial intelligence. As a step towards this goal, in\nthis work, we introduce CRAFT, a new visual question answering dataset that\nrequires causal reasoning about physical forces and object interactions. It\ncontains 58K video and question pairs that are generated from 10K videos from\n20 different virtual environments, containing various objects in motion that\ninteract with each other and the scene. Two question categories from CRAFT\ninclude previously studied descriptive and counterfactual questions. Besides,\ninspired by the theories of force dynamics in cognitive linguistics, we\nintroduce new question categories that involve understanding the interactions\nof objects through the notions of cause, enable, and prevent. Our results\ndemonstrate that even though these tasks seem to be simple and intuitive for\nhumans, the evaluated baseline models, including existing state-of-the-art\nmethods, do not yet deal with the challenges posed in our benchmark dataset.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 09:11:32 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 10:55:23 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Ates", "Tayfun", ""], ["Atesoglu", "Muhammed Samil", ""], ["Yigit", "Cagatay", ""], ["Kesen", "Ilker", ""], ["Kobas", "Mert", ""], ["Erdem", "Erkut", ""], ["Erdem", "Aykut", ""], ["Goksun", "Tilbe", ""], ["Yuret", "Deniz", ""]]}, {"id": "2012.04307", "submitter": "Ale\\v{s} \\v{Z}agar", "authors": "Ale\\v{s} \\v{Z}agar, Marko Robnik-\\v{S}ikonja", "title": "Cross-lingual Approach to Abstractive Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic text summarization extracts important information from texts and\npresents the information in the form of a summary. Abstractive summarization\napproaches progressed significantly by switching to deep neural networks, but\nresults are not yet satisfactory, especially for languages where large training\nsets do not exist. In several natural language processing tasks, cross-lingual\nmodel transfers are successfully applied in low-resource languages. For\nsummarization such cross-lingual model transfer was so far not attempted due to\na non-reusable decoder side of neural models. In our work, we used a pretrained\nEnglish summarization model based on deep neural networks and\nsequence-to-sequence architecture to summarize Slovene news articles. We solved\nthe problem of inadequate decoder by using an additional language model for\ntarget language evaluation. We developed several models with different\nproportions of target language data for fine-tuning. The results were assessed\nwith automatic evaluation measures and with small-scale human evaluation. The\nresults show that summaries of cross-lingual models fine-tuned with relatively\nsmall amount of target language data are useful and of similar quality to an\nabstractive summarizer trained with much more data in the target language.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 09:30:38 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["\u017dagar", "Ale\u0161", ""], ["Robnik-\u0160ikonja", "Marko", ""]]}, {"id": "2012.04332", "submitter": "Eyal Orbach", "authors": "Eyal Orbach (Bar Ilan University), Yoav Goldberg (Bar Ilan University\n  and Allen Institute for Artificial Intelligence)", "title": "Facts2Story: Controlling Text Generation by Key Facts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advancements in self-attention neural network architectures have\nraised the bar for open-ended text generation. Yet, while current methods are\ncapable of producing a coherent text which is several hundred words long,\nattaining control over the content that is being generated -- as well as\nevaluating it -- are still open questions. We propose a controlled generation\ntask which is based on expanding a sequence of facts, expressed in natural\nlanguage, into a longer narrative. We introduce human-based evaluation metrics\nfor this task, as well as a method for deriving a large training dataset. We\nevaluate three methods on this task, based on fine-tuning pre-trained models.\nWe show that while auto-regressive, unidirectional Language Models such as GPT2\nproduce better fluency, they struggle to adhere to the requested facts. We\npropose a plan-and-cloze model (using fine-tuned XLNet) which produces\ncompetitive fluency while adhering to the requested content.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 10:14:29 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Orbach", "Eyal", "", "Bar Ilan University"], ["Goldberg", "Yoav", "", "Bar Ilan University\n  and Allen Institute for Artificial Intelligence"]]}, {"id": "2012.04334", "submitter": "Lingyong Yan", "authors": "Lingyong Yan, Xianpei Han, Le Sun, Fangchao Liu and Ning Bian", "title": "From Bag of Sentences to Document: Distantly Supervised Relation\n  Extraction via Machine Reading Comprehension", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distant supervision (DS) is a promising approach for relation extraction but\noften suffers from the noisy label problem. Traditional DS methods usually\nrepresent an entity pair as a bag of sentences and denoise labels using\nmulti-instance learning techniques. The bag-based paradigm, however, fails to\nleverage the inter-sentence-level and the entity-level evidence for relation\nextraction, and their denoising algorithms are often specialized and\ncomplicated. In this paper, we propose a new DS paradigm--document-based\ndistant supervision, which models relation extraction as a document-based\nmachine reading comprehension (MRC) task. By re-organizing all sentences about\nan entity as a document and extracting relations via querying the document with\nrelation-specific questions, the document-based DS paradigm can simultaneously\nencode and exploit all sentence-level, inter-sentence-level, and entity-level\nevidence. Furthermore, we design a new loss function--DSLoss (distant\nsupervision loss), which can effectively train MRC models using only\n$\\langle$document, question, answer$\\rangle$ tuples, therefore noisy label\nproblem can be inherently resolved. Experiments show that our method achieves\nnew state-of-the-art DS performance.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 10:16:27 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 03:05:41 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Yan", "Lingyong", ""], ["Han", "Xianpei", ""], ["Sun", "Le", ""], ["Liu", "Fangchao", ""], ["Bian", "Ning", ""]]}, {"id": "2012.04373", "submitter": "Zihan Liu", "authors": "Zihan Liu, Yan Xu, Tiezheng Yu, Wenliang Dai, Ziwei Ji, Samuel\n  Cahyawijaya, Andrea Madotto, Pascale Fung", "title": "CrossNER: Evaluating Cross-Domain Named Entity Recognition", "comments": "Accepted in AAAI-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-domain named entity recognition (NER) models are able to cope with the\nscarcity issue of NER samples in target domains. However, most of the existing\nNER benchmarks lack domain-specialized entity types or do not focus on a\ncertain domain, leading to a less effective cross-domain evaluation. To address\nthese obstacles, we introduce a cross-domain NER dataset (CrossNER), a\nfully-labeled collection of NER data spanning over five diverse domains with\nspecialized entity categories for different domains. Additionally, we also\nprovide a domain-related corpus since using it to continue pre-training\nlanguage models (domain-adaptive pre-training) is effective for the domain\nadaptation. We then conduct comprehensive experiments to explore the\neffectiveness of leveraging different levels of the domain corpus and\npre-training strategies to do domain-adaptive pre-training for the cross-domain\ntask. Results show that focusing on the fractional corpus containing\ndomain-specialized entities and utilizing a more challenging pre-training\nstrategy in domain-adaptive pre-training are beneficial for the NER domain\nadaptation, and our proposed method can consistently outperform existing\ncross-domain NER baselines. Nevertheless, experiments also illustrate the\nchallenge of this cross-domain NER task. We hope that our dataset and baselines\nwill catalyze research in the NER domain adaptation area. The code and data are\navailable at https://github.com/zliucr/CrossNER.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 11:31:55 GMT"}, {"version": "v2", "created": "Sun, 13 Dec 2020 07:43:16 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Liu", "Zihan", ""], ["Xu", "Yan", ""], ["Yu", "Tiezheng", ""], ["Dai", "Wenliang", ""], ["Ji", "Ziwei", ""], ["Cahyawijaya", "Samuel", ""], ["Madotto", "Andrea", ""], ["Fung", "Pascale", ""]]}, {"id": "2012.04380", "submitter": "Ryan Beal Mr.", "authors": "Ryan Beal, Stuart E. Middleton, Timothy J. Norman, Sarvapali D.\n  Ramchurn", "title": "Combining Machine Learning and Human Experts to Predict Match Outcomes\n  in Football: A Baseline Model", "comments": "Pre-print. Accepted at: The Thirty-Third Annual Conference on\n  Innovative Applications of Artificial Intelligence (IAAI-21). 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a new application-focused benchmark dataset and\nresults from a set of baseline Natural Language Processing and Machine Learning\nmodels for prediction of match outcomes for games of football (soccer). By\ndoing so we give a baseline for the prediction accuracy that can be achieved\nexploiting both statistical match data and contextual articles from human\nsports journalists. Our dataset is focuses on a representative time-period over\n6 seasons of the English Premier League, and includes newspaper match previews\nfrom The Guardian. The models presented in this paper achieve an accuracy of\n63.18% showing a 6.9% boost on the traditional statistical methods.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 11:52:14 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Beal", "Ryan", ""], ["Middleton", "Stuart E.", ""], ["Norman", "Timothy J.", ""], ["Ramchurn", "Sarvapali D.", ""]]}, {"id": "2012.04395", "submitter": "Yuan Zhang", "authors": "Yuan Zhang, Zhiyang Teng, Yue Zhang", "title": "End-to-End Chinese Parsing Exploiting Lexicons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chinese parsing has traditionally been solved by three pipeline systems\nincluding word-segmentation, part-of-speech tagging and dependency parsing\nmodules. In this paper, we propose an end-to-end Chinese parsing model based on\ncharacter inputs which jointly learns to output word segmentation,\npart-of-speech tags and dependency structures. In particular, our parsing model\nrelies on word-char graph attention networks, which can enrich the character\ninputs with external word knowledge. Experiments on three Chinese parsing\nbenchmark datasets show the effectiveness of our models, achieving the\nstate-of-the-art results on end-to-end Chinese parsing.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 12:24:36 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Zhang", "Yuan", ""], ["Teng", "Zhiyang", ""], ["Zhang", "Yue", ""]]}, {"id": "2012.04443", "submitter": "Stefanos Angelidis", "authors": "Stefanos Angelidis, Reinald Kim Amplayo, Yoshihiko Suhara, Xiaolan\n  Wang, Mirella Lapata", "title": "Extractive Opinion Summarization in Quantized Transformer Spaces", "comments": "To appear in Transactions of the Association for Computational\n  Linguistics (TACL); 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Quantized Transformer (QT), an unsupervised system for\nextractive opinion summarization. QT is inspired by Vector-Quantized\nVariational Autoencoders, which we repurpose for popularity-driven\nsummarization. It uses a clustering interpretation of the quantized space and a\nnovel extraction algorithm to discover popular opinions among hundreds of\nreviews, a significant step towards opinion summarization of practical scope.\nIn addition, QT enables controllable summarization without further training, by\nutilizing properties of the quantized space to extract aspect-specific\nsummaries. We also make publicly available SPACE, a large-scale evaluation\nbenchmark for opinion summarizers, comprising general and aspect-specific\nsummaries for 50 hotels. Experiments demonstrate the promise of our approach,\nwhich is validated by human studies where judges showed clear preference for\nour method over competitive baselines.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 14:23:46 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Angelidis", "Stefanos", ""], ["Amplayo", "Reinald Kim", ""], ["Suhara", "Yoshihiko", ""], ["Wang", "Xiaolan", ""], ["Lapata", "Mirella", ""]]}, {"id": "2012.04538", "submitter": "Soroush Vosoughi Dr", "authors": "Chris Miller and Soroush Vosoughi", "title": "Big Green at WNUT 2020 Shared Task-1: Relation Extraction as\n  Contextualized Sequence Classification", "comments": "Proceedings of the 6th Workshop on Noisy User-generated Text (W-NUT)\n  at EMNLP 2020", "journal-ref": null, "doi": "10.18653/v1/2020.wnut-1.36", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Relation and event extraction is an important task in natural language\nprocessing. We introduce a system which uses contextualized knowledge graph\ncompletion to classify relations and events between known entities in a noisy\ntext environment. We report results which show that our system is able to\neffectively extract relations and events from a dataset of wet lab protocols.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 06:38:53 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Miller", "Chris", ""], ["Vosoughi", "Soroush", ""]]}, {"id": "2012.04539", "submitter": "Soroush Vosoughi Dr", "authors": "Dylan Whang and Soroush Vosoughi", "title": "Dartmouth CS at WNUT-2020 Task 2: Informative COVID-19 Tweet\n  Classification Using BERT", "comments": "Proceedings of the 6th Workshop on Noisy User-generated Text (W-NUT)\n  at EMNLP 2020", "journal-ref": null, "doi": "10.18653/v1/2020.wnut-1.72", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We describe the systems developed for the WNUT-2020 shared task 2,\nidentification of informative COVID-19 English Tweets. BERT is a highly\nperformant model for Natural Language Processing tasks. We increased BERT's\nperformance in this classification task by fine-tuning BERT and concatenating\nits embeddings with Tweet-specific features and training a Support Vector\nMachine (SVM) for classification (henceforth called BERT+). We compared its\nperformance to a suite of machine learning models. We used a Twitter specific\ndata cleaning pipeline and word-level TF-IDF to extract features for the\nnon-BERT models. BERT+ was the top performing model with an F1-score of 0.8713.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 07:55:31 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Whang", "Dylan", ""], ["Vosoughi", "Soroush", ""]]}, {"id": "2012.04540", "submitter": "Soroush Vosoughi Dr", "authors": "Weicheng Ma, Ruibo Liu, Lili Wang, Soroush Vosoughi", "title": "Improvements and Extensions on Metaphor Detection", "comments": null, "journal-ref": null, "doi": "10.18653/v1/2021.unimplicit-1.5", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Metaphors are ubiquitous in human language. The metaphor detection task (MD)\naims at detecting and interpreting metaphors from written language, which is\ncrucial in natural language understanding (NLU) research. In this paper, we\nintroduce a pre-trained Transformer-based model into MD. Our model outperforms\nthe previous state-of-the-art models by large margins in our evaluations, with\nrelative improvements on the F-1 score from 5.33% to 28.39%. Second, we extend\nMD to a classification task about the metaphoricity of an entire piece of text\nto make MD applicable in more general NLU scenes. Finally, we clean up the\nimproper or outdated annotations in one of the MD benchmark datasets and\nre-benchmark it with our Transformer-based model. This approach could be\napplied to other existing MD datasets as well, since the metaphoricity\nannotations in these benchmark datasets may be outdated. Future research\nefforts are also necessary to build an up-to-date and well-annotated dataset\nconsisting of longer and more complex texts.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 08:17:42 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Ma", "Weicheng", ""], ["Liu", "Ruibo", ""], ["Wang", "Lili", ""], ["Vosoughi", "Soroush", ""]]}, {"id": "2012.04545", "submitter": "Angelo Ziletti", "authors": "Angelo Ziletti, Christoph Berns, Oliver Treichel, Thomas Weber,\n  Jennifer Liang, Stephanie Kammerath, Marion Schwaerzler, Jagatheswari\n  Virayah, David Ruau, Xin Ma, Andreas Mattern", "title": "Discovering key topics from short, real-world medical inquiries via\n  natural language processing and unsupervised learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Millions of unsolicited medical inquiries are received by pharmaceutical\ncompanies every year. It has been hypothesized that these inquiries represent a\ntreasure trove of information, potentially giving insight into matters\nregarding medicinal products and the associated medical treatments. However,\ndue to the large volume and specialized nature of the inquiries, it is\ndifficult to perform timely, recurrent, and comprehensive analyses. Here, we\npropose a machine learning approach based on natural language processing and\nunsupervised learning to automatically discover key topics in real-world\nmedical inquiries from customers. This approach does not require ontologies nor\nannotations. The discovered topics are meaningful and medically relevant, as\njudged by medical information specialists, thus demonstrating that unsolicited\nmedical inquiries are a source of valuable customer insights. Our work paves\nthe way for the machine-learning-driven analysis of medical inquiries in the\npharmaceutical industry, which ultimately aims at improving patient care.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 16:37:34 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Ziletti", "Angelo", ""], ["Berns", "Christoph", ""], ["Treichel", "Oliver", ""], ["Weber", "Thomas", ""], ["Liang", "Jennifer", ""], ["Kammerath", "Stephanie", ""], ["Schwaerzler", "Marion", ""], ["Virayah", "Jagatheswari", ""], ["Ruau", "David", ""], ["Ma", "Xin", ""], ["Mattern", "Andreas", ""]]}, {"id": "2012.04575", "submitter": "Judit Acs", "authors": "Judit Acs and Andras Kornai", "title": "The Role of Interpretable Patterns in Deep Learning for Morphology", "comments": "Best paper at the Hungarian NLP conference (MSZNY2020)", "journal-ref": "XVI. Magyar Sz\\'am\\'it\\'og\\'epes Nyelv\\'eszeti Konferencia, 2020,\n  page 171-179 (MSZNY2020)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We examine the role of character patterns in three tasks: morphological\nanalysis, lemmatization and copy. We use a modified version of the standard\nsequence-to-sequence model, where the encoder is a pattern matching network.\nEach pattern scores all possible N character long subwords (substrings) on the\nsource side, and the highest scoring subword's score is used to initialize the\ndecoder as well as the input to the attention mechanism. This method allows\nlearning which subwords of the input are important for generating the output.\nBy training the models on the same source but different target, we can compare\nwhat subwords are important for different tasks and how they relate to each\nother. We define a similarity metric, a generalized form of the Jaccard\nsimilarity, and assign a similarity score to each pair of the three tasks that\nwork on the same source but may differ in target. We examine how these three\ntasks are related to each other in 12 languages. Our code is publicly\navailable.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 17:20:20 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Acs", "Judit", ""], ["Kornai", "Andras", ""]]}, {"id": "2012.04584", "submitter": "Gautier Izacard", "authors": "Gautier Izacard and Edouard Grave", "title": "Distilling Knowledge from Reader to Retriever for Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of information retrieval is an important component of many natural\nlanguage processing systems, such as open domain question answering. While\ntraditional methods were based on hand-crafted features, continuous\nrepresentations based on neural networks recently obtained competitive results.\nA challenge of using such methods is to obtain supervised data to train the\nretriever model, corresponding to pairs of query and support documents. In this\npaper, we propose a technique to learn retriever models for downstream tasks,\ninspired by knowledge distillation, and which does not require annotated pairs\nof query and documents. Our approach leverages attention scores of a reader\nmodel, used to solve the task based on retrieved documents, to obtain synthetic\nlabels for the retriever. We evaluate our method on question answering,\nobtaining state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 17:36:34 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Izacard", "Gautier", ""], ["Grave", "Edouard", ""]]}, {"id": "2012.04585", "submitter": "Oren Tsur", "authors": "Stepan Zakharov, Omri Hadar, Tovit Hakak, Dina Grossman, Yifat\n  Ben-David Kolikant, Oren Tsur", "title": "Discourse Parsing of Contentious, Non-Convergent Online Discussions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Online discourse is often perceived as polarized and unproductive. While some\nconversational discourse parsing frameworks are available, they do not\nnaturally lend themselves to the analysis of contentious and polarizing\ndiscussions. Inspired by the Bakhtinian theory of Dialogism, we propose a novel\ntheoretical and computational framework, better suited for non-convergent\ndiscussions. We redefine the measure of a successful discussion, and develop a\nnovel discourse annotation schema which reflects a hierarchy of discursive\nstrategies. We consider an array of classification models -- from Logistic\nRegression to BERT. We also consider various feature types and representations,\ne.g., LIWC categories, standard embeddings, conversational sequences, and\nnon-conversational discourse markers learnt separately. Given the 31 labels in\nthe tagset, an average F-Score of 0.61 is achieved if we allow a different\nmodel for each tag, and 0.526 with a single model. The promising results\nachieved in annotating discussions according to the proposed schema paves the\nway for a number of downstream tasks and applications such as early detection\nof discussion trajectories, active moderation of open discussions, and\nteacher-assistive bots. Finally, we share the first labeled dataset of\ncontentious non-convergent online discussions.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 17:36:39 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Zakharov", "Stepan", ""], ["Hadar", "Omri", ""], ["Hakak", "Tovit", ""], ["Grossman", "Dina", ""], ["Kolikant", "Yifat Ben-David", ""], ["Tsur", "Oren", ""]]}, {"id": "2012.04631", "submitter": "Didac Suris Coll-Vinent", "authors": "D\\'idac Sur\\'is, Dave Epstein, Carl Vondrick", "title": "Globetrotter: Unsupervised Multilingual Translation from Visual\n  Alignment", "comments": "19 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-language machine translation without parallel corpora is challenging\nbecause there is no explicit supervision between languages. Existing\nunsupervised methods typically rely on topological properties of the language\nrepresentations. We introduce a framework that instead uses the visual modality\nto align multiple languages, using images as the bridge between them. We\nestimate the cross-modal alignment between language and images, and use this\nestimate to guide the learning of cross-lingual representations. Our language\nrepresentations are trained jointly in one model with a single stage.\nExperiments with fifty-two languages show that our method outperforms baselines\non unsupervised word-level and sentence-level translation using retrieval.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 18:50:40 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Sur\u00eds", "D\u00eddac", ""], ["Epstein", "Dave", ""], ["Vondrick", "Carl", ""]]}, {"id": "2012.04682", "submitter": "Leo Tam", "authors": "Leo K. Tam and Xiaosong Wang and Daguang Xu", "title": "Transformer Query-Target Knowledge Discovery (TEND): Drug Discovery from\n  CORD-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work established skip-gram word2vec models could be used to mine\nknowledge in the materials science literature for the discovery of\nthermoelectrics. Recent transformer architectures have shown great progress in\nlanguage modeling and associated fine-tuned tasks, but they have yet to be\nadapted for drug discovery. We present a RoBERTa transformer-based method that\nextends the masked language token prediction using query-target conditioning to\ntreat the specificity challenge. The transformer discovery method entails\nseveral benefits over the word2vec method including domain-specific (antiviral)\nanalogy performance, negation handling, and flexible query analysis (specific)\nand is demonstrated on influenza drug discovery. To stimulate COVID-19\nresearch, we release an influenza clinical trials and antiviral analogies\ndataset used in conjunction with the COVID-19 Open Research Dataset Challenge\n(CORD-19) literature dataset in the study. We examine k-shot fine-tuning to\nimprove the downstream analogies performance as well as to mine analogies for\nmodel explainability. Further, the query-target analysis is verified in a\nforward chaining analysis against the influenza drug clinical trials dataset,\nbefore adapted for COVID-19 drugs (combinations and side-effects) and on-going\nclinical trials. In consideration of the present topic, we release the model,\ndataset, and code.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 04:30:31 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 00:09:17 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Tam", "Leo K.", ""], ["Wang", "Xiaosong", ""], ["Xu", "Daguang", ""]]}, {"id": "2012.04687", "submitter": "Thibault Cordier", "authors": "Thibault Cordier, Tanguy Urvoy, Lina M. Rojas-Barahona, Fabrice\n  Lef\\`evre", "title": "Diluted Near-Optimal Expert Demonstrations for Guiding Dialogue\n  Stochastic Policy Optimisation", "comments": "8 pages, Accepted at Human in the Loop Dialogue Systems Workshop,\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A learning dialogue agent can infer its behaviour from interactions with the\nusers. These interactions can be taken from either human-to-human or\nhuman-machine conversations. However, human interactions are scarce and costly,\nmaking learning from few interactions essential. One solution to speedup the\nlearning process is to guide the agent's exploration with the help of an\nexpert. We present in this paper several imitation learning strategies for\ndialogue policy where the guiding expert is a near-optimal handcrafted policy.\nWe incorporate these strategies with state-of-the-art reinforcement learning\nmethods based on Q-learning and actor-critic. We notably propose a randomised\nexploration policy which allows for a seamless hybridisation of the learned\npolicy and the expert. Our experiments show that our hybridisation strategy\noutperforms several baselines, and that it can accelerate the learning when\nfacing real humans.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 15:00:36 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Cordier", "Thibault", ""], ["Urvoy", "Tanguy", ""], ["Rojas-Barahona", "Lina M.", ""], ["Lef\u00e8vre", "Fabrice", ""]]}, {"id": "2012.04698", "submitter": "Nishtha Madaan", "authors": "Nishtha Madaan, Inkit Padhi, Naveen Panwar, Diptikalyan Saha", "title": "Generate Your Counterfactuals: Towards Controlled Counterfactual\n  Generation for Text", "comments": "Accepted at AAAI Conference on Artificial Intelligence (AAAI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning has seen tremendous growth recently, which has led to larger\nadoption of ML systems for educational assessments, credit risk, healthcare,\nemployment, criminal justice, to name a few. The trustworthiness of ML and NLP\nsystems is a crucial aspect and requires a guarantee that the decisions they\nmake are fair and robust. Aligned with this, we propose a framework GYC, to\ngenerate a set of counterfactual text samples, which are crucial for testing\nthese ML systems. Our main contributions include a) We introduce GYC, a\nframework to generate counterfactual samples such that the generation is\nplausible, diverse, goal-oriented, and effective, b) We generate counterfactual\nsamples, that can direct the generation towards a corresponding condition such\nas named-entity tag, semantic role label, or sentiment. Our experimental\nresults on various domains show that GYC generates counterfactual text samples\nexhibiting the above four properties. GYC generates counterfactuals that can\nact as test cases to evaluate a model and any text debiasing algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 19:34:53 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 18:24:46 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Madaan", "Nishtha", ""], ["Padhi", "Inkit", ""], ["Panwar", "Naveen", ""], ["Saha", "Diptikalyan", ""]]}, {"id": "2012.04726", "submitter": "Jeff Da", "authors": "Jeff Da and Maxwell Forbes and Rowan Zellers and Anthony Zheng and\n  Jena D. Hwang and Antoine Bosselut and Yejin Choi", "title": "Edited Media Understanding: Reasoning About Implications of Manipulated\n  Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multimodal disinformation, from `deepfakes' to simple edits that deceive, is\nan important societal problem. Yet at the same time, the vast majority of media\nedits are harmless -- such as a filtered vacation photo. The difference between\nthis example, and harmful edits that spread disinformation, is one of intent.\nRecognizing and describing this intent is a major challenge for today's AI\nsystems.\n  We present the task of Edited Media Understanding, requiring models to answer\nopen-ended questions that capture the intent and implications of an image edit.\nWe introduce a dataset for our task, EMU, with 48k question-answer pairs\nwritten in rich natural language. We evaluate a wide variety of\nvision-and-language models for our task, and introduce a new model PELICAN,\nwhich builds upon recent progress in pretrained multimodal representations. Our\nmodel obtains promising results on our dataset, with humans rating its answers\nas accurate 40.35% of the time. At the same time, there is still much work to\nbe done -- humans prefer human-annotated captions 93.56% of the time -- and we\nprovide analysis that highlights areas for further progress.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 20:30:43 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Da", "Jeff", ""], ["Forbes", "Maxwell", ""], ["Zellers", "Rowan", ""], ["Zheng", "Anthony", ""], ["Hwang", "Jena D.", ""], ["Bosselut", "Antoine", ""], ["Choi", "Yejin", ""]]}, {"id": "2012.04778", "submitter": "Yichuan Li", "authors": "Kai Shu, Yichuan Li, Kaize Ding, Huan Liu", "title": "Fact-Enhanced Synthetic News Generation", "comments": "AAAI 2021 Preprint Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advanced text generation methods have witnessed great success in text\nsummarization, language translation, and synthetic news generation. However,\nthese techniques can be abused to generate disinformation and fake news. To\nbetter understand the potential threats of synthetic news, we develop a new\ngeneration method FactGen to generate high-quality news content. The existing\ntext generation methods either afford limited supplementary information or lose\nconsistency between the input and output which makes the synthetic news less\ntrustworthy. To address these issues, FactGen retrieves external facts to\nenrich the output and reconstructs the input claim from the generated content\nto improve the consistency among the input and the output. Experiment results\non real-world datasets show that the generated news contents of FactGen are\nconsistent and contain rich facts. We also discuss the possible defending\nmethod to identify these synthetic news pieces if FactGen is used to generate\nsynthetic news.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 22:54:35 GMT"}, {"version": "v2", "created": "Sun, 13 Dec 2020 04:56:25 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Shu", "Kai", ""], ["Li", "Yichuan", ""], ["Ding", "Kaize", ""], ["Liu", "Huan", ""]]}, {"id": "2012.04780", "submitter": "Sarthak Dash", "authors": "Sarthak Dash, Gaetano Rossiello, Nandana Mihindukulasooriya, Sugato\n  Bagchi, Alfio Gliozzo", "title": "Joint Entity and Relation Canonicalization in Open Knowledge Graphs\n  using Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noun phrases and relation phrases in open knowledge graphs are not\ncanonicalized, leading to an explosion of redundant and ambiguous\nsubject-relation-object triples. Existing approaches to face this problem take\na two-step approach: first, they generate embedding representations for both\nnoun and relation phrases, then a clustering algorithm is used to group them\nusing the embeddings as features. In this work, we propose Canonicalizing Using\nVariational AutoEncoders (CUVA), a joint model to learn both embeddings and\ncluster assignments in an end-to-end approach, which leads to a better vector\nrepresentation for the noun and relation phrases. Our evaluation over multiple\nbenchmarks shows that CUVA outperforms the existing state of the art\napproaches. Moreover, we introduce CanonicNell a novel dataset to evaluate\nentity canonicalization systems.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 22:58:30 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Dash", "Sarthak", ""], ["Rossiello", "Gaetano", ""], ["Mihindukulasooriya", "Nandana", ""], ["Bagchi", "Sugato", ""], ["Gliozzo", "Alfio", ""]]}, {"id": "2012.04796", "submitter": "Petr Plechac", "authors": "Petr Plechac", "title": "On an Unknown Ancestor of Burrows' Delta Measure", "comments": "To appear in: Interf\\'erences litteraires/literaire interferenties;\n  forthcoming special issue on \"Literature and/as (the) Digital\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This article points out some surprising similarities between a 1944 study by\nGeorgy Udny Yule and modern approaches to authorship attribution.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 00:10:57 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Plechac", "Petr", ""]]}, {"id": "2012.04808", "submitter": "Yichong Xu", "authors": "Yichong Xu, Chenguang Zhu, Ruochen Xu, Yang Liu, Michael Zeng, Xuedong\n  Huang", "title": "Fusing Context Into Knowledge Graph for Commonsense Question Answering", "comments": "To appear at ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Commonsense question answering (QA) requires a model to grasp commonsense and\nfactual knowledge to answer questions about world events. Many prior methods\ncouple language modeling with knowledge graphs (KG). However, although a KG\ncontains rich structural information, it lacks the context to provide a more\nprecise understanding of the concepts. This creates a gap when fusing knowledge\ngraphs into language modeling, especially when there is insufficient labeled\ndata. Thus, we propose to employ external entity descriptions to provide\ncontextual information for knowledge understanding. We retrieve descriptions of\nrelated concepts from Wiktionary and feed them as additional input to\npre-trained language models. The resulting model achieves state-of-the-art\nresult in the CommonsenseQA dataset and the best result among non-generative\nmodels in OpenBookQA.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 00:57:49 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 19:11:10 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Xu", "Yichong", ""], ["Zhu", "Chenguang", ""], ["Xu", "Ruochen", ""], ["Liu", "Yang", ""], ["Zeng", "Michael", ""], ["Huang", "Xuedong", ""]]}, {"id": "2012.04812", "submitter": "George Stoica", "authors": "George Stoica, Emmanouil Antonios Platanios, Barnab\\'as P\\'oczos", "title": "Improving Relation Extraction by Leveraging Knowledge Graph Link\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Relation extraction (RE) aims to predict a relation between a subject and an\nobject in a sentence, while knowledge graph link prediction (KGLP) aims to\npredict a set of objects, O, given a subject and a relation from a knowledge\ngraph. These two problems are closely related as their respective objectives\nare intertwined: given a sentence containing a subject and an object o, a RE\nmodel predicts a relation that can then be used by a KGLP model together with\nthe subject, to predict a set of objects O. Thus, we expect object o to be in\nset O. In this paper, we leverage this insight by proposing a multi-task\nlearning approach that improves the performance of RE models by jointly\ntraining on RE and KGLP tasks. We illustrate the generality of our approach by\napplying it on several existing RE models and empirically demonstrate how it\nhelps them achieve consistent performance gains.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 01:08:13 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Stoica", "George", ""], ["Platanios", "Emmanouil Antonios", ""], ["P\u00f3czos", "Barnab\u00e1s", ""]]}, {"id": "2012.04821", "submitter": "Qiaoben Bao", "authors": "Haiyun Jiang, Qiaoben Bao, Qiao Cheng, Deqing Yang, Li Wang and\n  Yanghua Xiao", "title": "Complex Relation Extraction: Challenges and Opportunities", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation extraction aims to identify the target relations of entities in\ntexts. Relation extraction is very important for knowledge base construction\nand text understanding. Traditional binary relation extraction, including\nsupervised, semi-supervised and distant supervised ones, has been extensively\nstudied and significant results are achieved. In recent years, many complex\nrelation extraction tasks, i.e., the variants of simple binary relation\nextraction, are proposed to meet the complex applications in practice. However,\nthere is no literature to fully investigate and summarize these complex\nrelation extraction works so far. In this paper, we first report the recent\nprogress in traditional simple binary relation extraction. Then we summarize\nthe existing complex relation extraction tasks and present the definition,\nrecent progress, challenges and opportunities for each task.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 02:05:00 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Jiang", "Haiyun", ""], ["Bao", "Qiaoben", ""], ["Cheng", "Qiao", ""], ["Yang", "Deqing", ""], ["Wang", "Li", ""], ["Xiao", "Yanghua", ""]]}, {"id": "2012.04882", "submitter": "Yunlong Liang", "authors": "Yunlong Liang, Fandong Meng, Ying Zhang, Jinan Xu, Yufeng Chen and Jie\n  Zhou", "title": "Infusing Multi-Source Knowledge with Heterogeneous Graph Neural Network\n  for Emotional Conversation Generation", "comments": "Accepted at AAAI 2021, Code:https://github.com/XL2248/HGNN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of emotional conversation systems depends on sufficient\nperception and appropriate expression of emotions. In a real-world\nconversation, we firstly instinctively perceive emotions from multi-source\ninformation, including the emotion flow of dialogue history, facial\nexpressions, and personalities of speakers, and then express suitable emotions\naccording to our personalities, but these multiple types of information are\ninsufficiently exploited in emotional conversation fields. To address this\nissue, we propose a heterogeneous graph-based model for emotional conversation\ngeneration. Specifically, we design a Heterogeneous Graph-Based Encoder to\nrepresent the conversation content (i.e., the dialogue history, its emotion\nflow, facial expressions, and speakers' personalities) with a heterogeneous\ngraph neural network, and then predict suitable emotions for feedback. After\nthat, we employ an Emotion-Personality-Aware Decoder to generate a response not\nonly relevant to the conversation context but also with appropriate emotions,\nby taking the encoded graph representations, the predicted emotions from the\nencoder and the personality of the current speaker as inputs. Experimental\nresults show that our model can effectively perceive emotions from multi-source\nknowledge and generate a satisfactory response, which significantly outperforms\nprevious state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 06:09:31 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Liang", "Yunlong", ""], ["Meng", "Fandong", ""], ["Zhang", "Ying", ""], ["Xu", "Jinan", ""], ["Chen", "Yufeng", ""], ["Zhou", "Jie", ""]]}, {"id": "2012.04946", "submitter": "Jos Tellings", "authors": "Martijn van der Klis and Jos Tellings", "title": "Multidimensional scaling and linguistic theory", "comments": "29 pages; copyrighted figures left out, reference to source of figure\n  instead", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper reports on the state-of-the-art in the application of\nmultidimensional scaling (MDS) techniques to create semantic maps in linguistic\nresearch. MDS refers to a statistical technique that represents objects\n(lexical items, linguistic contexts, languages, etc.) as points in a space so\nthat close similarity between the objects corresponds to close distances\nbetween the corresponding points in the representation. We focus on the recent\ntrend to apply MDS to parallel corpus data in order to investigate a certain\nlinguistic phenomenon from a cross-linguistic perspective.\n  We first introduce the mathematical foundations of MDS, intended for\nnon-experts, so that readers understand notions such as 'eigenvalues',\n'dimensionality reduction', 'stress values', etc. as they appear in linguistic\nMDS writing.\n  We then give an exhaustive overview of past research that employs MDS\ntechniques in combination with parallel corpus data, and propose a set of\nterminology to succinctly describe the key parameters of a particular MDS\napplication. We go over various research questions that have been answered with\nthe aid of MDS maps, showing that the methodology covers topics in a spectrum\nranging from classic typology (e.g. language classification) to formal\nlinguistics (e.g. study of a phenomenon in a single language).\n  We finally identify two lines of future research that build on the insights\nof earlier MDS research described in the paper. First, we envisage the use of\nMDS in the investigation of cross-linguistic variation of compositional\nstructures, an important area in variation research that has not been\napproached by parallel corpus work yet. Second, we discuss how MDS can be\ncomplemented and compared with other dimensionality reduction techniques that\nhave seen little use in the linguistic domain so far.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 10:02:09 GMT"}, {"version": "v2", "created": "Sat, 13 Mar 2021 14:20:55 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["van der Klis", "Martijn", ""], ["Tellings", "Jos", ""]]}, {"id": "2012.04955", "submitter": "Marco Gaido", "authors": "Marco Gaido, Beatrice Savoldi, Luisa Bentivogli, Matteo Negri, Marco\n  Turchi", "title": "Breeding Gender-aware Direct Speech Translation Systems", "comments": "Outstanding paper at COLING 2020", "journal-ref": "In Proceedings of the 28th International Conference on\n  Computational Linguistics, Dec 2020, 3951-3964. Online", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In automatic speech translation (ST), traditional cascade approaches\ninvolving separate transcription and translation steps are giving ground to\nincreasingly competitive and more robust direct solutions. In particular, by\ntranslating speech audio data without intermediate transcription, direct ST\nmodels are able to leverage and preserve essential information present in the\ninput (e.g. speaker's vocal characteristics) that is otherwise lost in the\ncascade framework. Although such ability proved to be useful for gender\ntranslation, direct ST is nonetheless affected by gender bias just like its\ncascade counterpart, as well as machine translation and numerous other natural\nlanguage processing applications. Moreover, direct ST systems that exclusively\nrely on vocal biometric features as a gender cue can be unsuitable and\npotentially harmful for certain users. Going beyond speech signals, in this\npaper we compare different approaches to inform direct ST models about the\nspeaker's gender and test their ability to handle gender translation from\nEnglish into Italian and French. To this aim, we manually annotated large\ndatasets with speakers' gender information and used them for experiments\nreflecting different possible real-world scenarios. Our results show that\ngender-aware direct ST solutions can significantly outperform strong - but\ngender-unaware - direct ST models. In particular, the translation of\ngender-marked words can increase up to 30 points in accuracy while preserving\noverall translation quality.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 10:18:03 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Gaido", "Marco", ""], ["Savoldi", "Beatrice", ""], ["Bentivogli", "Luisa", ""], ["Negri", "Matteo", ""], ["Turchi", "Marco", ""]]}, {"id": "2012.04964", "submitter": "Marco Gaido", "authors": "Marco Gaido, Mattia A. Di Gangi, Matteo Negri, Marco Turchi", "title": "On Knowledge Distillation for Direct Speech Translation", "comments": "Accepted at CLiC-IT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Direct speech translation (ST) has shown to be a complex task requiring\nknowledge transfer from its sub-tasks: automatic speech recognition (ASR) and\nmachine translation (MT). For MT, one of the most promising techniques to\ntransfer knowledge is knowledge distillation. In this paper, we compare the\ndifferent solutions to distill knowledge in a sequence-to-sequence task like\nST. Moreover, we analyze eventual drawbacks of this approach and how to\nalleviate them maintaining the benefits in terms of translation quality.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 10:33:13 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Gaido", "Marco", ""], ["Di Gangi", "Mattia A.", ""], ["Negri", "Matteo", ""], ["Turchi", "Marco", ""]]}, {"id": "2012.04987", "submitter": "Biyang Guo", "authors": "Biyang Guo, Songqiao Han, Xiao Han, Hailiang Huang, Ting Lu", "title": "Label Confusion Learning to Enhance Text Classification Models", "comments": "8 pages,3 figures, 5 tables. Accepted by AAAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representing a true label as a one-hot vector is a common practice in\ntraining text classification models. However, the one-hot representation may\nnot adequately reflect the relation between the instances and labels, as labels\nare often not completely independent and instances may relate to multiple\nlabels in practice. The inadequate one-hot representations tend to train the\nmodel to be over-confident, which may result in arbitrary prediction and model\noverfitting, especially for confused datasets (datasets with very similar\nlabels) or noisy datasets (datasets with labeling errors). While training\nmodels with label smoothing (LS) can ease this problem in some degree, it still\nfails to capture the realistic relation among labels. In this paper, we propose\na novel Label Confusion Model (LCM) as an enhancement component to current\npopular text classification models. LCM can learn label confusion to capture\nsemantic overlap among labels by calculating the similarity between instances\nand labels during training and generate a better label distribution to replace\nthe original one-hot label vector, thus improving the final classification\nperformance. Extensive experiments on five text classification benchmark\ndatasets reveal the effectiveness of LCM for several widely used deep learning\nclassification models. Further experiments also verify that LCM is especially\nhelpful for confused or noisy datasets and superior to the label smoothing\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 11:34:35 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Guo", "Biyang", ""], ["Han", "Songqiao", ""], ["Han", "Xiao", ""], ["Huang", "Hailiang", ""], ["Lu", "Ting", ""]]}, {"id": "2012.04995", "submitter": "Runze Wang", "authors": "Run-Ze Wang, Zhen-Hua Ling, Jing-Bo Zhou, Yu Hu", "title": "Tracking Interaction States for Multi-Turn Text-to-SQL Semantic Parsing", "comments": "Accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of multi-turn text-to-SQL semantic parsing aims to translate natural\nlanguage utterances in an interaction into SQL queries in order to answer them\nusing a database which normally contains multiple table schemas. Previous\nstudies on this task usually utilized contextual information to enrich\nutterance representations and to further influence the decoding process. While\nthey ignored to describe and track the interaction states which are determined\nby history SQL queries and are related with the intent of current utterance. In\nthis paper, two kinds of interaction states are defined based on schema items\nand SQL keywords separately. A relational graph neural network and a non-linear\nlayer are designed to update the representations of these two states\nrespectively. The dynamic schema-state and SQL-state representations are then\nutilized to decode the SQL query corresponding to current utterance.\nExperimental results on the challenging CoSQL dataset demonstrate the\neffectiveness of our proposed method, which achieves better performance than\nother published methods on the task leaderboard.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 11:59:58 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Wang", "Run-Ze", ""], ["Ling", "Zhen-Hua", ""], ["Zhou", "Jing-Bo", ""], ["Hu", "Yu", ""]]}, {"id": "2012.05011", "submitter": "Rishi Hazra", "authors": "Rishi Hazra, Sonu Dixit, Sayambhu Sen", "title": "Infinite use of finite means: Zero-Shot Generalization using\n  Compositional Emergent Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human language has been described as a system that makes \\textit{use of\nfinite means to express an unlimited array of thoughts}. Of particular interest\nis the aspect of compositionality, whereby, the meaning of a compound language\nexpression can be deduced from the meaning of its constituent parts. If\nartificial agents can develop compositional communication protocols akin to\nhuman language, they can be made to seamlessly generalize to unseen\ncombinations. However, the real question is, how do we induce compositionality\nin emergent communication? Studies have recognized the role of curiosity in\nenabling linguistic development in children. It is this same intrinsic urge\nthat drives us to master complex tasks with decreasing amounts of explicit\nreward. In this paper, we seek to use this intrinsic feedback in inducing a\nsystematic and unambiguous protolanguage in artificial agents. We show how\nthese rewards can be leveraged in training agents to induce compositionality in\nabsence of any external feedback. Additionally, we introduce gComm, an\nenvironment for investigating grounded language acquisition in 2D-grid\nenvironments. Using this, we demonstrate how compositionality can enable agents\nto not only interact with unseen objects but also transfer skills from one task\nto another in a zero-shot setting: \\textit{Can an agent, trained to `pull' and\n`push twice', `pull twice'?}.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 12:47:20 GMT"}, {"version": "v2", "created": "Sun, 13 Dec 2020 04:19:33 GMT"}, {"version": "v3", "created": "Wed, 19 May 2021 19:46:42 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Hazra", "Rishi", ""], ["Dixit", "Sonu", ""], ["Sen", "Sayambhu", ""]]}, {"id": "2012.05107", "submitter": "Pranav Aggarwal", "authors": "Pranav Aggarwal, Ajinkya Kale", "title": "Towards Zero-shot Cross-lingual Image Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There has been a recent spike in interest in multi-modal Language and Vision\nproblems. On the language side, most of these models primarily focus on English\nsince most multi-modal datasets are monolingual. We try to bridge this gap with\na zero-shot approach for learning multi-modal representations using\ncross-lingual pre-training on the text side. We present a simple yet practical\napproach for building a cross-lingual image retrieval model which trains on a\nmonolingual training dataset but can be used in a zero-shot cross-lingual\nfashion during inference. We also introduce a new objective function which\ntightens the text embedding clusters by pushing dissimilar texts from each\nother. Finally, we introduce a new 1K multi-lingual MSCOCO2014 caption test\ndataset (XTD10) in 7 languages that we collected using a crowdsourcing\nplatform. We use this as the test set for evaluating zero-shot model\nperformance across languages. XTD10 dataset is made publicly available here:\nhttps://github.com/adobe-research/Cross-lingual-Test-Dataset-XTD10\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 22:13:21 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Aggarwal", "Pranav", ""], ["Kale", "Ajinkya", ""]]}, {"id": "2012.05168", "submitter": "Kaitao Song", "authors": "Zhonghao Sheng, Kaitao Song, Xu Tan, Yi Ren, Wei Ye, Shikun Zhang, Tao\n  Qin", "title": "SongMASS: Automatic Song Writing with Pre-training and Alignment\n  Constraint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic song writing aims to compose a song (lyric and/or melody) by\nmachine, which is an interesting topic in both academia and industry. In\nautomatic song writing, lyric-to-melody generation and melody-to-lyric\ngeneration are two important tasks, both of which usually suffer from the\nfollowing challenges: 1) the paired lyric and melody data are limited, which\naffects the generation quality of the two tasks, considering a lot of paired\ntraining data are needed due to the weak correlation between lyric and melody;\n2) Strict alignments are required between lyric and melody, which relies on\nspecific alignment modeling. In this paper, we propose SongMASS to address the\nabove challenges, which leverages masked sequence to sequence (MASS)\npre-training and attention based alignment modeling for lyric-to-melody and\nmelody-to-lyric generation. Specifically, 1) we extend the original\nsentence-level MASS pre-training to song level to better capture long\ncontextual information in music, and use a separate encoder and decoder for\neach modality (lyric or melody); 2) we leverage sentence-level attention mask\nand token-level attention constraint during training to enhance the alignment\nbetween lyric and melody. During inference, we use a dynamic programming\nstrategy to obtain the alignment between each word/syllable in lyric and note\nin melody. We pre-train SongMASS on unpaired lyric and melody datasets, and\nboth objective and subjective evaluations demonstrate that SongMASS generates\nlyric and melody with significantly better quality than the baseline method\nwithout pre-training or alignment constraint.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 16:56:59 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Sheng", "Zhonghao", ""], ["Song", "Kaitao", ""], ["Tan", "Xu", ""], ["Ren", "Yi", ""], ["Ye", "Wei", ""], ["Zhang", "Shikun", ""], ["Qin", "Tao", ""]]}, {"id": "2012.05292", "submitter": "Kevin Chen", "authors": "Kevin Chen, Junshen K. Chen, Jo Chuang, Marynel V\\'azquez, Silvio\n  Savarese", "title": "Topological Planning with Transformers for Vision-and-Language\n  Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional approaches to vision-and-language navigation (VLN) are trained\nend-to-end but struggle to perform well in freely traversable environments.\nInspired by the robotics community, we propose a modular approach to VLN using\ntopological maps. Given a natural language instruction and topological map, our\napproach leverages attention mechanisms to predict a navigation plan in the\nmap. The plan is then executed with low-level actions (e.g. forward, rotate)\nusing a robust controller. Experiments show that our method outperforms\nprevious end-to-end approaches, generates interpretable navigation plans, and\nexhibits intelligent behaviors such as backtracking.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 20:02:03 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Chen", "Kevin", ""], ["Chen", "Junshen K.", ""], ["Chuang", "Jo", ""], ["V\u00e1zquez", "Marynel", ""], ["Savarese", "Silvio", ""]]}, {"id": "2012.05300", "submitter": "Xingran Zhu", "authors": "Xingran Zhu", "title": "Cross-lingual Word Sense Disambiguation using mBERT Embeddings with\n  Syntactic Dependencies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cross-lingual word sense disambiguation (WSD) tackles the challenge of\ndisambiguating ambiguous words across languages given context. The pre-trained\nBERT embedding model has been proven to be effective in extracting contextual\ninformation of words, and have been incorporated as features into many\nstate-of-the-art WSD systems. In order to investigate how syntactic information\ncan be added into the BERT embeddings to result in both semantics- and\nsyntax-incorporated word embeddings, this project proposes the concatenated\nembeddings by producing dependency parse tress and encoding the relative\nrelationships of words into the input embeddings. Two methods are also proposed\nto reduce the size of the concatenated embeddings. The experimental results\nshow that the high dimensionality of the syntax-incorporated embeddings\nconstitute an obstacle for the classification task, which needs to be further\naddressed in future studies.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 20:22:11 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Zhu", "Xingran", ""]]}, {"id": "2012.05302", "submitter": "Olga Golovneva", "authors": "Olga Golovneva and Charith Peris", "title": "Generative Adversarial Networks for Annotated Data Augmentation in Data\n  Sparse NLU", "comments": "8 pages; accepted for the ICON 2020 (17th International Conference on\n  Natural Language Processing)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data sparsity is one of the key challenges associated with model development\nin Natural Language Understanding (NLU) for conversational agents. The\nchallenge is made more complex by the demand for high quality annotated\nutterances commonly required for supervised learning, usually resulting in\nweeks of manual labor and high cost. In this paper, we present our results on\nboosting NLU model performance through training data augmentation using a\nsequential generative adversarial network (GAN). We explore data generation in\nthe context of two tasks, the bootstrapping of a new language and the handling\nof low resource features. For both tasks we explore three sequential GAN\narchitectures, one with a token-level reward function, another with our own\nimplementation of a token-level Monte Carlo rollout reward, and a third with\nsentence-level reward. We evaluate the performance of these feedback models\nacross several sampling methodologies and compare our results to upsampling the\noriginal data to the same scale. We further improve the GAN model performance\nthrough the transfer learning of the pretrained embeddings. Our experiments\nreveal synthetic data generated using the sequential generative adversarial\nnetwork provides significant performance boosts across multiple metrics and can\nbe a major benefit to the NLU tasks.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 20:38:17 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Golovneva", "Olga", ""], ["Peris", "Charith", ""]]}, {"id": "2012.05318", "submitter": "Mika H\\\"am\\\"al\\\"ainen", "authors": "Mika H\\\"am\\\"al\\\"ainen, Niko Partanen, Khalid Alnajjar", "title": "Normalization of Different Swedish Dialects Spoken in Finland", "comments": "In Proceedings of the 4th ACM SIGSPATIAL Workshop on Geospatial\n  Humanities (GeoHumanities'20)", "journal-ref": null, "doi": "10.1145/3423337.3429435", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Our study presents a dialect normalization method for different Finland\nSwedish dialects covering six regions. We tested 5 different models, and the\nbest model improved the word error rate from 76.45 to 28.58. Contrary to\nresults reported in earlier research on Finnish dialects, we found that\ntraining the model with one word at a time gave best results. We believe this\nis due to the size of the training data available for the model. Our models are\naccessible as a Python package. The study provides important information about\nthe adaptability of these methods in different contexts, and gives important\nbaselines for further study.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 20:59:31 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["H\u00e4m\u00e4l\u00e4inen", "Mika", ""], ["Partanen", "Niko", ""], ["Alnajjar", "Khalid", ""]]}, {"id": "2012.05331", "submitter": "Mika H\\\"am\\\"al\\\"ainen", "authors": "Niko Partanen, Mika H\\\"am\\\"al\\\"ainen, Tiina Klooster", "title": "Speech Recognition for Endangered and Extinct Samoyedic languages", "comments": "the 34th Pacific Asia Conference on Language, Information and\n  Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Our study presents a series of experiments on speech recognition with\nendangered and extinct Samoyedic languages, spoken in Northern and Southern\nSiberia. To best of our knowledge, this is the first time a functional ASR\nsystem is built for an extinct language. We achieve with Kamas language a Label\nError Rate of 15\\%, and conclude through careful error analysis that this\nquality is already very useful as a starting point for refined human\ntranscriptions. Our results with related Nganasan language are more modest,\nwith best model having the error rate of 33\\%. We show, however, through\nexperiments where Kamas training data is enlarged incrementally, that Nganasan\nresults are in line with what is expected under low-resource circumstances of\nthe language. Based on this, we provide recommendations for scenarios in which\nfurther language documentation or archive processing activities could benefit\nfrom modern ASR technology. All training data and processing scripts haven been\npublished on Zenodo with clear licences to ensure further work in this\nimportant topic.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 21:41:40 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Partanen", "Niko", ""], ["H\u00e4m\u00e4l\u00e4inen", "Mika", ""], ["Klooster", "Tiina", ""]]}, {"id": "2012.05395", "submitter": "Zhaofeng Wu", "authors": "Zhaofeng Wu, Hao Peng, Noah A. Smith", "title": "Infusing Finetuning with Semantic Dependencies", "comments": "TACL 2021", "journal-ref": null, "doi": "10.1162/tacl_a_00363", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For natural language processing systems, two kinds of evidence support the\nuse of text representations from neural language models \"pretrained\" on large\nunannotated corpora: performance on application-inspired benchmarks (Peters et\nal., 2018, inter alia), and the emergence of syntactic abstractions in those\nrepresentations (Tenney et al., 2019, inter alia). On the other hand, the lack\nof grounded supervision calls into question how well these representations can\never capture meaning (Bender and Koller, 2020). We apply novel probes to recent\nlanguage models -- specifically focusing on predicate-argument structure as\noperationalized by semantic dependencies (Ivanova et al., 2012) -- and find\nthat, unlike syntax, semantics is not brought to the surface by today's\npretrained models. We then use convolutional graph encoders to explicitly\nincorporate semantic parses into task-specific finetuning, yielding benefits to\nnatural language understanding (NLU) tasks in the GLUE benchmark. This approach\ndemonstrates the potential for general-purpose (rather than task-specific)\nlinguistic supervision, above and beyond conventional pretraining and\nfinetuning. Several diagnostics help to localize the benefits of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 01:27:24 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2020 19:56:30 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2021 07:40:54 GMT"}, {"version": "v4", "created": "Tue, 1 Jun 2021 19:09:55 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Wu", "Zhaofeng", ""], ["Peng", "Hao", ""], ["Smith", "Noah A.", ""]]}, {"id": "2012.05403", "submitter": "Abhinav Aggarwal", "authors": "Oluwaseyi Feyisetan, Abhinav Aggarwal, Zekun Xu, Nathanael Teissier", "title": "Research Challenges in Designing Differentially Private Text Generation\n  Mechanisms", "comments": "14 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Accurately learning from user data while ensuring quantifiable privacy\nguarantees provides an opportunity to build better Machine Learning (ML) models\nwhile maintaining user trust. Recent literature has demonstrated the\napplicability of a generalized form of Differential Privacy to provide\nguarantees over text queries. Such mechanisms add privacy preserving noise to\nvectorial representations of text in high dimension and return a text based\nprojection of the noisy vectors. However, these mechanisms are sub-optimal in\ntheir trade-off between privacy and utility. This is due to factors such as a\nfixed global sensitivity which leads to too much noise added in dense spaces\nwhile simultaneously guaranteeing protection for sensitive outliers. In this\nproposal paper, we describe some challenges in balancing the tradeoff between\nprivacy and utility for these differentially private text mechanisms. At a high\nlevel, we provide two proposals: (1) a framework called LAC which defers some\nof the noise to a privacy amplification step and (2), an additional suite of\nthree different techniques for calibrating the noise based on the local region\naround a word. Our objective in this paper is not to evaluate a single solution\nbut to further the conversation on these challenges and chart pathways for\nbuilding better mechanisms.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 01:44:50 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Feyisetan", "Oluwaseyi", ""], ["Aggarwal", "Abhinav", ""], ["Xu", "Zekun", ""], ["Teissier", "Nathanael", ""]]}, {"id": "2012.05414", "submitter": "Yangming Li", "authors": "Yangming Li, Kaisheng Yao", "title": "Rewriter-Evaluator Architecture for Neural Machine Translation", "comments": "A full paper accepted at ACL-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Encoder-decoder has been widely used in neural machine translation (NMT). A\nfew methods have been proposed to improve it with multiple passes of decoding.\nHowever, their full potential is limited by a lack of appropriate termination\npolicies. To address this issue, we present a novel architecture,\nRewriter-Evaluator. It consists of a rewriter and an evaluator. Translating a\nsource sentence involves multiple passes. At every pass, the rewriter produces\na new translation to improve the past translation and the evaluator estimates\nthe translation quality to decide whether to terminate the rewriting process.\nWe also propose prioritized gradient descent (PGD) that facilitates training\nthe rewriter and the evaluator jointly. Though incurring multiple passes of\ndecoding, Rewriter-Evaluator with the proposed PGD method can be trained with a\nsimilar time to that of training encoder-decoder models. We apply the proposed\narchitecture to improve the general NMT models (e.g., Transformer). We conduct\nextensive experiments on two translation tasks, Chinese-English and\nEnglish-German, and show that the proposed architecture notably improves the\nperformances of NMT models and significantly outperforms previous baselines.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 02:21:34 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 03:05:22 GMT"}, {"version": "v3", "created": "Fri, 7 May 2021 03:04:33 GMT"}, {"version": "v4", "created": "Mon, 10 May 2021 02:11:35 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Li", "Yangming", ""], ["Yao", "Kaisheng", ""]]}, {"id": "2012.05418", "submitter": "Yangming Li", "authors": "Yangming Li, Lemao Liu, Shuming Shi", "title": "Segmenting Natural Language Sentences via Lexical Unit Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present Lexical Unit Analysis (LUA), a framework for general\nsequence segmentation tasks. Given a natural language sentence, LUA scores all\nthe valid segmentation candidates and utilizes dynamic programming (DP) to\nextract the maximum scoring one. LUA enjoys a number of appealing properties\nsuch as inherently guaranteeing the predicted segmentation to be valid and\nfacilitating globally optimal training and inference. Besides, the practical\ntime complexity of LUA can be reduced to linear time, which is very efficient.\nWe have conducted extensive experiments on 5 tasks, including syntactic\nchunking, named entity recognition (NER), slot filling, Chinese word\nsegmentation, and Chinese part-of-speech (POS) tagging, across 15 datasets. Our\nmodels have achieved the state-of-the-art performances on 13 of them. The\nresults also show that the F1 score of identifying long-length segments is\nnotably improved.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 02:31:52 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 02:59:12 GMT"}, {"version": "v3", "created": "Fri, 16 Apr 2021 08:30:03 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Li", "Yangming", ""], ["Liu", "Lemao", ""], ["Shi", "Shuming", ""]]}, {"id": "2012.05426", "submitter": "Yangming Li", "authors": "Yangming Li, Lemao Liu, Shuming Shi", "title": "Empirical Analysis of Unlabeled Entity Problem in Named Entity\n  Recognition", "comments": "Accepted as a conference paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many scenarios, named entity recognition (NER) models severely suffer from\nunlabeled entity problem, where the entities of a sentence may not be fully\nannotated. Through empirical studies performed on synthetic datasets, we find\ntwo causes of performance degradation. One is the reduction of annotated\nentities and the other is treating unlabeled entities as negative instances.\nThe first cause has less impact than the second one and can be mitigated by\nadopting pretraining language models. The second cause seriously misguides a\nmodel in training and greatly affects its performances. Based on the above\nobservations, we propose a general approach, which can almost eliminate the\nmisguidance brought by unlabeled entities. The key idea is to use negative\nsampling that, to a large extent, avoids training NER models with unlabeled\nentities. Experiments on synthetic datasets and real-world datasets show that\nour model is robust to unlabeled entity problem and surpasses prior baselines.\nOn well-annotated datasets, our model is competitive with the state-of-the-art\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 02:53:59 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 02:49:27 GMT"}, {"version": "v3", "created": "Wed, 13 Jan 2021 08:01:02 GMT"}, {"version": "v4", "created": "Thu, 4 Feb 2021 03:34:31 GMT"}, {"version": "v5", "created": "Thu, 18 Mar 2021 06:38:57 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Li", "Yangming", ""], ["Liu", "Lemao", ""], ["Shi", "Shuming", ""]]}, {"id": "2012.05444", "submitter": "Shubhanshu Mishra", "authors": "Shubhanshu Mishra, Daniel Collier", "title": "A Framework for Generating Annotated Social Media Corpora with\n  Demographics, Stance, Civility, and Topicality", "comments": "Code at: https://github.com/socialmediaie/StudentDebtFbComments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper we introduce a framework for annotating a social media text\ncorpora for various categories. Since, social media data is generated via\nindividuals, it is important to annotate the text for the individuals\ndemographic attributes to enable a socio-technical analysis of the corpora.\nFurthermore, when analyzing a large data-set we can often annotate a small\nsample of data and then train a prediction model using this sample to annotate\nthe full data for the relevant categories. We use a case study of a Facebook\ncomment corpora on student loan discussion which was annotated for gender,\nmilitary affiliation, age-group, political leaning, race, stance, topicalilty,\nneoliberlistic views and civility of the comment. We release three datasets of\nFacebook comments for further research at:\nhttps://github.com/socialmediaie/StudentDebtFbComments\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 04:06:25 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Mishra", "Shubhanshu", ""], ["Collier", "Daniel", ""]]}, {"id": "2012.05453", "submitter": "Vivek Khetan", "authors": "Vivek Khetan, Roshni Ramnani, Mayuresh Anand, Shubhashis Sengupta and\n  Andrew E.Fano", "title": "Causal BERT : Language models for causality detection between events\n  expressed in text", "comments": "17 pages, 4 figures, to be published in Advances in Intelligent\n  Systems and Computing, Appendixed by Vivek Khetan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Causality understanding between events is a critical natural language\nprocessing task that is helpful in many areas, including health care, business\nrisk management and finance. On close examination, one can find a huge amount\nof textual content both in the form of formal documents or in content arising\nfrom social media like Twitter, dedicated to communicating and exploring\nvarious types of causality in the real world. Recognizing these \"Cause-Effect\"\nrelationships between natural language events continues to remain a challenge\nsimply because it is often expressed implicitly. Implicit causality is hard to\ndetect through most of the techniques employed in literature and can also, at\ntimes be perceived as ambiguous or vague. Also, although well-known datasets do\nexist for this problem, the examples in them are limited in the range and\ncomplexity of the causal relationships they depict especially when related to\nimplicit relationships. Most of the contemporary methods are either based on\nlexico-semantic pattern matching or are feature-driven supervised methods.\nTherefore, as expected these methods are more geared towards handling explicit\ncausal relationships leading to limited coverage for implicit relationships and\nare hard to generalize. In this paper, we investigate the language model's\ncapabilities for causal association among events expressed in natural language\ntext using sentence context combined with event information, and by leveraging\nmasked event context with in-domain and out-of-domain data distribution. Our\nproposed methods achieve the state-of-art performance in three different data\ndistributions and can be leveraged for extraction of a causal diagram and/or\nbuilding a chain of events from unstructured text.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 04:59:12 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 21:15:26 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Khetan", "Vivek", ""], ["Ramnani", "Roshni", ""], ["Anand", "Mayuresh", ""], ["Sengupta", "Shubhashis", ""], ["Fano", "Andrew E.", ""]]}, {"id": "2012.05481", "submitter": "Binbin Zhang", "authors": "Binbin Zhang, Di Wu, Zhuoyuan Yao, Xiong Wang, Fan Yu, Chao Yang,\n  Liyong Guo, Yaguang Hu, Lei Xie, Xin Lei", "title": "Unified Streaming and Non-streaming Two-pass End-to-end Model for Speech\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a novel two-pass approach to unify streaming and\nnon-streaming end-to-end (E2E) speech recognition in a single model. Our model\nadopts the hybrid CTC/attention architecture, in which the conformer layers in\nthe encoder are modified. We propose a dynamic chunk-based attention strategy\nto allow arbitrary right context length. At inference time, the CTC decoder\ngenerates n-best hypotheses in a streaming way. The inference latency could be\neasily controlled by only changing the chunk size. The CTC hypotheses are then\nrescored by the attention decoder to get the final result. This efficient\nrescoring process causes very little sentence-level latency. Our experiments on\nthe open 170-hour AISHELL-1 dataset show that, the proposed method can unify\nthe streaming and non-streaming model simply and efficiently. On the AISHELL-1\ntest set, our unified model achieves 5.60% relative character error rate (CER)\nreduction in non-streaming ASR compared to a standard non-streaming\ntransformer. The same model achieves 5.42% CER with 640ms latency in a\nstreaming ASR system.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 06:54:54 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Zhang", "Binbin", ""], ["Wu", "Di", ""], ["Yao", "Zhuoyuan", ""], ["Wang", "Xiong", ""], ["Yu", "Fan", ""], ["Yang", "Chao", ""], ["Guo", "Liyong", ""], ["Hu", "Yaguang", ""], ["Xie", "Lei", ""], ["Lei", "Xin", ""]]}, {"id": "2012.05489", "submitter": "Musarrat Husssain", "authors": "Musarrat Hussain, Jamil Hussain, Taqdir Ali, Fahad Ahmed Satti,\n  Sungyoung Lee", "title": "AI Driven Knowledge Extraction from Clinical Practice Guidelines:\n  Turning Research into Practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background and Objectives: Clinical Practice Guidelines (CPGs) represent the\nforemost methodology for sharing state-of-the-art research findings in the\nhealthcare domain with medical practitioners to limit practice variations,\nreduce clinical cost, improve the quality of care, and provide evidence based\ntreatment. However, extracting relevant knowledge from the plethora of CPGs is\nnot feasible for already burdened healthcare professionals, leading to large\ngaps between clinical findings and real practices. It is therefore imperative\nthat state-of-the-art Computing research, especially machine learning is used\nto provide artificial intelligence based solution for extracting the knowledge\nfrom CPGs and reducing the gap between healthcare research/guidelines and\npractice. Methods: This research presents a novel methodology for knowledge\nextraction from CPGs to reduce the gap and turn the latest research findings\ninto clinical practice. First, our system classifies the CPG sentences into\nfour classes such as condition-action, condition-consequences, action, and\nnot-applicable based on the information presented in a sentence. We use deep\nlearning with state-of-the-art word embedding, improved word vectors technique\nin classification process. Second, it identifies qualifier terms in the\nclassified sentences, which assist in recognizing the condition and action\nphrases in a sentence. Finally, the condition and action phrase are processed\nand transformed into plain rule If Condition(s) Then Action format. Results: We\nevaluate the methodology on three different domains guidelines including\nHypertension, Rhinosinusitis, and Asthma. The deep learning model classifies\nthe CPG sentences with an accuracy of 95%. While rule extraction was validated\nby user-centric approach, which achieved a Jaccard coefficient of 0.6, 0.7, and\n0.4 with three human experts extracted rules, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 07:23:02 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Hussain", "Musarrat", ""], ["Hussain", "Jamil", ""], ["Ali", "Taqdir", ""], ["Satti", "Fahad Ahmed", ""], ["Lee", "Sungyoung", ""]]}, {"id": "2012.05491", "submitter": "Hao Li", "authors": "Hao Li (1), Huan Wang (1) and Guanghua Liu (2) ((1) College of\n  Informatics, Huazhong Agricultural University, (2) Department of Computer\n  Science and Engineering, University at Buffalo, The State University of New\n  York)", "title": "An Event Correlation Filtering Method for Fake News Detection", "comments": "24 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, social network platforms have been the prime source for people to\nexperience news and events due to their capacities to spread information\nrapidly, which inevitably provides a fertile ground for the dissemination of\nfake news. Thus, it is significant to detect fake news otherwise it could cause\npublic misleading and panic. Existing deep learning models have achieved great\nprogress to tackle the problem of fake news detection. However, training an\neffective deep learning model usually requires a large amount of labeled news,\nwhile it is expensive and time-consuming to provide sufficient labeled news in\nactual applications. To improve the detection performance of fake news, we take\nadvantage of the event correlations of news and propose an event correlation\nfiltering method (ECFM) for fake news detection, mainly consisting of the news\ncharacterizer, the pseudo label annotator, the event credibility updater, and\nthe news entropy selector. The news characterizer is responsible for extracting\ntextual features from news, which cooperates with the pseudo label annotator to\nassign pseudo labels for unlabeled news by fully exploiting the event\ncorrelations of news. In addition, the event credibility updater employs\nadaptive Kalman filter to weaken the credibility fluctuations of events. To\nfurther improve the detection performance, the news entropy selector\nautomatically discovers high-quality samples from pseudo labeled news by\nquantifying their news entropy. Finally, ECFM is proposed to integrate them to\ndetect fake news in an event correlation filtering manner. Extensive\nexperiments prove that the explainable introduction of the event correlations\nof news is beneficial to improve the detection performance of fake news.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 07:31:07 GMT"}, {"version": "v2", "created": "Sun, 13 Dec 2020 07:52:18 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Li", "Hao", ""], ["Wang", "Huan", ""], ["Liu", "Guanghua", ""]]}, {"id": "2012.05541", "submitter": "Maria Zimina", "authors": "Maria Zimina-Poirot (CLILLAC-ARP), Nicolas Ballier (CLILLAC-ARP),\n  Jean-Baptiste Yun\\`es (IRIF)", "title": "Approches quantitatives de l'analyse des pr{\\'e}dictions en traduction\n  automatique neuronale (TAN)", "comments": "in French. JADT 2020 : 15{\\`e}mes Journ{\\'e}es Internationales\n  d'Analyse statistique des Donn{\\'e}es Textuelles, Universit{\\'e} de Toulouse,\n  Jun 2020, Toulouse, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As part of a larger project on optimal learning conditions in neural machine\ntranslation, we investigate characteristic training phases of translation\nengines. All our experiments are carried out using OpenNMT-Py: the\npre-processing step is implemented using the Europarl training corpus and the\nINTERSECT corpus is used for validation. Longitudinal analyses of training\nphases suggest that the progression of translations is not always linear.\nFollowing the results of textometric explorations, we identify the importance\nof the phenomena related to chronological progression, in order to map\ndifferent processes at work in neural machine translation (NMT).\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 09:31:59 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Zimina-Poirot", "Maria", "", "CLILLAC-ARP"], ["Ballier", "Nicolas", "", "CLILLAC-ARP"], ["Yun\u00e8s", "Jean-Baptiste", "", "IRIF"]]}, {"id": "2012.05628", "submitter": "Wietse de Vries", "authors": "Wietse de Vries, Malvina Nissim", "title": "As Good as New. How to Successfully Recycle English GPT-2 to Make Models\n  for Other Languages", "comments": "Findings of ACL 2021 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large generative language models have been very successful for English, but\nother languages lag behind, in part due to data and computational limitations.\nWe propose a method that may overcome these problems by adapting existing\npre-trained models to new languages. Specifically, we describe the adaptation\nof English GPT-2 to Italian and Dutch by retraining lexical embeddings without\ntuning the Transformer layers. As a result, we obtain lexical embeddings for\nItalian and Dutch that are aligned with the original English lexical\nembeddings. Additionally, we scale up complexity by transforming relearned\nlexical embeddings of GPT-2 small to the GPT-2 medium embedding space. This\nmethod minimises the amount of training and prevents losing information during\nadaptation that was learned by GPT-2. English GPT-2 models with relearned\nlexical embeddings can generate realistic sentences in Italian and Dutch.\nThough on average these sentences are still identifiable as artificial by\nhumans, they are assessed on par with sentences generated by a GPT-2 model\nfully trained from scratch.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 12:27:16 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 09:21:35 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 07:57:32 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["de Vries", "Wietse", ""], ["Nissim", "Malvina", ""]]}, {"id": "2012.05680", "submitter": "Leanne Nortje", "authors": "Leanne Nortje, Herman Kamper", "title": "Direct multimodal few-shot learning of speech and images", "comments": "Accepted to Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose direct multimodal few-shot models that learn a shared embedding\nspace of spoken words and images from only a few paired examples. Imagine an\nagent is shown an image along with a spoken word describing the object in the\npicture, e.g. pen, book and eraser. After observing a few paired examples of\neach class, the model is asked to identify the \"book\" in a set of unseen\npictures. Previous work used a two-step indirect approach relying on learned\nunimodal representations: speech-speech and image-image comparisons are\nperformed across the support set of given speech-image pairs. We propose two\ndirect models which instead learn a single multimodal space where inputs from\ndifferent modalities are directly comparable: a multimodal triplet network\n(MTriplet) and a multimodal correspondence autoencoder (MCAE). To train these\ndirect models, we mine speech-image pairs: the support set is used to pair up\nunlabelled in-domain speech and images. In a speech-to-image digit matching\ntask, direct models outperform indirect models, with the MTriplet achieving the\nbest multimodal five-shot accuracy. We show that the improvements are due to\nthe combination of unsupervised and transfer learning in the direct models, and\nthe absence of two-step compounding errors.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 14:06:57 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 15:45:49 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Nortje", "Leanne", ""], ["Kamper", "Herman", ""]]}, {"id": "2012.05684", "submitter": "Kostadin Cvejoski", "authors": "Kostadin Cvejoski, Ramses J. Sanchez, Bogdan Georgiev, Christian\n  Bauckhage and Cesar Ojeda", "title": "Recurrent Point Review Models", "comments": "8 pages, 6 figures, Published in: 2020 International Joint Conference\n  on Neural Networks (IJCNN)", "journal-ref": "2020 International Joint Conference on Neural Networks (IJCNN),\n  Glasgow, United Kingdom, 2020, pp. 1-8", "doi": "10.1109/IJCNN48605.2020.9206768", "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural network models represent the state-of-the-art methodologies for\nnatural language processing. Here we build on top of these methodologies to\nincorporate temporal information and model how to review data changes with\ntime. Specifically, we use the dynamic representations of recurrent point\nprocess models, which encode the history of how business or service reviews are\nreceived in time, to generate instantaneous language models with improved\nprediction capabilities. Simultaneously, our methodologies enhance the\npredictive power of our point process models by incorporating summarized review\ncontent representations. We provide recurrent network and temporal convolution\nsolutions for modeling the review content. We deploy our methodologies in the\ncontext of recommender systems, effectively characterizing the change in\npreference and taste of users as time evolves. Source code is available at [1].\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 14:11:42 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Cvejoski", "Kostadin", ""], ["Sanchez", "Ramses J.", ""], ["Georgiev", "Bogdan", ""], ["Bauckhage", "Christian", ""], ["Ojeda", "Cesar", ""]]}, {"id": "2012.05685", "submitter": "Bogdan Georgiev", "authors": "David Biesner, Kostadin Cvejoski, Bogdan Georgiev, Rafet Sifa, Erik\n  Krupicka", "title": "Generative Deep Learning Techniques for Password Generation", "comments": "25 pages, 13 figures. Comments welcome!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Password guessing approaches via deep learning have recently been\ninvestigated with significant breakthroughs in their ability to generate novel,\nrealistic password candidates. In the present work we study a broad collection\nof deep learning and probabilistic based models in the light of password\nguessing: attention-based deep neural networks, autoencoding mechanisms and\ngenerative adversarial networks. We provide novel generative deep-learning\nmodels in terms of variational autoencoders exhibiting state-of-art sampling\nperformance, yielding additional latent-space features such as interpolations\nand targeted sampling. Lastly, we perform a thorough empirical analysis in a\nunified controlled framework over well-known datasets (RockYou, LinkedIn,\nYouku, Zomato, Pwnd). Our results not only identify the most promising schemes\ndriven by deep neural networks, but also illustrate the strengths of each\napproach in terms of generation variability and sample uniqueness.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 14:11:45 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 20:43:19 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Biesner", "David", ""], ["Cvejoski", "Kostadin", ""], ["Georgiev", "Bogdan", ""], ["Sifa", "Rafet", ""], ["Krupicka", "Erik", ""]]}, {"id": "2012.05715", "submitter": "Wlodek Zadrozny", "authors": "Wlodek W. Zadrozny", "title": "Towards Coinductive Models for Natural Language Understanding. Bringing\n  together Deep Learning and Deep Semantics", "comments": "32 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article contains a proposal to add coinduction to the computational\napparatus of natural language understanding. This, we argue, will provide a\nbasis for more realistic, computationally sound, and scalable models of natural\nlanguage dialogue, syntax and semantics. Given that the bottom up, inductively\nconstructed, semantic and syntactic structures are brittle, and seemingly\nincapable of adequately representing the meaning of longer sentences or\nrealistic dialogues, natural language understanding is in need of a new\nfoundation. Coinduction, which uses top down constraints, has been successfully\nused in the design of operating systems and programming languages. Moreover,\nimplicitly it has been present in text mining, machine translation, and in some\nattempts to model intensionality and modalities, which provides evidence that\nit works. This article shows high level formalizations of some of such uses.\n  Since coinduction and induction can coexist, they can provide a common\nlanguage and a conceptual model for research in natural language understanding.\nIn particular, such an opportunity seems to be emerging in research on\ncompositionality. This article shows several examples of the joint appearance\nof induction and coinduction in natural language processing. We argue that the\nknown individual limitations of induction and coinduction can be overcome in\nempirical settings by a combination of the the two methods. We see an open\nproblem in providing a theory of their joint use.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 03:10:36 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Zadrozny", "Wlodek W.", ""]]}, {"id": "2012.05742", "submitter": "Andreas Nugaard Holm", "authors": "Andreas Nugaard Holm, Barbara Plank, Dustin Wright, Isabelle\n  Augenstein", "title": "Longitudinal Citation Prediction using Temporal Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Citation count prediction is the task of predicting the number of citations a\npaper has gained after a period of time. Prior work viewed this as a static\nprediction task. As papers and their citations evolve over time, considering\nthe dynamics of the number of citations a paper will receive would seem\nlogical. Here, we introduce the task of sequence citation prediction. The goal\nis to accurately predict the trajectory of the number of citations a scholarly\nwork receives over time. We propose to view papers as a structured network of\ncitations, allowing us to use topological information as a learning signal.\nAdditionally, we learn how this dynamic citation network changes over time and\nthe impact of paper meta-data such as authors, venues and abstracts. To\napproach the new task, we derive a dynamic citation network from Semantic\nScholar spanning over 42 years. We present a model which exploits topological\nand temporal information using graph convolution networks paired with sequence\nprediction, and compare it against multiple baselines, testing the importance\nof topological and temporal information and analyzing model performance. Our\nexperiments show that leveraging both the temporal and topological information\ngreatly increases the performance of predicting citation counts over time.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 15:25:16 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 14:48:17 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Holm", "Andreas Nugaard", ""], ["Plank", "Barbara", ""], ["Wright", "Dustin", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "2012.05776", "submitter": "Andrea Lekkas", "authors": "Andrea Lekkas, Peter Schneider-Kamp, Isabelle Augenstein", "title": "Multi-Sense Language Modelling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The effectiveness of a language model is influenced by its token\nrepresentations, which must encode contextual information and handle the same\nword form having a plurality of meanings (polysemy). Currently, none of the\ncommon language modelling architectures explicitly model polysemy. We propose a\nlanguage model which not only predicts the next word, but also its sense in\ncontext. We argue that this higher prediction granularity may be useful for end\ntasks such as assistive writing, and allow for more a precise linking of\nlanguage models with knowledge bases. We find that multi-sense language\nmodelling requires architectures that go beyond standard language models, and\nhere propose a structured prediction framework that decomposes the task into a\nword followed by a sense prediction task. For sense prediction, we utilise a\nGraph Attention Network, which encodes definitions and example uses of word\nsenses. Overall, we find that multi-sense language modelling is a highly\nchallenging task, and suggest that future work focus on the creation of more\nannotated training datasets.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 16:06:05 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Lekkas", "Andrea", ""], ["Schneider-Kamp", "Peter", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "2012.05786", "submitter": "Sridhar Suresh Ragupathi", "authors": "Kartheek Akella, Sai Himal Allu, Sridhar Suresh Ragupathi, Aman\n  Singhal, Zeeshan Khan, Vinay P. Namboodiri, C V Jawahar", "title": "Exploring Pair-Wise NMT for Indian Languages", "comments": "ICON 2020 Short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we address the task of improving pair-wise machine translation\nfor specific low resource Indian languages. Multilingual NMT models have\ndemonstrated a reasonable amount of effectiveness on resource-poor languages.\nIn this work, we show that the performance of these models can be significantly\nimproved upon by using back-translation through a filtered back-translation\nprocess and subsequent fine-tuning on the limited pair-wise language corpora.\nThe analysis in this paper suggests that this method can significantly improve\na multilingual model's performance over its baseline, yielding state-of-the-art\nresults for various Indian languages.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 16:22:36 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Akella", "Kartheek", ""], ["Allu", "Sai Himal", ""], ["Ragupathi", "Sridhar Suresh", ""], ["Singhal", "Aman", ""], ["Khan", "Zeeshan", ""], ["Namboodiri", "Vinay P.", ""], ["Jawahar", "C V", ""]]}, {"id": "2012.05818", "submitter": "Qingqing Cao", "authors": "Qingqing Cao, Oriana Riva, Aruna Balasubramanian, Niranjan\n  Balasubramanian", "title": "Bew: Towards Answering Business-Entity-Related Web Questions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present BewQA, a system specifically designed to answer a class of\nquestions that we call Bew questions. Bew questions are related to\nbusinesses/services such as restaurants, hotels, and movie theaters; for\nexample, \"Until what time is happy hour?\". These questions are challenging to\nanswer because the answers are found in open-domain Web, are present in short\nsentences without surrounding context, and are dynamic since the webpage\ninformation can be updated frequently. Under these conditions, existing QA\nsystems perform poorly. We present a practical approach, called BewQA, that can\nanswer Bew queries by mining a template of the business-related webpages and\nusing the template to guide the search. We show how we can extract the template\nautomatically by leveraging aggregator websites that aggregate information\nabout business entities in a domain (e.g., restaurants). We answer a given\nquestion by identifying the section from the extracted template that is most\nlikely to contain the answer. By doing so we can extract the answers even when\nthe answer span does not have sufficient context. Importantly, BewQA does not\nrequire any training. We crowdsource a new dataset of 1066 Bew questions and\nground-truth answers in the restaurant domain. Compared to state-of-the-art QA\nmodels, BewQA has a 27 percent point improvement in F1 score. Compared to a\ncommercial search engine, BewQA answered correctly 29% more Bew questions.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 16:46:55 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Cao", "Qingqing", ""], ["Riva", "Oriana", ""], ["Balasubramanian", "Aruna", ""], ["Balasubramanian", "Niranjan", ""]]}, {"id": "2012.05879", "submitter": "Mohammad Sadegh Rasooli", "authors": "Mohammad Sadegh Rasooli, Farzane Bakhtyari, Fatemeh Shafiei, Mahsa\n  Ravanbakhsh, Chris Callison-Burch", "title": "Automatic Standardization of Colloquial Persian", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Iranian Persian language has two varieties: standard and colloquial. Most\nnatural language processing tools for Persian assume that the text is in\nstandard form: this assumption is wrong in many real applications especially\nweb content. This paper describes a simple and effective standardization\napproach based on sequence-to-sequence translation. We design an algorithm for\ngenerating artificial parallel colloquial-to-standard data for learning a\nsequence-to-sequence model. Moreover, we annotate a publicly available\nevaluation data consisting of 1912 sentences from a diverse set of domains. Our\nintrinsic evaluation shows a higher BLEU score of 62.8 versus 61.7 compared to\nan off-the-shelf rule-based standardization model in which the original text\nhas a BLEU score of 46.4. We also show that our model improves\nEnglish-to-Persian machine translation in scenarios for which the training data\nis from colloquial Persian with 1.4 absolute BLEU score difference in the\ndevelopment data, and 0.8 in the test data.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 18:39:26 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Rasooli", "Mohammad Sadegh", ""], ["Bakhtyari", "Farzane", ""], ["Shafiei", "Fatemeh", ""], ["Ravanbakhsh", "Mahsa", ""], ["Callison-Burch", "Chris", ""]]}, {"id": "2012.05906", "submitter": "Alessandro Provetti", "authors": "Justina Deveikyte, Helyette Geman, Carlo Piccari, Alessandro Provetti", "title": "A Sentiment Analysis Approach to the Prediction of Market Volatility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction and quantification of future volatility and returns play an\nimportant role in financial modelling, both in portfolio optimization and risk\nmanagement. Natural language processing today allows to process news and social\nmedia comments to detect signals of investors' confidence. We have explored the\nrelationship between sentiment extracted from financial news and tweets and\nFTSE100 movements. We investigated the strength of the correlation between\nsentiment measures on a given day and market volatility and returns observed\nthe next day. The findings suggest that there is evidence of correlation\nbetween sentiment and stock market movements: the sentiment captured from news\nheadlines could be used as a signal to predict market returns; the same does\nnot apply for volatility. Also, in a surprising finding, for the sentiment\nfound in Twitter comments we obtained a correlation coefficient of -0.7, and\np-value below 0.05, which indicates a strong negative correlation between\npositive sentiment captured from the tweets on a given day and the volatility\nobserved the next day. We developed an accurate classifier for the prediction\nof market volatility in response to the arrival of new information by deploying\ntopic modelling, based on Latent Dirichlet Allocation, to extract feature\nvectors from a collection of tweets and financial news. The obtained features\nwere used as additional input to the classifier. Thanks to the combination of\nsentiment and topic modelling our classifier achieved a directional prediction\naccuracy for volatility of 63%.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 01:15:48 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Deveikyte", "Justina", ""], ["Geman", "Helyette", ""], ["Piccari", "Carlo", ""], ["Provetti", "Alessandro", ""]]}, {"id": "2012.05958", "submitter": "Mihaela Bornea", "authors": "Mihaela Bornea, Lin Pan, Sara Rosenthal, Radu Florian, Avirup Sil", "title": "Multilingual Transfer Learning for QA Using Translation as Data\n  Augmentation", "comments": null, "journal-ref": "AAAI 2021", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work on multilingual question answering has mostly focused on using\nlarge multilingual pre-trained language models (LM) to perform zero-shot\nlanguage-wise learning: train a QA model on English and test on other\nlanguages. In this work, we explore strategies that improve cross-lingual\ntransfer by bringing the multilingual embeddings closer in the semantic space.\nOur first strategy augments the original English training data with machine\ntranslation-generated data. This results in a corpus of multilingual\nsilver-labeled QA pairs that is 14 times larger than the original training set.\nIn addition, we propose two novel strategies, language adversarial training and\nlanguage arbitration framework, which significantly improve the (zero-resource)\ncross-lingual transfer performance and result in LM embeddings that are less\nlanguage-variant. Empirically, we show that the proposed models outperform the\nprevious zero-shot baseline on the recently introduced multilingual MLQA and\nTyDiQA datasets.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 20:29:34 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Bornea", "Mihaela", ""], ["Pan", "Lin", ""], ["Rosenthal", "Sara", ""], ["Florian", "Radu", ""], ["Sil", "Avirup", ""]]}, {"id": "2012.05983", "submitter": "Zachary Brown", "authors": "Zachary C. Brown, Nathaniel Robinson, David Wingate, Nancy Fulda", "title": "Towards Neural Programming Interfaces", "comments": "24 pages total (13 for main paper and references, 11 for Appendix 1),\n  accepted for publication in Advances in Neural Information Processing Systems\n  33 (NeurIPS 2020)", "journal-ref": "Neural Information Processing Systems 33 (2020) 17416-17428", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is notoriously difficult to control the behavior of artificial neural\nnetworks such as generative neural language models. We recast the problem of\ncontrolling natural language generation as that of learning to interface with a\npretrained language model, just as Application Programming Interfaces (APIs)\ncontrol the behavior of programs by altering hyperparameters. In this new\nparadigm, a specialized neural network (called a Neural Programming Interface\nor NPI) learns to interface with a pretrained language model by manipulating\nthe hidden activations of the pretrained model to produce desired outputs.\nImportantly, no permanent changes are made to the weights of the original\nmodel, allowing us to re-purpose pretrained models for new tasks without\noverwriting any aspect of the language model. We also contribute a new data set\nconstruction algorithm and GAN-inspired loss function that allows us to train\nNPI models to control outputs of autoregressive transformers. In experiments\nagainst other state-of-the-art approaches, we demonstrate the efficacy of our\nmethods using OpenAI's GPT-2 model, successfully controlling noun selection,\ntopic aversion, offensive speech filtering, and other aspects of language while\nlargely maintaining the controlled model's fluency under deterministic\nsettings.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 21:17:04 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 04:38:51 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Brown", "Zachary C.", ""], ["Robinson", "Nathaniel", ""], ["Wingate", "David", ""], ["Fulda", "Nancy", ""]]}, {"id": "2012.06025", "submitter": "Yasas Senarath", "authors": "Yasas Senarath, Uthayasanker Thayasivam", "title": "Exploring Deep Neural Networks and Transfer Learning for Analyzing\n  Emotions in Tweets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present an experiment on using deep learning and transfer\nlearning techniques for emotion analysis in tweets and suggest a method to\ninterpret our deep learning models. The proposed approach for emotion analysis\ncombines a Long Short Term Memory (LSTM) network with a Convolutional Neural\nNetwork (CNN). Then we extend this approach for emotion intensity prediction\nusing transfer learning technique. Furthermore, we propose a technique to\nvisualize the importance of each word in a tweet to get a better understanding\nof the model. Experimentally, we show in our analysis that the proposed models\noutperform the state-of-the-art in emotion classification while maintaining\ncompetitive results in predicting emotion intensity.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 23:45:53 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Senarath", "Yasas", ""], ["Thayasivam", "Uthayasanker", ""]]}, {"id": "2012.06048", "submitter": "Fei Yuan", "authors": "Fei Yuan, Linjun Shou, Jian Pei, Wutao Lin, Ming Gong, Yan Fu, Daxin\n  Jiang", "title": "Reinforced Multi-Teacher Selection for Knowledge Distillation", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In natural language processing (NLP) tasks, slow inference speed and huge\nfootprints in GPU usage remain the bottleneck of applying pre-trained deep\nmodels in production. As a popular method for model compression, knowledge\ndistillation transfers knowledge from one or multiple large (teacher) models to\na small (student) model. When multiple teacher models are available in\ndistillation, the state-of-the-art methods assign a fixed weight to a teacher\nmodel in the whole distillation. Furthermore, most of the existing methods\nallocate an equal weight to every teacher model. In this paper, we observe\nthat, due to the complexity of training examples and the differences in student\nmodel capability, learning differentially from teacher models can lead to\nbetter performance of student models distilled. We systematically develop a\nreinforced method to dynamically assign weights to teacher models for different\ntraining instances and optimize the performance of student model. Our extensive\nexperimental results on several NLP tasks clearly verify the feasibility and\neffectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 08:56:39 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 02:48:07 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Yuan", "Fei", ""], ["Shou", "Linjun", ""], ["Pei", "Jian", ""], ["Lin", "Wutao", ""], ["Gong", "Ming", ""], ["Fu", "Yan", ""], ["Jiang", "Daxin", ""]]}, {"id": "2012.06051", "submitter": "Philippe Schwaller", "authors": "Philippe Schwaller, Daniel Probst, Alain C. Vaucher, Vishnu H. Nair,\n  David Kreutter, Teodoro Laino, Jean-Louis Reymond", "title": "Mapping the Space of Chemical Reactions Using Attention-Based Neural\n  Networks", "comments": "https://rxn4chemistry.github.io/rxnfp/", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organic reactions are usually assigned to classes containing reactions with\nsimilar reagents and mechanisms. Reaction classes facilitate the communication\nof complex concepts and efficient navigation through chemical reaction space.\nHowever, the classification process is a tedious task. It requires the\nidentification of the corresponding reaction class template via annotation of\nthe number of molecules in the reactions, the reaction center, and the\ndistinction between reactants and reagents. This work shows that\ntransformer-based models can infer reaction classes from non-annotated, simple\ntext-based representations of chemical reactions. Our best model reaches a\nclassification accuracy of 98.2%. We also show that the learned representations\ncan be used as reaction fingerprints that capture fine-grained differences\nbetween reaction classes better than traditional reaction fingerprints. The\ninsights into chemical reaction space enabled by our learned fingerprints are\nillustrated by an interactive reaction atlas providing visual clustering and\nsimilarity searching.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 10:25:30 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Schwaller", "Philippe", ""], ["Probst", "Daniel", ""], ["Vaucher", "Alain C.", ""], ["Nair", "Vishnu H.", ""], ["Kreutter", "David", ""], ["Laino", "Teodoro", ""], ["Reymond", "Jean-Louis", ""]]}, {"id": "2012.06075", "submitter": "Tonatiuh Hern\\'andez-Del-Toro M.Sc.", "authors": "Tonatiuh Hern\\'andez-Del-Toro, Carlos A. Reyes-Garc\\'ia", "title": "An algorithm for onset detection of linguistic segments in continuous\n  electroencephalogram signals", "comments": null, "journal-ref": "Proceedings of the 11th Models and Analysis of Vocal Emissions for\n  Biomedical Applications (MAVEBA), pages 249-252, Florence, Italy, 2019.\n  Firenze University Press", "doi": "10.36253/978-88-6453-961-4", "report-no": null, "categories": "eess.SP cs.CL cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Brain Computer Interface based on imagined words can decode the word a\nsubject is thinking on through brain signals to control an external device. In\norder to build a fully asynchronous Brain Computer Interface based on imagined\nwords in electroencephalogram signals as source, we need to solve the problem\nof detecting the onset of the imagined words. Although there has been some\nresearch in this field, the problem has not been fully solved. In this paper we\npresent an approach to solve this problem by using values from statistics,\ninformation theory and chaos theory as features to correctly identify the onset\nof imagined words in a continuous signal. On detecting the onsets of imagined\nwords, the highest True Positive Rate achieved by our approach was obtained\nusing features based on the generalized Hurst exponent, this True Positive Rate\nwas 0.69 and 0.77 with a timing error tolerance region of 3 and 4 seconds\nrespectively.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 01:38:06 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Hern\u00e1ndez-Del-Toro", "Tonatiuh", ""], ["Reyes-Garc\u00eda", "Carlos A.", ""]]}, {"id": "2012.06106", "submitter": "Xin Jia", "authors": "Xin Jia, Wenjie Zhou, Xu Sun, Yunfang Wu", "title": "EQG-RACE: Examination-Type Question Generation", "comments": "Accepted by AAAI-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question Generation (QG) is an essential component of the automatic\nintelligent tutoring systems, which aims to generate high-quality questions for\nfacilitating the reading practice and assessments. However, existing QG\ntechnologies encounter several key issues concerning the biased and unnatural\nlanguage sources of datasets which are mainly obtained from the Web (e.g.\nSQuAD). In this paper, we propose an innovative Examination-type Question\nGeneration approach (EQG-RACE) to generate exam-like questions based on a\ndataset extracted from RACE. Two main strategies are employed in EQG-RACE for\ndealing with discrete answer information and reasoning among long contexts. A\nRough Answer and Key Sentence Tagging scheme is utilized to enhance the\nrepresentations of input. An Answer-guided Graph Convolutional Network (AG-GCN)\nis designed to capture structure information in revealing the inter-sentences\nand intra-sentence relations. Experimental results show a state-of-the-art\nperformance of EQG-RACE, which is apparently superior to the baselines. In\naddition, our work has established a new QG prototype with a reshaped dataset\nand QG method, which provides an important benchmark for related research in\nfuture work. We will make our data and code publicly available for further\nresearch.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 03:52:17 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Jia", "Xin", ""], ["Zhou", "Wenjie", ""], ["Sun", "Xu", ""], ["Wu", "Yunfang", ""]]}, {"id": "2012.06143", "submitter": "Matiss Rikters", "authors": "Mat\\=iss Rikters, Ryokan Ri, Tong Li, Toshiaki Nakazawa", "title": "Document-aligned Japanese-English Conversation Parallel Corpus", "comments": "Published in proceedings of the Fifth Conference on Machine\n  Translation, 2020", "journal-ref": "Proceedings of the Fifth Conference on Machine Translation (2020),\n  pages 637-643", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence-level (SL) machine translation (MT) has reached acceptable quality\nfor many high-resourced languages, but not document-level (DL) MT, which is\ndifficult to 1) train with little amount of DL data; and 2) evaluate, as the\nmain methods and data sets focus on SL evaluation. To address the first issue,\nwe present a document-aligned Japanese-English conversation corpus, including\nbalanced, high-quality business conversation data for tuning and testing. As\nfor the second issue, we manually identify the main areas where SL MT fails to\nproduce adequate translations in lack of context. We then create an evaluation\nset where these phenomena are annotated to alleviate automatic evaluation of DL\nsystems. We train MT models using our corpus to demonstrate how using context\nleads to improvements.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 06:03:33 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Rikters", "Mat\u012bss", ""], ["Ri", "Ryokan", ""], ["Li", "Tong", ""], ["Nakazawa", "Toshiaki", ""]]}, {"id": "2012.06153", "submitter": "Xiaoqi Jiao", "authors": "Xiaoqi Jiao, Huating Chang, Yichun Yin, Lifeng Shang, Xin Jiang, Xiao\n  Chen, Linlin Li, Fang Wang and Qun Liu", "title": "Improving Task-Agnostic BERT Distillation with Layer Mapping Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation (KD) which transfers the knowledge from a large\nteacher model to a small student model, has been widely used to compress the\nBERT model recently. Besides the supervision in the output in the original KD,\nrecent works show that layer-level supervision is crucial to the performance of\nthe student BERT model. However, previous works designed the layer mapping\nstrategy heuristically (e.g., uniform or last-layer), which can lead to\ninferior performance. In this paper, we propose to use the genetic algorithm\n(GA) to search for the optimal layer mapping automatically. To accelerate the\nsearch process, we further propose a proxy setting where a small portion of the\ntraining corpus are sampled for distillation, and three representative tasks\nare chosen for evaluation. After obtaining the optimal layer mapping, we\nperform the task-agnostic BERT distillation with it on the whole corpus to\nbuild a compact student model, which can be directly fine-tuned on downstream\ntasks. Comprehensive experiments on the evaluation benchmarks demonstrate that\n1) layer mapping strategy has a significant effect on task-agnostic BERT\ndistillation and different layer mappings can result in quite different\nperformances; 2) the optimal layer mapping strategy from the proposed search\nprocess consistently outperforms the other heuristic ones; 3) with the optimal\nlayer mapping, our student model achieves state-of-the-art performance on the\nGLUE tasks.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 06:29:58 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Jiao", "Xiaoqi", ""], ["Chang", "Huating", ""], ["Yin", "Yichun", ""], ["Shang", "Lifeng", ""], ["Jiang", "Xin", ""], ["Chen", "Xiao", ""], ["Li", "Linlin", ""], ["Wang", "Fang", ""], ["Liu", "Qun", ""]]}, {"id": "2012.06154", "submitter": "Daniel Khashabi Mr.", "authors": "Daniel Khashabi, Arman Cohan, Siamak Shakeri, Pedram Hosseini, Pouya\n  Pezeshkpour, Malihe Alikhani, Moin Aminnaseri, Marzieh Bitaab, Faeze Brahman,\n  Sarik Ghazarian, Mozhdeh Gheini, Arman Kabiri, Rabeeh Karimi Mahabadi, Omid\n  Memarrast, Ahmadreza Mosallanezhad, Erfan Noury, Shahab Raji, Mohammad Sadegh\n  Rasooli, Sepideh Sadeghi, Erfan Sadeqi Azer, Niloofar Safi Samghabadi, Mahsa\n  Shafaei, Saber Sheybani, Ali Tazarv, Yadollah Yaghoobzadeh", "title": "ParsiNLU: A Suite of Language Understanding Challenges for Persian", "comments": "To appear on Transactions of the Association for Computational\n  Linguistics (TACL), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the progress made in recent years in addressing natural language\nunderstanding (NLU) challenges, the majority of this progress remains to be\nconcentrated on resource-rich languages like English. This work focuses on\nPersian language, one of the widely spoken languages in the world, and yet\nthere are few NLU datasets available for this rich language. The availability\nof high-quality evaluation datasets is a necessity for reliable assessment of\nthe progress on different NLU tasks and domains. We introduce ParsiNLU, the\nfirst benchmark in Persian language that includes a range of high-level tasks\n-- Reading Comprehension, Textual Entailment, etc. These datasets are collected\nin a multitude of ways, often involving manual annotations by native speakers.\nThis results in over 14.5$k$ new instances across 6 distinct NLU tasks.\nBesides, we present the first results on state-of-the-art monolingual and\nmulti-lingual pre-trained language-models on this benchmark and compare them\nwith human performance, which provides valuable insights into our ability to\ntackle natural language understanding challenges in Persian. We hope ParsiNLU\nfosters further research and advances in Persian language understanding.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 06:31:42 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 17:02:32 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Khashabi", "Daniel", ""], ["Cohan", "Arman", ""], ["Shakeri", "Siamak", ""], ["Hosseini", "Pedram", ""], ["Pezeshkpour", "Pouya", ""], ["Alikhani", "Malihe", ""], ["Aminnaseri", "Moin", ""], ["Bitaab", "Marzieh", ""], ["Brahman", "Faeze", ""], ["Ghazarian", "Sarik", ""], ["Gheini", "Mozhdeh", ""], ["Kabiri", "Arman", ""], ["Mahabadi", "Rabeeh Karimi", ""], ["Memarrast", "Omid", ""], ["Mosallanezhad", "Ahmadreza", ""], ["Noury", "Erfan", ""], ["Raji", "Shahab", ""], ["Rasooli", "Mohammad Sadegh", ""], ["Sadeghi", "Sepideh", ""], ["Azer", "Erfan Sadeqi", ""], ["Samghabadi", "Niloofar Safi", ""], ["Shafaei", "Mahsa", ""], ["Sheybani", "Saber", ""], ["Tazarv", "Ali", ""], ["Yaghoobzadeh", "Yadollah", ""]]}, {"id": "2012.06185", "submitter": "Zhiyun Fan", "authors": "Zhiyun Fan, Meng Li, Shiyu Zhou, Bo Xu", "title": "Exploring wav2vec 2.0 on speaker verification and language\n  identification", "comments": "Self-supervised, speaker verification, language identification,\n  multi-task learning, wav2vec 2.0", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wav2vec 2.0 is a recently proposed self-supervised framework for speech\nrepresentation learning. It follows a two-stage training process of\npre-training and fine-tuning, and performs well in speech recognition tasks\nespecially ultra-low resource cases. In this work, we attempt to extend\nself-supervised framework to speaker verification and language identification.\nFirst, we use some preliminary experiments to indicate that wav2vec 2.0 can\ncapture the information about the speaker and language. Then we demonstrate the\neffectiveness of wav2vec 2.0 on the two tasks respectively. For speaker\nverification, we obtain a new state-of-the-art result, Equal Error Rate (EER)\nof 3.61% on the VoxCeleb1 dataset. For language identification, we obtain an\nEER of 12.02% on 1 second condition and an EER of 3.47% on full-length\ncondition of the AP17-OLR dataset. Finally, we utilize one model to achieve the\nunified modeling by the multi-task learning for the two tasks.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 08:22:23 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 14:17:22 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Fan", "Zhiyun", ""], ["Li", "Meng", ""], ["Zhou", "Shiyu", ""], ["Xu", "Bo", ""]]}, {"id": "2012.06236", "submitter": "Deepanway Ghosal", "authors": "Abhinaba Roy, Deepanway Ghosal, Erik Cambria, Navonil Majumder, Rada\n  Mihalcea, Soujanya Poria", "title": "Improving Zero Shot Learning Baselines with Commonsense Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Zero shot learning -- the problem of training and testing on a completely\ndisjoint set of classes -- relies greatly on its ability to transfer knowledge\nfrom train classes to test classes. Traditionally semantic embeddings\nconsisting of human defined attributes (HA) or distributed word embeddings\n(DWE) are used to facilitate this transfer by improving the association between\nvisual and semantic embeddings. In this paper, we take advantage of explicit\nrelations between nodes defined in ConceptNet, a commonsense knowledge graph,\nto generate commonsense embeddings of the class labels by using a graph\nconvolution network-based autoencoder. Our experiments performed on three\nstandard benchmark datasets surpass the strong baselines when we fuse our\ncommonsense embeddings with existing semantic embeddings i.e. HA and DWE.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 10:52:04 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Roy", "Abhinaba", ""], ["Ghosal", "Deepanway", ""], ["Cambria", "Erik", ""], ["Majumder", "Navonil", ""], ["Mihalcea", "Rada", ""], ["Poria", "Soujanya", ""]]}, {"id": "2012.06259", "submitter": "Valya Mendelev", "authors": "Valentin Mendelev, Tina Raissi, Guglielmo Camporese, Manuel Giollo", "title": "Improved Robustness to Disfluencies in RNN-Transducer Based Speech\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic Speech Recognition (ASR) based on Recurrent Neural Network\nTransducers (RNN-T) is gaining interest in the speech community. We investigate\ndata selection and preparation choices aiming for improved robustness of RNN-T\nASR to speech disfluencies with a focus on partial words. For evaluation we use\nclean data, data with disfluencies and a separate dataset with speech affected\nby stuttering. We show that after including a small amount of data with\ndisfluencies in the training set the recognition accuracy on the tests with\ndisfluencies and stuttering improves. Increasing the amount of training data\nwith disfluencies gives additional gains without degradation on the clean data.\nWe also show that replacing partial words with a dedicated token helps to get\neven better accuracy on utterances with disfluencies and stutter. The\nevaluation of our best model shows 22.5% and 16.4% relative WER reduction on\nthose two evaluation sets.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 11:47:13 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Mendelev", "Valentin", ""], ["Raissi", "Tina", ""], ["Camporese", "Guglielmo", ""], ["Giollo", "Manuel", ""]]}, {"id": "2012.06262", "submitter": "Hyunji Park", "authors": "Hyunji Hayley Park, Katherine J. Zhang, Coleman Haley, Kenneth\n  Steimel, Han Liu, Lane Schwartz", "title": "Morphology Matters: A Multilingual Language Modeling Analysis", "comments": "To appear in TACL, a pre-MIT Press publication version; 15 pages, 3\n  figures; for the datasets, see\n  https://github.com/hayleypark/MorphologyMatters", "journal-ref": "Transactions of the Association for Computational Linguistics 9\n  (2021) 261-276", "doi": "10.1162/tacl_a_00365", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior studies in multilingual language modeling (e.g., Cotterell et al.,\n2018; Mielke et al., 2019) disagree on whether or not inflectional morphology\nmakes languages harder to model. We attempt to resolve the disagreement and\nextend those studies. We compile a larger corpus of 145 Bible translations in\n92 languages and a larger number of typological features. We fill in missing\ntypological data for several languages and consider corpus-based measures of\nmorphological complexity in addition to expert-produced typological features.\nWe find that several morphological measures are significantly associated with\nhigher surprisal when LSTM models are trained with BPE-segmented data. We also\ninvestigate linguistically-motivated subword segmentation strategies like\nMorfessor and Finite-State Transducers (FSTs) and find that these segmentation\nstrategies yield better performance and reduce the impact of a language's\nmorphology on language modeling.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 11:55:55 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Park", "Hyunji Hayley", ""], ["Zhang", "Katherine J.", ""], ["Haley", "Coleman", ""], ["Steimel", "Kenneth", ""], ["Liu", "Han", ""], ["Schwartz", "Lane", ""]]}, {"id": "2012.06274", "submitter": "Damir Koren\\v{c}i\\'c", "authors": "Damir Koren\\v{c}i\\'c (1), Strahil Ristov (1), Jelena Repar (1), Jan\n  \\v{S}najder (2) ((1) Rudjer Bo\\v{s}kovi\\'c Institute, Croatia, (2) University\n  of Zagreb, Faculty of Electrical Engineering and Computing, Croatia)", "title": "A Topic Coverage Approach to Evaluation of Topic Models", "comments": "Results and contributions unchanged; Added new references; Improved\n  the contextualization and the description of the work (abstr, intro, 7.1\n  concl, rw, concl); Moved technical details of data and model building to\n  appendices; Improved layout;", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Topic models are widely used unsupervised models of text capable of learning\ntopics - weighted lists of words and documents - from large collections of text\ndocuments. When topic models are used for discovery of topics in text\ncollections, a question that arises naturally is how well the model-induced\ntopics correspond to topics of interest to the analyst. In this paper we\nrevisit and extend a so far neglected approach to topic model evaluation based\non measuring topic coverage - computationally matching model topics with a set\nof reference topics that models are expected to uncover. The approach is well\nsuited for analyzing models' performance in topic discovery and for large-scale\nanalysis of both topic models and measures of model quality. We propose new\nmeasures of coverage and evaluate, in a series of experiments, different types\nof topic models on two distinct text domains for which interest for topic\ndiscovery exists. The experiments include evaluation of model quality, analysis\nof coverage of distinct topic categories, and the analysis of the relationship\nbetween coverage and other methods of topic model evaluation. The contributions\nof the paper include new measures of coverage, insights into both topic models\nand other methods of model evaluation, and the datasets and code for\nfacilitating future research of both topic coverage and other approaches to\ntopic model evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 12:08:27 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 16:27:00 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Koren\u010di\u0107", "Damir", ""], ["Ristov", "Strahil", ""], ["Repar", "Jelena", ""], ["\u0160najder", "Jan", ""]]}, {"id": "2012.06340", "submitter": "Kenny Zhuo Ming Lu", "authors": "Kenny Zhuo Ming Lu", "title": "Control Flow Obfuscation for FJ using Continuation Passing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Control flow obfuscation deters software reverse engineering attempts by\naltering the program's control flow transfer. The alternation should not affect\nthe software's run-time behaviour. In this paper, we propose a control flow\nobfuscation approach for FJ with exception handling. The approach is based on a\nsource to source transformation using continuation passing style (CPS). We\nargue that the proposed CPS transformation causes malicious attacks using\ncontext insensitive static analysis and context sensitive analysis with fixed\ncall string to lose precision.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 06:41:52 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 04:34:52 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Lu", "Kenny Zhuo Ming", ""]]}, {"id": "2012.06431", "submitter": "Leon Derczynski", "authors": "Ren\\'e Haas, Leon Derczynski", "title": "Discriminating Between Similar Nordic Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic language identification is a challenging problem. Discriminating\nbetween closely related languages is especially difficult. This paper presents\na machine learning approach for automatic language identification for the\nNordic languages, which often suffer miscategorisation by existing\nstate-of-the-art tools. Concretely we will focus on discrimination between six\nNordic languages: Danish, Swedish, Norwegian (Nynorsk), Norwegian (Bokm{\\aa}l),\nFaroese and Icelandic.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 15:46:15 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Haas", "Ren\u00e9", ""], ["Derczynski", "Leon", ""]]}, {"id": "2012.06460", "submitter": "Ivan Vuli\\'c", "authors": "Marko Vidoni, Ivan Vuli\\'c, Goran Glava\\v{s}", "title": "Orthogonal Language and Task Adapters in Zero-Shot Cross-Lingual\n  Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adapter modules, additional trainable parameters that enable efficient\nfine-tuning of pretrained transformers, have recently been used for language\nspecialization of multilingual transformers, improving downstream zero-shot\ncross-lingual transfer. In this work, we propose orthogonal language and task\nadapters (dubbed orthoadapters) for cross-lingual transfer. They are trained to\nencode language- and task-specific information that is complementary (i.e.,\northogonal) to the knowledge already stored in the pretrained transformer's\nparameters. Our zero-shot cross-lingual transfer experiments, involving three\ntasks (POS-tagging, NER, NLI) and a set of 10 diverse languages, 1) point to\nthe usefulness of orthoadapters in cross-lingual transfer, especially for the\nmost complex NLI task, but also 2) indicate that the optimal adapter\nconfiguration highly depends on the task and the target language. We hope that\nour work will motivate a wider investigation of usefulness of orthogonality\nconstraints in language- and task-specific fine-tuning of pretrained\ntransformers.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 16:32:41 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Vidoni", "Marko", ""], ["Vuli\u0107", "Ivan", ""], ["Glava\u0161", "Goran", ""]]}, {"id": "2012.06561", "submitter": "Pavel Naumov", "authors": "Pavel Naumov, Kevin Ros", "title": "Comprehension and Knowledge", "comments": "To appear in Proceedings 35th AAAI Conference on Artificial\n  Intelligence (AAAI 21), February 2-9, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of an agent to comprehend a sentence is tightly connected to the\nagent's prior experiences and background knowledge. The paper suggests to\ninterpret comprehension as a modality and proposes a complete bimodal logical\nsystem that describes an interplay between comprehension and knowledge\nmodalities.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 18:42:08 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 22:24:35 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Naumov", "Pavel", ""], ["Ros", "Kevin", ""]]}, {"id": "2012.06606", "submitter": "Arkaitz Zubiaga", "authors": "Arkaitz Zubiaga", "title": "TF-CR: Weighting Embeddings for Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text classification, as the task consisting in assigning categories to\ntextual instances, is a very common task in information science. Methods\nlearning distributed representations of words, such as word embeddings, have\nbecome popular in recent years as the features to use for text classification\ntasks. Despite the increasing use of word embeddings for text classification,\nthese are generally used in an unsupervised manner, i.e. information derived\nfrom class labels in the training data are not exploited. While word embeddings\ninherently capture the distributional characteristics of words, and contexts\nobserved around them in a large dataset, they aren't optimised to consider the\ndistributions of words across categories in the classification dataset at hand.\nTo optimise text representations based on word embeddings by incorporating\nclass distributions in the training data, we propose the use of weighting\nschemes that assign a weight to embeddings of each word based on its saliency\nin each class. To achieve this, we introduce a novel weighting scheme, Term\nFrequency-Category Ratio (TF-CR), which can weight high-frequency,\ncategory-exclusive words higher when computing word embeddings. Our experiments\non 16 classification datasets show the effectiveness of TF-CR, leading to\nimproved performance scores over existing weighting schemes, with a performance\ngap that increases as the size of the training data grows.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 19:23:28 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Zubiaga", "Arkaitz", ""]]}, {"id": "2012.06659", "submitter": "Yuzong Liu", "authors": "Shaoshi Ling, Yuzong Liu", "title": "DeCoAR 2.0: Deep Contextualized Acoustic Representations with Vector\n  Quantization", "comments": "Submitted to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent success in speech representation learning enables a new way to\nleverage unlabeled data to train speech recognition model. In speech\nrepresentation learning, a large amount of unlabeled data is used in a\nself-supervised manner to learn a feature representation. Then a smaller amount\nof labeled data is used to train a downstream ASR system using the new feature\nrepresentations. Based on our previous work DeCoAR and inspirations from other\nspeech representation learning, we propose DeCoAR 2.0, a Deep Contextualized\nAcoustic Representation with vector quantization. We introduce several\nmodifications over the DeCoAR: first, we use Transformers in encoding module\ninstead of LSTMs; second, we introduce a vector quantization layer between\nencoder and reconstruction modules; third, we propose an objective that\ncombines the reconstructive loss with vector quantization diversity loss to\ntrain speech representations. Our experiments show consistent improvements over\nother speech representations in different data-sparse scenarios. Without\nfine-tuning, a light-weight ASR model trained on 10 hours of LibriSpeech\nlabeled data with DeCoAR 2.0 features outperforms the model trained on the full\n960-hour dataset with filterbank features.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 22:07:23 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Ling", "Shaoshi", ""], ["Liu", "Yuzong", ""]]}, {"id": "2012.06690", "submitter": "Zefang Liu", "authors": "Zefang Liu", "title": "Yelp Review Rating Prediction: Machine Learning and Deep Learning Models", "comments": "8 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We predict restaurant ratings from Yelp reviews based on Yelp Open Dataset.\nData distribution is presented, and one balanced training dataset is built. Two\nvectorizers are experimented for feature engineering. Four machine learning\nmodels including Naive Bayes, Logistic Regression, Random Forest, and Linear\nSupport Vector Machine are implemented. Four transformer-based models\ncontaining BERT, DistilBERT, RoBERTa, and XLNet are also applied. Accuracy,\nweighted F1 score, and confusion matrix are used for model evaluation. XLNet\nachieves 70% accuracy for 5-star classification compared with Logistic\nRegression with 64% accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 01:07:48 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Liu", "Zefang", ""]]}, {"id": "2012.06717", "submitter": "Hsiang-Yun Chien", "authors": "Hsiang-Yun Sherry Chien, Jinhan Zhang and Christopher. J. Honey", "title": "Mapping the Timescale Organization of Neural Language Models", "comments": "23 pages, 4 main figures, 10 appendix figures; published as a\n  conference paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the human brain, sequences of language input are processed within a\ndistributed and hierarchical architecture, in which higher stages of processing\nencode contextual information over longer timescales. In contrast, in recurrent\nneural networks which perform natural language processing, we know little about\nhow the multiple timescales of contextual information are functionally\norganized. Therefore, we applied tools developed in neuroscience to map the\n\"processing timescales\" of individual units within a word-level LSTM language\nmodel. This timescale-mapping method assigned long timescales to units\npreviously found to track long-range syntactic dependencies. Additionally, the\nmapping revealed a small subset of the network (less than 15% of units) with\nlong timescales and whose function had not previously been explored. We next\nprobed the functional organization of the network by examining the relationship\nbetween the processing timescale of units and their network connectivity. We\nidentified two classes of long-timescale units: \"controller\" units composed a\ndensely interconnected subnetwork and strongly projected to the rest of the\nnetwork, while \"integrator\" units showed the longest timescales in the network,\nand expressed projection profiles closer to the mean projection profile.\nAblating integrator and controller units affected model performance at\ndifferent positions within a sentence, suggesting distinctive functions of\nthese two sets of units. Finally, we tested the generalization of these results\nto a character-level LSTM model and models with different architectures. In\nsummary, we demonstrated a model-free technique for mapping the timescale\norganization in recurrent neural networks, and we applied this method to reveal\nthe timescale and functional organization of neural language models.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 03:52:15 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 21:15:45 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Chien", "Hsiang-Yun Sherry", ""], ["Zhang", "Jinhan", ""], ["Honey", "Christopher. J.", ""]]}, {"id": "2012.06749", "submitter": "Yanzhang He", "authors": "Rohit Prabhavalkar, Yanzhang He, David Rybach, Sean Campbell, Arun\n  Narayanan, Trevor Strohman, Tara N. Sainath", "title": "Less Is More: Improved RNN-T Decoding Using Limited Label Context and\n  Path Merging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end models that condition the output label sequence on all previously\npredicted labels have emerged as popular alternatives to conventional systems\nfor automatic speech recognition (ASR). Since unique label histories correspond\nto distinct models states, such models are decoded using an approximate\nbeam-search process which produces a tree of hypotheses.\n  In this work, we study the influence of the amount of label context on the\nmodel's accuracy, and its impact on the efficiency of the decoding process. We\nfind that we can limit the context of the recurrent neural network transducer\n(RNN-T) during training to just four previous word-piece labels, without\ndegrading word error rate (WER) relative to the full-context baseline. Limiting\ncontext also provides opportunities to improve the efficiency of the\nbeam-search process during decoding by removing redundant paths from the active\nbeam, and instead retaining them in the final lattice. This path-merging scheme\ncan also be applied when decoding the baseline full-context model through an\napproximation. Overall, we find that the proposed path-merging scheme is\nextremely effective allowing us to improve oracle WERs by up to 36% over the\nbaseline, while simultaneously reducing the number of model evaluations by up\nto 5.3% without any degradation in WER.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 07:39:21 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Prabhavalkar", "Rohit", ""], ["He", "Yanzhang", ""], ["Rybach", "David", ""], ["Campbell", "Sean", ""], ["Narayanan", "Arun", ""], ["Strohman", "Trevor", ""], ["Sainath", "Tara N.", ""]]}, {"id": "2012.06754", "submitter": "Yichao Luo", "authors": "Yichao Luo, Zhengyan Li, Bingning Wang, Xiaoyu Xing, Qi Zhang,\n  Xuanjing Huang", "title": "SenSeNet: Neural Keyphrase Generation with Document Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Keyphrase Generation (KG) is the task of generating central topics from a\ngiven document or literary work, which captures the crucial information\nnecessary to understand the content. Documents such as scientific literature\ncontain rich meta-sentence information, which represents the logical-semantic\nstructure of the documents. However, previous approaches ignore the constraints\nof document logical structure, and hence they mistakenly generate keyphrases\nfrom unimportant sentences. To address this problem, we propose a new method\ncalled Sentence Selective Network (SenSeNet) to incorporate the meta-sentence\ninductive bias into KG. In SenSeNet, we use a straight-through estimator for\nend-to-end training and incorporate weak supervision in the training of the\nsentence selection module. Experimental results show that SenSeNet can\nconsistently improve the performance of major KG models based on seq2seq\nframework, which demonstrate the effectiveness of capturing structural\ninformation and distinguishing the significance of sentences in KG task.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 08:21:08 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Luo", "Yichao", ""], ["Li", "Zhengyan", ""], ["Wang", "Bingning", ""], ["Xing", "Xiaoyu", ""], ["Zhang", "Qi", ""], ["Huang", "Xuanjing", ""]]}, {"id": "2012.06780", "submitter": "Hao Zhang", "authors": "Fuzhao Xue, Aixin Sun, Hao Zhang, Eng Siong Chng", "title": "GDPNet: Refining Latent Multi-View Graph for Relation Extraction", "comments": "To appear at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation Extraction (RE) is to predict the relation type of two entities that\nare mentioned in a piece of text, e.g., a sentence or a dialogue. When the\ngiven text is long, it is challenging to identify indicative words for the\nrelation prediction. Recent advances on RE task are from BERT-based sequence\nmodeling and graph-based modeling of relationships among the tokens in the\nsequence. In this paper, we propose to construct a latent multi-view graph to\ncapture various possible relationships among tokens. We then refine this graph\nto select important words for relation prediction. Finally, the representation\nof the refined graph and the BERT-based sequence representation are\nconcatenated for relation extraction. Specifically, in our proposed GDPNet\n(Gaussian Dynamic Time Warping Pooling Net), we utilize Gaussian Graph\nGenerator (GGG) to generate edges of the multi-view graph. The graph is then\nrefined by Dynamic Time Warping Pooling (DTWPool). On DialogRE and TACRED, we\nshow that GDPNet achieves the best performance on dialogue-level RE, and\ncomparable performance with the state-of-the-arts on sentence-level RE.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 10:43:41 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Xue", "Fuzhao", ""], ["Sun", "Aixin", ""], ["Zhang", "Hao", ""], ["Chng", "Eng Siong", ""]]}, {"id": "2012.06836", "submitter": "Francesco Barchi", "authors": "Emanuele Parisi, Francesco Barchi, Andrea Bartolini, Giuseppe\n  Tagliavini, Andrea Acquaviva", "title": "Source Code Classification for Energy Efficiency in Parallel Ultra\n  Low-Power Microcontrollers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The analysis of source code through machine learning techniques is an\nincreasingly explored research topic aiming at increasing smartness in the\nsoftware toolchain to exploit modern architectures in the best possible way. In\nthe case of low-power, parallel embedded architectures, this means finding the\nconfiguration, for instance in terms of the number of cores, leading to minimum\nenergy consumption. Depending on the kernel to be executed, the energy optimal\nscaling configuration is not trivial. While recent work has focused on\ngeneral-purpose systems to learn and predict the best execution target in terms\nof the execution time of a snippet of code or kernel (e.g. offload OpenCL\nkernel on multicore CPU or GPU), in this work we focus on static compile-time\nfeatures to assess if they can be successfully used to predict the minimum\nenergy configuration on PULP, an ultra-low-power architecture featuring an\non-chip cluster of RISC-V processors. Experiments show that using machine\nlearning models on the source code to select the best energy scaling\nconfiguration automatically is viable and has the potential to be used in the\ncontext of automatic system configuration for energy minimisation.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 15:12:03 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Parisi", "Emanuele", ""], ["Barchi", "Francesco", ""], ["Bartolini", "Andrea", ""], ["Tagliavini", "Giuseppe", ""], ["Acquaviva", "Andrea", ""]]}, {"id": "2012.06847", "submitter": "Zana Bu\\c{c}inca", "authors": "Zana Bucinca, Yucel Yemez, Engin Erzin, Metin Sezgin", "title": "AffectON: Incorporating Affect Into Dialog Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Due to its expressivity, natural language is paramount for explicit and\nimplicit affective state communication among humans. The same linguistic\ninquiry (e.g., How are you?) might induce responses with different affects\ndepending on the affective state of the conversational partner(s) and the\ncontext of the conversation. Yet, most dialog systems do not consider affect as\nconstitutive aspect of response generation. In this paper, we introduce\nAffectON, an approach for generating affective responses during inference. For\ngenerating language in a targeted affect, our approach leverages a\nprobabilistic language model and an affective space. AffectON is language model\nagnostic, since it can work with probabilities generated by any language model\n(e.g., sequence-to-sequence models, neural language models, n-grams). Hence, it\ncan be employed for both affective dialog and affective language generation. We\nexperimented with affective dialog generation and evaluated the generated text\nobjectively and subjectively. For the subjective part of the evaluation, we\ndesigned a custom user interface for rating and provided recommendations for\nthe design of such interfaces. The results, both subjective and objective\ndemonstrate that our approach is successful in pulling the generated language\ntoward the targeted affect, with little sacrifice in syntactic coherence.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 16:02:08 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Bucinca", "Zana", ""], ["Yemez", "Yucel", ""], ["Erzin", "Engin", ""], ["Sezgin", "Metin", ""]]}, {"id": "2012.06943", "submitter": "Snehasish Mukherjee", "authors": "Snehasish Mukherjee, Phaniram Sayapaneni, Shankar Subramanya", "title": "Discriminative Pre-training for Low Resource Title Compression in\n  Conversational Grocery", "comments": "To be published in Proceedings of ACM SIGIR Workshop on eCommerce\n  (SIGIR eCom 20) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The ubiquity of smart voice assistants has made conversational shopping\ncommonplace. This is especially true for low consideration segments like\ngrocery. A central problem in conversational grocery is the automatic\ngeneration of short product titles that can be read out fast during a\nconversation. Several supervised models have been proposed in the literature\nthat leverage manually labeled datasets and additional product features to\ngenerate short titles automatically. However, obtaining large amounts of\nlabeled data is expensive and most grocery item pages are not as feature-rich\nas other categories. To address this problem we propose a pre-training based\nsolution that makes use of unlabeled data to learn contextual product\nrepresentations which can then be fine-tuned to obtain better title compression\neven in a low resource setting. We use a self-attentive BiLSTM encoder network\nwith a time distributed softmax layer for the title compression task. We\novercome the vocabulary mismatch problem by using a hybrid embedding layer that\ncombines pre-trained word embeddings with trainable character level\nconvolutions. We pre-train this network as a discriminator on a replaced-token\ndetection task over a large number of unlabeled grocery product titles.\nFinally, we fine tune this network, without any modifications, with a small\nlabeled dataset for the title compression task. Experiments on Walmart's online\ngrocery catalog show our model achieves performance comparable to\nstate-of-the-art models like BERT and XLNet. When fine tuned on all of the\navailable training data our model attains an F1 score of 0.8558 which lags the\nbest performing model, BERT-Base, by 2.78% and XLNet by 0.28% only, while using\n55 times lesser parameters than both. Further, when allowed to fine tune on 5%\nof the training data only, our model outperforms BERT-Base by 24.3% in F1\nscore.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 02:34:56 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Mukherjee", "Snehasish", ""], ["Sayapaneni", "Phaniram", ""], ["Subramanya", "Shankar", ""]]}, {"id": "2012.06971", "submitter": "Song Changhe", "authors": "Changhe Song, Jingbei Li, Yixuan Zhou, Zhiyong Wu, Helen Meng", "title": "Syntactic representation learning for neural network based TTS with\n  syntactic parse tree traversal", "comments": "This paper was submitted to ICASSP2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syntactic structure of a sentence text is correlated with the prosodic\nstructure of the speech that is crucial for improving the prosody and\nnaturalness of a text-to-speech (TTS) system. Nowadays TTS systems usually try\nto incorporate syntactic structure information with manually designed features\nbased on expert knowledge. In this paper, we propose a syntactic representation\nlearning method based on syntactic parse tree traversal to automatically\nutilize the syntactic structure information. Two constituent label sequences\nare linearized through left-first and right-first traversals from constituent\nparse tree. Syntactic representations are then extracted at word level from\neach constituent label sequence by a corresponding uni-directional gated\nrecurrent unit (GRU) network. Meanwhile, nuclear-norm maximization loss is\nintroduced to enhance the discriminability and diversity of the embeddings of\nconstituent labels. Upsampled syntactic representations and phoneme embeddings\nare concatenated to serve as the encoder input of Tacotron2. Experimental\nresults demonstrate the effectiveness of our proposed approach, with mean\nopinion score (MOS) increasing from 3.70 to 3.82 and ABX preference exceeding\nby 17% compared with the baseline. In addition, for sentences with multiple\nsyntactic parse trees, prosodic differences can be clearly perceived from the\nsynthesized speeches.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 05:52:07 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Song", "Changhe", ""], ["Li", "Jingbei", ""], ["Zhou", "Yixuan", ""], ["Wu", "Zhiyong", ""], ["Meng", "Helen", ""]]}, {"id": "2012.07000", "submitter": "Siyi Ma", "authors": "Dandan Song, Siyi Ma, Zhanchen Sun, Sicheng Yang, Lejian Liao", "title": "KVL-BERT: Knowledge Enhanced Visual-and-Linguistic BERT for Visual\n  Commonsense Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reasoning is a critical ability towards complete visual understanding. To\ndevelop machine with cognition-level visual understanding and reasoning\nabilities, the visual commonsense reasoning (VCR) task has been introduced. In\nVCR, given a challenging question about an image, a machine must answer\ncorrectly and then provide a rationale justifying its answer. The methods\nadopting the powerful BERT model as the backbone for learning joint\nrepresentation of image content and natural language have shown promising\nimprovements on VCR. However, none of the existing methods have utilized\ncommonsense knowledge in visual commonsense reasoning, which we believe will be\ngreatly helpful in this task. With the support of commonsense knowledge,\ncomplex questions even if the required information is not depicted in the image\ncan be answered with cognitive reasoning. Therefore, we incorporate commonsense\nknowledge into the cross-modal BERT, and propose a novel Knowledge Enhanced\nVisual-and-Linguistic BERT (KVL-BERT for short) model. Besides taking visual\nand linguistic contents as input, external commonsense knowledge extracted from\nConceptNet is integrated into the multi-layer Transformer. In order to reserve\nthe structural information and semantic representation of the original\nsentence, we propose using relative position embedding and mask-self-attention\nto weaken the effect between the injected commonsense knowledge and other\nunrelated components in the input sequence. Compared to other task-specific\nmodels and general task-agnostic pre-training models, our KVL-BERT outperforms\nthem by a large margin.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 08:22:33 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Song", "Dandan", ""], ["Ma", "Siyi", ""], ["Sun", "Zhanchen", ""], ["Yang", "Sicheng", ""], ["Liao", "Lejian", ""]]}, {"id": "2012.07004", "submitter": "Yutai Hou", "authors": "Yutai Hou, Sanyuan Chen, Wanxiang Che, Cheng Chen, Ting Liu", "title": "C2C-GenDA: Cluster-to-Cluster Generation for Data Augmentation of Slot\n  Filling", "comments": "Accepted by AAAI-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Slot filling, a fundamental module of spoken language understanding, often\nsuffers from insufficient quantity and diversity of training data. To remedy\nthis, we propose a novel Cluster-to-Cluster generation framework for Data\nAugmentation (DA), named C2C-GenDA. It enlarges the training set by\nreconstructing existing utterances into alternative expressions while keeping\nsemantic. Different from previous DA works that reconstruct utterances one by\none independently, C2C-GenDA jointly encodes multiple existing utterances of\nthe same semantics and simultaneously decodes multiple unseen expressions.\nJointly generating multiple new utterances allows to consider the relations\nbetween generated instances and encourages diversity. Besides, encoding\nmultiple existing utterances endows C2C with a wider view of existing\nexpressions, helping to reduce generation that duplicates existing data.\nExperiments on ATIS and Snips datasets show that instances augmented by\nC2C-GenDA improve slot filling by 7.99 (11.9%) and 5.76 (13.6%) F-scores\nrespectively, when there are only hundreds of training utterances.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 08:35:37 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Hou", "Yutai", ""], ["Chen", "Sanyuan", ""], ["Che", "Wanxiang", ""], ["Chen", "Cheng", ""], ["Liu", "Ting", ""]]}, {"id": "2012.07011", "submitter": "Ziyue Qiao", "authors": "Ziyue Qiao, Zhiyuan Ning, Yi Du, Yuanchun Zhou", "title": "Context-Enhanced Entity and Relation Embedding for Knowledge Graph\n  Completion", "comments": "2 pages, accepted by AAAI-21 student abstract and poster program", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most researches for knowledge graph completion learn representations of\nentities and relations to predict missing links in incomplete knowledge graphs.\nHowever, these methods fail to take full advantage of both the contextual\ninformation of entity and relation. Here, we extract contexts of entities and\nrelations from the triplets which they compose. We propose a model named AggrE,\nwhich conducts efficient aggregations respectively on entity context and\nrelation context in multi-hops, and learns context-enhanced entity and relation\nembeddings for knowledge graph completion. The experiment results show that\nAggrE is competitive to existing models.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 09:20:42 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Qiao", "Ziyue", ""], ["Ning", "Zhiyuan", ""], ["Du", "Yi", ""], ["Zhou", "Yuanchun", ""]]}, {"id": "2012.07019", "submitter": "Yinuo Guo", "authors": "Yinuo Guo, Zeqi Lin, Jian-Guang Lou, Dongmei Zhang", "title": "Iterative Utterance Segmentation for Neural Semantic Parsing", "comments": "Accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural semantic parsers usually fail to parse long and complex utterances\ninto correct meaning representations, due to the lack of exploiting the\nprinciple of compositionality. To address this issue, we present a novel\nframework for boosting neural semantic parsers via iterative utterance\nsegmentation. Given an input utterance, our framework iterates between two\nneural modules: a segmenter for segmenting a span from the utterance, and a\nparser for mapping the span into a partial meaning representation. Then, these\nintermediate parsing results are composed into the final meaning\nrepresentation. One key advantage is that this framework does not require any\nhandcraft templates or additional labeled data for utterance segmentation: we\nachieve this through proposing a novel training method, in which the parser\nprovides pseudo supervision for the segmenter. Experiments on Geo,\nComplexWebQuestions, and Formulas show that our framework can consistently\nimprove performances of neural semantic parsers in different domains. On data\nsplits that require compositional generalization, our framework brings\nsignificant accuracy gains: Geo 63.1 to 81.2, Formulas 59.7 to 72.7,\nComplexWebQuestions 27.1 to 56.3.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 09:46:24 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Guo", "Yinuo", ""], ["Lin", "Zeqi", ""], ["Lou", "Jian-Guang", ""], ["Zhang", "Dongmei", ""]]}, {"id": "2012.07073", "submitter": "Hussein Al-Natsheh", "authors": "Wael Farhan, Muhy Eddin Za'ter, Qusai Abu Obaidah, Hisham al Bataineh,\n  Zyad Sober, Hussein T. Al-Natsheh", "title": "SPARTA: Speaker Profiling for ARabic TAlk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper proposes a novel approach to an automatic estimation of three\nspeaker traits from Arabic speech: gender, emotion, and dialect. After showing\npromising results on different text classification tasks, the multi-task\nlearning (MTL) approach is used in this paper for Arabic speech classification\ntasks. The dataset was assembled from six publicly available datasets. First,\nThe datasets were edited and thoroughly divided into train, development, and\ntest sets (open to the public), and a benchmark was set for each task and\ndataset throughout the paper. Then, three different networks were explored:\nLong Short Term Memory (LSTM), Convolutional Neural Network (CNN), and\nFully-Connected Neural Network (FCNN) on five different types of features: two\nraw features (MFCC and MEL) and three pre-trained vectors (i-vectors,\nd-vectors, and x-vectors). LSTM and CNN networks were implemented using raw\nfeatures: MFCC and MEL, where FCNN was explored on the pre-trained vectors\nwhile varying the hyper-parameters of these networks to obtain the best results\nfor each dataset and task. MTL was evaluated against the single task learning\n(STL) approach for the three tasks and six datasets, in which the MTL and\npre-trained vectors almost constantly outperformed STL. All the data and\npre-trained models used in this paper are available and can be acquired by the\npublic.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 14:45:01 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Farhan", "Wael", ""], ["Za'ter", "Muhy Eddin", ""], ["Obaidah", "Qusai Abu", ""], ["Bataineh", "Hisham al", ""], ["Sober", "Zyad", ""], ["Al-Natsheh", "Hussein T.", ""]]}, {"id": "2012.07138", "submitter": "Hongming Zhang", "authors": "Hongming Zhang, Yintong Huo, Xinran Zhao, Yangqiu Song, Dan Roth", "title": "Learning Contextual Causality from Time-consecutive Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Causality knowledge is crucial for many artificial intelligence systems.\nConventional textual-based causality knowledge acquisition methods typically\nrequire laborious and expensive human annotations. As a result, their scale is\noften limited. Moreover, as no context is provided during the annotation, the\nresulting causality knowledge records (e.g., ConceptNet) typically do not take\nthe context into consideration. To explore a more scalable way of acquiring\ncausality knowledge, in this paper, we jump out of the textual domain and\ninvestigate the possibility of learning contextual causality from the visual\nsignal. Compared with pure text-based approaches, learning causality from the\nvisual signal has the following advantages: (1) Causality knowledge belongs to\nthe commonsense knowledge, which is rarely expressed in the text but rich in\nvideos; (2) Most events in the video are naturally time-ordered, which provides\na rich resource for us to mine causality knowledge from; (3) All the objects in\nthe video can be used as context to study the contextual property of causal\nrelations. In detail, we first propose a high-quality dataset Vis-Causal and\nthen conduct experiments to demonstrate that with good language and visual\nrepresentation models as well as enough training signals, it is possible to\nautomatically discover meaningful causal knowledge from the videos. Further\nanalysis also shows that the contextual property of causal relations indeed\nexists, taking which into consideration might be crucial if we want to use the\ncausality knowledge in real applications, and the visual signal could serve as\na good resource for learning such contextual causality.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 20:24:48 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Zhang", "Hongming", ""], ["Huo", "Yintong", ""], ["Zhao", "Xinran", ""], ["Song", "Yangqiu", ""], ["Roth", "Dan", ""]]}, {"id": "2012.07162", "submitter": "Chi Chen", "authors": "Chi Chen, Maosong Sun, and Yang Liu", "title": "Mask-Align: Self-Supervised Neural Word Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word alignment, which aims to align translationally equivalent words between\nsource and target sentences, plays an important role in many natural language\nprocessing tasks. Current unsupervised neural alignment methods focus on\ninducing alignments from neural machine translation models, which does not\nleverage the full context in the target sequence. In this paper, we propose\nMask-Align, a self-supervised word alignment model that takes advantage of the\nfull context on the target side. Our model masks out each target token and\npredicts it conditioned on both source and the remaining target tokens. This\ntwo-step process is based on the assumption that the source token contributing\nmost to recovering the masked target token should be aligned. We also introduce\nan attention variant called leaky attention, which alleviates the problem of\nunexpected high cross-attention weights on special tokens such as periods.\nExperiments on four language pairs show that our model outperforms previous\nunsupervised neural aligners and obtains new state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 21:44:29 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 06:14:58 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Chen", "Chi", ""], ["Sun", "Maosong", ""], ["Liu", "Yang", ""]]}, {"id": "2012.07280", "submitter": "Seanie Lee", "authors": "Seanie Lee, Dong Bok Lee, Sung Ju Hwang", "title": "Contrastive Learning with Adversarial Perturbations for Conditional Text\n  Generation", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, sequence-to-sequence (seq2seq) models with the Transformer\narchitecture have achieved remarkable performance on various conditional text\ngeneration tasks, such as machine translation. However, most of them are\ntrained with teacher forcing with the ground truth label given at each time\nstep, without being exposed to incorrectly generated tokens during training,\nwhich hurts its generalization to unseen inputs, that is known as the \"exposure\nbias\" problem. In this work, we propose to mitigate the conditional text\ngeneration problem by contrasting positive pairs with negative pairs, such that\nthe model is exposed to various valid or incorrect perturbations of the inputs,\nfor improved generalization. However, training the model with naive contrastive\nlearning framework using random non-target sequences as negative examples is\nsuboptimal, since they are easily distinguishable from the correct output,\nespecially so with models pretrained with large text corpora. Also, generating\npositive examples requires domain-specific augmentation heuristics which may\nnot generalize over diverse domains. To tackle this problem, we propose a\nprincipled method to generate positive and negative samples for contrastive\nlearning of seq2seq models. Specifically, we generate negative examples by\nadding small perturbations to the input sequence to minimize its conditional\nlikelihood, and positive examples by adding large perturbations while enforcing\nit to have a high conditional likelihood. Such \"hard\" positive and negative\npairs generated using our method guides the model to better distinguish correct\noutputs from incorrect ones. We empirically show that our proposed method\nsignificantly improves the generalization of the seq2seq on three text\ngeneration tasks - machine translation, text summarization, and question\ngeneration.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 06:20:27 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2021 05:40:46 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 05:19:38 GMT"}, {"version": "v4", "created": "Mon, 22 Feb 2021 07:26:48 GMT"}, {"version": "v5", "created": "Wed, 3 Mar 2021 08:44:34 GMT"}, {"version": "v6", "created": "Wed, 10 Mar 2021 13:27:34 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Lee", "Seanie", ""], ["Lee", "Dong Bok", ""], ["Hwang", "Sung Ju", ""]]}, {"id": "2012.07300", "submitter": "Yicheng Zou", "authors": "Yicheng Zou, Jun Lin, Lujun Zhao, Yangyang Kang, Zhuoren Jiang,\n  Changlong Sun, Qi Zhang, Xuanjing Huang, Xiaozhong Liu", "title": "Unsupervised Summarization for Chat Logs with Topic-Oriented Ranking and\n  Context-Aware Auto-Encoders", "comments": "Accepted by AAAI 2021, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic chat summarization can help people quickly grasp important\ninformation from numerous chat messages. Unlike conventional documents, chat\nlogs usually have fragmented and evolving topics. In addition, these logs\ncontain a quantity of elliptical and interrogative sentences, which make the\nchat summarization highly context dependent. In this work, we propose a novel\nunsupervised framework called RankAE to perform chat summarization without\nemploying manually labeled data. RankAE consists of a topic-oriented ranking\nstrategy that selects topic utterances according to centrality and diversity\nsimultaneously, as well as a denoising auto-encoder that is carefully designed\nto generate succinct but context-informative summaries based on the selected\nutterances. To evaluate the proposed method, we collect a large-scale dataset\nof chat logs from a customer service environment and build an annotated set\nonly for model evaluation. Experimental results show that RankAE significantly\noutperforms other unsupervised methods and is able to generate high-quality\nsummaries in terms of relevance and topic coverage.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 07:31:17 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 07:39:46 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Zou", "Yicheng", ""], ["Lin", "Jun", ""], ["Zhao", "Lujun", ""], ["Kang", "Yangyang", ""], ["Jiang", "Zhuoren", ""], ["Sun", "Changlong", ""], ["Zhang", "Qi", ""], ["Huang", "Xuanjing", ""], ["Liu", "Xiaozhong", ""]]}, {"id": "2012.07311", "submitter": "Yicheng Zou", "authors": "Yicheng Zou, Lujun Zhao, Yangyang Kang, Jun Lin, Minlong Peng, Zhuoren\n  Jiang, Changlong Sun, Qi Zhang, Xuanjing Huang, Xiaozhong Liu", "title": "Topic-Oriented Spoken Dialogue Summarization for Customer Service with\n  Saliency-Aware Topic Modeling", "comments": "Accepted by AAAI 2021, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a customer service system, dialogue summarization can boost service\nefficiency by automatically creating summaries for long spoken dialogues in\nwhich customers and agents try to address issues about specific topics. In this\nwork, we focus on topic-oriented dialogue summarization, which generates highly\nabstractive summaries that preserve the main ideas from dialogues. In spoken\ndialogues, abundant dialogue noise and common semantics could obscure the\nunderlying informative content, making the general topic modeling approaches\ndifficult to apply. In addition, for customer service, role-specific\ninformation matters and is an indispensable part of a summary. To effectively\nperform topic modeling on dialogues and capture multi-role information, in this\nwork we propose a novel topic-augmented two-stage dialogue summarizer (TDS)\njointly with a saliency-aware neural topic model (SATM) for topic-oriented\nsummarization of customer service dialogues. Comprehensive studies on a\nreal-world Chinese customer service dataset demonstrated the superiority of our\nmethod against several strong baselines.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 07:50:25 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 07:34:17 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Zou", "Yicheng", ""], ["Zhao", "Lujun", ""], ["Kang", "Yangyang", ""], ["Lin", "Jun", ""], ["Peng", "Minlong", ""], ["Jiang", "Zhuoren", ""], ["Sun", "Changlong", ""], ["Zhang", "Qi", ""], ["Huang", "Xuanjing", ""], ["Liu", "Xiaozhong", ""]]}, {"id": "2012.07331", "submitter": "Yuma Koizumi", "authors": "Yuma Koizumi, Yasunori Ohishi, Daisuke Niizumi, Daiki Takeuchi,\n  Masahiro Yasuda", "title": "Audio Captioning using Pre-Trained Large-Scale Language Model Guided by\n  Audio-based Similar Caption Retrieval", "comments": "Submitted to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The goal of audio captioning is to translate input audio into its description\nusing natural language. One of the problems in audio captioning is the lack of\ntraining data due to the difficulty in collecting audio-caption pairs by\ncrawling the web. In this study, to overcome this problem, we propose to use a\npre-trained large-scale language model. Since an audio input cannot be directly\ninputted into such a language model, we utilize guidance captions retrieved\nfrom a training dataset based on similarities that may exist in different\naudio. Then, the caption of the audio input is generated by using a pre-trained\nlanguage model while referring to the guidance captions. Experimental results\nshow that (i) the proposed method has succeeded to use a pre-trained language\nmodel for audio captioning, and (ii) the oracle performance of the pre-trained\nmodel-based caption generator was clearly better than that of the conventional\nmethod trained from scratch.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 08:27:36 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Koizumi", "Yuma", ""], ["Ohishi", "Yasunori", ""], ["Niizumi", "Daisuke", ""], ["Takeuchi", "Daiki", ""], ["Yasuda", "Masahiro", ""]]}, {"id": "2012.07335", "submitter": "Hao Fu", "authors": "Hao Fu, Shaojun Zhou, Qihong Yang, Junjie Tang, Guiquan Liu, Kaikui\n  Liu, Xiaolong Li", "title": "LRC-BERT: Latent-representation Contrastive Knowledge Distillation for\n  Natural Language Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pre-training models such as BERT have achieved great results in various\nnatural language processing problems. However, a large number of parameters\nneed significant amounts of memory and the consumption of inference time, which\nmakes it difficult to deploy them on edge devices. In this work, we propose a\nknowledge distillation method LRC-BERT based on contrastive learning to fit the\noutput of the intermediate layer from the angular distance aspect, which is not\nconsidered by the existing distillation methods. Furthermore, we introduce a\ngradient perturbation-based training architecture in the training phase to\nincrease the robustness of LRC-BERT, which is the first attempt in knowledge\ndistillation. Additionally, in order to better capture the distribution\ncharacteristics of the intermediate layer, we design a two-stage training\nmethod for the total distillation loss. Finally, by verifying 8 datasets on the\nGeneral Language Understanding Evaluation (GLUE) benchmark, the performance of\nthe proposed LRC-BERT exceeds the existing state-of-the-art methods, which\nproves the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 08:39:38 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Fu", "Hao", ""], ["Zhou", "Shaojun", ""], ["Yang", "Qihong", ""], ["Tang", "Junjie", ""], ["Liu", "Guiquan", ""], ["Liu", "Kaikui", ""], ["Li", "Xiaolong", ""]]}, {"id": "2012.07347", "submitter": "Maxim Vashkevich", "authors": "Maxim Vashkevich and Yulia Rushkevich", "title": "Classification of ALS patients based on acoustic analysis of sustained\n  vowel phonations", "comments": null, "journal-ref": "Biomedical Signal Processing and Control, Volume 65, March 2021,\n  102350", "doi": "10.1016/j.bspc.2020.102350", "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Amyotrophic lateral sclerosis (ALS) is incurable neurological disorder with\nrapidly progressive course. Common early symptoms of ALS are difficulty in\nswallowing and speech. However, early acoustic manifestation of speech and\nvoice symptoms is very variable, that making their detection very challenging,\nboth by human specialists and automatic systems. This study presents an\napproach to voice assessment for automatic system that separates healthy people\nfrom patients with ALS. In particular, this work focus on analysing of sustain\nphonation of vowels /a/ and /i/ to perform automatic classification of ALS\npatients. A wide range of acoustic features such as MFCC, formants, jitter,\nshimmer, vibrato, PPE, GNE, HNR, etc. were analysed. We also proposed a new set\nof acoustic features for characterizing harmonic structure of the vowels.\nCalculation of these features is based on pitch synchronized voice analysis. A\nlinear discriminant analysis (LDA) was used to classify the phonation produced\nby patients with ALS and those by healthy individuals. Several algorithms of\nfeature selection were tested to find optimal feature subset for LDA model. The\nstudy's experiments show that the most successful LDA model based on 32\nfeatures picked out by LASSO feature selection algorithm attains 99.7% accuracy\nwith 99.3% sensitivity and 99.9% specificity. Among the classifiers with a\nsmall number of features, we can highlight LDA model with 5 features, which has\n89.0% accuracy (87.5% sensitivity and 90.4% specificity).\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 08:56:53 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 08:41:07 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Vashkevich", "Maxim", ""], ["Rushkevich", "Yulia", ""]]}, {"id": "2012.07379", "submitter": "Tianyang Cao", "authors": "Tianyang Cao, Shuang Zeng, Songge Zhao, Mairgup Mansur, Baobao Chang", "title": "Generating Math Word Problems from Equations with Topic Controlling and\n  Commonsense Enforcement", "comments": "long paper accepted by ICANN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent years have seen significant advancement in text generation tasks with\nthe help of neural language models. However, there exists a challenging task:\ngenerating math problem text based on mathematical equations, which has made\nlittle progress so far. In this paper, we present a novel equation-to-problem\ntext generation model. In our model, 1) we propose a flexible scheme to\neffectively encode math equations, we then enhance the equation encoder by a\nVaritional Autoen-coder (VAE) 2) given a math equation, we perform topic\nselection, followed by which a dynamic topic memory mechanism is introduced to\nrestrict the topic distribution of the generator 3) to avoid commonsense\nviolation in traditional generation model, we pretrain word embedding with\nbackground knowledge graph (KG), and we link decoded words to related words in\nKG, targeted at injecting background knowledge into our model. We evaluate our\nmodel through both automatic metrices and human evaluation, experiments\ndemonstrate our model outperforms baseline and previous models in both accuracy\nand richness of generated problem text.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 10:02:11 GMT"}, {"version": "v2", "created": "Sun, 25 Jul 2021 10:49:30 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Cao", "Tianyang", ""], ["Zeng", "Shuang", ""], ["Zhao", "Songge", ""], ["Mansur", "Mairgup", ""], ["Chang", "Baobao", ""]]}, {"id": "2012.07387", "submitter": "Herman Kamper", "authors": "Lisa van Staden, Herman Kamper", "title": "A comparison of self-supervised speech representations as input features\n  for unsupervised acoustic word embeddings", "comments": "Accepted to SLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many speech processing tasks involve measuring the acoustic similarity\nbetween speech segments. Acoustic word embeddings (AWE) allow for efficient\ncomparisons by mapping speech segments of arbitrary duration to\nfixed-dimensional vectors. For zero-resource speech processing, where\nunlabelled speech is the only available resource, some of the best AWE\napproaches rely on weak top-down constraints in the form of automatically\ndiscovered word-like segments. Rather than learning embeddings at the segment\nlevel, another line of zero-resource research has looked at representation\nlearning at the short-time frame level. Recent approaches include\nself-supervised predictive coding and correspondence autoencoder (CAE) models.\nIn this paper we consider whether these frame-level features are beneficial\nwhen used as inputs for training to an unsupervised AWE model. We compare\nframe-level features from contrastive predictive coding (CPC), autoregressive\npredictive coding and a CAE to conventional MFCCs. These are used as inputs to\na recurrent CAE-based AWE model. In a word discrimination task on English and\nXitsonga data, all three representation learning approaches outperform MFCCs,\nwith CPC consistently showing the biggest improvement. In cross-lingual\nexperiments we find that CPC features trained on English can also be\ntransferred to Xitsonga.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 10:17:25 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["van Staden", "Lisa", ""], ["Kamper", "Herman", ""]]}, {"id": "2012.07396", "submitter": "Herman Kamper", "authors": "Kayode Olaleye, Benjamin van Niekerk, Herman Kamper", "title": "Towards localisation of keywords in speech using weak supervision", "comments": "Accepted to NeurIPS-SAS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developments in weakly supervised and self-supervised models could enable\nspeech technology in low-resource settings where full transcriptions are not\navailable. We consider whether keyword localisation is possible using two forms\nof weak supervision where location information is not provided explicitly. In\nthe first, only the presence or absence of a word is indicated, i.e. a\nbag-of-words (BoW) labelling. In the second, visual context is provided in the\nform of an image paired with an unlabelled utterance; a model then needs to be\ntrained in a self-supervised fashion using the paired data. For keyword\nlocalisation, we adapt a saliency-based method typically used in the vision\ndomain. We compare this to an existing technique that performs localisation as\na part of the network architecture. While the saliency-based method is more\nflexible (it can be applied without architectural restrictions), we identify a\ncritical limitation when using it for keyword localisation. Of the two forms of\nsupervision, the visually trained model performs worse than the BoW-trained\nmodel. We show qualitatively that the visually trained model sometimes locate\nsemantically related words, but this is not consistent. While our results show\nthat there is some signal allowing for localisation, it also calls for other\nlocalisation methods better matched to these forms of weak supervision.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 10:30:51 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Olaleye", "Kayode", ""], ["van Niekerk", "Benjamin", ""], ["Kamper", "Herman", ""]]}, {"id": "2012.07410", "submitter": "Xiuying Chen", "authors": "Xiuying Chen, Zhi Cui, Jiayi Zhang, Chen Wei, Jianwei Cui, Bin Wang,\n  Dongyan Zhao, Rui Yan", "title": "Reasoning in Dialog: Improving Response Generation by Context Reading\n  Comprehension", "comments": "9 pages, 1 figure", "journal-ref": "AAAI 2021", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In multi-turn dialog, utterances do not always take the full form of\nsentences \\cite{Carbonell1983DiscoursePA}, which naturally makes understanding\nthe dialog context more difficult. However, it is essential to fully grasp the\ndialog context to generate a reasonable response. Hence, in this paper, we\npropose to improve the response generation performance by examining the model's\nability to answer a reading comprehension question, where the question is\nfocused on the omitted information in the dialog. Enlightened by the multi-task\nlearning scheme, we propose a joint framework that unifies these two tasks,\nsharing the same encoder to extract the common and task-invariant features with\ndifferent decoders to learn task-specific features. To better fusing\ninformation from the question and the dialog history in the encoding part, we\npropose to augment the Transformer architecture with a memory updater, which is\ndesigned to selectively store and update the history dialog information so as\nto support downstream tasks. For the experiment, we employ human annotators to\nwrite and examine a large-scale dialog reading comprehension dataset. Extensive\nexperiments are conducted on this dataset, and the results show that the\nproposed model brings substantial improvements over several strong baselines on\nboth tasks. In this way, we demonstrate that reasoning can indeed help better\nresponse generation and vice versa. We release our large-scale dataset for\nfurther research.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 10:58:01 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Chen", "Xiuying", ""], ["Cui", "Zhi", ""], ["Zhang", "Jiayi", ""], ["Wei", "Chen", ""], ["Cui", "Jianwei", ""], ["Wang", "Bin", ""], ["Zhao", "Dongyan", ""], ["Yan", "Rui", ""]]}, {"id": "2012.07412", "submitter": "Zhijing Jin", "authors": "Qipeng Guo, Zhijing Jin, Ziyu Wang, Xipeng Qiu, Weinan Zhang, Jun Zhu,\n  Zheng Zhang, David Wipf", "title": "Fork or Fail: Cycle-Consistent Training with Many-to-One Mappings", "comments": "A condensed version is accepted to AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cycle-consistent training is widely used for jointly learning a forward and\ninverse mapping between two domains of interest without the cumbersome\nrequirement of collecting matched pairs within each domain. In this regard, the\nimplicit assumption is that there exists (at least approximately) a\nground-truth bijection such that a given input from either domain can be\naccurately reconstructed from successive application of the respective\nmappings. But in many applications no such bijection can be expected to exist\nand large reconstruction errors can compromise the success of cycle-consistent\ntraining. As one important instance of this limitation, we consider\npractically-relevant situations where there exists a many-to-one or surjective\nmapping between domains. To address this regime, we develop a conditional\nvariational autoencoder (CVAE) approach that can be viewed as converting\nsurjective mappings to implicit bijections whereby reconstruction errors in\nboth directions can be minimized, and as a natural byproduct, realistic output\ndiversity can be obtained in the one-to-many direction. As theoretical\nmotivation, we analyze a simplified scenario whereby minima of the proposed\nCVAE-based energy function align with the recovery of ground-truth surjective\nmappings. On the empirical side, we consider a synthetic image dataset with\nknown ground-truth, as well as a real-world application involving natural\nlanguage generation from knowledge graphs and vice versa, a prototypical\nsurjective case. For the latter, our CVAE pipeline can capture such many-to-one\nmappings during cycle training while promoting textural diversity for\ngraph-to-text tasks. Our code is available at github.com/QipengGuo/CycleGT\n  *A condensed version of this paper has been accepted to AISTATS 2021. This\nversion contains additional content and updates.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 10:59:59 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 17:37:06 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2021 11:18:37 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Guo", "Qipeng", ""], ["Jin", "Zhijing", ""], ["Wang", "Ziyu", ""], ["Qiu", "Xipeng", ""], ["Zhang", "Weinan", ""], ["Zhu", "Jun", ""], ["Zhang", "Zheng", ""], ["Wipf", "David", ""]]}, {"id": "2012.07419", "submitter": "Mingzhe Li", "authors": "Mingzhe Li, Xiuying Chen, Min Yang, Shen Gao, Dongyan Zhao and Rui Yan", "title": "The Style-Content Duality of Attractiveness: Learning to Write\n  Eye-Catching Headlines via Disentanglement", "comments": "Accepted by AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eye-catching headlines function as the first device to trigger more clicks,\nbringing reciprocal effect between producers and viewers. Producers can obtain\nmore traffic and profits, and readers can have access to outstanding articles.\nWhen generating attractive headlines, it is important to not only capture the\nattractive content but also follow an eye-catching written style. In this\npaper, we propose a Disentanglement-based Attractive Headline Generator (DAHG)\nthat generates headline which captures the attractive content following the\nattractive style. Concretely, we first devise a disentanglement module to\ndivide the style and content of an attractive prototype headline into latent\nspaces, with two auxiliary constraints to ensure the two spaces are indeed\ndisentangled. The latent content information is then used to further polish the\ndocument representation and help capture the salient part. Finally, the\ngenerator takes the polished document as input to generate headline under the\nguidance of the attractive style. Extensive experiments on the public Kuaibao\ndataset show that DAHG achieves state-of-the-art performance. Human evaluation\nalso demonstrates that DAHG triggers 22% more clicks than existing models.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 11:11:43 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Li", "Mingzhe", ""], ["Chen", "Xiuying", ""], ["Yang", "Min", ""], ["Gao", "Shen", ""], ["Zhao", "Dongyan", ""], ["Yan", "Rui", ""]]}, {"id": "2012.07463", "submitter": "Demi Guo", "authors": "Demi Guo, Alexander M. Rush, Yoon Kim", "title": "Parameter-Efficient Transfer Learning with Diff Pruning", "comments": "ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While task-specific finetuning of pretrained networks has led to significant\nempirical advances in NLP, the large size of networks makes finetuning\ndifficult to deploy in multi-task, memory-constrained settings. We propose diff\npruning as a simple approach to enable parameter-efficient transfer learning\nwithin the pretrain-finetune framework. This approach views finetuning as\nlearning a task-specific diff vector that is applied on top of the pretrained\nparameter vector, which remains fixed and is shared across different tasks. The\ndiff vector is adaptively pruned during training with a differentiable\napproximation to the L0-norm penalty to encourage sparsity. Diff pruning\nbecomes parameter-efficient as the number of tasks increases, as it requires\nstoring only the nonzero positions and weights of the diff vector for each\ntask, while the cost of storing the shared pretrained model remains constant.\nIt further does not require access to all tasks during training, which makes it\nattractive in settings where tasks arrive in stream or the set of tasks is\nunknown. We find that models finetuned with diff pruning can match the\nperformance of fully finetuned baselines on the GLUE benchmark while only\nmodifying 0.5% of the pretrained model's parameters per task.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 12:34:01 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 14:39:17 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Guo", "Demi", ""], ["Rush", "Alexander M.", ""], ["Kim", "Yoon", ""]]}, {"id": "2012.07490", "submitter": "Hugo J. Bello", "authors": "Hugo J. Bello, Nora Palomar, Elisa Gallego, Lourdes Jim\\'enez\n  Navascu\\'es and Celia Lozano", "title": "Machine Learning to study the impact of gender-based violence in the\n  news media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While it remains a taboo topic, gender-based violence (GBV) undermines the\nhealth, dignity, security and autonomy of its victims. Many factors have been\nstudied to generate or maintain this kind of violence, however, the influence\nof the media is still uncertain. Here, we use Machine Learning tools to\nextrapolate the effect of the news in GBV. By feeding neural networks with\nnews, the topic information associated with each article can be recovered. Our\nfindings show a relationship between GBV news and public awareness, the effect\nof mediatic GBV cases, and the intrinsic thematic relationship of GBV news.\nBecause the used neural model can be easily adjusted, this also allows us to\nextend our approach to other media sources or topics\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 08:42:33 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Bello", "Hugo J.", ""], ["Palomar", "Nora", ""], ["Gallego", "Elisa", ""], ["Navascu\u00e9s", "Lourdes Jim\u00e9nez", ""], ["Lozano", "Celia", ""]]}, {"id": "2012.07499", "submitter": "Petar Milin", "authors": "Petar Milin, Benjamin V. Tucker, and Dagmar Divjak", "title": "A learning perspective on the emergence of abstractions: the curious\n  case of phonemes", "comments": "45 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper we use a range of modeling techniques to investigate\nwhether an abstract phone could emerge from exposure to speech sounds. We test\ntwo opposing principles regarding the development of language knowledge in\nlinguistically untrained language users: Memory-Based Learning (MBL) and\nError-Correction Learning (ECL). A process of generalization underlies the\nabstractions linguists operate with, and we probed whether MBL and ECL could\ngive rise to a type of language knowledge that resembles linguistic\nabstractions. Each model was presented with a significant amount of\npre-processed speech produced by one speaker. We assessed the consistency or\nstability of what the models have learned and their ability to give rise to\nabstract categories. Both types of models fare differently with regard to these\ntests. We show that ECL learning models can learn abstractions and that at\nleast part of the phone inventory can be reliably identified from the input.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 13:33:34 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 15:08:48 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2020 14:06:59 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Milin", "Petar", ""], ["Tucker", "Benjamin V.", ""], ["Divjak", "Dagmar", ""]]}, {"id": "2012.07510", "submitter": "AmirHossein Taghavi Khoonsari", "authors": "H. Jafarian, A. H. Taghavi, A. Javaheri and R. Rawassizadeh", "title": "Exploiting BERT to improve aspect-based sentiment analysis performance\n  on Persian language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Aspect-based sentiment analysis (ABSA) is a more detailed task in sentiment\nanalysis, by identifying opinion polarity toward a certain aspect in a text.\nThis method is attracting more attention from the community, due to the fact\nthat it provides more thorough and useful information. However, there are few\nlanguage-specific researches on Persian language. The present research aims to\nimprove the ABSA on the Persian Pars-ABSA dataset. This research shows the\npotential of using pre-trained BERT model and taking advantage of using\nsentence-pair input on an ABSA task. The results indicate that employing\nPars-BERT pre-trained model along with natural language inference auxiliary\nsentence (NLI-M) could boost the ABSA task accuracy up to 91% which is 5.5%\n(absolute) higher than state-of-the-art studies on Pars-ABSA dataset.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 16:47:20 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Jafarian", "H.", ""], ["Taghavi", "A. H.", ""], ["Javaheri", "A.", ""], ["Rawassizadeh", "R.", ""]]}, {"id": "2012.07512", "submitter": "Shreekanth Prabhu", "authors": "Priya S. Nayak, Rhythm Girdhar, Shreekanth M. Prabhu", "title": "Linguistic Classification using Instance-Based Learning", "comments": "8 pages,3 papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Traditionally linguists have organized languages of the world as language\nfamilies modelled as trees. In this work we take a contrarian approach and\nquestion the tree-based model that is rather restrictive. For example, the\naffinity that Sanskrit independently has with languages across Indo-European\nlanguages is better illustrated using a network model. We can say the same\nabout inter-relationship between languages in India, where the\ninter-relationships are better discovered than assumed. To enable such a\ndiscovery, in this paper we have made use of instance-based learning techniques\nto assign language labels to words. We vocalize each word and then classify it\nby making use of our custom linguistic distance metric of the word relative to\ntraining sets containing language labels. We construct the training sets by\nmaking use of word clusters and assigning a language and category label to that\ncluster. Further, we make use of clustering coefficients as a quality metric\nfor our research. We believe our work has the potential to usher in a new era\nin linguistics. We have limited this work for important languages in India.\nThis work can be further strengthened by applying Adaboost for classification\ncoupled with structural equivalence concepts of social network analysis.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 04:12:10 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Nayak", "Priya S.", ""], ["Girdhar", "Rhythm", ""], ["Prabhu", "Shreekanth M.", ""]]}, {"id": "2012.07515", "submitter": "Uwe Aickelin", "authors": "J Liu, R Bai, Z Lu, P Ge, D Liu, Uwe Aickelin", "title": "Data-Driven Regular Expressions Evolution for Medical Text\n  Classification Using Genetic Programming", "comments": "2020 IEEE Congress on Evolutionary Computation (CEC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In medical fields, text classification is one of the most important tasks\nthat can significantly reduce human workload through structured information\ndigitization and intelligent decision support. Despite the popularity of\nlearning-based text classification techniques, it is hard for human to\nunderstand or manually fine-tune the classification results for better\nprecision and recall, due to the black box nature of learning. This study\nproposes a novel regular expression-based text classification method making use\nof genetic programming (GP) approaches to evolve regular expressions that can\nclassify a given medical text inquiry with satisfactory precision and recall\nwhile allow human to read the classifier and fine-tune accordingly if\nnecessary. Given a seed population of regular expressions (can be randomly\ninitialized or manually constructed by experts), our method evolves a\npopulation of regular expressions according to chosen fitness function, using a\nnovel regular expression syntax and a series of carefully chosen reproduction\noperators. Our method is evaluated with real-life medical text inquiries from\nan online healthcare provider and shows promising performance. More\nimportantly, our method generates classifiers that can be fully understood,\nchecked and updated by medical doctors, which are fundamentally crucial for\nmedical related practices.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 03:44:46 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Liu", "J", ""], ["Bai", "R", ""], ["Lu", "Z", ""], ["Ge", "P", ""], ["Liu", "D", ""], ["Aickelin", "Uwe", ""]]}, {"id": "2012.07516", "submitter": "Shang-Wen Li", "authors": "Shang-Wen Li, Jason Krone, Shuyan Dong, Yi Zhang, and Yaser Al-onaizan", "title": "Meta learning to classify intent and slot labels with noisy few shot\n  examples", "comments": "accepted by IEEE Spoken Language Technology Workshop, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently deep learning has dominated many machine learning areas, including\nspoken language understanding (SLU). However, deep learning models are\nnotorious for being data-hungry, and the heavily optimized models are usually\nsensitive to the quality of the training examples provided and the consistency\nbetween training and inference conditions. To improve the performance of SLU\nmodels on tasks with noisy and low training resources, we propose a new SLU\nbenchmarking task: few-shot robust SLU, where SLU comprises two core problems,\nintent classification (IC) and slot labeling (SL). We establish the task by\ndefining few-shot splits on three public IC/SL datasets, ATIS, SNIPS, and TOP,\nand adding two types of natural noises (adaptation example missing/replacing\nand modality mismatch) to the splits. We further propose a novel noise-robust\nfew-shot SLU model based on prototypical networks. We show the model\nconsistently outperforms the conventional fine-tuning baseline and another\npopular meta-learning method, Model-Agnostic Meta-Learning (MAML), in terms of\nachieving better IC accuracy and SL F1, and yielding smaller performance\nvariation when noises are present.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 18:53:30 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Li", "Shang-Wen", ""], ["Krone", "Jason", ""], ["Dong", "Shuyan", ""], ["Zhang", "Yi", ""], ["Al-onaizan", "Yaser", ""]]}, {"id": "2012.07517", "submitter": "Kashif Ahmad", "authors": "Abdullah Hamid, Nasrullah Shiekh, Naina Said, Kashif Ahmad, Asma Gul,\n  Laiq Hassan, Ala Al-Fuqaha", "title": "Fake News Detection in Social Media using Graph Neural Networks and NLP\n  Techniques: A COVID-19 Use-case", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper presents our solutions for the MediaEval 2020 task namely FakeNews:\nCorona Virus and 5G Conspiracy Multimedia Twitter-Data-Based Analysis. The task\naims to analyze tweets related to COVID-19 and 5G conspiracy theories to detect\nmisinformation spreaders. The task is composed of two sub-tasks namely (i)\ntext-based, and (ii) structure-based fake news detection. For the first task,\nwe propose six different solutions relying on Bag of Words (BoW) and BERT\nembedding. Three of the methods aim at binary classification task by\ndifferentiating in 5G conspiracy and the rest of the COVID-19 related tweets\nwhile the rest of them treat the task as ternary classification problem. In the\nternary classification task, our BoW and BERT based methods obtained an\nF1-score of .606% and .566% on the development set, respectively. On the binary\nclassification, the BoW and BERT based solutions obtained an average F1-score\nof .666% and .693%, respectively. On the other hand, for structure-based fake\nnews detection, we rely on Graph Neural Networks (GNNs) achieving an average\nROC of .95% on the development set.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 16:41:04 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Hamid", "Abdullah", ""], ["Shiekh", "Nasrullah", ""], ["Said", "Naina", ""], ["Ahmad", "Kashif", ""], ["Gul", "Asma", ""], ["Hassan", "Laiq", ""], ["Al-Fuqaha", "Ala", ""]]}, {"id": "2012.07521", "submitter": "Nenad Savic", "authors": "Nenad Savic, Nicolas Bovio, Fabian Gilbert and Irina Guseva Canu", "title": "Procode: the Swiss Multilingual Solution for Automatic Coding and\n  Recoding of Occupations and Economic Activities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Objective. Epidemiological studies require data that are in alignment with\nthe classifications established for occupations or economic activities. The\nclassifications usually include hundreds of codes and titles. Manual coding of\nraw data may result in misclassification and be time consuming. The goal was to\ndevelop and test a web-tool, named Procode, for coding of free-texts against\nclassifications and recoding between different classifications. Methods. Three\ntext classifiers, i.e. Complement Naive Bayes (CNB), Support Vector Machine\n(SVM) and Random Forest Classifier (RFC), were investigated using a k-fold\ncross-validation. 30 000 free-texts with manually assigned classification codes\nof French classification of occupations (PCS) and French classification of\nactivities (NAF) were available. For recoding, Procode integrated a workflow\nthat converts codes of one classification to another according to existing\ncrosswalks. Since this is a straightforward operation, only the recoding time\nwas measured. Results. Among the three investigated text classifiers, CNB\nresulted in the best performance, where the classifier predicted accurately\n57-81% and 63-83% classification codes for PCS and NAF, respectively. SVM lead\nto somewhat lower results (by 1-2%), while RFC coded accurately up to 30% of\nthe data. The coding operation required one minute per 10 000 records, while\nthe recoding was faster, i.e. 5-10 seconds. Conclusion. The algorithm\nintegrated in Procode showed satisfactory performance, since the tool had to\nassign the right code by choosing between 500-700 different choices. Based on\nthe results, the authors decided to implement CNB in Procode. In future, if\nanother classifier shows a superior performance, an update will include the\nrequired modifications.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 07:46:21 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Savic", "Nenad", ""], ["Bovio", "Nicolas", ""], ["Gilbert", "Fabian", ""], ["Canu", "Irina Guseva", ""]]}, {"id": "2012.07527", "submitter": "Amir Najafi", "authors": "Armin Karamzade, Amir Najafi and Seyed Abolfazl Motahari", "title": "Regularizing Recurrent Neural Networks via Sequence Mixup", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we extend a class of celebrated regularization techniques\noriginally proposed for feed-forward neural networks, namely Input Mixup (Zhang\net al., 2017) and Manifold Mixup (Verma et al., 2018), to the realm of\nRecurrent Neural Networks (RNN). Our proposed methods are easy to implement and\nhave a low computational complexity, while leverage the performance of simple\nneural architectures in a variety of tasks. We have validated our claims\nthrough several experiments on real-world datasets, and also provide an\nasymptotic theoretical analysis to further investigate the properties and\npotential impacts of our proposed techniques. Applying sequence mixup to\nBiLSTM-CRF model (Huang et al., 2015) to Named Entity Recognition task on\nCoNLL-2003 data (Sang and De Meulder, 2003) has improved the F-1 score on the\ntest stage and reduced the loss, considerably.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 05:43:40 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Karamzade", "Armin", ""], ["Najafi", "Amir", ""], ["Motahari", "Seyed Abolfazl", ""]]}, {"id": "2012.07528", "submitter": "Souheil Fenghour Fenghour", "authors": "Souheil Fenghour, Daqing Chen, Kun Guo, Perry Xiao", "title": "Disentangling Homophemes in Lip Reading using Perplexity Analysis", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The performance of automated lip reading using visemes as a classification\nschema has achieved less success compared with the use of ASCII characters and\nwords largely due to the problem of different words sharing identical visemes.\nThe Generative Pre-Training transformer is an effective autoregressive language\nmodel used for many tasks in Natural Language Processing, including sentence\nprediction and text classification.\n  This paper proposes a new application for this model and applies it in the\ncontext of lip reading, where it serves as a language model to convert visual\nspeech in the form of visemes, to language in the form of words and sentences.\nThe network uses the search for optimal perplexity to perform the\nviseme-to-word mapping and is thus a solution to the one-to-many mapping\nproblem that exists whereby various words that sound different when spoken look\nidentical. This paper proposes a method to tackle the one-to-many mapping\nproblem when performing automated lip reading using solely visual cues in two\nseparate scenarios: the first scenario is where the word boundary, that is, the\nbeginning and the ending of a word, is unknown; and the second scenario is\nwhere the boundary is known.\n  Sentences from the benchmark BBC dataset \"Lip Reading Sentences in the\nWild\"(LRS2), are classified with a character error rate of 10.7% and a word\nerror rate of 18.0%. The main contribution of this paper is to propose a method\nof predicting words through the use of perplexity analysis when only visual\ncues are present, using an autoregressive language model.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 12:12:17 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Fenghour", "Souheil", ""], ["Chen", "Daqing", ""], ["Guo", "Kun", ""], ["Xiao", "Perry", ""]]}, {"id": "2012.07534", "submitter": "Safa Alsafari", "authors": "Safa Alsafari, Samira Sadaoui, Malek Mouhoub", "title": "Effect of Word Embedding Models on Hate and Offensive Speech Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks have been adopted successfully in hate speech detection\nproblems. Nevertheless, the effect of the word embedding models on the neural\nnetwork's performance has not been appropriately examined in the literature. In\nour study, through different detection tasks, 2-class, 3-class, and 6-class\nclassification, we investigate the impact of both word embedding models and\nneural network architectures on the predictive accuracy. Our focus is on the\nArabic language. We first train several word embedding models on a large-scale\nunlabelled Arabic text corpus. Next, based on a dataset of Arabic hate and\noffensive speech, for each detection task, we train several neural network\nclassifiers using the pre-trained word embedding models. This task yields a\nlarge number of various learned models, which allows conducting an exhaustive\ncomparison. The empirical analysis demonstrates, on the one hand, the\nsuperiority of the skip-gram models and, on the other hand, the superiority of\nthe CNN network across the three detection tasks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 02:43:45 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Alsafari", "Safa", ""], ["Sadaoui", "Samira", ""], ["Mouhoub", "Malek", ""]]}, {"id": "2012.07535", "submitter": "Yassir Fathullah", "authors": "Yassir Fathullah, Mark Gales, Andrey Malinin", "title": "Ensemble Distillation Approaches for Grammatical Error Correction", "comments": "Submitted to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ensemble approaches are commonly used techniques to improving a system by\ncombining multiple model predictions. Additionally these schemes allow the\nuncertainty, as well as the source of the uncertainty, to be derived for the\nprediction. Unfortunately these benefits come at a computational and memory\ncost. To address this problem ensemble distillation (EnD) and more recently\nensemble distribution distillation (EnDD) have been proposed that compress the\nensemble into a single model, representing either the ensemble average\nprediction or prediction distribution respectively. This paper examines the\napplication of both these distillation approaches to a sequence prediction\ntask, grammatical error correction (GEC). This is an important application area\nfor language learning tasks as it can yield highly useful feedback to the\nlearner. It is, however, more challenging than the standard tasks investigated\nfor distillation as the prediction of any grammatical correction to a word will\nbe highly dependent on both the input sequence and the generated output history\nfor the word. The performance of both EnD and EnDD are evaluated on both\npublicly available GEC tasks as well as a spoken language task.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 15:00:45 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 09:45:47 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Fathullah", "Yassir", ""], ["Gales", "Mark", ""], ["Malinin", "Andrey", ""]]}, {"id": "2012.07536", "submitter": "Pinelopi Papalampidi", "authors": "Pinelopi Papalampidi, Frank Keller, Mirella Lapata", "title": "Movie Summarization via Sparse Graph Construction", "comments": "Accepted at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We summarize full-length movies by creating shorter videos containing their\nmost informative scenes. We explore the hypothesis that a summary can be\ncreated by assembling scenes which are turning points (TPs), i.e., key events\nin a movie that describe its storyline. We propose a model that identifies TP\nscenes by building a sparse movie graph that represents relations between\nscenes and is constructed using multimodal information. According to human\njudges, the summaries created by our approach are more informative and\ncomplete, and receive higher ratings, than the outputs of sequence-based models\nand general-purpose summarization algorithms. The induced graphs are\ninterpretable, displaying different topology for different movie genres.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 13:54:34 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Papalampidi", "Pinelopi", ""], ["Keller", "Frank", ""], ["Lapata", "Mirella", ""]]}, {"id": "2012.07538", "submitter": "Md Saiful Islam", "authors": "Khondoker Ittehadul Islam, Md. Saiful Islam and Md Ruhul Amin", "title": "Sentiment analysis in Bengali via transfer learning using multi-lingual\n  BERT", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentiment analysis (SA) in Bengali is challenging due to this Indo-Aryan\nlanguage's highly inflected properties with more than 160 different inflected\nforms for verbs and 36 different forms for noun and 24 different forms for\npronouns. The lack of standard labeled datasets in the Bengali domain makes the\ntask of SA even harder. In this paper, we present manually tagged 2-class and\n3-class SA datasets in Bengali. We also demonstrate that the multi-lingual BERT\nmodel with relevant extensions can be trained via the approach of transfer\nlearning over those novel datasets to improve the state-of-the-art performance\nin sentiment classification tasks. This deep learning model achieves an\naccuracy of 71\\% for 2-class sentiment classification compared to the current\nstate-of-the-art accuracy of 68\\%. We also present the very first Bengali SA\nclassifier for the 3-class manually tagged dataset, and our proposed model\nachieves an accuracy of 60\\%. We further use this model to analyze the\nsentiment of public comments in the online daily newspaper. Our analysis shows\nthat people post negative comments for political or sports news more often,\nwhile the religious article comments represent positive sentiment. The dataset\nand code is publicly available at\nhttps://github.com/KhondokerIslam/Bengali\\_Sentiment.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 10:21:11 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Islam", "Khondoker Ittehadul", ""], ["Islam", "Md. Saiful", ""], ["Amin", "Md Ruhul", ""]]}, {"id": "2012.07551", "submitter": "Herman Kamper", "authors": "Herman Kamper, Benjamin van Niekerk", "title": "Towards unsupervised phone and word segmentation using self-supervised\n  vector-quantized neural networks", "comments": "Accepted to Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate segmenting and clustering speech into low-bitrate phone-like\nsequences without supervision. We specifically constrain pretrained\nself-supervised vector-quantized (VQ) neural networks so that blocks of\ncontiguous feature vectors are assigned to the same code, thereby giving a\nvariable-rate segmentation of the speech into discrete units. Two segmentation\nmethods are considered. In the first, features are greedily merged until a\nprespecified number of segments are reached. The second uses dynamic\nprogramming to optimize a squared error with a penalty term to encourage fewer\nbut longer segments. We show that these VQ segmentation methods can be used\nwithout alteration across a wide range of tasks: unsupervised phone\nsegmentation, ABX phone discrimination, same-different word discrimination, and\nas inputs to a symbolic word segmentation algorithm. The penalized dynamic\nprogramming method generally performs best. While performance on individual\ntasks is only comparable to the state-of-the-art in some cases, in all tasks a\nreasonable competing approach is outperformed at a substantially lower bitrate.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 14:17:33 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 12:12:43 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Kamper", "Herman", ""], ["van Niekerk", "Benjamin", ""]]}, {"id": "2012.07553", "submitter": "Xiang Cheng", "authors": "Xiang Cheng, Mitchell Bowden, Bhushan Ramesh Bhange, Priyanka Goyal,\n  Thomas Packer, Faizan Javed", "title": "An End-to-End Solution for Named Entity Recognition in eCommerce Search", "comments": "Accepted by AAAI IAAI-2021 Highly Innovative Applications of AI track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity recognition (NER) is a critical step in modern search query\nunderstanding. In the domain of eCommerce, identifying the key entities, such\nas brand and product type, can help a search engine retrieve relevant products\nand therefore offer an engaging shopping experience. Recent research shows\npromising results on shared benchmark NER tasks using deep learning methods,\nbut there are still unique challenges in the industry regarding domain\nknowledge, training data, and model production. This paper demonstrates an\nend-to-end solution to address these challenges. The core of our solution is a\nnovel model training framework \"TripleLearn\" which iteratively learns from\nthree separate training datasets, instead of one training set as is\ntraditionally done. Using this approach, the best model lifts the F1 score from\n69.5 to 93.3 on the holdout test data. In our offline experiments, TripleLearn\nimproved the model performance compared to traditional training approaches\nwhich use a single set of training data. Moreover, in the online A/B test, we\nsee significant improvements in user engagement and revenue conversion. The\nmodel has been live on homedepot.com for more than 9 months, boosting search\nconversions and revenue. Beyond our application, this TripleLearn framework, as\nwell as the end-to-end process, is model-independent and problem-independent,\nso it can be generalized to more industrial applications, especially to the\neCommerce industry which has similar data foundations and problems.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 04:58:13 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Cheng", "Xiang", ""], ["Bowden", "Mitchell", ""], ["Bhange", "Bhushan Ramesh", ""], ["Goyal", "Priyanka", ""], ["Packer", "Thomas", ""], ["Javed", "Faizan", ""]]}, {"id": "2012.07557", "submitter": "Long Phan", "authors": "Trung-Hieu Tran, Long Phan, Truong-Son Nguyen, Tien-Huy Nguyen", "title": "Leveraging Transfer Learning for Reliable Intelligence Identification on\n  Vietnamese SNSs (ReINTEL)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposed several transformer-based approaches for Reliable\nIntelligence Identification on Vietnamese social network sites at VLSP 2020\nevaluation campaign. We exploit both of monolingual and multilingual\npre-trained models. Besides, we utilize the ensemble method to improve the\nrobustness of different approaches. Our team achieved a score of 0.9378 at\nROC-AUC metric in the private test set which is competitive to other\nparticipants.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 15:43:50 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 15:10:07 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Tran", "Trung-Hieu", ""], ["Phan", "Long", ""], ["Nguyen", "Truong-Son", ""], ["Nguyen", "Tien-Huy", ""]]}, {"id": "2012.07563", "submitter": "Musarrat Husssain", "authors": "Musarrat Hussain, Fahad Ahmed Satti, Jamil Hussain, Taqdir Ali, Syed\n  Imran Ali, Hafiz Syed Muhammad Bilal, Gwang Hoon Park, Sungyoung Lee", "title": "A Practical Approach towards Causality Mining in Clinical Text using\n  Active Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Objective: Causality mining is an active research area, which requires the\napplication of state-of-the-art natural language processing techniques. In the\nhealthcare domain, medical experts create clinical text to overcome the\nlimitation of well-defined and schema driven information systems. The objective\nof this research work is to create a framework, which can convert clinical text\ninto causal knowledge. Methods: A practical approach based on term expansion,\nphrase generation, BERT based phrase embedding and semantic matching, semantic\nenrichment, expert verification, and model evolution has been used to construct\na comprehensive causality mining framework. This active transfer learning based\nframework along with its supplementary services, is able to extract and enrich,\ncausal relationships and their corresponding entities from clinical text.\nResults: The multi-model transfer learning technique when applied over multiple\niterations, gains performance improvements in terms of its accuracy and recall\nwhile keeping the precision constant. We also present a comparative analysis of\nthe presented techniques with their common alternatives, which demonstrate the\ncorrectness of our approach and its ability to capture most causal\nrelationships. Conclusion: The presented framework has provided cutting-edge\nresults in the healthcare domain. However, the framework can be tweaked to\nprovide causality detection in other domains, as well. Significance: The\npresented framework is generic enough to be utilized in any domain, healthcare\nservices can gain massive benefits due to the voluminous and various nature of\nits data. This causal knowledge extraction framework can be used to summarize\nclinical text, create personas, discover medical knowledge, and provide\nevidence to clinical decision making.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 06:51:13 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Hussain", "Musarrat", ""], ["Satti", "Fahad Ahmed", ""], ["Hussain", "Jamil", ""], ["Ali", "Taqdir", ""], ["Ali", "Syed Imran", ""], ["Bilal", "Hafiz Syed Muhammad", ""], ["Park", "Gwang Hoon", ""], ["Lee", "Sungyoung", ""]]}, {"id": "2012.07565", "submitter": "Le Bao", "authors": "Xiaoxiao Li, Rabah Al-Zaidy, Amy Zhang, Stefan Baral, Le Bao, C. Lee\n  Giles", "title": "Automating Document Classification with Distant Supervision to Increase\n  the Efficiency of Systematic Reviews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Systematic reviews of scholarly documents often provide complete\nand exhaustive summaries of literature relevant to a research question.\nHowever, well-done systematic reviews are expensive, time-demanding, and\nlabor-intensive. Here, we propose an automatic document classification approach\nto significantly reduce the effort in reviewing documents. Methods: We first\ndescribe a manual document classification procedure that is used to curate a\npertinent training dataset and then propose three classifiers: a keyword-guided\nmethod, a cluster analysis-based refined method, and a random forest approach\nthat utilizes a large set of feature tokens. As an example, this approach is\nused to identify documents studying female sex workers that are assumed to\ncontain content relevant to either HIV or violence. We compare the performance\nof the three classifiers by cross-validation and conduct a sensitivity analysis\non the portion of data utilized in training the model. Results: The random\nforest approach provides the highest area under the curve (AUC) for both\nreceiver operating characteristic (ROC) and precision/recall (PR). Analyses of\nprecision and recall suggest that random forest could facilitate manually\nreviewing 20\\% of the articles while containing 80\\% of the relevant cases.\nFinally, we found a good classifier could be obtained by using a relatively\nsmall training sample size. Conclusions: In sum, the automated procedure of\ndocument classification presented here could improve both the precision and\nefficiency of systematic reviews, as well as facilitating live reviews, where\nreviews are updated regularly.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 22:45:40 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Li", "Xiaoxiao", ""], ["Al-Zaidy", "Rabah", ""], ["Zhang", "Amy", ""], ["Baral", "Stefan", ""], ["Bao", "Le", ""], ["Giles", "C. Lee", ""]]}, {"id": "2012.07575", "submitter": "Junming Huang", "authors": "Junming Huang, Gavin Cook, Yu Xie", "title": "Large-scale Quantitative Evidence of Media Impact on Public Opinion\n  toward China", "comments": "20 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Do mass media influence people's opinion of other countries? Using BERT, a\ndeep neural network-based natural language processing model, we analyze a large\ncorpus of 267,907 China-related articles published by The New York Times since\n1970. We then compare our output from The New York Times to a longitudinal data\nset constructed from 101 cross-sectional surveys of the American public's views\non China. We find that the reporting of The New York Times on China in one year\nexplains 54% of the variance in American public opinion on China in the next.\nOur result confirms hypothesized links between media and public opinion and\nhelps shed light on how mass media can influence public opinion of foreign\ncountries.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 20:14:54 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 15:37:46 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Huang", "Junming", ""], ["Cook", "Gavin", ""], ["Xie", "Yu", ""]]}, {"id": "2012.07580", "submitter": "Zied Bouraoui", "authors": "Na Li, Zied Bouraoui, Jose Camacho Collados, Luis Espinosa-Anke, Qing\n  Gu, Steven Schockaert", "title": "Modelling General Properties of Nouns by Selectively Averaging\n  Contextualised Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the success of pre-trained language models has largely eliminated the\nneed for high-quality static word vectors in many NLP applications, such\nvectors continue to play an important role in tasks where words need to be\nmodelled in the absence of linguistic context. In this paper, we explore how\nthe contextualised embeddings predicted by BERT can be used to produce\nhigh-quality word vectors for such domains, in particular related to knowledge\nbase completion, where our focus is on capturing the semantic properties of\nnouns. We find that a simple strategy of averaging the contextualised\nembeddings of masked word mentions leads to vectors that outperform the static\nword vectors learned by BERT, as well as those from standard word embedding\nmodels, in property induction tasks. We notice in particular that masking\ntarget words is critical to achieve this strong performance, as the resulting\nvectors focus less on idiosyncratic properties and more on general semantic\nproperties. Inspired by this view, we propose a filtering strategy which is\naimed at removing the most idiosyncratic mention vectors, allowing us to obtain\nfurther performance gains in property induction.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 14:03:03 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 15:00:19 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Li", "Na", ""], ["Bouraoui", "Zied", ""], ["Collados", "Jose Camacho", ""], ["Espinosa-Anke", "Luis", ""], ["Gu", "Qing", ""], ["Schockaert", "Steven", ""]]}, {"id": "2012.07587", "submitter": "Ashwin Rachha", "authors": "Ashwin Rachha and Gaurav Vanmane", "title": "Detecting Insincere Questions from Text: A Transfer Learning Approach", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The internet today has become an unrivalled source of information where\npeople converse on content based websites such as Quora, Reddit, StackOverflow\nand Twitter asking doubts and sharing knowledge with the world. A major arising\nproblem with such websites is the proliferation of toxic comments or instances\nof insincerity wherein the users instead of maintaining a sincere motive\nindulge in spreading toxic and divisive content. The straightforward course of\naction in confronting this situation is detecting such content beforehand and\npreventing it from subsisting online. In recent times Transfer Learning in\nNatural Language Processing has seen an unprecedented growth. Today with the\nexistence of transformers and various state of the art innovations, a\ntremendous growth has been made in various NLP domains. The introduction of\nBERT has caused quite a stir in the NLP community. As mentioned, when\npublished, BERT dominated performance benchmarks and thereby inspired many\nother authors to experiment with it and publish similar models. This led to the\ndevelopment of a whole BERT-family, each member being specialized on a\ndifferent task. In this paper we solve the Insincere Questions Classification\nproblem by fine tuning four cutting age models viz BERT, RoBERTa, DistilBERT\nand ALBERT.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 15:03:48 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Rachha", "Ashwin", ""], ["Vanmane", "Gaurav", ""]]}, {"id": "2012.07589", "submitter": "Ananda Das", "authors": "Ananda Das, Partha Pratim Das", "title": "Incorporating Domain Knowledge To Improve Topic Segmentation Of Long\n  MOOC Lecture Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Topical Segmentation poses a great role in reducing search space of the\ntopics taught in a lecture video specially when the video metadata lacks topic\nwise segmentation information. This segmentation information eases user efforts\nof searching, locating and browsing a topic inside a lecture video. In this\nwork we propose an algorithm, that combines state-of-the art language model and\ndomain knowledge graph for automatically detecting different coherent topics\npresent inside a long lecture video. We use the language model on\nspeech-to-text transcription to capture the implicit meaning of the whole video\nwhile the knowledge graph provides us the domain specific dependencies between\ndifferent concepts of that subjects. Also leveraging the domain knowledge we\ncan capture the way instructor binds and connects different concepts while\nteaching, which helps us in achieving better segmentation accuracy. We tested\nour approach on NPTEL lecture videos and holistic evaluation shows that it out\nperforms the other methods described in the literature.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 13:37:40 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Das", "Ananda", ""], ["Das", "Partha Pratim", ""]]}, {"id": "2012.07599", "submitter": "Rahat Zaman", "authors": "Md. Rahat-uz-Zaman and Shadmaan Hye", "title": "Agglomerative Clustering of Handwritten Numerals to Determine Similarity\n  of Different Languages", "comments": "Submitted to the 22nd International Conference on Computer and\n  Information Technology (ICCIT), 18-20 December, 2019, 6 pages, 5 figures and\n  1 table", "journal-ref": null, "doi": "10.1109/ICCIT48885.2019.9038550", "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Handwritten numerals of different languages have various characteristics.\nSimilarities and dissimilarities of the languages can be measured by analyzing\nthe extracted features of the numerals. Handwritten numeral datasets are\navailable and accessible for many renowned languages of different regions. In\nthis paper, several handwritten numeral datasets of different languages are\ncollected. Then they are used to find the similarity among those written\nlanguages through determining and comparing the similitude of each handwritten\nnumerals. This will help to find which languages have the same or adjacent\nparent language. Firstly, a similarity measure of two numeral images is\nconstructed with a Siamese network. Secondly, the similarity of the numeral\ndatasets is determined with the help of the Siamese network and a new random\nsample with replacement similarity averaging technique. Finally, an\nagglomerative clustering is done based on the similarities of each dataset.\nThis clustering technique shows some very interesting properties of the\ndatasets. The property focused in this paper is the regional resemblance of the\ndatasets. By analyzing the clusters, it becomes easy to identify which\nlanguages are originated from similar regions.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 04:36:25 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Rahat-uz-Zaman", "Md.", ""], ["Hye", "Shadmaan", ""]]}, {"id": "2012.07609", "submitter": "Vivek Kaushal", "authors": "Vivek Kaushal and Kavita Vemuri", "title": "Clickbait in Hindi News Media : A Preliminary Study", "comments": "Accepted as a short paper in the 17th International Conference on\n  Natural Language Processing, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A corpus of Hindi news headlines shared on Twitter was created by collecting\ntweets of 5 mainstream Hindi news sources for a period of 4 months. 7\nindependent annotators were recruited to mark the 20 most retweeted news posts\nby each of the 5 news sources on its clickbait nature. The clickbait score\nhence generated was assessed for its correlation with interactions on the\nplatform (retweets, favorites, reader replies), tweet word count, and\nnormalized POS (part-of-speech) tag counts in tweets. A positive correlation\nwas observed between readers' interactions with tweets and tweets' clickbait\nscore. Significant correlations were also observed for POS tag counts and\nclickbait score. The prevalence of clickbait in mainstream Hindi news media was\nfound to be similar to its prevalence in English news media. We hope that our\nobservations would provide a platform for discussions on clickbait in\nmainstream Hindi news media.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 14:59:08 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Kaushal", "Vivek", ""], ["Vemuri", "Kavita", ""]]}, {"id": "2012.07610", "submitter": "Jiawei Liu", "authors": "Jiawei Liu, Zhe Gao, Yangyang Kang, Zhuoren Jiang, Guoxiu He,\n  Changlong Sun, Xiaozhong Liu, Wei Lu", "title": "Time to Transfer: Predicting and Evaluating Machine-Human Chatting\n  Handoff", "comments": "9pages, 4 figures, accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is chatbot able to completely replace the human agent? The short answer could\nbe - \"it depends...\". For some challenging cases, e.g., dialogue's topical\nspectrum spreads beyond the training corpus coverage, the chatbot may\nmalfunction and return unsatisfied utterances. This problem can be addressed by\nintroducing the Machine-Human Chatting Handoff (MHCH), which enables\nhuman-algorithm collaboration. To detect the normal/transferable utterances, we\npropose a Difficulty-Assisted Matching Inference (DAMI) network, utilizing\ndifficulty-assisted encoding to enhance the representations of utterances.\nMoreover, a matching inference mechanism is introduced to capture the\ncontextual matching features. A new evaluation metric, Golden Transfer within\nTolerance (GT-T), is proposed to assess the performance by considering the\ntolerance property of the MHCH. To provide insights into the task and validate\nthe proposed model, we collect two new datasets. Extensive experimental results\nare presented and contrasted against a series of baseline models to demonstrate\nthe efficacy of our model on MHCH.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 15:02:08 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Liu", "Jiawei", ""], ["Gao", "Zhe", ""], ["Kang", "Yangyang", ""], ["Jiang", "Zhuoren", ""], ["He", "Guoxiu", ""], ["Sun", "Changlong", ""], ["Liu", "Xiaozhong", ""], ["Lu", "Wei", ""]]}, {"id": "2012.07619", "submitter": "Maartje ter Hoeve", "authors": "Maartje ter Hoeve, Julia Kiseleva, Maarten de Rijke", "title": "What Makes a Good Summary? Investigating the Focus of Automatic\n  Summarization in an Educational Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic text summarization has enjoyed great progress over the last years.\nHowever, there is little research that investigates whether the current\nresearch focus adheres to users' needs. Importantly, these needs are dependent\non the envisioned target group of the generated summaries. One such important\ntarget group is formed by students, due to their usage of summaries in their\nstudy activities. For this reason, we investigate students' needs regarding\nautomatically generated summaries by means of a survey amongst university\nstudents and find that the current direction of the field does not fully align\nwith their needs. Motivated by our findings, we formulate three groups of\nimplications that together help us formulate a renewed perspective on future\nresearch on automatic summarization. First, the educational domain requires a\nbroader perspective on automatic summarization, beyond the approaches that are\ncurrently the standard. We illustrate how we can expand these approaches\nregarding the input material, the purpose of the summaries and their potential\nformat and we define requirements for datasets that can facilitate these\nresearch directions. Second, we propose a methodology to evaluate the\nusefulness of a summary based on the identified needs of a target group. Third,\nin more general terms, we hope that our survey will be reused to investigate\nthe needs of different user groups of automatically generated summaries to\nbroaden our perspective even further.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 15:12:35 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 19:08:43 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["ter Hoeve", "Maartje", ""], ["Kiseleva", "Julia", ""], ["de Rijke", "Maarten", ""]]}, {"id": "2012.07637", "submitter": "Konstantin Fackeldey", "authors": "Marcus Weber and Konstantin Fackeldey", "title": "The Complexity of Comparative Text Analysis -- \"The Gardener is always\n  the Murderer\" says the Fourth Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a heated debate about how far computers can map the complexity of\ntext analysis compared to the abilities of the whole team of human researchers.\nA \"deep\" analysis of a given text is still beyond the possibilities of modern\ncomputers.\n  In the heart of the existing computational text analysis algorithms there are\noperations with real numbers, such as additions and multiplications according\nto the rules of algebraic fields. However, the process of \"comparing\" has a\nvery precise mathematical structure, which is different from the structure of\nan algebraic field. The mathematical structure of \"comparing\" can be expressed\nby using Boolean rings. We build on this structure and define the corresponding\nalgebraic equations lifting algorithms of comparative text analysis onto the\n\"correct\" algebraic basis. From this point of view, we can investigate the\nquestion of {\\em computational} complexity of comparative text analysis.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 10:32:35 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Weber", "Marcus", ""], ["Fackeldey", "Konstantin", ""]]}, {"id": "2012.07652", "submitter": "Aditya Pal", "authors": "Aditya Pal, Abhijit Mustafi", "title": "Vartani Spellcheck -- Automatic Context-Sensitive Spelling Correction of\n  OCR-generated Hindi Text Using BERT and Levenshtein Distance", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional Optical Character Recognition (OCR) systems that generate text of\nhighly inflectional Indic languages like Hindi tend to suffer from poor\naccuracy due to a wide alphabet set, compound characters and difficulty in\nsegmenting characters in a word. Automatic spelling error detection and\ncontext-sensitive error correction can be used to improve accuracy by\npost-processing the text generated by these OCR systems. A majority of\npreviously developed language models for error correction of Hindi spelling\nhave been context-free. In this paper, we present Vartani Spellcheck - a\ncontext-sensitive approach for spelling correction of Hindi text using a\nstate-of-the-art transformer - BERT in conjunction with the Levenshtein\ndistance algorithm, popularly known as Edit Distance. We use a lookup\ndictionary and context-based named entity recognition (NER) for detection of\npossible spelling errors in the text. Our proposed technique has been tested on\na large corpus of text generated by the widely used Tesseract OCR on the Hindi\nepic Ramayana. With an accuracy of 81%, the results show a significant\nimprovement over some of the previously established context-sensitive error\ncorrection mechanisms for Hindi. We also explain how Vartani Spellcheck may be\nused for on-the-fly autocorrect suggestion during continuous typing in a text\neditor environment.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 15:49:54 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Pal", "Aditya", ""], ["Mustafi", "Abhijit", ""]]}, {"id": "2012.07701", "submitter": "Mir Tafseer Nayeem", "authors": "Susmoy Chakraborty, Mir Tafseer Nayeem, Wasi Uddin Ahmad", "title": "Simple or Complex? Learning to Predict Readability of Bengali Texts", "comments": "Accepted for publication at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Determining the readability of a text is the first step to its\nsimplification. In this paper, we present a readability analysis tool capable\nof analyzing text written in the Bengali language to provide in-depth\ninformation on its readability and complexity. Despite being the 7th most\nspoken language in the world with 230 million native speakers, Bengali suffers\nfrom a lack of fundamental resources for natural language processing.\nReadability related research of the Bengali language so far can be considered\nto be narrow and sometimes faulty due to the lack of resources. Therefore, we\ncorrectly adopt document-level readability formulas traditionally used for U.S.\nbased education system to the Bengali language with a proper age-to-age\ncomparison. Due to the unavailability of large-scale human-annotated corpora,\nwe further divide the document-level task into sentence-level and experiment\nwith neural architectures, which will serve as a baseline for the future works\nof Bengali readability prediction. During the process, we present several\nhuman-annotated corpora and dictionaries such as a document-level dataset\ncomprising 618 documents with 12 different grade levels, a large-scale\nsentence-level dataset comprising more than 96K sentences with simple and\ncomplex labels, a consonant conjunct count algorithm and a corpus of 341 words\nto validate the effectiveness of the algorithm, a list of 3,396 easy words, and\nan updated pronunciation dictionary with more than 67K words. These resources\ncan be useful for several other tasks of this low-resource language. We make\nour Code & Dataset publicly available at\nhttps://github.com/tafseer-nayeem/BengaliReadability} for reproduciblity.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 01:41:35 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Chakraborty", "Susmoy", ""], ["Nayeem", "Mir Tafseer", ""], ["Ahmad", "Wasi Uddin", ""]]}, {"id": "2012.07743", "submitter": "Michael Fromm", "authors": "Michael Fromm, Evgeniy Faerman, Max Berrendorf, Siddharth Bhargava,\n  Ruoxia Qi, Yao Zhang, Lukas Dennert, Sophia Selle, Yang Mao, Thomas Seidl", "title": "Argument Mining Driven Analysis of Peer-Reviews", "comments": null, "journal-ref": null, "doi": "10.5281/zenodo.4314390", "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Peer reviewing is a central process in modern research and essential for\nensuring high quality and reliability of published work. At the same time, it\nis a time-consuming process and increasing interest in emerging fields often\nresults in a high review workload, especially for senior researchers in this\narea. How to cope with this problem is an open question and it is vividly\ndiscussed across all major conferences. In this work, we propose an Argument\nMining based approach for the assistance of editors, meta-reviewers, and\nreviewers. We demonstrate that the decision process in the field of scientific\npublications is driven by arguments and automatic argument identification is\nhelpful in various use-cases. One of our findings is that arguments used in the\npeer-review process differ from arguments in other domains making the transfer\nof pre-trained models difficult. Therefore, we provide the community with a new\npeer-review dataset from different computer science conferences with annotated\narguments. In our extensive empirical evaluation, we show that Argument Mining\ncan be used to efficiently extract the most relevant parts from reviews, which\nare paramount for the publication decision. The process remains interpretable\nsince the extracted arguments can be highlighted in a review without detaching\nthem from their context.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 16:06:21 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Fromm", "Michael", ""], ["Faerman", "Evgeniy", ""], ["Berrendorf", "Max", ""], ["Bhargava", "Siddharth", ""], ["Qi", "Ruoxia", ""], ["Zhang", "Yao", ""], ["Dennert", "Lukas", ""], ["Selle", "Sophia", ""], ["Mao", "Yang", ""], ["Seidl", "Thomas", ""]]}, {"id": "2012.07749", "submitter": "Elisa Ferracane", "authors": "Elisa Ferracane, Sandeep Konam", "title": "Towards Fairness in Classifying Medical Conversations into SOAP Sections", "comments": "To be presented at AAAI TAIH Workshop 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning algorithms are more widely deployed in healthcare, the\nquestion of algorithmic fairness becomes more critical to examine. Our work\nseeks to identify and understand disparities in a deployed model that\nclassifies doctor-patient conversations into sections of a medical SOAP note.\nWe employ several metrics to measure disparities in the classifier performance,\nand find small differences in a portion of the disadvantaged groups. A deeper\nanalysis of the language in these conversations and further stratifying the\ngroups suggests these differences are related to and often attributable to the\ntype of medical appointment (e.g., psychiatric vs. internist). Our findings\nstress the importance of understanding the disparities that may exist in the\ndata itself and how that affects a model's ability to equally distribute\nbenefits.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 14:55:22 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Ferracane", "Elisa", ""], ["Konam", "Sandeep", ""]]}, {"id": "2012.07788", "submitter": "Niklas Muennighoff", "authors": "Niklas Muennighoff", "title": "Vilio: State-of-the-art Visio-Linguistic Models applied to Hateful Memes", "comments": "Presented at NIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents Vilio, an implementation of state-of-the-art\nvisio-linguistic models and their application to the Hateful Memes Dataset. The\nimplemented models have been fitted into a uniform code-base and altered to\nyield better performance. The goal of Vilio is to provide a user-friendly\nstarting point for any visio-linguistic problem. An ensemble of 5 different V+L\nmodels implemented in Vilio achieves 2nd place in the Hateful Memes Challenge\nout of 3,300 participants. The code is available at\nhttps://github.com/Muennighoff/vilio.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 18:25:03 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Muennighoff", "Niklas", ""]]}, {"id": "2012.07805", "submitter": "Nicholas Carlini", "authors": "Nicholas Carlini, Florian Tramer, Eric Wallace, Matthew Jagielski,\n  Ariel Herbert-Voss, Katherine Lee, Adam Roberts, Tom Brown, Dawn Song, Ulfar\n  Erlingsson, Alina Oprea, Colin Raffel", "title": "Extracting Training Data from Large Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has become common to publish large (billion parameter) language models\nthat have been trained on private datasets. This paper demonstrates that in\nsuch settings, an adversary can perform a training data extraction attack to\nrecover individual training examples by querying the language model.\n  We demonstrate our attack on GPT-2, a language model trained on scrapes of\nthe public Internet, and are able to extract hundreds of verbatim text\nsequences from the model's training data. These extracted examples include\n(public) personally identifiable information (names, phone numbers, and email\naddresses), IRC conversations, code, and 128-bit UUIDs. Our attack is possible\neven though each of the above sequences are included in just one document in\nthe training data.\n  We comprehensively evaluate our extraction attack to understand the factors\nthat contribute to its success. Worryingly, we find that larger models are more\nvulnerable than smaller models. We conclude by drawing lessons and discussing\npossible safeguards for training large language models.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 18:39:09 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 17:45:26 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Carlini", "Nicholas", ""], ["Tramer", "Florian", ""], ["Wallace", "Eric", ""], ["Jagielski", "Matthew", ""], ["Herbert-Voss", "Ariel", ""], ["Lee", "Katherine", ""], ["Roberts", "Adam", ""], ["Brown", "Tom", ""], ["Song", "Dawn", ""], ["Erlingsson", "Ulfar", ""], ["Oprea", "Alina", ""], ["Raffel", "Colin", ""]]}, {"id": "2012.07808", "submitter": "Reinald Kim Amplayo", "authors": "Reinald Kim Amplayo, Stefanos Angelidis, Mirella Lapata", "title": "Unsupervised Opinion Summarization with Content Planning", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recent success of deep learning techniques for abstractive summarization\nis predicated on the availability of large-scale datasets. When summarizing\nreviews (e.g., for products or movies), such training data is neither available\nnor can be easily sourced, motivating the development of methods which rely on\nsynthetic datasets for supervised training. We show that explicitly\nincorporating content planning in a summarization model not only yields output\nof higher quality, but also allows the creation of synthetic datasets which are\nmore natural, resembling real world document-summary pairs. Our content plans\ntake the form of aspect and sentiment distributions which we induce from data\nwithout access to expensive annotations. Synthetic datasets are created by\nsampling pseudo-reviews from a Dirichlet distribution parametrized by our\ncontent planner, while our model generates summaries based on input reviews and\ninduced content plans. Experimental results on three domains show that our\napproach outperforms competitive models in generating informative, coherent,\nand fluent summaries that capture opinion consensus.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 18:41:58 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Amplayo", "Reinald Kim", ""], ["Angelidis", "Stefanos", ""], ["Lapata", "Mirella", ""]]}, {"id": "2012.07974", "submitter": "Chanwoo Kim", "authors": "Chanwoo Kim, Dhananjaya Gowda, Dongsoo Lee, Jiyeon Kim, Ankur Kumar,\n  Sungsoo Kim, Abhinav Garg, and Changwoo Han", "title": "A review of on-device fully neural end-to-end automatic speech\n  recognition algorithms", "comments": "Accepted as an invited paper to the Asilomar Conference on Signals,\n  Systems, and Computers 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we review various end-to-end automatic speech recognition\nalgorithms and their optimization techniques for on-device applications.\nConventional speech recognition systems comprise a large number of discrete\ncomponents such as an acoustic model, a language model, a pronunciation model,\na text-normalizer, an inverse-text normalizer, a decoder based on a Weighted\nFinite State Transducer (WFST), and so on. To obtain sufficiently high speech\nrecognition accuracy with such conventional speech recognition systems, a very\nlarge language model (up to 100 GB) is usually needed. Hence, the corresponding\nWFST size becomes enormous, which prohibits their on-device implementation.\nRecently, fully neural network end-to-end speech recognition algorithms have\nbeen proposed. Examples include speech recognition systems based on\nConnectionist Temporal Classification (CTC), Recurrent Neural Network\nTransducer (RNN-T), Attention-based Encoder-Decoder models (AED), Monotonic\nChunk-wise Attention (MoChA), transformer-based speech recognition systems, and\nso on. These fully neural network-based systems require much smaller memory\nfootprints compared to conventional algorithms, therefore their on-device\nimplementation has become feasible. In this paper, we review such end-to-end\nspeech recognition models. We extensively discuss their structures,\nperformance, and advantages compared to conventional algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 22:18:08 GMT"}, {"version": "v2", "created": "Sat, 19 Dec 2020 08:27:51 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Kim", "Chanwoo", ""], ["Gowda", "Dhananjaya", ""], ["Lee", "Dongsoo", ""], ["Kim", "Jiyeon", ""], ["Kumar", "Ankur", ""], ["Kim", "Sungsoo", ""], ["Garg", "Abhinav", ""], ["Han", "Changwoo", ""]]}, {"id": "2012.07978", "submitter": "Geetanjali Bihani", "authors": "Geetanjali Bihani, Julia Taylor Rayz", "title": "Model Choices Influence Attributive Word Associations: A Semi-supervised\n  Analysis of Static Word Embeddings", "comments": "2020 IEEE/WIC/ACM International Joint Conference on Web Intelligence\n  and Intelligent Agent Technology (WI-IAT'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Static word embeddings encode word associations, extensively utilized in\ndownstream NLP tasks. Although prior studies have discussed the nature of such\nword associations in terms of biases and lexical regularities captured, the\nvariation in word associations based on the embedding training procedure\nremains in obscurity. This work aims to address this gap by assessing\nattributive word associations across five different static word embedding\narchitectures, analyzing the impact of the choice of the model architecture,\ncontext learning flavor and training corpora. Our approach utilizes a\nsemi-supervised clustering method to cluster annotated proper nouns and\nadjectives, based on their word embedding features, revealing underlying\nattributive word associations formed in the embedding space, without\nintroducing any confirmation bias. Our results reveal that the choice of the\ncontext learning flavor during embedding training (CBOW vs skip-gram) impacts\nthe word association distinguishability and word embeddings' sensitivity to\ndeviations in the training corpora. Moreover, it is empirically shown that even\nwhen trained over the same corpora, there is significant inter-model disparity\nand intra-model similarity in the encoded word associations across different\nword embedding models, portraying specific patterns in the way the embedding\nspace is created for each embedding architecture.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 22:27:18 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Bihani", "Geetanjali", ""], ["Rayz", "Julia Taylor", ""]]}, {"id": "2012.08012", "submitter": "Faeze Brahman", "authors": "Faeze Brahman, Vered Shwartz, Rachel Rudinger, Yejin Choi", "title": "Learning to Rationalize for Nonmonotonic Reasoning with Distant\n  Supervision", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The black-box nature of neural models has motivated a line of research that\naims to generate natural language rationales to explain why a model made\ncertain predictions. Such rationale generation models, to date, have been\ntrained on dataset-specific crowdsourced rationales, but this approach is\ncostly and is not generalizable to new tasks and domains. In this paper, we\ninvestigate the extent to which neural models can reason about natural language\nrationales that explain model predictions, relying only on distant supervision\nwith no additional annotation cost for human-written rationales. We investigate\nmultiple ways to automatically generate rationales using pre-trained language\nmodels, neural knowledge models, and distant supervision from related tasks,\nand train generative models capable of composing explanatory rationales for\nunseen instances. We demonstrate our approach on the defeasible inference task,\na nonmonotonic reasoning task in which an inference may be strengthened or\nweakened when new information (an update) is introduced. Our model shows\npromises at generating post-hoc rationales explaining why an inference is more\nor less likely given the additional information, however, it mostly generates\ntrivial rationales reflecting the fundamental limitations of neural language\nmodels. Conversely, the more realistic setup of jointly predicting the update\nor its type and generating rationale is more challenging, suggesting an\nimportant future direction.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 23:50:20 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Brahman", "Faeze", ""], ["Shwartz", "Vered", ""], ["Rudinger", "Rachel", ""], ["Choi", "Yejin", ""]]}, {"id": "2012.08013", "submitter": "Nicholas Egan", "authors": "Nicholas Egan, John Bohannon", "title": "Primer AI's Systems for Acronym Identification and Disambiguation", "comments": "In the Scientific Document Understanding workshop at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The prevalence of ambiguous acronyms make scientific documents harder to\nunderstand for humans and machines alike, presenting a need for models that can\nautomatically identify acronyms in text and disambiguate their meaning. We\nintroduce new methods for acronym identification and disambiguation: our\nacronym identification model projects learned token embeddings onto tag\npredictions, and our acronym disambiguation model finds training examples with\nsimilar sentence embeddings as test examples. Both of our systems achieve\nsignificant performance gains over previously suggested methods, and perform\ncompetitively on the SDU@AAAI-21 shared task leaderboard. Our models were\ntrained in part on new distantly-supervised datasets for these tasks which we\ncall AuxAI and AuxAD. We also identified a duplication conflict issue in the\nSciAD dataset, and formed a deduplicated version of SciAD that we call\nSciAD-dedupe. We publicly released all three of these datasets, and hope that\nthey help the community make further strides in scientific document\nunderstanding.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 23:59:05 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 00:50:40 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Egan", "Nicholas", ""], ["Bohannon", "John", ""]]}, {"id": "2012.08020", "submitter": "Leonid Boytsov", "authors": "Leonid Boytsov", "title": "Traditional IR rivals neural models on the MS MARCO Document Ranking\n  Leaderboard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short document describes a traditional IR system that achieved MRR@100\nequal to 0.298 on the MS MARCO Document Ranking leaderboard (on 2020-12-06).\nAlthough inferior to most BERT-based models, it outperformed several neural\nruns (as well as all non-neural ones), including two submissions that used a\nlarge pretrained Transformer model for re-ranking. We provide software and data\nto reproduce our results.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 00:35:41 GMT"}, {"version": "v2", "created": "Sat, 19 Dec 2020 11:03:16 GMT"}, {"version": "v3", "created": "Wed, 17 Mar 2021 18:20:00 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Boytsov", "Leonid", ""]]}, {"id": "2012.08113", "submitter": "Nicholas Altieri", "authors": "Nick Altieri, Briton Park, Mara Olson, John DeNero, Anobel Odisho, Bin\n  Yu", "title": "Enriched Annotations for Tumor Attribute Classification from Pathology\n  Reports with Limited Labeled Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Precision medicine has the potential to revolutionize healthcare, but much of\nthe data for patients is locked away in unstructured free-text, limiting\nresearch and delivery of effective personalized treatments. Generating large\nannotated datasets for information extraction from clinical notes is often\nchallenging and expensive due to the high level of expertise needed for high\nquality annotations. To enable natural language processing for small dataset\nsizes, we develop a novel enriched hierarchical annotation scheme and\nalgorithm, Supervised Line Attention (SLA), and apply this algorithm to\npredicting categorical tumor attributes from kidney and colon cancer pathology\nreports from the University of California San Francisco (UCSF). Whereas\nprevious work only annotated document level labels, we in addition ask the\nannotators to enrich the traditional label by asking them to also highlight the\nrelevant line or potentially lines for the final label, which leads to a 20%\nincrease of annotation time required per document. With the enriched\nannotations, we develop a simple and interpretable machine learning algorithm\nthat first predicts the relevant lines in the document and then predicts the\ntumor attribute. Our results show across the small dataset sizes of 32, 64,\n128, and 186 labeled documents per cancer, SLA only requires half the number of\nlabeled documents as state-of-the-art methods to achieve similar or better\nmicro-f1 and macro-f1 scores for the vast majority of comparisons that we made.\nAccounting for the increased annotation time, this leads to a 40% reduction in\ntotal annotation time over the state of the art.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 06:31:38 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Altieri", "Nick", ""], ["Park", "Briton", ""], ["Olson", "Mara", ""], ["DeNero", "John", ""], ["Odisho", "Anobel", ""], ["Yu", "Bin", ""]]}, {"id": "2012.08117", "submitter": "Jiayi Zhang", "authors": "Jiayi Zhang, Zhi Cui, Xiaoqiang Xia, Yalong Guo, Yanran Li, Chen Wei,\n  Jianwei Cui", "title": "Writing Polishment with Simile: Task, Dataset and A Neural Approach", "comments": "Accepted in AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simile is a figure of speech that directly makes a comparison, showing\nsimilarities between two different things, e.g. \"Reading papers can be dull\nsometimes,like watching grass grow\". Human writers often interpolate\nappropriate similes into proper locations of the plain text to vivify their\nwritings. However, none of existing work has explored neural simile\ninterpolation, including both locating and generation. In this paper, we\npropose a new task of Writing Polishment with Simile (WPS) to investigate\nwhether machines are able to polish texts with similes as we human do.\nAccordingly, we design a two-staged Locate&Gen model based on transformer\narchitecture. Our model firstly locates where the simile interpolation should\nhappen, and then generates a location-specific simile. We also release a\nlarge-scale Chinese Simile (CS) dataset containing 5 million similes with\ncontext. The experimental results demonstrate the feasibility of WPS task and\nshed light on the future research directions towards better automatic text\npolishment.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 06:39:54 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Zhang", "Jiayi", ""], ["Cui", "Zhi", ""], ["Xia", "Xiaoqiang", ""], ["Guo", "Yalong", ""], ["Li", "Yanran", ""], ["Wei", "Chen", ""], ["Cui", "Jianwei", ""]]}, {"id": "2012.08128", "submitter": "Yao Zhu", "authors": "Yao Zhu, Hongzhi Liu, Zhonghai Wu, Yingpeng Du", "title": "Relation-Aware Neighborhood Matching Model for Entity Alignment", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity alignment which aims at linking entities with the same meaning from\ndifferent knowledge graphs (KGs) is a vital step for knowledge fusion. Existing\nresearch focused on learning embeddings of entities by utilizing structural\ninformation of KGs for entity alignment. These methods can aggregate\ninformation from neighboring nodes but may also bring noise from neighbors.\nMost recently, several researchers attempted to compare neighboring nodes in\npairs to enhance the entity alignment. However, they ignored the relations\nbetween entities which are also important for neighborhood matching. In\naddition, existing methods paid less attention to the positive interactions\nbetween the entity alignment and the relation alignment. To deal with these\nissues, we propose a novel Relation-aware Neighborhood Matching model named RNM\nfor entity alignment. Specifically, we propose to utilize the neighborhood\nmatching to enhance the entity alignment. Besides comparing neighbor nodes when\nmatching neighborhood, we also try to explore useful information from the\nconnected relations. Moreover, an iterative framework is designed to leverage\nthe positive interactions between the entity alignment and the relation\nalignment in a semi-supervised manner. Experimental results on three real-world\ndatasets demonstrate that the proposed model RNM performs better than\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 07:22:39 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Zhu", "Yao", ""], ["Liu", "Hongzhi", ""], ["Wu", "Zhonghai", ""], ["Du", "Yingpeng", ""]]}, {"id": "2012.08146", "submitter": "Amol Kelkar", "authors": "Amol Kelkar, Nachiketa Rajpurohit, Utkarsh Mittal and Peter Relan", "title": "Generation of complex database queries and API calls from natural\n  language utterances", "comments": "Accepted at WeCNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generating queries corresponding to natural language questions is a long\nstanding problem. Traditional methods lack language flexibility, while newer\nsequence-to-sequence models require large amount of data. Schema-agnostic\nsequence-to-sequence models can be fine-tuned for a specific schema using a\nsmall dataset but these models have relatively low accuracy. We present a\nmethod that transforms the query generation problem into an intent\nclassification and slot filling problem. This method can work using small\ndatasets. For questions similar to the ones in the training dataset, it\nproduces complex queries with high accuracy. For other questions, it can use a\ntemplate-based approach or predict query pieces to construct the queries, still\nat a higher accuracy than sequence-to-sequence models. On a real-world dataset,\na schema fine-tuned state-of-the-art generative model had 60\\% exact match\naccuracy for the query generation task, while our method resulted in 92\\% exact\nmatch accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 08:28:52 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Kelkar", "Amol", ""], ["Rajpurohit", "Nachiketa", ""], ["Mittal", "Utkarsh", ""], ["Relan", "Peter", ""]]}, {"id": "2012.08148", "submitter": "Matteo Antonio Senese", "authors": "Matteo A. Senese, Alberto Benincasa, Barbara Caputo, Giuseppe Rizzo", "title": "A Response Retrieval Approach for Dialogue Using a Multi-Attentive\n  Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents our work for the ninth edition of the Dialogue System\nTechnology Challenge (DSTC9). Our solution addresses the track number four:\nSimulated Interactive MultiModal Conversations. The task consists in providing\nan algorithm able to simulate a shopping assistant that supports the user with\nhis/her requests. We address the task of response retrieval, that is the task\nof retrieving the most appropriate agent response from a pool of response\ncandidates. Our approach makes use of a neural architecture based on\ntransformer with a multi-attentive structure that conditions the response of\nthe agent on the request made by the user and on the product the user is\nreferring to. Final experiments on the SIMMC Fashion Dataset show that our\napproach achieves the second best scores on all the retrieval metrics defined\nby the organizers. The source code is available at\nhttps://github.com/D2KLab/dstc9-SIMMC.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 08:35:58 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Senese", "Matteo A.", ""], ["Benincasa", "Alberto", ""], ["Caputo", "Barbara", ""], ["Rizzo", "Giuseppe", ""]]}, {"id": "2012.08150", "submitter": "Shuo Zhang", "authors": "Shuo Zhang, Junzhou Zhao, Pinghui Wang, Nuo Xu, Yang Yang, Yiting Liu,\n  Yi Huang, Junlan Feng", "title": "Learning to Check Contract Inconsistencies", "comments": "Accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Contract consistency is important in ensuring the legal validity of the\ncontract. In many scenarios, a contract is written by filling the blanks in a\nprecompiled form. Due to carelessness, two blanks that should be filled with\nthe same (or different)content may be incorrectly filled with different (or\nsame) content. This will result in the issue of contract inconsistencies, which\nmay severely impair the legal validity of the contract. Traditional methods to\naddress this issue mainly rely on manual contract review, which is\nlabor-intensive and costly. In this work, we formulate a novel Contract\nInconsistency Checking (CIC) problem, and design an end-to-end framework,\ncalled Pair-wise Blank Resolution (PBR), to solve the CIC problem with high\naccuracy. Our PBR model contains a novel BlankCoder to address the challenge of\nmodeling meaningless blanks. BlankCoder adopts a two-stage attention mechanism\nthat adequately associates a meaningless blank with its relevant descriptions\nwhile avoiding the incorporation of irrelevant context words. Experiments\nconducted on real-world datasets show the promising performance of our method\nwith a balanced accuracy of 94.05% and an F1 score of 90.90% in the CIC\nproblem.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 08:43:07 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Zhang", "Shuo", ""], ["Zhao", "Junzhou", ""], ["Wang", "Pinghui", ""], ["Xu", "Nuo", ""], ["Yang", "Yang", ""], ["Liu", "Yiting", ""], ["Huang", "Yi", ""], ["Feng", "Junlan", ""]]}, {"id": "2012.08206", "submitter": "Carlos Badenes-Olmedo", "authors": "Carlos Badenes-Olmedo, Jose-Luis Redondo Garc\\'ia, Oscar Corcho", "title": "Efficient Clustering from Distributions over Topics", "comments": "Accepted at the 9th International Conference on Knowledge Capture\n  (K-CAP 2017)", "journal-ref": "ACM Proceedings of the Knowledge Capture Conference, article 17,\n  K-CAP 2017", "doi": "10.1145/3148011.3148019", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There are many scenarios where we may want to find pairs of textually similar\ndocuments in a large corpus (e.g. a researcher doing literature review, or an\nR&D project manager analyzing project proposals). To programmatically discover\nthose connections can help experts to achieve those goals, but brute-force\npairwise comparisons are not computationally adequate when the size of the\ndocument corpus is too large. Some algorithms in the literature divide the\nsearch space into regions containing potentially similar documents, which are\nlater processed separately from the rest in order to reduce the number of pairs\ncompared. However, this kind of unsupervised methods still incur in high\ntemporal costs. In this paper, we present an approach that relies on the\nresults of a topic modeling algorithm over the documents in a collection, as a\nmeans to identify smaller subsets of documents where the similarity function\ncan then be computed. This approach has proved to obtain promising results when\nidentifying similar documents in the domain of scientific publications. We have\ncompared our approach against state of the art clustering techniques and with\ndifferent configurations for the topic modeling algorithm. Results suggest that\nour approach outperforms (> 0.5) the other analyzed techniques in terms of\nefficiency.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 10:52:19 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Badenes-Olmedo", "Carlos", ""], ["Garc\u00eda", "Jose-Luis Redondo", ""], ["Corcho", "Oscar", ""]]}, {"id": "2012.08266", "submitter": "Dmitry Tsarkov", "authors": "Dmitry Tsarkov, Tibor Tihon, Nathan Scales, Nikola Momchev, Danila\n  Sinopalnikov, Nathanael Sch\\\"arli", "title": "*-CFQ: Analyzing the Scalability of Machine Learning on a Compositional\n  Task", "comments": "Accepted, AAAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present *-CFQ (\"star-CFQ\"): a suite of large-scale datasets of varying\nscope based on the CFQ semantic parsing benchmark, designed for principled\ninvestigation of the scalability of machine learning systems in a realistic\ncompositional task setting. Using this suite, we conduct a series of\nexperiments investigating the ability of Transformers to benefit from increased\ntraining size under conditions of fixed computational cost. We show that\ncompositional generalization remains a challenge at all training sizes, and we\nshow that increasing the scope of natural language leads to consistently higher\nerror rates, which are only partially offset by increased training data. We\nfurther show that while additional training data from a related domain improves\nthe accuracy in data-starved situations, this improvement is limited and\ndiminishes as the distance from the related domain to the target domain\nincreases.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 13:01:26 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Tsarkov", "Dmitry", ""], ["Tihon", "Tibor", ""], ["Scales", "Nathan", ""], ["Momchev", "Nikola", ""], ["Sinopalnikov", "Danila", ""], ["Sch\u00e4rli", "Nathanael", ""]]}, {"id": "2012.08290", "submitter": "Ron Zhu", "authors": "Ron Zhu", "title": "Enhance Multimodal Transformer With External Label And In-Domain\n  Pretrain: Hateful Meme Challenge Winning Solution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hateful meme detection is a new research area recently brought out that\nrequires both visual, linguistic understanding of the meme and some background\nknowledge to performing well on the task. This technical report summarises the\nfirst place solution of the Hateful Meme Detection Challenge 2020, which\nextending state-of-the-art visual-linguistic transformers to tackle this\nproblem. At the end of the report, we also point out the shortcomings and\npossible directions for improving the current methodology.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 13:57:21 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Zhu", "Ron", ""]]}, {"id": "2012.08312", "submitter": "Nalin Kumar", "authors": "Deepak Kumar, Nalin Kumar and Subhankar Mishra", "title": "QUARC: Quaternion Multi-Modal Fusion Architecture For Hate Speech\n  Classification", "comments": "Accepted in Proc. of the 4th International Workshop on Dialog Systems\n  (IWDS2021) in conjunction with the IEEE BigComp2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hate speech, quite common in the age of social media, at times harmless but\ncan also cause mental trauma to someone or even riots in communities. Image of\na religious symbol with derogatory comment or video of a man abusing a\nparticular community, all become hate speech with its every modality (such as\ntext, image, and audio) contributing towards it. Models based on a particular\nmodality of hate speech post on social media are not useful, rather, we need\nmodels like multi-modal fusion models that consider both image and text while\nclassifying hate speech. Text-image fusion models are heavily parameterized,\nhence we propose a quaternion neural network-based model having additional\nfusion components for each pair of modalities. The model is tested on the\nMMHS150K twitter dataset for hate speech classification. The model shows an\nalmost 75% reduction in parameters and also benefits us in terms of storage\nspace and training time while being at par in terms of performance as compared\nto its real counterpart.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 14:13:40 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Kumar", "Deepak", ""], ["Kumar", "Nalin", ""], ["Mishra", "Subhankar", ""]]}, {"id": "2012.08377", "submitter": "Peixiang Zhong", "authors": "Peixiang Zhong, Di Wang, Pengfei Li, Chen Zhang, Hao Wang, Chunyan\n  Miao", "title": "CARE: Commonsense-Aware Emotional Response Generation with Latent\n  Concepts", "comments": "AAAI-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rationality and emotion are two fundamental elements of humans. Endowing\nagents with rationality and emotion has been one of the major milestones in AI.\nHowever, in the field of conversational AI, most existing models only\nspecialize in one aspect and neglect the other, which often leads to dull or\nunrelated responses. In this paper, we hypothesize that combining rationality\nand emotion into conversational agents can improve response quality. To test\nthe hypothesis, we focus on one fundamental aspect of rationality, i.e.,\ncommonsense, and propose CARE, a novel model for commonsense-aware emotional\nresponse generation. Specifically, we first propose a framework to learn and\nconstruct commonsense-aware emotional latent concepts of the response given an\ninput message and a desired emotion. We then propose three methods to\ncollaboratively incorporate the latent concepts into response generation.\nExperimental results on two large-scale datasets support our hypothesis and\nshow that our model can produce more accurate and commonsense-aware emotional\nresponses and achieve better human ratings than state-of-the-art models that\nonly specialize in one aspect.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 15:47:30 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 05:53:41 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Zhong", "Peixiang", ""], ["Wang", "Di", ""], ["Li", "Pengfei", ""], ["Zhang", "Chen", ""], ["Wang", "Hao", ""], ["Miao", "Chunyan", ""]]}, {"id": "2012.08383", "submitter": "Peixiang Zhong", "authors": "Peixiang Zhong, Yong Liu, Hao Wang, Chunyan Miao", "title": "Keyword-Guided Neural Conversational Model", "comments": "AAAI-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of imposing conversational goals/keywords on open-domain\nconversational agents, where the agent is required to lead the conversation to\na target keyword smoothly and fast. Solving this problem enables the\napplication of conversational agents in many real-world scenarios, e.g.,\nrecommendation and psychotherapy. The dominant paradigm for tackling this\nproblem is to 1) train a next-turn keyword classifier, and 2) train a\nkeyword-augmented response retrieval model. However, existing approaches in\nthis paradigm have two limitations: 1) the training and evaluation datasets for\nnext-turn keyword classification are directly extracted from conversations\nwithout human annotations, thus, they are noisy and have low correlation with\nhuman judgements, and 2) during keyword transition, the agents solely rely on\nthe similarities between word embeddings to move closer to the target keyword,\nwhich may not reflect how humans converse. In this paper, we assume that human\nconversations are grounded on commonsense and propose a keyword-guided neural\nconversational model that can leverage external commonsense knowledge graphs\n(CKG) for both keyword transition and response retrieval. Automatic evaluations\nsuggest that commonsense improves the performance of both next-turn keyword\nprediction and keyword-augmented response retrieval. In addition, both\nself-play and human evaluations show that our model produces responses with\nsmoother keyword transition and reaches the target keyword faster than\ncompetitive baselines.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 15:55:32 GMT"}, {"version": "v2", "created": "Sun, 27 Dec 2020 04:00:07 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2021 05:55:23 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Zhong", "Peixiang", ""], ["Liu", "Yong", ""], ["Wang", "Hao", ""], ["Miao", "Chunyan", ""]]}, {"id": "2012.08396", "submitter": "Xiang Li", "authors": "Wenjie Qin, Xiang Li, Yuhui Sun, Deyi Xiong, Jianwei Cui, Bin Wang", "title": "Modeling Homophone Noise for Robust Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a robust neural machine translation (NMT)\nframework. The framework consists of a homophone noise detector and a\nsyllable-aware NMT model to homophone errors. The detector identifies potential\nhomophone errors in a textual sentence and converts them into syllables to form\na mixed sequence that is then fed into the syllable-aware NMT. Extensive\nexperiments on Chinese->English translation demonstrate that our proposed\nmethod not only significantly outperforms baselines on noisy test sets with\nhomophone noise, but also achieves a substantial improvement on clean text.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 16:12:04 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Qin", "Wenjie", ""], ["Li", "Xiang", ""], ["Sun", "Yuhui", ""], ["Xiong", "Deyi", ""], ["Cui", "Jianwei", ""], ["Wang", "Bin", ""]]}, {"id": "2012.08407", "submitter": "Yifan Zhang", "authors": "Yifan Zhang, Fan Yang, Marjan Hosseinia, Arjun Mukherjee", "title": "Multi-Aspect Sentiment Analysis with Latent Sentiment-Aspect Attribution", "comments": "8 pages, published in The 2020 IEEE/WIC/ACM International Joint\n  Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we introduce a new framework called the sentiment-aspect\nattribution module (SAAM). SAAM works on top of traditional neural networks and\nis designed to address the problem of multi-aspect sentiment classification and\nsentiment regression. The framework works by exploiting the correlations\nbetween sentence-level embedding features and variations of document-level\naspect rating scores. We demonstrate several variations of our framework on top\nof CNN and RNN based models. Experiments on a hotel review dataset and a beer\nreview dataset have shown SAAM can improve sentiment analysis performance over\ncorresponding base models. Moreover, because of the way our framework\nintuitively combines sentence-level scores into document-level scores, it is\nable to provide a deeper insight into data (e.g., semi-supervised sentence\naspect labeling). Hence, we end the paper with a detailed analysis that shows\nthe potential of our models for other applications such as sentiment snippet\nextraction.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 16:34:36 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Zhang", "Yifan", ""], ["Yang", "Fan", ""], ["Hosseinia", "Marjan", ""], ["Mukherjee", "Arjun", ""]]}, {"id": "2012.08478", "submitter": "Yao Fu", "authors": "Yao Fu, Chuanqi Tan, Mosha Chen, Songfang Huang, Fei Huang", "title": "Nested Named Entity Recognition with Partially-Observed TreeCRFs", "comments": "AAAI 2021 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Named entity recognition (NER) is a well-studied task in natural language\nprocessing. However, the widely-used sequence labeling framework is difficult\nto detect entities with nested structures. In this work, we view nested NER as\nconstituency parsing with partially-observed trees and model it with\npartially-observed TreeCRFs. Specifically, we view all labeled entity spans as\nobserved nodes in a constituency tree, and other spans as latent nodes. With\nthe TreeCRF we achieve a uniform way to jointly model the observed and the\nlatent nodes. To compute the probability of partial trees with partial\nmarginalization, we propose a variant of the Inside algorithm, the\n\\textsc{Masked Inside} algorithm, that supports different inference operations\nfor different nodes (evaluation for the observed, marginalization for the\nlatent, and rejection for nodes incompatible with the observed) with efficient\nparallelized implementation, thus significantly speeding up training and\ninference. Experiments show that our approach achieves the state-of-the-art\n(SOTA) F1 scores on the ACE2004, ACE2005 dataset, and shows comparable\nperformance to SOTA models on the GENIA dataset. Our approach is implemented\nat: \\url{https://github.com/FranxYao/Partially-Observed-TreeCRFs}.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 18:20:36 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Fu", "Yao", ""], ["Tan", "Chuanqi", ""], ["Chen", "Mosha", ""], ["Huang", "Songfang", ""], ["Huang", "Fei", ""]]}, {"id": "2012.08492", "submitter": "Muhao Chen", "authors": "Cunchao Zhu, Muhao Chen, Changjun Fan, Guangquan Cheng, Yan Zhan", "title": "Learning from History: Modeling Temporal Knowledge Graphs with\n  Sequential Copy-Generation Networks", "comments": "AAAI 2021; Updated in accordance with camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large knowledge graphs often grow to store temporal facts that model the\ndynamic relations or interactions of entities along the timeline. Since such\ntemporal knowledge graphs often suffer from incompleteness, it is important to\ndevelop time-aware representation learning models that help to infer the\nmissing temporal facts. While the temporal facts are typically evolving, it is\nobserved that many facts often show a repeated pattern along the timeline, such\nas economic crises and diplomatic activities. This observation indicates that a\nmodel could potentially learn much from the known facts appeared in history. To\nthis end, we propose a new representation learning model for temporal knowledge\ngraphs, namely CyGNet, based on a novel timeaware copy-generation mechanism.\nCyGNet is not only able to predict future facts from the whole entity\nvocabulary, but also capable of identifying facts with repetition and\naccordingly predicting such future facts with reference to the known facts in\nthe past. We evaluate the proposed method on the knowledge graph completion\ntask using five benchmark datasets. Extensive experiments demonstrate the\neffectiveness of CyGNet for predicting future facts with repetition as well as\nde novo fact prediction.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 18:38:03 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 10:03:52 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Zhu", "Cunchao", ""], ["Chen", "Muhao", ""], ["Fan", "Changjun", ""], ["Cheng", "Guangquan", ""], ["Zhan", "Yan", ""]]}, {"id": "2012.08508", "submitter": "David Ding", "authors": "David Ding, Felix Hill, Adam Santoro, Malcolm Reynolds, Matt Botvinick", "title": "Attention over learned object embeddings enables complex visual\n  reasoning", "comments": "22 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have achieved success in a wide array of perceptual tasks but\noften fail at tasks involving both perception and higher-level reasoning. On\nthese more challenging tasks, bespoke approaches (such as modular symbolic\ncomponents, independent dynamics models or semantic parsers) targeted towards\nthat specific type of task have typically performed better. The downside to\nthese targeted approaches, however, is that they can be more brittle than\ngeneral-purpose neural networks, requiring significant modification or even\nredesign according to the particular task at hand. Here, we propose a more\ngeneral neural-network-based approach to dynamic visual reasoning problems that\nobtains state-of-the-art performance on three different domains, in each case\noutperforming bespoke modular approaches tailored specifically to the task. Our\nmethod relies on learned object-centric representations, self-attention and\nself-supervised dynamics learning, and all three elements together are required\nfor strong performance to emerge. The success of this combination suggests that\nthere may be no need to trade off flexibility for performance on problems\ninvolving spatio-temporal or causal-style reasoning. With the right soft biases\nand learning objectives in a neural network we may be able to attain the best\nof both worlds.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 18:57:40 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 17:58:42 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Ding", "David", ""], ["Hill", "Felix", ""], ["Santoro", "Adam", ""], ["Reynolds", "Malcolm", ""], ["Botvinick", "Matt", ""]]}, {"id": "2012.08549", "submitter": "Subendhu Rongali", "authors": "Subendhu Rongali, Beiye Liu, Liwei Cai, Konstantine Arkoudas, Chengwei\n  Su, and Wael Hamza", "title": "Exploring Transfer Learning For End-to-End Spoken Language Understanding", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Voice Assistants such as Alexa, Siri, and Google Assistant typically use a\ntwo-stage Spoken Language Understanding pipeline; first, an Automatic Speech\nRecognition (ASR) component to process customer speech and generate text\ntranscriptions, followed by a Natural Language Understanding (NLU) component to\nmap transcriptions to an actionable hypothesis. An end-to-end (E2E) system that\ngoes directly from speech to a hypothesis is a more attractive option. These\nsystems were shown to be smaller, faster, and better optimized. However, they\nrequire massive amounts of end-to-end training data and in addition, don't take\nadvantage of the already available ASR and NLU training data.\n  In this work, we propose an E2E system that is designed to jointly train on\nmultiple speech-to-text tasks, such as ASR (speech-transcription) and SLU\n(speech-hypothesis), and text-to-text tasks, such as NLU (text-hypothesis). We\ncall this the Audio-Text All-Task (AT-AT) Model and we show that it beats the\nperformance of E2E models trained on individual tasks, especially ones trained\non limited data. We show this result on an internal music dataset and two\npublic datasets, FluentSpeech and SNIPS Audio, where we achieve\nstate-of-the-art results. Since our model can process both speech and text\ninput sequences and learn to predict a target sequence, it also allows us to do\nzero-shot E2E SLU by training on only text-hypothesis data (without any speech)\nfrom a new domain. We evaluate this ability of our model on the Facebook TOP\ndataset and set a new benchmark for zeroshot E2E performance. We will soon\nrelease the audio data collected for the TOP dataset for future research.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 19:02:15 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Rongali", "Subendhu", ""], ["Liu", "Beiye", ""], ["Cai", "Liwei", ""], ["Arkoudas", "Konstantine", ""], ["Su", "Chengwei", ""], ["Hamza", "Wael", ""]]}, {"id": "2012.08561", "submitter": "Kevin Clark", "authors": "Kevin Clark, Minh-Thang Luong, Quoc V. Le, Christopher D. Manning", "title": "Pre-Training Transformers as Energy-Based Cloze Models", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Electric, an energy-based cloze model for representation\nlearning over text. Like BERT, it is a conditional generative model of tokens\ngiven their contexts. However, Electric does not use masking or output a full\ndistribution over tokens that could occur in a context. Instead, it assigns a\nscalar energy score to each input token indicating how likely it is given its\ncontext. We train Electric using an algorithm based on noise-contrastive\nestimation and elucidate how this learning objective is closely related to the\nrecently proposed ELECTRA pre-training method. Electric performs well when\ntransferred to downstream tasks and is particularly effective at producing\nlikelihood scores for text: it re-ranks speech recognition n-best lists better\nthan language models and much faster than masked language models. Furthermore,\nit offers a clearer and more principled view of what ELECTRA learns during\npre-training.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 19:17:33 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Clark", "Kevin", ""], ["Luong", "Minh-Thang", ""], ["Le", "Quoc V.", ""], ["Manning", "Christopher D.", ""]]}, {"id": "2012.08673", "submitter": "Linjie Li", "authors": "Linjie Li, Zhe Gan, Jingjing Liu", "title": "A Closer Look at the Robustness of Vision-and-Language Pre-trained\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large-scale pre-trained multimodal transformers, such as ViLBERT and UNITER,\nhave propelled the state of the art in vision-and-language (V+L) research to a\nnew level. Although achieving impressive performance on standard tasks, to\ndate, it still remains unclear how robust these pre-trained models are. To\ninvestigate, we conduct a host of thorough evaluations on existing pre-trained\nmodels over 4 different types of V+L specific model robustness: (i) Linguistic\nVariation; (ii) Logical Reasoning; (iii) Visual Content Manipulation; and (iv)\nAnswer Distribution Shift. Interestingly, by standard model finetuning,\npre-trained V+L models already exhibit better robustness than many\ntask-specific state-of-the-art methods. To further enhance model robustness, we\npropose Mango, a generic and efficient approach that learns a Multimodal\nAdversarial Noise GeneratOr in the embedding space to fool pre-trained V+L\nmodels. Differing from previous studies focused on one specific type of\nrobustness, Mango is task-agnostic, and enables universal performance lift for\npre-trained models over diverse tasks designed to evaluate broad aspects of\nrobustness. Comprehensive experiments demonstrate that Mango achieves new state\nof the art on 7 out of 9 robustness benchmarks, surpassing existing methods by\na significant margin. As the first comprehensive study on V+L robustness, this\nwork puts robustness of pre-trained models into sharper focus, pointing new\ndirections for future study.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 23:41:42 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 23:51:50 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Li", "Linjie", ""], ["Gan", "Zhe", ""], ["Liu", "Jingjing", ""]]}, {"id": "2012.08695", "submitter": "Weizhou Shen", "authors": "Weizhou Shen, Junqing Chen, Xiaojun Quan and Zhixian Xie", "title": "DialogXL: All-in-One XLNet for Multi-Party Conversation Emotion\n  Recognition", "comments": "Accepted by AAAI 2021 main conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents our pioneering effort for emotion recognition in\nconversation (ERC) with pre-trained language models. Unlike regular documents,\nconversational utterances appear alternately from different parties and are\nusually organized as hierarchical structures in previous work. Such structures\nare not conducive to the application of pre-trained language models such as\nXLNet. To address this issue, we propose an all-in-one XLNet model, namely\nDialogXL, with enhanced memory to store longer historical context and\ndialog-aware self-attention to deal with the multi-party structures.\nSpecifically, we first modify the recurrence mechanism of XLNet from\nsegment-level to utterance-level in order to better model the conversational\ndata. Second, we introduce dialog-aware self-attention in replacement of the\nvanilla self-attention in XLNet to capture useful intra- and inter-speaker\ndependencies. Extensive experiments are conducted on four ERC benchmarks with\nmainstream models presented for comparison. The experimental results show that\nthe proposed model outperforms the baselines on all the datasets. Several other\nexperiments such as ablation study and error analysis are also conducted and\nthe results confirm the role of the critical modules of DialogXL.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 01:50:46 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Shen", "Weizhou", ""], ["Chen", "Junqing", ""], ["Quan", "Xiaojun", ""], ["Xie", "Zhixian", ""]]}, {"id": "2012.08743", "submitter": "Ngo Thi-Vinh", "authors": "Thi-Vinh Ngo, Phuong-Thai Nguyen, Thanh-Le Ha, Khac-Quy Dinh, Le-Minh\n  Nguyen", "title": "Improving Multilingual Neural Machine Translation For Low-Resource\n  Languages: French,English - Vietnamese", "comments": "The 3rd Workshop on Technologies for MT of Low Resource Languages\n  (LoResMT 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Prior works have demonstrated that a low-resource language pair can benefit\nfrom multilingual machine translation (MT) systems, which rely on many language\npairs' joint training. This paper proposes two simple strategies to address the\nrare word issue in multilingual MT systems for two low-resource language pairs:\nFrench-Vietnamese and English-Vietnamese. The first strategy is about dynamical\nlearning word similarity of tokens in the shared space among source languages\nwhile another one attempts to augment the translation ability of rare words\nthrough updating their embeddings during the training. Besides, we leverage\nmonolingual data for multilingual MT systems to increase the amount of\nsynthetic parallel corpora while dealing with the data sparsity problem. We\nhave shown significant improvements of up to +1.62 and +2.54 BLEU points over\nthe bilingual baseline systems for both language pairs and released our\ndatasets for the research community.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 04:43:43 GMT"}, {"version": "v2", "created": "Sat, 10 Jul 2021 12:12:42 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Ngo", "Thi-Vinh", ""], ["Nguyen", "Phuong-Thai", ""], ["Ha", "Thanh-Le", ""], ["Dinh", "Khac-Quy", ""], ["Nguyen", "Le-Minh", ""]]}, {"id": "2012.08773", "submitter": "Jiaxiang Hao", "authors": "Hao Jiaxiang", "title": "Building domain specific lexicon based on TikTok comment dataset", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the sentiment analysis task, predicting the sentiment tendency of a\nsentence is an important branch. Previous research focused more on sentiment\nanalysis in English, for example, analyzing the sentiment tendency of sentences\nbased on Valence, Arousal, Dominance of sentences. the emotional tendency is\ndifferent between the two languages. For example, the sentence order between\nChinese and English may present different emotions. This paper tried a method\nthat builds a domain-specific lexicon. In this way, the model can classify\nChinese words with emotional tendency. In this approach, based on the [13], an\nultra-dense space embedding table is trained through word embedding of Chinese\nTikTok review and emotional lexicon sources(seed words). The result of the\nmodel is a domain-specific lexicon, which presents the emotional tendency of\nwords. I collected Chinese TikTok comments as training data. By comparing The\ntraining results with the PCA method to evaluate the performance of the model\nin Chinese sentiment classification, the results show that the model has done\nwell in Chinese. The source code has released on\ngithub:https://github.com/h2222/douyin_comment_dataset\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 07:26:43 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Jiaxiang", "Hao", ""]]}, {"id": "2012.08789", "submitter": "Chen Xing", "authors": "Chen Xing, Wencong Xiao, Yong Li, Wei Lin", "title": "Focusing More on Conflicts with Mis-Predictions Helps Language\n  Pre-Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose to improve the effectiveness of language\npre-training methods with the help of mis-predictions during pre-training.\nNeglecting words in the input sentence that have conflicting semantics with\nmis-predictions is likely to be the reason of generating mis-predictions at\npre-training. Therefore, we hypothesis that mis-predictions during pre-training\ncan act as detectors of the ill focuses of the model. If we train the model to\nfocus more on the conflicts with the mis-predictions while focus less on the\nrest words in the input sentence, the mis-predictions can be more easily\ncorrected and the entire model could be better trained. Towards this end, we\nintroduce Focusing Less on Context of Mis-predictions(McMisP). In McMisP, we\nrecord the co-occurrence information between words to detect the conflicting\nwords with mis-predictions in an unsupervised way. Then McMisP uses such\ninformation to guide the attention modules when a mis-prediction occurs.\nSpecifically, several attention modules in the Transformer are optimized to\nfocus more on words in the input sentence that have co-occurred rarely with the\nmis-predictions and vice versa. Results show that McMisP significantly\nexpedites BERT and ELECTRA and improves their performances on downstream tasks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 08:21:51 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Xing", "Chen", ""], ["Xiao", "Wencong", ""], ["Li", "Yong", ""], ["Lin", "Wei", ""]]}, {"id": "2012.08790", "submitter": "Yichao Zhou", "authors": "Yichao Zhou, Yu Yan, Rujun Han, J. Harry Caufield, Kai-Wei Chang,\n  Yizhou Sun, Peipei Ping, and Wei Wang", "title": "Clinical Temporal Relation Extraction with Probabilistic Soft Logic\n  Regularization and Global Inference", "comments": "10 pages, 4 figures, 7 tables, accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a steady need in the medical community to precisely extract\nthe temporal relations between clinical events. In particular, temporal\ninformation can facilitate a variety of downstream applications such as case\nreport retrieval and medical question answering. Existing methods either\nrequire expensive feature engineering or are incapable of modeling the global\nrelational dependencies among the events. In this paper, we propose a novel\nmethod, Clinical Temporal ReLation Exaction with Probabilistic Soft Logic\nRegularization and Global Inference (CTRL-PG) to tackle the problem at the\ndocument level. Extensive experiments on two benchmark datasets, I2B2-2012 and\nTB-Dense, demonstrate that CTRL-PG significantly outperforms baseline methods\nfor temporal relation extraction.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 08:23:03 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Zhou", "Yichao", ""], ["Yan", "Yu", ""], ["Han", "Rujun", ""], ["Caufield", "J. Harry", ""], ["Chang", "Kai-Wei", ""], ["Sun", "Yizhou", ""], ["Ping", "Peipei", ""], ["Wang", "Wei", ""]]}, {"id": "2012.08844", "submitter": "Lihu Chen", "authors": "Lihu Chen, Ga\\\"el Varoquaux, Fabian M. Suchanek", "title": "A Lightweight Neural Model for Biomedical Entity Linking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Biomedical entity linking aims to map biomedical mentions, such as diseases\nand drugs, to standard entities in a given knowledge base. The specific\nchallenge in this context is that the same biomedical entity can have a wide\nrange of names, including synonyms, morphological variations, and names with\ndifferent word orderings. Recently, BERT-based methods have advanced the\nstate-of-the-art by allowing for rich representations of word sequences.\nHowever, they often have hundreds of millions of parameters and require heavy\ncomputing resources, which limits their applications in resource-limited\nscenarios. Here, we propose a lightweight neural method for biomedical entity\nlinking, which needs just a fraction of the parameters of a BERT model and much\nless computing resources. Our method uses a simple alignment layer with\nattention mechanisms to capture the variations between mention and entity\nnames. Yet, we show that our model is competitive with previous work on\nstandard evaluation benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 10:34:37 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 20:06:24 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Chen", "Lihu", ""], ["Varoquaux", "Ga\u00ebl", ""], ["Suchanek", "Fabian M.", ""]]}, {"id": "2012.08883", "submitter": "Lei Sha", "authors": "Lei Sha, Thomas Lukasiewicz", "title": "Multi-type Disentanglement without Adversarial Training", "comments": null, "journal-ref": "Thirty-Fifth AAAI Conference on Artificial Intelligence\n  (AAAI-2021)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Controlling the style of natural language by disentangling the latent space\nis an important step towards interpretable machine learning. After the latent\nspace is disentangled, the style of a sentence can be transformed by tuning the\nstyle representation without affecting other features of the sentence. Previous\nworks usually use adversarial training to guarantee that disentangled vectors\ndo not affect each other. However, adversarial methods are difficult to train.\nEspecially when there are multiple features (e.g., sentiment, or tense, which\nwe call style types in this paper), each feature requires a separate\ndiscriminator for extracting a disentangled style vector corresponding to that\nfeature. In this paper, we propose a unified distribution-controlling method,\nwhich provides each specific style value (the value of style types, e.g.,\npositive sentiment, or past tense) with a unique representation. This method\ncontributes a solid theoretical basis to avoid adversarial training in\nmulti-type disentanglement. We also propose multiple loss functions to achieve\na style-content disentanglement as well as a disentanglement among multiple\nstyle types. In addition, we observe that if two different style types always\nhave some specific style values that occur together in the dataset, they will\naffect each other when transferring the style values. We call this phenomenon\ntraining bias, and we propose a loss function to alleviate such training bias\nwhile disentangling multiple types. We conduct experiments on two datasets\n(Yelp service reviews and Amazon product reviews) to evaluate the\nstyle-disentangling effect and the unsupervised style transfer performance on\ntwo style types: sentiment and tense. The experimental results show the\neffectiveness of our model.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 11:47:18 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Sha", "Lei", ""], ["Lukasiewicz", "Thomas", ""]]}, {"id": "2012.08884", "submitter": "Lei Sha", "authors": "Lei Sha, Oana-Maria Camburu, and Thomas Lukasiewicz", "title": "Learning from the Best: Rationalizing Prediction by Adversarial\n  Information Calibration", "comments": null, "journal-ref": "Proceedings of the 35th AAAI Conference on Artificial\n  Intelligence, 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Explaining the predictions of AI models is paramount in safety-critical\napplications, such as in legal or medical domains. One form of explanation for\na prediction is an extractive rationale, i.e., a subset of features of an\ninstance that lead the model to give its prediction on the instance. Previous\nworks on generating extractive rationales usually employ a two-phase model: a\nselector that selects the most important features (i.e., the rationale)\nfollowed by a predictor that makes the prediction based exclusively on the\nselected features. One disadvantage of these works is that the main signal for\nlearning to select features comes from the comparison of the answers given by\nthe predictor and the ground-truth answers. In this work, we propose to squeeze\nmore information from the predictor via an information calibration method. More\nprecisely, we train two models jointly: one is a typical neural model that\nsolves the task at hand in an accurate but black-box manner, and the other is a\nselector-predictor model that additionally produces a rationale for its\nprediction. The first model is used as a guide to the second model. We use an\nadversarial-based technique to calibrate the information extracted by the two\nmodels such that the difference between them is an indicator of the missed or\nover-selected features. In addition, for natural language tasks, we propose to\nuse a language-model-based regularizer to encourage the extraction of fluent\nrationales. Experimental results on a sentiment analysis task as well as on\nthree tasks from the legal domain show the effectiveness of our approach to\nrationale extraction.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 11:54:15 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 10:07:27 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Sha", "Lei", ""], ["Camburu", "Oana-Maria", ""], ["Lukasiewicz", "Thomas", ""]]}, {"id": "2012.08919", "submitter": "Denisa A. O. Roberts", "authors": "Denisa A.O. Roberts", "title": "Multilingual Evidence Retrieval and Fact Verification to Combat Global\n  Disinformation: The Power of Polyglotism", "comments": "Accepted ECIR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article investigates multilingual evidence retrieval and fact\nverification as a step to combat global disinformation, a first effort of this\nkind, to the best of our knowledge. The goal is building multilingual systems\nthat retrieve in evidence-rich languages to verify claims in evidence-poor\nlanguages that are more commonly targeted by disinformation. To this end, our\nEnmBERT fact verification system shows evidence of transfer learning ability\nand 400 example mixed English-Romanian dataset is made available for\ncross-lingual transfer learning evaluation.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 13:10:56 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 23:02:58 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Roberts", "Denisa A. O.", ""]]}, {"id": "2012.08920", "submitter": "Kun Zhang", "authors": "Kun Zhang, Le Wu, Guangyi Lv, Meng Wang, Enhong Chen, Shulan Ruan", "title": "R$^2$-Net: Relation of Relation Learning Network for Sentence Semantic\n  Matching", "comments": "This paper has been accepted to/by AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentence semantic matching is one of the fundamental tasks in natural\nlanguage processing, which requires an agent to determine the semantic relation\namong input sentences. Recently, deep neural networks have achieved impressive\nperformance in this area, especially BERT. Despite the effectiveness of these\nmodels, most of them treat output labels as meaningless one-hot vectors,\nunderestimating the semantic information and guidance of relations that these\nlabels reveal, especially for tasks with a small number of labels. To address\nthis problem, we propose a Relation of Relation Learning Network (R2-Net) for\nsentence semantic matching. Specifically, we first employ BERT to encode the\ninput sentences from a global perspective. Then a CNN-based encoder is designed\nto capture keywords and phrase information from a local perspective. To fully\nleverage labels for better relation information extraction, we introduce a\nself-supervised relation of relation classification task for guiding R2-Net to\nconsider more about labels. Meanwhile, a triplet loss is employed to\ndistinguish the intra-class and inter-class relations in a finer granularity.\nEmpirical experiments on two sentence semantic matching tasks demonstrate the\nsuperiority of our proposed model. As a byproduct, we have released the codes\nto facilitate other researches.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 13:11:30 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Zhang", "Kun", ""], ["Wu", "Le", ""], ["Lv", "Guangyi", ""], ["Wang", "Meng", ""], ["Chen", "Enhong", ""], ["Ruan", "Shulan", ""]]}, {"id": "2012.08958", "submitter": "Made Nindyatama Nityasya", "authors": "Made Nindyatama Nityasya, Haryo Akbarianto Wibowo, Radityo Eko\n  Prasojo, Alham Fikri Aji", "title": "Costs to Consider in Adopting NLP for Your Business", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Natural Language Processing (NLP) have largely pushed deep\ntransformer-based models as the go-to state-of-the-art technique without much\nregard to the production and utilization cost. Companies planning to adopt\nthese methods into their business face difficulties because of the lack of\nmachine, data, and human resources to build them. We compare both the\nperformance and the cost of classical learning algorithms to the latest ones in\ncommon sequence and text labeling tasks. In our industrial datasets, we find\nthat classical models often perform on par with deep neural ones despite the\nlower cost. We show the trade-off between performance gain and the cost across\nthe models to give more insights for AI-pivoting business. Further, we call for\nmore research into low-cost models, especially for under-resourced languages.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 13:57:31 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 01:38:24 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Nityasya", "Made Nindyatama", ""], ["Wibowo", "Haryo Akbarianto", ""], ["Prasojo", "Radityo Eko", ""], ["Aji", "Alham Fikri", ""]]}, {"id": "2012.08987", "submitter": "Hanlei Zhang", "authors": "Hanlei Zhang, Hua Xu, Ting-En Lin, Rui Lyu", "title": "Discovering New Intents with Deep Aligned Clustering", "comments": "Accepted by AAAI 2021 (Main Track, Long Paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering new intents is a crucial task in dialogue systems. Most existing\nmethods are limited in transferring the prior knowledge from known intents to\nnew intents. They also have difficulties in providing high-quality supervised\nsignals to learn clustering-friendly features for grouping unlabeled intents.\nIn this work, we propose an effective method, Deep Aligned Clustering, to\ndiscover new intents with the aid of the limited known intent data. Firstly, we\nleverage a few labeled known intent samples as prior knowledge to pre-train the\nmodel. Then, we perform k-means to produce cluster assignments as\npseudo-labels. Moreover, we propose an alignment strategy to tackle the label\ninconsistency problem during clustering assignments. Finally, we learn the\nintent representations under the supervision of the aligned pseudo-labels. With\nan unknown number of new intents, we predict the number of intent categories by\neliminating low-confidence intent-wise clusters. Extensive experiments on two\nbenchmark datasets show that our method is more robust and achieves substantial\nimprovements over the state-of-the-art methods. The codes are released at\nhttps://github.com/thuiar/DeepAligned-Clustering.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 14:32:06 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 09:45:17 GMT"}, {"version": "v3", "created": "Mon, 21 Dec 2020 01:19:56 GMT"}, {"version": "v4", "created": "Tue, 22 Dec 2020 02:20:28 GMT"}, {"version": "v5", "created": "Tue, 9 Feb 2021 15:27:51 GMT"}, {"version": "v6", "created": "Fri, 19 Mar 2021 03:03:33 GMT"}, {"version": "v7", "created": "Mon, 22 Mar 2021 02:35:17 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Zhang", "Hanlei", ""], ["Xu", "Hua", ""], ["Lin", "Ting-En", ""], ["Lyu", "Rui", ""]]}, {"id": "2012.09005", "submitter": "Claudio Pinhanez", "authors": "Claudio Pinhanez, Paulo Cavalin, Victor Ribeiro, Heloisa Candello,\n  Julio Nogima, Ana Appel, Mauro Pichiliani, Maira Gatti de Bayser, Melina\n  Guerra, Henrique Ferreira, Gabriel Malfatti", "title": "Using Meta-Knowledge Mined from Identifiers to Improve Intent\n  Recognition in Neuro-Symbolic Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we explore the use of meta-knowledge embedded in intent\nidentifiers to improve intent recognition in conversational systems. As\nevidenced by the analysis of thousands of real-world chatbots and in interviews\nwith professional chatbot curators, developers and domain experts tend to\norganize the set of chatbot intents by identifying them using proto-taxonomies,\ni.e., meta-knowledge connecting high-level, symbolic concepts shared across\ndifferent intents. By using neuro-symbolic algorithms able to incorporate such\nproto-taxonomies to expand intent representation, we show that such mined\nmeta-knowledge can improve accuracy in intent recognition. In a dataset with\nintents and example utterances from hundreds of professional chatbots, we saw\nimprovements of more than 10% in the equal error rate (EER) in almost a third\nof the chatbots when we apply those algorithms in comparison to a baseline of\nthe same algorithms without the meta-knowledge. The meta-knowledge proved to be\neven more relevant in detecting out-of-scope utterances, decreasing the false\nacceptance rate (FAR) in more than 20\\% in about half of the chatbots. The\nexperiments demonstrate that such symbolic meta-knowledge structures can be\neffectively mined and used by neuro-symbolic algorithms, apparently by\nincorporating into the learning process higher-level structures of the problem\nbeing solved. Based on these results, we also discuss how the use of mined\nmeta-knowledge can be an answer for the challenge of knowledge acquisition in\nneuro-symbolic algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 15:04:50 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Pinhanez", "Claudio", ""], ["Cavalin", "Paulo", ""], ["Ribeiro", "Victor", ""], ["Candello", "Heloisa", ""], ["Nogima", "Julio", ""], ["Appel", "Ana", ""], ["Pichiliani", "Mauro", ""], ["de Bayser", "Maira Gatti", ""], ["Guerra", "Melina", ""], ["Ferreira", "Henrique", ""], ["Malfatti", "Gabriel", ""]]}, {"id": "2012.09035", "submitter": "Theodore Sumers", "authors": "Theodore R. Sumers, Mark K. Ho, Thomas L. Griffiths", "title": "Show or Tell? Demonstration is More Robust to Changes in Shared\n  Perception than Explanation", "comments": "7 pages, 4 figures. Proceedings for the 42nd Annual Meeting of the\n  Cognitive Science Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successful teaching entails a complex interaction between a teacher and a\nlearner. The teacher must select and convey information based on what they\nthink the learner perceives and believes. Teaching always involves misaligned\nbeliefs, but studies of pedagogy often focus on situations where teachers and\nlearners share perceptions. Nonetheless, a teacher and learner may not always\nexperience or attend to the same aspects of the environment. Here, we study how\nmisaligned perceptions influence communication. We hypothesize that the\nefficacy of different forms of communication depends on the shared perceptual\nstate between teacher and learner. We develop a cooperative teaching game to\ntest whether concrete mediums (demonstrations, or \"showing\") are more robust\nthan abstract ones (language, or \"telling\") when the teacher and learner are\nnot perceptually aligned. We find evidence that (1) language-based teaching is\nmore affected by perceptual misalignment, but (2) demonstration-based teaching\nis less likely to convey nuanced information. We discuss implications for human\npedagogy and machine learning.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 15:53:02 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Sumers", "Theodore R.", ""], ["Ho", "Mark K.", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "2012.09090", "submitter": "Prateek Chaudhry", "authors": "Prateek Chaudhry and Matthew Lease", "title": "You Are What You Tweet: Profiling Users by Past Tweets to Improve Hate\n  Speech Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hate speech detection research has predominantly focused on purely\ncontent-based methods, without exploiting any additional context. We briefly\ncritique pros and cons of this task formulation. We then investigate profiling\nusers by their past utterances as an informative prior to better predict\nwhether new utterances constitute hate speech. To evaluate this, we augment\nthree Twitter hate speech datasets with additional timeline data, then embed\nthis additional context into a strong baseline model. Promising results suggest\nmerit for further investigation, though analysis is complicated by differences\nin annotation schemes and processes, as well as Twitter API limitations and\ndata sharing policies.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 17:17:47 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Chaudhry", "Prateek", ""], ["Lease", "Matthew", ""]]}, {"id": "2012.09118", "submitter": "Martins Samuel Dogo", "authors": "Martins Samuel Dogo, Deepak P, Anna Jurek-Loughrey", "title": "Exploring Thematic Coherence in Fake News", "comments": "10 pages, 1 figure, to be published in Proceedings of the 8th\n  International Workshop on News Recommendation and Analytics (INRA 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spread of fake news remains a serious global issue; understanding and\ncurtailing it is paramount. One way of differentiating between deceptive and\ntruthful stories is by analyzing their coherence. This study explores the use\nof topic models to analyze the coherence of cross-domain news shared online.\nExperimental results on seven cross-domain datasets demonstrate that fake news\nshows a greater thematic deviation between its opening sentences and its\nremainder.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 18:01:04 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 01:56:29 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Dogo", "Martins Samuel", ""], ["P", "Deepak", ""], ["Jurek-Loughrey", "Anna", ""]]}, {"id": "2012.09123", "submitter": "Lei Cao", "authors": "Lei Cao, Huijun Zhang, and Ling Feng", "title": "Building and Using Personal Knowledge Graph to Improve Suicidal Ideation\n  Detection on Social Media", "comments": "Accepted to IEEE Transaction on Multimedia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A large number of individuals are suffering from suicidal ideation in the\nworld. There are a number of causes behind why an individual might suffer from\nsuicidal ideation. As the most popular platform for self-expression, emotion\nrelease, and personal interaction, individuals may exhibit a number of symptoms\nof suicidal ideation on social media. Nevertheless, challenges from both data\nand knowledge aspects remain as obstacles, constraining the social media-based\ndetection performance. Data implicitness and sparsity make it difficult to\ndiscover the inner true intentions of individuals based on their posts.\nInspired by psychological studies, we build and unify a high-level\nsuicide-oriented knowledge graph with deep neural networks for suicidal\nideation detection on social media. We further design a two-layered attention\nmechanism to explicitly reason and establish key risk factors to individual's\nsuicidal ideation. The performance study on microblog and Reddit shows that: 1)\nwith the constructed personal knowledge graph, the social media-based suicidal\nideation detection can achieve over 93% accuracy; and 2) among the six\ncategories of personal factors, post, personality, and experience are the top-3\nkey indicators. Under these categories, posted text, stress level, stress\nduration, posted image, and ruminant thinking contribute to one's suicidal\nideation detection.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 18:09:32 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Cao", "Lei", ""], ["Zhang", "Huijun", ""], ["Feng", "Ling", ""]]}, {"id": "2012.09157", "submitter": "Xinyan Zhao", "authors": "Xinyan Zhao, V.G.Vinod Vydiswaran", "title": "LIREx: Augmenting Language Inference with Relevant Explanation", "comments": "Accepted at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language explanations (NLEs) are a special form of data annotation in\nwhich annotators identify rationales (most significant text tokens) when\nassigning labels to data instances, and write out explanations for the labels\nin natural language based on the rationales. NLEs have been shown to capture\nhuman reasoning better, but not as beneficial for natural language inference\n(NLI). In this paper, we analyze two primary flaws in the way NLEs are\ncurrently used to train explanation generators for language inference tasks. We\nfind that the explanation generators do not take into account the variability\ninherent in human explanation of labels, and that the current explanation\ngeneration models generate spurious explanations. To overcome these\nlimitations, we propose a novel framework, LIREx, that incorporates both a\nrationale-enabled explanation generator and an instance selector to select only\nrelevant, plausible NLEs to augment NLI models. When evaluated on the\nstandardized SNLI data set, LIREx achieved an accuracy of 91.87%, an\nimprovement of 0.32 over the baseline and matching the best-reported\nperformance on the data set. It also achieves significantly better performance\nthan previous studies when transferred to the out-of-domain MultiNLI data set.\nQualitative analysis shows that LIREx generates flexible, faithful, and\nrelevant NLEs that allow the model to be more robust to spurious explanations.\nThe code is available at https://github.com/zhaoxy92/LIREx.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 18:49:29 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Zhao", "Xinyan", ""], ["Vydiswaran", "V. G. Vinod", ""]]}, {"id": "2012.09216", "submitter": "Te-Lin Wu", "authors": "Te-Lin Wu, Shikhar Singh, Sayan Paul, Gully Burns, Nanyun Peng", "title": "MELINDA: A Multimodal Dataset for Biomedical Experiment Method\n  Classification", "comments": "In The Thirty-Fifth AAAI Conference on Artificial Intelligence\n  (AAAI-21), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a new dataset, MELINDA, for Multimodal biomEdicaL experImeNt\nmethoD clAssification. The dataset is collected in a fully automated distant\nsupervision manner, where the labels are obtained from an existing curated\ndatabase, and the actual contents are extracted from papers associated with\neach of the records in the database. We benchmark various state-of-the-art NLP\nand computer vision models, including unimodal models which only take either\ncaption texts or images as inputs, and multimodal models. Extensive experiments\nand analysis show that multimodal models, despite outperforming unimodal ones,\nstill need improvements especially on a less-supervised way of grounding visual\nconcepts with languages, and better transferability to low resource domains. We\nrelease our dataset and the benchmarks to facilitate future research in\nmultimodal learning, especially to motivate targeted improvements for\napplications in scientific domains.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 19:11:36 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Wu", "Te-Lin", ""], ["Singh", "Shikhar", ""], ["Paul", "Sayan", ""], ["Burns", "Gully", ""], ["Peng", "Nanyun", ""]]}, {"id": "2012.09332", "submitter": "Tunazzina Islam", "authors": "Tunazzina Islam, Dan Goldwasser", "title": "Do You Do Yoga? Understanding Twitter Users' Types and Motivations using\n  Social and Textual Information", "comments": "accepted at 2021 IEEE 15th International Conference on Semantic\n  Computing (ICSC), 4 pages. Minor changes for camera-ready version. arXiv\n  admin note: text overlap with arXiv:2012.02939", "journal-ref": null, "doi": "10.1109/ICSC50631.2021.00067", "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging social media data to understand people's lifestyle choices is an\nexciting domain to explore but requires a multiview formulation of the data. In\nthis paper, we propose a joint embedding model based on the fusion of neural\nnetworks with attention mechanism by incorporating social and textual\ninformation of users to understand their activities and motivations. We use\nwell-being related tweets from Twitter, focusing on 'Yoga'. We demonstrate our\nmodel on two downstream tasks: (i) finding user type such as either\npractitioner or promotional (promoting yoga studio/gym), other; (ii) finding\nuser motivation i.e. health benefit, spirituality, love to tweet/retweet about\nyoga but do not practice yoga.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 00:15:13 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 05:20:56 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 15:50:42 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Islam", "Tunazzina", ""], ["Goldwasser", "Dan", ""]]}, {"id": "2012.09355", "submitter": "Jiho Noh", "authors": "Jiho Noh and Ramakanth Kavuluru", "title": "Literature Retrieval for Precision Medicine with Neural Matching and\n  Faceted Summarization", "comments": "Accepted to EMNLP 2020 Findings as Long Paper (11 page, 4 figures)", "journal-ref": null, "doi": "10.18653/v1/2020.findings-emnlp.304", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Information retrieval (IR) for precision medicine (PM) often involves looking\nfor multiple pieces of evidence that characterize a patient case. This\ntypically includes at least the name of a condition and a genetic variation\nthat applies to the patient. Other factors such as demographic attributes,\ncomorbidities, and social determinants may also be pertinent. As such, the\nretrieval problem is often formulated as ad hoc search but with multiple facets\n(e.g., disease, mutation) that may need to be incorporated. In this paper, we\npresent a document reranking approach that combines neural query-document\nmatching and text summarization toward such retrieval scenarios. Our\narchitecture builds on the basic BERT model with three specific components for\nreranking: (a). document-query matching (b). keyword extraction and (c).\nfacet-conditioned abstractive summarization. The outcomes of (b) and (c) are\nused to essentially transform a candidate document into a concise summary that\ncan be compared with the query at hand to compute a relevance score. Component\n(a) directly generates a matching score of a candidate document for a query.\nThe full architecture benefits from the complementary potential of\ndocument-query matching and the novel document transformation approach based on\nsummarization along PM facets. Evaluations using NIST's TREC-PM track datasets\n(2017--2019) show that our model achieves state-of-the-art performance. To\nfoster reproducibility, our code is made available here:\nhttps://github.com/bionlproc/text-summ-for-doc-retrieval.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 02:01:32 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Noh", "Jiho", ""], ["Kavuluru", "Ramakanth", ""]]}, {"id": "2012.09369", "submitter": "Ravi Sharma", "authors": "Ravi Sharma, Sri Divya Pagadala, Pratool Bharti, Sriram Chellappan,\n  Trine Schmidt and Raj Goyal", "title": "Assessing COVID-19 Impacts on College Students via Automated Processing\n  of Free-form Text", "comments": "8 pages, 5 figures, HEALTHINF - 14th International Conference on\n  Health Informatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we report experimental results on assessing the impact of\nCOVID-19 on college students by processing free-form texts generated by them.\nBy free-form texts, we mean textual entries posted by college students\n(enrolled in a four year US college) via an app specifically designed to assess\nand improve their mental health. Using a dataset comprising of more than 9000\ntextual entries from 1451 students collected over four months (split between\npre and post COVID-19), and established NLP techniques, a) we assess how topics\nof most interest to student change between pre and post COVID-19, and b) we\nassess the sentiments that students exhibit in each topic between pre and post\nCOVID-19. Our analysis reveals that topics like Education became noticeably\nless important to students post COVID-19, while Health became much more\ntrending. We also found that across all topics, negative sentiment among\nstudents post COVID-19 was much higher compared to pre-COVID-19. We expect our\nstudy to have an impact on policy-makers in higher education across several\nspectra, including college administrators, teachers, parents, and mental health\ncounselors.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 02:46:48 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Sharma", "Ravi", ""], ["Pagadala", "Sri Divya", ""], ["Bharti", "Pratool", ""], ["Chellappan", "Sriram", ""], ["Schmidt", "Trine", ""], ["Goyal", "Raj", ""]]}, {"id": "2012.09370", "submitter": "Zhendong Chu", "authors": "Zhendong Chu, Haiyun Jiang, Yanghua Xiao, Wei Wang", "title": "InSRL: A Multi-view Learning Framework Fusing Multiple Information\n  Sources for Distantly-supervised Relation Extraction", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distant supervision makes it possible to automatically label bags of\nsentences for relation extraction by leveraging knowledge bases, but suffers\nfrom the sparse and noisy bag issues. Additional information sources are\nurgently needed to supplement the training data and overcome these issues. In\nthis paper, we introduce two widely-existing sources in knowledge bases, namely\nentity descriptions, and multi-grained entity types to enrich the distantly\nsupervised data. We see information sources as multiple views and fusing them\nto construct an intact space with sufficient information. An end-to-end\nmulti-view learning framework is proposed for relation extraction via Intact\nSpace Representation Learning (InSRL), and the representations of single views\nare jointly learned simultaneously. Moreover, inner-view and cross-view\nattention mechanisms are used to highlight important information on different\nlevels on an entity-pair basis. The experimental results on a popular benchmark\ndataset demonstrate the necessity of additional information sources and the\neffectiveness of our framework. We will release the implementation of our model\nand dataset with multiple information sources after the anonymized review\nphase.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 02:49:46 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Chu", "Zhendong", ""], ["Jiang", "Haiyun", ""], ["Xiao", "Yanghua", ""], ["Wang", "Wei", ""]]}, {"id": "2012.09392", "submitter": "Sangwoo Mo", "authors": "Seung Jun Moon, Sangwoo Mo, Kimin Lee, Jaeho Lee, Jinwoo Shin", "title": "MASKER: Masked Keyword Regularization for Reliable Text Classification", "comments": "AAAI 2021. First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pre-trained language models have achieved state-of-the-art accuracies on\nvarious text classification tasks, e.g., sentiment analysis, natural language\ninference, and semantic textual similarity. However, the reliability of the\nfine-tuned text classifiers is an often underlooked performance criterion. For\ninstance, one may desire a model that can detect out-of-distribution (OOD)\nsamples (drawn far from training distribution) or be robust against domain\nshifts. We claim that one central obstacle to the reliability is the\nover-reliance of the model on a limited number of keywords, instead of looking\nat the whole context. In particular, we find that (a) OOD samples often contain\nin-distribution keywords, while (b) cross-domain samples may not always contain\nkeywords; over-relying on the keywords can be problematic for both cases. In\nlight of this observation, we propose a simple yet effective fine-tuning\nmethod, coined masked keyword regularization (MASKER), that facilitates\ncontext-based prediction. MASKER regularizes the model to reconstruct the\nkeywords from the rest of the words and make low-confidence predictions without\nenough context. When applied to various pre-trained language models (e.g.,\nBERT, RoBERTa, and ALBERT), we demonstrate that MASKER improves OOD detection\nand cross-domain generalization without degrading classification accuracy. Code\nis available at https://github.com/alinlab/MASKER.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 04:54:16 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Moon", "Seung Jun", ""], ["Mo", "Sangwoo", ""], ["Lee", "Kimin", ""], ["Lee", "Jaeho", ""], ["Shin", "Jinwoo", ""]]}, {"id": "2012.09411", "submitter": "Xiang Hu", "authors": "Xiang Hu, Zujie Wen, Yafang Wang, Xiaolong Li, Gerard de Melo", "title": "Interactive Question Clarification in Dialogue via Reinforcement\n  Learning", "comments": "COLING industry track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coping with ambiguous questions has been a perennial problem in real-world\ndialogue systems. Although clarification by asking questions is a common form\nof human interaction, it is hard to define appropriate questions to elicit more\nspecific intents from a user. In this work, we propose a reinforcement model to\nclarify ambiguous questions by suggesting refinements of the original query. We\nfirst formulate a collection partitioning problem to select a set of labels\nenabling us to distinguish potential unambiguous intents. We list the chosen\nlabels as intent phrases to the user for further confirmation. The selected\nlabel along with the original user query then serves as a refined query, for\nwhich a suitable response can more easily be identified. The model is trained\nusing reinforcement learning with a deep policy network. We evaluate our model\nbased on real-world user clicks and demonstrate significant improvements across\nseveral different experiments.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 06:38:04 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Hu", "Xiang", ""], ["Wen", "Zujie", ""], ["Wang", "Yafang", ""], ["Li", "Xiaolong", ""], ["de Melo", "Gerard", ""]]}, {"id": "2012.09446", "submitter": "Patrick Huber", "authors": "Patrick Huber and Giuseppe Carenini", "title": "Unsupervised Learning of Discourse Structures using a Tree Autoencoder", "comments": "Accepted to AAAI 2021, 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Discourse information, as postulated by popular discourse theories, such as\nRST and PDTB, has been shown to improve an increasing number of downstream NLP\ntasks, showing positive effects and synergies of discourse with important\nreal-world applications. While methods for incorporating discourse become more\nand more sophisticated, the growing need for robust and general discourse\nstructures has not been sufficiently met by current discourse parsers, usually\ntrained on small scale datasets in a strictly limited number of domains. This\nmakes the prediction for arbitrary tasks noisy and unreliable. The overall\nresulting lack of high-quality, high-quantity discourse trees poses a severe\nlimitation to further progress. In order the alleviate this shortcoming, we\npropose a new strategy to generate tree structures in a task-agnostic,\nunsupervised fashion by extending a latent tree induction framework with an\nauto-encoding objective. The proposed approach can be applied to any\ntree-structured objective, such as syntactic parsing, discourse parsing and\nothers. However, due to the especially difficult annotation process to generate\ndiscourse trees, we initially develop a method to generate larger and more\ndiverse discourse treebanks. In this paper we are inferring general tree\nstructures of natural text in multiple domains, showing promising results on a\ndiverse set of tasks.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 08:40:34 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Huber", "Patrick", ""], ["Carenini", "Giuseppe", ""]]}, {"id": "2012.09466", "submitter": "Minglun Han", "authors": "Minglun Han and Linhao Dong and Shiyu Zhou and Bo Xu", "title": "CIF-based Collaborative Decoding for End-to-end Contextual Speech\n  Recognition", "comments": "Accepted by ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end (E2E) models have achieved promising results on multiple speech\nrecognition benchmarks, and shown the potential to become the mainstream.\nHowever, the unified structure and the E2E training hamper injecting contextual\ninformation into them for contextual biasing. Though contextual LAS (CLAS)\ngives an excellent all-neural solution, the degree of biasing to given context\ninformation is not explicitly controllable. In this paper, we focus on\nincorporating context information into the continuous integrate-and-fire (CIF)\nbased model that supports contextual biasing in a more controllable fashion.\nSpecifically, an extra context processing network is introduced to extract\ncontextual embeddings, integrate acoustically relevant context information and\ndecode the contextual output distribution, thus forming a collaborative\ndecoding with the decoder of the CIF-based model. Evaluated on the named entity\nrich evaluation sets of HKUST/AISHELL-2, our method brings relative character\nerror rate (CER) reduction of 8.83%/21.13% and relative named entity character\nerror rate (NE-CER) reduction of 40.14%/51.50% when compared with a strong\nbaseline. Besides, it keeps the performance on original evaluation set without\ndegradation.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 09:40:11 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 07:42:44 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Han", "Minglun", ""], ["Dong", "Linhao", ""], ["Zhou", "Shiyu", ""], ["Xu", "Bo", ""]]}, {"id": "2012.09478", "submitter": "Bj\\\"orn Schuller", "authors": "Katrin D. Bartl-Pokorny, Florian B. Pokorny, Anton Batliner, Shahin\n  Amiriparian, Anastasia Semertzidou, Florian Eyben, Elena Kramer, Florian\n  Schmidt, Rainer Sch\\\"onweiler, Markus Wehler, Bj\\\"orn W. Schuller", "title": "The voice of COVID-19: Acoustic correlates of infection", "comments": "8 pages", "journal-ref": null, "doi": "10.1121/10.0005194", "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  COVID-19 is a global health crisis that has been affecting many aspects of\nour daily lives throughout the past year. The symptomatology of COVID-19 is\nheterogeneous with a severity continuum. A considerable proportion of symptoms\nare related to pathological changes in the vocal system, leading to the\nassumption that COVID-19 may also affect voice production. For the very first\ntime, the present study aims to investigate voice acoustic correlates of an\ninfection with COVID-19 on the basis of a comprehensive acoustic parameter set.\nWe compare 88 acoustic features extracted from recordings of the vowels /i:/,\n/e:/, /o:/, /u:/, and /a:/ produced by 11 symptomatic COVID-19 positive and 11\nCOVID-19 negative German-speaking participants. We employ the Mann-Whitney U\ntest and calculate effect sizes to identify features with the most prominent\ngroup differences. The mean voiced segment length and the number of voiced\nsegments per second yield the most important differences across all vowels\nindicating discontinuities in the pulmonic airstream during phonation in\nCOVID-19 positive participants. Group differences in the front vowels /i:/ and\n/e:/ are additionally reflected in the variation of the fundamental frequency\nand the harmonics-to-noise ratio, group differences in back vowels /o:/ and\n/u:/ in statistics of the Mel-frequency cepstral coefficients and the spectral\nslope. Findings of this study can be considered an important proof-of-concept\ncontribution for a potential future voice-based identification of individuals\ninfected with COVID-19.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 10:12:41 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Bartl-Pokorny", "Katrin D.", ""], ["Pokorny", "Florian B.", ""], ["Batliner", "Anton", ""], ["Amiriparian", "Shahin", ""], ["Semertzidou", "Anastasia", ""], ["Eyben", "Florian", ""], ["Kramer", "Elena", ""], ["Schmidt", "Florian", ""], ["Sch\u00f6nweiler", "Rainer", ""], ["Wehler", "Markus", ""], ["Schuller", "Bj\u00f6rn W.", ""]]}, {"id": "2012.09486", "submitter": "Kevin Denamganai", "authors": "Kevin Denamgana\\\"i and James Alfred Walker", "title": "ReferentialGym: A Nomenclature and Framework for Language Emergence &\n  Grounding in (Visual) Referential Games", "comments": "Accepted at 4th NeurIPS Workshop on Emergent Communication (EmeCom @\n  NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural languages are powerful tools wielded by human beings to communicate\ninformation and co-operate towards common goals. Their values lie in some main\nproperties like compositionality, hierarchy and recurrent syntax, which\ncomputational linguists have been researching the emergence of in artificial\nlanguages induced by language games. Only relatively recently, the AI community\nhas started to investigate language emergence and grounding working towards\nbetter human-machine interfaces. For instance, interactive/conversational AI\nassistants that are able to relate their vision to the ongoing conversation.\n  This paper provides two contributions to this research field. Firstly, a\nnomenclature is proposed to understand the main initiatives in studying\nlanguage emergence and grounding, accounting for the variations in assumptions\nand constraints. Secondly, a PyTorch based deep learning framework is\nintroduced, entitled ReferentialGym, which is dedicated to furthering the\nexploration of language emergence and grounding. By providing baseline\nimplementations of major algorithms and metrics, in addition to many different\nfeatures and approaches, ReferentialGym attempts to ease the entry barrier to\nthe field and provide the community with common implementations.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 10:22:15 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Denamgana\u00ef", "Kevin", ""], ["Walker", "James Alfred", ""]]}, {"id": "2012.09544", "submitter": "Siyuan Feng", "authors": "Siyuan Feng, Odette Scharenborg", "title": "The effectiveness of unsupervised subword modeling with autoregressive\n  and cross-lingual phone-aware networks", "comments": "18 pages (including 1 page as supplementary material), 13 figures.\n  Accepted for publication in IEEE Open Journal of Signal Processing (OJ-SP)", "journal-ref": null, "doi": "10.1109/OJSP.2021.3076914", "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study addresses unsupervised subword modeling, i.e., learning acoustic\nfeature representations that can distinguish between subword units of a\nlanguage. We propose a two-stage learning framework that combines\nself-supervised learning and cross-lingual knowledge transfer. The framework\nconsists of autoregressive predictive coding (APC) as the front-end and a\ncross-lingual deep neural network (DNN) as the back-end. Experiments on the ABX\nsubword discriminability task conducted with the Libri-light and ZeroSpeech\n2017 databases showed that our approach is competitive or superior to\nstate-of-the-art studies. Comprehensive and systematic analyses at the phoneme-\nand articulatory feature (AF)-level showed that our approach was better at\ncapturing diphthong than monophthong vowel information, while also differences\nin the amount of information captured for different types of consonants were\nobserved. Moreover, a positive correlation was found between the effectiveness\nof the back-end in capturing a phoneme's information and the quality of the\ncross-lingual phone labels assigned to the phoneme. The AF-level analysis\ntogether with t-SNE visualization results showed that the proposed approach is\nbetter than MFCC and APC features in capturing manner and place of articulation\ninformation, vowel height, and backness information. Taken together, the\nanalyses showed that the two stages in our approach are both effective in\ncapturing phoneme and AF information. Nevertheless, monophthong vowel\ninformation is less well captured than consonant information, which suggests\nthat future research should focus on improving capturing monophthong vowel\ninformation.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 12:33:49 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 09:50:15 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Feng", "Siyuan", ""], ["Scharenborg", "Odette", ""]]}, {"id": "2012.09647", "submitter": "Tian Lan", "authors": "Tian Lan, Xian-Ling Mao, Xiaoyan Gao, Wei Wei, Heyan Huang", "title": "Ultra-Fast, Low-Storage, Highly Effective Coarse-grained Selection in\n  Retrieval-based Chatbot by Using Deep Semantic Hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the coarse-grained selection module in retrieval-based chatbot.\nCoarse-grained selection is a basic module in a retrieval-based chatbot, which\nconstructs a rough candidate set from the whole database to speed up the\ninteraction with customers. So far, there are two kinds of approaches for\ncoarse-grained selection module: (1) sparse representation; (2) dense\nrepresentation. To the best of our knowledge, there is no systematic comparison\nbetween these two approaches in retrieval-based chatbots, and which kind of\nmethod is better in real scenarios is still an open question. In this paper, we\nfirst systematically compare these two methods from four aspects: (1)\neffectiveness; (2) index stoarge; (3) search time cost; (4) human evaluation.\nExtensive experiment results demonstrate that dense representation method\nsignificantly outperforms the sparse representation, but costs more time and\nstorage occupation. In order to overcome these fatal weaknesses of dense\nrepresentation method, we propose an ultra-fast, low-storage, and highly\neffective Deep Semantic Hashing Coarse-grained selection method, called DSHC\nmodel. Specifically, in our proposed DSHC model, a hashing optimizing module\nthat consists of two autoencoder models is stacked on a trained dense\nrepresentation model, and three loss functions are designed to optimize it. The\nhash codes provided by hashing optimizing module effectively preserve the rich\nsemantic and similarity information in dense vectors. Extensive experiment\nresults prove that, our proposed DSHC model can achieve much faster speed and\nlower storage than sparse representation, with limited performance loss\ncompared with dense representation. Besides, our source codes have been\npublicly released for future research.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 14:54:59 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 12:48:59 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Lan", "Tian", ""], ["Mao", "Xian-Ling", ""], ["Gao", "Xiaoyan", ""], ["Wei", "Wei", ""], ["Huang", "Heyan", ""]]}, {"id": "2012.09686", "submitter": "Nauros Romim", "authors": "Nauros Romim, Mosahed Ahmed, Hriteshwar Talukder, Md Saiful Islam", "title": "Hate Speech detection in the Bengali language: A dataset and its\n  baseline evaluation", "comments": "13 pages, 02 figures. To appear on International Joint Conference on\n  Advances in Computational Intelligence, 20-21 November 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social media sites such as YouTube and Facebook have become an integral part\nof everyone's life and in the last few years, hate speech in the social media\ncomment section has increased rapidly. Detection of hate speech on social media\nwebsites faces a variety of challenges including small imbalanced data sets,\nthe findings of an appropriate model and also the choice of feature analysis\nmethod. further more, this problem is more severe for the Bengali speaking\ncommunity due to the lack of gold standard labelled datasets. This paper\npresents a new dataset of 30,000 user comments tagged by crowd sourcing and\nvarified by experts. All the comments are collected from YouTube and Facebook\ncomment section and classified into seven categories: sports, entertainment,\nreligion, politics, crime, celebrity and TikTok & meme. A total of 50\nannotators annotated each comment three times and the majority vote was taken\nas the final annotation. Nevertheless, we have conducted base line experiments\nand several deep learning models along with extensive pre-trained Bengali word\nembedding such as Word2Vec, FastText and BengFastText on this dataset to\nfacilitate future research opportunities. The experiment illustrated that\nalthough all deep learning models performed well, SVM achieved the best result\nwith 87.5% accuracy. Our core contribution is to make this benchmark dataset\navailable and accessible to facilitate further research in the field of in the\nfield of Bengali hate speech detection.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 15:53:54 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Romim", "Nauros", ""], ["Ahmed", "Mosahed", ""], ["Talukder", "Hriteshwar", ""], ["Islam", "Md Saiful", ""]]}, {"id": "2012.09692", "submitter": "Marc Franco-Salvador", "authors": "Sanja \\v{S}tajner, Seren Yenikent and Marc Franco-Salvador", "title": "Benchmarking Automatic Detection of Psycholinguistic Characteristics for\n  Better Human-Computer Interaction", "comments": "39 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When two people pay attention to each other and are interested in what the\nother has to say or write, they almost instantly adapt their writing/speaking\nstyle to match the other. For a successful interaction with a user, chatbots\nand dialogue systems should be able to do the same. We propose a framework\nconsisting of five psycholinguistic textual characteristics for better\nhuman-computer interaction. We describe the annotation processes used for\ncollecting the data, and benchmark five binary classification tasks,\nexperimenting with different training sizes and model architectures. We perform\nexperiments in English, Spanish, German, Chinese, and Arabic. The best\narchitectures noticeably outperform several baselines and achieve\nmacro-averaged F1-scores between 72% and 96% depending on the language and the\ntask. Similar results are achieved even with a small amount of training data.\nThe proposed framework proved to be fairly easy to model for various languages\neven with small amount of manually annotated data if right architectures are\nused. At the same time, it showed potential for improving user satisfaction if\napplied in existing commercial chatbots.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 16:00:08 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 10:43:04 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2021 10:01:49 GMT"}, {"version": "v4", "created": "Wed, 13 Jan 2021 10:06:15 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["\u0160tajner", "Sanja", ""], ["Yenikent", "Seren", ""], ["Franco-Salvador", "Marc", ""]]}, {"id": "2012.09766", "submitter": "Sofian Chaybouti", "authors": "Sofian Chaybouti, Achraf Saghe, Aymen Shabou", "title": "MIX : a Multi-task Learning Approach to Solve Open-Domain Question\n  Answering", "comments": "7 pages, 7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce MIX : a multi-task deep learning approach to\nsolve Open-Domain Question Answering. First, we design our system as a\nmulti-stage pipeline made of 3 building blocks : a BM25-based Retriever, to\nreduce the search space; RoBERTa based Scorer and Extractor, to rank retrieved\nparagraphs and extract relevant spans of text respectively. Eventually, we\nfurther improve computational efficiency of our system to deal with the\nscalability challenge : thanks to multi-task learning, we parallelize the close\ntasks solved by the Scorer and the Extractor. Our system is on par with\nstate-of-the-art performances on the squad-open benchmark while being simpler\nconceptually.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 17:22:30 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 20:06:03 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Chaybouti", "Sofian", ""], ["Saghe", "Achraf", ""], ["Shabou", "Aymen", ""]]}, {"id": "2012.09807", "submitter": "Federico Bianchi", "authors": "Federico Bianchi and Bingqing Yu and Jacopo Tagliabue", "title": "BERT Goes Shopping: Comparing Distributional Models for Product\n  Representations", "comments": "Updated version. Published as a workshop paper at ECNLP 4 at\n  ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings (e.g., word2vec) have been applied successfully to eCommerce\nproducts through~\\textit{prod2vec}. Inspired by the recent performance\nimprovements on several NLP tasks brought by contextualized embeddings, we\npropose to transfer BERT-like architectures to eCommerce: our model --\n~\\textit{Prod2BERT} -- is trained to generate representations of products\nthrough masked session modeling. Through extensive experiments over multiple\nshops, different tasks, and a range of design choices, we systematically\ncompare the accuracy of~\\textit{Prod2BERT} and~\\textit{prod2vec} embeddings:\nwhile~\\textit{Prod2BERT} is found to be superior in several scenarios, we\nhighlight the importance of resources and hyperparameters in the best\nperforming models. Finally, we provide guidelines to practitioners for training\nembeddings under a variety of computational and data constraints.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 18:18:03 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 13:05:44 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Bianchi", "Federico", ""], ["Yu", "Bingqing", ""], ["Tagliabue", "Jacopo", ""]]}, {"id": "2012.09823", "submitter": "Magdalena Biesialska", "authors": "Magdalena Biesialska and Katarzyna Biesialska and Marta R.\n  Costa-juss\\`a", "title": "Continual Lifelong Learning in Natural Language Processing: A Survey", "comments": "COLING 2020", "journal-ref": "Proceedings of the 28th International Conference on Computational\n  Linguistics (COLING 2020), Barcelona, Spain (Online), pp. 6523--6541", "doi": "10.18653/v1/2020.coling-main.574", "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning (CL) aims to enable information systems to learn from a\ncontinuous data stream across time. However, it is difficult for existing deep\nlearning architectures to learn a new task without largely forgetting\npreviously acquired knowledge. Furthermore, CL is particularly challenging for\nlanguage learning, as natural language is ambiguous: it is discrete,\ncompositional, and its meaning is context-dependent. In this work, we look at\nthe problem of CL through the lens of various NLP tasks. Our survey discusses\nmajor challenges in CL and current methods applied in neural network models. We\nalso provide a critical review of the existing CL evaluation methods and\ndatasets in NLP. Finally, we present our outlook on future research directions.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 18:44:36 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Biesialska", "Magdalena", ""], ["Biesialska", "Katarzyna", ""], ["Costa-juss\u00e0", "Marta R.", ""]]}, {"id": "2012.09852", "submitter": "Hanrui Wang", "authors": "Hanrui Wang and Zhekai Zhang and Song Han", "title": "SpAtten: Efficient Sparse Attention Architecture with Cascade Token and\n  Head Pruning", "comments": "Published as a conference paper in HPCA 2021; 15 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The attention mechanism is becoming increasingly popular in Natural Language\nProcessing (NLP) applications, showing superior performance than convolutional\nand recurrent architectures. However, general-purpose platforms such as CPUs\nand GPUs are inefficient when performing attention inference due to complicated\ndata movement and low arithmetic intensity. Moreover, existing NN accelerators\nmainly focus on optimizing convolutional or recurrent models, and cannot\nefficiently support attention. In this paper, we present SpAtten, an efficient\nalgorithm-architecture co-design that leverages token sparsity, head sparsity,\nand quantization opportunities to reduce the attention computation and memory\naccess. Inspired by the high redundancy of human languages, we propose the\nnovel cascade token pruning to prune away unimportant tokens in the sentence.\nWe also propose cascade head pruning to remove unessential heads. Cascade\npruning is fundamentally different from weight pruning since there is no\ntrainable weight in the attention mechanism, and the pruned tokens and heads\nare selected on the fly. To efficiently support them on hardware, we design a\nnovel top-k engine to rank token and head importance scores with high\nthroughput. Furthermore, we propose progressive quantization that first fetches\nMSBs only and performs the computation; if the confidence is low, it fetches\nLSBs and recomputes the attention outputs, trading computation for memory\nreduction.\n  Extensive experiments on 30 benchmarks show that, on average, SpAtten reduces\nDRAM access by 10.0x with no accuracy loss, and achieves 1.6x, 3.0x, 162x, 347x\nspeedup, and 1,4x, 3.2x, 1193x, 4059x energy savings over A3 accelerator,\nMNNFast accelerator, TITAN Xp GPU, Xeon CPU, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 18:59:07 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 03:49:57 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Wang", "Hanrui", ""], ["Zhang", "Zhekai", ""], ["Han", "Song", ""]]}, {"id": "2012.09936", "submitter": "Stavroula Skylaki", "authors": "Stavroula Skylaki, Ali Oskooei, Omar Bari, Nadja Herger, Zac Kriegman\n  (Thomson Reuters Labs)", "title": "Named Entity Recognition in the Legal Domain using a Pointer Generator\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named Entity Recognition (NER) is the task of identifying and classifying\nnamed entities in unstructured text. In the legal domain, named entities of\ninterest may include the case parties, judges, names of courts, case numbers,\nreferences to laws etc. We study the problem of legal NER with noisy text\nextracted from PDF files of filed court cases from US courts. The \"gold\nstandard\" training data for NER systems provide annotation for each token of\nthe text with the corresponding entity or non-entity label. We work with only\npartially complete training data, which differ from the gold standard NER data\nin that the exact location of the entities in the text is unknown and the\nentities may contain typos and/or OCR mistakes. To overcome the challenges of\nour noisy training data, e.g. text extraction errors and/or typos and unknown\nlabel indices, we formulate the NER task as a text-to-text sequence generation\ntask and train a pointer generator network to generate the entities in the\ndocument rather than label them. We show that the pointer generator can be\neffective for NER in the absence of gold standard data and outperforms the\ncommon NER neural network architectures in long legal documents.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 21:10:34 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Skylaki", "Stavroula", "", "Thomson Reuters Labs"], ["Oskooei", "Ali", "", "Thomson Reuters Labs"], ["Bari", "Omar", "", "Thomson Reuters Labs"], ["Herger", "Nadja", "", "Thomson Reuters Labs"], ["Kriegman", "Zac", "", "Thomson Reuters Labs"]]}, {"id": "2012.09938", "submitter": "Pratyay Banerjee", "authors": "Pratyay Banerjee, Chitta Baral, Man Luo, Arindam Mitra, Kuntal Pal,\n  Tran C. Son, Neeraj Varshney", "title": "Can Transformers Reason About Effects of Actions?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A recent work has shown that transformers are able to \"reason\" with facts and\nrules in a limited setting where the rules are natural language expressions of\nconjunctions of conditions implying a conclusion. Since this suggests that\ntransformers may be used for reasoning with knowledge given in natural\nlanguage, we do a rigorous evaluation of this with respect to a common form of\nknowledge and its corresponding reasoning -- the reasoning about effects of\nactions. Reasoning about action and change has been a top focus in the\nknowledge representation subfield of AI from the early days of AI and more\nrecently it has been a highlight aspect in common sense question answering. We\nconsider four action domains (Blocks World, Logistics, Dock-Worker-Robots and a\nGeneric Domain) in natural language and create QA datasets that involve\nreasoning about the effects of actions in these domains. We investigate the\nability of transformers to (a) learn to reason in these domains and (b)\ntransfer that learning from the generic domains to the other domains.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 21:12:58 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Banerjee", "Pratyay", ""], ["Baral", "Chitta", ""], ["Luo", "Man", ""], ["Mitra", "Arindam", ""], ["Pal", "Kuntal", ""], ["Son", "Tran C.", ""], ["Varshney", "Neeraj", ""]]}, {"id": "2012.09966", "submitter": "Reut Apel", "authors": "Reut Apel, Ido Erev, Roi Reichart, and Moshe Tennenholtz", "title": "Predicting Decisions in Language Based Persuasion Games", "comments": "Under review for the Journal of Artificial Intelligence Research\n  (JAIR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sender-receiver interactions, and specifically persuasion games, are widely\nresearched in economic modeling and artificial intelligence, and serve as a\nsolid foundation for powerful applications. However, in the classic persuasion\ngames setting, the messages sent from the expert to the decision-maker are\nabstract or well-structured application-specific signals rather than natural\n(human) language messages, although natural language is a very common\ncommunication signal in real-world persuasion setups. This paper addresses the\nuse of natural language in persuasion games, exploring its impact on the\ndecisions made by the players and aiming to construct effective models for the\nprediction of these decisions. For this purpose, we conduct an online repeated\ninteraction experiment. At each trial of the interaction, an informed expert\naims to sell an uninformed decision-maker a vacation in a hotel, by sending her\na review that describes the hotel. While the expert is exposed to several\nscored reviews, the decision-maker observes only the single review sent by the\nexpert, and her payoff in case she chooses to take the hotel is a random draw\nfrom the review score distribution available to the expert only. The expert's\npayoff, in turn, depends on the number of times the decision-maker chooses the\nhotel. We consider a number of modeling approaches for this setup, differing\nfrom each other in the model type (deep neural network (DNN) vs. linear\nclassifier), the type of features used by the model (textual, behavioral or\nboth) and the source of the textual features (DNN-based vs. hand-crafted). Our\nresults demonstrate that given a prefix of the interaction sequence, our models\ncan predict the future decisions of the decision-maker, particularly when a\nsequential modeling approach and hand-crafted textual features are applied.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 22:52:47 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 09:08:52 GMT"}, {"version": "v3", "created": "Thu, 1 Jul 2021 18:27:09 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Apel", "Reut", ""], ["Erev", "Ido", ""], ["Reichart", "Roi", ""], ["Tennenholtz", "Moshe", ""]]}, {"id": "2012.10018", "submitter": "Chengqi Zhao", "authors": "Chengqi Zhao and Mingxuan Wang and Qianqian Dong and Rong Ye and Lei\n  Li", "title": "NeurST: Neural Speech Translation Toolkit", "comments": "Accepted by ACL 2021 (system demonstration)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NeurST is an open-source toolkit for neural speech translation. The toolkit\nmainly focuses on end-to-end speech translation, which is easy to use, modify,\nand extend to advanced speech translation research and products. NeurST aims at\nfacilitating the speech translation research for NLP researchers and building\nreliable benchmarks for this field. It provides step-by-step recipes for\nfeature extraction, data preprocessing, distributed training, and evaluation.\nIn this paper, we will introduce the framework design of NeurST and show\nexperimental results for different benchmark datasets, which can be regarded as\nreliable baselines for future research. The toolkit is publicly available at\nhttps://github.com/bytedance/neurst/ and we will continuously update the\nperformance of NeurST with other counterparts and studies at\nhttps://st-benchmark.github.io/.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 02:33:58 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 06:22:46 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 12:38:32 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Zhao", "Chengqi", ""], ["Wang", "Mingxuan", ""], ["Dong", "Qianqian", ""], ["Ye", "Rong", ""], ["Li", "Lei", ""]]}, {"id": "2012.10033", "submitter": "Jerry Zikun Chen", "authors": "Jerry Zikun Chen, Shi Yu, Haoran Wang", "title": "Exploring Fluent Query Reformulations with Text-to-Text Transformers and\n  Reinforcement Learning", "comments": "Workshop on the 9th Dialog System Technology Challenge (DSTC-9), AAAI\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Query reformulation aims to alter noisy or ambiguous text sequences into\ncoherent ones closer to natural language questions. This is to prevent errors\nfrom propagating in a client-facing pipeline and promote better communication\nwith users. Besides, it is crucial to maintain performance in downstream\nenvironments like question answering when rephrased queries are given as input.\nWe show that under the previous framework (AQA), attempts to alter RL\nalgorithms do not bring significant benefits to either reward acquisition or\nsequence fluency. Instead, we leverage a query-reformulating text-to-text\ntransformer (QRT5) and apply policy-based RL algorithms to further nudge this\nreformulator and obtain better answers downstream by generating\nreward-acquiring query trajectories. QRT5 shows better sample efficiency in RL\nto achieve the same level of QA performance as the previous approach. It can\ngenerate reformulations with more readability based on query well-formedness\nevaluations and can generalize to out-of-sample data. Our framework is\ndemonstrated to be flexible, allowing reward signals to be sourced from\ndifferent downstream environments such as intent classification.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 03:16:37 GMT"}, {"version": "v2", "created": "Sun, 4 Jul 2021 01:08:13 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Chen", "Jerry Zikun", ""], ["Yu", "Shi", ""], ["Wang", "Haoran", ""]]}, {"id": "2012.10052", "submitter": "Ayush Kaushal", "authors": "Ayush Kaushal and Tejas Vaidhya", "title": "Leveraging Event Specific and Chunk Span features to Extract COVID\n  Events from tweets", "comments": "EMNLP 2020 Workshop, Oral, 8 pages", "journal-ref": null, "doi": "10.18653/v1/2020.wnut-1.79", "report-no": null, "categories": "cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Twitter has acted as an important source of information during disasters and\npandemic, especially during the times of COVID-19. In this paper, we describe\nour system entry for WNUT 2020 Shared Task-3. The task was aimed at automating\nthe extraction of a variety of COVID-19 related events from Twitter, such as\nindividuals who recently contracted the virus, someone with symptoms who were\ndenied testing and believed remedies against the infection. The system consists\nof separate multi-task models for slot-filling subtasks and\nsentence-classification subtasks while leveraging the useful sentence-level\ninformation for the corresponding event. The system uses COVID-Twitter-Bert\nwith attention-weighted pooling of candidate slot-chunk features to capture the\nuseful information chunks. The system ranks 1st at the leader-board with F1 of\n0.6598, without using any ensembles or additional datasets. The code and\ntrained models are available at this https URL.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 04:49:32 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Kaushal", "Ayush", ""], ["Vaidhya", "Tejas", ""]]}, {"id": "2012.10055", "submitter": "Shota Horiguchi", "authors": "Shota Horiguchi, Paola Garcia, Yusuke Fujita, Shinji Watanabe, Kenji\n  Nagamatsu", "title": "End-to-End Speaker Diarization as Post-Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the utilization of an end-to-end diarization model as\npost-processing of conventional clustering-based diarization. Clustering-based\ndiarization methods partition frames into clusters of the number of speakers;\nthus, they typically cannot handle overlapping speech because each frame is\nassigned to one speaker. On the other hand, some end-to-end diarization methods\ncan handle overlapping speech by treating the problem as multi-label\nclassification. Although some methods can treat a flexible number of speakers,\nthey do not perform well when the number of speakers is large. To compensate\nfor each other's weakness, we propose to use a two-speaker end-to-end\ndiarization method as post-processing of the results obtained by a\nclustering-based method. We iteratively select two speakers from the results\nand update the results of the two speakers to improve the overlapped region.\nExperimental results show that the proposed algorithm consistently improved the\nperformance of the state-of-the-art methods across CALLHOME, AMI, and DIHARD II\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 05:31:07 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 15:56:02 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Horiguchi", "Shota", ""], ["Garcia", "Paola", ""], ["Fujita", "Yusuke", ""], ["Watanabe", "Shinji", ""], ["Nagamatsu", "Kenji", ""]]}, {"id": "2012.10063", "submitter": "Xiong Liu", "authors": "Xiong Liu, Luca A. Finelli, Greg L. Hersch, Iya Khalil", "title": "Attention-Based LSTM Network for COVID-19 Clinical Trial Parsing", "comments": null, "journal-ref": "2020 IEEE International Conference on Big Data (IEEE BigData 2020)", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 clinical trial design is a critical task in developing therapeutics\nfor the prevention and treatment of COVID-19. In this study, we apply a deep\nlearning approach to extract eligibility criteria variables from COVID-19\ntrials to enable quantitative analysis of trial design and optimization.\nSpecifically, we train attention-based bidirectional Long Short-Term Memory\n(Att-BiLSTM) models and use the optimal model to extract entities (i.e.,\nvariables) from the eligibility criteria of COVID-19 trials. We compare the\nperformance of Att-BiLSTM with traditional ontology-based method. The result on\na benchmark dataset shows that Att-BiLSTM outperforms the ontology model.\nAtt-BiLSTM achieves a precision of 0.942, recall of 0.810, and F1 of 0.871,\nwhile the ontology model only achieves a precision of 0.715, recall of 0.659,\nand F1 of 0.686. Our analyses demonstrate that Att-BiLSTM is an effective\napproach for characterizing patient populations in COVID-19 clinical trials.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 05:55:52 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Liu", "Xiong", ""], ["Finelli", "Luca A.", ""], ["Hersch", "Greg L.", ""], ["Khalil", "Iya", ""]]}, {"id": "2012.10074", "submitter": "Jianqiang Ma", "authors": "Jianqiang Ma, Zeyu Yan, Shuai Pang, Yang Zhang, Jianping Shen", "title": "Mention Extraction and Linking for SQL Query Generation", "comments": "Accepted in EMNLP 2020. This work is also known as \"IE-SQL:\n  Text-to-SQL as Information Extraction\"", "journal-ref": null, "doi": "10.18653/v1/2020.emnlp-main.563", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  On the WikiSQL benchmark, state-of-the-art text-to-SQL systems typically take\na slot-filling approach by building several dedicated models for each type of\nslots. Such modularized systems are not only complex butalso of limited\ncapacity for capturing inter-dependencies among SQL clauses. To solve these\nproblems, this paper proposes a novel extraction-linking approach, where a\nunified extractor recognizes all types of slot mentions appearing in the\nquestion sentence before a linker maps the recognized columns to the table\nschema to generate executable SQL queries. Trained with automatically generated\nannotations, the proposed method achieves the first place on the WikiSQL\nbenchmark.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 06:51:23 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Ma", "Jianqiang", ""], ["Yan", "Zeyu", ""], ["Pang", "Shuai", ""], ["Zhang", "Yang", ""], ["Shen", "Jianping", ""]]}, {"id": "2012.10120", "submitter": "Mana Iwata", "authors": "Mana Iwata, Yoshiro Matsuda, Yoshimasa Utsumi, Yoshitoshi Tanaka,\n  Kazuhide Nakata", "title": "Technical Progress Analysis Using a Dynamic Topic Model for Technical\n  Terms to Revise Patent Classification Codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Japanese patents are assigned a patent classification code, FI (File Index),\nthat is unique to Japan. FI is a subdivision of the IPC, an international\npatent classification code, that is related to Japanese technology. FIs are\nrevised to keep up with technological developments. These revisions have\nalready established more than 30,000 new FIs since 2006. However, these\nrevisions require a lot of time and workload. Moreover, these revisions are not\nautomated and are thus inefficient. Therefore, using machine learning to assist\nin the revision of patent classification codes (FI) will lead to improved\naccuracy and efficiency. This study analyzes patent documents from this new\nperspective of assisting in the revision of patent classification codes with\nmachine learning. To analyze time-series changes in patents, we used the\ndynamic topic model (DTM), which is an extension of the latent Dirichlet\nallocation (LDA). Also, unlike English, the Japanese language requires\nmorphological analysis. Patents contain many technical words that are not used\nin everyday life, so morphological analysis using a common dictionary is not\nsufficient. Therefore, we used a technique for extracting technical terms from\ntext. After extracting technical terms, we applied them to DTM. In this study,\nwe determined the technological progress of the lighting class F21 for 14 years\nand compared it with the actual revision of patent classification codes. In\nother words, we extracted technical terms from Japanese patents and applied DTM\nto determine the progress of Japanese technology. Then, we analyzed the results\nfrom the new perspective of revising patent classification codes with machine\nlearning. As a result, it was found that those whose topics were on the rise\nwere judged to be new technologies.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 09:24:01 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Iwata", "Mana", ""], ["Matsuda", "Yoshiro", ""], ["Utsumi", "Yoshimasa", ""], ["Tanaka", "Yoshitoshi", ""], ["Nakata", "Kazuhide", ""]]}, {"id": "2012.10187", "submitter": "Tianyi Liu", "authors": "Tianyi Liu, Xiangyu Lin, Weijia Jia, Mingliang Zhou, Wei Zhao", "title": "Regularized Attentive Capsule Network for Overlapped Relation Extraction", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distantly supervised relation extraction has been widely applied in knowledge\nbase construction due to its less requirement of human efforts. However, the\nautomatically established training datasets in distant supervision contain\nlow-quality instances with noisy words and overlapped relations, introducing\ngreat challenges to the accurate extraction of relations. To address this\nproblem, we propose a novel Regularized Attentive Capsule Network (RA-CapNet)\nto better identify highly overlapped relations in each informal sentence. To\ndiscover multiple relation features in an instance, we embed multi-head\nattention into the capsule network as the low-level capsules, where the\nsubtraction of two entities acts as a new form of relation query to select\nsalient features regardless of their positions. To further discriminate\noverlapped relation features, we devise disagreement regularization to\nexplicitly encourage the diversity among both multiple attention heads and\nlow-level capsules. Extensive experiments conducted on widely used datasets\nshow that our model achieves significant improvements in relation extraction.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 12:17:08 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Liu", "Tianyi", ""], ["Lin", "Xiangyu", ""], ["Jia", "Weijia", ""], ["Zhou", "Mingliang", ""], ["Zhao", "Wei", ""]]}, {"id": "2012.10209", "submitter": "Hanlei Zhang", "authors": "Hanlei Zhang, Hua Xu, Ting-En Lin", "title": "Deep Open Intent Classification with Adaptive Decision Boundary", "comments": "Accepted by AAAI 2021 (Main Track, Long Paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open intent classification is a challenging task in dialogue systems. On the\none hand, it should ensure the quality of known intent identification. On the\nother hand, it needs to detect the open (unknown) intent without prior\nknowledge. Current models are limited in finding the appropriate decision\nboundary to balance the performances of both known intents and the open intent.\nIn this paper, we propose a post-processing method to learn the adaptive\ndecision boundary (ADB) for open intent classification. We first utilize the\nlabeled known intent samples to pre-train the model. Then, we automatically\nlearn the adaptive spherical decision boundary for each known class with the\naid of well-trained features. Specifically, we propose a new loss function to\nbalance both the empirical risk and the open space risk. Our method does not\nneed open intent samples and is free from modifying the model architecture.\nMoreover, our approach is surprisingly insensitive with less labeled data and\nfewer known intents. Extensive experiments on three benchmark datasets show\nthat our method yields significant improvements compared with the\nstate-of-the-art methods. The codes are released at\nhttps://github.com/thuiar/Adaptive-Decision-Boundary.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 13:05:11 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 07:53:55 GMT"}, {"version": "v3", "created": "Wed, 23 Dec 2020 09:19:11 GMT"}, {"version": "v4", "created": "Thu, 11 Feb 2021 02:34:12 GMT"}, {"version": "v5", "created": "Thu, 1 Apr 2021 13:27:49 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Zhang", "Hanlei", ""], ["Xu", "Hua", ""], ["Lin", "Ting-En", ""]]}, {"id": "2012.10210", "submitter": "Tom Winterbottom", "authors": "Thomas Winterbottom, Sarah Xiao, Alistair McLean, Noura Al Moubayed", "title": "On Modality Bias in the TVQA Dataset", "comments": "10 pages, 4 Figures, 2 Tables, +Supp Mats, BMVC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  TVQA is a large scale video question answering (video-QA) dataset based on\npopular TV shows. The questions were specifically designed to require \"both\nvision and language understanding to answer\". In this work, we demonstrate an\ninherent bias in the dataset towards the textual subtitle modality. We infer\nsaid bias both directly and indirectly, notably finding that models trained\nwith subtitles learn, on-average, to suppress video feature contribution. Our\nresults demonstrate that models trained on only the visual information can\nanswer ~45% of the questions, while using only the subtitles achieves ~68%. We\nfind that a bilinear pooling based joint representation of modalities damages\nmodel performance by 9% implying a reliance on modality specific information.\nWe also show that TVQA fails to benefit from the RUBi modality bias reduction\ntechnique popularised in VQA. By simply improving text processing using BERT\nembeddings with the simple model first proposed for TVQA, we achieve\nstate-of-the-art results (72.13%) compared to the highly complex STAGE model\n(70.50%). We recommend a multimodal evaluation framework that can highlight\nbiases in models and isolate visual and textual reliant subsets of data. Using\nthis framework we propose subsets of TVQA that respond exclusively to either or\nboth modalities in order to facilitate multimodal modelling as TVQA originally\nintended.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 13:06:23 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Winterbottom", "Thomas", ""], ["Xiao", "Sarah", ""], ["McLean", "Alistair", ""], ["Moubayed", "Noura Al", ""]]}, {"id": "2012.10226", "submitter": "Omkar Gurjar", "authors": "Omkar Gurjar and Manish Gupta", "title": "Should I visit this place? Inclusion and Exclusion Phrase Mining from\n  Reviews", "comments": "Accepted at European Conference On Information Retrieval (ECIR) 2021;\n  8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although several automatic itinerary generation services have made travel\nplanning easy, often times travellers find themselves in unique situations\nwhere they cannot make the best out of their trip. Visitors differ in terms of\nmany factors such as suffering from a disability, being of a particular dietary\npreference, travelling with a toddler, etc. While most tourist spots are\nuniversal, others may not be inclusive for all. In this paper, we focus on the\nproblem of mining inclusion and exclusion phrases associated with 11 such\nfactors, from reviews related to a tourist spot. While existing work on tourism\ndata mining mainly focuses on structured extraction of trip related\ninformation, personalized sentiment analysis, and automatic itinerary\ngeneration, to the best of our knowledge this is the first work on\ninclusion/exclusion phrase mining from tourism reviews. Using a dataset of 2000\nreviews related to 1000 tourist spots, our broad level classifier provides a\nbinary overlap F1 of $\\sim$80 and $\\sim$82 to classify a phrase as inclusion or\nexclusion respectively. Further, our inclusion/exclusion classifier provides an\nF1 of $\\sim$98 and $\\sim$97 for 11-class inclusion and exclusion classification\nrespectively. We believe that our work can significantly improve the quality of\nan automatic itinerary generation service.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 13:43:13 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Gurjar", "Omkar", ""], ["Gupta", "Manish", ""]]}, {"id": "2012.10235", "submitter": "Zhihong Shao", "authors": "Zhihong Shao, Zitao Liu, Jiyong Zhang, Zhongqin Wu, Minlie Huang", "title": "AdvExpander: Generating Natural Language Adversarial Examples by\n  Expanding Text", "comments": "Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are vital to expose the vulnerability of machine\nlearning models. Despite the success of the most popular substitution-based\nmethods which substitutes some characters or words in the original examples,\nonly substitution is insufficient to uncover all robustness issues of models.\nIn this paper, we present AdvExpander, a method that crafts new adversarial\nexamples by expanding text, which is complementary to previous\nsubstitution-based methods. We first utilize linguistic rules to determine\nwhich constituents to expand and what types of modifiers to expand with. We\nthen expand each constituent by inserting an adversarial modifier searched from\na CVAE-based generative model which is pre-trained on a large scale corpus. To\nsearch adversarial modifiers, we directly search adversarial latent codes in\nthe latent space without tuning the pre-trained parameters. To ensure that our\nadversarial examples are label-preserving for text matching, we also constrain\nthe modifications with a heuristic rule. Experiments on three classification\ntasks verify the effectiveness of AdvExpander and the validity of our\nadversarial examples. AdvExpander crafts a new type of adversarial examples by\ntext expansion, thereby promising to reveal new robustness issues.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 13:50:17 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Shao", "Zhihong", ""], ["Liu", "Zitao", ""], ["Zhang", "Jiyong", ""], ["Wu", "Zhongqin", ""], ["Huang", "Minlie", ""]]}, {"id": "2012.10251", "submitter": "Saja Khaled Tawalbeh", "authors": "Saja AL-Tawalbeh, Mohammad AL-Smadi", "title": "A Benchmark Arabic Dataset for Commonsense Explanation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Language comprehension and commonsense knowledge validation by machines are\nchallenging tasks that are still under researched and evaluated for Arabic\ntext. In this paper, we present a benchmark Arabic dataset for commonsense\nexplanation. The dataset consists of Arabic sentences that does not make sense\nalong with three choices to select among them the one that explains why the\nsentence is false. Furthermore, this paper presents baseline results to assist\nand encourage the future evaluation of research in this field. The dataset is\ndistributed under the Creative Commons CC-BY-SA 4.0 license and can be found on\nGitHub\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 14:07:10 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["AL-Tawalbeh", "Saja", ""], ["AL-Smadi", "Mohammad", ""]]}, {"id": "2012.10267", "submitter": "Pham Quang Nhat Minh Mr", "authors": "Nguyen Manh Duc Tuan, Pham Quang Nhat Minh", "title": "ReINTEL Challenge 2020: A Multimodal Ensemble Model for Detecting\n  Unreliable Information on Vietnamese SNS", "comments": "5 pages, ReINTEL Task at VLSP 2020 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we present our methods for unrealiable information\nidentification task at VLSP 2020 ReINTEL Challenge. The task is to classify a\npiece of information into reliable or unreliable category. We propose a novel\nmultimodal ensemble model which combines two multimodal models to solve the\ntask. In each multimodal model, we combined feature representations acquired\nfrom three different data types: texts, images, and metadata. Multimodal\nfeatures are derived from three neural networks and fused for classification.\nExperimental results showed that our proposed multimodal ensemble model\nimproved against single models in term of ROC AUC score. We obtained 0.9445 AUC\nscore on the private test of the challenge.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 14:33:08 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Tuan", "Nguyen Manh Duc", ""], ["Minh", "Pham Quang Nhat", ""]]}, {"id": "2012.10271", "submitter": "Dimitrios Christofidellis", "authors": "Dimitrios Christofidellis, Matteo Manica, Leonidas Georgopoulos, Hans\n  Vandierendonck", "title": "Understood in Translation, Transformers for Domain Understanding", "comments": "4 figures, 7 tables, main text pages 8, appendix pages 6", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge acquisition is the essential first step of any Knowledge Graph (KG)\napplication. This knowledge can be extracted from a given corpus (KG generation\nprocess) or specified from an existing KG (KG specification process). Focusing\non domain specific solutions, knowledge acquisition is a labor intensive task\nusually orchestrated and supervised by subject matter experts. Specifically,\nthe domain of interest is usually manually defined and then the needed\ngeneration or extraction tools are utilized to produce the KG. Herein, we\npropose a supervised machine learning method, based on Transformers, for domain\ndefinition of a corpus. We argue why such automated definition of the domain's\nstructure is beneficial both in terms of construction time and quality of the\ngenerated graph. The proposed method is extensively validated on three public\ndatasets (WebNLG, NYT and DocRED) by comparing it with two reference methods\nbased on CNNs and RNNs models. The evaluation shows the efficiency of our model\nin this task. Focusing on scientific document understanding, we present a new\nhealth domain dataset based on publications extracted from PubMed and we\nsuccessfully utilize our method on this. Lastly, we demonstrate how this work\nlays the foundation for fully automated and unsupervised KG generation.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 14:47:47 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Christofidellis", "Dimitrios", ""], ["Manica", "Matteo", ""], ["Georgopoulos", "Leonidas", ""], ["Vandierendonck", "Hans", ""]]}, {"id": "2012.10275", "submitter": "Pham Quang Nhat Minh Mr", "authors": "Pham Quang Nhat Minh", "title": "An Empirical Study of Using Pre-trained BERT Models for Vietnamese\n  Relation Extraction Task at VLSP 2020", "comments": "6 pages, VLSP 2020 Workshop, Camera Ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we present an empirical study of using pre-trained BERT models\nfor the relation extraction task at the VLSP 2020 Evaluation Campaign. We\napplied two state-of-the-art BERT-based models: R-BERT and BERT model with\nentity starts. For each model, we compared two pre-trained BERT models:\nFPTAI/vibert and NlpHUST/vibert4news. We found that NlpHUST/vibert4news model\nsignificantly outperforms FPTAI/vibert for the Vietnamese relation extraction\ntask. Finally, we proposed an ensemble model that combines R-BERT and BERT with\nentity starts. Our proposed ensemble model slightly improved against two single\nmodels on the development data and the test data provided by the task\norganizers.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 14:53:49 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 09:39:14 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Minh", "Pham Quang Nhat", ""]]}, {"id": "2012.10285", "submitter": "Tom Winterbottom", "authors": "Thomas Winterbottom, Sarah Xiao, Alistair McLean, Noura Al Moubayed", "title": "Trying Bilinear Pooling in Video-QA", "comments": "16 Pages, 8 Figures, 4 Tables, +Supp Mats", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Bilinear pooling (BLP) refers to a family of operations recently developed\nfor fusing features from different modalities predominantly developed for VQA\nmodels. A bilinear (outer-product) expansion is thought to encourage models to\nlearn interactions between two feature spaces and has experimentally\noutperformed `simpler' vector operations (concatenation and\nelement-wise-addition/multiplication) on VQA benchmarks. Successive BLP\ntechniques have yielded higher performance with lower computational expense and\nare often implemented alongside attention mechanisms. However, despite\nsignificant progress in VQA, BLP methods have not been widely applied to more\nrecently explored video question answering (video-QA) tasks. In this paper, we\nbegin to bridge this research gap by applying BLP techniques to various\nvideo-QA benchmarks, namely: TVQA, TGIF-QA, Ego-VQA and MSVD-QA. We share our\nresults on the TVQA baseline model, and the recently proposed\nheterogeneous-memory-enchanced multimodal attention (HME) model. Our\nexperiments include both simply replacing feature concatenation in the existing\nmodels with BLP, and a modified version of the TVQA baseline to accommodate BLP\nwe name the `dual-stream' model. We find that our relatively simple integration\nof BLP does not increase, and mostly harms, performance on these video-QA\nbenchmarks. Using recently proposed theoretical multimodal fusion taxonomies,\nwe offer insight into why BLP-driven performance gain for video-QA benchmarks\nmay be more difficult to achieve than in earlier VQA models. We suggest a few\nadditional `best-practices' to consider when applying BLP to video-QA. We\nstress that video-QA models should carefully consider where the complex\nrepresentational potential from BLP is actually needed to avoid computational\nexpense on `redundant' fusion.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 15:01:50 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Winterbottom", "Thomas", ""], ["Xiao", "Sarah", ""], ["McLean", "Alistair", ""], ["Moubayed", "Noura Al", ""]]}, {"id": "2012.10289", "submitter": "Binny Mathew", "authors": "Binny Mathew, Punyajoy Saha, Seid Muhie Yimam, Chris Biemann, Pawan\n  Goyal, and Animesh Mukherjee", "title": "HateXplain: A Benchmark Dataset for Explainable Hate Speech Detection", "comments": "12 pages, 7 figues, 8 tables. Accepted at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hate speech is a challenging issue plaguing the online social media. While\nbetter models for hate speech detection are continuously being developed, there\nis little research on the bias and interpretability aspects of hate speech. In\nthis paper, we introduce HateXplain, the first benchmark hate speech dataset\ncovering multiple aspects of the issue. Each post in our dataset is annotated\nfrom three different perspectives: the basic, commonly used 3-class\nclassification (i.e., hate, offensive or normal), the target community (i.e.,\nthe community that has been the victim of hate speech/offensive speech in the\npost), and the rationales, i.e., the portions of the post on which their\nlabelling decision (as hate, offensive or normal) is based. We utilize existing\nstate-of-the-art models and observe that even models that perform very well in\nclassification do not score high on explainability metrics like model\nplausibility and faithfulness. We also observe that models, which utilize the\nhuman rationales for training, perform better in reducing unintended bias\ntowards target communities. We have made our code and dataset public at\nhttps://github.com/punyajoy/HateXplain\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 15:12:14 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Mathew", "Binny", ""], ["Saha", "Punyajoy", ""], ["Yimam", "Seid Muhie", ""], ["Biemann", "Chris", ""], ["Goyal", "Pawan", ""], ["Mukherjee", "Animesh", ""]]}, {"id": "2012.10309", "submitter": "Peng Shi", "authors": "Peng Shi, Patrick Ng, Zhiguo Wang, Henghui Zhu, Alexander Hanbo Li,\n  Jun Wang, Cicero Nogueira dos Santos, Bing Xiang", "title": "Learning Contextual Representations for Semantic Parsing with\n  Generation-Augmented Pre-Training", "comments": "Accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most recently, there has been significant interest in learning contextual\nrepresentations for various NLP tasks, by leveraging large scale text corpora\nto train large neural language models with self-supervised learning objectives,\nsuch as Masked Language Model (MLM). However, based on a pilot study, we\nobserve three issues of existing general-purpose language models when they are\napplied to text-to-SQL semantic parsers: fail to detect column mentions in the\nutterances, fail to infer column mentions from cell values, and fail to compose\ncomplex SQL queries. To mitigate these issues, we present a model pre-training\nframework, Generation-Augmented Pre-training (GAP), that jointly learns\nrepresentations of natural language utterances and table schemas by leveraging\ngeneration models to generate pre-train data. GAP MODEL is trained on 2M\nutterance-schema pairs and 30K utterance-schema-SQL triples, whose utterances\nare produced by generative models. Based on experimental results, neural\nsemantic parsers that leverage GAP MODEL as a representation encoder obtain new\nstate-of-the-art results on both SPIDER and CRITERIA-TO-SQL benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 15:53:50 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Shi", "Peng", ""], ["Ng", "Patrick", ""], ["Wang", "Zhiguo", ""], ["Zhu", "Henghui", ""], ["Li", "Alexander Hanbo", ""], ["Wang", "Jun", ""], ["Santos", "Cicero Nogueira dos", ""], ["Xiang", "Bing", ""]]}, {"id": "2012.10582", "submitter": "Yining Hong", "authors": "Yining Hong, Qing Li, Daniel Ciao, Siyuan Haung, Song-Chun Zhu", "title": "Learning by Fixing: Solving Math Word Problems with Weak Supervision", "comments": null, "journal-ref": "AAAI2021", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous neural solvers of math word problems (MWPs) are learned with full\nsupervision and fail to generate diverse solutions. In this paper, we address\nthis issue by introducing a \\textit{weakly-supervised} paradigm for learning\nMWPs. Our method only requires the annotations of the final answers and can\ngenerate various solutions for a single problem. To boost weakly-supervised\nlearning, we propose a novel \\textit{learning-by-fixing} (LBF) framework, which\ncorrects the misperceptions of the neural network via symbolic reasoning.\nSpecifically, for an incorrect solution tree generated by the neural network,\nthe \\textit{fixing} mechanism propagates the error from the root node to the\nleaf nodes and infers the most probable fix that can be executed to get the\ndesired answer. To generate more diverse solutions, \\textit{tree\nregularization} is applied to guide the efficient shrinkage and exploration of\nthe solution space, and a \\textit{memory buffer} is designed to track and save\nthe discovered various fixes for each problem. Experimental results on the\nMath23K dataset show the proposed LBF framework significantly outperforms\nreinforcement learning baselines in weakly-supervised learning. Furthermore, it\nachieves comparable top-1 and much better top-3/5 answer accuracies than\nfully-supervised methods, demonstrating its strength in producing diverse\nsolutions.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 03:10:21 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Hong", "Yining", ""], ["Li", "Qing", ""], ["Ciao", "Daniel", ""], ["Haung", "Siyuan", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "2012.10586", "submitter": "Jianze Liang", "authors": "Jianze Liang, Chengqi Zhao, Mingxuan Wang, Xipeng Qiu, Lei Li", "title": "Finding Sparse Structures for Domain Specific Neural Machine Translation", "comments": "Accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation often adopts the fine-tuning approach to adapt to\nspecific domains. However, nonrestricted fine-tuning can easily degrade on the\ngeneral domain and over-fit to the target domain. To mitigate the issue, we\npropose Prune-Tune, a novel domain adaptation method via gradual pruning. It\nlearns tiny domain-specific sub-networks during fine-tuning on new domains.\nPrune-Tune alleviates the over-fitting and the degradation problem without\nmodel modification. Furthermore, Prune-Tune is able to sequentially learn a\nsingle network with multiple disjoint domain-specific sub-networks for multiple\ndomains. Empirical experiment results show that Prune-Tune outperforms several\nstrong competitors in the target domain test set without sacrificing the\nquality on the general domain in both single and multi-domain settings. The\nsource code and data are available at https://github.com/ohlionel/Prune-Tune.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 03:33:27 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 16:57:21 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Liang", "Jianze", ""], ["Zhao", "Chengqi", ""], ["Wang", "Mingxuan", ""], ["Qiu", "Xipeng", ""], ["Li", "Lei", ""]]}, {"id": "2012.10595", "submitter": "Jaehun Jung", "authors": "Jaehun Jung, Jinhong Jung, U Kang", "title": "T-GAP: Learning to Walk across Time for Temporal Knowledge Graph\n  Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Temporal knowledge graphs (TKGs) inherently reflect the transient nature of\nreal-world knowledge, as opposed to static knowledge graphs. Naturally,\nautomatic TKG completion has drawn much research interests for a more realistic\nmodeling of relational reasoning. However, most of the existing mod-els for TKG\ncompletion extend static KG embeddings that donot fully exploit TKG structure,\nthus lacking in 1) account-ing for temporally relevant events already residing\nin the lo-cal neighborhood of a query, and 2) path-based inference that\nfacilitates multi-hop reasoning and better interpretability. In this paper, we\npropose T-GAP, a novel model for TKG completion that maximally utilizes both\ntemporal information and graph structure in its encoder and decoder. T-GAP\nencodes query-specific substructure of TKG by focusing on the temporal\ndisplacement between each event and the query times-tamp, and performs\npath-based inference by propagating attention through the graph. Our empirical\nexperiments demonstrate that T-GAP not only achieves superior performance\nagainst state-of-the-art baselines, but also competently generalizes to queries\nwith unseen timestamps. Through extensive qualitative analyses, we also show\nthat T-GAP enjoys from transparent interpretability, and follows human\nintuition in its reasoning process.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 04:45:32 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Jung", "Jaehun", ""], ["Jung", "Jinhong", ""], ["Kang", "U", ""]]}, {"id": "2012.10608", "submitter": "Jiacheng Ye", "authors": "Tao Gui, Jiacheng Ye, Qi Zhang, Zhengyan Li, Zichu Fei, Yeyun Gong and\n  Xuanjing Huang", "title": "Uncertainty-Aware Label Refinement for Sequence Labeling", "comments": "Accepted by EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Conditional random fields (CRF) for label decoding has become ubiquitous in\nsequence labeling tasks. However, the local label dependencies and inefficient\nViterbi decoding have always been a problem to be solved. In this work, we\nintroduce a novel two-stage label decoding framework to model long-term label\ndependencies, while being much more computationally efficient. A base model\nfirst predicts draft labels, and then a novel two-stream self-attention model\nmakes refinements on these draft predictions based on long-range label\ndependencies, which can achieve parallel decoding for a faster prediction. In\naddition, in order to mitigate the side effects of incorrect draft labels,\nBayesian neural networks are used to indicate the labels with a high\nprobability of being wrong, which can greatly assist in preventing error\npropagation. The experimental results on three sequence labeling benchmarks\ndemonstrated that the proposed method not only outperformed the CRF-based\nmethods but also greatly accelerated the inference process.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 06:56:59 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Gui", "Tao", ""], ["Ye", "Jiacheng", ""], ["Zhang", "Qi", ""], ["Li", "Zhengyan", ""], ["Fei", "Zichu", ""], ["Gong", "Yeyun", ""], ["Huang", "Xuanjing", ""]]}, {"id": "2012.10668", "submitter": "Jean-Philippe Bernardy", "authors": "Jean-Philippe Bernardy, Stergios Chatzikyriakidis", "title": "FraCaS: Temporal Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we propose an implementation of temporal semantics which is\nsuitable for inference problems. This implementation translates syntax trees to\nlogical formulas, suitable for consumption by the Coq proof assistant. We\nsupport several phenomena including: temporal references, temporal adverbs,\naspectual classes and progressives. We apply these semantics to the complete\nFraCaS testsuite. We obtain an accuracy of 81 percent overall and 73 percent\nfor problems explicitly marked as related to temporal reference.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 11:55:46 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Bernardy", "Jean-Philippe", ""], ["Chatzikyriakidis", "Stergios", ""]]}, {"id": "2012.10776", "submitter": "Kevin Denamgana\\\"i", "authors": "Kevin Denamgana\\\"i and James Alfred Walker", "title": "On (Emergent) Systematic Generalisation and Compositionality in Visual\n  Referential Games with Straight-Through Gumbel-Softmax Estimator", "comments": "Accepted at 4th NeurIPS Workshop on Emergent Communication (EmeCom @\n  NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The drivers of compositionality in artificial languages that emerge when two\n(or more) agents play a non-visual referential game has been previously\ninvestigated using approaches based on the REINFORCE algorithm and the (Neural)\nIterated Learning Model. Following the more recent introduction of the\n\\textit{Straight-Through Gumbel-Softmax} (ST-GS) approach, this paper\ninvestigates to what extent the drivers of compositionality identified so far\nin the field apply in the ST-GS context and to what extent do they translate\ninto (emergent) systematic generalisation abilities, when playing a visual\nreferential game. Compositionality and the generalisation abilities of the\nemergent languages are assessed using topographic similarity and zero-shot\ncompositional tests. Firstly, we provide evidence that the test-train split\nstrategy significantly impacts the zero-shot compositional tests when dealing\nwith visual stimuli, whilst it does not when dealing with symbolic ones.\nSecondly, empirical evidence shows that using the ST-GS approach with small\nbatch sizes and an overcomplete communication channel improves compositionality\nin the emerging languages. Nevertheless, while shown robust with symbolic\nstimuli, the effect of the batch size is not so clear-cut when dealing with\nvisual stimuli. Our results also show that not all overcomplete communication\nchannels are created equal. Indeed, while increasing the maximum sentence\nlength is found to be beneficial to further both compositionality and\ngeneralisation abilities, increasing the vocabulary size is found detrimental.\nFinally, a lack of correlation between the language compositionality at\ntraining-time and the agents' generalisation abilities is observed in the\ncontext of discriminative referential games with visual stimuli. This is\nsimilar to previous observations in the field using the generative variant with\nsymbolic stimuli.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 20:40:09 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Denamgana\u00ef", "Kevin", ""], ["Walker", "James Alfred", ""]]}, {"id": "2012.10813", "submitter": "Kaixin Ma", "authors": "Yikang Li, Pulkit Goel, Varsha Kuppur Rajendra, Har Simrat Singh,\n  Jonathan Francis, Kaixin Ma, Eric Nyberg, Alessandro Oltramari", "title": "Lexically-constrained Text Generation through Commonsense Knowledge\n  Extraction and Injection", "comments": "AAAI-CSKG 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional text generation has been a challenging task that is yet to see\nhuman-level performance from state-of-the-art models. In this work, we\nspecifically focus on the Commongen benchmark, wherein the aim is to generate a\nplausible sentence for a given set of input concepts. Despite advances in other\ntasks, large pre-trained language models that are fine-tuned on this dataset\noften produce sentences that are syntactically correct but qualitatively\ndeviate from a human understanding of common sense. Furthermore, generated\nsequences are unable to fulfill such lexical requirements as matching\npart-of-speech and full concept coverage. In this paper, we explore how\ncommonsense knowledge graphs can enhance model performance, with respect to\ncommonsense reasoning and lexically-constrained decoding. We propose strategies\nfor enhancing the semantic correctness of the generated text, which we\naccomplish through: extracting commonsense relations from Conceptnet, injecting\nthese relations into the Unified Language Model (UniLM) through attention\nmechanisms, and enforcing the aforementioned lexical requirements through\noutput constraints. By performing several ablations, we find that commonsense\ninjection enables the generation of sentences that are more aligned with human\nunderstanding, while remaining compliant with lexical requirements.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 23:23:40 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Li", "Yikang", ""], ["Goel", "Pulkit", ""], ["Rajendra", "Varsha Kuppur", ""], ["Singh", "Har Simrat", ""], ["Francis", "Jonathan", ""], ["Ma", "Kaixin", ""], ["Nyberg", "Eric", ""], ["Oltramari", "Alessandro", ""]]}, {"id": "2012.10821", "submitter": "Sebastiano Vascon Mr", "authors": "Sebastiano Vascon, Sinem Aslan, Gianluca Bigaglia, Lorenzo Giudice,\n  Marcello Pelillo", "title": "Transductive Visual Verb Sense Disambiguation", "comments": "Accepted at the IEEE Workshop on Application of Computer Vision 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verb Sense Disambiguation is a well-known task in NLP, the aim is to find the\ncorrect sense of a verb in a sentence. Recently, this problem has been extended\nin a multimodal scenario, by exploiting both textual and visual features of\nambiguous verbs leading to a new problem, the Visual Verb Sense Disambiguation\n(VVSD). Here, the sense of a verb is assigned considering the content of an\nimage paired with it rather than a sentence in which the verb appears.\nAnnotating a dataset for this task is more complex than textual disambiguation,\nbecause assigning the correct sense to a pair of $<$image, verb$>$ requires\nboth non-trivial linguistic and visual skills. In this work, differently from\nthe literature, the VVSD task will be performed in a transductive\nsemi-supervised learning (SSL) setting, in which only a small amount of labeled\ninformation is required, reducing tremendously the need for annotated data. The\ndisambiguation process is based on a graph-based label propagation method which\ntakes into account mono or multimodal representations for $<$image, verb$>$\npairs. Experiments have been carried out on the recently published dataset\nVerSe, the only available dataset for this task. The achieved results\noutperform the current state-of-the-art by a large margin while using only a\nsmall fraction of labeled samples per sense. Code available:\nhttps://github.com/GiBg1aN/TVVSD.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 01:07:30 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Vascon", "Sebastiano", ""], ["Aslan", "Sinem", ""], ["Bigaglia", "Gianluca", ""], ["Giudice", "Lorenzo", ""], ["Pelillo", "Marcello", ""]]}, {"id": "2012.10824", "submitter": "Jian Liu", "authors": "Jian Liu, Lei Gao, Sujie Guo, Rui Ding, Xin Huang, Long Ye, Qinghua\n  Meng, Asef Nazari and Dhananjay Thiruvady", "title": "A hybrid deep-learning approach for complex biochemical named entity\n  recognition", "comments": "21 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity recognition (NER) of chemicals and drugs is a critical domain of\ninformation extraction in biochemical research. NER provides support for text\nmining in biochemical reactions, including entity relation extraction,\nattribute extraction, and metabolic response relationship extraction. However,\nthe existence of complex naming characteristics in the biomedical field, such\nas polysemy and special characters, make the NER task very challenging. Here,\nwe propose a hybrid deep learning approach to improve the recognition accuracy\nof NER. Specifically, our approach applies the Bidirectional Encoder\nRepresentations from Transformers (BERT) model to extract the underlying\nfeatures of the text, learns a representation of the context of the text\nthrough Bi-directional Long Short-Term Memory (BILSTM), and incorporates the\nmulti-head attention (MHATT) mechanism to extract chapter-level features. In\nthis approach, the MHATT mechanism aims to improve the recognition accuracy of\nabbreviations to efficiently deal with the problem of inconsistency in\nfull-text labels. Moreover, conditional random field (CRF) is used to label\nsequence tags because this probabilistic method does not need strict\nindependence assumptions and can accommodate arbitrary context information. The\nexperimental evaluation on a publicly-available dataset shows that the proposed\nhybrid approach achieves the best recognition performance; in particular, it\nsubstantially improves performance in recognizing abbreviations, polysemes, and\nlow-frequency entities, compared with the state-of-the-art approaches. For\ninstance, compared with the recognition accuracies for low-frequency entities\nproduced by the BILSTM-CRF algorithm, those produced by the hybrid approach on\ntwo entity datasets (MULTIPLE and IDENTIFIER) have been increased by 80% and\n21.69%, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 01:30:07 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Liu", "Jian", ""], ["Gao", "Lei", ""], ["Guo", "Sujie", ""], ["Ding", "Rui", ""], ["Huang", "Xin", ""], ["Ye", "Long", ""], ["Meng", "Qinghua", ""], ["Nazari", "Asef", ""], ["Thiruvady", "Dhananjay", ""]]}, {"id": "2012.10877", "submitter": "Nuo Chen", "authors": "Nuo Chen, Fenglin Liu, Chenyu You, Peilin Zhou, Yuexian Zou", "title": "Adaptive Bi-directional Attention: Exploring Multi-Granularity\n  Representations for Machine Reading Comprehension", "comments": "five paes, four figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, the attention-enhanced multi-layer encoder, such as Transformer,\nhas been extensively studied in Machine Reading Comprehension (MRC). To predict\nthe answer, it is common practice to employ a predictor to draw information\nonly from the final encoder layer which generates the \\textit{coarse-grained}\nrepresentations of the source sequences, i.e., passage and question. Previous\nstudies have shown that the representation of source sequence becomes more\n\\textit{coarse-grained} from \\textit{fine-grained} as the encoding layer\nincreases. It is generally believed that with the growing number of layers in\ndeep neural networks, the encoding process will gather relevant information for\neach location increasingly, resulting in more \\textit{coarse-grained}\nrepresentations, which adds the likelihood of similarity to other locations\n(referring to homogeneity). Such a phenomenon will mislead the model to make\nwrong judgments so as to degrade the performance. To this end, we propose a\nnovel approach called Adaptive Bidirectional Attention, which adaptively\nexploits the source representations of different levels to the predictor.\nExperimental results on the benchmark dataset, SQuAD 2.0 demonstrate the\neffectiveness of our approach, and the results are better than the previous\nstate-of-the-art model by 2.5$\\%$ EM and 2.3$\\%$ F1 scores.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 09:31:35 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 08:42:32 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Chen", "Nuo", ""], ["Liu", "Fenglin", ""], ["You", "Chenyu", ""], ["Zhou", "Peilin", ""], ["Zou", "Yuexian", ""]]}, {"id": "2012.11014", "submitter": "Kenneth Marino", "authors": "Kenneth Marino, Xinlei Chen, Devi Parikh, Abhinav Gupta, Marcus\n  Rohrbach", "title": "KRISP: Integrating Implicit and Symbolic Knowledge for Open-Domain\n  Knowledge-Based VQA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most challenging question types in VQA is when answering the\nquestion requires outside knowledge not present in the image. In this work we\nstudy open-domain knowledge, the setting when the knowledge required to answer\na question is not given/annotated, neither at training nor test time. We tap\ninto two types of knowledge representations and reasoning. First, implicit\nknowledge which can be learned effectively from unsupervised language\npre-training and supervised training data with transformer-based models.\nSecond, explicit, symbolic knowledge encoded in knowledge bases. Our approach\ncombines both - exploiting the powerful implicit reasoning of transformer\nmodels for answer prediction, and integrating symbolic representations from a\nknowledge graph, while never losing their explicit semantics to an implicit\nembedding. We combine diverse sources of knowledge to cover the wide variety of\nknowledge needed to solve knowledge-based questions. We show our approach,\nKRISP (Knowledge Reasoning with Implicit and Symbolic rePresentations),\nsignificantly outperforms state-of-the-art on OK-VQA, the largest available\ndataset for open-domain knowledge-based VQA. We show with extensive ablations\nthat while our model successfully exploits implicit knowledge reasoning, the\nsymbolic answer module which explicitly connects the knowledge graph to the\nanswer vocabulary is critical to the performance of our method and generalizes\nto rare answers.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 20:13:02 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Marino", "Kenneth", ""], ["Chen", "Xinlei", ""], ["Parikh", "Devi", ""], ["Gupta", "Abhinav", ""], ["Rohrbach", "Marcus", ""]]}, {"id": "2012.11099", "submitter": "Yongkang Liu", "authors": "Yongkang Liu, Shi Feng, Daling Wang, Kaisong Song, Feiliang Ren, Yifei\n  Zhang", "title": "A Graph Reasoning Network for Multi-turn Response Selection via\n  Customized Pre-training", "comments": "Accepted by AAAI 2021;10 pages,6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate response selection for multi-turn conversation in\nretrieval-based chatbots. Existing studies pay more attention to the matching\nbetween utterances and responses by calculating the matching score based on\nlearned features, leading to insufficient model reasoning ability. In this\npaper, we propose a graph-reasoning network (GRN) to address the problem. GRN\nfirst conducts pre-training based on ALBERT using next utterance prediction and\nutterance order prediction tasks specifically devised for response selection.\nThese two customized pre-training tasks can endow our model with the ability of\ncapturing semantical and chronological dependency between utterances. We then\nfine-tune the model on an integrated network with sequence reasoning and graph\nreasoning structures. The sequence reasoning module conducts inference based on\nthe highly summarized context vector of utterance-response pairs from the\nglobal perspective. The graph reasoning module conducts the reasoning on the\nutterance-level graph neural network from the local perspective. Experiments on\ntwo conversational reasoning datasets show that our model can dramatically\noutperform the strong baseline methods and can achieve performance which is\nclose to human-level.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 03:38:29 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 02:12:11 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Liu", "Yongkang", ""], ["Feng", "Shi", ""], ["Wang", "Daling", ""], ["Song", "Kaisong", ""], ["Ren", "Feiliang", ""], ["Zhang", "Yifei", ""]]}, {"id": "2012.11138", "submitter": "Shoma Ishida", "authors": "Shoma Ishida, Satoshi Ono", "title": "Adjust-free adversarial example generation in speech recognition using\n  evolutionary multi-objective optimization under black-box condition", "comments": null, "journal-ref": "Artif Life Robotics (2021)", "doi": "10.1007/s10015-020-00671-x", "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a black-box adversarial attack method to automatic speech\nrecognition systems. Some studies have attempted to attack neural networks for\nspeech recognition; however, these methods did not consider the robustness of\ngenerated adversarial examples against timing lag with a target speech. The\nproposed method in this paper adopts Evolutionary Multi-objective Optimization\n(EMO)that allows it generating robust adversarial examples under black-box\nscenario. Experimental results showed that the proposed method successfully\ngenerated adjust-free adversarial examples, which are sufficiently robust\nagainst timing lag so that an attacker does not need to take the timing of\nplaying it against the target speech.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 06:35:52 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 15:53:04 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Ishida", "Shoma", ""], ["Ono", "Satoshi", ""]]}, {"id": "2012.11142", "submitter": "Ishani Mondal", "authors": "Ishani Mondal", "title": "Towards Incorporating Entity-specific Knowledge Graph Information in\n  Predicting Drug-Drug Interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Off-the-shelf biomedical embeddings obtained from the recently released\nvarious pre-trained language models (such as BERT, XLNET) have demonstrated\nstate-of-the-art results (in terms of accuracy) for the various natural\nlanguage understanding tasks (NLU) in the biomedical domain. Relation\nClassification (RC) falls into one of the most critical tasks. In this paper,\nwe explore how to incorporate domain knowledge of the biomedical entities (such\nas drug, disease, genes), obtained from Knowledge Graph (KG) Embeddings, for\npredicting Drug-Drug Interaction from textual corpus. We propose a new method,\nBERTKG-DDI, to combine drug embeddings obtained from its interaction with other\nbiomedical entities along with domain-specific BioBERT embedding-based RC\narchitecture. Experiments conducted on the DDIExtraction 2013 corpus clearly\nindicate that this strategy improves other baselines architectures by 4.1%\nmacro F1-score.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 06:44:32 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Mondal", "Ishani", ""]]}, {"id": "2012.11145", "submitter": "Ayush Kaushal", "authors": "Tejas Vaidhya and Ayush Kaushal", "title": "Domain specific BERT representation for Named Entity Recognition of lab\n  protocol", "comments": "EMNLP 2020 Workshop; 5 pages", "journal-ref": null, "doi": "10.18653/v1/2020.wnut-1.34", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Supervised models trained to predict properties from representations have\nbeen achieving high accuracy on a variety of tasks. For instance, the BERT\nfamily seems to work exceptionally well on the downstream task from NER tagging\nto the range of other linguistic tasks. But the vocabulary used in the medical\nfield contains a lot of different tokens used only in the medical industry such\nas the name of different diseases, devices, organisms, medicines, etc. that\nmakes it difficult for traditional BERT model to create contextualized\nembedding. In this paper, we are going to illustrate the System for Named\nEntity Tagging based on Bio-Bert. Experimental results show that our model\ngives substantial improvements over the baseline and stood the fourth runner up\nin terms of F1 score, and first runner up in terms of Recall with just 2.21 F1\nscore behind the best one.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 06:54:38 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Vaidhya", "Tejas", ""], ["Kaushal", "Ayush", ""]]}, {"id": "2012.11157", "submitter": "Deng Cai", "authors": "Deng Cai and Yizhe Zhang and Yichen Huang and Wai Lam and Bill Dolan", "title": "Narrative Incoherence Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose the task of narrative incoherence detection as a new arena for\ninter-sentential semantic understanding: Given a multi-sentence narrative,\ndecide whether there exist any semantic discrepancies in the narrative flow.\nSpecifically, we focus on the missing sentence and discordant sentence\ndetection. Despite its simple setup, this task is challenging as the model\nneeds to understand and analyze a multi-sentence narrative, and predict\nincoherence at the sentence level. As an initial step towards this task, we\nimplement several baselines either directly analyzing the raw text\n(\\textit{token-level}) or analyzing learned sentence representations\n(\\textit{sentence-level}). We observe that while token-level modeling has\nbetter performance when the input contains fewer sentences, sentence-level\nmodeling performs better on longer narratives and possesses an advantage in\nefficiency and flexibility. Pre-training on large-scale data and auxiliary\nsentence prediction training objective further boost the detection performance\nof the sentence-level model.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 07:18:08 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 11:47:45 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Cai", "Deng", ""], ["Zhang", "Yizhe", ""], ["Huang", "Yichen", ""], ["Lam", "Wai", ""], ["Dolan", "Bill", ""]]}, {"id": "2012.11163", "submitter": "Pingchuan Ma", "authors": "Pingchuan Ma and Shuai Wang", "title": "MT-Teql: Evaluating and Augmenting Consistency of Text-to-SQL Models\n  with Metamorphic Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-to-SQL is a task to generate SQL queries from human utterances. However,\ndue to the variation of natural language, two semantically equivalent\nutterances may appear differently in the lexical level. Likewise, user\npreferences (e.g., the choice of normal forms) can lead to dramatic changes in\ntable structures when expressing conceptually identical schemas. Envisioning\nthe general difficulty for text-to-SQL models to preserve prediction\nconsistency against linguistic and schema variations, we propose MT-Teql, a\nMetamorphic Testing-based framework for systematically evaluating and\naugmenting the consistency of TExt-to-SQL models. Inspired by the principles of\nsoftware metamorphic testing, MT-Teql delivers a model-agnostic framework which\nimplements a comprehensive set of metamorphic relations (MRs) to conduct\nsemantics-preserving transformations toward utterances and schemas. Model\nInconsistency can be exposed when the original and transformed inputs induce\ndifferent SQL queries. In addition, we leverage the transformed inputs to\nretrain models for further model robustness boost. Our experiments show that\nour framework exposes thousands of prediction errors from SOTA models and\nenriches existing datasets by order of magnitude, eliminating over 40%\ninconsistency errors without compromising standard accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 07:43:31 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Ma", "Pingchuan", ""], ["Wang", "Shuai", ""]]}, {"id": "2012.11164", "submitter": "Ishani Mondal", "authors": "Ishani Mondal, Sukannya Purkayastha, Sudeshna Sarkar, Pawan Goyal,\n  Jitesh Pillai, Amitava Bhattacharyya, Mahanandeeshwar Gattu", "title": "Medical Entity Linking using Triplet Network", "comments": "ClinicalNLP@NAACL 2019", "journal-ref": null, "doi": "10.18653/v1/W19-1912", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Entity linking (or Normalization) is an essential task in text mining that\nmaps the entity mentions in the medical text to standard entities in a given\nKnowledge Base (KB). This task is of great importance in the medical domain. It\ncan also be used for merging different medical and clinical ontologies. In this\npaper, we center around the problem of disease linking or normalization. This\ntask is executed in two phases: candidate generation and candidate scoring. In\nthis paper, we present an approach to rank the candidate Knowledge Base entries\nbased on their similarity with disease mention. We make use of the Triplet\nNetwork for candidate ranking. While the existing methods have used carefully\ngenerated sieves and external resources for candidate generation, we introduce\na robust and portable candidate generation scheme that does not make use of the\nhand-crafted rules. Experimental results on the standard benchmark NCBI disease\ndataset demonstrate that our system outperforms the prior methods by a\nsignificant margin.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 07:44:37 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Mondal", "Ishani", ""], ["Purkayastha", "Sukannya", ""], ["Sarkar", "Sudeshna", ""], ["Goyal", "Pawan", ""], ["Pillai", "Jitesh", ""], ["Bhattacharyya", "Amitava", ""], ["Gattu", "Mahanandeeshwar", ""]]}, {"id": "2012.11169", "submitter": "Ke Shi", "authors": "Ke Shi, Zhengyuan Liu, Nancy F. Chen", "title": "An End-to-End Document-Level Neural Discourse Parser Exploiting\n  Multi-Granularity Representations", "comments": "11 pages, 3 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document-level discourse parsing, in accordance with the Rhetorical Structure\nTheory (RST), remains notoriously challenging. Challenges include the deep\nstructure of document-level discourse trees, the requirement of subtle semantic\njudgments, and the lack of large-scale training corpora. To address such\nchallenges, we propose to exploit robust representations derived from multiple\nlevels of granularity across syntax and semantics, and in turn incorporate such\nrepresentations in an end-to-end encoder-decoder neural architecture for more\nresourceful discourse processing. In particular, we first use a pre-trained\ncontextual language model that embodies high-order and long-range dependency to\nenable finer-grain semantic, syntactic, and organizational representations. We\nfurther encode such representations with boundary and hierarchical information\nto obtain more refined modeling for document-level discourse processing.\nExperimental results show that our parser achieves the state-of-the-art\nperformance, approaching human-level performance on the benchmarked RST\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 08:01:04 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Shi", "Ke", ""], ["Liu", "Zhengyuan", ""], ["Chen", "Nancy F.", ""]]}, {"id": "2012.11204", "submitter": "Mehrdad Farahani", "authors": "Mehrdad Farahani, Mohammad Gharachorloo, Mohammad Manthouri", "title": "Leveraging ParsBERT and Pretrained mT5 for Persian Abstractive Text\n  Summarization", "comments": "7 pages, 7 figures, 3 tables, csicc2021 conference", "journal-ref": null, "doi": "10.1109/CSICC52343.2021.9420563", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text summarization is one of the most critical Natural Language Processing\n(NLP) tasks. More and more researches are conducted in this field every day.\nPre-trained transformer-based encoder-decoder models have begun to gain\npopularity for these tasks. This paper proposes two methods to address this\ntask and introduces a novel dataset named pn-summary for Persian abstractive\ntext summarization. The models employed in this paper are mT5 and an\nencoder-decoder version of the ParsBERT model (i.e., a monolingual BERT model\nfor Persian). These models are fine-tuned on the pn-summary dataset. The\ncurrent work is the first of its kind and, by achieving promising results, can\nserve as a baseline for any future work.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 09:35:52 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Farahani", "Mehrdad", ""], ["Gharachorloo", "Mohammad", ""], ["Manthouri", "Mohammad", ""]]}, {"id": "2012.11213", "submitter": "Shintaro Yamamoto", "authors": "Shintaro Yamamoto, Anne Lauscher, Simone Paolo Ponzetto, Goran\n  Glava\\v{s}, Shigeo Morishima", "title": "Self-Supervised Learning for Visual Summary Identification in Scientific\n  Publications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Providing visual summaries of scientific publications can increase\ninformation access for readers and thereby help deal with the exponential\ngrowth in the number of scientific publications. Nonetheless, efforts in\nproviding visual publication summaries have been few and far apart, primarily\nfocusing on the biomedical domain. This is primarily because of the limited\navailability of annotated gold standards, which hampers the application of\nrobust and high-performing supervised learning techniques. To address these\nproblems we create a new benchmark dataset for selecting figures to serve as\nvisual summaries of publications based on their abstracts, covering several\ndomains in computer science. Moreover, we develop a self-supervised learning\napproach, based on heuristic matching of inline references to figures with\nfigure captions. Experiments in both biomedical and computer science domains\nshow that our model is able to outperform the state of the art despite being\nself-supervised and therefore not relying on any annotated training data.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 09:48:58 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 09:00:18 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Yamamoto", "Shintaro", ""], ["Lauscher", "Anne", ""], ["Ponzetto", "Simone Paolo", ""], ["Glava\u0161", "Goran", ""], ["Morishima", "Shigeo", ""]]}, {"id": "2012.11321", "submitter": "Ruben Cartuyvels", "authors": "Ruben Cartuyvels, Graham Spinks and Marie-Francine Moens", "title": "Autoregressive Reasoning over Chains of Facts with Transformers", "comments": "Published at International Conference on Computational Linguistics\n  2020 (ICCL) (COLING)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes an iterative inference algorithm for multi-hop\nexplanation regeneration, that retrieves relevant factual evidence in the form\nof text snippets, given a natural language question and its answer. Combining\nmultiple sources of evidence or facts for multi-hop reasoning becomes\nincreasingly hard when the number of sources needed to make an inference grows.\nOur algorithm copes with this by decomposing the selection of facts from a\ncorpus autoregressively, conditioning the next iteration on previously selected\nfacts. This allows us to use a pairwise learning-to-rank loss. We validate our\nmethod on datasets of the TextGraphs 2019 and 2020 Shared Tasks for explanation\nregeneration. Existing work on this task either evaluates facts in isolation or\nartificially limits the possible chains of facts, thus limiting multi-hop\ninference. We demonstrate that our algorithm, when used with a pre-trained\ntransformer model, outperforms the previous state-of-the-art in terms of\nprecision, training time and inference efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 13:17:27 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Cartuyvels", "Ruben", ""], ["Spinks", "Graham", ""], ["Moens", "Marie-Francine", ""]]}, {"id": "2012.11357", "submitter": "Tian Lan", "authors": "Tian Lan, Xian-Ling Mao, Zhipeng Zhao, Wei Wei, Heyan Huang", "title": "Self-attention Comparison Module for Boosting Performance on\n  Retrieval-based Open-Domain Dialog Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the pre-trained language models are widely used, retrieval-based\nopen-domain dialog systems, have attracted considerable attention from\nresearchers recently. Most of the previous works select a suitable response\nonly according to the matching degree between the query and each individual\ncandidate response. Although good performance has been achieved, these recent\nworks ignore the comparison among the candidate responses, which could provide\nrich information for selecting the most appropriate response. Intuitively,\nbetter decisions could be made when the models can get access to the comparison\ninformation among all the candidate responses. In order to leverage the\ncomparison information among the candidate responses, in this paper, we propose\na novel and plug-in Self-attention Comparison Module for retrieval-based\nopen-domain dialog systems, called SCM. Extensive experiment results\ndemonstrate that our proposed self-attention comparison module effectively\nboosts the performance of the existing retrieval-based open-domain dialog\nsystems. Besides, we have publicly released our source codes for future\nresearch.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 14:10:42 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Lan", "Tian", ""], ["Mao", "Xian-Ling", ""], ["Zhao", "Zhipeng", ""], ["Wei", "Wei", ""], ["Huang", "Heyan", ""]]}, {"id": "2012.11384", "submitter": "Wang Xu", "authors": "Wang Xu, Kehai Chen and Tiejun Zhao", "title": "Document-Level Relation Extraction with Reconstruction", "comments": "9 pages, 5 figures, 6 tables. Accepted by AAAI 2021 (Long Paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In document-level relation extraction (DocRE), graph structure is generally\nused to encode relation information in the input document to classify the\nrelation category between each entity pair, and has greatly advanced the DocRE\ntask over the past several years. However, the learned graph representation\nuniversally models relation information between all entity pairs regardless of\nwhether there are relationships between these entity pairs. Thus, those entity\npairs without relationships disperse the attention of the encoder-classifier\nDocRE for ones with relationships, which may further hind the improvement of\nDocRE. To alleviate this issue, we propose a novel\nencoder-classifier-reconstructor model for DocRE. The reconstructor manages to\nreconstruct the ground-truth path dependencies from the graph representation,\nto ensure that the proposed DocRE model pays more attention to encode entity\npairs with relationships in the training. Furthermore, the reconstructor is\nregarded as a relationship indicator to assist relation classification in the\ninference, which can further improve the performance of DocRE model.\nExperimental results on a large-scale DocRE dataset show that the proposed\nmodel can significantly improve the accuracy of relation extraction on a strong\nheterogeneous graph-based baseline.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 14:29:31 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Xu", "Wang", ""], ["Chen", "Kehai", ""], ["Zhao", "Tiejun", ""]]}, {"id": "2012.11420", "submitter": "Omar Sharif", "authors": "Omar Sharif, Eftekhar Hossain, Mohammed Moshiul Hoque", "title": "TechTexC: Classification of Technical Texts using Convolution and\n  Bidirectional Long Short Term Memory Network", "comments": "5 pages, 3 tables, This paper is accepted and presented at 17th\n  International Conference on Natural Language Processing (ICON 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper illustrates the details description of technical text\nclassification system and its results that developed as a part of participation\nin the shared task TechDofication 2020. The shared task consists of two\nsub-tasks: (i) first task identify the coarse-grained technical domain of given\ntext in a specified language and (ii) the second task classify a text of\ncomputer science domain into fine-grained sub-domains. A classification system\n(called 'TechTexC') is developed to perform the classification task using three\ntechniques: convolution neural network (CNN), bidirectional long short term\nmemory (BiLSTM) network, and combined CNN with BiLSTM. Results show that CNN\nwith BiLSTM model outperforms the other techniques concerning task-1 of\nsub-tasks (a, b, c and g) and task-2a. This combined model obtained f1 scores\nof 82.63 (sub-task a), 81.95 (sub-task b), 82.39 (sub-task c), 84.37 (sub-task\ng), and 67.44 (task-2a) on the development dataset. Moreover, in the case of\ntest set, the combined CNN with BiLSTM approach achieved that higher accuracy\nfor the subtasks 1a (70.76%), 1b (79.97%), 1c (65.45%), 1g (49.23%) and 2a\n(70.14%).\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 15:22:47 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Sharif", "Omar", ""], ["Hossain", "Eftekhar", ""], ["Hoque", "Mohammed Moshiul", ""]]}, {"id": "2012.11468", "submitter": "Yunmo Chen", "authors": "Yunmo Chen, Sixing Lu, Fan Yang, Xiaojiang Huang, Xing Fan, Chenlei\n  Guo", "title": "Pattern-aware Data Augmentation for Query Rewriting in Voice Assistant\n  Systems", "comments": "Accepted to DEEP-DIAL 2021 workshop at AAAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Query rewriting (QR) systems are widely used to reduce the friction caused by\nerrors in a spoken language understanding pipeline. However, the underlying\nsupervised models require a large number of labeled pairs, and these pairs are\nhard and costly to be collected. Therefore, We propose an augmentation\nframework that learns patterns from existing training pairs and generates\nrewrite candidates from rewrite labels inversely to compensate for insufficient\nQR training data. The proposed framework casts the augmentation problem as a\nsequence-to-sequence generation task and enforces the optimization process with\na policy gradient technique for controllable rewarding. This approach goes\nbeyond the traditional heuristics or rule-based augmentation methods and is not\nconstrained to generate predefined patterns of swapping/replacing words. Our\nexperimental results show its effectiveness compared with a fully trained QR\nbaseline and demonstrate its potential application in boosting the QR\nperformance on low-resource domains or locales.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 16:36:32 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Chen", "Yunmo", ""], ["Lu", "Sixing", ""], ["Yang", "Fan", ""], ["Huang", "Xiaojiang", ""], ["Fan", "Xing", ""], ["Guo", "Chenlei", ""]]}, {"id": "2012.11587", "submitter": "Chuang Gan", "authors": "Jianwei Yang, Jiayuan Mao, Jiajun Wu, Devi Parikh, David D. Cox,\n  Joshua B. Tenenbaum, Chuang Gan", "title": "Object-Centric Diagnosis of Visual Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When answering questions about an image, it not only needs knowing what --\nunderstanding the fine-grained contents (e.g., objects, relationships) in the\nimage, but also telling why -- reasoning over grounding visual cues to derive\nthe answer for a question. Over the last few years, we have seen significant\nprogress on visual question answering. Though impressive as the accuracy grows,\nit still lags behind to get knowing whether these models are undertaking\ngrounding visual reasoning or just leveraging spurious correlations in the\ntraining data. Recently, a number of works have attempted to answer this\nquestion from perspectives such as grounding and robustness. However, most of\nthem are either focusing on the language side or coarsely studying the\npixel-level attention maps. In this paper, by leveraging the step-wise object\ngrounding annotations provided in the GQA dataset, we first present a\nsystematical object-centric diagnosis of visual reasoning on grounding and\nrobustness, particularly on the vision side. According to the extensive\ncomparisons across different models, we find that even models with high\naccuracy are not good at grounding objects precisely, nor robust to visual\ncontent perturbations. In contrast, symbolic and modular models have a\nrelatively better grounding and robustness, though at the cost of accuracy. To\nreconcile these different aspects, we further develop a diagnostic model,\nnamely Graph Reasoning Machine. Our model replaces purely symbolic visual\nrepresentation with probabilistic scene graph and then applies teacher-forcing\ntraining for the visual reasoning module. The designed model improves the\nperformance on all three metrics over the vanilla neural-symbolic model while\ninheriting the transparency. Further ablation studies suggest that this\nimprovement is mainly due to more accurate image understanding and proper\nintermediate reasoning supervisions.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 18:59:28 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Yang", "Jianwei", ""], ["Mao", "Jiayuan", ""], ["Wu", "Jiajun", ""], ["Parikh", "Devi", ""], ["Cox", "David D.", ""], ["Tenenbaum", "Joshua B.", ""], ["Gan", "Chuang", ""]]}, {"id": "2012.11599", "submitter": "Ishani Mondal", "authors": "Ishani Mondal", "title": "BERTChem-DDI : Improved Drug-Drug Interaction Prediction from text using\n  Chemical Structure Information", "comments": "arXiv admin note: substantial text overlap with arXiv:2012.11142", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditional biomedical version of embeddings obtained from pre-trained\nlanguage models have recently shown state-of-the-art results for relation\nextraction (RE) tasks in the medical domain. In this paper, we explore how to\nincorporate domain knowledge, available in the form of molecular structure of\ndrugs, for predicting Drug-Drug Interaction from textual corpus. We propose a\nmethod, BERTChem-DDI, to efficiently combine drug embeddings obtained from the\nrich chemical structure of drugs along with off-the-shelf domain-specific\nBioBERT embedding-based RE architecture. Experiments conducted on the\nDDIExtraction 2013 corpus clearly indicate that this strategy improves other\nstrong baselines architectures by 3.4\\% macro F1-score.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 07:13:52 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Mondal", "Ishani", ""]]}, {"id": "2012.11635", "submitter": "Muhammad Khalifa", "authors": "Muhammad Khalifa, Hady Elsahar, Marc Dymetman", "title": "A Distributional Approach to Controlled Text Generation", "comments": "ICLR 2021 camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a Distributional Approach for addressing Controlled Text\nGeneration from pre-trained Language Models (LMs). This approach permits to\nspecify, in a single formal framework, both \"pointwise\" and \"distributional\"\nconstraints over the target LM -- to our knowledge, the first model with such\ngenerality -- while minimizing KL divergence from the initial LM distribution.\nThe optimal target distribution is then uniquely determined as an explicit EBM\n(Energy-Based Model) representation. From that optimal representation we then\ntrain a target controlled Autoregressive LM through an adaptive distributional\nvariant of Policy Gradient. We conduct a first set of experiments over\npointwise constraints showing the advantages of our approach over a set of\nbaselines, in terms of obtaining a controlled LM balancing constraint\nsatisfaction with divergence from the initial LM. We then perform experiments\nover distributional constraints, a unique feature of our approach,\ndemonstrating its potential as a remedy to the problem of Bias in Language\nModels. Through an ablation study, we show the effectiveness of our adaptive\ntechnique for obtaining faster convergence. (Code available at\nhttps://github.com/naver/gdc)\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 19:02:41 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 10:18:59 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Khalifa", "Muhammad", ""], ["Elsahar", "Hady", ""], ["Dymetman", "Marc", ""]]}, {"id": "2012.11657", "submitter": "Ehsaneddin Asgari", "authors": "Ehsaneddin Asgari and Masoud Jalili Sabet and Philipp Dufter and\n  Christopher Ringlstetter and Hinrich Sch\\\"utze", "title": "Subword Sampling for Low Resource Word Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Annotation projection is an important area in NLP that can greatly contribute\nto creating language resources for low-resource languages. Word alignment plays\na key role in this setting. However, most of the existing word alignment\nmethods are designed for a high resource setting in machine translation where\nmillions of parallel sentences are available. This amount reduces to a few\nthousands of sentences when dealing with low-resource languages failing the\nexisting established IBM models. In this paper, we propose subword\nsampling-based alignment of text units. This method's hypothesis is that the\naggregation of different granularities of text for certain language pairs can\nhelp word-level alignment. For certain languages for which gold-standard\nalignments exist, we propose an iterative Bayesian optimization framework to\noptimize selecting possible subwords from the space of possible subword\nrepresentations of the source and target sentences. We show that the subword\nsampling method consistently outperforms word-level alignment on six language\npairs: English-German, English-French, English-Romanian, English-Persian,\nEnglish-Hindi, and English-Inuktitut. In addition, we show that the\nhyperparameters learned for certain language pairs can be applied to other\nlanguages at no supervision and consistently improve the alignment results. We\nobserve that using $5K$ parallel sentences together with our proposed subword\nsampling approach, we obtain similar F1 scores to the use of $100K$'s of\nparallel sentences in existing word-level fast-align/eflomal alignment methods.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 19:47:04 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 21:38:39 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Asgari", "Ehsaneddin", ""], ["Sabet", "Masoud Jalili", ""], ["Dufter", "Philipp", ""], ["Ringlstetter", "Christopher", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "2012.11685", "submitter": "Bhaskar Mitra", "authors": "Bhaskar Mitra", "title": "Neural Methods for Effective, Efficient, and Exposure-Aware Information\n  Retrieval", "comments": "PhD thesis, Univ College London (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks with deep architectures have demonstrated significant\nperformance improvements in computer vision, speech recognition, and natural\nlanguage processing. The challenges in information retrieval (IR), however, are\ndifferent from these other application areas. A common form of IR involves\nranking of documents--or short passages--in response to keyword-based queries.\nEffective IR systems must deal with query-document vocabulary mismatch problem,\nby modeling relationships between different query and document terms and how\nthey indicate relevance. Models should also consider lexical matches when the\nquery contains rare terms--such as a person's name or a product model\nnumber--not seen during training, and to avoid retrieving semantically related\nbut irrelevant results. In many real-life IR tasks, the retrieval involves\nextremely large collections--such as the document index of a commercial Web\nsearch engine--containing billions of documents. Efficient IR methods should\ntake advantage of specialized IR data structures, such as inverted index, to\nefficiently retrieve from large collections. Given an information need, the IR\nsystem also mediates how much exposure an information artifact receives by\ndeciding whether it should be displayed, and where it should be positioned,\namong other results. Exposure-aware IR systems may optimize for additional\nobjectives, besides relevance, such as parity of exposure for retrieved items\nand content publishers. In this thesis, we present novel neural architectures\nand methods motivated by the specific needs and challenges of IR tasks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 21:20:16 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 21:47:04 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Mitra", "Bhaskar", ""]]}, {"id": "2012.11740", "submitter": "Gideon Maillette de Buy Wenniger", "authors": "Thomas van Dongen, Gideon Maillette de Buy Wenniger, Lambert Schomaker", "title": "SChuBERT: Scholarly Document Chunks with BERT-encoding boost Citation\n  Count Prediction", "comments": "Published at the First Workshop on Scholarly Document Processing, at\n  EMNLP 2020. Minor corrections were made to the workshop version, including\n  addition of color to Figures 1,2", "journal-ref": "Proceedings of the First Workshop on Scholarly Document\n  Processing. Association for Computational Linguistics. (2020) 158-167.\n  EMNLP|SDP 2020 https://www.aclweb.org/anthology/2020.sdp-1.17/", "doi": "10.18653/v1/2020.sdp-1.17", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the number of citations of scholarly documents is an upcoming task\nin scholarly document processing. Besides the intrinsic merit of this\ninformation, it also has a wider use as an imperfect proxy for quality which\nhas the advantage of being cheaply available for large volumes of scholarly\ndocuments. Previous work has dealt with number of citations prediction with\nrelatively small training data sets, or larger datasets but with short,\nincomplete input text. In this work we leverage the open access ACL Anthology\ncollection in combination with the Semantic Scholar bibliometric database to\ncreate a large corpus of scholarly documents with associated citation\ninformation and we propose a new citation prediction model called SChuBERT. In\nour experiments we compare SChuBERT with several state-of-the-art citation\nprediction models and show that it outperforms previous methods by a large\nmargin. We also show the merit of using more training data and longer input for\nnumber of citations prediction.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 23:14:18 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["van Dongen", "Thomas", ""], ["Wenniger", "Gideon Maillette de Buy", ""], ["Schomaker", "Lambert", ""]]}, {"id": "2012.11760", "submitter": "Amir Pouran Ben Veyseh", "authors": "Amir Pouran Ben Veyseh, Franck Dernoncourt, Thien Huu Nguyen, Walter\n  Chang, Leo Anthony Celi", "title": "Acronym Identification and Disambiguation Shared Tasks for Scientific\n  Document Understanding", "comments": "Task overview for Acronym Identification and Acronym Disambiguation\n  at Scientific Document Understanding workshop at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Acronyms are the short forms of longer phrases and they are frequently used\nin writing, especially scholarly writing, to save space and facilitate the\ncommunication of information. As such, every text understanding tool should be\ncapable of recognizing acronyms in text (i.e., acronym identification) and also\nfinding their correct meaning (i.e., acronym disambiguation). As most of the\nprior works on these tasks are restricted to the biomedical domain and use\nunsupervised methods or models trained on limited datasets, they fail to\nperform well for scientific document understanding. To push forward research in\nthis direction, we have organized two shared task for acronym identification\nand acronym disambiguation in scientific documents, named AI@SDU and AD@SDU,\nrespectively. The two shared tasks have attracted 52 and 43 participants,\nrespectively. While the submitted systems make substantial improvements\ncompared to the existing baselines, there are still far from the human-level\nperformance. This paper reviews the two shared tasks and the prominent\nparticipating systems for each of them.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 00:29:15 GMT"}, {"version": "v2", "created": "Fri, 25 Dec 2020 22:02:10 GMT"}, {"version": "v3", "created": "Tue, 29 Dec 2020 23:47:46 GMT"}, {"version": "v4", "created": "Wed, 6 Jan 2021 04:34:52 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Veyseh", "Amir Pouran Ben", ""], ["Dernoncourt", "Franck", ""], ["Nguyen", "Thien Huu", ""], ["Chang", "Walter", ""], ["Celi", "Leo Anthony", ""]]}, {"id": "2012.11805", "submitter": "Zijian Li", "authors": "Zhifeng Hao, Di Lv, Zijian Li, Ruichu Cai, Wen Wen, Boyan Xu", "title": "Semi-Supervised Disentangled Framework for Transferable Named Entity\n  Recognition", "comments": null, "journal-ref": null, "doi": "10.1016/j.neunet.2020.11.017", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity recognition (NER) for identifying proper nouns in unstructured\ntext is one of the most important and fundamental tasks in natural language\nprocessing. However, despite the widespread use of NER models, they still\nrequire a large-scale labeled data set, which incurs a heavy burden due to\nmanual annotation. Domain adaptation is one of the most promising solutions to\nthis problem, where rich labeled data from the relevant source domain are\nutilized to strengthen the generalizability of a model based on the target\ndomain. However, the mainstream cross-domain NER models are still affected by\nthe following two challenges (1) Extracting domain-invariant information such\nas syntactic information for cross-domain transfer. (2) Integrating\ndomain-specific information such as semantic information into the model to\nimprove the performance of NER. In this study, we present a semi-supervised\nframework for transferable NER, which disentangles the domain-invariant latent\nvariables and domain-specific latent variables. In the proposed framework, the\ndomain-specific information is integrated with the domain-specific latent\nvariables by using a domain predictor. The domain-specific and domain-invariant\nlatent variables are disentangled using three mutual information regularization\nterms, i.e., maximizing the mutual information between the domain-specific\nlatent variables and the original embedding, maximizing the mutual information\nbetween the domain-invariant latent variables and the original embedding, and\nminimizing the mutual information between the domain-specific and\ndomain-invariant latent variables. Extensive experiments demonstrated that our\nmodel can obtain state-of-the-art performance with cross-domain and\ncross-lingual NER benchmark data sets.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 02:55:04 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Hao", "Zhifeng", ""], ["Lv", "Di", ""], ["Li", "Zijian", ""], ["Cai", "Ruichu", ""], ["Wen", "Wen", ""], ["Xu", "Boyan", ""]]}, {"id": "2012.11808", "submitter": "Jiho Noh", "authors": "Jiho Noh, Ramakanth Kavuluru", "title": "Improved Biomedical Word Embeddings in the Transformer Era", "comments": "This paper has been accepted for publication in the Journal of\n  Biomedical Informatics", "journal-ref": null, "doi": "10.1016/j.jbi.2021.103867", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Biomedical word embeddings are usually pre-trained on free text corpora with\nneural methods that capture local and global distributional properties. They\nare leveraged in downstream tasks using various neural architectures that are\ndesigned to optimize task-specific objectives that might further tune such\nembeddings. Since 2018, however, there is a marked shift from these static\nembeddings to contextual embeddings motivated by language models (e.g., ELMo,\ntransformers such as BERT, and ULMFiT). These dynamic embeddings have the added\nbenefit of being able to distinguish homonyms and acronyms given their context.\nHowever, static embeddings are still relevant in low resource settings (e.g.,\nsmart devices, IoT elements) and to study lexical semantics from a\ncomputational linguistics perspective. In this paper, we jointly learn word and\nconcept embeddings by first using the skip-gram method and further fine-tuning\nthem with correlational information manifesting in co-occurring Medical Subject\nHeading (MeSH) concepts in biomedical citations. This fine-tuning is\naccomplished with the BERT transformer architecture in the two-sentence input\nmode with a classification objective that captures MeSH pair co-occurrence. In\nessence, we repurpose a transformer architecture (typically used to generate\ndynamic embeddings) to improve static embeddings using concept correlations. We\nconduct evaluations of these tuned static embeddings using multiple datasets\nfor word relatedness developed by previous efforts. Without selectively culling\nconcepts and terms (as was pursued by previous efforts), we believe we offer\nthe most exhaustive evaluation of static embeddings to date with clear\nperformance improvements across the board. We provide our code and embeddings\nfor public use for downstream applications and research endeavors:\nhttps://github.com/bionlproc/BERT-CRel-Embeddings\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 03:03:50 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 16:19:09 GMT"}, {"version": "v3", "created": "Fri, 23 Jul 2021 16:54:04 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Noh", "Jiho", ""], ["Kavuluru", "Ramakanth", ""]]}, {"id": "2012.11820", "submitter": "Soujanya Poria", "authors": "Soujanya Poria, Navonil Majumder, Devamanyu Hazarika, Deepanway\n  Ghosal, Rishabh Bhardwaj, Samson Yu Bai Jian, Pengfei Hong, Romila Ghosh,\n  Abhinaba Roy, Niyati Chhaya, Alexander Gelbukh, Rada Mihalcea", "title": "Recognizing Emotion Cause in Conversations", "comments": "https://github.com/declare-lab/RECCON, Accepted at Cognitive\n  Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We address the problem of recognizing emotion cause in conversations, define\ntwo novel sub-tasks of this problem, and provide a corresponding dialogue-level\ndataset, along with strong Transformer-based baselines. The dataset is\navailable at https://github.com/declare-lab/RECCON.\n  Introduction: Recognizing the cause behind emotions in text is a fundamental\nyet under-explored area of research in NLP. Advances in this area hold the\npotential to improve interpretability and performance in affect-based models.\nIdentifying emotion causes at the utterance level in conversations is\nparticularly challenging due to the intermingling dynamics among the\ninterlocutors.\n  Method: We introduce the task of Recognizing Emotion Cause in CONversations\nwith an accompanying dataset named RECCON, containing over 1,000 dialogues and\n10,000 utterance cause-effect pairs. Furthermore, we define different cause\ntypes based on the source of the causes, and establish strong Transformer-based\nbaselines to address two different sub-tasks on this dataset: causal span\nextraction and causal emotion entailment.\n  Result: Our Transformer-based baselines, which leverage contextual\npre-trained embeddings, such as RoBERTa, outperform the state-of-the-art\nemotion cause extraction approaches\n  Conclusion: We introduce a new task highly relevant for (explainable)\nemotion-aware artificial intelligence: recognizing emotion cause in\nconversations, provide a new highly challenging publicly available\ndialogue-level dataset for this task, and give strong baseline results on this\ndataset.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 03:51:35 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 08:43:38 GMT"}, {"version": "v3", "created": "Tue, 20 Jul 2021 04:06:14 GMT"}, {"version": "v4", "created": "Wed, 28 Jul 2021 23:42:48 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Poria", "Soujanya", ""], ["Majumder", "Navonil", ""], ["Hazarika", "Devamanyu", ""], ["Ghosal", "Deepanway", ""], ["Bhardwaj", "Rishabh", ""], ["Jian", "Samson Yu Bai", ""], ["Hong", "Pengfei", ""], ["Ghosh", "Romila", ""], ["Roy", "Abhinaba", ""], ["Chhaya", "Niyati", ""], ["Gelbukh", "Alexander", ""], ["Mihalcea", "Rada", ""]]}, {"id": "2012.11881", "submitter": "Sharath Nittur Sridhar", "authors": "Sharath Nittur Sridhar, Anthony Sarah", "title": "Undivided Attention: Are Intermediate Layers Necessary for BERT?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent times, BERT-based models have been extremely successful in solving\na variety of natural language processing (NLP) tasks such as reading\ncomprehension, natural language inference, sentiment analysis, etc. All\nBERT-based architectures have a self-attention block followed by a block of\nintermediate layers as the basic building component. However, a strong\njustification for the inclusion of these intermediate layers remains missing in\nthe literature. In this work we investigate the importance of intermediate\nlayers on the overall network performance of downstream tasks. We show that\nreducing the number of intermediate layers and modifying the architecture for\nBERT-Base results in minimal loss in fine-tuning accuracy for downstream tasks\nwhile decreasing the number of parameters and training time of the model.\nAdditionally, we use the central kernel alignment (CKA) similarity metric and\nprobing classifiers to demonstrate that removing intermediate layers has little\nimpact on the learned self-attention representations.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 08:46:14 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Sridhar", "Sharath Nittur", ""], ["Sarah", "Anthony", ""]]}, {"id": "2012.11896", "submitter": "Yubei Xiao", "authors": "Yubei Xiao, Ke Gong, Pan Zhou, Guolin Zheng, Xiaodan Liang, Liang Lin", "title": "Adversarial Meta Sampling for Multilingual Low-Resource Speech\n  Recognition", "comments": "accepted in AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-resource automatic speech recognition (ASR) is challenging, as the\nlow-resource target language data cannot well train an ASR model. To solve this\nissue, meta-learning formulates ASR for each source language into many small\nASR tasks and meta-learns a model initialization on all tasks from different\nsource languages to access fast adaptation on unseen target languages. However,\nfor different source languages, the quantity and difficulty vary greatly\nbecause of their different data scales and diverse phonological systems, which\nleads to task-quantity and task-difficulty imbalance issues and thus a failure\nof multilingual meta-learning ASR (MML-ASR). In this work, we solve this\nproblem by developing a novel adversarial meta sampling (AMS) approach to\nimprove MML-ASR. When sampling tasks in MML-ASR, AMS adaptively determines the\ntask sampling probability for each source language. Specifically, for each\nsource language, if the query loss is large, it means that its tasks are not\nwell sampled to train ASR model in terms of its quantity and difficulty and\nthus should be sampled more frequently for extra learning. Inspired by this\nfact, we feed the historical task query loss of all source language domain into\na network to learn a task sampling policy for adversarially increasing the\ncurrent query loss of MML-ASR. Thus, the learnt task sampling policy can master\nthe learning situation of each language and thus predicts good task sampling\nprobability for each language for more effective learning. Finally, experiment\nresults on two multilingual datasets show significant performance improvement\nwhen applying our AMS on MML-ASR, and also demonstrate the applicability of AMS\nto other low-resource speech tasks and transfer learning ASR approaches.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 09:33:14 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 14:01:54 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 07:10:59 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Xiao", "Yubei", ""], ["Gong", "Ke", ""], ["Zhou", "Pan", ""], ["Zheng", "Guolin", ""], ["Liang", "Xiaodan", ""], ["Lin", "Liang", ""]]}, {"id": "2012.11926", "submitter": "Timo Schick", "authors": "Timo Schick and Hinrich Sch\\\"utze", "title": "Few-Shot Text Generation with Pattern-Exploiting Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing pretrained language models with simple task descriptions or prompts\nin natural language yields impressive few-shot results for a wide range of text\nclassification tasks when combined with gradient-based learning from examples.\nIn this paper, we show that the underlying idea can also be applied to text\ngeneration tasks: We adapt Pattern-Exploiting Training (PET), a recently\nproposed few-shot approach, for finetuning generative language models on text\ngeneration tasks. On several text summarization and headline generation\ndatasets, our proposed variant of PET gives consistent improvements over a\nstrong baseline in few-shot settings.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 10:53:07 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Schick", "Timo", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "2012.11937", "submitter": "Chao-Hong Tan", "authors": "Chao-Hong Tan, Xiaoyu Yang, Zi'ou Zheng, Tianda Li, Yufei Feng,\n  Jia-Chen Gu, Quan Liu, Dan Liu, Zhen-Hua Ling, Xiaodan Zhu", "title": "Learning to Retrieve Entity-Aware Knowledge and Generate Responses with\n  Copy Mechanism for Task-Oriented Dialogue Systems", "comments": "Accepted by AAAI 2021, Workshop on DSTC 9", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-oriented conversational modeling with unstructured knowledge access, as\ntrack 1 of the 9th Dialogue System Technology Challenges (DSTC 9), requests to\nbuild a system to generate response given dialogue history and knowledge\naccess. This challenge can be separated into three subtasks, (1)\nknowledge-seeking turn detection, (2) knowledge selection, and (3)\nknowledge-grounded response generation. We use pre-trained language models,\nELECTRA and RoBERTa, as our base encoder for different subtasks. For subtask 1\nand 2, the coarse-grained information like domain and entity are used to\nenhance knowledge usage. For subtask 3, we use a latent variable to encode\ndialog history and selected knowledge better and generate responses combined\nwith copy mechanism. Meanwhile, some useful post-processing strategies are\nperformed on the model's final output to make further knowledge usage in the\ngeneration task. As shown in released evaluation results, our proposed system\nranks second under objective metrics and ranks fourth under human metrics.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 11:36:37 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Tan", "Chao-Hong", ""], ["Yang", "Xiaoyu", ""], ["Zheng", "Zi'ou", ""], ["Li", "Tianda", ""], ["Feng", "Yufei", ""], ["Gu", "Jia-Chen", ""], ["Liu", "Quan", ""], ["Liu", "Dan", ""], ["Ling", "Zhen-Hua", ""], ["Zhu", "Xiaodan", ""]]}, {"id": "2012.11960", "submitter": "Kai Chen", "authors": "Kai Chen, Meng Niu, Qingcai Chen", "title": "A Hierarchical Reasoning Graph Neural Network for The Automatic Scoring\n  of Answer Transcriptions in Video Job Interviews", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the task of automatically scoring the competency of candidates\nbased on textual features, from the automatic speech recognition (ASR)\ntranscriptions in the asynchronous video job interview (AVI). The key challenge\nis how to construct the dependency relation between questions and answers, and\nconduct the semantic level interaction for each question-answer (QA) pair.\nHowever, most of the recent studies in AVI focus on how to represent questions\nand answers better, but ignore the dependency information and interaction\nbetween them, which is critical for QA evaluation. In this work, we propose a\nHierarchical Reasoning Graph Neural Network (HRGNN) for the automatic\nassessment of question-answer pairs. Specifically, we construct a\nsentence-level relational graph neural network to capture the dependency\ninformation of sentences in or between the question and the answer. Based on\nthese graphs, we employ a semantic-level reasoning graph attention network to\nmodel the interaction states of the current QA session. Finally, we propose a\ngated recurrent unit encoder to represent the temporal question-answer pairs\nfor the final prediction. Empirical results conducted on CHNAT (a real-world\ndataset) validate that our proposed model significantly outperforms\ntext-matching based benchmark models. Ablation studies and experimental results\nwith 10 random seeds also show the effectiveness and stability of our models.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 12:27:45 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Chen", "Kai", ""], ["Niu", "Meng", ""], ["Chen", "Qingcai", ""]]}, {"id": "2012.11967", "submitter": "Anna Glazkova", "authors": "Anna Glazkova, Maksim Glazkov, Timofey Trifonov", "title": "g2tmn at Constraint@AAAI2021: Exploiting CT-BERT and Ensembling Learning\n  for COVID-19 Fake News Detection", "comments": "The winning solution at the Constraint shared task (AAAI-2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The COVID-19 pandemic has had a huge impact on various areas of human life.\nHence, the coronavirus pandemic and its consequences are being actively\ndiscussed on social media. However, not all social media posts are truthful.\nMany of them spread fake news that cause panic among readers, misinform people\nand thus exacerbate the effect of the pandemic. In this paper, we present our\nresults at the Constraint@AAAI2021 Shared Task: COVID-19 Fake News Detection in\nEnglish. In particular, we propose our approach using the transformer-based\nensemble of COVID-Twitter-BERT (CT-BERT) models. We describe the models used,\nthe ways of text preprocessing and adding extra data. As a result, our best\nmodel achieved the weighted F1-score of 98.69 on the test set (the first place\nin the leaderboard) of this shared task that attracted 166 submitted teams in\ntotal.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 12:43:12 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 09:29:13 GMT"}, {"version": "v3", "created": "Wed, 13 Jan 2021 11:36:32 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Glazkova", "Anna", ""], ["Glazkov", "Maksim", ""], ["Trifonov", "Timofey", ""]]}, {"id": "2012.11988", "submitter": "Shuai Lin", "authors": "Shuai Lin, Pan Zhou, Xiaodan Liang, Jianheng Tang, Ruihui Zhao,\n  Ziliang Chen, Liang Lin", "title": "Graph-Evolving Meta-Learning for Low-Resource Medical Dialogue\n  Generation", "comments": "Accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Human doctors with well-structured medical knowledge can diagnose a disease\nmerely via a few conversations with patients about symptoms. In contrast,\nexisting knowledge-grounded dialogue systems often require a large number of\ndialogue instances to learn as they fail to capture the correlations between\ndifferent diseases and neglect the diagnostic experience shared among them. To\naddress this issue, we propose a more natural and practical paradigm, i.e.,\nlow-resource medical dialogue generation, which can transfer the diagnostic\nexperience from source diseases to target ones with a handful of data for\nadaptation. It is capitalized on a commonsense knowledge graph to characterize\nthe prior disease-symptom relations. Besides, we develop a Graph-Evolving\nMeta-Learning (GEML) framework that learns to evolve the commonsense graph for\nreasoning disease-symptom correlations in a new disease, which effectively\nalleviates the needs of a large number of dialogues. More importantly, by\ndynamically evolving disease-symptom graphs, GEML also well addresses the\nreal-world challenges that the disease-symptom correlations of each disease may\nvary or evolve along with more diagnostic cases. Extensive experiment results\non the CMDD dataset and our newly-collected Chunyu dataset testify the\nsuperiority of our approach over state-of-the-art approaches. Besides, our GEML\ncan generate an enriched dialogue-sensitive knowledge graph in an online\nmanner, which could benefit other tasks grounded on knowledge graph.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 13:20:23 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Lin", "Shuai", ""], ["Zhou", "Pan", ""], ["Liang", "Xiaodan", ""], ["Tang", "Jianheng", ""], ["Zhao", "Ruihui", ""], ["Chen", "Ziliang", ""], ["Lin", "Liang", ""]]}, {"id": "2012.11995", "submitter": "Cheng-Han Chiang", "authors": "Cheng-Han Chiang and Hung-yi Lee", "title": "Pre-Training a Language Model Without Human Language", "comments": "9 pages, work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study how the intrinsic nature of pre-training data\ncontributes to the fine-tuned downstream performance. To this end, we pre-train\ndifferent transformer-based masked language models on several corpora with\ncertain features, and we fine-tune those language models on GLUE benchmarks. We\nfind that models pre-trained on unstructured data beat those trained directly\nfrom scratch on downstream tasks. Our results also show that pre-training on\nstructured data does not always make the model acquire ability that can be\ntransferred to natural language downstream tasks. To our great astonishment, we\nuncover that pre-training on certain non-human language data gives GLUE\nperformance close to performance pre-trained on another non-English language.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 13:38:06 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Chiang", "Cheng-Han", ""], ["Lee", "Hung-yi", ""]]}, {"id": "2012.12007", "submitter": "Yubo Xie", "authors": "Yubo Xie, Junze Li, Pearl Pu", "title": "Uncertainty and Surprisal Jointly Deliver the Punchline: Exploiting\n  Incongruity-Based Features for Humor Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humor recognition has been widely studied as a text classification problem\nusing data-driven approaches. However, most existing work does not examine the\nactual joke mechanism to understand humor. We break down any joke into two\ndistinct components: the set-up and the punchline, and further explore the\nspecial relationship between them. Inspired by the incongruity theory of humor,\nwe model the set-up as the part developing semantic uncertainty, and the\npunchline disrupting audience expectations. With increasingly powerful language\nmodels, we were able to feed the set-up along with the punchline into the GPT-2\nlanguage model, and calculate the uncertainty and surprisal values of the\njokes. By conducting experiments on the SemEval 2021 Task 7 dataset, we found\nthat these two features have better capabilities of telling jokes from\nnon-jokes, compared with existing baselines.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 13:48:09 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Xie", "Yubo", ""], ["Li", "Junze", ""], ["Pu", "Pearl", ""]]}, {"id": "2012.12065", "submitter": "Guy Rosin", "authors": "Guy D. Rosin, Ido Guy, Kira Radinsky", "title": "Event-Driven Query Expansion", "comments": "9 pages, WSDM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A significant number of event-related queries are issued in Web search. In\nthis paper, we seek to improve retrieval performance by leveraging events and\nspecifically target the classic task of query expansion. We propose a method to\nexpand an event-related query by first detecting the events related to it.\nThen, we derive the candidates for expansion as terms semantically related to\nboth the query and the events. To identify the candidates, we utilize a novel\nmechanism to simultaneously embed words and events in the same vector space. We\nshow that our proposed method of leveraging events improves query expansion\nperformance significantly compared with state-of-the-art methods on various\nnewswire TREC datasets.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 14:56:54 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Rosin", "Guy D.", ""], ["Guy", "Ido", ""], ["Radinsky", "Kira", ""]]}, {"id": "2012.12112", "submitter": "Raviraj Joshi", "authors": "Ramchandra Joshi, Rushabh Karnavat, Kaustubh Jirapure, Raviraj Joshi", "title": "Domain Adaptation of NMT models for English-Hindi Machine Translation\n  Task at AdapMT ICON 2020", "comments": "Accepted at AdaptMT ICON 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in Neural Machine Translation (NMT) models have proved to\nproduce a state of the art results on machine translation for low resource\nIndian languages. This paper describes the neural machine translation systems\nfor the English-Hindi language presented in AdapMT Shared Task ICON 2020. The\nshared task aims to build a translation system for Indian languages in specific\ndomains like Artificial Intelligence (AI) and Chemistry using a small in-domain\nparallel corpus. We evaluated the effectiveness of two popular NMT models i.e,\nLSTM, and Transformer architectures for the English-Hindi machine translation\ntask based on BLEU scores. We train these models primarily using the out of\ndomain data and employ simple domain adaptation techniques based on the\ncharacteristics of the in-domain dataset. The fine-tuning and mixed-domain data\napproaches are used for domain adaptation. Our team was ranked first in the\nchemistry and general domain En-Hi translation task and second in the AI domain\nEn-Hi translation task.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 15:46:40 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 11:59:51 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Joshi", "Ramchandra", ""], ["Karnavat", "Rushabh", ""], ["Jirapure", "Kaustubh", ""], ["Joshi", "Raviraj", ""]]}, {"id": "2012.12121", "submitter": "Cheng Yi", "authors": "Cheng Yi, Jianzhong Wang, Ning Cheng, Shiyu Zhou, Bo Xu", "title": "Applying Wav2vec2.0 to Speech Recognition in Various Low-resource\n  Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are several domains that own corresponding widely used feature\nextractors, such as ResNet, BERT, and GPT-x. These models are usually\npre-trained on large amounts of unlabeled data by self-supervision and can be\neffectively applied to downstream tasks. In the speech domain, wav2vec2.0\nstarts to show its powerful representation ability and feasibility of ultra-low\nresource speech recognition on the Librispeech corpus, which belongs to the\naudiobook domain. However, wav2vec2.0 has not been examined on real spoken\nscenarios and languages other than English. To verify its universality over\nlanguages, we apply pre-trained models to solve low-resource speech recognition\ntasks in various spoken languages. We achieve more than 20% relative\nimprovements in six languages compared with previous work. Among these\nlanguages, English achieves a gain of 52.4%. Moreover, using coarse-grained\nmodeling units, such as subword or character, achieves better results than\nfine-grained modeling units, such as phone or letter.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 15:59:44 GMT"}, {"version": "v2", "created": "Sun, 17 Jan 2021 16:29:50 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Yi", "Cheng", ""], ["Wang", "Jianzhong", ""], ["Cheng", "Ning", ""], ["Zhou", "Shiyu", ""], ["Xu", "Bo", ""]]}, {"id": "2012.12184", "submitter": "Mauricio Toro", "authors": "Santiago Cortes and Juan Mu\\~noz and David Betancur and Mauricio Toro", "title": "COVID-19 Emotion Monitoring as a Tool to Increase Preparedness for\n  Disease Outbreaks in Developing Regions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The COVID-19 pandemic brought many challenges, from hospital-occupation\nmanagement to lock-down mental-health repercussions such as anxiety or\ndepression. In this work, we present a solution for the later problem by\ndeveloping a Twitter emotion-monitor system based on a state-of-the-art\nnatural-language processing model. The system monitors six different emotions\non accounts in cities, as well as politicians and health-authorities Twitter\naccounts. With an anonymous use of the emotion monitor, health authorities and\nprivate health-insurance companies can develop strategies to tackle problems\nsuch as suicide and clinical depression. The model chosen for such a task is a\nBidirectional-Encoder Representations from Transformers (BERT) pre-trained on a\nSpanish corpus (BETO). The model performed well on a validation dataset. The\nsystem is deployed online as part of a web application for simulation and data\nanalysis of COVID-19, in Colombia, available at\nhttps://epidemiologia-matematica.org.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 12:58:06 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Cortes", "Santiago", ""], ["Mu\u00f1oz", "Juan", ""], ["Betancur", "David", ""], ["Toro", "Mauricio", ""]]}, {"id": "2012.12305", "submitter": "Svetlana Kiritchenko", "authors": "Svetlana Kiritchenko, Isar Nejadgholi, Kathleen C. Fraser", "title": "Confronting Abusive Language Online: A Survey from the Ethical and Human\n  Rights Perspective", "comments": "published in Journal of Artificial Intelligence Research, 71:\n  431-478, July 2021", "journal-ref": null, "doi": "10.1613/jair.1.12590", "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pervasiveness of abusive content on the internet can lead to severe\npsychological and physical harm. Significant effort in Natural Language\nProcessing (NLP) research has been devoted to addressing this problem through\nabusive content detection and related sub-areas, such as the detection of hate\nspeech, toxicity, cyberbullying, etc. Although current technologies achieve\nhigh classification performance in research studies, it has been observed that\nthe real-life application of this technology can cause unintended harms, such\nas the silencing of under-represented groups. We review a large body of NLP\nresearch on automatic abuse detection with a new focus on ethical challenges,\norganized around eight established ethical principles: privacy, accountability,\nsafety and security, transparency and explainability, fairness and\nnon-discrimination, human control of technology, professional responsibility,\nand promotion of human values. In many cases, these principles relate not only\nto situational ethical codes, which may be context-dependent, but are in fact\nconnected to universal human rights, such as the right to privacy, freedom from\ndiscrimination, and freedom of expression. We highlight the need to examine the\nbroad social impacts of this technology, and to bring ethical and human rights\nconsiderations to every stage of the application life-cycle, from task\nformulation and dataset design, to model training and evaluation, to\napplication deployment. Guided by these principles, we identify several\nopportunities for rights-respecting, socio-technical solutions to detect and\nconfront online abuse, including `nudging', `quarantining', value sensitive\ndesign, counter-narratives, style transfer, and AI-driven public education\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 19:27:11 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 16:53:43 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Kiritchenko", "Svetlana", ""], ["Nejadgholi", "Isar", ""], ["Fraser", "Kathleen C.", ""]]}, {"id": "2012.12311", "submitter": "Prashant Rajaram", "authors": "Prashant Rajaram and Puneet Manchanda", "title": "Video Influencers: Unboxing the Mystique", "comments": "61 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Influencer marketing is being used increasingly as a tool to reach customers\nbecause of the growing popularity of social media stars who primarily reach\ntheir audience(s) via custom videos. Despite the rapid growth in influencer\nmarketing, there has been little research on the design and effectiveness of\ninfluencer videos. Using publicly available data on YouTube influencer videos,\nwe implement novel interpretable deep learning architectures, supported by\ntransfer learning, to identify significant relationships between advertising\ncontent in videos (across text, audio, and images) and video views, interaction\nrates and sentiment. By avoiding ex-ante feature engineering and instead using\nex-post interpretation, our approach avoids making a trade-off between\ninterpretability and predictive ability. We filter out relationships that are\naffected by confounding factors unassociated with an increase in attention to\nvideo elements, thus facilitating the generation of plausible causal\nrelationships between video elements and marketing outcomes which can be tested\nin the field. A key finding is that brand mentions in the first 30 seconds of a\nvideo are on average associated with a significant increase in attention to the\nbrand but a significant decrease in sentiment expressed towards the video. We\nillustrate the learnings from our approach for both influencers and brands.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 19:32:52 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Rajaram", "Prashant", ""], ["Manchanda", "Puneet", ""]]}, {"id": "2012.12350", "submitter": "Zecheng He", "authors": "Zecheng He, Srinivas Sunkara, Xiaoxue Zang, Ying Xu, Lijuan Liu, Nevan\n  Wichers, Gabriel Schubiner, Ruby Lee, Jindong Chen and Blaise Ag\\\"uera y\n  Arcas", "title": "ActionBert: Leveraging User Actions for Semantic Understanding of User\n  Interfaces", "comments": "Accepted to AAAI Conference on Artificial Intelligence (AAAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As mobile devices are becoming ubiquitous, regularly interacting with a\nvariety of user interfaces (UIs) is a common aspect of daily life for many\npeople. To improve the accessibility of these devices and to enable their usage\nin a variety of settings, building models that can assist users and accomplish\ntasks through the UI is vitally important. However, there are several\nchallenges to achieve this. First, UI components of similar appearance can have\ndifferent functionalities, making understanding their function more important\nthan just analyzing their appearance. Second, domain-specific features like\nDocument Object Model (DOM) in web pages and View Hierarchy (VH) in mobile\napplications provide important signals about the semantics of UI elements, but\nthese features are not in a natural language format. Third, owing to a large\ndiversity in UIs and absence of standard DOM or VH representations, building a\nUI understanding model with high coverage requires large amounts of training\ndata.\n  Inspired by the success of pre-training based approaches in NLP for tackling\na variety of problems in a data-efficient way, we introduce a new pre-trained\nUI representation model called ActionBert. Our methodology is designed to\nleverage visual, linguistic and domain-specific features in user interaction\ntraces to pre-train generic feature representations of UIs and their\ncomponents. Our key intuition is that user actions, e.g., a sequence of clicks\non different UI components, reveals important information about their\nfunctionality. We evaluate the proposed model on a wide variety of downstream\ntasks, ranging from icon classification to UI component retrieval based on its\nnatural language description. Experiments show that the proposed ActionBert\nmodel outperforms multi-modal baselines across all downstream tasks by up to\n15.5%.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 20:49:52 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 20:37:39 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["He", "Zecheng", ""], ["Sunkara", "Srinivas", ""], ["Zang", "Xiaoxue", ""], ["Xu", "Ying", ""], ["Liu", "Lijuan", ""], ["Wichers", "Nevan", ""], ["Schubiner", "Gabriel", ""], ["Lee", "Ruby", ""], ["Chen", "Jindong", ""], ["Arcas", "Blaise Ag\u00fcera y", ""]]}, {"id": "2012.12352", "submitter": "Letitia Parcalabescu", "authors": "Letitia Parcalabescu and Albert Gatt and Anette Frank and Iacer\n  Calixto", "title": "Seeing past words: Testing the cross-modal capabilities of pretrained\n  V&L models on counting tasks", "comments": "Paper accepted for publication at MMSR 2021; 13 pages, 3 figures, 7\n  Tables", "journal-ref": "Proceedings of the 1st Workshop on Multimodal Semantic\n  Representations (MMSR), 2021, Groningen, Netherlands (Online), Association\n  for Computational Linguistics, p. 32--44", "doi": null, "report-no": null, "categories": "cs.CV cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the reasoning ability of pretrained vision and language (V&L)\nmodels in two tasks that require multimodal integration: (1) discriminating a\ncorrect image-sentence pair from an incorrect one, and (2) counting entities in\nan image. We evaluate three pretrained V&L models on these tasks: ViLBERT,\nViLBERT 12-in-1 and LXMERT, in zero-shot and finetuned settings. Our results\nshow that models solve task (1) very well, as expected, since all models are\npretrained on task (1). However, none of the pretrained V&L models is able to\nadequately solve task (2), our counting probe, and they cannot generalise to\nout-of-distribution quantities. We propose a number of explanations for these\nfindings: LXMERT (and to some extent ViLBERT 12-in-1) show some evidence of\ncatastrophic forgetting on task (1). Concerning our results on the counting\nprobe, we find evidence that all models are impacted by dataset bias, and also\nfail to individuate entities in the visual input. While a selling point of\npretrained V&L models is their ability to solve complex tasks, our findings\nsuggest that understanding their reasoning and grounding capabilities requires\nmore targeted investigations on specific phenomena.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 21:01:44 GMT"}, {"version": "v2", "created": "Fri, 7 May 2021 16:38:24 GMT"}, {"version": "v3", "created": "Mon, 24 May 2021 11:03:08 GMT"}, {"version": "v4", "created": "Thu, 17 Jun 2021 17:51:56 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Parcalabescu", "Letitia", ""], ["Gatt", "Albert", ""], ["Frank", "Anette", ""], ["Calixto", "Iacer", ""]]}, {"id": "2012.12366", "submitter": "Casper Hansen", "authors": "Dongsheng Wang and Casper Hansen and Lucas Chaves Lima and Christian\n  Hansen and Maria Maistro and Jakob Grue Simonsen and Christina Lioma", "title": "Multi-Head Self-Attention with Role-Guided Masks", "comments": "Accepted at ECIR@2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state of the art in learning meaningful semantic representations of words\nis the Transformer model and its attention mechanisms. Simply put, the\nattention mechanisms learn to attend to specific parts of the input dispensing\nrecurrence and convolutions. While some of the learned attention heads have\nbeen found to play linguistically interpretable roles, they can be redundant or\nprone to errors. We propose a method to guide the attention heads towards roles\nidentified in prior work as important. We do this by defining role-specific\nmasks to constrain the heads to attend to specific parts of the input, such\nthat different heads are designed to play different roles. Experiments on text\nclassification and machine translation using 7 different datasets show that our\nmethod outperforms competitive attention-based, CNN, and RNN baselines.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 21:34:02 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Wang", "Dongsheng", ""], ["Hansen", "Casper", ""], ["Lima", "Lucas Chaves", ""], ["Hansen", "Christian", ""], ["Maistro", "Maria", ""], ["Simonsen", "Jakob Grue", ""], ["Lioma", "Christina", ""]]}, {"id": "2012.12382", "submitter": "Reno Kriz", "authors": "Reno Kriz, Marianna Apidianaki, Chris Callison-Burch", "title": "Simple-QE: Better Automatic Quality Estimation for Text Simplification", "comments": "4 pages, 1 figure, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Text simplification systems generate versions of texts that are easier to\nunderstand for a broader audience. The quality of simplified texts is generally\nestimated using metrics that compare to human references, which can be\ndifficult to obtain. We propose Simple-QE, a BERT-based quality estimation (QE)\nmodel adapted from prior summarization QE work, and show that it correlates\nwell with human quality judgments. Simple-QE does not require human references,\nwhich makes the model useful in a practical setting where users would need to\nbe informed about the quality of generated simplifications. We also show that\nwe can adapt this approach to accurately predict the complexity of\nhuman-written texts.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 22:02:37 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Kriz", "Reno", ""], ["Apidianaki", "Marianna", ""], ["Callison-Burch", "Chris", ""]]}, {"id": "2012.12458", "submitter": "Bill Byrne", "authors": "Bill Byrne, Karthik Krishnamoorthi, Saravanan Ganesh, Mihir Sanjay\n  Kale", "title": "TicketTalk: Toward human-level performance with end-to-end,\n  transaction-based dialog systems", "comments": "Eight pages, 4 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present a data-driven, end-to-end approach to transaction-based dialog\nsystems that performs at near-human levels in terms of verbal response quality\nand factual grounding accuracy. We show that two essential components of the\nsystem produce these results: a sufficiently large and diverse, in-domain\nlabeled dataset, and a neural network-based, pre-trained model that generates\nboth verbal responses and API call predictions. In terms of data, we introduce\nTicketTalk, a movie ticketing dialog dataset with 23,789 annotated\nconversations. The movie ticketing conversations range from completely\nopen-ended and unrestricted to more structured, both in terms of their\nknowledge base, discourse features, and number of turns. In qualitative human\nevaluations, model-generated responses trained on just 10,000 TicketTalk\ndialogs were rated to \"make sense\" 86.5 percent of the time, almost the same as\nhuman responses in the same contexts. Our simple, API-focused annotation schema\nresults in a much easier labeling task making it faster and more cost\neffective. It is also the key component for being able to predict API calls\naccurately. We handle factual grounding by incorporating API calls in the\ntraining data, allowing our model to learn which actions to take and when.\nTrained on the same 10,000-dialog set, the model's API call predictions were\nrated to be correct 93.9 percent of the time in our evaluations, surpassing the\nratings for the corresponding human labels. We show how API prediction and\nresponse generation scores improve as the dataset size incrementally increases\nfrom 5000 to 21,000 dialogs. Our analysis also clearly illustrates the benefits\nof pre-training. We are publicly releasing the TicketTalk dataset with this\npaper to facilitate future work on transaction-based dialogs.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 02:43:37 GMT"}, {"version": "v2", "created": "Sun, 27 Dec 2020 20:51:17 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Byrne", "Bill", ""], ["Krishnamoorthi", "Karthik", ""], ["Ganesh", "Saravanan", ""], ["Kale", "Mihir Sanjay", ""]]}, {"id": "2012.12465", "submitter": "Shaolei Zhang", "authors": "Shaolei Zhang, Yang Feng, Liangyou Li", "title": "Future-Guided Incremental Transformer for Simultaneous Translation", "comments": "Accepted by AAAI 2021. 9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneous translation (ST) starts translations synchronously while reading\nsource sentences, and is used in many online scenarios. The previous wait-k\npolicy is concise and achieved good results in ST. However, wait-k policy faces\ntwo weaknesses: low training speed caused by the recalculation of hidden states\nand lack of future source information to guide training. For the low training\nspeed, we propose an incremental Transformer with an average embedding layer\n(AEL) to accelerate the speed of calculation of the hidden states during\ntraining. For future-guided training, we propose a conventional Transformer as\nthe teacher of the incremental Transformer, and try to invisibly embed some\nfuture information in the model through knowledge distillation. We conducted\nexperiments on Chinese-English and German-English simultaneous translation\ntasks and compared with the wait-k policy to evaluate the proposed method. Our\nmethod can effectively increase the training speed by about 28 times on average\nat different k and implicitly embed some predictive abilities in the model,\nachieving better translation quality than wait-k baseline.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 03:04:49 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Zhang", "Shaolei", ""], ["Feng", "Yang", ""], ["Li", "Liangyou", ""]]}, {"id": "2012.12543", "submitter": "Asad Ullah", "authors": "Asad Ullah, Tauseef Ahmed", "title": "Code Switching Language Model Using Monolingual Training Data", "comments": "submitted to ICASSP2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training a code-switching (CS) language model using only monolingual data is\nstill an ongoing research problem. In this paper, a CS language model is\ntrained using only monolingual training data. As recurrent neural network (RNN)\nmodels are best suited for predicting sequential data. In this work, an RNN\nlanguage model is trained using alternate batches from only monolingual English\nand Spanish data and the perplexity of the language model is computed. From the\nresults, it is concluded that using alternate batches of monolingual data in\ntraining reduced the perplexity of a CS language model. The results were\nconsistently improved using mean square error (MSE) in the output embeddings of\nRNN based language model. By combining both methods, perplexity is reduced from\n299.63 to 80.38. The proposed methods were comparable to the language model\nfine tune with code-switch training data.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 08:56:39 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 02:13:43 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Ullah", "Asad", ""], ["Ahmed", "Tauseef", ""]]}, {"id": "2012.12573", "submitter": "Wei Qiu", "authors": "Yue Guo, Wei Qiu, Yizhong Wang, Trevor Cohen", "title": "Automated Lay Language Summarization of Biomedical Scientific Reviews", "comments": "Yue Guo and Wei Qiu contribute equally to this work. This paper is\n  accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Health literacy has emerged as a crucial factor in making appropriate health\ndecisions and ensuring treatment outcomes. However, medical jargon and the\ncomplex structure of professional language in this domain make health\ninformation especially hard to interpret. Thus, there is an urgent unmet need\nfor automated methods to enhance the accessibility of the biomedical literature\nto the general population. This problem can be framed as a type of translation\nproblem between the language of healthcare professionals, and that of the\ngeneral public. In this paper, we introduce the novel task of automated\ngeneration of lay language summaries of biomedical scientific reviews, and\nconstruct a dataset to support the development and evaluation of automated\nmethods through which to enhance the accessibility of the biomedical\nliterature. We conduct analyses of the various challenges in solving this task,\nincluding not only summarization of the key points but also explanation of\nbackground knowledge and simplification of professional language. We experiment\nwith state-of-the-art summarization models as well as several data augmentation\ntechniques, and evaluate their performance using both automated metrics and\nhuman assessment. Results indicate that automatically generated summaries\nproduced using contemporary neural architectures can achieve promising quality\nand readability as compared with reference summaries developed for the lay\npublic by experts (best ROUGE-L of 50.24 and Flesch-Kincaid readability score\nof 13.30). We also discuss the limitations of the current attempt, providing\ninsights and directions for future work.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 10:01:18 GMT"}, {"version": "v2", "created": "Sat, 24 Jul 2021 08:13:53 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Guo", "Yue", ""], ["Qiu", "Wei", ""], ["Wang", "Yizhong", ""], ["Cohen", "Trevor", ""]]}, {"id": "2012.12624", "submitter": "Jinhyuk Lee", "authors": "Jinhyuk Lee, Mujeen Sung, Jaewoo Kang, Danqi Chen", "title": "Learning Dense Representations of Phrases at Scale", "comments": "ACL 2021. Code available at\n  https://github.com/princeton-nlp/DensePhrases", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-domain question answering can be reformulated as a phrase retrieval\nproblem, without the need for processing documents on-demand during inference\n(Seo et al., 2019). However, current phrase retrieval models heavily depend on\nsparse representations and still underperform retriever-reader approaches. In\nthis work, we show for the first time that we can learn dense representations\nof phrases alone that achieve much stronger performance in open-domain QA. We\npresent an effective method to learn phrase representations from the\nsupervision of reading comprehension tasks, coupled with novel negative\nsampling methods. We also propose a query-side fine-tuning strategy, which can\nsupport transfer learning and reduce the discrepancy between training and\ninference. On five popular open-domain QA datasets, our model DensePhrases\nimproves over previous phrase retrieval models by 15%-25% absolute accuracy and\nmatches the performance of state-of-the-art retriever-reader models. Our model\nis easy to parallelize due to pure dense representations and processes more\nthan 10 questions per second on CPUs. Finally, we directly use our pre-indexed\ndense phrase representations for two slot filling tasks, showing the promise of\nutilizing DensePhrases as a dense knowledge base for downstream tasks.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 12:28:17 GMT"}, {"version": "v2", "created": "Sat, 2 Jan 2021 00:42:50 GMT"}, {"version": "v3", "created": "Wed, 2 Jun 2021 12:20:23 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Lee", "Jinhyuk", ""], ["Sung", "Mujeen", ""], ["Kang", "Jaewoo", ""], ["Chen", "Danqi", ""]]}, {"id": "2012.12627", "submitter": "Xi Victoria Lin", "authors": "Xi Victoria Lin and Richard Socher and Caiming Xiong", "title": "Bridging Textual and Tabular Data for Cross-Domain Text-to-SQL Semantic\n  Parsing", "comments": "EMNLP Findings 2020 long paper extended; 23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DB cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present BRIDGE, a powerful sequential architecture for modeling\ndependencies between natural language questions and relational databases in\ncross-DB semantic parsing. BRIDGE represents the question and DB schema in a\ntagged sequence where a subset of the fields are augmented with cell values\nmentioned in the question. The hybrid sequence is encoded by BERT with minimal\nsubsequent layers and the text-DB contextualization is realized via the\nfine-tuned deep attention in BERT. Combined with a pointer-generator decoder\nwith schema-consistency driven search space pruning, BRIDGE attained\nstate-of-the-art performance on popular cross-DB text-to-SQL benchmarks, Spider\n(71.1\\% dev, 67.5\\% test with ensemble model) and WikiSQL (92.6\\% dev, 91.9\\%\ntest). Our analysis shows that BRIDGE effectively captures the desired\ncross-modal dependencies and has the potential to generalize to more text-DB\nrelated tasks. Our implementation is available at\n\\url{https://github.com/salesforce/TabularSemanticParsing}.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 12:33:52 GMT"}, {"version": "v2", "created": "Thu, 31 Dec 2020 01:02:40 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Lin", "Xi Victoria", ""], ["Socher", "Richard", ""], ["Xiong", "Caiming", ""]]}, {"id": "2012.12641", "submitter": "Frieder Stolzenburg", "authors": "Claudia Schon, Sophie Siebert, Frieder Stolzenburg", "title": "Negation in Cognitive Reasoning", "comments": "18 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Negation is both an operation in formal logic and in natural language by\nwhich a proposition is replaced by one stating the opposite, as by the addition\nof \"not\" or another negation cue. Treating negation in an adequate way is\nrequired for cognitive reasoning, which aims at modeling the human ability to\ndraw meaningful conclusions despite incomplete and inconsistent knowledge. One\ntask of cognitive reasoning is answering questions given by sentences in\nnatural language. There are tools based on discourse representation theory to\nconvert sentences automatically into a formal logic representation, and\nadditional knowledge can be added using the predicate names in the formula and\nknowledge databases. However, the knowledge in logic databases in practice\nalways is incomplete. Hence, forward reasoning of automated reasoning systems\nalone does not suffice to derive answers to questions because, instead of\ncomplete proofs, often only partial positive knowledge can be derived, while\nnegative knowledge is used only during the reasoning process. In consequence,\nwe aim at eliminating syntactic negation, strictly speaking, the negated event\nor property. In this paper, we describe an effective procedure to determine the\nnegated event or property in order to replace it by its inverse. This lays the\nbasis of cognitive reasoning, employing both logic and machine learning for\ngeneral question answering. We evaluate our procedure by several benchmarks and\ndemonstrate its practical usefulness in our cognitive reasoning system.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 13:22:53 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 11:55:19 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Schon", "Claudia", ""], ["Siebert", "Sophie", ""], ["Stolzenburg", "Frieder", ""]]}, {"id": "2012.12756", "submitter": "Soumitra Ghosh", "authors": "Soumitra Ghosh, Arkaprava Roy, Asif Ekbal and Pushpak Bhattacharyya", "title": "EmotionGIF-IITP-AINLPML: Ensemble-based Automated Deep Neural System for\n  predicting category(ies) of a GIF response", "comments": "EmotionGIF 2020, the shared task of SocialNLP 2020 (in conjunction\n  with ACL 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we describe the systems submitted by our IITP-AINLPML team in\nthe shared task of SocialNLP 2020, EmotionGIF 2020, on predicting the\ncategory(ies) of a GIF response for a given unlabelled tweet. For the round 1\nphase of the task, we propose an attention-based Bi-directional GRU network\ntrained on both the tweet (text) and their replies (text wherever available)\nand the given category(ies) for its GIF response. In the round 2 phase, we\nbuild several deep neural-based classifiers for the task and report the final\npredictions through a majority voting based ensemble technique. Our proposed\nmodels attain the best Mean Recall (MR) scores of 52.92% and 53.80% in round 1\nand round 2, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 15:52:27 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Ghosh", "Soumitra", ""], ["Roy", "Arkaprava", ""], ["Ekbal", "Asif", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "2012.12799", "submitter": "Guillermo Marco Rem\\'on", "authors": "Guillermo Marco Rem\\'on, Julio Gonzalo", "title": "Automatic Scansion of Spanish Poetry without Syllabification", "comments": "in Spanish. Under review for the journal Procesamiento del Lenguaje\n  Natural http://www.sepln.org/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, several systems of automated metric analysis of Spanish\npoetry have emerged. These systems rely on complex methods of syllabification\nand stress assignment, which use PoS-tagging libraries, whose computational\ncost is high. This cost increases with the calculation of metric ambiguities.\nFurthermore, they do not consider determining issues in syllabic count such as\nthe phenomena of compensation between hemistichs of verses of more than eleven\nsyllables. However, it is possible to carry out an informative and accurate\nmetric analysis without using these costly methods. We propose an algorithm\nthat performs accurate scansion (number of syllables, stress pattern and type\nof verse) without syllabification. It addresses metric ambiguities and takes\ninto account the hemistichs compensation. Our algorithm outperforms the current\nstate of the art by 2% in fixed-metre poetry, and 25% in mixed-metre poetry. It\nalso runs 21 and 25 times faster, respectively. Finally, a desktop application\nis offered as a tool for researchers of Spanish poetry.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 16:59:43 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Rem\u00f3n", "Guillermo Marco", ""], ["Gonzalo", "Julio", ""]]}, {"id": "2012.12871", "submitter": "Nithin Holla", "authors": "Phillip Lippe, Nithin Holla, Shantanu Chandra, Santhosh Rajamanickam,\n  Georgios Antoniou, Ekaterina Shutova, Helen Yannakoudakis", "title": "A Multimodal Framework for the Detection of Hateful Memes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasingly common expression of online hate speech is multimodal in\nnature and comes in the form of memes. Designing systems to automatically\ndetect hateful content is of paramount importance if we are to mitigate its\nundesirable effects on the society at large. The detection of multimodal hate\nspeech is an intrinsically difficult and open problem: memes convey a message\nusing both images and text and, hence, require multimodal reasoning and joint\nvisual and language understanding. In this work, we seek to advance this line\nof research and develop a multimodal framework for the detection of hateful\nmemes. We improve the performance of existing multimodal approaches beyond\nsimple fine-tuning and, among others, show the effectiveness of upsampling of\ncontrastive examples to encourage multimodality and ensemble learning based on\ncross-validation to improve robustness. We furthermore analyze model\nmisclassifications and discuss a number of hypothesis-driven augmentations and\ntheir effects on performance, presenting important implications for future\nresearch in the field. Our best approach comprises an ensemble of UNITER-based\nmodels and achieves an AUROC score of 80.53, placing us 4th on phase 2 of the\n2020 Hateful Memes Challenge organized by Facebook.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 18:37:11 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 14:28:17 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Lippe", "Phillip", ""], ["Holla", "Nithin", ""], ["Chandra", "Shantanu", ""], ["Rajamanickam", "Santhosh", ""], ["Antoniou", "Georgios", ""], ["Shutova", "Ekaterina", ""], ["Yannakoudakis", "Helen", ""]]}, {"id": "2012.12975", "submitter": "Riza Velioglu", "authors": "Riza Velioglu, Jewgeni Rose", "title": "Detecting Hate Speech in Memes Using Multimodal Deep Learning\n  Approaches: Prize-winning solution to Hateful Memes Challenge", "comments": "Presented at NeurIPS (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memes on the Internet are often harmless and sometimes amusing. However, by\nusing certain types of images, text, or combinations of both, the seemingly\nharmless meme becomes a multimodal type of hate speech -- a hateful meme. The\nHateful Memes Challenge is a first-of-its-kind competition which focuses on\ndetecting hate speech in multimodal memes and it proposes a new data set\ncontaining 10,000+ new examples of multimodal content. We utilize VisualBERT --\nwhich meant to be the BERT of vision and language -- that was trained\nmultimodally on images and captions and apply Ensemble Learning. Our approach\nachieves 0.811 AUROC with an accuracy of 0.765 on the challenge test set and\nplaced third out of 3,173 participants in the Hateful Memes Challenge.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 21:09:52 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Velioglu", "Riza", ""], ["Rose", "Jewgeni", ""]]}, {"id": "2012.13004", "submitter": "Prasanna Kumar Muthukumar", "authors": "Deblin Bagchi, Shannon Wotherspoon, Zhuolin Jiang and Prasanna\n  Muthukumar", "title": "Speech Synthesis as Augmentation for Low-Resource ASR", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Speech synthesis might hold the key to low-resource speech recognition. Data\naugmentation techniques have become an essential part of modern speech\nrecognition training. Yet, they are simple, naive, and rarely reflect\nreal-world conditions. Meanwhile, speech synthesis techniques have been rapidly\ngetting closer to the goal of achieving human-like speech. In this paper, we\ninvestigate the possibility of using synthesized speech as a form of data\naugmentation to lower the resources necessary to build a speech recognizer. We\nexperiment with three different kinds of synthesizers: statistical parametric,\nneural, and adversarial. Our findings are interesting and point to new research\ndirections for the future.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 22:19:42 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Bagchi", "Deblin", ""], ["Wotherspoon", "Shannon", ""], ["Jiang", "Zhuolin", ""], ["Muthukumar", "Prasanna", ""]]}, {"id": "2012.13023", "submitter": "Nurendra Choudhary", "authors": "Nurendra Choudhary, Nikhil Rao, Sumeet Katariya, Karthik Subbian,\n  Chandan K. Reddy", "title": "Self-Supervised Hyperboloid Representations from Logical Queries over\n  Knowledge Graphs", "comments": "Accepted at the Web Conference 2021 (WWW '21)", "journal-ref": null, "doi": "10.1145/3442381.3449974", "report-no": null, "categories": "cs.LG cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge Graphs (KGs) are ubiquitous structures for information storagein\nseveral real-world applications such as web search, e-commerce, social\nnetworks, and biology. Querying KGs remains a foundational and challenging\nproblem due to their size and complexity. Promising approaches to tackle this\nproblem include embedding the KG units (e.g., entities and relations) in a\nEuclidean space such that the query embedding contains the information relevant\nto its results. These approaches, however, fail to capture the hierarchical\nnature and semantic information of the entities present in the graph.\nAdditionally, most of these approaches only utilize multi-hop queries (that can\nbe modeled by simple translation operations) to learn embeddings and ignore\nmore complex operations such as intersection and union of simpler queries. To\ntackle such complex operations, in this paper, we formulate KG representation\nlearning as a self-supervised logical query reasoning problem that utilizes\ntranslation, intersection and union queries over KGs. We propose Hyperboloid\nEmbeddings (HypE), a novel self-supervised dynamic reasoning framework, that\nutilizes positive first-order existential queries on a KG to learn\nrepresentations of its entities and relations as hyperboloids in a Poincar\\'e\nball. HypE models the positive first-order queries as geometrical translation,\nintersection, and union. For the problem of KG reasoning in real-world\ndatasets, the proposed HypE model significantly outperforms the state-of-the\nart results. We also apply HypE to an anomaly detection task on a popular\ne-commerce website product taxonomy as well as hierarchically organized web\narticles and demonstrate significant performance improvements compared to\nexisting baseline methods. Finally, we also visualize the learned HypE\nembeddings in a Poincar\\'e ball to clearly interpret and comprehend the\nrepresentation space.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 23:19:00 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 02:17:31 GMT"}, {"version": "v3", "created": "Wed, 12 May 2021 19:23:14 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Choudhary", "Nurendra", ""], ["Rao", "Nikhil", ""], ["Katariya", "Sumeet", ""], ["Subbian", "Karthik", ""], ["Reddy", "Chandan K.", ""]]}, {"id": "2012.13031", "submitter": "Ghazi Felhi", "authors": "Ghazi Felhi, Joseph Le Roux, Djam\\'e Seddah", "title": "Disentangling semantics in language through VAEs and a certain\n  architectural choice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an unsupervised method to obtain disentangled representations of\nsentences that single out semantic content. Using modified Transformers as\nbuilding blocks, we train a Variational Autoencoder to translate the sentence\nto a fixed number of hierarchically structured latent variables. We study the\ninfluence of each latent variable in generation on the dependency structure of\nsentences, and on the predicate structure it yields when passed through an Open\nInformation Extraction model. Our model could separate verbs, subjects, direct\nobjects, and prepositional objects into latent variables we identified. We show\nthat varying the corresponding latent variables results in varying these\nelements in sentences, and that swapping them between couples of sentences\nleads to the expected partial semantic swap.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 00:01:40 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 18:48:35 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Felhi", "Ghazi", ""], ["Roux", "Joseph Le", ""], ["Seddah", "Djam\u00e9", ""]]}, {"id": "2012.13042", "submitter": "Soroush Vosoughi Dr", "authors": "Xiaobo Guo, Soroush Vosoughi", "title": "Multi-modal Identification of State-Sponsored Propaganda on Social Media", "comments": "Proceedings of the 25th International Conference on Pattern\n  Recognition (ICPR 2020)", "journal-ref": null, "doi": "10.1109/ICPR48806.2021.9412672", "report-no": null, "categories": "cs.CL cs.AI cs.SI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The prevalence of state-sponsored propaganda on the Internet has become a\ncause for concern in the recent years. While much effort has been made to\nidentify state-sponsored Internet propaganda, the problem remains far from\nbeing solved because the ambiguous definition of propaganda leads to unreliable\ndata labelling, and the huge amount of potential predictive features causes the\nmodels to be inexplicable. This paper is the first attempt to build a balanced\ndataset for this task. The dataset is comprised of propaganda by three\ndifferent organizations across two time periods. A multi-model framework for\ndetecting propaganda messages solely based on the visual and textual content is\nproposed which achieves a promising performance on detecting propaganda by the\nthree organizations both for the same time period (training and testing on data\nfrom the same time period) (F1=0.869) and for different time periods (training\non past, testing on future) (F1=0.697). To reduce the influence of false\npositive predictions, we change the threshold to test the relationship between\nthe false positive and true positive rates and provide explanations for the\npredictions made by our models with visualization tools to enhance the\ninterpretability of our framework. Our new dataset and general framework\nprovide a strong benchmark for the task of identifying state-sponsored Internet\npropaganda and point out a potential path for future work on this task.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 00:43:09 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Guo", "Xiaobo", ""], ["Vosoughi", "Soroush", ""]]}, {"id": "2012.13048", "submitter": "Peter Clark", "authors": "Oyvind Tafjord, Bhavana Dalvi Mishra, Peter Clark", "title": "ProofWriter: Generating Implications, Proofs, and Abductive Statements\n  over Natural Language", "comments": "Findings of ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers have been shown to emulate logical deduction over natural\nlanguage theories (logical rules expressed in natural language), reliably\nassigning true/false labels to candidate implications. However, their ability\nto generate implications of a theory has not yet been demonstrated, and methods\nfor reconstructing proofs of answers are imperfect. In this work we show that a\ngenerative model, called ProofWriter, can reliably generate both implications\nof a theory and the natural language proof(s) that support them. In particular,\niterating a 1-step implication generator results in proofs that are highly\nreliable, and represent actual model decisions (rather than post-hoc\nrationalizations). On the RuleTaker dataset, the accuracy of ProofWriter's\nproofs exceed previous methods by +9% absolute, and in a way that generalizes\nto proof depths unseen in training and on out-of-domain problems. We also show\nthat generative techniques can perform a type of abduction with high precision:\nGiven a theory and an unprovable conclusion, identify a missing fact that\nallows the conclusion to be proved, along with a proof. These results\nsignificantly improve the viability of neural methods for systematically\nreasoning over natural language.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 00:55:46 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 19:15:08 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Tafjord", "Oyvind", ""], ["Mishra", "Bhavana Dalvi", ""], ["Clark", "Peter", ""]]}, {"id": "2012.13122", "submitter": "Naeha Sharif", "authors": "Naeha Sharif, Mohammed Bennamoun, Wei Liu, Syed Afaq Ali Shah", "title": "SubICap: Towards Subword-informed Image Captioning", "comments": "8 pages", "journal-ref": "Workshop on Applications of Computer Vision (WACV), 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing Image Captioning (IC) systems model words as atomic units in\ncaptions and are unable to exploit the structural information in the words.\nThis makes representation of rare words very difficult and out-of-vocabulary\nwords impossible. Moreover, to avoid computational complexity, existing IC\nmodels operate over a modest sized vocabulary of frequent words, such that the\nidentity of rare words is lost. In this work we address this common limitation\nof IC systems in dealing with rare words in the corpora. We decompose words\ninto smaller constituent units 'subwords' and represent captions as a sequence\nof subwords instead of words. This helps represent all words in the corpora\nusing a significantly lower subword vocabulary, leading to better parameter\nlearning. Using subword language modeling, our captioning system improves\nvarious metric scores, with a training vocabulary size approximately 90% less\nthan the baseline and various state-of-the-art word-level models. Our\nquantitative and qualitative results and analysis signify the efficacy of our\nproposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 06:10:36 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Sharif", "Naeha", ""], ["Bennamoun", "Mohammed", ""], ["Liu", "Wei", ""], ["Shah", "Syed Afaq Ali", ""]]}, {"id": "2012.13137", "submitter": "Naeha Sharif", "authors": "Naeha Sharif, Lyndon White, Mohammed Bennamoun, Wei Liu, Syed Afaq Ali\n  Shah", "title": "WEmbSim: A Simple yet Effective Metric for Image Captioning", "comments": "7 pages", "journal-ref": "International Conference on Digital Image Computing: Techniques\n  and Applications (DICTA), 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The area of automatic image caption evaluation is still undergoing intensive\nresearch to address the needs of generating captions which can meet adequacy\nand fluency requirements. Based on our past attempts at developing highly\nsophisticated learning-based metrics, we have discovered that a simple cosine\nsimilarity measure using the Mean of Word Embeddings(MOWE) of captions can\nactually achieve a surprisingly high performance on unsupervised caption\nevaluation. This inspires our proposed work on an effective metric WEmbSim,\nwhich beats complex measures such as SPICE, CIDEr and WMD at system-level\ncorrelation with human judgments. Moreover, it also achieves the best accuracy\nat matching human consensus scores for caption pairs, against commonly used\nunsupervised methods. Therefore, we believe that WEmbSim sets a new baseline\nfor any complex metric to be justified.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 06:39:43 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Sharif", "Naeha", ""], ["White", "Lyndon", ""], ["Bennamoun", "Mohammed", ""], ["Liu", "Wei", ""], ["Shah", "Syed Afaq Ali", ""]]}, {"id": "2012.13152", "submitter": "Yu Tsao", "authors": "Xugang Lu, Peng Shen, Yu Tsao, Hisashi Kawai", "title": "Unsupervised neural adaptation model based on optimal transport for\n  spoken language identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the mismatch of statistical distributions of acoustic speech between\ntraining and testing sets, the performance of spoken language identification\n(SLID) could be drastically degraded. In this paper, we propose an unsupervised\nneural adaptation model to deal with the distribution mismatch problem for\nSLID. In our model, we explicitly formulate the adaptation as to reduce the\ndistribution discrepancy on both feature and classifier for training and\ntesting data sets. Moreover, inspired by the strong power of the optimal\ntransport (OT) to measure distribution discrepancy, a Wasserstein distance\nmetric is designed in the adaptation loss. By minimizing the classification\nloss on the training data set with the adaptation loss on both training and\ntesting data sets, the statistical distribution difference between training and\ntesting domains is reduced. We carried out SLID experiments on the oriental\nlanguage recognition (OLR) challenge data corpus where the training and testing\ndata sets were collected from different conditions. Our results showed that\nsignificant improvements were achieved on the cross domain test tasks.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 07:37:19 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Lu", "Xugang", ""], ["Shen", "Peng", ""], ["Tsao", "Yu", ""], ["Kawai", "Hisashi", ""]]}, {"id": "2012.13163", "submitter": "Zuchao Li", "authors": "Kailai Sun, Zuchao Li, Hai Zhao", "title": "Cross-lingual Universal Dependency Parsing Only from One Monolingual\n  Treebank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syntactic parsing is a highly linguistic processing task whose parser\nrequires training on treebanks from the expensive human annotation. As it is\nunlikely to obtain a treebank for every human language, in this work, we\npropose an effective cross-lingual UD parsing framework for transferring parser\nfrom only one source monolingual treebank to any other target languages without\ntreebank available. To reach satisfactory parsing accuracy among quite\ndifferent languages, we introduce two language modeling tasks into dependency\nparsing as multi-tasking. Assuming only unlabeled data from target languages\nplus the source treebank can be exploited together, we adopt a self-training\nstrategy for further performance improvement in terms of our multi-task\nframework. Our proposed cross-lingual parsers are implemented for English,\nChinese, and 22 UD treebanks. The empirical study shows that our cross-lingual\nparsers yield promising results for all target languages, for the first time,\napproaching the parser performance which is trained in its own target treebank.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 08:14:36 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 06:36:16 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Sun", "Kailai", ""], ["Li", "Zuchao", ""], ["Zhao", "Hai", ""]]}, {"id": "2012.13176", "submitter": "Marta R. Costa-juss\\`a", "authors": "Marta R. Costa-juss\\`a, Carlos Escolano, Christine Basta, Javier\n  Ferrando, Roser Batlle and Ksenia Kharitonova", "title": "Gender Bias in Multilingual Neural Machine Translation: The Architecture\n  Matters", "comments": "12 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual Neural Machine Translation architectures mainly differ in the\namount of sharing modules and parameters among languages. In this paper, and\nfrom an algorithmic perspective, we explore if the chosen architecture, when\ntrained with the same data, influences the gender bias accuracy. Experiments in\nfour language pairs show that Language-Specific encoders-decoders exhibit less\nbias than the Shared encoder-decoder architecture. Further interpretability\nanalysis of source embeddings and the attention shows that, in the\nLanguage-Specific case, the embeddings encode more gender information, and its\nattention is more diverted. Both behaviors help in mitigating gender bias.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 09:27:52 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Costa-juss\u00e0", "Marta R.", ""], ["Escolano", "Carlos", ""], ["Basta", "Christine", ""], ["Ferrando", "Javier", ""], ["Batlle", "Roser", ""], ["Kharitonova", "Ksenia", ""]]}, {"id": "2012.13185", "submitter": "Yinya Huang", "authors": "Yinya Huang, Meng Fang, Xunlin Zhan, Qingxing Cao, Xiaodan Liang,\n  Liang Lin", "title": "REM-Net: Recursive Erasure Memory Network for Commonsense Evidence\n  Refinement", "comments": "Accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When answering a question, people often draw upon their rich world knowledge\nin addition to the particular context. While recent works retrieve supporting\nfacts/evidence from commonsense knowledge bases to supply additional\ninformation to each question, there is still ample opportunity to advance it on\nthe quality of the evidence. It is crucial since the quality of the evidence is\nthe key to answering commonsense questions, and even determines the upper bound\non the QA systems performance. In this paper, we propose a recursive erasure\nmemory network (REM-Net) to cope with the quality improvement of evidence. To\naddress this, REM-Net is equipped with a module to refine the evidence by\nrecursively erasing the low-quality evidence that does not explain the question\nanswering. Besides, instead of retrieving evidence from existing knowledge\nbases, REM-Net leverages a pre-trained generative model to generate candidate\nevidence customized for the question. We conduct experiments on two commonsense\nquestion answering datasets, WIQA and CosmosQA. The results demonstrate the\nperformance of REM-Net and show that the refined evidence is explainable.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 10:07:32 GMT"}, {"version": "v2", "created": "Sun, 3 Jan 2021 10:48:56 GMT"}, {"version": "v3", "created": "Thu, 25 Mar 2021 12:53:00 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Huang", "Yinya", ""], ["Fang", "Meng", ""], ["Zhan", "Xunlin", ""], ["Cao", "Qingxing", ""], ["Liang", "Xiaodan", ""], ["Lin", "Liang", ""]]}, {"id": "2012.13189", "submitter": "Yves Rychener", "authors": "Yves Rychener, Xavier Renard, Djam\\'e Seddah, Pascal Frossard, Marcin\n  Detyniecki", "title": "Sentence-Based Model Agnostic NLP Interpretability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, interpretability of Black-Box Natural Language Processing (NLP) models\nbased on surrogates, like LIME or SHAP, uses word-based sampling to build the\nexplanations. In this paper we explore the use of sentences to tackle NLP\ninterpretability. While this choice may seem straight forward, we show that,\nwhen using complex classifiers like BERT, the word-based approach raises issues\nnot only of computational complexity, but also of an out of distribution\nsampling, eventually leading to non founded explanations. By using sentences,\nthe altered text remains in-distribution and the dimensionality of the problem\nis reduced for better fidelity to the black-box at comparable computational\ncomplexity.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 10:32:41 GMT"}, {"version": "v2", "created": "Sun, 27 Dec 2020 17:54:38 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Rychener", "Yves", ""], ["Renard", "Xavier", ""], ["Seddah", "Djam\u00e9", ""], ["Frossard", "Pascal", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "2012.13190", "submitter": "Yves Rychener", "authors": "Yves Rychener, Xavier Renard, Djam\\'e Seddah, Pascal Frossard, Marcin\n  Detyniecki", "title": "QUACKIE: A NLP Classification Task With Ground Truth Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NLP Interpretability aims to increase trust in model predictions. This makes\nevaluating interpretability approaches a pressing issue. There are multiple\ndatasets for evaluating NLP Interpretability, but their dependence on human\nprovided ground truths raises questions about their unbiasedness. In this work,\nwe take a different approach and formulate a specific classification task by\ndiverting question-answering datasets. For this custom classification task, the\ninterpretability ground-truth arises directly from the definition of the\nclassification problem. We use this method to propose a benchmark and lay the\ngroundwork for future research in NLP interpretability by evaluating a wide\nrange of current state of the art methods.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 10:43:20 GMT"}, {"version": "v2", "created": "Sun, 27 Dec 2020 18:04:17 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Rychener", "Yves", ""], ["Renard", "Xavier", ""], ["Seddah", "Djam\u00e9", ""], ["Frossard", "Pascal", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "2012.13235", "submitter": "Vlad Sandulescu", "authors": "Vlad Sandulescu", "title": "Detecting Hateful Memes Using a Multimodal Deep Ensemble", "comments": "6 pages, NeurIPS 2020, The Hateful Memes Challenge Workshop at\n  NeurIPS 2020", "journal-ref": "The Hateful Memes Challenge Workshop at NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While significant progress has been made using machine learning algorithms to\ndetect hate speech, important technical challenges still remain to be solved in\norder to bring their performance closer to human accuracy. We investigate\nseveral of the most recent visual-linguistic Transformer architectures and\npropose improvements to increase their performance for this task. The proposed\nmodel outperforms the baselines by a large margin and ranks 5$^{th}$ on the\nleaderboard out of 3,100+ participants.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 13:01:44 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Sandulescu", "Vlad", ""]]}, {"id": "2012.13255", "submitter": "Armen Aghajanyan", "authors": "Armen Aghajanyan, Luke Zettlemoyer, Sonal Gupta", "title": "Intrinsic Dimensionality Explains the Effectiveness of Language Model\n  Fine-Tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although pretrained language models can be fine-tuned to produce\nstate-of-the-art results for a very wide range of language understanding tasks,\nthe dynamics of this process are not well understood, especially in the low\ndata regime. Why can we use relatively vanilla gradient descent algorithms\n(e.g., without strong regularization) to tune a model with hundreds of millions\nof parameters on datasets with only hundreds or thousands of labeled examples?\nIn this paper, we argue that analyzing fine-tuning through the lens of\nintrinsic dimension provides us with empirical and theoretical intuitions to\nexplain this remarkable phenomenon. We empirically show that common pre-trained\nmodels have a very low intrinsic dimension; in other words, there exists a low\ndimension reparameterization that is as effective for fine-tuning as the full\nparameter space. For example, by optimizing only 200 trainable parameters\nrandomly projected back into the full space, we can tune a RoBERTa model to\nachieve 90\\% of the full parameter performance levels on MRPC. Furthermore, we\nempirically show that pre-training implicitly minimizes intrinsic dimension\nand, perhaps surprisingly, larger models tend to have lower intrinsic dimension\nafter a fixed number of pre-training updates, at least in part explaining their\nextreme effectiveness. Lastly, we connect intrinsic dimensionality with low\ndimensional task representations and compression based generalization bounds to\nprovide intrinsic-dimension-based generalization bounds that are independent of\nthe full parameter count.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 07:42:30 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Aghajanyan", "Armen", ""], ["Zettlemoyer", "Luke", ""], ["Gupta", "Sonal", ""]]}, {"id": "2012.13260", "submitter": "Libo Qin", "authors": "Libo Qin, Zhouyang Li, Wanxiang Che, Minheng Ni, Ting Liu", "title": "Co-GAT: A Co-Interactive Graph Attention Network for Joint Dialog Act\n  Recognition and Sentiment Classification", "comments": "Accepted by AAAI2021 (Long Paper). arXiv admin note: text overlap\n  with arXiv:2008.06914", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a dialog system, dialog act recognition and sentiment classification are\ntwo correlative tasks to capture speakers intentions, where dialog act and\nsentiment can indicate the explicit and the implicit intentions separately. The\ndialog context information (contextual information) and the mutual interaction\ninformation are two key factors that contribute to the two related tasks.\nUnfortunately, none of the existing approaches consider the two important\nsources of information simultaneously. In this paper, we propose a\nCo-Interactive Graph Attention Network (Co-GAT) to jointly perform the two\ntasks. The core module is a proposed co-interactive graph interaction layer\nwhere a cross-utterances connection and a cross-tasks connection are\nconstructed and iteratively updated with each other, achieving to consider the\ntwo types of information simultaneously. Experimental results on two public\ndatasets show that our model successfully captures the two sources of\ninformation and achieve the state-of-the-art performance.\n  In addition, we find that the contributions from the contextual and mutual\ninteraction information do not fully overlap with contextualized word\nrepresentations (BERT, Roberta, XLNet).\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 14:10:24 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Qin", "Libo", ""], ["Li", "Zhouyang", ""], ["Che", "Wanxiang", ""], ["Ni", "Minheng", ""], ["Liu", "Ting", ""]]}, {"id": "2012.13339", "submitter": "Rishabh Maheshwary", "authors": "Rishabh Maheshwary, Saket Maheshwary, Vikram Pudi", "title": "A Context Aware Approach for Generating Natural Language Attacks", "comments": "Accepted as Student Poster at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an important task of attacking natural language processing models in\na black box setting. We propose an attack strategy that crafts semantically\nsimilar adversarial examples on text classification and entailment tasks. Our\nproposed attack finds candidate words by considering the information of both\nthe original word and its surrounding context. It jointly leverages masked\nlanguage modelling and next sentence prediction for context understanding. In\ncomparison to attacks proposed in prior literature, we are able to generate\nhigh quality adversarial examples that do significantly better both in terms of\nsuccess rate and word perturbation percentage.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 17:24:54 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Maheshwary", "Rishabh", ""], ["Maheshwary", "Saket", ""], ["Pudi", "Vikram", ""]]}, {"id": "2012.13354", "submitter": "Grusha Prasad", "authors": "Grusha Prasad and Yixin Nie and Mohit Bansal and Robin Jia and Douwe\n  Kiela and Adina Williams", "title": "To what extent do human explanations of model behavior align with actual\n  model behavior?", "comments": "10 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given the increasingly prominent role NLP models (will) play in our lives, it\nis important to evaluate models on their alignment with human expectations of\nhow models behave. Using Natural Language Inference (NLI) as a case study, we\ninvestigated the extent to which human-generated explanations of models'\ninference decisions align with how models actually make these decisions. More\nspecifically, we defined two alignment metrics that quantify how well natural\nlanguage human explanations align with model sensitivity to input words, as\nmeasured by integrated gradients. Then, we evaluated six different transformer\nmodels (the base and large versions of BERT, RoBERTa and ELECTRA), and found\nthat the BERT-base model has the highest alignment with human-generated\nexplanations, for both alignment metrics. Additionally, the base versions of\nthe models we surveyed tended to have higher alignment with human-generated\nexplanations than their larger counterparts, suggesting that increasing the\nnumber model parameters could result in worse alignment with human\nexplanations. Finally, we find that a model's alignment with human explanations\nis not predicted by the model's accuracy on NLI, suggesting that accuracy and\nalignment are orthogonal, and both are important ways to evaluate models.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 17:40:06 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Prasad", "Grusha", ""], ["Nie", "Yixin", ""], ["Bansal", "Mohit", ""], ["Jia", "Robin", ""], ["Kiela", "Douwe", ""], ["Williams", "Adina", ""]]}, {"id": "2012.13391", "submitter": "Yixin Nie", "authors": "Yixin Nie, Mary Williamson, Mohit Bansal, Douwe Kiela, Jason Weston", "title": "I like fish, especially dolphins: Addressing Contradictions in Dialogue\n  Modeling", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To quantify how well natural language understanding models can capture\nconsistency in a general conversation, we introduce the DialoguE COntradiction\nDEtection task (DECODE) and a new conversational dataset containing both\nhuman-human and human-bot contradictory dialogues. We then compare a structured\nutterance-based approach of using pre-trained Transformer models for\ncontradiction detection with the typical unstructured approach. Results reveal\nthat: (i) our newly collected dataset is notably more effective at providing\nsupervision for the dialogue contradiction detection task than existing NLI\ndata including those aimed to cover the dialogue domain; (ii) the structured\nutterance-based approach is more robust and transferable on both analysis and\nout-of-distribution dialogues than its unstructured counterpart. We also show\nthat our best contradiction detection model correlates well with human\njudgments and further provide evidence for its usage in both automatically\nevaluating and improving the consistency of state-of-the-art generative\nchatbots.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 18:47:49 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 18:32:21 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Nie", "Yixin", ""], ["Williamson", "Mary", ""], ["Bansal", "Mohit", ""], ["Kiela", "Douwe", ""], ["Weston", "Jason", ""]]}, {"id": "2012.13436", "submitter": "Sarveswaran Kengatharaiyer", "authors": "Kengatharaiyer Sarveswaran and Gihan Dias", "title": "ThamizhiUDp: A Dependency Parser for Tamil", "comments": "5 Pages, Published at ICON2020: 17th International Conference on\n  Natural Language Processing (December 18-21, 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper describes how we developed a neural-based dependency parser,\nnamely ThamizhiUDp, which provides a complete pipeline for the dependency\nparsing of the Tamil language text using Universal Dependency formalism. We\nhave considered the phases of the dependency parsing pipeline and identified\ntools and resources in each of these phases to improve the accuracy and to\ntackle data scarcity. ThamizhiUDp uses Stanza for tokenisation and\nlemmatisation, ThamizhiPOSt and ThamizhiMorph for generating Part of Speech\n(POS) and Morphological annotations, and uuparser with multilingual training\nfor dependency parsing. ThamizhiPOSt is our POS tagger, which is based on the\nStanza, trained with Amrita POS-tagged corpus. It is the current\nstate-of-the-art in Tamil POS tagging with an F1 score of 93.27. Our\nmorphological analyzer, ThamizhiMorph is a rule-based system with a very good\ncoverage of Tamil. Our dependency parser ThamizhiUDp was trained using\nmultilingual data. It shows a Labelled Assigned Score (LAS) of 62.39, 4 points\nhigher than the current best achieved for Tamil dependency parsing. Therefore,\nwe show that breaking up the dependency parsing pipeline to accommodate\nexisting tools and resources is a viable approach for low-resource languages.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 20:20:50 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Sarveswaran", "Kengatharaiyer", ""], ["Dias", "Gihan", ""]]}, {"id": "2012.13454", "submitter": "Kevin Knight", "authors": "Xing Shi, Yijun Xiao, Kevin Knight", "title": "Why Neural Machine Translation Prefers Empty Outputs", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate why neural machine translation (NMT) systems assign high\nprobability to empty translations. We find two explanations. First, label\nsmoothing makes correct-length translations less confident, making it easier\nfor the empty translation to finally outscore them. Second, NMT systems use the\nsame, high-frequency EoS word to end all target sentences, regardless of\nlength. This creates an implicit smoothing that increases zero-length\ntranslations. Using different EoS types in target sentences of different\nlengths exposes and eliminates this implicit smoothing.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 22:25:22 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Shi", "Xing", ""], ["Xiao", "Yijun", ""], ["Knight", "Kevin", ""]]}, {"id": "2012.13568", "submitter": "Gang Chen", "authors": "Gang Chen, Maosong Sun, and Yang Liu", "title": "Towards a Universal Continuous Knowledge Base", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In artificial intelligence (AI), knowledge is the information required by an\nintelligent system to accomplish tasks. While traditional knowledge bases use\ndiscrete, symbolic representations, detecting knowledge encoded in the\ncontinuous representations learned from data has received increasing attention\nrecently. In this work, we propose a method for building a continuous knowledge\nbase (CKB) that can store knowledge imported from multiple, diverse neural\nnetworks. The key idea of our approach is to define an interface for each\nneural network and cast knowledge transferring as a function simulation\nproblem. Experiments on text classification show promising results: the CKB\nimports knowledge from a single model and then exports the knowledge to a new\nmodel, achieving comparable performance with the original model. More\ninteresting, we import the knowledge from multiple models to the knowledge\nbase, from which the fused knowledge is exported back to a single model,\nachieving a higher accuracy than the original model. With the CKB, it is also\neasy to achieve knowledge distillation and transfer learning. Our work opens\nthe door to building a universal continuous knowledge base to collect, store,\nand organize all continuous knowledge encoded in various neural networks\ntrained for different AI tasks.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 12:27:44 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 14:10:33 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Chen", "Gang", ""], ["Sun", "Maosong", ""], ["Liu", "Yang", ""]]}, {"id": "2012.13575", "submitter": "Pei-Hsin Wang", "authors": "Pei-Hsin Wang, Sheng-Iou Hsieh, Shih-Chieh Chang, Yu-Ting Chen, Jia-Yu\n  Pan, Wei Wei, Da-Chang Juan", "title": "Contextual Temperature for Language Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temperature scaling has been widely used as an effective approach to control\nthe smoothness of a distribution, which helps the model performance in various\ntasks. Current practices to apply temperature scaling assume either a fixed, or\na manually-crafted dynamically changing schedule. However, our studies indicate\nthat the individual optimal trajectory for each class can change with the\ncontext. To this end, we propose contextual temperature, a generalized approach\nthat learns an optimal temperature trajectory for each vocabulary over the\ncontext. Experimental results confirm that the proposed method significantly\nimproves state-of-the-art language models, achieving a perplexity of 55.31 and\n62.89 on the test set of Penn Treebank and WikiText-2, respectively. In-depth\nanalyses show that the behaviour of the learned temperature schedules varies\ndramatically by vocabulary, and that the optimal schedules help in controlling\nthe uncertainties. These evidences further justify the need for the proposed\nmethod and its advantages over fixed temperature schedules.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 13:50:03 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Wang", "Pei-Hsin", ""], ["Hsieh", "Sheng-Iou", ""], ["Chang", "Shih-Chieh", ""], ["Chen", "Yu-Ting", ""], ["Pan", "Jia-Yu", ""], ["Wei", "Wei", ""], ["Juan", "Da-Chang", ""]]}, {"id": "2012.13577", "submitter": "Jiangjie Chen", "authors": "Jiangjie Chen, Qiaoben Bao, Jiaze Chen, Changzhi Sun, Hao Zhou,\n  Yanghua Xiao, Lei Li", "title": "LOREN: Logic Enhanced Neural Reasoning for Fact Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a natural language statement, how to verify whether it is supported,\nrefuted, or unknown according to a large-scale knowledge source like Wikipedia?\nExisting neural-network-based methods often regard a sentence as a whole. While\nwe argue that it is beneficial to decompose a statement into multiple\nverifiable logical points. In this paper, we propose LOREN, a novel approach\nfor fact verification that integrates both Logic guided Reasoning and Neural\ninference. The key insight of LOREN is that it decomposes a statement into\nmultiple reasoning units around the central phrases. Instead of directly\nvalidating a single reasoning unit, LOREN turns it into a question-answering\ntask and calculates the confidence of every single hypothesis using neural\nnetworks in the embedding space. They are aggregated to make a final prediction\nusing a neural joint reasoner guided by a set of three-valued logic rules.\nLOREN enjoys the additional merit of interpretability -- it is easy to explain\nhow it reaches certain results with intermediate results and why it makes\nmistakes. We evaluate LOREN on FEVER, a public benchmark for fact verification.\nExperiments show that our proposed LOREN outperforms other previously published\nmethods and achieves 73.43% of the FEVER score.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 13:57:04 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Chen", "Jiangjie", ""], ["Bao", "Qiaoben", ""], ["Chen", "Jiaze", ""], ["Sun", "Changzhi", ""], ["Zhou", "Hao", ""], ["Xiao", "Yanghua", ""], ["Li", "Lei", ""]]}, {"id": "2012.13624", "submitter": "Kalpani Anuradha Welivita", "authors": "Anuradha Welivita, Yubo Xie, Pearl Pu", "title": "Fine-grained Emotion and Intent Learning in Movie Dialogues", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel large-scale emotional dialogue dataset, consisting of 1M\ndialogues retrieved from the OpenSubtitles corpus and annotated with 32\nemotions and 9 empathetic response intents using a BERT-based fine-grained\ndialogue emotion classifier. This work explains the complex pipeline used to\npreprocess movie subtitles and select good movie dialogues to annotate. We also\ndescribe the semi-supervised learning process followed to train a fine-grained\nemotion classifier to annotate these dialogues. Despite the large set of\nlabels, our dialogue emotion classifier achieved an accuracy of $65\\%$ and was\nused to annotate 1M emotional movie dialogues from OpenSubtitles. This scale of\nemotional dialogue classification has never been attempted before, both in\nterms of dataset size and fine-grained emotion and intent categories.\nVisualization techniques used to analyze the quality of the resultant dataset\nsuggest that it conforms to the patterns of human social interaction.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 20:29:56 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Welivita", "Anuradha", ""], ["Xie", "Yubo", ""], ["Pu", "Pearl", ""]]}, {"id": "2012.13675", "submitter": "Soroush Vosoughi Dr", "authors": "Neeti Pokhriyal, Abenezer Dara, Benjamin Valentino, Soroush Vosoughi", "title": "Social media data reveals signal for public consumer perceptions", "comments": "In Proceedings of the ACM International Conference on AI in Finance\n  (ICAIF '20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Researchers have used social media data to estimate various macroeconomic\nindicators about public behaviors, mostly as a way to reduce surveying costs.\nOne of the most widely cited economic indicator is consumer confidence index\n(CCI). Numerous studies in the past have focused on using social media,\nespecially Twitter data, to predict CCI. However, the strong correlations\ndisappeared when those models were tested with newer data according to a recent\ncomprehensive survey. In this work, we revisit this problem of assessing the\ntrue potential of using social media data to measure CCI, by proposing a robust\nnon-parametric Bayesian modeling framework grounded in Gaussian Process\nRegression (which provides both an estimate and an uncertainty associated with\nit). Integral to our framework is a principled experimentation methodology that\ndemonstrates how digital data can be employed to reduce the frequency of\nsurveys, and thus periodic polling would be needed only to calibrate our model.\nVia extensive experimentation we show how the choice of different\nmicro-decisions, such as the smoothing interval, various types of lags etc.\nhave an important bearing on the results. By using decadal data (2008-2019)\nfrom Reddit, we show that both monthly and daily estimates of CCI can, indeed,\nbe reliably estimated at least several months in advance, and that our model\nestimates are far superior to those generated by the existing methods.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2020 03:58:20 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Pokhriyal", "Neeti", ""], ["Dara", "Abenezer", ""], ["Valentino", "Benjamin", ""], ["Vosoughi", "Soroush", ""]]}, {"id": "2012.13693", "submitter": "Sagar Gubbi Venkatesh", "authors": "Sagar Gubbi Venkatesh and Anirban Biswas and Raviteja Upadrashta and\n  Vikram Srinivasan and Partha Talukdar and Bharadwaj Amrutur", "title": "Spatial Reasoning from Natural Language Instructions for Robot\n  Manipulation", "comments": "Accepted for ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Robots that can manipulate objects in unstructured environments and\ncollaborate with humans can benefit immensely by understanding natural\nlanguage. We propose a pipelined architecture of two stages to perform spatial\nreasoning on the text input. All the objects in the scene are first localized,\nand then the instruction for the robot in natural language and the localized\nco-ordinates are mapped to the start and end co-ordinates corresponding to the\nlocations where the robot must pick up and place the object respectively. We\nshow that representing the localized objects by quantizing their positions to a\nbinary grid is preferable to representing them as a list of 2D co-ordinates. We\nalso show that attention improves generalization and can overcome biases in the\ndataset. The proposed method is used to pick-and-place playing cards using a\nrobot arm.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2020 07:53:19 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 15:24:57 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Venkatesh", "Sagar Gubbi", ""], ["Biswas", "Anirban", ""], ["Upadrashta", "Raviteja", ""], ["Srinivasan", "Vikram", ""], ["Talukdar", "Partha", ""], ["Amrutur", "Bharadwaj", ""]]}, {"id": "2012.13695", "submitter": "Sagar Gubbi Venkatesh", "authors": "Sagar Gubbi Venkatesh and Raviteja Upadrashta and Bharadwaj Amrutur", "title": "Translating Natural Language Instructions to Computer Programs for Robot\n  Manipulation", "comments": "Submitted to IROS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  It is highly desirable for robots that work alongside humans to be able to\nunderstand instructions in natural language. Existing language conditioned\nimitation learning models directly predict the actuator commands from the image\nobservation and the instruction text. Rather than directly predicting actuator\ncommands, we propose translating the natural language instruction to a Python\nfunction which queries the scene by accessing the output of the object detector\nand controls the robot to perform the specified task. This enables the use of\nnon-differentiable modules such as a constraint solver when computing commands\nto the robot. Moreover, the labels in this setup are significantly more\ninformative computer programs that capture the intent of the expert rather than\nteleoperated demonstrations. We show that the proposed method performs better\nthan training a neural network to directly predict the robot actions.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2020 07:57:55 GMT"}, {"version": "v2", "created": "Sat, 20 Mar 2021 07:33:27 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Venkatesh", "Sagar Gubbi", ""], ["Upadrashta", "Raviteja", ""], ["Amrutur", "Bharadwaj", ""]]}, {"id": "2012.13838", "submitter": "Zhiying Jiang", "authors": "Zhiying Jiang, Raphael Tang, Ji Xin, Jimmy Lin", "title": "Inserting Information Bottlenecks for Attribution in Transformers", "comments": "Accepted by EMNLP2020 Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pretrained transformers achieve the state of the art across tasks in natural\nlanguage processing, motivating researchers to investigate their inner\nmechanisms. One common direction is to understand what features are important\nfor prediction. In this paper, we apply information bottlenecks to analyze the\nattribution of each feature for prediction on a black-box model. We use BERT as\nthe example and evaluate our approach both quantitatively and qualitatively. We\nshow the effectiveness of our method in terms of attribution and the ability to\nprovide insight into how information flows through layers. We demonstrate that\nour technique outperforms two competitive methods in degradation tests on four\ndatasets. Code is available at https://github.com/bazingagin/IBA.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 00:35:43 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Jiang", "Zhiying", ""], ["Tang", "Raphael", ""], ["Xin", "Ji", ""], ["Lin", "Jimmy", ""]]}, {"id": "2012.13866", "submitter": "Li Bei", "authors": "Bei Li, Ziyang Wang, Hui Liu, Quan Du, Tong Xiao, Chunliang Zhang and\n  Jingbo Zhu", "title": "Learning Light-Weight Translation Models from Deep Transformer", "comments": "Accepted by AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep models have shown tremendous improvements in neural machine\ntranslation (NMT). However, systems of this kind are computationally expensive\nand memory intensive. In this paper, we take a natural step towards learning\nstrong but light-weight NMT systems. We proposed a novel group-permutation\nbased knowledge distillation approach to compressing the deep Transformer model\ninto a shallow model. The experimental results on several benchmarks validate\nthe effectiveness of our method. Our compressed model is 8X shallower than the\ndeep model, with almost no loss in BLEU. To further enhance the teacher model,\nwe present a Skipping Sub-Layer method to randomly omit sub-layers to introduce\nperturbation into training, which achieves a BLEU score of 30.63 on\nEnglish-German newstest2014. The code is publicly available at\nhttps://github.com/libeineu/GPKD.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 05:33:21 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Li", "Bei", ""], ["Wang", "Ziyang", ""], ["Liu", "Hui", ""], ["Du", "Quan", ""], ["Xiao", "Tong", ""], ["Zhang", "Chunliang", ""], ["Zhu", "Jingbo", ""]]}, {"id": "2012.13872", "submitter": "Yaman Kumar Singla", "authors": "Swapnil Parekh, Yaman Kumar Singla, Changyou Chen, Junyi Jessy Li,\n  Rajiv Ratn Shah", "title": "My Teacher Thinks The World Is Flat! Interpreting Automatic Essay\n  Scoring Mechanism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significant progress has been made in deep-learning based Automatic Essay\nScoring (AES) systems in the past two decades. However, little research has\nbeen put to understand and interpret the black-box nature of these\ndeep-learning based scoring models. Recent work shows that automated scoring\nsystems are prone to even common-sense adversarial samples. Their lack of\nnatural language understanding capability raises questions on the models being\nactively used by millions of candidates for life-changing decisions. With\nscoring being a highly multi-modal task, it becomes imperative for scoring\nmodels to be validated and tested on all these modalities. We utilize recent\nadvances in interpretability to find the extent to which features such as\ncoherence, content and relevance are important for automated scoring mechanisms\nand why they are susceptible to adversarial samples. We find that the systems\ntested consider essays not as a piece of prose having the characteristics of\nnatural flow of speech and grammatical structure, but as `word-soups' where a\nfew words are much more important than the other words. Removing the context\nsurrounding those few important words causes the prose to lose the flow of\nspeech and grammar, however has little impact on the predicted score. We also\nfind that since the models are not semantically grounded with world-knowledge\nand common sense, adding false facts such as ``the world is flat'' actually\nincreases the score instead of decreasing it.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 06:19:20 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Parekh", "Swapnil", ""], ["Singla", "Yaman Kumar", ""], ["Chen", "Changyou", ""], ["Li", "Junyi Jessy", ""], ["Shah", "Rajiv Ratn", ""]]}, {"id": "2012.13873", "submitter": "Hao Zhang", "authors": "Fuzhao Xue, Aixin Sun, Hao Zhang, Eng Siong Chng", "title": "An Embarrassingly Simple Model for Dialogue Relation Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue relation extraction (RE) is to predict the relation type of two\nentities mentioned in a dialogue. In this paper, we model Dialogue RE as a\nmulti-label classification task and propose a simple yet effective model named\nSimpleRE. SimpleRE captures the interrelations among multiple relations in a\ndialogue through a novel input format, BERT Relation Token Sequence (BRS). In\nBRS, multiple [CLS] tokens are used to capture different relations between\ndifferent pairs of entities. A Relation Refinement Gate (RRG) is designed to\nextract relation-specific semantic representation adaptively. Experiments on\nDialogRE show that SimpleRE achieves the best performance with much shorter\ntraining time. SimpleRE outperforms all direct baselines on sentence-level RE\nwithout using external resources.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 06:22:23 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Xue", "Fuzhao", ""], ["Sun", "Aixin", ""], ["Zhang", "Hao", ""], ["Chng", "Eng Siong", ""]]}, {"id": "2012.13905", "submitter": "Marinella Petrocchi", "authors": "Michela Fazzolari and Francesco Buccafurri and Gianluca Lax and\n  Marinella Petrocchi", "title": "Improving Opinion Spam Detection by Cumulative Relative Frequency\n  Distribution", "comments": "Manuscript accepted for publication in ACM Journal of Data and\n  Information Quality. This is the pre-final version, before proofs checking", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the last years, online reviews became very important since they can\ninfluence the purchase decision of consumers and the reputation of businesses,\ntherefore, the practice of writing fake reviews can have severe consequences on\ncustomers and service providers. Various approaches have been proposed for\ndetecting opinion spam in online reviews, especially based on supervised\nclassifiers. In this contribution, we start from a set of effective features\nused for classifying opinion spam and we re-engineered them, by considering the\nCumulative Relative Frequency Distribution of each feature. By an experimental\nevaluation carried out on real data from Yelp.com, we show that the use of the\ndistributional features is able to improve the performances of classifiers.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 10:23:44 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Fazzolari", "Michela", ""], ["Buccafurri", "Francesco", ""], ["Lax", "Gianluca", ""], ["Petrocchi", "Marinella", ""]]}, {"id": "2012.13915", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang, Yuwei Wu, Junru Zhou, Sufeng Duan, Hai Zhao, Rui Wang", "title": "SG-Net: Syntax Guided Transformer for Language Representation", "comments": "The early version accepted by IEEE Transactions on Pattern Analysis\n  and Machine Intelligence (TPAMI). Journal extension of arXiv:1908.05147 (AAAI\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding human language is one of the key themes of artificial\nintelligence. For language representation, the capacity of effectively modeling\nthe linguistic knowledge from the detail-riddled and lengthy texts and getting\nrid of the noises is essential to improve its performance. Traditional\nattentive models attend to all words without explicit constraint, which results\nin inaccurate concentration on some dispensable words. In this work, we propose\nusing syntax to guide the text modeling by incorporating explicit syntactic\nconstraints into attention mechanisms for better linguistically motivated word\nrepresentations. In detail, for self-attention network (SAN) sponsored\nTransformer-based encoder, we introduce syntactic dependency of interest (SDOI)\ndesign into the SAN to form an SDOI-SAN with syntax-guided self-attention.\nSyntax-guided network (SG-Net) is then composed of this extra SDOI-SAN and the\nSAN from the original Transformer encoder through a dual contextual\narchitecture for better linguistics inspired representation. The proposed\nSG-Net is applied to typical Transformer encoders. Extensive experiments on\npopular benchmark tasks, including machine reading comprehension, natural\nlanguage inference, and neural machine translation show the effectiveness of\nthe proposed SG-Net design.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 11:09:35 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 05:48:45 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["Wu", "Yuwei", ""], ["Zhou", "Junru", ""], ["Duan", "Sufeng", ""], ["Zhao", "Hai", ""], ["Wang", "Rui", ""]]}, {"id": "2012.13939", "submitter": "Kashif Munir", "authors": "Kashif Munir, Hai Zhao, Zuchao Li", "title": "Adaptive Convolution for Semantic Role Labeling", "comments": "This submission is an early version of our recently accepted IEEE/ACM\n  TASLP paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Semantic role labeling (SRL) aims at elaborating the meaning of a sentence by\nforming a predicate-argument structure. Recent researches depicted that the\neffective use of syntax can improve SRL performance. However, syntax is a\ncomplicated linguistic clue and is hard to be effectively applied in a\ndownstream task like SRL. This work effectively encodes syntax using adaptive\nconvolution which endows strong flexibility to existing convolutional networks.\nThe existing CNNs may help in encoding a complicated structure like syntax for\nSRL, but it still has shortcomings. Contrary to traditional convolutional\nnetworks that use same filters for different inputs, adaptive convolution uses\nadaptively generated filters conditioned on syntactically informed inputs. We\nachieve this with the integration of a filter generation network which\ngenerates the input specific filters. This helps the model to focus on\nimportant syntactic features present inside the input, thus enlarging the gap\nbetween syntax-aware and syntax-agnostic SRL systems. We further study a\nhashing technique to compress the size of the filter generation network for SRL\nin terms of trainable parameters. Experiments on CoNLL-2009 dataset confirm\nthat the proposed model substantially outperforms most previous SRL systems for\nboth English and Chinese languages\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 13:26:11 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Munir", "Kashif", ""], ["Zhao", "Hai", ""], ["Li", "Zuchao", ""]]}, {"id": "2012.13978", "submitter": "Zhi Wen", "authors": "Zhi Wen, Xing Han Lu, Siva Reddy", "title": "MeDAL: Medical Abbreviation Disambiguation Dataset for Natural Language\n  Understanding Pretraining", "comments": "EMNLP 2020 Clinical NLP", "journal-ref": "In Proceedings of the 3rd Clinical Natural Language Processing\n  Workshop, pp. 130-135. 2020", "doi": "10.18653/v1/2020.clinicalnlp-1.15", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the biggest challenges that prohibit the use of many current NLP\nmethods in clinical settings is the availability of public datasets. In this\nwork, we present MeDAL, a large medical text dataset curated for abbreviation\ndisambiguation, designed for natural language understanding pre-training in the\nmedical domain. We pre-trained several models of common architectures on this\ndataset and empirically showed that such pre-training leads to improved\nperformance and convergence speed when fine-tuning on downstream medical tasks.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 17:17:39 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Wen", "Zhi", ""], ["Lu", "Xing Han", ""], ["Reddy", "Siva", ""]]}, {"id": "2012.13980", "submitter": "Tatiana Kozitsina", "authors": "Tatiana Kozitsina (Babkina), Viacheslav Goiko, Roman Palkin, Valentin\n  Khomutenko, Yulia Mundrievskaya, Maria Sukhareva, Isak Froumin, and Mikhail\n  Myagkov", "title": "Measuring University Impact: Wikipedia approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impact of Universities on the social, economic and political landscape is\none of the key directions in contemporary educational evaluation. In this\npaper, we discuss the new methodological technique that evaluates the impact of\nuniversity based on popularity (number of page-views) of their alumni's pages\non Wikipedia. It allows revealing the alumni popularity dynamics and tracking\nits state. Preliminary analysis shows that the number of page-views is higher\nfor the contemporary persons that prove the perspectives of this approach.\nThen, universities were ranked based on the methodology and compared to the\nfamous international university rankings ARWU and QS based only on alumni\nscales: for the top 10 universities, there is an intersection of two\nuniversities (Columbia University, Stanford University). The correlation\ncoefficients between different university rankings are provided in the paper.\nFinally, the ranking based on the alumni popularity was compared with the\nranking of universities based on the popularity of their webpages on Wikipedia:\nthere is a strong connection between these indicators.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 17:41:56 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Kozitsina", "Tatiana", "", "Babkina"], ["Goiko", "Viacheslav", ""], ["Palkin", "Roman", ""], ["Khomutenko", "Valentin", ""], ["Mundrievskaya", "Yulia", ""], ["Sukhareva", "Maria", ""], ["Froumin", "Isak", ""], ["Myagkov", "Mikhail", ""]]}, {"id": "2012.13985", "submitter": "Alexis Ross", "authors": "Alexis Ross, Ana Marasovi\\'c, Matthew E. Peters", "title": "Explaining NLP Models via Minimal Contrastive Editing (MiCE)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Humans have been shown to give contrastive explanations, which explain why an\nobserved event happened rather than some other counterfactual event (the\ncontrast case). Despite the influential role that contrastivity plays in how\nhumans explain, this property is largely missing from current methods for\nexplaining NLP models. We present Minimal Contrastive Editing (MiCE), a method\nfor producing contrastive explanations of model predictions in the form of\nedits to inputs that change model outputs to the contrast case. Our experiments\nacross three tasks--binary sentiment classification, topic classification, and\nmultiple-choice question answering--show that MiCE is able to produce edits\nthat are not only contrastive, but also minimal and fluent, consistent with\nhuman contrastive edits. We demonstrate how MiCE edits can be used for two use\ncases in NLP system development--debugging incorrect model outputs and\nuncovering dataset artifacts--and thereby illustrate that producing contrastive\nexplanations is a promising research direction for model interpretability.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 18:06:26 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 21:53:54 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Ross", "Alexis", ""], ["Marasovi\u0107", "Ana", ""], ["Peters", "Matthew E.", ""]]}, {"id": "2012.14005", "submitter": "Cheng Tang", "authors": "Cheng Tang, Andrew Arnold", "title": "Neural document expansion for ad-hoc information retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, Nogueira et al. [2019] proposed a new approach to document\nexpansion based on a neural Seq2Seq model, showing significant improvement on\nshort text retrieval task. However, this approach needs a large amount of\nin-domain training data. In this paper, we show that this neural document\nexpansion approach can be effectively adapted to standard IR tasks, where\nlabels are scarce and many long documents are present.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 20:00:08 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Tang", "Cheng", ""], ["Arnold", "Andrew", ""]]}, {"id": "2012.14011", "submitter": "Yining Hong", "authors": "Yining Hong, Qing Li, Ran Gong, Daniel Ciao, Siyuan Huang, Song-Chun\n  Zhu", "title": "SMART: A Situation Model for Algebra Story Problems via Attributed\n  Grammar", "comments": null, "journal-ref": "AAAI2021", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving algebra story problems remains a challenging task in artificial\nintelligence, which requires a detailed understanding of real-world situations\nand a strong mathematical reasoning capability. Previous neural solvers of math\nword problems directly translate problem texts into equations, lacking an\nexplicit interpretation of the situations, and often fail to handle more\nsophisticated situations. To address such limits of neural solvers, we\nintroduce the concept of a \\emph{situation model}, which originates from\npsychology studies to represent the mental states of humans in problem-solving,\nand propose \\emph{SMART}, which adopts attributed grammar as the representation\nof situation models for algebra story problems. Specifically, we first train an\ninformation extraction module to extract nodes, attributes, and relations from\nproblem texts and then generate a parse graph based on a pre-defined attributed\ngrammar. An iterative learning strategy is also proposed to improve the\nperformance of SMART further. To rigorously study this task, we carefully\ncurate a new dataset named \\emph{ASP6.6k}. Experimental results on ASP6.6k show\nthat the proposed model outperforms all previous neural solvers by a large\nmargin while preserving much better interpretability. To test these models'\ngeneralization capability, we also design an out-of-distribution (OOD)\nevaluation, in which problems are more complex than those in the training set.\nOur model exceeds state-of-the-art models by 17\\% in the OOD evaluation,\ndemonstrating its superior generalization ability.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 21:03:40 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Hong", "Yining", ""], ["Li", "Qing", ""], ["Gong", "Ran", ""], ["Ciao", "Daniel", ""], ["Huang", "Siyuan", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "2012.14022", "submitter": "Peyman Passban", "authors": "Peyman Passban, Yimeng Wu, Mehdi Rezagholizadeh, Qun Liu", "title": "ALP-KD: Attention-Based Layer Projection for Knowledge Distillation", "comments": "AAAI 2021. This work has been done while Peyman Passban was at Huawei", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation is considered as a training and compression strategy\nin which two neural networks, namely a teacher and a student, are coupled\ntogether during training. The teacher network is supposed to be a trustworthy\npredictor and the student tries to mimic its predictions. Usually, a student\nwith a lighter architecture is selected so we can achieve compression and yet\ndeliver high-quality results. In such a setting, distillation only happens for\nfinal predictions whereas the student could also benefit from teacher's\nsupervision for internal components.\n  Motivated by this, we studied the problem of distillation for intermediate\nlayers. Since there might not be a one-to-one alignment between student and\nteacher layers, existing techniques skip some teacher layers and only distill\nfrom a subset of them. This shortcoming directly impacts quality, so we instead\npropose a combinatorial technique which relies on attention. Our model fuses\nteacher-side information and takes each layer's significance into\nconsideration, then performs distillation between combined teacher layers and\nthose of the student. Using our technique, we distilled a 12-layer BERT (Devlin\net al. 2019) into 6-, 4-, and 2-layer counterparts and evaluated them on GLUE\ntasks (Wang et al. 2018). Experimental results show that our combinatorial\napproach is able to outperform other existing techniques.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 22:30:13 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Passban", "Peyman", ""], ["Wu", "Yimeng", ""], ["Rezagholizadeh", "Mehdi", ""], ["Liu", "Qun", ""]]}, {"id": "2012.14072", "submitter": "Yangyang Zhao", "authors": "Yangyang Zhao, Zhenyu Wang and Zhenhua Huang", "title": "Automatic Curriculum Learning With Over-repetition Penalty for Dialogue\n  Policy Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue policy learning based on reinforcement learning is difficult to be\napplied to real users to train dialogue agents from scratch because of the high\ncost. User simulators, which choose random user goals for the dialogue agent to\ntrain on, have been considered as an affordable substitute for real users.\nHowever, this random sampling method ignores the law of human learning, making\nthe learned dialogue policy inefficient and unstable. We propose a novel\nframework, Automatic Curriculum Learning-based Deep Q-Network (ACL-DQN), which\nreplaces the traditional random sampling method with a teacher policy model to\nrealize the dialogue policy for automatic curriculum learning. The teacher\nmodel arranges a meaningful ordered curriculum and automatically adjusts it by\nmonitoring the learning progress of the dialogue agent and the over-repetition\npenalty without any requirement of prior knowledge. The learning progress of\nthe dialogue agent reflects the relationship between the dialogue agent's\nability and the sampled goals' difficulty for sample efficiency. The\nover-repetition penalty guarantees the sampled diversity. Experiments show that\nthe ACL-DQN significantly improves the effectiveness and stability of dialogue\ntasks with a statistically significant margin. Furthermore, the framework can\nbe further improved by equipping with different curriculum schedules, which\ndemonstrates that the framework has strong generalizability.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 02:44:49 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Zhao", "Yangyang", ""], ["Wang", "Zhenyu", ""], ["Huang", "Zhenhua", ""]]}, {"id": "2012.14094", "submitter": "Ivan Montero", "authors": "Ivan Montero, Shayne Longpre, Ni Lao, Andrew J. Frank, Christopher\n  DuBois", "title": "Pivot Through English: Reliably Answering Multilingual Questions without\n  Document Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing methods for open-retrieval question answering in lower resource\nlanguages (LRLs) lag significantly behind English. They not only suffer from\nthe shortcomings of non-English document retrieval, but are reliant on\nlanguage-specific supervision for either the task or translation. We formulate\na task setup more realistic to available resources, that circumvents document\nretrieval to reliably transfer knowledge from English to lower resource\nlanguages. Assuming a strong English question answering model or database, we\ncompare and analyze methods that pivot through English: to map foreign queries\nto English and then English answers back to target language answers. Within\nthis task setup we propose Reranked Multilingual Maximal Inner Product Search\n(RM-MIPS), akin to semantic similarity retrieval over the English training set\nwith reranking, which outperforms the strongest baselines by 2.7% on XQuAD and\n6.2% on MKQA. Analysis demonstrates the particular efficacy of this strategy\nover state-of-the-art alternatives in challenging settings: low-resource\nlanguages, with extensive distractor data and query distribution misalignment.\nCircumventing retrieval, our analysis shows this approach offers rapid answer\ngeneration to almost any language off-the-shelf, without the need for any\nadditional training data in the target language.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 04:38:45 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 00:59:16 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Montero", "Ivan", ""], ["Longpre", "Shayne", ""], ["Lao", "Ni", ""], ["Frank", "Andrew J.", ""], ["DuBois", "Christopher", ""]]}, {"id": "2012.14116", "submitter": "Zenan Xu", "authors": "Zenan Xu, Daya Guo, Duyu Tang, Qinliang Su, Linjun Shou, Ming Gong,\n  Wanjun Zhong, Xiaojun Quan, Nan Duan and Daxin Jiang", "title": "Syntax-Enhanced Pre-trained Model", "comments": "Accepted by ACL-IJCNLP 2021: The Joint Conference of the 59th Annual\n  Meeting of the Association for Computational Linguistics and the 11th\n  International Joint Conference on Natural Language Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of leveraging the syntactic structure of text to enhance\npre-trained models such as BERT and RoBERTa. Existing methods utilize syntax of\ntext either in the pre-training stage or in the fine-tuning stage, so that they\nsuffer from discrepancy between the two stages. Such a problem would lead to\nthe necessity of having human-annotated syntactic information, which limits the\napplication of existing methods to broader scenarios. To address this, we\npresent a model that utilizes the syntax of text in both pre-training and\nfine-tuning stages. Our model is based on Transformer with a syntax-aware\nattention layer that considers the dependency tree of the text. We further\nintroduce a new pre-training task of predicting the syntactic distance among\ntokens in the dependency tree. We evaluate the model on three downstream tasks,\nincluding relation classification, entity typing, and question answering.\nResults show that our model achieves state-of-the-art performance on six public\nbenchmark datasets. We have two major findings. First, we demonstrate that\ninfusing automatically produced syntax of text improves pre-trained models.\nSecond, global syntactic distances among tokens bring larger performance gains\ncompared to local head relations between contiguous tokens.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 06:48:04 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 08:13:49 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Xu", "Zenan", ""], ["Guo", "Daya", ""], ["Tang", "Duyu", ""], ["Su", "Qinliang", ""], ["Shou", "Linjun", ""], ["Gong", "Ming", ""], ["Zhong", "Wanjun", ""], ["Quan", "Xiaojun", ""], ["Duan", "Nan", ""], ["Jiang", "Daxin", ""]]}, {"id": "2012.14124", "submitter": "Keisuke Shirai", "authors": "Keisuke Shirai, Kazuma Hashimoto, Akiko Eriguchi, Takashi Ninomiya,\n  Shinsuke Mori", "title": "Neural Text Generation with Artificial Negative Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural text generation models conditioning on given input (e.g. machine\ntranslation and image captioning) are usually trained by maximum likelihood\nestimation of target text. However, the trained models suffer from various\ntypes of errors at inference time. In this paper, we propose to suppress an\narbitrary type of errors by training the text generation model in a\nreinforcement learning framework, where we use a trainable reward function that\nis capable of discriminating between references and sentences containing the\ntargeted type of errors. We create such negative examples by artificially\ninjecting the targeted errors to the references. In experiments, we focus on\ntwo error types, repeated and dropped tokens in model-generated text. The\nexperimental results show that our method can suppress the generation errors\nand achieve significant improvements on two machine translation and two image\ncaptioning tasks.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 07:25:10 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Shirai", "Keisuke", ""], ["Hashimoto", "Kazuma", ""], ["Eriguchi", "Akiko", ""], ["Ninomiya", "Takashi", ""], ["Mori", "Shinsuke", ""]]}, {"id": "2012.14136", "submitter": "Sajad Sotudeh", "authors": "Sajad Sotudeh, Arman Cohan, Nazli Goharian", "title": "On Generating Extended Summaries of Long Documents", "comments": "Accepted at SDU 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work in document summarization has mainly focused on generating short\nsummaries of a document. While this type of summary helps get a high-level view\nof a given document, it is desirable in some cases to know more detailed\ninformation about its salient points that can't fit in a short summary. This is\ntypically the case for longer documents such as a research paper, legal\ndocument, or a book. In this paper, we present a new method for generating\nextended summaries of long papers. Our method exploits hierarchical structure\nof the documents and incorporates it into an extractive summarization model\nthrough a multi-task learning approach. We then present our results on three\nlong summarization datasets, arXiv-Long, PubMed-Long, and Longsumm. Our method\noutperforms or matches the performance of strong baselines. Furthermore, we\nperform a comprehensive analysis over the generated results, shedding insights\non future research for long-form summary generation task. Our analysis shows\nthat our multi-tasking approach can adjust extraction probability distribution\nto the favor of summary-worthy sentences across diverse sections. Our datasets,\nand codes are publicly available at\nhttps://github.com/Georgetown-IR-Lab/ExtendedSumm\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 08:10:28 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Sotudeh", "Sajad", ""], ["Cohan", "Arman", ""], ["Goharian", "Nazli", ""]]}, {"id": "2012.14164", "submitter": "Martin Andrews", "authors": "Yew Ken Chia and Sam Witteveen and Martin Andrews", "title": "Red Dragon AI at TextGraphs 2020 Shared Task: LIT : LSTM-Interleaved\n  Transformer for Multi-Hop Explanation Ranking", "comments": "Accepted paper for TextGraphs-14 workshop at COLING 2020. (6 pages\n  including references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable question answering for science questions is a challenging task\nthat requires multi-hop inference over a large set of fact sentences. To\ncounter the limitations of methods that view each query-document pair in\nisolation, we propose the LSTM-Interleaved Transformer which incorporates\ncross-document interactions for improved multi-hop ranking. The LIT\narchitecture can leverage prior ranking positions in the re-ranking setting.\nOur model is competitive on the current leaderboard for the TextGraphs 2020\nshared task, achieving a test-set MAP of 0.5607, and would have gained third\nplace had we submitted before the competition deadline. Our code implementation\nis made available at\nhttps://github.com/mdda/worldtree_corpus/tree/textgraphs_2020\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 09:54:00 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Chia", "Yew Ken", ""], ["Witteveen", "Sam", ""], ["Andrews", "Martin", ""]]}, {"id": "2012.14210", "submitter": "Nils Reimers", "authors": "Nils Reimers and Iryna Gurevych", "title": "The Curse of Dense Low-Dimensional Information Retrieval for Large Index\n  Sizes", "comments": "Published at ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Information Retrieval using dense low-dimensional representations recently\nbecame popular and showed out-performance to traditional sparse-representations\nlike BM25. However, no previous work investigated how dense representations\nperform with large index sizes. We show theoretically and empirically that the\nperformance for dense representations decreases quicker than sparse\nrepresentations for increasing index sizes. In extreme cases, this can even\nlead to a tipping point where at a certain index size sparse representations\noutperform dense representations. We show that this behavior is tightly\nconnected to the number of dimensions of the representations: The lower the\ndimension, the higher the chance for false positives, i.e. returning irrelevant\ndocuments.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 12:25:25 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 07:25:23 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Reimers", "Nils", ""], ["Gurevych", "Iryna", ""]]}, {"id": "2012.14271", "submitter": "Ryota Hinami", "authors": "Ryota Hinami, Shonosuke Ishiwatari, Kazuhiko Yasuda, and Yusuke Matsui", "title": "Towards Fully Automated Manga Translation", "comments": "Accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of machine translation of manga, Japanese comics. Manga\ntranslation involves two important problems in machine translation:\ncontext-aware and multimodal translation. Since text and images are mixed up in\nan unstructured fashion in Manga, obtaining context from the image is essential\nfor manga translation. However, it is still an open problem how to extract\ncontext from image and integrate into MT models. In addition, corpus and\nbenchmarks to train and evaluate such model is currently unavailable. In this\npaper, we make the following four contributions that establishes the foundation\nof manga translation research. First, we propose multimodal context-aware\ntranslation framework. We are the first to incorporate context information\nobtained from manga image. It enables us to translate texts in speech bubbles\nthat cannot be translated without using context information (e.g., texts in\nother speech bubbles, gender of speakers, etc.). Second, for training the\nmodel, we propose the approach to automatic corpus construction from pairs of\noriginal manga and their translations, by which large parallel corpus can be\nconstructed without any manual labeling. Third, we created a new benchmark to\nevaluate manga translation. Finally, on top of our proposed methods, we devised\na first comprehensive system for fully automated manga translation.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 15:20:52 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 02:37:55 GMT"}, {"version": "v3", "created": "Sat, 9 Jan 2021 14:21:31 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Hinami", "Ryota", ""], ["Ishiwatari", "Shonosuke", ""], ["Yasuda", "Kazuhiko", ""], ["Matsui", "Yusuke", ""]]}, {"id": "2012.14309", "submitter": "Li-Min Wang", "authors": "Li-Min Wang, Hsing-Yi Lai, Sun-Ting Tsai, Shan-Jyun Wu, Meng-Xue Tsai,\n  Daw-Wei Wang, Yi-Ching Su, Chen Siang Ng, and Tzay-Ming Hong", "title": "Mechanism of Evolution Shared by Gene and Language", "comments": "15 pages, 13 figures, 3 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cond-mat.soft cs.CL physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general mechanism for evolution to explain the diversity of gene\nand language. To quantify their common features and reveal the hidden\nstructures, several statistical properties and patterns are examined based on a\nnew method called the rank-rank analysis. We find that the classical\ncorrespondence, \"domain plays the role of word in gene language\", is not\nrigorous, and propose to replace domain by protein. In addition, we devise a\nnew evolution unit, syllgram, to include the characteristics of spoken and\nwritten language. Based on the correspondence between (protein, domain) and\n(word, syllgram), we discover that both gene and language shared a common\nscaling structure and scale-free network. Like the Rosetta stone, this work may\nhelp decipher the secret behind non-coding DNA and unknown languages.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 15:46:19 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Wang", "Li-Min", ""], ["Lai", "Hsing-Yi", ""], ["Tsai", "Sun-Ting", ""], ["Wu", "Shan-Jyun", ""], ["Tsai", "Meng-Xue", ""], ["Wang", "Daw-Wei", ""], ["Su", "Yi-Ching", ""], ["Ng", "Chen Siang", ""], ["Hong", "Tzay-Ming", ""]]}, {"id": "2012.14312", "submitter": "Juan Rocha", "authors": "Juan Rocha, Linda Luvuno, Jesse Rieb, Erin Crockett, Katja Malmborg,\n  Michael Schoon, Garry Peterson", "title": "Panarchy: ripples of a boundary concept", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  How do social-ecological systems change over time? In 2002 Holling and\ncolleagues proposed the concept of Panarchy, which presented social-ecological\nsystems as an interacting set of adaptive cycles, each of which is produced by\nthe dynamic tensions between novelty and efficiency at multiple scales.\nInitially introduced as a conceptual framework and set of metaphors, panarchy\nhas gained the attention of scholars across many disciplines and its ideas\ncontinue to inspire further conceptual developments. Almost twenty years after\nthis concept was introduced we review how it has been used, tested, extended\nand revised. We do this by combining qualitative methods and machine learning.\nDocument analysis was used to code panarchy features that are commonly used in\nthe scientific literature (N = 42), a qualitative analysis that was\ncomplemented with topic modeling of 2177 documents. We find that the adaptive\ncycle is the feature of panarchy that has attracted the most attention.\nChallenges remain in empirically grounding the metaphor, but recent theoretical\nand empirical work offers some avenues for future research.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 15:47:45 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Rocha", "Juan", ""], ["Luvuno", "Linda", ""], ["Rieb", "Jesse", ""], ["Crockett", "Erin", ""], ["Malmborg", "Katja", ""], ["Schoon", "Michael", ""], ["Peterson", "Garry", ""]]}, {"id": "2012.14320", "submitter": "Yian Li", "authors": "Yian Li, Hai Zhao", "title": "BURT: BERT-inspired Universal Representation from Learning Meaningful\n  Segment", "comments": "arXiv admin note: text overlap with arXiv:2009.04656", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although pre-trained contextualized language models such as BERT achieve\nsignificant performance on various downstream tasks, current language\nrepresentation still only focuses on linguistic objective at a specific\ngranularity, which may not applicable when multiple levels of linguistic units\nare involved at the same time. Thus this work introduces and explores the\nuniversal representation learning, i.e., embeddings of different levels of\nlinguistic unit in a uniform vector space. We present a universal\nrepresentation model, BURT (BERT-inspired Universal Representation from\nlearning meaningful segmenT), to encode different levels of linguistic unit\ninto the same vector space. Specifically, we extract and mask meaningful\nsegments based on point-wise mutual information (PMI) to incorporate different\ngranular objectives into the pre-training stage. We conduct experiments on\ndatasets for English and Chinese including the GLUE and CLUE benchmarks, where\nour model surpasses its baselines and alternatives on a wide range of\ndownstream tasks. We present our approach of constructing analogy datasets in\nterms of words, phrases and sentences and experiment with multiple\nrepresentation models to examine geometric properties of the learned vector\nspace through a task-independent evaluation. Finally, we verify the\neffectiveness of our unified pre-training strategy in two real-world text\nmatching scenarios. As a result, our model significantly outperforms existing\ninformation retrieval (IR) methods and yields universal representations that\ncan be directly applied to retrieval-based question-answering and natural\nlanguage generation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 16:02:28 GMT"}, {"version": "v2", "created": "Thu, 31 Dec 2020 09:56:21 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Li", "Yian", ""], ["Zhao", "Hai", ""]]}, {"id": "2012.14353", "submitter": "Md. Rezaul Karim", "authors": "Md. Rezaul Karim and Sumon Kanti Dey and Tanhim Islam and Sagor Sarker\n  and Mehadi Hasan Menon and Kabir Hossain and Bharathi Raja Chakravarthi and\n  Md. Azam Hossain and Stefan Decker", "title": "DeepHateExplainer: Explainable Hate Speech Detection in Under-resourced\n  Bengali Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The exponential growths of social media and micro-blogging sites not only\nprovide platforms for empowering freedom of expressions and individual voices,\nbut also enables people to express anti-social behavior like online harassment,\ncyberbullying, and hate speech. Numerous works have been proposed to utilize\ntextual data for social and anti-social behavior analysis, by predicting the\ncontexts mostly for highly-resourced languages like English. However, some\nlanguages are under-resourced, e.g., South Asian languages like Bengali, that\nlack computational resources for accurate natural language processing (NLP). In\nthis paper, we propose an explainable approach for hate speech detection from\nthe under-resourced Bengali language, which we called DeepHateExplainer.\nBengali texts are first comprehensively preprocessed, before classifying them\ninto political, personal, geopolitical, and religious hates using a neural\nensemble method of transformer-based neural architectures (i.e., monolingual\nBangla BERT-base, multilingual BERT-cased/uncased, and XLM-RoBERTa).\nImportant~(most and least) terms are then identified using sensitivity analysis\nand layer-wise relevance propagation~(LRP), before providing\nhuman-interpretable explanations. Finally, we compute comprehensiveness and\nsufficiency scores to measure the quality of explanations w.r.t faithfulness.\nEvaluations against machine learning~(linear and tree-based models) and neural\nnetworks (i.e., CNN, Bi-LSTM, and Conv-LSTM with word embeddings) baselines\nyield F1-scores of 78%, 91%, 89%, and 84%, for political, personal,\ngeopolitical, and religious hates, respectively, outperforming both ML and DNN\nbaselines.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 16:46:03 GMT"}, {"version": "v2", "created": "Sun, 21 Feb 2021 13:47:23 GMT"}, {"version": "v3", "created": "Mon, 26 Jul 2021 10:44:53 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Karim", "Md. Rezaul", ""], ["Dey", "Sumon Kanti", ""], ["Islam", "Tanhim", ""], ["Sarker", "Sagor", ""], ["Menon", "Mehadi Hasan", ""], ["Hossain", "Kabir", ""], ["Chakravarthi", "Bharathi Raja", ""], ["Hossain", "Md. Azam", ""], ["Decker", "Stefan", ""]]}, {"id": "2012.14388", "submitter": "Yinfei Yang", "authors": "Ziyi Yang, Yinfei Yang, Daniel Cer, Jax Law, Eric Darve", "title": "Universal Sentence Representation Learning with Conditional Masked\n  Language Model", "comments": "preprint, updated license", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel training method, Conditional Masked Language\nModeling (CMLM), to effectively learn sentence representations on large scale\nunlabeled corpora. CMLM integrates sentence representation learning into MLM\ntraining by conditioning on the encoded vectors of adjacent sentences. Our\nEnglish CMLM model achieves state-of-the-art performance on SentEval, even\noutperforming models learned using (semi-)supervised signals. As a fully\nunsupervised learning method, CMLM can be conveniently extended to a broad\nrange of languages and domains. We find that a multilingual CMLM model\nco-trained with bitext retrieval~(BR) and natural language inference~(NLI)\ntasks outperforms the previous state-of-the-art multilingual models by a large\nmargin. We explore the same language bias of the learned representations, and\npropose a principle component based approach to remove the language identifying\ninformation from the representation while still retaining sentence semantics.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 18:06:37 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 03:29:11 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Yang", "Ziyi", ""], ["Yang", "Yinfei", ""], ["Cer", "Daniel", ""], ["Law", "Jax", ""], ["Darve", "Eric", ""]]}, {"id": "2012.14500", "submitter": "Xiangci Li", "authors": "Xiangci Li, Gully Burns, Nanyun Peng", "title": "A Paragraph-level Multi-task Learning Model for Scientific\n  Fact-Verification", "comments": "5 pages; The AAAI-21 Workshop on Scientific Document Understanding", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Even for domain experts, it is a non-trivial task to verify a scientific\nclaim by providing supporting or refuting evidence rationales. The situation\nworsens as misinformation is proliferated on social media or news websites,\nmanually or programmatically, at every moment. As a result, an automatic\nfact-verification tool becomes crucial for combating the spread of\nmisinformation. In this work, we propose a novel, paragraph-level, multi-task\nlearning model for the SciFact task by directly computing a sequence of\ncontextualized sentence embeddings from a BERT model and jointly training the\nmodel on rationale selection and stance prediction.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 21:51:31 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 02:29:18 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Li", "Xiangci", ""], ["Burns", "Gully", ""], ["Peng", "Nanyun", ""]]}, {"id": "2012.14535", "submitter": "Linfeng Song", "authors": "Jie Hao, Linfeng Song, Liwei Wang, Kun Xu, Zhaopeng Tu and Dong Yu", "title": "Robust Dialogue Utterance Rewriting as Sequence Tagging", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of dialogue rewriting aims to reconstruct the latest dialogue\nutterance by copying the missing content from the dialogue context. Until now,\nthe existing models for this task suffer from the robustness issue, i.e.,\nperformances drop dramatically when testing on a different domain. We address\nthis robustness issue by proposing a novel sequence-tagging-based model so that\nthe search space is significantly reduced, yet the core of this task is still\nwell covered. As a common issue of most tagging models for text generation, the\nmodel's outputs may lack fluency. To alleviate this issue, we inject the loss\nsignal from BLEU or GPT-2 under a REINFORCE framework. Experiments show huge\nimprovements of our model over the current state-of-the-art systems on domain\ntransfer.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 00:05:35 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Hao", "Jie", ""], ["Song", "Linfeng", ""], ["Wang", "Liwei", ""], ["Xu", "Kun", ""], ["Tu", "Zhaopeng", ""], ["Yu", "Dong", ""]]}, {"id": "2012.14541", "submitter": "Matan Orbach", "authors": "Matan Orbach, Orith Toledo-Ronen, Artem Spector, Ranit Aharonov, Yoav\n  Katz and Noam Slonim", "title": "YASO: A New Benchmark for Targeted Sentiment Analysis", "comments": "For the associated TSA corpus, see\n  https://www.research.ibm.com/haifa/dept/vst/debating_data.shtml#Targeted%20Sentiment%20Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis research has shifted over the years from the analysis of\nfull documents or single sentences to a finer-level of detail -- identifying\nthe sentiment towards single words or phrases -- with the task of Targeted\nSentiment Analysis (TSA). While this problem is attracting a plethora of works\nfocusing on algorithmic aspects, they are typically evaluated on a selection\nfrom a handful of datasets, and little effort, if any, is dedicated to the\nexpansion of the available evaluation data. In this work, we present YASO -- a\nnew crowd-sourced TSA evaluation dataset, collected using a new annotation\nscheme for labeling targets and their sentiments. The dataset contains 2,215\nEnglish sentences from movie, business and product reviews, and 7,415 terms and\ntheir corresponding sentiments annotated within these sentences. Our analysis\nverifies the reliability of our annotations, and explores the characteristics\nof the collected data. Lastly, benchmark results using five contemporary TSA\nsystems lay the foundation for future work, and show there is ample room for\nimprovement on this challenging new dataset.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 00:25:15 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Orbach", "Matan", ""], ["Toledo-Ronen", "Orith", ""], ["Spector", "Artem", ""], ["Aharonov", "Ranit", ""], ["Katz", "Yoav", ""], ["Slonim", "Noam", ""]]}, {"id": "2012.14583", "submitter": "Liang Ding", "authors": "Liang Ding, Longyue Wang, Xuebo Liu, Derek F. Wong, Dacheng Tao,\n  Zhaopeng Tu", "title": "Understanding and Improving Lexical Choice in Non-Autoregressive\n  Translation", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation (KD) is essential for training non-autoregressive\ntranslation (NAT) models by reducing the complexity of the raw data with an\nautoregressive teacher model. In this study, we empirically show that as a side\neffect of this training, the lexical choice errors on low-frequency words are\npropagated to the NAT model from the teacher model. To alleviate this problem,\nwe propose to expose the raw data to NAT models to restore the useful\ninformation of low-frequency words, which are missed in the distilled data. To\nthis end, we introduce an extra Kullback-Leibler divergence term derived by\ncomparing the lexical choice of NAT model and that embedded in the raw data.\nExperimental results across language pairs and model architectures demonstrate\nthe effectiveness and universality of the proposed approach. Extensive analyses\nconfirm our claim that our approach improves performance by reducing the\nlexical choice errors on low-frequency words. Encouragingly, our approach\npushes the SOTA NAT performance on the WMT14 English-German and WMT16\nRomanian-English datasets up to 27.8 and 33.8 BLEU points, respectively. The\nsource code will be released.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 03:18:50 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 07:22:16 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Ding", "Liang", ""], ["Wang", "Longyue", ""], ["Liu", "Xuebo", ""], ["Wong", "Derek F.", ""], ["Tao", "Dacheng", ""], ["Tu", "Zhaopeng", ""]]}, {"id": "2012.14602", "submitter": "Oleg Vasilyev", "authors": "Oleg Vasilyev and John Bohannon", "title": "Is human scoring the best criteria for summary evaluation?", "comments": "7 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normally, summary quality measures are compared with quality scores produced\nby human annotators. A higher correlation with human scores is considered to be\na fair indicator of a better measure. We discuss observations that cast doubt\non this view. We attempt to show a possibility of an alternative indicator.\nGiven a family of measures, we explore a criterion of selecting the best\nmeasure not relying on correlations with human scores. Our observations for the\nBLANC family of measures suggest that the criterion is universal across very\ndifferent styles of summaries.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 04:48:52 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Vasilyev", "Oleg", ""], ["Bohannon", "John", ""]]}, {"id": "2012.14610", "submitter": "Barlas Oguz", "authors": "Barlas Oguz, Xilun Chen, Vladimir Karpukhin, Stan Peshterliev, Dmytro\n  Okhonko, Michael Schlichtkrull, Sonal Gupta, Yashar Mehdad, Scott Yih", "title": "UniK-QA: Unified Representations of Structured and Unstructured\n  Knowledge for Open-Domain Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study open-domain question answering with structured, unstructured and\nsemi-structured knowledge sources, including text, tables, lists and knowledge\nbases. Departing from prior work, we propose a unifying approach that\nhomogenizes all sources by reducing them to text and applies the\nretriever-reader model which has so far been limited to text sources only. Our\napproach greatly improves the results on knowledge-base QA tasks by 11 points,\ncompared to latest graph-based methods. More importantly, we demonstrate that\nour unified knowledge (UniK-QA) model is a simple and yet effective way to\ncombine heterogeneous sources of knowledge, advancing the state-of-the-art\nresults on two popular question answering benchmarks, NaturalQuestions and\nWebQuestions, by 3.5 and 2.6 points, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 05:14:08 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 00:01:35 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Oguz", "Barlas", ""], ["Chen", "Xilun", ""], ["Karpukhin", "Vladimir", ""], ["Peshterliev", "Stan", ""], ["Okhonko", "Dmytro", ""], ["Schlichtkrull", "Michael", ""], ["Gupta", "Sonal", ""], ["Mehdad", "Yashar", ""], ["Yih", "Scott", ""]]}, {"id": "2012.14642", "submitter": "Le Qi", "authors": "Le Qi, Yu Zhang, Qingyu Yin, Ting Liu", "title": "Multiple Structural Priors Guided Self Attention Network for Language\n  Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self attention networks (SANs) have been widely utilized in recent NLP\nstudies. Unlike CNNs or RNNs, standard SANs are usually position-independent,\nand thus are incapable of capturing the structural priors between sequences of\nwords. Existing studies commonly apply one single mask strategy on SANs for\nincorporating structural priors while failing at modeling more abundant\nstructural information of texts. In this paper, we aim at introducing multiple\ntypes of structural priors into SAN models, proposing the Multiple Structural\nPriors Guided Self Attention Network (MS-SAN) that transforms different\nstructural priors into different attention heads by using a novel multi-mask\nbased multi-head attention mechanism. In particular, we integrate two\ncategories of structural priors, including the sequential order and the\nrelative position of words. For the purpose of capturing the latent\nhierarchical structure of the texts, we extract these information not only from\nthe word contexts but also from the dependency syntax trees. Experimental\nresults on two tasks show that MS-SAN achieves significant improvements against\nother strong baselines.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 07:30:03 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Qi", "Le", ""], ["Zhang", "Yu", ""], ["Yin", "Qingyu", ""], ["Liu", "Ting", ""]]}, {"id": "2012.14645", "submitter": "Yangming Li", "authors": "Yangming Li, Kaisheng Yao", "title": "Interpretable NLG for Task-oriented Dialogue Systems with Heterogeneous\n  Rendering Machines", "comments": "Accepted as a conference paper at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end neural networks have achieved promising performances in natural\nlanguage generation (NLG). However, they are treated as black boxes and lack\ninterpretability. To address this problem, we propose a novel framework,\nheterogeneous rendering machines (HRM), that interprets how neural generators\nrender an input dialogue act (DA) into an utterance. HRM consists of a renderer\nset and a mode switcher. The renderer set contains multiple decoders that vary\nin both structure and functionality. For every generation step, the mode\nswitcher selects an appropriate decoder from the renderer set to generate an\nitem (a word or a phrase). To verify the effectiveness of our method, we have\nconducted extensive experiments on 5 benchmark datasets. In terms of automatic\nmetrics (e.g., BLEU), our model is competitive with the current\nstate-of-the-art method. The qualitative analysis shows that our model can\ninterpret the rendering process of neural generators well. Human evaluation\nalso confirms the interpretability of our proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 07:41:48 GMT"}, {"version": "v2", "created": "Sun, 7 Feb 2021 06:49:37 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Li", "Yangming", ""], ["Yao", "Kaisheng", ""]]}, {"id": "2012.14653", "submitter": "Yi-Chia Wang", "authors": "Yi-Chia Wang, Alexandros Papangelis, Runze Wang, Zhaleh Feizollahi,\n  Gokhan Tur, Robert Kraut", "title": "Can You be More Social? Injecting Politeness and Positivity into\n  Task-Oriented Conversational Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goal-oriented conversational agents are becoming prevalent in our daily\nlives. For these systems to engage users and achieve their goals, they need to\nexhibit appropriate social behavior as well as provide informative replies that\nguide users through tasks. The first component of the research in this paper\napplies statistical modeling techniques to understand conversations between\nusers and human agents for customer service. Analyses show that social language\nused by human agents is associated with greater users' responsiveness and task\ncompletion. The second component of the research is the construction of a\nconversational agent model capable of injecting social language into an agent's\nresponses while still preserving content. The model uses a sequence-to-sequence\ndeep learning architecture, extended with a social language understanding\nelement. Evaluation in terms of content preservation and social language level\nusing both human judgment and automatic linguistic measures shows that the\nmodel can generate responses that enable agents to address users' issues in a\nmore socially appropriate way.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 08:22:48 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Wang", "Yi-Chia", ""], ["Papangelis", "Alexandros", ""], ["Wang", "Runze", ""], ["Feizollahi", "Zhaleh", ""], ["Tur", "Gokhan", ""], ["Kraut", "Robert", ""]]}, {"id": "2012.14660", "submitter": "Zihao Fu", "authors": "Zihao Fu, Wai Lam, Anthony Man-Cho So, Bei Shi", "title": "A Theoretical Analysis of the Repetition Problem in Text Generation", "comments": "AAAI 21 Paper with Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text generation tasks, including translation, summarization, language models,\nand etc. see rapid growth during recent years. Despite the remarkable\nachievements, the repetition problem has been observed in nearly all text\ngeneration models undermining the generation performance extensively. To solve\nthe repetition problem, many methods have been proposed, but there is no\nexisting theoretical analysis to show why this problem happens and how it is\nresolved. In this paper, we propose a new framework for theoretical analysis\nfor the repetition problem. We first define the Average Repetition Probability\n(ARP) to characterize the repetition problem quantitatively. Then, we conduct\nan extensive analysis of the Markov generation model and derive several upper\nbounds of the average repetition probability with intuitive understanding. We\nshow that most of the existing methods are essentially minimizing the upper\nbounds explicitly or implicitly. Grounded on our theory, we show that the\nrepetition problem is, unfortunately, caused by the traits of our language\nitself. One major reason is attributed to the fact that there exist too many\nwords predicting the same word as the subsequent word with high probability.\nConsequently, it is easy to go back to that word and form repetitions and we\ndub it as the high inflow problem. Furthermore, we derive a concentration bound\nof the average repetition probability for a general generation model. Finally,\nbased on the theoretical upper bounds, we propose a novel rebalanced encoding\napproach to alleviate the high inflow problem. The experimental results show\nthat our theoretical framework is applicable in general generation models and\nour proposed rebalanced encoding approach alleviates the repetition problem\nsignificantly. The source code of this paper can be obtained from\nhttps://github.com/fuzihaofzh/repetition-problem-nlg.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 08:51:47 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 01:00:17 GMT"}, {"version": "v3", "created": "Thu, 28 Jan 2021 14:12:31 GMT"}, {"version": "v4", "created": "Mon, 22 Mar 2021 02:55:21 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Fu", "Zihao", ""], ["Lam", "Wai", ""], ["So", "Anthony Man-Cho", ""], ["Shi", "Bei", ""]]}, {"id": "2012.14666", "submitter": "Baolin Peng", "authors": "Baolin Peng, Chunyuan Li, Zhu Zhang, Chenguang Zhu, Jinchao Li,\n  Jianfeng Gao", "title": "RADDLE: An Evaluation Benchmark and Analysis Platform for Robust\n  Task-oriented Dialog Systems", "comments": "12 pages; Project website at aka.ms/raddle", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For task-oriented dialog systems to be maximally useful, it must be able to\nprocess conversations in a way that is (1) generalizable with a small number of\ntraining examples for new task domains, and (2) robust to user input in various\nstyles, modalities or domains. In pursuit of these goals, we introduce the\nRADDLE benchmark, a collection of corpora and tools for evaluating the\nperformance of models across a diverse set of domains. By including tasks with\nlimited training data, RADDLE is designed to favor and encourage models with a\nstrong generalization ability. RADDLE also includes a diagnostic checklist that\nfacilitates detailed robustness analysis in aspects such as language\nvariations, speech errors, unseen entities, and out-of-domain utterances. We\nevaluate recent state-of-the-art systems based on pre-training and fine-tuning,\nand find that grounded pre-training on heterogeneous dialog corpora performs\nbetter than training a separate model per domain. Overall, existing models are\nless than satisfactory in robustness evaluation, which suggests opportunities\nfor future improvement.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 08:58:49 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Peng", "Baolin", ""], ["Li", "Chunyuan", ""], ["Zhang", "Zhu", ""], ["Zhu", "Chenguang", ""], ["Li", "Jinchao", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2012.14681", "submitter": "Sathish Indurthi", "authors": "Hyojung Han, Sathish Indurthi, Mohd Abbas Zaidi, Nikhil Kumar\n  Lakumarapu, Beomseok Lee, Sangha Kim, Chanwoo Kim, Inchul Hwang", "title": "Faster Re-translation Using Non-Autoregressive Model For Simultaneous\n  Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, simultaneous translation has gathered a lot of attention since it\nenables compelling applications such as subtitle translation for a live event\nor real-time video-call translation. Some of these translation applications\nallow editing of partial translation giving rise to re-translation approaches.\nThe current re-translation approaches are based on autoregressive sequence\ngeneration models (ReTA), which generate tar-get tokens in the (partial)\ntranslation sequentially. The multiple re-translations with sequential\ngeneration inReTAmodelslead to an increased inference time gap between the\nincoming source input and the corresponding target output as the source input\ngrows. Besides, due to the large number of inference operations involved, the\nReTA models are not favorable for resource-constrained devices. In this work,\nwe propose a faster re-translation system based on a non-autoregressive\nsequence generation model (FReTNA) to overcome the aforementioned limitations.\nWe evaluate the proposed model on multiple translation tasks and our model\nreduces the inference times by several orders and achieves a competitive\nBLEUscore compared to the ReTA and streaming (Wait-k) models.The proposed model\nreduces the average computation time by a factor of 20 when compared to the\nReTA model by incurring a small drop in the translation quality. It also\noutperforms the streaming-based Wait-k model both in terms of computation time\n(1.5 times lower) and translation quality.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 09:43:27 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 03:45:18 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Han", "Hyojung", ""], ["Indurthi", "Sathish", ""], ["Zaidi", "Mohd Abbas", ""], ["Lakumarapu", "Nikhil Kumar", ""], ["Lee", "Beomseok", ""], ["Kim", "Sangha", ""], ["Kim", "Chanwoo", ""], ["Hwang", "Inchul", ""]]}, {"id": "2012.14682", "submitter": "Lei Li", "authors": "Lei Li, Yankai Lin, Shuhuai Ren, Deli Chen, Xuancheng Ren, Peng Li,\n  Jie Zhou, Xu Sun", "title": "Accelerating Pre-trained Language Models via Calibrated Cascade", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dynamic early exiting aims to accelerate pre-trained language models' (PLMs)\ninference by exiting in shallow layer without passing through the entire model.\nIn this paper, we analyze the working mechanism of dynamic early exiting and\nfind it cannot achieve a satisfying trade-off between inference speed and\nperformance. On one hand, the PLMs' representations in shallow layers are not\nsufficient for accurate prediction. One the other hand, the internal off-ramps\ncannot provide reliable exiting decisions. To remedy this, we instead propose\nCascadeBERT, which dynamically selects a proper-sized, complete model in a\ncascading manner. To obtain more reliable model selection, we further devise a\ndifficulty-aware objective, encouraging the model output class probability to\nreflect the real difficulty of each instance. Extensive experimental results\ndemonstrate the superiority of our proposal over strong baseline models of\nPLMs' acceleration including both dynamic early exiting and knowledge\ndistillation methods.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 09:43:50 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Li", "Lei", ""], ["Lin", "Yankai", ""], ["Ren", "Shuhuai", ""], ["Chen", "Deli", ""], ["Ren", "Xuancheng", ""], ["Li", "Peng", ""], ["Zhou", "Jie", ""], ["Sun", "Xu", ""]]}, {"id": "2012.14710", "submitter": "Hongqiu Wu", "authors": "Hongqiu Wu and Hai Zhao and Min Zhang", "title": "Code Summarization with Structure-induced Transformer", "comments": "Findings of ACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code summarization (CS) is becoming a promising area in recent language\nunderstanding, which aims to generate sensible human language automatically for\nprogramming language in the format of source code, serving in the most\nconvenience of programmer developing. It is well known that programming\nlanguages are highly structured. Thus previous works attempt to apply\nstructure-based traversal (SBT) or non-sequential models like Tree-LSTM and\ngraph neural network (GNN) to learn structural program semantics. However, it\nis surprising that incorporating SBT into advanced encoder like Transformer\ninstead of LSTM has been shown no performance gain, which lets GNN become the\nonly rest means modeling such necessary structural clue in source code. To\nrelease such inconvenience, we propose structure-induced Transformer, which\nencodes sequential code inputs with multi-view structural clues in terms of a\nnewly-proposed structure-induced self-attention mechanism. Extensive\nexperiments show that our proposed structure-induced Transformer helps achieve\nnew state-of-the-art results on benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 11:37:43 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 02:54:32 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Wu", "Hongqiu", ""], ["Zhao", "Hai", ""], ["Zhang", "Min", ""]]}, {"id": "2012.14740", "submitter": "Lei Cui", "authors": "Yang Xu, Yiheng Xu, Tengchao Lv, Lei Cui, Furu Wei, Guoxin Wang,\n  Yijuan Lu, Dinei Florencio, Cha Zhang, Wanxiang Che, Min Zhang, Lidong Zhou", "title": "LayoutLMv2: Multi-modal Pre-training for Visually-Rich Document\n  Understanding", "comments": "ACL 2021 main conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Pre-training of text and layout has proved effective in a variety of\nvisually-rich document understanding tasks due to its effective model\narchitecture and the advantage of large-scale unlabeled scanned/digital-born\ndocuments. In this paper, we present \\textbf{LayoutLMv2} by pre-training text,\nlayout and image in a multi-modal framework, where new model architectures and\npre-training tasks are leveraged. Specifically, LayoutLMv2 not only uses the\nexisting masked visual-language modeling task but also the new text-image\nalignment and text-image matching tasks in the pre-training stage, where\ncross-modality interaction is better learned. Meanwhile, it also integrates a\nspatial-aware self-attention mechanism into the Transformer architecture, so\nthat the model can fully understand the relative positional relationship among\ndifferent text blocks. Experiment results show that LayoutLMv2 outperforms\nstrong baselines and achieves new state-of-the-art results on a wide variety of\ndownstream visually-rich document understanding tasks, including FUNSD (0.7895\n-> 0.8420), CORD (0.9493 -> 0.9601), SROIE (0.9524 -> 0.9781), Kleister-NDA\n(0.834 -> 0.852), RVL-CDIP (0.9443 -> 0.9564), and DocVQA (0.7295 -> 0.8672).\nThe pre-trained LayoutLMv2 model is publicly available at\nhttps://aka.ms/layoutlmv2.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 13:01:52 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 07:02:57 GMT"}, {"version": "v3", "created": "Tue, 11 May 2021 06:42:33 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Xu", "Yang", ""], ["Xu", "Yiheng", ""], ["Lv", "Tengchao", ""], ["Cui", "Lei", ""], ["Wei", "Furu", ""], ["Wang", "Guoxin", ""], ["Lu", "Yijuan", ""], ["Florencio", "Dinei", ""], ["Zhang", "Cha", ""], ["Che", "Wanxiang", ""], ["Zhang", "Min", ""], ["Zhou", "Lidong", ""]]}, {"id": "2012.14756", "submitter": "Yixuan Su", "authors": "Yixuan Su, Deng Cai, Qingyu Zhou, Zibo Lin, Simon Baker, Yunbo Cao,\n  Shuming Shi, Nigel Collier, Yan Wang", "title": "Dialogue Response Selection with Hierarchical Curriculum Learning", "comments": "Accepted as long paper to the main conference of ACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study the learning of a matching model for dialogue response selection.\nMotivated by the recent finding that models trained with random negative\nsamples are not ideal in real-world scenarios, we propose a hierarchical\ncurriculum learning framework that trains the matching model in an\n\"easy-to-difficult\" scheme. Our learning framework consists of two\ncomplementary curricula: (1) corpus-level curriculum (CC); and (2)\ninstance-level curriculum (IC). In CC, the model gradually increases its\nability in finding the matching clues between the dialogue context and a\nresponse candidate. As for IC, it progressively strengthens the model's ability\nin identifying the mismatching information between the dialogue context and a\nresponse candidate. Empirical studies on three benchmark datasets with three\nstate-of-the-art matching models demonstrate that the proposed learning\nframework significantly improves the model performance across various\nevaluation metrics.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 14:06:41 GMT"}, {"version": "v2", "created": "Sun, 23 May 2021 21:53:36 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Su", "Yixuan", ""], ["Cai", "Deng", ""], ["Zhou", "Qingyu", ""], ["Lin", "Zibo", ""], ["Baker", "Simon", ""], ["Cao", "Yunbo", ""], ["Shi", "Shuming", ""], ["Collier", "Nigel", ""], ["Wang", "Yan", ""]]}, {"id": "2012.14763", "submitter": "Wei Zhu", "authors": "Wei Zhu, Daniel Cheung", "title": "CMV-BERT: Contrastive multi-vocab pretraining of BERT", "comments": "will add more detailed technical contents, and more detailed\n  experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we represent CMV-BERT, which improves the pretraining of a\nlanguage model via two ingredients: (a) contrastive learning, which is well\nstudied in the area of computer vision; (b) multiple vocabularies, one of which\nis fine-grained and the other is coarse-grained. The two methods both provide\ndifferent views of an original sentence, and both are shown to be beneficial.\nDownstream tasks demonstrate our proposed CMV-BERT are effective in improving\nthe pretrained language models.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 14:23:50 GMT"}, {"version": "v2", "created": "Sun, 30 May 2021 12:44:39 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Zhu", "Wei", ""], ["Cheung", "Daniel", ""]]}, {"id": "2012.14768", "submitter": "Xuebo Liu", "authors": "Xuebo Liu, Longyue Wang, Derek F. Wong, Liang Ding, Lidia S. Chao,\n  Zhaopeng Tu", "title": "Understanding and Improving Encoder Layer Fusion in Sequence-to-Sequence\n  Learning", "comments": "Accepted to ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Encoder layer fusion (EncoderFusion) is a technique to fuse all the encoder\nlayers (instead of the uppermost layer) for sequence-to-sequence (Seq2Seq)\nmodels, which has proven effective on various NLP tasks. However, it is still\nnot entirely clear why and when EncoderFusion should work. In this paper, our\nmain contribution is to take a step further in understanding EncoderFusion.\nMany of previous studies believe that the success of EncoderFusion comes from\nexploiting surface and syntactic information embedded in lower encoder layers.\nUnlike them, we find that the encoder embedding layer is more important than\nother intermediate encoder layers. In addition, the uppermost decoder layer\nconsistently pays more attention to the encoder embedding layer across NLP\ntasks. Based on this observation, we propose a simple fusion method,\nSurfaceFusion, by fusing only the encoder embedding layer for the softmax\nlayer. Experimental results show that SurfaceFusion outperforms EncoderFusion\non several NLP benchmarks, including machine translation, text summarization,\nand grammatical error correction. It obtains the state-of-the-art performance\non WMT16 Romanian-English and WMT14 English-French translation tasks. Extensive\nanalyses reveal that SurfaceFusion learns more expressive bilingual word\nembeddings by building a closer relationship between relevant source and target\nembedding. Source code is freely available at\nhttps://github.com/SunbowLiu/SurfaceFusion.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 14:26:59 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 11:46:55 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Liu", "Xuebo", ""], ["Wang", "Longyue", ""], ["Wong", "Derek F.", ""], ["Ding", "Liang", ""], ["Chao", "Lidia S.", ""], ["Tu", "Zhaopeng", ""]]}, {"id": "2012.14769", "submitter": "Linyang Li", "authors": "Linyang Li, Yunfan Shao, Demin Song, Xipeng Qiu, Xuanjing Huang", "title": "Generating Adversarial Examples in Chinese Texts Using Sentence-Pieces", "comments": "pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks in texts are mostly substitution-based methods that\nreplace words or characters in the original texts to achieve success attacks.\nRecent methods use pre-trained language models as the substitutes generator.\nWhile in Chinese, such methods are not applicable since words in Chinese\nrequire segmentations first. In this paper, we propose a pre-train language\nmodel as the substitutes generator using sentence-pieces to craft adversarial\nexamples in Chinese. The substitutions in the generated adversarial examples\nare not characters or words but \\textit{'pieces'}, which are more natural to\nChinese readers. Experiments results show that the generated adversarial\nsamples can mislead strong target models and remain fluent and semantically\npreserved.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 14:28:07 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Li", "Linyang", ""], ["Shao", "Yunfan", ""], ["Song", "Demin", ""], ["Qiu", "Xipeng", ""], ["Huang", "Xuanjing", ""]]}, {"id": "2012.14774", "submitter": "Yumo Xu", "authors": "Yumo Xu and Mirella Lapata", "title": "Generating Query Focused Summaries from Query-Free Resources", "comments": "ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The availability of large-scale datasets has driven the development of neural\nmodels that create generic summaries from single or multiple documents. In this\nwork we consider query focused summarization (QFS), a task for which training\ndata in the form of queries, documents, and summaries is not readily available.\nWe propose to decompose QFS into (1) query modeling (i.e., finding supportive\nevidence within a set of documents for a query) and (2) conditional language\nmodeling (i.e., summary generation). We introduce MaRGE, a Masked ROUGE\nRegression framework for evidence estimation and ranking which relies on a\nunified representation for summaries and queries, so that summaries in generic\ndata can be converted into proxy queries for learning a query model.\nExperiments across QFS benchmarks and query types show that our model achieves\nstate-of-the-art performance despite learning from weak supervision.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 14:39:35 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 21:34:37 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Xu", "Yumo", ""], ["Lapata", "Mirella", ""]]}, {"id": "2012.14778", "submitter": "Alessio Santamaria", "authors": "Filippo Bonchi and Alessio Santamaria", "title": "Combining Semilattices and Semimodules", "comments": null, "journal-ref": "Foundations of Software Science and Computation Structures.\n  FOSSACS 2021. Lecture Notes in Computer Science, vol 12650 (2021), pp\n  102-123. Springer, Cham", "doi": "10.1007/978-3-030-71995-1_6", "report-no": null, "categories": "cs.CL math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe the canonical weak distributive law $\\delta \\colon \\mathcal S\n\\mathcal P \\to \\mathcal P \\mathcal S$ of the powerset monad $\\mathcal P$ over\nthe $S$-left-semimodule monad $\\mathcal S$, for a class of semirings $S$. We\nshow that the composition of $\\mathcal P$ with $\\mathcal S$ by means of such\n$\\delta$ yields almost the monad of convex subsets previously introduced by\nJacobs: the only difference consists in the absence in Jacobs's monad of the\nempty convex set. We provide a handy characterisation of the canonical weak\nlifting of $\\mathcal P$ to $\\mathbb{EM}(\\mathcal S)$ as well as an algebraic\ntheory for the resulting composed monad. Finally, we restrict the composed\nmonad to finitely generated convex subsets and we show that it is presented by\nan algebraic theory combining semimodules and semilattices with bottom, which\nare the algebras for the finite powerset monad $\\mathcal P_f$.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 14:44:13 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 12:23:01 GMT"}, {"version": "v3", "created": "Sun, 24 Jan 2021 16:47:41 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Bonchi", "Filippo", ""], ["Santamaria", "Alessio", ""]]}, {"id": "2012.14781", "submitter": "Jiangnan Li", "authors": "Jiangnan Li, Zheng Lin, Peng Fu, Qingyi Si, Weiping Wang", "title": "A Hierarchical Transformer with Speaker Modeling for Emotion Recognition\n  in Conversation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion Recognition in Conversation (ERC) is a more challenging task than\nconventional text emotion recognition. It can be regarded as a personalized and\ninteractive emotion recognition task, which is supposed to consider not only\nthe semantic information of text but also the influences from speakers. The\ncurrent method models speakers' interactions by building a relation between\nevery two speakers. However, this fine-grained but complicated modeling is\ncomputationally expensive, hard to extend, and can only consider local context.\nTo address this problem, we simplify the complicated modeling to a binary\nversion: Intra-Speaker and Inter-Speaker dependencies, without identifying\nevery unique speaker for the targeted speaker. To better achieve the simplified\ninteraction modeling of speakers in Transformer, which shows excellent ability\nto settle long-distance dependency, we design three types of masks and\nrespectively utilize them in three independent Transformer blocks. The designed\nmasks respectively model the conventional context modeling, Intra-Speaker\ndependency, and Inter-Speaker dependency. Furthermore, different speaker-aware\ninformation extracted by Transformer blocks diversely contributes to the\nprediction, and therefore we utilize the attention mechanism to automatically\nweight them. Experiments on two ERC datasets indicate that our model is\nefficacious to achieve better performance.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 14:47:35 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Li", "Jiangnan", ""], ["Lin", "Zheng", ""], ["Fu", "Peng", ""], ["Si", "Qingyi", ""], ["Wang", "Weiping", ""]]}, {"id": "2012.14827", "submitter": "Siru Ouyang", "authors": "Siru Ouyang, Zhuosheng Zhang, Hai Zhao", "title": "Dialogue Graph Modeling for Conversational Machine Reading", "comments": "Findings of ACL: ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational Machine Reading (CMR) aims at answering questions in a\ncomplicated manner. Machine needs to answer questions through interactions with\nusers based on given rule document, user scenario and dialogue history, and ask\nquestions to clarify if necessary. In this paper, we propose a dialogue graph\nmodeling framework to improve the understanding and reasoning ability of\nmachine on CMR task. There are three types of graph in total. Specifically,\nDiscourse Graph is designed to learn explicitly and extract the discourse\nrelation among rule texts as well as the extra knowledge of scenario;\nDecoupling Graph is used for understanding local and contextualized connection\nwithin rule texts. And finally a global graph for fusing the information\ntogether and reply to the user with our final decision being either\n\"Yes/No/Irrelevant\" or to ask a follow-up question to clarify.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 16:08:36 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 09:49:27 GMT"}, {"version": "v3", "created": "Sat, 29 May 2021 11:15:08 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Ouyang", "Siru", ""], ["Zhang", "Zhuosheng", ""], ["Zhao", "Hai", ""]]}, {"id": "2012.14837", "submitter": "Lasha Abzianidze", "authors": "Lasha Abzianidze, Johan Bos, Stephan Oepen", "title": "DRS at MRP 2020: Dressing up Discourse Representation Structures as\n  Graphs", "comments": "10 pages, 4 figures, 4 tables, CoNLL 2020 Shared Task", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Discourse Representation Theory (DRT) is a formal account for representing\nthe meaning of natural language discourse. Meaning in DRT is modeled via a\nDiscourse Representation Structure (DRS), a meaning representation with a\nmodel-theoretic interpretation, which is usually depicted as nested boxes. In\ncontrast, a directed labeled graph is a common data structure used to encode\nsemantics of natural language texts. The paper describes the procedure of\ndressing up DRSs as directed labeled graphs to include DRT as a new framework\nin the 2020 shared task on Cross-Framework and Cross-Lingual Meaning\nRepresentation Parsing. Since one of the goals of the shared task is to\nencourage unified models for several semantic graph frameworks, the conversion\nprocedure was biased towards making the DRT graph framework somewhat similar to\nother graph-based meaning representation frameworks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 16:36:49 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Abzianidze", "Lasha", ""], ["Bos", "Johan", ""], ["Oepen", "Stephan", ""]]}, {"id": "2012.14854", "submitter": "Lasha Abzianidze", "authors": "Lasha Abzianidze, Rik van Noord, Chunliu Wang, Johan Bos", "title": "The Parallel Meaning Bank: A Framework for Semantically Annotating\n  Multiple Languages", "comments": "13 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper gives a general description of the ideas behind the Parallel\nMeaning Bank, a framework with the aim to provide an easy way to annotate\ncompositional semantics for texts written in languages other than English. The\nannotation procedure is semi-automatic, and comprises seven layers of\nlinguistic information: segmentation, symbolisation, semantic tagging, word\nsense disambiguation, syntactic structure, thematic role labelling, and\nco-reference. New languages can be added to the meaning bank as long as the\ndocuments are based on translations from English, but also introduce new\ninteresting challenges on the linguistics assumptions underlying the Parallel\nMeaning Bank.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 17:04:10 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Abzianidze", "Lasha", ""], ["van Noord", "Rik", ""], ["Wang", "Chunliu", ""], ["Bos", "Johan", ""]]}, {"id": "2012.14862", "submitter": "Si Sun", "authors": "Si Sun, Yingzhuo Qian, Zhenghao Liu, Chenyan Xiong, Kaitao Zhang, Jie\n  Bao, Zhiyuan Liu and Paul Bennett", "title": "Few-Shot Text Ranking with Meta Adapted Synthetic Weak Supervision", "comments": "14 pages, accepted by ACL-IJCNLP 2021 (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effectiveness of Neural Information Retrieval (Neu-IR) often depends on a\nlarge scale of in-domain relevance training signals, which are not always\navailable in real-world ranking scenarios. To democratize the benefits of\nNeu-IR, this paper presents MetaAdaptRank, a domain adaptive learning method\nthat generalizes Neu-IR models from label-rich source domains to few-shot\ntarget domains. Drawing on source-domain massive relevance supervision,\nMetaAdaptRank contrastively synthesizes a large number of weak supervision\nsignals for target domains and meta-learns to reweight these synthetic \"weak\"\ndata based on their benefits to the target-domain ranking accuracy of Neu-IR\nmodels. Experiments on three TREC benchmarks in the web, news, and biomedical\ndomains show that MetaAdaptRank significantly improves the few-shot ranking\naccuracy of Neu-IR models. Further analyses indicate that MetaAdaptRank thrives\nfrom both its contrastive weak data synthesis and meta-reweighted data\nselection. The code and data of this paper can be obtained from\nhttps://github.com/thunlp/MetaAdaptRank.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 17:28:53 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 16:35:46 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Sun", "Si", ""], ["Qian", "Yingzhuo", ""], ["Liu", "Zhenghao", ""], ["Xiong", "Chenyan", ""], ["Zhang", "Kaitao", ""], ["Bao", "Jie", ""], ["Liu", "Zhiyuan", ""], ["Bennett", "Paul", ""]]}, {"id": "2012.14913", "submitter": "Mor Geva", "authors": "Mor Geva, Roei Schuster, Jonathan Berant, Omer Levy", "title": "Transformer Feed-Forward Layers Are Key-Value Memories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Feed-forward layers constitute two-thirds of a transformer model's\nparameters, yet their role in the network remains under-explored. We show that\nfeed-forward layers in transformer-based language models operate as key-value\nmemories, where each key correlates with textual patterns in the training\nexamples, and each value induces a distribution over the output vocabulary. Our\nexperiments show that the learned patterns are human-interpretable, and that\nlower layers tend to capture shallow patterns, while upper layers learn more\nsemantic ones. The values complement the keys' input patterns by inducing\noutput distributions that concentrate probability mass on tokens likely to\nappear immediately after each pattern, particularly in the upper layers.\nFinally, we demonstrate that the output of a feed-forward layer is a\ncomposition of its memories, which is subsequently refined throughout the\nmodel's layers via residual connections to produce the final output\ndistribution.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 19:12:05 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Geva", "Mor", ""], ["Schuster", "Roei", ""], ["Berant", "Jonathan", ""], ["Levy", "Omer", ""]]}, {"id": "2012.14919", "submitter": "Mingda Chen", "authors": "Mingda Chen, Sam Wiseman, Kevin Gimpel", "title": "WikiTableT: A Large-Scale Data-to-Text Dataset for Generating Wikipedia\n  Article Sections", "comments": "Findings of ACL 2021, camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Datasets for data-to-text generation typically focus either on multi-domain,\nsingle-sentence generation or on single-domain, long-form generation. In this\nwork, we cast generating Wikipedia sections as a data-to-text generation task\nand create a large-scale dataset, WikiTableT, that pairs Wikipedia sections\nwith their corresponding tabular data and various metadata. WikiTableT contains\nmillions of instances, covering a broad range of topics, as well as a variety\nof flavors of generation tasks with different levels of flexibility. We\nbenchmark several training and decoding strategies on WikiTableT. Our\nqualitative analysis shows that the best approaches can generate fluent and\nhigh quality texts but they struggle with coherence and factuality, showing the\npotential for our dataset to inspire future work on long-form generation.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 19:35:34 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 00:42:42 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Chen", "Mingda", ""], ["Wiseman", "Sam", ""], ["Gimpel", "Kevin", ""]]}, {"id": "2012.14956", "submitter": "Rishabh Maheshwary", "authors": "Rishabh Maheshwary, Saket Maheshwary and Vikram Pudi", "title": "Generating Natural Language Attacks in a Hard Label Black Box Setting", "comments": "Accepted at AAAI 2021 (Main Conference)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an important and challenging task of attacking natural language\nprocessing models in a hard label black box setting. We propose a\ndecision-based attack strategy that crafts high quality adversarial examples on\ntext classification and entailment tasks. Our proposed attack strategy\nleverages population-based optimization algorithm to craft plausible and\nsemantically similar adversarial examples by observing only the top label\npredicted by the target model. At each iteration, the optimization procedure\nallow word replacements that maximizes the overall semantic similarity between\nthe original and the adversarial text. Further, our approach does not rely on\nusing substitute models or any kind of training data. We demonstrate the\nefficacy of our proposed approach through extensive experimentation and\nablation studies on five state-of-the-art target models across seven benchmark\ndatasets. In comparison to attacks proposed in prior literature, we are able to\nachieve a higher success rate with lower word perturbation percentage that too\nin a highly restricted setting.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 22:01:38 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 10:59:14 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Maheshwary", "Rishabh", ""], ["Maheshwary", "Saket", ""], ["Pudi", "Vikram", ""]]}, {"id": "2012.14978", "submitter": "Chunyuan Li", "authors": "Jiaxin Huang, Chunyuan Li, Krishan Subudhi, Damien Jose, Shobana\n  Balakrishnan, Weizhu Chen, Baolin Peng, Jianfeng Gao, Jiawei Han", "title": "Few-Shot Named Entity Recognition: A Comprehensive Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a comprehensive study to efficiently build named entity\nrecognition (NER) systems when a small number of in-domain labeled data is\navailable. Based upon recent Transformer-based self-supervised pre-trained\nlanguage models (PLMs), we investigate three orthogonal schemes to improve the\nmodel generalization ability for few-shot settings: (1) meta-learning to\nconstruct prototypes for different entity types, (2) supervised pre-training on\nnoisy web data to extract entity-related generic representations and (3)\nself-training to leverage unlabeled in-domain data. Different combinations of\nthese schemes are also considered. We perform extensive empirical comparisons\non 10 public NER datasets with various proportions of labeled data, suggesting\nuseful insights for future research. Our experiments show that (i) in the\nfew-shot learning setting, the proposed NER schemes significantly improve or\noutperform the commonly used baseline, a PLM-based linear classifier fine-tuned\non domain labels; (ii) We create new state-of-the-art results on both few-shot\nand training-free settings compared with existing methods. We will release our\ncode and pre-trained models for reproducible research.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 23:43:16 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Huang", "Jiaxin", ""], ["Li", "Chunyuan", ""], ["Subudhi", "Krishan", ""], ["Jose", "Damien", ""], ["Balakrishnan", "Shobana", ""], ["Chen", "Weizhu", ""], ["Peng", "Baolin", ""], ["Gao", "Jianfeng", ""], ["Han", "Jiawei", ""]]}, {"id": "2012.14983", "submitter": "Sabrina Mielke", "authors": "Sabrina J. Mielke, Arthur Szlam, Y-Lan Boureau, Emily Dinan", "title": "Linguistic calibration through metacognition: aligning dialogue agent\n  responses with expected correctness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-domain dialogue agents have vastly improved, but still confidently\nhallucinate knowledge or express doubt when asked straightforward questions. In\nthis work, we analyze whether state-of-the-art chit-chat models can express\nmetacognition capabilities through their responses: does a verbalized\nexpression of doubt (or confidence) match the likelihood that the model's\nanswer is incorrect (or correct)? We find that these models are poorly\ncalibrated in this sense, yet we show that the representations within the\nmodels can be used to accurately predict likelihood of correctness. By\nincorporating these correctness predictions into the training of a controllable\ngeneration model, we obtain a dialogue agent with greatly improved linguistic\ncalibration.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 00:12:36 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Mielke", "Sabrina J.", ""], ["Szlam", "Arthur", ""], ["Boureau", "Y-Lan", ""], ["Dinan", "Emily", ""]]}, {"id": "2012.15015", "submitter": "Jiwei Li", "authors": "Yuxian Meng, Shuhe Wang, Qinghong Han, Xiaofei Sun, Fei Wu, Rui Yan\n  and Jiwei Li", "title": "OpenViDial: A Large-Scale, Open-Domain Dialogue Dataset with Visual\n  Contexts", "comments": "Dataset, visual features and code are found at\n  https://github.com/ShannonAI/OpenViDial", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When humans converse, what a speaker will say next significantly depends on\nwhat he sees. Unfortunately, existing dialogue models generate dialogue\nutterances only based on preceding textual contexts, and visual contexts are\nrarely considered. This is due to a lack of a large-scale multi-module dialogue\ndataset with utterances paired with visual contexts. In this paper, we release\n{\\bf OpenViDial}, a large-scale multi-module dialogue dataset. The dialogue\nturns and visual contexts are extracted from movies and TV series, where each\ndialogue turn is paired with the corresponding visual context in which it takes\nplace. OpenViDial contains a total number of 1.1 million dialogue turns, and\nthus 1.1 million visual contexts stored in images. Based on this dataset, we\npropose a family of encoder-decoder models leveraging both textual and visual\ncontexts, from coarse-grained image features extracted from CNNs to\nfine-grained object features extracted from Faster R-CNNs. We observe that\nvisual information significantly improves dialogue generation qualities,\nverifying the necessity of integrating multi-modal features for dialogue\nlearning. Our work marks an important step towards large-scale multi-modal\ndialogue learning.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 03:02:50 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 13:15:07 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Meng", "Yuxian", ""], ["Wang", "Shuhe", ""], ["Han", "Qinghong", ""], ["Sun", "Xiaofei", ""], ["Wu", "Fei", ""], ["Yan", "Rui", ""], ["Li", "Jiwei", ""]]}, {"id": "2012.15022", "submitter": "Yujia Qin", "authors": "Yujia Qin, Yankai Lin, Ryuichi Takanobu, Zhiyuan Liu, Peng Li, Heng\n  Ji, Minlie Huang, Maosong Sun, Jie Zhou", "title": "ERICA: Improving Entity and Relation Understanding for Pre-trained\n  Language Models via Contrastive Learning", "comments": "Accepted by ACL-IJCNLP 2021 main conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained Language Models (PLMs) have shown superior performance on various\ndownstream Natural Language Processing (NLP) tasks. However, conventional\npre-training objectives do not explicitly model relational facts in text, which\nare crucial for textual understanding. To address this issue, we propose a\nnovel contrastive learning framework ERICA to obtain a deep understanding of\nthe entities and their relations in text. Specifically, we define two novel\npre-training tasks to better understand entities and relations: (1) the entity\ndiscrimination task to distinguish which tail entity can be inferred by the\ngiven head entity and relation; (2) the relation discrimination task to\ndistinguish whether two relations are close or not semantically, which involves\ncomplex relational reasoning. Experimental results demonstrate that ERICA can\nimprove typical PLMs (BERT and RoBERTa) on several language understanding\ntasks, including relation extraction, entity typing and question answering,\nespecially under low-resource settings.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 03:35:22 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 05:08:18 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Qin", "Yujia", ""], ["Lin", "Yankai", ""], ["Takanobu", "Ryuichi", ""], ["Liu", "Zhiyuan", ""], ["Li", "Peng", ""], ["Ji", "Heng", ""], ["Huang", "Minlie", ""], ["Sun", "Maosong", ""], ["Zhou", "Jie", ""]]}, {"id": "2012.15023", "submitter": "Aditya Pathak Kumar", "authors": "Priyankit Acharya, Aditya Ku. Pathak, Rakesh Ch. Balabantaray, and\n  Anil Ku. Singh", "title": "Language Identification of Devanagari Poems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Language Identification is a very important part of several text processing\npipelines. Extensive research has been done in this field. This paper proposes\na procedure for automatic language identification of poems for poem analysis\ntask, consisting of 10 Devanagari based languages of India i.e. Angika, Awadhi,\nBraj, Bhojpuri, Chhattisgarhi, Garhwali, Haryanvi, Hindi, Magahi, and Maithili.\nWe collated corpora of poems of varying length and studied the similarity of\npoems among the 10 languages at the lexical level. Finally, various language\nidentification systems based on supervised machine learning and deep learning\ntechniques are applied and evaluated.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 03:36:18 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Acharya", "Priyankit", ""], ["Pathak", "Aditya Ku.", ""], ["Balabantaray", "Rakesh Ch.", ""], ["Singh", "Anil Ku.", ""]]}, {"id": "2012.15045", "submitter": "Sheng Shen", "authors": "Sheng Shen, Alexei Baevski, Ari S. Morcos, Kurt Keutzer, Michael Auli,\n  Douwe Kiela", "title": "Reservoir Transformers", "comments": "ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that transformers obtain impressive performance even when some\nof the layers are randomly initialized and never updated. Inspired by old and\nwell-established ideas in machine learning, we explore a variety of non-linear\n\"reservoir\" layers interspersed with regular transformer layers, and show\nimprovements in wall-clock compute time until convergence, as well as overall\nperformance, on various machine translation and (masked) language modelling\ntasks.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 05:20:16 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 19:32:18 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Shen", "Sheng", ""], ["Baevski", "Alexei", ""], ["Morcos", "Ari S.", ""], ["Keutzer", "Kurt", ""], ["Auli", "Michael", ""], ["Kiela", "Douwe", ""]]}, {"id": "2012.15070", "submitter": "Rongzhou Bao", "authors": "Rongzhou Bao, Jiayi Wang, Zhuosheng Zhang, Hai Zhao", "title": "Enhancing Pre-trained Language Model with Lexical Simplification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For both human readers and pre-trained language models (PrLMs), lexical\ndiversity may lead to confusion and inaccuracy when understanding the\nunderlying semantic meanings of given sentences. By substituting complex words\nwith simple alternatives, lexical simplification (LS) is a recognized method to\nreduce such lexical diversity, and therefore to improve the understandability\nof sentences. In this paper, we leverage LS and propose a novel approach which\ncan effectively improve the performance of PrLMs in text classification. A\nrule-based simplification process is applied to a given sentence. PrLMs are\nencouraged to predict the real label of the given sentence with auxiliary\ninputs from the simplified version. Using strong PrLMs (BERT and ELECTRA) as\nbaselines, our approach can still further improve the performance in various\ntext classification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 07:49:00 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Bao", "Rongzhou", ""], ["Wang", "Jiayi", ""], ["Zhang", "Zhuosheng", ""], ["Zhao", "Hai", ""]]}, {"id": "2012.15075", "submitter": "Ana Valeria Gonzalez", "authors": "Ana Valeria Gonzalez, Gagan Bansal, Angela Fan, Robin Jia, Yashar\n  Mehdad and Srinivasan Iyer", "title": "Human Evaluation of Spoken vs. Visual Explanations for Open-Domain QA", "comments": "pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  While research on explaining predictions of open-domain QA systems (ODQA) to\nusers is gaining momentum, most works have failed to evaluate the extent to\nwhich explanations improve user trust. While few works evaluate explanations\nusing user studies, they employ settings that may deviate from the end-user's\nusage in-the-wild: ODQA is most ubiquitous in voice-assistants, yet current\nresearch only evaluates explanations using a visual display, and may\nerroneously extrapolate conclusions about the most performant explanations to\nother modalities. To alleviate these issues, we conduct user studies that\nmeasure whether explanations help users correctly decide when to accept or\nreject an ODQA system's answer. Unlike prior work, we control for explanation\nmodality, e.g., whether they are communicated to users through a spoken or\nvisual interface, and contrast effectiveness across modalities. Our results\nshow that explanations derived from retrieved evidence passages can outperform\nstrong baselines (calibrated confidence) across modalities but the best\nexplanation strategy in fact changes with the modality. We show common failure\ncases of current explanations, emphasize end-to-end evaluation of explanations,\nand caution against evaluating them in proxy modalities that are different from\ndeployment.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 08:19:02 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Gonzalez", "Ana Valeria", ""], ["Bansal", "Gagan", ""], ["Fan", "Angela", ""], ["Jia", "Robin", ""], ["Mehdad", "Yashar", ""], ["Iyer", "Srinivasan", ""]]}, {"id": "2012.15079", "submitter": "Wazir Ali", "authors": "Wazir Ali, Jay Kumar, Zenglin Xu, Congjian Luo, Junyu Lu, Junming\n  Shao, Rajesh Kumar, and Yazhou Ren", "title": "A Subword Guided Neural Word Segmentation Model for Sindhi", "comments": "Journal Paper, 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks employ multiple processing layers for learning text\nrepresentations to alleviate the burden of manual feature engineering in\nNatural Language Processing (NLP). Such text representations are widely used to\nextract features from unlabeled data. The word segmentation is a fundamental\nand inevitable prerequisite for many languages. Sindhi is an under-resourced\nlanguage, whose segmentation is challenging as it exhibits space omission,\nspace insertion issues, and lacks the labeled corpus for segmentation. In this\npaper, we investigate supervised Sindhi Word Segmentation (SWS) using unlabeled\ndata with a Subword Guided Neural Word Segmenter (SGNWS) for Sindhi. In order\nto learn text representations, we incorporate subword representations to\nrecurrent neural architecture to capture word information at morphemic-level,\nwhich takes advantage of Bidirectional Long-Short Term Memory (BiLSTM),\nself-attention mechanism, and Conditional Random Field (CRF). Our proposed\nSGNWS model achieves an F1 value of 98.51% without relying on feature\nengineering. The empirical results demonstrate the benefits of the proposed\nmodel over the existing Sindhi word segmenters.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 08:31:31 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Ali", "Wazir", ""], ["Kumar", "Jay", ""], ["Xu", "Zenglin", ""], ["Luo", "Congjian", ""], ["Lu", "Junyu", ""], ["Shao", "Junming", ""], ["Kumar", "Rajesh", ""], ["Ren", "Yazhou", ""]]}, {"id": "2012.15086", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang, Haojie Yu, Hai Zhao, Rui Wang, Masao Utiyama", "title": "Accurate Word Representations with Universal Visual Guidance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word representation is a fundamental component in neural language\nunderstanding models. Recently, pre-trained language models (PrLMs) offer a new\nperformant method of contextualized word representations by leveraging the\nsequence-level context for modeling. Although the PrLMs generally give more\naccurate contextualized word representations than non-contextualized models do,\nthey are still subject to a sequence of text contexts without diverse hints for\nword representation from multimodality. This paper thus proposes a visual\nrepresentation method to explicitly enhance conventional word embedding with\nmultiple-aspect senses from visual guidance. In detail, we build a small-scale\nword-image dictionary from a multimodal seed dataset where each word\ncorresponds to diverse related images. The texts and paired images are encoded\nin parallel, followed by an attention layer to integrate the multimodal\nrepresentations. We show that the method substantially improves the accuracy of\ndisambiguation. Experiments on 12 natural language understanding and machine\ntranslation tasks further verify the effectiveness and the generalization\ncapability of the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 09:11:50 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["Yu", "Haojie", ""], ["Zhao", "Hai", ""], ["Wang", "Rui", ""], ["Utiyama", "Masao", ""]]}, {"id": "2012.15115", "submitter": "Michael Sejr Schlichtkrull", "authors": "Michael Schlichtkrull, Vladimir Karpukhin, Barlas O\\u{g}uz, Mike\n  Lewis, Wen-tau Yih, Sebastian Riedel", "title": "Joint Verification and Reranking for Open Fact Checking Over Tables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured information is an important knowledge source for automatic\nverification of factual claims. Nevertheless, the majority of existing research\ninto this task has focused on textual data, and the few recent inquiries into\nstructured data have been for the closed-domain setting where appropriate\nevidence for each claim is assumed to have already been retrieved. In this\npaper, we investigate verification over structured data in the open-domain\nsetting, introducing a joint reranking-and-verification model which fuses\nevidence documents in the verification component. Our open-domain model\nachieves performance comparable to the closed-domain state-of-the-art on the\nTabFact dataset, and demonstrates performance gains from the inclusion of\nmultiple tables as well as a significant improvement over a heuristic retrieval\nbaseline.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 11:22:31 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Schlichtkrull", "Michael", ""], ["Karpukhin", "Vladimir", ""], ["O\u011fuz", "Barlas", ""], ["Lewis", "Mike", ""], ["Yih", "Wen-tau", ""], ["Riedel", "Sebastian", ""]]}, {"id": "2012.15127", "submitter": "Danni Liu", "authors": "Danni Liu, Jan Niehues, James Cross, Francisco Guzm\\'an, Xian Li", "title": "Improving Zero-Shot Translation by Disentangling Positional Information", "comments": "ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual neural machine translation has shown the capability of directly\ntranslating between language pairs unseen in training, i.e. zero-shot\ntranslation. Despite being conceptually attractive, it often suffers from low\noutput quality. The difficulty of generalizing to new translation directions\nsuggests the model representations are highly specific to those language pairs\nseen in training. We demonstrate that a main factor causing the\nlanguage-specific representations is the positional correspondence to input\ntokens. We show that this can be easily alleviated by removing residual\nconnections in an encoder layer. With this modification, we gain up to 18.5\nBLEU points on zero-shot translation while retaining quality on supervised\ndirections. The improvements are particularly prominent between related\nlanguages, where our proposed model outperforms pivot-based translation.\nMoreover, our approach allows easy integration of new languages, which\nsubstantially expands translation coverage. By thorough inspections of the\nhidden layer outputs, we show that our approach indeed leads to more\nlanguage-independent representations.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 12:20:41 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 18:00:50 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Liu", "Danni", ""], ["Niehues", "Jan", ""], ["Cross", "James", ""], ["Guzm\u00e1n", "Francisco", ""], ["Li", "Xian", ""]]}, {"id": "2012.15150", "submitter": "Qingyu Zhou", "authors": "Zhongli Li, Qingyu Zhou, Chao Li, Ke Xu, Yunbo Cao", "title": "Improving BERT with Syntax-aware Local Attention", "comments": "In ACL Findings 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pre-trained Transformer-based neural language models, such as BERT, have\nachieved remarkable results on varieties of NLP tasks. Recent works have shown\nthat attention-based models can benefit from more focused attention over local\nregions. Most of them restrict the attention scope within a linear span, or\nconfine to certain tasks such as machine translation and question answering. In\nthis paper, we propose a syntax-aware local attention, where the attention\nscopes are restrained based on the distances in the syntactic structure. The\nproposed syntax-aware local attention can be integrated with pretrained\nlanguage models, such as BERT, to render the model to focus on syntactically\nrelevant words. We conduct experiments on various single-sentence benchmarks,\nincluding sentence classification and sequence labeling tasks. Experimental\nresults show consistent gains over BERT on all benchmark datasets. The\nextensive studies verify that our model achieves better performance owing to\nmore focused attention over syntactically relevant words.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 13:29:58 GMT"}, {"version": "v2", "created": "Mon, 24 May 2021 12:59:51 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Li", "Zhongli", ""], ["Zhou", "Qingyu", ""], ["Li", "Chao", ""], ["Xu", "Ke", ""], ["Cao", "Yunbo", ""]]}, {"id": "2012.15156", "submitter": "Gautier Izacard", "authors": "Gautier Izacard, Fabio Petroni, Lucas Hosseini, Nicola De Cao,\n  Sebastian Riedel, Edouard Grave", "title": "A Memory Efficient Baseline for Open Domain Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, retrieval systems based on dense representations have led to\nimportant improvements in open-domain question answering, and related tasks.\nWhile very effective, this approach is also memory intensive, as the dense\nvectors for the whole knowledge source need to be kept in memory. In this\npaper, we study how the memory footprint of dense retriever-reader systems can\nbe reduced. We consider three strategies to reduce the index size: dimension\nreduction, vector quantization and passage filtering. We evaluate our approach\non two question answering benchmarks: TriviaQA and NaturalQuestions, showing\nthat it is possible to get competitive systems using less than 6Gb of memory.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 13:46:06 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Izacard", "Gautier", ""], ["Petroni", "Fabio", ""], ["Hosseini", "Lucas", ""], ["De Cao", "Nicola", ""], ["Riedel", "Sebastian", ""], ["Grave", "Edouard", ""]]}, {"id": "2012.15178", "submitter": "Asrul Sani Ariesandy", "authors": "Asrul Sani Ariesandy, Mukhlis Amien, Alham Fikri Aji, Radityo Eko\n  Prasojo", "title": "Synthetic Source Language Augmentation for Colloquial Neural Machine\n  Translation", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) is typically domain-dependent and\nstyle-dependent, and it requires lots of training data. State-of-the-art NMT\nmodels often fall short in handling colloquial variations of its source\nlanguage and the lack of parallel data in this regard is a challenging hurdle\nin systematically improving the existing models. In this work, we develop a\nnovel colloquial Indonesian-English test-set collected from YouTube transcript\nand Twitter. We perform synthetic style augmentation to the source of formal\nIndonesian language and show that it improves the baseline Id-En models (in\nBLEU) over the new test data.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 14:52:15 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Ariesandy", "Asrul Sani", ""], ["Amien", "Mukhlis", ""], ["Aji", "Alham Fikri", ""], ["Prasojo", "Radityo Eko", ""]]}, {"id": "2012.15180", "submitter": "Thang M. Pham", "authors": "Thang M. Pham, Trung Bui, Long Mai, Anh Nguyen", "title": "Out of Order: How Important Is The Sequential Order of Words in a\n  Sentence in Natural Language Understanding Tasks?", "comments": "9+7 pages, 4+4 figures. Findings of ACL 2021 (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Do state-of-the-art natural language understanding models care about word\norder - one of the most important characteristics of a sequence? Not always! We\nfound 75% to 90% of the correct predictions of BERT-based classifiers, trained\non many GLUE tasks, remain constant after input words are randomly shuffled.\nDespite BERT embeddings are famously contextual, the contribution of each\nindividual word to downstream tasks is almost unchanged even after the word's\ncontext is shuffled. BERT-based models are able to exploit superficial cues\n(e.g. the sentiment of keywords in sentiment analysis; or the word-wise\nsimilarity between sequence-pair inputs in natural language inference) to make\ncorrect decisions when tokens are arranged in random orders. Encouraging\nclassifiers to capture word order information improves the performance on most\nGLUE tasks, SQuAD 2.0 and out-of-samples. Our work suggests that many GLUE\ntasks are not challenging machines to understand the meaning of a sentence.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 14:56:12 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 17:55:13 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Pham", "Thang M.", ""], ["Bui", "Trung", ""], ["Mai", "Long", ""], ["Nguyen", "Anh", ""]]}, {"id": "2012.15197", "submitter": "Leilei Gan", "authors": "Leilei Gan, Zhiyang Teng, Yue Zhang, Linchao Zhu, Fei Wu, Yi Yang", "title": "SemGloVe: Semantic Co-occurrences for GloVe from BERT", "comments": "10 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GloVe learns word embeddings by leveraging statistical information from word\nco-occurrence matrices. However, word pairs in the matrices are extracted from\na predefined local context window, which might lead to limited word pairs and\npotentially semantic irrelevant word pairs. In this paper, we propose SemGloVe,\nwhich distills semantic co-occurrences from BERT into static GloVe word\nembeddings. Particularly, we propose two models to extract co-occurrence\nstatistics based on either the masked language model or the multi-head\nattention weights of BERT. Our methods can extract word pairs without limiting\nby the local window assumption and can define the co-occurrence weights by\ndirectly considering the semantic distance between word pairs. Experiments on\nseveral word similarity datasets and four external tasks show that SemGloVe can\noutperform GloVe.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 15:38:26 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Gan", "Leilei", ""], ["Teng", "Zhiyang", ""], ["Zhang", "Yue", ""], ["Zhu", "Linchao", ""], ["Wu", "Fei", ""], ["Yang", "Yi", ""]]}, {"id": "2012.15228", "submitter": "Tomasz Limisiewicz", "authors": "Tomasz Limisiewicz and David Mare\\v{c}ek", "title": "Introducing Orthogonal Constraint in Structural Probes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  With the recent success of pre-trained models in NLP, a significant focus was\nput on interpreting their representations. One of the most prominent approaches\nis structural probing (Hewitt and Manning, 2019), where a linear projection of\nword embeddings is performed in order to approximate the topology of dependency\nstructures. In this work, we introduce a new type of structural probing, where\nthe linear projection is decomposed into 1. isomorphic space rotation; 2.\nlinear scaling that identifies and scales the most relevant dimensions. In\naddition to syntactic dependency, we evaluate our method on novel tasks\n(lexical hypernymy and position in a sentence). We jointly train the probes for\nmultiple tasks and experimentally show that lexical and syntactic information\nis separated in the representations. Moreover, the orthogonal constraint makes\nthe Structural Probes less vulnerable to memorization.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 17:14:25 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 18:51:16 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Limisiewicz", "Tomasz", ""], ["Mare\u010dek", "David", ""]]}, {"id": "2012.15229", "submitter": "Nada Aldarrab", "authors": "Nada Aldarrab and Jonathan May", "title": "Can Sequence-to-Sequence Models Crack Substitution Ciphers?", "comments": "ACL 2021 main conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decipherment of historical ciphers is a challenging problem. The language of\nthe target plaintext might be unknown, and ciphertext can have a lot of noise.\nState-of-the-art decipherment methods use beam search and a neural language\nmodel to score candidate plaintext hypotheses for a given cipher, assuming the\nplaintext language is known. We propose an end-to-end multilingual model for\nsolving simple substitution ciphers. We test our model on synthetic and real\nhistorical ciphers and show that our proposed method can decipher text without\nexplicit language identification while still being robust to noise.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 17:16:33 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 18:38:07 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Aldarrab", "Nada", ""], ["May", "Jonathan", ""]]}, {"id": "2012.15243", "submitter": "Hongming Zhang", "authors": "Hongming Zhang, Haoyu Wang, Dan Roth", "title": "Unsupervised Label-aware Event Trigger and Argument Classification", "comments": "ACL 2021 Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Identifying events and mapping them to pre-defined event types has long been\nan important natural language processing problem. Most previous work has been\nheavily relying on labor-intensive and domain-specific annotations while\nignoring the semantic meaning contained in the labels of the event types. As a\nresult, the learned models cannot effectively generalize to new domains, where\nnew event types could be introduced. In this paper, we propose an unsupervised\nevent extraction pipeline, which first identifies events with available tools\n(e.g., SRL) and then automatically maps them to pre-defined event types with\nour proposed unsupervised classification model. Rather than relying on\nannotated data, our model matches the semantics of identified events with those\nof event type labels. Specifically, we leverage pre-trained language models to\ncontextually represent pre-defined types for both event triggers and arguments.\nAfter we map identified events to the target types via representation\nsimilarity, we use the event ontology (e.g., argument type \"Victim\" can only\nappear as the argument of event type \"Attack\") as global constraints to\nregularize the prediction. The proposed approach is shown to be very effective\nwhen tested on the ACE-2005 dataset, which has 33 trigger and 22 argument\ntypes. Without using any annotation, we successfully map 83% of the triggers\nand 54% of the arguments to the correct types, almost doubling the performance\nof previous zero-shot approaches.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 17:47:24 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 04:18:40 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Zhang", "Hongming", ""], ["Wang", "Haoyu", ""], ["Roth", "Dan", ""]]}, {"id": "2012.15262", "submitter": "Ryuichi Takanobu", "authors": "Jiexi Liu, Ryuichi Takanobu, Jiaxin Wen, Dazhen Wan, Hongguang Li,\n  Weiran Nie, Cheng Li, Wei Peng, Minlie Huang", "title": "Robustness Testing of Language Understanding in Task-Oriented Dialog", "comments": "ACL 2021 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most language understanding models in task-oriented dialog systems are\ntrained on a small amount of annotated training data, and evaluated in a small\nset from the same distribution. However, these models can lead to system\nfailure or undesirable output when being exposed to natural language\nperturbation or variation in practice. In this paper, we conduct comprehensive\nevaluation and analysis with respect to the robustness of natural language\nunderstanding models, and introduce three important aspects related to language\nunderstanding in real-world dialog systems, namely, language variety, speech\ncharacteristics, and noise perturbation. We propose a model-agnostic toolkit\nLAUG to approximate natural language perturbations for testing the robustness\nissues in task-oriented dialog. Four data augmentation approaches covering the\nthree aspects are assembled in LAUG, which reveals critical robustness issues\nin state-of-the-art models. The augmented dataset through LAUG can be used to\nfacilitate future research on the robustness testing of language understanding\nin task-oriented dialog.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 18:18:47 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 17:30:54 GMT"}, {"version": "v3", "created": "Fri, 4 Jun 2021 17:21:23 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Liu", "Jiexi", ""], ["Takanobu", "Ryuichi", ""], ["Wen", "Jiaxin", ""], ["Wan", "Dazhen", ""], ["Li", "Hongguang", ""], ["Nie", "Weiran", ""], ["Li", "Cheng", ""], ["Peng", "Wei", ""], ["Huang", "Minlie", ""]]}, {"id": "2012.15263", "submitter": "William Dyer", "authors": "William Dyer, Richard Futrell, Zoey Liu, and Gregory Scontras", "title": "Predicting cross-linguistic adjective order with information gain", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Languages vary in their placement of multiple adjectives before, after, or\nsurrounding the noun, but they typically exhibit strong intra-language\ntendencies on the relative order of those adjectives (e.g., the preference for\n`big blue box' in English, `grande bo\\^{i}te bleue' in French, and\n`alsund\\={u}q al'azraq alkab\\={\\i}r' in Arabic). We advance a new quantitative\naccount of adjective order across typologically-distinct languages based on\nmaximizing information gain. Our model addresses the left-right asymmetry of\nFrench-type ANA sequences with the same approach as AAN and NAA orderings,\nwithout appeal to other mechanisms. We find that, across 32 languages, the\npreferred order of adjectives largely mirrors an efficient algorithm of\nmaximizing information gain.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 18:21:55 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Dyer", "William", ""], ["Futrell", "Richard", ""], ["Liu", "Zoey", ""], ["Scontras", "Gregory", ""]]}, {"id": "2012.15283", "submitter": "Rujun Han", "authors": "Rujun Han, Xiang Ren, Nanyun Peng", "title": "DEER: A Data Efficient Language Model for Event Temporal Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pretrained language models (LMs) such as BERT, RoBERTa, and ELECTRA are\neffective at improving the performances of a variety of downstream NLP tasks.\nRecently, researchers have incorporated domain and task-specific knowledge in\nthese LMs' training objectives and further enhanced models' capability of\nhandling downstream tasks. However, none of these LMs are designed specifically\nfor event temporal reasoning. We propose DEER, a language model that is trained\nto focus on event temporal relations and performs better under low-resource\nsettings than original LMs. More specifically, we create a large number of\ntraining samples to simulate the machine reading comprehension and information\nextraction tasks for event temporal understanding and leverage a\ngenerator-discriminator structure to reinforce the LMs' capability of event\ntemporal reasoning. Our experimental results show that DEER can achieve SOTA\nresults and works particularly well in low-resource settings across 5 widely\nused datasets.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 18:57:16 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Han", "Rujun", ""], ["Ren", "Xiang", ""], ["Peng", "Nanyun", ""]]}, {"id": "2012.15329", "submitter": "Raphael Schumann", "authors": "Raphael Schumann and Stefan Riezler", "title": "Generating Landmark Navigation Instructions from Maps as a Graph-to-Text\n  Problem", "comments": "Accepted at ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Car-focused navigation services are based on turns and distances of named\nstreets, whereas navigation instructions naturally used by humans are centered\naround physical objects called landmarks. We present a neural model that takes\nOpenStreetMap representations as input and learns to generate navigation\ninstructions that contain visible and salient landmarks from human natural\nlanguage instructions. Routes on the map are encoded in a location- and\nrotation-invariant graph representation that is decoded into natural language\ninstructions. Our work is based on a novel dataset of 7,672 crowd-sourced\ninstances that have been verified by human navigation in Street View. Our\nevaluation shows that the navigation instructions generated by our system have\nsimilar properties as human-generated instructions, and lead to successful\nhuman navigation in Street View.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 21:22:04 GMT"}, {"version": "v2", "created": "Fri, 7 May 2021 16:13:40 GMT"}, {"version": "v3", "created": "Wed, 26 May 2021 16:07:16 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Schumann", "Raphael", ""], ["Riezler", "Stefan", ""]]}, {"id": "2012.15332", "submitter": "Ozan \\.Irsoy", "authors": "Ozan \\.Irsoy, Adrian Benton, Karl Stratos", "title": "k\\=oan: A Corrected CBOW Implementation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  It is a common belief in the NLP community that continuous bag-of-words\n(CBOW) word embeddings tend to underperform skip-gram (SG) embeddings. We find\nthat this belief is founded less on theoretical differences in their training\nobjectives but more on faulty CBOW implementations in standard software\nlibraries such as the official implementation word2vec.c and Gensim. We show\nthat our correct implementation of CBOW yields word embeddings that are fully\ncompetitive with SG on various intrinsic and extrinsic tasks while being more\nthan three times as fast to train. We release our implementation, k\\=oan, at\nhttps://github.com/bloomberg/koan.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 21:37:28 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["\u0130rsoy", "Ozan", ""], ["Benton", "Adrian", ""], ["Stratos", "Karl", ""]]}, {"id": "2012.15349", "submitter": "Christopher Potts", "authors": "Christopher Potts, Zhengxuan Wu, Atticus Geiger, Douwe Kiela", "title": "DynaSent: A Dynamic Benchmark for Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce DynaSent ('Dynamic Sentiment'), a new English-language benchmark\ntask for ternary (positive/negative/neutral) sentiment analysis. DynaSent\ncombines naturally occurring sentences with sentences created using the\nopen-source Dynabench Platform, which facilities human-and-model-in-the-loop\ndataset creation. DynaSent has a total of 121,634 sentences, each validated by\nfive crowdworkers, and its development and test splits are designed to produce\nchance performance for even the best models we have been able to develop; when\nfuture models solve this task, we will use them to create DynaSent version 2,\ncontinuing the dynamic evolution of this benchmark. Here, we report on the\ndataset creation effort, focusing on the steps we took to increase quality and\nreduce artifacts. We also present evidence that DynaSent's Neutral category is\nmore coherent than the comparable category in other benchmarks, and we motivate\ntraining models from scratch for each round over successive fine-tuning.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 22:38:21 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Potts", "Christopher", ""], ["Wu", "Zhengxuan", ""], ["Geiger", "Atticus", ""], ["Kiela", "Douwe", ""]]}, {"id": "2012.15353", "submitter": "Jacob Turton", "authors": "Jacob Turton, David Vinson, Robert Elliott Smith", "title": "Deriving Contextualised Semantic Features from BERT (and Other\n  Transformer Model) Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Models based on the transformer architecture, such as BERT, have marked a\ncrucial step forward in the field of Natural Language Processing. Importantly,\nthey allow the creation of word embeddings that capture important semantic\ninformation about words in context. However, as single entities, these\nembeddings are difficult to interpret and the models used to create them have\nbeen described as opaque. Binder and colleagues proposed an intuitive embedding\nspace where each dimension is based on one of 65 core semantic features.\nUnfortunately, the space only exists for a small dataset of 535 words, limiting\nits uses. Previous work (Utsumi, 2018, 2020, Turton, Vinson & Smith, 2020) has\nshown that Binder features can be derived from static embeddings and\nsuccessfully extrapolated to a large new vocabulary. Taking the next step, this\npaper demonstrates that Binder features can be derived from the BERT embedding\nspace. This provides contextualised Binder embeddings, which can aid in\nunderstanding semantic differences between words in context. It additionally\nprovides insights into how semantic features are represented across the\ndifferent layers of the BERT model.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 22:52:29 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Turton", "Jacob", ""], ["Vinson", "David", ""], ["Smith", "Robert Elliott", ""]]}, {"id": "2012.15355", "submitter": "Peng Xu", "authors": "Peng Xu, Dhruv Kumar, Wei Yang, Wenjie Zi, Keyi Tang, Chenyang Huang,\n  Jackie Chi Kit Cheung, Simon J.D. Prince, Yanshuai Cao", "title": "Optimizing Deeper Transformers on Small Datasets", "comments": "Accepted at ACL 2021 main conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  It is a common belief that training deep transformers from scratch requires\nlarge datasets. Consequently, for small datasets, people usually use shallow\nand simple additional layers on top of pre-trained models during fine-tuning.\nThis work shows that this does not always need to be the case: with proper\ninitialization and optimization, the benefits of very deep transformers can\ncarry over to challenging tasks with small datasets, including Text-to-SQL\nsemantic parsing and logical reading comprehension. In particular, we\nsuccessfully train $48$ layers of transformers, comprising $24$ fine-tuned\nlayers from pre-trained RoBERTa and $24$ relation-aware layers trained from\nscratch. With fewer training steps and no task-specific pre-training, we obtain\nthe state-of-the-art performance on the challenging cross-domain Text-to-SQL\nparsing benchmark Spider. We achieve this by deriving a novel Data-dependent\nTransformer Fixed-update initialization scheme (DT-Fixup), inspired by the\nprior T-Fixup work. Further error analysis shows that increasing depth can help\nimprove generalization on small datasets for hard cases that require reasoning\nand structural understanding.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 22:53:49 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 17:12:23 GMT"}, {"version": "v3", "created": "Thu, 27 May 2021 16:53:14 GMT"}, {"version": "v4", "created": "Mon, 31 May 2021 16:45:47 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Xu", "Peng", ""], ["Kumar", "Dhruv", ""], ["Yang", "Wei", ""], ["Zi", "Wenjie", ""], ["Tang", "Keyi", ""], ["Huang", "Chenyang", ""], ["Cheung", "Jackie Chi Kit", ""], ["Prince", "Simon J. D.", ""], ["Cao", "Yanshuai", ""]]}, {"id": "2012.15375", "submitter": "Weiyan Shi", "authors": "Weiyan Shi, Yu Li, Saurav Sahay, Zhou Yu", "title": "Refine and Imitate: Reducing Repetition and Inconsistency in Persuasion\n  Dialogues via Reinforcement Learning and Human Demonstration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent success of large-scale language models on various\ndownstream NLP tasks, the repetition and inconsistency problems still persist\nin dialogue response generation. Previous approaches have attempted to avoid\nrepetition by penalizing the language model's undesirable behaviors in the loss\nfunction. However, these methods focus on token-level information and can lead\nto incoherent responses and uninterpretable behaviors. To alleviate these\nissues, we propose to apply reinforcement learning to refine an MLE-based\nlanguage model without user simulators, and distill sentence-level information\nabout repetition, inconsistency and task relevance through rewards. In\naddition, to better accomplish the dialogue task, the model learns from human\ndemonstration to imitate intellectual activities such as persuasion, and\nselects the most persuasive responses. Experiments show that our model\noutperforms previous state-of-the-art dialogue models on both automatic metrics\nand human evaluation results on a donation persuasion task, and generates more\ndiverse, consistent and persuasive conversations according to the user\nfeedback.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 00:02:51 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Shi", "Weiyan", ""], ["Li", "Yu", ""], ["Sahay", "Saurav", ""], ["Yu", "Zhou", ""]]}, {"id": "2012.15404", "submitter": "Yang Zhang", "authors": "Yang Zhang, Liqun Deng, Yasheng Wang", "title": "Unified Mandarin TTS Front-end Based on Distilled BERT Model", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The front-end module in a typical Mandarin text-to-speech system (TTS) is\ncomposed of a long pipeline of text processing components, which requires\nextensive efforts to build and is prone to large accumulative model size and\ncascade errors. In this paper, a pre-trained language model (PLM) based model\nis proposed to simultaneously tackle the two most important tasks in TTS\nfront-end, i.e., prosodic structure prediction (PSP) and grapheme-to-phoneme\n(G2P) conversion. We use a pre-trained Chinese BERT[1] as the text encoder and\nemploy multi-task learning technique to adapt it to the two TTS front-end\ntasks. Then, the BERT encoder is distilled into a smaller model by employing a\nknowledge distillation technique called TinyBERT[2], making the whole model\nsize 25% of that of benchmark pipeline models while maintaining competitive\nperformance on both tasks. With the proposed the methods, we are able to run\nthe whole TTS front-end module in a light and unified manner, which is more\nfriendly to deployment on mobile devices.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 02:34:57 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Zhang", "Yang", ""], ["Deng", "Liqun", ""], ["Wang", "Yasheng", ""]]}, {"id": "2012.15409", "submitter": "Wei Li", "authors": "Wei Li, Can Gao, Guocheng Niu, Xinyan Xiao, Hao Liu, Jiachen Liu, Hua\n  Wu, Haifeng Wang", "title": "UNIMO: Towards Unified-Modal Understanding and Generation via\n  Cross-Modal Contrastive Learning", "comments": "The paper has been accepted by the main conference of ACL2021 as a\n  long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existed pre-training methods either focus on single-modal tasks or\nmulti-modal tasks, and cannot effectively adapt to each other. They can only\nutilize single-modal data (i.e. text or image) or limited multi-modal data\n(i.e. image-text pairs). In this work, we propose a unified-modal pre-training\narchitecture, namely UNIMO, which can effectively adapt to both single-modal\nand multi-modal understanding and generation tasks. Large scale of free text\ncorpus and image collections can be utilized to improve the capability of\nvisual and textual understanding, and cross-modal contrastive learning (CMCL)\nis leveraged to align the textual and visual information into a unified\nsemantic space over a corpus of image-text pairs. As the non-paired\nsingle-modal data is very rich, our model can utilize much larger scale of data\nto learn more generalizable representations. Moreover, the textual knowledge\nand visual knowledge can enhance each other in the unified semantic space. The\nexperimental results show that UNIMO significantly improves the performance of\nseveral single-modal and multi-modal downstream tasks. Our code and pre-trained\nmodels are public at\nhttps://github.com/PaddlePaddle/Research/tree/master/NLP/UNIMO\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 02:46:47 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 13:18:54 GMT"}, {"version": "v3", "created": "Thu, 20 May 2021 13:18:38 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Li", "Wei", ""], ["Gao", "Can", ""], ["Niu", "Guocheng", ""], ["Xiao", "Xinyan", ""], ["Liu", "Hao", ""], ["Liu", "Jiachen", ""], ["Wu", "Hua", ""], ["Wang", "Haifeng", ""]]}, {"id": "2012.15416", "submitter": "Damian Pascual", "authors": "Damian Pascual, Beni Egressy, Florian Bolli, Roger Wattenhofer", "title": "Directed Beam Search: Plug-and-Play Lexically Constrained Language\n  Generation", "comments": "Preprint. Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large pre-trained language models are capable of generating realistic text.\nHowever, controlling these models so that the generated text satisfies lexical\nconstraints, i.e., contains specific words, is a challenging problem. Given\nthat state-of-the-art language models are too large to be trained from scratch\nin a manageable time, it is desirable to control these models without\nre-training them. Methods capable of doing this are called plug-and-play.\nRecent plug-and-play methods have been successful in constraining small\nbidirectional language models as well as forward models in tasks with a\nrestricted search space, e.g., machine translation. However, controlling large\ntransformer-based models to meet lexical constraints without re-training them\nremains a challenge. In this work, we propose Directed Beam Search (DBS), a\nplug-and-play method for lexically constrained language generation. Our method\ncan be applied to any language model, is easy to implement and can be used for\ngeneral language generation. In our experiments we use DBS to control GPT-2. We\ndemonstrate its performance on keyword-to-phrase generation and we obtain\ncomparable results as a state-of-the-art non-plug-and-play model for lexically\nconstrained story generation.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 03:05:44 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Pascual", "Damian", ""], ["Egressy", "Beni", ""], ["Bolli", "Florian", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "2012.15419", "submitter": "Faiza Khattak", "authors": "Paul Grouchy, Shobhit Jain, Michael Liu, Kuhan Wang, Max Tian, Nidhi\n  Arora, Hillary Ngai, Faiza Khan Khattak, Elham Dolatabadi, Sedef Akinli Kocak", "title": "An Experimental Evaluation of Transformer-based Language Models in the\n  Biomedical Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the growing amount of text in health data, there have been rapid\nadvances in large pre-trained models that can be applied to a wide variety of\nbiomedical tasks with minimal task-specific modifications. Emphasizing the cost\nof these models, which renders technical replication challenging, this paper\nsummarizes experiments conducted in replicating BioBERT and further\npre-training and careful fine-tuning in the biomedical domain. We also\ninvestigate the effectiveness of domain-specific and domain-agnostic\npre-trained models across downstream biomedical NLP tasks. Our finding confirms\nthat pre-trained models can be impactful in some downstream NLP tasks (QA and\nNER) in the biomedical domain; however, this improvement may not justify the\nhigh cost of domain-specific pre-training.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 03:09:38 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Grouchy", "Paul", ""], ["Jain", "Shobhit", ""], ["Liu", "Michael", ""], ["Wang", "Kuhan", ""], ["Tian", "Max", ""], ["Arora", "Nidhi", ""], ["Ngai", "Hillary", ""], ["Khattak", "Faiza Khan", ""], ["Dolatabadi", "Elham", ""], ["Kocak", "Sedef Akinli", ""]]}, {"id": "2012.15421", "submitter": "Olga Majewska", "authors": "Olga Majewska, Ivan Vuli\\'c, Goran Glava\\v{s}, Edoardo M. Ponti, Anna\n  Korhonen", "title": "Verb Knowledge Injection for Multilingual Event Processing", "comments": "19 pages, 1 figure, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In parallel to their overwhelming success across NLP tasks, language ability\nof deep Transformer networks, pretrained via language modeling (LM) objectives\nhas undergone extensive scrutiny. While probing revealed that these models\nencode a range of syntactic and semantic properties of a language, they are\nstill prone to fall back on superficial cues and simple heuristics to solve\ndownstream tasks, rather than leverage deeper linguistic knowledge. In this\npaper, we target one such area of their deficiency, verbal reasoning. We\ninvestigate whether injecting explicit information on verbs' semantic-syntactic\nbehaviour improves the performance of LM-pretrained Transformers in event\nextraction tasks -- downstream tasks for which accurate verb processing is\nparamount. Concretely, we impart the verb knowledge from curated lexical\nresources into dedicated adapter modules (dubbed verb adapters), allowing it to\ncomplement, in downstream tasks, the language knowledge obtained during\nLM-pretraining. We first demonstrate that injecting verb knowledge leads to\nperformance gains in English event extraction. We then explore the utility of\nverb adapters for event extraction in other languages: we investigate (1)\nzero-shot language transfer with multilingual Transformers as well as (2)\ntransfer via (noisy automatic) translation of English verb-based lexical\nconstraints. Our results show that the benefits of verb knowledge injection\nindeed extend to other languages, even when verb adapters are trained on\nnoisily translated constraints.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 03:24:34 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Majewska", "Olga", ""], ["Vuli\u0107", "Ivan", ""], ["Glava\u0161", "Goran", ""], ["Ponti", "Edoardo M.", ""], ["Korhonen", "Anna", ""]]}, {"id": "2012.15425", "submitter": "Guy Lapalme", "authors": "Guy Lapalme", "title": "The jsRealB Text Realizer: Organization and Use Cases", "comments": "25 page, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes the design principles behind jsRealB, a surface realizer\nwritten in JavaScript for English or French sentences from a specification\ninspired by the constituent syntax formalism. It can be used either within a\nweb page or as a node .js module. We show that the seemingly simple process of\ntext realization involves many interesting implementation challenges in order\nto take into account the specifics of each language. jsRealB has a large\ncoverage of English and French and has been used to develop realistic\ndata-to-text applications and to reproduce existing literary texts and\nsentences with Universal Dependency annotations. Its source code and that of\nits applications are available on GitHub.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 03:32:58 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Lapalme", "Guy", ""]]}, {"id": "2012.15454", "submitter": "Wei-Ning Hsu", "authors": "Wei-Ning Hsu, David Harwath, Christopher Song, James Glass", "title": "Text-Free Image-to-Speech Synthesis Using Learned Segmental Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we present the first model for directly synthesizing fluent,\nnatural-sounding spoken audio captions for images that does not require natural\nlanguage text as an intermediate representation or source of supervision.\nInstead, we connect the image captioning module and the speech synthesis module\nwith a set of discrete, sub-word speech units that are discovered with a\nself-supervised visual grounding task. We conduct experiments on the Flickr8k\nspoken caption dataset in addition to a novel corpus of spoken audio captions\ncollected for the popular MSCOCO dataset, demonstrating that our generated\ncaptions also capture diverse visual semantics of the images they describe. We\ninvestigate several different intermediate speech representations, and\nempirically find that the representation must satisfy several important\nproperties to serve as drop-in replacements for text.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 05:28:38 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Hsu", "Wei-Ning", ""], ["Harwath", "David", ""], ["Song", "Christopher", ""], ["Glass", "James", ""]]}, {"id": "2012.15455", "submitter": "Alham Fikri Aji", "authors": "Alham Fikri Aji, Kenneth Heafield", "title": "Exploring Monolingual Data for Neural Machine Translation with Knowledge\n  Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore two types of monolingual data that can be included in knowledge\ndistillation training for neural machine translation (NMT). The first is the\nsource-side monolingual data. Second, is the target-side monolingual data that\nis used as back-translation data. Both datasets are (forward-)translated by a\nteacher model from source-language to target-language, which are then combined\ninto a dataset for smaller student models. We find that source-side monolingual\ndata improves model performance when evaluated by test-set originated from\nsource-side. Likewise, target-side data has a positive effect on the test-set\nin the opposite direction. We also show that it is not required to train the\nstudent model with the same data used by the teacher, as long as the domains\nare the same. Finally, we find that combining source-side and target-side\nyields in better performance than relying on just one side of the monolingual\ndata.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 05:28:42 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Aji", "Alham Fikri", ""], ["Heafield", "Kenneth", ""]]}, {"id": "2012.15466", "submitter": "Zhuofeng Wu", "authors": "Zhuofeng Wu, Sinong Wang, Jiatao Gu, Madian Khabsa, Fei Sun, Hao Ma", "title": "CLEAR: Contrastive Learning for Sentence Representation", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language models have proven their unique powers in capturing\nimplicit language features. However, most pre-training approaches focus on the\nword-level training objective, while sentence-level objectives are rarely\nstudied. In this paper, we propose Contrastive LEArning for sentence\nRepresentation (CLEAR), which employs multiple sentence-level augmentation\nstrategies in order to learn a noise-invariant sentence representation. These\naugmentations include word and span deletion, reordering, and substitution.\nFurthermore, we investigate the key reasons that make contrastive learning\neffective through numerous experiments. We observe that different sentence\naugmentations during pre-training lead to different performance improvements on\nvarious downstream tasks. Our approach is shown to outperform multiple existing\nmethods on both SentEval and GLUE benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 06:40:13 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Wu", "Zhuofeng", ""], ["Wang", "Sinong", ""], ["Gu", "Jiatao", ""], ["Khabsa", "Madian", ""], ["Sun", "Fei", ""], ["Ma", "Hao", ""]]}, {"id": "2012.15482", "submitter": "Srinivasan Iyer", "authors": "Kushal Lakhotia, Bhargavi Paranjape, Asish Ghoshal, Wen-tau Yih,\n  Yashar Mehdad, Srinivasan Iyer", "title": "FiD-Ex: Improving Sequence-to-Sequence Models for Extractive Rationale\n  Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language (NL) explanations of model predictions are gaining\npopularity as a means to understand and verify decisions made by large\nblack-box pre-trained models, for NLP tasks such as Question Answering (QA) and\nFact Verification. Recently, pre-trained sequence to sequence (seq2seq) models\nhave proven to be very effective in jointly making predictions, as well as\ngenerating NL explanations. However, these models have many shortcomings; they\ncan fabricate explanations even for incorrect predictions, they are difficult\nto adapt to long input documents, and their training requires a large amount of\nlabeled data. In this paper, we develop FiD-Ex, which addresses these\nshortcomings for seq2seq models by: 1) introducing sentence markers to\neliminate explanation fabrication by encouraging extractive generation, 2)\nusing the fusion-in-decoder architecture to handle long input contexts, and 3)\nintermediate fine-tuning on re-structured open domain QA datasets to improve\nfew-shot performance. FiD-Ex significantly improves over prior work in terms of\nexplanation metrics and task accuracy, on multiple tasks from the ERASER\nexplainability benchmark, both in the fully supervised and in the few-shot\nsettings.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 07:22:15 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Lakhotia", "Kushal", ""], ["Paranjape", "Bhargavi", ""], ["Ghoshal", "Asish", ""], ["Yih", "Wen-tau", ""], ["Mehdad", "Yashar", ""], ["Iyer", "Srinivasan", ""]]}, {"id": "2012.15484", "submitter": "Kiran Ramnath", "authors": "Kiran Ramnath and Mark Hasegawa-Johnson", "title": "Seeing is Knowing! Fact-based Visual Question Answering using Knowledge\n  Graph Embeddings", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Fact-based Visual Question Answering (FVQA), a challenging variant of VQA,\nrequires a QA-system to include facts from a diverse knowledge graph (KG) in\nits reasoning process to produce an answer. Large KGs, especially common-sense\nKGs, are known to be incomplete, i.e., not all non-existent facts are always\nincorrect. Therefore, being able to reason over incomplete KGs for QA is a\ncritical requirement in real-world applications that has not been addressed\nextensively in the literature. We develop a novel QA architecture that allows\nus to reason over incomplete KGs, something current FVQA state-of-the-art\n(SOTA) approaches lack due to their critical reliance on fact retrieval. We use\nKG Embeddings, a technique widely used for KG completion, for the downstream\ntask of FVQA. We also employ a new image representation technique we call\n'Image-as-Knowledge' to enable this capability, alongside a simple one-step\nCoAttention mechanism to attend to text and image during QA. Our FVQA\narchitecture is faster during inference time, being O(m), as opposed to\nexisting FVQA SOTA methods which are O(N log N), where m = number of vertices,\nN = number of edges = O(m^2). KG embeddings are shown to hold complementary\ninformation to word embeddings: a combination of both metrics permits\nperformance comparable to SOTA methods in the standard answer retrieval task,\nand significantly better (26% absolute) in the proposed missing-edge reasoning\ntask.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 07:24:55 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 18:20:46 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Ramnath", "Kiran", ""], ["Hasegawa-Johnson", "Mark", ""]]}, {"id": "2012.15495", "submitter": "Ahmad Rashid", "authors": "Ahmad Rashid, Vasileios Lioutas, Abbas Ghaddar and Mehdi\n  Rezagholizadeh", "title": "Towards Zero-Shot Knowledge Distillation for Natural Language Processing", "comments": "13 pages, 8 tables, 2 algorithms and 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Distillation (KD) is a common knowledge transfer algorithm used for\nmodel compression across a variety of deep learning based natural language\nprocessing (NLP) solutions. In its regular manifestations, KD requires access\nto the teacher's training data for knowledge transfer to the student network.\nHowever, privacy concerns, data regulations and proprietary reasons may prevent\naccess to such data. We present, to the best of our knowledge, the first work\non Zero-Shot Knowledge Distillation for NLP, where the student learns from the\nmuch larger teacher without any task specific data. Our solution combines out\nof domain data and adversarial training to learn the teacher's output\ndistribution. We investigate six tasks from the GLUE benchmark and demonstrate\nthat we can achieve between 75% and 92% of the teacher's classification score\n(accuracy or F1) while compressing the model 30 times.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 08:16:29 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Rashid", "Ahmad", ""], ["Lioutas", "Vasileios", ""], ["Ghaddar", "Abbas", ""], ["Rezagholizadeh", "Mehdi", ""]]}, {"id": "2012.15504", "submitter": "Andrea Madotto Mr", "authors": "Andrea Madotto, Zhaojiang Lin, Zhenpeng Zhou, Seungwhan Moon, Paul\n  Crook, Bing Liu, Zhou Yu, Eunjoon Cho, Zhiguang Wang", "title": "Continual Learning in Task-Oriented Dialogue Systems", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Continual learning in task-oriented dialogue systems can allow us to add new\ndomains and functionalities through time without incurring the high cost of a\nwhole system retraining. In this paper, we propose a continual learning\nbenchmark for task-oriented dialogue systems with 37 domains to be learned\ncontinuously in four settings, such as intent recognition, state tracking,\nnatural language generation, and end-to-end. Moreover, we implement and compare\nmultiple existing continual learning baselines, and we propose a simple yet\neffective architectural method based on residual adapters. Our experiments\ndemonstrate that the proposed architectural method and a simple replay-based\nstrategy perform comparably well but they both achieve inferior performance to\nthe multi-task learning baseline, in where all the data are shown at once,\nshowing that continual learning in task-oriented dialogue systems is a\nchallenging task. Furthermore, we reveal several trade-offs between different\ncontinual learning methods in term of parameter usage and memory size, which\nare important in the design of a task-oriented dialogue system. The proposed\nbenchmark is released together with several baselines to promote more research\nin this direction.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 08:44:25 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Madotto", "Andrea", ""], ["Lin", "Zhaojiang", ""], ["Zhou", "Zhenpeng", ""], ["Moon", "Seungwhan", ""], ["Crook", "Paul", ""], ["Liu", "Bing", ""], ["Yu", "Zhou", ""], ["Cho", "Eunjoon", ""], ["Wang", "Zhiguang", ""]]}, {"id": "2012.15515", "submitter": "Zhixing Tan", "authors": "Zhixing Tan, Shuo Wang, Zonghan Yang, Gang Chen, Xuancheng Huang,\n  Maosong Sun, Yang Liu", "title": "Neural Machine Translation: A Review of Methods, Resources, and Tools", "comments": "Accepted by AI Open", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine translation (MT) is an important sub-field of natural language\nprocessing that aims to translate natural languages using computers. In recent\nyears, end-to-end neural machine translation (NMT) has achieved great success\nand has become the new mainstream method in practical MT systems. In this\narticle, we first provide a broad review of the methods for NMT and focus on\nmethods relating to architectures, decoding, and data augmentation. Then we\nsummarize the resources and tools that are useful for researchers. Finally, we\nconclude with a discussion of possible future research directions.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 09:35:27 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Tan", "Zhixing", ""], ["Wang", "Shuo", ""], ["Yang", "Zonghan", ""], ["Chen", "Gang", ""], ["Huang", "Xuancheng", ""], ["Sun", "Maosong", ""], ["Liu", "Yang", ""]]}, {"id": "2012.15516", "submitter": "Wissam Antoun", "authors": "Wissam Antoun, Fady Baly, Hazem Hajj", "title": "AraELECTRA: Pre-Training Text Discriminators for Arabic Language\n  Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in English language representation enabled a more sample-efficient\npre-training task by Efficiently Learning an Encoder that Classifies Token\nReplacements Accurately (ELECTRA). Which, instead of training a model to\nrecover masked tokens, it trains a discriminator model to distinguish true\ninput tokens from corrupted tokens that were replaced by a generator network.\nOn the other hand, current Arabic language representation approaches rely only\non pretraining via masked language modeling. In this paper, we develop an\nArabic language representation model, which we name AraELECTRA. Our model is\npretrained using the replaced token detection objective on large Arabic text\ncorpora. We evaluate our model on multiple Arabic NLP tasks, including reading\ncomprehension, sentiment analysis, and named-entity recognition and we show\nthat AraELECTRA outperforms current state-of-the-art Arabic language\nrepresentation models, given the same pretraining data and with even a smaller\nmodel size.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 09:35:39 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 13:23:41 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Antoun", "Wissam", ""], ["Baly", "Fady", ""], ["Hajj", "Hazem", ""]]}, {"id": "2012.15520", "submitter": "Wissam Antoun", "authors": "Wissam Antoun, Fady Baly, Hazem Hajj", "title": "AraGPT2: Pre-Trained Transformer for Arabic Language Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, pre-trained transformer-based architectures have proven to be very\nefficient at language modeling and understanding, given that they are trained\non a large enough corpus. Applications in language generation for Arabic are\nstill lagging in comparison to other NLP advances primarily due to the lack of\nadvanced Arabic language generation models. In this paper, we develop the first\nadvanced Arabic language generation model, AraGPT2, trained from scratch on a\nlarge Arabic corpus of internet text and news articles. Our largest model,\nAraGPT2-mega, has 1.46 billion parameters, which makes it the largest Arabic\nlanguage model available. The Mega model was evaluated and showed success on\ndifferent tasks including synthetic news generation, and zero-shot question\nanswering. For text generation, our best model achieves a perplexity of 29.8 on\nheld-out Wikipedia articles. A study conducted with human evaluators showed the\nsignificant success of AraGPT2-mega in generating news articles that are\ndifficult to distinguish from articles written by humans. We thus develop and\nrelease an automatic discriminator model with a 98% percent accuracy in\ndetecting model-generated text. The models are also publicly available, hoping\nto encourage new research directions and applications for Arabic NLP.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 09:48:05 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 13:11:53 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Antoun", "Wissam", ""], ["Baly", "Fady", ""], ["Hajj", "Hazem", ""]]}, {"id": "2012.15524", "submitter": "Xinying Song", "authors": "Xinying Song, Alex Salcianu, Yang Song, Dave Dopson, Denny Zhou", "title": "Linear-Time WordPiece Tokenization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  WordPiece tokenization is a subword-based tokenization schema adopted by\nBERT: it segments the input text via a longest-match-first tokenization\nstrategy, known as Maximum Matching or MaxMatch. To the best of our knowledge,\nall published MaxMatch algorithms are quadratic (or higher). In this paper, we\npropose LinMaxMatch, a novel linear-time algorithm for MaxMatch and WordPiece\ntokenization. Inspired by the Aho-Corasick algorithm, we introduce additional\nlinkages on top of the trie built from the vocabulary, allowing smart\ntransitions when the trie matching cannot continue. Experimental results show\nthat our algorithm is 3x faster on average than two production systems by\nHuggingFace and TensorFlow Text. Regarding long-tail inputs, our algorithm is\n4.5x faster at the 95 percentile. This work has immediate practical value\n(reducing inference latency, saving compute resources, etc.) and is of\ntheoretical interest by providing an optimal complexity solution to the\ndecades-old MaxMatch problem.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 10:01:29 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Song", "Xinying", ""], ["Salcianu", "Alex", ""], ["Song", "Yang", ""], ["Dopson", "Dave", ""], ["Zhou", "Denny", ""]]}, {"id": "2012.15525", "submitter": "Weizhen Qi", "authors": "Weizhen Qi, Yeyun Gong, Jian Jiao, Yu Yan, Weizhu Chen, Dayiheng Liu,\n  Kewen Tang, Houqiang Li, Jiusheng Chen, Ruofei Zhang, Ming Zhou, Nan Duan", "title": "BANG: Bridging Autoregressive and Non-autoregressive Generation with\n  Large Scale Pretraining", "comments": "Accepted by ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose BANG, a new pretraining model to Bridge the gap\nbetween Autoregressive (AR) and Non-autoregressive (NAR) Generation. AR and NAR\ngeneration can be uniformly regarded as to what extent previous tokens can be\nattended, and BANG bridges AR and NAR generation by designing a novel model\nstructure for large-scale pretraining. The pretrained BANG model can\nsimultaneously support AR, NAR and semi-NAR generation to meet different\nrequirements. Experiments on question generation (SQuAD 1.1), summarization\n(XSum) and dialogue generation (PersonaChat) show that BANG improves NAR and\nsemi-NAR performance significantly as well as attaining comparable performance\nwith strong AR pretrained models. Compared with the semi-NAR strong baselines,\nBANG achieves absolute improvements of 14.01 and 5.24 in the overall scores of\nSQuAD 1.1 and XSum, respectively. In addition, BANG achieves absolute\nimprovements of 10.73, 6.39 and 5.90 in the overall scores of SQuAD, XSUM and\nPersonaChat respectively compared with the strong NAR baselines.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 10:09:29 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 11:12:31 GMT"}, {"version": "v3", "created": "Wed, 16 Jun 2021 06:11:08 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Qi", "Weizhen", ""], ["Gong", "Yeyun", ""], ["Jiao", "Jian", ""], ["Yan", "Yu", ""], ["Chen", "Weizhu", ""], ["Liu", "Dayiheng", ""], ["Tang", "Kewen", ""], ["Li", "Houqiang", ""], ["Chen", "Jiusheng", ""], ["Zhang", "Ruofei", ""], ["Zhou", "Ming", ""], ["Duan", "Nan", ""]]}, {"id": "2012.15534", "submitter": "Xiaoguang Li", "authors": "Shaobo Li, Xiaoguang Li, Lifeng Shang, Xin Jiang, Qun Liu, Chengjie\n  Sun, Zhenzhou Ji, Bingquan Liu", "title": "HopRetriever: Retrieve Hops over Wikipedia to Answer Complex Questions", "comments": "Accepted at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Collecting supporting evidence from large corpora of text (e.g., Wikipedia)\nis of great challenge for open-domain Question Answering (QA). Especially, for\nmulti-hop open-domain QA, scattered evidence pieces are required to be gathered\ntogether to support the answer extraction. In this paper, we propose a new\nretrieval target, hop, to collect the hidden reasoning evidence from Wikipedia\nfor complex question answering. Specifically, the hop in this paper is defined\nas the combination of a hyperlink and the corresponding outbound link document.\nThe hyperlink is encoded as the mention embedding which models the structured\nknowledge of how the outbound link entity is mentioned in the textual context,\nand the corresponding outbound link document is encoded as the document\nembedding representing the unstructured knowledge within it. Accordingly, we\nbuild HopRetriever which retrieves hops over Wikipedia to answer complex\nquestions. Experiments on the HotpotQA dataset demonstrate that HopRetriever\noutperforms previously published evidence retrieval methods by large margins.\nMoreover, our approach also yields quantifiable interpretations of the evidence\ncollection process.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 10:36:01 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Li", "Shaobo", ""], ["Li", "Xiaoguang", ""], ["Shang", "Lifeng", ""], ["Jiang", "Xin", ""], ["Liu", "Qun", ""], ["Sun", "Chengjie", ""], ["Ji", "Zhenzhou", ""], ["Liu", "Bingquan", ""]]}, {"id": "2012.15543", "submitter": "Zheng-Yu Niu", "authors": "Jun Xu, Zeyang Lei, Haifeng Wang, Zheng-Yu Niu, Hua Wu, Wanxiang Che,\n  Ting Liu", "title": "Discovering Dialog Structure Graph for Open-Domain Dialog Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning interpretable dialog structure from human-human dialogs yields basic\ninsights into the structure of conversation, and also provides background\nknowledge to facilitate dialog generation. In this paper, we conduct\nunsupervised discovery of dialog structure from chitchat corpora, and then\nleverage it to facilitate dialog generation in downstream systems. To this end,\nwe present a Discrete Variational Auto-Encoder with Graph Neural Network\n(DVAE-GNN), to discover a unified human-readable dialog structure. The\nstructure is a two-layer directed graph that contains session-level semantics\nin the upper-layer vertices, utterance-level semantics in the lower-layer\nvertices, and edges among these semantic vertices. In particular, we integrate\nGNN into DVAE to fine-tune utterance-level semantics for more effective\nrecognition of session-level semantic vertex. Furthermore, to alleviate the\ndifficulty of discovering a large number of utterance-level semantics, we\ndesign a coupling mechanism that binds each utterance-level semantic vertex\nwith a distinct phrase to provide prior semantics. Experimental results on two\nbenchmark corpora confirm that DVAE-GNN can discover meaningful dialog\nstructure, and the use of dialog structure graph as background knowledge can\nfacilitate a graph grounded conversational system to conduct coherent\nmulti-turn dialog generation.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 10:58:37 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Xu", "Jun", ""], ["Lei", "Zeyang", ""], ["Wang", "Haifeng", ""], ["Niu", "Zheng-Yu", ""], ["Wu", "Hua", ""], ["Che", "Wanxiang", ""], ["Liu", "Ting", ""]]}, {"id": "2012.15547", "submitter": "Shuming Ma", "authors": "Shuming Ma, Jian Yang, Haoyang Huang, Zewen Chi, Li Dong, Dongdong\n  Zhang, Hany Hassan Awadalla, Alexandre Muzio, Akiko Eriguchi, Saksham\n  Singhal, Xia Song, Arul Menezes, Furu Wei", "title": "XLM-T: Scaling up Multilingual Machine Translation with Pretrained\n  Cross-lingual Transformer Encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual machine translation enables a single model to translate between\ndifferent languages. Most existing multilingual machine translation systems\nadopt a randomly initialized Transformer backbone. In this work, inspired by\nthe recent success of language model pre-training, we present XLM-T, which\ninitializes the model with an off-the-shelf pretrained cross-lingual\nTransformer encoder and fine-tunes it with multilingual parallel data. This\nsimple method achieves significant improvements on a WMT dataset with 10\nlanguage pairs and the OPUS-100 corpus with 94 pairs. Surprisingly, the method\nis also effective even upon the strong baseline with back-translation.\nMoreover, extensive analysis of XLM-T on unsupervised syntactic parsing, word\nalignment, and multilingual classification explains its effectiveness for\nmachine translation. The code will be at https://aka.ms/xlm-t.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 11:16:51 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Ma", "Shuming", ""], ["Yang", "Jian", ""], ["Huang", "Haoyang", ""], ["Chi", "Zewen", ""], ["Dong", "Li", ""], ["Zhang", "Dongdong", ""], ["Awadalla", "Hany Hassan", ""], ["Muzio", "Alexandre", ""], ["Eriguchi", "Akiko", ""], ["Singhal", "Saksham", ""], ["Song", "Xia", ""], ["Menezes", "Arul", ""], ["Wei", "Furu", ""]]}, {"id": "2012.15562", "submitter": "Jonas Pfeiffer", "authors": "Jonas Pfeiffer, Ivan Vuli\\'c, Iryna Gurevych, Sebastian Ruder", "title": "UNKs Everywhere: Adapting Multilingual Language Models to New Scripts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massively multilingual language models such as multilingual BERT offer\nstate-of-the-art cross-lingual transfer performance on a range of NLP tasks.\nHowever, due to limited capacity and large differences in pretraining data\nsizes, there is a profound performance gap between resource-rich and\nresource-poor target languages. The ultimate challenge is dealing with\nunder-resourced languages not covered at all by the models and written in\nscripts unseen during pretraining. In this work, we propose a series of novel\ndata-efficient methods that enable quick and effective adaptation of pretrained\nmultilingual models to such low-resource languages and unseen scripts. Relying\non matrix factorization, our methods capitalize on the existing latent\nknowledge about multiple languages already available in the pretrained model's\nembedding matrix. Furthermore, we show that learning of the new dedicated\nembedding matrix in the target language can be improved by leveraging a small\nnumber of vocabulary items (i.e., the so-called lexically overlapping tokens)\nshared between mBERT's and target language vocabulary. Our adaptation\ntechniques offer substantial performance gains for languages with unseen\nscripts. We also demonstrate that they can yield improvements for low-resource\nlanguages written in scripts covered by the pretrained model.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 11:37:28 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 16:57:18 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Pfeiffer", "Jonas", ""], ["Vuli\u0107", "Ivan", ""], ["Gurevych", "Iryna", ""], ["Ruder", "Sebastian", ""]]}, {"id": "2012.15573", "submitter": "Nafise Sadat Moosavi", "authors": "Mingzhu Wu, Nafise Sadat Moosavi, Dan Roth, Iryna Gurevych", "title": "Coreference Reasoning in Machine Reading Comprehension", "comments": "Accepted at ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coreference resolution is essential for natural language understanding and\nhas been long studied in NLP. In recent years, as the format of Question\nAnswering (QA) became a standard for machine reading comprehension (MRC), there\nhave been data collection efforts, e.g., Dasigi et al. (2019), that attempt to\nevaluate the ability of MRC models to reason about coreference. However, as we\nshow, coreference reasoning in MRC is a greater challenge than earlier thought;\nMRC datasets do not reflect the natural distribution and, consequently, the\nchallenges of coreference reasoning. Specifically, success on these datasets\ndoes not reflect a model's proficiency in coreference reasoning. We propose a\nmethodology for creating MRC datasets that better reflect the challenges of\ncoreference reasoning and use it to create a sample evaluation set. The results\non our dataset show that state-of-the-art models still struggle with these\nphenomena. Furthermore, we develop an effective way to use naturally occurring\ncoreference phenomena from existing coreference resolution datasets when\ntraining MRC models. This allows us to show an improvement in the coreference\nreasoning abilities of state-of-the-art models. The code and the resulting\ndataset are available at https://github.com/UKPLab/coref-reasoning-in-qa.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 12:18:41 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 14:51:23 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Wu", "Mingzhu", ""], ["Moosavi", "Nafise Sadat", ""], ["Roth", "Dan", ""], ["Gurevych", "Iryna", ""]]}, {"id": "2012.15606", "submitter": "Paul R\\\"ottger", "authors": "Paul R\\\"ottger, Bertram Vidgen, Dong Nguyen, Zeerak Waseem, Helen\n  Margetts, Janet B. Pierrehumbert", "title": "HateCheck: Functional Tests for Hate Speech Detection Models", "comments": "Accepted at ACL 2021 (Main Conference)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Detecting online hate is a difficult task that even state-of-the-art models\nstruggle with. Typically, hate speech detection models are evaluated by\nmeasuring their performance on held-out test data using metrics such as\naccuracy and F1 score. However, this approach makes it difficult to identify\nspecific model weak points. It also risks overestimating generalisable model\nperformance due to increasingly well-evidenced systematic gaps and biases in\nhate speech datasets. To enable more targeted diagnostic insights, we introduce\nHateCheck, a suite of functional tests for hate speech detection models. We\nspecify 29 model functionalities motivated by a review of previous research and\na series of interviews with civil society stakeholders. We craft test cases for\neach functionality and validate their quality through a structured annotation\nprocess. To illustrate HateCheck's utility, we test near-state-of-the-art\ntransformer models as well as two popular commercial models, revealing critical\nmodel weaknesses.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 13:44:56 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 14:23:15 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["R\u00f6ttger", "Paul", ""], ["Vidgen", "Bertram", ""], ["Nguyen", "Dong", ""], ["Waseem", "Zeerak", ""], ["Margetts", "Helen", ""], ["Pierrehumbert", "Janet B.", ""]]}, {"id": "2012.15613", "submitter": "Phillip Rust", "authors": "Phillip Rust, Jonas Pfeiffer, Ivan Vuli\\'c, Sebastian Ruder, Iryna\n  Gurevych", "title": "How Good is Your Tokenizer? On the Monolingual Performance of\n  Multilingual Language Models", "comments": "ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we provide a systematic and comprehensive empirical comparison\nof pretrained multilingual language models versus their monolingual\ncounterparts with regard to their monolingual task performance. We study a set\nof nine typologically diverse languages with readily available pretrained\nmonolingual models on a set of five diverse monolingual downstream tasks. We\nfirst aim to establish, via fair and controlled comparisons, if a gap between\nthe multilingual and the corresponding monolingual representation of that\nlanguage exists, and subsequently investigate the reason for any performance\ndifference. To disentangle conflating factors, we train new monolingual models\non the same data, with monolingually and multilingually trained tokenizers. We\nfind that while the pretraining data size is an important factor, a designated\nmonolingual tokenizer plays an equally important role in the downstream\nperformance. Our results show that languages that are adequately represented in\nthe multilingual model's vocabulary exhibit negligible performance decreases\nover their monolingual counterparts. We further find that replacing the\noriginal multilingual tokenizer with the specialized monolingual tokenizer\nimproves the downstream performance of the multilingual model for almost every\ntask and language.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 14:11:00 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 18:17:59 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Rust", "Phillip", ""], ["Pfeiffer", "Jonas", ""], ["Vuli\u0107", "Ivan", ""], ["Ruder", "Sebastian", ""], ["Gurevych", "Iryna", ""]]}, {"id": "2012.15621", "submitter": "Won Ik Cho", "authors": "Won Ik Cho, Sangwhan Moon, Youngsook Song", "title": "Open Korean Corpora: A Practical Report", "comments": "Published in NLP-OSS@EMNLP 2020; Fixed some typos; Shared for further\n  update", "journal-ref": null, "doi": "10.18653/v1/2020.nlposs-1.12", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Korean is often referred to as a low-resource language in the research\ncommunity. While this claim is partially true, it is also because the\navailability of resources is inadequately advertised and curated. This work\ncurates and reviews a list of Korean corpora, first describing\ninstitution-level resource development, then further iterate through a list of\ncurrent open datasets for different types of tasks. We then propose a direction\non how open-source dataset construction and releases should be done for\nless-resourced languages to promote research.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 14:23:55 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Cho", "Won Ik", ""], ["Moon", "Sangwhan", ""], ["Song", "Youngsook", ""]]}, {"id": "2012.15639", "submitter": "Lemao Liu", "authors": "Haisong Zhang, Lemao Liu, Haiyun Jiang, Yangming Li, Enbo Zhao, Kun\n  Xu, Linfeng Song, Suncong Zheng, Botong Zhou, Jianchen Zhu, Xiao Feng, Tao\n  Chen, Tao Yang, Dong Yu, Feng Zhang, Zhanhui Kang, Shuming Shi", "title": "TexSmart: A Text Understanding System for Fine-Grained NER and Enhanced\n  Semantic Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technique report introduces TexSmart, a text understanding system that\nsupports fine-grained named entity recognition (NER) and enhanced semantic\nanalysis functionalities. Compared to most previous publicly available text\nunderstanding systems and tools, TexSmart holds some unique features. First,\nthe NER function of TexSmart supports over 1,000 entity types, while most other\npublic tools typically support several to (at most) dozens of entity types.\nSecond, TexSmart introduces new semantic analysis functions like semantic\nexpansion and deep semantic representation, that are absent in most previous\nsystems. Third, a spectrum of algorithms (from very fast algorithms to those\nthat are relatively slow but more accurate) are implemented for one function in\nTexSmart, to fulfill the requirements of different academic and industrial\napplications. The adoption of unsupervised or weakly-supervised algorithms is\nespecially emphasized, with the goal of easily updating our models to include\nfresh data with less human annotation efforts.\n  The main contents of this report include major functions of TexSmart,\nalgorithms for achieving these functions, how to use the TexSmart toolkit and\nWeb APIs, and evaluation results of some key algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 14:58:01 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Zhang", "Haisong", ""], ["Liu", "Lemao", ""], ["Jiang", "Haiyun", ""], ["Li", "Yangming", ""], ["Zhao", "Enbo", ""], ["Xu", "Kun", ""], ["Song", "Linfeng", ""], ["Zheng", "Suncong", ""], ["Zhou", "Botong", ""], ["Zhu", "Jianchen", ""], ["Feng", "Xiao", ""], ["Chen", "Tao", ""], ["Yang", "Tao", ""], ["Yu", "Dong", ""], ["Zhang", "Feng", ""], ["Kang", "Zhanhui", ""], ["Shi", "Shuming", ""]]}, {"id": "2012.15643", "submitter": "Changlong Yu", "authors": "Changlong Yu, Hongming Zhang, Yangqiu Song and Wilfred Ng", "title": "CoCoLM: COmplex COmmonsense Enhanced Language Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large-scale pre-trained language models have demonstrated strong knowledge\nrepresentation ability. However, recent studies suggest that even though these\ngiant models contains rich simple commonsense knowledge (e.g., bird can fly and\nfish can swim.), they often struggle with the complex commonsense knowledge\nthat involves multiple eventualities (verb-centric phrases, e.g., identifying\nthe relationship between ``Jim yells at Bob'' and ``Bob is upset'').To address\nthis problem, in this paper, we propose to help pre-trained language models\nbetter incorporate complex commonsense knowledge. Different from existing\nfine-tuning approaches, we do not focus on a specific task and propose a\ngeneral language model named CoCoLM. Through the careful training over a\nlarge-scale eventuality knowledge graphs ASER, we successfully teach\npre-trained language models (i.e., BERT and RoBERTa) rich complex commonsense\nknowledge among eventualities. Experiments on multiple downstream commonsense\ntasks that requires the correct understanding of eventualities demonstrate the\neffectiveness of CoCoLM.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 15:05:36 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Yu", "Changlong", ""], ["Zhang", "Hongming", ""], ["Song", "Yangqiu", ""], ["Ng", "Wilfred", ""]]}, {"id": "2012.15671", "submitter": "Jingjing Xu", "authors": "Jingjing Xu, Hao Zhou, Chun Gan, Zaixiang Zheng, Lei Li", "title": "Vocabulary Learning via Optimal Transport for Machine Translation", "comments": "Accepted by ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of token vocabulary affects the performance of machine\ntranslation. This paper aims to figure out what is a good vocabulary and\nwhether one can find the optimal vocabulary without trial training. To answer\nthese questions, we first provide an alternative understanding of the role of\nvocabulary from the perspective of information theory. Motivated by this, we\nformulate the quest of vocabularization -- finding the best token dictionary\nwith a proper size -- as an optimal transport (OT) problem. We propose VOLT, a\nsimple and efficient solution without trial training. Empirical results show\nthat VOLT outperforms widely-used vocabularies in diverse scenarios, including\nWMT-14 English-German and TED's 52 translation directions. For example, VOLT\nachieves almost 70% vocabulary size reduction and 0.5 BLEU gain on\nEnglish-German translation. Also, compared to BPE-search, VOLT reduces the\nsearch time from 384 GPU hours to 30 GPU hours on English-German translation.\nCodes are available at https://github.com/Jingjing-NLP/VOLT .\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 15:49:49 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 10:11:10 GMT"}, {"version": "v3", "created": "Wed, 7 Jul 2021 07:51:14 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Xu", "Jingjing", ""], ["Zhou", "Hao", ""], ["Gan", "Chun", ""], ["Zheng", "Zaixiang", ""], ["Li", "Lei", ""]]}, {"id": "2012.15674", "submitter": "Shuohuan Wang", "authors": "Xuan Ouyang, Shuohuan Wang, Chao Pang, Yu Sun, Hao Tian, Hua Wu,\n  Haifeng Wang", "title": "ERNIE-M: Enhanced Multilingual Representation by Aligning Cross-lingual\n  Semantics with Monolingual Corpora", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have demonstrated that pre-trained cross-lingual models\nachieve impressive performance on downstream cross-lingual tasks. This\nimprovement stems from the learning of a large amount of monolingual and\nparallel corpora. While it is generally acknowledged that parallel corpora are\ncritical for improving the model performance, existing methods are often\nconstrained by the size of parallel corpora, especially for the low-resource\nlanguages. In this paper, we propose ERNIE-M, a new training method that\nencourages the model to align the representation of multiple languages with\nmonolingual corpora, to break the constraint of parallel corpus size on the\nmodel performance. Our key insight is to integrate the idea of back translation\nin the pre-training process. We generate pseudo-parallel sentences pairs on a\nmonolingual corpus to enable the learning of semantic alignment between\ndifferent languages, which enhances the semantic modeling of cross-lingual\nmodels. Experimental results show that ERNIE-M outperforms existing\ncross-lingual models and delivers new state-of-the-art results on various\ncross-lingual downstream tasks. The codes and pre-trained models will be made\npublicly available.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 15:52:27 GMT"}, {"version": "v2", "created": "Fri, 1 Jan 2021 18:11:28 GMT"}, {"version": "v3", "created": "Sat, 10 Apr 2021 15:17:51 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Ouyang", "Xuan", ""], ["Wang", "Shuohuan", ""], ["Pang", "Chao", ""], ["Sun", "Yu", ""], ["Tian", "Hao", ""], ["Wu", "Hua", ""], ["Wang", "Haifeng", ""]]}, {"id": "2012.15682", "submitter": "Mengjie Zhao", "authors": "Mengjie Zhao, Yi Zhu, Ehsan Shareghi, Ivan Vuli\\'c, Roi Reichart, Anna\n  Korhonen, Hinrich Sch\\\"utze", "title": "A Closer Look at Few-Shot Crosslingual Transfer: The Choice of Shots\n  Matters", "comments": "ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Few-shot crosslingual transfer has been shown to outperform its zero-shot\ncounterpart with pretrained encoders like multilingual BERT. Despite its\ngrowing popularity, little to no attention has been paid to standardizing and\nanalyzing the design of few-shot experiments. In this work, we highlight a\nfundamental risk posed by this shortcoming, illustrating that the model\nexhibits a high degree of sensitivity to the selection of few shots. We conduct\na large-scale experimental study on 40 sets of sampled few shots for six\ndiverse NLP tasks across up to 40 languages. We provide an analysis of success\nand failure cases of few-shot transfer, which highlights the role of lexical\nfeatures. Additionally, we show that a straightforward full model finetuning\napproach is quite effective for few-shot transfer, outperforming several\nstate-of-the-art few-shot approaches. As a step towards standardizing few-shot\ncrosslingual experimental designs, we make our sampled few shots publicly\navailable.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 16:03:48 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 12:34:52 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Zhao", "Mengjie", ""], ["Zhu", "Yi", ""], ["Shareghi", "Ehsan", ""], ["Vuli\u0107", "Ivan", ""], ["Reichart", "Roi", ""], ["Korhonen", "Anna", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "2012.15688", "submitter": "Shuohuan Wang", "authors": "Siyu Ding, Junyuan Shang, Shuohuan Wang, Yu Sun, Hao Tian, Hua Wu,\n  Haifeng Wang", "title": "ERNIE-Doc: A Retrospective Long-Document Modeling Transformer", "comments": "Accepted by ACL 2021 (main conference, long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers are not suited for processing long documents, due to their\nquadratically increasing memory and time consumption. Simply truncating a long\ndocument or applying the sparse attention mechanism will incur the context\nfragmentation problem or lead to an inferior modeling capability against\ncomparable model sizes. In this paper, we propose ERNIE-Doc, a document-level\nlanguage pretraining model based on Recurrence Transformers. Two well-designed\ntechniques, namely the retrospective feed mechanism and the enhanced recurrence\nmechanism, enable ERNIE-Doc, which has a much longer effective context length,\nto capture the contextual information of a complete document. We pretrain\nERNIE-Doc to explicitly learn the relationships among segments with an\nadditional document-aware segment-reordering objective. Various experiments\nwere conducted on both English and Chinese document-level tasks. ERNIE-Doc\nimproved the state-of-the-art language modeling result of perplexity to 16.8 on\nWikiText-103. Moreover, it outperformed competitive pretraining models by a\nlarge margin on most language understanding tasks, such as text classification\nand question answering.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 16:12:48 GMT"}, {"version": "v2", "created": "Mon, 24 May 2021 14:51:58 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Ding", "Siyu", ""], ["Shang", "Junyuan", ""], ["Wang", "Shuohuan", ""], ["Sun", "Yu", ""], ["Tian", "Hao", ""], ["Wu", "Hua", ""], ["Wang", "Haifeng", ""]]}, {"id": "2012.15695", "submitter": "Amir Mohammad Rostami", "authors": "Amir Mohammad Rostami, Ali Karimi, Mohammad Ali Akhaee", "title": "EfficientNet-Absolute Zero for Continuous Speech Keyword Spotting", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Keyword spotting is a process of finding some specific words or phrases in\nrecorded speeches by computers. Deep neural network algorithms, as a powerful\nengine, can handle this problem if they are trained over an appropriate\ndataset. To this end, the football keyword dataset (FKD), as a new keyword\nspotting dataset in Persian, is collected with crowdsourcing. This dataset\ncontains nearly 31000 samples in 18 classes. The continuous speech synthesis\nmethod proposed to made FKD usable in the practical application which works\nwith continuous speeches. Besides, we proposed a lightweight architecture\ncalled EfficientNet-A0 (absolute zero) by applying the compound scaling method\non EfficientNet-B0 for keyword spotting task. Finally, the proposed\narchitecture is evaluated with various models. It is realized that\nEfficientNet-A0 and Resnet models outperform other models on this dataset.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 16:21:27 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Rostami", "Amir Mohammad", ""], ["Karimi", "Ali", ""], ["Akhaee", "Mohammad Ali", ""]]}, {"id": "2012.15699", "submitter": "Chenglei Si", "authors": "Chenglei Si, Zhengyan Zhang, Fanchao Qi, Zhiyuan Liu, Yasheng Wang,\n  Qun Liu, Maosong Sun", "title": "Better Robustness by More Coverage: Adversarial Training with Mixup\n  Augmentation for Robust Fine-tuning", "comments": "ACL 2021 (Findings)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pretrained language models (PLMs) perform poorly under adversarial attacks.\nTo improve the adversarial robustness, adversarial data augmentation (ADA) has\nbeen widely adopted to cover more search space of adversarial attacks by adding\ntextual adversarial examples during training. However, the number of\nadversarial examples for text augmentation is still extremely insufficient due\nto the exponentially large attack search space. In this work, we propose a\nsimple and effective method to cover a much larger proportion of the attack\nsearch space, called Adversarial and Mixup Data Augmentation (AMDA).\nSpecifically, AMDA linearly interpolates the representations of pairs of\ntraining samples to form new virtual samples, which are more abundant and\ndiverse than the discrete text adversarial examples in conventional ADA.\nMoreover, to fairly evaluate the robustness of different models, we adopt a\nchallenging evaluation setup, which generates a new set of adversarial examples\ntargeting each model. In text classification experiments of BERT and RoBERTa,\nAMDA achieves significant robustness gains under two strong adversarial attacks\nand alleviates the performance degradation of ADA on the clean data. Our code\nis available at: https://github.com/thunlp/MixADA .\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 16:28:07 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 09:19:34 GMT"}, {"version": "v3", "created": "Sun, 6 Jun 2021 02:56:56 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Si", "Chenglei", ""], ["Zhang", "Zhengyan", ""], ["Qi", "Fanchao", ""], ["Liu", "Zhiyuan", ""], ["Wang", "Yasheng", ""], ["Liu", "Qun", ""], ["Sun", "Maosong", ""]]}, {"id": "2012.15701", "submitter": "Lu Hou", "authors": "Haoli Bai, Wei Zhang, Lu Hou, Lifeng Shang, Jing Jin, Xin Jiang, Qun\n  Liu, Michael Lyu, Irwin King", "title": "BinaryBERT: Pushing the Limit of BERT Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid development of large pre-trained language models has greatly\nincreased the demand for model compression techniques, among which quantization\nis a popular solution. In this paper, we propose BinaryBERT, which pushes BERT\nquantization to the limit by weight binarization. We find that a binary BERT is\nhard to be trained directly than a ternary counterpart due to its complex and\nirregular loss landscape. Therefore, we propose ternary weight splitting, which\ninitializes BinaryBERT by equivalently splitting from a half-sized ternary\nnetwork. The binary model thus inherits the good performance of the ternary\none, and can be further enhanced by fine-tuning the new architecture after\nsplitting. Empirical results show that our BinaryBERT has only a slight\nperformance drop compared with the full-precision model while being 24x\nsmaller, achieving the state-of-the-art compression results on the GLUE and\nSQuAD benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 16:34:54 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 13:13:45 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Bai", "Haoli", ""], ["Zhang", "Wei", ""], ["Hou", "Lu", ""], ["Shang", "Lifeng", ""], ["Jin", "Jing", ""], ["Jiang", "Xin", ""], ["Liu", "Qun", ""], ["Lyu", "Michael", ""], ["King", "Irwin", ""]]}, {"id": "2012.15710", "submitter": "Peyman Passban", "authors": "Peyman Passban, Puneeth S.M. Saladi, Qun Liu", "title": "Revisiting Robust Neural Machine Translation: A Transformer Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers (Vaswani et al., 2017) have brought a remarkable improvement in\nthe performance of neural machine translation (NMT) systems, but they could be\nsurprisingly vulnerable to noise. Accordingly, we tried to investigate how\nnoise breaks Transformers and if there exist solutions to deal with such\nissues. There is a large body of work in the NMT literature on analyzing the\nbehaviour of conventional models for the problem of noise but it seems\nTransformers are understudied in this context.\n  Therefore, we introduce a novel data-driven technique to incorporate noise\nduring training. This idea is comparable to the well-known fine-tuning\nstrategy. Moreover, we propose two new extensions to the original Transformer,\nthat modify the neural architecture as well as the training process to handle\nnoise. We evaluated our techniques to translate the English--German pair in\nboth directions. Experimental results show that our models have a higher\ntolerance to noise. More specifically, they perform with no deterioration where\nup to 10% of entire test words are infected by noise.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 16:55:05 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Passban", "Peyman", ""], ["Saladi", "Puneeth S. M.", ""], ["Liu", "Qun", ""]]}, {"id": "2012.15715", "submitter": "Mikel Artetxe", "authors": "Aitor Ormazabal, Mikel Artetxe, Aitor Soroa, Gorka Labaka, Eneko\n  Agirre", "title": "Beyond Offline Mapping: Learning Cross Lingual Word Embeddings through\n  Context Anchoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research on cross-lingual word embeddings has been dominated by\nunsupervised mapping approaches that align monolingual embeddings. Such methods\ncritically rely on those embeddings having a similar structure, but it was\nrecently shown that the separate training in different languages causes\ndepartures from this assumption. In this paper, we propose an alternative\napproach that does not have this limitation, while requiring a weak seed\ndictionary (e.g., a list of identical words) as the only form of supervision.\nRather than aligning two fixed embedding spaces, our method works by fixing the\ntarget language embeddings, and learning a new set of embeddings for the source\nlanguage that are aligned with them. To that end, we use an extension of\nskip-gram that leverages translated context words as anchor points, and\nincorporates self-learning and iterative restarts to reduce the dependency on\nthe initial dictionary. Our approach outperforms conventional mapping methods\non bilingual lexicon induction, and obtains competitive results in the\ndownstream XNLI task.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 17:10:14 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Ormazabal", "Aitor", ""], ["Artetxe", "Mikel", ""], ["Soroa", "Aitor", ""], ["Labaka", "Gorka", ""], ["Agirre", "Eneko", ""]]}, {"id": "2012.15717", "submitter": "Wenhao Zhu", "authors": "Wenhao Zhu, Shujian Huang, Tong Pu, Xu Zhang, Jian Yu, Wei Chen,\n  Yanfeng Wang and Jiajun Chen", "title": "FDMT: A Benchmark Dataset for Fine-grained Domain Adaptation in Machine\n  Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous domain adaptation research usually neglect the diversity in\ntranslation within a same domain, which is a core problem for adapting a\ngeneral neural machine translation (NMT) model into a specific domain in\nreal-world scenarios. One representative of such challenging scenarios is to\ndeploy a translation system for a conference with a specific topic, e.g.\ncomputer networks or natural language processing, where there is usually\nextremely less resources due to the limited time schedule. To motivate a wide\ninvestigation in such settings, we present a real-world fine-grained domain\nadaptation task in machine translation (FDMT). The FDMT dataset (Zh-En)\nconsists of four sub-domains of information technology: autonomous vehicles, AI\neducation, real-time networks and smart phone. To be closer to reality, FDMT\ndoes not employ any in-domain bilingual training data. Instead, each sub-domain\nis equipped with monolingual data, bilingual dictionary and knowledge base, to\nencourage in-depth exploration of these available resources. Corresponding\ndevelopment set and test set are provided for evaluation purpose. We make\nquantitative experiments and deep analyses in this new setting, which\nbenchmarks the fine-grained domain adaptation task and reveals several\nchallenging problems that need to be addressed.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 17:15:09 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Zhu", "Wenhao", ""], ["Huang", "Shujian", ""], ["Pu", "Tong", ""], ["Zhang", "Xu", ""], ["Yu", "Jian", ""], ["Chen", "Wei", ""], ["Wang", "Yanfeng", ""], ["Chen", "Jiajun", ""]]}, {"id": "2012.15723", "submitter": "Tianyu Gao", "authors": "Tianyu Gao, Adam Fisch, Danqi Chen", "title": "Making Pre-trained Language Models Better Few-shot Learners", "comments": "Accepted to ACL 2021. The code is publicly available at\n  https://github.com/princeton-nlp/LM-BFF", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent GPT-3 model (Brown et al., 2020) achieves remarkable few-shot\nperformance solely by leveraging a natural-language prompt and a few task\ndemonstrations as input context. Inspired by their findings, we study few-shot\nlearning in a more practical scenario, where we use smaller language models for\nwhich fine-tuning is computationally efficient. We present LM-BFF--better\nfew-shot fine-tuning of language models--a suite of simple and complementary\ntechniques for fine-tuning language models on a small number of annotated\nexamples. Our approach includes (1) prompt-based fine-tuning together with a\nnovel pipeline for automating prompt generation; and (2) a refined strategy for\ndynamically and selectively incorporating demonstrations into each context.\nFinally, we present a systematic evaluation for analyzing few-shot performance\non a range of NLP tasks, including classification and regression. Our\nexperiments demonstrate that our methods combine to dramatically outperform\nstandard fine-tuning procedures in this low resource setting, achieving up to\n30% absolute improvement, and 11% on average across all tasks. Our approach\nmakes minimal assumptions on task resources and domain expertise, and hence\nconstitutes a strong task-agnostic method for few-shot learning.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 17:21:26 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 12:41:36 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Gao", "Tianyu", ""], ["Fisch", "Adam", ""], ["Chen", "Danqi", ""]]}, {"id": "2012.15738", "submitter": "Denis Emelin", "authors": "Denis Emelin, Ronan Le Bras, Jena D. Hwang, Maxwell Forbes, Yejin Choi", "title": "Moral Stories: Situated Reasoning about Norms, Intents, Actions, and\n  their Consequences", "comments": "For the 'Moral Stories' dataset, see\n  https://github.com/demelin/moral_stories", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In social settings, much of human behavior is governed by unspoken rules of\nconduct. For artificial systems to be fully integrated into social\nenvironments, adherence to such norms is a central prerequisite. We investigate\nwhether contemporary NLG models can function as behavioral priors for systems\ndeployed in social settings by generating action hypotheses that achieve\npredefined goals under moral constraints. Moreover, we examine if models can\nanticipate likely consequences of (im)moral actions, or explain why certain\nactions are preferable by generating relevant norms. For this purpose, we\nintroduce 'Moral Stories', a crowd-sourced dataset of structured, branching\nnarratives for the study of grounded, goal-oriented social reasoning. Finally,\nwe propose decoding strategies that effectively combine multiple expert models\nto significantly improve the quality of generated actions, consequences, and\nnorms compared to strong baselines, e.g. though abductive reasoning.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 17:28:01 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Emelin", "Denis", ""], ["Bras", "Ronan Le", ""], ["Hwang", "Jena D.", ""], ["Forbes", "Maxwell", ""], ["Choi", "Yejin", ""]]}, {"id": "2012.15761", "submitter": "Bertie Vidgen Dr", "authors": "Bertie Vidgen, Tristan Thrush, Zeerak Waseem, Douwe Kiela", "title": "Learning from the Worst: Dynamically Generated Datasets to Improve\n  Online Hate Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a human-and-model-in-the-loop process for dynamically generating\ndatasets and training better performing and more robust hate detection models.\nWe provide a new dataset of ~40,000 entries, generated and labelled by trained\nannotators over four rounds of dynamic data creation. It includes ~15,000\nchallenging perturbations and each hateful entry has fine-grained labels for\nthe type and target of hate. Hateful entries make up 54% of the dataset, which\nis substantially higher than comparable datasets. We show that model\nperformance is substantially improved using this approach. Models trained on\nlater rounds of data collection perform better on test sets and are harder for\nannotators to trick. They also perform better on HateCheck, a suite of\nfunctional tests for online hate detection. We provide the code, dataset and\nannotation guidelines for other researchers to use. Accepted at ACL 2021.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 17:36:48 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 08:05:32 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Vidgen", "Bertie", ""], ["Thrush", "Tristan", ""], ["Waseem", "Zeerak", ""], ["Kiela", "Douwe", ""]]}, {"id": "2012.15781", "submitter": "Han Guo", "authors": "Han Guo, Nazneen Fatema Rajani, Peter Hase, Mohit Bansal, Caiming\n  Xiong", "title": "FastIF: Scalable Influence Functions for Efficient Model Interpretation\n  and Debugging", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Influence functions approximate the 'influences' of training data-points for\ntest predictions and have a wide variety of applications. Despite the\npopularity, their computational cost does not scale well with model and\ntraining data size. We present FastIF, a set of simple modifications to\ninfluence functions that significantly improves their run-time. We use\nk-Nearest Neighbors (kNN) to narrow the search space down to a subset of good\ncandidate data points, identify the configurations that best balance the\nspeed-quality trade-off in estimating the inverse Hessian-vector product, and\nintroduce a fast parallel variant. Our proposed method achieves about 80x\nspeedup while being highly correlated with the original influence values. With\nthe availability of the fast influence functions, we demonstrate their\nusefulness in four applications. First, we examine whether influential\ndata-points can 'explain' test time behavior using the framework of\nsimulatability. Second, we visualize the influence interactions between\ntraining and test data-points. Third, we show that we can correct model errors\nby additional fine-tuning on certain influential data-points, improving the\naccuracy of a trained MNLI model by 2.6% on the HANS challenge set using a\nsmall number of gradient updates. Finally, we experiment with a\ndata-augmentation setup where we use influence functions to search for new\ndata-points unseen during training to improve model performance. Overall, our\nfast influence functions can be efficiently applied to large models and\ndatasets, and our experiments demonstrate the potential of influence functions\nin model interpretation and correcting model errors. Code is available at\nhttps://github.com/salesforce/fast-influence-functions\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:02:34 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Guo", "Han", ""], ["Rajani", "Nazneen Fatema", ""], ["Hase", "Peter", ""], ["Bansal", "Mohit", ""], ["Xiong", "Caiming", ""]]}, {"id": "2012.15784", "submitter": "Rajkumar Pujari", "authors": "Rajkumar Pujari and Dan Goldwasser", "title": "Understanding Politics via Contextualized Discourse Processing", "comments": "16 pages including appendix, 18 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Politicians often have underlying agendas when reacting to events. Arguments\nin contexts of various events reflect a fairly consistent set of agendas for a\ngiven entity. In spite of recent advances in Pretrained Language Models (PLMs),\nthose text representations are not designed to capture such nuanced patterns.\nIn this paper, we propose a Compositional Reader model consisting of encoder\nand composer modules, that attempts to capture and leverage such information to\ngenerate more effective representations for entities, issues, and events. These\nrepresentations are contextualized by tweets, press releases, issues, news\narticles, and participating entities. Our model can process several documents\nat once and generate composed representations for multiple entities over\nseveral issues or events. Via qualitative and quantitative empirical analysis,\nwe show that these representations are meaningful and effective.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:07:07 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Pujari", "Rajkumar", ""], ["Goldwasser", "Dan", ""]]}, {"id": "2012.15786", "submitter": "Shih-Ting Lin", "authors": "Shih-Ting Lin, Nathanael Chambers, Greg Durrett", "title": "Conditional Generation of Temporally-ordered Event Sequences", "comments": "ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Models of narrative schema knowledge have proven useful for a range of\nevent-related tasks, but they typically do not capture the temporal\nrelationships between events. We propose a single model that addresses both\ntemporal ordering, sorting given events into the order they occurred, and event\ninfilling, predicting new events which fit into an existing temporally-ordered\nsequence. We use a BART-based conditional generation model that can capture\nboth temporality and common event co-occurrence, meaning it can be flexibly\napplied to different tasks in this space. Our model is trained as a denoising\nautoencoder: we take temporally-ordered event sequences, shuffle them, delete\nsome events, and then attempt to recover the original event sequence. This task\nteaches the model to make inferences given incomplete knowledge about the\nevents in an underlying scenario. On the temporal ordering task, we show that\nour model is able to unscramble event sequences from existing datasets without\naccess to explicitly labeled temporal training data, outperforming both a\nBERT-based pairwise model and a BERT-based pointer network. On event infilling,\nhuman evaluation shows that our model is able to generate events that fit\nbetter temporally into the input events when compared to GPT-2 story completion\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:10:18 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 06:44:48 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Lin", "Shih-Ting", ""], ["Chambers", "Nathanael", ""], ["Durrett", "Greg", ""]]}, {"id": "2012.15788", "submitter": "James Thorne", "authors": "James Thorne, Andreas Vlachos", "title": "Evidence-based Factual Error Correction", "comments": "Accepted at ACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the task of factual error correction: performing edits\nto a claim so that the generated rewrite is better supported by evidence. This\nextends the well-studied task of fact verification by providing a mechanism to\ncorrect written texts that are refuted or only partially supported by evidence.\nWe demonstrate that it is feasible to train factual error correction systems\nfrom existing fact checking datasets which only contain labeled claims\naccompanied by evidence, but not the correction. We achieve this by employing a\ntwo-stage distant supervision approach that incorporates evidence into masked\nclaims when generating corrections. Our approach, based on the T5 transformer\nand using retrieved evidence, achieved better results than existing work which\nused a pointer copy network and gold evidence, producing accurate factual error\ncorrections for 5x more instances in human evaluation and a .125 increase in\nSARI score. The evaluation is conducted on a dataset of 65,000 instances based\non a recent fact verification shared task and we release it to enable further\nwork on the task.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:11:26 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 16:23:26 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Thorne", "James", ""], ["Vlachos", "Andreas", ""]]}, {"id": "2012.15793", "submitter": "Alexander Hoyle", "authors": "Alexander Hoyle, Ana Marasovi\\'c, Noah Smith", "title": "Promoting Graph Awareness in Linearized Graph-to-Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating text from structured inputs, such as meaning representations or\nRDF triples, has often involved the use of specialized graph-encoding neural\nnetworks. However, recent applications of pretrained transformers to\nlinearizations of graph inputs have yielded state-of-the-art generation results\non graph-to-text tasks. Here, we explore the ability of these linearized models\nto encode local graph structures, in particular their invariance to the graph\nlinearization strategy and their ability to reconstruct corrupted inputs. Our\nfindings motivate solutions to enrich the quality of models' implicit graph\nencodings via scaffolding. Namely, we use graph-denoising objectives\nimplemented in a multi-task text-to-text framework. We find that these\ndenoising scaffolds lead to substantial improvements in downstream generation\nin low-resource settings.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:17:57 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Hoyle", "Alexander", ""], ["Marasovi\u0107", "Ana", ""], ["Smith", "Noah", ""]]}, {"id": "2012.15810", "submitter": "Nathan Schneider", "authors": "Omri Abend, Nathan Schneider, Dotan Dvir, Jakob Prange, Ari Rappoport", "title": "UCCA's Foundational Layer: Annotation Guidelines v2.1", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This is the annotation manual for Universal Conceptual Cognitive Annotation\n(UCCA; Abend and Rappoport, 2013), specifically the Foundational Layer. UCCA is\na graph-based semantic annotation scheme based on typological linguistic\nprinciples. It has been applied to several languages; for ease of exposition\nthese guidelines give examples mainly in English. New annotators may wish to\nstart with the tutorial on the UCCA framework (Abend et al., 2020). Further\nresources are available at the project homepage:\nhttps://universalconceptualcognitiveannotation.github.io\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:34:29 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Abend", "Omri", ""], ["Schneider", "Nathan", ""], ["Dvir", "Dotan", ""], ["Prange", "Jakob", ""], ["Rappoport", "Ari", ""]]}, {"id": "2012.15814", "submitter": "Jiayuan Mao", "authors": "Ruocheng Wang, Jiayuan Mao, Samuel J. Gershman, Jiajun Wu", "title": "Language-Mediated, Object-Centric Representation Learning", "comments": "ACL 2021 Findings. First two authors contributed equally; last two\n  authors contributed equally. Project page: https://lang-orl.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Language-mediated, Object-centric Representation Learning (LORL),\na paradigm for learning disentangled, object-centric scene representations from\nvision and language. LORL builds upon recent advances in unsupervised object\ndiscovery and segmentation, notably MONet and Slot Attention. While these\nalgorithms learn an object-centric representation just by reconstructing the\ninput image, LORL enables them to further learn to associate the learned\nrepresentations to concepts, i.e., words for object categories, properties, and\nspatial relationships, from language input. These object-centric concepts\nderived from language facilitate the learning of object-centric\nrepresentations. LORL can be integrated with various unsupervised object\ndiscovery algorithms that are language-agnostic. Experiments show that the\nintegration of LORL consistently improves the performance of unsupervised\nobject discovery methods on two datasets via the help of language. We also show\nthat concepts learned by LORL, in conjunction with object discovery methods,\naid downstream tasks such as referring expression comprehension.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:36:07 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 04:37:54 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Wang", "Ruocheng", ""], ["Mao", "Jiayuan", ""], ["Gershman", "Samuel J.", ""], ["Wu", "Jiajun", ""]]}, {"id": "2012.15828", "submitter": "Wenhui Wang", "authors": "Wenhui Wang, Hangbo Bao, Shaohan Huang, Li Dong, Furu Wei", "title": "MiniLMv2: Multi-Head Self-Attention Relation Distillation for\n  Compressing Pretrained Transformers", "comments": "Monolingual and multilingual distilled models:\n  https://github.com/microsoft/unilm/tree/master/minilm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize deep self-attention distillation in MiniLM (Wang et al., 2020)\nby only using self-attention relation distillation for task-agnostic\ncompression of pretrained Transformers. In particular, we define multi-head\nself-attention relations as scaled dot-product between the pairs of query, key,\nand value vectors within each self-attention module. Then we employ the above\nrelational knowledge to train the student model. Besides its simplicity and\nunified principle, more favorably, there is no restriction in terms of the\nnumber of student's attention heads, while most previous work has to guarantee\nthe same head number between teacher and student. Moreover, the fine-grained\nself-attention relations tend to fully exploit the interaction knowledge\nlearned by Transformer. In addition, we thoroughly examine the layer selection\nstrategy for teacher models, rather than just relying on the last layer as in\nMiniLM. We conduct extensive experiments on compressing both monolingual and\nmultilingual pretrained models. Experimental results demonstrate that our\nmodels distilled from base-size and large-size teachers (BERT, RoBERTa and\nXLM-R) outperform the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:51:26 GMT"}, {"version": "v2", "created": "Sun, 27 Jun 2021 10:11:02 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Wang", "Wenhui", ""], ["Bao", "Hangbo", ""], ["Huang", "Shaohan", ""], ["Dong", "Li", ""], ["Wei", "Furu", ""]]}, {"id": "2012.15832", "submitter": "Ofir Press", "authors": "Ofir Press, Noah A. Smith, Mike Lewis", "title": "Shortformer: Better Language Modeling using Shorter Inputs", "comments": "To appear at ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing the input length has been a driver of progress in language\nmodeling with transformers. We identify conditions where shorter inputs are not\nharmful, and achieve perplexity and efficiency improvements through two new\nmethods that decrease input length. First, we show that initially training a\nmodel on short subsequences before moving on to longer ones both reduces\noverall training time and, surprisingly, substantially improves perplexity.\nSecond, we show how to improve the efficiency of recurrence methods in\ntransformers, which let models condition on previously processed tokens when\ngenerating sequences that exceed the maximal length the transformer can handle\nat once. Existing methods require computationally expensive relative position\nembeddings; we introduce a simple alternative of adding absolute position\nembeddings to queries and keys instead of to word embeddings, which efficiently\nproduces superior results. We show that these recurrent models also benefit\nfrom short input lengths. Combining these techniques speeds up training by a\nfactor of 1.65, reduces memory usage, and substantially improves perplexity on\nWikiText-103, without adding any parameters.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:52:59 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 02:14:46 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Press", "Ofir", ""], ["Smith", "Noah A.", ""], ["Lewis", "Mike", ""]]}, {"id": "2012.15833", "submitter": "Xiang Kong", "authors": "Jiatao Gu, Xiang Kong", "title": "Fully Non-autoregressive Neural Machine Translation: Tricks of the Trade", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully non-autoregressive neural machine translation (NAT) is proposed to\nsimultaneously predict tokens with single forward of neural networks, which\nsignificantly reduces the inference latency at the expense of quality drop\ncompared to the Transformer baseline. In this work, we target on closing the\nperformance gap while maintaining the latency advantage. We first inspect the\nfundamental issues of fully NAT models, and adopt dependency reduction in the\nlearning space of output tokens as the basic guidance. Then, we revisit methods\nin four different aspects that have been proven effective for improving NAT\nmodels, and carefully combine these techniques with necessary modifications.\nOur extensive experiments on three translation benchmarks show that the\nproposed system achieves the new state-of-the-art results for fully NAT models,\nand obtains comparable performance with the autoregressive and iterative NAT\nsystems. For instance, one of the proposed models achieves 27.49 BLEU points on\nWMT14 En-De with approximately 16.5X speed up at inference time.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:52:59 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Gu", "Jiatao", ""], ["Kong", "Xiang", ""]]}, {"id": "2012.15837", "submitter": "Rajkumar Pujari", "authors": "Rajkumar Pujari and Dan Goldwasser", "title": "Using Natural Language Relations between Answer Choices for Machine\n  Comprehension", "comments": "Published at NAACL-HLT 2019. This version has link to code\n  repository. 6 pages, 3 figures & 2 tables", "journal-ref": "Proceedings of the 2019 Conference of the North {A}merican Chapter\n  of the Association for Computational Linguistics: Human Language\n  Technologies, Volume 1 (Long and Short Papers)", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When evaluating an answer choice for Reading Comprehension task, other answer\nchoices available for the question and the answers of related questions about\nthe same paragraph often provide valuable information. In this paper, we\npropose a method to leverage the natural language relations between the answer\nchoices, such as entailment and contradiction, to improve the performance of\nmachine comprehension. We use a stand-alone question answering (QA) system to\nperform QA task and a Natural Language Inference (NLI) system to identify the\nrelations between the choice pairs. Then we perform inference using an Integer\nLinear Programming (ILP)-based relational framework to re-evaluate the\ndecisions made by the standalone QA system in light of the relations identified\nby the NLI system. We also propose a multitask learning model that learns both\nthe tasks jointly.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:55:30 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Pujari", "Rajkumar", ""], ["Goldwasser", "Dan", ""]]}, {"id": "2012.15856", "submitter": "Qinyuan Ye", "authors": "Qinyuan Ye, Belinda Z. Li, Sinong Wang, Benjamin Bolte, Hao Ma,\n  Wen-tau Yih, Xiang Ren, Madian Khabsa", "title": "Studying Strategically: Learning to Mask for Closed-book QA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Closed-book question-answering (QA) is a challenging task that requires a\nmodel to directly answer questions without access to external knowledge. It has\nbeen shown that directly fine-tuning pre-trained language models with\n(question, answer) examples yields surprisingly competitive performance, which\nis further improved upon through adding an intermediate pre-training stage\nbetween general pre-training and fine-tuning. Prior work used a heuristic\nduring this intermediate stage, whereby named entities and dates are masked,\nand the model is trained to recover these tokens. In this paper, we aim to\nlearn the optimal masking strategy for the intermediate pre-training stage. We\nfirst train our masking policy to extract spans that are likely to be tested,\nusing supervision from the downstream task itself, then deploy the learned\npolicy during intermediate pre-training. Thus, our policy packs task-relevant\nknowledge into the parameters of a language model. Our approach is particularly\neffective on TriviaQA, outperforming strong heuristics when used to pre-train\nBART.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:59:08 GMT"}, {"version": "v2", "created": "Fri, 1 Jan 2021 18:50:48 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Ye", "Qinyuan", ""], ["Li", "Belinda Z.", ""], ["Wang", "Sinong", ""], ["Bolte", "Benjamin", ""], ["Ma", "Hao", ""], ["Yih", "Wen-tau", ""], ["Ren", "Xiang", ""], ["Khabsa", "Madian", ""]]}, {"id": "2012.15859", "submitter": "Seraphina Goldfarb-Tarrant", "authors": "Seraphina Goldfarb-Tarrant, Rebecca Marchant, Ricardo Mu\\~noz Sanchez,\n  Mugdha Pandya, Adam Lopez", "title": "Intrinsic Bias Metrics Do Not Correlate with Application Bias", "comments": "In Proceedings of ACL 2021, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Natural Language Processing (NLP) systems learn harmful societal biases that\ncause them to amplify inequality as they are deployed in more and more\nsituations. To guide efforts at debiasing these systems, the NLP community\nrelies on a variety of metrics that quantify bias in models. Some of these\nmetrics are intrinsic, measuring bias in word embedding spaces, and some are\nextrinsic, measuring bias in downstream tasks that the word embeddings enable.\nDo these intrinsic and extrinsic metrics correlate with each other? We compare\nintrinsic and extrinsic metrics across hundreds of trained models covering\ndifferent tasks and experimental conditions. Our results show no reliable\ncorrelation between these metrics that holds in all scenarios across tasks and\nlanguages. We urge researchers working on debiasing to focus on extrinsic\nmeasures of bias, and to make using these measures more feasible via creation\nof new challenge sets and annotated test data. To aid this effort, we release\ncode, a new intrinsic metric, and an annotated test set focused on gender bias\nin hate speech.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:59:44 GMT"}, {"version": "v2", "created": "Sat, 2 Jan 2021 11:41:05 GMT"}, {"version": "v3", "created": "Wed, 2 Jun 2021 10:14:20 GMT"}, {"version": "v4", "created": "Sat, 5 Jun 2021 11:07:49 GMT"}, {"version": "v5", "created": "Tue, 8 Jun 2021 15:03:11 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Goldfarb-Tarrant", "Seraphina", ""], ["Marchant", "Rebecca", ""], ["Sanchez", "Ricardo Mu\u00f1oz", ""], ["Pandya", "Mugdha", ""], ["Lopez", "Adam", ""]]}]