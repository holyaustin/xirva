[{"id": "0812.3070", "submitter": "Alex Arenas", "authors": "J. Borge, A. Arenas", "title": "A Computational Model to Disentangle Semantic Information Embedded in\n  Word Association Norms", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI physics.data-an physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two well-known databases of semantic relationships between pairs of words\nused in psycholinguistics, feature-based and association-based, are studied as\ncomplex networks. We propose an algorithm to disentangle feature based\nrelationships from free association semantic networks. The algorithm uses the\nrich topology of the free association semantic network to produce a new set of\nrelationships between words similar to those observed in feature production\nnorms.\n", "versions": [{"version": "v1", "created": "Tue, 16 Dec 2008 14:24:23 GMT"}], "update_date": "2008-12-17", "authors_parsed": [["Borge", "J.", ""], ["Arenas", "A.", ""]]}, {"id": "0812.4446", "submitter": "Peter Turney", "authors": "Peter D. Turney (National Research Council of Canada)", "title": "The Latent Relation Mapping Engine: Algorithm and Experiments", "comments": "related work available at http://purl.org/peter.turney/", "journal-ref": "Journal of Artificial Intelligence Research, (2008), 33, 615-655", "doi": "10.1613/jair.2693", "report-no": "NRC-50738", "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many AI researchers and cognitive scientists have argued that analogy is the\ncore of cognition. The most influential work on computational modeling of\nanalogy-making is Structure Mapping Theory (SMT) and its implementation in the\nStructure Mapping Engine (SME). A limitation of SME is the requirement for\ncomplex hand-coded representations. We introduce the Latent Relation Mapping\nEngine (LRME), which combines ideas from SME and Latent Relational Analysis\n(LRA) in order to remove the requirement for hand-coded representations. LRME\nbuilds analogical mappings between lists of words, using a large corpus of raw\ntext to automatically discover the semantic relations among the words. We\nevaluate LRME on a set of twenty analogical mapping problems, ten based on\nscientific analogies and ten based on common metaphors. LRME achieves\nhuman-level performance on the twenty problems. We compare LRME with a variety\nof alternative approaches and find that they are not able to reach the same\nlevel of performance.\n", "versions": [{"version": "v1", "created": "Tue, 23 Dec 2008 20:08:53 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Turney", "Peter D.", "", "National Research Council of Canada"]]}]