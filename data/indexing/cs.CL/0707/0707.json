[{"id": "0707.0895", "submitter": "Damian H. Zanette", "authors": "Damian H. Zanette", "title": "Segmentation and Context of Literary and Musical Sequences", "comments": "To appear in Complex Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL physics.data-an", "license": null, "abstract": "  We test a segmentation algorithm, based on the calculation of the\nJensen-Shannon divergence between probability distributions, to two symbolic\nsequences of literary and musical origin. The first sequence represents the\nsuccessive appearance of characters in a theatrical play, and the second\nrepresents the succession of tones from the twelve-tone scale in a keyboard\nsonata. The algorithm divides the sequences into segments of maximal\ncompositional divergence between them. For the play, these segments are related\nto changes in the frequency of appearance of different characters and in the\ngeographical setting of the action. For the sonata, the segments correspond to\ntonal domains and reveal in detail the characteristic tonal progression of such\nkind of musical composition.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2007 01:45:05 GMT"}], "update_date": "2007-07-09", "authors_parsed": [["Zanette", "Damian H.", ""]]}, {"id": "0707.1913", "submitter": "Daniel Lemire", "authors": "Owen Kaser, Daniel Lemire", "title": "Removing Manually-Generated Boilerplate from Electronic Texts:\n  Experiments with Project Gutenberg e-Books", "comments": "short version appeared in CASCON 2007 proceedings, available from\n  http://portal.acm.org/citation.cfm?id=1321246 Source code at\n  https://github.com/lemire/gutenberg-headers", "journal-ref": null, "doi": null, "report-no": "Department of CSAS, UNBSJ Technical Report TR-07-001", "categories": "cs.DL cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative work on unstructured or semi-structured documents, such as in\nliterature corpora or source code, often involves agreed upon templates\ncontaining metadata. These templates are not consistent across users and over\ntime. Rule-based parsing of these templates is expensive to maintain and tends\nto fail as new documents are added. Statistical techniques based on frequent\noccurrences have the potential to identify automatically a large fraction of\nthe templates, thus reducing the burden on the programmers. We investigate the\ncase of the Project Gutenberg corpus, where most documents are in ASCII format\nwith preambles and epilogues that are often copied and pasted or manually\ntyped. We show that a statistical approach can solve most cases though some\ndocuments require knowledge of English. We also survey various technical\nsolutions that make our approach applicable to large data sets.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2007 02:30:10 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2009 19:57:15 GMT"}, {"version": "v3", "created": "Mon, 22 Aug 2016 21:02:58 GMT"}], "update_date": "2016-08-24", "authors_parsed": [["Kaser", "Owen", ""], ["Lemire", "Daniel", ""]]}, {"id": "0707.3269", "submitter": "Laurent Romary", "authors": "Laurent Romary (INRIA Lorraine - LORIA), Nancy Ide (INRIA Lorraine -\n  LORIA)", "title": "International Standard for a Linguistic Annotation Framework", "comments": null, "journal-ref": "Natural Language Engineering 10, 3-4 (09/2004) 211-225", "doi": null, "report-no": null, "categories": "cs.CL", "license": null, "abstract": "  This paper describes the Linguistic Annotation Framework under development\nwithin ISO TC37 SC4 WG1. The Linguistic Annotation Framework is intended to\nserve as a basis for harmonizing existing language resources as well as\ndeveloping new ones.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2007 15:24:48 GMT"}], "update_date": "2007-07-24", "authors_parsed": [["Romary", "Laurent", "", "INRIA Lorraine - LORIA"], ["Ide", "Nancy", "", "INRIA Lorraine -\n  LORIA"]]}, {"id": "0707.3270", "submitter": "Laurent Romary", "authors": "Laurent Romary (INRIA Lorraine - LORIA), Nancy Ide, Adam Kilgarriff", "title": "A Formal Model of Dictionary Structure and Content", "comments": null, "journal-ref": "Dans Euralex 2000 Euralex 2000, Stuttgart : Allemagne (2000)", "doi": null, "report-no": null, "categories": "cs.CL", "license": null, "abstract": "  We show that a general model of lexical information conforms to an abstract\nmodel that reflects the hierarchy of information found in a typical dictionary\nentry. We show that this model can be mapped into a well-formed XML document,\nand how the XSL transformation language can be used to implement a semantics\ndefined over the abstract model to enable extraction and manipulation of the\ninformation in any format.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2007 15:25:27 GMT"}], "update_date": "2007-07-24", "authors_parsed": [["Romary", "Laurent", "", "INRIA Lorraine - LORIA"], ["Ide", "Nancy", ""], ["Kilgarriff", "Adam", ""]]}, {"id": "0707.3559", "submitter": "Wilson Wong", "authors": "Wilson Wong", "title": "Practical Approach to Knowledge-based Question Answering with Natural\n  Language Understanding and Advanced Reasoning", "comments": "Master of Science thesis, National Technical University College of\n  Malaysia, 2005", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.IR", "license": null, "abstract": "  This research hypothesized that a practical approach in the form of a\nsolution framework known as Natural Language Understanding and Reasoning for\nIntelligence (NaLURI), which combines full-discourse natural language\nunderstanding, powerful representation formalism capable of exploiting\nontological information and reasoning approach with advanced features, will\nsolve the following problems without compromising practicality factors: 1)\nrestriction on the nature of question and response, and 2) limitation to scale\nacross domains and to real-life natural language text.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2007 14:30:27 GMT"}], "update_date": "2007-07-25", "authors_parsed": [["Wong", "Wilson", ""]]}, {"id": "0707.3972", "submitter": "Ted Pedersen", "authors": "Ted Pedersen", "title": "Learning Probabilistic Models of Word Sense Disambiguation", "comments": "195 pages", "journal-ref": "PhD dissertation, May 1998, Department of Computer Science and\n  Engineering, Southern Methodist University", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": null, "abstract": "  This dissertation presents several new methods of supervised and unsupervised\nlearning of word sense disambiguation models. The supervised methods focus on\nperforming model searches through a space of probabilistic models, and the\nunsupervised methods rely on the use of Gibbs Sampling and the Expectation\nMaximization (EM) algorithm. In both the supervised and unsupervised case, the\nNaive Bayesian model is found to perform well. An explanation for this success\nis presented in terms of learning rates and bias-variance decompositions.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2007 17:02:40 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Pedersen", "Ted", ""]]}]