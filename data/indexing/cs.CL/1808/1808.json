[{"id": "1808.00054", "submitter": "Michael Hahn", "authors": "Michael Hahn, Frank Keller", "title": "Modeling Task Effects in Human Reading with Neural Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans read by making a sequence of fixations and saccades. They often skip\nwords, without apparent detriment to understanding. We offer a novel\nexplanation for skipping: readers optimize a tradeoff between performing a\nlanguage-related task and fixating as few words as possible. We propose a\nneural architecture that combines an attention module (deciding whether to skip\nwords) and a task module (memorizing the input). We show that our model\npredicts human skipping behavior, while also modeling reading times well, even\nthough it skips 40% of the input. A key prediction of our model is that\ndifferent reading tasks should result in different skipping behaviors. We\nconfirm this prediction in an eye-tracking experiment in which participants\nanswers questions about a text. We are able to capture these experimental\nresults using the our model, replacing the memorization module with a task\nmodule that performs neural question answering.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 20:02:08 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 17:44:53 GMT"}, {"version": "v3", "created": "Fri, 25 Jun 2021 08:05:05 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Hahn", "Michael", ""], ["Keller", "Frank", ""]]}, {"id": "1808.00103", "submitter": "Paul Sheridan", "authors": "Paul Sheridan, Mikael Onsj\\\"o, Claudia Becerra, Sergio Jimenez, and\n  George Due\\~nas", "title": "An Ontology-Based Recommender System with an Application to the Star\n  Trek Television Franchise", "comments": "25 pages, 6 figures, 5 tables, minor revisions", "journal-ref": "Future Internet 2019, 11(9), 182", "doi": "10.3390/fi11090182", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering based recommender systems have proven to be extremely\nsuccessful in settings where user preference data on items is abundant.\nHowever, collaborative filtering algorithms are hindered by their weakness\nagainst the item cold-start problem and general lack of interpretability.\nOntology-based recommender systems exploit hierarchical organizations of users\nand items to enhance browsing, recommendation, and profile construction. While\nontology-based approaches address the shortcomings of their collaborative\nfiltering counterparts, ontological organizations of items can be difficult to\nobtain for items that mostly belong to the same category (e.g., television\nseries episodes). In this paper, we present an ontology-based recommender\nsystem that integrates the knowledge represented in a large ontology of\nliterary themes to produce fiction content recommendations. The main novelty of\nthis work is an ontology-based method for computing similarities between items\nand its integration with the classical Item-KNN (K-nearest neighbors)\nalgorithm. As a study case, we evaluated the proposed method against other\napproaches by performing the classical rating prediction task on a collection\nof Star Trek television series episodes in an item cold-start scenario. This\ntransverse evaluation provides insights into the utility of different\ninformation resources and methods for the initial stages of recommender system\ndevelopment. We found our proposed method to be a convenient alternative to\ncollaborative filtering approaches for collections of mostly similar items,\nparticularly when other content-based approaches are not applicable or\notherwise unavailable. Aside from the new methods, this paper contributes a\ntestbed for future research and an online framework to collaboratively extend\nthe ontology of literary themes to cover other narrative content.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 22:53:30 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 00:34:39 GMT"}, {"version": "v3", "created": "Fri, 23 Aug 2019 00:20:35 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Sheridan", "Paul", ""], ["Onsj\u00f6", "Mikael", ""], ["Becerra", "Claudia", ""], ["Jimenez", "Sergio", ""], ["Due\u00f1as", "George", ""]]}, {"id": "1808.00179", "submitter": "Mark Fishel", "authors": "Elizaveta Korotkova, Maksym Del, Mark Fishel", "title": "Monolingual and Cross-lingual Zero-shot Style Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We introduce the task of zero-shot style transfer between different\nlanguages. Our training data includes multilingual parallel corpora, but does\nnot contain any parallel sentences between styles, similarly to the recent\nprevious work. We propose a unified multilingual multi-style machine\ntranslation system design, that allows to perform zero-shot style conversions\nduring inference; moreover, it does so both monolingually and cross-lingually.\nOur model allows to increase the presence of dissimilar styles in corpus by up\nto 3 times, easily learns to operate with various contractions, and provides\nreasonable lexicon swaps as we see from manual evaluation.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 06:12:49 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Korotkova", "Elizaveta", ""], ["Del", "Maksym", ""], ["Fishel", "Mark", ""]]}, {"id": "1808.00265", "submitter": "Yundong Zhang", "authors": "Yundong Zhang, Juan Carlos Niebles, Alvaro Soto", "title": "Interpretable Visual Question Answering by Visual Grounding from\n  Attention Supervision Mining", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key aspect of VQA models that are interpretable is their ability to ground\ntheir answers to relevant regions in the image. Current approaches with this\ncapability rely on supervised learning and human annotated groundings to train\nattention mechanisms inside the VQA architecture. Unfortunately, obtaining\nhuman annotations specific for visual grounding is difficult and expensive. In\nthis work, we demonstrate that we can effectively train a VQA architecture with\ngrounding supervision that can be automatically obtained from available region\ndescriptions and object annotations. We also show that our model trained with\nthis mined supervision generates visual groundings that achieve a higher\ncorrelation with respect to manually-annotated groundings, meanwhile achieving\nstate-of-the-art VQA accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 11:06:08 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Zhang", "Yundong", ""], ["Niebles", "Juan Carlos", ""], ["Soto", "Alvaro", ""]]}, {"id": "1808.00300", "submitter": "Mateusz Malinowski", "authors": "Mateusz Malinowski and Carl Doersch and Adam Santoro and Peter\n  Battaglia", "title": "Learning Visual Question Answering by Bootstrapping Hard Attention", "comments": "ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanisms in biological perception are thought to select subsets\nof perceptual information for more sophisticated processing which would be\nprohibitive to perform on all sensory inputs. In computer vision, however,\nthere has been relatively little exploration of hard attention, where some\ninformation is selectively ignored, in spite of the success of soft attention,\nwhere information is re-weighted and aggregated, but never filtered out. Here,\nwe introduce a new approach for hard attention and find it achieves very\ncompetitive performance on a recently-released visual question answering\ndatasets, equalling and in some cases surpassing similar soft attention\narchitectures while entirely ignoring some features. Even though the hard\nattention mechanism is thought to be non-differentiable, we found that the\nfeature magnitudes correlate with semantic relevance, and provide a useful\nsignal for our mechanism's attentional selection criterion. Because hard\nattention selects important features of the input information, it can also be\nmore efficient than analogous soft attention mechanisms. This is especially\nimportant for recent approaches that use non-local pairwise operations, whereby\ncomputational and memory costs are quadratic in the size of the set of\nfeatures.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 12:39:43 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Malinowski", "Mateusz", ""], ["Doersch", "Carl", ""], ["Santoro", "Adam", ""], ["Battaglia", "Peter", ""]]}, {"id": "1808.00423", "submitter": "Fabrice Daniel", "authors": "Marc Velay and Fabrice Daniel", "title": "Seq2Seq and Multi-Task Learning for joint intent and content extraction\n  for domain specific interpreters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study evaluates the performances of an LSTM network for detecting and\nextracting the intent and content of com- mands for a financial chatbot. It\npresents two techniques, sequence to sequence learning and Multi-Task Learning,\nwhich might improve on the previous task.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 17:04:48 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Velay", "Marc", ""], ["Daniel", "Fabrice", ""]]}, {"id": "1808.00491", "submitter": "Jan Niehues", "authors": "Jan Niehues, Ngoc-Quan Pham, Thanh-Le Ha, Matthias Sperber and Alex\n  Waibel", "title": "Low-Latency Neural Speech Translation", "comments": "5 Pages; Interspeech", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through the development of neural machine translation, the quality of machine\ntranslation systems has been improved significantly. By exploiting advancements\nin deep learning, systems are now able to better approximate the complex\nmapping from source sentences to target sentences. But with this ability, new\nchallenges also arise. An example is the translation of partial sentences in\nlow-latency speech translation. Since the model has only seen complete\nsentences in training, it will always try to generate a complete sentence,\nthough the input may only be a partial sentence. We show that NMT systems can\nbe adapted to scenarios where no task-specific training data is available.\nFurthermore, this is possible without losing performance on the original\ntraining data. We achieve this by creating artificial data and by using\nmulti-task learning. After adaptation, we are able to reduce the number of\ncorrections displayed during incremental output construction by 45%, without a\ndecrease in translation quality.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 18:17:05 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Niehues", "Jan", ""], ["Pham", "Ngoc-Quan", ""], ["Ha", "Thanh-Le", ""], ["Sperber", "Matthias", ""], ["Waibel", "Alex", ""]]}, {"id": "1808.00521", "submitter": "Emre Yilmaz", "authors": "Emre Y{\\i}lmaz, Henk van den Heuvel and David A. van Leeuwen", "title": "Code-Switching Detection with Data-Augmented Acoustic and Language\n  Models", "comments": "Accepted for publication at SLTU 2018. arXiv admin note: substantial\n  text overlap with arXiv:1807.10945", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the code-switching detection performance of a\ncode-switching (CS) automatic speech recognition (ASR) system with\ndata-augmented acoustic and language models. We focus on the recognition of\nFrisian-Dutch radio broadcasts where one of the mixed languages, namely\nFrisian, is under-resourced. Recently, we have explored how the acoustic\nmodeling (AM) can benefit from monolingual speech data belonging to the\nhigh-resourced mixed language. For this purpose, we have trained\nstate-of-the-art AMs on a significantly increased amount of CS speech by\napplying automatic transcription and monolingual Dutch speech. Moreover, we\nhave improved the language model (LM) by creating CS text in various ways\nincluding text generation using recurrent LMs trained on existing CS text.\nMotivated by the significantly improved CS ASR performance, we delve into the\nCS detection performance of the same ASR system in this work by reporting CS\ndetection accuracies together with a detailed detection error analysis.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2018 15:16:33 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Y\u0131lmaz", "Emre", ""], ["Heuvel", "Henk van den", ""], ["van Leeuwen", "David A.", ""]]}, {"id": "1808.00525", "submitter": "Jinseok Kim", "authors": "Jinseok Kim and Jenna Kim", "title": "The impact of imbalanced training data on machine learning for author\n  name disambiguation", "comments": "17 pages, 3 figures, and 3 tables", "journal-ref": "Kim, J. & Kim, J. (2018). The impact of imbalanced training data\n  on machine learning for author name disambiguation. Scientometrics", "doi": "10.1007/s11192-018-2865-9", "report-no": null, "categories": "cs.IR cs.CL cs.DL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In supervised machine learning for author name disambiguation, negative\ntraining data are often dominantly larger than positive training data. This\npaper examines how the ratios of negative to positive training data can affect\nthe performance of machine learning algorithms to disambiguate author names in\nbibliographic records. On multiple labeled datasets, three classifiers -\nLogistic Regression, Na\\\"ive Bayes, and Random Forest - are trained through\nrepresentative features such as coauthor names, and title words extracted from\nthe same training data but with various positive-negative training data ratios.\nResults show that increasing negative training data can improve disambiguation\nperformance but with a few percent of performance gains and sometimes degrade\nit. Logistic Regression and Na\\\"ive Bayes learn optimal disambiguation models\neven with a base ratio (1:1) of positive and negative training data. Also, the\nperformance improvement by Random Forest tends to quickly saturate roughly\nafter 1:10 ~ 1:15. These findings imply that contrary to the common practice\nusing all training data, name disambiguation algorithms can be trained using\npart of negative training data without degrading much disambiguation\nperformance while increasing computational efficiency. This study calls for\nmore attention from author name disambiguation scholars to methods for machine\nlearning from imbalanced data.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 14:29:27 GMT"}, {"version": "v2", "created": "Fri, 3 Aug 2018 02:59:12 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Kim", "Jinseok", ""], ["Kim", "Jenna", ""]]}, {"id": "1808.00563", "submitter": "Anirudh Raju", "authors": "Anirudh Raju, Sankaran Panchapagesan, Xing Liu, Arindam Mandal, Nikko\n  Strom", "title": "Data Augmentation for Robust Keyword Spotting under Playback\n  Interference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate on-device keyword spotting (KWS) with low false accept and false\nreject rate is crucial to customer experience for far-field voice control of\nconversational agents. It is particularly challenging to maintain low false\nreject rate in real world conditions where there is (a) ambient noise from\nexternal sources such as TV, household appliances, or other speech that is not\ndirected at the device (b) imperfect cancellation of the audio playback from\nthe device, resulting in residual echo, after being processed by the Acoustic\nEcho Cancellation (AEC) system. In this paper, we propose a data augmentation\nstrategy to improve keyword spotting performance under these challenging\nconditions. The training set audio is artificially corrupted by mixing in music\nand TV/movie audio, at different signal to interference ratios. Our results\nshow that we get around 30-45% relative reduction in false reject rates, at a\nrange of false alarm rates, under audio playback from such devices.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 21:00:50 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Raju", "Anirudh", ""], ["Panchapagesan", "Sankaran", ""], ["Liu", "Xing", ""], ["Mandal", "Arindam", ""], ["Strom", "Nikko", ""]]}, {"id": "1808.00639", "submitter": "Zhehuai Chen", "authors": "Zhehuai Chen and Yanmin Qian and Kai Yu", "title": "Sequence Discriminative Training for Deep Learning based Acoustic\n  Keyword Spotting", "comments": "accepted by Speech Communication, 08/02/2018", "journal-ref": "Speech Communication, vol. 102, 100-111, 2018", "doi": "10.1016/j.specom.2018.08.001", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech recognition is a sequence prediction problem. Besides employing\nvarious deep learning approaches for framelevel classification, sequence-level\ndiscriminative training has been proved to be indispensable to achieve the\nstate-of-the-art performance in large vocabulary continuous speech recognition\n(LVCSR). However, keyword spotting (KWS), as one of the most common speech\nrecognition tasks, almost only benefits from frame-level deep learning due to\nthe difficulty of getting competing sequence hypotheses. The few studies on\nsequence discriminative training for KWS are limited for fixed vocabulary or\nLVCSR based methods and have not been compared to the state-of-the-art deep\nlearning based KWS approaches. In this paper, a sequence discriminative\ntraining framework is proposed for both fixed vocabulary and unrestricted\nacoustic KWS. Sequence discriminative training for both sequence-level\ngenerative and discriminative models are systematically investigated. By\nintroducing word-independent phone lattices or non-keyword blank symbols to\nconstruct competing hypotheses, feasible and efficient sequence discriminative\ntraining approaches are proposed for acoustic KWS. Experiments showed that the\nproposed approaches obtained consistent and significant improvement in both\nfixed vocabulary and unrestricted KWS tasks, compared to previous frame-level\ndeep learning based acoustic KWS methods.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 02:26:53 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Chen", "Zhehuai", ""], ["Qian", "Yanmin", ""], ["Yu", "Kai", ""]]}, {"id": "1808.00665", "submitter": "Junichi Yamagishi", "authors": "Hieu-Thi Luong, Xin Wang, Junichi Yamagishi, Nobuyuki Nishizawa", "title": "Investigating accuracy of pitch-accent annotations in neural\n  network-based speech synthesis and denoising effects", "comments": "Accepted for Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigated the impact of noisy linguistic features on the performance of\na Japanese speech synthesis system based on neural network that uses WaveNet\nvocoder. We compared an ideal system that uses manually corrected linguistic\nfeatures including phoneme and prosodic information in training and test sets\nagainst a few other systems that use corrupted linguistic features. Both\nsubjective and objective results demonstrate that corrupted linguistic\nfeatures, especially those in the test set, affected the ideal system's\nperformance significantly in a statistical sense due to a mismatched condition\nbetween the training and test sets. Interestingly, while an utterance-level\nTuring test showed that listeners had a difficult time differentiating\nsynthetic speech from natural speech, it further indicated that adding noise to\nthe linguistic features in the training set can partially reduce the effect of\nthe mismatch, regularize the model, and help the system perform better when\nlinguistic features of the test set are noisy.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 04:25:30 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Luong", "Hieu-Thi", ""], ["Wang", "Xin", ""], ["Yamagishi", "Junichi", ""], ["Nishizawa", "Nobuyuki", ""]]}, {"id": "1808.00687", "submitter": "Zhehuai Chen", "authors": "Zhehuai Chen", "title": "Linguistic Search Optimization for Deep Learning Based LVCSR", "comments": "accepted by Doctoral Consortium, INTERSPEECH 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep learning based large vocabulary con- tinuous speech\nrecognition (LVCSR) invoke growing demands in large scale speech transcription.\nThe inference process of a speech recognizer is to find a sequence of labels\nwhose corresponding acoustic and language models best match the input feature\n[1]. The main computation includes two stages: acoustic model (AM) inference\nand linguistic search (weighted finite-state transducer, WFST). Large\ncomputational overheads of both stages hamper the wide application of LVCSR.\nBenefit from stronger classifiers, deep learning, and more powerful computing\ndevices, we propose general ideas and some initial trials to solve these\nfundamental problems.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 06:47:23 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Chen", "Zhehuai", ""]]}, {"id": "1808.00694", "submitter": "Jyoti Jha", "authors": "Jyoti Jha, Sreekavitha Parupalli, Navjyoti Singh", "title": "OntoSenseNet: A Verb-Centric Ontological Resource for Indian Languages", "comments": "14 pages, 8 tables, 2 figures", "journal-ref": null, "doi": "10.13140/RG.2.2.29641.03687", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following approaches for understanding lexical meaning developed by Yaska,\nPatanjali and Bhartrihari from Indian linguistic traditions and extending\napproaches developed by Leibniz and Brentano in the modern times, a framework\nof formal ontology of language was developed. This framework proposes that\nmeaning of words are in-formed by intrinsic and extrinsic ontological\nstructures. The paper aims to capture such intrinsic and extrinsic meanings of\nwords for two major Indian languages, namely, Hindi and Telugu. Parts-of-speech\nhave been rendered into sense-types and sense-classes. Using them we have\ndeveloped a gold- standard annotated lexical resource to support semantic\nunderstanding of a language. The resource has collection of Hindi and Telugu\nlexicons, which has been manually annotated by native speakers of the languages\nfollowing our annotation guidelines. Further, the resource was utilised to\nderive adverbial sense-class distribution of verbs and karaka-verb sense- type\ndistribution. Different corpora (news, novels) were compared using verb\nsense-types distribution. Word Embedding was used as an aid for the enrichment\nof the resource. This is a work in progress that aims at lexical coverage of\nlanguage extensively.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 07:18:55 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Jha", "Jyoti", ""], ["Parupalli", "Sreekavitha", ""], ["Singh", "Navjyoti", ""]]}, {"id": "1808.00926", "submitter": "Aleksander Smywi\\'nski-Pohl", "authors": "Micha{\\l} Ptaszy\\'nski and Gniewosz Leliwa and Mateusz Piech and\n  Aleksander Smywi\\'nski-Pohl", "title": "Cyberbullying Detection -- Technical Report 2/2018, Department of\n  Computer Science AGH, University of Science and Technology", "comments": null, "journal-ref": null, "doi": null, "report-no": "2/2018 CS AGH", "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The research described in this paper concerns automatic cyberbullying\ndetection in social media. There are two goals to achieve: building a gold\nstandard cyberbullying detection dataset and measuring the performance of the\nSamurai cyberbullying detection system. The Formspring dataset provided in a\nKaggle competition was re-annotated as a part of the research. The annotation\nprocedure is described in detail and, unlike many other recent data annotation\ninitiatives, does not use Mechanical Turk for finding people willing to perform\nthe annotation. The new annotation compared to the old one seems to be more\ncoherent since all tested cyberbullying detection system performed better on\nthe former. The performance of the Samurai system is compared with 5 commercial\nsystems and one well-known machine learning algorithm, used for classifying\ntextual content, namely Fasttext. It turns out that Samurai scores the best in\nall measures (accuracy, precision and recall), while Fasttext is the\nsecond-best performing algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 17:22:06 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Ptaszy\u0144ski", "Micha\u0142", ""], ["Leliwa", "Gniewosz", ""], ["Piech", "Mateusz", ""], ["Smywi\u0144ski-Pohl", "Aleksander", ""]]}, {"id": "1808.00957", "submitter": "Yash Kumar Lal", "authors": "Vaibhav Kumar, Mrinal Dhar, Dhruv Khattar, Yash Kumar Lal, Abhimanshu\n  Mishra, Manish Shrivastava, Vasudeva Varma", "title": "SWDE : A Sub-Word And Document Embedding Based Engine for Clickbait\n  Detection", "comments": "Accepted at SIGIR 2018 as Computational Surprise in Information\n  Retrieval (CompS) Workshop Paper. arXiv admin note: substantial text overlap\n  with arXiv:1710.01507", "journal-ref": "\"SWDE : A Sub-Word And Document Embedding Based Engine for\n  Clickbait Detection\". In Proceedings of SIGIR 2018 Workshop on Computational\n  Surprise in Information Retrieval, Ann Arbor, MI, USA, July 8-12 (CompS'18,\n  SIGIR), 4 pages", "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to expand their reach and increase website ad revenue, media outlets\nhave started using clickbait techniques to lure readers to click on articles on\ntheir digital platform. Having successfully enticed the user to open the\narticle, the article fails to satiate his curiosity serving only to boost\nclick-through rates. Initial methods for this task were dependent on feature\nengineering, which varies with each dataset. Industry systems have relied on an\nexhaustive set of rules to get the job done. Neural networks have barely been\nexplored to perform this task. We propose a novel approach considering\ndifferent textual embeddings of a news headline and the related article. We\ngenerate sub-word level embeddings of the title using Convolutional Neural\nNetworks and use them to train a bidirectional LSTM architecture. An attention\nlayer allows for calculation of significance of each term towards the nature of\nthe post. We also generate Doc2Vec embeddings of the title and article text and\nmodel how they interact, following which it is concatenated with the output of\nthe previous component. Finally, this representation is passed through a neural\nnetwork to obtain a score for the headline. We test our model over 2538 posts\n(having trained it on 17000 records) and achieve an accuracy of 83.49%\noutscoring previous state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 09:02:00 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Kumar", "Vaibhav", ""], ["Dhar", "Mrinal", ""], ["Khattar", "Dhruv", ""], ["Lal", "Yash Kumar", ""], ["Mishra", "Abhimanshu", ""], ["Shrivastava", "Manish", ""], ["Varma", "Vasudeva", ""]]}, {"id": "1808.01160", "submitter": "Adrian {\\L}a\\'ncucki", "authors": "Szymon Malik, Adrian Lancucki, Jan Chorowski", "title": "Efficient Purely Convolutional Text Encoding", "comments": "As accepted to: LaCATODA Workshop, ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we focus on a lightweight convolutional architecture that\ncreates fixed-size vector embeddings of sentences. Such representations are\nuseful for building NLP systems, including conversational agents. Our work\nderives from a recently proposed recursive convolutional architecture for\nauto-encoding text paragraphs at byte level. We propose alternations that\nsignificantly reduce training time, the number of parameters, and improve\nauto-encoding accuracy. Finally, we evaluate the representations created by our\nmodel on tasks from SentEval benchmark suite, and show that it can serve as a\nbetter, yet fairly low-resource alternative to popular bag-of-words embeddings.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2018 11:31:26 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Malik", "Szymon", ""], ["Lancucki", "Adrian", ""], ["Chorowski", "Jan", ""]]}, {"id": "1808.01175", "submitter": "Muhammed Tarik Altuncu", "authors": "M. Tarik Altuncu, Sophia N. Yaliraki, Mauricio Barahona", "title": "Content-driven, unsupervised clustering of news articles through\n  multiscale graph partitioning", "comments": "8 pages; 5 figures; To present at KDD 2018: Data Science, Journalism\n  & Media workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The explosion in the amount of news and journalistic content being generated\nacross the globe, coupled with extended and instantaneous access to information\nthrough online media, makes it difficult and time-consuming to monitor news\ndevelopments and opinion formation in real time. There is an increasing need\nfor tools that can pre-process, analyse and classify raw text to extract\ninterpretable content; specifically, identifying topics and content-driven\ngroupings of articles. We present here such a methodology that brings together\npowerful vector embeddings from Natural Language Processing with tools from\nGraph Theory that exploit diffusive dynamics on graphs to reveal natural\npartitions across scales. Our framework uses a recent deep neural network text\nanalysis methodology (Doc2vec) to represent text in vector form and then\napplies a multi-scale community detection method (Markov Stability) to\npartition a similarity graph of document vectors. The method allows us to\nobtain clusters of documents with similar content, at different levels of\nresolution, in an unsupervised manner. We showcase our approach with the\nanalysis of a corpus of 9,000 news articles published by Vox Media over one\nyear. Our results show consistent groupings of documents according to content\nwithout a priori assumptions about the number or type of clusters to be found.\nThe multilevel clustering reveals a quasi-hierarchy of topics and subtopics\nwith increased intelligibility and improved topic coherence as compared to\nexternal taxonomy services and standard topic detection methods.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2018 12:57:15 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Altuncu", "M. Tarik", ""], ["Yaliraki", "Sophia N.", ""], ["Barahona", "Mauricio", ""]]}, {"id": "1808.01216", "submitter": "Md Shad Akhtar", "authors": "Md Shad Akhtar, Deepanway Ghosal, Asif Ekbal, Pushpak Bhattacharyya,\n  Sadao Kurohashi", "title": "A Multi-task Ensemble Framework for Emotion, Sentiment and Intensity\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, through multi-task ensemble framework we address three\nproblems of emotion and sentiment analysis i.e. \"emotion classification &\nintensity\", \"valence, arousal & dominance for emotion\" and \"valence & arousal}\nfor sentiment\". The underlying problems cover two granularities (i.e.\ncoarse-grained and fine-grained) and a diverse range of domains (i.e. tweets,\nFacebook posts, news headlines, blogs, letters etc.). The ensemble model aims\nto leverage the learned representations of three deep learning models (i.e.\nCNN, LSTM and GRU) and a hand-crafted feature representation for the\npredictions. Experimental results on the benchmark datasets show the efficacy\nof our proposed multi-task ensemble frameworks. We obtain the performance\nimprovement of 2-3 points on an average over single-task systems for most of\nthe problems and domains.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2018 14:58:55 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 06:35:37 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Akhtar", "Md Shad", ""], ["Ghosal", "Deepanway", ""], ["Ekbal", "Asif", ""], ["Bhattacharyya", "Pushpak", ""], ["Kurohashi", "Sadao", ""]]}, {"id": "1808.01371", "submitter": "Nikolai Yakovenko", "authors": "Raul Puri, Robert Kirby, Nikolai Yakovenko and Bryan Catanzaro", "title": "Large Scale Language Modeling: Converging on 40GB of Text in Four Hours", "comments": "8 pages; To appear in High Performance Machine Learning Workshop\n  (HPML) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown how to train Convolutional Neural Networks (CNNs)\nrapidly on large image datasets, then transfer the knowledge gained from these\nmodels to a variety of tasks. Following [Radford 2017], in this work, we\ndemonstrate similar scalability and transfer for Recurrent Neural Networks\n(RNNs) for Natural Language tasks. By utilizing mixed precision arithmetic and\na 32k batch size distributed across 128 NVIDIA Tesla V100 GPUs, we are able to\ntrain a character-level 4096-dimension multiplicative LSTM (mLSTM) for\nunsupervised text reconstruction over 3 epochs of the 40 GB Amazon Reviews\ndataset in four hours. This runtime compares favorably with previous work\ntaking one month to train the same size and configuration for one epoch over\nthe same dataset. Converging large batch RNN models can be challenging. Recent\nwork has suggested scaling the learning rate as a function of batch size, but\nwe find that simply scaling the learning rate as a function of batch size leads\neither to significantly worse convergence or immediate divergence for this\nproblem. We provide a learning rate schedule that allows our model to converge\nwith a 32k batch size. Since our model converges over the Amazon Reviews\ndataset in hours, and our compute requirement of 128 Tesla V100 GPUs, while\nsubstantial, is commercially available, this work opens up large scale\nunsupervised NLP training to most commercial applications and deep learning\nresearchers. A model can be trained over most public or private text datasets\novernight.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2018 21:44:29 GMT"}, {"version": "v2", "created": "Sat, 11 Aug 2018 01:59:23 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Puri", "Raul", ""], ["Kirby", "Robert", ""], ["Yakovenko", "Nikolai", ""], ["Catanzaro", "Bryan", ""]]}, {"id": "1808.01410", "submitter": "Daisy Stanton", "authors": "Daisy Stanton, Yuxuan Wang, RJ Skerry-Ryan", "title": "Predicting Expressive Speaking Style From Text In End-To-End Speech\n  Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global Style Tokens (GSTs) are a recently-proposed method to learn latent\ndisentangled representations of high-dimensional data. GSTs can be used within\nTacotron, a state-of-the-art end-to-end text-to-speech synthesis system, to\nuncover expressive factors of variation in speaking style. In this work, we\nintroduce the Text-Predicted Global Style Token (TP-GST) architecture, which\ntreats GST combination weights or style embeddings as \"virtual\" speaking style\nlabels within Tacotron. TP-GST learns to predict stylistic renderings from text\nalone, requiring neither explicit labels during training nor auxiliary inputs\nfor inference. We show that, when trained on a dataset of expressive speech,\nour system generates audio with more pitch and energy variation than two\nstate-of-the-art baseline models. We further demonstrate that TP-GSTs can\nsynthesize speech with background noise removed, and corroborate these analyses\nwith positive results on human-rated listener preference audiobook tasks.\nFinally, we demonstrate that multi-speaker TP-GST models successfully factorize\nspeaker identity and speaking style. We provide a website with audio samples\nfor each of our findings.\n", "versions": [{"version": "v1", "created": "Sat, 4 Aug 2018 02:21:07 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Stanton", "Daisy", ""], ["Wang", "Yuxuan", ""], ["Skerry-Ryan", "RJ", ""]]}, {"id": "1808.01426", "submitter": "Niantao Xie", "authors": "Niantao Xie, Sujian Li, Huiling Ren, and Qibin Zhai", "title": "Abstractive Summarization Improved by WordNet-based Extractive Sentences", "comments": "12 pages, 2 figures, NLPCC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the seq2seq abstractive summarization models have achieved good\nresults on the CNN/Daily Mail dataset. Still, how to improve abstractive\nmethods with extractive methods is a good research direction, since extractive\nmethods have their potentials of exploiting various efficient features for\nextracting important sentences in one text. In this paper, in order to improve\nthe semantic relevance of abstractive summaries, we adopt the WordNet based\nsentence ranking algorithm to extract the sentences which are most semantically\nto one text. Then, we design a dual attentional seq2seq framework to generate\nsummaries with consideration of the extracted information. At the same time, we\ncombine pointer-generator and coverage mechanisms to solve the problems of\nout-of-vocabulary (OOV) words and duplicate words which exist in the\nabstractive models. Experiments on the CNN/Daily Mail dataset show that our\nmodels achieve competitive performance with the state-of-the-art ROUGE scores.\nHuman evaluations also show that the summaries generated by our models have\nhigh semantic relevance to the original text.\n", "versions": [{"version": "v1", "created": "Sat, 4 Aug 2018 05:03:43 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Xie", "Niantao", ""], ["Li", "Sujian", ""], ["Ren", "Huiling", ""], ["Zhai", "Qibin", ""]]}, {"id": "1808.01535", "submitter": "Huan Song", "authors": "Huan Song, Megan Willi, Jayaraman J. Thiagarajan, Visar Berisha,\n  Andreas Spanias", "title": "Triplet Network with Attention for Speaker Diarization", "comments": "Interspeech2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In automatic speech processing systems, speaker diarization is a crucial\nfront-end component to separate segments from different speakers. Inspired by\nthe recent success of deep neural networks (DNNs) in semantic inferencing,\ntriplet loss-based architectures have been successfully used for this problem.\nHowever, existing work utilizes conventional i-vectors as the input\nrepresentation and builds simple fully connected networks for metric learning,\nthus not fully leveraging the modeling power of DNN architectures. This paper\ninvestigates the importance of learning effective representations from the\nsequences directly in metric learning pipelines for speaker diarization. More\nspecifically, we propose to employ attention models to learn embeddings and the\nmetric jointly in an end-to-end fashion. Experiments are conducted on the\nCALLHOME conversational speech corpus. The diarization results demonstrate\nthat, besides providing a unified model, the proposed approach achieves\nimproved performance when compared against existing approaches.\n", "versions": [{"version": "v1", "created": "Sat, 4 Aug 2018 21:10:03 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Song", "Huan", ""], ["Willi", "Megan", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Berisha", "Visar", ""], ["Spanias", "Andreas", ""]]}, {"id": "1808.01591", "submitter": "Pankaj Gupta", "authors": "Pankaj Gupta and Hinrich Sch\\\"utze", "title": "LISA: Explaining Recurrent Neural Network Judgments via Layer-wIse\n  Semantic Accumulation and Example to Pattern Transformation", "comments": "2018 Conference on Empirical Methods in Natural Language Processing\n  (EMNLP2018) workshop on Analyzing and Interpreting Neural Networks for NLP\n  (BlackBoxNLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are temporal networks and cumulative in\nnature that have shown promising results in various natural language processing\ntasks. Despite their success, it still remains a challenge to understand their\nhidden behavior. In this work, we analyze and interpret the cumulative nature\nof RNN via a proposed technique named as Layer-wIse-Semantic-Accumulation\n(LISA) for explaining decisions and detecting the most likely (i.e., saliency)\npatterns that the network relies on while decision making. We demonstrate (1)\nLISA: \"How an RNN accumulates or builds semantics during its sequential\nprocessing for a given text example and expected response\" (2) Example2pattern:\n\"How the saliency patterns look like for each category in the data according to\nthe network in decision making\". We analyse the sensitiveness of RNNs about\ndifferent inputs to check the increase or decrease in prediction scores and\nfurther extract the saliency patterns learned by the network. We employ two\nrelation classification datasets: SemEval 10 Task 8 and TAC KBP Slot Filling to\nexplain RNN predictions via the LISA and example2pattern.\n", "versions": [{"version": "v1", "created": "Sun, 5 Aug 2018 09:50:47 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Gupta", "Pankaj", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1808.01662", "submitter": "Sebastian Pado", "authors": "Abhijeet Gupta and Gemma Boleda and Sebastian Pado", "title": "Instantiation", "comments": "submitted to Computational Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computational linguistics, a large body of work exists on distributed\nmodeling of lexical relations, focussing largely on lexical relations such as\nhypernymy (scientist -- person) that hold between two categories, as expressed\nby common nouns. In contrast, computational linguistics has paid little\nattention to entities denoted by proper nouns (Marie Curie, Mumbai, ...). These\nhave investigated in detail by the Knowledge Representation and Semantic Web\ncommunities, but generally not with regard to their linguistic properties.\n  Our paper closes this gap by investigating and modeling the lexical relation\nof instantiation, which holds between an entity-denoting and a\ncategory-denoting expression (Marie Curie -- scientist or Mumbai -- city). We\npresent a new, principled dataset for the task of instantiation detection as\nwell as experiments and analyses on this dataset. We obtain the following\nresults: (a), entities belonging to one category form a region in\ndistributional space, but the embedding for the category word is typically\nlocated outside this subspace; (b) it is easy to learn to distinguish entities\nfrom categories from distributional evidence, but due to (a), instantiation\nproper is much harder to learn when using common nouns as representations of\ncategories; (c) this problem can be alleviated by using category\nrepresentations based on entity rather than category word embeddings.\n", "versions": [{"version": "v1", "created": "Sun, 5 Aug 2018 17:47:18 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Gupta", "Abhijeet", ""], ["Boleda", "Gemma", ""], ["Pado", "Sebastian", ""]]}, {"id": "1808.01741", "submitter": "Walid Saba", "authors": "Walid S. Saba", "title": "Logical Semantics and Commonsense Knowledge: Where Did we Go Wrong, and\n  How to Go Forward, Again", "comments": "Ontology, Commonsense Knowledge, Language Understanding, Reasoning,\n  Types, Logical Semantics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue that logical semantics might have faltered due to its failure in\ndistinguishing between two fundamentally very different types of concepts:\nontological concepts, that should be types in a strongly-typed ontology, and\nlogical concepts, that are predicates corresponding to properties of and\nrelations between objects of various ontological types. We will then show that\naccounting for these differences amounts to the integration of lexical and\ncompositional semantics in one coherent framework, and to an embedding in our\nlogical semantics of a strongly-typed ontology that reflects our commonsense\nview of the world and the way we talk about it in ordinary language. We will\nshow that in such a framework a number of challenges in natural language\nsemantics can be adequately and systematically treated.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 06:20:41 GMT"}, {"version": "v2", "created": "Thu, 9 Aug 2018 04:06:20 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Saba", "Walid S.", ""]]}, {"id": "1808.01742", "submitter": "Rezvaneh Rezapour", "authors": "Rezvaneh Rezapour", "title": "Using Linguistic Cues for Analyzing Social Movements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growth of social media usage, social activists try to leverage this\nplatform to raise the awareness related to a social issue and engage the public\nworldwide. The broad use of social media platforms in recent years, made it\neasier for the people to stay up-to-date on the news related to regional and\nworldwide events. While social media, namely Twitter, assists social movements\nto connect with more people and mobilize the movement, traditional media such\nas news articles help in spreading the news related to the events in a broader\naspect. In this study, we analyze linguistic features and cues, such as\nindividualism vs. pluralism, sentiment and emotion to examine the relationship\nbetween the medium and discourse over time. We conduct this work in a specific\napplication context, the \"Black Lives Matter\" (BLM) movement, and compare\ndiscussions related to this event in social media vs. news articles.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 06:22:17 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Rezapour", "Rezvaneh", ""]]}, {"id": "1808.01843", "submitter": "Yinglong Ma", "authors": "Yinglong Ma, Peng Zhang and Jiangang Ma", "title": "An Efficient Approach to Learning Chinese Judgment Document Similarity\n  Based on Knowledge Summarization", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A previous similar case in common law systems can be used as a reference with\nrespect to the current case such that identical situations can be treated\nsimilarly in every case. However, current approaches for judgment document\nsimilarity computation failed to capture the core semantics of judgment\ndocuments and therefore suffer from lower accuracy and higher computation\ncomplexity. In this paper, a knowledge block summarization based machine\nlearning approach is proposed to compute the semantic similarity of Chinese\njudgment documents. By utilizing domain ontologies for judgment documents, the\ncore semantics of Chinese judgment documents is summarized based on knowledge\nblocks. Then the WMD algorithm is used to calculate the similarity between\nknowledge blocks. At last, the related experiments were made to illustrate that\nour approach is very effective and efficient in achieving higher accuracy and\nfaster computation speed in comparison with the traditional approaches.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 12:24:19 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Ma", "Yinglong", ""], ["Zhang", "Peng", ""], ["Ma", "Jiangang", ""]]}, {"id": "1808.01916", "submitter": "Murali Karthick Baskar", "authors": "Murali Karthick Baskar, Martin Karafiat, Lukas Burget, Karel Vesely,\n  Frantisek Grezl and Jan Honza Cernocky", "title": "Residual Memory Networks: Feed-forward approach to learn long temporal\n  dependencies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep recurrent neural network (RNN) architectures is complicated due\nto the increased network complexity. This disrupts the learning of higher order\nabstracts using deep RNN. In case of feed-forward networks training deep\nstructures is simple and faster while learning long-term temporal information\nis not possible. In this paper we propose a residual memory neural network\n(RMN) architecture to model short-time dependencies using deep feed-forward\nlayers having residual and time delayed connections. The residual connection\npaves way to construct deeper networks by enabling unhindered flow of gradients\nand the time delay units capture temporal information with shared weights. The\nnumber of layers in RMN signifies both the hierarchical processing depth and\ntemporal depth. The computational complexity in training RMN is significantly\nless when compared to deep recurrent networks. RMN is further extended as\nbi-directional RMN (BRMN) to capture both past and future information.\nExperimental analysis is done on AMI corpus to substantiate the capability of\nRMN in learning long-term information and hierarchical information. Recognition\nperformance of RMN trained with 300 hours of Switchboard corpus is compared\nwith various state-of-the-art LVCSR systems. The results indicate that RMN and\nBRMN gains 6 % and 3.8 % relative improvement over LSTM and BLSTM networks.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 14:00:40 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Baskar", "Murali Karthick", ""], ["Karafiat", "Martin", ""], ["Burget", "Lukas", ""], ["Vesely", "Karel", ""], ["Grezl", "Frantisek", ""], ["Cernocky", "Jan Honza", ""]]}, {"id": "1808.01935", "submitter": "Yuanbo Hou", "authors": "Yuanbo Hou, Qiuqiang Kong and Shengchen Li", "title": "Audio Tagging With Connectionist Temporal Classification Model Using\n  Sequential Labelled Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio tagging aims to predict one or several labels in an audio clip. Many\nprevious works use weakly labelled data (WLD) for audio tagging, where only\npresence or absence of sound events is known, but the order of sound events is\nunknown. To use the order information of sound events, we propose sequential\nlabelled data (SLD), where both the presence or absence and the order\ninformation of sound events are known. To utilize SLD in audio tagging, we\npropose a Convolutional Recurrent Neural Network followed by a Connectionist\nTemporal Classification (CRNN-CTC) objective function to map from an audio clip\nspectrogram to SLD. Experiments show that CRNN-CTC obtains an Area Under Curve\n(AUC) score of 0.986 in audio tagging, outperforming the baseline CRNN of 0.908\nand 0.815 with Max Pooling and Average Pooling, respectively. In addition, we\nshow CRNN-CTC has the ability to predict the order of sound events in an audio\nclip.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 14:40:31 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Hou", "Yuanbo", ""], ["Kong", "Qiuqiang", ""], ["Li", "Shengchen", ""]]}, {"id": "1808.02022", "submitter": "Saeedeh Shekarpour", "authors": "Saeedeh Shekarpour, Ankita Saxena, Krishnaprasad Thirunarayan, Valerie\n  L. Shalin, Amit Sheth", "title": "Principles for Developing a Knowledge Graph of Interlinked Events from\n  News Headlines on Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever-growing datasets published on Linked Open Data mainly contain\nencyclopedic information. However, there is a lack of quality structured and\nsemantically annotated datasets extracted from unstructured real-time sources.\nIn this paper, we present principles for developing a knowledge graph of\ninterlinked events using the case study of news headlines published on Twitter\nwhich is a real-time and eventful source of fresh information. We represent the\nessential pipeline containing the required tasks ranging from choosing\nbackground data model, event annotation (i.e., event recognition and\nclassification), entity annotation and eventually interlinking events. The\nstate-of-the-art is limited to domain-specific scenarios for recognizing and\nclassifying events, whereas this paper plays the role of a domain-agnostic\nroad-map for developing a knowledge graph of interlinked events.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 03:04:35 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Shekarpour", "Saeedeh", ""], ["Saxena", "Ankita", ""], ["Thirunarayan", "Krishnaprasad", ""], ["Shalin", "Valerie L.", ""], ["Sheth", "Amit", ""]]}, {"id": "1808.02082", "submitter": "Rajiv Ratn Shah", "authors": "Debanjan Mahata, Jasper Friedrichs, Rajiv Ratn Shah, Jing Jiang", "title": "Did you take the pill? - Detecting Personal Intake of Medicine from\n  Twitter", "comments": "arXiv admin note: substantial text overlap with arXiv:1805.06375", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining social media messages such as tweets, articles, and Facebook posts for\nhealth and drug related information has received significant interest in\npharmacovigilance research. Social media sites (e.g., Twitter), have been used\nfor monitoring drug abuse, adverse reactions of drug usage and analyzing\nexpression of sentiments related to drugs. Most of these studies are based on\naggregated results from a large population rather than specific sets of\nindividuals. In order to conduct studies at an individual level or specific\ncohorts, identifying posts mentioning intake of medicine by the user is\nnecessary. Towards this objective we develop a classifier for identifying\nmentions of personal intake of medicine in tweets. We train a stacked ensemble\nof shallow convolutional neural network (CNN) models on an annotated dataset.\nWe use random search for tuning the hyper-parameters of the CNN models and\npresent an ensemble of best models for the prediction task. Our system produces\nstate-of-the-art result, with a micro-averaged F-score of 0.693. We believe\nthat the developed classifier has direct uses in the areas of psychology,\nhealth informatics, pharmacovigilance and affective computing for tracking\nmoods, emotions and sentiments of patients expressing intake of medicine in\nsocial media.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2018 02:39:38 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Mahata", "Debanjan", ""], ["Friedrichs", "Jasper", ""], ["Shah", "Rajiv Ratn", ""], ["Jiang", "Jing", ""]]}, {"id": "1808.02113", "submitter": "Cynthia Freeman", "authors": "Cynthia Freeman, Jonathan Merriman, Abhinav Aggarwal, Ian Beaver,\n  Abdullah Mueen", "title": "Paying Attention to Attention: Highlighting Influential Samples in\n  Sequential Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In (Yang et al. 2016), a hierarchical attention network (HAN) is created for\ndocument classification. The attention layer can be used to visualize text\ninfluential in classifying the document, thereby explaining the model's\nprediction. We successfully applied HAN to a sequential analysis task in the\nform of real-time monitoring of turn taking in conversations. However, we\ndiscovered instances where the attention weights were uniform at the stopping\npoint (indicating all turns were equivalently influential to the classifier),\npreventing meaningful visualization for real-time human review or classifier\nimprovement. We observed that attention weights for turns fluctuated as the\nconversations progressed, indicating turns had varying influence based on\nconversation state. Leveraging this observation, we develop a method to create\nmore informative real-time visuals (as confirmed by human reviewers) in cases\nof uniform attention weights using the changes in turn importance as a\nconversation progresses over time.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 21:05:55 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Freeman", "Cynthia", ""], ["Merriman", "Jonathan", ""], ["Aggarwal", "Abhinav", ""], ["Beaver", "Ian", ""], ["Mueen", "Abdullah", ""]]}, {"id": "1808.02171", "submitter": "Suyoun Kim", "authors": "Suyoun Kim, Florian Metze", "title": "Dialog-context aware end-to-end speech recognition", "comments": "submitted to SLT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing speech recognition systems are typically built at the sentence\nlevel, although it is known that dialog context, e.g. higher-level knowledge\nthat spans across sentences or speakers, can help the processing of long\nconversations. The recent progress in end-to-end speech recognition systems\npromises to integrate all available information (e.g. acoustic, language\nresources) into a single model, which is then jointly optimized. It seems\nnatural that such dialog context information should thus also be integrated\ninto the end-to-end models to improve further recognition accuracy. In this\nwork, we present a dialog-context aware speech recognition model, which\nexplicitly uses context information beyond sentence-level information, in an\nend-to-end fashion. Our dialog-context model captures a history of\nsentence-level context so that the whole system can be trained with\ndialog-context information in an end-to-end manner. We evaluate our proposed\napproach on the Switchboard conversational speech corpus and show that our\nsystem outperforms a comparable sentence-level end-to-end speech recognition\nsystem.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 01:04:39 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Kim", "Suyoun", ""], ["Metze", "Florian", ""]]}, {"id": "1808.02228", "submitter": "Hung-Yi Lee", "authors": "Yu-Hsuan Wang and Hung-yi Lee and Lin-shan Lee", "title": "Segmental Audio Word2Vec: Representing Utterances as Sequences of\n  Vectors with Applications in Spoken Term Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While Word2Vec represents words (in text) as vectors carrying semantic\ninformation, audio Word2Vec was shown to be able to represent signal segments\nof spoken words as vectors carrying phonetic structure information. Audio\nWord2Vec can be trained in an unsupervised way from an unlabeled corpus, except\nthe word boundaries are needed. In this paper, we extend audio Word2Vec from\nword-level to utterance-level by proposing a new segmental audio Word2Vec, in\nwhich unsupervised spoken word boundary segmentation and audio Word2Vec are\njointly learned and mutually enhanced, so an utterance can be directly\nrepresented as a sequence of vectors carrying phonetic structure information.\nThis is achieved by a segmental sequence-to-sequence autoencoder (SSAE), in\nwhich a segmentation gate trained with reinforcement learning is inserted in\nthe encoder. Experiments on English, Czech, French and German show very good\nperformance in both unsupervised spoken word segmentation and spoken term\ndetection applications (significantly better than frame-based DTW).\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 06:47:50 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Wang", "Yu-Hsuan", ""], ["Lee", "Hung-yi", ""], ["Lee", "Lin-shan", ""]]}, {"id": "1808.02280", "submitter": "Hung-Yi Lee", "authors": "Chia-Hsuan Lee and Shang-Ming Wang and Huan-Cheng Chang and Hung-Yi\n  Lee", "title": "ODSQA: Open-domain Spoken Question Answering Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reading comprehension by machine has been widely studied, but machine\ncomprehension of spoken content is still a less investigated problem. In this\npaper, we release Open-Domain Spoken Question Answering Dataset (ODSQA) with\nmore than three thousand questions. To the best of our knowledge, this is the\nlargest real SQA dataset. On this dataset, we found that ASR errors have\ncatastrophic impact on SQA. To mitigate the effect of ASR errors, subword units\nare involved, which brings consistent improvements over all the models. We\nfurther found that data augmentation on text-based QA training examples can\nimprove SQA.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 09:47:00 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Lee", "Chia-Hsuan", ""], ["Wang", "Shang-Ming", ""], ["Chang", "Huan-Cheng", ""], ["Lee", "Hung-Yi", ""]]}, {"id": "1808.02290", "submitter": "Subhabrata Dutta", "authors": "Subhabrata Dutta, Tanmoy Chakraborty and Dipankar Das", "title": "How did the discussion go: Discourse act classification in social media\n  conversations", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-01872-6_6", "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel attention based hierarchical LSTM model to classify\ndiscourse act sequences in social media conversations, aimed at mining data\nfrom online discussion using textual meanings beyond sentence level. The very\nuniqueness of the task is the complete categorization of possible pragmatic\nroles in informal textual discussions, contrary to extraction of\nquestion-answers, stance detection or sarcasm identification which are very\nmuch role specific tasks. Early attempt was made on a Reddit discussion\ndataset. We train our model on the same data, and present test results on two\ndifferent datasets, one from Reddit and one from Facebook. Our proposed model\noutperformed the previous one in terms of domain independence; without using\nplatform-dependent structural features, our hierarchical LSTM with word\nrelevance attention mechanism achieved F1-scores of 71\\% and 66\\% respectively\nto predict discourse roles of comments in Reddit and Facebook discussions.\nEfficiency of recurrent and convolutional architectures in order to learn\ndiscursive representation on the same task has been presented and analyzed,\nwith different word and comment embedding schemes. Our attention mechanism\nenables us to inquire into relevance ordering of text segments according to\ntheir roles in discourse. We present a human annotator experiment to unveil\nimportant observations about modeling and data annotation. Equipped with our\ntext-based discourse identification model, we inquire into how heterogeneous\nnon-textual features like location, time, leaning of information etc. play\ntheir roles in charaterizing online discussions on Facebook.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 10:14:38 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Dutta", "Subhabrata", ""], ["Chakraborty", "Tanmoy", ""], ["Das", "Dipankar", ""]]}, {"id": "1808.02374", "submitter": "Artuur Leeuwenberg", "authors": "Artuur Leeuwenberg and Marie-Francine Moens", "title": "Word-Level Loss Extensions for Neural Temporal Relation Classification", "comments": "Accepted at the 27th International Conference on Computational\n  Linguistics (COLING 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unsupervised pre-trained word embeddings are used effectively for many tasks\nin natural language processing to leverage unlabeled textual data. Often these\nembeddings are either used as initializations or as fixed word representations\nfor task-specific classification models. In this work, we extend our\nclassification model's task loss with an unsupervised auxiliary loss on the\nword-embedding level of the model. This is to ensure that the learned word\nrepresentations contain both task-specific features, learned from the\nsupervised loss component, and more general features learned from the\nunsupervised loss component. We evaluate our approach on the task of temporal\nrelation extraction, in particular, narrative containment relation extraction\nfrom clinical records, and show that continued training of the embeddings on\nthe unsupervised objective together with the task objective gives better\ntask-specific embeddings, and results in an improvement over the state of the\nart on the THYME dataset, using only a general-domain part-of-speech tagger as\nlinguistic resource.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 14:00:11 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Leeuwenberg", "Artuur", ""], ["Moens", "Marie-Francine", ""]]}, {"id": "1808.02504", "submitter": "Sri Harish Mallidi", "authors": "Sri Harish Mallidi, Roland Maas, Kyle Goehner, Ariya Rastrow, Spyros\n  Matsoukas, Bj\\\"orn Hoffmeister", "title": "Device-directed Utterance Detection", "comments": "Interspeech 2018 (accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a classifier for distinguishing device-directed\nqueries from background speech in the context of interactions with voice\nassistants. Applications include rejection of false wake-ups or unintended\ninteractions as well as enabling wake-word free follow-up queries. Consider the\nexample interaction: $\"Computer,~play~music\", \"Computer,~reduce~the~volume\"$.\nIn this interaction, the user needs to repeat the wake-word ($Computer$) for\nthe second query. To allow for more natural interactions, the device could\nimmediately re-enter listening state after the first query (without wake-word\nrepetition) and accept or reject a potential follow-up as device-directed or\nbackground speech. The proposed model consists of two long short-term memory\n(LSTM) neural networks trained on acoustic features and automatic speech\nrecognition (ASR) 1-best hypotheses, respectively. A feed-forward deep neural\nnetwork (DNN) is then trained to combine the acoustic and 1-best embeddings,\nderived from the LSTMs, with features from the ASR decoder. Experimental\nresults show that ASR decoder, acoustic embeddings, and 1-best embeddings yield\nan equal-error-rate (EER) of $9.3~\\%$, $10.9~\\%$ and $20.1~\\%$, respectively.\nCombination of the features resulted in a $44~\\%$ relative improvement and a\nfinal EER of $5.2~\\%$.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 18:19:30 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Mallidi", "Sri Harish", ""], ["Maas", "Roland", ""], ["Goehner", "Kyle", ""], ["Rastrow", "Ariya", ""], ["Matsoukas", "Spyros", ""], ["Hoffmeister", "Bj\u00f6rn", ""]]}, {"id": "1808.02563", "submitter": "Yuval Merhav", "authors": "Yuval Merhav and Stephen Ash", "title": "Design Challenges in Named Entity Transliteration", "comments": "COLING 2018 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze some of the fundamental design challenges that impact the\ndevelopment of a multilingual state-of-the-art named entity transliteration\nsystem, including curating bilingual named entity datasets and evaluation of\nmultiple transliteration methods. We empirically evaluate the transliteration\ntask using traditional weighted finite state transducer (WFST) approach against\ntwo neural approaches: the encoder-decoder recurrent neural network method and\nthe recent, non-sequential Transformer method. In order to improve availability\nof bilingual named entity transliteration datasets, we release personal name\nbilingual dictionaries minded from Wikidata for English to Russian, Hebrew,\nArabic and Japanese Katakana. Our code and dictionaries are publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 22:01:37 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Merhav", "Yuval", ""], ["Ash", "Stephen", ""]]}, {"id": "1808.02586", "submitter": "Van-Khanh Tran", "authors": "Van-Khanh Tran and Le-Minh Nguyen", "title": "Adversarial Domain Adaptation for Variational Neural Language Generation\n  in Dialogue Systems", "comments": "Accepted at COLING 2018, 13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Domain Adaptation arises when we aim at learning from source domain a model\nthat can per- form acceptably well on a different target domain. It is\nespecially crucial for Natural Language Generation (NLG) in Spoken Dialogue\nSystems when there are sufficient annotated data in the source domain, but\nthere is a limited labeled data in the target domain. How to effectively\nutilize as much of existing abilities from source domains is a crucial issue in\ndomain adaptation. In this paper, we propose an adversarial training procedure\nto train a Variational encoder-decoder based language generator via multiple\nadaptation steps. In this procedure, a model is first trained on a source\ndomain data and then fine-tuned on a small set of target domain utterances\nunder the guidance of two proposed critics. Experimental results show that the\nproposed method can effec- tively leverage the existing knowledge in the source\ndomain to adapt to another related domain by using only a small amount of\nin-domain data.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 00:02:18 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Tran", "Van-Khanh", ""], ["Nguyen", "Le-Minh", ""]]}, {"id": "1808.02608", "submitter": "Takaaki Hori", "authors": "Takaaki Hori, Jaejin Cho, Shinji Watanabe", "title": "End-to-end Speech Recognition with Word-based RNN Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the impact of word-based RNN language models\n(RNN-LMs) on the performance of end-to-end automatic speech recognition (ASR).\nIn our prior work, we have proposed a multi-level LM, in which character-based\nand word-based RNN-LMs are combined in hybrid CTC/attention-based ASR. Although\nthis multi-level approach achieves significant error reduction in the Wall\nStreet Journal (WSJ) task, two different LMs need to be trained and used for\ndecoding, which increase the computational cost and memory usage. In this\npaper, we further propose a novel word-based RNN-LM, which allows us to decode\nwith only the word-based LM, where it provides look-ahead word probabilities to\npredict next characters instead of the character-based LM, leading competitive\naccuracy with less computation compared to the multi-level LM. We demonstrate\nthe efficacy of the word-based RNN-LMs using a larger corpus, LibriSpeech, in\naddition to WSJ we used in the prior work. Furthermore, we show that the\nproposed model achieves 5.1 %WER for WSJ Eval'92 test set when the vocabulary\nsize is increased, which is the best WER reported for end-to-end ASR systems on\nthis benchmark.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 03:05:11 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Hori", "Takaaki", ""], ["Cho", "Jaejin", ""], ["Watanabe", "Shinji", ""]]}, {"id": "1808.02622", "submitter": "Peter J Liu", "authors": "Peter J. Liu", "title": "Learning to Write Notes in Electronic Health Records", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinicians spend a significant amount of time inputting free-form textual\nnotes into Electronic Health Records (EHR) systems. Much of this documentation\nwork is seen as a burden, reducing time spent with patients and contributing to\nclinician burnout. With the aspiration of AI-assisted note-writing, we propose\na new language modeling task predicting the content of notes conditioned on\npast data from a patient's medical record, including patient demographics,\nlabs, medications, and past notes. We train generative models using the public,\nde-identified MIMIC-III dataset and compare generated notes with those in the\ndataset on multiple measures. We find that much of the content can be\npredicted, and that many common templates found in notes can be learned. We\ndiscuss how such models can be useful in supporting assistive note-writing\nfeatures such as error-detection and auto-complete.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 04:49:41 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Liu", "Peter J.", ""]]}, {"id": "1808.02632", "submitter": "Pan Lu", "authors": "Peng Gao, Pan Lu, Hongsheng Li, Shuang Li, Yikang Li, Steven Hoi,\n  Xiaogang Wang", "title": "Question-Guided Hybrid Convolution for Visual Question Answering", "comments": "17 pages, 4 figures, accepted in ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel Question-Guided Hybrid Convolution (QGHC)\nnetwork for Visual Question Answering (VQA). Most state-of-the-art VQA methods\nfuse the high-level textual and visual features from the neural network and\nabandon the visual spatial information when learning multi-modal features.To\naddress these problems, question-guided kernels generated from the input\nquestion are designed to convolute with visual features for capturing the\ntextual and visual relationship in the early stage. The question-guided\nconvolution can tightly couple the textual and visual information but also\nintroduce more parameters when learning kernels. We apply the group\nconvolution, which consists of question-independent kernels and\nquestion-dependent kernels, to reduce the parameter size and alleviate\nover-fitting. The hybrid convolution can generate discriminative multi-modal\nfeatures with fewer parameters. The proposed approach is also complementary to\nexisting bilinear pooling fusion and attention based VQA methods. By\nintegrating with them, our method could further boost the performance.\nExtensive experiments on public VQA datasets validate the effectiveness of\nQGHC.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 05:39:00 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Gao", "Peng", ""], ["Lu", "Pan", ""], ["Li", "Hongsheng", ""], ["Li", "Shuang", ""], ["Li", "Yikang", ""], ["Hoi", "Steven", ""], ["Wang", "Xiaogang", ""]]}, {"id": "1808.02636", "submitter": "Atri Mandal", "authors": "Atri Mandal, Nikhil Malhotra, Shivali Agarwal, Anupama Ray, Giriprasad\n  Sridhara", "title": "Cognitive system to achieve human-level accuracy in automated assignment\n  of helpdesk email tickets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ticket assignment/dispatch is a crucial part of service delivery business\nwith lot of scope for automation and optimization. In this paper, we present an\nend-to-end automated helpdesk email ticket assignment system, which is also\noffered as a service. The objective of the system is to determine the nature of\nthe problem mentioned in an incoming email ticket and then automatically\ndispatch it to an appropriate resolver group (or team) for resolution.\n  The proposed system uses an ensemble classifier augmented with a configurable\nrule engine. While design of classifier that is accurate is one of the main\nchallenges, we also need to address the need of designing a system that is\nrobust and adaptive to changing business needs. We discuss some of the main\ndesign challenges associated with email ticket assignment automation and how we\nsolve them. The design decisions for our system are driven by high accuracy,\ncoverage, business continuity, scalability and optimal usage of computational\nresources.\n  Our system has been deployed in production of three major service providers\nand currently assigning over 40,000 emails per month, on an average, with an\naccuracy close to 90% and covering at least 90% of email tickets. This\ntranslates to achieving human-level accuracy and results in a net saving of\nabout 23000 man-hours of effort per annum.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 06:04:35 GMT"}, {"version": "v2", "created": "Thu, 9 Aug 2018 06:27:47 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Mandal", "Atri", ""], ["Malhotra", "Nikhil", ""], ["Agarwal", "Shivali", ""], ["Ray", "Anupama", ""], ["Sridhara", "Giriprasad", ""]]}, {"id": "1808.02724", "submitter": "Tzoof Avny", "authors": "Dana Sagi, Tzoof Avny, Kira Radinsky, Eugene Agichtein", "title": "Learning to Focus when Ranking Answers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main challenges in ranking is embedding the query and document\npairs into a joint feature space, which can then be fed to a learning-to-rank\nalgorithm. To achieve this representation, the conventional state of the art\napproaches perform extensive feature engineering that encode the similarity of\nthe query-answer pair. Recently, deep-learning solutions have shown that it is\npossible to achieve comparable performance, in some settings, by learning the\nsimilarity representation directly from data. Unfortunately, previous models\nperform poorly on longer texts, or on texts with significant portion of\nirrelevant information, or which are grammatically incorrect. To overcome these\nlimitations, we propose a novel ranking algorithm for question answering,\nQARAT, which uses an attention mechanism to learn on which words and phrases to\nfocus when building the mutual representation. We demonstrate superior ranking\nperformance on several real-world question-answer ranking datasets, and provide\nvisualization of the attention mechanism to otter more insights into how our\nmodels of attention could benefit ranking for difficult question answering\nchallenges.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 11:06:15 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Sagi", "Dana", ""], ["Avny", "Tzoof", ""], ["Radinsky", "Kira", ""], ["Agichtein", "Eugene", ""]]}, {"id": "1808.02733", "submitter": "Mat\\=iss Rikters", "authors": "Mat\\=iss Rikters", "title": "Debugging Neural Machine Translations", "comments": null, "journal-ref": "Baltic DB&IS 2018 Joint Proceedings of the Conference Forum,\n  Trakai, Lithuania, 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe a tool for debugging the output and attention\nweights of neural machine translation (NMT) systems and for improved\nestimations of confidence about the output based on the attention. The purpose\nof the tool is to help researchers and developers find weak and faulty example\ntranslations that their NMT systems produce without the need for reference\ntranslations. Our tool also includes an option to directly compare translation\noutputs from two different NMT engines or experiments. In addition, we present\na demo website of our tool with examples of good and bad translations:\nhttp://attention.lielakeda.lv\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 11:55:36 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Rikters", "Mat\u012bss", ""]]}, {"id": "1808.02747", "submitter": "Shang-Yu Su", "authors": "Shang-Yu Su, Kai-Ling Lo, Yi-Ting Yeh, Yun-Nung Chen", "title": "Natural Language Generation by Hierarchical Decoding with Linguistic\n  Patterns", "comments": "Published in NAACL-HLT 2018, the first two authors have equal\n  contributions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Natural language generation (NLG) is a critical component in spoken dialogue\nsystems. Classic NLG can be divided into two phases: (1) sentence planning:\ndeciding on the overall sentence structure, (2) surface realization:\ndetermining specific word forms and flattening the sentence structure into a\nstring. Many simple NLG models are based on recurrent neural networks (RNN) and\nsequence-to-sequence (seq2seq) model, which basically contains an\nencoder-decoder structure; these NLG models generate sentences from scratch by\njointly optimizing sentence planning and surface realization using a simple\ncross entropy loss training criterion. However, the simple encoder-decoder\narchitecture usually suffers from generating complex and long sentences,\nbecause the decoder has to learn all grammar and diction knowledge. This paper\nintroduces a hierarchical decoding NLG model based on linguistic patterns in\ndifferent levels, and shows that the proposed method outperforms the\ntraditional one with a smaller model size. Furthermore, the design of the\nhierarchical decoding is flexible and easily-extensible in various NLG systems.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 13:12:10 GMT"}, {"version": "v2", "created": "Thu, 9 Aug 2018 03:20:38 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Su", "Shang-Yu", ""], ["Lo", "Kai-Ling", ""], ["Yeh", "Yi-Ting", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1808.02772", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang, Yafang Huang, Pengfei Zhu, Hai Zhao", "title": "Effective Character-augmented Word Embedding for Machine Reading\n  Comprehension", "comments": "Accepted by NLPCC 2018. Early work of arXiv:1806.09103", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine reading comprehension is a task to model relationship between passage\nand query. In terms of deep learning framework, most of state-of-the-art models\nsimply concatenate word and character level representations, which has been\nshown suboptimal for the concerned task. In this paper, we empirically explore\ndifferent integration strategies of word and character embeddings and propose a\ncharacter-augmented reader which attends character-level representation to\naugment word embedding with a short list to improve word representations,\nespecially for rare words. Experimental results show that the proposed approach\nhelps the baseline model significantly outperform state-of-the-art baselines on\nvarious public benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2018 15:37:20 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 06:48:40 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["Huang", "Yafang", ""], ["Zhu", "Pengfei", ""], ["Zhao", "Hai", ""]]}, {"id": "1808.02831", "submitter": "Melanie Tosik", "authors": "Melanie Tosik and Antonio Mallia and Kedar Gangopadhyay", "title": "Debunking Fake News One Feature at a Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Identifying the stance of a news article body with respect to a certain\nheadline is the first step to automated fake news detection. In this paper, we\nintroduce a 2-stage ensemble model to solve the stance detection task. By using\nonly hand-crafted features as input to a gradient boosting classifier, we are\nable to achieve a score of 9161.5 out of 11651.25 (78.63%) on the official Fake\nNews Challenge (Stage 1) dataset. We identify the most useful features for\ndetecting fake news and discuss how sampling techniques can be used to improve\nrecall accuracy on a highly imbalanced dataset.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 15:45:06 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Tosik", "Melanie", ""], ["Mallia", "Antonio", ""], ["Gangopadhyay", "Kedar", ""]]}, {"id": "1808.02939", "submitter": "Yuan Gong", "authors": "Yuan Gong, Christian Poellabauer", "title": "Towards Learning Fine-Grained Disentangled Representations from Speech", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning disentangled representations of high-dimensional data is currently\nan active research area. However, compared to the field of computer vision,\nless work has been done for speech processing. In this paper, we provide a\nreview of two representative efforts on this topic and propose the novel\nconcept of fine-grained disentangled speech representation learning.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 20:59:26 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Gong", "Yuan", ""], ["Poellabauer", "Christian", ""]]}, {"id": "1808.02961", "submitter": "Philip Liu", "authors": "Pengfei Liu, Ji Zhang, Cane Wing-Ki Leung, Chao He and Thomas L.\n  Griffiths", "title": "Exploiting Effective Representations for Chinese Sentiment Analysis\n  Using a Multi-Channel Convolutional Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Effective representation of a text is critical for various natural language\nprocessing tasks. For the particular task of Chinese sentiment analysis, it is\nimportant to understand and choose an effective representation of a text from\ndifferent forms of Chinese representations such as word, character and pinyin.\nThis paper presents a systematic study of the effect of these representations\nfor Chinese sentiment analysis by proposing a multi-channel convolutional\nneural network (MCCNN), where each channel corresponds to a representation.\nExperimental results show that: (1) Word wins on the dataset of low OOV rate\nwhile character wins otherwise; (2) Using these representations in combination\ngenerally improves the performance; (3) The representations based on MCCNN\noutperform conventional ngram features using SVM; (4) The proposed MCCNN model\nachieves the competitive performance against the state-of-the-art model\nfastText for Chinese sentiment analysis.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 23:06:12 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Liu", "Pengfei", ""], ["Zhang", "Ji", ""], ["Leung", "Cane Wing-Ki", ""], ["He", "Chao", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "1808.03027", "submitter": "Mohammad Kamel", "authors": "Mohammad Kamel, Neda Keyvani and Hadi Sadoghi Yazdi", "title": "Sentimental Content Analysis and Knowledge Extraction from News Articles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In web era, since technology has revolutionized mankind life, plenty of data\nand information are published on the Internet each day. For instance, news\nagencies publish news on their websites all over the world. These raw data\ncould be an important resource for knowledge extraction. These shared data\ncontain emotions (i.e., positive, neutral or negative) toward various topics;\ntherefore, sentimental content extraction could be a beneficial task in many\naspects. Extracting the sentiment of news illustrates highly valuable\ninformation about the events over a period of time, the viewpoint of a media or\nnews agency to these events. In this paper an attempt is made to propose an\napproach for news analysis and extracting useful knowledge from them. Firstly,\nwe attempt to extract a noise robust sentiment of news documents; therefore,\nthe news associated to six countries: United State, United Kingdom, Germany,\nCanada, France and Australia in 5 different news categories: Politics, Sports,\nBusiness, Entertainment and Technology are downloaded. In this paper we compare\nthe condition of different countries in each 5 news topics based on the\nextracted sentiments and emotional contents in news documents. Moreover, we\npropose an approach to reduce the bulky news data to extract the hottest topics\nand news titles as a knowledge. Eventually, we generate a word model to map\neach word to a fixed-size vector by Word2Vec in order to understand the\nrelations between words in our collected news database.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 05:42:49 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Kamel", "Mohammad", ""], ["Keyvani", "Neda", ""], ["Yazdi", "Hadi Sadoghi", ""]]}, {"id": "1808.03028", "submitter": "Pruthwik Mishra", "authors": "Pruthwik Mishra and Litton J Kurisinkel and Dipti Misra Sharma", "title": "Arithmetic Word Problem Solver using Frame Identification", "comments": "9 pages, 3 figures, CICLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic Word problem solving has always posed a great challenge for the NLP\ncommunity. Usually a word problem is a narrative comprising of a few sentences\nand a question is asked about a quantity referred in the sentences. Solving\nword problem involves reasoning across sentences, identification of operations,\ntheir order, relevant quantities and discarding irrelevant quantities. In this\npaper, we present a novel approach for automatic arithmetic word problem\nsolving. Our approach starts with frame identification. Each frame can either\nbe classified as a state or an action frame. The frame identification is\ndependent on the verb in a sentence. Every frame is unique and is identified by\nits slots. The slots are filled using dependency parsed output of a sentence.\nThe slots are entity holder, entity, quantity of the entity, recipient,\nadditional information like place, time. The slots and frames helps to identify\nthe type of question asked and the entity referred. Action frames act on state\nframe(s) which causes a change in quantities of the state frames. The frames\nare then used to build a graph where any change in quantities can be propagated\nto the neighboring nodes. Most of the current solvers can only answer questions\nrelated to the quantity, while our system can answer different kinds of\nquestions like `who', `what' other than the quantity related questions `how\nmany'.\n  There are three major contributions of this paper. 1. Frame Annotated Corpus\n(with a frame annotation tool) 2. Frame Identification Module 3. A new easily\nunderstandable Framework for word problem solving\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 05:57:13 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Mishra", "Pruthwik", ""], ["Kurisinkel", "Litton J", ""], ["Sharma", "Dipti Misra", ""]]}, {"id": "1808.03090", "submitter": "Ruihua Song", "authors": "Wen-Feng Cheng, Chao-Chung Wu, Ruihua Song, Jianlong Fu, Xing Xie,\n  Jian-Yun Nie", "title": "Image Inspired Poetry Generation in XiaoIce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision is a common source of inspiration for poetry. The objects and the\nsentimental imprints that one perceives from an image may lead to various\nfeelings depending on the reader. In this paper, we present a system of poetry\ngeneration from images to mimic the process. Given an image, we first extract a\nfew keywords representing objects and sentiments perceived from the image.\nThese keywords are then expanded to related ones based on their associations in\nhuman written poems. Finally, verses are generated gradually from the keywords\nusing recurrent neural networks trained on existing poems. Our approach is\nevaluated by human assessors and compared to other generation baselines. The\nresults show that our method can generate poems that are more artistic than the\nbaseline methods. This is one of the few attempts to generate poetry from\nimages. By deploying our proposed approach, XiaoIce has already generated more\nthan 12 million poems for users since its release in July 2017. A book of its\npoems has been published by Cheers Publishing, which claimed that the book is\nthe first-ever poetry collection written by an AI in human history.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 11:17:38 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Cheng", "Wen-Feng", ""], ["Wu", "Chao-Chung", ""], ["Song", "Ruihua", ""], ["Fu", "Jianlong", ""], ["Xie", "Xing", ""], ["Nie", "Jian-Yun", ""]]}, {"id": "1808.03137", "submitter": "Roman Klinger", "authors": "Evgeny Kim and Roman Klinger", "title": "A Survey on Sentiment and Emotion Analysis for Computational Literary\n  Studies", "comments": "Under open review at ZFDG, revised version after review\n  (https://zfdg.de/2019_008)", "journal-ref": null, "doi": "10.17175/2019_008", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Emotions are a crucial part of compelling narratives: literature tells us\nabout people with goals, desires, passions, and intentions. Emotion analysis is\npart of the broader and larger field of sentiment analysis, and receives\nincreasing attention in literary studies. In the past, the affective dimension\nof literature was mainly studied in the context of literary hermeneutics.\nHowever, with the emergence of the research field known as Digital Humanities\n(DH), some studies of emotions in a literary context have taken a computational\nturn. Given the fact that DH is still being formed as a field, this direction\nof research can be rendered relatively new. In this survey, we offer an\noverview of the existing body of research on emotion analysis as applied to\nliterature. The research under review deals with a variety of topics including\ntracking dramatic changes of a plot development, network analysis of a literary\ntext, and understanding the emotionality of texts, among other topics.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 13:12:07 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 09:54:01 GMT"}, {"version": "v3", "created": "Tue, 16 Mar 2021 19:14:25 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Kim", "Evgeny", ""], ["Klinger", "Roman", ""]]}, {"id": "1808.03175", "submitter": "Pruthwik Mishra", "authors": "Ketan Kumar Todi, Pruthwik Mishra, Dipti Misra Sharma", "title": "Building a Kannada POS Tagger Using Machine Learning and Neural Network\n  Models", "comments": "10 pages, 2 figures, CICLING-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  POS Tagging serves as a preliminary task for many NLP applications. Kannada\nis a relatively poor Indian language with very limited number of quality NLP\ntools available for use. An accurate and reliable POS Tagger is essential for\nmany NLP tasks like shallow parsing, dependency parsing, sentiment analysis,\nnamed entity recognition. We present a statistical POS tagger for Kannada using\ndifferent machine learning and neural network models. Our Kannada POS tagger\noutperforms the state-of-the-art Kannada POS tagger by 6%. Our contribution in\nthis paper is three folds - building a generic POS Tagger, comparing the\nperformances of different modeling techniques, exploring the use of character\nand word embeddings together for Kannada POS Tagging.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 14:16:30 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Todi", "Ketan Kumar", ""], ["Mishra", "Pruthwik", ""], ["Sharma", "Dipti Misra", ""]]}, {"id": "1808.03227", "submitter": "Mahtab Ahmed", "authors": "Mahtab Ahmed, Jumayel Islam, Muhammad Rifayat Samee, Robert E. Mercer", "title": "Identifying Protein-Protein Interaction using Tree LSTM and Structured\n  Attention", "comments": "9 Pages, 2 Figures, Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Identifying interactions between proteins is important to understand\nunderlying biological processes. Extracting a protein-protein interaction (PPI)\nfrom the raw text is often very difficult. Previous supervised learning methods\nhave used handcrafted features on human-annotated data sets. In this paper, we\npropose a novel tree recurrent neural network with structured attention\narchitecture for doing PPI. Our architecture achieves state of the art results\n(precision, recall, and F1-score) on the AIMed and BioInfer benchmark data\nsets. Moreover, our models achieve a significant improvement over previous best\nmodels without any explicit feature extraction. Our experimental results show\nthat traditional recurrent networks have inferior performance compared to tree\nrecurrent networks for the supervised PPI problem.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 19:08:12 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Ahmed", "Mahtab", ""], ["Islam", "Jumayel", ""], ["Samee", "Muhammad Rifayat", ""], ["Mercer", "Robert E.", ""]]}, {"id": "1808.03299", "submitter": "Pranav Dhakras", "authors": "Pruthwik Mishra and Prathyusha Danda and Pranav Dhakras", "title": "Code-Mixed Sentiment Analysis Using Machine Learning and Neural Network\n  Approaches", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentiment Analysis for Indian Languages (SAIL)-Code Mixed tools contest aimed\nat identifying the sentence level sentiment polarity of the code-mixed dataset\nof Indian languages pairs (Hi-En, Ben-Hi-En). Hi-En dataset is henceforth\nreferred to as HI-EN and Ben-Hi-En dataset as BN-EN respectively. For this, we\nsubmitted four models for sentiment analysis of code-mixed HI-EN and BN-EN\ndatasets. The first model was an ensemble voting classifier consisting of three\nclassifiers - linear SVM, logistic regression and random forests while the\nsecond one was a linear SVM. Both the models used TF-IDF feature vectors of\ncharacter n-grams where n ranged from 2 to 6. We used scikit-learn (sklearn)\nmachine learning library for implementing both the approaches. Run1 was\nobtained from the voting classifier and Run2 used the linear SVM model for\nproducing the results. Out of the four submitted outputs Run2 outperformed Run1\nin both the datasets. We finished first in the contest for both HI-EN with an\nF-score of 0.569 and BN-EN with an F-score of 0.526.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 18:38:16 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Mishra", "Pruthwik", ""], ["Danda", "Prathyusha", ""], ["Dhakras", "Pranav", ""]]}, {"id": "1808.03353", "submitter": "Noga Zaslavsky", "authors": "Noga Zaslavsky, Charles Kemp, Terry Regier and Naftali Tishby", "title": "Efficient human-like semantic representations via the Information\n  Bottleneck principle", "comments": null, "journal-ref": "Cognitively Informed Artificial Intelligence Workshop at NIPS 2017", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maintaining efficient semantic representations of the environment is a major\nchallenge both for humans and for machines. While human languages represent\nuseful solutions to this problem, it is not yet clear what computational\nprinciple could give rise to similar solutions in machines. In this work we\npropose an answer to this open question. We suggest that languages compress\npercepts into words by optimizing the Information Bottleneck (IB) tradeoff\nbetween the complexity and accuracy of their lexicons. We present empirical\nevidence that this principle may give rise to human-like semantic\nrepresentations, by exploring how human languages categorize colors. We show\nthat color naming systems across languages are near-optimal in the IB sense,\nand that these natural systems are similar to artificial IB color naming\nsystems with a single tradeoff parameter controlling the cross-language\nvariability. In addition, the IB systems evolve through a sequence of\nstructural phase transitions, demonstrating a possible adaptation process. This\nwork thus identifies a computational principle that characterizes human\nsemantic systems, and that could usefully inform semantic representations in\nmachines.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 21:44:58 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Zaslavsky", "Noga", ""], ["Kemp", "Charles", ""], ["Regier", "Terry", ""], ["Tishby", "Naftali", ""]]}, {"id": "1808.03370", "submitter": "Jiahao Chen", "authors": "Jeff Bezanson and Jake Bolewski and Jiahao Chen", "title": "Fast Flexible Function Dispatch in Julia", "comments": "15 pages, repository at https://github.com/jiahao/julia-type-system", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CL cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technical computing is a challenging application area for programming\nlanguages to address. This is evinced by the unusually large number of\nspecialized languages in the area (e.g. MATLAB, R), and the complexity of\ncommon software stacks, often involving multiple languages and custom code\ngenerators. We believe this is ultimately due to key characteristics of the\ndomain: highly complex operators, a need for extensive code specialization for\nperformance, and a desire for permissive high-level programming styles allowing\nproductive experimentation. The Julia language attempts to provide a more\neffective structure for this kind of programming by allowing programmers to\nexpress complex polymorphic behaviors using dynamic multiple dispatch over\nparametric types. The forms of extension and reuse permitted by this paradigm\nhave proven valuable for technical computing. We report on how this approach\nhas allowed domain experts to express useful abstractions while simultaneously\nproviding a natural path to better performance for high-level technical code.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 23:09:16 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Bezanson", "Jeff", ""], ["Bolewski", "Jake", ""], ["Chen", "Jiahao", ""]]}, {"id": "1808.03430", "submitter": "Pengfei Zhu", "authors": "Pengfei Zhu, Zhuosheng Zhang, Jiangtong Li, Yafang Huang, Hai Zhao", "title": "Lingke: A Fine-grained Multi-turn Chatbot for Customer Service", "comments": "Accepted by COLING 2018 demonstration paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional chatbots usually need a mass of human dialogue data, especially\nwhen using supervised machine learning method. Though they can easily deal with\nsingle-turn question answering, for multi-turn the performance is usually\nunsatisfactory. In this paper, we present Lingke, an information retrieval\naugmented chatbot which is able to answer questions based on given product\nintroduction document and deal with multi-turn conversations. We will introduce\na fine-grained pipeline processing to distill responses based on unstructured\ndocuments, and attentive sequential context-response matching for multi-turn\nconversations.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 06:58:33 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Zhu", "Pengfei", ""], ["Zhang", "Zhuosheng", ""], ["Li", "Jiangtong", ""], ["Huang", "Yafang", ""], ["Zhao", "Hai", ""]]}, {"id": "1808.03437", "submitter": "Imane Guellil", "authors": "Imane Guellil (ESI), Faical Azouaou, Fodil Benali, Ala-Eddine Hachani,\n  Houda Saadane", "title": "Hybrid approach for transliteration of Algerian arabizi: a primary study", "comments": "in French", "journal-ref": "25e conf\\'erence sur le Traitement Automatique des Langues\n  Naturelles (TALN), May 2018, Rennes, France", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hybrid approach for the transliteration of Algerian Arabizi: A primary\nstudy In this paper, we present a hybrid approach for the transliteration of\nthe Algerian Arabizi. We define a set of rules enable us the passage from\nArabizi to Arabic. Through these rules, we generate a set of candidates for the\ntransliteration of each Arabizi word into arabic. Then, we extract the best\ncandidate. This approach was evaluated by using three test corpora, and the\nobtained results show an improvement of the precision score which is equal to\n75.11% for the best result. These results allow us to verify that our approach\nis very competitive comparing to others works that treat Arabizi\ntransliteration in general.\n  Keywords: Arabizi, Dialecte Alg\\'erien, Arabizi Alg\\'erien,\nTranslit\\'eration.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 07:46:48 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Guellil", "Imane", "", "ESI"], ["Azouaou", "Faical", ""], ["Benali", "Fodil", ""], ["Hachani", "Ala-Eddine", ""], ["Saadane", "Houda", ""]]}, {"id": "1808.03465", "submitter": "Wenpeng Yin", "authors": "Wenpeng Yin, Dan Roth", "title": "TwoWingOS: A Two-Wing Optimization Strategy for Evidential Claim\n  Verification", "comments": "EMNLP 2018 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining whether a given claim is supported by evidence is a fundamental\nNLP problem that is best modeled as Textual Entailment. However, given a large\ncollection of text, finding evidence that could support or refute a given claim\nis a challenge in itself, amplified by the fact that different evidence might\nbe needed to support or refute a claim. Nevertheless, most prior work decouples\nevidence identification from determining the truth value of the claim given the\nevidence.\n  We propose to consider these two aspects jointly. We develop TwoWingOS\n(two-wing optimization strategy), a system that, while identifying appropriate\nevidence for a claim, also determines whether or not the claim is supported by\nthe evidence. Given the claim, TwoWingOS attempts to identify a subset of the\nevidence candidates; given the predicted evidence, it then attempts to\ndetermine the truth value of the corresponding claim. We treat this challenge\nas coupled optimization problems, training a joint model for it. TwoWingOS\noffers two advantages: (i) Unlike pipeline systems, it facilitates\nflexible-size evidence set, and (ii) Joint training improves both the claim\nentailment and the evidence identification. Experiments on a benchmark dataset\nshow state-of-the-art performance. Code: https://github.com/yinwenpeng/FEVER\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 09:27:44 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 15:55:23 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Yin", "Wenpeng", ""], ["Roth", "Dan", ""]]}, {"id": "1808.03507", "submitter": "Steffen Pauws", "authors": "Steffen Pauws, Albert Gatt, Emiel Krahmer, Ehud Reiter", "title": "Making effective use of healthcare data using data-to-text technology", "comments": "27 pages, 2 figures, book chapter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Healthcare organizations are in a continuous effort to improve health\noutcomes, reduce costs and enhance patient experience of care. Data is\nessential to measure and help achieving these improvements in healthcare\ndelivery. Consequently, a data influx from various clinical, financial and\noperational sources is now overtaking healthcare organizations and their\npatients. The effective use of this data, however, is a major challenge.\nClearly, text is an important medium to make data accessible. Financial reports\nare produced to assess healthcare organizations on some key performance\nindicators to steer their healthcare delivery. Similarly, at a clinical level,\ndata on patient status is conveyed by means of textual descriptions to\nfacilitate patient review, shift handover and care transitions. Likewise,\npatients are informed about data on their health status and treatments via\ntext, in the form of reports or via ehealth platforms by their doctors.\nUnfortunately, such text is the outcome of a highly labour-intensive process if\nit is done by healthcare professionals. It is also prone to incompleteness,\nsubjectivity and hard to scale up to different domains, wider audiences and\nvarying communication purposes. Data-to-text is a recent breakthrough\ntechnology in artificial intelligence which automatically generates natural\nlanguage in the form of text or speech from data. This chapter provides a\nsurvey of data-to-text technology, with a focus on how it can be deployed in a\nhealthcare setting. It will (1) give an up-to-date synthesis of data-to-text\napproaches, (2) give a categorized overview of use cases in healthcare, (3)\nseek to make a strong case for evaluating and implementing data-to-text in a\nhealthcare setting, and (4) highlight recent research challenges.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 12:33:45 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Pauws", "Steffen", ""], ["Gatt", "Albert", ""], ["Krahmer", "Emiel", ""], ["Reiter", "Ehud", ""]]}, {"id": "1808.03570", "submitter": "Chia-Yu Li", "authors": "Chia Yu Li and Ngoc Thang Vu", "title": "Densely Connected Convolutional Networks for Speech Recognition", "comments": "5 pages, 3 figures, the 13th ITG conference on Speech Communication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents our latest investigation on Densely Connected\nConvolutional Networks (DenseNets) for acoustic modelling (AM) in automatic\nspeech recognition. DenseN-ets are very deep, compact convolutional neural\nnetworks, which have demonstrated incredible improvements over the\nstate-of-the-art results on several data sets in computer vision. Our\nexperimental results show that DenseNet can be used for AM significantly\noutperforming other neural-based models such as DNNs, CNNs, VGGs. Furthermore,\nresults on Wall Street Journal revealed that with only a half of the training\ndata DenseNet was able to outperform other models trained with the full data\nset by a large margin.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 14:54:10 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Li", "Chia Yu", ""], ["Vu", "Ngoc Thang", ""]]}, {"id": "1808.03703", "submitter": "Daniel Kondratyuk", "authors": "Daniel Kondratyuk, Tom\\'a\\v{s} Gaven\\v{c}iak, Milan Straka, Jan\n  Haji\\v{c}", "title": "LemmaTag: Jointly Tagging and Lemmatizing for Morphologically-Rich\n  Languages with BRNNs", "comments": "8 pages, 3 figures. Submitted to EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present LemmaTag, a featureless neural network architecture that jointly\ngenerates part-of-speech tags and lemmas for sentences by using bidirectional\nRNNs with character-level and word-level embeddings. We demonstrate that both\ntasks benefit from sharing the encoding part of the network, predicting tag\nsubcategories, and using the tagger output as an input to the lemmatizer. We\nevaluate our model across several languages with complex morphology, which\nsurpasses state-of-the-art accuracy in both part-of-speech tagging and\nlemmatization in Czech, German, and Arabic.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 20:46:32 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 16:36:40 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Kondratyuk", "Daniel", ""], ["Gaven\u010diak", "Tom\u00e1\u0161", ""], ["Straka", "Milan", ""], ["Haji\u010d", "Jan", ""]]}, {"id": "1808.03712", "submitter": "Eirini Papagiannopoulou", "authors": "Eirini Papagiannopoulou, Grigorios Tsoumakas", "title": "Unsupervised Keyphrase Extraction from Scientific Publications", "comments": "author pre-print version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel unsupervised keyphrase extraction approach that filters\ncandidate keywords using outlier detection. It starts by training word\nembeddings on the target document to capture semantic regularities among the\nwords. It then uses the minimum covariance determinant estimator to model the\ndistribution of non-keyphrase word vectors, under the assumption that these\nvectors come from the same distribution, indicative of their irrelevance to the\nsemantics expressed by the dimensions of the learned vector representation.\nCandidate keyphrases only consist of words that are detected as outliers of\nthis dominant distribution. Empirical results show that our approach\noutperforms state-of-the-art and recent unsupervised keyphrase extraction\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 21:50:59 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 08:02:49 GMT"}, {"version": "v3", "created": "Sun, 12 Jul 2020 08:51:07 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Papagiannopoulou", "Eirini", ""], ["Tsoumakas", "Grigorios", ""]]}, {"id": "1808.03726", "submitter": "Muhao Chen", "authors": "Muhao Chen, Yingtao Tian, Haochen Chen, Kai-Wei Chang, Steven Skiena,\n  Carlo Zaniolo", "title": "Learning to Represent Bilingual Dictionaries", "comments": "CoNLL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilingual word embeddings have been widely used to capture the similarity of\nlexical semantics in different human languages. However, many applications,\nsuch as cross-lingual semantic search and question answering, can be largely\nbenefited from the cross-lingual correspondence between sentences and lexicons.\nTo bridge this gap, we propose a neural embedding model that leverages\nbilingual dictionaries. The proposed model is trained to map the literal word\ndefinitions to the cross-lingual target words, for which we explore with\ndifferent sentence encoding techniques. To enhance the learning process on\nlimited resources, our model adopts several critical learning strategies,\nincluding multi-task learning on different bridges of languages, and joint\nlearning of the dictionary model with a bilingual word embedding model.\nExperimental evaluation focuses on two applications. The results of the\ncross-lingual reverse dictionary retrieval task show our model's promising\nability of comprehending bilingual concepts based on descriptions, and\nhighlight the effectiveness of proposed learning strategies in improving\nperformance. Meanwhile, our model effectively addresses the bilingual\nparaphrase identification problem and significantly outperforms previous\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 23:21:07 GMT"}, {"version": "v2", "created": "Fri, 31 Aug 2018 10:14:33 GMT"}, {"version": "v3", "created": "Fri, 6 Sep 2019 20:14:24 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Chen", "Muhao", ""], ["Tian", "Yingtao", ""], ["Chen", "Haochen", ""], ["Chang", "Kai-Wei", ""], ["Skiena", "Steven", ""], ["Zaniolo", "Carlo", ""]]}, {"id": "1808.03728", "submitter": "Zehao Dou", "authors": "Zehao Dou and Zhihua Zhang", "title": "Hierarchical Attention: What Really Counts in Various NLP Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanisms in sequence to sequence models have shown great ability\nand wonderful performance in various natural language processing (NLP) tasks,\nsuch as sentence embedding, text generation, machine translation, machine\nreading comprehension, etc. Unfortunately, existing attention mechanisms only\nlearn either high-level or low-level features. In this paper, we think that the\nlack of hierarchical mechanisms is a bottleneck in improving the performance of\nthe attention mechanisms, and propose a novel Hierarchical Attention Mechanism\n(Ham) based on the weighted sum of different layers of a multi-level attention.\nHam achieves a state-of-the-art BLEU score of 0.26 on Chinese poem generation\ntask and a nearly 6.5% averaged improvement compared with the existing machine\nreading comprehension models such as BIDAF and Match-LSTM. Furthermore, our\nexperiments and theorems reveal that Ham has greater generalization and\nrepresentation ability than existing attention mechanisms.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 23:28:33 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Dou", "Zehao", ""], ["Zhang", "Zhihua", ""]]}, {"id": "1808.03731", "submitter": "Dat Quoc Nguyen", "authors": "Dat Quoc Nguyen and Karin Verspoor", "title": "From POS tagging to dependency parsing for biomedical event extraction", "comments": "Accepted for publication in BMC Bioinformatics", "journal-ref": null, "doi": "10.1186/s12859-019-2604-0", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Given the importance of relation or event extraction from\nbiomedical research publications to support knowledge capture and synthesis,\nand the strong dependency of approaches to this information extraction task on\nsyntactic information, it is valuable to understand which approaches to\nsyntactic processing of biomedical text have the highest performance. Results:\nWe perform an empirical study comparing state-of-the-art traditional\nfeature-based and neural network-based models for two core natural language\nprocessing tasks of part-of-speech (POS) tagging and dependency parsing on two\nbenchmark biomedical corpora, GENIA and CRAFT. To the best of our knowledge,\nthere is no recent work making such comparisons in the biomedical context;\nspecifically no detailed analysis of neural models on this data is available.\nExperimental results show that in general, the neural models outperform the\nfeature-based models on two benchmark biomedical corpora GENIA and CRAFT. We\nalso perform a task-oriented evaluation to investigate the influences of these\nmodels in a downstream application on biomedical event extraction, and show\nthat better intrinsic parsing performance does not always imply better\nextrinsic event extraction performance. Conclusion: We have presented a\ndetailed empirical study comparing traditional feature-based and neural\nnetwork-based models for POS tagging and dependency parsing in the biomedical\ncontext, and also investigated the influence of parser selection for a\nbiomedical event extraction downstream task. Availability of data and material:\nWe make the retrained models available at\nhttps://github.com/datquocnguyen/BioPosDep\n", "versions": [{"version": "v1", "created": "Sat, 11 Aug 2018 01:03:45 GMT"}, {"version": "v2", "created": "Wed, 2 Jan 2019 16:56:23 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Nguyen", "Dat Quoc", ""], ["Verspoor", "Karin", ""]]}, {"id": "1808.03733", "submitter": "Yuanfeng Song", "authors": "Di Jiang, Yuanfeng Song, Rongzhong Lian, Siqi Bao, Jinhua Peng, Huang\n  He, and Hua Wu", "title": "Familia: A Configurable Topic Modeling Framework for Industrial Text\n  Engineering", "comments": "21 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, a variety of topic models have been proposed for text\nengineering. However, except Probabilistic Latent Semantic Analysis (PLSA) and\nLatent Dirichlet Allocation (LDA), most of existing topic models are seldom\napplied or considered in industrial scenarios. This phenomenon is caused by the\nfact that there are very few convenient tools to support these topic models so\nfar. Intimidated by the demanding expertise and labor of designing and\nimplementing parameter inference algorithms, software engineers are prone to\nsimply resort to PLSA/LDA, without considering whether it is proper for their\nproblem at hand or not. In this paper, we propose a configurable topic modeling\nframework named Familia, in order to bridge the huge gap between academic\nresearch fruits and current industrial practice. Familia supports an important\nline of topic models that are widely applicable in text engineering scenarios.\nIn order to relieve burdens of software engineers without knowledge of Bayesian\nnetworks, Familia is able to conduct automatic parameter inference for a\nvariety of topic models. Simply through changing the data organization of\nFamilia, software engineers are able to easily explore a broad spectrum of\nexisting topic models or even design their own topic models, and find the one\nthat best suits the problem at hand. With its superior extendability, Familia\nhas a novel sampling mechanism that strikes balance between effectiveness and\nefficiency of parameter inference. Furthermore, Familia is essentially a big\ntopic modeling framework that supports parallel parameter inference and\ndistributed parameter storage. The utilities and necessity of Familia are\ndemonstrated in real-life industrial applications. Familia would significantly\nenlarge software engineers' arsenal of topic models and pave the way for\nutilizing highly customized topic models in real-life problems.\n", "versions": [{"version": "v1", "created": "Sat, 11 Aug 2018 01:14:50 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 06:26:12 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Jiang", "Di", ""], ["Song", "Yuanfeng", ""], ["Lian", "Rongzhong", ""], ["Bao", "Siqi", ""], ["Peng", "Jinhua", ""], ["He", "Huang", ""], ["Wu", "Hua", ""]]}, {"id": "1808.03738", "submitter": "Dayiheng Liu", "authors": "Dayiheng Liu, Jiancheng Lv, Kexin Yang and Qian Qu", "title": "Ancient-Modern Chinese Translation with a Large Training Dataset", "comments": "To appear in the ACM Transactions on Asian and Low-Resource Language\n  Information Processing (TALLIP)", "journal-ref": null, "doi": "10.1145/3325887", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ancient Chinese brings the wisdom and spirit culture of the Chinese nation.\nAutomatic translation from ancient Chinese to modern Chinese helps to inherit\nand carry forward the quintessence of the ancients. However, the lack of\nlarge-scale parallel corpus limits the study of machine translation in\nAncient-Modern Chinese. In this paper, we propose an Ancient-Modern Chinese\nclause alignment approach based on the characteristics of these two languages.\nThis method combines both lexical-based information and statistical-based\ninformation, which achieves 94.2 F1-score on our manual annotation Test set. We\nuse this method to create a new large-scale Ancient-Modern Chinese parallel\ncorpus which contains 1.24M bilingual pairs. To our best knowledge, this is the\nfirst large high-quality Ancient-Modern Chinese dataset. Furthermore, we\nanalyzed and compared the performance of the SMT and various NMT models on this\ndataset and provided a strong baseline for this task.\n", "versions": [{"version": "v1", "created": "Sat, 11 Aug 2018 02:06:25 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 04:46:01 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Liu", "Dayiheng", ""], ["Lv", "Jiancheng", ""], ["Yang", "Kexin", ""], ["Qu", "Qian", ""]]}, {"id": "1808.03747", "submitter": "Bai Li", "authors": "Bai Li, Ran Zhang, Frank Rudzicz", "title": "Dropout during inference as a model for neurological degeneration in an\n  image captioning network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We replicate a variation of the image captioning architecture by Vinyals et\nal. (2015), then introduce dropout during inference mode to simulate the\neffects of neurodegenerative diseases like Alzheimer's disease (AD) and\nWernicke's aphasia (WA). We evaluate the effects of dropout on language\nproduction by measuring the KL-divergence of word frequency distributions and\nother linguistic metrics as dropout is added. We find that the generated\nsentences most closely approximate the word frequency distribution of the\ntraining corpus when using a moderate dropout of 0.4 during inference.\n", "versions": [{"version": "v1", "created": "Sat, 11 Aug 2018 03:50:27 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Li", "Bai", ""], ["Zhang", "Ran", ""], ["Rudzicz", "Frank", ""]]}, {"id": "1808.03752", "submitter": "Kai Wang", "authors": "Kai Wang and Yu Liu and Xiujuan Xu and Dan Lin", "title": "Knowledge Graph Embedding with Entity Neighbors and Deep Memory Network", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graph Embedding (KGE) aims to represent entities and relations of\nknowledge graph in a low-dimensional continuous vector space. Recent works\nfocus on incorporating structural knowledge with additional information, such\nas entity descriptions, relation paths and so on. However, common used\nadditional information usually contains plenty of noise, which makes it hard to\nlearn valuable representation. In this paper, we propose a new kind of\nadditional information, called entity neighbors, which contain both semantic\nand topological features about given entity. We then develop a deep memory\nnetwork model to encode information from neighbors. Employing a gating\nmechanism, representations of structure and neighbors are integrated into a\njoint representation. The experimental results show that our model outperforms\nexisting KGE methods utilizing entity descriptions and achieves\nstate-of-the-art metrics on 4 datasets.\n", "versions": [{"version": "v1", "created": "Sat, 11 Aug 2018 05:05:06 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Wang", "Kai", ""], ["Liu", "Yu", ""], ["Xu", "Xiujuan", ""], ["Lin", "Dan", ""]]}, {"id": "1808.03793", "submitter": "Pankaj Gupta", "authors": "Pankaj Gupta and Florian Buettner and Hinrich Sch\\\"utze", "title": "Document Informed Neural Autoregressive Topic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context information around words helps in determining their actual meaning,\nfor example \"networks\" used in contexts of artificial neural networks or\nbiological neuron networks. Generative topic models infer topic-word\ndistributions, taking no or only little context into account. Here, we extend a\nneural autoregressive topic model to exploit the full context information\naround words in a document in a language modeling fashion. This results in an\nimproved performance in terms of generalization, interpretability and\napplicability. We apply our modeling approach to seven data sets from various\ndomains and demonstrate that our approach consistently outperforms\nstateof-the-art generative topic models. With the learned representations, we\nshow on an average a gain of 9.6% (0.57 Vs 0.52) in precision at retrieval\nfraction 0.02 and 7.2% (0.582 Vs 0.543) in F1 for text categorization.\n", "versions": [{"version": "v1", "created": "Sat, 11 Aug 2018 12:16:09 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Gupta", "Pankaj", ""], ["Buettner", "Florian", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1808.03806", "submitter": "Tsung-Ting Kuo", "authors": "Tsung-Ting Kuo, Jina Huh, Jihoon Kim, Robert El-Kareh, Siddharth\n  Singh, Stephanie Feudjio Feupe, Vincent Kuri, Gordon Lin, Michele E. Day,\n  Lucila Ohno-Machado, and Chun-Nan Hsu", "title": "The Impact of Automatic Pre-annotation in Clinical Note Data Element\n  Extraction - the CLEAN Tool", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective. Annotation is expensive but essential for clinical note review and\nclinical natural language processing (cNLP). However, the extent to which\ncomputer-generated pre-annotation is beneficial to human annotation is still an\nopen question. Our study introduces CLEAN (CLinical note rEview and\nANnotation), a pre-annotation-based cNLP annotation system to improve clinical\nnote annotation of data elements, and comprehensively compares CLEAN with the\nwidely-used annotation system Brat Rapid Annotation Tool (BRAT).\n  Materials and Methods. CLEAN includes an ensemble pipeline (CLEAN-EP) with a\nnewly developed annotation tool (CLEAN-AT). A domain expert and a novice\nuser/annotator participated in a comparative usability test by tagging 87 data\nelements related to Congestive Heart Failure (CHF) and Kawasaki Disease (KD)\ncohorts in 84 public notes.\n  Results. CLEAN achieved higher note-level F1-score (0.896) over BRAT (0.820),\nwith significant difference in correctness (P-value < 0.001), and the mostly\nrelated factor being system/software (P-value < 0.001). No significant\ndifference (P-value 0.188) in annotation time was observed between CLEAN (7.262\nminutes/note) and BRAT (8.286 minutes/note). The difference was mostly\nassociated with note length (P-value < 0.001) and system/software (P-value\n0.013). The expert reported CLEAN to be useful/satisfactory, while the novice\nreported slight improvements.\n  Discussion. CLEAN improves the correctness of annotation and increases\nusefulness/satisfaction with the same level of efficiency. Limitations include\nuntested impact of pre-annotation correctness rate, small sample size, small\nuser size, and restrictedly validated gold standard.\n  Conclusion. CLEAN with pre-annotation can be beneficial for an expert to deal\nwith complex annotation tasks involving numerous and diverse target data\nelements.\n", "versions": [{"version": "v1", "created": "Sat, 11 Aug 2018 13:55:27 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Kuo", "Tsung-Ting", ""], ["Huh", "Jina", ""], ["Kim", "Jihoon", ""], ["El-Kareh", "Robert", ""], ["Singh", "Siddharth", ""], ["Feupe", "Stephanie Feudjio", ""], ["Kuri", "Vincent", ""], ["Lin", "Gordon", ""], ["Day", "Michele E.", ""], ["Ohno-Machado", "Lucila", ""], ["Hsu", "Chun-Nan", ""]]}, {"id": "1808.03815", "submitter": "Jiaxun Cai", "authors": "Jiaxun Cai, Shexia He, Zuchao Li, Hai Zhao", "title": "A Full End-to-End Semantic Role Labeler, Syntax-agnostic Over\n  Syntax-aware?", "comments": "In Proceedings of the 27th International Conference on Computational\n  Linguistics (COLING 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic role labeling (SRL) is to recognize the predicate-argument structure\nof a sentence, including subtasks of predicate disambiguation and argument\nlabeling. Previous studies usually formulate the entire SRL problem into two or\nmore subtasks. For the first time, this paper introduces an end-to-end neural\nmodel which unifiedly tackles the predicate disambiguation and the argument\nlabeling in one shot. Using a biaffine scorer, our model directly predicts all\nsemantic role labels for all given word pairs in the sentence without relying\non any syntactic parse information. Specifically, we augment the BiLSTM encoder\nwith a non-linear transformation to further distinguish the predicate and the\nargument in a given sentence, and model the semantic role labeling process as a\nword pair classification task by employing the biaffine attentional mechanism.\nThough the proposed model is syntax-agnostic with local decoder, it outperforms\nthe state-of-the-art syntax-aware SRL systems on the CoNLL-2008, 2009\nbenchmarks for both English and Chinese. To our best knowledge, we report the\nfirst syntax-agnostic SRL model that surpasses all known syntax-aware models.\n", "versions": [{"version": "v1", "created": "Sat, 11 Aug 2018 14:59:07 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 02:37:20 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Cai", "Jiaxun", ""], ["He", "Shexia", ""], ["Li", "Zuchao", ""], ["Zhao", "Hai", ""]]}, {"id": "1808.03835", "submitter": "Dat Quoc Nguyen", "authors": "Dat Quoc Nguyen", "title": "jLDADMM: A Java package for the LDA and DMM topic models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this technical report, we present jLDADMM---an easy-to-use Java toolkit\nfor conventional topic models. jLDADMM is released to provide alternatives for\ntopic modeling on normal or short texts. It provides implementations of the\nLatent Dirichlet Allocation topic model and the one-topic-per-document\nDirichlet Multinomial Mixture model (i.e. mixture of unigrams), using collapsed\nGibbs sampling. In addition, jLDADMM supplies a document clustering evaluation\nto compare topic models. jLDADMM is open-source and available to download at:\nhttps://github.com/datquocnguyen/jLDADMM\n", "versions": [{"version": "v1", "created": "Sat, 11 Aug 2018 16:47:58 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Nguyen", "Dat Quoc", ""]]}, {"id": "1808.03840", "submitter": "Viresh Ranjan", "authors": "Viresh Ranjan, Heeyoung Kwon, Niranjan Balasubramanian, Minh Hoai", "title": "Fake Sentence Detection as a Training Task for Sentence Encoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence encoders are typically trained on language modeling tasks with large\nunlabeled datasets. While these encoders achieve state-of-the-art results on\nmany sentence-level tasks, they are difficult to train with long training\ncycles. We introduce fake sentence detection as a new training task for\nlearning sentence encoders. We automatically generate fake sentences by\ncorrupting original sentences from a source collection and train the encoders\nto produce representations that are effective at detecting fake sentences. This\nbinary classification task turns to be quite efficient for training sentence\nencoders. We compare a basic BiLSTM encoder trained on this task with a strong\nsentence encoding models (Skipthought and FastSent) trained on a language\nmodeling task. We find that the BiLSTM trains much faster on fake sentence\ndetection (20 hours instead of weeks) using smaller amounts of data (1M instead\nof 64M sentences). Further analysis shows the learned representations capture\nmany syntactic and semantic properties expected from good sentence\nrepresentations.\n", "versions": [{"version": "v1", "created": "Sat, 11 Aug 2018 17:31:15 GMT"}, {"version": "v2", "created": "Wed, 22 Aug 2018 15:35:34 GMT"}, {"version": "v3", "created": "Thu, 23 Aug 2018 01:50:42 GMT"}, {"version": "v4", "created": "Fri, 24 Aug 2018 03:55:24 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Ranjan", "Viresh", ""], ["Kwon", "Heeyoung", ""], ["Balasubramanian", "Niranjan", ""], ["Hoai", "Minh", ""]]}, {"id": "1808.03867", "submitter": "Maha Elbayad", "authors": "Maha Elbayad and Laurent Besacier and Jakob Verbeek", "title": "Pervasive Attention: 2D Convolutional Neural Networks for\n  Sequence-to-Sequence Prediction", "comments": "Accepted at CoNLL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current state-of-the-art machine translation systems are based on\nencoder-decoder architectures, that first encode the input sequence, and then\ngenerate an output sequence based on the input encoding. Both are interfaced\nwith an attention mechanism that recombines a fixed encoding of the source\ntokens based on the decoder state. We propose an alternative approach which\ninstead relies on a single 2D convolutional neural network across both\nsequences. Each layer of our network re-codes source tokens on the basis of the\noutput sequence produced so far. Attention-like properties are therefore\npervasive throughout the network. Our model yields excellent results,\noutperforming state-of-the-art encoder-decoder systems, while being\nconceptually simpler and having fewer parameters.\n", "versions": [{"version": "v1", "created": "Sat, 11 Aug 2018 21:23:24 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 18:22:01 GMT"}, {"version": "v3", "created": "Thu, 1 Nov 2018 14:41:56 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Elbayad", "Maha", ""], ["Besacier", "Laurent", ""], ["Verbeek", "Jakob", ""]]}, {"id": "1808.03894", "submitter": "Reza Ghaeini", "authors": "Reza Ghaeini, Xiaoli Z. Fern, Prasad Tadepalli", "title": "Interpreting Recurrent and Attention-Based Neural Models: a Case Study\n  on Natural Language Inference", "comments": "11 pages, 11 figures, accepted as a short paper at EMNLP 2018", "journal-ref": "EMNLP 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have achieved remarkable success in natural language\ninference (NLI) tasks. While these models are widely explored, they are hard to\ninterpret and it is often unclear how and why they actually work. In this\npaper, we take a step toward explaining such deep learning based models through\na case study on a popular neural model for NLI. In particular, we propose to\ninterpret the intermediate layers of NLI models by visualizing the saliency of\nattention and LSTM gating signals. We present several examples for which our\nmethods are able to reveal interesting insights and identify the critical\ninformation contributing to the model decisions.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2018 05:42:26 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Ghaeini", "Reza", ""], ["Fern", "Xiaoli Z.", ""], ["Tadepalli", "Prasad", ""]]}, {"id": "1808.03915", "submitter": "Motoki Sato", "authors": "Motoki Sato, Hiroki Ouch, Yuta Tsuboi", "title": "Addressee and Response Selection for Multilingual Conversation", "comments": "coling 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Developing conversational systems that can converse in many languages is an\ninteresting challenge for natural language processing. In this paper, we\nintroduce multilingual addressee and response selection. In this task, a\nconversational system predicts an appropriate addressee and response for an\ninput message in multiple languages. A key to developing such multilingual\nresponding systems is how to utilize high-resource language data to compensate\nfor low-resource language data. We present several knowledge transfer methods\nfor conversational systems. To evaluate our methods, we create a new\nmultilingual conversation dataset. Experiments on the dataset demonstrate the\neffectiveness of our methods.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2018 09:37:25 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Sato", "Motoki", ""], ["Ouch", "Hiroki", ""], ["Tsuboi", "Yuta", ""]]}, {"id": "1808.03920", "submitter": "Paul Pu Liang", "authors": "Paul Pu Liang, Ziyin Liu, Amir Zadeh, Louis-Philippe Morency", "title": "Multimodal Language Analysis with Recurrent Multistage Fusion", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational modeling of human multimodal language is an emerging research\narea in natural language processing spanning the language, visual and acoustic\nmodalities. Comprehending multimodal language requires modeling not only the\ninteractions within each modality (intra-modal interactions) but more\nimportantly the interactions between modalities (cross-modal interactions). In\nthis paper, we propose the Recurrent Multistage Fusion Network (RMFN) which\ndecomposes the fusion problem into multiple stages, each of them focused on a\nsubset of multimodal signals for specialized, effective fusion. Cross-modal\ninteractions are modeled using this multistage fusion approach which builds\nupon intermediate representations of previous stages. Temporal and intra-modal\ninteractions are modeled by integrating our proposed fusion approach with a\nsystem of recurrent neural networks. The RMFN displays state-of-the-art\nperformance in modeling human multimodal language across three public datasets\nrelating to multimodal sentiment analysis, emotion recognition, and speaker\ntraits recognition. We provide visualizations to show that each stage of fusion\nfocuses on a different subset of multimodal signals, learning increasingly\ndiscriminative multimodal representations.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2018 10:04:45 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Liang", "Paul Pu", ""], ["Liu", "Ziyin", ""], ["Zadeh", "Amir", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1808.03926", "submitter": "Adnan Akhundov", "authors": "Adnan Akhundov, Dietrich Trautmann, Georg Groh", "title": "Sequence Labeling: A Practical Approach", "comments": "For the source code and detailed experimental results, see\n  http://github.com/aakhundov/sequence-labeling", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We take a practical approach to solving sequence labeling problem assuming\nunavailability of domain expertise and scarcity of informational and\ncomputational resources. To this end, we utilize a universal end-to-end\nBi-LSTM-based neural sequence labeling model applicable to a wide range of NLP\ntasks and languages. The model combines morphological, semantic, and structural\ncues extracted from data to arrive at informed predictions. The model's\nperformance is evaluated on eight benchmark datasets (covering three tasks:\nPOS-tagging, NER, and Chunking, and four languages: English, German, Dutch, and\nSpanish). We observe state-of-the-art results on four of them: CoNLL-2012\n(English NER), CoNLL-2002 (Dutch NER), GermEval 2014 (German NER), Tiger Corpus\n(German POS-tagging), and competitive performance on the rest.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2018 11:53:04 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Akhundov", "Adnan", ""], ["Trautmann", "Dietrich", ""], ["Groh", "Georg", ""]]}, {"id": "1808.03967", "submitter": "Akshay Budhkar", "authors": "Akshay Budhkar and Frank Rudzicz", "title": "Augmenting word2vec with latent Dirichlet allocation within a clinical\n  application", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents three hybrid models that directly combine latent\nDirichlet allocation and word embedding for distinguishing between speakers\nwith and without Alzheimer's disease from transcripts of picture descriptions.\nTwo of our models get F-scores over the current state-of-the-art using\nautomatic methods on the DementiaBank dataset.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2018 16:32:18 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Budhkar", "Akshay", ""], ["Rudzicz", "Frank", ""]]}, {"id": "1808.03976", "submitter": "Sungchul Choi", "authors": "Jaeyoung Kim, Sion Jang, Sungchul Choi, Eunjeong Park", "title": "Text Classification using Capsules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an empirical exploration of the use of capsule networks\nfor text classification. While it has been shown that capsule networks are\neffective for image classification, their validity in the domain of text has\nnot been explored. In this paper, we show that capsule networks indeed have the\npotential for text classification and that they have several advantages over\nconvolutional neural networks. We further suggest a simple routing method that\neffectively reduces the computational complexity of dynamic routing. We\nutilized seven benchmark datasets to demonstrate that capsule networks, along\nwith the proposed routing method provide comparable results.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2018 18:08:38 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 00:41:23 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Kim", "Jaeyoung", ""], ["Jang", "Sion", ""], ["Choi", "Sungchul", ""], ["Park", "Eunjeong", ""]]}, {"id": "1808.03986", "submitter": "Badri Narayana Patro", "authors": "Badri N. Patro, Sandeep Kumar, Vinod K. Kurmi, Vinay P. Namboodiri", "title": "Multimodal Differential Network for Visual Question Generation", "comments": "EMNLP 2018 (accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Generating natural questions from an image is a semantic task that requires\nusing visual and language modality to learn multimodal representations. Images\ncan have multiple visual and language contexts that are relevant for generating\nquestions namely places, captions, and tags. In this paper, we propose the use\nof exemplars for obtaining the relevant context. We obtain this by using a\nMultimodal Differential Network to produce natural and engaging questions. The\ngenerated questions show a remarkable similarity to the natural questions as\nvalidated by a human study. Further, we observe that the proposed approach\nsubstantially improves over state-of-the-art benchmarks on the quantitative\nmetrics (BLEU, METEOR, ROUGE, and CIDEr).\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2018 18:56:56 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 10:23:19 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Patro", "Badri N.", ""], ["Kumar", "Sandeep", ""], ["Kurmi", "Vinod K.", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "1808.04029", "submitter": "Antonio Jose Jimeno Yepes", "authors": "Antonio Jimeno Yepes", "title": "Confidence penalty, annealing Gaussian noise and zoneout for biLSTM-CRF\n  networks for named entity recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity recognition (NER) is used to identify relevant entities in text.\nA bidirectional LSTM (long short term memory) encoder with a neural conditional\nrandom fields (CRF) decoder (biLSTM-CRF) is the state of the art methodology.\nIn this work, we have done an analysis of several methods that intend to\noptimize the performance of networks based on this architecture, which in some\ncases encourage overfitting avoidance. These methods target exploration of\nparameter space, regularization of LSTMs and penalization of confident output\ndistributions. Results show that the optimization methods improve the\nperformance of the biLSTM-CRF NER baseline system, setting a new state of the\nart performance for the CoNLL-2003 Spanish set with an F1 of 87.18.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 00:16:55 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 01:14:42 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Yepes", "Antonio Jimeno", ""]]}, {"id": "1808.04064", "submitter": "Zhirui Zhang", "authors": "Zhirui Zhang, Shuangzhi Wu, Shujie Liu, Mu Li, Ming Zhou, Tong Xu", "title": "Regularizing Neural Machine Translation by Target-bidirectional\n  Agreement", "comments": "Accepted by AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Neural Machine Translation (NMT) has achieved remarkable progress in\nthe past several years, most NMT systems still suffer from a fundamental\nshortcoming as in other sequence generation tasks: errors made early in\ngeneration process are fed as inputs to the model and can be quickly amplified,\nharming subsequent sequence generation. To address this issue, we propose a\nnovel model regularization method for NMT training, which aims to improve the\nagreement between translations generated by left-to-right (L2R) and\nright-to-left (R2L) NMT decoders. This goal is achieved by introducing two\nKullback-Leibler divergence regularization terms into the NMT training\nobjective to reduce the mismatch between output probabilities of L2R and R2L\nmodels. In addition, we also employ a joint training strategy to allow L2R and\nR2L models to improve each other in an interactive update process. Experimental\nresults show that our proposed method significantly outperforms\nstate-of-the-art baselines on Chinese-English and English-German translation\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 05:03:42 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 19:08:27 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Zhang", "Zhirui", ""], ["Wu", "Shuangzhi", ""], ["Liu", "Shujie", ""], ["Li", "Mu", ""], ["Zhou", "Ming", ""], ["Xu", "Tong", ""]]}, {"id": "1808.04071", "submitter": "Yanpeng Zhao", "authors": "Yanpeng Zhao, Wei Bi, Deng Cai, Xiaojiang Liu, Kewei Tu, Shuming Shi", "title": "Language Style Transfer from Sentences with Arbitrary Unknown Styles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Language style transfer is the problem of migrating the content of a source\nsentence to a target style. In many of its applications, parallel training data\nare not available and source sentences to be transferred may have arbitrary and\nunknown styles. First, each sentence is encoded into its content and style\nlatent representations. Then, by recombining the content with the target style,\nwe decode a sentence aligned in the target domain. To adequately constrain the\nencoding and decoding functions, we couple them with two loss functions. The\nfirst is a style discrepancy loss, enforcing that the style representation\naccurately encodes the style information guided by the discrepancy between the\nsentence style and the target style. The second is a cycle consistency loss,\nwhich ensures that the transferred sentence should preserve the content of the\noriginal sentence disentangled from its style. We validate the effectiveness of\nour model in three tasks: sentiment modification of restaurant reviews, dialog\nresponse revision with a romantic style, and sentence rewriting with a\nShakespearean style.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 06:08:45 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Zhao", "Yanpeng", ""], ["Bi", "Wei", ""], ["Cai", "Deng", ""], ["Liu", "Xiaojiang", ""], ["Tu", "Kewei", ""], ["Shi", "Shuming", ""]]}, {"id": "1808.04091", "submitter": "Damai Dai", "authors": "Damai Dai", "title": "Live Video Comment Generation Based on Surrounding Frames and Live\n  Comments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the task of live comment generation. Live comments\nare a new form of comments on videos, which can be regarded as a mixture of\ncomments and chats. A high-quality live comment should be not only relevant to\nthe video, but also interactive with other users. In this work, we first\nconstruct a new dataset for live comment generation. Then, we propose a novel\nend-to-end model to generate the human-like live comments by referring to the\nvideo and the other users' comments. Finally, we evaluate our model on the\nconstructed dataset. Experimental results show that our method can\nsignificantly outperform the baselines.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 07:52:49 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Dai", "Damai", ""]]}, {"id": "1808.04108", "submitter": "Chia-Hung Wan", "authors": "Chia-Hung Wan, Shun-Po Chuang and Hung-Yi Lee", "title": "Towards Audio to Scene Image Synthesis using Generative Adversarial\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can imagine a scene from a sound. We want machines to do so by using\nconditional generative adversarial networks (GANs). By applying the techniques\nincluding spectral norm, projection discriminator and auxiliary classifier,\ncompared with naive conditional GAN, the model can generate images with better\nquality in terms of both subjective and objective evaluations. Almost\nthree-fourth of people agree that our model have the ability to generate images\nrelated to sounds. By inputting different volumes of the same sound, our model\noutput different scales of changes based on the volumes, showing that our model\ntruly knows the relationship between sounds and images to some extent.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 08:46:42 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Wan", "Chia-Hung", ""], ["Chuang", "Shun-Po", ""], ["Lee", "Hung-Yi", ""]]}, {"id": "1808.04122", "submitter": "Dai Quoc Nguyen", "authors": "Dai Quoc Nguyen and Thanh Vu and Tu Dinh Nguyen and Dat Quoc Nguyen\n  and Dinh Phung", "title": "A Capsule Network-based Embedding Model for Knowledge Graph Completion\n  and Search Personalization", "comments": "To appear in Proceedings of NAACL 2019. 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce an embedding model, named CapsE, exploring a\ncapsule network to model relationship triples (subject, relation, object). Our\nCapsE represents each triple as a 3-column matrix where each column vector\nrepresents the embedding of an element in the triple. This 3-column matrix is\nthen fed to a convolution layer where multiple filters are operated to generate\ndifferent feature maps. These feature maps are reconstructed into corresponding\ncapsules which are then routed to another capsule to produce a continuous\nvector. The length of this vector is used to measure the plausibility score of\nthe triple. Our proposed CapsE obtains better performance than previous\nstate-of-the-art embedding models for knowledge graph completion on two\nbenchmark datasets WN18RR and FB15k-237, and outperforms strong search\npersonalization baselines on SEARCH17.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 09:35:44 GMT"}, {"version": "v2", "created": "Sun, 19 Aug 2018 03:46:29 GMT"}, {"version": "v3", "created": "Wed, 6 Mar 2019 10:59:09 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Nguyen", "Dai Quoc", ""], ["Vu", "Thanh", ""], ["Nguyen", "Tu Dinh", ""], ["Nguyen", "Dat Quoc", ""], ["Phung", "Dinh", ""]]}, {"id": "1808.04126", "submitter": "Daniil Sorokin", "authors": "Daniil Sorokin and Iryna Gurevych", "title": "Modeling Semantics with Gated Graph Neural Networks for Knowledge Base\n  Question Answering", "comments": "Accepted as COLING 2018 Long Paper, 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most approaches to Knowledge Base Question Answering are based on\nsemantic parsing. In this paper, we address the problem of learning vector\nrepresentations for complex semantic parses that consist of multiple entities\nand relations. Previous work largely focused on selecting the correct semantic\nrelations for a question and disregarded the structure of the semantic parse:\nthe connections between entities and the directions of the relations. We\npropose to use Gated Graph Neural Networks to encode the graph structure of the\nsemantic parse. We show on two data sets that the graph networks outperform all\nbaseline models that do not explicitly model the structure. The error analysis\nconfirms that our approach can successfully process complex semantic parses.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 09:50:43 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Sorokin", "Daniil", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1808.04127", "submitter": "Robert Schwarzenberg", "authors": "David Harbecke, Robert Schwarzenberg, Christoph Alt", "title": "Learning Explanations from Language Data", "comments": "Appears in 2018 EMNLP Workshop on Analyzing and Interpreting Neural\n  Networks for NLP (BlackboxNLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PatternAttribution is a recent method, introduced in the vision domain, that\nexplains classifications of deep neural networks. We demonstrate that it also\ngenerates meaningful interpretations in the language domain.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 09:51:46 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Harbecke", "David", ""], ["Schwarzenberg", "Robert", ""], ["Alt", "Christoph", ""]]}, {"id": "1808.04151", "submitter": "Soravit Changpinyo", "authors": "Soravit Changpinyo, Hexiang Hu, Fei Sha", "title": "Multi-Task Learning for Sequence Tagging: An Empirical Study", "comments": "In Proceedings of the 27th International Conference on Computational\n  Linguistics (COLING 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study three general multi-task learning (MTL) approaches on 11 sequence\ntagging tasks. Our extensive empirical results show that in about 50% of the\ncases, jointly learning all 11 tasks improves upon either independent or\npairwise learning of the tasks. We also show that pairwise MTL can inform us\nwhat tasks can benefit others or what tasks can be benefited if they are\nlearned jointly. In particular, we identify tasks that can always benefit\nothers as well as tasks that can always be harmed by others. Interestingly, one\nof our MTL approaches yields embeddings of the tasks that reveal the natural\nclustering of semantic and syntactic tasks. Our inquiries have opened the doors\nto further utilization of MTL in NLP.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 11:15:23 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Changpinyo", "Soravit", ""], ["Hu", "Hexiang", ""], ["Sha", "Fei", ""]]}, {"id": "1808.04164", "submitter": "Christian Hardmeier", "authors": "Liane Guillou and Christian Hardmeier", "title": "Automatic Reference-Based Evaluation of Pronoun Translation Misses the\n  Point", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare the performance of the APT and AutoPRF metrics for pronoun\ntranslation against a manually annotated dataset comprising human judgements as\nto the correctness of translations of the PROTEST test suite. Although there is\nsome correlation with the human judgements, a range of issues limit the\nperformance of the automated metrics. Instead, we recommend the use of\nsemi-automatic metrics and test suites in place of fully automatic metrics.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 12:04:44 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Guillou", "Liane", ""], ["Hardmeier", "Christian", ""]]}, {"id": "1808.04189", "submitter": "Graham Neubig", "authors": "Graham Neubig, Junjie Hu", "title": "Rapid Adaptation of Neural Machine Translation to New Languages", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines the problem of adapting neural machine translation\nsystems to new, low-resourced languages (LRLs) as effectively and rapidly as\npossible. We propose methods based on starting with massively multilingual\n\"seed models\", which can be trained ahead-of-time, and then continuing training\non data related to the LRL. We contrast a number of strategies, leading to a\nnovel, simple, yet effective method of \"similar-language regularization\", where\nwe jointly train on both a LRL of interest and a similar high-resourced\nlanguage to prevent over-fitting to small LRL data. Experiments demonstrate\nthat massively multilingual models, even without any explicit adaptation, are\nsurprisingly effective, achieving BLEU scores of up to 15.5 with no data from\nthe LRL, and that the proposed similar-language regularization method improves\nover other adaptation methods by 1.7 BLEU points average over 4 LRL settings.\nCode to reproduce experiments at https://github.com/neubig/rapid-adaptation\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 13:06:24 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Neubig", "Graham", ""], ["Hu", "Junjie", ""]]}, {"id": "1808.04208", "submitter": "Heike Adel", "authors": "Apostolos Kemos and Heike Adel and Hinrich Sch\\\"utze", "title": "Neural Semi-Markov Conditional Random Fields for Robust Character-Based\n  Part-of-Speech Tagging", "comments": "NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Character-level models of tokens have been shown to be effective at dealing\nwith within-token noise and out-of-vocabulary words. But these models still\nrely on correct token boundaries. In this paper, we propose a novel end-to-end\ncharacter-level model and demonstrate its effectiveness in multilingual\nsettings and when token boundaries are noisy. Our model is a semi-Markov\nconditional random field with neural networks for character and segment\nrepresentation. It requires no tokenizer. The model matches state-of-the-art\nbaselines for various languages and significantly outperforms them on a noisy\nEnglish version of a part-of-speech tagging benchmark dataset. Our code and the\nnoisy dataset are publicly available at http://cistern.cis.lmu.de/semiCRF.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 13:44:22 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 18:47:19 GMT"}, {"version": "v3", "created": "Thu, 2 Jan 2020 10:35:51 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Kemos", "Apostolos", ""], ["Adel", "Heike", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1808.04216", "submitter": "Tobias Backes", "authors": "Tobias Backes", "title": "Effective Unsupervised Author Disambiguation with Relative Frequencies", "comments": "Proceedings of JCDL 2018", "journal-ref": null, "doi": "10.1145/3197026.3197036", "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This work addresses the problem of author name homonymy in the Web of\nScience. Aiming for an efficient, simple and straightforward solution, we\nintroduce a novel probabilistic similarity measure for author name\ndisambiguation based on feature overlap. Using the researcher-ID available for\na subset of the Web of Science, we evaluate the application of this measure in\nthe context of agglomeratively clustering author mentions. We focus on a\nconcise evaluation that shows clearly for which problem setups and at which\ntime during the clustering process our approach works best. In contrast to most\nother works in this field, we are sceptical towards the performance of author\nname disambiguation methods in general and compare our approach to the trivial\nsingle-cluster baseline. Our results are presented separately for each correct\nclustering size as we can explain that, when treating all cases together, the\ntrivial baseline and more sophisticated approaches are hardly distinguishable\nin terms of evaluation results. Our model shows state-of-the-art performance\nfor all correct clustering sizes without any discriminative training and with\ntuning only one convergence parameter.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 10:09:54 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Backes", "Tobias", ""]]}, {"id": "1808.04217", "submitter": "Siddhartha Brahma", "authors": "Siddhartha Brahma", "title": "Unsupervised Learning of Sentence Representations Using Sequence\n  Consistency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing universal distributed representations of sentences is a fundamental\ntask in natural language processing. We propose ConsSent, a simple yet\nsurprisingly powerful unsupervised method to learn such representations by\nenforcing consistency constraints on sequences of tokens. We consider two\nclasses of such constraints -- sequences that form a sentence and between two\nsequences that form a sentence when merged. We learn sentence encoders by\ntraining them to distinguish between consistent and inconsistent examples, the\nlatter being generated by randomly perturbing consistent examples in six\ndifferent ways. Extensive evaluation on several transfer learning and\nlinguistic probing tasks shows improved performance over strong unsupervised\nand supervised baselines, substantially surpassing them in several cases. Our\nbest results are achieved by training sentence encoders in a multitask setting\nand by an ensemble of encoders trained on the individual tasks.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 08:15:01 GMT"}, {"version": "v2", "created": "Sat, 29 Sep 2018 16:24:31 GMT"}, {"version": "v3", "created": "Thu, 3 Jan 2019 19:25:44 GMT"}, {"version": "v4", "created": "Wed, 23 Jan 2019 19:54:25 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Brahma", "Siddhartha", ""]]}, {"id": "1808.04254", "submitter": "Gizem Karaali", "authors": "Herbert Gangl, Gizem Karaali, Woohyung Lee", "title": "Homophonic Quotients of Linguistic Free Groups: German, Korean, and\n  Turkish", "comments": null, "journal-ref": "Revised and final version at: Involve 12:3 (2019) 463-474", "doi": null, "report-no": null, "categories": "math.GR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1993, the homophonic quotient groups for French and English (the quotient\nof the free group generated by the French (respectively English) alphabet\ndetermined by relations representing standard pronunciation rules) were\nexplicitly characterized [5]. In this paper we apply the same methodology to\nthree different language systems: German, Korean, and Turkish. We argue that\nour results point to some interesting differences between these three languages\n(or at least their current script systems).\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 12:40:58 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Gangl", "Herbert", ""], ["Karaali", "Gizem", ""], ["Lee", "Woohyung", ""]]}, {"id": "1808.04314", "submitter": "Victor Mijangos Mr.", "authors": "Ximena Gutierrez-Vasques and Victor Mijangos", "title": "Comparing morphological complexity of Spanish, Otomi and Nahuatl", "comments": "7 pages, CLING 2018 Workshop on Linguistic Complexity and Natural\n  Language Processing (LC&NLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use two small parallel corpora for comparing the morphological complexity\nof Spanish, Otomi and Nahuatl. These are languages that belong to different\nlinguistic families, the latter are low-resourced. We take into account two\nquantitative criteria, on one hand the distribution of types over tokens in a\ncorpus, on the other, perplexity and entropy as indicators of word structure\npredictability. We show that a language can be complex in terms of how many\ndifferent morphological word forms can produce, however, it may be less complex\nin terms of predictability of its internal structure of words.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 16:16:11 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Gutierrez-Vasques", "Ximena", ""], ["Mijangos", "Victor", ""]]}, {"id": "1808.04334", "submitter": "James O' Neill", "authors": "James O' Neill and Danushka Bollegala", "title": "Angular-Based Word Meta-Embedding Learning", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ensembling word embeddings to improve distributed word representations has\nshown good success for natural language processing tasks in recent years. These\napproaches either carry out straightforward mathematical operations over a set\nof vectors or use unsupervised learning to find a lower-dimensional\nrepresentation. This work compares meta-embeddings trained for different\nlosses, namely loss functions that account for angular distance between the\nreconstructed embedding and the target and those that account normalized\ndistances based on the vector length. We argue that meta-embeddings are better\nto treat the ensemble set equally in unsupervised learning as the respective\nquality of each embedding is unknown for upstream tasks prior to\nmeta-embedding. We show that normalization methods that account for this such\nas cosine and KL-divergence objectives outperform meta-embedding trained on\nstandard $\\ell_1$ and $\\ell_2$ loss on \\textit{defacto} word similarity and\nrelatedness datasets and find it outperforms existing meta-learning strategies.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 17:20:20 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Neill", "James O'", ""], ["Bollegala", "Danushka", ""]]}, {"id": "1808.04339", "submitter": "Vineet John", "authors": "Vineet John, Lili Mou, Hareesh Bahuleyan, Olga Vechtomova", "title": "Disentangled Representation Learning for Non-Parallel Text Style\n  Transfer", "comments": "11 pages, 7 figures, 6 tables; Preliminary work rejected by EMNLP-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tackles the problem of disentangling the latent variables of style\nand content in language models. We propose a simple yet effective approach,\nwhich incorporates auxiliary multi-task and adversarial objectives, for label\nprediction and bag-of-words prediction, respectively. We show, both\nqualitatively and quantitatively, that the style and content are indeed\ndisentangled in the latent space. This disentangled latent representation\nlearning method is applied to style transfer on non-parallel corpora. We\nachieve substantially better results in terms of transfer accuracy, content\npreservation and language fluency, in comparison to previous state-of-the-art\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 17:26:49 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 03:42:33 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["John", "Vineet", ""], ["Mou", "Lili", ""], ["Bahuleyan", "Hareesh", ""], ["Vechtomova", "Olga", ""]]}, {"id": "1808.04343", "submitter": "Siddhartha Brahma", "authors": "Siddhartha Brahma", "title": "REGMAPR - Text Matching Made Easy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text matching is a fundamental problem in natural language processing. Neural\nmodels using bidirectional LSTMs for sentence encoding and inter-sentence\nattention mechanisms perform remarkably well on several benchmark datasets. We\npropose REGMAPR - a simple and general architecture for text matching that does\nnot use inter-sentence attention. Starting from a Siamese architecture, we\naugment the embeddings of the words with two features based on exact and para-\nphrase match between words in the two sentences. We train the model using three\ntypes of regularization on datasets for textual entailment, paraphrase\ndetection and semantic related- ness. REGMAPR performs comparably or better\nthan more complex neural models or models using a large number of handcrafted\nfeatures. REGMAPR achieves state-of-the-art results for paraphrase detection on\nthe SICK dataset and for textual entailment on the SNLI dataset among models\nthat do not use inter-sentence attention.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 17:38:54 GMT"}, {"version": "v2", "created": "Wed, 29 Aug 2018 03:28:55 GMT"}, {"version": "v3", "created": "Mon, 10 Sep 2018 22:12:53 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Brahma", "Siddhartha", ""]]}, {"id": "1808.04359", "submitter": "Akshat Agarwal", "authors": "Akshat Agarwal, Swaminathan Gurumurthy, Vasu Sharma, Mike Lewis, Katia\n  Sycara", "title": "Community Regularization of Visually-Grounded Dialog", "comments": "7 pages, ICML/AAMAS Adaptive Learning Agents Workshop 2018 and CVPR\n  Visual Dialog Workshop 2018. Code available at\n  https://github.com/agakshat/visualdialog-pytorch", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of conducting visually grounded dialog involves learning\ngoal-oriented cooperative dialog between autonomous agents who exchange\ninformation about a scene through several rounds of questions and answers in\nnatural language. We posit that requiring artificial agents to adhere to the\nrules of human language, while also requiring them to maximize information\nexchange through dialog is an ill-posed problem. We observe that humans do not\nstray from a common language because they are social creatures who live in\ncommunities, and have to communicate with many people everyday, so it is far\neasier to stick to a common language even at the cost of some efficiency loss.\nUsing this as inspiration, we propose and evaluate a multi-agent\ncommunity-based dialog framework where each agent interacts with, and learns\nfrom, multiple agents, and show that this community-enforced regularization\nresults in more relevant and coherent dialog (as judged by human evaluators)\nwithout sacrificing task performance (as judged by quantitative metrics).\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 22:09:43 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 20:01:29 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Agarwal", "Akshat", ""], ["Gurumurthy", "Swaminathan", ""], ["Sharma", "Vasu", ""], ["Lewis", "Mike", ""], ["Sycara", "Katia", ""]]}, {"id": "1808.04364", "submitter": "Qiongkai Xu", "authors": "Qiongkai Xu, Juyan Zhang, Lizhen Qu, Lexing Xie, Richard Nock", "title": "D-PAGE: Diverse Paraphrase Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the diversity aspect of paraphrase generation.\nPrior deep learning models employ either decoding methods or add random input\nnoise for varying outputs. We propose a simple method Diverse Paraphrase\nGeneration (D-PAGE), which extends neural machine translation (NMT) models to\nsupport the generation of diverse paraphrases with implicit rewriting patterns.\nOur experimental results on two real-world benchmark datasets demonstrate that\nour model generates at least one order of magnitude more diverse outputs than\nthe baselines in terms of a new evaluation metric Jeffrey's Divergence. We have\nalso conducted extensive experiments to understand various properties of our\nmodel with a focus on diversity.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 10:18:54 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Xu", "Qiongkai", ""], ["Zhang", "Juyan", ""], ["Qu", "Lizhen", ""], ["Xie", "Lexing", ""], ["Nock", "Richard", ""]]}, {"id": "1808.04365", "submitter": "Ivan P Yamshchikov", "authors": "Alexey Tikhonov, Ivan P. Yamshchikov", "title": "What is wrong with style transfer for texts?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of recent machine learning papers work with an automated style\ntransfer for texts and, counter to intuition, demonstrate that there is no\nconsensus formulation of this NLP task. Different researchers propose different\nalgorithms, datasets and target metrics to address it. This short opinion paper\naims to discuss possible formalization of this NLP task in anticipation of a\nfurther growing interest to it.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 11:50:03 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Tikhonov", "Alexey", ""], ["Yamshchikov", "Ivan P.", ""]]}, {"id": "1808.04444", "submitter": "Rami Al-Rfou", "authors": "Rami Al-Rfou, Dokook Choe, Noah Constant, Mandy Guo, Llion Jones", "title": "Character-Level Language Modeling with Deeper Self-Attention", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LSTMs and other RNN variants have shown strong performance on character-level\nlanguage modeling. These models are typically trained using truncated\nbackpropagation through time, and it is common to assume that their success\nstems from their ability to remember long-term contexts. In this paper, we show\nthat a deep (64-layer) transformer model with fixed context outperforms RNN\nvariants by a large margin, achieving state of the art on two popular\nbenchmarks: 1.13 bits per character on text8 and 1.06 on enwik8. To get good\nresults at this depth, we show that it is important to add auxiliary losses,\nboth at intermediate network layers and intermediate sequence positions.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 18:44:38 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 17:08:57 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Al-Rfou", "Rami", ""], ["Choe", "Dokook", ""], ["Constant", "Noah", ""], ["Guo", "Mandy", ""], ["Jones", "Llion", ""]]}, {"id": "1808.04446", "submitter": "Mathieu Seurin", "authors": "Florian Strub and Mathieu Seurin and Ethan Perez and Harm de Vries and\n  J\\'er\\'emie Mary and Philippe Preux and Aaron Courville and Olivier Pietquin", "title": "Visual Reasoning with Multi-hop Feature Modulation", "comments": "In Proc of ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent breakthroughs in computer vision and natural language processing have\nspurred interest in challenging multi-modal tasks such as visual\nquestion-answering and visual dialogue. For such tasks, one successful approach\nis to condition image-based convolutional network computation on language via\nFeature-wise Linear Modulation (FiLM) layers, i.e., per-channel scaling and\nshifting. We propose to generate the parameters of FiLM layers going up the\nhierarchy of a convolutional network in a multi-hop fashion rather than all at\nonce, as in prior work. By alternating between attending to the language input\nand generating FiLM layer parameters, this approach is better able to scale to\nsettings with longer input sequences such as dialogue. We demonstrate that\nmulti-hop FiLM generation achieves state-of-the-art for the short input\nsequence task ReferIt --- on-par with single-hop FiLM generation --- while also\nsignificantly outperforming prior state-of-the-art and single-hop FiLM\ngeneration on the GuessWhat?! visual dialogue task.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2018 14:32:02 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 11:36:42 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Strub", "Florian", ""], ["Seurin", "Mathieu", ""], ["Perez", "Ethan", ""], ["de Vries", "Harm", ""], ["Mary", "J\u00e9r\u00e9mie", ""], ["Preux", "Philippe", ""], ["Courville", "Aaron", ""], ["Pietquin", "Olivier", ""]]}, {"id": "1808.04459", "submitter": "Sarvesh Patil", "authors": "Sarvesh Patil", "title": "Deep Learning Based Natural Language Processing for End to End Speech\n  Translation", "comments": "4 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep Learning methods employ multiple processing layers to learn hierarchial\nrepresentations of data. They have already been deployed in a humongous number\nof applications and have produced state-of-the-art results. Recently with the\ngrowth in processing power of computers to be able to do high dimensional\ntensor calculations, Natural Language Processing (NLP) applications have been\ngiven a significant boost in terms of efficiency as well as accuracy. In this\npaper, we will take a look at various signal processing techniques and then\napplication of them to produce a speech-to-text system using Deep Recurrent\nNeural Networks.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 14:21:35 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Patil", "Sarvesh", ""]]}, {"id": "1808.04525", "submitter": "Raphael Shu", "authors": "Raphael Shu and Hideki Nakayama", "title": "Discrete Structural Planning for Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural planning is important for producing long sentences, which is a\nmissing part in current language generation models. In this work, we add a\nplanning phase in neural machine translation to control the coarse structure of\noutput sentences. The model first generates some planner codes, then predicts\nreal output words conditioned on them. The codes are learned to capture the\ncoarse structure of the target sentence. In order to obtain the codes, we\ndesign an end-to-end neural network with a discretization bottleneck, which\npredicts the simplified part-of-speech tags of target sentences. Experiments\nshow that the translation performance are generally improved by planning ahead.\nWe also find that translations with different structures can be obtained by\nmanipulating the planner codes.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 05:13:23 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Shu", "Raphael", ""], ["Nakayama", "Hideki", ""]]}, {"id": "1808.04538", "submitter": "Satya Krishna Gorti", "authors": "Satya Krishna Gorti and Jeremy Ma", "title": "Text-to-Image-to-Text Translation using Cycle Consistent Adversarial\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Text-to-Image translation has been an active area of research in the recent\npast. The ability for a network to learn the meaning of a sentence and generate\nan accurate image that depicts the sentence shows ability of the model to think\nmore like humans. Popular methods on text to image translation make use of\nGenerative Adversarial Networks (GANs) to generate high quality images based on\ntext input, but the generated images don't always reflect the meaning of the\nsentence given to the model as input. We address this issue by using a\ncaptioning network to caption on generated images and exploit the distance\nbetween ground truth captions and generated captions to improve the network\nfurther. We show extensive comparisons between our method and existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 05:45:25 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Gorti", "Satya Krishna", ""], ["Ma", "Jeremy", ""]]}, {"id": "1808.04614", "submitter": "Tomer Wolfson", "authors": "Jonathan Berant, Daniel Deutch, Amir Globerson, Tova Milo, Tomer\n  Wolfson", "title": "Explaining Queries over Web Tables to Non-Experts", "comments": "Short paper version to appear in ICDE 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing a reliable natural language (NL) interface for querying tables has\nbeen a longtime goal of researchers in both the data management and natural\nlanguage processing (NLP) communities. Such an interface receives as input an\nNL question, translates it into a formal query, executes the query and returns\nthe results. Errors in the translation process are not uncommon, and users\ntypically struggle to understand whether their query has been mapped correctly.\nWe address this problem by explaining the obtained formal queries to non-expert\nusers. Two methods for query explanations are presented: the first translates\nqueries into NL, while the second method provides a graphic representation of\nthe query cell-based provenance (in its execution on a given table). Our\nsolution augments a state-of-the-art NL interface over web tables, enhancing it\nin both its training and deployment phase. Experiments, including a user study\nconducted on Amazon Mechanical Turk, show our solution to improve both the\ncorrectness and reliability of an NL interface.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 10:23:32 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Berant", "Jonathan", ""], ["Deutch", "Daniel", ""], ["Globerson", "Amir", ""], ["Milo", "Tova", ""], ["Wolfson", "Tomer", ""]]}, {"id": "1808.04660", "submitter": "Zhiyuan Zhang", "authors": "Zhiyuan Zhang, Wei Li, Jingjing Xu and Xu Sun", "title": "Primal Meaning Recommendation via On-line Encyclopedia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polysemy is a very common phenomenon in modern languages. Under many\ncircumstances, there exists a primal meaning for the expression. We define the\nprimal meaning of an expression to be a frequently used sense of that\nexpression from which its other frequent senses can be deduced. Many of the new\nappearing meanings of the expressions are either originated from a primal\nmeaning, or are merely literal references to the original expression, e.g.,\napple (fruit), Apple (Inc), and Apple (movie). When constructing a knowledge\nbase from on-line encyclopedia data, it would be more efficient to be aware of\nthe information about the importance of the senses. In this paper, we would\nlike to explore a way to automatically recommend the primal meaning of an\nexpression based on the textual descriptions of the multiple senses of an\nexpression from on-line encyclopedia websites. We propose a hybrid model that\ncaptures both the pattern of the description and the relationship between\ndifferent descriptions with both weakly supervised and unsupervised models. The\nexperiment results show that our method yields a good result with a P@1\n(precision) score of 83.3 per cent, and a MAP (mean average precision) of 90.5\nper cent, surpassing the UMFS-WE baseline by a big margin (P@1 is 61.1 per cent\nand MAP is 76.3 per cent).\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 12:37:31 GMT"}, {"version": "v2", "created": "Tue, 9 Apr 2019 04:53:55 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Zhang", "Zhiyuan", ""], ["Li", "Wei", ""], ["Xu", "Jingjing", ""], ["Sun", "Xu", ""]]}, {"id": "1808.04670", "submitter": "Ariel Ekgren", "authors": "Ariel Ekgren, Amaru Cuba Gyllensten, Magnus Sahlgren", "title": "R-grams: Unsupervised Learning of Semantic Units in Natural Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper investigates data-driven segmentation using Re-Pair or Byte Pair\nEncoding-techniques. In contrast to previous work which has primarily been\nfocused on subword units for machine translation, we are interested in the\ngeneral properties of such segments above the word level. We call these\nsegments r-grams, and discuss their properties and the effect they have on the\ntoken frequency distribution. The proposed approach is evaluated by\ndemonstrating its viability in embedding techniques, both in monolingual and\nmultilingual test settings. We also provide a number of qualitative examples of\nthe proposed methodology, demonstrating its viability as a language-invariant\nsegmentation procedure.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 13:15:43 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 13:59:03 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Ekgren", "Ariel", ""], ["Gyllensten", "Amaru Cuba", ""], ["Sahlgren", "Magnus", ""]]}, {"id": "1808.04694", "submitter": "Man Liu", "authors": "Liu Man", "title": "A Hassle-Free Machine Learning Method for Cohort Selection of Clinical\n  Trials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional text classification techniques in clinical domain have heavily\nrelied on the manually extracted textual cues. This paper proposes a generally\nsupervised machine learning method that is equally hassle-free and does not use\nclinical knowledge. The employed methods were simple to implement, fast to run\nand yet effective. This paper proposes a novel named entity recognition (NER)\nbased an ensemble system capable of learning the keyword features in the\ndocument. Instead of merely considering the whole sentence/paragraph for\nanalysis, the NER based keyword features can stress the important clinic\nrelevant phases more. In addition, to capture the semantic information in the\ndocuments, the FastText features originating from the document level FastText\nclassification results are exploited.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 04:24:34 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Man", "Liu", ""]]}, {"id": "1808.04706", "submitter": "Fei Zuo", "authors": "Fei Zuo, Xiaopeng Li, Patrick Young, Lannan Luo, Qiang Zeng, Zhexin\n  Zhang", "title": "Neural Machine Translation Inspired Binary Code Similarity Comparison\n  beyond Function Pairs", "comments": "Accepted by Network and Distributed Systems Security (NDSS) Symposium\n  2019", "journal-ref": null, "doi": "10.14722/ndss.2019.23492", "report-no": null, "categories": "cs.SE cs.CL cs.CR cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary code analysis allows analyzing binary code without having access to\nthe corresponding source code. A binary, after disassembly, is expressed in an\nassembly language. This inspires us to approach binary analysis by leveraging\nideas and techniques from Natural Language Processing (NLP), a rich area\nfocused on processing text of various natural languages. We notice that binary\ncode analysis and NLP share a lot of analogical topics, such as semantics\nextraction, summarization, and classification. This work utilizes these ideas\nto address two important code similarity comparison problems. (I) Given a pair\nof basic blocks for different instruction set architectures (ISAs), determining\nwhether their semantics is similar or not; and (II) given a piece of code of\ninterest, determining if it is contained in another piece of assembly code for\na different ISA. The solutions to these two problems have many applications,\nsuch as cross-architecture vulnerability discovery and code plagiarism\ndetection. We implement a prototype system INNEREYE and perform a comprehensive\nevaluation. A comparison between our approach and existing approaches to\nProblem I shows that our system outperforms them in terms of accuracy,\nefficiency and scalability. And the case studies utilizing the system\ndemonstrate that our solution to Problem II is effective. Moreover, this\nresearch showcases how to apply ideas and techniques from NLP to large-scale\nbinary code analysis.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 22:26:08 GMT"}, {"version": "v2", "created": "Sun, 16 Dec 2018 21:50:13 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Zuo", "Fei", ""], ["Li", "Xiaopeng", ""], ["Young", "Patrick", ""], ["Luo", "Lannan", ""], ["Zeng", "Qiang", ""], ["Zhang", "Zhexin", ""]]}, {"id": "1808.04736", "submitter": "Heike Adel", "authors": "Heike Adel and Anton Bryl and David Weiss and Aliaksei Severyn", "title": "Adversarial Neural Networks for Cross-lingual Sequence Tagging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study cross-lingual sequence tagging with little or no labeled data in the\ntarget language. Adversarial training has previously been shown to be effective\nfor training cross-lingual sentence classifiers. However, it is not clear if\nlanguage-agnostic representations enforced by an adversarial language\ndiscriminator will also enable effective transfer for token-level prediction\ntasks. Therefore, we experiment with different types of adversarial training on\ntwo tasks: dependency parsing and sentence compression. We show that\nadversarial training consistently leads to improved cross-lingual performance\non each task compared to a conventionally trained baseline.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 15:12:55 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Adel", "Heike", ""], ["Bryl", "Anton", ""], ["Weiss", "David", ""], ["Severyn", "Aliaksei", ""]]}, {"id": "1808.04776", "submitter": "Jason  Weston", "authors": "Jason Weston, Emily Dinan, Alexander H. Miller", "title": "Retrieve and Refine: Improved Sequence Generation Models For Dialogue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence generation models for dialogue are known to have several problems:\nthey tend to produce short, generic sentences that are uninformative and\nunengaging. Retrieval models on the other hand can surface interesting\nresponses, but are restricted to the given retrieval set leading to erroneous\nreplies that cannot be tuned to the specific context. In this work we develop a\nmodel that combines the two approaches to avoid both their deficiencies: first\nretrieve a response and then refine it -- the final sequence generator treating\nthe retrieval as additional context. We show on the recent CONVAI2 challenge\ntask our approach produces responses superior to both standard retrieval and\ngeneration models in human evaluations.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 16:13:44 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 17:23:52 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Weston", "Jason", ""], ["Dinan", "Emily", ""], ["Miller", "Alexander H.", ""]]}, {"id": "1808.04800", "submitter": "Marcos Zampieri", "authors": "Liviu P. Dinu, Alina Maria Ciobanu, Marcos Zampieri, Shervin Malmasi", "title": "Classifier Ensembles for Dialect and Language Variety Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present ensemble-based systems for dialect and language\nvariety identification using the datasets made available by the organizers of\nthe VarDial Evaluation Campaign 2018. We present a system developed to\ndiscriminate between Flemish and Dutch in subtitles and a system trained to\ndiscriminate between four Arabic dialects: Egyptian, Levantine, Gulf, North\nAfrican, and Modern Standard Arabic in speech broadcasts. Finally, we compare\nthe performance of these two systems with the other systems submitted to the\nDiscriminating between Dutch and Flemish in Subtitles (DFS) and the Arabic\nDialect Identification (ADI) shared tasks at VarDial 2018.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 17:22:25 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Dinu", "Liviu P.", ""], ["Ciobanu", "Alina Maria", ""], ["Zampieri", "Marcos", ""], ["Malmasi", "Shervin", ""]]}, {"id": "1808.04816", "submitter": "Ankur Padia", "authors": "Ankur Padia, Frank Ferraro, Tim Finin", "title": "KGCleaner : Identifying and Correcting Errors Produced by Information\n  Extraction Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  KGCleaner is a framework to identify and correct errors in data produced and\ndelivered by an information extraction system. These tasks have been\nunderstudied and KGCleaner is the first to address both. We introduce a\nmulti-task model that jointly learns to predict if an extracted relation is\ncredible and repair it if not. We evaluate our approach and other models as\ninstance of our framework on two collections: a Wikidata corpus of nearly 700K\nfacts and 5M fact-relevant sentences and a collection of 30K facts from the\n2015 TAC Knowledge Base Population task. For credibility classification,\nparameter efficient simple shallow neural network can achieve an absolute\nperformance gain of 30 $F_1$ points on Wikidata and comparable performance on\nTAC. For the repair task, significant performance (at more than twice) gain can\nbe obtained depending on the nature of the dataset and the models.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 17:55:13 GMT"}, {"version": "v2", "created": "Wed, 15 Aug 2018 14:11:00 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Padia", "Ankur", ""], ["Ferraro", "Frank", ""], ["Finin", "Tim", ""]]}, {"id": "1808.04850", "submitter": "Zhiyang Teng", "authors": "Zhiyang Teng, Yue Zhang", "title": "Two Local Models for Neural Constituent Parsing", "comments": "COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-local features have been exploited by syntactic parsers for capturing\ndependencies between sub output structures. Such features have been a key to\nthe success of state-of-the-art statistical parsers. With the rise of deep\nlearning, however, it has been shown that local output decisions can give\nhighly competitive accuracies, thanks to the power of dense neural input\nrepresentations that embody global syntactic information. We investigate two\nconceptually simple local neural models for constituent parsing, which make\nlocal decisions to constituent spans and CFG rules, respectively. Consistent\nwith previous findings along the line, our best model gives highly competitive\nresults, achieving the labeled bracketing F1 scores of 92.4% on PTB and 87.3%\non CTB 5.1.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 18:34:17 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 12:26:57 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Teng", "Zhiyang", ""], ["Zhang", "Yue", ""]]}, {"id": "1808.04865", "submitter": "Qipeng Guo", "authors": "Qipeng Guo, Xipeng Qiu, Xiangyang Xue, Zheng Zhang", "title": "Top-Down Tree Structured Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text generation is a fundamental building block in natural language\nprocessing tasks. Existing sequential models performs autoregression directly\nover the text sequence and have difficulty generating long sentences of complex\nstructures. This paper advocates a simple approach that treats sentence\ngeneration as a tree-generation task. By explicitly modelling syntactic\nstructures in a constituent syntactic tree and performing top-down,\nbreadth-first tree generation, our model fixes dependencies appropriately and\nperforms implicit global planning. This is in contrast to transition-based\ndepth-first generation process, which has difficulty dealing with incomplete\ntexts when parsing and also does not incorporate future contexts in planning.\nOur preliminary results on two generation tasks and one parsing task\ndemonstrate that this is an effective strategy.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 19:12:44 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Guo", "Qipeng", ""], ["Qiu", "Xipeng", ""], ["Xue", "Xiangyang", ""], ["Zhang", "Zheng", ""]]}, {"id": "1808.04891", "submitter": "Tyler Etchart", "authors": "David Wingate, William Myers, Nancy Fulda, Tyler Etchart", "title": "Embedding Grammars", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classic grammars and regular expressions can be used for a variety of\npurposes, including parsing, intent detection, and matching. However, the\ncomparisons are performed at a structural level, with constituent elements\n(words or characters) matched exactly. Recent advances in word embeddings show\nthat semantically related words share common features in a vector-space\nrepresentation, suggesting the possibility of a hybrid grammar and word\nembedding. In this paper, we blend the structure of standard context-free\ngrammars with the semantic generalization capabilities of word embeddings to\ncreate hybrid semantic grammars. These semantic grammars generalize the\nspecific terminals used by the programmer to other words and phrases with\nrelated meanings, allowing the construction of compact grammars that match an\nentire region of the vector space rather than matching specific elements.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 20:52:43 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Wingate", "David", ""], ["Myers", "William", ""], ["Fulda", "Nancy", ""], ["Etchart", "Tyler", ""]]}, {"id": "1808.04911", "submitter": "Weiming Wen", "authors": "Weiming Wen and Songwen Su and Zhou Yu", "title": "Cross-Lingual Cross-Platform Rumor Verification Pivoting on Multimedia\n  Content", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing popularity of smart devices, rumors with multimedia\ncontent become more and more common on social networks. The multimedia\ninformation usually makes rumors look more convincing. Therefore, finding an\nautomatic approach to verify rumors with multimedia content is a pressing task.\nPrevious rumor verification research only utilizes multimedia as input\nfeatures. We propose not to use the multimedia content but to find external\ninformation in other news platforms pivoting on it. We introduce a new features\nset, cross-lingual cross-platform features that leverage the semantic\nsimilarity between the rumors and the external information. When implemented,\nmachine learning methods utilizing such features achieved the state-of-the-art\nrumor verification results.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 22:04:34 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 07:05:22 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Wen", "Weiming", ""], ["Su", "Songwen", ""], ["Yu", "Zhou", ""]]}, {"id": "1808.04926", "submitter": "Divyansh Kaushik", "authors": "Divyansh Kaushik, Zachary C. Lipton", "title": "How Much Reading Does Reading Comprehension Require? A Critical\n  Investigation of Popular Benchmarks", "comments": "To appear in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent papers address reading comprehension, where examples consist of\n(question, passage, answer) tuples. Presumably, a model must combine\ninformation from both questions and passages to predict corresponding answers.\nHowever, despite intense interest in the topic, with hundreds of published\npapers vying for leaderboard dominance, basic questions about the difficulty of\nmany popular benchmarks remain unanswered. In this paper, we establish sensible\nbaselines for the bAbI, SQuAD, CBT, CNN, and Who-did-What datasets, finding\nthat question- and passage-only models often perform surprisingly well. On $14$\nout of $20$ bAbI tasks, passage-only models achieve greater than $50\\%$\naccuracy, sometimes matching the full model. Interestingly, while CBT provides\n$20$-sentence stories only the last is needed for comparably accurate\nprediction. By comparison, SQuAD and CNN appear better-constructed.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 23:59:26 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 16:48:54 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Kaushik", "Divyansh", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "1808.04928", "submitter": "Zachariah Zhang", "authors": "Jingshu Liu, Zachariah Zhang, Narges Razavian", "title": "Deep EHR: Chronic Disease Prediction Using Medical Notes", "comments": "Machine Learning for Health Care conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early detection of preventable diseases is important for better disease\nmanagement, improved inter-ventions, and more efficient health-care resource\nallocation. Various machine learning approacheshave been developed to utilize\ninformation in Electronic Health Record (EHR) for this task. Majorityof\nprevious attempts, however, focus on structured fields and lose the vast amount\nof information inthe unstructured notes. In this work we propose a general\nmulti-task framework for disease onsetprediction that combines both free-text\nmedical notes and structured information. We compareperformance of different\ndeep learning architectures including CNN, LSTM and hierarchical models.In\ncontrast to traditional text-based prediction models, our approach does not\nrequire disease specificfeature engineering, and can handle negations and\nnumerical values that exist in the text. Ourresults on a cohort of about 1\nmillion patients show that models using text outperform modelsusing just\nstructured data, and that models capable of using numerical values and\nnegations in thetext, in addition to the raw text, further improve performance.\nAdditionally, we compare differentvisualization methods for medical\nprofessionals to interpret model predictions.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 00:10:55 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Liu", "Jingshu", ""], ["Zhang", "Zachariah", ""], ["Razavian", "Narges", ""]]}, {"id": "1808.04943", "submitter": "Sudipta Kar", "authors": "Sudipta Kar, Suraj Maharjan, Thamar Solorio", "title": "Folksonomication: Predicting Tags for Movies from Plot Synopses Using\n  Emotion Flow Encoded Neural Network", "comments": "To Appear at COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Folksonomy of movies covers a wide range of heterogeneous information about\nmovies, like the genre, plot structure, visual experiences, soundtracks,\nmetadata, and emotional experiences from watching a movie. Being able to\nautomatically generate or predict tags for movies can help recommendation\nengines improve retrieval of similar movies, and help viewers know what to\nexpect from a movie in advance. In this work, we explore the problem of\ncreating tags for movies from plot synopses. We propose a novel neural network\nmodel that merges information from synopses and emotion flows throughout the\nplots to predict a set of tags for movies. We compare our system with multiple\nbaselines and found that the addition of emotion flows boosts the performance\nof the network by learning ~18\\% more tags than a traditional machine learning\nsystem.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 01:50:56 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Kar", "Sudipta", ""], ["Maharjan", "Suraj", ""], ["Solorio", "Thamar", ""]]}, {"id": "1808.04961", "submitter": "Vishwajeet Kumar", "authors": "Vishwajeet Kumar, Ganesh Ramakrishnan, Yuan-Fang Li", "title": "Putting the Horse Before the Cart:A Generator-Evaluator Framework for\n  Question Generation from Text", "comments": "10 pages, The SIGNLL Conference on Computational Natural Language\n  Learning (CoNLL 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic question generation (QG) is a useful yet challenging task in NLP.\nRecent neural network-based approaches represent the state-of-the-art in this\ntask. In this work, we attempt to strengthen them significantly by adopting a\nholistic and novel generator-evaluator framework that directly optimizes\nobjectives that reward semantics and structure. The {\\it generator} is a\nsequence-to-sequence model that incorporates the {\\it structure} and {\\it\nsemantics} of the question being generated. The generator predicts an answer in\nthe passage that the question can pivot on. Employing the copy and coverage\nmechanisms, it also acknowledges other contextually important (and possibly\nrare) keywords in the passage that the question needs to conform to, while not\nredundantly repeating words. The {\\it evaluator} model evaluates and assigns a\nreward to each predicted question based on its conformity to the {\\it\nstructure} of ground-truth questions. We propose two novel QG-specific reward\nfunctions for text conformity and answer conformity of the generated question.\nThe evaluator also employs structure-sensitive rewards based on evaluation\nmeasures such as BLEU, GLEU, and ROUGE-L, which are suitable for QG. In\ncontrast, most of the previous works only optimize the cross-entropy loss,\nwhich can induce inconsistencies between training (objective) and testing\n(evaluation) measures. Our evaluation shows that our approach significantly\noutperforms state-of-the-art systems on the widely-used SQuAD benchmark as per\nboth automatic and human evaluation.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 04:05:02 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2019 15:55:04 GMT"}, {"version": "v3", "created": "Mon, 24 Jun 2019 03:49:57 GMT"}, {"version": "v4", "created": "Sat, 3 Aug 2019 18:45:18 GMT"}, {"version": "v5", "created": "Sun, 15 Sep 2019 19:18:13 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Kumar", "Vishwajeet", ""], ["Ramakrishnan", "Ganesh", ""], ["Li", "Yuan-Fang", ""]]}, {"id": "1808.04963", "submitter": "Jingkang Wang", "authors": "Jingkang Wang, Jianing Zhou, Jie Zhou, Gongshen Liu", "title": "Multiple Character Embeddings for Chinese Word Segmentation", "comments": "To appear in ACL-SRW 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chinese word segmentation (CWS) is often regarded as a character-based\nsequence labeling task in most current works which have achieved great success\nwith the help of powerful neural networks. However, these works neglect an\nimportant clue: Chinese characters incorporate both semantic and phonetic\nmeanings. In this paper, we introduce multiple character embeddings including\nPinyin Romanization and Wubi Input, both of which are easily accessible and\neffective in depicting semantics of characters. We propose a novel shared\nBi-LSTM-CRF model to fuse linguistic features efficiently by sharing the LSTM\nnetwork during the training procedure. Extensive experiments on five corpora\nshow that extra embeddings help obtain a significant improvement in labeling\naccuracy. Specifically, we achieve the state-of-the-art performance in AS and\nCityU corpora with F1 scores of 96.9 and 97.3, respectively without leveraging\nany external lexical resources.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 04:10:35 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 02:32:34 GMT"}, {"version": "v3", "created": "Thu, 30 May 2019 13:07:58 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Wang", "Jingkang", ""], ["Zhou", "Jianing", ""], ["Zhou", "Jie", ""], ["Liu", "Gongshen", ""]]}, {"id": "1808.05077", "submitter": "Ahsan Adeel", "authors": "Kia Dashtipour, Mandar Gogate, Ahsan Adeel, Cosimo Ieracitano, Hadi\n  Larijani, and Amir Hussain", "title": "Exploiting Deep Learning for Persian Sentiment Analysis", "comments": "To appear in the 9th International Conference on Brain Inspired\n  Cognitive Systems (BICS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of social media is enabling people to freely express their opinions\nabout products and services. The aim of sentiment analysis is to automatically\ndetermine subject's sentiment (e.g., positive, negative, or neutral) towards a\nparticular aspect such as topic, product, movie, news etc. Deep learning has\nrecently emerged as a powerful machine learning technique to tackle a growing\ndemand of accurate sentiment analysis. However, limited work has been conducted\nto apply deep learning algorithms to languages other than English, such as\nPersian. In this work, two deep learning models (deep autoencoders and deep\nconvolutional neural networks (CNNs)) are developed and applied to a novel\nPersian movie reviews dataset. The proposed deep learning models are analyzed\nand compared with the state-of-the-art shallow multilayer perceptron (MLP)\nbased machine learning model. Simulation results demonstrate the enhanced\nperformance of deep learning over state-of-the-art MLP.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 13:46:54 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Dashtipour", "Kia", ""], ["Gogate", "Mandar", ""], ["Adeel", "Ahsan", ""], ["Ieracitano", "Cosimo", ""], ["Larijani", "Hadi", ""], ["Hussain", "Amir", ""]]}, {"id": "1808.05079", "submitter": "Ahsan Adeel", "authors": "Imane Guellil, Ahsan Adeel, Faical Azouaou, and Amir Hussain", "title": "SentiALG: Automated Corpus Annotation for Algerian Sentiment Analysis", "comments": "To appear in the 9th International Conference on Brain Inspired\n  Cognitive Systems (BICS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data annotation is an important but time-consuming and costly procedure. To\nsort a text into two classes, the very first thing we need is a good annotation\nguideline, establishing what is required to qualify for each class. In the\nliterature, the difficulties associated with an appropriate data annotation has\nbeen underestimated. In this paper, we present a novel approach to\nautomatically construct an annotated sentiment corpus for Algerian dialect (a\nMaghrebi Arabic dialect). The construction of this corpus is based on an\nAlgerian sentiment lexicon that is also constructed automatically. The\npresented work deals with the two widely used scripts on Arabic social media:\nArabic and Arabizi. The proposed approach automatically constructs a sentiment\ncorpus containing 8000 messages (where 4000 are dedicated to Arabic and 4000 to\nArabizi). The achieved F1-score is up to 72% and 78% for an Arabic and Arabizi\ntest sets, respectively. Ongoing work is aimed at integrating transliteration\nprocess for Arabizi messages to further improve the obtained results.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 13:48:16 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Guellil", "Imane", ""], ["Adeel", "Ahsan", ""], ["Azouaou", "Faical", ""], ["Hussain", "Amir", ""]]}, {"id": "1808.05306", "submitter": "Hailin Chen", "authors": "Feng Nie, Hailin Chen, Jinpeng Wang, Jin-Ge Yao, Chin-Yew Lin, Rong\n  Pan", "title": "Incorporating Consistency Verification into Neural Data-to-Document\n  Generation", "comments": "Withdraw due to unqualified content and opinions of other authors;\n  this work is not yet qualified for a conference submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent neural models for data-to-document generation have achieved remarkable\nprogress in producing fluent and informative texts. However, large proportions\nof generated texts do not actually conform to the input data. To address this\nissue, we propose a new training framework which attempts to verify the\nconsistency between the generated texts and the input data to guide the\ntraining process. To measure the consistency, a relation extraction model is\napplied to check information overlaps between the input data and the generated\ntexts. The non-differentiable consistency signal is optimized via reinforcement\nlearning. Experimental results on a recently released challenging dataset\nROTOWIRE show improvements from our framework in various metrics.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 23:23:20 GMT"}, {"version": "v2", "created": "Sat, 18 Aug 2018 00:32:35 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Nie", "Feng", ""], ["Chen", "Hailin", ""], ["Wang", "Jinpeng", ""], ["Yao", "Jin-Ge", ""], ["Lin", "Chin-Yew", ""], ["Pan", "Rong", ""]]}, {"id": "1808.05312", "submitter": "Arun Narayanan", "authors": "Arun Narayanan, Ananya Misra, Khe Chai Sim, Golan Pundak, Anshuman\n  Tripathi, Mohamed Elfeky, Parisa Haghani, Trevor Strohman, Michiel Bacchiani", "title": "Toward domain-invariant speech recognition via large scale training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current state-of-the-art automatic speech recognition systems are trained to\nwork in specific `domains', defined based on factors like application, sampling\nrate and codec. When such recognizers are used in conditions that do not match\nthe training domain, performance significantly drops. This work explores the\nidea of building a single domain-invariant model for varied use-cases by\ncombining large scale training data from multiple application domains. Our\nfinal system is trained using 162,000 hours of speech. Additionally, each\nutterance is artificially distorted during training to simulate effects like\nbackground noise, codec distortion, and sampling rates. Our results show that,\neven at such a scale, a model thus trained works almost as well as those\nfine-tuned to specific subsets: A single model can be robust to multiple\napplication domains, and variations like codecs and noise. More importantly,\nsuch models generalize better to unseen conditions and allow for rapid\nadaptation -- we show that by using as little as 10 hours of data from a new\ndomain, an adapted domain-invariant model can match performance of a\ndomain-specific model trained from scratch using 70 times as much data. We also\nhighlight some of the limitations of such models and areas that need addressing\nin future work.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 00:24:49 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Narayanan", "Arun", ""], ["Misra", "Ananya", ""], ["Sim", "Khe Chai", ""], ["Pundak", "Golan", ""], ["Tripathi", "Anshuman", ""], ["Elfeky", "Mohamed", ""], ["Haghani", "Parisa", ""], ["Strohman", "Trevor", ""], ["Bacchiani", "Michiel", ""]]}, {"id": "1808.05326", "submitter": "Rowan Zellers", "authors": "Rowan Zellers, Yonatan Bisk, Roy Schwartz, Yejin Choi", "title": "SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense\n  Inference", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a partial description like \"she opened the hood of the car,\" humans can\nreason about the situation and anticipate what might come next (\"then, she\nexamined the engine\"). In this paper, we introduce the task of grounded\ncommonsense inference, unifying natural language inference and commonsense\nreasoning.\n  We present SWAG, a new dataset with 113k multiple choice questions about a\nrich spectrum of grounded situations. To address the recurring challenges of\nthe annotation artifacts and human biases found in many existing datasets, we\npropose Adversarial Filtering (AF), a novel procedure that constructs a\nde-biased dataset by iteratively training an ensemble of stylistic classifiers,\nand using them to filter the data. To account for the aggressive adversarial\nfiltering, we use state-of-the-art language models to massively oversample a\ndiverse set of potential counterfactuals. Empirical results demonstrate that\nwhile humans can solve the resulting inference problems with high accuracy\n(88%), various competitive models struggle on our task. We provide\ncomprehensive analysis that indicates significant opportunities for future\nresearch.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 02:21:01 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Zellers", "Rowan", ""], ["Bisk", "Yonatan", ""], ["Schwartz", "Roy", ""], ["Choi", "Yejin", ""]]}, {"id": "1808.05374", "submitter": "Effi Levi", "authors": "Effi Levi, Saggy Herman and Ari Rappoport", "title": "Computing Word Classes Using Spectral Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering a lexicon of words is a well-studied problem in natural language\nprocessing (NLP). Word clusters are used to deal with sparse data in\nstatistical language processing, as well as features for solving various NLP\ntasks (text categorization, question answering, named entity recognition and\nothers).\n  Spectral clustering is a widely used technique in the field of image\nprocessing and speech recognition. However, it has scarcely been explored in\nthe context of NLP; specifically, the method used in this (Meila and Shi, 2001)\nhas never been used to cluster a general word lexicon.\n  We apply spectral clustering to a lexicon of words, evaluating the resulting\nclusters by using them as features for solving two classical NLP tasks:\nsemantic role labeling and dependency parsing. We compare performance with\nBrown clustering, a widely-used technique for word clustering, as well as with\nother clustering methods. We show that spectral clusters produce similar\nresults to Brown clusters, and outperform other clustering methods. In\naddition, we quantify the overlap between spectral and Brown clusters, showing\nthat each model captures some information which is uncaptured by the other.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 08:11:24 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Levi", "Effi", ""], ["Herman", "Saggy", ""], ["Rappoport", "Ari", ""]]}, {"id": "1808.05437", "submitter": "Wei Li", "authors": "Wei Li, Xuancheng Ren, Damai Dai, Yunfang Wu, Houfeng Wang, Xu Sun", "title": "Sememe Prediction: Learning Semantic Knowledge from Unstructured Textual\n  Wiki Descriptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Huge numbers of new words emerge every day, leading to a great need for\nrepresenting them with semantic meaning that is understandable to NLP systems.\nSememes are defined as the minimum semantic units of human languages, the\ncombination of which can represent the meaning of a word. Manual construction\nof sememe based knowledge bases is time-consuming and labor-intensive.\nFortunately, communities are devoted to composing the descriptions of words in\nthe wiki websites. In this paper, we explore to automatically predict lexical\nsememes based on the descriptions of the words in the wiki websites. We view\nthis problem as a weakly ordered multi-label task and propose a Label\nDistributed seq2seq model (LD-seq2seq) with a novel soft loss function to solve\nthe problem. In the experiments, we take a real-world sememe knowledge base\nHowNet and the corresponding descriptions of the words in Baidu Wiki for\ntraining and evaluation. The results show that our LD-seq2seq model not only\nbeats all the baselines significantly on the test set, but also outperforms\namateur human annotators in a random subset of the test set.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 12:13:16 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Li", "Wei", ""], ["Ren", "Xuancheng", ""], ["Dai", "Damai", ""], ["Wu", "Yunfang", ""], ["Wang", "Houfeng", ""], ["Sun", "Xu", ""]]}, {"id": "1808.05439", "submitter": "Jaroslaw Kwapien", "authors": "Tomasz Stanisz, Jaros{\\l}aw Kwapie\\'n, Stanis{\\l}aw Dro\\.zd\\.z", "title": "Linguistic data mining with complex networks: a stylometric-oriented\n  approach", "comments": null, "journal-ref": "Information Sciences 482, 301-320 (2019)", "doi": "10.1016/j.ins.2019.01.040", "report-no": null, "categories": "cs.CL nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By representing a text by a set of words and their co-occurrences, one\nobtains a word-adjacency network being a reduced representation of a given\nlanguage sample. In this paper, the possibility of using network representation\nto extract information about individual language styles of literary texts is\nstudied. By determining selected quantitative characteristics of the networks\nand applying machine learning algorithms, it is possible to distinguish between\ntexts of different authors. Within the studied set of texts, English and\nPolish, a properly rescaled weighted clustering coefficients and weighted\ndegrees of only a few nodes in the word-adjacency networks are sufficient to\nobtain the authorship attribution accuracy over 90%. A correspondence between\nthe text authorship and the word-adjacency network structure can therefore be\nfound. The network representation allows to distinguish individual language\nstyles by comparing the way the authors use particular words and punctuation\nmarks. The presented approach can be viewed as a generalization of the\nauthorship attribution methods based on simple lexical features.\n  Additionally, other network parameters are studied, both local and global\nones, for both the unweighted and weighted networks. Their potential to capture\nthe writing style diversity is discussed; some differences between languages\nare observed.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 12:14:07 GMT"}, {"version": "v2", "created": "Thu, 17 Jan 2019 12:13:12 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Stanisz", "Tomasz", ""], ["Kwapie\u0144", "Jaros\u0142aw", ""], ["Dro\u017cd\u017c", "Stanis\u0142aw", ""]]}, {"id": "1808.05505", "submitter": "Myeongjun Jang", "authors": "Myeongjun Jang, Pilsung Kang", "title": "Paraphrase Thought: Sentence Embedding Module Imitating Human Language\n  Recognition", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence embedding is an important research topic in natural language\nprocessing. It is essential to generate a good embedding vector that fully\nreflects the semantic meaning of a sentence in order to achieve an enhanced\nperformance for various natural language processing tasks, such as machine\ntranslation and document classification. Thus far, various sentence embedding\nmodels have been proposed, and their feasibility has been demonstrated through\ngood performances on tasks following embedding, such as sentiment analysis and\nsentence classification. However, because the performances of sentence\nclassification and sentiment analysis can be enhanced by using a simple\nsentence representation method, it is not sufficient to claim that these models\nfully reflect the meanings of sentences based on good performances for such\ntasks. In this paper, inspired by human language recognition, we propose the\nfollowing concept of semantic coherence, which should be satisfied for a good\nsentence embedding method: similar sentences should be located close to each\nother in the embedding space. Then, we propose the Paraphrase-Thought\n(P-thought) model to pursue semantic coherence as much as possible.\nExperimental results on two paraphrase identification datasets (MS COCO and STS\nbenchmark) show that the P-thought models outperform the benchmarked sentence\nembedding methods.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 14:20:50 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 04:18:29 GMT"}, {"version": "v3", "created": "Mon, 15 Oct 2018 01:21:26 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Jang", "Myeongjun", ""], ["Kang", "Pilsung", ""]]}, {"id": "1808.05535", "submitter": "Filipe Rodrigues", "authors": "Filipe Rodrigues, Ioulia Markou, Francisco Pereira", "title": "Combining time-series and textual data for taxi demand prediction in\n  event areas: a deep learning approach", "comments": "20 pages, 6 figures", "journal-ref": "Rodrigues, F., Markou, I., Pereira, F. Combining time-series and\n  textual data for taxi demand prediction in event areas: a deep learning\n  approach. In Information Fusion, Elsevier, 2018", "doi": "10.1016/j.inffus.2018.07.007", "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate time-series forecasting is vital for numerous areas of application\nsuch as transportation, energy, finance, economics, etc. However, while modern\ntechniques are able to explore large sets of temporal data to build forecasting\nmodels, they typically neglect valuable information that is often available\nunder the form of unstructured text. Although this data is in a radically\ndifferent format, it often contains contextual explanations for many of the\npatterns that are observed in the temporal data. In this paper, we propose two\ndeep learning architectures that leverage word embeddings, convolutional layers\nand attention mechanisms for combining text information with time-series data.\nWe apply these approaches for the problem of taxi demand forecasting in event\nareas. Using publicly available taxi data from New York, we empirically show\nthat by fusing these two complementary cross-modal sources of information, the\nproposed models are able to significantly reduce the error in the forecasts.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 15:19:34 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Rodrigues", "Filipe", ""], ["Markou", "Ioulia", ""], ["Pereira", "Francisco", ""]]}, {"id": "1808.05542", "submitter": "Preslav Nakov", "authors": "Pepa Atanasova, Alberto Barron-Cedeno, Tamer Elsayed, Reem Suwaileh,\n  Wajdi Zaghouani, Spas Kyuchukov, Giovanni Da San Martino, Preslav Nakov", "title": "Overview of the CLEF-2018 CheckThat! Lab on Automatic Identification and\n  Verification of Political Claims. Task 1: Check-Worthiness", "comments": "Computational journalism, Check-worthiness, Fact-checking, Veracity", "journal-ref": "CLEF-2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an overview of the CLEF-2018 CheckThat! Lab on Automatic\nIdentification and Verification of Political Claims, with focus on Task 1:\nCheck-Worthiness. The task asks to predict which claims in a political debate\nshould be prioritized for fact-checking. In particular, given a debate or a\npolitical speech, the goal was to produce a ranked list of its sentences based\non their worthiness for fact checking. We offered the task in both English and\nArabic, based on debates from the 2016 US Presidential Campaign, as well as on\nsome speeches during and after the campaign. A total of 30 teams registered to\nparticipate in the Lab and seven teams actually submitted systems for Task~1.\nThe most successful approaches used by the participants relied on recurrent and\nmulti-layer neural networks, as well as on combinations of distributional\nrepresentations, on matchings claims' vocabulary against lexicons, and on\nmeasures of syntactic dependency. The best systems achieved mean average\nprecision of 0.18 and 0.15 on the English and on the Arabic test datasets,\nrespectively. This leaves large room for further improvement, and thus we\nrelease all datasets and the scoring scripts, which should enable further\nresearch in check-worthiness estimation.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 12:51:21 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Atanasova", "Pepa", ""], ["Barron-Cedeno", "Alberto", ""], ["Elsayed", "Tamer", ""], ["Suwaileh", "Reem", ""], ["Zaghouani", "Wajdi", ""], ["Kyuchukov", "Spas", ""], ["Martino", "Giovanni Da San", ""], ["Nakov", "Preslav", ""]]}, {"id": "1808.05599", "submitter": "Yi-Lin Tuan", "authors": "Yi-Lin Tuan and Hung-Yi Lee", "title": "Improving Conditional Sequence Generative Adversarial Networks by\n  Stepwise Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence generative adversarial networks (SeqGAN) have been used to improve\nconditional sequence generation tasks, for example, chit-chat dialogue\ngeneration. To stabilize the training of SeqGAN, Monte Carlo tree search (MCTS)\nor reward at every generation step (REGS) is used to evaluate the goodness of a\ngenerated subsequence. MCTS is computationally intensive, but the performance\nof REGS is worse than MCTS. In this paper, we propose stepwise GAN (StepGAN),\nin which the discriminator is modified to automatically assign scores\nquantifying the goodness of each subsequence at every generation step. StepGAN\nhas significantly less computational costs than MCTS. We demonstrate that\nStepGAN outperforms previous GAN-based methods on both synthetic experiment and\nchit-chat dialogue generation.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 17:41:00 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2019 09:50:15 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Tuan", "Yi-Lin", ""], ["Lee", "Hung-Yi", ""]]}, {"id": "1808.05611", "submitter": "Andrey Kutuzov", "authors": "Andrey Kutuzov, Mohammad Dorgham, Oleksiy Oliynyk, Chris Biemann,\n  Alexander Panchenko", "title": "Learning Graph Embeddings from WordNet-based Similarity Measures", "comments": "Accepted to StarSem 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present path2vec, a new approach for learning graph embeddings that relies\non structural measures of pairwise node similarities. The model learns\nrepresentations for nodes in a dense space that approximate a given\nuser-defined graph distance measure, such as e.g. the shortest path distance or\ndistance measures that take information beyond the graph structure into\naccount. Evaluation of the proposed model on semantic similarity and word sense\ndisambiguation tasks, using various WordNet-based similarity measures, show\nthat our approach yields competitive results, outperforming strong graph\nembedding baselines. The model is computationally efficient, being orders of\nmagnitude faster than the direct computation of graph-based distances.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 17:59:14 GMT"}, {"version": "v2", "created": "Fri, 17 Aug 2018 12:08:22 GMT"}, {"version": "v3", "created": "Wed, 10 Apr 2019 16:26:09 GMT"}, {"version": "v4", "created": "Fri, 12 Apr 2019 11:50:36 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Kutuzov", "Andrey", ""], ["Dorgham", "Mohammad", ""], ["Oliynyk", "Oleksiy", ""], ["Biemann", "Chris", ""], ["Panchenko", "Alexander", ""]]}, {"id": "1808.05668", "submitter": "Mohammadzaman Zamani", "authors": "Mohammadzaman Zamani, Anneke Buffone, H. Andrew Schwartz", "title": "Predicting Human Trustfulness from Facebook Language", "comments": "CLPsych2018", "journal-ref": "In Proceedings of the Fifth Workshop on Computational Linguistics\n  and Clinical Psychology: From Keyboard to Clinic, pages 174-181, 2018", "doi": "10.18653/v1/W18-0619", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trustfulness -- one's general tendency to have confidence in unknown people\nor situations -- predicts many important real-world outcomes such as mental\nhealth and likelihood to cooperate with others such as clinicians. While\ndata-driven measures of interpersonal trust have previously been introduced,\nhere, we develop the first language-based assessment of the personality trait\nof trustfulness by fitting one's language to an accepted questionnaire-based\ntrust score. Further, using trustfulness as a type of case study, we explore\nthe role of questionnaire size as well as word count in developing\nlanguage-based predictive models of users' psychological traits. We find that\nleveraging a longer questionnaire can yield greater test set accuracy, while,\nfor training, we find it beneficial to include users who took smaller\nquestionnaires which offers more observations for training. Similarly, after\nnoting a decrease in individual prediction error as word count increased, we\nfound a word count-weighted training scheme was helpful when there were very\nfew users in the first place.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 20:22:18 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Zamani", "Mohammadzaman", ""], ["Buffone", "Anneke", ""], ["Schwartz", "H. Andrew", ""]]}, {"id": "1808.05697", "submitter": "Aditya Siddhant", "authors": "Aditya Siddhant, Zachary C. Lipton", "title": "Deep Bayesian Active Learning for Natural Language Processing: Results\n  of a Large-Scale Empirical Study", "comments": "To be presented at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recent papers investigate Active Learning (AL) for mitigating the\ndata dependence of deep learning for natural language processing. However, the\napplicability of AL to real-world problems remains an open question. While in\nsupervised learning, practitioners can try many different methods, evaluating\neach against a validation set before selecting a model, AL affords no such\nluxury. Over the course of one AL run, an agent annotates its dataset\nexhausting its labeling budget. Thus, given a new task, an active learner has\nno opportunity to compare models and acquisition functions. This paper provides\na large scale empirical study of deep active learning, addressing multiple\ntasks and, for each, multiple datasets, multiple models, and a full suite of\nacquisition functions. We find that across all settings, Bayesian active\nlearning by disagreement, using uncertainty estimates provided either by\nDropout or Bayes-by Backprop significantly improves over i.i.d. baselines and\nusually outperforms classic uncertainty sampling.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 22:46:40 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 01:26:33 GMT"}, {"version": "v3", "created": "Mon, 24 Sep 2018 17:25:51 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Siddhant", "Aditya", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "1808.05700", "submitter": "Nelson Liu", "authors": "Nelson F. Liu and Jonathan May and Michael Pust and Kevin Knight", "title": "Augmenting Statistical Machine Translation with Subword Translation of\n  Out-of-Vocabulary Words", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most statistical machine translation systems cannot translate words that are\nunseen in the training data. However, humans can translate many classes of\nout-of-vocabulary (OOV) words (e.g., novel morphological variants,\nmisspellings, and compounds) without context by using orthographic clues.\nFollowing this observation, we describe and evaluate several general methods\nfor OOV translation that use only subword information. We pose the OOV\ntranslation problem as a standalone task and intrinsically evaluate our\napproaches on fourteen typologically diverse languages across varying resource\nlevels. Adding OOV translators to a statistical machine translation system\nyields consistent BLEU gains (0.5 points on average, and up to 2.0) for all\nfourteen languages, especially in low-resource scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 23:05:17 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Liu", "Nelson F.", ""], ["May", "Jonathan", ""], ["Pust", "Michael", ""], ["Knight", "Kevin", ""]]}, {"id": "1808.05759", "submitter": "Minghao Hu", "authors": "Minghao Hu, Furu Wei, Yuxing Peng, Zhen Huang, Nan Yang, Dongsheng Li", "title": "Read + Verify: Machine Reading Comprehension with Unanswerable Questions", "comments": "To appear at AAAI-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine reading comprehension with unanswerable questions aims to abstain\nfrom answering when no answer can be inferred. In addition to extract answers,\nprevious works usually predict an additional \"no-answer\" probability to detect\nunanswerable cases. However, they fail to validate the answerability of the\nquestion by verifying the legitimacy of the predicted answer. To address this\nproblem, we propose a novel read-then-verify system, which not only utilizes a\nneural reader to extract candidate answers and produce no-answer probabilities,\nbut also leverages an answer verifier to decide whether the predicted answer is\nentailed by the input snippets. Moreover, we introduce two auxiliary losses to\nhelp the reader better handle answer extraction as well as no-answer detection,\nand investigate three different architectures for the answer verifier. Our\nexperiments on the SQuAD 2.0 dataset show that our system achieves a score of\n74.2 F1 on the test set, achieving state-of-the-art results at the time of\nsubmission (Aug. 28th, 2018).\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2018 05:18:52 GMT"}, {"version": "v2", "created": "Thu, 23 Aug 2018 14:19:12 GMT"}, {"version": "v3", "created": "Mon, 27 Aug 2018 13:18:03 GMT"}, {"version": "v4", "created": "Wed, 5 Sep 2018 13:45:42 GMT"}, {"version": "v5", "created": "Thu, 15 Nov 2018 06:53:09 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Hu", "Minghao", ""], ["Wei", "Furu", ""], ["Peng", "Yuxing", ""], ["Huang", "Zhen", ""], ["Yang", "Nan", ""], ["Li", "Dongsheng", ""]]}, {"id": "1808.05857", "submitter": "Zahra Shakeri Hossein Abad", "authors": "Zahra Shakeri Hossein Abad, Vincenzo Gervasi, Didar Zowghi, Ken Barker", "title": "ELICA: An Automated Tool for Dynamic Extraction of Requirements Relevant\n  Information", "comments": "2018 IEEE 26th International Requirements Engineering Conference\n  Workshops", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Requirements elicitation requires extensive knowledge and deep understanding\nof the problem domain where the final system will be situated. However, in many\nsoftware development projects, analysts are required to elicit the requirements\nfrom an unfamiliar domain, which often causes communication barriers between\nanalysts and stakeholders. In this paper, we propose a requirements ELICitation\nAid tool (ELICA) to help analysts better understand the target application\ndomain by dynamic extraction and labeling of requirements-relevant knowledge.\nTo extract the relevant terms, we leverage the flexibility and power of\nWeighted Finite State Transducers (WFSTs) in dynamic modeling of natural\nlanguage processing tasks. In addition to the information conveyed through\ntext, ELICA captures and processes non-linguistic information about the\nintention of speakers such as their confidence level, analytical tone, and\nemotions. The extracted information is made available to the analysts as a set\nof labeled snippets with highlighted relevant terms which can also be exported\nas an artifact of the Requirements Engineering (RE) process. The application\nand usefulness of ELICA are demonstrated through a case study. This study shows\nhow pre-existing relevant information about the application domain and the\ninformation captured during an elicitation meeting, such as the conversation\nand stakeholders' intentions, can be captured and used to support analysts\nachieving their tasks.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 00:19:13 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Abad", "Zahra Shakeri Hossein", ""], ["Gervasi", "Vincenzo", ""], ["Zowghi", "Didar", ""], ["Barker", "Ken", ""]]}, {"id": "1808.05902", "submitter": "Filipe Rodrigues", "authors": "Filipe Rodrigues, Mariana Louren\\c{c}o, Bernardete Ribeiro, Francisco\n  Pereira", "title": "Learning Supervised Topic Models for Classification and Regression from\n  Crowds", "comments": "14 pages", "journal-ref": "Rodrigues, F., Lourenco, M., Ribeiro, B. and Pereira, F.C., 2017.\n  Learning supervised topic models for classification and regression from\n  crowds. IEEE transactions on pattern analysis and machine intelligence,\n  39(12), pp.2409-2422", "doi": "10.1109/TPAMI.2017.2648786", "report-no": null, "categories": "stat.ML cs.CL cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing need to analyze large collections of documents has led to great\ndevelopments in topic modeling. Since documents are frequently associated with\nother related variables, such as labels or ratings, much interest has been\nplaced on supervised topic models. However, the nature of most annotation\ntasks, prone to ambiguity and noise, often with high volumes of documents, deem\nlearning under a single-annotator assumption unrealistic or unpractical for\nmost real-world applications. In this article, we propose two supervised topic\nmodels, one for classification and another for regression problems, which\naccount for the heterogeneity and biases among different annotators that are\nencountered in practice when learning from crowds. We develop an efficient\nstochastic variational inference algorithm that is able to scale to very large\ndatasets, and we empirically demonstrate the advantages of the proposed model\nover state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2018 15:32:24 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Rodrigues", "Filipe", ""], ["Louren\u00e7o", "Mariana", ""], ["Ribeiro", "Bernardete", ""], ["Pereira", "Francisco", ""]]}, {"id": "1808.05906", "submitter": "Bichen Shi", "authors": "Bichen Shi, Thanh-Binh Le, Neil Hurley and Georgiana Ifrim", "title": "Story Disambiguation: Tracking Evolving News Stories across News and\n  Social Streams", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following a particular news story online is an important but difficult task,\nas the relevant information is often scattered across different domains/sources\n(e.g., news articles, blogs, comments, tweets), presented in various formats\nand language styles, and may overlap with thousands of other stories. In this\nwork we join the areas of topic tracking and entity disambiguation, and propose\na framework named Story Disambiguation - a cross-domain story tracking approach\nthat builds on real-time entity disambiguation and a learning-to-rank framework\nto represent and update the rich semantic structure of news stories. Given a\ntarget news story, specified by a seed set of documents, the goal is to\neffectively select new story-relevant documents from an incoming document\nstream. We represent stories as entity graphs and we model the story tracking\nproblem as a learning-to-rank task. This enables us to track content with high\naccuracy, from multiple domains, in real-time. We study a range of text, entity\nand graph based features to understand which type of features are most\neffective for representing stories. We further propose new semi-supervised\nlearning techniques to automatically update the story representation over time.\nOur empirical study shows that we outperform the accuracy of state-of-the-art\nmethods for tracking mixed-domain document streams, while requiring fewer\nlabeled data to seed the tracked stories. This is particularly the case for\nlocal news stories that are easily over shadowed by other trending stories, and\nfor complex news stories with ambiguous content in noisy stream environments.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 09:02:37 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Shi", "Bichen", ""], ["Le", "Thanh-Binh", ""], ["Hurley", "Neil", ""], ["Ifrim", "Georgiana", ""]]}, {"id": "1808.05907", "submitter": "Shubham Bhardwaj", "authors": "Shubham Bhardwaj", "title": "Syntree2Vec - An algorithm to augment syntactic hierarchy into word\n  embeddings", "comments": "6 pages, 3 figures, (rejected at ACL - initial stage work)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings aims to map sense of the words into a lower dimensional\nvector space in order to reason over them. Training embeddings on domain\nspecific data helps express concepts more relevant to their use case but comes\nat a cost of accuracy when data is less. Our effort is to minimise this by\ninfusing syntactic knowledge into the embeddings. We propose a graph based\nembedding algorithm inspired from node2vec. Experimental results have shown\nthat our algorithm improves the syntactic strength and gives robust performance\non meagre data.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 14:40:56 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Bhardwaj", "Shubham", ""]]}, {"id": "1808.05908", "submitter": "Siddhartha Brahma", "authors": "Siddhartha Brahma", "title": "Improved Language Modeling by Decoding the Past", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highly regularized LSTMs achieve impressive results on several benchmark\ndatasets in language modeling. We propose a new regularization method based on\ndecoding the last token in the context using the predicted distribution of the\nnext token. This biases the model towards retaining more contextual\ninformation, in turn improving its ability to predict the next token. With\nnegligible overhead in the number of parameters and training time, our Past\nDecode Regularization (PDR) method achieves a word level perplexity of 55.6 on\nthe Penn Treebank and 63.5 on the WikiText-2 datasets using a single softmax.\nWe also show gains by using PDR in combination with a mixture-of-softmaxes,\nachieving a word level perplexity of 53.8 and 60.5 on these datasets. In\naddition, our method achieves 1.169 bits-per-character on the Penn Treebank\nCharacter dataset for character level language modeling. These results\nconstitute a new state-of-the-art in their respective settings.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 18:44:58 GMT"}, {"version": "v2", "created": "Sat, 29 Sep 2018 16:29:06 GMT"}, {"version": "v3", "created": "Thu, 3 Jan 2019 19:23:46 GMT"}, {"version": "v4", "created": "Wed, 23 Jan 2019 19:52:46 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Brahma", "Siddhartha", ""]]}, {"id": "1808.05927", "submitter": "Josemar Caetano", "authors": "Josemar Alves Caetano, Gabriel Magno, Evandro Cunha, Wagner Meira Jr.,\n  Humberto T. Marques-Neto, Virgilio Almeida", "title": "Characterizing the public perception of WhatsApp through the lens of\n  media", "comments": "Accepted as a full paper at the 2nd International Workshop on Rumours\n  and Deception in Social Media (RDSM 2018), co-located with CIKM 2018 in\n  Turin. Please cite the RDSM version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  WhatsApp is, as of 2018, a significant component of the global information\nand communication infrastructure, especially in developing countries. However,\nprobably due to its strong end-to-end encryption, WhatsApp became an attractive\nplace for the dissemination of misinformation, extremism and other forms of\nundesirable behavior. In this paper, we investigate the public perception of\nWhatsApp through the lens of media. We analyze two large datasets of news and\nshow the kind of content that is being associated with WhatsApp in different\nregions of the world and over time. Our analyses include the examination of\nnamed entities, general vocabulary, and topics addressed in news articles that\nmention WhatsApp, as well as the polarity of these texts. Among other results,\nwe demonstrate that the vocabulary and topics around the term \"whatsapp\" in the\nmedia have been changing over the years and in 2018 concentrate on matters\nrelated to misinformation, politics and criminal scams. More generally, our\nfindings are useful to understand the impact that tools like WhatsApp play in\nthe contemporary society and how they are seen by the communities themselves.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2018 16:47:52 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Caetano", "Josemar Alves", ""], ["Magno", "Gabriel", ""], ["Cunha", "Evandro", ""], ["Meira", "Wagner", "Jr."], ["Marques-Neto", "Humberto T.", ""], ["Almeida", "Virgilio", ""]]}, {"id": "1808.05946", "submitter": "Hao Chen", "authors": "Hao Chen, Maria Vasardani, Stephan Winter", "title": "Disambiguating fine-grained place names from descriptions by clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Everyday place descriptions often contain place names of fine-grained\nfeatures, such as buildings or businesses, that are more difficult to\ndisambiguate than names referring to larger places, for example cities or\nnatural geographic features. Fine-grained places are often significantly more\nfrequent and more similar to each other, and disambiguation heuristics\ndeveloped for larger places, such as those based on population or containment\nrelationships, are often not applicable in these cases. In this research, we\naddress the disambiguation of fine-grained place names from everyday place\ndescriptions. For this purpose, we evaluate the performance of different\nexisting clustering-based approaches, since clustering approaches require no\nmore knowledge other than the locations of ambiguous place names. We consider\nnot only approaches developed specifically for place name disambiguation, but\nalso clustering algorithms developed for general data mining that could\npotentially be leveraged. We compare these methods with a novel algorithm, and\nshow that the novel algorithm outperforms the other algorithms in terms of\ndisambiguation precision and distance error over several tested datasets.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2018 05:14:41 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Chen", "Hao", ""], ["Vasardani", "Maria", ""], ["Winter", "Stephan", ""]]}, {"id": "1808.06021", "submitter": "Amir Karami", "authors": "Amir Karami and Matthew Collins", "title": "What do the US West Coast Public Libraries Post on Twitter?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twitter has provided a great opportunity for public libraries to disseminate\ninformation for a variety of purposes. Twitter data have been applied in\ndifferent domains such as health, politics, and history. There are thousands of\npublic libraries in the US, but no study has yet investigated the content of\ntheir social media posts like tweets to find their interests. Moreover,\ntraditional content analysis of Twitter content is not an efficient task for\nexploring thousands of tweets. Therefore, there is a need for automatic methods\nto overcome the limitations of manual methods. This paper proposes a\ncomputational approach to collecting and analyzing using Twitter Application\nProgramming Interfaces (API) and investigates more than 138,000 tweets from 48\nUS west coast libraries using topic modeling. We found 20 topics and assigned\nthem to five categories including public relations, book, event, training, and\nsocial good. Our results show that the US west coast libraries are more\ninterested in using Twitter for public relations and book-related events. This\nresearch has both practical and theoretical applications for libraries as well\nas other organizations to explore social media actives of their customer and\nthemselves.\n", "versions": [{"version": "v1", "created": "Fri, 17 Aug 2018 23:50:01 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 15:11:22 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Karami", "Amir", ""], ["Collins", "Matthew", ""]]}, {"id": "1808.06022", "submitter": "Amir Karami", "authors": "Amir Karami, Frank Webb, Vanessa L. Kitzie", "title": "Characterizing Transgender Health Issues in Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although there are millions of transgender people in the world, a lack of\ninformation exists about their health issues. This issue has consequences for\nthe medical field, which only has a nascent understanding of how to identify\nand meet this population's health-related needs. Social media sites like\nTwitter provide new opportunities for transgender people to overcome these\nbarriers by sharing their personal health experiences. Our research employs a\ncomputational framework to collect tweets from self-identified transgender\nusers, detect those that are health-related, and identify their information\nneeds. This framework is significant because it provides a macro-scale\nperspective on an issue that lacks investigation at national or demographic\nlevels. Our findings identified 54 distinct health-related topics that we\ngrouped into 7 broader categories. Further, we found both linguistic and\ntopical differences in the health-related information shared by transgender men\n(TM) as com-pared to transgender women (TW). These findings can help inform\nmedical and policy-based strategies for health interventions within transgender\ncommunities. Also, our proposed approach can inform the development of\ncomputational strategies to identify the health-related information needs of\nother marginalized populations.\n", "versions": [{"version": "v1", "created": "Sat, 18 Aug 2018 00:00:19 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 15:08:24 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Karami", "Amir", ""], ["Webb", "Frank", ""], ["Kitzie", "Vanessa L.", ""]]}, {"id": "1808.06068", "submitter": "Luis Espinosa-Anke", "authors": "Luis Espinosa-Anke and Steven Schockaert", "title": "SeVeN: Augmenting Word Embeddings with Unsupervised Relation Vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SeVeN (Semantic Vector Networks), a hybrid resource that encodes\nrelationships between words in the form of a graph. Different from traditional\nsemantic networks, these relations are represented as vectors in a continuous\nvector space. We propose a simple pipeline for learning such relation vectors,\nwhich is based on word vector averaging in combination with an ad hoc\nautoencoder. We show that by explicitly encoding relational information in a\ndedicated vector space we can capture aspects of word meaning that are\ncomplementary to what is captured by word embeddings. For example, by examining\nclusters of relation vectors, we observe that relational similarities can be\nidentified at a more abstract level than with traditional word vector\ndifferences. Finally, we test the effectiveness of semantic vector networks in\ntwo tasks: measuring word similarity and neural text categorization. SeVeN is\navailable at bitbucket.org/luisespinosa/seven.\n", "versions": [{"version": "v1", "created": "Sat, 18 Aug 2018 10:23:09 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Espinosa-Anke", "Luis", ""], ["Schockaert", "Steven", ""]]}, {"id": "1808.06075", "submitter": "Gehui Shen", "authors": "Gehui Shen, Zhi-Hong Deng, Ting Huang and Xi Chen", "title": "Learning to Compose over Tree Structures via POS Tags", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recursive Neural Network (RecNN), a type of models which compose words or\nphrases recursively over syntactic tree structures, has been proven to have\nsuperior ability to obtain sentence representation for a variety of NLP tasks.\nHowever, RecNN is born with a thorny problem that a shared compositional\nfunction for each node of trees can't capture the complex semantic\ncompositionality so that the expressive power of model is limited. In this\npaper, in order to address this problem, we propose Tag-Guided\nHyperRecNN/TreeLSTM (TG-HRecNN/TreeLSTM), which introduces hypernetwork into\nRecNNs to take as inputs Part-of-Speech (POS) tags of word/phrase and generate\nthe semantic composition parameters dynamically. Experimental results on five\ndatasets for two typical NLP tasks show proposed models both obtain significant\nimprovement compared with RecNN and TreeLSTM consistently. Our TG-HTreeLSTM\noutperforms all existing RecNN-based models and achieves or is competitive with\nstate-of-the-art on four sentence classification benchmarks. The effectiveness\nof our models is also demonstrated by qualitative analysis.\n", "versions": [{"version": "v1", "created": "Sat, 18 Aug 2018 11:53:24 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 01:57:49 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Shen", "Gehui", ""], ["Deng", "Zhi-Hong", ""], ["Huang", "Ting", ""], ["Chen", "Xi", ""]]}, {"id": "1808.06110", "submitter": "Jose Berengueres Ph.D", "authors": "Jose Berengueres", "title": "Emoji Sentiment Scores of Writers using Odds Ratio and Fisher Exact Test", "comments": "ACM Special issue, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sentiment of a given emoji is traditionally calculated by averaging the\nratings {-1, 0 or +1} given by various users to a given context where the emoji\nappears. However, using such formula complicates the statistical significance\nanalysis particularly for low sample sizes. Here, we provide sentiment scores\nusing odds and a sentiment mapping to a 4-icon scale. We show how odds ratio\nstatistics leads to simpler sentiment analysis. Finally, we provide a list of\nsentiment scores with the often-missing exact p-values and CI for the most\ncommon emoji.\n", "versions": [{"version": "v1", "created": "Sat, 18 Aug 2018 18:37:05 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 11:19:12 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Berengueres", "Jose", ""]]}, {"id": "1808.06116", "submitter": "Abdullah Alrajeh", "authors": "Abdullah Alrajeh", "title": "A Recipe for Arabic-English Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a recipe for building a good Arabic-English neural\nmachine translation. We compare neural systems with traditional phrase-based\nsystems using various parallel corpora including UN, ISI and Ummah. We also\ninvestigate the importance of special preprocessing of the Arabic script. The\npresented results are based on test sets from NIST MT 2005 and 2012. The best\nneural system produces a gain of +13 BLEU points compared to an equivalent\nsimple phrase-based system in NIST MT12 test set. Unexpectedly, we find that\ntuning a model trained on the whole data using a small high quality corpus like\nUmmah gives a substantial improvement (+3 BLEU points). We also find that\ntraining a neural system with a small Arabic-English corpus is competitive to a\ntraditional phrase-based system.\n", "versions": [{"version": "v1", "created": "Sat, 18 Aug 2018 19:04:54 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Alrajeh", "Abdullah", ""]]}, {"id": "1808.06161", "submitter": "Di Jin", "authors": "Di Jin and Peter Szolovits", "title": "Hierarchical Neural Networks for Sequential Sentence Classification in\n  Medical Scientific Abstracts", "comments": "Accepted by EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prevalent models based on artificial neural network (ANN) for sentence\nclassification often classify sentences in isolation without considering the\ncontext in which sentences appear. This hampers the traditional sentence\nclassification approaches to the problem of sequential sentence classification,\nwhere structured prediction is needed for better overall classification\nperformance. In this work, we present a hierarchical sequential labeling\nnetwork to make use of the contextual information within surrounding sentences\nto help classify the current sentence. Our model outperforms the\nstate-of-the-art results by 2%-3% on two benchmarking datasets for sequential\nsentence classification in medical scientific abstracts.\n", "versions": [{"version": "v1", "created": "Sun, 19 Aug 2018 05:06:28 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Jin", "Di", ""], ["Szolovits", "Peter", ""]]}, {"id": "1808.06167", "submitter": "He Bai", "authors": "He Bai, Yu Zhou, Jiajun Zhang, Liang Zhao, Mei-Yuh Hwang and Chengqing\n  Zong", "title": "Source-Critical Reinforcement Learning for Transferring Spoken Language\n  Understanding to a New Language", "comments": "10 pages, 4 figures, COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To deploy a spoken language understanding (SLU) model to a new language,\nlanguage transferring is desired to avoid the trouble of acquiring and labeling\na new big SLU corpus. Translating the original SLU corpus into the target\nlanguage is an attractive strategy. However, SLU corpora consist of plenty of\nsemantic labels (slots), which general-purpose translators cannot handle well,\nnot to mention additional culture differences. This paper focuses on the\nlanguage transferring task given a tiny in-domain parallel SLU corpus. The\nin-domain parallel corpus can be used as the first adaptation on the general\ntranslator. But more importantly, we show how to use reinforcement learning\n(RL) to further finetune the adapted translator, where translated sentences\nwith more proper slot tags receive higher rewards. We evaluate our approach on\nChinese to English language transferring for SLU systems. The experimental\nresults show that the generated English SLU corpus via adaptation and\nreinforcement learning gives us over 97% in the slot F1 score and over 84%\naccuracy in domain classification. It demonstrates the effectiveness of the\nproposed language transferring method. Compared with naive translation, our\nproposed method improves domain classification accuracy by relatively 22%, and\nthe slot filling F1 score by relatively more than 71%.\n", "versions": [{"version": "v1", "created": "Sun, 19 Aug 2018 05:49:46 GMT"}, {"version": "v2", "created": "Wed, 22 Aug 2018 15:16:26 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Bai", "He", ""], ["Zhou", "Yu", ""], ["Zhang", "Jiajun", ""], ["Zhao", "Liang", ""], ["Hwang", "Mei-Yuh", ""], ["Zong", "Chengqing", ""]]}, {"id": "1808.06170", "submitter": "Zhiwei Wang", "authors": "Zhiwei Wang, Yao Ma, Dawei Yin, Jiliang Tang", "title": "Linked Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) have been proven to be effective in modeling\nsequential data and they have been applied to boost a variety of tasks such as\ndocument classification, speech recognition and machine translation. Most of\nexisting RNN models have been designed for sequences assumed to be identically\nand independently distributed (i.i.d). However, in many real-world\napplications, sequences are naturally linked. For example, web documents are\nconnected by hyperlinks; and genes interact with each other. On the one hand,\nlinked sequences are inherently not i.i.d., which poses tremendous challenges\nto existing RNN models. On the other hand, linked sequences offer link\ninformation in addition to the sequential information, which enables\nunprecedented opportunities to build advanced RNN models. In this paper, we\nstudy the problem of RNN for linked sequences. In particular, we introduce a\nprincipled approach to capture link information and propose a linked Recurrent\nNeural Network (LinkedRNN), which models sequential and link information\ncoherently. We conduct experiments on real-world datasets from multiple domains\nand the experimental results validate the effectiveness of the proposed\nframework.\n", "versions": [{"version": "v1", "created": "Sun, 19 Aug 2018 06:21:58 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Wang", "Zhiwei", ""], ["Ma", "Yao", ""], ["Yin", "Dawei", ""], ["Tang", "Jiliang", ""]]}, {"id": "1808.06218", "submitter": "Logan Lebanoff", "authors": "Logan Lebanoff, Kaiqiang Song, Fei Liu", "title": "Adapting the Neural Encoder-Decoder Framework from Single to\n  Multi-Document Summarization", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating a text abstract from a set of documents remains a challenging\ntask. The neural encoder-decoder framework has recently been exploited to\nsummarize single documents, but its success can in part be attributed to the\navailability of large parallel data automatically acquired from the Web. In\ncontrast, parallel data for multi-document summarization are scarce and costly\nto obtain. There is a pressing need to adapt an encoder-decoder model trained\non single-document summarization data to work with multiple-document input. In\nthis paper, we present an initial investigation into a novel adaptation method.\nIt exploits the maximal marginal relevance method to select representative\nsentences from multi-document input, and leverages an abstractive\nencoder-decoder model to fuse disparate sentences to an abstractive summary.\nThe adaptation method is robust and itself requires no training data. Our\nsystem compares favorably to state-of-the-art extractive and abstractive\napproaches judged by automatic metrics and human assessors.\n", "versions": [{"version": "v1", "created": "Sun, 19 Aug 2018 14:43:09 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 17:56:41 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Lebanoff", "Logan", ""], ["Song", "Kaiqiang", ""], ["Liu", "Fei", ""]]}, {"id": "1808.06219", "submitter": "Logan Lebanoff", "authors": "Logan Lebanoff, Fei Liu", "title": "Automatic Detection of Vague Words and Sentences in Privacy Policies", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Website privacy policies represent the single most important source of\ninformation for users to gauge how their personal data are collected, used and\nshared by companies. However, privacy policies are often vague and people\nstruggle to understand the content. Their opaqueness poses a significant\nchallenge to both users and policy regulators. In this paper, we seek to\nidentify vague content in privacy policies. We construct the first corpus of\nhuman-annotated vague words and sentences and present empirical studies on\nautomatic vagueness detection. In particular, we investigate context-aware and\ncontext-agnostic models for predicting vague words, and explore\nauxiliary-classifier generative adversarial networks for characterizing\nsentence vagueness. Our experimental results demonstrate the effectiveness of\nproposed approaches. Finally, we provide suggestions for resolving vagueness\nand improving the usability of privacy policies.\n", "versions": [{"version": "v1", "created": "Sun, 19 Aug 2018 15:12:19 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 18:01:54 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Lebanoff", "Logan", ""], ["Liu", "Fei", ""]]}, {"id": "1808.06226", "submitter": "Taku Kudo", "authors": "Taku Kudo, John Richardson", "title": "SentencePiece: A simple and language independent subword tokenizer and\n  detokenizer for Neural Text Processing", "comments": "Accepted as a demo paper at EMNLP2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes SentencePiece, a language-independent subword tokenizer\nand detokenizer designed for Neural-based text processing, including Neural\nMachine Translation. It provides open-source C++ and Python implementations for\nsubword units. While existing subword segmentation tools assume that the input\nis pre-tokenized into word sequences, SentencePiece can train subword models\ndirectly from raw sentences, which allows us to make a purely end-to-end and\nlanguage independent system. We perform a validation experiment of NMT on\nEnglish-Japanese machine translation, and find that it is possible to achieve\ncomparable accuracy to direct subword training from raw sentences. We also\ncompare the performance of subword training and segmentation with various\nconfigurations. SentencePiece is available under the Apache 2 license at\nhttps://github.com/google/sentencepiece.\n", "versions": [{"version": "v1", "created": "Sun, 19 Aug 2018 16:49:06 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Kudo", "Taku", ""], ["Richardson", "John", ""]]}, {"id": "1808.06232", "submitter": "Aaron Steven White", "authors": "Aaron Steven White, Rachel Rudinger, Kyle Rawlins, Benjamin Van Durme", "title": "Lexicosyntactic Inference in Neural Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate neural models' ability to capture lexicosyntactic inferences:\ninferences triggered by the interaction of lexical and syntactic information.\nWe take the task of event factuality prediction as a case study and build a\nfactuality judgment dataset for all English clause-embedding verbs in various\nsyntactic contexts. We use this dataset, which we make publicly available, to\nprobe the behavior of current state-of-the-art neural systems, showing that\nthese systems make certain systematic errors that are clearly visible through\nthe lens of factuality prediction.\n", "versions": [{"version": "v1", "created": "Sun, 19 Aug 2018 17:45:51 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["White", "Aaron Steven", ""], ["Rudinger", "Rachel", ""], ["Rawlins", "Kyle", ""], ["Van Durme", "Benjamin", ""]]}, {"id": "1808.06244", "submitter": "Wenhu Chen", "authors": "Wenhu Chen, Jianshu Chen, Yu Su, Xin Wang, Dong Yu, Xifeng Yan and\n  William Yang Wang", "title": "XL-NBT: A Cross-lingual Neural Belief Tracking Framework", "comments": "13 pages, 5 figures, 3 tables, accepted to EMNLP 2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-oriented dialog systems are becoming pervasive, and many companies\nheavily rely on them to complement human agents for customer service in call\ncenters. With globalization, the need for providing cross-lingual customer\nsupport becomes more urgent than ever. However, cross-lingual support poses\ngreat challenges---it requires a large amount of additional annotated data from\nnative speakers. In order to bypass the expensive human annotation and achieve\nthe first step towards the ultimate goal of building a universal dialog system,\nwe set out to build a cross-lingual state tracking framework. Specifically, we\nassume that there exists a source language with dialog belief tracking\nannotations while the target languages have no annotated dialog data of any\nform. Then, we pre-train a state tracker for the source language as a teacher,\nwhich is able to exploit easy-to-access parallel data. We then distill and\ntransfer its own knowledge to the student state tracker in target languages. We\nspecifically discuss two types of common parallel resources: bilingual corpus\nand bilingual dictionary, and design different transfer learning strategies\naccordingly. Experimentally, we successfully use English state tracker as the\nteacher to transfer its knowledge to both Italian and German trackers and\nachieve promising results.\n", "versions": [{"version": "v1", "created": "Sun, 19 Aug 2018 19:08:10 GMT"}, {"version": "v2", "created": "Sat, 25 Aug 2018 16:26:38 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Chen", "Wenhu", ""], ["Chen", "Jianshu", ""], ["Su", "Yu", ""], ["Wang", "Xin", ""], ["Yu", "Dong", ""], ["Yan", "Xifeng", ""], ["Wang", "William Yang", ""]]}, {"id": "1808.06267", "submitter": "Antonios Anastasopoulos", "authors": "Antonios Anastasopoulos, Alison Lui, Toan Nguyen, and David Chiang", "title": "Neural Machine Translation of Text from Non-Native Speakers", "comments": "accepted at NAACL-HLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) systems are known to degrade when confronted\nwith noisy data, especially when the system is trained only on clean data. In\nthis paper, we show that augmenting training data with sentences containing\nartificially-introduced grammatical errors can make the system more robust to\nsuch errors. In combination with an automatic grammar error correction system,\nwe can recover 1.5 BLEU out of 2.4 BLEU lost due to grammatical errors. We also\npresent a set of Spanish translations of the JFLEG grammar error correction\ncorpus, which allows for testing NMT robustness to real grammatical errors.\n", "versions": [{"version": "v1", "created": "Sun, 19 Aug 2018 22:42:06 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 19:51:33 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Anastasopoulos", "Antonios", ""], ["Lui", "Alison", ""], ["Nguyen", "Toan", ""], ["Chiang", "David", ""]]}, {"id": "1808.06288", "submitter": "Junichi Yamagishi", "authors": "Hieu-Thi Luong and Junichi Yamagishi", "title": "Multimodal speech synthesis architecture for unsupervised speaker\n  adaptation", "comments": "Accepted for Interspeech 2018, India", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new architecture for speaker adaptation of\nmulti-speaker neural-network speech synthesis systems, in which an unseen\nspeaker's voice can be built using a relatively small amount of speech data\nwithout transcriptions. This is sometimes called \"unsupervised speaker\nadaptation\". More specifically, we concatenate the layers to the audio inputs\nwhen performing unsupervised speaker adaptation while we concatenate them to\nthe text inputs when synthesizing speech from text. Two new training schemes\nfor the new architecture are also proposed in this paper. These training\nschemes are not limited to speech synthesis, other applications are suggested.\nExperimental results show that the proposed model not only enables adaptation\nto unseen speakers using untranscribed speech but it also improves the\nperformance of multi-speaker modeling and speaker adaptation using transcribed\naudio files.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 02:36:19 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Luong", "Hieu-Thi", ""], ["Yamagishi", "Junichi", ""]]}, {"id": "1808.06289", "submitter": "Liang Wang", "authors": "Liang Wang, Sujian Li, Wei Zhao, Kewei Shen, Meng Sun, Ruoyu Jia,\n  Jingming Liu", "title": "Multi-Perspective Context Aggregation for Semi-supervised Cloze-style\n  Reading Comprehension", "comments": "11 pages, 2 figures, 5 tables, Accepted to COLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cloze-style reading comprehension has been a popular task for measuring the\nprogress of natural language understanding in recent years. In this paper, we\ndesign a novel multi-perspective framework, which can be seen as the joint\ntraining of heterogeneous experts and aggregate context information from\ndifferent perspectives. Each perspective is modeled by a simple aggregation\nmodule. The outputs of multiple aggregation modules are fed into a one-timestep\npointer network to get the final answer. At the same time, to tackle the\nproblem of insufficient labeled data, we propose an efficient sampling\nmechanism to automatically generate more training examples by matching the\ndistribution of candidates between labeled and unlabeled data. We conduct our\nexperiments on a recently released cloze-test dataset CLOTH (Xie et al., 2017),\nwhich consists of nearly 100k questions designed by professional teachers.\nResults show that our method achieves new state-of-the-art performance over\nprevious strong baselines.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 02:36:55 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Wang", "Liang", ""], ["Li", "Sujian", ""], ["Zhao", "Wei", ""], ["Shen", "Kewei", ""], ["Sun", "Meng", ""], ["Jia", "Ruoyu", ""], ["Liu", "Jingming", ""]]}, {"id": "1808.06304", "submitter": "Daya Guo", "authors": "Daya Guo, Yibo Sun, Duyu Tang, Nan Duan, Jian Yin, Hong Chi, James\n  Cao, Peng Chen and Ming Zhou", "title": "Question Generation from SQL Queries Improves Neural Semantic Parsing", "comments": "The paper will be presented in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how to learn a semantic parser of state-of-the-art accuracy with\nless supervised training data. We conduct our study on WikiSQL, the largest\nhand-annotated semantic parsing dataset to date. First, we demonstrate that\nquestion generation is an effective method that empowers us to learn a\nstate-of-the-art neural network based semantic parser with thirty percent of\nthe supervised training data. Second, we show that applying question generation\nto the full supervised training data further improves the state-of-the-art\nmodel. In addition, we observe that there is a logarithmic relationship between\nthe accuracy of a semantic parser and the amount of training data.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 04:39:58 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 13:00:13 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Guo", "Daya", ""], ["Sun", "Yibo", ""], ["Tang", "Duyu", ""], ["Duan", "Nan", ""], ["Yin", "Jian", ""], ["Chi", "Hong", ""], ["Cao", "James", ""], ["Chen", "Peng", ""], ["Zhou", "Ming", ""]]}, {"id": "1808.06305", "submitter": "Bin Wang", "authors": "Bin Wang, Fenxiao Chen, Angela Wang, C.-C. Jay Kuo", "title": "Post-Processing of Word Representations via Variance Normalization and\n  Dynamic Embedding", "comments": "8 pages, 2 figures", "journal-ref": "2019 International Conference on Multimedia and Expo", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although embedded vector representations of words offer impressive\nperformance on many natural language processing (NLP) applications, the\ninformation of ordered input sequences is lost to some extent if only\ncontext-based samples are used in the training. For further performance\nimprovement, two new post-processing techniques, called post-processing via\nvariance normalization (PVN) and post-processing via dynamic embedding (PDE),\nare proposed in this work. The PVN method normalizes the variance of principal\ncomponents of word vectors while the PDE method learns orthogonal latent\nvariables from ordered input sequences. The PVN and the PDE methods can be\nintegrated to achieve better performance. We apply these post-processing\ntechniques to two popular word embedding methods (i.e., word2vec and GloVe) to\nyield their post-processed representations. Extensive experiments are conducted\nto demonstrate the effectiveness of the proposed post-processing techniques.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 04:51:33 GMT"}, {"version": "v2", "created": "Wed, 5 Sep 2018 23:03:33 GMT"}, {"version": "v3", "created": "Mon, 4 Feb 2019 05:34:09 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Wang", "Bin", ""], ["Chen", "Fenxiao", ""], ["Wang", "Angela", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "1808.06497", "submitter": "Keting Lu", "authors": "Keting Lu, Shiqi Zhang, Xiaoping Chen", "title": "Goal-oriented Dialogue Policy Learning from Failures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning methods have been used for learning dialogue policies.\nHowever, learning an effective dialogue policy frequently requires\nprohibitively many conversations. This is partly because of the sparse rewards\nin dialogues, and the very few successful dialogues in early learning phase.\nHindsight experience replay (HER) enables learning from failures, but the\nvanilla HER is inapplicable to dialogue learning due to the implicit goals. In\nthis work, we develop two complex HER methods providing different trade-offs\nbetween complexity and performance, and, for the first time, enabled HER-based\ndialogue policy learning. Experiments using a realistic user simulator show\nthat our HER methods perform better than existing experience replay methods (as\napplied to deep Q-networks) in learning rate.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 15:04:30 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2018 13:51:34 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Lu", "Keting", ""], ["Zhang", "Shiqi", ""], ["Chen", "Xiaoping", ""]]}, {"id": "1808.06511", "submitter": "Ji Ma", "authors": "Ji Ma, Kuzman Ganchev and David Weiss", "title": "State-of-the-art Chinese Word Segmentation with Bi-LSTMs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide variety of neural-network architectures have been proposed for the\ntask of Chinese word segmentation.\n  Surprisingly, we find that a bidirectional LSTM model, when combined with\nstandard deep learning techniques and best practices, can achieve better\naccuracy on many of the popular datasets as compared to models based on more\ncomplex neural-network architectures.\n  Furthermore, our error analysis shows that out-of-vocabulary words remain\nchallenging for neural-network models, and many of the remaining errors are\nunlikely to be fixed through architecture changes.\n  Instead, more effort should be made on exploring resources for further\nimprovement.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 15:19:38 GMT"}, {"version": "v2", "created": "Fri, 24 Aug 2018 16:44:16 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Ma", "Ji", ""], ["Ganchev", "Kuzman", ""], ["Weiss", "David", ""]]}, {"id": "1808.06528", "submitter": "Bernhard Kratzwald", "authors": "Bernhard Kratzwald and Stefan Feuerriegel", "title": "Adaptive Document Retrieval for Deep Question Answering", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art systems in deep question answering proceed as follows: (1)\nan initial document retrieval selects relevant documents, which (2) are then\nprocessed by a neural network in order to extract the final answer. Yet the\nexact interplay between both components is poorly understood, especially\nconcerning the number of candidate documents that should be retrieved. We show\nthat choosing a static number of documents -- as used in prior research --\nsuffers from a noise-information trade-off and yields suboptimal results. As a\nremedy, we propose an adaptive document retrieval model. This learns the\noptimal candidate number for document retrieval, conditional on the size of the\ncorpus and the query. We report extensive experimental results showing that our\nadaptive approach outperforms state-of-the-art methods on multiple benchmark\ndatasets, as well as in the context of corpora with variable sizes.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 15:53:32 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Kratzwald", "Bernhard", ""], ["Feuerriegel", "Stefan", ""]]}, {"id": "1808.06570", "submitter": "Zining Zhu", "authors": "Zining Zhu, Jekaterina Novikova, Frank Rudzicz", "title": "Detecting cognitive impairments by agreeing on interpretations of\n  linguistic features", "comments": "NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linguistic features have shown promising applications for detecting various\ncognitive impairments. To improve detection accuracies, increasing the amount\nof data or the number of linguistic features have been two applicable\napproaches. However, acquiring additional clinical data can be expensive, and\nhand-crafting features is burdensome. In this paper, we take a third approach,\nproposing Consensus Networks (CNs), a framework to classify after reaching\nagreements between modalities. We divide linguistic features into\nnon-overlapping subsets according to their modalities, and let neural networks\nlearn low-dimensional representations that agree with each other. These\nrepresentations are passed into a classifier network. All neural networks are\noptimized iteratively.\n  In this paper, we also present two methods that improve the performance of\nCNs. We then present ablation studies to illustrate the effectiveness of\nmodality division. To understand further what happens in CNs, we visualize the\nrepresentations during training. Overall, using all of the 413 linguistic\nfeatures, our models significantly outperform traditional classifiers, which\nare used by the state-of-the-art papers.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 17:05:46 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 15:55:46 GMT"}, {"version": "v3", "created": "Thu, 28 Mar 2019 03:12:56 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Zhu", "Zining", ""], ["Novikova", "Jekaterina", ""], ["Rudzicz", "Frank", ""]]}, {"id": "1808.06640", "submitter": "Yanai Elazar", "authors": "Yanai Elazar and Yoav Goldberg", "title": "Adversarial Removal of Demographic Attributes from Text Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Representation Learning and Adversarial Training seem to\nsucceed in removing unwanted features from the learned representation. We show\nthat demographic information of authors is encoded in -- and can be recovered\nfrom -- the intermediate representations learned by text-based neural\nclassifiers. The implication is that decisions of classifiers trained on\ntextual data are not agnostic to -- and likely condition on -- demographic\nattributes. When attempting to remove such demographic information using\nadversarial training, we find that while the adversarial component achieves\nchance-level development-set accuracy during training, a post-hoc classifier,\ntrained on the encoded sentences from the first part, still manages to reach\nsubstantially higher classification accuracies on the same data. This behavior\nis consistent across several tasks, demographic properties and datasets. We\nexplore several techniques to improve the effectiveness of the adversarial\ncomponent. Our main conclusion is a cautionary one: do not rely on the\nadversarial training to achieve invariant representation to sensitive features.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 18:20:01 GMT"}, {"version": "v2", "created": "Sun, 2 Sep 2018 10:29:44 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Elazar", "Yanai", ""], ["Goldberg", "Yoav", ""]]}, {"id": "1808.06696", "submitter": "Dmitry Ustalov", "authors": "Dmitry Ustalov and Alexander Panchenko and Chris Biemann and Simone\n  Paolo Ponzetto", "title": "Watset: Local-Global Graph Clustering with Applications in Sense and\n  Frame Induction", "comments": "58 pages, 17 figures, accepted at the Computational Linguistics\n  journal", "journal-ref": "Computational Linguistics 45:3 (2019) 423-479", "doi": "10.1162/COLI_a_00354", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a detailed theoretical and computational analysis of the Watset\nmeta-algorithm for fuzzy graph clustering, which has been found to be widely\napplicable in a variety of domains. This algorithm creates an intermediate\nrepresentation of the input graph that reflects the \"ambiguity\" of its nodes.\nThen, it uses hard clustering to discover clusters in this \"disambiguated\"\nintermediate graph. After outlining the approach and analyzing its\ncomputational complexity, we demonstrate that Watset shows competitive results\nin three applications: unsupervised synset induction from a synonymy graph,\nunsupervised semantic frame induction from dependency triples, and unsupervised\nsemantic class induction from a distributional thesaurus. Our algorithm is\ngeneric and can be also applied to other networks of linguistic data.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 21:06:01 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 18:16:29 GMT"}, {"version": "v3", "created": "Mon, 8 Apr 2019 17:15:26 GMT"}, {"version": "v4", "created": "Wed, 19 Jun 2019 08:04:32 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Ustalov", "Dmitry", ""], ["Panchenko", "Alexander", ""], ["Biemann", "Chris", ""], ["Ponzetto", "Simone Paolo", ""]]}, {"id": "1808.06729", "submitter": "Bradley Hauer", "authors": "Bradley Hauer, Yixing Luan, Grzegorz Kondrak", "title": "You Shall Know the Most Frequent Sense by the Company it Keeps", "comments": "Updated to reflect the camera-ready version accepted to ICSC 2019", "journal-ref": "Proceedings of IEEE ICSC 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Identification of the most frequent sense of a polysemous word is an\nimportant semantic task. We introduce two concepts that can benefit MFS\ndetection: companions, which are the most frequently co-occurring words, and\nthe most frequent translation in a bitext. We present two novel methods that\nincorporate these new concepts, and show that they advance the state of the art\non MFS detection.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 01:18:37 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 15:06:47 GMT"}, {"version": "v3", "created": "Fri, 15 Feb 2019 16:25:36 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Hauer", "Bradley", ""], ["Luan", "Yixing", ""], ["Kondrak", "Grzegorz", ""]]}, {"id": "1808.06738", "submitter": "Tianyi Liu", "authors": "Tianyi Liu, Xinsong Zhang, Wanhao Zhou and Weijia Jia", "title": "Neural Relation Extraction via Inner-Sentence Noise Reduction and\n  Transfer Learning", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting relations is critical for knowledge base completion and\nconstruction in which distant supervised methods are widely used to extract\nrelational facts automatically with the existing knowledge bases. However, the\nautomatically constructed datasets comprise amounts of low-quality sentences\ncontaining noisy words, which is neglected by current distant supervised\nmethods resulting in unacceptable precisions. To mitigate this problem, we\npropose a novel word-level distant supervised approach for relation extraction.\nWe first build Sub-Tree Parse(STP) to remove noisy words that are irrelevant to\nrelations. Then we construct a neural network inputting the sub-tree while\napplying the entity-wise attention to identify the important semantic features\nof relational words in each instance. To make our model more robust against\nnoisy words, we initialize our network with a priori knowledge learned from the\nrelevant task of entity classification by transfer learning. We conduct\nextensive experiments using the corpora of New York Times(NYT) and Freebase.\nExperiments show that our approach is effective and improves the area of\nPrecision/Recall(PR) from 0.35 to 0.39 over the state-of-the-art work.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 02:15:05 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 16:03:03 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Liu", "Tianyi", ""], ["Zhang", "Xinsong", ""], ["Zhou", "Wanhao", ""], ["Jia", "Weijia", ""]]}, {"id": "1808.06740", "submitter": "Ziyu Yao", "authors": "Ziyu Yao, Xiujun Li, Jianfeng Gao, Brian Sadler and Huan Sun", "title": "Interactive Semantic Parsing for If-Then Recipes via Hierarchical\n  Reinforcement Learning", "comments": "13 pages, 2 figures, accepted by AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a text description, most existing semantic parsers synthesize a program\nin one shot. However, it is quite challenging to produce a correct program\nsolely based on the description, which in reality is often ambiguous or\nincomplete. In this paper, we investigate interactive semantic parsing, where\nthe agent can ask the user clarification questions to resolve ambiguities via a\nmulti-turn dialogue, on an important type of programs called \"If-Then recipes.\"\nWe develop a hierarchical reinforcement learning (HRL) based agent that\nsignificantly improves the parsing performance with minimal questions to the\nuser. Results under both simulation and human evaluation show that our agent\nsubstantially outperforms non-interactive semantic parsers and rule-based\nagents.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 02:39:08 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 18:08:39 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Yao", "Ziyu", ""], ["Li", "Xiujun", ""], ["Gao", "Jianfeng", ""], ["Sadler", "Brian", ""], ["Sun", "Huan", ""]]}, {"id": "1808.06752", "submitter": "Alexey Romanov", "authors": "Alexey Romanov and Chaitanya Shivade", "title": "Lessons from Natural Language Inference in the Clinical Domain", "comments": "Extended version of the EMNLP 2018 paper. Dataset and code available\n  at https://jgc128.github.io/mednli/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State of the art models using deep neural networks have become very good in\nlearning an accurate mapping from inputs to outputs. However, they still lack\ngeneralization capabilities in conditions that differ from the ones encountered\nduring training. This is even more challenging in specialized, and knowledge\nintensive domains, where training data is limited. To address this gap, we\nintroduce MedNLI - a dataset annotated by doctors, performing a natural\nlanguage inference task (NLI), grounded in the medical history of patients. We\npresent strategies to: 1) leverage transfer learning using datasets from the\nopen domain, (e.g. SNLI) and 2) incorporate domain knowledge from external data\nand lexical sources (e.g. medical terminologies). Our results demonstrate\nperformance gains using both strategies.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 04:00:23 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 16:06:44 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Romanov", "Alexey", ""], ["Shivade", "Chaitanya", ""]]}, {"id": "1808.06773", "submitter": "Hai Ye", "authors": "Hai Ye and Lu Wang", "title": "Semi-Supervised Learning for Neural Keyphrase Generation", "comments": "To appear in EMNLP 2018 (12 pages, 7 figures, 6 tables)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of generating keyphrases that summarize the key points\nfor a given document. While sequence-to-sequence (seq2seq) models have achieved\nremarkable performance on this task (Meng et al., 2017), model training often\nrelies on large amounts of labeled data, which is only applicable to\nresource-rich domains. In this paper, we propose semi-supervised keyphrase\ngeneration methods by leveraging both labeled data and large-scale unlabeled\nsamples for learning. Two strategies are proposed. First, unlabeled documents\nare first tagged with synthetic keyphrases obtained from unsupervised keyphrase\nextraction methods or a selflearning algorithm, and then combined with labeled\nsamples for training. Furthermore, we investigate a multi-task learning\nframework to jointly learn to generate keyphrases as well as the titles of the\narticles. Experimental results show that our semi-supervised learning-based\nmethods outperform a state-of-the-art model trained with labeled data only.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 05:38:32 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 12:57:07 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Ye", "Hai", ""], ["Wang", "Lu", ""]]}, {"id": "1808.06810", "submitter": "Johannes Hellrich", "authors": "Johannes Hellrich, Bernd Kampe, Udo Hahn", "title": "The Influence of Down-Sampling Strategies on SVD Word Embedding\n  Stability", "comments": "Updated for RepEval 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stability of word embedding algorithms, i.e., the consistency of the word\nrepresentations they reveal when trained repeatedly on the same data set, has\nrecently raised concerns. We here compare word embedding algorithms on three\ncorpora of different sizes, and evaluate both their stability and accuracy. We\nfind strong evidence that down-sampling strategies (used as part of their\ntraining procedures) are particularly influential for the stability of\nSVDPPMI-type embeddings. This finding seems to explain diverging reports on\ntheir stability and lead us to a simple modification which provides superior\nstability as well as accuracy on par with skip-gram embeddings.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 09:11:11 GMT"}, {"version": "v2", "created": "Mon, 8 Apr 2019 11:32:59 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Hellrich", "Johannes", ""], ["Kampe", "Bernd", ""], ["Hahn", "Udo", ""]]}, {"id": "1808.06826", "submitter": "J\\\"org Tiedemann", "authors": "J\\\"org Tiedemann and Yves Scherrer", "title": "Measuring Semantic Abstraction of Multilingual NMT with Paraphrase\n  Recognition and Generation Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate whether multilingual neural translation models\nlearn stronger semantic abstractions of sentences than bilingual ones. We test\nthis hypotheses by measuring the perplexity of such models when applied to\nparaphrases of the source language. The intuition is that an encoder produces\nbetter representations if a decoder is capable of recognizing synonymous\nsentences in the same language even though the model is never trained for that\ntask. In our setup, we add 16 different auxiliary languages to a bidirectional\nbilingual baseline model (English-French) and test it with in-domain and\nout-of-domain paraphrases in English. The results show that the perplexity is\nsignificantly reduced in each of the cases, indicating that meaning can be\ngrounded in translation. This is further supported by a study on paraphrase\ngeneration that we also include at the end of the paper.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 10:07:18 GMT"}, {"version": "v2", "created": "Fri, 3 May 2019 09:06:57 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Tiedemann", "J\u00f6rg", ""], ["Scherrer", "Yves", ""]]}, {"id": "1808.06834", "submitter": "Rohit Sakala Venkata Krishna", "authors": "Sakala Venkata Krishna Rohit and Navjyoti Singh", "title": "Analysis of Speeches in Indian Parliamentary Debates", "comments": "CICLING 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing usage of the internet, more and more data is being\ndigitized including parliamentary debates but they are in an unstructured\nformat. There is a need to convert them into a structured format for linguistic\nanalysis. Much work has been done on parliamentary data such as Hansard,\nAmerican congressional floor-debate data on various aspects but less on\npragmatics. In this paper, we provide a dataset for the synopsis of Indian\nparliamentary debates and perform stance classification of speeches i.e\nidentifying if the speaker is supporting the bill/issue or against it. We also\nanalyze the intention of the speeches beyond mere sentences i.e pragmatics in\nthe parliament. Based on thorough manual analysis of the debates, we developed\nan annotation scheme of 4 mutually exclusive categories to analyze the purpose\nof the speeches: to find out ISSUES, to BLAME, to APPRECIATE and for CALL FOR\nACTION. We have annotated the dataset provided, with these 4 categories and\nconducted preliminary experiments for automatic detection of the categories.\nOur automated classification approach gave us promising results.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 10:25:30 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Rohit", "Sakala Venkata Krishna", ""], ["Singh", "Navjyoti", ""]]}, {"id": "1808.06853", "submitter": "Seid Muhie Yimam", "authors": "Seid Muhie Yimam, Chris Biemann", "title": "Demonstrating PAR4SEM - A Semantic Writing Aid with Adaptive\n  Paraphrasing", "comments": "EMNLP Demo paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present Par4Sem, a semantic writing aid tool based on\nadaptive paraphrasing. Unlike many annotation tools that are primarily used to\ncollect training examples, Par4Sem is integrated into a real word application,\nin this case a writing aid tool, in order to collect training examples from\nusage data. Par4Sem is a tool, which supports an adaptive, iterative, and\ninteractive process where the underlying machine learning models are updated\nfor each iteration using new training examples from usage data. After\nmotivating the use of ever-learning tools in NLP applications, we evaluate\nPar4Sem by adopting it to a text simplification task through mere usage.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 11:37:57 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Yimam", "Seid Muhie", ""], ["Biemann", "Chris", ""]]}, {"id": "1808.06876", "submitter": "Giannis Bekoulis", "authors": "Giannis Bekoulis, Johannes Deleu, Thomas Demeester, Chris Develder", "title": "Adversarial training for multi-context joint entity and relation\n  extraction", "comments": "EMNLP 2018, code is available at\n  https://github.com/bekou/multihead_joint_entity_relation_extraction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training (AT) is a regularization method that can be used to\nimprove the robustness of neural network methods by adding small perturbations\nin the training data. We show how to use AT for the tasks of entity recognition\nand relation extraction. In particular, we demonstrate that applying AT to a\ngeneral purpose baseline model for jointly extracting entities and relations,\nallows improving the state-of-the-art effectiveness on several datasets in\ndifferent contexts (i.e., news, biomedical, and real estate data) and for\ndifferent languages (English and Dutch).\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 12:52:03 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2018 12:14:56 GMT"}, {"version": "v3", "created": "Mon, 14 Jan 2019 09:05:47 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Bekoulis", "Giannis", ""], ["Deleu", "Johannes", ""], ["Demeester", "Thomas", ""], ["Develder", "Chris", ""]]}, {"id": "1808.06880", "submitter": "Yuding Liang", "authors": "Yuding Liang and Kenny Q. Zhu", "title": "Automatic Generation of Text Descriptive Comments for Code Blocks", "comments": "aaai 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework to automatically generate descriptive comments for\nsource code blocks. While this problem has been studied by many researchers\npreviously, their methods are mostly based on fixed template and achieves poor\nresults. Our framework does not rely on any template, but makes use of a new\nrecursive neural network called Code-RNN to extract features from the source\ncode and embed them into one vector. When this vector representation is input\nto a new recurrent neural network (Code-GRU), the overall framework generates\ntext descriptions of the code with accuracy (Rouge-2 value) significantly\nhigher than other learning-based approaches such as sequence-to-sequence model.\nThe Code-RNN model can also be used in other scenario where the representation\nof code is required.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 12:53:52 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Liang", "Yuding", ""], ["Zhu", "Kenny Q.", ""]]}, {"id": "1808.06885", "submitter": "Fei Sun", "authors": "Fei Sun, Peng Jiang, Hanxiao Sun, Changhua Pei, Wenwu Ou, Xiaobo Wang", "title": "Multi-Source Pointer Network for Product Title Summarization", "comments": "10 pages, To appear in CIKM 2018, fix mistakes in dataset stats", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study the product title summarization problem in E-commerce\napplications for display on mobile devices. Comparing with conventional\nsentence summarization, product title summarization has some extra and\nessential constraints. For example, factual errors or loss of the key\ninformation are intolerable for E-commerce applications. Therefore, we abstract\ntwo more constraints for product title summarization: (i) do not introduce\nirrelevant information; (ii) retain the key information (e.g., brand name and\ncommodity name). To address these issues, we propose a novel multi-source\npointer network by adding a new knowledge encoder for pointer network. The\nfirst constraint is handled by pointer mechanism. For the second constraint, we\nrestore the key information by copying words from the knowledge encoder with\nthe help of the soft gating mechanism. For evaluation, we build a large\ncollection of real-world product titles along with human-written short titles.\nExperimental results demonstrate that our model significantly outperforms the\nother baselines. Finally, online deployment of our proposed model has yielded a\nsignificant business impact, as measured by the click-through rate.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 13:07:53 GMT"}, {"version": "v2", "created": "Sun, 30 Sep 2018 15:31:02 GMT"}, {"version": "v3", "created": "Mon, 8 Oct 2018 16:44:32 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Sun", "Fei", ""], ["Jiang", "Peng", ""], ["Sun", "Hanxiao", ""], ["Pei", "Changhua", ""], ["Ou", "Wenwu", ""], ["Wang", "Xiaobo", ""]]}, {"id": "1808.06945", "submitter": "Jingjing Xu", "authors": "Jingjing Xu, Xuancheng Ren, Yi Zhang, Qi Zeng, Xiaoyan Cai, Xu Sun", "title": "A Skeleton-Based Model for Promoting Coherence Among Sentences in\n  Narrative Story Generation", "comments": "Accepted by EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Narrative story generation is a challenging problem because it demands the\ngenerated sentences with tight semantic connections, which has not been well\nstudied by most existing generative models. To address this problem, we propose\na skeleton-based model to promote the coherence of generated stories. Different\nfrom traditional models that generate a complete sentence at a stroke, the\nproposed model first generates the most critical phrases, called skeleton, and\nthen expands the skeleton to a complete and fluent sentence. The skeleton is\nnot manually defined, but learned by a reinforcement learning method. Compared\nto the state-of-the-art models, our skeleton-based model can generate\nsignificantly more coherent text according to human evaluation and automatic\nevaluation. The G-score is improved by 20.1% in the human evaluation. The code\nis available at https://github.com/lancopku/Skeleton-Based-Generation-Model\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 14:55:34 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 08:16:21 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Xu", "Jingjing", ""], ["Ren", "Xuancheng", ""], ["Zhang", "Yi", ""], ["Zeng", "Qi", ""], ["Cai", "Xiaoyan", ""], ["Sun", "Xu", ""]]}, {"id": "1808.07016", "submitter": "Chi Sun", "authors": "Chi Sun, Hang Yan, Xipeng Qiu and Xuanjing Huang", "title": "Gaussian Word Embedding with a Wasserstein Distance Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared with word embedding based on point representation,\ndistribution-based word embedding shows more flexibility in expressing\nuncertainty and therefore embeds richer semantic information when representing\nwords. The Wasserstein distance provides a natural notion of dissimilarity with\nprobability measures and has a closed-form solution when measuring the distance\nbetween two Gaussian distributions. Therefore, with the aim of representing\nwords in a highly efficient way, we propose to operate a Gaussian word\nembedding model with a loss function based on the Wasserstein distance. Also,\nexternal information from ConceptNet will be used to semi-supervise the results\nof the Gaussian word embedding. Thirteen datasets from the word similarity\ntask, together with one from the word entailment task, and six datasets from\nthe downstream document classification task will be evaluated in this paper to\ntest our hypothesis.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 16:59:39 GMT"}, {"version": "v2", "created": "Wed, 22 Aug 2018 14:06:14 GMT"}, {"version": "v3", "created": "Thu, 23 Aug 2018 11:15:28 GMT"}, {"version": "v4", "created": "Fri, 24 Aug 2018 13:32:51 GMT"}, {"version": "v5", "created": "Mon, 27 Aug 2018 14:03:29 GMT"}, {"version": "v6", "created": "Tue, 28 Aug 2018 06:30:09 GMT"}, {"version": "v7", "created": "Sat, 1 Sep 2018 12:20:26 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Sun", "Chi", ""], ["Yan", "Hang", ""], ["Qiu", "Xipeng", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1808.07036", "submitter": "Mark Yatskar", "authors": "Eunsol Choi, He He, Mohit Iyyer, Mark Yatskar, Wen-tau Yih, Yejin\n  Choi, Percy Liang, Luke Zettlemoyer", "title": "QuAC : Question Answering in Context", "comments": "EMNLP Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present QuAC, a dataset for Question Answering in Context that contains\n14K information-seeking QA dialogs (100K questions in total). The dialogs\ninvolve two crowd workers: (1) a student who poses a sequence of freeform\nquestions to learn as much as possible about a hidden Wikipedia text, and (2) a\nteacher who answers the questions by providing short excerpts from the text.\nQuAC introduces challenges not found in existing machine comprehension\ndatasets: its questions are often more open-ended, unanswerable, or only\nmeaningful within the dialog context, as we show in a detailed qualitative\nevaluation. We also report results for a number of reference models, including\na recently state-of-the-art reading comprehension architecture extended to\nmodel dialog context. Our best model underperforms humans by 20 F1, suggesting\nthat there is significant room for future work on this data. Dataset, baseline,\nand leaderboard available at http://quac.ai.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 17:46:12 GMT"}, {"version": "v2", "created": "Wed, 22 Aug 2018 00:50:43 GMT"}, {"version": "v3", "created": "Tue, 28 Aug 2018 00:58:48 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Choi", "Eunsol", ""], ["He", "He", ""], ["Iyyer", "Mohit", ""], ["Yatskar", "Mark", ""], ["Yih", "Wen-tau", ""], ["Choi", "Yejin", ""], ["Liang", "Percy", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1808.07042", "submitter": "Siva Reddy", "authors": "Siva Reddy and Danqi Chen and Christopher D. Manning", "title": "CoQA: A Conversational Question Answering Challenge", "comments": "TACL (presented at NAACL 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Humans gather information by engaging in conversations involving a series of\ninterconnected questions and answers. For machines to assist in information\ngathering, it is therefore essential to enable them to answer conversational\nquestions. We introduce CoQA, a novel dataset for building Conversational\nQuestion Answering systems. Our dataset contains 127k questions with answers,\nobtained from 8k conversations about text passages from seven diverse domains.\nThe questions are conversational, and the answers are free-form text with their\ncorresponding evidence highlighted in the passage. We analyze CoQA in depth and\nshow that conversational questions have challenging phenomena not present in\nexisting reading comprehension datasets, e.g., coreference and pragmatic\nreasoning. We evaluate strong conversational and reading comprehension models\non CoQA. The best system obtains an F1 score of 65.4%, which is 23.4 points\nbehind human performance (88.8%), indicating there is ample room for\nimprovement. We launch CoQA as a challenge to the community at\nhttp://stanfordnlp.github.io/coqa/\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 17:52:02 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2019 20:50:21 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Reddy", "Siva", ""], ["Chen", "Danqi", ""], ["Manning", "Christopher D.", ""]]}, {"id": "1808.07046", "submitter": "Mohammad Kamel", "authors": "Mohammad Kamel, Hadi Sadoghi-Yazdi", "title": "ISNA-Set: A novel English Corpus of Iran NEWS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  News agencies publish news on their websites all over the world. Moreover,\ncreating novel corpuses is necessary to bring natural processing to new\ndomains. Textual processing of online news is challenging in terms of the\nstrategy of collecting data, the complex structure of news websites, and\nselecting or designing suitable algorithms for processing these types of data.\nDespite the previous works which focus on creating corpuses for Iran news in\nPersian, in this paper, we introduce a new corpus for English news of a\nnational news agency. ISNA-Set is a new dataset of English news of Iranian\nStudents News Agency (ISNA), as one of the most famous news agencies in Iran.\nWe statistically analyze the data and the sentiments of news, and also extract\nentities and part-of-speech tagging.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 17:58:05 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Kamel", "Mohammad", ""], ["Sadoghi-Yazdi", "Hadi", ""]]}, {"id": "1808.07048", "submitter": "Samuel L\\\"aubli", "authors": "Samuel L\\\"aubli, Rico Sennrich, Martin Volk", "title": "Has Machine Translation Achieved Human Parity? A Case for Document-level\n  Evaluation", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research suggests that neural machine translation achieves parity with\nprofessional human translation on the WMT Chinese--English news translation\ntask. We empirically test this claim with alternative evaluation protocols,\ncontrasting the evaluation of single sentences and entire documents. In a\npairwise ranking experiment, human raters assessing adequacy and fluency show a\nstronger preference for human over machine translation when evaluating\ndocuments as compared to isolated sentences. Our findings emphasise the need to\nshift towards document-level evaluation as machine translation improves to the\ndegree that errors which are hard or impossible to spot at the sentence-level\nbecome decisive in discriminating quality of different translation outputs.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 17:58:21 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["L\u00e4ubli", "Samuel", ""], ["Sennrich", "Rico", ""], ["Volk", "Martin", ""]]}, {"id": "1808.07104", "submitter": "Yury Zemlyanskiy", "authors": "Yury Zemlyanskiy and Fei Sha", "title": "Aiming to Know You Better Perhaps Makes Me a More Engaging Dialogue\n  Partner", "comments": "To appear in the proceedings of Conference on Computational Natural\n  Language Learning, CoNLL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been several attempts to define a plausible motivation for a\nchit-chat dialogue agent that can lead to engaging conversations. In this work,\nwe explore a new direction where the agent specifically focuses on discovering\ninformation about its interlocutor. We formalize this approach by defining a\nquantitative metric. We propose an algorithm for the agent to maximize it. We\nvalidate the idea with human evaluation where our system outperforms various\nbaselines. We demonstrate that the metric indeed correlates with the human\njudgments of engagingness.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 19:52:08 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Zemlyanskiy", "Yury", ""], ["Sha", "Fei", ""]]}, {"id": "1808.07118", "submitter": "Soumil Mandal", "authors": "Soumil Mandal, Anil Kumar Singh", "title": "Language Identification in Code-Mixed Data using Multichannel Neural\n  Networks and Context Capture", "comments": "The 4th Workshop on Noisy User-Generated Text (W-NUT), collocated\n  with EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An accurate language identification tool is an absolute necessity for\nbuilding complex NLP systems to be used on code-mixed data. Lot of work has\nbeen recently done on the same, but there's still room for improvement.\nInspired from the recent advancements in neural network architectures for\ncomputer vision tasks, we have implemented multichannel neural networks\ncombining CNN and LSTM for word level language identification of code-mixed\ndata. Combining this with a Bi-LSTM-CRF context capture module, accuracies of\n93.28% and 93.32% is achieved on our two testing sets.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 20:22:09 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Mandal", "Soumil", ""], ["Singh", "Anil Kumar", ""]]}, {"id": "1808.07166", "submitter": "Manuel Ortega-Rodr\\'iguez", "authors": "Manuel Ortega-Rodr\\'iguez, Hugo Sol\\'is-S\\'anchez, Ricardo\n  Gamboa-Alfaro", "title": "Deciding the status of controversial phonemes using frequency\n  distributions; an application to semiconsonants in Spanish", "comments": "24 pages, 10 figures", "journal-ref": "Physica A 503 (2018) 1020-1029", "doi": "10.1016/j.physa.2018.08.031", "report-no": null, "categories": "cs.CL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploiting the fact that natural languages are complex systems, the present\nexploratory article proposes a direct method based on frequency distributions\nthat may be useful when making a decision on the status of problematic\nphonemes, an open problem in linguistics. The main notion is that natural\nlanguages, which can be considered from a complex outlook as information\nprocessing machines, and which somehow manage to set appropriate levels of\nredundancy, already \"made the choice\" whether a linguistic unit is a phoneme or\nnot, and this would be reflected in a greater smoothness in a frequency versus\nrank graph. For the particular case we chose to study, we conclude that it is\nreasonable to consider the Spanish semiconsonant /w/ as a separate phoneme from\nits vowel counterpart /u/, on the one hand, and possibly also the semiconsonant\n/j/ as a separate phoneme from its vowel counterpart /i/, on the other. As\nlanguage has been so central a topic in the study of complexity, this\ndiscussion grants us, in addition, an opportunity to gain insight into emerging\nproperties in the broader complex systems debate.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 00:32:23 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Ortega-Rodr\u00edguez", "Manuel", ""], ["Sol\u00eds-S\u00e1nchez", "Hugo", ""], ["Gamboa-Alfaro", "Ricardo", ""]]}, {"id": "1808.07185", "submitter": "Yu Wu", "authors": "Jun Chen, Xiaoming Zhang, Yu Wu, Zhao Yan, Zhoujun Li", "title": "Keyphrase Generation with Correlation Constraints", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study automatic keyphrase generation. Although conventional\napproaches to this task show promising results, they neglect correlation among\nkeyphrases, resulting in duplication and coverage issues. To solve these\nproblems, we propose a new sequence-to-sequence architecture for keyphrase\ngeneration named CorrRNN, which captures correlation among multiple keyphrases\nin two ways. First, we employ a coverage vector to indicate whether the word in\nthe source document has been summarized by previous phrases to improve the\ncoverage for keyphrases. Second, preceding phrases are taken into account to\neliminate duplicate phrases and improve result coherence. Experiment results\nshow that our model significantly outperforms the state-of-the-art method on\nbenchmark datasets in terms of both accuracy and diversity.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 02:06:08 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Chen", "Jun", ""], ["Zhang", "Xiaoming", ""], ["Wu", "Yu", ""], ["Yan", "Zhao", ""], ["Li", "Zhoujun", ""]]}, {"id": "1808.07187", "submitter": "Xingxing Zhang", "authors": "Xingxing Zhang, Mirella Lapata, Furu Wei and Ming Zhou", "title": "Neural Latent Extractive Document Summarization", "comments": "to appear in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extractive summarization models require sentence-level labels, which are\nusually created heuristically (e.g., with rule-based methods) given that most\nsummarization datasets only have document-summary pairs. Since these labels\nmight be suboptimal, we propose a latent variable extractive model where\nsentences are viewed as latent variables and sentences with activated variables\nare used to infer gold summaries. During training the loss comes\n\\emph{directly} from gold summaries. Experiments on the CNN/Dailymail dataset\nshow that our model improves over a strong extractive baseline trained on\nheuristically approximated labels and also performs competitively to several\nrecent models.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 02:18:40 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 06:27:09 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Zhang", "Xingxing", ""], ["Lapata", "Mirella", ""], ["Wei", "Furu", ""], ["Zhou", "Ming", ""]]}, {"id": "1808.07191", "submitter": "Shuming Ma", "authors": "Deli Chen, Shuming Ma, Pengcheng Yang, Xu Sun", "title": "Identifying High-Quality Chinese News Comments Based on Multi-Target\n  Text Matching Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of information technology, there is an explosive growth\nin the number of online comment concerning news, blogs and so on. The massive\ncomments are overloaded, and often contain some misleading and unwelcome\ninformation. Therefore, it is necessary to identify high-quality comments and\nfilter out low-quality comments. In this work, we introduce a novel task:\nhigh-quality comment identification (HQCI), which aims to automatically assess\nthe quality of online comments. First, we construct a news comment corpus,\nwhich consists of news, comments, and the corresponding quality label. Second,\nwe analyze the dataset, and find the quality of comments can be measured in\nthree aspects: informativeness, consistency, and novelty. Finally, we propose a\nnovel multi-target text matching model, which can measure three aspects by\nreferring to the news and surrounding comments. Experimental results show that\nour method can outperform various baselines by a large margin on the news\ndataset.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 02:33:15 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Chen", "Deli", ""], ["Ma", "Shuming", ""], ["Yang", "Pengcheng", ""], ["Sun", "Xu", ""]]}, {"id": "1808.07214", "submitter": "Amir Zeldes", "authors": "Amir Zeldes", "title": "A Characterwise Windowed Approach to Hebrew Morphological Segmentation", "comments": "SIGMORPHON 2018, 15th Workshop on Computational Research in\n  Phonetics, Phonology, and Morphology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach to the segmentation of orthographic word\nforms in contemporary Hebrew, focusing purely on splitting without carrying out\nmorphological analysis or disambiguation. Casting the analysis task as\ncharacter-wise binary classification and using adjacent character and\nword-based lexicon-lookup features, this approach achieves over 98% accuracy on\nthe benchmark SPMRL shared task data for Hebrew, and 97% accuracy on a new out\nof domain Wikipedia dataset, an improvement of ~4% and 5% over previous state\nof the art performance.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 04:15:38 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 18:20:51 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Zeldes", "Amir", ""]]}, {"id": "1808.07228", "submitter": "Ganbin Zhou", "authors": "Ganbin Zhou, Rongyu Cao, Xiang Ao, Ping Luo, Fen Lin, Leyu Lin, Qing\n  He", "title": "Hierarchical Neural Network for Extracting Knowledgeable Snippets and\n  Documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we focus on extracting knowledgeable snippets and annotating\nknowledgeable documents from Web corpus, consisting of the documents from\nsocial media and We-media. Informally, knowledgeable snippets refer to the text\ndescribing concepts, properties of entities, or relations among entities, while\nknowledgeable documents are the ones with enough knowledgeable snippets. These\nknowledgeable snippets and documents could be helpful in multiple applications,\nsuch as knowledge base construction and knowledge-oriented service. Previous\nstudies extracted the knowledgeable snippets using the pattern-based method.\nHere, we propose the semantic-based method for this task. Specifically, a CNN\nbased model is developed to extract knowledgeable snippets and annotate\nknowledgeable documents simultaneously. Additionally, a \"low-level sharing,\nhigh-level splitting\" structure of CNN is designed to handle the documents from\ndifferent content domains. Compared with building multiple domain-specific\nCNNs, this joint model not only critically saves the training time, but also\nimproves the prediction accuracy visibly. The superiority of the proposed\nmethod is demonstrated in a real dataset from Wechat public platform.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 05:57:13 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Zhou", "Ganbin", ""], ["Cao", "Rongyu", ""], ["Ao", "Xiang", ""], ["Luo", "Ping", ""], ["Lin", "Fen", ""], ["Lin", "Leyu", ""], ["He", "Qing", ""]]}, {"id": "1808.07231", "submitter": "Ji Ho Park", "authors": "Ji Ho Park, Jamin Shin, Pascale Fung", "title": "Reducing Gender Bias in Abusive Language Detection", "comments": "6 pages. Accepted at the Conference on Empirical Methods in Natural\n  Language Processing (EMNLP), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abusive language detection models tend to have a problem of being biased\ntoward identity words of a certain group of people because of imbalanced\ntraining datasets. For example, \"You are a good woman\" was considered \"sexist\"\nwhen trained on an existing dataset. Such model bias is an obstacle for models\nto be robust enough for practical use. In this work, we measure gender biases\non models trained with different abusive language datasets, while analyzing the\neffect of different pre-trained word embeddings and model architectures. We\nalso experiment with three bias mitigation methods: (1) debiased word\nembeddings, (2) gender swap data augmentation, and (3) fine-tuning with a\nlarger corpus. These methods can effectively reduce gender bias by 90-98% and\ncan be extended to correct model bias in other scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 06:00:56 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Park", "Ji Ho", ""], ["Shin", "Jamin", ""], ["Fung", "Pascale", ""]]}, {"id": "1808.07235", "submitter": "Ji Ho Park", "authors": "Ji Ho Park", "title": "Finding Good Representations of Emotions for Text Classification", "comments": "HKUST MPhil Thesis, 87 pages", "journal-ref": "HKUST MPhil Thesis, 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is important for machines to interpret human emotions properly for better\nhuman-machine communications, as emotion is an essential part of human-to-human\ncommunications. One aspect of emotion is reflected in the language we use. How\nto represent emotions in texts is a challenge in natural language processing\n(NLP). Although continuous vector representations like word2vec have become the\nnew norm for NLP problems, their limitations are that they do not take emotions\ninto consideration and can unintentionally contain bias toward certain\nidentities like different genders.\n  This thesis focuses on improving existing representations in both word and\nsentence levels by explicitly taking emotions inside text and model bias into\naccount in their training process. Our improved representations can help to\nbuild more robust machine learning models for affect-related text\nclassification like sentiment/emotion analysis and abusive language detection.\n  We first propose representations called emotional word vectors (EVEC), which\nis learned from a convolutional neural network model with an emotion-labeled\ncorpus, which is constructed using hashtags. Secondly, we extend to learning\nsentence-level representations with a huge corpus of texts with the pseudo task\nof recognizing emojis. Our results show that, with the representations trained\nfrom millions of tweets with weakly supervised labels such as hashtags and\nemojis, we can solve sentiment/emotion analysis tasks more effectively.\n  Lastly, as examples of model bias in representations of existing approaches,\nwe explore a specific problem of automatic detection of abusive language. We\naddress the issue of gender bias in various neural network models by conducting\nexperiments to measure and reduce those biases in the representations in order\nto build more robust classification models.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 06:07:24 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Park", "Ji Ho", ""]]}, {"id": "1808.07244", "submitter": "Chongyang Tao", "authors": "Chongyang Tao, Wei Wu, Can Xu, Yansong Feng, Dongyan Zhao, Rui Yan", "title": "Improving Matching Models with Hierarchical Contextualized\n  Representations for Multi-turn Response Selection", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study context-response matching with pre-trained\ncontextualized representations for multi-turn response selection in\nretrieval-based chatbots. Existing models, such as Cove and ELMo, are trained\nwith limited context (often a single sentence or paragraph), and may not work\nwell on multi-turn conversations, due to the hierarchical nature, informal\nlanguage, and domain-specific words. To address the challenges, we propose\npre-training hierarchical contextualized representations, including contextual\nword-level and sentence-level representations, by learning a dialogue\ngeneration model from large-scale conversations with a hierarchical\nencoder-decoder architecture. Then the two levels of representations are\nblended into the input and output layer of a matching model respectively.\nExperimental results on two benchmark conversation datasets indicate that the\nproposed hierarchical contextualized representations can bring significantly\nand consistently improvement to existing matching models for response\nselection.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 06:58:01 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 07:10:41 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Tao", "Chongyang", ""], ["Wu", "Wei", ""], ["Xu", "Can", ""], ["Feng", "Yansong", ""], ["Zhao", "Dongyan", ""], ["Yan", "Rui", ""]]}, {"id": "1808.07290", "submitter": "Lei Wang", "authors": "Dongxiang Zhang, Lei Wang, Luming Zhang, Bing Tian Dai and Heng Tao\n  Shen", "title": "The Gap of Semantic Parsing: A Survey on Automatic Math Word Problem\n  Solvers", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving mathematical word problems (MWPs) automatically is challenging,\nprimarily due to the semantic gap between human-readable words and\nmachine-understandable logics. Despite the long history dated back to the1960s,\nMWPs have regained intensive attention in the past few years with the\nadvancement of Artificial Intelligence (AI). Solving MWPs successfully is\nconsidered as a milestone towards general AI. Many systems have claimed\npromising results in self-crafted and small-scale datasets. However, when\napplied on large and diverse datasets, none of the proposed methods in the\nliterature achieves high precision, revealing that current MWP solvers still\nhave much room for improvement. This motivated us to present a comprehensive\nsurvey to deliver a clear and complete picture of automatic math problem\nsolvers. In this survey, we emphasize on algebraic word problems, summarize\ntheir extracted features and proposed techniques to bridge the semantic gap and\ncompare their performance in the publicly accessible datasets. We also cover\nautomatic solvers for other types of math problems such as geometric problems\nthat require the understanding of diagrams. Finally, we identify several\nemerging research directions for the readers with interests in MWPs.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 09:18:38 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 05:51:46 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Zhang", "Dongxiang", ""], ["Wang", "Lei", ""], ["Zhang", "Luming", ""], ["Dai", "Bing Tian", ""], ["Shen", "Heng Tao", ""]]}, {"id": "1808.07311", "submitter": "Yi Zhang", "authors": "Yi Zhang, Jingjing Xu, Pengcheng Yang, Xu Sun", "title": "Learning Sentiment Memories for Sentiment Modification without Parallel\n  Data", "comments": "Accepted by EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of sentiment modification requires reversing the sentiment of the\ninput and preserving the sentiment-independent content. However, aligned\nsentences with the same content but different sentiments are usually\nunavailable. Due to the lack of such parallel data, it is hard to extract\nsentiment independent content and reverse the sentiment in an unsupervised way.\nPrevious work usually can not reconcile sentiment transformation and content\npreservation. In this paper, motivated by the fact the non-emotional context\n(e.g., \"staff\") provides strong cues for the occurrence of emotional words\n(e.g., \"friendly\"), we propose a novel method that automatically extracts\nappropriate sentiment information from learned sentiment memories according to\nspecific context. Experiments show that our method substantially improves the\ncontent preservation degree and achieves the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 10:57:04 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Zhang", "Yi", ""], ["Xu", "Jingjing", ""], ["Yang", "Pengcheng", ""], ["Sun", "Xu", ""]]}, {"id": "1808.07325", "submitter": "Yang Liu", "authors": "Yang Liu, Lixin Ji, Ruiyang Huang, Tuosiyu Ming, Chao Gao, Jianpeng\n  Zhang", "title": "An Attention-Gated Convolutional Neural Network for Sentence\n  Classification", "comments": "Accepted for publication in the Intelligent Data Analysis journal, 19\n  pages, 4 figures and 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classification of sentences is very challenging, since sentences contain\nthe limited contextual information. In this paper, we proposed an\nAttention-Gated Convolutional Neural Network (AGCNN) for sentence\nclassification, which generates attention weights from the feature's context\nwindows of different sizes by using specialized convolution encoders. It makes\nfull use of limited contextual information to extract and enhance the influence\nof important features in predicting the sentence's category. Experimental\nresults demonstrated that our model can achieve up to 3.1% higher accuracy than\nstandard CNN models, and gain competitive results over the baselines on four\nout of the six tasks. Besides, we designed an activation function, namely,\nNatural Logarithm rescaled Rectified Linear Unit (NLReLU). Experiments showed\nthat NLReLU can outperform ReLU and is comparable to other well-known\nactivation functions on AGCNN.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 12:03:48 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 13:35:25 GMT"}, {"version": "v3", "created": "Fri, 28 Dec 2018 09:22:44 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Liu", "Yang", ""], ["Ji", "Lixin", ""], ["Huang", "Ruiyang", ""], ["Ming", "Tuosiyu", ""], ["Gao", "Chao", ""], ["Zhang", "Jianpeng", ""]]}, {"id": "1808.07337", "submitter": "Hwiyeol Jo", "authors": "Hwiyeol Jo", "title": "Expansional Retrofitting for Word Vector Enrichment", "comments": "Anonymous NAACL2019 Submission Archieving before Public Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retrofitting techniques, which inject external resources into word\nrepresentations, have compensated the weakness of distributed representations\nin semantic and relational knowledge between words. Implicitly retrofitting\nword vectors by expansional technique outperforms retrofitting in word\nsimilarity tasks with word vector generalization. In this paper, we propose\nunsupervised extrofitting: expansional retrofitting (extrofitting) without\nexternal semantic lexicons. We also propose deep extrofitting: in-depth\nstacking of extrofitting and further combinations of extrofitting with\nretrofitting. When experimenting with GloVe, we show that our methods\noutperform the previous methods on most of word similarity tasks while\nrequiring only synonyms as an external resource. Lastly, we show the effect of\nword vector enrichment on text classification task, as a downstream task.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 12:49:46 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 15:13:07 GMT"}, {"version": "v3", "created": "Tue, 22 Jan 2019 23:54:56 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Jo", "Hwiyeol", ""]]}, {"id": "1808.07364", "submitter": "Abdalghani Abujabal", "authors": "Abdalghani Abujabal and Judith Gaspers", "title": "Neural Named Entity Recognition from Subword Units", "comments": "5 pages, INTERSPEECH 2019", "journal-ref": null, "doi": "10.21437/Interspeech.2019-1305", "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Named entity recognition (NER) is a vital task in spoken language\nunderstanding, which aims to identify mentions of named entities in text e.g.,\nfrom transcribed speech. Existing neural models for NER rely mostly on\ndedicated word-level representations, which suffer from two main shortcomings.\nFirst, the vocabulary size is large, yielding large memory requirements and\ntraining time. Second, these models are not able to learn morphological or\nphonological representations. To remedy the above shortcomings, we adopt a\nneural solution based on bidirectional LSTMs and conditional random fields,\nwhere we rely on subword units, namely characters, phonemes, and bytes. For\neach word in an utterance, our model learns a representation from each of the\nsubword units. We conducted experiments in a real-world large-scale setting for\nthe use case of a voice-controlled device covering four languages with up to\n5.5M utterances per language. Our experiments show that (1) with increasing\ntraining data, performance of models trained solely on subword units becomes\ncloser to that of models with dedicated word-level embeddings (91.35 vs 93.92\nF1 for English), while using a much smaller vocabulary size (332 vs 74K), (2)\nsubword units enhance models with dedicated word-level embeddings, and (3)\ncombining different subword units improves performance.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 13:56:51 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 11:16:47 GMT"}, {"version": "v3", "created": "Sun, 22 Sep 2019 10:14:53 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Abujabal", "Abdalghani", ""], ["Gaspers", "Judith", ""]]}, {"id": "1808.07374", "submitter": "Junyang Lin", "authors": "Junyang Lin, Xu Sun, Xuancheng Ren, Muyu Li and Qi Su", "title": "Learning When to Concentrate or Divert Attention: Self-Adaptive\n  Attention Temperature for Neural Machine Translation", "comments": "To appear in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the Neural Machine Translation (NMT) models are based on the\nsequence-to-sequence (Seq2Seq) model with an encoder-decoder framework equipped\nwith the attention mechanism. However, the conventional attention mechanism\ntreats the decoding at each time step equally with the same matrix, which is\nproblematic since the softness of the attention for different types of words\n(e.g. content words and function words) should differ. Therefore, we propose a\nnew model with a mechanism called Self-Adaptive Control of Temperature (SACT)\nto control the softness of attention by means of an attention temperature.\nExperimental results on the Chinese-English translation and English-Vietnamese\ntranslation demonstrate that our model outperforms the baseline models, and the\nanalysis and the case study show that our model can attend to the most relevant\nelements in the source-side contexts and generate the translation of high\nquality.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 14:13:24 GMT"}, {"version": "v2", "created": "Sun, 26 Aug 2018 16:19:56 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Lin", "Junyang", ""], ["Sun", "Xu", ""], ["Ren", "Xuancheng", ""], ["Li", "Muyu", ""], ["Su", "Qi", ""]]}, {"id": "1808.07383", "submitter": "Deunsol Yoon", "authors": "Deunsol Yoon, Dongbok Lee, SangKeun Lee", "title": "Dynamic Self-Attention : Computing Attention over Words Dynamically for\n  Sentence Embedding", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Dynamic Self-Attention (DSA), a new self-attention\nmechanism for sentence embedding. We design DSA by modifying dynamic routing in\ncapsule network (Sabouretal.,2017) for natural language processing. DSA attends\nto informative words with a dynamic weight vector. We achieve new\nstate-of-the-art results among sentence encoding methods in Stanford Natural\nLanguage Inference (SNLI) dataset with the least number of parameters, while\nshowing comparative results in Stanford Sentiment Treebank (SST) dataset.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 14:30:03 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Yoon", "Deunsol", ""], ["Lee", "Dongbok", ""], ["Lee", "SangKeun", ""]]}, {"id": "1808.07512", "submitter": "Xinyi Wang", "authors": "Xinyi Wang, Hieu Pham, Zihang Dai, Graham Neubig", "title": "SwitchOut: an Efficient Data Augmentation Algorithm for Neural Machine\n  Translation", "comments": "Accepted as a short paper at the 2018 Conference on Empirical Methods\n  in Natural Language Processing (EMNLP 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we examine methods for data augmentation for text-based tasks\nsuch as neural machine translation (NMT). We formulate the design of a data\naugmentation policy with desirable properties as an optimization problem, and\nderive a generic analytic solution. This solution not only subsumes some\nexisting augmentation schemes, but also leads to an extremely simple data\naugmentation strategy for NMT: randomly replacing words in both the source\nsentence and the target sentence with other random words from their\ncorresponding vocabularies. We name this method SwitchOut. Experiments on three\ntranslation datasets of different scales show that SwitchOut yields consistent\nimprovements of about 0.5 BLEU, achieving better or comparable performances to\nstrong alternatives such as word dropout (Sennrich et al., 2016a). Code to\nimplement this method is included in the appendix.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 18:26:43 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 15:43:09 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Wang", "Xinyi", ""], ["Pham", "Hieu", ""], ["Dai", "Zihang", ""], ["Neubig", "Graham", ""]]}, {"id": "1808.07531", "submitter": "Debanjan Ghosh", "authors": "Debanjan Ghosh and Alexander R. Fabbri and Smaranda Muresan", "title": "Sarcasm Analysis using Conversation Context", "comments": "Computational Linguistics (journal)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational models for sarcasm detection have often relied on the content\nof utterances in isolation. However, the speaker's sarcastic intent is not\nalways apparent without additional context. Focusing on social media\ndiscussions, we investigate three issues: (1) does modeling conversation\ncontext help in sarcasm detection; (2) can we identify what part of\nconversation context triggered the sarcastic reply; and (3) given a sarcastic\npost that contains multiple sentences, can we identify the specific sentence\nthat is sarcastic. To address the first issue, we investigate several types of\nLong Short-Term Memory (LSTM) networks that can model both the conversation\ncontext and the current turn. We show that LSTM networks with sentence-level\nattention on context and current turn, as well as the conditional LSTM network\n(Rocktaschel et al. 2016), outperform the LSTM model that reads only the\ncurrent turn. As conversation context, we consider the prior turn, the\nsucceeding turn or both. Our computational models are tested on two types of\nsocial media platforms: Twitter and discussion forums. We discuss several\ndifferences between these datasets ranging from their size to the nature of the\ngold-label annotations. To address the last two issues, we present a\nqualitative analysis of attention weights produced by the LSTM models (with\nattention) and discuss the results compared with human performance on the two\ntasks.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 19:21:04 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 16:29:54 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Ghosh", "Debanjan", ""], ["Fabbri", "Alexander R.", ""], ["Muresan", "Smaranda", ""]]}, {"id": "1808.07561", "submitter": "Ankur Bapna", "authors": "Ankur Bapna, Mia Xu Chen, Orhan Firat, Yuan Cao, Yonghui Wu", "title": "Training Deeper Neural Machine Translation Models with Transparent\n  Attention", "comments": "To appear in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While current state-of-the-art NMT models, such as RNN seq2seq and\nTransformers, possess a large number of parameters, they are still shallow in\ncomparison to convolutional models used for both text and vision applications.\nIn this work we attempt to train significantly (2-3x) deeper Transformer and\nBi-RNN encoders for machine translation. We propose a simple modification to\nthe attention mechanism that eases the optimization of deeper models, and\nresults in consistent gains of 0.7-1.1 BLEU on the benchmark WMT'14\nEnglish-German and WMT'15 Czech-English tasks for both architectures.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 20:53:37 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 20:10:24 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Bapna", "Ankur", ""], ["Chen", "Mia Xu", ""], ["Firat", "Orhan", ""], ["Cao", "Yuan", ""], ["Wu", "Yonghui", ""]]}, {"id": "1808.07582", "submitter": "Xinyue Liu", "authors": "Xinyue Liu, Xiangnan Kong, Lei Liu, Kuorong Chiang", "title": "TreeGAN: Syntax-Aware Sequence Generation with Generative Adversarial\n  Networks", "comments": "IEEE International Conference on Data Mining (ICDM'18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Generative Adversarial Networks (GANs) have shown great capacity on image\ngeneration, in which a discriminative model guides the training of a generative\nmodel to construct images that resemble real images. Recently, GANs have been\nextended from generating images to generating sequences (e.g., poems, music and\ncodes). Existing GANs on sequence generation mainly focus on general sequences,\nwhich are grammar-free. In many real-world applications, however, we need to\ngenerate sequences in a formal language with the constraint of its\ncorresponding grammar. For example, to test the performance of a database, one\nmay want to generate a collection of SQL queries, which are not only similar to\nthe queries of real users, but also follow the SQL syntax of the target\ndatabase. Generating such sequences is highly challenging because both the\ngenerator and discriminator of GANs need to consider the structure of the\nsequences and the given grammar in the formal language. To address these\nissues, we study the problem of syntax-aware sequence generation with GANs, in\nwhich a collection of real sequences and a set of pre-defined grammatical rules\nare given to both discriminator and generator. We propose a novel GAN\nframework, namely TreeGAN, to incorporate a given Context-Free Grammar (CFG)\ninto the sequence generation process. In TreeGAN, the generator employs a\nrecurrent neural network (RNN) to construct a parse tree. Each generated parse\ntree can then be translated to a valid sequence of the given grammar. The\ndiscriminator uses a tree-structured RNN to distinguish the generated trees\nfrom real trees. We show that TreeGAN can generate sequences for any CFG and\nits generation fully conforms with the given syntax. Experiments on synthetic\nand real data sets demonstrated that TreeGAN significantly improves the quality\nof the sequence generation in context-free languages.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2018 22:32:34 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Liu", "Xinyue", ""], ["Kong", "Xiangnan", ""], ["Liu", "Lei", ""], ["Chiang", "Kuorong", ""]]}, {"id": "1808.07599", "submitter": "Yuchen Zhang", "authors": "Yuchen Zhang and Nianwen Xue", "title": "Structured Interpretation of Temporal Relations", "comments": "9 pages, 2 figures, 8 tables, LREC-2018", "journal-ref": "Yuchen Zhang and Nianwen Xue. 2018. Structured Interpretation of\n  Temporal Relations. In Proceedings of the 11th Language Resources and\n  Evaluation Conference (LREC-2018), Miyazaki, Japan", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal relations between events and time expressions in a document are\noften modeled in an unstructured manner where relations between individual\npairs of time expressions and events are considered in isolation. This often\nresults in inconsistent and incomplete annotation and computational modeling.\nWe propose a novel annotation approach where events and time expressions in a\ndocument form a dependency tree in which each dependency relation corresponds\nto an instance of temporal anaphora where the antecedent is the parent and the\nanaphor is the child. We annotate a corpus of 235 documents using this approach\nin the two genres of news and narratives, with 48 documents doubly annotated.\nWe report a stable and high inter-annotator agreement on the doubly annotated\nsubset, validating our approach, and perform a quantitative comparison between\nthe two genres of the entire corpus. We make this corpus publicly available.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 00:37:58 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Zhang", "Yuchen", ""], ["Xue", "Nianwen", ""]]}, {"id": "1808.07604", "submitter": "Guangxiang Zhao", "authors": "Guangxiang Zhao, Jingjing Xu, Qi Zeng, Xuancheng Ren", "title": "Review-Driven Multi-Label Music Style Classification by Exploiting Style\n  Correlations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores a new natural language processing task, review-driven\nmulti-label music style classification. This task requires the system to\nidentify multiple styles of music based on its reviews on websites. The biggest\nchallenge lies in the complicated relations of music styles. It has brought\nfailure to many multi-label classification methods. To tackle this problem, we\npropose a novel deep learning approach to automatically learn and exploit style\ncorrelations. The proposed method consists of two parts: a label-graph based\nneural network, and a soft training mechanism with correlation-based continuous\nlabel representation. Experimental results show that our approach achieves\nlarge improvements over the baselines on the proposed dataset. Especially, the\nmicro F1 is improved from 53.9 to 64.5, and the one-error is reduced from 30.5\nto 22.6. Furthermore, the visualized analysis shows that our approach performs\nwell in capturing style correlations.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 02:02:32 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Zhao", "Guangxiang", ""], ["Xu", "Jingjing", ""], ["Zeng", "Qi", ""], ["Ren", "Xuancheng", ""]]}, {"id": "1808.07624", "submitter": "Lingfei Wu", "authors": "Kun Xu, Lingfei Wu, Zhiguo Wang, Mo Yu, Liwei Chen, Vadim Sheinin", "title": "Exploiting Rich Syntactic Information for Semantic Parsing with\n  Graph-to-Sequence Model", "comments": "EMNLP'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing neural semantic parsers mainly utilize a sequence encoder, i.e., a\nsequential LSTM, to extract word order features while neglecting other valuable\nsyntactic information such as dependency graph or constituent trees. In this\npaper, we first propose to use the \\textit{syntactic graph} to represent three\ntypes of syntactic information, i.e., word order, dependency and constituency\nfeatures. We further employ a graph-to-sequence model to encode the syntactic\ngraph and decode a logical form. Experimental results on benchmark datasets\nshow that our model is comparable to the state-of-the-art on Jobs640, ATIS and\nGeo880. Experimental results on adversarial examples demonstrate the robustness\nof the model is also improved by encoding more syntactic information.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 03:58:21 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Xu", "Kun", ""], ["Wu", "Lingfei", ""], ["Wang", "Zhiguo", ""], ["Yu", "Mo", ""], ["Chen", "Liwei", ""], ["Sheinin", "Vadim", ""]]}, {"id": "1808.07625", "submitter": "Jianpeng Cheng J", "authors": "Jianpeng Cheng and Mirella Lapata", "title": "Weakly-supervised Neural Semantic Parsing with a Generative Ranker", "comments": "In EMNLP-CoNLL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weakly-supervised semantic parsers are trained on utterance-denotation pairs,\ntreating logical forms as latent. The task is challenging due to the large\nsearch space and spuriousness of logical forms. In this paper we introduce a\nneural parser-ranker system for weakly-supervised semantic parsing. The parser\ngenerates candidate tree-structured logical forms from utterances using clues\nof denotations. These candidates are then ranked based on two criterion: their\nlikelihood of executing to the correct denotation, and their agreement with the\nutterance semantics. We present a scheduled training procedure to balance the\ncontribution of the two objectives. Furthermore, we propose to use a neurally\nencoded lexicon to inject prior domain knowledge to the model. Experiments on\nthree Freebase datasets demonstrate the effectiveness of our semantic parser,\nachieving results within the state-of-the-art range.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 04:03:58 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Cheng", "Jianpeng", ""], ["Lapata", "Mirella", ""]]}, {"id": "1808.07644", "submitter": "Minghao Hu", "authors": "Minghao Hu, Yuxing Peng, Furu Wei, Zhen Huang, Dongsheng Li, Nan Yang,\n  Ming Zhou", "title": "Attention-Guided Answer Distillation for Machine Reading Comprehension", "comments": "To appear at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite that current reading comprehension systems have achieved significant\nadvancements, their promising performances are often obtained at the cost of\nmaking an ensemble of numerous models. Besides, existing approaches are also\nvulnerable to adversarial attacks. This paper tackles these problems by\nleveraging knowledge distillation, which aims to transfer knowledge from an\nensemble model to a single model. We first demonstrate that vanilla knowledge\ndistillation applied to answer span prediction is effective for reading\ncomprehension systems. We then propose two novel approaches that not only\npenalize the prediction on confusing answers but also guide the training with\nalignment information distilled from the ensemble. Experiments show that our\nbest student model has only a slight drop of 0.4% F1 on the SQuAD test set\ncompared to the ensemble teacher, while running 12x faster during inference. It\neven outperforms the teacher on adversarial SQuAD datasets and NarrativeQA\nbenchmark.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 06:27:58 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 02:22:22 GMT"}, {"version": "v3", "created": "Thu, 13 Sep 2018 12:24:43 GMT"}, {"version": "v4", "created": "Mon, 17 Sep 2018 06:54:53 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Hu", "Minghao", ""], ["Peng", "Yuxing", ""], ["Wei", "Furu", ""], ["Huang", "Zhen", ""], ["Li", "Dongsheng", ""], ["Yang", "Nan", ""], ["Zhou", "Ming", ""]]}, {"id": "1808.07645", "submitter": "Huang Hu", "authors": "Huang Hu, Xianchao Wu, Bingfeng Luo, Chongyang Tao, Can Xu, Wei Wu,\n  Zhan Chen", "title": "Playing 20 Question Game with Policy-Based Reinforcement Learning", "comments": "Accepted by EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 20 Questions (Q20) game is a well known game which encourages deductive\nreasoning and creativity. In the game, the answerer first thinks of an object\nsuch as a famous person or a kind of animal. Then the questioner tries to guess\nthe object by asking 20 questions. In a Q20 game system, the user is considered\nas the answerer while the system itself acts as the questioner which requires a\ngood strategy of question selection to figure out the correct object and win\nthe game. However, the optimal policy of question selection is hard to be\nderived due to the complexity and volatility of the game environment. In this\npaper, we propose a novel policy-based Reinforcement Learning (RL) method,\nwhich enables the questioner agent to learn the optimal policy of question\nselection through continuous interactions with users. To facilitate training,\nwe also propose to use a reward network to estimate the more informative\nreward. Compared to previous methods, our RL method is robust to noisy answers\nand does not rely on the Knowledge Base of objects. Experimental results show\nthat our RL method clearly outperforms an entropy-based engineering system and\nhas competitive performance in a noisy-free simulation environment.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 06:34:32 GMT"}, {"version": "v2", "created": "Sun, 26 Aug 2018 09:47:54 GMT"}, {"version": "v3", "created": "Mon, 24 Jun 2019 06:28:09 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Hu", "Huang", ""], ["Wu", "Xianchao", ""], ["Luo", "Bingfeng", ""], ["Tao", "Chongyang", ""], ["Xu", "Can", ""], ["Wu", "Wei", ""], ["Chen", "Zhan", ""]]}, {"id": "1808.07658", "submitter": "Xipeng Qiu", "authors": "Junkun Chen and Kaiyu Chen and Xinchi Chen and Xipeng Qiu and Xuanjing\n  Huang", "title": "Exploring Shared Structures and Hierarchies for Multiple NLP Tasks", "comments": "8", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing shared neural architecture plays an important role in multi-task\nlearning. The challenge is that finding an optimal sharing scheme heavily\nrelies on the expert knowledge and is not scalable to a large number of diverse\ntasks. Inspired by the promising work of neural architecture search (NAS), we\napply reinforcement learning to automatically find possible shared architecture\nfor multi-task learning. Specifically, we use a controller to select from a set\nof shareable modules and assemble a task-specific architecture, and repeat the\nsame procedure for other tasks. The controller is trained with reinforcement\nlearning to maximize the expected accuracies for all tasks. We conduct\nextensive experiments on two types of tasks, text classification and sequence\nlabeling, which demonstrate the benefits of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 08:07:44 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Chen", "Junkun", ""], ["Chen", "Kaiyu", ""], ["Chen", "Xinchi", ""], ["Qiu", "Xipeng", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1808.07674", "submitter": "Wajdi Zaghouani", "authors": "Wajdi Zaghouani and Anis Charfi", "title": "Arap-Tweet: A Large Multi-Dialect Twitter Corpus for Gender, Age and\n  Language Variety Identification", "comments": "Proceedings of the Eleventh International Conference on Language\n  Resources and Evaluation (LREC 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present Arap-Tweet, which is a large-scale and\nmulti-dialectal corpus of Tweets from 11 regions and 16 countries in the Arab\nworld representing the major Arabic dialectal varieties. To build this corpus,\nwe collected data from Twitter and we provided a team of experienced annotators\nwith annotation guidelines that they used to annotate the corpus for age\ncategories, gender, and dialectal variety. During the data collection effort,\nwe based our search on distinctive keywords that are specific to the different\nArabic dialects and we also validated the location using Twitter API. In this\npaper, we report on the corpus data collection and annotation efforts. We also\npresent some issues that we encountered during these phases. Then, we present\nthe results of the evaluation performed to ensure the consistency of the\nannotation. The provided corpus will enrich the limited set of available\nlanguage resources for Arabic and will be an invaluable enabler for developing\nauthor profiling tools and NLP tools for Arabic.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 09:41:17 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Zaghouani", "Wajdi", ""], ["Charfi", "Anis", ""]]}, {"id": "1808.07678", "submitter": "Wajdi Zaghouani", "authors": "Wajdi Zaghouani and Anis Charfi", "title": "Guidelines and Annotation Framework for Arabic Author Profiling", "comments": "Proceedings of the Eleventh International Conference on Language\n  Resources and Evaluation (LREC 2018), The 3rd Workshop on Open-Source Arabic\n  Corpora and Processing Tools: with ArabicWeb16 Data Challenge. arXiv admin\n  note: text overlap with arXiv:1808.07674", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present the annotation pipeline and the guidelines we wrote\nas part of an effort to create a large manually annotated Arabic author\nprofiling dataset from various social media sources covering 16 Arabic\ncountries and 11 dialectal regions. The target size of the annotated ARAP-Tweet\ncorpus is more than 2.4 million words. We illustrate and summarize our general\nand dialect-specific guidelines for each of the dialectal regions selected. We\nalso present the annotation framework and logistics. We control the annotation\nquality frequently by computing the inter-annotator agreement during the\nannotation process. Finally, we describe the issues encountered during the\nannotation phase, especially those related to the peculiarities of Arabic\ndialectal varieties as used in social media.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 09:52:26 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Zaghouani", "Wajdi", ""], ["Charfi", "Anis", ""]]}, {"id": "1808.07688", "submitter": "Amber Nigam", "authors": "Amber Nigam, Arpan Saxena and Ishan Sodhi", "title": "Role of Intonation in Scoring Spoken English", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we have introduced and evaluated intonation based feature for\nscoring the English speech of nonnative English speakers in Indian context. For\nthis, we created an automated spoken English scoring engine to learn from the\nmanual evaluation of spoken English. This involved using an existing Automatic\nSpeech Recognition (ASR) engine to convert the speech to text. Thereafter,\nmacro features like accuracy, fluency and prosodic features were used to build\na scoring model. In the process, we introduced SimIntonation, short for\nsimilarity between spoken intonation pattern and \"ideal\" i.e. training\nintonation pattern. Our results show that it is a highly predictive feature\nunder controlled environment. We also categorized interword pauses into 4\ndistinct types for a granular evaluation of pauses and their impact on speech\nevaluation. Moreover, we took steps to moderate test difficulty through its\nevaluation across parameters like difficult word count, average sentence\nreadability and lexical density. Our results show that macro features like\naccuracy and intonation, and micro features like pause-topography are strongly\npredictive. The scoring of spoken English is not within the purview of this\npaper.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 10:13:52 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 06:33:28 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Nigam", "Amber", ""], ["Saxena", "Arpan", ""], ["Sodhi", "Ishan", ""]]}, {"id": "1808.07699", "submitter": "Octavian-Eugen Ganea", "authors": "Nikolaos Kolitsas, Octavian-Eugen Ganea, Thomas Hofmann", "title": "End-to-End Neural Entity Linking", "comments": "Full paper at CoNLL 2018: Conference on Computational Natural\n  Language Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity Linking (EL) is an essential task for semantic text understanding and\ninformation extraction. Popular methods separately address the Mention\nDetection (MD) and Entity Disambiguation (ED) stages of EL, without leveraging\ntheir mutual dependency. We here propose the first neural end-to-end EL system\nthat jointly discovers and links entities in a text document. The main idea is\nto consider all possible spans as potential mentions and learn contextual\nsimilarity scores over their entity candidates that are useful for both MD and\nED decisions. Key components are context-aware mention embeddings, entity\nembeddings and a probabilistic mention - entity map, without demanding other\nengineered features. Empirically, we show that our end-to-end method\nsignificantly outperforms popular systems on the Gerbil platform when enough\ntraining data is available. Conversely, if testing datasets follow different\nannotation conventions compared to the training set (e.g. queries/ tweets vs\nnews documents), our ED model coupled with a traditional NER system offers the\nbest or second best EL accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 11:16:57 GMT"}, {"version": "v2", "created": "Wed, 29 Aug 2018 17:44:38 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Kolitsas", "Nikolaos", ""], ["Ganea", "Octavian-Eugen", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1808.07724", "submitter": "Dimitri Kartsaklis", "authors": "Dimitri Kartsaklis, Mohammad Taher Pilehvar, Nigel Collier", "title": "Mapping Text to Knowledge Graph Entities using Multi-Sense LSTMs", "comments": "Accepted for presentation at EMNLP 2018 (main conference)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of mapping natural language text to\nknowledge base entities. The mapping process is approached as a composition of\na phrase or a sentence into a point in a multi-dimensional entity space\nobtained from a knowledge graph. The compositional model is an LSTM equipped\nwith a dynamic disambiguation mechanism on the input word embeddings (a\nMulti-Sense LSTM), addressing polysemy issues. Further, the knowledge base\nspace is prepared by collecting random walks from a graph enhanced with textual\nfeatures, which act as a set of semantic bridges between text and knowledge\nbase entities. The ideas of this work are demonstrated on large-scale\ntext-to-entity mapping and entity classification tasks, with state of the art\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 12:47:01 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Kartsaklis", "Dimitri", ""], ["Pilehvar", "Mohammad Taher", ""], ["Collier", "Nigel", ""]]}, {"id": "1808.07733", "submitter": "Kalpesh Krishna", "authors": "Kalpesh Krishna, Preethi Jyothi, Mohit Iyyer", "title": "Revisiting the Importance of Encoding Logic Rules in Sentiment\n  Classification", "comments": "EMNLP 2018 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the performance of different sentiment classification models on\nsyntactically complex inputs like A-but-B sentences. The first contribution of\nthis analysis addresses reproducible research: to meaningfully compare\ndifferent models, their accuracies must be averaged over far more random seeds\nthan what has traditionally been reported. With proper averaging in place, we\nnotice that the distillation model described in arXiv:1603.06318v4 [cs.LG],\nwhich incorporates explicit logic rules for sentiment classification, is\nineffective. In contrast, using contextualized ELMo embeddings\n(arXiv:1802.05365v2 [cs.CL]) instead of logic rules yields significantly better\nperformance. Additionally, we provide analysis and visualizations that\ndemonstrate ELMo's ability to implicitly learn logic rules. Finally, a\ncrowdsourced analysis reveals how ELMo outperforms baseline models even on\nsentences with ambiguous sentiment labels.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 13:03:55 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Krishna", "Kalpesh", ""], ["Jyothi", "Preethi", ""], ["Iyyer", "Mohit", ""]]}, {"id": "1808.07851", "submitter": "Alexander Panchenko", "authors": "Alexander Panchenko", "title": "Sentiment Index of the Russian Speaking Facebook", "comments": "In Proceedings of the 20th International Conference on Computational\n  Linguistics and Intellectual Technologies (Dialogue'2014). Moscow, Russia.\n  RGGU", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A sentiment index measures the average emotional level in a corpus. We\nintroduce four such indexes and use them to gauge average \"positiveness\" of a\npopulation during some period based on posts in a social network. This article\nfor the first time presents a text-, rather than word-based sentiment index.\nFurthermore, this study presents the first large-scale study of the sentiment\nindex of the Russian-speaking Facebook. Our results are consistent with the\nprior experiments for the English language.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 17:24:42 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Panchenko", "Alexander", ""]]}, {"id": "1808.07894", "submitter": "Zhirui Zhang", "authors": "Zhirui Zhang, Shuo Ren, Shujie Liu, Jianyong Wang, Peng Chen, Mu Li,\n  Ming Zhou, Enhong Chen", "title": "Style Transfer as Unsupervised Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language style transferring rephrases text with specific stylistic attributes\nwhile preserving the original attribute-independent content. One main challenge\nin learning a style transfer system is a lack of parallel data where the source\nsentence is in one style and the target sentence in another style. With this\nconstraint, in this paper, we adapt unsupervised machine translation methods\nfor the task of automatic style transfer. We first take advantage of\nstyle-preference information and word embedding similarity to produce\npseudo-parallel data with a statistical machine translation (SMT) framework.\nThen the iterative back-translation approach is employed to jointly train two\nneural machine translation (NMT) based transfer systems. To control the noise\ngenerated during joint training, a style classifier is introduced to guarantee\nthe accuracy of style transfer and penalize bad candidates in the generated\npseudo data. Experiments on benchmark datasets show that our proposed method\noutperforms previous state-of-the-art models in terms of both accuracy of style\ntransfer and quality of input-output correspondence.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 18:18:32 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Zhang", "Zhirui", ""], ["Ren", "Shuo", ""], ["Liu", "Shujie", ""], ["Wang", "Jianyong", ""], ["Chen", "Peng", ""], ["Li", "Mu", ""], ["Zhou", "Ming", ""], ["Chen", "Enhong", ""]]}, {"id": "1808.07910", "submitter": "Nicolas Ford", "authors": "Nicolas Ford, Daniel Duckworth, Mohammad Norouzi, and George E. Dahl", "title": "The Importance of Generation Order in Language Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural language models are a critical component of state-of-the-art systems\nfor machine translation, summarization, audio transcription, and other tasks.\nThese language models are almost universally autoregressive in nature,\ngenerating sentences one token at a time from left to right. This paper studies\nthe influence of token generation order on model quality via a novel two-pass\nlanguage model that produces partially-filled sentence \"templates\" and then\nfills in missing tokens. We compare various strategies for structuring these\ntwo passes and observe a surprisingly large variation in model quality. We find\nthe most effective strategy generates function words in the first pass followed\nby content words in the second. We believe these experimental results justify a\nmore extensive investigation of generation order for neural language models.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 19:17:24 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Ford", "Nicolas", ""], ["Duckworth", "Daniel", ""], ["Norouzi", "Mohammad", ""], ["Dahl", "George E.", ""]]}, {"id": "1808.07913", "submitter": "Romain Paulus", "authors": "Wojciech Kry\\'sci\\'nski, Romain Paulus, Caiming Xiong, Richard Socher", "title": "Improving Abstraction in Text Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstractive text summarization aims to shorten long text documents into a\nhuman readable form that contains the most important facts from the original\ndocument. However, the level of actual abstraction as measured by novel phrases\nthat do not appear in the source document remains low in existing approaches.\nWe propose two techniques to improve the level of abstraction of generated\nsummaries. First, we decompose the decoder into a contextual network that\nretrieves relevant parts of the source document, and a pretrained language\nmodel that incorporates prior knowledge about language generation. Second, we\npropose a novelty metric that is optimized directly through policy learning to\nencourage the generation of novel phrases. Our model achieves results\ncomparable to state-of-the-art models, as determined by ROUGE scores and human\nevaluations, while achieving a significantly higher level of abstraction as\nmeasured by n-gram overlap with the source document.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 19:19:27 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Kry\u015bci\u0144ski", "Wojciech", ""], ["Paulus", "Romain", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1808.07931", "submitter": "Jason Rosenfeld", "authors": "Steve Yang, Jason Rosenfeld, Jacques Makutonin", "title": "Financial Aspect-Based Sentiment Analysis using Deep Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The topic of aspect-based sentiment analysis (ABSA) has been explored for a\nvariety of industries, but it still remains much unexplored in finance. The\nrecent release of data for an open challenge (FiQA) from the companion\nproceedings of WWW '18 has provided valuable finance-specific annotations. FiQA\ncontains high quality labels, but it still lacks data quantity to apply\ntraditional ABSA deep learning architecture. In this paper, we employ\nhigh-level semantic representations and methods of inductive transfer learning\nfor NLP. We experiment with extensions of recently developed domain adaptation\nmethods and target task fine-tuning that significantly improve performance on a\nsmall dataset. Our results show an 8.7% improvement in the F1 score for\nclassification and an 11% improvement over the MSE for regression on current\nstate-of-the-art results.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 20:23:36 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Yang", "Steve", ""], ["Rosenfeld", "Jason", ""], ["Makutonin", "Jacques", ""]]}, {"id": "1808.07982", "submitter": "Yi-Lin Tuan", "authors": "Yi-Lin Tuan, Jinzhi Zhang, Yujia Li, Hung-yi Lee", "title": "Proximal Policy Optimization and its Dynamic Version for Sequence\n  Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In sequence generation task, many works use policy gradient for model\noptimization to tackle the intractable backpropagation issue when maximizing\nthe non-differentiable evaluation metrics or fooling the discriminator in\nadversarial learning. In this paper, we replace policy gradient with proximal\npolicy optimization (PPO), which is a proved more efficient reinforcement\nlearning algorithm, and propose a dynamic approach for PPO (PPO-dynamic). We\ndemonstrate the efficacy of PPO and PPO-dynamic on conditional sequence\ngeneration tasks including synthetic experiment and chit-chat chatbot. The\nresults show that PPO and PPO-dynamic can beat policy gradient by stability and\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 02:14:43 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Tuan", "Yi-Lin", ""], ["Zhang", "Jinzhi", ""], ["Li", "Yujia", ""], ["Lee", "Hung-yi", ""]]}, {"id": "1808.07999", "submitter": "Arthur Jacobs M", "authors": "Arthur M. Jacobs, Annette Kinder", "title": "Features of word similarity", "comments": "20 pages, 1 Figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this theoretical note we compare different types of computational models\nof word similarity and association in their ability to predict a set of about\n900 rating data. Using regression and predictive modeling tools (neural net,\ndecision tree) the performance of a total of 28 models using different\ncombinations of both surface and semantic word features is evaluated. The\nresults present evidence for the hypothesis that word similarity ratings are\nbased on more than only semantic relatedness. The limited cross-validated\nperformance of the models asks for the development of psychological process\nmodels of the word similarity rating task.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 03:46:45 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Jacobs", "Arthur M.", ""], ["Kinder", "Annette", ""]]}, {"id": "1808.08003", "submitter": "Wenhu Chen", "authors": "Wenhu Chen, Guanlin Li, Shujie Liu, Zhirui Zhang, Mu Li, Ming Zhou", "title": "Approximate Distribution Matching for Sequence-to-Sequence Learning", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-Sequence models were introduced to tackle many real-life problems\nlike machine translation, summarization, image captioning, etc. The standard\noptimization algorithms are mainly based on example-to-example matching like\nmaximum likelihood estimation, which is known to suffer from data sparsity\nproblem. Here we present an alternate view to explain sequence-to-sequence\nlearning as a distribution matching problem, where each source or target\nexample is viewed to represent a local latent distribution in the source or\ntarget domain. Then, we interpret sequence-to-sequence learning as learning a\ntransductive model to transform the source local latent distributions to match\ntheir corresponding target distributions. In our framework, we approximate both\nthe source and target latent distributions with recurrent neural networks\n(augmenter). During training, the parallel augmenters learn to better\napproximate the local latent distributions, while the sequence prediction model\nlearns to minimize the KL-divergence of the transformed source distributions\nand the approximated target distributions. This algorithm can alleviate the\ndata sparsity issues in sequence learning by locally augmenting more unseen\ndata pairs and increasing the model's robustness. Experiments conducted on\nmachine translation and image captioning consistently demonstrate the\nsuperiority of our proposed algorithm over the other competing algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 05:00:17 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 05:09:44 GMT"}, {"version": "v3", "created": "Sun, 2 Sep 2018 04:38:56 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Chen", "Wenhu", ""], ["Li", "Guanlin", ""], ["Liu", "Shujie", ""], ["Zhang", "Zhirui", ""], ["Li", "Mu", ""], ["Zhou", "Ming", ""]]}, {"id": "1808.08047", "submitter": "Michael Roth", "authors": "Michael Roth", "title": "Role Semantics for Better Models of Implicit Discourse Relations", "comments": "Published at IWCS 2017 (yes, it's old by now but still relevant :P)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Predicting the structure of a discourse is challenging because relations\nbetween discourse segments are often implicit and thus hard to distinguish\ncomputationally. I extend previous work to classify implicit discourse\nrelations by introducing a novel set of features on the level of semantic\nroles. My results demonstrate that such features are helpful, yielding results\ncompetitive with other feature-rich approaches on the PDTB. My main\ncontribution is an analysis of improvements that can be traced back to\nrole-based features, providing insights into why and when role semantics is\nhelpful.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 08:32:38 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Roth", "Michael", ""]]}, {"id": "1808.08079", "submitter": "Dieuwke Hupkes", "authors": "Mario Giulianelli, Jack Harding, Florian Mohnert, Dieuwke Hupkes,\n  Willem Zuidema", "title": "Under the Hood: Using Diagnostic Classifiers to Investigate and Improve\n  how Language Models Track Agreement Information", "comments": "to appear at the EMNLP workshop \"Analyzing and interpreting neural\n  networks for NLP\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How do neural language models keep track of number agreement between subject\nand verb? We show that `diagnostic classifiers', trained to predict number from\nthe internal states of a language model, provide a detailed understanding of\nhow, when, and where this information is represented. Moreover, they give us\ninsight into when and where number information is corrupted in cases where the\nlanguage model ends up making agreement errors. To demonstrate the causal role\nplayed by the representations we find, we then use agreement information to\ninfluence the course of the LSTM during the processing of difficult sentences.\nResults from such an intervention reveal a large increase in the language\nmodel's accuracy. Together, these results show that diagnostic classifiers give\nus an unrivalled detailed look into the representation of linguistic\ninformation in neural models, and demonstrate that this knowledge can be used\nto improve their performance.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 10:29:45 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 13:51:39 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Giulianelli", "Mario", ""], ["Harding", "Jack", ""], ["Mohnert", "Florian", ""], ["Hupkes", "Dieuwke", ""], ["Zuidema", "Willem", ""]]}, {"id": "1808.08098", "submitter": "Mika M\\\"antyl\\\"a", "authors": "Mika M\\\"antyl\\\"a, Ma\\\"elick Claes, Umar Farooq", "title": "Measuring LDA Topic Stability from Clusters of Replicated Runs", "comments": "ESEM '18 ACM / IEEE International Symposium on Empirical Software\n  Engineering and Measurement (ESEM)}{October 11--12, 2018}{Oulu, Finland}", "journal-ref": null, "doi": "10.1145/3239235.3267435", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Unstructured and textual data is increasing rapidly and Latent\nDirichlet Allocation (LDA) topic modeling is a popular data analysis methods\nfor it. Past work suggests that instability of LDA topics may lead to\nsystematic errors. Aim: We propose a method that relies on replicated LDA runs,\nclustering, and providing a stability metric for the topics. Method: We\ngenerate k LDA topics and replicate this process n times resulting in n*k\ntopics. Then we use K-medioids to cluster the n*k topics to k clusters. The k\nclusters now represent the original LDA topics and we present them like normal\nLDA topics showing the ten most probable words. For the clusters, we try\nmultiple stability metrics, out of which we recommend Rank-Biased Overlap,\nshowing the stability of the topics inside the clusters. Results: We provide an\ninitial validation where our method is used for 270,000 Mozilla Firefox commit\nmessages with k=20 and n=20. We show how our topic stability metrics are\nrelated to the contents of the topics. Conclusions: Advances in text mining\nenable us to analyze large masses of text in software engineering but\nnon-deterministic algorithms, such as LDA, may lead to unreplicable\nconclusions. Our approach makes LDA stability transparent and is also\ncomplementary rather than alternative to many prior works that focus on LDA\nparameter tuning.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 11:37:40 GMT"}], "update_date": "2018-09-04", "authors_parsed": [["M\u00e4ntyl\u00e4", "Mika", ""], ["Claes", "Ma\u00eblick", ""], ["Farooq", "Umar", ""]]}, {"id": "1808.08149", "submitter": "Shen Li", "authors": "Hengru Xu, Shen Li, Renfen Hu, Si Li, Sheng Gao", "title": "From Random to Supervised: A Novel Dropout Mechanism Integrated with\n  Global Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout is used to avoid overfitting by randomly dropping units from the\nneural networks during training. Inspired by dropout, this paper presents\nGI-Dropout, a novel dropout method integrating with global information to\nimprove neural networks for text classification. Unlike the traditional dropout\nmethod in which the units are dropped randomly according to the same\nprobability, we aim to use explicit instructions based on global information of\nthe dataset to guide the training process. With GI-Dropout, the model is\nsupposed to pay more attention to inapparent features or patterns. Experiments\ndemonstrate the effectiveness of the dropout with global information on seven\ntext classification tasks, including sentiment analysis and topic\nclassification.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 14:17:01 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 02:04:51 GMT"}, {"version": "v3", "created": "Wed, 10 Oct 2018 07:54:51 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Xu", "Hengru", ""], ["Li", "Shen", ""], ["Hu", "Renfen", ""], ["Li", "Si", ""], ["Gao", "Sheng", ""]]}, {"id": "1808.08266", "submitter": "Mingyang Zhou", "authors": "Mingyang Zhou, Runxiang Cheng, Yong Jae Lee, Zhou Yu", "title": "A Visual Attention Grounding Neural Model for Multimodal Machine\n  Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel multimodal machine translation model that utilizes\nparallel visual and textual information. Our model jointly optimizes the\nlearning of a shared visual-language embedding and a translator. The model\nleverages a visual attention grounding mechanism that links the visual\nsemantics with the corresponding textual semantics. Our approach achieves\ncompetitive state-of-the-art results on the Multi30K and the Ambiguous COCO\ndatasets. We also collected a new multilingual multimodal product description\ndataset to simulate a real-world international online shopping scenario. On\nthis dataset, our visual attention grounding model outperforms other methods by\na large margin.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 18:47:29 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 06:23:02 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Zhou", "Mingyang", ""], ["Cheng", "Runxiang", ""], ["Lee", "Yong Jae", ""], ["Yu", "Zhou", ""]]}, {"id": "1808.08270", "submitter": "Md Rizwan Parvez", "authors": "Md Rizwan Parvez, Tolga Bolukbasi, Kai-Wei Chang, Venkatesh Saligrama", "title": "Robust Text Classifier on Test-Time Budgets", "comments": "To appear at EMNLP-IJCAI 2019, 6 pages + 2 pages appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generic and interpretable learning framework for building robust\ntext classification model that achieves accuracy comparable to full models\nunder test-time budget constraints. Our approach learns a selector to identify\nwords that are relevant to the prediction tasks and passes them to the\nclassifier for processing. The selector is trained jointly with the classifier\nand directly learns to incorporate with the classifier. We further propose a\ndata aggregation scheme to improve the robustness of the classifier. Our\nlearning framework is general and can be incorporated with any type of text\nclassification model. On real-world data, we show that the proposed approach\nimproves the performance of a given classifier and speeds up the model with a\nmere loss in accuracy performance.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 19:22:12 GMT"}, {"version": "v2", "created": "Wed, 29 Aug 2018 04:29:26 GMT"}, {"version": "v3", "created": "Sun, 1 Sep 2019 22:26:48 GMT"}, {"version": "v4", "created": "Wed, 11 Sep 2019 01:21:25 GMT"}, {"version": "v5", "created": "Fri, 13 Sep 2019 19:46:04 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Parvez", "Md Rizwan", ""], ["Bolukbasi", "Tolga", ""], ["Chang", "Kai-Wei", ""], ["Saligrama", "Venkatesh", ""]]}, {"id": "1808.08316", "submitter": "Tu  Nguyen", "authors": "Tu Ngoc Nguyen, Tuan Tran and Wolfgang Nejdl", "title": "A Trio Neural Model for Dynamic Entity Relatedness Ranking", "comments": "In Proceedings of CoNLL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring entity relatedness is a fundamental task for many natural language\nprocessing and information retrieval applications. Prior work often studies\nentity relatedness in static settings and an unsupervised manner. However,\nentities in real-world are often involved in many different relationships,\nconsequently entity-relations are very dynamic over time. In this work, we\npropose a neural networkbased approach for dynamic entity relatedness,\nleveraging the collective attention as supervision. Our model is capable of\nlearning rich and different entity representations in a joint framework.\nThrough extensive experiments on large-scale datasets, we demonstrate that our\nmethod achieves better results than competitive baselines.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 21:29:53 GMT"}, {"version": "v2", "created": "Wed, 29 Aug 2018 22:00:03 GMT"}, {"version": "v3", "created": "Fri, 7 Sep 2018 00:38:54 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Nguyen", "Tu Ngoc", ""], ["Tran", "Tuan", ""], ["Nejdl", "Wolfgang", ""]]}, {"id": "1808.08357", "submitter": "Bijil Abraham Philip", "authors": "Bijil Abraham Philip, Manas Jog, Apurv Milind Upasani", "title": "Dr. Tux: A Question Answering System for Ubuntu users", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various forums and question answering (Q&A) sites are available online that\nallow Ubuntu users to find results similar to their queries. However, searching\nfor a result is often time consuming as it requires the user to find a specific\nproblem instance relevant to his/her query from a large set of questions. In\nthis paper, we present an automated question answering system for Ubuntu users\ncalled Dr. Tux that is designed to answer user's queries by selecting the most\nsimilar question from an online database. The prototype was implemented in\nPython and uses NLTK and CoreNLP tools for Natural Language Processing. The\ndata for the prototype was taken from the AskUbuntu website which contains\nabout 150k questions. The results obtained from the manual evaluation of the\nprototype were promising while also presenting some interesting opportunities\nfor improvement.\n", "versions": [{"version": "v1", "created": "Sat, 25 Aug 2018 05:17:43 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Philip", "Bijil Abraham", ""], ["Jog", "Manas", ""], ["Upasani", "Apurv Milind", ""]]}, {"id": "1808.08392", "submitter": "Wajdi Zaghouani", "authors": "Ossama Obeid, Salam Khalifa, Nizar Habash, Houda Bouamor, Wajdi\n  Zaghouani, Kemal Oflazer", "title": "MADARi: A Web Interface for Joint Arabic Morphological Annotation and\n  Spelling Correction", "comments": "Proceedings of the Eleventh International Conference on Language\n  Resources and Evaluation (LREC 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we introduce MADARi, a joint morphological annotation and\nspelling correction system for texts in Standard and Dialectal Arabic. The\nMADARi framework provides intuitive interfaces for annotating text and managing\nthe annotation process of a large number of sizable documents. Morphological\nannotation includes indicating, for a word, in context, its baseword, clitics,\npart-of-speech, lemma, gloss, and dialect identification. MADARi has a suite of\nutilities to help with annotator productivity. For example, annotators are\nprovided with pre-computed analyses to assist them in their task and reduce the\namount of work needed to complete it. MADARi also allows annotators to query a\nmorphological analyzer for a list of possible analyses in multiple dialects or\nlook up previously submitted analyses. The MADARi management interface enables\na lead annotator to easily manage and organize the whole annotation process\nremotely and concurrently. We describe the motivation, design and\nimplementation of this interface; and we present details from a user study\nworking with this system.\n", "versions": [{"version": "v1", "created": "Sat, 25 Aug 2018 09:32:30 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Obeid", "Ossama", ""], ["Khalifa", "Salam", ""], ["Habash", "Nizar", ""], ["Bouamor", "Houda", ""], ["Zaghouani", "Wajdi", ""], ["Oflazer", "Kemal", ""]]}, {"id": "1808.08409", "submitter": "Radu Tudor Ionescu", "authors": "Radu Tudor Ionescu, Andrei M. Butnaru", "title": "Improving the results of string kernels in sentiment analysis and Arabic\n  dialect identification by adapting them to your test set", "comments": "Accepted at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, string kernels have obtained state-of-the-art results in various\ntext classification tasks such as Arabic dialect identification or native\nlanguage identification. In this paper, we apply two simple yet effective\ntransductive learning approaches to further improve the results of string\nkernels. The first approach is based on interpreting the pairwise string kernel\nsimilarities between samples in the training set and samples in the test set as\nfeatures. Our second approach is a simple self-training method based on two\nlearning iterations. In the first iteration, a classifier is trained on the\ntraining set and tested on the test set, as usual. In the second iteration, a\nnumber of test samples (to which the classifier associated higher confidence\nscores) are added to the training set for another round of training. However,\nthe ground-truth labels of the added test samples are not necessary. Instead,\nwe use the labels predicted by the classifier in the first training iteration.\nBy adapting string kernels to the test set, we report significantly better\naccuracy rates in English polarity classification and Arabic dialect\nidentification.\n", "versions": [{"version": "v1", "created": "Sat, 25 Aug 2018 11:08:28 GMT"}, {"version": "v2", "created": "Fri, 31 Aug 2018 13:17:00 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Ionescu", "Radu Tudor", ""], ["Butnaru", "Andrei M.", ""]]}, {"id": "1808.08432", "submitter": "Athanasios Giannakopoulos", "authors": "Christian Abbet, Meryem M'hamdi, Athanasios Giannakopoulos, Robert\n  West, Andreea Hossmann, Michael Baeriswyl and Claudiu Musat", "title": "Churn Intent Detection in Multilingual Chatbot Conversations and Social\n  Media", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method to detect when users express the intent to leave a\nservice, also known as churn. While previous work focuses solely on social\nmedia, we show that this intent can be detected in chatbot conversations. As\ncompanies increasingly rely on chatbots they need an overview of potentially\nchurny users. To this end, we crowdsource and publish a dataset of churn intent\nexpressions in chatbot interactions in German and English. We show that\nclassifiers trained on social media data can detect the same intent in the\ncontext of chatbots.\n  We introduce a classification architecture that outperforms existing work on\nchurn intent detection in social media. Moreover, we show that, using bilingual\nword embeddings, a system trained on combined English and German data\noutperforms monolingual approaches. As the only existing dataset is in English,\nwe crowdsource and publish a novel dataset of German tweets. We thus underline\nthe universal aspect of the problem, as examples of churn intent in English\nhelp us identify churn in German tweets and chatbot conversations.\n", "versions": [{"version": "v1", "created": "Sat, 25 Aug 2018 14:24:23 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Abbet", "Christian", ""], ["M'hamdi", "Meryem", ""], ["Giannakopoulos", "Athanasios", ""], ["West", "Robert", ""], ["Hossmann", "Andreea", ""], ["Baeriswyl", "Michael", ""], ["Musat", "Claudiu", ""]]}, {"id": "1808.08437", "submitter": "Jiatao Gu", "authors": "Jiatao Gu, Yong Wang, Yun Chen, Kyunghyun Cho and Victor O.K. Li", "title": "Meta-Learning for Low-Resource Neural Machine Translation", "comments": "Accepted as a full paper at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose to extend the recently introduced model-agnostic\nmeta-learning algorithm (MAML) for low-resource neural machine translation\n(NMT). We frame low-resource translation as a meta-learning problem, and we\nlearn to adapt to low-resource languages based on multilingual high-resource\nlanguage tasks. We use the universal lexical\nrepresentation~\\citep{gu2018universal} to overcome the input-output mismatch\nacross different languages. We evaluate the proposed meta-learning strategy\nusing eighteen European languages (Bg, Cs, Da, De, El, Es, Et, Fr, Hu, It, Lt,\nNl, Pl, Pt, Sk, Sl, Sv and Ru) as source tasks and five diverse languages (Ro,\nLv, Fi, Tr and Ko) as target tasks. We show that the proposed approach\nsignificantly outperforms the multilingual, transfer learning based\napproach~\\citep{zoph2016transfer} and enables us to train a competitive NMT\nsystem with only a fraction of training examples. For instance, the proposed\napproach can achieve as high as 22.04 BLEU on Romanian-English WMT'16 by seeing\nonly 16,000 translated words (~600 parallel sentences).\n", "versions": [{"version": "v1", "created": "Sat, 25 Aug 2018 15:10:59 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Gu", "Jiatao", ""], ["Wang", "Yong", ""], ["Chen", "Yun", ""], ["Cho", "Kyunghyun", ""], ["Li", "Victor O. K.", ""]]}, {"id": "1808.08438", "submitter": "Zhong Zhou", "authors": "Zhong Zhou, Matthias Sperber, Alex Waibel", "title": "Paraphrases as Foreign Languages in Multilingual Neural Machine\n  Translation", "comments": null, "journal-ref": "Proceedings of 57th Annual Meeting of the Association for\n  Computational Linguistics Student Research Workshop, 2019", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Paraphrases, the rewordings of the same semantic meaning, are useful for\nimproving generalization and translation. However, prior works only explore\nparaphrases at the word or phrase level, not at the sentence or corpus level.\nUnlike previous works that only explore paraphrases at the word or phrase\nlevel, we use different translations of the whole training data that are\nconsistent in structure as paraphrases at the corpus level. We train on\nparallel paraphrases in multiple languages from various sources. We treat\nparaphrases as foreign languages, tag source sentences with paraphrase labels,\nand train on parallel paraphrases in the style of multilingual Neural Machine\nTranslation (NMT). Our multi-paraphrase NMT that trains only on two languages\noutperforms the multilingual baselines. Adding paraphrases improves the rare\nword translation and increases entropy and diversity in lexical choice. Adding\nthe source paraphrases boosts performance better than adding the target ones.\nCombining both the source and the target paraphrases lifts performance further;\ncombining paraphrases with multilingual data helps but has mixed performance.\nWe achieve a BLEU score of 57.2 for French-to-English translation using 24\ncorpus-level paraphrases of the Bible, which outperforms the multilingual\nbaselines and is +34.7 above the single-source single-target NMT baseline.\n", "versions": [{"version": "v1", "created": "Sat, 25 Aug 2018 15:20:30 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 08:29:27 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Zhou", "Zhong", ""], ["Sperber", "Matthias", ""], ["Waibel", "Alex", ""]]}, {"id": "1808.08450", "submitter": "Dat Quoc Nguyen", "authors": "Zenan Zhai and Dat Quoc Nguyen and Karin Verspoor", "title": "Comparing CNN and LSTM character-level embeddings in BiLSTM-CRF models\n  for chemical and disease named entity recognition", "comments": "In Proceedings of the 9th International Workshop on Health Text\n  Mining and Information Analysis (LOUHI 2018), to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare the use of LSTM-based and CNN-based character-level word\nembeddings in BiLSTM-CRF models to approach chemical and disease named entity\nrecognition (NER) tasks. Empirical results over the BioCreative V CDR corpus\nshow that the use of either type of character-level word embeddings in\nconjunction with the BiLSTM-CRF models leads to comparable state-of-the-art\nperformance. However, the models using CNN-based character-level word\nembeddings have a computational performance advantage, increasing training time\nover word-based models by 25% while the LSTM-based character-level word\nembeddings more than double the required training time.\n", "versions": [{"version": "v1", "created": "Sat, 25 Aug 2018 17:02:29 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Zhai", "Zenan", ""], ["Nguyen", "Dat Quoc", ""], ["Verspoor", "Karin", ""]]}, {"id": "1808.08470", "submitter": "Y. Alex Kolchinski", "authors": "Y. Alex Kolchinski and Christopher Potts", "title": "Representing Social Media Users for Sarcasm Detection", "comments": "To appear in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore two methods for representing authors in the context of textual\nsarcasm detection: a Bayesian approach that directly represents authors'\npropensities to be sarcastic, and a dense embedding approach that can learn\ninteractions between the author and the text. Using the SARC dataset of Reddit\ncomments, we show that augmenting a bidirectional RNN with these\nrepresentations improves performance; the Bayesian approach suffices in\nhomogeneous contexts, whereas the added power of the dense embeddings proves\nvaluable in more diverse ones.\n", "versions": [{"version": "v1", "created": "Sat, 25 Aug 2018 21:04:53 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Kolchinski", "Y. Alex", ""], ["Potts", "Christopher", ""]]}, {"id": "1808.08482", "submitter": "Zhisong Zhang", "authors": "Zhisong Zhang, Rui Wang, Masao Utiyama, Eiichiro Sumita and Hai Zhao", "title": "Exploring Recombination for Efficient Decoding of Neural Machine\n  Translation", "comments": "Due to the policy of our institute, with the agreement of all of the\n  author, we decide to withdraw this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Neural Machine Translation (NMT), the decoder can capture the features of\nthe entire prediction history with neural connections and representations. This\nmeans that partial hypotheses with different prefixes will be regarded\ndifferently no matter how similar they are. However, this might be inefficient\nsince some partial hypotheses can contain only local differences that will not\ninfluence future predictions. In this work, we introduce recombination in NMT\ndecoding based on the concept of the \"equivalence\" of partial hypotheses.\nHeuristically, we use a simple $n$-gram suffix based equivalence function and\nadapt it into beam search decoding. Through experiments on large-scale\nChinese-to-English and English-to-Germen translation tasks, we show that the\nproposed method can obtain similar translation quality with a smaller beam\nsize, making NMT decoding more efficient.\n", "versions": [{"version": "v1", "created": "Sat, 25 Aug 2018 23:26:10 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 01:08:02 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Zhang", "Zhisong", ""], ["Wang", "Rui", ""], ["Utiyama", "Masao", ""], ["Sumita", "Eiichiro", ""], ["Zhao", "Hai", ""]]}, {"id": "1808.08485", "submitter": "Hai Wang", "authors": "Hai Wang and Hoifung Poon", "title": "Deep Probabilistic Logic: A Unifying Framework for Indirect Supervision", "comments": "EMNLP 2018 final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has emerged as a versatile tool for a wide range of NLP tasks,\ndue to its superior capacity in representation learning. But its applicability\nis limited by the reliance on annotated examples, which are difficult to\nproduce at scale. Indirect supervision has emerged as a promising direction to\naddress this bottleneck, either by introducing labeling functions to\nautomatically generate noisy examples from unlabeled text, or by imposing\nconstraints over interdependent label decisions. A plethora of methods have\nbeen proposed, each with respective strengths and limitations. Probabilistic\nlogic offers a unifying language to represent indirect supervision, but\nend-to-end modeling with probabilistic logic is often infeasible due to\nintractable inference and learning. In this paper, we propose deep\nprobabilistic logic (DPL) as a general framework for indirect supervision, by\ncomposing probabilistic logic with deep learning. DPL models label decisions as\nlatent variables, represents prior knowledge on their relations using weighted\nfirst-order logical formulas, and alternates between learning a deep neural\nnetwork for the end task and refining uncertain formula weights for indirect\nsupervision, using variational EM. This framework subsumes prior indirect\nsupervision methods as special cases, and enables novel combination via\ninfusion of rich domain and linguistic knowledge. Experiments on biomedical\nmachine reading demonstrate the promise of this approach.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 00:02:36 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Wang", "Hai", ""], ["Poon", "Hoifung", ""]]}, {"id": "1808.08493", "submitter": "Emmanouil Antonios Platanios", "authors": "Emmanouil Antonios Platanios and Mrinmaya Sachan and Graham Neubig and\n  Tom Mitchell", "title": "Contextual Parameter Generation for Universal Neural Machine Translation", "comments": "Published in the proceedings of Empirical Methods in Natural Language\n  Processing (EMNLP), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple modification to existing neural machine translation (NMT)\nmodels that enables using a single universal model to translate between\nmultiple languages while allowing for language specific parameterization, and\nthat can also be used for domain adaptation. Our approach requires no changes\nto the model architecture of a standard NMT system, but instead introduces a\nnew component, the contextual parameter generator (CPG), that generates the\nparameters of the system (e.g., weights in a neural network). This parameter\ngenerator accepts source and target language embeddings as input, and generates\nthe parameters for the encoder and the decoder, respectively. The rest of the\nmodel remains unchanged and is shared across all languages. We show how this\nsimple modification enables the system to use monolingual data for training and\nalso perform zero-shot translation. We further show it is able to surpass\nstate-of-the-art performance for both the IWSLT-15 and IWSLT-17 datasets and\nthat the learned language embeddings are able to uncover interesting\nrelationships between languages.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 01:17:50 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Platanios", "Emmanouil Antonios", ""], ["Sachan", "Mrinmaya", ""], ["Neubig", "Graham", ""], ["Mitchell", "Tom", ""]]}, {"id": "1808.08504", "submitter": "J. Walker Orr", "authors": "J. Walker Orr, Prasad Tadepalli, Xiaoli Fern", "title": "Event Detection with Neural Networks: A Rigorous Empirical Evaluation", "comments": "5 pages, EMNLP2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting events and classifying them into predefined types is an important\nstep in knowledge extraction from natural language texts. While the neural\nnetwork models have generally led the state-of-the-art, the differences in\nperformance between different architectures have not been rigorously studied.\nIn this paper we present a novel GRU-based model that combines syntactic\ninformation along with temporal structure through an attention mechanism. We\nshow that it is competitive with other neural network architectures through\nempirical evaluations under different random initializations and\ntraining-validation-test splits of ACE2005 dataset.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 04:04:39 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Orr", "J. Walker", ""], ["Tadepalli", "Prasad", ""], ["Fern", "Xiaoli", ""]]}, {"id": "1808.08518", "submitter": "Asaf Amrami", "authors": "Asaf Amrami and Yoav Goldberg", "title": "Word Sense Induction with Neural biLM and Symmetric Patterns", "comments": "8 pages, accepted as a short paper in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An established method for Word Sense Induction (WSI) uses a language model to\npredict probable substitutes for target words, and induces senses by clustering\nthese resulting substitute vectors.\n  We replace the ngram-based language model (LM) with a recurrent one. Beyond\nbeing more accurate, the use of the recurrent LM allows us to effectively query\nit in a creative way, using what we call dynamic symmetric patterns.\n  The combination of the RNN-LM and the dynamic symmetric patterns results in\nstrong substitute vectors for WSI, allowing to surpass the current\nstate-of-the-art on the SemEval 2013 WSI shared task by a large margin.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 08:36:15 GMT"}, {"version": "v2", "created": "Thu, 30 Aug 2018 05:26:27 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Amrami", "Asaf", ""], ["Goldberg", "Yoav", ""]]}, {"id": "1808.08538", "submitter": "Adam Tsakalidis", "authors": "Adam Tsakalidis, Nikolaos Aletras, Alexandra I. Cristea, Maria Liakata", "title": "Nowcasting the Stance of Social Media Users in a Sudden Vote: The Case\n  of the Greek Referendum", "comments": "Preprint accepted for publication in the ACM International Conference\n  on Information and Knowledge Management (CIKM 2018)", "journal-ref": null, "doi": "10.1145/3269206.3271783", "report-no": null, "categories": "cs.CY cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling user voting intention in social media is an important research\narea, with applications in analysing electorate behaviour, online political\ncampaigning and advertising. Previous approaches mainly focus on predicting\nnational general elections, which are regularly scheduled and where data of\npast results and opinion polls are available. However, there is no evidence of\nhow such models would perform during a sudden vote under time-constrained\ncircumstances. That poses a more challenging task compared to traditional\nelections, due to its spontaneous nature. In this paper, we focus on the 2015\nGreek bailout referendum, aiming to nowcast on a daily basis the voting\nintention of 2,197 Twitter users. We propose a semi-supervised multiple\nconvolution kernel learning approach, leveraging temporally sensitive text and\nnetwork information. Our evaluation under a real-time simulation framework\ndemonstrates the effectiveness and robustness of our approach against\ncompetitive baselines, achieving a significant 20% increase in F-score compared\nto solely text-based models.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 11:58:04 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Tsakalidis", "Adam", ""], ["Aletras", "Nikolaos", ""], ["Cristea", "Alexandra I.", ""], ["Liakata", "Maria", ""]]}, {"id": "1808.08561", "submitter": "Junyang Lin", "authors": "Junyang Lin, Qi Su, Pengcheng Yang, Shuming Ma, Xu Sun", "title": "Semantic-Unit-Based Dilated Convolution for Multi-Label Text\n  Classification", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel model for multi-label text classification, which is based\non sequence-to-sequence learning. The model generates higher-level semantic\nunit representations with multi-level dilated convolution as well as a\ncorresponding hybrid attention mechanism that extracts both the information at\nthe word-level and the level of the semantic unit. Our designed dilated\nconvolution effectively reduces dimension and supports an exponential expansion\nof receptive fields without loss of local information, and the\nattention-over-attention mechanism is able to capture more summary relevant\ninformation from the source context. Results of our experiments show that the\nproposed model has significant advantages over the baseline models on the\ndataset RCV1-V2 and Ren-CECps, and our analysis demonstrates that our model is\ncompetitive to the deterministic hierarchical models and it is more robust to\nclassifying low-frequency labels.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 14:36:22 GMT"}, {"version": "v2", "created": "Sun, 11 Nov 2018 19:12:35 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Lin", "Junyang", ""], ["Su", "Qi", ""], ["Yang", "Pengcheng", ""], ["Ma", "Shuming", ""], ["Sun", "Xu", ""]]}, {"id": "1808.08573", "submitter": "Zied Elloumi", "authors": "Zied Elloumi, Laurent Besacier, Olivier Galibert, Benjamin Lecouteux", "title": "Analyzing Learned Representations of a Deep ASR Performance Prediction\n  Model", "comments": "EMNLP 2018 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper addresses a relatively new task: prediction of ASR performance on\nunseen broadcast programs. In a previous paper, we presented an ASR performance\nprediction system using CNNs that encode both text (ASR transcript) and speech,\nin order to predict word error rate. This work is dedicated to the analysis of\nspeech signal embeddings and text embeddings learnt by the CNN while training\nour prediction model. We try to better understand which information is captured\nby the deep model and its relation with different conditioning factors. It is\nshown that hidden layers convey a clear signal about speech style, accent and\nbroadcast type. We then try to leverage these 3 types of information at\ntraining time through multi-task learning. Our experiments show that this\nallows to train slightly more efficient ASR performance prediction systems that\n- in addition - simultaneously tag the analyzed utterances according to their\nspeech style, accent and broadcast program origin.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 15:10:47 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 09:59:05 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Elloumi", "Zied", ""], ["Besacier", "Laurent", ""], ["Galibert", "Olivier", ""], ["Lecouteux", "Benjamin", ""]]}, {"id": "1808.08575", "submitter": "Wang Chen", "authors": "Wang Chen, Yifan Gao, Jiani Zhang, Irwin King, Michael R. Lyu", "title": "Title-Guided Encoding for Keyphrase Generation", "comments": "AAAI 19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyphrase generation (KG) aims to generate a set of keyphrases given a\ndocument, which is a fundamental task in natural language processing (NLP).\nMost previous methods solve this problem in an extractive manner, while\nrecently, several attempts are made under the generative setting using deep\nneural networks. However, the state-of-the-art generative methods simply treat\nthe document title and the document main body equally, ignoring the leading\nrole of the title to the overall document. To solve this problem, we introduce\na new model called Title-Guided Network (TG-Net) for automatic keyphrase\ngeneration task based on the encoder-decoder architecture with two new\nfeatures: (i) the title is additionally employed as a query-like input, and\n(ii) a title-guided encoder gathers the relevant information from the title to\neach word in the document. Experiments on a range of KG datasets demonstrate\nthat our model outperforms the state-of-the-art models with a large margin,\nespecially for documents with either very low or very high title length ratios.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 15:28:11 GMT"}, {"version": "v2", "created": "Thu, 30 Aug 2018 13:38:57 GMT"}, {"version": "v3", "created": "Thu, 6 Sep 2018 08:50:21 GMT"}, {"version": "v4", "created": "Thu, 15 Nov 2018 09:47:42 GMT"}, {"version": "v5", "created": "Wed, 16 Jan 2019 14:50:21 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Chen", "Wang", ""], ["Gao", "Yifan", ""], ["Zhang", "Jiani", ""], ["King", "Irwin", ""], ["Lyu", "Michael R.", ""]]}, {"id": "1808.08583", "submitter": "Chunqi Wang", "authors": "Chunqi Wang, Ji Zhang, Haiqing Chen", "title": "Semi-Autoregressive Neural Machine Translation", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing approaches to neural machine translation are typically\nautoregressive models. While these models attain state-of-the-art translation\nquality, they are suffering from low parallelizability and thus slow at\ndecoding long sequences. In this paper, we propose a novel model for fast\nsequence generation --- the semi-autoregressive Transformer (SAT). The SAT\nkeeps the autoregressive property in global but relieves in local and thus is\nable to produce multiple successive words in parallel at each time step.\nExperiments conducted on English-German and Chinese-English translation tasks\nshow that the SAT achieves a good balance between translation quality and\ndecoding speed. On WMT'14 English-German translation, the SAT achieves\n5.58$\\times$ speedup while maintains 88\\% translation quality, significantly\nbetter than the previous non-autoregressive methods. When produces two words at\neach time step, the SAT is almost lossless (only 1\\% degeneration in BLEU\nscore).\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 16:22:30 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 07:40:45 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Wang", "Chunqi", ""], ["Zhang", "Ji", ""], ["Chen", "Haiqing", ""]]}, {"id": "1808.08609", "submitter": "Pasquale Minervini", "authors": "Pasquale Minervini, Sebastian Riedel", "title": "Adversarially Regularising Neural NLI Models to Integrate Logical\n  Background Knowledge", "comments": "Accepted at the SIGNLL Conference on Computational Natural Language\n  Learning (CoNLL 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are inputs to machine learning models designed to cause\nthe model to make a mistake. They are useful for understanding the shortcomings\nof machine learning models, interpreting their results, and for regularisation.\nIn NLP, however, most example generation strategies produce input text by using\nknown, pre-specified semantic transformations, requiring significant manual\neffort and in-depth understanding of the problem and domain. In this paper, we\ninvestigate the problem of automatically generating adversarial examples that\nviolate a set of given First-Order Logic constraints in Natural Language\nInference (NLI). We reduce the problem of identifying such adversarial examples\nto a combinatorial optimisation problem, by maximising a quantity measuring the\ndegree of violation of such constraints and by using a language model for\ngenerating linguistically-plausible examples. Furthermore, we propose a method\nfor adversarially regularising neural NLI models for incorporating background\nknowledge. Our results show that, while the proposed method does not always\nimprove results on the SNLI and MultiNLI datasets, it significantly and\nconsistently increases the predictive accuracy on adversarially-crafted\ndatasets -- up to a 79.6% relative improvement -- while drastically reducing\nthe number of background knowledge violations. Furthermore, we show that\nadversarial examples transfer among model architectures, and that the proposed\nadversarial training procedure improves the robustness of NLI models to\nadversarial examples.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 18:36:20 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Minervini", "Pasquale", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1808.08622", "submitter": "James Ferguson", "authors": "James Ferguson, Colin Lockard, Daniel S. Weld, Hannaneh Hajishirzi", "title": "Semi-Supervised Event Extraction with Paraphrase Clusters", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised event extraction systems are limited in their accuracy due to the\nlack of available training data. We present a method for self-training event\nextraction systems by bootstrapping additional training data. This is done by\ntaking advantage of the occurrence of multiple mentions of the same event\ninstances across newswire articles from multiple sources. If our system can\nmake a highconfidence extraction of some mentions in such a cluster, it can\nthen acquire diverse training examples by adding the other mentions as well.\nOur experiments show significant performance improvements on multiple event\nextractors over ACE 2005 and TAC-KBP 2015 datasets.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 21:12:43 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Ferguson", "James", ""], ["Lockard", "Colin", ""], ["Weld", "Daniel S.", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "1808.08626", "submitter": "James Ferguson", "authors": "James Ferguson, Janara Christensen, Edward Li, Edgar Gonz\\`alez", "title": "Identifying Domain Adjacent Instances for Semantic Parsers", "comments": "EMNLP 2018 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the semantics of a sentence are not representable in a semantic parser's\noutput schema, parsing will inevitably fail. Detection of these instances is\ncommonly treated as an out-of-domain classification problem. However, there is\nalso a more subtle scenario in which the test data is drawn from the same\ndomain. In addition to formalizing this problem of domain-adjacency, we present\na comparison of various baselines that could be used to solve it. We also\npropose a new simple sentence representation that emphasizes words which are\nunexpected. This approach improves the performance of a downstream semantic\nparser run on in-domain and domain-adjacent instances.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 21:33:32 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Ferguson", "James", ""], ["Christensen", "Janara", ""], ["Li", "Edward", ""], ["Gonz\u00e0lez", "Edgar", ""]]}, {"id": "1808.08643", "submitter": "Yi Luan", "authors": "Yi Luan, Mari Ostendorf, Hannaneh Hajishirzi", "title": "Scientific Relation Extraction with Selectively Incorporated Concept\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our submission for the SemEval 2018 Task 7 shared task\non semantic relation extraction and classification in scientific papers. We\nextend the end-to-end relation extraction model of (Miwa and Bansal) with\nenhancements such as a character-level encoding attention mechanism on\nselecting pretrained concept candidate embeddings. Our official submission\nranked the second in relation classification task (Subtask 1.1 and Subtask 2\nSenerio 2), and the first in the relation extraction task (Subtask 2 Scenario\n1).\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 23:31:02 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Luan", "Yi", ""], ["Ostendorf", "Mari", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "1808.08644", "submitter": "Yuval Pinter", "authors": "Yuval Pinter and Jacob Eisenstein", "title": "Predicting Semantic Relations using Global Graph Properties", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic graphs, such as WordNet, are resources which curate natural language\non two distinguishable layers. On the local level, individual relations between\nsynsets (semantic building blocks) such as hypernymy and meronymy enhance our\nunderstanding of the words used to express their meanings. Globally, analysis\nof graph-theoretic properties of the entire net sheds light on the structure of\nhuman language as a whole. In this paper, we combine global and local\nproperties of semantic graphs through the framework of Max-Margin Markov Graph\nModels (M3GM), a novel extension of Exponential Random Graph Model (ERGM) that\nscales to large multi-relational graphs. We demonstrate how such global\nmodeling improves performance on the local task of predicting semantic\nrelations between synsets, yielding new state-of-the-art results on the WN18RR\ndataset, a challenging version of WordNet link prediction in which \"easy\"\nreciprocal cases are removed. In addition, the M3GM model identifies\nmultirelational motifs that are characteristic of well-formed lexical semantic\nontologies.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 00:01:11 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Pinter", "Yuval", ""], ["Eisenstein", "Jacob", ""]]}, {"id": "1808.08669", "submitter": "Yangming Zhou", "authors": "Jiahui Qiu, Qi Wang, Yangming Zhou, Tong Ruan, Ju Gao", "title": "Fast and Accurate Recognition of Chinese Clinical Named Entities with\n  Residual Dilated Convolutions", "comments": "8 pages, 3 figures. Accepted as regular paper by 2018 IEEE\n  International Conference on Bioinformatics and Biomedicine. arXiv admin note:\n  text overlap with arXiv:1804.05017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical Named Entity Recognition (CNER) aims to identify and classify\nclinical terms such as diseases, symptoms, treatments, exams, and body parts in\nelectronic health records, which is a fundamental and crucial task for clinical\nand translation research. In recent years, deep learning methods have achieved\nsignificant success in CNER tasks. However, these methods depend greatly on\nRecurrent Neural Networks (RNNs), which maintain a vector of hidden activations\nthat are propagated through time, thus causing too much time to train models.\nIn this paper, we propose a Residual Dilated Convolutional Neural Network with\nConditional Random Field (RD-CNN-CRF) to solve it. Specifically, Chinese\ncharacters and dictionary features are first projected into dense vector\nrepresentations, then they are fed into the residual dilated convolutional\nneural network to capture contextual features. Finally, a conditional random\nfield is employed to capture dependencies between neighboring tags.\nComputational results on the CCKS-2017 Task 2 benchmark dataset show that our\nproposed RD-CNN-CRF method competes favorably with state-of-the-art RNN-based\nmethods both in terms of computational performance and training time.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 02:42:48 GMT"}, {"version": "v2", "created": "Wed, 29 Aug 2018 05:56:52 GMT"}, {"version": "v3", "created": "Tue, 27 Nov 2018 13:31:30 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Qiu", "Jiahui", ""], ["Wang", "Qi", ""], ["Zhou", "Yangming", ""], ["Ruan", "Tong", ""], ["Gao", "Ju", ""]]}, {"id": "1808.08672", "submitter": "Jorge Balazs", "authors": "Jorge A. Balazs, Edison Marrese-Taylor, Yutaka Matsuo", "title": "IIIDYT at IEST 2018: Implicit Emotion Classification With Deep\n  Contextualized Word Representations", "comments": "Accepted as a system description paper for the Implicit Emotion\n  Shared Task of WASSA 2018 (EMNLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe our system designed for the WASSA 2018 Implicit\nEmotion Shared Task (IEST), which obtained 2$^{\\text{nd}}$ place out of 26\nteams with a test macro F1 score of $0.710$. The system is composed of a single\npre-trained ELMo layer for encoding words, a Bidirectional Long-Short Memory\nNetwork BiLSTM for enriching word representations with context, a max-pooling\noperation for creating sentence representations from said word vectors, and a\nDense Layer for projecting the sentence representations into label space. Our\nofficial submission was obtained by ensembling 6 of these models initialized\nwith different random seeds. The code for replicating this paper is available\nat https://github.com/jabalazs/implicit_emotion.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 02:57:42 GMT"}, {"version": "v2", "created": "Sat, 1 Sep 2018 14:37:11 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Balazs", "Jorge A.", ""], ["Marrese-Taylor", "Edison", ""], ["Matsuo", "Yutaka", ""]]}, {"id": "1808.08703", "submitter": "Afroz Ahamad Siddiqui", "authors": "Afroz Ahamad", "title": "Generating Text through Adversarial Training using Skip-Thought Vectors", "comments": "NAACL 2019: https://www.aclweb.org/anthology/N19-3008", "journal-ref": "\"Proceedings of the 2019 Conference of the North {A}merican\n  Chapter of the Association for Computational Linguistics: Student Research\n  Workshop, Jun 2019, Pages 53-60\"", "doi": "10.18653/v1/N19-3008", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GANs have been shown to perform exceedingly well on tasks pertaining to image\ngeneration and style transfer. In the field of language modelling, word\nembeddings such as GLoVe and word2vec are state-of-the-art methods for applying\nneural network models on textual data. Attempts have been made to utilize GANs\nwith word embeddings for text generation. This study presents an approach to\ntext generation using Skip-Thought sentence embeddings with GANs based on\ngradient penalty functions and f-measures. The proposed architecture aims to\nreproduce writing style in the generated text by modelling the way of\nexpression at a sentence level across all the works of an author. Extensive\nexperiments were run in different embedding settings on a variety of tasks\nincluding conditional text generation and language generation. The model\noutperforms baseline text generation networks across several automated\nevaluation metrics like BLEU-n, METEOR and ROUGE. Further, wide applicability\nand effectiveness in real life tasks are demonstrated through human judgement\nscores.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 06:51:07 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 21:37:36 GMT"}, {"version": "v3", "created": "Sat, 16 May 2020 10:18:53 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Ahamad", "Afroz", ""]]}, {"id": "1808.08720", "submitter": "Thomas Demeester", "authors": "Thomas Demeester, Johannes Deleu, Fr\\'ederic Godin, Chris Develder", "title": "Predefined Sparseness in Recurrent Sequence Models", "comments": "the SIGNLL Conference on Computational Natural Language Learning\n  (CoNLL, 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inducing sparseness while training neural networks has been shown to yield\nmodels with a lower memory footprint but similar effectiveness to dense models.\nHowever, sparseness is typically induced starting from a dense model, and thus\nthis advantage does not hold during training. We propose techniques to enforce\nsparseness upfront in recurrent sequence models for NLP applications, to also\nbenefit training. First, in language modeling, we show how to increase hidden\nstate sizes in recurrent layers without increasing the number of parameters,\nleading to more expressive models. Second, for sequence labeling, we show that\nword embeddings with predefined sparseness lead to similar performance as dense\nembeddings, at a fraction of the number of trainable parameters.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 07:55:41 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Demeester", "Thomas", ""], ["Deleu", "Johannes", ""], ["Godin", "Fr\u00e9deric", ""], ["Develder", "Chris", ""]]}, {"id": "1808.08732", "submitter": "Fenglin Liu", "authors": "Fenglin Liu, Xuancheng Ren, Yuanxin Liu, Houfeng Wang and Xu Sun", "title": "simNet: Stepwise Image-Topic Merging Network for Generating Detailed and\n  Comprehensive Image Captions", "comments": "Accepted by Conference on Empirical Methods in Natural Language\n  Processing 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The encode-decoder framework has shown recent success in image captioning.\nVisual attention, which is good at detailedness, and semantic attention, which\nis good at comprehensiveness, have been separately proposed to ground the\ncaption on the image. In this paper, we propose the Stepwise Image-Topic\nMerging Network (simNet) that makes use of the two kinds of attention at the\nsame time. At each time step when generating the caption, the decoder\nadaptively merges the attentive information in the extracted topics and the\nimage according to the generated context, so that the visual information and\nthe semantic information can be effectively combined. The proposed approach is\nevaluated on two benchmark datasets and reaches the state-of-the-art\nperformances.(The code is available at https://github.com/lancopku/simNet)\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 08:37:42 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Liu", "Fenglin", ""], ["Ren", "Xuancheng", ""], ["Liu", "Yuanxin", ""], ["Wang", "Houfeng", ""], ["Sun", "Xu", ""]]}, {"id": "1808.08744", "submitter": "Glorianna Jagfeld", "authors": "Matthias Blohm, Glorianna Jagfeld, Ekta Sood, Xiang Yu, Ngoc Thang Vu", "title": "Comparing Attention-based Convolutional and Recurrent Neural Networks:\n  Success and Limitations in Machine Reading Comprehension", "comments": "CoNLL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a machine reading comprehension model based on the\ncompare-aggregate framework with two-staged attention that achieves\nstate-of-the-art results on the MovieQA question answering dataset. To\ninvestigate the limitations of our model as well as the behavioral difference\nbetween convolutional and recurrent neural networks, we generate adversarial\nexamples to confuse the model and compare to human performance. Furthermore, we\nassess the generalizability of our model by analyzing its differences to human\ninference,\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 09:04:22 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Blohm", "Matthias", ""], ["Jagfeld", "Glorianna", ""], ["Sood", "Ekta", ""], ["Yu", "Xiang", ""], ["Vu", "Ngoc Thang", ""]]}, {"id": "1808.08745", "submitter": "Shashi Narayan", "authors": "Shashi Narayan and Shay B. Cohen and Mirella Lapata", "title": "Don't Give Me the Details, Just the Summary! Topic-Aware Convolutional\n  Neural Networks for Extreme Summarization", "comments": "11, 2018 Conference on Empirical Methods in Natural Language\n  Processing, EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce extreme summarization, a new single-document summarization task\nwhich does not favor extractive strategies and calls for an abstractive\nmodeling approach. The idea is to create a short, one-sentence news summary\nanswering the question \"What is the article about?\". We collect a real-world,\nlarge-scale dataset for this task by harvesting online articles from the\nBritish Broadcasting Corporation (BBC). We propose a novel abstractive model\nwhich is conditioned on the article's topics and based entirely on\nconvolutional neural networks. We demonstrate experimentally that this\narchitecture captures long-range dependencies in a document and recognizes\npertinent content, outperforming an oracle extractive system and\nstate-of-the-art abstractive approaches when evaluated automatically and by\nhumans.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 09:08:18 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Narayan", "Shashi", ""], ["Cohen", "Shay B.", ""], ["Lapata", "Mirella", ""]]}, {"id": "1808.08762", "submitter": "Aarne Talman", "authors": "Aarne Talman, Anssi Yli-Jyr\\\"a and J\\\"org Tiedemann", "title": "Sentence Embeddings in NLI with Iterative Refinement Encoders", "comments": "To appear in JNLE", "journal-ref": "Nat. Lang. Eng. 25 (2019) 467-482", "doi": "10.1017/S1351324919000202", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence-level representations are necessary for various NLP tasks. Recurrent\nneural networks have proven to be very effective in learning distributed\nrepresentations and can be trained efficiently on natural language inference\ntasks. We build on top of one such model and propose a hierarchy of BiLSTM and\nmax pooling layers that implements an iterative refinement strategy and yields\nstate of the art results on the SciTail dataset as well as strong results for\nSNLI and MultiNLI. We can show that the sentence embeddings learned in this way\ncan be utilized in a wide variety of transfer learning tasks, outperforming\nInferSent on 7 out of 10 and SkipThought on 8 out of 9 SentEval sentence\nembedding evaluation tasks. Furthermore, our model beats the InferSent model in\n8 out of 10 recently published SentEval probing tasks designed to evaluate\nsentence embeddings' ability to capture some of the important linguistic\nproperties of sentences.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 09:50:56 GMT"}, {"version": "v2", "created": "Mon, 3 Jun 2019 19:50:52 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Talman", "Aarne", ""], ["Yli-Jyr\u00e4", "Anssi", ""], ["Tiedemann", "J\u00f6rg", ""]]}, {"id": "1808.08773", "submitter": "Pratik Jawanpuria", "authors": "Pratik Jawanpuria, Arjun Balgovind, Anoop Kunchukuttan, Bamdev Mishra", "title": "Learning Multilingual Word Embeddings in Latent Metric Space: A\n  Geometric Approach", "comments": "Accepted in Transactions of the Association for Computational\n  Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel geometric approach for learning bilingual mappings given\nmonolingual embeddings and a bilingual dictionary. Our approach decouples\nlearning the transformation from the source language to the target language\ninto (a) learning rotations for language-specific embeddings to align them to a\ncommon space, and (b) learning a similarity metric in the common space to model\nsimilarities between the embeddings. We model the bilingual mapping problem as\nan optimization problem on smooth Riemannian manifolds. We show that our\napproach outperforms previous approaches on the bilingual lexicon induction and\ncross-lingual word similarity tasks. We also generalize our framework to\nrepresent multiple languages in a common latent space. In particular, the\nlatent space representations for several languages are learned jointly, given\nbilingual dictionaries for multiple language pairs. We illustrate the\neffectiveness of joint learning for multiple languages in zero-shot word\ntranslation setting. Our implementation is available at\nhttps://github.com/anoopkunchukuttan/geomm .\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 10:37:16 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 17:30:39 GMT"}, {"version": "v3", "created": "Tue, 18 Dec 2018 09:48:26 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Jawanpuria", "Pratik", ""], ["Balgovind", "Arjun", ""], ["Kunchukuttan", "Anoop", ""], ["Mishra", "Bamdev", ""]]}, {"id": "1808.08780", "submitter": "Yerai Doval", "authors": "Yerai Doval, Jose Camacho-Collados, Luis Espinosa-Anke, Steven\n  Schockaert", "title": "Improving Cross-Lingual Word Embeddings by Meeting in the Middle", "comments": "11 pages, 4 tables, 1 figure. EMNLP 2018 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual word embeddings are becoming increasingly important in\nmultilingual NLP. Recently, it has been shown that these embeddings can be\neffectively learned by aligning two disjoint monolingual vector spaces through\nlinear transformations, using no more than a small bilingual dictionary as\nsupervision. In this work, we propose to apply an additional transformation\nafter the initial alignment step, which moves cross-lingual synonyms towards a\nmiddle point between them. By applying this transformation our aim is to obtain\na better cross-lingual integration of the vector spaces. In addition, and\nperhaps surprisingly, the monolingual spaces also improve by this\ntransformation. This is in contrast to the original alignment, which is\ntypically learned such that the structure of the monolingual spaces is\npreserved. Our experiments confirm that the resulting cross-lingual embeddings\noutperform state-of-the-art models in both monolingual and cross-lingual\nevaluation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 10:54:37 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Doval", "Yerai", ""], ["Camacho-Collados", "Jose", ""], ["Espinosa-Anke", "Luis", ""], ["Schockaert", "Steven", ""]]}, {"id": "1808.08782", "submitter": "Daniel Fleischer", "authors": "Alon Rozental, Daniel Fleischer, Zohar Kelrich", "title": "Amobee at IEST 2018: Transfer Learning from Language Models", "comments": "7 pages, accepted to the 9th WASSA Workshop, part of the EMNLP 2018\n  Conference; added links to open-source material", "journal-ref": null, "doi": "10.18653/v1/W18-6207", "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the system developed at Amobee for the WASSA 2018\nimplicit emotions shared task (IEST). The goal of this task was to predict the\nemotion expressed by missing words in tweets without an explicit mention of\nthose words. We developed an ensemble system consisting of language models\ntogether with LSTM-based networks containing a CNN attention mechanism. Our\napproach represents a novel use of language models (specifically trained on a\nlarge Twitter dataset) to predict and classify emotions. Our system reached 1st\nplace with a macro $\\text{F}_1$ score of 0.7145.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 11:04:55 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 14:47:18 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Rozental", "Alon", ""], ["Fleischer", "Daniel", ""], ["Kelrich", "Zohar", ""]]}, {"id": "1808.08795", "submitter": "Jingjing Xu", "authors": "Liangchen Luo, Jingjing Xu, Junyang Lin, Qi Zeng, Xu Sun", "title": "An Auto-Encoder Matching Model for Learning Utterance-Level Semantic\n  Dependency in Dialogue Generation", "comments": "Accepted by EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating semantically coherent responses is still a major challenge in\ndialogue generation. Different from conventional text generation tasks, the\nmapping between inputs and responses in conversations is more complicated,\nwhich highly demands the understanding of utterance-level semantic dependency,\na relation between the whole meanings of inputs and outputs. To address this\nproblem, we propose an Auto-Encoder Matching (AEM) model to learn such\ndependency. The model contains two auto-encoders and one mapping module. The\nauto-encoders learn the semantic representations of inputs and responses, and\nthe mapping module learns to connect the utterance-level representations.\nExperimental results from automatic and human evaluations demonstrate that our\nmodel is capable of generating responses of high coherence and fluency compared\nto baseline models. The code is available at https://github.com/lancopku/AMM\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 11:46:13 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Luo", "Liangchen", ""], ["Xu", "Jingjing", ""], ["Lin", "Junyang", ""], ["Zeng", "Qi", ""], ["Sun", "Xu", ""]]}, {"id": "1808.08836", "submitter": "Ana Valeria Gonzalez", "authors": "Ana V. Gonz\\'alez-Gardu\\~no, Isabelle Augenstein, Anders S{\\o}gaard", "title": "A strong baseline for question relevancy ranking", "comments": "To appear at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The best systems at the SemEval-16 and SemEval-17 community question\nanswering shared tasks -- a task that amounts to question relevancy ranking --\ninvolve complex pipelines and manual feature engineering. Despite this, many of\nthese still fail at beating the IR baseline, i.e., the rankings provided by\nGoogle's search engine. We present a strong baseline for question relevancy\nranking by training a simple multi-task feed forward network on a bag of 14\ndistance measures for the input question pair. This baseline model, which is\nfast to train and uses only language-independent features, outperforms the best\nshared task systems on the task of retrieving relevant previously asked\nquestions.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 13:19:49 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Gonz\u00e1lez-Gardu\u00f1o", "Ana V.", ""], ["Augenstein", "Isabelle", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "1808.08850", "submitter": "Carlos-Emiliano Gonz\\'alez-Gallardo", "authors": "Carlos-Emiliano Gonz\\'alez-Gallardo and Juan-Manuel Torres-Moreno", "title": "WiSeBE: Window-based Sentence Boundary Evaluation", "comments": "In proceedings of the 17th Mexican International Conference on\n  Artificial Intelligence (MICAI), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence Boundary Detection (SBD) has been a major research topic since\nAutomatic Speech Recognition transcripts have been used for further Natural\nLanguage Processing tasks like Part of Speech Tagging, Question Answering or\nAutomatic Summarization. But what about evaluation? Do standard evaluation\nmetrics like precision, recall, F-score or classification error; and more\nimportant, evaluating an automatic system against a unique reference is enough\nto conclude how well a SBD system is performing given the final application of\nthe transcript? In this paper we propose Window-based Sentence Boundary\nEvaluation (WiSeBE), a semi-supervised metric for evaluating Sentence Boundary\nDetection systems based on multi-reference (dis)agreement. We evaluate and\ncompare the performance of different SBD systems over a set of Youtube\ntranscripts using WiSeBE and standard metrics. This double evaluation gives an\nunderstanding of how WiSeBE is a more reliable metric for the SBD task.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 14:02:58 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Gonz\u00e1lez-Gallardo", "Carlos-Emiliano", ""], ["Torres-Moreno", "Juan-Manuel", ""]]}, {"id": "1808.08858", "submitter": "Stefanos Angelidis", "authors": "Stefanos Angelidis, Mirella Lapata", "title": "Summarizing Opinions: Aspect Extraction Meets Sentiment Prediction and\n  They Are Both Weakly Supervised", "comments": "In EMNLP 2018 (long paper). For supplementary material, see\n  http://stangelid.github.io/supplemental.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural framework for opinion summarization from online product\nreviews which is knowledge-lean and only requires light supervision (e.g., in\nthe form of product domain labels and user-provided ratings). Our method\ncombines two weakly supervised components to identify salient opinions and form\nextractive summaries from multiple reviews: an aspect extractor trained under a\nmulti-task objective, and a sentiment predictor based on multiple instance\nlearning. We introduce an opinion summarization dataset that includes a\ntraining set of product reviews from six diverse domains and human-annotated\ndevelopment and test sets with gold standard aspect annotations, salience\nlabels, and opinion summaries. Automatic evaluation shows significant\nimprovements over baselines, and a large-scale study indicates that our opinion\nsummaries are preferred by human judges according to multiple criteria.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 14:17:08 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Angelidis", "Stefanos", ""], ["Lapata", "Mirella", ""]]}, {"id": "1808.08859", "submitter": "Nikolay Bogoychev Mr", "authors": "Nikolay Bogoychev, Marcin Junczys-Dowmunt, Kenneth Heafield and Alham\n  Fikri Aji", "title": "Accelerating Asynchronous Stochastic Gradient Descent for Neural Machine\n  Translation", "comments": "To appear in EMNLP 2018 as a short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to extract the best possible performance from asynchronous\nstochastic gradient descent one must increase the mini-batch size and scale the\nlearning rate accordingly. In order to achieve further speedup we introduce a\ntechnique that delays gradient updates effectively increasing the mini-batch\nsize. Unfortunately with the increase of mini-batch size we worsen the stale\ngradient problem in asynchronous stochastic gradient descent (SGD) which makes\nthe model convergence poor. We introduce local optimizers which mitigate the\nstale gradient problem and together with fine tuning our momentum we are able\nto train a shallow machine translation system 27% faster than an optimized\nbaseline with negligible penalty in BLEU.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 14:19:18 GMT"}, {"version": "v2", "created": "Fri, 14 Sep 2018 11:58:14 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Bogoychev", "Nikolay", ""], ["Junczys-Dowmunt", "Marcin", ""], ["Heafield", "Kenneth", ""], ["Aji", "Alham Fikri", ""]]}, {"id": "1808.08932", "submitter": "Natalia Loukachevitch", "authors": "Natalia Loukachevitch, Nicolay Rusnachenko", "title": "Extracting Sentiment Attitudes From Analytical Texts", "comments": null, "journal-ref": "Proceedings of International Conference on Computational\n  Linguistics and Intellectual Technologies Dialoque-2018, 2018, p.459-468", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the RuSentRel corpus including analytical texts in\nthe sphere of international relations. For each document we annotated\nsentiments from the author to mentioned named entities, and sentiments of\nrelations between mentioned entities. In the current experiments, we considered\nthe problem of extracting sentiment relations between entities for the whole\ndocuments as a three-class machine learning task. We experimented with\nconventional machine-learning methods (Naive Bayes, SVM, Random Forest).\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 17:15:54 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Loukachevitch", "Natalia", ""], ["Rusnachenko", "Nicolay", ""]]}, {"id": "1808.08933", "submitter": "Xilun Chen", "authors": "Xilun Chen and Claire Cardie", "title": "Unsupervised Multilingual Word Embeddings", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual Word Embeddings (MWEs) represent words from multiple languages\nin a single distributional vector space. Unsupervised MWE (UMWE) methods\nacquire multilingual embeddings without cross-lingual supervision, which is a\nsignificant advantage over traditional supervised approaches and opens many new\npossibilities for low-resource languages. Prior art for learning UMWEs,\nhowever, merely relies on a number of independently trained Unsupervised\nBilingual Word Embeddings (UBWEs) to obtain multilingual embeddings. These\nmethods fail to leverage the interdependencies that exist among many languages.\nTo address this shortcoming, we propose a fully unsupervised framework for\nlearning MWEs that directly exploits the relations between all language pairs.\nOur model substantially outperforms previous approaches in the experiments on\nmultilingual word translation and cross-lingual word similarity. In addition,\nour model even beats supervised approaches trained with cross-lingual\nresources.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 17:22:15 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 17:58:00 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Chen", "Xilun", ""], ["Cardie", "Claire", ""]]}, {"id": "1808.08946", "submitter": "Gongbo Tang", "authors": "Gongbo Tang, Mathias M\\\"uller, Annette Rios, Rico Sennrich", "title": "Why Self-Attention? A Targeted Evaluation of Neural Machine Translation\n  Architectures", "comments": "11 pages, 5 figures, accepted by EMNLP 2018 (v2: corrected author\n  names; v3: fix to CNN context-window size, and new post-publication\n  experiments in section 6)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, non-recurrent architectures (convolutional, self-attentional) have\noutperformed RNNs in neural machine translation. CNNs and self-attentional\nnetworks can connect distant words via shorter network paths than RNNs, and it\nhas been speculated that this improves their ability to model long-range\ndependencies. However, this theoretical argument has not been tested\nempirically, nor have alternative explanations for their strong performance\nbeen explored in-depth. We hypothesize that the strong performance of CNNs and\nself-attentional networks could also be due to their ability to extract\nsemantic features from the source text, and we evaluate RNNs, CNNs and\nself-attention networks on two tasks: subject-verb agreement (where capturing\nlong-range dependencies is required) and word sense disambiguation (where\nsemantic feature extraction is required). Our experimental results show that:\n1) self-attentional networks and CNNs do not outperform RNNs in modeling\nsubject-verb agreement over long distances; 2) self-attentional networks\nperform distinctly better than RNNs and CNNs on word sense disambiguation.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 17:51:27 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 07:36:44 GMT"}, {"version": "v3", "created": "Sun, 11 Nov 2018 16:49:47 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Tang", "Gongbo", ""], ["M\u00fcller", "Mathias", ""], ["Rios", "Annette", ""], ["Sennrich", "Rico", ""]]}, {"id": "1808.08949", "submitter": "Matthew Peters", "authors": "Matthew E. Peters, Mark Neumann, Luke Zettlemoyer, Wen-tau Yih", "title": "Dissecting Contextual Word Embeddings: Architecture and Representation", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual word representations derived from pre-trained bidirectional\nlanguage models (biLMs) have recently been shown to provide significant\nimprovements to the state of the art for a wide range of NLP tasks. However,\nmany questions remain as to how and why these models are so effective. In this\npaper, we present a detailed empirical study of how the choice of neural\narchitecture (e.g. LSTM, CNN, or self attention) influences both end task\naccuracy and qualitative properties of the representations that are learned. We\nshow there is a tradeoff between speed and accuracy, but all architectures\nlearn high quality contextual representations that outperform word embeddings\nfor four challenging NLP tasks. Additionally, all architectures learn\nrepresentations that vary with network depth, from exclusively morphological\nbased at the word embedding layer through local syntax based in the lower\ncontextual layers to longer range semantics such coreference at the upper\nlayers. Together, these results suggest that unsupervised biLMs, independent of\narchitecture, are learning much more about the structure of language than\npreviously appreciated.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 17:54:29 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2018 23:36:12 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Peters", "Matthew E.", ""], ["Neumann", "Mark", ""], ["Zettlemoyer", "Luke", ""], ["Yih", "Wen-tau", ""]]}, {"id": "1808.08953", "submitter": "Jonathan Mamou", "authors": "Jonathan Mamou, Oren Pereg, Moshe Wasserblat, Alon Eirew, Yael Green,\n  Shira Guskin, Peter Izsak, Daniel Korat", "title": "Term Set Expansion based NLP Architect by Intel AI Lab", "comments": "EMNLP 2018 System Demonstrations. arXiv admin note: substantial text\n  overlap with arXiv:1807.10104", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SetExpander, a corpus-based system for expanding a seed set of\nterms into amore complete set of terms that belong to the same semantic class.\nSetExpander implements an iterative end-to-end workflow. It enables users to\neasily select a seed set of terms, expand it, view the expanded set, validate\nit, re-expand the validated set and store it, thus simplifying the extraction\nof domain-specific fine-grained semantic classes.SetExpander has been used\nsuccessfully in real-life use cases including integration into an automated\nrecruitment system and an issues and defects resolution system. A video demo of\nSetExpander is available at\nhttps://drive.google.com/open?id=1e545bB87Autsch36DjnJHmq3HWfSd1Rv (some images\nwere blurred for privacy reasons)\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 12:19:07 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 10:55:24 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Mamou", "Jonathan", ""], ["Pereg", "Oren", ""], ["Wasserblat", "Moshe", ""], ["Eirew", "Alon", ""], ["Green", "Yael", ""], ["Guskin", "Shira", ""], ["Izsak", "Peter", ""], ["Korat", "Daniel", ""]]}, {"id": "1808.08987", "submitter": "Jiaji Huang Dr.", "authors": "Jiaji Huang, Yi Li, Wei Ping, Liang Huang", "title": "Large Margin Neural Language Model", "comments": "9 pages. Accepted as a long paper in EMNLP2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a large margin criterion for training neural language models.\nConventionally, neural language models are trained by minimizing perplexity\n(PPL) on grammatical sentences. However, we demonstrate that PPL may not be the\nbest metric to optimize in some tasks, and further propose a large margin\nformulation. The proposed method aims to enlarge the margin between the \"good\"\nand \"bad\" sentences in a task-specific sense. It is trained end-to-end and can\nbe widely applied to tasks that involve re-scoring of generated text. Compared\nwith minimum-PPL training, our method gains up to 1.1 WER reduction for speech\nrecognition and 1.0 BLEU increase for machine translation.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 18:31:33 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Huang", "Jiaji", ""], ["Li", "Yi", ""], ["Ping", "Wei", ""], ["Huang", "Liang", ""]]}, {"id": "1808.09006", "submitter": "Marzieh Fadaee", "authors": "Marzieh Fadaee and Christof Monz", "title": "Back-Translation Sampling by Targeting Difficult Words in Neural Machine\n  Translation", "comments": "11 pages, 2 figures. Accepted at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation has achieved state-of-the-art performance for\nseveral language pairs using a combination of parallel and synthetic data.\nSynthetic data is often generated by back-translating sentences randomly\nsampled from monolingual data using a reverse translation model. While\nback-translation has been shown to be very effective in many cases, it is not\nentirely clear why. In this work, we explore different aspects of\nback-translation, and show that words with high prediction loss during training\nbenefit most from the addition of synthetic data. We introduce several\nvariations of sampling strategies targeting difficult-to-predict words using\nprediction losses and frequencies of words. In addition, we also target the\ncontexts of difficult words and sample sentences that are similar in context.\nExperimental results for the WMT news translation task show that our method\nimproves translation quality by up to 1.7 and 1.2 Bleu points over\nback-translation using random sampling for German-English and English-German,\nrespectively.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 19:27:01 GMT"}, {"version": "v2", "created": "Fri, 21 Sep 2018 09:24:58 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Fadaee", "Marzieh", ""], ["Monz", "Christof", ""]]}, {"id": "1808.09012", "submitter": "Hareesh Bahuleyan", "authors": "Hareesh Bahuleyan", "title": "Natural Language Generation with Neural Variational Models", "comments": "Masters Thesis, University of Waterloo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis, we explore the use of deep neural networks for generation of\nnatural language. Specifically, we implement two sequence-to-sequence neural\nvariational models - variational autoencoders (VAE) and variational\nencoder-decoders (VED). VAEs for text generation are difficult to train due to\nissues associated with the Kullback-Leibler (KL) divergence term of the loss\nfunction vanishing to zero. We successfully train VAEs by implementing\noptimization heuristics such as KL weight annealing and word dropout. We also\ndemonstrate the effectiveness of this continuous latent space through\nexperiments such as random sampling, linear interpolation and sampling from the\nneighborhood of the input. We argue that if VAEs are not designed\nappropriately, it may lead to bypassing connections which results in the latent\nspace being ignored during training. We show experimentally with the example of\ndecoder hidden state initialization that such bypassing connections degrade the\nVAE into a deterministic model, thereby reducing the diversity of generated\nsentences. We discover that the traditional attention mechanism used in\nsequence-to-sequence VED models serves as a bypassing connection, thereby\ndeteriorating the model's latent space. In order to circumvent this issue, we\npropose the variational attention mechanism where the attention context vector\nis modeled as a random variable that can be sampled from a distribution. We\nshow empirically using automatic evaluation metrics, namely entropy and\ndistinct measures, that our variational attention model generates more diverse\noutput sentences than the deterministic attention model. A qualitative analysis\nwith human evaluation study proves that our model simultaneously produces\nsentences that are of high quality and equally fluent as the ones generated by\nthe deterministic attention counterpart.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 19:40:53 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Bahuleyan", "Hareesh", ""]]}, {"id": "1808.09029", "submitter": "Sachin Mehta", "authors": "Sachin Mehta and Rik Koncel-Kedziorski and Mohammad Rastegari and\n  Hannaneh Hajishirzi", "title": "Pyramidal Recurrent Unit for Language Modeling", "comments": "Accepted as a long paper in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LSTMs are powerful tools for modeling contextual information, as evidenced by\ntheir success at the task of language modeling. However, modeling contexts in\nvery high dimensional space can lead to poor generalizability. We introduce the\nPyramidal Recurrent Unit (PRU), which enables learning representations in high\ndimensional space with more generalization power and fewer parameters. PRUs\nreplace the linear transformation in LSTMs with more sophisticated interactions\nincluding pyramidal and grouped linear transformations. This architecture gives\nstrong results on word-level language modeling while reducing the number of\nparameters significantly. In particular, PRU improves the perplexity of a\nrecent state-of-the-art language model Merity et al. (2018) by up to 1.3 points\nwhile learning 15-20% fewer parameters. For similar number of model parameters,\nPRU outperforms all previous RNN models that exploit different gating\nmechanisms and transformations. We provide a detailed examination of the PRU\nand its behavior on the language modeling tasks. Our code is open-source and\navailable at https://sacmehta.github.io/PRU/\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 20:31:27 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Mehta", "Sachin", ""], ["Koncel-Kedziorski", "Rik", ""], ["Rastegari", "Mohammad", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "1808.09031", "submitter": "Rebecca Marvin", "authors": "Rebecca Marvin and Tal Linzen", "title": "Targeted Syntactic Evaluation of Language Models", "comments": "Accepted to EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a dataset for evaluating the grammaticality of the predictions of\na language model. We automatically construct a large number of minimally\ndifferent pairs of English sentences, each consisting of a grammatical and an\nungrammatical sentence. The sentence pairs represent different variations of\nstructure-sensitive phenomena: subject-verb agreement, reflexive anaphora and\nnegative polarity items. We expect a language model to assign a higher\nprobability to the grammatical sentence than the ungrammatical one. In an\nexperiment using this data set, an LSTM language model performed poorly on many\nof the constructions. Multi-task training with a syntactic objective (CCG\nsupertagging) improved the LSTM's accuracy, but a large gap remained between\nits performance and the accuracy of human participants recruited online. This\nsuggests that there is considerable room for improvement over LSTMs in\ncapturing syntax in a language model.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 20:42:51 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Marvin", "Rebecca", ""], ["Linzen", "Tal", ""]]}, {"id": "1808.09037", "submitter": "Scott A. Hale", "authors": "Chico Q. Camargo, Scott A. Hale, Peter John, and Helen Z. Margetts", "title": "Volatility in the Issue Attention Economy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.IT math.IT physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent election surprises and regime changes have left the impression that\npolitics has become more fast-moving and unstable. While modern politics does\nseem more volatile, there is little systematic evidence to support this claim.\nThis paper seeks to address this gap in knowledge by reporting data over the\nlast seventy years using public opinion polls and traditional media data from\nthe UK and Germany. These countries are good cases to study because both have\nexperienced considerable changes in electoral behaviour and have new political\nparties during the time period studied. We measure volatility in public opinion\nand in media coverage using approaches from information theory, tracking the\nchange in word-use patterns across over 700,000 articles. Our preliminary\nanalysis suggests an increase in the number of opinion issues over time and a\ngrowth in lack of predictability of the media series from the 1970s.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 21:28:46 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Camargo", "Chico Q.", ""], ["Hale", "Scott A.", ""], ["John", "Peter", ""], ["Margetts", "Helen Z.", ""]]}, {"id": "1808.09040", "submitter": "Wenhan Xiong", "authors": "Wenhan Xiong, Mo Yu, Shiyu Chang, Xiaoxiao Guo, William Yang Wang", "title": "One-Shot Relational Learning for Knowledge Graphs", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs (KGs) are the key components of various natural language\nprocessing applications. To further expand KGs' coverage, previous studies on\nknowledge graph completion usually require a large number of training instances\nfor each relation. However, we observe that long-tail relations are actually\nmore common in KGs and those newly added relations often do not have many known\ntriples for training. In this work, we aim at predicting new facts under a\nchallenging setting where only one training instance is available. We propose a\none-shot relational learning framework, which utilizes the knowledge extracted\nby embedding models and learns a matching metric by considering both the\nlearned embeddings and one-hop graph structures. Empirically, our model yields\nconsiderable performance improvements over existing embedding models, and also\neliminates the need of re-training the embedding models when dealing with newly\nadded relations.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 21:42:56 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Xiong", "Wenhan", ""], ["Yu", "Mo", ""], ["Chang", "Shiyu", ""], ["Guo", "Xiaoxiao", ""], ["Wang", "William Yang", ""]]}, {"id": "1808.09042", "submitter": "Alexey Romanov", "authors": "Alexey Romanov, Anna Rumshisky, Anna Rogers, David Donahue", "title": "Adversarial Decomposition of Text Representation", "comments": "Accepted at NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a method for adversarial decomposition of text\nrepresentation. This method can be used to decompose a representation of an\ninput sentence into several independent vectors, each of them responsible for a\nspecific aspect of the input sentence. We evaluate the proposed method on two\ncase studies: the conversion between different social registers and diachronic\nlanguage change. We show that the proposed method is capable of fine-grained\ncontrolled change of these aspects of the input sentence. It is also learning a\ncontinuous (rather than categorical) representation of the style of the\nsentence, which is more linguistically realistic. The model uses\nadversarial-motivational training and includes a special motivational loss,\nwhich acts opposite to the discriminator and encourages a better decomposition.\nFurthermore, we evaluate the obtained meaning embeddings on a downstream task\nof paraphrase detection and show that they significantly outperform the\nembeddings of a regular autoencoder.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 21:49:12 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 14:54:47 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Romanov", "Alexey", ""], ["Rumshisky", "Anna", ""], ["Rogers", "Anna", ""], ["Donahue", "David", ""]]}, {"id": "1808.09055", "submitter": "Miryam de Lhoneux", "authors": "Miryam de Lhoneux, Johannes Bjerva, Isabelle Augenstein and Anders\n  S{\\o}gaard", "title": "Parameter sharing between dependency parsers for related languages", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work has suggested that parameter sharing between transition-based\nneural dependency parsers for related languages can lead to better performance,\nbut there is no consensus on what parameters to share. We present an evaluation\nof 27 different parameter sharing strategies across 10 languages, representing\nfive pairs of related languages, each pair from a different language family. We\nfind that sharing transition classifier parameters always helps, whereas the\nusefulness of sharing word and/or character LSTM parameters varies. Based on\nthis result, we propose an architecture where the transition classifier is\nshared, and the sharing of word and character parameters is controlled by a\nparameter that can be tuned on validation data. This model is linguistically\nmotivated and obtains significant improvements over a monolingually trained\nbaseline. We also find that sharing transition classifier parameters helps when\ntraining a parser on unrelated language pairs, but we find that, in the case of\nunrelated languages, sharing too many parameters does not help.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 22:47:59 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 21:56:51 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["de Lhoneux", "Miryam", ""], ["Bjerva", "Johannes", ""], ["Augenstein", "Isabelle", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "1808.09060", "submitter": "Miryam de Lhoneux", "authors": "Aaron Smith, Miryam de Lhoneux, Sara Stymne and Joakim Nivre", "title": "An Investigation of the Interactions Between Pre-Trained Word\n  Embeddings, Character Models and POS Tags in Dependency Parsing", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a comprehensive analysis of the interactions between pre-trained\nword embeddings, character models and POS tags in a transition-based dependency\nparser. While previous studies have shown POS information to be less important\nin the presence of character models, we show that in fact there are complex\ninteractions between all three techniques. In isolation each produces large\nimprovements over a baseline system using randomly initialised word embeddings\nonly, but combining them quickly leads to diminishing returns. We categorise\nwords by frequency, POS tag and language in order to systematically investigate\nhow each of the techniques affects parsing quality. For many word categories,\napplying any two of the three techniques is almost as good as the full combined\nsystem. Character models tend to be more important for low-frequency open-class\nwords, especially in morphologically rich languages, while POS tags can help\ndisambiguate high-frequency function words. We also show that large character\nembedding sizes help even for languages with small character sets, especially\nin morphologically rich languages.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 23:11:47 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Smith", "Aaron", ""], ["de Lhoneux", "Miryam", ""], ["Stymne", "Sara", ""], ["Nivre", "Joakim", ""]]}, {"id": "1808.09075", "submitter": "Fei Liu", "authors": "Minghao Wu, Fei Liu, Trevor Cohn", "title": "Evaluating the Utility of Hand-crafted Features in Sequence Labelling", "comments": "Accepted to EMNLP 2018 (camera-ready)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional wisdom is that hand-crafted features are redundant for deep\nlearning models, as they already learn adequate representations of text\nautomatically from corpora. In this work, we test this claim by proposing a new\nmethod for exploiting handcrafted features as part of a novel hybrid learning\napproach, incorporating a feature auto-encoder loss component. We evaluate on\nthe task of named entity recognition (NER), where we show that including manual\nfeatures for part-of-speech, word shapes and gazetteers can improve the\nperformance of a neural CRF model. We obtain a $F_1$ of 91.89 for the\nCoNLL-2003 English shared task, which significantly outperforms a collection of\nhighly competitive baseline models. We also present an ablation study showing\nthe importance of auto-encoding, over using features as either inputs or\noutputs alone, and moreover, show including the autoencoder components reduces\ntraining requirements to 60\\%, while retaining the same predictive accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 00:53:06 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Wu", "Minghao", ""], ["Liu", "Fei", ""], ["Cohn", "Trevor", ""]]}, {"id": "1808.09091", "submitter": "Paria Jamshid Lou", "authors": "Paria Jamshid Lou and Mark Johnson", "title": "Disfluency Detection using a Noisy Channel Model and a Deep Neural\n  Language Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a model for disfluency detection in spontaneous speech\ntranscripts called LSTM Noisy Channel Model. The model uses a Noisy Channel\nModel (NCM) to generate n-best candidate disfluency analyses and a Long\nShort-Term Memory (LSTM) language model to score the underlying fluent\nsentences of each analysis. The LSTM language model scores, along with other\nfeatures, are used in a MaxEnt reranker to identify the most plausible\nanalysis. We show that using an LSTM language model in the reranking process of\nnoisy channel disfluency model improves the state-of-the-art in disfluency\ndetection.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 02:23:56 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Lou", "Paria Jamshid", ""], ["Johnson", "Mark", ""]]}, {"id": "1808.09092", "submitter": "Paria Jamshid Lou", "authors": "Paria Jamshid Lou and Peter Anderson and Mark Johnson", "title": "Disfluency Detection using Auto-Correlational Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the natural language processing community has moved away\nfrom task-specific feature engineering, i.e., researchers discovering ad-hoc\nfeature representations for various tasks, in favor of general-purpose methods\nthat learn the input representation by themselves. However, state-of-the-art\napproaches to disfluency detection in spontaneous speech transcripts currently\nstill depend on an array of hand-crafted features, and other representations\nderived from the output of pre-existing systems such as language models or\ndependency parsers. As an alternative, this paper proposes a simple yet\neffective model for automatic disfluency detection, called an\nauto-correlational neural network (ACNN). The model uses a convolutional neural\nnetwork (CNN) and augments it with a new auto-correlation operator at the\nlowest layer that can capture the kinds of \"rough copy\" dependencies that are\ncharacteristic of repair disfluencies in speech. In experiments, the ACNN model\noutperforms the baseline CNN on a disfluency detection task with a 5% increase\nin f-score, which is close to the previous best result on this task.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 02:28:12 GMT"}, {"version": "v2", "created": "Sun, 28 Oct 2018 02:23:15 GMT"}, {"version": "v3", "created": "Fri, 10 Apr 2020 07:43:36 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Lou", "Paria Jamshid", ""], ["Anderson", "Peter", ""], ["Johnson", "Mark", ""]]}, {"id": "1808.09101", "submitter": "Linfeng Song", "authors": "Linfeng Song, Yue Zhang, Zhiguo Wang and Daniel Gildea", "title": "N-ary Relation Extraction using Graph State LSTM", "comments": "EMNLP 18 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-sentence $n$-ary relation extraction detects relations among $n$\nentities across multiple sentences. Typical methods formulate an input as a\n\\textit{document graph}, integrating various intra-sentential and\ninter-sentential dependencies. The current state-of-the-art method splits the\ninput graph into two DAGs, adopting a DAG-structured LSTM for each. Though\nbeing able to model rich linguistic knowledge by leveraging graph edges,\nimportant information can be lost in the splitting procedure. We propose a\ngraph-state LSTM model, which uses a parallel state to model each word,\nrecurrently enriching state values via message passing. Compared with DAG\nLSTMs, our graph LSTM keeps the original graph structure, and speeds up\ncomputation by allowing more parallelization. On a standard benchmark, our\nmodel shows the best result in the literature.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 03:37:39 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Song", "Linfeng", ""], ["Zhang", "Yue", ""], ["Wang", "Zhiguo", ""], ["Gildea", "Daniel", ""]]}, {"id": "1808.09111", "submitter": "Junxian He", "authors": "Junxian He, Graham Neubig, Taylor Berg-Kirkpatrick", "title": "Unsupervised Learning of Syntactic Structure with Invertible Neural\n  Projections", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised learning of syntactic structure is typically performed using\ngenerative models with discrete latent variables and multinomial parameters. In\nmost cases, these models have not leveraged continuous word representations. In\nthis work, we propose a novel generative model that jointly learns discrete\nsyntactic structure and continuous word representations in an unsupervised\nfashion by cascading an invertible neural network with a structured generative\nprior. We show that the invertibility condition allows for efficient exact\ninference and marginal likelihood computation in our model so long as the prior\nis well-behaved. In experiments we instantiate our approach with both Markov\nand tree-structured priors, evaluating on two tasks: part-of-speech (POS)\ninduction, and unsupervised dependency parsing without gold POS annotation. On\nthe Penn Treebank, our Markov-structured model surpasses state-of-the-art\nresults on POS induction. Similarly, we find that our tree-structured model\nachieves state-of-the-art performance on unsupervised dependency parsing for\nthe difficult training condition where neither gold POS annotation nor\npunctuation-based constraints are available.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 04:33:25 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["He", "Junxian", ""], ["Neubig", "Graham", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}, {"id": "1808.09115", "submitter": "Tommi Gr\\\"ondahl", "authors": "Tommi Gr\\\"ondahl, Luca Pajola, Mika Juuti, Mauro Conti, N. Asokan", "title": "All You Need is \"Love\": Evading Hate-speech Detection", "comments": "11 pages, Proceedings of the 11th ACM Workshop on Artificial\n  Intelligence and Security (AISec) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the spread of social networks and their unfortunate use for hate speech,\nautomatic detection of the latter has become a pressing problem. In this paper,\nwe reproduce seven state-of-the-art hate speech detection models from prior\nwork, and show that they perform well only when tested on the same type of data\nthey were trained on. Based on these results, we argue that for successful hate\nspeech detection, model architecture is less important than the type of data\nand labeling criteria. We further show that all proposed detection techniques\nare brittle against adversaries who can (automatically) insert typos, change\nword boundaries or add innocuous words to the original hate speech. A\ncombination of these methods is also effective against Google Perspective -- a\ncutting-edge solution from industry. Our experiments demonstrate that\nadversarial training does not completely mitigate the attacks, and using\ncharacter-level features makes the models systematically more attack-resistant\nthan using word-level features.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 04:49:54 GMT"}, {"version": "v2", "created": "Fri, 31 Aug 2018 15:48:23 GMT"}, {"version": "v3", "created": "Mon, 5 Nov 2018 16:06:57 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Gr\u00f6ndahl", "Tommi", ""], ["Pajola", "Luca", ""], ["Juuti", "Mika", ""], ["Conti", "Mauro", ""], ["Asokan", "N.", ""]]}, {"id": "1808.09121", "submitter": "Mohammad Taher Pilehvar", "authors": "Mohammad Taher Pilehvar, Jose Camacho-Collados", "title": "WiC: the Word-in-Context Dataset for Evaluating Context-Sensitive\n  Meaning Representations", "comments": "NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By design, word embeddings are unable to model the dynamic nature of words'\nsemantics, i.e., the property of words to correspond to potentially different\nmeanings. To address this limitation, dozens of specialized meaning\nrepresentation techniques such as sense or contextualized embeddings have been\nproposed. However, despite the popularity of research on this topic, very few\nevaluation benchmarks exist that specifically focus on the dynamic semantics of\nwords. In this paper we show that existing models have surpassed the\nperformance ceiling of the standard evaluation dataset for the purpose, i.e.,\nStanford Contextual Word Similarity, and highlight its shortcomings. To address\nthe lack of a suitable benchmark, we put forward a large-scale Word in Context\ndataset, called WiC, based on annotations curated by experts, for generic\nevaluation of context-sensitive representations. WiC is released in\nhttps://pilehvar.github.io/wic/.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 05:16:35 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 12:56:45 GMT"}, {"version": "v3", "created": "Sat, 27 Apr 2019 09:31:59 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Pilehvar", "Mohammad Taher", ""], ["Camacho-Collados", "Jose", ""]]}, {"id": "1808.09132", "submitter": "Panupong Pasupat", "authors": "Panupong Pasupat, Tian-Shun Jiang, Evan Zheran Liu, Kelvin Guu, Percy\n  Liang", "title": "Mapping Natural Language Commands to Web Elements", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The web provides a rich, open-domain environment with textual, structural,\nand spatial properties. We propose a new task for grounding language in this\nenvironment: given a natural language command (e.g., \"click on the second\narticle\"), choose the correct element on the web page (e.g., a hyperlink or\ntext box). We collected a dataset of over 50,000 commands that capture various\nphenomena such as functional references (e.g. \"find who made this site\"),\nrelational reasoning (e.g. \"article by john\"), and visual reasoning (e.g.\n\"top-most article\"). We also implemented and analyzed three baseline models\nthat capture different phenomena present in the dataset.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 06:09:39 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 03:22:58 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Pasupat", "Panupong", ""], ["Jiang", "Tian-Shun", ""], ["Liu", "Evan Zheran", ""], ["Guu", "Kelvin", ""], ["Liang", "Percy", ""]]}, {"id": "1808.09147", "submitter": "Yizhong Wang", "authors": "Yizhong Wang, Sujian Li and Jingfeng Yang", "title": "Toward Fast and Accurate Neural Discourse Segmentation", "comments": "6 pages, camera-ready version of EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discourse segmentation, which segments texts into Elementary Discourse Units,\nis a fundamental step in discourse analysis. Previous discourse segmenters rely\non complicated hand-crafted features and are not practical in actual use. In\nthis paper, we propose an end-to-end neural segmenter based on BiLSTM-CRF\nframework. To improve its accuracy, we address the problem of data\ninsufficiency by transferring a word representation model that is trained on a\nlarge corpus. We also propose a restricted self-attention mechanism in order to\ncapture useful information within a neighborhood. Experiments on the RST-DT\ncorpus show that our model is significantly faster than previous methods, while\nachieving new state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 07:27:45 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Wang", "Yizhong", ""], ["Li", "Sujian", ""], ["Yang", "Jingfeng", ""]]}, {"id": "1808.09160", "submitter": "Hardy Hardy", "authors": "Hardy and Andreas Vlachos", "title": "Guided Neural Language Generation for Abstractive Summarization using\n  Abstract Meaning Representation", "comments": "Accepted in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on abstractive summarization has made progress with neural\nencoder-decoder architectures. However, such models are often challenged due to\ntheir lack of explicit semantic modeling of the source document and its\nsummary. In this paper, we extend previous work on abstractive summarization\nusing Abstract Meaning Representation (AMR) with a neural language generation\nstage which we guide using the source document. We demonstrate that this\nguidance improves summarization results by 7.4 and 10.5 points in ROUGE-2 using\ngold standard AMR parses and parses obtained from an off-the-shelf parser\nrespectively. We also find that the summarization performance using the latter\nis 2 ROUGE-2 points higher than that of a well-established neural\nencoder-decoder approach trained on a larger dataset. Code is available at\n\\url{https://github.com/sheffieldnlp/AMR2Text-summ}\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 08:04:21 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Hardy", "", ""], ["Vlachos", "Andreas", ""]]}, {"id": "1808.09178", "submitter": "Dieuwke Hupkes", "authors": "Dieuwke Hupkes, Sanne Bouwmeester, Raquel Fern\\'andez", "title": "Analysing the potential of seq-to-seq models for incremental\n  interpretation in task-oriented dialogue", "comments": "accepted to the EMNLP2018 workshop \"Analyzing and interpreting neural\n  networks for NLP\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how encoder-decoder models trained on a synthetic dataset of\ntask-oriented dialogues process disfluencies, such as hesitations and\nself-corrections. We find that, contrary to earlier results, disfluencies have\nvery little impact on the task success of seq-to-seq models with attention.\nUsing visualisation and diagnostic classifiers, we analyse the representations\nthat are incrementally built by the model, and discover that models develop\nlittle to no awareness of the structure of disfluencies. However, adding\ndisfluencies to the data appears to help the model create clearer\nrepresentations overall, as evidenced by the attention patterns the different\nmodels exhibit.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 09:00:37 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Hupkes", "Dieuwke", ""], ["Bouwmeester", "Sanne", ""], ["Fern\u00e1ndez", "Raquel", ""]]}, {"id": "1808.09180", "submitter": "Clara Vania", "authors": "Clara Vania, Andreas Grivas and Adam Lopez", "title": "What do character-level models learn about morphology? The case of\n  dependency parsing", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When parsing morphologically-rich languages with neural models, it is\nbeneficial to model input at the character level, and it has been claimed that\nthis is because character-level models learn morphology. We test these claims\nby comparing character-level models to an oracle with access to explicit\nmorphological analysis on twelve languages with varying morphological\ntypologies. Our results highlight many strengths of character-level models, but\nalso show that they are poor at disambiguating some words, particularly in the\nface of case syncretism. We then demonstrate that explicitly modeling\nmorphological case improves our best model, showing that character-level models\ncan benefit from targeted forms of explicit morphological modeling.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 09:02:48 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Vania", "Clara", ""], ["Grivas", "Andreas", ""], ["Lopez", "Adam", ""]]}, {"id": "1808.09187", "submitter": "Bowen Wu", "authors": "Bowen Wu, Nan Jiang, Zhifeng Gao, Mengyuan Li, Zongsheng Wang, Suke\n  Li, Qihang Feng, Wenge Rong, Baoxun Wang", "title": "Why Do Neural Response Generation Models Prefer Universal Replies?", "comments": "Preprint of the paper presented to the AAAI 2020 Workshop on\n  Interactive and Conversational Recommendation Systems (WICRS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in sequence-to-sequence learning reveal a purely data-driven\napproach to the response generation task. Despite its diverse applications,\nexisting neural models are prone to producing short and generic replies, making\nit infeasible to tackle open-domain challenges. In this research, we analyze\nthis critical issue in light of the model's optimization goal and the specific\ncharacteristics of the human-to-human dialog corpus. By decomposing the black\nbox into parts, a detailed analysis of the probability limit was conducted to\nreveal the reason behind these universal replies. Based on these analyses, we\npropose a max-margin ranking regularization term to avoid the models leaning to\nthese replies. Finally, empirical experiments on case studies and benchmarks\nwith several metrics validate this approach.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 09:11:49 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 08:31:23 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Wu", "Bowen", ""], ["Jiang", "Nan", ""], ["Gao", "Zhifeng", ""], ["Li", "Mengyuan", ""], ["Wang", "Zongsheng", ""], ["Li", "Suke", ""], ["Feng", "Qihang", ""], ["Rong", "Wenge", ""], ["Wang", "Baoxun", ""]]}, {"id": "1808.09238", "submitter": "Martin Schmitt", "authors": "Martin Schmitt, Simon Steinheber, Konrad Schreiber and Benjamin Roth", "title": "Joint Aspect and Polarity Classification for Aspect-based Sentiment\n  Analysis with End-to-End Neural Networks", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a new model for aspect-based sentiment analysis. In\ncontrast to previous approaches, we jointly model the detection of aspects and\nthe classification of their polarity in an end-to-end trainable neural network.\nWe conduct experiments with different neural architectures and word\nrepresentations on the recent GermEval 2017 dataset. We were able to show\nconsiderable performance gains by using the joint modeling approach in all\nsettings compared to pipeline approaches. The combination of a convolutional\nneural network and fasttext embeddings outperformed the best submission of the\nshared task in 2017, establishing a new state of the art.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 11:53:05 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Schmitt", "Martin", ""], ["Steinheber", "Simon", ""], ["Schreiber", "Konrad", ""], ["Roth", "Benjamin", ""]]}, {"id": "1808.09308", "submitter": "Mohammad Taher Pilehvar", "authors": "Mohammad Taher Pilehvar, Dimitri Kartsaklis, Victor Prokhorov, Nigel\n  Collier", "title": "Card-660: Cambridge Rare Word Dataset - a Reliable Benchmark for\n  Infrequent Word Representation Models", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rare word representation has recently enjoyed a surge of interest, owing to\nthe crucial role that effective handling of infrequent words can play in\naccurate semantic understanding. However, there is a paucity of reliable\nbenchmarks for evaluation and comparison of these techniques. We show in this\npaper that the only existing benchmark (the Stanford Rare Word dataset) suffers\nfrom low-confidence annotations and limited vocabulary; hence, it does not\nconstitute a solid comparison framework. In order to fill this evaluation gap,\nwe propose CAmbridge Rare word Dataset (Card-660), an expert-annotated word\nsimilarity dataset which provides a highly reliable, yet challenging, benchmark\nfor rare word representation techniques. Through a set of experiments we show\nthat even the best mainstream word embeddings, with millions of words in their\nvocabularies, are unable to achieve performances higher than 0.43 (Pearson\ncorrelation) on the dataset, compared to a human-level upperbound of 0.90. We\nrelease the dataset and the annotation materials at\nhttps://pilehvar.github.io/card-660/.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 14:01:07 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Pilehvar", "Mohammad Taher", ""], ["Kartsaklis", "Dimitri", ""], ["Prokhorov", "Victor", ""], ["Collier", "Nigel", ""]]}, {"id": "1808.09315", "submitter": "Yi Yang", "authors": "Yi Yang", "title": "Convolutional Neural Networks with Recurrent Neural Filters", "comments": "Accepted by EMNLP 2018 as a short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a class of convolutional neural networks (CNNs) that utilize\nrecurrent neural networks (RNNs) as convolution filters. A convolution filter\nis typically implemented as a linear affine transformation followed by a\nnon-linear function, which fails to account for language compositionality. As a\nresult, it limits the use of high-order filters that are often warranted for\nnatural language processing tasks. In this work, we model convolution filters\nwith RNNs that naturally capture compositionality and long-term dependencies in\nlanguage. We show that simple CNN architectures equipped with recurrent neural\nfilters (RNFs) achieve results that are on par with the best published ones on\nthe Stanford Sentiment Treebank and two answer sentence selection datasets.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 14:13:26 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Yang", "Yi", ""]]}, {"id": "1808.09333", "submitter": "Dongyeop Kang", "authors": "Dongyeop Kang, Tushar Khot, Ashish Sabharwal, Peter Clark", "title": "Bridging Knowledge Gaps in Neural Entailment via Symbolic Models", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most textual entailment models focus on lexical gaps between the premise text\nand the hypothesis, but rarely on knowledge gaps. We focus on filling these\nknowledge gaps in the Science Entailment task, by leveraging an external\nstructured knowledge base (KB) of science facts. Our new architecture combines\nstandard neural entailment models with a knowledge lookup module. To facilitate\nthis lookup, we propose a fact-level decomposition of the hypothesis, and\nverifying the resulting sub-facts against both the textual premise and the\nstructured KB. Our model, NSnet, learns to aggregate predictions from these\nheterogeneous data formats. On the SciTail dataset, NSnet outperforms a simpler\ncombination of the two predictions by 3% and the base entailment model by 5%.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 14:45:47 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 14:24:03 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Kang", "Dongyeop", ""], ["Khot", "Tushar", ""], ["Sabharwal", "Ashish", ""], ["Clark", "Peter", ""]]}, {"id": "1808.09334", "submitter": "Ryan Cotterell Ryan D Cotterell", "authors": "Sebastian Ruder, Ryan Cotterell, Yova Kementchedjhieva, Anders\n  S{\\o}gaard", "title": "A Discriminative Latent-Variable Model for Bilingual Lexicon Induction", "comments": "Proceedings of the 2018 Conference on Empirical Methods in Natural\n  Language Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel discriminative latent-variable model for the task of\nbilingual lexicon induction. Our model combines the bipartite matching\ndictionary prior of Haghighi et al. (2008) with a state-of-the-art\nembedding-based approach. To train the model, we derive an efficient Viterbi EM\nalgorithm. We provide empirical improvements on six language pairs under two\nmetrics and show that the prior theoretically and empirically helps to mitigate\nthe hubness problem. We also demonstrate how previous work may be viewed as a\nsimilarly fashioned latent-variable model, albeit with a different prior.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 14:47:33 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 13:43:19 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Ruder", "Sebastian", ""], ["Cotterell", "Ryan", ""], ["Kementchedjhieva", "Yova", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "1808.09352", "submitter": "Aida Nematzadeh", "authors": "Aida Nematzadeh and Kaylee Burns and Erin Grant and Alison Gopnik and\n  Thomas L. Griffiths", "title": "Evaluating Theory of Mind in Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new dataset for evaluating question answering models with\nrespect to their capacity to reason about beliefs. Our tasks are inspired by\ntheory-of-mind experiments that examine whether children are able to reason\nabout the beliefs of others, in particular when those beliefs differ from\nreality. We evaluate a number of recent neural models with memory augmentation.\nWe find that all fail on our tasks, which require keeping track of inconsistent\nstates of the world; moreover, the models' accuracy decreases notably when\nrandom sentences are introduced to the tasks at test.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 15:16:17 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Nematzadeh", "Aida", ""], ["Burns", "Kaylee", ""], ["Grant", "Erin", ""], ["Gopnik", "Alison", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "1808.09353", "submitter": "Morgan Gallant", "authors": "Morgan Gallant, Haruna Isah, Farhana Zulkernine, Shahzad Khan", "title": "Xu: An Automated Query Expansion and Optimization Tool", "comments": "Accepted to IEEE COMPSAC 2019", "journal-ref": null, "doi": "10.1109/COMPSAC.2019.00070", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The exponential growth of information on the Internet is a big challenge for\ninformation retrieval systems towards generating relevant results. Novel\napproaches are required to reformat or expand user queries to generate a\nsatisfactory response and increase recall and precision. Query expansion (QE)\nis a technique to broaden users' queries by introducing additional tokens or\nphrases based on some semantic similarity metrics. The tradeoff is the added\ncomputational complexity to find semantically similar words and a possible\nincrease in noise in information retrieval. Despite several research efforts on\nthis topic, QE has not yet been explored enough and more work is needed on\nsimilarity matching and composition of query terms with an objective to\nretrieve a small set of most appropriate responses. QE should be scalable,\nfast, and robust in handling complex queries with a good response time and\nnoise ceiling. In this paper, we propose Xu, an automated QE technique, using\nhigh dimensional clustering of word vectors and Datamuse API, an open source\nquery engine to find semantically similar words. We implemented Xu as a command\nline tool and evaluated its performances using datasets containing news\narticles and human-generated QEs. The evaluation results show that Xu was\nbetter than Datamuse by achieving about 88% accuracy with reference to the\nhuman-generated QE.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 15:18:14 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 22:08:28 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Gallant", "Morgan", ""], ["Isah", "Haruna", ""], ["Zulkernine", "Farhana", ""], ["Khan", "Shahzad", ""]]}, {"id": "1808.09354", "submitter": "Daniel Hershcovich", "authors": "Daniel Hershcovich, Omri Abend and Ari Rappoport", "title": "Universal Dependency Parsing with a General Transition-Based DAG Parser", "comments": "CoNLL 2018 UD Shared Task", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents our experiments with applying TUPA to the CoNLL 2018 UD\nshared task. TUPA is a general neural transition-based DAG parser, which we use\nto present the first experiments on recovering enhanced dependencies as part of\nthe general parsing task. TUPA was designed for parsing UCCA, a\ncross-linguistic semantic annotation scheme, exhibiting reentrancy,\ndiscontinuity and non-terminal nodes. By converting UD trees and graphs to a\nUCCA-like DAG format, we train TUPA almost without modification on the UD\nparsing task. The generic nature of our approach lends itself naturally to\nmultitask learning. Our code is available at\nhttps://github.com/CoNLL-UD-2018/HUJI\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 15:19:33 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Hershcovich", "Daniel", ""], ["Abend", "Omri", ""], ["Rappoport", "Ari", ""]]}, {"id": "1808.09357", "submitter": "Hao Peng", "authors": "Hao Peng, Roy Schwartz, Sam Thomson, and Noah A. Smith", "title": "Rational Recurrences", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the tremendous empirical success of neural models in natural language\nprocessing, many of them lack the strong intuitions that accompany classical\nmachine learning approaches. Recently, connections have been shown between\nconvolutional neural networks (CNNs) and weighted finite state automata\n(WFSAs), leading to new interpretations and insights. In this work, we show\nthat some recurrent neural networks also share this connection to WFSAs. We\ncharacterize this connection formally, defining rational recurrences to be\nrecurrent hidden state update functions that can be written as the Forward\ncalculation of a finite set of WFSAs. We show that several recent neural models\nuse rational recurrences. Our analysis provides a fresh view of these models\nand facilitates devising new neural architectures that draw inspiration from\nWFSAs. We present one such model, which performs better than two recent\nbaselines on language modeling and text classification. Our results demonstrate\nthat transferring intuitions from classical models like WFSAs can be an\neffective approach to designing and understanding neural models.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 15:28:25 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Peng", "Hao", ""], ["Schwartz", "Roy", ""], ["Thomson", "Sam", ""], ["Smith", "Noah A.", ""]]}, {"id": "1808.09367", "submitter": "Yujia Bao", "authors": "Yujia Bao, Shiyu Chang, Mo Yu, Regina Barzilay", "title": "Deriving Machine Attention from Human Rationales", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based models are successful when trained on large amounts of data.\nIn this paper, we demonstrate that even in the low-resource scenario, attention\ncan be learned effectively. To this end, we start with discrete human-annotated\nrationales and map them into continuous attention. Our central hypothesis is\nthat this mapping is general across domains, and thus can be transferred from\nresource-rich domains to low-resource ones. Our model jointly learns a\ndomain-invariant representation and induces the desired mapping between\nrationales and attention. Our empirical results validate this hypothesis and\nshow that our approach delivers significant gains over state-of-the-art\nbaselines, yielding over 15% average error reduction on benchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 15:38:41 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Bao", "Yujia", ""], ["Chang", "Shiyu", ""], ["Yu", "Mo", ""], ["Barzilay", "Regina", ""]]}, {"id": "1808.09374", "submitter": "Xinyi Wang", "authors": "Xinyi Wang, Hieu Pham, Pengcheng Yin, Graham Neubig", "title": "A Tree-based Decoder for Neural Machine Translation", "comments": "Accepted as a short paper at the 2018 Conference on Empirical Methods\n  in Natural Language Processing (EMNLP 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Neural Machine Translation (NMT) show that adding\nsyntactic information to NMT systems can improve the quality of their\ntranslations. Most existing work utilizes some specific types of\nlinguistically-inspired tree structures, like constituency and dependency parse\ntrees. This is often done via a standard RNN decoder that operates on a\nlinearized target tree structure. However, it is an open question of what\nspecific linguistic formalism, if any, is the best structural representation\nfor NMT. In this paper, we (1) propose an NMT model that can naturally generate\nthe topology of an arbitrary tree structure on the target side, and (2)\nexperiment with various target tree structures. Our experiments show the\nsurprising result that our model delivers the best improvements with balanced\nbinary trees constructed without any linguistic knowledge; this model\noutperforms standard seq2seq models by up to 2.1 BLEU points, and other methods\nfor incorporating target-side syntax by up to 0.7 BLEU.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 15:52:19 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Wang", "Xinyi", ""], ["Pham", "Hieu", ""], ["Yin", "Pengcheng", ""], ["Neubig", "Graham", ""]]}, {"id": "1808.09381", "submitter": "Michael Auli", "authors": "Sergey Edunov, Myle Ott, Michael Auli, David Grangier", "title": "Understanding Back-Translation at Scale", "comments": "12 pages; EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An effective method to improve neural machine translation with monolingual\ndata is to augment the parallel training corpus with back-translations of\ntarget language sentences. This work broadens the understanding of\nback-translation and investigates a number of methods to generate synthetic\nsource sentences. We find that in all but resource poor settings\nback-translations obtained via sampling or noised beam outputs are most\neffective. Our analysis shows that sampling or noisy synthetic data gives a\nmuch stronger training signal than data generated by beam or greedy search. We\nalso compare how synthetic data compares to genuine bitext and study various\ndomain effects. Finally, we scale to hundreds of millions of monolingual\nsentences and achieve a new state of the art of 35 BLEU on the WMT'14\nEnglish-German test set.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 16:05:40 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 01:42:36 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Edunov", "Sergey", ""], ["Ott", "Myle", ""], ["Auli", "Michael", ""], ["Grangier", "David", ""]]}, {"id": "1808.09384", "submitter": "Saku Sugawara", "authors": "Saku Sugawara, Kentaro Inui, Satoshi Sekine, Akiko Aizawa", "title": "What Makes Reading Comprehension Questions Easier?", "comments": "12 pages, EMNLP2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A challenge in creating a dataset for machine reading comprehension (MRC) is\nto collect questions that require a sophisticated understanding of language to\nanswer beyond using superficial cues. In this work, we investigate what makes\nquestions easier across recent 12 MRC datasets with three question styles\n(answer extraction, description, and multiple choice). We propose to employ\nsimple heuristics to split each dataset into easy and hard subsets and examine\nthe performance of two baseline models for each of the subsets. We then\nmanually annotate questions sampled from each subset with both validity and\nrequisite reasoning skills to investigate which skills explain the difference\nbetween easy and hard questions. From this study, we observed that (i) the\nbaseline performances for the hard subsets remarkably degrade compared to those\nof entire datasets, (ii) hard questions require knowledge inference and\nmultiple-sentence reasoning in comparison with easy questions, and (iii)\nmultiple-choice questions tend to require a broader range of reasoning skills\nthan answer extraction and description questions. These results suggest that\none might overestimate recent advances in MRC.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 16:17:43 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Sugawara", "Saku", ""], ["Inui", "Kentaro", ""], ["Sekine", "Satoshi", ""], ["Aizawa", "Akiko", ""]]}, {"id": "1808.09386", "submitter": "Anjalie Field", "authors": "Anjalie Field, Doron Kliger, Shuly Wintner, Jennifer Pan, Dan\n  Jurafsky, Yulia Tsvetkov", "title": "Framing and Agenda-setting in Russian News: a Computational Analysis of\n  Intricate Political Strategies", "comments": "Accepted as a full paper at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Amidst growing concern over media manipulation, NLP attention has focused on\novert strategies like censorship and \"fake news'\". Here, we draw on two\nconcepts from the political science literature to explore subtler strategies\nfor government media manipulation: agenda-setting (selecting what topics to\ncover) and framing (deciding how topics are covered). We analyze 13 years (100K\narticles) of the Russian newspaper Izvestia and identify a strategy of\ndistraction: articles mention the U.S. more frequently in the month directly\nfollowing an economic downturn in Russia. We introduce embedding-based methods\nfor cross-lingually projecting English frames to Russian, and discover that\nthese articles emphasize U.S. moral failings and threats to the U.S. Our work\noffers new ways to identify subtle media manipulation strategies at the\nintersection of agenda-setting and framing.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 16:20:20 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 16:40:45 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Field", "Anjalie", ""], ["Kliger", "Doron", ""], ["Wintner", "Shuly", ""], ["Pan", "Jennifer", ""], ["Jurafsky", "Dan", ""], ["Tsvetkov", "Yulia", ""]]}, {"id": "1808.09401", "submitter": "Artuur Leeuwenberg", "authors": "Artuur Leeuwenberg, Marie-Francine Moens", "title": "Temporal Information Extraction by Predicting Relative Time-lines", "comments": "Accepted at the Conference on Empirical Methods in Natural Language\n  Processing (EMNLP 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The current leading paradigm for temporal information extraction from text\nconsists of three phases: (1) recognition of events and temporal expressions,\n(2) recognition of temporal relations among them, and (3) time-line\nconstruction from the temporal relations. In contrast to the first two phases,\nthe last phase, time-line construction, received little attention and is the\nfocus of this work. In this paper, we propose a new method to construct a\nlinear time-line from a set of (extracted) temporal relations. But more\nimportantly, we propose a novel paradigm in which we directly predict start and\nend-points for events from the text, constituting a time-line without going\nthrough the intermediate step of prediction of temporal relations as in earlier\nwork. Within this paradigm, we propose two models that predict in linear\ncomplexity, and a new training loss using TimeML-style annotations, yielding\npromising results.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 16:46:30 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Leeuwenberg", "Artuur", ""], ["Moens", "Marie-Francine", ""]]}, {"id": "1808.09408", "submitter": "Maximin Coavoux", "authors": "Maximin Coavoux, Shashi Narayan, Shay B. Cohen", "title": "Privacy-preserving Neural Representations of Text", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article deals with adversarial attacks towards deep learning systems for\nNatural Language Processing (NLP), in the context of privacy protection. We\nstudy a specific type of attack: an attacker eavesdrops on the hidden\nrepresentations of a neural text classifier and tries to recover information\nabout the input text. Such scenario may arise in situations when the\ncomputation of a neural network is shared across multiple devices, e.g. some\nhidden representation is computed by a user's device and sent to a cloud-based\nmodel. We measure the privacy of a hidden representation by the ability of an\nattacker to predict accurately specific private information from it and\ncharacterize the tradeoff between the privacy and the utility of neural\nrepresentations. Finally, we propose several defense methods based on modified\ntraining objectives and show that they improve the privacy of neural\nrepresentations.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 16:57:37 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Coavoux", "Maximin", ""], ["Narayan", "Shashi", ""], ["Cohen", "Shay B.", ""]]}, {"id": "1808.09409", "submitter": "Zi Lin", "authors": "Zi Lin, Yuguang Duan, Yuanyuan Zhao, Weiwei Sun and Xiaojun Wan", "title": "Semantic Role Labeling for Learner Chinese: the Importance of Syntactic\n  Parsing and L2-L1 Parallel Data", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies semantic parsing for interlanguage (L2), taking semantic\nrole labeling (SRL) as a case task and learner Chinese as a case language. We\nfirst manually annotate the semantic roles for a set of learner texts to derive\na gold standard for automatic SRL. Based on the new data, we then evaluate\nthree off-the-shelf SRL systems, i.e., the PCFGLA-parser-based,\nneural-parser-based and neural-syntax-agnostic systems, to gauge how successful\nSRL for learner Chinese can be. We find two non-obvious facts: 1) the\nL1-sentence-trained systems performs rather badly on the L2 data; 2) the\nperformance drop from the L1 data to the L2 data of the two parser-based\nsystems is much smaller, indicating the importance of syntactic parsing in SRL\nfor interlanguages. Finally, the paper introduces a new agreement-based model\nto explore the semantic coherency information in the large-scale L2-L1 parallel\ndata. We then show such information is very effective to enhance SRL for\nlearner texts. Our model achieves an F-score of 72.06, which is a 2.02 point\nimprovement over the best baseline.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 16:57:47 GMT"}, {"version": "v2", "created": "Wed, 29 Aug 2018 16:51:51 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Lin", "Zi", ""], ["Duan", "Yuguang", ""], ["Zhao", "Yuanyuan", ""], ["Sun", "Weiwei", ""], ["Wan", "Xiaojun", ""]]}, {"id": "1808.09419", "submitter": "Manaal Faruqui", "authors": "Manaal Faruqui, Dipanjan Das", "title": "Identifying Well-formed Natural Language Questions", "comments": null, "journal-ref": "Proc. of EMNLP 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding search queries is a hard problem as it involves dealing with\n\"word salad\" text ubiquitously issued by users. However, if a query resembles a\nwell-formed question, a natural language processing pipeline is able to perform\nmore accurate interpretation, thus reducing downstream compounding errors.\nHence, identifying whether or not a query is well formed can enhance query\nunderstanding. Here, we introduce a new task of identifying a well-formed\nnatural language question. We construct and release a dataset of 25,100\npublicly available questions classified into well-formed and non-wellformed\ncategories and report an accuracy of 70.7% on the test set. We also show that\nour classifier can be used to improve the performance of neural\nsequence-to-sequence models for generating questions for reading comprehension.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 17:20:51 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Faruqui", "Manaal", ""], ["Das", "Dipanjan", ""]]}, {"id": "1808.09422", "submitter": "Manaal Faruqui", "authors": "Manaal Faruqui, Ellie Pavlick, Ian Tenney, Dipanjan Das", "title": "WikiAtomicEdits: A Multilingual Corpus of Wikipedia Edits for Modeling\n  Language and Discourse", "comments": null, "journal-ref": "Proc. of EMNLP 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We release a corpus of 43 million atomic edits across 8 languages. These\nedits are mined from Wikipedia edit history and consist of instances in which a\nhuman editor has inserted a single contiguous phrase into, or deleted a single\ncontiguous phrase from, an existing sentence. We use the collected data to show\nthat the language generated during editing differs from the language that we\nobserve in standard corpora, and that models trained on edits encode different\naspects of semantics and discourse than models trained on raw, unstructured\ntext. We release the full corpus as a resource to aid ongoing research in\nsemantics, discourse, and representation learning.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 17:25:27 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Faruqui", "Manaal", ""], ["Pavlick", "Ellie", ""], ["Tenney", "Ian", ""], ["Das", "Dipanjan", ""]]}, {"id": "1808.09442", "submitter": "Yun-Nung Chen", "authors": "Shang-Yu Su and Xiujun Li and Jianfeng Gao and Jingjing Liu and\n  Yun-Nung Chen", "title": "Discriminative Deep Dyna-Q: Robust Planning for Dialogue Policy Learning", "comments": "11 pages, 10 figures, EMNLP 2018 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a Discriminative Deep Dyna-Q (D3Q) approach to improving\nthe effectiveness and robustness of Deep Dyna-Q (DDQ), a recently proposed\nframework that extends the Dyna-Q algorithm to integrate planning for\ntask-completion dialogue policy learning. To obviate DDQ's high dependency on\nthe quality of simulated experiences, we incorporate an RNN-based discriminator\nin D3Q to differentiate simulated experience from real user experience in order\nto control the quality of training data. Experiments show that D3Q\nsignificantly outperforms DDQ by controlling the quality of simulated\nexperience used for planning. The effectiveness and robustness of D3Q is\nfurther demonstrated in a domain extension setting, where the agent's\ncapability of adapting to a changing environment is tested.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 17:59:08 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 17:50:22 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Su", "Shang-Yu", ""], ["Li", "Xiujun", ""], ["Gao", "Jianfeng", ""], ["Liu", "Jingjing", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "1808.09463", "submitter": "Christina Niklaus", "authors": "Matthias Cetto, Christina Niklaus, Andr\\'e Freitas, Siegfried\n  Handschuh", "title": "Graphene: A Context-Preserving Open Information Extraction System", "comments": "27th International Conference on Computational Linguistics (COLING\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce Graphene, an Open IE system whose goal is to generate accurate,\nmeaningful and complete propositions that may facilitate a variety of\ndownstream semantic applications. For this purpose, we transform syntactically\ncomplex input sentences into clean, compact structures in the form of core\nfacts and accompanying contexts, while identifying the rhetorical relations\nthat hold between them in order to maintain their semantic relationship. In\nthat way, we preserve the context of the relational tuples extracted from a\nsource sentence, generating a novel lightweight semantic representation for\nOpen IE that enhances the expressiveness of the extracted propositions.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 18:00:44 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Cetto", "Matthias", ""], ["Niklaus", "Christina", ""], ["Freitas", "Andr\u00e9", ""], ["Handschuh", "Siegfried", ""]]}, {"id": "1808.09465", "submitter": "Felix Stahlberg", "authors": "Felix Stahlberg, Adria de Gispert, Bill Byrne", "title": "The University of Cambridge's Machine Translation Systems for WMT18", "comments": "WMT18 system description paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The University of Cambridge submission to the WMT18 news translation task\nfocuses on the combination of diverse models of translation. We compare\nrecurrent, convolutional, and self-attention-based neural models on\nGerman-English, English-German, and Chinese-English. Our final system combines\nall neural models together with a phrase-based SMT system in an MBR-based\nscheme. We report small but consistent gains on top of strong Transformer\nensembles.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 18:02:31 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Stahlberg", "Felix", ""], ["de Gispert", "Adria", ""], ["Byrne", "Bill", ""]]}, {"id": "1808.09468", "submitter": "Manaal Faruqui", "authors": "Jan A. Botha, Manaal Faruqui, John Alex, Jason Baldridge, Dipanjan Das", "title": "Learning To Split and Rephrase From Wikipedia Edit History", "comments": null, "journal-ref": "Proc. of EMNLP 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Split and rephrase is the task of breaking down a sentence into shorter ones\nthat together convey the same meaning. We extract a rich new dataset for this\ntask by mining Wikipedia's edit history: WikiSplit contains one million\nnaturally occurring sentence rewrites, providing sixty times more distinct\nsplit examples and a ninety times larger vocabulary than the WebSplit corpus\nintroduced by Narayan et al. (2017) as a benchmark for this task. Incorporating\nWikiSplit as training data produces a model with qualitatively better\npredictions that score 32 BLEU points above the prior best result on the\nWebSplit benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 18:03:32 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Botha", "Jan A.", ""], ["Faruqui", "Manaal", ""], ["Alex", "John", ""], ["Baldridge", "Jason", ""], ["Das", "Dipanjan", ""]]}, {"id": "1808.09479", "submitter": "Mohammadzaman Zamani", "authors": "Mohammadzaman Zamani, H. Andrew Schwartz, Veronica E. Lynn, Salvatore\n  Giorgi and Niranjan Balasubramanian", "title": "Residualized Factor Adaptation for Community Social Media Prediction\n  Tasks", "comments": "Conference on Empirical Methods in Natural Language Processing (EMNLP\n  2018)", "journal-ref": "Proceedings of the 2018 Conference on Empirical Methods in Natural\n  Language Processing, pages 3560-3569, 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive models over social media language have shown promise in capturing\ncommunity outcomes, but approaches thus far largely neglect the\nsocio-demographic context (e.g. age, education rates, race) of the community\nfrom which the language originates. For example, it may be inaccurate to assume\npeople in Mobile, Alabama, where the population is relatively older, will use\nwords the same way as those from San Francisco, where the median age is younger\nwith a higher rate of college education. In this paper, we present residualized\nfactor adaptation, a novel approach to community prediction tasks which both\n(a) effectively integrates community attributes, as well as (b) adapts\nlinguistic features to community attributes (factors). We use eleven\ndemographic and socioeconomic attributes, and evaluate our approach over five\ndifferent community-level predictive tasks, spanning health (heart disease\nmortality, percent fair/poor health), psychology (life satisfaction), and\neconomics (percent housing price increase, foreclosure rate). Our evaluation\nshows that residualized factor adaptation significantly improves 4 out of 5\ncommunity-level outcome predictions over prior state-of-the-art for\nincorporating socio-demographic contexts.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 18:23:56 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Zamani", "Mohammadzaman", ""], ["Schwartz", "H. Andrew", ""], ["Lynn", "Veronica E.", ""], ["Giorgi", "Salvatore", ""], ["Balasubramanian", "Niranjan", ""]]}, {"id": "1808.09492", "submitter": "Jianmo Ni", "authors": "Jianmo Ni, Chenguang Zhu, Weizhu Chen, Julian McAuley", "title": "Learning to Attend On Essential Terms: An Enhanced Retriever-Reader\n  Model for Open-domain Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-domain question answering remains a challenging task as it requires\nmodels that are capable of understanding questions and answers, collecting\nuseful information, and reasoning over evidence. Previous work typically\nformulates this task as a reading comprehension or entailment problem given\nevidence retrieved from search engines. However, existing techniques struggle\nto retrieve indirectly related evidence when no directly related evidence is\nprovided, especially for complex questions where it is hard to parse precisely\nwhat the question asks. In this paper we propose a retriever-reader model that\nlearns to attend on essential terms during the question answering process. We\nbuild (1) an essential term selector which first identifies the most important\nwords in a question, then reformulates the query and searches for related\nevidence; and (2) an enhanced reader that distinguishes between essential terms\nand distracting words to predict the answer. We evaluate our model on multiple\nopen-domain multiple-choice QA datasets, notably performing at the level of the\nstate-of-the-art on the AI2 Reasoning Challenge (ARC) dataset.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 18:48:30 GMT"}, {"version": "v2", "created": "Thu, 30 Aug 2018 01:08:29 GMT"}, {"version": "v3", "created": "Wed, 5 Sep 2018 19:23:15 GMT"}, {"version": "v4", "created": "Tue, 2 Oct 2018 20:46:35 GMT"}, {"version": "v5", "created": "Thu, 9 May 2019 21:35:02 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Ni", "Jianmo", ""], ["Zhu", "Chenguang", ""], ["Chen", "Weizhu", ""], ["McAuley", "Julian", ""]]}, {"id": "1808.09500", "submitter": "Aditi Chaudhary", "authors": "Aditi Chaudhary, Chunting Zhou, Lori Levin, Graham Neubig, David R.\n  Mortensen, Jaime G. Carbonell", "title": "Adapting Word Embeddings to New Languages with Morphological and\n  Phonological Subword Representations", "comments": "Accepted at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much work in Natural Language Processing (NLP) has been for resource-rich\nlanguages, making generalization to new, less-resourced languages challenging.\nWe present two approaches for improving generalization to low-resourced\nlanguages by adapting continuous word representations using linguistically\nmotivated subword units: phonemes, morphemes and graphemes. Our method requires\nneither parallel corpora nor bilingual dictionaries and provides a significant\ngain in performance over previous methods relying on these resources. We\ndemonstrate the effectiveness of our approaches on Named Entity Recognition for\nfour languages, namely Uyghur, Turkish, Bengali and Hindi, of which Uyghur and\nBengali are low resource languages, and also perform experiments on Machine\nTranslation. Exploiting subwords with transfer learning gives us a boost of\n+15.2 NER F1 for Uyghur and +9.7 F1 for Bengali. We also show improvements in\nthe monolingual setting where we achieve (avg.) +3 F1 and (avg.) +1.35 BLEU.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 19:11:20 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Chaudhary", "Aditi", ""], ["Zhou", "Chunting", ""], ["Levin", "Lori", ""], ["Neubig", "Graham", ""], ["Mortensen", "David R.", ""], ["Carbonell", "Jaime G.", ""]]}, {"id": "1808.09502", "submitter": "Lucy H. Lin", "authors": "Lucy H. Lin, Scott Miles, Noah A. Smith", "title": "Semantic Matching Against a Corpus: New Applications and Methods", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the case of a domain expert who wishes to explore the extent to\nwhich a particular idea is expressed in a text collection. We propose the task\nof semantically matching the idea, expressed as a natural language proposition,\nagainst a corpus. We create two preliminary tasks derived from existing\ndatasets, and then introduce a more realistic one on disaster recovery designed\nfor emergency managers, whom we engaged in a user study. On the latter, we find\nthat a new model built from natural language entailment data produces\nhigher-quality matches than simple word-vector averaging, both on\nexpert-crafted queries and on ones produced by the subjects themselves. This\nwork provides a proof-of-concept for such applications of semantic matching and\nillustrates key challenges.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 19:15:57 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Lin", "Lucy H.", ""], ["Miles", "Scott", ""], ["Smith", "Noah A.", ""]]}, {"id": "1808.09522", "submitter": "Jinyu Li", "authors": "Jinyu Li, Changliang Liu, Yifan Gong", "title": "Layer Trajectory LSTM", "comments": "Accepted at Interspeech 2018. Note the computational cost in Table 2\n  in the original Interspeech publication was doubled. Please refer this\n  publication for the right computational cost", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is popular to stack LSTM layers to get better modeling power, especially\nwhen large amount of training data is available. However, an LSTM-RNN with too\nmany vanilla LSTM layers is very hard to train and there still exists the\ngradient vanishing issue if the network goes too deep. This issue can be\npartially solved by adding skip connections between layers, such as residual\nLSTM. In this paper, we propose a layer trajectory LSTM (ltLSTM) which builds a\nlayer-LSTM using all the layer outputs from a standard multi-layer time-LSTM.\nThis layer-LSTM scans the outputs from time-LSTMs, and uses the summarized\nlayer trajectory information for final senone classification. The\nforward-propagation of time-LSTM and layer-LSTM can be handled in two separate\nthreads in parallel so that the network computation time is the same as the\nstandard time-LSTM. With a layer-LSTM running through layers, a gated path is\nprovided from the output layer to the bottom layer, alleviating the gradient\nvanishing issue. Trained with 30 thousand hours of EN-US Microsoft internal\ndata, the proposed ltLSTM performed significantly better than the standard\nmulti-layer LSTM and residual LSTM, with up to 9.0% relative word error rate\nreduction across different tasks.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 20:13:18 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Li", "Jinyu", ""], ["Liu", "Changliang", ""], ["Gong", "Yifan", ""]]}, {"id": "1808.09542", "submitter": "Noah Weber", "authors": "Noah Weber, Leena Shekhar, Niranjan Balasubramanian, Nathanael\n  Chambers", "title": "Hierarchical Quantized Representations for Script Generation", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scripts define knowledge about how everyday scenarios (such as going to a\nrestaurant) are expected to unfold. One of the challenges to learning scripts\nis the hierarchical nature of the knowledge. For example, a suspect arrested\nmight plead innocent or guilty, and a very different track of events is then\nexpected to happen. To capture this type of information, we propose an\nautoencoder model with a latent space defined by a hierarchy of categorical\nvariables. We utilize a recently proposed vector quantization based approach,\nwhich allows continuous embeddings to be associated with each latent variable\nvalue. This permits the decoder to softly decide what portions of the latent\nhierarchy to condition on by attending over the value embeddings for a given\nsetting. Our model effectively encodes and generates scripts, outperforming a\nrecent language modeling-based method on several standard tasks, and allowing\nthe autoencoder model to achieve substantially lower perplexity scores compared\nto the previous language modeling-based method.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 20:53:56 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Weber", "Noah", ""], ["Shekhar", "Leena", ""], ["Balasubramanian", "Niranjan", ""], ["Chambers", "Nathanael", ""]]}, {"id": "1808.09543", "submitter": "Sanket Vaibhav Mehta", "authors": "Sanket Vaibhav Mehta, Jay Yoon Lee, Jaime Carbonell", "title": "Towards Semi-Supervised Learning for Deep Semantic Role Labeling", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural models have shown several state-of-the-art performances on Semantic\nRole Labeling (SRL). However, the neural models require an immense amount of\nsemantic-role corpora and are thus not well suited for low-resource languages\nor domains. The paper proposes a semi-supervised semantic role labeling method\nthat outperforms the state-of-the-art in limited SRL training corpora. The\nmethod is based on explicitly enforcing syntactic constraints by augmenting the\ntraining objective with a syntactic-inconsistency loss component and uses\nSRL-unlabeled instances to train a joint-objective LSTM. On CoNLL-2012 English\nsection, the proposed semi-supervised training with 1%, 10% SRL-labeled data\nand varying amounts of SRL-unlabeled data achieves +1.58, +0.78 F1,\nrespectively, over the pre-trained models that were trained on SOTA\narchitecture with ELMo on the same SRL-labeled data. Additionally, by using the\nsyntactic-inconsistency loss on inference time, the proposed model achieves\n+3.67, +2.1 F1 over pre-trained model on 1%, 10% SRL-labeled data,\nrespectively.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 20:55:41 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Mehta", "Sanket Vaibhav", ""], ["Lee", "Jay Yoon", ""], ["Carbonell", "Jaime", ""]]}, {"id": "1808.09551", "submitter": "Fr\\'ederic Godin", "authors": "Fr\\'ederic Godin, Kris Demuynck, Joni Dambre, Wesley De Neve and\n  Thomas Demeester", "title": "Explaining Character-Aware Neural Networks for Word-Level Prediction: Do\n  They Discover Linguistic Rules?", "comments": "Accepted at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Character-level features are currently used in different neural network-based\nnatural language processing algorithms. However, little is known about the\ncharacter-level patterns those models learn. Moreover, models are often\ncompared only quantitatively while a qualitative analysis is missing. In this\npaper, we investigate which character-level patterns neural networks learn and\nif those patterns coincide with manually-defined word segmentations and\nannotations. To that end, we extend the contextual decomposition technique\n(Murdoch et al. 2018) to convolutional neural networks which allows us to\ncompare convolutional neural networks and bidirectional long short-term memory\nnetworks. We evaluate and compare these models for the task of morphological\ntagging on three morphologically different languages and show that these models\nimplicitly discover understandable linguistic rules. Our implementation can be\nfound at https://github.com/FredericGodin/ContextualDecomposition-NLP .\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 21:44:26 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Godin", "Fr\u00e9deric", ""], ["Demuynck", "Kris", ""], ["Dambre", "Joni", ""], ["De Neve", "Wesley", ""], ["Demeester", "Thomas", ""]]}, {"id": "1808.09564", "submitter": "Renjie Zheng", "authors": "Renjie Zheng, Mingbo Ma and Liang Huang", "title": "Multi-Reference Training with Pseudo-References for Neural Translation\n  and Text Generation", "comments": "10 pages", "journal-ref": "Published in EMNLP 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural text generation, including neural machine translation, image\ncaptioning, and summarization, has been quite successful recently. However,\nduring training time, typically only one reference is considered for each\nexample, even though there are often multiple references available, e.g., 4\nreferences in NIST MT evaluations, and 5 references in image captioning data.\nWe first investigate several different ways of utilizing multiple human\nreferences during training. But more importantly, we then propose an algorithm\nto generate exponentially many pseudo-references by first compressing existing\nhuman references into lattices and then traversing them to generate new\npseudo-references. These approaches lead to substantial improvements over\nstrong baselines in both machine translation (+1.5 BLEU) and image captioning\n(+3.1 BLEU / +11.7 CIDEr).\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 22:30:11 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Zheng", "Renjie", ""], ["Ma", "Mingbo", ""], ["Huang", "Liang", ""]]}, {"id": "1808.09582", "submitter": "Yilin Yang", "authors": "Yilin Yang, Liang Huang, Mingbo Ma", "title": "Breaking the Beam Search Curse: A Study of (Re-)Scoring Methods and\n  Stopping Criteria for Neural Machine Translation", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beam search is widely used in neural machine translation, and usually\nimproves translation quality compared to greedy search. It has been widely\nobserved that, however, beam sizes larger than 5 hurt translation quality. We\nexplain why this happens, and propose several methods to address this problem.\nFurthermore, we discuss the optimal stopping criteria for these methods.\nResults show that our hyperparameter-free methods outperform the widely-used\nhyperparameter-free heuristic of length normalization by +2.0 BLEU, and achieve\nthe best results among all methods on Chinese-to-English translation.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 23:50:22 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 05:14:35 GMT"}, {"version": "v3", "created": "Sat, 27 Oct 2018 00:19:00 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Yang", "Yilin", ""], ["Huang", "Liang", ""], ["Ma", "Mingbo", ""]]}, {"id": "1808.09586", "submitter": "Mee Seong Im", "authors": "Venkat R. Dasari, Mee Seong Im, Billy Geerhart", "title": "Complexity and mission computability of adaptive computing systems", "comments": "6 pages, 3 figures, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC cs.CL cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a subset of computational problems that are computable in polynomial\ntime for which an existing algorithm may not complete due to a lack of high\nperformance technology on a mission field. We define a subclass of\ndeterministic polynomial time complexity class called mission class, as many\npolynomial problems are not computable in mission time. By focusing on such\nsubclass of languages in the context for successful military applications, we\nalso discuss their computational and communicational constraints. We\ninvestigate feasible (non)linear models that will minimize energy and maximize\nmemory, efficiency, and computational power, and also provide an approximate\nsolution obtained within a pre-determined length of computation time using\nlimited resources so that an optimal solution to a language could be\ndetermined.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 00:03:04 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Dasari", "Venkat R.", ""], ["Im", "Mee Seong", ""], ["Geerhart", "Billy", ""]]}, {"id": "1808.09588", "submitter": "Srinivasan Iyer", "authors": "Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, Luke Zettlemoyer", "title": "Mapping Language to Code in Programmatic Context", "comments": "Accepted at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Source code is rarely written in isolation. It depends significantly on the\nprogrammatic context, such as the class that the code would reside in. To study\nthis phenomenon, we introduce the task of generating class member functions\ngiven English documentation and the programmatic context provided by the rest\nof the class. This task is challenging because the desired code can vary\ngreatly depending on the functionality the class provides (e.g., a sort\nfunction may or may not be available when we are asked to \"return the smallest\nelement\" in a particular member variable list). We introduce CONCODE, a new\nlarge dataset with over 100,000 examples consisting of Java classes from online\ncode repositories, and develop a new encoder-decoder architecture that models\nthe interaction between the method documentation and the class environment. We\nalso present a detailed error analysis suggesting that there is significant\nroom for future work on this task.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 00:08:25 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Iyer", "Srinivasan", ""], ["Konstas", "Ioannis", ""], ["Cheung", "Alvin", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1808.09602", "submitter": "Yi Luan", "authors": "Yi Luan, Luheng He, Mari Ostendorf and Hannaneh Hajishirzi", "title": "Multi-Task Identification of Entities, Relations, and Coreference for\n  Scientific Knowledge Graph Construction", "comments": null, "journal-ref": "EMNLP 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a multi-task setup of identifying and classifying entities,\nrelations, and coreference clusters in scientific articles. We create SciERC, a\ndataset that includes annotations for all three tasks and develop a unified\nframework called Scientific Information Extractor (SciIE) for with shared span\nrepresentations. The multi-task setup reduces cascading errors between tasks\nand leverages cross-sentence relations through coreference links. Experiments\nshow that our multi-task model outperforms previous models in scientific\ninformation extraction without using any domain-specific features. We further\nshow that the framework supports construction of a scientific knowledge graph,\nwhich we use to analyze information in scientific literature.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 01:53:12 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Luan", "Yi", ""], ["He", "Luheng", ""], ["Ostendorf", "Mari", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "1808.09633", "submitter": "Dinghan Shen", "authors": "Dinghan Shen, Xinyuan Zhang, Ricardo Henao, Lawrence Carin", "title": "Improved Semantic-Aware Network Embedding with Fine-Grained Word\n  Alignment", "comments": "To appear at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embeddings, which learn low-dimensional representations for each\nvertex in a large-scale network, have received considerable attention in recent\nyears. For a wide range of applications, vertices in a network are typically\naccompanied by rich textual information such as user profiles, paper abstracts,\netc. We propose to incorporate semantic features into network embeddings by\nmatching important words between text sequences for all pairs of vertices. We\nintroduce a word-by-word alignment framework that measures the compatibility of\nembeddings between word pairs, and then adaptively accumulates these alignment\nfeatures with a simple yet effective aggregation function. In experiments, we\nevaluate the proposed framework on three real-world benchmarks for downstream\ntasks, including link prediction and multi-label vertex classification. Results\ndemonstrate that our model outperforms state-of-the-art network embedding\nmethods by a large margin.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 04:23:02 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Shen", "Dinghan", ""], ["Zhang", "Xinyuan", ""], ["Henao", "Ricardo", ""], ["Carin", "Lawrence", ""]]}, {"id": "1808.09634", "submitter": "Wen-Chin Huang", "authors": "Wen-Chin Huang, Hsin-Te Hwang, Yu-Huai Peng, Yu Tsao, Hsin-Min Wang", "title": "Voice Conversion Based on Cross-Domain Features Using Variational Auto\n  Encoders", "comments": "Accepted to ISCSLP 2018", "journal-ref": null, "doi": "10.1109/ISCSLP.2018.8706604", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An effective approach to non-parallel voice conversion (VC) is to utilize\ndeep neural networks (DNNs), specifically variational auto encoders (VAEs), to\nmodel the latent structure of speech in an unsupervised manner. A previous\nstudy has confirmed the ef- fectiveness of VAE using the STRAIGHT spectra for\nVC. How- ever, VAE using other types of spectral features such as mel- cepstral\ncoefficients (MCCs), which are related to human per- ception and have been\nwidely used in VC, have not been prop- erly investigated. Instead of using one\nspecific type of spectral feature, it is expected that VAE may benefit from\nusing multi- ple types of spectral features simultaneously, thereby improving\nthe capability of VAE for VC. To this end, we propose a novel VAE framework\n(called cross-domain VAE, CDVAE) for VC. Specifically, the proposed framework\nutilizes both STRAIGHT spectra and MCCs by explicitly regularizing multiple\nobjectives in order to constrain the behavior of the learned encoder and de-\ncoder. Experimental results demonstrate that the proposed CD- VAE framework\noutperforms the conventional VAE framework in terms of subjective tests.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 04:32:42 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Huang", "Wen-Chin", ""], ["Hwang", "Hsin-Te", ""], ["Peng", "Yu-Huai", ""], ["Tsao", "Yu", ""], ["Wang", "Hsin-Min", ""]]}, {"id": "1808.09637", "submitter": "He He", "authors": "He He and Derek Chen and Anusha Balakrishnan and Percy Liang", "title": "Decoupling Strategy and Generation in Negotiation Dialogues", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We consider negotiation settings in which two agents use natural language to\nbargain on goods. Agents need to decide on both high-level strategy (e.g.,\nproposing \\$50) and the execution of that strategy (e.g., generating \"The bike\nis brand new. Selling for just \\$50.\"). Recent work on negotiation trains\nneural models, but their end-to-end nature makes it hard to control their\nstrategy, and reinforcement learning tends to lead to degenerate solutions. In\nthis paper, we propose a modular approach based on coarse di- alogue acts\n(e.g., propose(price=50)) that decouples strategy and generation. We show that\nwe can flexibly set the strategy using supervised learning, reinforcement\nlearning, or domain-specific knowledge without degeneracy, while our\nretrieval-based generation can maintain context-awareness and produce diverse\nutterances. We test our approach on the recently proposed DEALORNODEAL game,\nand we also collect a richer dataset based on real items on Craigslist. Human\nevaluation shows that our systems achieve higher task success rate and more\nhuman-like negotiation behavior than previous approaches.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 04:59:15 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["He", "He", ""], ["Chen", "Derek", ""], ["Balakrishnan", "Anusha", ""], ["Liang", "Percy", ""]]}, {"id": "1808.09644", "submitter": "Haoyue Shi", "authors": "Haoyue Shi, Hao Zhou, Jiaze Chen, Lei Li", "title": "On Tree-Based Neural Sentence Modeling", "comments": "To Appear at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks with tree-based sentence encoders have shown better results\non many downstream tasks. Most of existing tree-based encoders adopt syntactic\nparsing trees as the explicit structure prior. To study the effectiveness of\ndifferent tree structures, we replace the parsing trees with trivial trees\n(i.e., binary balanced tree, left-branching tree and right-branching tree) in\nthe encoders. Though trivial trees contain no syntactic information, those\nencoders get competitive or even better results on all of the ten downstream\ntasks we investigated. This surprising result indicates that explicit syntax\nguidance may not be the main contributor to the superior performances of\ntree-based neural sentence modeling. Further analysis show that tree modeling\ngives better results when crucial words are closer to the final representation.\nAdditional experiments give more clues on how to design an effective tree-based\nencoder. Our code is open-source and available at\nhttps://github.com/ExplorerFreda/TreeEnc.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 05:32:17 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Shi", "Haoyue", ""], ["Zhou", "Hao", ""], ["Chen", "Jiaze", ""], ["Li", "Lei", ""]]}, {"id": "1808.09648", "submitter": "Avikalp Srivastava", "authors": "Avikalp Srivastava, Hsin Wen Liu, Sumio Fujita", "title": "Adapting Visual Question Answering Models for Enhancing Multimodal\n  Community Q&A Platforms", "comments": "Submitted for review at CIKM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question categorization and expert retrieval methods have been crucial for\ninformation organization and accessibility in community question & answering\n(CQA) platforms. Research in this area, however, has dealt with only the text\nmodality. With the increasing multimodal nature of web content, we focus on\nextending these methods for CQA questions accompanied by images. Specifically,\nwe leverage the success of representation learning for text and images in the\nvisual question answering (VQA) domain, and adapt the underlying concept and\narchitecture for automated category classification and expert retrieval on\nimage-based questions posted on Yahoo! Chiebukuro, the Japanese counterpart of\nYahoo! Answers.\n  To the best of our knowledge, this is the first work to tackle the\nmultimodality challenge in CQA, and to adapt VQA models for tasks on a more\necologically valid source of visual questions. Our analysis of the differences\nbetween visual QA and community QA data drives our proposal of novel\naugmentations of an attention method tailored for CQA, and use of auxiliary\ntasks for learning better grounding features. Our final model markedly\noutperforms the text-only and VQA model baselines for both tasks of\nclassification and expert retrieval on real-world multimodal CQA data.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 05:53:17 GMT"}, {"version": "v2", "created": "Sat, 25 May 2019 20:24:44 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Srivastava", "Avikalp", ""], ["Liu", "Hsin Wen", ""], ["Fujita", "Sumio", ""]]}, {"id": "1808.09653", "submitter": "Ge Gao", "authors": "Ge Gao, Eunsol Choi, Yejin Choi, and Luke Zettlemoyer", "title": "Neural Metaphor Detection in Context", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present end-to-end neural models for detecting metaphorical word use in\ncontext. We show that relatively standard BiLSTM models which operate on\ncomplete sentences work well in this setting, in comparison to previous work\nthat used more restricted forms of linguistic context. These models establish a\nnew state-of-the-art on existing verb metaphor detection benchmarks, and show\nstrong performance on jointly predicting the metaphoricity of all words in a\nrunning text.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 06:32:47 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Gao", "Ge", ""], ["Choi", "Eunsol", ""], ["Choi", "Yejin", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1808.09658", "submitter": "Yang Gao", "authors": "Yang Gao, Christian M. Meyer, Iryna Gurevych", "title": "APRIL: Interactively Learning to Summarise by Combining Active\n  Preference Learning and Reinforcement Learning", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to perform automatic document summarisation without using\nreference summaries. Instead, our method interactively learns from users'\npreferences. The merit of preference-based interactive summarisation is that\npreferences are easier for users to provide than reference summaries. Existing\npreference-based interactive learning methods suffer from high sample\ncomplexity, i.e. they need to interact with the oracle for many rounds in order\nto converge. In this work, we propose a new objective function, which enables\nus to leverage active learning, preference learning and reinforcement learning\ntechniques in order to reduce the sample complexity. Both simulation and\nreal-user experiments suggest that our method significantly advances the state\nof the art. Our source code is freely available at\nhttps://github.com/UKPLab/emnlp2018-april.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 06:49:49 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Gao", "Yang", ""], ["Meyer", "Christian M.", ""], ["Gurevych", "Iryna", ""]]}, {"id": "1808.09663", "submitter": "Sidak Pal Singh", "authors": "Sidak Pal Singh, Andreas Hug, Aymeric Dieuleveut, Martin Jaggi", "title": "Context Mover's Distance & Barycenters: Optimal Transport of Contexts\n  for Building Representations", "comments": "AISTATS 2020. Also, accepted previously at ICLR 2019 DeepGenStruct\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a framework for building unsupervised representations of entities\nand their compositions, where each entity is viewed as a probability\ndistribution rather than a vector embedding. In particular, this distribution\nis supported over the contexts which co-occur with the entity and are embedded\nin a suitable low-dimensional space. This enables us to consider representation\nlearning from the perspective of Optimal Transport and take advantage of its\ntools such as Wasserstein distance and barycenters. We elaborate how the method\ncan be applied for obtaining unsupervised representations of text and\nillustrate the performance (quantitatively as well as qualitatively) on tasks\nsuch as measuring sentence similarity, word entailment and similarity, where we\nempirically observe significant gains (e.g., 4.1% relative improvement over\nSent2vec, GenSen).\n  The key benefits of the proposed approach include: (a) capturing uncertainty\nand polysemy via modeling the entities as distributions, (b) utilizing the\nunderlying geometry of the particular task (with the ground cost), (c)\nsimultaneously providing interpretability with the notion of optimal transport\nbetween contexts and (d) easy applicability on top of existing point embedding\nmethods. The code, as well as prebuilt histograms, are available under\nhttps://github.com/context-mover/.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 07:18:29 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 10:02:56 GMT"}, {"version": "v3", "created": "Thu, 20 Dec 2018 21:18:56 GMT"}, {"version": "v4", "created": "Sat, 23 Mar 2019 01:18:50 GMT"}, {"version": "v5", "created": "Tue, 13 Aug 2019 15:45:32 GMT"}, {"version": "v6", "created": "Sat, 29 Feb 2020 18:04:45 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Singh", "Sidak Pal", ""], ["Hug", "Andreas", ""], ["Dieuleveut", "Aymeric", ""], ["Jaggi", "Martin", ""]]}, {"id": "1808.09688", "submitter": "Felix Stahlberg", "authors": "Felix Stahlberg, Danielle Saunders, Bill Byrne", "title": "An Operation Sequence Model for Explainable Neural Machine Translation", "comments": "BlackboxNLP workshop at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to achieve explainable neural machine translation (NMT) by\nchanging the output representation to explain itself. We present a novel\napproach to NMT which generates the target sentence by monotonically walking\nthrough the source sentence. Word reordering is modeled by operations which\nallow setting markers in the target sentence and move a target-side write head\nbetween those markers. In contrast to many modern neural models, our system\nemits explicit word alignment information which is often crucial to practical\nmachine translation as it improves explainability. Our technique can outperform\na plain text system in terms of BLEU score under the recent Transformer\narchitecture on Japanese-English and Portuguese-English, and is within 0.5 BLEU\ndifference on Spanish-English.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 08:56:42 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Stahlberg", "Felix", ""], ["Saunders", "Danielle", ""], ["Byrne", "Bill", ""]]}, {"id": "1808.09716", "submitter": "Mostafa Abdou", "authors": "Mostafa Abdou, Artur Kulmizev, Vinit Ravishankar, Lasha Abzianidze,\n  and Johan Bos", "title": "What can we learn from Semantic Tagging?", "comments": "9 pages with references and appendixes. EMNLP 2018 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the effects of multi-task learning using the recently\nintroduced task of semantic tagging. We employ semantic tagging as an auxiliary\ntask for three different NLP tasks: part-of-speech tagging, Universal\nDependency parsing, and Natural Language Inference. We compare full neural\nnetwork sharing, partial neural network sharing, and what we term the learning\nwhat to share setting where negative transfer between tasks is less likely. Our\nfindings show considerable improvements for all tasks, particularly in the\nlearning what to share setting, which shows consistent gains across all tasks.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 10:30:03 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Abdou", "Mostafa", ""], ["Kulmizev", "Artur", ""], ["Ravishankar", "Vinit", ""], ["Abzianidze", "Lasha", ""], ["Bos", "Johan", ""]]}, {"id": "1808.09718", "submitter": "Yi-Ting Huang", "authors": "Yi-Ting Huang, Meng Chang Chen, Yeali S. Sun", "title": "Characterizing the Influence of Features on Reading Difficulty\n  Estimation for Non-native Readers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the number of people studying English as a second language\n(ESL) has surpassed the number of native speakers. Recent work have\ndemonstrated the success of providing personalized content based on reading\ndifficulty, such as information retrieval and summarization. However, almost\nall prior studies of reading difficulty are designed for native speakers,\nrather than non-native readers. In this study, we investigate various features\nfor ESL readers, by conducting a linear regression to estimate the reading\nlevel of English language sources. This estimation is based not only on the\ncomplexity of lexical and syntactic features, but also several novel concepts,\nincluding the age of word and grammar acquisition from several sources, word\nsense from WordNet, and the implicit relation between sentences. By employing\nBayesian Information Criterion (BIC) to select the optimal model, we find that\nthe combination of the number of words, the age of word acquisition and the\nheight of the parsing tree generate better results than alternative competing\nmodels. Thus, our results show that proposed second language reading difficulty\nestimation outperforms other first language reading difficulty estimations.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 10:32:24 GMT"}], "update_date": "2018-09-04", "authors_parsed": [["Huang", "Yi-Ting", ""], ["Chen", "Meng Chang", ""], ["Sun", "Yeali S.", ""]]}, {"id": "1808.09722", "submitter": "Bennett Kleinberg", "authors": "Bennett Kleinberg, Maximilian Mozes, Isabelle van der Vegt", "title": "Identifying the sentiment styles of YouTube's vloggers", "comments": "10 pages, EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vlogs provide a rich public source of data in a novel setting. This paper\nexamined the continuous sentiment styles employed in 27,333 vlogs using a\ndynamic intra-textual approach to sentiment analysis. Using unsupervised\nclustering, we identified seven distinct continuous sentiment trajectories\ncharacterized by fluctuations of sentiment throughout a vlog's narrative time.\nWe provide a taxonomy of these seven continuous sentiment styles and found that\nvlogs whose sentiment builds up towards a positive ending are the most\nprevalent in our sample. Gender was associated with preferences for different\ncontinuous sentiment trajectories. This paper discusses the findings with\nrespect to previous work and concludes with an outlook towards possible uses of\nthe corpus, method and findings of this paper for related areas of research.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 10:45:45 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Kleinberg", "Bennett", ""], ["Mozes", "Maximilian", ""], ["van der Vegt", "Isabelle", ""]]}, {"id": "1808.09732", "submitter": "Yi-Ting Huang", "authors": "Yi-Ting Huang, Meng Chang Chen, Yeali S. Sun", "title": "Development and Evaluation of a Personalized Computer-aided Question\n  Generation for English Learners to Improve Proficiency and Correct Mistakes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last several years, the field of computer assisted language learning\nhas increasingly focused on computer aided question generation. However, this\napproach often provides test takers with an exhaustive amount of questions that\nare not designed for any specific testing purpose. In this work, we present a\npersonalized computer aided question generation that generates multiple choice\nquestions at various difficulty levels and types, including vocabulary, grammar\nand reading comprehension. In order to improve the weaknesses of test takers,\nit selects questions depending on an estimated proficiency level and unclear\nconcepts behind incorrect responses. This results show that the students with\nthe personalized automatic quiz generation corrected their mistakes more\nfrequently than ones only with computer aided question generation. Moreover,\nstudents demonstrated the most progress between the pretest and post test and\ncorrectly answered more difficult questions. Finally, we investigated the\npersonalizing strategy and found that a student could make a significant\nprogress if the proposed system offered the vocabulary questions at the same\nlevel of his or her proficiency level, and if the grammar and reading\ncomprehension questions were at a level lower than his or her proficiency\nlevel.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 11:26:07 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Huang", "Yi-Ting", ""], ["Chen", "Meng Chang", ""], ["Sun", "Yeali S.", ""]]}, {"id": "1808.09733", "submitter": "Barbara Plank", "authors": "Barbara Plank and \\v{Z}eljko Agi\\'c", "title": "Distant Supervision from Disparate Sources for Low-Resource\n  Part-of-Speech Tagging", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce DsDs: a cross-lingual neural part-of-speech tagger that learns\nfrom disparate sources of distant supervision, and realistically scales to\nhundreds of low-resource languages. The model exploits annotation projection,\ninstance selection, tag dictionaries, morphological lexicons, and distributed\nrepresentations, all in a uniform framework. The approach is simple, yet\nsurprisingly effective, resulting in a new state of the art without access to\nany gold annotated data.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 11:30:22 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Plank", "Barbara", ""], ["Agi\u0107", "\u017deljko", ""]]}, {"id": "1808.09744", "submitter": "Madhumita Sushil", "authors": "Madhumita Sushil and Simon \\v{S}uster and Walter Daelemans", "title": "Rule induction for global explanation of trained models", "comments": "Accepted at the Workshop on 'Analyzing and interpreting neural\n  networks for NLP' (BlackboxNLP), EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the behavior of a trained network and finding explanations for\nits outputs is important for improving the network's performance and\ngeneralization ability, and for ensuring trust in automated systems. Several\napproaches have previously been proposed to identify and visualize the most\nimportant features by analyzing a trained network. However, the relations\nbetween different features and classes are lost in most cases. We propose a\ntechnique to induce sets of if-then-else rules that capture these relations to\nglobally explain the predictions of a network. We first calculate the\nimportance of the features in the trained network. We then weigh the original\ninputs with these feature importance scores, simplify the transformed input\nspace, and finally fit a rule induction model to explain the model predictions.\nWe find that the output rule-sets can explain the predictions of a neural\nnetwork trained for 4-class text classification from the 20 newsgroups dataset\nto a macro-averaged F-score of 0.80. We make the code available at\nhttps://github.com/clips/interpret_with_rules.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 12:02:11 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Sushil", "Madhumita", ""], ["\u0160uster", "Simon", ""], ["Daelemans", "Walter", ""]]}, {"id": "1808.09772", "submitter": "Antoine Tixier", "authors": "Antoine J.-P. Tixier", "title": "Notes on Deep Learning for NLP", "comments": "work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  My notes on Deep Learning for NLP.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 12:58:45 GMT"}, {"version": "v2", "created": "Thu, 30 Aug 2018 17:44:54 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Tixier", "Antoine J. -P.", ""]]}, {"id": "1808.09861", "submitter": "Jiateng Xie", "authors": "Jiateng Xie, Zhilin Yang, Graham Neubig, Noah A. Smith, and Jaime\n  Carbonell", "title": "Neural Cross-Lingual Named Entity Recognition with Minimal Resources", "comments": "EMNLP 2018 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For languages with no annotated resources, unsupervised transfer of natural\nlanguage processing models such as named-entity recognition (NER) from\nresource-rich languages would be an appealing capability. However, differences\nin words and word order across languages make it a challenging problem. To\nimprove mapping of lexical items across languages, we propose a method that\nfinds translations based on bilingual word embeddings. To improve robustness to\nword order differences, we propose to use self-attention, which allows for a\ndegree of flexibility with respect to word order. We demonstrate that these\nmethods achieve state-of-the-art or competitive NER performance on commonly\ntested languages under a cross-lingual setting, with much lower resource\nrequirements than past approaches. We also evaluate the challenges of applying\nthese methods to Uyghur, a low-resource language.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 14:55:31 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 22:32:41 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Xie", "Jiateng", ""], ["Yang", "Zhilin", ""], ["Neubig", "Graham", ""], ["Smith", "Noah A.", ""], ["Carbonell", "Jaime", ""]]}, {"id": "1808.09888", "submitter": "Shi Yin", "authors": "Shi Yin, Yi Zhou, Chenguang Li, Shangfei Wang, Jianmin Ji, Xiaoping\n  Chen, Ruili Wang", "title": "KDSL: a Knowledge-Driven Supervised Learning Framework for Word Sense\n  Disambiguation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose KDSL, a new word sense disambiguation (WSD) framework that\nutilizes knowledge to automatically generate sense-labeled data for supervised\nlearning. First, from WordNet, we automatically construct a semantic knowledge\nbase called DisDict, which provides refined feature words that highlight the\ndifferences among word senses, i.e., synsets. Second, we automatically generate\nnew sense-labeled data by DisDict from unlabeled corpora. Third, these\ngenerated data, together with manually labeled data and unlabeled data, are fed\nto a neural framework conducting supervised and unsupervised learning jointly\nto model the semantic relations among synsets, feature words and their\ncontexts. The experimental results show that KDSL outperforms several\nrepresentative state-of-the-art methods on various major benchmarks.\nInterestingly, it performs relatively well even when manually labeled data is\nunavailable, thus provides a potential solution for similar tasks in a lack of\nmanual annotations.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 12:20:37 GMT"}, {"version": "v2", "created": "Thu, 30 Aug 2018 04:01:52 GMT"}, {"version": "v3", "created": "Wed, 5 Sep 2018 00:47:51 GMT"}, {"version": "v4", "created": "Mon, 24 Sep 2018 07:31:08 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Yin", "Shi", ""], ["Zhou", "Yi", ""], ["Li", "Chenguang", ""], ["Wang", "Shangfei", ""], ["Ji", "Jianmin", ""], ["Chen", "Xiaoping", ""], ["Wang", "Ruili", ""]]}, {"id": "1808.09889", "submitter": "Javid Dadashkarimi", "authors": "Javid Dadashkarimi and Alexander Fabbri and Sekhar Tatikonda and\n  Dragomir R. Radev", "title": "Zero-shot Transfer Learning for Semantic Parsing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural networks have shown impressive performance on large datasets,\napplying these models to tasks where little data is available remains a\nchallenging problem.\n  In this paper we propose to use feature transfer in a zero-shot experimental\nsetting on the task of semantic parsing.\n  We first introduce a new method for learning the shared space between\nmultiple domains based on the prediction of the domain label for each example.\n  Our experiments support the superiority of this method in a zero-shot\nexperimental setting in terms of accuracy metrics compared to state-of-the-art\ntechniques.\n  In the second part of this paper we study the impact of individual domains\nand examples on semantic parsing performance.\n  We use influence functions to this aim and investigate the sensitivity of\ndomain-label classification loss on each example.\n  Our findings reveal that cross-domain adversarial attacks identify useful\nexamples for training even from the domains the least similar to the target\ndomain. Augmenting our training data with these influential examples further\nboosts our accuracy at both the token and the sequence level.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 16:12:36 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Dadashkarimi", "Javid", ""], ["Fabbri", "Alexander", ""], ["Tatikonda", "Sekhar", ""], ["Radev", "Dragomir R.", ""]]}, {"id": "1808.09890", "submitter": "Isak Czeresnia Etinger", "authors": "Isak Czeresnia Etinger", "title": "An Adaptive Conversational Bot Framework", "comments": "5 pages, Microsoft, \\'Ecole polytechnique", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we enable users to heavily specify criteria for database queries in a\nuser-friendly way? This paper describes a general framework of a conversational\nbot that extracts meaningful information from user's sentences, that asks\nsubsequent questions to complete missing information, and that adjusts its\nquestions and information-extraction parameters for later conversations\ndepending on users' behavior. Additionally, we provide a comparison of existing\ntools and give novel techniques to implement such framework. Finally, we\nexemplify the framework with a bot to query movies in a database, whose code is\navailable for Microsoft employees.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 21:37:42 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Etinger", "Isak Czeresnia", ""]]}, {"id": "1808.09891", "submitter": "Zhan Su", "authors": "Peng Zhang, Zhan Su, Lipeng Zhang, Benyou Wang, Dawei Song", "title": "A Quantum Many-body Wave Function Inspired Language Modeling Approach", "comments": "10 pages,4 figures,CIKM", "journal-ref": "The 27th ACM International Conference on Information and Knowledge\n  Management, October 22--26, 2018, Torino, Italy", "doi": "10.1145/3269206.3271723", "report-no": "fp0675", "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently proposed quantum language model (QLM) aimed at a principled\napproach to modeling term dependency by applying the quantum probability\ntheory. The latest development for a more effective QLM has adopted word\nembeddings as a kind of global dependency information and integrated the\nquantum-inspired idea in a neural network architecture. While these\nquantum-inspired LMs are theoretically more general and also practically\neffective, they have two major limitations. First, they have not taken into\naccount the interaction among words with multiple meanings, which is common and\nimportant in understanding natural language text. Second, the integration of\nthe quantum-inspired LM with the neural network was mainly for effective\ntraining of parameters, yet lacking a theoretical foundation accounting for\nsuch integration. To address these two issues, in this paper, we propose a\nQuantum Many-body Wave Function (QMWF) inspired language modeling approach. The\nQMWF inspired LM can adopt the tensor product to model the aforesaid\ninteraction among words. It also enables us to reveal the inherent necessity of\nusing Convolutional Neural Network (CNN) in QMWF language modeling.\nFurthermore, our approach delivers a simple algorithm to represent and match\ntext/sentence pairs. Systematic evaluation shows the effectiveness of the\nproposed QMWF-LM algorithm, in comparison with the state of the art\nquantum-inspired LMs and a couple of CNN-based methods, on three typical\nQuestion Answering (QA) datasets.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2018 13:39:44 GMT"}, {"version": "v2", "created": "Thu, 30 Aug 2018 02:34:18 GMT"}, {"version": "v3", "created": "Mon, 3 Sep 2018 14:23:37 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Zhang", "Peng", ""], ["Su", "Zhan", ""], ["Zhang", "Lipeng", ""], ["Wang", "Benyou", ""], ["Song", "Dawei", ""]]}, {"id": "1808.09896", "submitter": "Yinfei Yang", "authors": "Cen Chen, Minghui Qiu, Yinfei Yang, Jun Zhou, Jun Huang, Xiaolong Li,\n  Forrest Bao", "title": "Review Helpfulness Prediction with Embedding-Gated CNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Product reviews, in the form of texts dominantly, significantly help\nconsumers finalize their purchasing decisions. Thus, it is important for\ne-commerce companies to predict review helpfulness to present and recommend\nreviews in a more informative manner. In this work, we introduce a\nconvolutional neural network model that is able to extract abstract features\nfrom multi-granularity representations. Inspired by the fact that different\nwords contribute to the meaning of a sentence differently, we consider to learn\nword-level embedding-gates for all the representations. Furthermore, as it is\ncommon that some product domains/categories have rich user reviews, other\ndomains not. To help domains with less sufficient data, we integrate our model\ninto a cross-domain relationship learning framework for effectively\ntransferring knowledge from other domains. Extensive experiments show that our\nmodel yields better performance than the existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 15:52:06 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Chen", "Cen", ""], ["Qiu", "Minghui", ""], ["Yang", "Yinfei", ""], ["Zhou", "Jun", ""], ["Huang", "Jun", ""], ["Li", "Xiaolong", ""], ["Bao", "Forrest", ""]]}, {"id": "1808.09920", "submitter": "Nicola De Cao", "authors": "Nicola De Cao, Wilker Aziz, Ivan Titov", "title": "Question Answering by Reasoning Across Documents with Graph\n  Convolutional Networks", "comments": "To appear in Conference of the North American Chapter of the\n  Association for Computational Linguistics (NAACL), 2019. 13 pages, 3 figures,\n  6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most research in reading comprehension has focused on answering questions\nbased on individual documents or even single paragraphs. We introduce a neural\nmodel which integrates and reasons relying on information spread within\ndocuments and across multiple documents. We frame it as an inference problem on\na graph. Mentions of entities are nodes of this graph while edges encode\nrelations between different mentions (e.g., within- and cross-document\nco-reference). Graph convolutional networks (GCNs) are applied to these graphs\nand trained to perform multi-step reasoning. Our Entity-GCN method is scalable\nand compact, and it achieves state-of-the-art results on a multi-document\nquestion answering dataset, WikiHop (Welbl et al., 2018).\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 16:44:51 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 13:34:32 GMT"}, {"version": "v3", "created": "Sun, 7 Apr 2019 15:31:22 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["De Cao", "Nicola", ""], ["Aziz", "Wilker", ""], ["Titov", "Ivan", ""]]}, {"id": "1808.09930", "submitter": "Marten van Schijndel", "authors": "Marten van Schijndel and Tal Linzen", "title": "A Neural Model of Adaptation in Reading", "comments": "Accepted for presentation at EMNLP 2018 Updated with final\n  camera-ready version (more colorblind-friendly, better catastrophic\n  forgetting eval)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been argued that humans rapidly adapt their lexical and syntactic\nexpectations to match the statistics of the current linguistic context. We\nprovide further support to this claim by showing that the addition of a simple\nadaptation mechanism to a neural language model improves our predictions of\nhuman reading times compared to a non-adaptive model. We analyze the\nperformance of the model on controlled materials from psycholinguistic\nexperiments and show that it adapts not only to lexical items but also to\nabstract syntactic structures.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 17:10:47 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 19:22:10 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["van Schijndel", "Marten", ""], ["Linzen", "Tal", ""]]}, {"id": "1808.09942", "submitter": "Nitish Gupta", "authors": "Nitish Gupta and Mike Lewis", "title": "Neural Compositional Denotational Semantics for Question Answering", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering compositional questions requiring multi-step reasoning is\nchallenging. We introduce an end-to-end differentiable model for interpreting\nquestions about a knowledge graph (KG), which is inspired by formal approaches\nto semantics. Each span of text is represented by a denotation in a KG and a\nvector that captures ungrounded aspects of meaning. Learned composition modules\nrecursively combine constituent spans, culminating in a grounding for the\ncomplete sentence which answers the question. For example, to interpret \"not\ngreen\", the model represents \"green\" as a set of KG entities and \"not\" as a\ntrainable ungrounded vector---and then uses this vector to parameterize a\ncomposition function that performs a complement operation. For each sentence,\nwe build a parse chart subsuming all possible parses, allowing the model to\njointly learn both the composition operators and output structure by gradient\ndescent from end-task supervision. The model learns a variety of challenging\nsemantic operators, such as quantifiers, disjunctions and composed relations,\nand infers latent syntactic structure. It also generalizes well to longer\nquestions than seen in its training data, in contrast to RNN, its tree-based\nvariants, and semantic parsing baselines.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 17:43:11 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Gupta", "Nitish", ""], ["Lewis", "Mike", ""]]}, {"id": "1808.09943", "submitter": "Colin Cherry", "authors": "Colin Cherry and George Foster and Ankur Bapna and Orhan Firat and\n  Wolfgang Macherey", "title": "Revisiting Character-Based Neural Machine Translation with Capacity and\n  Compression", "comments": "To appear at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Translating characters instead of words or word-fragments has the potential\nto simplify the processing pipeline for neural machine translation (NMT), and\nimprove results by eliminating hyper-parameters and manual feature engineering.\nHowever, it results in longer sequences in which each symbol contains less\ninformation, creating both modeling and computational challenges. In this\npaper, we show that the modeling problem can be solved by standard\nsequence-to-sequence architectures of sufficient depth, and that deep models\noperating at the character level outperform identical models operating over\nword fragments. This result implies that alternative architectures for handling\ncharacter input are better viewed as methods for reducing computation time than\nas improved ways of modeling longer sequences. From this perspective, we\nevaluate several techniques for character-level NMT, verify that they do not\nmatch the performance of our deep character baseline model, and evaluate the\nperformance versus computation time tradeoffs they offer. Within this\nframework, we also perform the first evaluation for NMT of conditional\ncomputation over time, in which the model learns which timesteps can be\nskipped, rather than having them be dictated by a fixed schedule specified\nbefore training begins.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 17:46:50 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Cherry", "Colin", ""], ["Foster", "George", ""], ["Bapna", "Ankur", ""], ["Firat", "Orhan", ""], ["Macherey", "Wolfgang", ""]]}, {"id": "1808.09996", "submitter": "Jatin Ganhotra", "authors": "Janarthanan Rajendran, Jatin Ganhotra, Satinder Singh, Lazaros\n  Polymenakos", "title": "Learning End-to-End Goal-Oriented Dialog with Multiple Answers", "comments": "EMNLP 2018. permuted-bAbI dialog tasks are available at -\n  https://github.com/IBM/permuted-bAbI-dialog-tasks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In a dialog, there can be multiple valid next utterances at any point. The\npresent end-to-end neural methods for dialog do not take this into account.\nThey learn with the assumption that at any time there is only one correct next\nutterance. In this work, we focus on this problem in the goal-oriented dialog\nsetting where there are different paths to reach a goal. We propose a new\nmethod, that uses a combination of supervised learning and reinforcement\nlearning approaches to address this issue. We also propose a new and more\neffective testbed, permuted-bAbI dialog tasks, by introducing multiple valid\nnext utterances to the original-bAbI dialog tasks, which allows evaluation of\ngoal-oriented dialog systems in a more realistic setting. We show that there is\na significant drop in performance of existing end-to-end neural methods from\n81.5% per-dialog accuracy on original-bAbI dialog tasks to 30.3% on\npermuted-bAbI dialog tasks. We also show that our proposed method improves the\nperformance and achieves 47.3% per-dialog accuracy on permuted-bAbI dialog\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 19:24:58 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Rajendran", "Janarthanan", ""], ["Ganhotra", "Jatin", ""], ["Singh", "Satinder", ""], ["Polymenakos", "Lazaros", ""]]}, {"id": "1808.10000", "submitter": "Phu Mon Htut", "authors": "Phu Mon Htut, Kyunghyun Cho, Samuel R. Bowman", "title": "Grammar Induction with Neural Language Models: An Unusual Replication", "comments": "To appear in Proceedings of EMNLP 2018 (short paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A substantial thread of recent work on latent tree learning has attempted to\ndevelop neural network models with parse-valued latent variables and train them\non non-parsing tasks, in the hope of having them discover interpretable tree\nstructure. In a recent paper, Shen et al. (2018) introduce such a model and\nreport near-state-of-the-art results on the target task of language modeling,\nand the first strong latent tree learning result on constituency parsing. In an\nattempt to reproduce these results, we discover issues that make the original\nresults hard to trust, including tuning and even training on what is\neffectively the test set. Here, we attempt to reproduce these results in a fair\nexperiment and to extend them to two new datasets. We find that the results of\nthis work are robust: All variants of the model under study outperform all\nlatent tree learning baselines, and perform competitively with symbolic grammar\ninduction systems. We find that this model represents the first empirical\nsuccess for latent tree learning, and that neural network language modeling\nwarrants further study as a setting for grammar induction.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 18:21:50 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Htut", "Phu Mon", ""], ["Cho", "Kyunghyun", ""], ["Bowman", "Samuel R.", ""]]}, {"id": "1808.10006", "submitter": "Kenton Murray", "authors": "Kenton Murray and David Chiang", "title": "Correcting Length Bias in Neural Machine Translation", "comments": "WMT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two problems in neural machine translation (NMT). First, in beam\nsearch, whereas a wider beam should in principle help translation, it often\nhurts NMT. Second, NMT has a tendency to produce translations that are too\nshort. Here, we argue that these problems are closely related and both rooted\nin label bias. We show that correcting the brevity problem almost eliminates\nthe beam problem; we compare some commonly-used methods for doing this, finding\nthat a simple per-word reward works well; and we introduce a simple and quick\nway to tune this reward using the perceptron algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 18:33:11 GMT"}, {"version": "v2", "created": "Fri, 31 Aug 2018 21:59:35 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Murray", "Kenton", ""], ["Chiang", "David", ""]]}, {"id": "1808.10009", "submitter": "Aishwarya Padmakumar", "authors": "Aishwarya Padmakumar and Peter Stone and Raymond J. Mooney", "title": "Learning a Policy for Opportunistic Active Learning", "comments": "EMNLP 2018 Camera Ready", "journal-ref": "EMNLP 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning identifies data points to label that are expected to be the\nmost useful in improving a supervised model. Opportunistic active learning\nincorporates active learning into interactive tasks that constrain possible\nqueries during interactions. Prior work has shown that opportunistic active\nlearning can be used to improve grounding of natural language descriptions in\nan interactive object retrieval task. In this work, we use reinforcement\nlearning for such an object retrieval task, to learn a policy that effectively\ntrades off task completion with model improvement that would benefit future\ntasks.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 18:40:26 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Padmakumar", "Aishwarya", ""], ["Stone", "Peter", ""], ["Mooney", "Raymond J.", ""]]}, {"id": "1808.10024", "submitter": "Shijie Wu", "authors": "Shijie Wu, Pamela Shapiro, Ryan Cotterell", "title": "Hard Non-Monotonic Attention for Character-Level Transduction", "comments": "Published in EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Character-level string-to-string transduction is an important component of\nvarious NLP tasks. The goal is to map an input string to an output string,\nwhere the strings may be of different lengths and have characters taken from\ndifferent alphabets. Recent approaches have used sequence-to-sequence models\nwith an attention mechanism to learn which parts of the input string the model\nshould focus on during the generation of the output string. Both soft attention\nand hard monotonic attention have been used, but hard non-monotonic attention\nhas only been used in other sequence modeling tasks such as image captioning\nand has required a stochastic approximation to compute the gradient. In this\nwork, we introduce an exact, polynomial-time algorithm for marginalizing over\nthe exponential number of non-monotonic alignments between two strings, showing\nthat hard attention models can be viewed as neural reparameterizations of the\nclassical IBM Model 1. We compare soft and hard non-monotonic attention\nexperimentally and find that the exact algorithm significantly improves\nperformance over the stochastic approximation and outperforms soft attention.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 20:00:20 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 23:59:49 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Wu", "Shijie", ""], ["Shapiro", "Pamela", ""], ["Cotterell", "Ryan", ""]]}, {"id": "1808.10025", "submitter": "Shirley Anugrah Hayati", "authors": "Shirley Anugrah Hayati, Raphael Olivier, Pravalika Avvaru, Pengcheng\n  Yin, Anthony Tomasic, Graham Neubig", "title": "Retrieval-Based Neural Code Generation", "comments": "This paper is accepted in EMNLP 2018. It has 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In models to generate program source code from natural language, representing\nthis code in a tree structure has been a common approach. However, existing\nmethods often fail to generate complex code correctly due to a lack of ability\nto memorize large and complex structures. We introduce ReCode, a method based\non subtree retrieval that makes it possible to explicitly reference existing\ncode examples within a neural code generation model. First, we retrieve\nsentences that are similar to input sentences using a dynamic-programming-based\nsentence similarity scoring method. Next, we extract n-grams of action\nsequences that build the associated abstract syntax tree. Finally, we increase\nthe probability of actions that cause the retrieved n-gram action subtree to be\nin the predicted code. We show that our approach improves the performance on\ntwo code generation tasks by up to +2.6 BLEU.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 20:01:21 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Hayati", "Shirley Anugrah", ""], ["Olivier", "Raphael", ""], ["Avvaru", "Pravalika", ""], ["Yin", "Pengcheng", ""], ["Tomasic", "Anthony", ""], ["Neubig", "Graham", ""]]}, {"id": "1808.10059", "submitter": "Sungjin Lee", "authors": "Sungjin Lee and Rahul Jha", "title": "Zero-Shot Adaptive Transfer for Conversational Language Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational agents such as Alexa and Google Assistant constantly need to\nincrease their language understanding capabilities by adding new domains. A\nmassive amount of labeled data is required for training each new domain. While\ndomain adaptation approaches alleviate the annotation cost, prior approaches\nsuffer from increased training time and suboptimal concept alignments. To\ntackle this, we introduce a novel Zero-Shot Adaptive Transfer method for slot\ntagging that utilizes the slot description for transferring reusable concepts\nacross domains, and enjoys efficient training without any explicit concept\nalignments. Extensive experimentation over a dataset of 10 domains relevant to\nour commercial personal digital assistant shows that our model outperforms\nprevious state-of-the-art systems by a large margin, and achieves an even\nhigher improvement in the low data regime.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 22:57:55 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Lee", "Sungjin", ""], ["Jha", "Rahul", ""]]}, {"id": "1808.10088", "submitter": "Mohan Li", "authors": "Mohan Li, Min Liu, Masanori Hattori", "title": "End-to-end Speech Recognition with Adaptive Computation Steps", "comments": "5 pages, 2 figures, submitted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present Adaptive Computation Steps (ACS) algo-rithm, which\nenables end-to-end speech recognition models to dy-namically decide how many\nframes should be processed to predict a linguistic output. The model that\napplies ACS algorithm follows the encoder-decoder framework, while unlike the\nattention-based mod-els, it produces alignments independently at the encoder\nside using the correlation between adjacent frames. Thus, predictions can be\nmade as soon as sufficient acoustic information is received, which makes the\nmodel applicable in online cases. Besides, a small change is made to the\ndecoding stage of the encoder-decoder framework, which allows the prediction to\nexploit bidirectional contexts. We verify the ACS algorithm on a Mandarin\nspeech corpus AIShell-1, and it achieves a 31.2% CER in the online occasion,\ncompared to the 32.4% CER of the attention-based model. To fully demonstrate\nthe advantage of ACS algorithm, offline experiments are conducted, in which our\nACS model achieves an 18.7% CER, outperforming the attention-based counterpart\nwith the CER of 22.0%.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 02:33:02 GMT"}, {"version": "v2", "created": "Wed, 26 Sep 2018 02:36:29 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Li", "Mohan", ""], ["Liu", "Min", ""], ["Hattori", "Masanori", ""]]}, {"id": "1808.10113", "submitter": "Yansen Wang", "authors": "Jian Guan, Yansen Wang, Minlie Huang", "title": "Story Ending Generation with Incremental Encoding and Commonsense\n  Knowledge", "comments": "Accepted in AAAI2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating a reasonable ending for a given story context, i.e., story ending\ngeneration, is a strong indication of story comprehension. This task requires\nnot only to understand the context clues which play an important role in\nplanning the plot but also to handle implicit knowledge to make a reasonable,\ncoherent story.\n  In this paper, we devise a novel model for story ending generation. The model\nadopts an incremental encoding scheme to represent context clues which are\nspanning in the story context. In addition, commonsense knowledge is applied\nthrough multi-source attention to facilitate story comprehension, and thus to\nhelp generate coherent and reasonable endings. Through building context clues\nand using implicit knowledge, the model is able to produce reasonable story\nendings. context clues implied in the post and make the inference based on it.\n  Automatic and manual evaluation shows that our model can generate more\nreasonable story endings than state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 04:30:33 GMT"}, {"version": "v2", "created": "Sat, 10 Nov 2018 06:35:24 GMT"}, {"version": "v3", "created": "Sun, 2 Dec 2018 05:37:52 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Guan", "Jian", ""], ["Wang", "Yansen", ""], ["Huang", "Minlie", ""]]}, {"id": "1808.10122", "submitter": "Sam Wiseman", "authors": "Sam Wiseman, Stuart M. Shieber, Alexander M. Rush", "title": "Learning Neural Templates for Text Generation", "comments": "EMNLP 2018; purity calculations updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural, encoder-decoder models have had significant empirical success\nin text generation, there remain several unaddressed problems with this style\nof generation. Encoder-decoder models are largely (a) uninterpretable, and (b)\ndifficult to control in terms of their phrasing or content. This work proposes\na neural generation system using a hidden semi-markov model (HSMM) decoder,\nwhich learns latent, discrete templates jointly with learning to generate. We\nshow that this model learns useful templates, and that these templates make\ngeneration both more interpretable and controllable. Furthermore, we show that\nthis approach scales to real data sets and achieves strong performance nearing\nthat of encoder-decoder text generation models.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 05:15:42 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 22:45:09 GMT"}, {"version": "v3", "created": "Mon, 17 Jun 2019 17:42:49 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Wiseman", "Sam", ""], ["Shieber", "Stuart M.", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1808.10128", "submitter": "Yu-An Chung", "authors": "Yu-An Chung, Yuxuan Wang, Wei-Ning Hsu, Yu Zhang, RJ Skerry-Ryan", "title": "Semi-Supervised Training for Improving Data Efficiency in End-to-End\n  Speech Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although end-to-end text-to-speech (TTS) models such as Tacotron have shown\nexcellent results, they typically require a sizable set of high-quality <text,\naudio> pairs for training, which are expensive to collect. In this paper, we\npropose a semi-supervised training framework to improve the data efficiency of\nTacotron. The idea is to allow Tacotron to utilize textual and acoustic\nknowledge contained in large, publicly-available text and speech corpora.\nImportantly, these external data are unpaired and potentially noisy.\nSpecifically, first we embed each word in the input text into word vectors and\ncondition the Tacotron encoder on them. We then use an unpaired speech corpus\nto pre-train the Tacotron decoder in the acoustic domain. Finally, we fine-tune\nthe model using available paired data. We demonstrate that the proposed\nframework enables Tacotron to generate intelligible speech using less than half\nan hour of paired training data.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 05:51:30 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Chung", "Yu-An", ""], ["Wang", "Yuxuan", ""], ["Hsu", "Wei-Ning", ""], ["Zhang", "Yu", ""], ["Skerry-Ryan", "RJ", ""]]}, {"id": "1808.10143", "submitter": "Sho Takase", "authors": "Sho Takase, Jun Suzuki, Masaaki Nagata", "title": "Direct Output Connection for a High-Rank Language Model", "comments": "EMNLP 2018 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a state-of-the-art recurrent neural network (RNN)\nlanguage model that combines probability distributions computed not only from a\nfinal RNN layer but also from middle layers. Our proposed method raises the\nexpressive power of a language model based on the matrix factorization\ninterpretation of language modeling introduced by Yang et al. (2018). The\nproposed method improves the current state-of-the-art language model and\nachieves the best score on the Penn Treebank and WikiText-2, which are the\nstandard benchmark datasets. Moreover, we indicate our proposed method\ncontributes to two application tasks: machine translation and headline\ngeneration. Our code is publicly available at:\nhttps://github.com/nttcslab-nlp/doc_lm.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 07:03:51 GMT"}, {"version": "v2", "created": "Fri, 31 Aug 2018 01:45:38 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Takase", "Sho", ""], ["Suzuki", "Jun", ""], ["Nagata", "Masaaki", ""]]}, {"id": "1808.10192", "submitter": "Preksha Nema I", "authors": "Preksha Nema, Mitesh M. Khapra", "title": "Towards a Better Metric for Evaluating Question Generation Systems", "comments": "10 pages", "journal-ref": "EMNLP, 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There has always been criticism for using $n$-gram based similarity metrics,\nsuch as BLEU, NIST, etc, for evaluating the performance of NLG systems.\nHowever, these metrics continue to remain popular and are recently being used\nfor evaluating the performance of systems which automatically generate\nquestions from documents, knowledge graphs, images, etc. Given the rising\ninterest in such automatic question generation (AQG) systems, it is important\nto objectively examine whether these metrics are suitable for this task. In\nparticular, it is important to verify whether such metrics used for evaluating\nAQG systems focus on answerability of the generated question by preferring\nquestions which contain all relevant information such as question type\n(Wh-types), entities, relations, etc. In this work, we show that current\nautomatic evaluation metrics based on $n$-gram similarity do not always\ncorrelate well with human judgments about answerability of a question. To\nalleviate this problem and as a first step towards better evaluation metrics\nfor AQG, we introduce a scoring function to capture answerability and show that\nwhen this scoring function is integrated with existing metrics, they correlate\nsignificantly better with human judgments. The scripts and data developed as a\npart of this work are made publicly available at\nhttps://github.com/PrekshaNema25/Answerability-Metric\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 09:12:19 GMT"}, {"version": "v2", "created": "Fri, 31 Aug 2018 08:00:16 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Nema", "Preksha", ""], ["Khapra", "Mitesh M.", ""]]}, {"id": "1808.10196", "submitter": "Christian Hardmeier", "authors": "Christian Hardmeier and Liane Guillou", "title": "Pronoun Translation in English-French Machine Translation: An Analysis\n  of Error Types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pronouns are a long-standing challenge in machine translation. We present a\nstudy of the performance of a range of rule-based, statistical and neural MT\nsystems on pronoun translation based on an extensive manual evaluation using\nthe PROTEST test suite, which enables a fine-grained analysis of different\npronoun types and sheds light on the difficulties of the task. We find that the\nrule-based approaches in our corpus perform poorly as a result of\noversimplification, whereas SMT and early NMT systems exhibit significant\nshortcomings due to a lack of awareness of the functional and referential\nproperties of pronouns. A recent Transformer-based NMT system with\ncross-sentence context shows very promising results on non-anaphoric pronouns\nand intra-sentential anaphora, but there is still considerable room for\nimprovement in examples with cross-sentence dependencies.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 09:30:14 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Hardmeier", "Christian", ""], ["Guillou", "Liane", ""]]}, {"id": "1808.10239", "submitter": "Ondrej Klejch", "authors": "Ond\\v{r}ej Klejch, Joachim Fainberg, Peter Bell", "title": "Learning to adapt: a meta-learning approach for speaker adaptation", "comments": "Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of automatic speech recognition systems can be improved by\nadapting an acoustic model to compensate for the mismatch between training and\ntesting conditions, for example by adapting to unseen speakers. The success of\nspeaker adaptation methods relies on selecting weights that are suitable for\nadaptation and using good adaptation schedules to update these weights in order\nnot to overfit to the adaptation data. In this paper we investigate a\nprincipled way of adapting all the weights of the acoustic model using a\nmeta-learning. We show that the meta-learner can learn to perform supervised\nand unsupervised speaker adaptation and that it outperforms a strong baseline\nadapting LHUC parameters when adapting a DNN AM with 1.5M parameters. We also\nreport initial experiments on adapting TDNN AMs, where the meta-learner\nachieves comparable performance with LHUC.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 11:47:07 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Klejch", "Ond\u0159ej", ""], ["Fainberg", "Joachim", ""], ["Bell", "Peter", ""]]}, {"id": "1808.10245", "submitter": "Younghun Lee", "authors": "Younghun Lee, Seunghyun Yoon and Kyomin Jung", "title": "Comparative Studies of Detecting Abusive Language on Twitter", "comments": "ALW2: 2nd Workshop on Abusive Language Online to be held at EMNLP\n  2018 (Brussels, Belgium), October 31st, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The context-dependent nature of online aggression makes annotating large\ncollections of data extremely difficult. Previously studied datasets in abusive\nlanguage detection have been insufficient in size to efficiently train deep\nlearning models. Recently, Hate and Abusive Speech on Twitter, a dataset much\ngreater in size and reliability, has been released. However, this dataset has\nnot been comprehensively studied to its potential. In this paper, we conduct\nthe first comparative study of various learning models on Hate and Abusive\nSpeech on Twitter, and discuss the possibility of using additional features and\ncontext data for improvements. Experimental results show that bidirectional GRU\nnetworks trained on word-level features, with Latent Topic Clustering modules,\nis the most accurate model scoring 0.805 F1.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 12:15:31 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Lee", "Younghun", ""], ["Yoon", "Seunghyun", ""], ["Jung", "Kyomin", ""]]}, {"id": "1808.10267", "submitter": "Anna Currey", "authors": "Anna Currey and Kenneth Heafield", "title": "Multi-Source Syntactic Neural Machine Translation", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel multi-source technique for incorporating source syntax\ninto neural machine translation using linearized parses. This is achieved by\nemploying separate encoders for the sequential and parsed versions of the same\nsource sentence; the resulting representations are then combined using a\nhierarchical attention mechanism. The proposed model improves over both seq2seq\nand parsed baselines by over 1 BLEU on the WMT17 English-German task. Further\nanalysis shows that our multi-source syntactic model is able to translate\nsuccessfully without any parsed input, unlike standard parsed methods. In\naddition, performance does not deteriorate as much on long sentences as for the\nbaselines.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 13:18:57 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Currey", "Anna", ""], ["Heafield", "Kenneth", ""]]}, {"id": "1808.10290", "submitter": "Wei Shi", "authors": "Wei Shi, Frances Yung, Vera Demberg", "title": "Acquiring Annotated Data with Cross-lingual Explicitation for Implicit\n  Discourse Relation Classification", "comments": "to appear on DISRPT@NAACL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit discourse relation classification is one of the most challenging and\nimportant tasks in discourse parsing, due to the lack of connective as strong\nlinguistic cues. A principle bottleneck to further improvement is the shortage\nof training data (ca.~16k instances in the PDTB). Shi et al. (2017) proposed to\nacquire additional data by exploiting connectives in translation: human\ntranslators mark discourse relations which are implicit in the source language\nexplicitly in the translation. Using back-translations of such explicitated\nconnectives improves discourse relation parsing performance. This paper\naddresses the open question of whether the choice of the translation language\nmatters, and whether multiple translations into different languages can be\neffectively used to improve the quality of the additional data.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 13:36:04 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 11:29:19 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Shi", "Wei", ""], ["Yung", "Frances", ""], ["Demberg", "Vera", ""]]}, {"id": "1808.10326", "submitter": "Shen Li", "authors": "Shen Li, Hengru Xu, Zhengdong Lu", "title": "Generalize Symbolic Knowledge With Neural Rule Engine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As neural networks have dominated the state-of-the-art results in a wide\nrange of NLP tasks, it attracts considerable attention to improve the\nperformance of neural models by integrating symbolic knowledge. Different from\nexisting works, this paper investigates the combination of these two powerful\nparadigms from the knowledge-driven side. We propose Neural Rule Engine (NRE),\nwhich can learn knowledge explicitly from logic rules and then generalize them\nimplicitly with neural networks. NRE is implemented with neural module networks\nin which each module represents an action of a logic rule. The experiments show\nthat NRE could greatly improve the generalization abilities of logic rules with\na significant increase in recall. Meanwhile, the precision is still maintained\nat a high level.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 14:51:43 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 06:07:15 GMT"}, {"version": "v3", "created": "Wed, 14 Aug 2019 07:15:49 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Li", "Shen", ""], ["Xu", "Hengru", ""], ["Lu", "Zhengdong", ""]]}, {"id": "1808.10399", "submitter": "Sven Buechel", "authors": "Sven Buechel, Anneke Buffone, Barry Slaff, Lyle Ungar, and Jo\\~ao\n  Sedoc", "title": "Modeling Empathy and Distress in Reaction to News Stories", "comments": "To appear at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational detection and understanding of empathy is an important factor\nin advancing human-computer interaction. Yet to date, text-based empathy\nprediction has the following major limitations: It underestimates the\npsychological complexity of the phenomenon, adheres to a weak notion of ground\ntruth where empathic states are ascribed by third parties, and lacks a shared\ncorpus. In contrast, this contribution presents the first publicly available\ngold standard for empathy prediction. It is constructed using a novel\nannotation methodology which reliably captures empathy assessments by the\nwriter of a statement using multi-item scales. This is also the first\ncomputational work distinguishing between multiple forms of empathy, empathic\nconcern, and personal distress, as recognized throughout psychology. Finally,\nwe present experimental results for three different predictive models, of which\na CNN performs the best.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 17:07:47 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Buechel", "Sven", ""], ["Buffone", "Anneke", ""], ["Slaff", "Barry", ""], ["Ungar", "Lyle", ""], ["Sedoc", "Jo\u00e3o", ""]]}, {"id": "1808.10432", "submitter": "Antonio Toral", "authors": "Antonio Toral, Sheila Castilho, Ke Hu, Andy Way", "title": "Attaining the Unattainable? Reassessing Claims of Human Parity in Neural\n  Machine Translation", "comments": "WMT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We reassess a recent study (Hassan et al., 2018) that claimed that machine\ntranslation (MT) has reached human parity for the translation of news from\nChinese into English, using pairwise ranking and considering three variables\nthat were not taken into account in that previous study: the language in which\nthe source side of the test set was originally written, the translation\nproficiency of the evaluators, and the provision of inter-sentential context.\nIf we consider only original source text (i.e. not translated from another\nlanguage, or translationese), then we find evidence showing that human parity\nhas not been achieved. We compare the judgments of professional translators\nagainst those of non-experts and discover that those of the experts result in\nhigher inter-annotator agreement and better discrimination between human and\nmachine translations. In addition, we analyse the human translations of the\ntest set and identify important translation issues. Finally, based on these\nfindings, we provide a set of recommendations for future human evaluations of\nMT.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 17:49:42 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Toral", "Antonio", ""], ["Castilho", "Sheila", ""], ["Hu", "Ke", ""], ["Way", "Andy", ""]]}, {"id": "1808.10485", "submitter": "Swabha Swayamdipta", "authors": "Swabha Swayamdipta and Sam Thomson and Kenton Lee and Luke Zettlemoyer\n  and Chris Dyer and Noah A. Smith", "title": "Syntactic Scaffolds for Semantic Structures", "comments": "Accepted at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the syntactic scaffold, an approach to incorporating syntactic\ninformation into semantic tasks. Syntactic scaffolds avoid expensive syntactic\nprocessing at runtime, only making use of a treebank during training, through a\nmultitask objective. We improve over strong baselines on PropBank semantics,\nframe semantics, and coreference resolution, achieving competitive performance\non all three tasks.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 19:01:20 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Swayamdipta", "Swabha", ""], ["Thomson", "Sam", ""], ["Lee", "Kenton", ""], ["Zettlemoyer", "Luke", ""], ["Dyer", "Chris", ""], ["Smith", "Noah A.", ""]]}, {"id": "1808.10503", "submitter": "Martin Tutek", "authors": "Martin Tutek and Jan \\v{S}najder", "title": "Iterative Recursive Attention Model for Interpretable Sequence\n  Classification", "comments": "7 pages, 5 figures, Analyzing and interpreting neural networks for\n  NLP Workshop at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language processing has greatly benefited from the introduction of\nthe attention mechanism. However, standard attention models are of limited\ninterpretability for tasks that involve a series of inference steps. We\ndescribe an iterative recursive attention model, which constructs incremental\nrepresentations of input data through reusing results of previously computed\nqueries. We train our model on sentiment classification datasets and\ndemonstrate its capacity to identify and combine different aspects of the input\nin an easily interpretable manner, while obtaining performance close to the\nstate of the art.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 20:19:02 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Tutek", "Martin", ""], ["\u0160najder", "Jan", ""]]}, {"id": "1808.10556", "submitter": "Alan Preciado-Grijalva Mr.", "authors": "Alan Preciado-Grijalva and Ramon F. Brena", "title": "Speaker Fluency Level Classification Using Machine Learning Techniques", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Level assessment for foreign language students is necessary for putting them\nin the right level group, furthermore, interviewing students is a very\ntime-consuming task, so we propose to automate the evaluation of speaker\nfluency level by implementing machine learning techniques. This work presents\nan audio processing system capable of classifying the level of fluency of\nnon-native English speakers using five different machine learning models. As a\nfirst step, we have built our own dataset, which consists of labeled audio\nconversations in English between people ranging in different fluency\ndomains/classes (low, intermediate, high). We segment the audio conversations\ninto 5s non-overlapped audio clips to perform feature extraction on them. We\nstart by extracting Mel cepstral coefficients from the audios, selecting 20\ncoefficients is an appropriate quantity for our data. We thereafter extracted\nzero-crossing rate, root mean square energy and spectral flux features, proving\nthat this improves model performance. Out of a total of 1424 audio segments,\nwith 70% training data and 30% test data, one of our trained models (support\nvector machine) achieved a classification accuracy of 94.39%, whereas the other\nfour models passed an 89% classification accuracy threshold.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 00:15:53 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Preciado-Grijalva", "Alan", ""], ["Brena", "Ramon F.", ""]]}, {"id": "1808.10568", "submitter": "Xi Victoria Lin", "authors": "Xi Victoria Lin and Richard Socher and Caiming Xiong", "title": "Multi-Hop Knowledge Graph Reasoning with Reward Shaping", "comments": "Accepted to EMNLP 2018, 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop reasoning is an effective approach for query answering (QA) over\nincomplete knowledge graphs (KGs). The problem can be formulated in a\nreinforcement learning (RL) setup, where a policy-based agent sequentially\nextends its inference path until it reaches a target. However, in an incomplete\nKG environment, the agent receives low-quality rewards corrupted by false\nnegatives in the training data, which harms generalization at test time.\nFurthermore, since no golden action sequence is used for training, the agent\ncan be misled by spurious search trajectories that incidentally lead to the\ncorrect answer. We propose two modeling advances to address both issues: (1) we\nreduce the impact of false negative supervision by adopting a pretrained\none-hop embedding model to estimate the reward of unobserved facts; (2) we\ncounter the sensitivity to spurious paths of on-policy RL by forcing the agent\nto explore a diverse set of paths using randomly generated edge masks. Our\napproach significantly improves over existing path-based KGQA models on several\nbenchmark datasets and is comparable or better than embedding-based models.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 01:55:09 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 22:00:49 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Lin", "Xi Victoria", ""], ["Socher", "Richard", ""], ["Xiong", "Caiming", ""]]}, {"id": "1808.10583", "submitter": "Xingyu Na", "authors": "Jiayu Du, Xingyu Na, Xuechen Liu and Hui Bu", "title": "AISHELL-2: Transforming Mandarin ASR Research Into Industrial Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AISHELL-1 is by far the largest open-source speech corpus available for\nMandarin speech recognition research. It was released with a baseline system\ncontaining solid training and testing pipelines for Mandarin ASR. In AISHELL-2,\n1000 hours of clean read-speech data from iOS is published, which is free for\nacademic usage. On top of AISHELL-2 corpus, an improved recipe is developed and\nreleased, containing key components for industrial applications, such as\nChinese word segmentation, flexible vocabulary expension and phone set\ntransformation etc. Pipelines support various state-of-the-art techniques, such\nas time-delayed neural networks and Lattic-Free MMI objective funciton. In\naddition, we also release dev and test data from other channels(Android and\nMic). For research community, we hope that AISHELL-2 corpus can be a solid\nresource for topics like transfer learning and robust ASR. For industry, we\nhope AISHELL-2 recipe can be a helpful reference for building meaningful\nindustrial systems and products.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 03:11:08 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 02:45:27 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Du", "Jiayu", ""], ["Na", "Xingyu", ""], ["Liu", "Xuechen", ""], ["Bu", "Hui", ""]]}, {"id": "1808.10584", "submitter": "Harsh Jhamtani", "authors": "Harsh Jhamtani, Taylor Berg-Kirkpatrick", "title": "Learning to Describe Differences Between Pairs of Similar Images", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the task of automatically generating text to\ndescribe the differences between two similar images. We collect a new dataset\nby crowd-sourcing difference descriptions for pairs of image frames extracted\nfrom video-surveillance footage. Annotators were asked to succinctly describe\nall the differences in a short paragraph. As a result, our novel dataset\nprovides an opportunity to explore models that align language and vision, and\ncapture visual salience. The dataset may also be a useful benchmark for\ncoherent multi-sentence generation. We perform a firstpass visual analysis that\nexposes clusters of differing pixels as a proxy for object-level differences.\nWe propose a model that captures visual salience by using a latent variable to\nalign clusters of differing pixels with output sentences. We find that, for\nboth single-sentence generation and as well as multi-sentence generation, the\nproposed model outperforms the models that use attention alone.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 03:15:28 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Jhamtani", "Harsh", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}, {"id": "1808.10592", "submitter": "Renjie Zheng", "authors": "Renjie Zheng, Yilin Yang, Mingbo Ma, Liang Huang", "title": "Ensemble Sequence Level Training for Multimodal MT: OSU-Baidu WMT18\n  Multimodal Machine Translation System Report", "comments": "5 pages", "journal-ref": "Published in WMT 2018", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes multimodal machine translation systems developed jointly\nby Oregon State University and Baidu Research for WMT 2018 Shared Task on\nmultimodal translation. In this paper, we introduce a simple approach to\nincorporate image information by feeding image features to the decoder side. We\nalso explore different sequence level training methods including scheduled\nsampling and reinforcement learning which lead to substantial improvements. Our\nsystems ensemble several models using different architectures and training\nmethods and achieve the best performance for three subtasks: En-De and En-Cs in\ntask 1 and (En+De+Fr)-Cs task 1B.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 04:14:40 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Zheng", "Renjie", ""], ["Yang", "Yilin", ""], ["Ma", "Mingbo", ""], ["Huang", "Liang", ""]]}, {"id": "1808.10596", "submitter": "Zhaochun Ren", "authors": "Xisen Jin, Wenqiang Lei, Zhaochun Ren, Hongshen Chen, Shangsong Liang,\n  Yihong Zhao, Dawei Yin", "title": "Explicit State Tracking with Semi-Supervision for Neural Dialogue\n  Generation", "comments": null, "journal-ref": "The 27th ACM International Conference on Information and Knowledge\n  Management, 2018", "doi": "10.1145/3269206.3271683", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of dialogue generation aims to automatically provide responses given\nprevious utterances. Tracking dialogue states is an important ingredient in\ndialogue generation for estimating users' intention. However, the\n\\emph{expensive nature of state labeling} and the \\emph{weak interpretability}\nmake the dialogue state tracking a challenging problem for both task-oriented\nand non-task-oriented dialogue generation: For generating responses in\ntask-oriented dialogues, state tracking is usually learned from manually\nannotated corpora, where the human annotation is expensive for training; for\ngenerating responses in non-task-oriented dialogues, most of existing work\nneglects the explicit state tracking due to the unlimited number of dialogue\nstates.\n  In this paper, we propose the \\emph{semi-supervised explicit dialogue state\ntracker} (SEDST) for neural dialogue generation. To this end, our approach has\ntwo core ingredients: \\emph{CopyFlowNet} and \\emph{posterior regularization}.\nSpecifically, we propose an encoder-decoder architecture, named\n\\emph{CopyFlowNet}, to represent an explicit dialogue state with a\nprobabilistic distribution over the vocabulary space. To optimize the training\nprocedure, we apply a posterior regularization strategy to integrate indirect\nsupervision. Extensive experiments conducted on both task-oriented and\nnon-task-oriented dialogue corpora demonstrate the effectiveness of our\nproposed model. Moreover, we find that our proposed semi-supervised dialogue\nstate tracker achieves a comparable performance as state-of-the-art supervised\nlearning baselines in state tracking procedure.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 04:27:41 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Jin", "Xisen", ""], ["Lei", "Wenqiang", ""], ["Ren", "Zhaochun", ""], ["Chen", "Hongshen", ""], ["Liang", "Shangsong", ""], ["Zhao", "Yihong", ""], ["Yin", "Dawei", ""]]}, {"id": "1808.10627", "submitter": "Dieuwke Hupkes", "authors": "Jaap Jumelet and Dieuwke Hupkes", "title": "Do Language Models Understand Anything? On the Ability of LSTMs to\n  Understand Negative Polarity Items", "comments": "Accepted to the EMNLP workshop \"Analyzing and interpreting neural\n  networks for NLP\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we attempt to link the inner workings of a neural language\nmodel to linguistic theory, focusing on a complex phenomenon well discussed in\nformal linguis- tics: (negative) polarity items. We briefly discuss the leading\nhypotheses about the licensing contexts that allow negative polarity items and\nevaluate to what extent a neural language model has the ability to correctly\nprocess a subset of such constructions. We show that the model finds a relation\nbetween the licensing context and the negative polarity item and appears to be\naware of the scope of this context, which we extract from a parse tree of the\nsentence. With this research, we hope to pave the way for other studies linking\nformal linguistics to deep learning.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 08:21:45 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Jumelet", "Jaap", ""], ["Hupkes", "Dieuwke", ""]]}, {"id": "1808.10628", "submitter": "Kyosuke Nishida", "authors": "Kyosuke Nishida, Itsumi Saito, Atsushi Otsuka, Hisako Asano, Junji\n  Tomita", "title": "Retrieve-and-Read: Multi-task Learning of Information Retrieval and\n  Reading Comprehension", "comments": "10 pages, 6 figure. Accepted as a full paper at CIKM 2018", "journal-ref": "CIKM 2018, October 22-26, 2018, Torino, Italy", "doi": "10.1145/3269206.3271702", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study considers the task of machine reading at scale (MRS) wherein,\ngiven a question, a system first performs the information retrieval (IR) task\nof finding relevant passages in a knowledge source and then carries out the\nreading comprehension (RC) task of extracting an answer span from the passages.\nPrevious MRS studies, in which the IR component was trained without considering\nanswer spans, struggled to accurately find a small number of relevant passages\nfrom a large set of passages. In this paper, we propose a simple and effective\napproach that incorporates the IR and RC tasks by using supervised multi-task\nlearning in order that the IR component can be trained by considering answer\nspans. Experimental results on the standard benchmark, answering SQuAD\nquestions using the full Wikipedia as the knowledge source, showed that our\nmodel achieved state-of-the-art performance. Moreover, we thoroughly evaluated\nthe individual contributions of our model components with our new Japanese\ndataset and SQuAD. The results showed significant improvements in the IR task\nand provided a new perspective on IR for RC: it is effective to teach which\npart of the passage answers the question rather than to give only a relevance\nscore to the whole passage.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 08:22:12 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Nishida", "Kyosuke", ""], ["Saito", "Itsumi", ""], ["Otsuka", "Atsushi", ""], ["Asano", "Hisako", ""], ["Tomita", "Junji", ""]]}, {"id": "1808.10653", "submitter": "Roman Klinger", "authors": "Florian Strohm and Roman Klinger", "title": "An Empirical Analysis of the Role of Amplifiers, Downtoners, and\n  Negations in Emotion Classification in Microblogs", "comments": "Accepted for publication at The 5th IEEE International Conference on\n  Data Science and Advanced Analytics (DSAA), https://dsaa2018.isi.it/", "journal-ref": null, "doi": "10.1109/DSAA.2018.00087", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effect of amplifiers, downtoners, and negations has been studied in\ngeneral and particularly in the context of sentiment analysis. However, there\nis only limited work which aims at transferring the results and methods to\ndiscrete classes of emotions, e. g., joy, anger, fear, sadness, surprise, and\ndisgust. For instance, it is not straight-forward to interpret which emotion\nthe phrase \"not happy\" expresses. With this paper, we aim at obtaining a better\nunderstanding of such modifiers in the context of emotion-bearing words and\ntheir impact on document-level emotion classification, namely, microposts on\nTwitter. We select an appropriate scope detection method for modifiers of\nemotion words, incorporate it in a document-level emotion classification model\nas additional bag of words and show that this approach improves the performance\nof emotion classification. In addition, we build a term weighting approach\nbased on the different modifiers into a lexical model for the analysis of the\nsemantics of modifiers and their impact on emotion meaning. We show that\namplifiers separate emotions expressed with an emotion- bearing word more\nclearly from other secondary connotations. Downtoners have the opposite effect.\nIn addition, we discuss the meaning of negations of emotion-bearing words. For\ninstance we show empirically that \"not happy\" is closer to sadness than to\nanger and that fear-expressing words in the scope of downtoners often express\nsurprise.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 09:55:06 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 14:34:32 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Strohm", "Florian", ""], ["Klinger", "Roman", ""]]}, {"id": "1808.10681", "submitter": "Nikolaos Pappas", "authors": "Nikolaos Pappas, Lesly Miculicich Werlen, James Henderson", "title": "Beyond Weight Tying: Learning Joint Input-Output Embeddings for Neural\n  Machine Translation", "comments": "To appear at WMT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tying the weights of the target word embeddings with the target word\nclassifiers of neural machine translation models leads to faster training and\noften to better translation quality. Given the success of this parameter\nsharing, we investigate other forms of sharing in between no sharing and hard\nequality of parameters. In particular, we propose a structure-aware output\nlayer which captures the semantic structure of the output space of words within\na joint input-output embedding. The model is a generalized form of weight tying\nwhich shares parameters but allows learning a more flexible relationship with\ninput word embeddings and allows the effective capacity of the output layer to\nbe controlled. In addition, the model shares weights across output classifiers\nand translation contexts which allows it to better leverage prior knowledge\nabout them. Our evaluation on English-to-Finnish and English-to-German datasets\nshows the effectiveness of the method against strong encoder-decoder baselines\ntrained with or without weight tying.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 11:14:36 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Pappas", "Nikolaos", ""], ["Werlen", "Lesly Miculicich", ""], ["Henderson", "James", ""]]}, {"id": "1808.10685", "submitter": "Barbara McGillivray", "authors": "Barbara McGillivray and Gard Jenset and Dominik Heil", "title": "Extracting Keywords from Open-Ended Business Survey Questions", "comments": "1 figure", "journal-ref": "Journal of Data Mining & Digital Humanities, 2020, Project (March\n  17, 2020) jdmdh:5398", "doi": "10.46298/jdmdh.5077", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-ended survey data constitute an important basis in research as well as\nfor making business decisions. Collecting and manually analysing free-text\nsurvey data is generally more costly than collecting and analysing survey data\nconsisting of answers to multiple-choice questions. Yet free-text data allow\nfor new content to be expressed beyond predefined categories and are a very\nvaluable source of new insights into people's opinions. At the same time,\nsurveys always make ontological assumptions about the nature of the entities\nthat are researched, and this has vital ethical consequences. Human\ninterpretations and opinions can only be properly ascertained in their richness\nusing textual data sources; if these sources are analyzed appropriately, the\nessential linguistic nature of humans and social entities is safeguarded.\nNatural Language Processing (NLP) offers possibilities for meeting this ethical\nbusiness challenge by automating the analysis of natural language and thus\nallowing for insightful investigations of human judgements. We present a\ncomputational pipeline for analysing large amounts of responses to open-ended\nquestions in surveys and extract keywords that appropriately represent people's\nopinions. This pipeline addresses the need to perform such tasks outside the\nscope of both commercial software and bespoke analysis, exceeds the performance\nto state-of-the-art systems, and performs this task in a transparent way that\nallows for scrutinising and exposing potential biases in the analysis.\nFollowing the principle of Open Data Science, our code is open-source and\ngeneralizable to other datasets.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 11:20:53 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2019 11:18:07 GMT"}, {"version": "v3", "created": "Fri, 7 Aug 2020 13:25:46 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["McGillivray", "Barbara", ""], ["Jenset", "Gard", ""], ["Heil", "Dominik", ""]]}, {"id": "1808.10696", "submitter": "Diane Bouchacourt", "authors": "Diane Bouchacourt and Marco Baroni", "title": "How agents see things: On visual representations in an emergent language\n  game", "comments": "2018 Conference on Empirical Methods in Natural Language Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is growing interest in the language developed by agents interacting in\nemergent-communication settings. Earlier studies have focused on the agents'\nsymbol usage, rather than on their representation of visual input. In this\npaper, we consider the referential games of Lazaridou et al. (2017) and\ninvestigate the representations the agents develop during their evolving\ninteraction. We find that the agents establish successful communication by\ninducing visual representations that almost perfectly align with each other,\nbut, surprisingly, do not capture the conceptual properties of the objects\ndepicted in the input images. We conclude that, if we are interested in\ndeveloping language-like communication systems, we must pay more attention to\nthe visual semantics agents associate to the symbols they use.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 11:56:10 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 14:11:46 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Bouchacourt", "Diane", ""], ["Baroni", "Marco", ""]]}, {"id": "1808.10701", "submitter": "Peter Makarov", "authors": "Peter Makarov and Simon Clematide", "title": "Imitation Learning for Neural Morphological String Transduction", "comments": "6 pages; accepted to EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We employ imitation learning to train a neural transition-based string\ntransducer for morphological tasks such as inflection generation and\nlemmatization. Previous approaches to training this type of model either rely\non an external character aligner for the production of gold action sequences,\nwhich results in a suboptimal model due to the unwarranted dependence on a\nsingle gold action sequence despite spurious ambiguity, or require warm\nstarting with an MLE model. Our approach only requires a simple expert policy,\neliminating the need for a character aligner or warm start. It also addresses\nfamiliar MLE training biases and leads to strong and state-of-the-art\nperformance on several benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 12:08:55 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Makarov", "Peter", ""], ["Clematide", "Simon", ""]]}, {"id": "1808.10785", "submitter": "Matthew Roddy", "authors": "Matthew Roddy, Gabriel Skantze, Naomi Harte", "title": "Multimodal Continuous Turn-Taking Prediction Using Multiscale RNNs", "comments": "Accepted for ICMI18", "journal-ref": null, "doi": "10.1145/3242969.3242997", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In human conversational interactions, turn-taking exchanges can be\ncoordinated using cues from multiple modalities. To design spoken dialog\nsystems that can conduct fluid interactions it is desirable to incorporate cues\nfrom separate modalities into turn-taking models. We propose that there is an\nappropriate temporal granularity at which modalities should be modeled. We\ndesign a multiscale RNN architecture to model modalities at separate timescales\nin a continuous manner. Our results show that modeling linguistic and acoustic\nfeatures at separate temporal rates can be beneficial for turn-taking modeling.\nWe also show that our approach can be used to incorporate gaze features into\nturn-taking models.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 14:38:50 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Roddy", "Matthew", ""], ["Skantze", "Gabriel", ""], ["Harte", "Naomi", ""]]}, {"id": "1808.10791", "submitter": "Stig-Arne Gr\\\"onroos", "authors": "Stig-Arne Gr\\\"onroos and Sami Virpioja and Mikko Kurimo", "title": "Cognate-aware morphological segmentation for multilingual neural\n  translation", "comments": "To appear in WMT18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes the Aalto University entry to the WMT18 News\nTranslation Shared Task. We participate in the multilingual subtrack with a\nsystem trained under the constrained condition to translate from English to\nboth Finnish and Estonian. The system is based on the Transformer model. We\nfocus on improving the consistency of morphological segmentation for words that\nare similar orthographically, semantically, and distributionally; such words\ninclude etymological cognates, loan words, and proper names. For this, we\nintroduce Cognate Morfessor, a multilingual variant of the Morfessor method. We\nshow that our approach improves the translation quality particularly for\nEstonian, which has less resources for training the translation model.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 14:54:49 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Gr\u00f6nroos", "Stig-Arne", ""], ["Virpioja", "Sami", ""], ["Kurimo", "Mikko", ""]]}, {"id": "1808.10792", "submitter": "Sebastian Gehrmann", "authors": "Sebastian Gehrmann, Yuntian Deng, Alexander M. Rush", "title": "Bottom-Up Abstractive Summarization", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network-based methods for abstractive summarization produce outputs\nthat are more fluent than other techniques, but which can be poor at content\nselection. This work proposes a simple technique for addressing this issue: use\na data-efficient content selector to over-determine phrases in a source\ndocument that should be part of the summary. We use this selector as a\nbottom-up attention step to constrain the model to likely phrases. We show that\nthis approach improves the ability to compress text, while still generating\nfluent summaries. This two-step process is both simpler and higher performing\nthan other end-to-end content selection models, leading to significant\nimprovements on ROUGE for both the CNN-DM and NYT corpus. Furthermore, the\ncontent selector can be trained with as little as 1,000 sentences, making it\neasy to transfer a trained summarizer to a new domain.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 14:55:52 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2018 02:04:07 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Gehrmann", "Sebastian", ""], ["Deng", "Yuntian", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1808.10802", "submitter": "Stig-Arne Gr\\\"onroos", "authors": "Stig-Arne Gr\\\"onroos and Benoit Huet and Mikko Kurimo and Jorma\n  Laaksonen and Bernard Merialdo and Phu Pham and Mats Sj\\\"oberg and Umut\n  Sulubacak and J\\\"org Tiedemann and Raphael Troncy and Ra\\'ul V\\'azquez", "title": "The MeMAD Submission to the WMT18 Multimodal Translation Task", "comments": "To appear in WMT18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the MeMAD project entry to the WMT Multimodal Machine\nTranslation Shared Task.\n  We propose adapting the Transformer neural machine translation (NMT)\narchitecture to a multi-modal setting. In this paper, we also describe the\npreliminary experiments with text-only translation systems leading us up to\nthis choice.\n  We have the top scoring system for both English-to-German and\nEnglish-to-French, according to the automatic metrics for flickr18.\n  Our experiments show that the effect of the visual features in our system is\nsmall. Our largest gains come from the quality of the underlying text-only NMT\nsystem. We find that appropriate use of additional data is effective.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 15:14:59 GMT"}, {"version": "v2", "created": "Mon, 3 Sep 2018 10:47:50 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Gr\u00f6nroos", "Stig-Arne", ""], ["Huet", "Benoit", ""], ["Kurimo", "Mikko", ""], ["Laaksonen", "Jorma", ""], ["Merialdo", "Bernard", ""], ["Pham", "Phu", ""], ["Sj\u00f6berg", "Mats", ""], ["Sulubacak", "Umut", ""], ["Tiedemann", "J\u00f6rg", ""], ["Troncy", "Raphael", ""], ["V\u00e1zquez", "Ra\u00fal", ""]]}, {"id": "1808.10805", "submitter": "Jiacheng Xu", "authors": "Jiacheng Xu and Greg Durrett", "title": "Spherical Latent Spaces for Stable Variational Autoencoders", "comments": "To appear in EMNLP 2018; 11 pages; Code release:\n  https://github.com/jiacheng-xu/vmf_vae_nlp", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hallmark of variational autoencoders (VAEs) for text processing is their\ncombination of powerful encoder-decoder models, such as LSTMs, with simple\nlatent distributions, typically multivariate Gaussians. These models pose a\ndifficult optimization problem: there is an especially bad local optimum where\nthe variational posterior always equals the prior and the model does not use\nthe latent variable at all, a kind of \"collapse\" which is encouraged by the KL\ndivergence term of the objective. In this work, we experiment with another\nchoice of latent distribution, namely the von Mises-Fisher (vMF) distribution,\nwhich places mass on the surface of the unit hypersphere. With this choice of\nprior and posterior, the KL divergence term now only depends on the variance of\nthe vMF distribution, giving us the ability to treat it as a fixed\nhyperparameter. We show that doing so not only averts the KL collapse, but\nconsistently gives better likelihoods than Gaussians across a range of modeling\nconditions, including recurrent language modeling and bag-of-words document\nmodeling. An analysis of the properties of our vMF representations shows that\nthey learn richer and more nuanced structures in their latent representations\nthan their Gaussian counterparts.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 15:21:05 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 01:38:24 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Xu", "Jiacheng", ""], ["Durrett", "Greg", ""]]}]