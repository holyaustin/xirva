[{"id": "1002.0478", "submitter": "Odile Piton", "authors": "Odile Piton (SAMM), H\\'el\\`ene Pignot", "title": "\\'Etude et traitement automatique de l'anglais du XVIIe si\\`ecle :\n  outils morphosyntaxiques et dictionnaires", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we record the main linguistic differences or singularities\nof 17th century English, analyse them morphologically and syntactically and\npropose equivalent forms in contemporary English. We show how 17th century\ntexts may be transcribed into modern English, combining the use of electronic\ndictionaries with rules of transcription implemented as transducers. Apr\\`es\navoir expos\\'e la constitution du corpus, nous recensons les principales\ndiff\\'erences ou particularit\\'es linguistiques de la langue anglaise du XVIIe\nsi\\`ecle, les analysons du point de vue morphologique et syntaxique et\nproposons des \\'equivalents en anglais contemporain (AC). Nous montrons comment\nnous pouvons effectuer une transcription automatique de textes anglais du XVIIe\nsi\\`ecle en anglais moderne, en combinant l'utilisation de dictionnaires\n\\'electroniques avec des r\\`egles de transcriptions impl\\'ement\\'ees sous forme\nde transducteurs.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2010 13:23:47 GMT"}], "update_date": "2010-02-03", "authors_parsed": [["Piton", "Odile", "", "SAMM"], ["Pignot", "H\u00e9l\u00e8ne", ""]]}, {"id": "1002.0479", "submitter": "Odile Piton", "authors": "Odile Piton (SAMM), H\\'el\\`ene Pignot (SAMM)", "title": "\"Mind your p's and q's\": or the peregrinations of an apostrophe in 17th\n  Century English", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If the use of the apostrophe in contemporary English often marks the Saxon\ngenitive, it may also indicate the omission of one or more let-ters. Some\nwriters (wrongly?) use it to mark the plural in symbols or abbreviations,\nvisual-ised thanks to the isolation of the morpheme \"s\". This punctuation mark\nwas imported from the Continent in the 16th century. During the 19th century\nits use was standardised. However the rules of its usage still seem problematic\nto many, including literate speakers of English. \"All too often, the apostrophe\nis misplaced\", or \"errant apostrophes are springing up every-where\" is a\ncomplaint that Internet users fre-quently come across when visiting grammar\nwebsites. Many of them detail its various uses and misuses, and attempt to\ncorrect the most common mistakes about it, especially its mis-use in the\nplural, called greengrocers' apostro-phes and humorously misspelled\n\"greengro-cers apostrophe's\". While studying English travel accounts published\nin the seventeenth century, we noticed that the different uses of this symbol\nmay accompany various models of metaplasms. We were able to highlight the\nlinguistic variations of some lexemes, and trace the origin of modern grammar\nrules gov-erning its usage.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2010 13:24:20 GMT"}], "update_date": "2010-02-03", "authors_parsed": [["Piton", "Odile", "", "SAMM"], ["Pignot", "H\u00e9l\u00e8ne", "", "SAMM"]]}, {"id": "1002.0481", "submitter": "Odile Piton", "authors": "Abdelmajid Ben Hamadou (MIRACL), Odile Piton, H\\'ela Fehri (MIRACL)", "title": "Recognition and translation Arabic-French of Named Entities: case of the\n  Sport places", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recognition of Arabic Named Entities (NE) is a problem in different\ndomains of Natural Language Processing (NLP) like automatic translation.\nIndeed, NE translation allows the access to multilingual in-formation. This\ntranslation doesn't always lead to expected result especially when NE contains\na person name. For this reason and in order to ameliorate translation, we can\ntransliterate some part of NE. In this context, we propose a method that\nintegrates translation and transliteration together. We used the linguis-tic\nNooJ platform that is based on local grammars and transducers. In this paper,\nwe focus on sport domain. We will firstly suggest a refinement of the\ntypological model presented at the MUC Conferences we will describe the\nintegration of an Arabic transliteration module into translation system.\nFinally, we will detail our method and give the results of the evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2010 13:24:38 GMT"}, {"version": "v2", "created": "Mon, 31 May 2010 08:22:36 GMT"}], "update_date": "2010-07-28", "authors_parsed": [["Hamadou", "Abdelmajid Ben", "", "MIRACL"], ["Piton", "Odile", "", "MIRACL"], ["Fehri", "H\u00e9la", "", "MIRACL"]]}, {"id": "1002.0485", "submitter": "Odile Piton", "authors": "Odile Piton, Klara Lagji", "title": "Morphological study of Albanian words, and processing with NooJ", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are developing electronic dictionaries and transducers for the automatic\nprocessing of the Albanian Language. We will analyze the words inside a linear\nsegment of text. We will also study the relationship between units of sense and\nunits of form. The composition of words takes different forms in Albanian. We\nhave found that morphemes are frequently concatenated or simply juxtaposed or\ncontracted. The inflected grammar of NooJ allows constructing the dictionaries\nof flexed forms (declensions or conjugations). The diversity of word structures\nrequires tools to identify words created by simple concatenation, or to treat\ncontractions. The morphological tools of NooJ allow us to create grammatical\ntools to represent and treat these phenomena. But certain problems exceed the\nmorphological analysis and must be represented by syntactical grammars.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2010 13:35:02 GMT"}], "update_date": "2010-02-03", "authors_parsed": [["Piton", "Odile", ""], ["Lagji", "Klara", ""]]}, {"id": "1002.0773", "submitter": "Steven Wegmann", "authors": "Steven Wegmann", "title": "Approximations to the MMI criterion and their effect on lattice-based\n  MMI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum mutual information (MMI) is a model selection criterion used for\nhidden Markov model (HMM) parameter estimation that was developed more than\ntwenty years ago as a discriminative alternative to the maximum likelihood\ncriterion for HMM-based speech recognition. It has been shown in the speech\nrecognition literature that parameter estimation using the current MMI\nparadigm, lattice-based MMI, consistently outperforms maximum likelihood\nestimation, but this is at the expense of undesirable convergence properties.\nIn particular, recognition performance is sensitive to the number of times that\nthe iterative MMI estimation algorithm, extended Baum-Welch, is performed. In\nfact, too many iterations of extended Baum-Welch will lead to degraded\nperformance, despite the fact that the MMI criterion improves at each\niteration. This phenomenon is at variance with the analogous behavior of\nmaximum likelihood estimation -- at least for the HMMs used in speech\nrecognition -- and it has previously been attributed to `over fitting'. In this\npaper, we present an analysis of lattice-based MMI that demonstrates, first of\nall, that the asymptotic behavior of lattice-based MMI is much worse than was\npreviously understood, i.e. it does not appear to converge at all, and, second\nof all, that this is not due to `over fitting'. Instead, we demonstrate that\nthe `over fitting' phenomenon is the result of standard methodology that\nexacerbates the poor behavior of two key approximations in the lattice-based\nMMI machinery. We also demonstrate that if we modify the standard methodology\nto improve the validity of these approximations, then the convergence\nproperties of lattice-based MMI become benign without sacrificing improvements\nto recognition accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2010 16:06:24 GMT"}], "update_date": "2010-02-04", "authors_parsed": [["Wegmann", "Steven", ""]]}, {"id": "1002.0904", "submitter": "Serguei Mokhov", "authors": "Serguei A. Mokhov", "title": "On Event Structure in the Torn Dress", "comments": "17 pages; a 2003 report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using Pustejovsky's \"The Syntax of Event Structure\" and Fong's \"On Mending a\nTorn Dress\" we give a glimpse of a Pustejovsky-like analysis to some example\nsentences in Fong. We attempt to give a framework for semantics to the noun\nphrases and adverbs as appropriate as well as the lexical entries for all words\nin the examples and critique both papers in light of our findings and\ndifficulties.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2010 06:30:14 GMT"}], "update_date": "2010-02-05", "authors_parsed": [["Mokhov", "Serguei A.", ""]]}, {"id": "1002.1095", "submitter": "Serguei Mokhov", "authors": "Frank Rudzicz and Serguei A. Mokhov", "title": "Towards a Heuristic Categorization of Prepositional Phrases in English\n  with WordNet", "comments": "8 pages; 4 tables; 1 figure; a year 2003 report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document discusses an approach and its rudimentary realization towards\nautomatic classification of PPs; the topic, that has not received as much\nattention in NLP as NPs and VPs. The approach is a rule-based heuristics\noutlined in several levels of our research. There are 7 semantic categories of\nPPs considered in this document that we are able to classify from an annotated\ncorpus.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2010 22:48:31 GMT"}], "update_date": "2010-02-08", "authors_parsed": [["Rudzicz", "Frank", ""], ["Mokhov", "Serguei A.", ""]]}, {"id": "1002.1919", "submitter": "Rdv Ijcsis", "authors": "Somnuk Sinthupoun, Ohm Sornil", "title": "Thai Rhetorical Structure Analysis", "comments": "IEEE format, International Journal of Computer Science and\n  Information Security, IJCSIS January 2010, ISSN 1947 5500,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 7, No. 1, pp. 95-105, January 2010, USA", "doi": null, "report-no": "Journal of Computer Science, ISSN 1947 5500", "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rhetorical structure analysis (RSA) explores discourse relations among\nelementary discourse units (EDUs) in a text. It is very useful in many text\nprocessing tasks employing relationships among EDUs such as text understanding,\nsummarization, and question-answering. Thai language with its distinctive\nlinguistic characteristics requires a unique technique. This article proposes\nan approach for Thai rhetorical structure analysis. First, EDUs are segmented\nby two hidden Markov models derived from syntactic rules. A rhetorical\nstructure tree is constructed from a clustering technique with its similarity\nmeasure derived from Thai semantic rules. Then, a decision tree whose features\nderived from the semantic rules is used to determine discourse relations.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2010 20:01:06 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2010 05:04:16 GMT"}], "update_date": "2010-03-17", "authors_parsed": [["Sinthupoun", "Somnuk", ""], ["Sornil", "Ohm", ""]]}, {"id": "1002.2034", "submitter": "Christophe Roche", "authors": "Christophe Roche (LISTIC)", "title": "Dire n'est pas concevoir", "comments": "12 pages", "journal-ref": "Ing\\'enierie des Connaissances, Grenoble : France (2007)", "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The conceptual modelling built from text is rarely an ontology. As a matter\nof fact, such a conceptualization is corpus-dependent and does not offer the\nmain properties we expect from ontology. Furthermore, ontology extracted from\ntext in general does not match ontology defined by expert using a formal\nlanguage. It is not surprising since ontology is an extra-linguistic\nconceptualization whereas knowledge extracted from text is the concern of\ntextual linguistics. Incompleteness of text and using rhetorical figures, like\nellipsis, modify the perception of the conceptualization we may have.\nOntological knowledge, which is necessary for text understanding, is not in\ngeneral embedded into documents.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2010 07:45:57 GMT"}], "update_date": "2010-02-11", "authors_parsed": [["Roche", "Christophe", "", "LISTIC"]]}, {"id": "1002.3320", "submitter": "Ashley Smith", "authors": "Raungrong Suleesathira", "title": "Co-channel Interference Cancellation for Space-Time Coded OFDM Systems\n  Using Adaptive Beamforming and Null Deepening", "comments": "Journal of Telecommunications,Volume 1, Issue 1, pp6-13, February\n  2010", "journal-ref": "Raungrong Suleesathira, \"Co-channel Interference Cancellation for\n  Space-Time Coded OFDM Systems Using Adaptive Beamforming and Null Deepening\",\n  Journal of Telecommunications, Volume 1, Issue 1, pp6-13, February 2010", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combined with space-time coding, the orthogonal frequency division\nmultiplexing (OFDM) system explores space diversity. It is a potential scheme\nto offer spectral efficiency and robust high data rate transmissions over\nfrequency-selective fading channel. However, space-time coding impairs the\nsystem ability to suppress interferences as the signals transmitted from two\ntransmit antennas are superposed and interfered at the receiver antennas. In\nthis paper, we developed an adaptive beamforming based on least mean squared\nerror algorithm and null deepening to combat co-channel interference (CCI) for\nthe space-time coded OFDM (STC-OFDM) system. To illustrate the performance of\nthe presented approach, it is compared to the null steering beamformer which\nrequires a prior knowledge of directions of arrival (DOAs). The structure of\nspace-time decoders are preserved although there is the use of beamformers\nbefore decoding. By incorporating the proposed beamformer as a CCI canceller in\nthe STC-OFDM systems, the performance improvement is achieved as shown in the\nsimulation results.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2010 17:30:22 GMT"}], "update_date": "2010-02-18", "authors_parsed": [["Suleesathira", "Raungrong", ""]]}, {"id": "1002.4665", "submitter": "Jordan Boyd-Graber", "authors": "Jordan Boyd-Graber, David M. Blei", "title": "Syntactic Topic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The syntactic topic model (STM) is a Bayesian nonparametric model of language\nthat discovers latent distributions of words (topics) that are both\nsemantically and syntactically coherent. The STM models dependency parsed\ncorpora where sentences are grouped into documents. It assumes that each word\nis drawn from a latent topic chosen by combining document-level features and\nthe local syntactic context. Each document has a distribution over latent\ntopics, as in topic models, which provides the semantic consistency. Each\nelement in the dependency parse tree also has a distribution over the topics of\nits children, as in latent-state syntax models, which provides the syntactic\nconsistency. These distributions are convolved so that the topic of each word\nis likely under both its document and syntactic context. We derive a fast\nposterior inference algorithm based on variational methods. We report\nqualitative and quantitative studies on both synthetic data and hand-parsed\ndocuments. We show that the STM is a more predictive model of language than\ncurrent models based only on syntax or only on topics.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2010 00:00:47 GMT"}], "update_date": "2010-03-04", "authors_parsed": [["Boyd-Graber", "Jordan", ""], ["Blei", "David M.", ""]]}, {"id": "1002.4820", "submitter": "Yann Desalle", "authors": "Yann Desalle (CLLE, Lordat), Bruno Gaume (CLLE), Karine Duvignau\n  (CLLE, Erss)", "title": "SLAM : Solutions lexicales automatique pour m\\'etaphores", "comments": "30 pages", "journal-ref": "Traitement Automatique des Langues 50, 1 (2009) 145--175", "doi": null, "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents SLAM, an Automatic Solver for Lexical Metaphors like\n?d\\'eshabiller* une pomme? (to undress* an apple). SLAM calculates a\nconventional solution for these productions. To carry on it, SLAM has to\nintersect the paradigmatic axis of the metaphorical verb ?d\\'eshabiller*?,\nwhere ?peler? (?to peel?) comes closer, with a syntagmatic axis that comes from\na corpus where ?peler une pomme? (to peel an apple) is semantically and\nsyntactically regular. We test this model on DicoSyn, which is a ?small world?\nnetwork of synonyms, to compute the paradigmatic axis and on Frantext.20, a\nFrench corpus, to compute the syntagmatic axis. Further, we evaluate the model\nwith a sample of an experimental corpus of the database of Flexsem\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2010 16:27:36 GMT"}], "update_date": "2010-02-26", "authors_parsed": [["Desalle", "Yann", "", "CLLE, Lordat"], ["Gaume", "Bruno", "", "CLLE"], ["Duvignau", "Karine", "", "CLLE, Erss"]]}]