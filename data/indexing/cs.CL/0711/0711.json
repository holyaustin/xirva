[{"id": "0711.0666", "submitter": "Bouselmi Ghazi", "authors": "Ghazi Bouselmi (INRIA Lorraine - LORIA), Dominique Fohr (INRIA\n  Lorraine - LORIA), Irina Illina (INRIA Lorraine - LORIA), Jean-Paul Haton\n  (INRIA Lorraine - LORIA)", "title": "Discriminative Phoneme Sequences Extraction for Non-Native Speaker's\n  Origin Classification", "comments": null, "journal-ref": "Dans ISSPA, International Symposium on Signal Processing and its\n  Applications (2007)", "doi": null, "report-no": null, "categories": "cs.CL", "license": null, "abstract": "  In this paper we present an automated method for the classification of the\norigin of non-native speakers. The origin of non-native speakers could be\nidentified by a human listener based on the detection of typical pronunciations\nfor each nationality. Thus we suppose the existence of several phoneme\nsequences that might allow the classification of the origin of non-native\nspeakers. Our new method is based on the extraction of discriminative sequences\nof phonemes from a non-native English speech database. These sequences are used\nto construct a probabilistic classifier for the speakers' origin. The existence\nof discriminative phone sequences in non-native speech is a significant result\nof this work. The system that we have developed achieved a significant correct\nclassification rate of 96.3% and a significant error reduction compared to some\nother tested techniques.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2007 15:20:47 GMT"}], "update_date": "2007-11-06", "authors_parsed": [["Bouselmi", "Ghazi", "", "INRIA Lorraine - LORIA"], ["Fohr", "Dominique", "", "INRIA\n  Lorraine - LORIA"], ["Illina", "Irina", "", "INRIA Lorraine - LORIA"], ["Haton", "Jean-Paul", "", "INRIA Lorraine - LORIA"]]}, {"id": "0711.0811", "submitter": "Bouselmi Ghazi", "authors": "Ghazi Bouselmi (INRIA Lorraine - LORIA), Dominique Fohr (INRIA\n  Lorraine - LORIA), Irina Illina (INRIA Lorraine - LORIA)", "title": "Combined Acoustic and Pronunciation Modelling for Non-Native Speech\n  Recognition", "comments": null, "journal-ref": "Dans InterSpeech 2007 (2007)", "doi": null, "report-no": null, "categories": "cs.CL", "license": null, "abstract": "  In this paper, we present several adaptation methods for non-native speech\nrecognition. We have tested pronunciation modelling, MLLR and MAP non-native\npronunciation adaptation and HMM models retraining on the HIWIRE foreign\naccented English speech database. The ``phonetic confusion'' scheme we have\ndeveloped consists in associating to each spoken phone several sequences of\nconfused phones. In our experiments, we have used different combinations of\nacoustic models representing the canonical and the foreign pronunciations:\nspoken and native models, models adapted to the non-native accent with MAP and\nMLLR. The joint use of pronunciation modelling and acoustic adaptation led to\nfurther improvements in recognition accuracy. The best combination of the above\nmentioned techniques resulted in a relative word error reduction ranging from\n46% to 71%.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2007 08:23:49 GMT"}], "update_date": "2007-11-07", "authors_parsed": [["Bouselmi", "Ghazi", "", "INRIA Lorraine - LORIA"], ["Fohr", "Dominique", "", "INRIA\n  Lorraine - LORIA"], ["Illina", "Irina", "", "INRIA Lorraine - LORIA"]]}, {"id": "0711.1038", "submitter": "Bouselmi Ghazi", "authors": "Ghazi Bouselmi (INRIA Lorraine - LORIA), Dominique Fohr (INRIA\n  Lorraine - LORIA), Irina Illina (INRIA Lorraine - LORIA), Jean-Paul Haton\n  (INRIA Lorraine - LORIA)", "title": "Am\\'elioration des Performances des Syst\\`emes Automatiques de\n  Reconnaissance de la Parole pour la Parole Non Native", "comments": null, "journal-ref": "Dans TAIMA'07, Traitement et Analyse de l'Information : M\\'ethodes\n  et Applications (2007)", "doi": null, "report-no": null, "categories": "cs.CL", "license": null, "abstract": "  In this article, we present an approach for non native automatic speech\nrecognition (ASR). We propose two methods to adapt existing ASR systems to the\nnon-native accents. The first method is based on the modification of acoustic\nmodels through integration of acoustic models from the mother tong. The\nphonemes of the target language are pronounced in a similar manner to the\nnative language of speakers. We propose to combine the models of confused\nphonemes so that the ASR system could recognize both concurrent\npronounciations. The second method we propose is a refinment of the\npronounciation error detection through the introduction of graphemic\nconstraints. Indeed, non native speakers may rely on the writing of words in\ntheir uttering. Thus, the pronounctiation errors might depend on the characters\ncomposing the words. The average error rate reduction that we observed is\n(22.5%) relative for the sentence error rate, and 34.5% (relative) in word\nerror rate.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2007 08:51:09 GMT"}], "update_date": "2007-11-08", "authors_parsed": [["Bouselmi", "Ghazi", "", "INRIA Lorraine - LORIA"], ["Fohr", "Dominique", "", "INRIA\n  Lorraine - LORIA"], ["Illina", "Irina", "", "INRIA Lorraine - LORIA"], ["Haton", "Jean-Paul", "", "INRIA Lorraine - LORIA"]]}, {"id": "0711.1360", "submitter": "Damian H. Zanette", "authors": "Damian H. Zanette", "title": "Analytical approach to bit-string models of language evolution", "comments": "To appear in Int. J. Mod. Phys. C", "journal-ref": null, "doi": "10.1142/S0129183108012340", "report-no": null, "categories": "physics.soc-ph cs.CL", "license": null, "abstract": "  A formulation of bit-string models of language evolution, based on\ndifferential equations for the population speaking each language, is introduced\nand preliminarily studied. Connections with replicator dynamics and diffusion\nprocesses are pointed out. The stability of the dominance state, where most of\nthe population speaks a single language, is analyzed within a mean-field-like\napproximation, while the homogeneous state, where the population is evenly\ndistributed among languages, can be exactly studied. This analysis discloses\nthe existence of a bistability region, where dominance coexists with\nhomogeneity as possible asymptotic states. Numerical resolution of the\ndifferential system validates these findings.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2007 21:05:38 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Zanette", "Damian H.", ""]]}, {"id": "0711.2023", "submitter": "Peter Turney", "authors": "Peter D. Turney (National Research Council of Canada)", "title": "Empirical Evaluation of Four Tensor Decomposition Algorithms", "comments": "related work available at http://purl.org/peter.turney/", "journal-ref": null, "doi": null, "report-no": "ERB-1152, NRC-49877", "categories": "cs.LG cs.CL cs.IR", "license": null, "abstract": "  Higher-order tensor decompositions are analogous to the familiar Singular\nValue Decomposition (SVD), but they transcend the limitations of matrices\n(second-order tensors). SVD is a powerful tool that has achieved impressive\nresults in information retrieval, collaborative filtering, computational\nlinguistics, computational vision, and other fields. However, SVD is limited to\ntwo-dimensional arrays of data (two modes), and many potential applications\nhave three or more modes, which require higher-order tensor decompositions.\nThis paper evaluates four algorithms for higher-order tensor decomposition:\nHigher-Order Singular Value Decomposition (HO-SVD), Higher-Order Orthogonal\nIteration (HOOI), Slice Projection (SP), and Multislice Projection (MP). We\nmeasure the time (elapsed run time), space (RAM and disk space requirements),\nand fit (tensor reconstruction accuracy) of the four algorithms, under a\nvariety of conditions. We find that standard implementations of HO-SVD and HOOI\ndo not scale up to larger tensors, due to increasing RAM requirements. We\nrecommend HOOI for tensors that are small enough for the available RAM and MP\nfor larger tensors.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2007 16:28:47 GMT"}], "update_date": "2007-11-14", "authors_parsed": [["Turney", "Peter D.", "", "National Research Council of Canada"]]}, {"id": "0711.2270", "submitter": "Igor M. Suslov", "authors": "I. M. Suslov (P.L.Kapitza Institute for Physical Problems, Moscow,\n  Russia)", "title": "Can a Computer Laugh ?", "comments": "English translation of the paper in Russian; 18 pages, 6 figures\n  included", "journal-ref": "Computer Chronicle (Moscow), 1994, issue 1, p.1", "doi": null, "report-no": null, "categories": "cs.CL cs.AI q-bio.NC", "license": null, "abstract": "  A computer model of \"a sense of humour\" suggested previously\n[arXiv:0711.2058,0711.2061], relating the humorous effect with a specific\nmalfunction in information processing, is given in somewhat different\nexposition. Psychological aspects of humour are elaborated more thoroughly. The\nmechanism of laughter is formulated on the more general level. Detailed\ndiscussion is presented for the higher levels of information processing, which\nare responsible for a perception of complex samples of humour. Development of a\nsense of humour in the process of evolution is discussed.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2007 18:32:09 GMT"}], "update_date": "2007-11-27", "authors_parsed": [["Suslov", "I. M.", "", "P.L.Kapitza Institute for Physical Problems, Moscow,\n  Russia"]]}, {"id": "0711.2444", "submitter": "Richard Moot", "authors": "Richard Moot (INRIA Futurs, Labri)", "title": "Proof nets for display logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL", "license": null, "abstract": "  This paper explores several extensions of proof nets for the Lambek calculus\nin order to handle the different connectives of display logic in a natural way.\nThe new proof net calculus handles some recent additions to the Lambek\nvocabulary such as Galois connections and Grishin interactions. It concludes\nwith an exploration of the generative capacity of the Lambek-Grishin calculus,\npresenting an embedding of lexicalized tree adjoining grammars into the\nLambek-Grishin calculus.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2007 15:39:48 GMT"}], "update_date": "2007-11-16", "authors_parsed": [["Moot", "Richard", "", "INRIA Futurs, Labri"]]}, {"id": "0711.3197", "submitter": "Igor M. Suslov", "authors": "I. M. Suslov (P.L.Kapitza Institute for Physical Problems, Moscow,\n  Russia)", "title": "How to realize \"a sense of humour\" in computers ?", "comments": "14 pages, 6 figures included", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI q-bio.NC", "license": null, "abstract": "  Computer model of a \"sense of humour\" suggested previously [arXiv:0711.2058,\n0711.2061, 0711.2270] is raised to the level of a realistic algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2007 19:57:23 GMT"}], "update_date": "2007-11-27", "authors_parsed": [["Suslov", "I. M.", "", "P.L.Kapitza Institute for Physical Problems, Moscow,\n  Russia"]]}, {"id": "0711.3412", "submitter": "Eric Laporte", "authors": "Ivan Berlocher, Hyun-Gue Huh (IGM-LabInfo), Eric Laporte\n  (IGM-LabInfo), Jee-Sun Nam", "title": "Morphological annotation of Korean with Directly Maintainable Resources", "comments": null, "journal-ref": "Dans Proceedings of the Language Resource and Evaluation\n  Consference (LREC) - Morphological annotation of Korean with Directly\n  Maintainable Resources, Genoa : Italie (2006)", "doi": null, "report-no": null, "categories": "cs.CL", "license": null, "abstract": "  This article describes an exclusively resource-based method of morphological\nannotation of written Korean text. Korean is an agglutinative language. Our\nannotator is designed to process text before the operation of a syntactic\nparser. In its present state, it annotates one-stem words only. The output is a\ngraph of morphemes annotated with accurate linguistic information. The\ngranularity of the tagset is 3 to 5 times higher than usual tagsets. A\ncomparison with a reference annotated corpus showed that it achieves 89% recall\nwithout any corpus training. The language resources used by the system are\nlexicons of stems, transducers of suffixes and transducers of generation of\nallomorphs. All can be easily updated, which allows users to control the\nevolution of the performances of the system. It has been claimed that\nmorphological annotation of Korean text could only be performed by a\nmorphological analysis module accessing a lexicon of morphemes. We show that it\ncan also be performed directly with a lexicon of words and without applying\nmorphological rules at annotation time, which speeds up annotation to 1,210\nword/s. The lexicon of words is obtained from the maintainable language\nresources through a fully automated compilation process.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2007 16:47:57 GMT"}], "update_date": "2007-11-22", "authors_parsed": [["Berlocher", "Ivan", "", "IGM-LabInfo"], ["Huh", "Hyun-Gue", "", "IGM-LabInfo"], ["Laporte", "Eric", "", "IGM-LabInfo"], ["Nam", "Jee-Sun", ""]]}, {"id": "0711.3449", "submitter": "Eric Laporte", "authors": "Eric Laporte (IGM-LabInfo)", "title": "Lexicon management and standard formats", "comments": null, "journal-ref": "Archives of Control Sciences 15, 3 (2005) 329-340", "doi": null, "report-no": null, "categories": "cs.CL", "license": null, "abstract": "  International standards for lexicon formats are in preparation. To a certain\nextent, the proposed formats converge with prior results of standardization\nprojects. However, their adequacy for (i) lexicon management and (ii)\nlexicon-driven applications have been little debated in the past, nor are they\nas a part of the present standardization effort. We examine these issues. IGM\nhas developed XML formats compatible with the emerging international standards,\nand we report experimental results on large-coverage lexica.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2007 20:34:08 GMT"}], "update_date": "2007-11-22", "authors_parsed": [["Laporte", "Eric", "", "IGM-LabInfo"]]}, {"id": "0711.3452", "submitter": "Eric Laporte", "authors": "Eric Laporte (IGM-LabInfo)", "title": "In memoriam Maurice Gross", "comments": "8 pages", "journal-ref": "Archives of Control Sciences 15, 3 (2005) 257-278", "doi": null, "report-no": null, "categories": "cs.CL", "license": null, "abstract": "  Maurice Gross (1934-2001) was both a great linguist and a pioneer in natural\nlanguage processing. This article is written in homage to his memory\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2007 20:38:29 GMT"}], "update_date": "2007-11-22", "authors_parsed": [["Laporte", "Eric", "", "IGM-LabInfo"]]}, {"id": "0711.3453", "submitter": "Eric Laporte", "authors": "Hyun-Gue Huh (IGM-LabInfo), Eric Laporte (IGM-LabInfo)", "title": "A resource-based Korean morphological annotation system", "comments": "6 pages", "journal-ref": "Dans Proceedings of the International Joint Conference on Natural\n  Language Processing (IJCNLP) - A resource-based Korean morphological\n  annotation system, Jeju : Cor\\'ee, R\\'epublique de (2005)", "doi": null, "report-no": null, "categories": "cs.CL", "license": null, "abstract": "  We describe a resource-based method of morphological annotation of written\nKorean text. Korean is an agglutinative language. The output of our system is a\ngraph of morphemes annotated with accurate linguistic information. The language\nresources used by the system can be easily updated, which allows us-ers to\ncontrol the evolution of the per-formances of the system. We show that\nmorphological annotation of Korean text can be performed directly with a\nlexicon of words and without morpho-logical rules.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2007 20:41:59 GMT"}], "update_date": "2007-11-22", "authors_parsed": [["Huh", "Hyun-Gue", "", "IGM-LabInfo"], ["Laporte", "Eric", "", "IGM-LabInfo"]]}, {"id": "0711.3454", "submitter": "Eric Laporte", "authors": "Eric Laporte (IGM-LabInfo), S\\'ebastien Paumier (IGM-LabInfo)", "title": "Graphes param\\'etr\\'es et outils de lexicalisation", "comments": null, "journal-ref": "Dans Verbum ex machina. Proceedings of TALN - Graphes\n  param\\'etr\\'es et outils de lexicalisation, Louvain : Belgique (2006)", "doi": null, "report-no": null, "categories": "cs.CL", "license": null, "abstract": "  Shifting to a lexicalized grammar reduces the number of parsing errors and\nimproves application results. However, such an operation affects a syntactic\nparser in all its aspects. One of our research objectives is to design a\nrealistic model for grammar lexicalization. We carried out experiments for\nwhich we used a grammar with a very simple content and formalism, and a very\ninformative syntactic lexicon, the lexicon-grammar of French elaborated by the\nLADL. Lexicalization was performed by applying the parameterized-graph\napproach. Our results tend to show that most information in the lexicon-grammar\ncan be transferred into a grammar and exploited successfully for the syntactic\nparsing of sentences.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2007 20:44:04 GMT"}], "update_date": "2007-11-22", "authors_parsed": [["Laporte", "Eric", "", "IGM-LabInfo"], ["Paumier", "S\u00e9bastien", "", "IGM-LabInfo"]]}, {"id": "0711.3457", "submitter": "Eric Laporte", "authors": "Eric Laporte (IGM-LabInfo)", "title": "Evaluation of a Grammar of French Determiners", "comments": "10 pages", "journal-ref": "Dans Annals of the 27th Congress of the Brazilian Society of\n  Computation - Evaluation of a Grammar of French Determiners, Rio de Janeiro :\n  Br\\'esil (2007)", "doi": null, "report-no": null, "categories": "cs.CL", "license": null, "abstract": "  Existing syntactic grammars of natural languages, even with a far from\ncomplete coverage, are complex objects. Assessments of the quality of parts of\nsuch grammars are useful for the validation of their construction. We evaluated\nthe quality of a grammar of French determiners that takes the form of a\nrecursive transition network. The result of the application of this local\ngrammar gives deeper syntactic information than chunking or information\navailable in treebanks. We performed the evaluation by comparison with a corpus\nindependently annotated with information on determiners. We obtained 86%\nprecision and 92% recall on text not tagged for parts of speech.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2007 20:49:21 GMT"}], "update_date": "2007-11-22", "authors_parsed": [["Laporte", "Eric", "", "IGM-LabInfo"]]}, {"id": "0711.3605", "submitter": "Eric Laporte", "authors": "Eric Laporte (IGM-LabInfo), Christian Lecl\\`ere (IGM-LabInfo), Maria\n  Carmelita P. Dias", "title": "Very strict selectional restrictions", "comments": null, "journal-ref": "Dans Proceedings - Very strict selectional restrictions. A\n  Comparison between Portuguese and French, Itatiaia : Br\\'esil (2006)", "doi": null, "report-no": null, "categories": "cs.CL", "license": null, "abstract": "  We discuss the characteristics and behaviour of two parallel classes of verbs\nin two Romance languages, French and Portuguese. Examples of these verbs are\nPort. abater [gado] and Fr. abattre [b\\'etail], both meaning \"slaughter\n[cattle]\". In both languages, the definition of the class of verbs includes\nseveral features: - They have only one essential complement, which is a direct\nobject. - The nominal distribution of the complement is very limited, i.e., few\nnouns can be selected as head nouns of the complement. However, this selection\nis not restricted to a single noun, as would be the case for verbal idioms such\nas Fr. monter la garde \"mount guard\". - We excluded from the class\nconstructions which are reductions of more complex constructions, e.g. Port.\nafinar [instrumento] com \"tune [instrument] with\".\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2007 15:54:31 GMT"}], "update_date": "2007-11-26", "authors_parsed": [["Laporte", "Eric", "", "IGM-LabInfo"], ["Lecl\u00e8re", "Christian", "", "IGM-LabInfo"], ["Dias", "Maria Carmelita P.", ""]]}, {"id": "0711.3691", "submitter": "Eric Laporte", "authors": "Olivier Blanc (IGM-LabInfo), Matthieu Constant (IGM-LabInfo), Eric\n  Laporte (IGM-LabInfo)", "title": "Outilex, plate-forme logicielle de traitement de textes \\'ecrits", "comments": null, "journal-ref": "Dans Verbum ex machina. Proceedings of TALN - Outilex, plate-forme\n  logicielle de traitement de textes \\'ecrits, Louvain : Belgique (2006)", "doi": null, "report-no": null, "categories": "cs.CL", "license": null, "abstract": "  The Outilex software platform, which will be made available to research,\ndevelopment and industry, comprises software components implementing all the\nfundamental operations of written text processing: processing without lexicons,\nexploitation of lexicons and grammars, language resource management. All data\nare structured in XML formats, and also in more compact formats, either\nreadable or binary, whenever necessary; the required format converters are\nincluded in the platform; the grammar formats allow for combining statistical\napproaches with resource-based approaches. Manually constructed lexicons for\nFrench and English, originating from the LADL, and of substantial coverage,\nwill be distributed with the platform under LGPL-LR license.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2007 09:45:13 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2007 10:22:14 GMT"}], "update_date": "2007-11-27", "authors_parsed": [["Blanc", "Olivier", "", "IGM-LabInfo"], ["Constant", "Matthieu", "", "IGM-LabInfo"], ["Laporte", "Eric", "", "IGM-LabInfo"]]}, {"id": "0711.3726", "submitter": "Stergos Afantenos", "authors": "Michael Zock and Stergos D. Afantenos", "title": "Let's get the student into the driver's seat", "comments": "6 pages", "journal-ref": "The Seventh International Symposium on Natural Language Processing\n  (SNLP 2007). Chonburi, Thailand", "doi": null, "report-no": null, "categories": "cs.CL", "license": null, "abstract": "  Speaking a language and achieving proficiency in another one is a highly\ncomplex process which requires the acquisition of various kinds of knowledge\nand skills, like the learning of words, rules and patterns and their connection\nto communicative goals (intentions), the usual starting point. To help the\nlearner to acquire these skills we propose an enhanced, electronic version of\nan age old method: pattern drills (henceforth PDs). While being highly regarded\nin the fifties, PDs have become unpopular since then, partially because of\ntheir lack of grounding (natural context) and rigidity. Despite these\nshortcomings we do believe in the virtues of this approach, at least with\nregard to the acquisition of basic linguistic reflexes or skills (automatisms),\nnecessary to survive in the new language. Of course, the method needs\nimprovement, and we will show here how this can be achieved. Unlike tapes or\nbooks, computers are open media, allowing for dynamic changes, taking users'\nperformances and preferences into account. Building an electronic version of\nPDs amounts to building an open resource, accomodatable to the users' ever\nchanging needs.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2007 13:44:55 GMT"}], "update_date": "2007-11-26", "authors_parsed": [["Zock", "Michael", ""], ["Afantenos", "Stergos D.", ""]]}, {"id": "0711.4475", "submitter": "{\\L}ukasz D{\\ke}bowski", "authors": "{\\L}ukasz D\\k{e}bowski", "title": "Valence extraction using EM selection and co-occurrence matrices", "comments": "24 pages, 3 tables", "journal-ref": "Language Resources and Evaluation 43:301-327, 2009", "doi": "10.1007/s10579-009-9100-5", "report-no": null, "categories": "cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses two new procedures for extracting verb valences from raw\ntexts, with an application to the Polish language. The first novel technique,\nthe EM selection algorithm, performs unsupervised disambiguation of valence\nframe forests, obtained by applying a non-probabilistic deep grammar parser and\nsome post-processing to the text. The second new idea concerns filtering of\nincorrect frames detected in the parsed text and is motivated by an observation\nthat verbs which take similar arguments tend to have similar frames. This\nphenomenon is described in terms of newly introduced co-occurrence matrices.\nUsing co-occurrence matrices, we split filtering into two steps. The list of\nvalid arguments is first determined for each verb, whereas the pattern\naccording to which the arguments are combined into frames is computed in the\nfollowing stage. Our best extracted dictionary reaches an $F$-score of 45%,\ncompared to an $F$-score of 39% for the standard frame-based BHT filtering.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2007 12:16:08 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2007 12:53:25 GMT"}, {"version": "v3", "created": "Fri, 11 Jul 2008 13:15:45 GMT"}, {"version": "v4", "created": "Wed, 10 Dec 2008 19:14:24 GMT"}, {"version": "v5", "created": "Wed, 29 Jul 2009 12:12:37 GMT"}, {"version": "v6", "created": "Fri, 27 Nov 2009 17:53:24 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["D\u0119bowski", "\u0141ukasz", ""]]}]